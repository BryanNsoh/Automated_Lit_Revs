- analysis: '>'
  authors:
  - Akbari M.
  - Syed A.
  - Kennedy W.S.
  - Erol-Kantarci M.
  citation_count: '0'
  description: In the midst of rising global population and environmental challenges,
    smart agriculture emerges as a vital solution by integrating advanced technologies
    to optimize agricultural practices. Through data-driven insights and automation,
    it tackles the necessity for sustainable resource management, enhancing productivity
    and resilience in the face of complex food security and ecological concerns. The
    prospects of utilizing the Internet of Things (IoT) for smart agriculture are
    tremendous, where many IoT devices can be deployed for local environment monitoring,
    precision farming, autonomous irrigation, and, soil management. In some use cases
    like smart monitoring and agrochemical applications, UAV-enabled mobile-edge computing
    (MEC) is proposed as an enabler to provide IoT nodes with additional resources
    by hosting their computation functions. From the implementation perspective, to
    flexibly manage the computation functions in UAVs and/or MEC server, the emerging
    network function virtualization (NFV) can be utilized. However, efficient orchestration
    of the virtualized functions would be a challenge. In this paper, we consider
    a decentralized UAV-aided MEC system for smart agricultural applications in which
    the processing nodes benefit from the NFV technology. We aim to propose a method
    for efficiently orchestrating the NFVs while some important metrics are minimized,
    i.e., the age of information (AoI) and total network energy consumption. Especially,
    we consider the case in which the network state is not fully observable to the
    orchestrator or the observations are exposed to uncertainties. Consequently, the
    problem is formulated as a decentralized partially observable Markov decision
    process (DEC-POMDP). As the formulated problem is NP-complete, we exploit some
    structural features of the proposed scheme to introduce the concept of symmetry
    and simplify the problem. Then, a novel decentralized federated learning-based
    solution is proposed to solve the problem. Simulation results show the effectiveness
    of the proposed approach in minimizing the total network energy consumption and
    achieving AoI values less than 200:msec to support demanding real-time applications.
  doi: 10.1109/OJCOMS.2024.3363132
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Open Journal of the Comm...
    >Volume: 5 AoI-Aware Energy-Efficient SFC in UAV-Aided Smart Agriculture Using
    Asynchronous Federated Learning Publisher: IEEE Cite This PDF Mohammad Akbari;
    Aisha Syed; W. Sean Kennedy; Melike Erol-Kantarci All Authors 79 Full Text Views
    Open Access Under a Creative Commons License Abstract Document Sections I. Introduction
    II. Related Works III. System Model IV. Problem Formulation V. DEC-POMDP Formulation
    Show Full Outline Authors Figures References Keywords Metrics Footnotes Abstract:
    In the midst of rising global population and environmental challenges, smart agriculture
    emerges as a vital solution by integrating advanced technologies to optimize agricultural
    practices. Through data-driven insights and automation, it tackles the necessity
    for sustainable resource management, enhancing productivity and resilience in
    the face of complex food security and ecological concerns. The prospects of utilizing
    the Internet of Things (IoT) for smart agriculture are tremendous, where many
    IoT devices can be deployed for local environment monitoring, precision farming,
    autonomous irrigation, and, soil management. In some use cases like smart monitoring
    and agrochemical applications, UAV-enabled mobile-edge computing (MEC) is proposed
    as an enabler to provide IoT nodes with additional resources by hosting their
    computation functions. From the implementation perspective, to flexibly manage
    the computation functions in UAVs and/or MEC server, the emerging network function
    virtualization (NFV) can be utilized. However, efficient orchestration of the
    virtualized functions would be a challenge. In this paper, we consider a decentralized
    UAV-aided MEC system for smart agricultural applications in which the processing
    nodes benefit from the NFV technology. We aim to propose a method for efficiently
    orchestrating the NFVs while some important metrics are minimized, i.e., the age
    of information (AoI) and total network energy consumption. Especially, we consider
    the case in which the network state is not fully observable to the orchestrator
    or the observations are exposed to uncertainties. Consequently, the problem is
    formulated as a decentralized partially observable Markov decision process (DEC-POMDP).
    As the formulated problem is NP-complete, we exploit some structural features
    of the proposed scheme to introduce the concept of symmetry and simplify the problem.
    Then, a novel decentralized federated learning-based solution is proposed to solve
    the problem. Simulation... (Show More) Published in: IEEE Open Journal of the
    Communications Society ( Volume: 5) Page(s): 1222 - 1242 Date of Publication:
    07 February 2024 Electronic ISSN: 2644-125X DOI: 10.1109/OJCOMS.2024.3363132 Publisher:
    IEEE Funding Agency: SECTION I. Introduction Smart farming in the contemporary
    world has gained paramount importance while playing a pivotal role in revolutionizing
    agricultural practices [1]. Conversely, the increasing global population along
    with environmental challenges have made the adoption of smart farming techniques
    indispensable. By leveraging data-driven insights, automation, and precision agriculture,
    smart farming not only enhances productivity but also addresses the pressing need
    for sustainable resource management [2]. On the other hand, the Internet of Things
    (IoT) has been a promising technology to provide connection among a large volume
    of devices that are deployed to provide a specific service for smart agriculture.
    A wide range of different use cases such as smart greenhouse monitoring, pest
    control, and irrigation/soil management can be considered [1], [3]. These use
    cases are mostly computation intensive and delay-sensitive [1], [4], [5]. A large
    volume of connected devices implies a large volume of data that must be processed
    accurately in a timely manner [6]. Such data computation and analysis demands
    a significant amount of processing and storage resources which put a constraint
    on energy-limited IoT devices. Depending on the specific application, the aggregated
    data from monitoring sensors, and captured images/videos from installed cameras
    in the field need to be processed in real-time to turn raw data into usable information.
    Introducing IoT and its applications in modern agriculture provides this industry
    with suitable tools to support farmers for better productivity, quality, and profitability
    [1]. Therefore, the scope of IoT extends beyond just agricultural land, encompassing
    a broader spectrum that includes the supply chain as well [7], [8]. Battery-operated
    IoT devices lack the capability to perform energy-intensive computations independently.
    Additionally, they face challenges related to limited processing power and storage
    capacity [9]. Therefore, MEC is proposed as a promising technology to address
    these limitations by offering additional computation and storage resources for
    IoT systems. This is achieved by providing servers where IoT devices can offload
    their computation tasks [10], [11]. On the other hand, large-scale agricultural
    operations often involve the distribution of IoT devices across expansive areas.
    In such scenarios, challenges may emerge concerning communication, particularly
    with issues related to the limited reachability between IoT devices and MEC infrastructure.
    To address these challenges, a proposed solution involves the integration of a
    network comprising unmanned aerial vehicles (UAVs) to enhance the capabilities
    of MEC [12], [13]. This approach aims to mitigate communication limitations stemming
    from the constrained transmission power of IoT devices and simultaneously improve
    network coverage. Due to the easy-to-deploy, cost-effective, and strong capabilities
    of the UAVs, UAV-aided MEC has attracted much attention and is widely utilized
    in smart agriculture to provide a high-quality line-of-sight (LoS) link to IoT
    devices [1], [3], [5], [14], [15], [16], [17]. The versatility and mobility exhibited
    by UAVs in response to changing weather conditions, alongside their straightforward
    deployment and economically viable maintenance costs, collectively establish UAVs
    as a proficient solution for supplying IoT devices with the necessary resources.
    Nevertheless, the UAVs themselves are quite often battery-powered which means
    their available energy is limited [6]. 1) Age of Information Besides energy, the
    freshness of information is another important aspect that needs to be considered
    in environmental monitoring and smart agriculture applications in which rapid
    protective and/or recovery actions are needed. Being more specific, within the
    realm of environmental monitoring applications and precision farming [18] in a
    UAV-aided MEC network, the IoT devices are strategically dispersed throughout
    specified regions to seamlessly gather real-time environmental data. Then the
    collected and pre-processed data by the UAVs finds its transmission route toward
    a localized MEC server; where a comprehensive analysis is conducted to facilitate
    the extraction of pertinent insights. These insights, in turn, play a pivotal
    role in fostering prompt agricultural decision-making and actions. The objectives
    can be the refinement of operations, the performance optimization, or the reduction
    of expenditure [1], [14], [19]. This expansion of smart agriculture’s scope ensures
    a secure and sustainable food supply chain, underpinned by contextual and situational
    awareness derived from real-time event processing [20]. Accordingly, such applications
    are characterized by their intensive computational demands and time-sensitive
    nature [1], [3], [5], [14], [18]. Concisely, the freshness of information becomes
    a critical factor that demands careful consideration. Packet delay and inter-delivery
    times, as two exemplary metrics that are commonly used to quantify the performance
    of real-time applications, are not adequate to represent the freshness of information
    received at the destination. Recently, age of information (AoI) has been proposed
    as a novel criterion to quantitatively evaluate the freshness of information [6],
    [17], [21]. For a flow of data packets, and with emphasis on the freshness of
    data at the destination, AoI is defined as the time elapsed from receiving the
    most recent packet belonging to that data-packet flow [22], [23]. 2) Network Function
    Virtualization (NFV) From the above discussion, in the context of UAV-enabled
    smart agriculture paradigm – which constitutes the focal point of this paper –
    UAVs are confronted with a substantial amount of data necessitating prompt processing.
    This scenario embodies a dynamic computational framework wherein a bunch of processing
    functions demands seamless implementation across both the UAVs and the local server
    [20], [24], [25]. NFV is a key technology for implementing and managing computing
    machines in a reliable, efficient, and robust manner [26]. The NFV virtualizes
    the network functions (NFs) and abstracts them from the physical hardware, which
    enables rapid service function chaining (SFC) and service provisioning in UAV-aided
    MEC applications [27]. Considering the data-intensive and computation-based application
    of smart agriculture, multiple computing functions in the form of virtual network
    functions (VNF) should be deployed sequentially and orderly to provide the processed
    data for the final decision-making at the local MEC-server. Utilizing NFV significantly
    enhances the agility in deploying and managing network components and improves
    the robustness and scalability of networks [27], [28]. Therefore, a critical challenge
    to address is the optimal and efficient placement of Virtual Network Functions
    (VNFs) and determining how to route information packets among VNF components over
    the available NFV infrastructure, i.e., UAVs and the MEC server. The decision
    to distribute and allocate VNFs between both UAVs and the server, rather than
    solely on one of them, aligns with the primary goal of the proposed scheme—to
    minimize the Age of Information (AoI) while maintaining energy efficiency. Network
    traffic and the workload on both UAVs and MEC servers fluctuate over time, while
    changing channel conditions between the parties necessitate adjustments in the
    required communication resources for packet forwarding. Furthermore, certain processing
    functions, such as compression, may alter the packet size, so the trade-off of
    performing these functions locally and sending the smaller packets with spending
    fewer communication resources versus doing the entire processing locally becomes
    pivotal. Consequently, the placement must dynamically adjust to new conditions
    to ensure the minimization of AoI and energy efficiency [28]. In light of this,
    a general condition has been considered where the VNFO can, depending on network
    conditions (processing node resources, service type, and channel conditions),
    decide on the optimal placement to minimize AoI and energy consumption. The work
    presented in [24] is a use-case of the practical implementation of smart agriculture
    in real-world contexts; where, the authors leverage a confluence of cloud computing,
    edge computing, and NFV technology to conceive a comprehensive framework tailored
    to the essential demands of soilless precision farming practiced within a fully-recirculating
    greenhouse [24]. 3) Federated Reinforcement Learning (FRL) The VNF placement and
    scheduling in our network settings can be expressed as integer programming with
    some constraints that reflect the service requirements and the network infrastructure’s
    restrictions. Nevertheless, this problem is NP-complete and there is no standard
    solver that can solve such problems in polynomial time [29], especially for large-scale
    networks where the required computation to find the optimal solution increases
    exponentially. Recently, machine learning algorithms and artificial intelligent
    (AI) based solutions appear as a viable way to solve such complex problems in
    polynomial time [17], [29], [30]. Since its inception in 2017 [31], Federated
    Learning (FL) has reshaped many emerging intelligent IoT systems toward advanced
    FL architecture. The distributed nature of FL, where some agents cooperatively
    train a global ML model without directly sharing the local data, makes FL an attractive
    alternative to traditional centralized ML schemes. To be more specific, FL by
    pushing intelligent ML functions to the network edge enhances the privacy and
    scalability of IoT applications and networks [30]. In this paper, our focus is
    on use cases in smart agriculture that require live streaming and analysis, such
    as surveillance and environmental monitoring. Specifically, we address the flexible
    dynamic orchestration of NFV-enabled SFCs within the context of delay-sensitive
    services. The approach involves distributing VNFs across processing nodes, utilizing
    UAVs and local MEC server in a UAV-aided MEC network. The objective is to perform
    SFC while ensuring the freshness of information by jointly minimizing AoI and
    total energy consumption throughout the network. Condensing the system model and
    the definition of the problem, we present the following key insights: In the realm
    of smart agriculture applications, real-time information is collected by IoT devices
    on a smart farm and transmitted through hovering UAVs to the local server. VNFs
    must be executed sequentially on the raw packets, as they represent split functionalities
    of a single processing job. Meanwhile, certain VNFs, such as compression, may
    potentially alter packet sizes. Various service types are assumed, each with its
    specific VNF chain. The challenge involves determining the optimal placement and
    scheduling of VNF chains on processing nodes (UAVs and the local server), accounting
    for processing time, transmission delay, and power consumption (both transmit
    and processing power) in a distributed manner. We will demonstrate analytically
    that the problem: Exhibits circular symmetry, wherein the optimal policies of
    the agents (UAVs) are identical. The local observations of the agents serve as
    sufficient statistics for determining the optimal policy, We will show how these
    two features will simplify the problem significantly. Subsequently, we present
    a novel solution for solving the modeled problem. The main contributions of our
    paper are summarized as follows: To the best of our knowledge this is the first
    time that the problem of dynamic orchestration of NFV-enabled SFCs in a multi-hop
    UAV-aided MEC network for smart agriculture is considered, while the problem is
    formulated as a joint AoI and Energy minimization. We formulate this joint optimization
    problem as a decentralized partially observable MDP (DEC-POMDP), where the parties
    are not aware of the true state and just make decisions based on their local observations.
    We adopted the structural feature of the problem and have analytically shown that
    under the satisfaction of certain symmetry conditions, the local observation of
    the parties (agents) would be a sufficient statistic for determining the optimal
    solution. As the formulated problem is NP-complete, we proposed a novel FL-based
    algorithm called Asynchronous FL Deep Q-Network (AFDQN) in which a set of distributed
    parties learn in parallel and aggregate their own experience through a coordinator.
    A Multi-hop network is considered, where the UAVs can offload their computing
    tasks to the other UAVs as well as the local MEC server. The rest of the paper
    is organized as follows: In Section II some state-of-the-art studies will be reviewed.
    Section III describes the system model and the main components of the system in
    detail. Section IV presents the problem definition and formulation. In Section
    V, the problem is expressed as a DEC-POMDP, and some analytical results are given
    that support our proposed FL-based solution presented in Section VI. The complexity
    analysis of the proposed algorithm is presented in Section VII. The effectiveness
    and performance of the proposed scheme is demonstrated in Section VIII. Finally,
    Section IX concludes the paper. SECTION II. Related Works In this section, we
    review some state-of-the-art studies on AoI and energy-aware UAV-aided MEC for
    smart agriculture. The prospects of using UAVs for smart agriculture are immense.
    Moreover, UAVs are easy to deploy and cost-effective which motivates their use
    in smart agriculture [1], [6], [32]. For a comprehensive survey on IoT-based smart
    agriculture and the emerging technologies mentioned in the previous section refer
    to [1]. In [13], Mozaffari et al. have considered the reliable design of IoT’s
    uplink communication in a scenario in which multiple UAVs are deployed to collect
    data from ground IoT devices. In particular, a framework for jointly optimizing
    the trajectory of the UAVs, IoT-to-UAV association, and IoT’s uplink power is
    proposed with the aim of minimizing the total energy consumption and mobility
    of the UAVs. However, in the formulated problem, the delay of the forwarded data
    across the UAV network is not considered. Nguyen et al. [5] have considered this
    issue as the problem of processing deadline-critical tasks which are fed to a
    network of hovering UAVs that support the IoT devices deployed in a smart farm.
    It is assumed that the smart farm is equipped with a multi-access MEC infrastructure.
    In such a circumstance, the energy-efficient monitoring problem is modeled as
    a multi-objective maximization problem which aims to maximize the number of tasks
    that are successfully processed before their deadline. Then, a Q-Learning-based
    solution is proposed to solve the problem. The same authors in [5] have extended
    their proposed scheme to a DQN-based solution [33] and to a multi-actor-based
    risk-sensitive RL approach [32]. Although, the goal of the aforementioned studies
    is to minimize the energy consumption in the network, however, the proposed solutions
    are basically centralized and the communication overhead of the centralized approaches
    is itself a source of energy waste. The AoI as a metric for determining the freshness
    of information has been used in some recent works On UAV-aided IoT networks [6],
    [17], [23], [34], [35]. Buyukates and Ulukus [34] examined a status update system
    where update packets require processing to extract embedded useful information.
    The source node sends information to a computation unit (CU) with a master node
    and worker nodes. The master node assigns tasks, aggregates results, and sends
    them back to the source node for updating. The analysis focuses on the age performance
    of various schemes in the presence of stragglers, considering i.i.d. exponential
    transmission delays and i.i.d. shifted exponential computation times. Then, the
    best scheme that minimizes the average age is presented. In [35], the authors
    analyzed the average age of information (AoI) and average peak AoI (PAoI) in a
    multiuser Mobile Edge Computing (MEC) system. The system considers three computing
    schemes: local computing, edge computing, and partial computing (where the computational
    tasks are partially performed at the edge and the remaining is performed by the
    local server). To address the complexity, upper and lower bounds on average AoI
    are provided, enabling an examination of optimal offloading decisions based on
    MEC system parameters. In [6], Han et al. modeled a UAV-aided IoT network using
    a Markov chain. The freshness of data packets is defined using AoI and they analyzed
    the IoT devices as first-come-first-served (FCFS) model and M/M/1 queue. Sun et
    al. [17], employed AoI to propose an AoI-energy-aware data collection scheme for
    IoT networks in which the UAVs are used to collect data. Here, AoI is used to
    quantify the temporal correlation among data packets. Then, an algorithm for determining
    the UAV’s flight speed, hovering locations, and allocated bandwidth to IoT devices
    is proposed that jointly minimizes energy consumption and the weighted sum of
    expected average AoI in the network. In [23], a UAV-aided wireless powered IoT
    scheme is proposed, where a UAV flies from a data center toward IoT sensory nodes
    to transfer energy and collect their information and then it returns back to the
    data center. The goal is to minimize the average AoI of the collected data from
    sensor modes. For such circumstances, an optimization problem is formulated, and
    then a suboptimal method is proposed that first decomposes the problem into two
    subproblems. The solution to the first subproblem is the input for the second
    subproblem. It is worth mentioning that the AoI is basically an end-to-end metric;
    Hence, even though the aforementioned works try to minimize the AoI, for the use
    cases in smart agriculture that the captured data needs some live processing before
    being turned into useful information, these approaches are not effective as they
    just consider the problem of finding the best data flow path. In the context of
    UAV-aided MEC for IoT networks, each service can be represented as a service function
    chain (SFC) consisting of ordered processing functions in the form of VNFs that
    can be geographically placed on to local MEC-server or the UAVs. However, in a
    network with numerous IoT devices and dynamic network load, the placement of VNF
    instances and routing among them in an optimal and efficient manner is a challenging
    problem [27], [28]. In the literature, this problem is referred to as the SFC
    dynamic orchestration problem (SFC-DOP) [27]. In [27], Liu et al. presented a
    DRL-based framework for dynamic SFC orchestration in IoT networks. Huang et al.
    in [36] dealt with the problem of scalability and flexibility of static orchestration
    of NFV-enabled SFCs. Then, a FL-based SFC orchestration is proposed which is scalable
    and benefits from low communication cost. Table 1 presents an overview of the
    previously mentioned studies, emphasizing the main topics they concentrated on.
    Although, in the literature, the UAV-aided MEC architecture is mainly proposed
    as a technique to compensate for the energy and computational limitations of IoT
    networks, however, existing solutions for NFV-enabled SFC require IoT nodes to
    exchange large volumes of local data with a centralized server or among the distributed
    agents. Considering the energy limitation of IoT devices and battery-powered UAVs,
    this significantly causes waste of the network energy. In this paper, we deal
    with this inconsistency and propose a novel FL-based solution for the dynamic
    orchestration of SFCs in a multi-hop and UAV-aided MEC network. To the best of
    our knowledge, this is the first time that the problem of dynamic orchestration
    of NFV-enabled SFCs in a multi-hop UAV-aided MEC network is considered. What makes
    our approach unique is the adoption of the inherent structural aspects of the
    problem, typical in most scenarios, to introduce a decentralized solution that
    is analytically demonstrated to be valid. The proposed method is asynchronous
    FL-based, enabling distributed parties to independently learn locally and subsequently
    contribute to the training of the global model asynchronously [38], [39]. In other
    words, the parties are allowed to directly share gradients with the coordinator
    (here, the MEC server) after every local update and asynchronous of the other
    parties. This further enhances the training speed and efficiency of our proposed
    approach [39]. The coordinator in turn can perform the aggregation and update
    the global model whenever an update from one of the distributed parties is received.
    This approach improves the whole system’s scalability and alleviates the straggler
    impact, i.e., users who may have slower performance [38]. TABLE 1 Summary of Related
    Works The following notations are used throughout the remainder of the paper.
    Matrices and sets are denoted by Bold upper-case characters, and vectors are denoted
    by bold lower-case characters. The cardinality of a set A is represented by |A|
    . The expected value of random variable X is denoted by E[X] . The indicator function
    1 A (a) is defined as 1 A (a)=1 if the element a belongs to A , and 1 A (a)=0
    if the element a does not belong to A . SECTION III. System Model A. General Description
    We consider a real-time IoT network for smart agriculture applications, where,
    the IoT network provides real-time monitoring and visibility to network operators
    by video/image streaming. For such circumstances, several use cases from remote
    monitoring to security can be considered. As it is depicted in Fig. 1, a set N
    of N IoT devices collect real-time information from a smart farm and send the
    packets to a local server. A UAV-aided MEC architecture is considered, where packets
    are forwarded through an Aerial Network consisting of U hovering UAVs toward the
    local server. We consider applications in which some processing functions, from
    primary processes (e.g., compression) to advanced ones (e.g., object recognition)
    must be sequentially performed on the raw packets. Each IoT device is associated
    with one of the UAVs in its range. U denote the set of all U UAVs in the network.
    The local server is indeed a MEC-server1 denoted by M . A set S={ S k } K k=1
    with |S|=K different service types is assumed. Each service type S k itself consists
    of a set F k ={ F k f } F k f=1 including F k different processing functions that
    should be performed on the packets of that service and F denotes a set of all
    processing functions of all services, F= ⋃ k∈S ( F k ) . The input and output
    packet sizes of the function f of service type k are ρ k f and ϱ k f , respectively.
    FIGURE 1. System model. Show All Let s k n ∈{0,1} denote the service type k∈S
    in IoT node n∈N is active, s k n =1 , or not, s k n =0 . In each IoT node one
    of the K different services is running, ∑ k∈S s k n =1,∀n∈N . To perform the processing
    functions, the MEC-server M and each UAV u is able to run F= ∑ k∈S F k different
    VNF types on their physical computing machine.2 The proposed architecture is based
    on ETSI-NFV standard [40] which is a globally accepted architecture for implementing
    the NFV. According to ETSI-NFV, in each physical machine (processing node) p∈U∪M
    (All U UAVs and the local server M), the VNF manager (VNFM) is responsible to
    manage its computing and storage resources among the VNFs it hosts. The total
    available resources at processing node p is indicated by C p , the computing capacity
    in Hz, and B p , the memory capacity in Byte. The VNF orchestrator (VNFO), hosted
    by the local server, places and schedules the chain of VNFs through Aerial Domain
    and Local (MEC) Server. For a summary of the key symbols and variables used in
    the system model and problem formulation, refer to Table 2. TABLE 2 Key Symbols
    and Variables B. VNF Placement and Scheduling We consider a discrete-time system
    with two hierarchical timing levels. First, the time is divided into equal time
    slots TS with duration T indexed by t=1,2,… . On top of that, we have the VNF-scheduling
    time slots t ~ with duration T ˜ that is multiples of T , and it is a single round
    of VNF placement and scheduling update. At the beginning of each time slot t ~
    , the VNFO updates the VNF placements. Each UAV u segregates data packets from
    IoT nodes sharing the same service type, say k , into a packet-flow Υ k u (t)
    , which it then transmits across the aerial network to the local server. The set
    F k ={ V fk } F k f=1 of F k different VNFs (processing functions) must be performed
    on data packets of the IoT nodes with service type k . At the beginning of each
    VNFO-level time slot t ~ , the VNFO determines the set of processing nodes Δ k
    u ( t ~ ) that participate in serving the k th service packet-flow Υ k u (t) of
    UAV u at t th TS. Each selected processing node p∈U∪M that belongs to Δ k u (
    t ~ ) performs a subset B k up ( t ~ ) of all functions F k that is supposed to
    be performed on the packet flow of service type k belongs to UAV u : B k up (
    t ~ )={ F k f  :  f ˙ k up ≤f≤ f ¨ k up }, B k up ( t ~ )⊆ F k , (1) View Source
    where f ˙ k up (S) and f ¨ k up (E) are the first and the last function (VNF)
    that p performs on the packet flow of service type k of UAV u . In summary, for
    each packet-flow Υ k u (t) , the VNFO selects and schedules the processing nodes
    that handle F k . These nodes can be each one of any other UAVs (intra-domain
    offloading) or local server (inter-domain offloading). Remark 1:Let P to−do p
    ( t ~ )={(u,k,f) : f∈ F k u is running on p} indicate a set of all assigned VNFs
    to the processing node p∈U∪M . We assume all assigned VNFs P to−do p ( t ~ ) to
    processing node p should be finished in a single round of VNF scheduling t ~ .
    Fig. 2 provides a comprehensive representation of crucial elements related to
    the proposed orchestration solution and the communication dynamics within the
    network. Operating at two distinct timing levels, the figure elucidates: 1) The
    VNFO timing (Tier 1), emphasizing interactions pivotal for establishing the proposed
    orchestration solution, and 2) the network-wide communication (Tier 2), encompassing
    all entities within the network. FIGURE 2. Network-wide timing model. Show All
    The upper segment of the figure illustrates how UAV 1 manages received packet
    flows from IoT nodes, accommodating two distinct service types. Following the
    assumed VNFO policy in a single round of VNF placement and scheduling, it is evident
    that for packets of service type 1, UAV1 processes them and subsequently forwards
    them to UAV3. UAV3, after performing the assigned VNFs, then forwards the packets
    to the local server, i.e., the final destination. Conversely, for packets of service
    type 2, UAV1 initiates some initial processing and then directly forwards them
    to the local server, where all remaining VNFs are executed. The lower section
    of the figure is dedicated to illustrating VNFO level operation, depicting control
    packets exchanged between the local server and agents for the training of the
    VNFO model. Further clarification on this VNFO communication is postponed to subsequent
    sections within the article. C. Communication (Access) Network There are three
    communication links among the network nodes: the wireless links between IoT nodes
    and an aerial network consisting of UAVs, the UAV-to-UAV wireless links, and the
    wireless link between the UAVs and the local terrestrial server. Let random process
    g nu (t)∈C denote the channel loss between IoT node n∈N and UAV u∈U , then the
    achievable bit rate of node n in up-link direction at time instant t will be R
    nu (t)= w n log 2 (1+ p nu | g nu (t)| σ 2 ),∀n∈N,u∈U , where w n and σ 2 denote
    the channel bandwidth of IoT device n and the noise variance, respectively, and
    p nu is the transmission power level. The channel between IoT nodes and UAVs and
    between UAVs and the local server can be modeled as an air-to-ground channel model
    [41]. According to this model, the path loss, g nu can be calculated as [37],
    g nu (t)= ( 4πf c ) 2 d 2 (t) η e , (2) View Source where f , c , and d are frequency
    of operation, speed of light, and distance between the transmitter and receiver,
    respectively; and η e is the average of excessive path loss in two cases of existing
    a LoS path, η LoS e , and non-LoS case, η nLoS e , η e = p LoS × η LoS e +(1−
    p LoS )× η nLoS e , (3) View Source where p LoS is the probability that a LoS
    path exists and can be closely approximated as [37], p LoS = 1 1+aexp−b(ψ−a) ,
    (4) View Source where, a and b are environment-related parameters. Similarly,
    in the downlink direction, the achievable bit rate of the link between UAV u∈U
    and MEC server M at time instant t will be R uM (t)= w uM log 2 (1+ p uM | g uM
    (t)| σ 2 ),∀u∈U , where w uM denotes the channel bandwidth, σ 2 is the noise variance,
    p uM is the transmission power level, and random process g uM (t)∈C denotes the
    channel Loss at time t . Finally, the UAV-to-UAV wireless channel also follows
    the same mathematical model, however, the only difference is that the probability
    of existing LoS is equal to 1, p LoS =1 . For each UAV u and service type k ,
    τ k u (t) is defined as the expectation value of IoT access network delay with
    respect to transmission rate R nu (t) , τ k u (t)= E R nu [ τ k nu (t)], τ k nu
    (t)= D nu /C+ Λ k nu / R nu (t), (5) View Source where, E R nu denotes the expectation
    with respect to R nu , D nu is distance between IoT node n∈N and UAV u∈U and Λ
    k nu is the packet length of service type S k ∈S . For the aerial radio links,
    Let random process g u u ´ (t)∈C denote the channel power gain between UAV u∈U
    and UAV (or local server M) u ´ ∈U∪M , then the achievable bit rate of the link
    at time instant t will be R u u ´ = w u u ´ log 2 (1+ p u u ´ | g u u ´ (t)| σ
    2 ),∀n∈N,u∈U∪M , where w u u ´ denote the channel bandwidth between UAV u , and
    UAV (or local server) u ´ , σ 2 is the noise variance, and p u u ´ is the transmission
    power level. In the following sections, we will focus on the VNFO’s functionality,
    and resource allocation of the radio access part is beyond the scope of this paper;
    hence, without loss of generality, we assume a fixed power and bandwidth allocated
    to all the participating nodes. SECTION IV. Problem Formulation Let χ fk pu (
    t ~ )∈{0,1} denote whether the processing node p at time slot t is selected to
    run VNF function f on the packet of the k th service type of UAV u : χ fk pu (
    t ~ )= { 1, 0, if p∈ Δ k u ( t ~ )andf∈ B k pu ( t ~ ) otherwise ∀k∈S,u∈U. (6)
    View Source For each service type k∈S of UAV u , only one of the processing nodes
    (UAVs or MEC-server) must be selected for serving each function f∈ F k : ∑ p∈U∪M
    χ fk pu ( t ~ )=1,∀f∈ F k , ∑ p∈U∪M χ fk pu ( t ~ )=0,∀f∄ F k . (7) View Source
    The relation (7), both left and right expressions together, implies that the packets
    belonging to the service packet-flows travel a loop-free route. Each packet belongs
    to packet-flow Υ k u (t) needs a specific computational capacity c fk in CPU cycle.
    Assuming that all the processing capacity of processing node p in a single time
    slot with duration T ˜ is C p T ˜ , to be assured that the computing capacity
    of the selected processing node is enough to serve the assigned VNFs and the scheduler
    does not exceed the processing node’s budget, the following condition at each
    VNF-scheduling time slot t ~ should be satisfied: ∑ u∈U ∑ k∈S ∑ f∈ F k 1 P to−do
    p ( t ~ ) (u,k,f) c fk ≤ C p T ˜ ,∀p∈U∪M. (8) View Source The same condition also
    needs to be fulfilled regarding the storage capacity requirement b fk (in Bytes):
    ∑ u∈U ∑ k∈S ∑ f∈ F k 1 P to−do p ( t ~ ) (u,k,f) b fk ≤ B p ,∀p∈U∪M (9) View Source
    where B p is the total amount of available storage capacity of the processing
    node p . A. Age of Information In order to quantify the freshness of the received
    packet at the destination, the AoI metric is adopted. As soon as an IoT node has
    a packet to send, it connects to its serving UAV and sends packets.3 For each
    packet flow of service type k that UAV u∈U receives directly from the IoT nodes
    that are connected to it and running this service type, the arrival time t k u
    is defined as the time elapsed from the beginning of the time slot t in which
    any packet has arrived in. Let Θ k u (t) denote the AoI of the packet-flow of
    service type k in UAV u , it can be calculated as, Θ k u (t)={ τ k u +T− t k u
    , Θ k u (t−1)+T, if  α k u (t)=1 if  α k u (t)=0 ∀k∈S,u∈U (10) View Source where
    binary variable α k u (t)∈{0,1} indicates whether any new packet of service flow
    k at TS t is received, α k u (t)=1 , or not, α k u (t)=0 . By definition, for
    every time slot t in which the UAV does not receive a new packet from a service
    packet flow, the AoI of that service packet flow increases by T . On each received
    packet from IoT node n with service type k , the set F n k of VNFs (processing
    functions) should be performed. As stated above, the VNFO determines the set of
    processing nodes p∈ Δ k u ( t ~ ) that participate in performing the VNFs on packet-flow
    Υ k u (t) by performing the set B k up ( t ~ ) of VNFs. B k up ( t ~ )=∅ means
    p hosts none of the required VNFs of Υ k u (t) . Let Δ k u ( t ~ )={ p 1 , p 2
    ,…, p L } denote the sequence of all UAVs that are already selected to sequentially
    do the chain of VNFs on the received packets of service type k . The processing
    time of every packet of this flow will be, Φ k u (t)= ∑ p v ∈ Δ k u ( t ~ ) ⎛
    ⎝ ⎜ ⌈ τ fk p v−i p v (t) T ⌉T+ ∑ ϑ∈ B k u p v ( t ~ ) (⌈ θ k ϑ T ⌉T ⎞ ⎠ ⎟ ), ∀k∈S,u∈U
    τ fk p v−i p v (t)= D p v−i p v /C+ Λ p v−i p v ( F k f )/ R p v−i p v (t) F k
    f = f ¨ k u p v−i , (11) View Source where θ k ϑ is the run time of ϑ th VNF for
    service type k , Λ p v−i p v ( F k f ) is the packet length of service type S
    k ∈S after doing the last VNF f ¨ k u p v−1 of the chain in p v−1 , and, Assuming
    that the queueing delay is negligible, τ fk p v−1 p v is total transmission delay
    between p v−1 and p v consists of propagation delay and transmission delay. If
    the binary variable β k u ( t ~ )∈{0,1} indicates whether the VNF scheduling (at
    VNF-scheduling time slots t ~ ) for the flow of packets belong to service type
    k of UAV u was successful, then, the AoI at the Local server will be, Π k u (t)={
    Θ k u (t)+ Φ k u (t), Π k u (t−1)+ T ˜ , if  β k u ( t ~ )=1 if β k u ( t ~ )=0
    ∀k∈S,u∈U. (12) View Source Note that T ˜ is the duration of a single round of
    VNF placement and scheduling. B. Energy Consumption The energy consumption of
    the network in the uplink direction can be calculated as, P UL (t)= ∑ n∈N ∑ k∈S
    ∑ u∈U s k n p nu Λ k nu / R nu (t), (13) View Source where Λ k nu / R nu (t) is
    the transmission time between IoT node n , with service type k , and UAV u at
    TS t . The other energy-consuming part of the access network is transmission among
    the processing nodes. If we represent the energy consumption in the aerial domain
    (including UAV-to-UAV and UAV-to-MEC links) at TS t with P Aerial (t) , then it
    will be as, P Aerial (t)= τ fk p v−i p v (t)= F k f = ∑ u∈U ∑ k∈S ∑ p v ∈ Δ k
    u p p v−i p v τ fk p v−i p v (t), D p v−i p v /C+ Λ p v−i p v ( F k f )/ R p v−i
    p v (t), f ¨ k u p v−i , (14) View Source where Λ p v−i p v ( F k f ) , f ¨ k
    u p v−1 and τ fk p v−1 p v are defined like (11). Finally, if Ψ k ϑ denotes the
    power each machine, that hosts the ϑ th VNF of service type k , consumes to run
    this VNF on each packet of this service type, then, the total network-wide required
    energy for performing the VNFs across a single packet of all service type can
    be calculated as follows: P NFV = ∑ u∈U ∑ k∈S ∑ p v ∈ Δ k u ∑ ϑ∈ B k u p v Ψ k
    ϑ θ k ϑ . (15) View Source In a single term, P NFV represents the energy consumption
    resulting from VNFs processing. Using (13)–(15), the total energy consumption
    of the network to process a single packet across all the service types belonging
    to all UAVs would be, P Total (t)= P UL (t)+ P Aerial (t)+ P NFV . (16) View Source
    The UAVs use a battery, hence their available energy to do the processes and perform
    the required communications is limited. Therefore, we need an energy-efficient
    VNFO solution with minimum communication overhead. A centralized ML method will
    be optimal, but it requires a large communication transaction to share the local
    observation with the central controller. Another drawback of adopting centralized
    architecture is that the centralized coordinator is not scalable and from the
    processing and communication viewpoint is a single point of failure. Therefore,
    in this paper, we deal with proposing a solution for the following problem of
    distributed NFV orchestration through the UAVs as distributed VNFO agents. Problem
    1 (Distributed VNFO for Joint AoI and Energy Minimization):Considering the service
    requirements of IoT nodes, UAVs/MEC-server available resources, and the condition
    of access networks, what is the optimal strategy of VNF placement and scheduling
    in each UAV to jointly minimize the average AoI and total energy consumption at
    the Local Server: Minimize χ fk pu ( t ~ ) s.t. γ AoI [ 1 UK ∑ u∈U ∑ k∈S Π k u
    (t)]+ γ E P total (t), ∑ p∈U∪M χ fk pu ( t ~ )=1,∀f∈ F k , ∑ p∈U∪M χ fk pu ( t
    ~ )=0,∀f∄ F k , ∑ u∈U ∑ k∈S ∑ f∈ F k 1 P to−do p ( t ~ ) (u,k,f) c fk ≤ C p T,
    ∀p∈U∪M, ∑ u∈U ∑ k∈S ∑ f∈ F k 1 P to−do p ( t ~ ) (u,k,f) b fk ≤ B p , ∀p∈U∪M.
    (17) View Source In each VNFO-level time slot T ˜ the orchestrator sequentially
    decides on the chain of VNFs of the service flows belonging to UAVs. For a class
    of stochastic sequential decision-making problems, the Markov Decision Process
    (MDP) has been a powerful framework for the mathematical formulation and study
    of this type of problems. Another point that is worth mentioning is that our proposed
    method in Section VI is FL-based where the UAVs follow the same model trained
    cooperatively. Therefore, minimizing the average AoI over UAVs or minimizing the
    maximum value of AoI over UAVs are basically the same. Depending on the environment
    state, the MDP output will be the best action (or at least the best upon the history
    of the observations and actions) which maximizes a specific utility function [42].
    For the case that the state is not fully observable to the deciding agent or the
    agent’s observations are exposed to noise or some source (sort) of uncertainties,
    another extended class of decision-making processes called Partially Observable
    MDP (POMDP) is adopted [43]. Both MDP and POMDP in their original scope are defined
    centralized [42], [43]. Partially Observable Stochastic Game (POSG) is the extended
    version of POMDP in which a set of distributed agents are involved in the decision-making
    process [44], [45]. By definition, if every agent has the same individual reward
    function, the POSG model becomes the Decentralized POMDP (DEC-POMDP) [45]. In
    the following two sections, first, we show how the problem can be modeled as a
    DEC-POMDP and then we will present our proposed method to solve the developed
    DEC-POMDP. SECTION V. DEC-POMDP Formulation In a multi-agent MDP with state uncertainty,
    a DEC-POMDP is formally defined as a tuple with the following definition. Definition
    1 (DEC-POMDP Model):DEC-POMDP G with a set U of U agents is defined as a tuple
    G=⟨U,S, b 0 ,A,O,T,O,R⟩ , where S is the finite set of global environment states,
    b 0 is the probability of the environment initially being in state s∈S , A= ∏
    u∈U A u is the joint action of all agents, where A u is the set of actions available
    to agent u , O= ∏ u∈U O u is joint observation, where O u is the observations
    available to agent u , T is the transition function T :  ⋃ s∈S (s×A(s))×S→[0,1]
    , where T( s ´ |s,A(s)) is defined as the transition probability from state s
    to s ´ by doing joint action A(s) , O is the observation function O :  ⋃ s∈S (s×A(s))×O→[0,1]
    , where O(O|s,A(s)) is defined as the joint observation at state s by doing joint
    action A(s) , R={ r u } U−1 u=0 is a set of reward functions r u  :  ⋃ s∈S (s×A(s))→R
    , where r u (s,A(s)) is defined as the reward received by u when A(s) is executed
    at the global state s . In a DEC-POMDP, each agent u∈U based on its local observation
    o u ∈ O u and a local policy π u performs an independent action a u ∈ A u . In
    each partially observable state s , the joint action A(s)= ∏ u∈U a u (s) from
    the joint policy P= ∏ u∈U π u determines the next global state s ´ and joint observations
    O according to transition and observation probability of T( s ´ |s,A(s)) and O(O|s,A(s))
    , respectively. According to Problem 1, our purpose is to find the best choice
    for the sets Δ k u (t) of processing nodes p and B k up (t) of the VNF chains
    for serving packet-flow Υ k u (t) of any service type k∈S of UAVs u∈U in a distributed
    manner. Remark 2 (Source of Uncertainties):We have considered a multi-hop network
    architecture, as depicted in Fig. 3, in which, 1) each agent u is not aware of
    the other agents’ observation o −u  (−u refers to all the agents except u , o
    −u = ∏ u ´ ≠u o u ´ ) , nor the action a −u ,4 2) each agent observes the result
    of doing its own action and the actions of the other agents, while it is not aware
    of the global state nor the action of the other agents. Therefore, according to
    Definition 1, it can be inferred that Problem 1 in its decentralized form is a
    DEC-POMDP. FIGURE 3. System model as a DEC-POMDP. Show All In DEC-POMDP, each
    agent based on its actions and observations creates a local database that in time
    t can be represented as h u ( t ~ )={ a u ( t ~ −1), o u ( t ~ ) } t ~ t ~ =1
    ,∀u∈U , where a u ( t ~ −1) and o u ( t ~ ) are the action of u at time slot t
    ~ −1 and its corresponding observation at t ~ . All the information is available
    to all the U agents at time t ~ defines as the joint history H( t ~ )= ∏ u∈U h
    u ( t ~ )={A( t ~ −1),O( t ~ ) } t ~ t ~ =1 . The POMDP state is hidden from the
    agents. Hence, the agents would not be able to choose their actions based on knowing
    the true state. The standard approach for dealing with POMDPs is to find a solution
    to the fully observable equivalent belief-MDP [43]. Where, belief B(s, t ~ )=P(s(
    t ~ )=s|H( t ~ ),B(0)),∀s∈S defines as a probability distribution over the state
    space of the original POMDP knowing the joint history H( t ~ ) , i.e., all the
    available information from the sequence of interactions that the agents have had
    until now,where B(0) is the initial value the belief state function. Belief state
    function B(s, t ~ ) is known as sufficient statistic for the history H( t ~ )
    [45]. Upon performing a new interaction at t ~ +1 , the belief value is updated
    from the belief point at time t considering the new interaction {A( t ~ −1),O(
    t ~ )} . Despite the current hidden state, in DEC-POMDP the agents need to infer
    the action (the policy) of the other agents. This leads to the definition of multi-agent
    belief function [46] with the following definition, b u  :  ⋃ s∈S (s× π −u (s))→[0,1],∀u∈U
    b u, t ~ (s, π −u )=P(s( t ~ )=s, π −u | h u ( t ~ ), b u (0)), π −u = ∏ u ´ ∈U,
    u ´ ≠u π u ´ . (18) View Source As it is evident, the multi-agent belief function
    is defined in a space that is a combination of the hidden global state s and joint
    policy π −u of the other agents. From Bellman expectation equation [47], the action-value
    function Q π u, t ~ [(s, π −u ), a π u ] is the expected return starting from
    state hidden state s , taking action a π u according to policy π u , while the
    other agents follow the joint policy π −u , Q π u, t ~ [(s, π −u ), a π u, t ~
    ]= E{ R u [(s, π −u ), a π u, t ~ ] + γ u Q π u, t ~ +1 [( s ´ , π −u ), a π u,
    t ~ +1 ]}. (19) View Source where the action-value function decomposed into immediate
    reward plus discounted action-value of the successor state, and γ u is the discount
    factor of agent u . With some mathematical manipulation, (19) can be written as,
    Q π u, t ~ [(s, π −u ), a π u, t ~ ]= R u [(s, π −u ), a π u, t ~ ] + γ u ∑ (
    o u , o −u )∈O O[ o u , o −u |s,( a π u , a −π −u )] ∑ s ´ ∈S T[ s ´ |s,( a −π
    −u )] × ∑ ( a π u , a −π −u )∈A π u ( a π u | s ´ ) Q π u,t [( s ´ , π −u ( o
    −u )), a ´ π u, t ~ +1 ( o u )]. (20) View Source Using (18), for a given belief
    state function b u, t ~ (s, π −u ) , the action-value function Q π u, t ~ ( b
    u, t ~ , a π u, t ~ ) will be, Q π u, t ~ ( b u, t ~ , a π u, t ~ )= ∑ s∈S ∑ π
    −u b u, t ~ (s, π −u ) Q π u, t ~ [(s, π −u ), a π u, t ~ ]. (21) View Source
    For an enough large value of t ~  ( t ~ →∞) , the goal is to find the optimal
    policy π ∗ u among available policies π u which leads to the optimal Q-value (action-value)
    function, Q ∗ u, t ~ ( b u, t ~ , a u, t ~ )=arg max π Q π u, t ~ ( b u, t ~ ,
    a π u, t ~ ). (22) View Source There is no straightforward solution for the aforementioned
    DEC-POMDP problem. Among decentralized methods, multi-agent solutions also need
    a large volume of communication overhead between the agents to share their local
    observations to converge. FL does not have the communication overhead of the centralized
    techniques and also does not necessitate the agents to share all of the data and
    local observations to converge. Although this specification is for providing privacy,
    in our problem it provides us with the gain of energy efficiency that arises because
    the agents (UAVs) do not need to share all of their observations. A few efforts,
    [45], [48], [49], have been made in the literature to capture and exploit some
    structural specifications of the understudied system (application) to find or
    at least simplify the problem of finding optimal policy (22). One of these works
    is one presented by Yongacoglu et al. [48], in which the authors have developed
    a class of POSGs that is characterized by symmetry across players in terms of
    cost and state dynamics. In view of this research, within the APPENDIX, we introduce
    a class of Symmetric DEC-POMDP and prove that Problem 1belongs to this class and
    is Circularly Symmetric. This implies that the best agents’ policy, π ∗ are the
    same, { π u } U−1 u=0 = π ∗ . In essence, this necessitates a distributed solution
    to determine the best policy while ensuring uniformity across all agents. Furthermore,
    in accordance with the circular symmetry characteristic of the problem, in Corollary
    22 we prove that local observations serve as sufficient statistics for each agent
    to ascertain the best policy. Corollary 22 guarantees that the local observation
    h u ( t ~ ) serves as a sufficient statistic to determine the optimal policy π
    ∗ for the agents (UAVs). This implies that the information encapsulated in the
    local observations of the individual agents is comprehensive enough to determine
    the optimal policy π ∗ . While this corollary does not suggest a particular method
    for identifying the optimal policy, it is promising and justifies our proposed
    FL-based algorithm in which the agents collaboratively engage in training a globally
    shared model. This approach aligns with the notion that leveraging decentralized
    insights from each agent’s local observations can contribute to the derivation
    of an effective and globally optimal policy because their observations are sufficient
    statistics. Capitalizing on the promising findings in this section, the subsequent
    section introduces our proposed approach to address Problem 1. SECTION VI. Symmetry-aided
    Asynchronous Federated DQN Framework In this section, we introduce our proposed
    Asynchronous Federated Deep Q-Network (AFDQN) algorithm and the components we
    have used in the proposed model as depicted in Fig. 4. In traditional RL, the
    problem is modeled as an MDP consisting of a tuple {s( t ~ ),a( t ~ ),r( t ~ ),s(
    t ~ +1)} . At each decision-making time t ~ , the agent is at state s( t ~ ) and
    takes an action a( t ~ ) based on a policy π that causes a state transition from
    s( t ~ ) to s( t ~ +1) while an immediate reward r( t ~ ) incurred. For our POMDP
    case in which the true state of the network is hidden, the true state s( t ~ )
    is replaced with belief-state b( t ~ ) . Mainly, the RL aims to guide the agent
    to find the best policy π ∗ defined as the best mapping from observation o( t
    ~ ) to action a( t ~ ) that maximizes the expected cumulative discounted future
    rewards R( t ~ )= E π { ∑ ∞ l=t γ (l− t ~ ) r(l)} , where γ∈[0,1] is a discount
    factor indicating how much future rewards is important. For our DEC-POMDP problem,
    this relation maps to (19). FIGURE 4. Block diagram of the proposed Asynchronous
    Federated-DQN (AFDQN). Show All A. Deep Q-Network (DQN) Part To estimate Q-value
    functions (21), deep reinforcement learning (DRL) is deployed, where Q-values
    are predicted using deep neural networks (DNNs) as function approximators. The
    estimated Q -functions are represented by { Q u ( o u ( t ~ ), a u ( t ~ ); θ
    u ( t ~ )) } U−1 u=0 , where the parameter θ u ( t ~ ) represents the weights
    of the agent u ’s neural network (NN). The updated value of θ u ( t ~ ) is used
    to approximate the true values of Q u ( t ~ ) [21], [50]. Let’s define the loss
    function L( θ u ( t ~ )) as the expectation value of the mean squared error of
    the estimated Q-value Q u ( o u ( t ~ ), a u ( t ~ ); θ u ( t ~ )) from the target
    value y( t ~ ) [21], L( θ u ( t ~ ))=E[(y( t ~ )− Q u ( o u ( t ~ ), a u ( t ~
    ); θ u ( t ~ )) ) 2 ], (23) View Source where, y( t ~ )= r u ( t ~ )+γ max a u
    ( t ~ +1) Q u ( o u ( t ~ +1), a u ( t ~ +1); θ u ( t ~ )) and a u ( t ~ +1) indicates
    the agent’s action generated by the DNN at t ~ +1 , given the observation o u
    ( t ~ +1) . At each iteration, the deep Q -function approximator is trained to
    learn the best estimate of the Q-function by minimizing the loss function L( θ
    u ( t ~ )) . To improve the stability of the algorithm and cope with samples correlation,
    as depicted in Fig. 4, two novel techniques, namely Fixed Target Network [51]
    and Experience Replay Buffer [52] are deployed, respectively. Utilizing these
    two techniques, the loss function L( θ u ( t ~ )) can be written as L( θ u ( t
    ~ )) = E D [( r u ( t ~ )+γ max a u ( t ~ +1) Q u (b( t ~ +1), a u ( t ~ +1);
    θ ´ u ( t ~ )) − Q u ( o u ( t ~ ), a u ( t ~ ); θ u ( t ~ )) ) 2 ], (24) View
    Source where θ ´ u ( t ~ ) denotes the target network parameters, and the expectation
    E D is taken over the randomly selected mini-batches of samples from the replay
    buffer D . B. Federated Learning Part As it is illustrated in Fig. 4, we have
    two main entities, the set U={0,1,…,U−1} of UAVs that are our distributed agents
    or in FL terminology, the agents, and the coordinator that in our model is local
    server (MEC-server). FL allows the UAVs (agents) to train a shared global model
    parameterized by θ g that is an exact copy of the agents’ local model { θ u }
    u=U−1 u=0 using their own dataset { D u } u=U−1 u=0 , while the original data
    remains in UAVs. After local training, agents share their local model updates
    with the coordinator. The coordinator then aggregates the received updates to
    build the global model θ g . As a result, relying on the distributed data training
    at the agents, the local server is able to enhance the training performance without
    significant communication overhead as it just needs an update of the local model
    parameters, not the agents’ local data. The federated learning procedure of our
    proposed method includes the following key steps. 1) Distributed Local Training
    Primarily, the local server initializes the global model, θ g,0 , and transmit
    it to the agents. Upon receiving θ g,0 , during VNFO time slots t ~ the agents
    interact with environment and train their local model { θ u ( t ~ ) } u=U−1 u=0
    using their own data set { D u ( t ~ ) } u=U−1 u=0 by minimizing a loss function
    { L u ( θ u ( t ~ )) } u=U−1 u=0 , θ ∗ u =arg min π u L u ( θ u (( t ~ ))),∀u∈U.
    (25) View Source Then, the agents upload their local update on { θ u ( t ~ ) }
    u=U−1 u=0 to the coordinator for aggregation. 2) Model Aggregation After collecting
    the agents’ local model updates, the next step is aggregating them into a new
    version of the global model which is performed by the coordinator by solving the
    following optimization problem. Problem 2 (Model Aggregation):Given the local
    model updates { θ u ( t ~ ) } u=U−1 u=0 of all agents, and knowing the local loss
    functions { L u (⋅) } u=U−1 u=0 , what is the optimal strategy for aggregating
    the local model that minimizes the global loss, θ ∗ g , L ∗ g =arg min L g , θ
    g L g ( ∏ u∈U L u ( θ g (( t ~ )))). (26) View Source According to Problem 2,
    θ ∗ g is the optimal value for θ g with having the local updates in hand; and
    L ∗ g is the best function (the best method) for aggregating the local loss function.
    The loss-aggregation function L ∗ g indicates the relative contribution of each
    agent on the global model, however, there is not a fixed method for determining
    this function and it depends mostly on the structure and specific features of
    the problem. Corollary 1:According to Lemma 2, The best setting for loss functions
    is (24) and { L u (⋅) } u=U−1 u=0 =L(⋅) , The optimal way for aggregating the
    local updates is averaging among the agent’s contributions, thus (25) can be rewritten
    as, θ ∗ g = ∑ u∈U ω u θ u , where ω u represents the relative contribution of
    each agent on the global model. After the derivation of a new update of θ g the
    coordinator broadcasts it to all agents. Upon receiving the update from the coordinator,
    the agents upgrade their local model accordingly. Until achieving a predefined
    level of accuracy or convergence of the global loss function, this process is
    continued. C. Asynchronous Networking The communication among the network entities
    follows the time slots t , but slot scheduling in which the agents share their
    own local model with the coordinator is distributed and asynchronous. Upon receiving
    an update, the coordinator aggregates it with the global model and updates the
    agents with the newly updated global model. In this way, we do not impose a strict
    constraint on synchronous communication with the local server (the coordinator).
    This significantly decreases the networking overhead in comparison with synchronous
    federation among distributed agents. During the training phase, we consider episodes
    in which the agent presets to a random initialization setting and starts interaction
    with the environment, and learns from its experience. Each episode contains T
    ˆ VNF scheduling round t ~ . In the deployment phase, the stream of packets that
    belong to different services is assigned based on an optimally determined VNF
    placement/scheduling policy. To avoid service interruption any fine-tuning and
    policy adaption to environmental changes, including the time the algorithm spends
    on fine-tuning and finding the optimal solution by coordinating multiple agents
    to train the global model, can be done in parallel. Definition 2 (Global Update
    Period):global update period 1≤η≤ T ˆ is defined as the period of updating the
    coordinator by the agents. We have two special settings, AFDQN-SGD ( η=1 ): In
    this case, every VNF scheduling slot t ~ , the agent sends the locally calculated
    SGD, ∇ θ L u ( θ u ( t ~ )) to the coordinator. Then, the coordinator uses the
    received local data to perform one step of gradient descent: θ g ( t ~ +1)= θ
    g ( t ~ )− γ ˙ ∇ θ L u ( θ u ( t ~ )). (27) View Source AFDQN-Avg ( η= T ˆ ):
    In this case, only one time during each episode, the agent sends the whole parameter
    θ u ( t ~ ) to the coordinator. Then, the coordinator updates θ g ( t ~ ) accordingly,
    θ g ( t ~ +1)=(1− γ ¨ ) θ g ( t ~ )+ γ ¨ θ u ( t ~ ), (28) View Source where,
    γ ˙ and γ ¨ are AFDQN-SGD and AFDQN-Avg forgetting factors, respectively. Introducing
    the forgetting factors γ ˙ and γ ¨ allows for the adjustment of learning rates
    during model updates. Rather than updating the global model instantly upon receiving
    a local update, it is beneficial to employ a weighted average approach, considering
    both the most recent update and the previous value of the Agent’s NN weight θ
    g . This approach, known as Asynchronous Weight Averaging [53] in the literature,
    proves advantageous in alleviating the impact of outdated updates, commonly referred
    to as stale weights, and consequently, it enhances overall stability. The only
    point is that the forgetting factors should be chosen small enough. Another worth
    mentioning point is that the AFDQN-SGD and a centralized approach doing mini-batch
    SGD in the local server are essentially different as the former is asynchronous,
    distributed, and fully based on local data. The details of the proposed AFDQN
    algorithm are described in Algorithm 1. Algorithm 1: AFDQN- η Algorithm Show All
    Considering our optimization problem, for each agent u∈U at VNF scheduling round
    t ~ , we define the observation space O u , the action space A u , and the reward
    function R u as follows: Observation: We define the observation space as a vector
    of: 1) CPU and storage requested by the local service flows { Υ k u (t)|t= t ~
    } k as { c fk (t)|t= t ~ } f,k and { b fk (t)|t= t ~ } f,k , respectively, 2)
    available CPU { C p } p and storage { B p } p of the processing nodes, 3) service
    arrival time { t k u } k , and 4) the transmission rate { R u p ´ } U∖ u ´ ∪M
    of the links between agent u and the other processing nodes. Therefore, the observation
    o u ( t ~ ) can be written as O u ( t ~ )= {{ c fk (t) } f,k ,{ b fk (t) } f,k
    , { C p } p ,{ B p } p ,{ t k u } k ,{ R u p ´ } U∖u⋃M } t= t ~ . (29) View Source
    Action: The action space is defined as all possible placement of the required
    VNFs for service flows { Υ k u (t)|t= t ~ } k as A u ( t ~ )={ χ fk pu ( t ~ )},∀p∈U∪M,k∈S,f∈
    F k . (30) View Source Reward: Our objective is to orchestrate the VNFs in a way
    that jointly minimizes the average AoI and total energy consumption over the network.
    So we define the reward as a linear combination of three terms as follows: R u
    ( t ~ )= ζ ¯ ¯ ¯ u ( t ~ )= Π ¯ ¯ ¯ ¯ ( t ~ )= ζ k u ( t ~ )= δ NFV ζ ¯ ¯ ¯ u
    ( t ~ )+ δ AoI Π ¯ ¯ ¯ ¯ ( t ~ )+ δ E P total ( t ~ ), 1 K ∑ k∈S ζ k u ( t ~ )
    1 UK ∑ u∈U ∑ k∈S Π k u ( t ~ ) { +1, −10, if (7)-(9)are satisfied otherwise. (31)
    View Source where δ NFV , δ AoI and δ E are the normalization factors for NFV
    scheduling result, AoI, and the energy consumption, respectively; ζ k u ( t ~
    ) is defined as the reward assigned to the result of NFV placement for service
    flow Υ k u (t)|t= t ~ . SECTION VII. Complexity Analysis In this section, we determine
    the computational complexity of the proposed Algorithm 1. We analyze the algorithm’s
    complexity through two distinct phases: Model Training and Action Selection, which
    occur during the deployment of the trained model. During each iteration of the
    global update period η , the process involves the training of local models by
    the agents (UAVs) and subsequently, the asynchronous aggregation of these local
    models by the MEC server to form the global model. The complexity of the local
    model training conducted by the agents can be expressed as the sum of two components:
    the complexity of action selection and the complexity of the back-propagation
    algorithm for each sample within the replay buffer. This sum is then further multiplied
    by the mini-batch size and η . It is worth noting that the multiplication by the
    mini-batch size accounts for the fact that, in each training iteration, the local
    agent randomly selects a mini-batch of samples from its own local replay buffer.
    The computational complexity of action selection in a fully connected neural network
    with a fixed number of hidden layers and neurons in each hidden layer is directly
    proportional to the sum of the input size and the output size of the neural network
    being used [54], [55]. The input size of the neural network is equivalent to the
    size of the state space, which from (29) is given by 2KF+2(U+1)+K+(U−1)+1 ; and,
    the output size of the neural network is equal to the size of the action space.
    which from (30) is given by KF(U+1) . It’s worth recalling that F= ∑ k∈S F k represents
    the overall count of distinct VNFs required to be executed across all service
    types. Hence, the computational complexity associated with action selection is
    represented by O(KFU) . Conversely, as indicated in equation [54], [55], for a
    specific sample extracted from the replay buffer, the computational complexity
    of the back-propagation process is directly proportional to the product of the
    neural network’s input and output sizes. Consequently, in our specific scenario,
    derived from the preceding computations, the overall algorithmic complexity for
    each agent can be expressed as O(ηO K 2 F 2 U) , where, O denotes the batch size.
    From Algorithm 1, each agent repeats the whole process of local model training
    η times preceding sharing the results with the local server. The last step is
    the aggregation process. While our algorithm conducts asynchronous aggregation,
    it’s important to note that the processing load escalates proportionally with
    the number of UAVs, U . As a result, the overall computational complexity for
    the training phase across the entire network is given by O(ηO F 2 K 2 U 2 ) .
    Based on the prior discussion, the complexity associated with the action selection
    for all U agents during the deployment phase is denoted as O(KF U 2 ) . SECTION
    VIII. Performance Evaluation In this section, the performance of the proposed
    algorithm is evaluated. The performance results are compared for four different
    methods of AFDQN-SGD, AFDQN-Avg, AFDQN with parameter η≠{1, T ˆ } , and a centralized
    case. In the centralized DQN method, all the observations are forwarded to the
    local server and the local server performs the VNF scheduling. Hence, its performance
    can be considered as an upper bound for the proposed AFDQN method. A. Simulation
    Setup The simulation is implemented by Python using OpenAI gym [56], a widely
    used tool for developing RL algorithms, and conducted in a computer with Intel
    Core i7–10700 CPU 2.90 GHz and 64 GB RAM. Using simulation, the impact of parameter
    η , the number of IoT nodes, and the effect of the received load by the agents
    are evaluated. To this purpose, while T ˆ =60 , five different values for the
    parameter of η consisting of 1 (corresponds to AFDQN-SGD), 10, 20, 30, and 60
    (corresponds to AFDQN-Avg) are considered. The other model parameters and simulation
    settings are summarized in Table 3 and Table 4. The proposed system model entirely
    matches none of the existing related works. However, the simulation parameters
    have been chosen to be in line with the typical values commonly used in similar
    studies within this context [6], [32], [33], [36], [37]. TABLE 3 Model Parameters
    and Simulation Settings Part I TABLE 4 Model Parameters and Simulation Settings
    Part II B. Simulation Results In Fig. 5, the convergence behavior of the AFDQN
    method is compared with the centralized method as a baseline. The two extreme
    cases of AFDQN-SGD and AFDQN-Avg are considered. As is evident from this figure,
    for the AFDQN method we have some variations around the value where it converged.
    The absolute value of these variations in AFDQN-Avg is more than AFDQ-SGD, and
    in AFDQN-SGD’s case, they are around the value achieved by the centralized method.
    Also, the AFDQN-Avg converged to a smaller value for total return, we expect this
    result will also be reflected in the performance of AFDQN-Avg against AFDQN-SGD.
    This will be investigated in the following experiments. In Fig. 6(a) and Fig.
    6(b), the minimum achievable average AoI and total energy consumption are investigated.
    The AoI value is averaged over all the agents and the total energy consumption
    is defined as the total energy consumption for sending a single packet of each
    service flow through the network from IoT nodes toward the local server. As can
    be seen, the maximum energy consumption of the three methods is limited to a maximum
    value corresponding to the maximum value of resources that the processing nodes
    can allocate to the requests. As a result, the negative side effect of the methods’
    drop in performance is mostly reflected in the value of the averaged AoI. For
    the AFDQN-Avg, this point is evidenced in Fig. 6(a), where we can see that at
    several points the values of the averaged AoI are more than 1 second. However,
    this is the worst-case choice for selecting the global update period η . Form
    Fig. 6(a), for the proposed AFDQN, we could achieve an average AoI of less than
    200 msec, which is acceptable for most real-time applications. Therefore, performance
    close to the centralized case can be achieved by the proposed method in a distributed
    manner, relying solely on the local observations of the UAVs and the sharing of
    trained local models, thus eliminating the need for exchanging the local observations,
    which can be time and energy-consuming. FIGURE 5. Episodic reward of agent 1 for
    the proposed method compared with centralized architecture. All agents follow
    the same policy, which is a copy of the cooperatively-trained global model. Show
    All FIGURE 6. (a) Average episodic AoI. (b) Average episodic total energy consumption
    of the proposed method compared with centralized architecture. All agents follow
    the same policy, which is a copy of the cooperatively-trained global model. Show
    All In Fig. 7(a) and Fig. 7(b), the network energy efficiency versus service availability
    is drawn. The network-wide energy efficiency is defined as the total number of
    successfully-supported service flows divided by the total energy consumption throughout
    the network to send a single packet from each one of the services flows. Also,
    service availability is defined as the percentage of the service flows that are
    supported successfully. In Fig. 7(a), the average network energy efficiency and
    the sample values in our simulation, as well as the standard deviation of the
    value, for AFDQN- 20 (η=20) are shown. The averaged network efficiency with increasing
    the value of the service availability increases in a way that for the service
    availability of more than 80 percent, it converges to around 82 percent. This
    convergence for large value of service availability shows that we were eventually
    able to provide energy efficiency as one of our objective functions. In Fig. 7(b),
    where the proposed AFDQN method with different values of η∈{20,30,60} is compared
    with the centralized approach, it can be seen that the energy efficiency of the
    centralized approach degrades as the availability reaches 100%. This behavior
    is because the centralized method has a single NN for all UAVs. For the availability
    values near 100%, the centralized agent is not able to do the job as efficiently
    as the AFDQN method where each agent has its own NN. FIGURE 7. Network-wide energy
    efficiency vs. percentage of service availability. The shaded area represents
    the standard deviation (SD) from the average value: (a) For AFDQN with η=20 .
    Sample values are shown for more illustration. (b) For AFDQN with η=20 , η=30
    , AFDQN-Avg and centralized architecture. Show All As illustrated in Table 3,
    the load of services (in terms of requested CPU and storage resources) is modeled
    as a normalized uniform random variable. The standard deviation (SD) of the values
    for both CPU request values and storage is 1.3 percent. In Fig. 8, the impact
    of increasing this value, up to 6 times the primary value of 1.3, on the network’s
    performance is examined. The network is first trained with the primary input-load
    SD value of 1.3, and then, we incrementally raised the SD of the input load. This
    can be implicitly considered as a test under non-stationary load. It is evident
    that in this situation the AoI will increase, as illustrated in Fig. 8. To be
    more specific, we considered a threshold of one second for the acceptable AoI.
    Hence, we have also drawn a graph of AoI violation (in percentage) in conjunction
    with the bar chart of averaged AoI to better reflect the effect of the load SD.
    The results demonstrate that the AFDQN-Avg method has better performance in this
    situation, which appears to contradict our previous observations where we concluded
    that decreasing the global update period improves the performance. This observation
    can be explained using the non-stationary behavior of the input load. In this
    case, the AFDQN-Avg lets the agents learn the variations and input model better,
    in comparison with AFDQN-10, which was chosen as an example for a case between
    two extreme cases, AFDQN-SGD and AFDQN-Avg. FIGURE 8. Averaged-AoI and AoI-violation
    percentage for AFDQN-10 and AFDQN-Avg versus standard deviation (SD) of the load
    normalized by SD of the load in the training phase. Show All The effect of increasing
    the number of IoT nodes per agent (UAV) on AoI and Energy consumption is investigated
    in Fig. 9. For this experiment, two AFDQN-10 and AFDQN-Avg cases are considered.
    The results show that AFDQN-10 had better performance than AFDQ-Avg. Another important
    point that should be mentioned relates to the behavior of the network for a large
    number of IoT nodes, e.g., 120 or more. As the number of IoT nodes increases,
    the load of the agents increases directly, this means that there are more CPU
    and storage requests. Because the resources in the processing nodes are limited,
    there comes a point where an increase in the number of IoT nodes will lead to
    more request rejection responses. In this situation, the fresh packets will drop,
    and that causes an increase in the AoI value. However, the network energy consumption
    does not change because the volume of the active processes does not change and
    remains equal to the maximum capacity of the processing nodes. FIGURE 9. The effect
    of increasing the number of IoT nodes per agent (UAV) on AoI and energy consumption.
    Show All For further exploration, Fig. 10 and Fig. 11 compare the performance
    of the proposed algorithm against two baseline algorithms: Multi-agent DQN (MDQN)
    [57] and the adapted version of heuristic Minimum-Delay algorithm [58]. In MDQN
    the agents operate independently based on locally trained models without coordination.
    The agents are equipped with an identical neural network featuring the same specifications
    as AFDQN. Conversely, the Minimum Delay algorithm selects actions at each VNF
    scheduling round t ´ to minimize end-to-end delay (not AoI) between IoT nodes
    and the local server. FIGURE 10. Averaged-AoI and AoI-violation percentage for
    AFDQN-avg compared with MDQN and Minimum-Delay versus standard deviation (SD)
    of the load normalized by SD of the load in the training phase. Show All FIGURE
    11. The effect of increasing the number of IoT nodes per agent (UAV) on AoI and
    energy consumption for AFDQN-avg compared with MDQN and Minimum-Delay. Show All
    In Fig. 10, a comparison similar to Fig. 8 assesses the impact of increasing load
    standard deviation (SD) on network performance in terms of AoI and AoI violation.
    Generally, an increase in SD raises the average AoI and AoI violation percentage
    for all methods, as larger SD values force agents to find the best action across
    a larger state space. As it is evident, the proposed AFDQN method exhibits the
    smallest average AoI and AoI violation percentage compared to baseline methods.
    However, the Minimum Delay method performs the worst due to its localized short-term
    target. Finally in Fig. 11, the impact of increasing the number of IoT nodes per
    agent (UAV) on the proposed method’s performance in terms of AoI and energy consumption
    is explored and compared with MDQN and Minimum Delay algorithms. Results demonstrate
    the superior performance of the proposed AFDQN method compared to baselines. Additionally,
    as the number of IoT nodes reaches 120 and beyond, there is an increased demand
    for CPU and storage; limited resources in processing nodes eventually lead to
    increased rejection of requests, causing a rise in AoI. However, network energy
    consumption remains unchanged, as the volume of active processes remains equal
    to the maximum capacity of processing nodes. SECTION IX. Conclusion We considered
    the problem of dynamic orchestration of NFV-enabled SFCs in smart agriculture
    applications to jointly minimize the AoI and energy consumption throughout the
    network. Especially, the problem is formulated as a decentralized POMDP. Then,
    adopting the symmetric structure of the network, we analytically proved that the
    optimal policy among the agents is behaving similarly. Accordingly, a novel federated-based
    DQN method was proposed to solve the problem efficiently. The proposed method
    is distributed and energy efficient, as the local agents just need to share the
    parameters of their locally trained model with each other. Although the primary
    goal of this method is to provide privacy among the agents, in our problem, this
    significantly decreased the communication overhead, and additionally, the total
    energy consumption of the network. In terms of freshness of information, the AoI
    is minimized jointly, and the achieved value for the AoI, while the parameter
    setting is set to be close to real values, is appropriate for most real-time applications.
    Appendix In this section, we aim to simplify the problem of determining the optimal
    policy (22) by utilizing some structural specifications of the developed system
    and problem. Inspiring by the work presented by Yongacoglu et al. [48], we introduce
    a class of Symmetric DEC-POMDP based on the Definition and Lemma presented below.
    Definition 3 (Symmetric DEC-POMDP):A DEC-POMDP is called symmetric if the following
    conditions hold: A u = A u ´ and γ u = γ u ´ , ∀u, u ´ ∈U∀u∈U , ∀a∈A , and an
    arbitrary permutation function σ(.) : r u (s,σ(a))= r σ(u) (s,a) , and T(⋅|s,σ(a))=T(⋅|s,a)
    . Lemma 1:Let G be a symmetric DEC-POMDP, for any u, u ´ ∈U , if π u = π u ´ ,
    then, π u is ϵ -best-response to π −u if and only if π u ´ is ϵ -best-response
    to π − u ´ , where ϵ -best-response (for an arbitrary ϵ≥0) defines as a policy
    that achieves (reach) a reward (cost) within ϵ of the maximum (minimum) value.
    In our VNF scheduling problem, as it is depicted in Fig. 3, at each VNF scheduling
    round t ~ , each distributed agent u∈U , has K packet-flow { Υ k u (t)|t= t ~
    } K k=1 belong to different services each of which requires running F k different
    VNFs on their packets. The agents decide on how to place these VNFs into available
    processing nodes, i.e., other U−1 UAVs, the local server, or itself, in a way
    that jointly minimizes the average AoI and energy consumption according to (17).
    All the agents follow the same goal and the priorities among the agents are the
    same. Without loss of generality, we assume that the agents have chosen the same
    discount factor, { γ u } u∈U =γ . Thus, it can be found that the agents conceptually
    have the same model; an intuitive inference that can be figured out better using
    the following Index Mapping rule. Definition 4 (Index Mapping):For each function
    f∈ F k of packet-flow Υ k u (t)|t= t ~ , by definition we assume that the policy
    π u ( t ~ ) outputs I fk u ∈{0,1,…,U−1,M} is the i th candidate processing node,
    I i , as depicted in Fig. 12. The actual selected processing node among p∈{u∪{
    u ´ } u ´ ≠u ∪M} , will be, p u ( t ~ )={ [(u+i)modU] th UAV, M, if  I i ≠ I M
    if  I i = I M , ∀ I fk u = I i . (32) View Source Then, χ fk pu (|t= t ~ )=1 ,
    and X k u , B k pu will be updated accordingly. FIGURE 12. Index mapping mechanism.
    Show All Now, according to Definition 3and Definition 4, the following lemma can
    be driven. Lemma 2:Problem 1is a symmetric DEC-POMDP. Proof:According to Definition
    4, the agents have the same set of actions { A u } u∈U ={ I i } i∈U∪M , so the
    condition (i) of Definition 3 is met. Let define C ℓ as circular shift operand
    with arbitrary value of ℓ , C ℓ (⋅)=[⋅+ℓ]modU . Considering a circular shift of
    ℓ over joint action A , C ℓ (A) , we will have, a C ℓ (u) = a u , thus from (32),
    for each I fk C ℓ (u) = I fk u = I i the selected processing node p C ℓ (u) (t)
    will be, p C ℓ (u) ( t ~ )={ [( C ℓ (u)+i)modU] th UAV, M, if  I i ≠ I M if  I
    i = I M , ∀ I fk C ℓ (u) = I i . View Source Or, p C ℓ (u) ( t ~ )= C ℓ ( p u
    ( t ~ )). (33) View Source Equation (33) means Problem 1 is circularly symmetric.
    To be more specific, we do not have any special dependency on the identity of
    the agents and the state transitions depend only on the profile of joint actions
    performed by all agents. Accordingly, permuting the agents’ actions does not change
    the conditional transition probabilities, T(⋅|s, C ℓ (A))=T(⋅|s,A) , and this
    permutation will lead to a corresponding permutation of rewards, r C ℓ (u) (s,A)=
    r u (s, C ℓ (A)) . Hence, the second condition of Definition 3 is also satisfied
    and the proof is complete. According to Lemma 2, being circularly symmetric means
    that the best agents’ policy, π ∗ are the same, { π u } U−1 u=0 = π ∗ . For such
    a condition, Lemma 1implies that the problem of finding the best policy can be
    reduced to finding π ∗ u , the best response to ∏ u ´ ≠u π u ´ , while π u ´ =
    π u ,∀ u ´ ≠u . Although this result is promising, from an implementation viewpoint,
    proposing a distributed solution for finding the best policy while requiring the
    same policy for all the agents is challenging. Recalling (18), in addition to
    the current hidden state, in DEC-POMDP the agents need to infer the action (the
    policy) of the other agents. The subsequent Corollary establishes a connection
    between this inference and solely relying on the local observations of the agents,
    thereby rendering it feasible. Corollary 2:With the same initialization of the
    belief function, { b u (0) } U−1 u=0 =b(0) , for a circularly symmetric DEC-POMDP,
    the local observation h u ( t ~ ) is a sufficient statistic for determining the
    optimal policy π ∗ . Proof:Assume that using a mechanism, the agents peruse the
    same policy π u ( t ~ ) , while they are learning the optimal policy π ∗ . Then,
    the multi-agent belief state b u, t ~ (s, π −u ) would be, b u, t ~ (s, π −u )=
    = = b u, t ~ ⎛ ⎝ s, ∏ u ´ ≠u π u ⎞ ⎠ P(s( t ~ )=s| h u ( t ~ ), b u (0), π u )
    b π u u (s, t ~ ).∀u∈U (34) View Source So, for each agent u , the local observation
    h u ( t ~ ) and knowing its local policy π u is enough for determining the belief-state
    b π u u (s, t ~ ) . In a DEC-POMDP, the set { b π u u (s, t ~ ) } U−1 u=0 is sufficient
    statistic for the joint history H , and the proof is complete. Authors Figures
    References Keywords Metrics Footnotes More Like This Artificial Intelligence and
    Internet of Things for Sustainable Farming and Smart Agriculture IEEE Access Published:
    2023 Multiagent Deep-Reinforcement-Learning-Based Virtual Resource Allocation
    Through Network Function Virtualization in Internet of Things IEEE Internet of
    Things Journal Published: 2021 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Open Journal of the Communications Society
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: AoI-Aware Energy-Efficient SFC in UAV-Aided Smart Agriculture Using Asynchronous
    Federated Learning
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Prasad V.
  - Yousuf A.
  - Mirzakhaninafchi H.
  - Satpathi A.
  - Kumar A.
  citation_count: '0'
  description: The food safety has become an increasingly important challenge worldwide,
    particularly as the world population continues to increase and arable lands are
    diminishing due to raising problems like urban development, land degradation,
    soil loss/erosion, water shortages, etc. The smart farming is indeed a new idea
    that refers to managing farms with the use of cutting-edge technologies such as
    sensors-based systems, Internet of Things (IoT), robotics, drones, artificial
    intelligence (AI), cloud computing, and big data to enhance the quality and quantity
    of products while optimizing the human labor needed for production. The disciplines
    and expertise now required for agricultural sector contain Global Positioning
    System (GPS), robotics/cybernetics, image processing (computer-based), climate/micro-climate
    prediction etc. The protected cultivation environment is a relatively easy system
    for automated machinery due to its structured nature. The development of systems
    is easier under the protected cultivation environment. The automation systems
    for protected cultivation deal with micro-climate control, seedling production,
    spraying, harvesting, irrigation etc. Here, some of the currently used smart farming
    technologies have been discussed highlighting their necessity, applications, and
    the automation under protected cultivation.
  doi: 10.1201/9781003402596-14
  full_citation: '>'
  full_text: '>

    "Access Provided By:University of Nebraska-Lincoln T&F eBooks ‍ Advanced Search
    Login About Us Subjects Browse Products Request a trial Librarian Resources What''s
    New!! HomeEnvironment & AgricultureBotanyProtected CultivationSmart Farming Technologies
    for Protected Cultivation Chapter Smart Farming Technologies for Protected Cultivation
    ByVishnu Prasad, Abrar Yousuf, Hasan Mirzakhaninafchi, Anurag Satpathi, Aekesh
    Kumar Book Protected Cultivation Edition 1st Edition First Published 2024 Imprint
    Apple Academic Press Pages 23 eBook ISBN 9781003402596 Share ABSTRACT The food
    safety has become an increasingly important challenge worldwide, particularly
    as the world population continues to increase and arable lands are diminishing
    due to raising problems like urban development, land degradation, soil loss/erosion,
    water shortages, etc. The smart farming is indeed a new idea that refers to managing
    farms with the use of cuttingedge technologies such as sensors-based systems,
    Internet of Things (IoT), robotics, drones, artificial intelligence (AI), cloud
    computing, and big data to enhance the quality and quantity of products while
    optimizing the human labor needed for production. The disciplines and expertise
    now required 404for agricultural sector contain Global Positioning System (GPS),
    robotics/ cybernetics, image processing (computer-based), climate/micro-climate
    prediction etc. The protected cultivation environment is a relatively easy system
    for automated machinery due to its structured nature. The development of systems
    is easier under the protected cultivation environment. The automation systems
    for protected cultivation deal with micro-climate control, seedling production,
    spraying, harvesting, irrigation etc. Here, some of the currently used smart farming
    technologies have been discussed highlighting their necessity, applications, and
    the automation under protected cultivation. Previous Chapter Next Chapter Your
    institution has not purchased this content. Please get in touch with your librarian
    to recommend this.  To purchase a print version of this book for personal use
    or request an inspection copy  GO TO ROUTLEDGE.COM  Policies Privacy Policy Terms
    & Conditions Cookie Policy Journals Taylor & Francis Online Corporate Taylor &
    Francis Group Help & Contact Students/Researchers Librarians/Institutions Connect
    with us Registered in England & Wales No. 3099067 5 Howick Place | London | SW1P
    1WG © 2024 Informa UK Limited"'
  inline_citation: '>'
  journal: 'Protected Cultivation: Structural Design, Crop Management Modeling, and
    Automation'
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Smart Farming Technologies for Protected Cultivation
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Rathore N.
  - Rajavat A.
  citation_count: '0'
  description: In today’s digital age, the Internet of Things (IoT) is gaining popularity.
    IoT has made everything smart, for example, smart cities (smart buildings and
    smart homes), smart healthcare (personal monitoring, smart wearables), industrial
    automation (especially manufacturing), commercial (shopping systems, retail),
    and even that agriculture too. IoT is becoming increasingly important in today’s
    digital age, resulting in a rapid rise in the number of devices connected to it.
    Massive amounts of data will be produced by such widely distributed IoT devices
    at the network’s edge. Processing these massive amounts of data in the centralized
    cloud is expected to result in increased 400bandwidth utilization, latency, and
    network congestion. Edge computing has become a popular paradigm in recent years
    for reducing network congestion and serving real-time IoT applications by providing
    services close to enduser devices. Agriculture is the foundation of the economy
    of any nation in the world. By 2050, the world population will need a 70% increase
    in food production to feed an estimated global population of more than 9 billion
    people. Potatoes are consumed all over the world and its production plays an important
    role in agriculture. The two primary diseases that adversely affect the yield
    of potato crop production are early blight and late blight. Therefore, in this
    work, we used containerized microservices to deploy machine learning models to
    resource restricted edge nodes on agricultural land for real-time disease and
    irrigation water requirement prediction in potato crops. Containers are lightweight
    and easy to deploy, making them the ideal choice for running machine learning
    models on resource-constrained edge nodes. We examined AlexNet, MobileNet, and
    VGG16, three deep convolutional neural networks (CNN), to detect these diseases
    automatically. A dataset of 7128 images containing healthy and diseased leaves
    of potato plants was used to train all three CNN models on the cloud. Even if
    training is outsourced, trained models need a lot of RAM; hence, the first aim
    of this study is to find a lightweight CNN model that can easily fit into resource-constrained
    devices. To improve potato crop yield and reduce economic losses, we found and
    deployed lightweight CNN model at the edge node to identify diseases in real time
    using leaf pictures recorded by in-place camera devices. The advantage of the
    developed technique is that by classifying potato leaf pictures in real time on-premises,
    there is no need to transfer images to the cloud for probable disease identification,
    which increases network congestion. The lightweight CNN model achieved 99.87%
    accuracy for both train and test images, according to the results. Precision (P),
    Recall (R), and F1 score (F1) are also displayed, to visualize the model’s efficiency.
    Similarly for real-time prediction of irrigation water requirement in potato crop,
    we trained two machine learning models, Support Vector Machine (SVM) and Logistic
    Regression (LR) on 100,000 values of records. Each record has four input parameters
    (soil moisture, temperature, humidity, and how many days the crop was planted
    before). With four input parameters in each record (soil moisture, temperature,
    humidity, and how many days before the crop was planted), the model decides whether
    the water pump should be turned on or off. The SVM model and the LR model attained
    92 and 73% accuracy, respectively, in determining whether the water pump should
    be turned ON or OFF.
  doi: 10.1201/9781003435228-24
  full_citation: '>'
  full_text: '>

    "Access Provided By:University of Nebraska-Lincoln T&F eBooks ‍ Advanced Search
    Login About Us Subjects Browse Products Request a trial Librarian Resources What''s
    New!! HomeEnvironment & AgricultureAgriculture & Environmental SciencesAgriculturePrecision
    Agriculture for SustainabilitySmart Farming Based on IOT-Edge Computing: Applying
    Machine Learning Models For Disease And Irrigation Water Requirement Prediction
    In Potato Crop Using Containerized Microservices Chapter Smart Farming Based on
    IOT-Edge Computing: Applying Machine Learning Models For Disease And Irrigation
    Water Requirement Prediction In Potato Crop Using Containerized Microservices
    ByNitin Rathore, Anand Rajavat Book Precision Agriculture for Sustainability Edition
    1st Edition First Published 2024 Imprint Apple Academic Press Pages 26 eBook ISBN
    9781003435228 Share ABSTRACT In today’s digital age, the Internet of Things (IoT)
    is gaining popularity. IoT has made everything smart, for example, smart cities
    (smart buildings and smart homes), smart healthcare (personal monitoring, smart
    wearables), industrial automation (especially manufacturing), commercial (shopping
    systems, retail), and even that agriculture too. IoT is becoming increasingly
    important in today’s digital age, resulting in a rapid rise in the number of devices
    connected to it. Massive amounts of data will be produced by such widely distributed
    IoT devices at the network’s edge. Processing these massive amounts of data in
    the centralized cloud is expected to result in increased 400bandwidth utilization,
    latency, and network congestion. Edge computing has become a popular paradigm
    in recent years for reducing network congestion and serving real-time IoT applications
    by providing services close to enduser devices. Agriculture is the foundation
    of the economy of any nation in the world. By 2050, the world population will
    need a 70% increase in food production to feed an estimated global population
    of more than 9 billion people. Potatoes are consumed all over the world and its
    production plays an important role in agriculture. The two primary diseases that
    adversely affect the yield of potato crop production are early blight and late
    blight. Therefore, in this work, we used containerized microservices to deploy
    machine learning models to resource restricted edge nodes on agricultural land
    for real-time disease and irrigation water requirement prediction in potato crops.
    Containers are lightweight and easy to deploy, making them the ideal choice for
    running machine learning models on resource-constrained edge nodes. We examined
    AlexNet, MobileNet, and VGG16, three deep convolutional neural networks (CNN),
    to detect these diseases automatically. A dataset of 7128 images containing healthy
    and diseased leaves of potato plants was used to train all three CNN models on
    the cloud. Even if training is outsourced, trained models need a lot of RAM; hence,
    the first aim of this study is to find a lightweight CNN model that can easily
    fit into resource-constrained devices. To improve potato crop yield and reduce
    economic losses, we found and deployed lightweight CNN model at the edge node
    to identify diseases in real time using leaf pictures recorded by in-place camera
    devices. The advantage of the developed technique is that by classifying potato
    leaf pictures in real time on-premises, there is no need to transfer images to
    the cloud for probable disease identification, which increases network congestion.
    The lightweight CNN model achieved 99.87% accuracy for both train and test images,
    according to the results. Precision (P), Recall (R), and F1 score (F1) are also
    displayed, to visualize the model’s efficiency. Similarly for real-time prediction
    of irrigation water requirement in potato crop, we trained two machine learning
    models, Support Vector Machine (SVM) and Logistic Regression (LR) on 100,000 values
    of records. Each record has four input parameters (soil moisture, temperature,
    humidity, and how many days the crop was planted before). With four input parameters
    in each record (soil moisture, temperature, humidity, and how many days before
    the crop was planted), the model decides whether the water pump should be turned
    on or off. The SVM model and the LR model attained 92 and 73% accuracy, respectively,
    in determining whether the water pump should be turned ON or OFF. Previous Chapter
    Next Chapter Your institution has not purchased this content. Please get in touch
    with your librarian to recommend this.  To purchase a print version of this book
    for personal use or request an inspection copy  GO TO ROUTLEDGE.COM  Policies
    Privacy Policy Terms & Conditions Cookie Policy Journals Taylor & Francis Online
    Corporate Taylor & Francis Group Help & Contact Students/Researchers Librarians/Institutions
    Connect with us Registered in England & Wales No. 3099067 5 Howick Place | London
    | SW1P 1WG © 2024 Informa UK Limited"'
  inline_citation: '>'
  journal: 'Precision Agriculture for Sustainability: Use of Smart Sensors, Actuators,
    and Decision Support Systems'
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'SMART FARMING BASED ON IOT-EDGE COMPUTING: APPLYING MACHINE LEARNING MODELS
    FOR DISEASE AND IRRIGATION WATER REQUIREMENT PREDICTION IN POTATO CROP USING CONTAINERIZED
    MICROSERVICES'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Ooi M.P.L.
  - Sohail S.
  - Huang V.G.
  - Hudson N.
  - Baughman M.
  - Rana O.
  - Hinze A.
  - Chard K.
  - Chard R.
  - Foster I.
  - Spyridopoulos T.
  - Nagra H.
  citation_count: '0'
  description: Sensor applications have become ubiquitous in modern society as the
    digital age continues to advance. AI-based techniques (e.g., machine learning)
    are effective at extracting actionable information from large amounts of data.
    An example would be an automated water irrigation system that uses AI-based techniques
    on soil quality data to decide how to best distribute water. However, these AI-based
    techniques are costly in terms of hardware resources, and Internet-of-Things (IoT)
    sensors are resource-constrained with respect to processing power, energy, and
    storage capacity. These limitations can compromise the security, performance,
    and reliability of sensor-driven applications. To address these concerns, cloud
    computing services can be used by sensor applications for data storage and processing.
    Unfortunately, cloud-based sensor applications that require real-time processing,
    such as medical applications (e.g., fall detection and stroke prediction), are
    vulnerable to issues such as network latency due to the sparse and unreliable
    networks between the sensor nodes and the cloud server [1]. As users approach
    the edge of the communications network, latency issues become more severe and
    frequent. A promising alternative is edge computing, which provides cloud-like
    capabilities at the edge of the network by pushing storage and processing capabilities
    from centralized nodes to edge devices that are closer to where the data are gathered,
    resulting in reduced network delays [2], [3].
  doi: 10.1109/MIM.2023.10328671
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Instrumentation & Measur...
    >Volume: 26 Issue: 9 Measurement and Applications: Exploring the Challenges and
    Opportunities of Hierarchical Federated Learning in Sensor Applications Publisher:
    IEEE Cite This PDF Melanie Po-Leen Ooi; Shaleeza Sohail; Victoria Guiying Huang;
    Nathaniel Hudson; Matt Baughman; Omer Rana; Annika Hinze; Kyle Chard; Ryan Chard
    All Authors 203 Full Text Views Abstract Document Sections Federated Learning
    for Precision Spraying A Hierarchical Federated Learning Architecture for Smart
    Farrning Application Requirements for Hierarchical Federated Learning Opportunities
    and Open Problems Conclusion Authors Figures References Keywords Metrics Abstract:
    Sensor applications have become ubiquitous in modern society as the digital age
    continues to advance. AI-based techniques (e.g., machine learning) are effective
    at extracting actionable information from large amounts of data. An example would
    be an automated water irrigation system that uses AI-based techniques on soil
    quality data to decide how to best distribute water. However, these AI-based techniques
    are costly in terms of hardware resources, and Internet-of-Things (IoT) sensors
    are resource-constrained with respect to processing power, energy, and storage
    capacity. These limitations can compromise the security, performance, and reliability
    of sensor-driven applications. To address these concerns, cloud computing services
    can be used by sensor applications for data storage and processing. Unfortunately,
    cloud-based sensor applications that require real-time processing, such as medical
    applications (e.g., fall detection and stroke prediction), are vulnerable to issues
    such as network latency due to the sparse and unreliable networks between the
    sensor nodes and the cloud server [1]. As users approach the edge of the communications
    network, latency issues become more severe and frequent. A promising alternative
    is edge computing, which provides cloud-like capabilities at the edge of the network
    by pushing storage and processing capabilities from centralized nodes to edge
    devices that are closer to where the data are gathered, resulting in reduced network
    delays [2], [3]. Published in: IEEE Instrumentation & Measurement Magazine ( Volume:
    26, Issue: 9, December 2023) Page(s): 21 - 31 Date of Publication: 24 November
    2023 ISSN Information: DOI: 10.1109/MIM.2023.10328671 Publisher: IEEE Funding
    Agency: Sensor applications have become ubiquitous in modern society as the digital
    age continues to advance. AI-based techniques (e.g., machine learning) are effective
    at extracting actionable information from large amounts of data. An example would
    be an automated water irrigation system that uses AI-based techniques on soil
    quality data to decide how to best distribute water. However, these AI-based techniques
    are costly in terms of hardware resources, and Internet-of-Things (IoT) sensors
    are resource-constrained with respect to processing power, energy, and storage
    capacity. These limitations can compromise the security, performance, and reliability
    of sensor-driven applications. To address these concerns, cloud computing services
    can be used by sensor applications for data storage and processing. Unfortunately,
    cloud-based sensor applications that require real-time processing, such as medical
    applications (e.g., fall detection and stroke prediction), are vulnerable to issues
    such as network latency due to the sparse and unreliable networks between the
    sensor nodes and the cloud server [1]. As users approach the edge of the communications
    network, latency issues become more severe and frequent. A promising alternative
    is edge computing, which provides cloud-like capabilities at the edge of the network
    by pushing storage and processing capabilities from centralized nodes to edge
    devices that are closer to where the data are gathered, resulting in reduced network
    delays [2], [3]. The most common machine learning approach used in cloud-based
    applications is Centralized Learning (Fig. 1a) where datasets from different clients
    are sent to a central cloud for storage and to train a machine learning model.
    A model trained in this centralized manner is potentially the most accurate model
    as it has been trained on all of the datasets. However, centralized training introduces
    challenges associated with transferring data to the cloud, such as data privacy
    and communication overheads. Conversely, Local Learning is an alternative where
    we train the machine learning models directly on the devices where the data are
    hosted using their own local computing resources (Fig. 1b), Since data are not
    shared among clients or with the server, local learning solves the privacy and
    communication overhead issues of centralized learning. However, local learning
    alone can struggle with machine learning bias. This is an emergent problem since
    data at these devices are often non-independent and identically distributed (iid).
    For instance, many data patterns sensors collect are geographically-related. Thus,
    sensors from different locations will likely collect different types of data.
    Learning independently can result in models that do not generalize well which
    can afflict the knowledge extraction across the entire system. A third alternative
    is to apply the recent Federated Learning (FL) paradigm for distributed learning
    (Fig. 1c). FL is a distributed machine learning technique that enables multiple
    clients (e.g., mobile devices, IoT devices) to collaboratively train a shared
    global model without needing their raw data transmitted to the cloud. Instead,
    local models are trained on each client using their own data, similar to local
    learning. Where FL diverges from local learning is that the server will periodically
    collect model updates from the client devices and “average” them to update the
    global model, which is then redistributed to the client devices for further training.
    FL has shown to work well in the face of non-iid data distributions which are
    common in sensor applications. Therefore, FL is a promising solution for several
    challenges associated with decentralized machine learning, such as data privacy,
    communication efficiency, scalability, data unavailability or heterogeneity, system
    heterogeneity in terms of computation power, storage, and energy availability,
    computation efficiency, and better model performance [4], [5]. Standard FL may
    incur high communication costs as the model updates need to be shared with the
    central server, creating an interesting trade-off when considering that centralized
    training requires that all data be shared with the central server (Fig. 2a). In
    cases where the communication between the sensors and the central server is very
    poor (i.e., low data transfer rate, unreliable connection), this can be a significant
    challenge. Such overhead can affect individual sensor life and the overall performance
    of the application, especially if the sensor application has power constraints
    and limited connectivity [6]. One possible solution is to expand the infrastructure
    and use hierarchical FL. Under hierarchical FL, there are additional aggregation
    nodes that may have stronger connections to the nearby sensors. These aggregation
    nodes also participate in additional levels of aggregation to make sure knowledge
    is learned throughout the entire system. Hierarchical FL overcomes some of these
    issues by allowing data to remain on the edge devices, such as sensors and smart
    devices. It enables optimization of computational and communication overheads
    that can be customized to suit the needs of specific applications and networks.
    Fig. 1. Comparison of (a) Centralized, (b) Local, and (c) Federated learning architectures.
    Federated learning enables collaborative learning among multiple edge devices
    without compromising data privacy. Centralized learning relies on a central server
    to train a global model on data from all devices, while local learning trains
    multiple local models on disjoint subsets of data. Show All Fig. 2. Illustration
    of (a) Standard federated learning (FL) and (b) Hierarchical federated learning
    and their interaction between lot devices, edge and cloud servers. The aggregation
    nodes are where the local model updates from the participating devices or intermediary
    nodes are combined to form a global model. Show All Different approaches of hierarchical
    FL can be employed by making use of available networking hubs and structures,
    such as a cloud server that is accessed over the internet and an edge server,
    which is a computer server that is located closer to the devices that it serves
    at the network edge (Fig. 2b). One option is to aggregate models within a cloud
    server, while other options can involve hierarchical aggregation at the edge server
    which sends the model updates to the cloud for further aggregation or storage.
    This allows local processing power and storage capacity to perform distributed
    learning without relying solely on a central server, resulting in improved scalability,
    reduced latency and privacy preservation of sensitive data. While hierarchical
    FL has shown potential in various domains, including precision agriculture and
    environmental monitoring, [4] points out that very few production FL applications
    have been reported, with most work being proof-of-concept prototypes. The paradigm
    itself is relatively new and its implementation requires careful consideration
    of various issues such as data inequality [7], [8] and malicious attacks [9]–[11].
    Another important challenge to overcome with FL is the cost of adoption and the
    incentives to incorporate FL into existing systems. In FL, devices must contribute
    their computational resources and data to train a model. However, some organizations
    may be reluctant to participate in a large FL endeavor due to the computational
    resources needed to participate and data transfer and communication costs. Furthermore,
    there may not be the right incentives to join if a benefit from the global model''s
    performance is not properly recognized. For example, an industry leader may be
    less incentivized to adopt multi-organizational FL if they are already the primary
    source of data as their marginal benefit would be significantly lower. To address
    these challenges, various methods have been proposed to incentivize participation
    in FL. These methods include providing monetary or non-monetary rewards for contributing
    data, ensuring that the global model''s performance benefits all participants,
    and providing greater control over the use of data by participants. For example,
    [12] proposed a reward-based mechanism that provides tokens to devices that contribute
    data to the FL model, which can then be used to purchase services or products.
    Authors in [13] propose a privacy-preserving FL model that allows participants
    to retain control over their data and provides incentives for contributing high-quality
    data. In this article, we present a case study of the feasibility and benefits
    of FL for precision agricultural spraying and extend it to a larger conceptual
    hierarchical FL architecture for smart farming. We also discuss ongoing efforts
    to improve hierarchical FL systems using standardized quality frameworks to systematically
    identify and prioritize the efforts. Finally, we cover open problems associated
    with this technology and highlight its potential to transform numerous domains
    such as precision agriculture, environmental monitoring, healthcare, and smart
    infrastructure. Our goal is to provide a roadmap for further development of hierarchical
    FL in instrumentation and measurement. Federated Learning for Precision Spraying
    In the previous section, we discussed the different types of learning architectures
    that can be applied to edge devices. In this section, we present a case study
    involving precision spraying in agriculture (Fig. 3) to highlight the benefits
    of FL. Traditional spraying methods often apply pesticides uniformly across an
    entire field, leading to waste and potential harm to crops. In contrast, precision
    spraying uses cameras, optical sensors, and GPS receivers to provide accurate
    location data, enabling robots to apply spray only where necessary. However, the
    advanced data processing and machine learning required for precision spraying
    can be resource-intensive, making it challenging to perform all operations on
    the sensor or robot alone. Data collected from sensors can be processed using
    cloud computing relying on connectivity, but this can be a challenge in remote
    environments. By relying on computational resources at the edge server, data can
    be processed in real-time or limited-time to accelerate the decision-making process.
    FL can further improve spray precision by enabling learning from different data
    sources (e.g., across different locations with different distributions of plant/weed
    species) while preserving data privacy and security. This is particularly important
    for farmers who are concerned about data privacy and potential cyberattacks. Furthermore,
    FL can be flexibly performed on a network of edge devices potentially of different
    types, which can scale up or down to meet the needs of different agricultural
    operations, making it a valuable tool for precision spraying. Fig. 3. Precision
    spraying prototype using edge federated learning. Show All In this feasibility
    study, we limit the discussion to a single source of information, which is a near-infrared
    hyperspectral imaging system that is used to guide the operations of a mobile
    precision pesticide spraying robot at each of the three pasture sites (Site A,
    B and C). Each robot processes the input information using a local machine learning
    model (e.g., an image classifier implemented by a Convolutional Neural Network).
    The intent is to have the robot apply spray to a plant only if the plant is classified
    as a weed, ensuring minimal impact on crops. Storing a machine learning model
    locally ensures that spray operations can continue in areas without network coverage.
    Although the local model is trained using local data (∼71 Megabytes), it periodically
    receives updates (∼0.04 Megabytes) from the server via FL to incorporate knowledge
    learned from other pasture sites. With FL, communication is significantly reduced
    from 71 Megabytes to 0.04 Megabytes. Different forms of computation resources
    reside in each pasture site, with the model potentially being trained on the robot
    using single-board computational devices such as Raspberry Pi or Jetson Nano.
    The locally-trained models from each pasture site are then aggregated using Federated
    Averaging [14], a popular aggregation algorithm in FL. The pasture sites are interconnected
    using communication infrastructure for sharing information and enabling FL. The
    dataset used during our evaluation consisted of four labelled classes: three species
    of pastoral weed and a background class of grass (Table 1). The evaluation results
    for our case study with different machine learning methods are shown in Fig. 4,
    whereby FL achieves 96% accuracy. This result is comparable to centralized learning
    where all the data are present, and a marked improvement compared to local learning
    where only local data are present. Our result confirms that FL is capable of addressing
    the dilemma between network latency, bandwidth limitations, data privacy and data
    sharing while providing comparable model performance. Table 1 Pasture Image dataset
    with imbalanced class distributions and disparate volumes of data across sites
    A Hierarchical Federated Learning Architecture for Smart Farrning We now consider
    broadening the precision spraying use case to a larger conceptual hierarchical
    FL architecture for smart farming. Precision agriculture often involves gathering
    heterogeneous data from various sensors within a farm. By leveraging FL, farmers
    can benefit from insights gained from other farms without compromising the privacy
    of their own raw data. This will enable them to enhance crop yields and minimize
    wastage. Fig. 5 illustrates the physical, cyber and networked (interconnected)
    view of a precision agriculture robot at work. Fig. 5a shows the “physical world”
    where the robot has sensors on board and navigates to perform tasks such as harvesting,
    weeding, and spraying. Fig. 5b represents the “cyber world” where the robot processes
    input information from its sensors using a local machine learning model to perform
    high priority tasks that must continue even when the communication fails (i.e.,
    navigation). The robot also monitors the quality of service for communication
    and decides whether to pass on further information or receive information from
    the cloud. Fig. 5c is the “interconnected world” where a group of robots is connected
    via a communication infrastructure for FL to share knowledge and improve their
    respective local machine learning models based on collective learned experiences.
    The types of sensor systems used for smart farming are heterogeneous. For example,
    a smart farm may rely heavily on IoT sensors and cameras to collect and process
    data related to soil quality and plant visual information. Additionally, smart
    farms may use multiple data sources to optimize farming operations. These data
    sources may include historical data, real-time sensor data, and publicly available
    data to predict soil water levels and future weather patterns with machine learning
    models. Fig. 6 illustrates an example of a hierarchical FL architecture for smart
    farming to train lightweight machine learning models on edge devices. Fig. 4.
    Classification accuracy comparison between centralized, local, and federated machine
    learning approaches trained on dataset described in table 1. Show All Fig. 5.
    Illustration of hierarchical federated learning in precision agriculture. (a)
    Physical world; (b) Cyber world; (c) Interconnected world. Show All Fig. 6. Illustration
    of a hierarchical federated learning architecture for smart farming. Show All
    In this example, the architecture uses Apache Kafka, a popular distributed event
    streaming platform. Kafka is used to collect data from IoT devices and sensors
    located at the edge of the network, enabling real-time processing and response
    to changing conditions. Instead of waiting for large amounts of data to be collected
    and sent to a remote, central server, data streaming enables the sensor devices
    to transmit the local models to the edge servers in real-time—thus reducing latency
    and facilitating more efficient use of available network bandwidth. Hierarchical
    FL allows for adaptive clustering of the edge devices involved in the FL process,
    whereby groups of devices can be divided into smaller clusters for the training
    depending on device availability, scalability and power requirements. By making
    use of Kafka clusters to facilitate communication between the edge devices and
    the FL framework, fault tolerance can be incorporated with multiple brokers running
    on different machines to ensure high availability and data replication. FuncX
    [15] is a federated function-as-a-service platform that enables computation, represented
    as programming functions, to be dispatched for execution on edge resources. FuncX
    is used here to manage the deployment of the machine learning models to the edge
    devices and to invoke the models for inference and training. FuncX uses the Parsl
    [16] parallel programming library to manage the parallel execution of the FL tasks
    on edge devices. It is worth noting that this simple architecture can be easily
    extended to include heterogeneous resources such as Raspberry Pis and Nvidia Jetsons
    with GPUs, which can be deployed near the sensors for more local data processing.
    This introduces interesting research questions on the implicit trade-offs related
    to such system heterogeneity. Overall, using a hierarchical FL architecture for
    edge devices has the potential to revolutionize smart farming by enabling more
    efficient and effective data sharing, processing and decision-making, resulting
    in improved crop yields and reduced water waste. It is also resilient against
    issues such as unreliable network connectivity, which is an important consideration
    as limited network coverage is commonly encountered in agricultural land. Similar
    architectures can be developed for other applications such as: Environmental monitoring:
    Hierarchical FL could enable better analysis of data collected from remote sensors
    and devices, leading to better understanding and management of natural resources.
    Healthcare: Medical sites can collaborate and share machine learning models to
    improve the accuracy of diagnosis and treatment without having to share sensitive
    patient information. Wearable monitoring devices: IoT devices are integrated into
    devices to monitor human biometric data such as heart rate, temperature and movement
    patterns aiming to identify potential safety hazards and improve worker safety
    in the hazardous work environment. Application Requirements for Hierarchical Federated
    Learning Hierarchical FL systems have great potential to realize new sensor-driven
    applications, as discussed in the previous section. However, the technology faces
    numerous challenges due to the diverse nature of these applications and the equally
    diverse performance requirements. Some of these requirements can conflict with
    one another. To address the needs of these systems systematically, we recommend
    using two widely recognized standards for software quality and data quality, which
    are the ISO/IEC 25012 [17] and ISO/IEC 25010 [18] frameworks, respectively. By
    applying these frameworks, we can identify and prioritize the requirements, design
    appropriate performance metrics, and develop techniques and algorithms that optimize
    the trade-offs between conflicting requirements. This will help ensure that hierarchical
    FL systems are reliable, efficient, and effective and can be deployed in a wide
    range of real-world applications. Functionality is a crucial metric that measures
    the system''s ability to perform consistently and accurately over time. This metric
    is closely related to data quality since poor-quality data can result in unreliable
    and inaccurate machine learning models. Optimizing hierarchical FL parameters,
    applying model personalization and transfer learning techniques, and adapting
    the models to the specific characteristics of each device can help improve functionality.
    Reliability is important for edge devices, which often operate under intermittent
    connectivity, mobility, and resource-constrained conditions [19]. These challenges
    can make it difficult to develop efficient and reliable FL systems. To overcome
    these challenges, researchers are exploring techniques such as task offloading
    [20], adaptive sampling [21], and reinforcement learning to optimize the system
    performance and adapt to changing edge computing environments [22]. Redundancy
    can be introduced by configuring the edge devices into different clusters, which
    may improve reliability in hierarchical FL. Performance efficiency can be evaluated
    by quantifying the computation and communication overheads. In hierarchical FL
    systems, the edge server acts as a coordinator, responsible for aggregating and
    processing the data from multiple edge devices [23]. This can create a huge computationaland
    communication burden on the edge server, which can result in high latency, reduced
    system performance, and increased communication costs. To mitigate these challenges,
    researchers are exploring techniques such as partitioning and scheduling to distribute
    the computation and communication load across multiple edge servers and among
    cloud and edge servers [6]. The use of data streaming techniques helps to further
    reduce communication overheads while also increasing the reliability of the edge
    systems. Furthermore, due to resource constraints, mobility, and varying edge
    computing environments, engineers should consider metrics like system scalability,
    cost/benefit balance, and application size on the edge device to evaluate resource
    utilization. Techniques like task offloading, adaptive sampling, and reinforcement
    learning can further optimize system performance and adapt to changing edge computing
    environments. The convergence rate of the learning process is also a critical
    consideration. Compatibility is essential in terms of device heterogeneity, where
    edge devices may not have the same type of sensors and may run on different operating
    systems and software. Edge devices used in FL systems may differ in terms of their
    hardware capabilities, such as CPU processing power, memory, and battery life,
    as well as their software configurations, such as operating systems and libraries.
    This heterogeneity can lead to statistical heterogeneity in the data collected
    from the devices, making it challenging to develop models that generalize well
    across all devices [24]. To overcome this challenge, researchers are exploring
    methods such as transfer learning [25] and model personalization [26] that can
    adapt the models to the specific characteristics of each device. Security is a
    significant concern for hierarchical FL systems. FL provides some level of privacy,
    but to protect data and models from malicious actors, techniques like secure aggregation,
    differential privacy, blockchain, and homomorphic encryption can be applied. Hierarchical
    FL systems may have edge servers from different sources, which makes the systems
    more vulnerable to security threats such as data leakage, model poisoning, and
    inference attacks [23]. To address these challenges, researchers are exploring
    techniques such as secure aggregation [27], differential privacy [28], and homomorphic
    encryption [29] to ensure that the data and models are protected from malicious
    actors. Metrics like confidentiality, currentness, and reliability can be used
    to evaluate the severity of security challenges, as defined by the ISO/IEC 25010
    standard for data security and accessibility. Dynamic infrastructure is a common
    problem in hierarchical FL systems. In these settings, the aggregation nodes are
    not necessarily static or fixed. It may be necessary for the aggregation node
    to change over time if a node is rendered offline due to low battery or a poor
    communication channel. This makes ensuring stable hierarchical FL difficult. Strategies
    to prevent this can be resource-aware real-time decision making where edge devices
    coordinate among themselves to decide how communication should be done among them.
    Software support: Currently, common FL frameworks (e.g., Flower, PySyft) do not
    natively support hierarchical FL, especially for highly dynamic systems where
    infrastructure may change over time. Opportunities and Open Problems The opportunities
    and future research directions for using FL for sensing and measurement can be
    organized into three key axes: resource management and coordination of devices
    that make up the FL system; data management and access; and application-specific
    considerations, such as the use of UAVs [30] and Internet of Medical Things [23].
    In this section, we elaborate on the first two axes, which have general applicability
    across different domains. The third is highly domain-specific and thus not included
    in this general roadmap. Resource Management and Coordination FL opens up new
    methods for supporting fault tolerance of IoT devices. The use of multiple IoT
    devices increases the completeness of data and facilitates the detection and correction
    of erroneous readings and faulty operations. An FL system capable of supporting
    multiple heterogeneous devices and able to recover from faults is reported in
    [31]. A hierarchical FLsystem able to account for the hierarchy of edge servers
    may result in multiple memberships for IoT devices requiring recovery and adaptation
    at several levels. Another exciting direction is the integration of self-adaptivity
    into IoT devices using hierarchical FL. IoT devices become self-adaptive by learning
    from their past behaviors and performance data, can detect changes in environmental
    conditions and predict equipment failure, and automatically adjust device parameters
    [32]. As IoT devices collect knowledge about their environment, they must share
    knowledge to better understand their environment and its dynamics. However, a
    collective system of self-aware devices does not have a centralized knowledge
    base. FL could facilitate sharing of knowledge between devices as a collective.
    Unlike context-aware systems, which typically assume a ground-truth-based environmental
    context that is true for all IoT devices, it is explicitly acknowledged that self-aware
    devices in the collective systems will have different experiences of a shared
    environment [33]. A federated system can be expanded to incorporate information
    for the edge servers at the membership level to provide self-adaptiveness for
    different branches of the edge computing infrastructure and provide context on
    how the information was gathered. Hierarchical FL architectures are inherently
    resilient against network latency and bandwidth limitations. They therefore open
    up new opportunities for network optimization due to the heterogeneity of edge
    environments. For example, network routing needs to be dynamically adapted and
    optimized to the traffic patterns and topologies to improve network throughput
    and latency. Meanwhile, new network designs and paradigms can be introduced, such
    as software-defined networking and blockchain. New algorithms and techniques that
    are specifically designed to optimize resource allocation in edge computing environments
    can dynamically allocate computational and communication resources to different
    tasks based on their priority and application-specific requirements. This allows
    for real-time balancing of multiple objectives. For example, a healthcare application
    that uses a large number of medical sensors to collect, adapt, and react to medical
    information in real time requires security robustness and resource optimization
    for computational and communication tasks [34]. The energy consumption of IoT
    devices and edge computing infrastructure can be optimized by dynamically adapting
    the computational workload and communication overhead to the available energy
    and power constraints. Exploring multi-objective optimization techniques such
    as evolutionary algorithms and Pareto optimization is another direction of research
    that is crucial due to the complexity of hierarchical FL systems. There is a need
    to balance multiple objectives and constraints, such as communication overhead,
    energy consumption, privacy preservation, and security, while creating a global
    machine learning model with limited and heterogeneous resources. This requires
    the coordination of multiple clients and servers at different layers of the system,
    creating a complex interaction network. Additionally, the underlying technologies
    used, such as wireless communication, data storage and processing, and machine
    learning algorithms, introduce their sets of constraints and trade-offs that need
    to be considered in the optimization process, where not only performance but scalability
    needs careful consideration when optimizing these conflicting objectives. Fig.
    7. Future directions for hierarchical federated learning in sensor applications.
    Show All Data Management and Access While FL adds a layer of privacy around user
    data by eliminating the need to share data with others, sharing model updates
    do not offer privacy guarantees as individual data points can be reconstructed
    [35]. To address this issue, privacy-preserving FL can be expanded using techniques
    such as differential privacy, homomorphic encryption, digital signature, and hash
    functions [23], [36]. These techniques enable FL in edge computing environments
    while preserving the privacy of data and participants. For instance, differential
    privacy provides privacy guarantees for medical image analysis. In unstable edge
    computing environments, such as smart healthcare, a privacy protection scheme
    is proposed that provides gradient privacy and resistance to collusion and replay
    attacks for the Internet of Medical Things (IoMT) [23]. A privacy protection technique
    for a hierarchical FL system needs to be computationally efficient and adaptable
    to the underlying learning algorithms, with an ability to effectively scale to
    a large number of clients and servers. Fig. 7 summarizes some of the opportunities
    presented by hierarchical FL that make it an exciting area of research for engineers
    and academicians in the field of instrumentation and measurement. Conclusion Electrical
    and Electronics Engineers have a critical role to play in driving technological
    advancements to address global challenges and advance the Sustainable Development
    Goals (SDGs) established by the United Nations in 2015. Hierarchical federated
    learning is an emerging technology that enhances the intelligence of sensor systems
    in many applications such as environmental quality management, personalized health-care
    devices, and precision agriculture. Secure, resilient, and robust sensor systems
    that support real-time, data-driven decision-making are valuable infrastructure
    for helping us reduce carbon emissions (SDG 13–Climate Action), promote sustainable
    urbanization (SDG 11-Sustainable Cities and Communities), and improve healthcare
    outcomes (SDG 3–Health and Well-being). We urge researchers and practitioners
    to collaborate on the opportunities and open problems presented in this article
    to realize the full potential of this technology. ACKNOWLEDGMENT This research
    was supported in part by the US Department of Energy (DOE) under Contract DE-AC02-06CHI1357,
    as well as the New Zealand Royal Society under the Rutherford Discovery Fellowship
    programme. Authors Figures References Keywords Metrics More Like This Integration
    of IoT, Edge Computing and Cloud Computing for Monitoring and Controlling Automated
    External Defibrillator Cabinets in Emergency Medical Service 2019 5th International
    Conference on Information Management (ICIM) Published: 2019 Cloud computing driven
    efficient mapping on soil moisture under sensor web environment 2016 Fifth International
    Conference on Agro-Geoinformatics (Agro-Geoinformatics) Published: 2016 Show More
    IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Instrumentation and Measurement Magazine
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Measurement and Applications: Exploring the Challenges and Opportunities
    of Hierarchical Federated Learning in Sensor Applications'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Chamara N.
  - Bai G.
  - Ge Y.
  citation_count: '1'
  description: 'Precision Agriculture (PA) promises to meet the future demands for
    food, feed, fiber, and fuel while keeping their production sustainable and environmentally
    friendly. PA relies heavily on sensing technologies to inform site-specific decision
    supports for planting, irrigation, fertilization, spraying, and harvesting. Traditional
    point-based sensors enjoy small data sizes but are limited in their capacity to
    measure plant and canopy parameters. On the other hand, imaging sensors can be
    powerful in measuring a wide range of these parameters, especially when coupled
    with Artificial Intelligence. The challenge, however, is the lack of computing,
    electric power, and connectivity infrastructure in agricultural fields, preventing
    the full utilization of imaging sensors. This paper reported AICropCAM, a field-deployable
    imaging framework that integrated edge image processing, Internet of Things (IoT),
    and LoRaWAN for low-power, long-range communication. The core component of AICropCAM
    is a stack of four Deep Convolutional Neural Networks (DCNN) models running sequentially:
    CropClassiNet for crop type classification, CanopySegNet for canopy cover quantification,
    PlantCountNet for plant and weed counting, and InsectNet for insect identification.
    These DCNN models were trained and tested with >43,000 field crop images collected
    offline. AICropCAM was embodied on a distributed wireless sensor network with
    its sensor node consisting of an RGB camera for image acquisition, a Raspberry
    Pi 4B single-board computer for edge image processing, and an Arduino MKR1310
    for LoRa communication and power management. Our testing showed that the time
    to run the DCNN models ranged from 0.20 s for InsectNet to 20.20 s for CanopySegNet,
    and power consumption ranged from 3.68 W for InsectNet to 5.83 W for CanopySegNet.
    The classification model CropClassiNet reported 94.5 % accuracy, and the segmentation
    model CanopySegNet reported 92.83 % accuracy. The two object detection models
    PlantCountNet and InsectNet reported mean average precision of 0.69 and 0.02 for
    the test images. Predictions from the DCNN models were transmitted to the ThingSpeak
    IoT platform for visualization and analytics. We concluded that AICropCAM successfully
    implemented image processing on the edge, drastically reduced the amount of data
    being transmitted, and could satisfy the real-time need for decision-making in
    PA. AICropCAM can be deployed on moving platforms such as center pivots or drones
    to increase its spatial coverage and resolution to support crop monitoring and
    field operations.'
  doi: 10.1016/j.compag.2023.108420
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Graphical abstract Keywords 1. Introduction 2. Materials
    and methods 3. Results and discussion 4. Conclusion and future perspectives Funding
    CRediT authorship contribution statement Declaration of Competing Interest Acknowledgements
    Data availability References Show full outline Cited by (1) Figures (12) Show
    6 more figures Tables (7) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6 Show
    all tables Computers and Electronics in Agriculture Volume 215, December 2023,
    108420 AICropCAM: Deploying classification, segmentation, detection, and counting
    deep-learning models for crop monitoring on the edge Author links open overlay
    panel Nipuna Chamara a, Geng Bai a, Yufeng Ge a b Show more Share Cite https://doi.org/10.1016/j.compag.2023.108420
    Get rights and content Under a Creative Commons license open access Highlights
    • We developed AICropCAM, an edge-computing enabled camera system for crop monitoring.
    • It integrated Raspberry Pi and Arduino for image processing and LoRa communication.
    • It ran a stack of four deep neural networks to characterize multiple plant/canopy
    parameters. • We quantified the power consumption and speed of the system for
    edge image-processing. • AICropCAM is a next-generation enabling technology for
    real-time, low-latency Ag applications. Abstract Precision Agriculture (PA) promises
    to meet the future demands for food, feed, fiber, and fuel while keeping their
    production sustainable and environmentally friendly. PA relies heavily on sensing
    technologies to inform site-specific decision supports for planting, irrigation,
    fertilization, spraying, and harvesting. Traditional point-based sensors enjoy
    small data sizes but are limited in their capacity to measure plant and canopy
    parameters. On the other hand, imaging sensors can be powerful in measuring a
    wide range of these parameters, especially when coupled with Artificial Intelligence.
    The challenge, however, is the lack of computing, electric power, and connectivity
    infrastructure in agricultural fields, preventing the full utilization of imaging
    sensors. This paper reported AICropCAM, a field-deployable imaging framework that
    integrated edge image processing, Internet of Things (IoT), and LoRaWAN for low-power,
    long-range communication. The core component of AICropCAM is a stack of four Deep
    Convolutional Neural Networks (DCNN) models running sequentially: CropClassiNet
    for crop type classification, CanopySegNet for canopy cover quantification, PlantCountNet
    for plant and weed counting, and InsectNet for insect identification. These DCNN
    models were trained and tested with >43,000 field crop images collected offline.
    AICropCAM was embodied on a distributed wireless sensor network with its sensor
    node consisting of an RGB camera for image acquisition, a Raspberry Pi 4B single-board
    computer for edge image processing, and an Arduino MKR1310 for LoRa communication
    and power management. Our testing showed that the time to run the DCNN models
    ranged from 0.20 s for InsectNet to 20.20 s for CanopySegNet, and power consumption
    ranged from 3.68 W for InsectNet to 5.83 W for CanopySegNet. The classification
    model CropClassiNet reported 94.5 % accuracy, and the segmentation model CanopySegNet
    reported 92.83 % accuracy. The two object detection models PlantCountNet and InsectNet
    reported mean average precision of 0.69 and 0.02 for the test images. Predictions
    from the DCNN models were transmitted to the ThingSpeak IoT platform for visualization
    and analytics. We concluded that AICropCAM successfully implemented image processing
    on the edge, drastically reduced the amount of data being transmitted, and could
    satisfy the real-time need for decision-making in PA. AICropCAM can be deployed
    on moving platforms such as center pivots or drones to increase its spatial coverage
    and resolution to support crop monitoring and field operations. Graphical abstract
    Download : Download high-res image (227KB) Download : Download full-size image
    Previous article in issue Next article in issue Keywords Artificial intelligenceComputer
    visionEdge computingInternet of thingsLoRaWANPrecision agriculture 1. Introduction
    The demands for food, feed, fiber, and fuel increase rapidly due to the fast expansion
    of the global population, income growth, technological advancement, and transport
    and logistics improvements (van Dijk et al., 2021). Precision agriculture (PA),
    which seeks to apply the right amount of inputs (fertilizers, irrigation water,
    pesticides, and other chemicals) in the right location at the right time, is essential
    to meet the requirements of future global food production, as well as environmental
    sustainability and climate resilience. PA is predicated on accurate sensor measurements,
    timely and sound decision-making, and automated actuators. The backbone of PA
    is the Internet of Things (IoT) technology that automates data collection, data
    analytics, data presentation, control, and efficient data communication (Chamara
    et al., 2022). Imaging sensors or digital cameras are essential for PA as they
    can capture more information than traditional scalar or vector sensors. Images
    can capture crop phenology for precise decision-making (Taylor and Browning, 2022,
    Tian et al., 2020). Cyclic events such as vegetative growth, flowering, leaf count
    and color change, maturation, and senescence are studied in crop phenology, which
    is essential to PA as it determines the management inputs required by crops. Moreover,
    images have rich information on the scene that allows for pest pressure evaluation.
    At present, a limited number of sensors are available for pest identification
    and pest pressure estimation. Among them, imaging sensors provide the most promising
    solution. Conventional (handcrafted feature extraction) and Artificial Intelligence
    (AI)-based image processing are the two branches of image processing. Traditional
    approaches extract image features defined by shape, texture, and color (Anubha
    et al., 2019, Yuan et al., 2019). The AI-based methods use Convolutional Neural
    Networks (CNN) to extract features from images (Luis et al., 2020). CNN models
    with multiple hidden layers for feature extraction and learning are considered
    Deep Convolutional Neural Networks (DCNN) (LeCun et al., 1998). Conventional imaging
    platforms in PA store images locally using onboard storage memories. Post processing
    refers to the processing of images stored at the central data storage in batches
    at a later time to extract useful information (Aasen et al., 2020). Imaging platforms
    that can access the internet through a stable connection with high bandwidth can
    automatically upload images to Cloud data storage. The vast majority of farmlands
    worldwide are in rural and remote areas with poor access to electric power and
    internet connectivity. This represents a big challenge for camera systems deployed
    in rural farmlands for high-speed image processing, data transmission, and low-latency
    decision-making (Richardson, 2019). Post-processing of crop images has been used
    for the estimation of leaf area index (Aasen et al., 2020), growth rate (Sakamoto
    et al., 2012), leaf chlorophyll and nitrogen content (Wang et al., 2014), fruit
    counts (Wang et al., 2014), and plant height (Sritarapipat et al., 2014). Further
    post-image processing allows for the assessment of biotic stress, such as pest
    density (Barbedo, 2014; Park et al., 2007) and weed pressure (Wang et al., 2019),
    as well as abiotic stress, such as nutrient deficiency (Ghorai et al., 2021).
    Richardson (2019) suggested that deep learning-based methods have the potential
    to facilitate the extraction of more sophisticated phenological data from both
    new and previously archived camera imagery compared to conventional image processing.
    Semantic segmentation-based canopy coverage (CC) estimation (Chamara et al., 2021;
    Liang et al., 2023), image classification-based crop identification (Anubha et
    al., 2019), disease identification (Sharma et al., 2020), growth stage prediction
    (Yasrab et al., 2021) and object detection-based plant feature identification
    (A. Wang et al., 2019) are examples of DCNN applications in agriculture. Conventional
    image processing requires less computational power and less energy, but they are
    limited in adaption to new scenarios, while deep learning requires high computational
    power and consumes more energy. DCNN models require large memory due to the large
    number of parameters these models hold. Therefore, it is not easy to implement
    these models practically in embedded systems that have less memory and computation
    power. These models also require a large amount of data to train to predict with
    high accuracy. Therefore, it is resource intensive. Edge image processing is the
    image processing done on image-capturing devices. The main advantage of edge image
    computing is that it lowers the high throughput data transmission requirement
    over a wireless IoT-enabled imaging network (Cao et al., 2020). Wang et al. (2022a)
    demonstrated the capability of identifying potted flowers with precision above
    89 % in real-time in a Jetson TX 2 computing module based on a DCNN algorithm.
    These authors suggested that a cloud-edge collaborative framework could achieve
    real-time and automatic learning for the DCNN model they have developed. Wang
    et al. (2022b) proposed a real-time weed detection model run on Jetson AGX Xavier
    for field robots. The authors proved it was possible to do real-time weed detection
    with a precision above 90 % yet required expensive hardware. Wang et al. (2022a)
    reviewed Raspberry Pi single-board computer-based real-time image processing applications.
    They concluded that Raspberry Pi (Datasheet Raspberry Pi Model B, 2019) is a cost-effective
    edge computing unit that could potentially be used as an edge image processing
    unit, and the capability of integrating it with IoT was also discussed. Zualkernan
    et al. (2022) demonstrated an edge image processing platform for the classification
    of animals and transmitting the identified animal and time of identification via
    LoRa for a camera trap. Past literature on IoT and image processing applications
    in agriculture has highlighted a research gap in edge image processing with IoT-enabled
    crop monitoring cameras. In-field crop cameras are expected to make real-time
    crop management decisions based on real-time image processing; however, poor internet
    connectivity in agricultural fields severely limits their capability. To address
    this gap, we have developed a novel imaging platform named AICropCAM that extracts
    plant and crop canopy level parameters through DCNN and uploads them to the Cloud
    via low-power, low-throughput communication protocols. We also demonstrated AICropCAM
    on an IoT-enable wireless sensor network in corn and soybean fields. A technology
    that addresses image processing at the lowest level (edge) and transmits only
    useful information can revolutionize real-time decision-making in PA. Therefore,
    the main objective of this paper is to demonstrate AICropCAM to perform edge image
    processing and low-throughput, low-power, and long-range data transmission through
    IoT technology. In this novel AICropCAM platform, multiple DCNN image processing
    algorithms run in series to extract plant-level and canopy-level features in an
    embedded system. Image classification, object detection with classification, and
    image segmentation are the three major applications of DCNN image processing,
    and all three are included in AICropCAM to demonstrate the capabilities of DCNN
    for image processing in PA. AICropCAM has trained models for canopy segmentation,
    crop classification, plant growth stage identification, plant counting, weed counting,
    and plant type identification. All the protocols that transmit data from AICropCAM
    to the Cloud were custom designed. AICropCAM sends the generated data to a cloud
    platform for logging, visualization, and analysis. Furthermore, this paper explains
    the DCNN model training process, model performance, and test results. We reported
    the model training comprehensively because it was essential for AICropCAM development.
    2. Materials and methods Essential activities in this research were data/image
    collection and preprocessing, hardware design for AICropCAM, software design for
    data transmission between the edge and the Cloud, deep learning model design,
    and model training and optimization (Fig. 1). AICropCAM was implemented in a corn
    and soybean field at the field phenotyping facility in Mead, Nebraska, USA (Bai
    et al., 2019). We demonstrated the training of the following DCNNs: CropClassiNet
    for classifying images based on image quality and crop type, CanopySegNet for
    segmenting crop canopy from the background, PlantCountNet for classifying and
    counting soybean and weed plants, and InsectNet for identifying insects and counting
    them. Download : Download high-res image (412KB) Download : Download full-size
    image Fig. 1. Steps of edge image processing program deployment on the embedded
    system (edge devices). 2.1. Image collection, annotation, preprocessing, and augmentation
    Image collection for DCNN model training occurred in four growing seasons using
    three different types of cameras: (i) commercially available Meidas SL122 trail
    cameras in 2019 (Meidas Trail Cameras, 2022), (ii) OV5642 imaging sensors with
    ArduCAM camera shields in 2020, and (iii) Raspberry Pi Camera Module V2 with Raspberry
    Pi Zero in 2021 and 2022 (Chamara, 2021). All the cameras were mounted on the
    bars horizontally extended and fixed on stationary poles erected vertically in
    the fields, as shown in Fig. 2A. The distance between the crop canopy and the
    cameras was maintained between 0.5 and 1.5 m throughout the growing seasons. Images
    used for training the InsectNet were also captured with smartphones as we could
    not collect enough images with insects from the three types of cameras mentioned
    above. Download : Download high-res image (338KB) Download : Download full-size
    image Fig. 2. Left: An Illustration of how AICropCAM was set up in the field for
    image collection. In addition to the camera, other components such as the solar
    panel and data logger were also shown. Right: A close-up view of AICropCAM and
    its hardware components. All three standard image annotation techniques in deep
    learning model training were utilized: (1) folder labeling for the image classification
    models, (2) pixel-level annotation for the semantic segmentation model, and (3)
    bounding boxes for object detection models. Images belonging to the same class
    were grouped into a single folder, and five distinct classes (or folders) were
    created: rejected, corn, soybean, grass, and night. Separating the crop canopy
    from the soil was done with pixel-level annotation and semantic segmentation.
    Bounding boxes, the smallest rectangle around an object, were drawn for corn plants,
    soybean plants, weed plants, and insects. Table 1 explains each type of annotation
    used in the model training. Table 1. Annotation criteria used to generate labels
    from the images to train and test the four deep convolutional neural network models
    in AICropCAM. Labeling Type Class Description Image classification (CropClassiNet)
    Rejected Images were labeled as rejected due to multiple reasons: blurred images
    caused by water droplets on the lens; the cameras turned away from the targeted
    crop; crops growing up to the camera blocking the view or capturing only a few
    leaves; people present in the images; lens covered with different stuff; and the
    camera was not installed in the field. Corn Images entirely covered by corn plants
    at different growth stages. Soybean Images entirely covered by soybean plants
    at different growth stages. Grass/Weed Images only comprise grass/weed plants
    at different growth stages. Night Images captured under low lighting conditions.
    Most of the cameras were not programmed to stop collecting images under low light.
    Crop canopy and background (CanopySegNet) Canopy Pixel labeling was done on the
    crop canopy. We used assisted freehand tool and the superpixel option in the MATLAB
    image labeler. Background Pixel labeling was done on the crop canopy. We used
    assisted freehand tool and the superpixel option in the MATLAB image labeler.
    Plant-type (PlantCountNet) Weed Weed present in the image was labeled using bounding
    boxes. It was challenging to locate the weed after the corn or soybean canopy
    was closed. Soybean Soybean plants present in the image were labeled using bounding
    boxes. Insects (InsectNet) Insects During the labeling process, without distinguishing
    insects based on their type, all the insects present in the images were labeled
    using bounding boxes. Image preprocessing is necessary for DCNN model training
    and real-time edge image processing. Differences in the input layer size in different
    DCNN models demand that images be resized before passing through the model for
    training or prediction purposes. High-resolution images improve accuracy but require
    more computational power. For specific applications, labeled datasets were only
    limitedly available. Therefore, image augmentation techniques were used to increase
    the number of image data sets, including scaling, flipping, cropping, rotation,
    color transformation, PCA color augmentation, and noise rejection (Paymode and
    Malode, 2022). Multiple augmentation techniques were used for each model, as detailed
    in Table 2. Additionally, Table 2 provides the numbers of images in training,
    validation, and testing for the four DCNN models. Table 2. DCNN model image allocation
    and image augmentation. Model Number of images Data Augmentation Techniques Total
    Training Validation Test CropClassiNet 43,611 30,528 9,810 3,273 Random rotation,
    random X  and Y reflection CanopySegNet 51 31 10 10 Transformation (random left/right
    reflection and random X/Y translation of ±10 pixels) PlantCountNet 110 88 11 11
    Transformation (same as CanopySegNet) InsectNet 542 326 108 108 Transformation
    (same as CanopySegNet) Our main objective was not to make the most accurate prediction
    for the DCNN models but to demonstrate the concept of implementing edge image
    processing and transmitting the results to the Cloud for decision-making. Therefore,
    we selected a limited number of images for CanopySegNet, PlantCountNet, and InsectNet,
    which were sufficient to train models with a reasonable degree of accuracy. 2.2.
    DCNN model architecture selection, training, evaluation, and deployment on the
    edge device The steps to select model architecture/model backbone weights and
    image input sizes to train the best model for CropClassiNet, CanopySegNet, PlantCountNet,
    and InsectNet are summarized in Fig. 3. Unlike many DCNN applications that prioritize
    higher accuracy, our application focused on finding the balance between accuracy
    and model deployability on the edge device. Download : Download high-res image
    (771KB) Download : Download full-size image Fig. 3. DCNN model selection process
    during the training and testing by attempting different model architectures, model
    backdone weights, and input image sizes. For example, in the development of CropSegNet
    (Segmentation), we selected DeepLabv3+ (Firdaus-Nawi et al., 2018) with weights
    initialized from pre-trained networks of ResNet18 (He et al., 2016), ResNet50,
    Xception, InceptionresnetV2, and MobileNetV2. The input image sizes tested were
    512 × 512 × 3 and 256 × 256 × 3, and training options were kept constant to find
    the best-performing networks, which should also be deployable to Raspberry Pi
    4B. This process identified DeepLabv3 + with ResNet50 as the most suitable model
    for CropSegNet, with an input image size of 512 × 512 × 3. Table 3 summarizes
    the hyperparameter values and training options for the final DCNN models deployed
    to the edge device. (1) (2) (3) (4) (5) (6) (7) Table 3. Hyperparameter values
    and training options for the best models (SGDM - stochastic gradient descent with
    momentum, RMSProp - Root mean square propagation). Training option and the function/Hyperparameters
    Values for CropClassiNet Values for CanopySegNet Values for InsectNet (320 × 320
    × 3) Values for PlantCountNet (320 × 320 × 3) Optimizer SGDM SGDM SGDM RMSProp
    Momentum 0.9 0.9 0.99 NA Initial learning rate 0.001 0.001 0.001 0.001 Learn rate
    schedule Piecewise Piecewise Piecewise Piecewise Learn rate drop period 10 10
    10 10 Learn rate drop factor 0.3 0.3 0.1 0.3 Minibatch size 16 4 16 32 L2Regularization
    NA 0.005 0.005 0.005 Validation frequency 3 3 3 10 Shuffle Every epoch Every epoch
    Every epoch Every epoch Validation patience 4 10 10 10 Max epochs 100 300 1000
    100 Execution environment Multi GPU Multi GPU GPU GPU The performance of the four
    DCNN models was evaluated using the indices calculated from Eq. (1), (2), (3),
    (4), (5), (6), (7). Accuracy, Precision, Recall, F1 score, and Jaccard index were
    used for the classification models CropClassiNet and CropSegNet, whereas IoU and
    mAP (Mean Average Precision) were used for PlantCountNet and InsectNet. Jaccard
    index gives the proportion of correctly predicted labels to the total number of
    labels. Model training was performed on an NVIDIA GeForce GTX 1650 Ti Mobile processor,
    a dedicated mid-range graphics card with 4 GB GDDR6 memory on a Dell XPS 15 9500
    Laptop. The laptop had an Intel Core i7-10750H 10th Gen processor,16 GB DDR4 RAM,
    and 1 TB SSD hard disk. 2.3. Hardware and software of AICropCAM The IoT data transmission
    and edge image processing hardware comprised the following major components: a
    Raspberry Pi 4B single-board computer, an Arduino MKR1310 development board, an
    Arduino MKR Relay Proto Shield, and a Dragino OLG02 outdoor dual channels LoRa
    Gateway (Fig. 4). The 12 V 8Ah battery powered the Raspberry Pi 4B, controlled
    through the relay shield managed by the Arduino MKR1310. A 3.7 V lithium polymer
    battery powered the Arduino MKR1310 board. There are two advantages of having
    a separate Arduino board. First, the Arduino board consumes less power than the
    Raspberry Pi 4B module. It can be switched on and off according to user requirements.
    Second, it allows uninterrupted communication between the edge node and the Cloud
    with low power. Download : Download high-res image (303KB) Download : Download
    full-size image Fig. 4. Hardware overview of AICropCAM and data flow. AICropCAM
    required programming on two hardware platforms. Arduino was programmed using C++
    in Arduino’s Integrated Development Environment. Raspberry Pi imaging and image
    processing program was developed in MATLAB and deployed onto the Raspberry Pi
    4B using the MATLAB Coder and MATLAB Compiler. A python program was designed to
    read the saved data in the Raspberry Pi 4B and serially communicate to the Arduino
    MKR1310. The primary functions of the MRK1310 program were to (1) turn on the
    Raspberry Pi 4B module based on the user-defined time intervals, (2) get the processed
    data, including the results of DCNN model predictions, through serial communication
    from the Raspberry Pi 4B, and (3) transmit the data to the ThingSpeak Cloud channel
    through the LoRa gateway. All the DCNN models were trained using the MATLAB deep
    learning toolbox. In the edge deployment, a MATLAB program runs multiple models
    logically depending on the prediction result of the previous model estimation,
    as shown in Fig. 5. MATLAB coder generated the C and C++ code derived from the
    program we developed to run on the Raspberry Pi. MATLAB Compiler generated the
    standalone application on the Raspberry Pi (The MathWorks, 2022). Download : Download
    high-res image (477KB) Download : Download full-size image Fig. 5. Overall sequential
    image processing and data generation flow chart. Table 4 lists the parameters
    generated by the models in AICropCAM. The abbreviations in Table 4 are fields
    holding data in the program to reduce the complexity of system development and
    maintain a common standard among different platforms. Fig. 6 shows the data generation
    from images. According to Fig. 6, the size of the images were around 2 MB before
    being fed into the image processing pipeline. The output message contains the
    crop type (CT), plant count (PC), weed count (WC), canopy coverage (CC), and pest
    count (PstC). The resulting message is typically less than 100 bytes. This represents
    a substantial reduction of memory size with the output being 0.00005 times the
    size of the original image. Consequently, this message can be transmitted in a
    single message via LoRa as the maximum LoRa packet size is around 256 bytes. Table
    4. List of parameters used to represent information in the images. Parameter Abbreviation
    Represent information Image location LOC Node ID manually entered/Global positioning
    system location coordinates Image orientation IO Accelerometer/Manually feed/Gravity
    switch Image quality/Crop type CT Image classification based on image quality
    and the crop type Plant count/Weed count PC/WC Multiclass object detection/classification
    Crop canopy coverage CC Semantic segmentation Pest count PstC Multiclass object
    detection/classification Download : Download high-res image (2MB) Download : Download
    full-size image Fig. 6. Examples of message generation and data size reduction
    for LoRa transmission. 2.4. Data transmission, visualization, and storage The
    data generated after image processing were saved on the Raspberry Pi 4B SD card,
    allowing access to the data remotely or through manual retrieval during field
    visits. Two options for transmitting the collected data to the ThingSpeak IoT
    platform are available. Firstly, the data can be uploaded directly from the Raspberry
    Pi 4B if internet connectivity is available for growers with Wi-Fi access. Secondly,
    the Raspberry Pi 4B transmits the recently acquired data to the Arduino MKR1310.
    The Arduino MKR1310 decodes the data received from the Raspberry Pi 4B and forwards
    it to the ThingSpeak. The second method is for low-rate, long-range communication
    beyond the limit of Wi-Fi. A single message receivable to the ThingSpeak server
    includes data for eight fields. In our demonstration, a single message was enough
    to transmit the data generated. Fields 1 and 2 are reserved for geographic coordinates
    (namely, latitude and longitude) to represent the device''s location. The third
    field was for camera orientation. Image quality/crop type, plant count, weed count,
    insect count, and crop canopy coverage were allocated from fields four to eight.
    ThingSpeak supports eight channels per gateway. If additional data is generated
    in the future, we have to create new channels to accommodate them. However, only
    data in a single channel can be passed through a single message. The Arduino-LoRa
    library was used to prepare the LoRa messages forwarded to the gateway (Mistry,
    2016). The message generated from the Arduino MKR1310 includes the device identification
    number and the data with the field number. Once the gateway receives this message,
    it adds the target client ID (generated by ThingSpeak when defining a device),
    host address (mqtt://mqtt3.thingspeak.com), server port number, username and password,
    channel ID, and the data in each field according to the Message Queuing Telemetry
    Transport (MQTT) protocol. Username and password ensure that only authorized devices
    can transmit data to the ThingSpeak platform. ThingSpeak provides two ways to
    interact with its platform, REST (Representative State Transfer) and MQTT protocols.
    The advantages of using MQTT over REST protocol are that it supports ThingSpeak
    data publishing, including immediate and minimum power consumption and data transmission
    over limited bandwidth, which encouraged us to select the MQTT protocol in our
    demonstration. 3. Results and discussion 3.1. DCNN model performance CropClassiNet
    had a test accuracy of 91.26 %, a Jaccard Index of 0.77, and an F1-score of 0.91;
    the confusion matrix is given in Fig. 7. The highest precision is for the “grass”
    class (100 %), and the lowest is for “soybean” (92.0 %). The highest recall is
    for the “corn” class (99.9 %), and the lowest is for “grass” (67.1 %). The primary
    goal of CropClassiNet is to determine the quality of new images and direct them
    for subsequent processing (Fig. 5). This step has never been executed in an image-based
    crop monitoring platform before. Further, CropClassiNet can eliminate erroneous
    images when humans are present in the camera’s field of view or when the camera
    is misaligned due to external factors. AICropCAM can send maintenance requests
    through IoT analytics if rejected images are continuously generated. Download
    : Download high-res image (275KB) Download : Download full-size image Fig. 7.
    Confusion matrix for test images by CropClassiNet. CanopySegNet on the test images
    achieved a global accuracy of 0.93, a weighted IoU of 0.87, and a mean BF score
    of 0.73. Fig. 8 shows an example of an original soybean image and the corresponding
    segmentation result by CanopySegNet, which estimated CC to be 18.72 %. Season-long,
    time-series images can be fed into CanopySegNet to generate diurnal and seasonal
    curves of crop CC, as shown in Fig. 9. Download : Download high-res image (621KB)
    Download : Download full-size image Fig. 8. An image of soybean crop and the segmentation
    result by CropSegNet to calculate canopy coverage. Download : Download high-res
    image (367KB) Download : Download full-size image Fig. 9. Examples of diurnal
    and seasonal variations of canopy coverage as computed by CropSegNet. According
    to Fig. 9, canopy coverage percentage variation is low during the daytime and
    reaches zero at night. This verifies the need to eliminate low-light images before
    segmenting. As shown in Fig. 5, it is possible to eliminate the generation of
    false values when the camera captures images under low light conditions by halting
    the process of running CanopySegNet. There are three diurnal variation series
    on 6/8/2021, 6/26/2021, and 7/12/2021 in Fig. 9. The CC increased from 8 % to
    95 % between 6/8/2021 to 7/12/2021. The seasonal trend showed that the CC reached
    a maximum around 7/8/2021. These results suggest that the proposed stacked models
    can track the daily and seasonal CC variation and eliminate the effect of lighting
    conditions on false value generation. Table 5. Performance of PlantCountNet and
    InsectNet on the test image set (Root mean square error (RMSE)/Final validation
    loss (FVL)). Model Name Architecture Input size Validation RMSE/FVL Mean average
    precision Object class PlantCountNet YOLOv2 320 × 320 × 3 0.888 (RMSE) 0.66 Soybean
    0.86 Weed InsectNet YOLOv4 320 × 320 × 3 26.2 (FVL) 0.02 Insect The overall performance
    of the PlantCountNet and InsectNet is given in Table 5. Fig. 10(A) and 10(B) show
    the result obtained by PlantCountNet for a soybean image at an early vegetative
    stage (V3). Meanwhile Fig. 10(C) and 10(D) shows the result at a reproductive
    stage (R1). It can be seen that, at V3 stage, the model outputs matched the labels
    of soybean and weed plants well, indicating a level of high accuracy. Download
    : Download high-res image (1MB) Download : Download full-size image Fig. 10. The
    result of PlantCountNet for soybean and weed counting: Manually annotated vs.
    model-predicted bounding boxes at V3 growth stage (A and B); manually annotated
    vs. model-predicted bounding boxes at R1 growth stage (C and D). The size of insects
    is very small compared to the size of images (Fig. 11), which is the main reason
    for the low mAP for InsectNet (Table 5). Increasing input image resolution beyond
    480 × 480 × 3 is impractical as it exceeds the memory limitation to load models
    into Raspberry Pi 4B. A potential solution could be to increase the resolution
    of the region of interest by splitting the original image while keeping the resolution
    the same. Also, we suggest using the approach recommended by Tetila et al., 2020a,
    Tetila et al., 2020b in the future on Raspberry Pi model 4B. As technology advances,
    we expect the memory capacities will increase for edge computing units. At the
    same time, the state-of-the-art object detection algorithms will improve the accuracy
    for small object detection. Download : Download high-res image (1MB) Download
    : Download full-size image Fig. 11. The result of InsectNet for insect counting
    in soybean. The top row shows a situation of high false positives and low false
    negatives: (A) and (B) are manually annotated and model-predicted insect labels,
    respectively. The bottom row shows a situation of low false positive and high
    false negative: (C) and (D) are manually annotated and model-predicted insect
    labels. 3.2. Power consumption for Raspberry Pi 4B Since edge cameras in farmlands
    have limited access to electric power, information on their power consumption
    is essential for designing IoT devices and systems. AICropCAM is designed to be
    energized by solar power. It runs on a rechargeable battery when there is no solar
    power. We monitored the maximum energy consumption of each task performed by AICropCAM,
    and the result is presented in Table 6. Four main strategies are available for
    the power management of IoT edge devices: Selecting power-efficient hardware,
    maintaining low power modes, dynamic power management, and cloud-based management.
    Raspberry Pi 4B is an affordable power-efficient single-board computer suitable
    for our application, but it does not naturally support low-power modes. Therefore,
    we introduced the Arduino MKR1310 LoRa module for the Raspberry Pi 4B dynamic
    power management. Furthermore, this Arduino module allows us to perform cloud-based
    central management independently. Table 6. Electrical power consumption of the
    Raspberry Pi 4B and the Arduino MKR1310 during edge image processing. Device Activity
    The maximum current range and the voltage recorded Raspberry Pi 4B Idle run 5.25
    V × (0.45 – 0.53) A Image classification 5.25 V × (0.97 – 1.04) A Image segmentation
    5.25 V × (0.98 – 1.11) A Weed and plant detection 5.25 V × (0.62 – 0.70) A Insect
    detection 5.25 V × (0.62 – 0.70) A Arduino MKR1310 Sleep mode <0.01A Serial communication
    <0.01A LoRa transmission <0.01A For our measurements, we used a Raspberry Pi 4B
    with 8 GB of RAM, connected to an HDMI monitor, a USB keyboard, and a USB mouse,
    and ran a MathWorks® Raspbian image (file used to boot the Raspberry Pi 4B). The
    Raspberry Pi 4B was operated at room temperature and connected to a wireless LAN
    access point and a laptop via an Ethernet cable. The electric current consumption
    for running each DCNN model was recorded during the test. CropClassiNet had the
    highest current consumption, while the PlantCountNet and InsectNet models had
    the lowest. As for LoRa transmission, we could not measure its current consumption
    because the lowest value our instrument could measure was 0.01A. Based on the
    manufacturer''s specifications, the Arduino MKR1310 consumes 104 uA at 5 V. The
    average time to run the DCNN models is essential to estimate the energy consumed
    for each prediction. These parameters listed in Table 7 provide essential guidelines
    for designing IoT sensor nodes with suitable batteries and power sources. We also
    noticed that typically the first prediction of a model took the longest time,
    but the rest take a considerably shorter time to predict. Table 7. Time duration
    needed for the selected DCNN models deployed in the Raspberry Pi 4B. Model/Task
    Input image size Time for predicting results (s) The maximum power demand for
    the activity (W) CropClassiNet/Image quality evaluation and crop classification
    224 × 224 × 3 6.44 5.46 CanopySegNet/Semantic segmentation to separate canopy
    from background 512 × 512 × 3 20.20 5.83 PlantCountNet/Weed and plant detection,
    classification, and counting 320 × 320 × 3 14.38 3.68 InsectNet/Insect detection
    320 × 320 × 3 0.20 3.68 Semantic segmentation was the most power-demanding activity,
    while insect detection was the least. Changing the order of the image processing
    models and adding new models or dropping existing models is possible during regular
    operation. It enables dynamic power management within the Raspberry Pi module.
    The main advantage of AICropCAM is that it implements a stack of four DCNN-based
    image processing models with multiple objectives. To the best of our knowledge,
    this is the first time such a system has been developed for a field crop monitoring
    camera. AICropCAM has applications such as setting up smart in-field or greenhouse
    IoT camera networks with edge computing capability, monitoring crops by attaching
    them to sprinkler irrigation systems (pivots and linear moves), or collecting
    crop information through ground or aerial mobile robots. The relatively short
    time to run each DCNN model makes the system suitable for real-time applications,
    including variable rate irrigation, fertilization, and spraying. For example,
    a pivot irrigated multi-cropping system with AICropCAM can automate irrigation
    or fertigation transition between different crops or crops at different growth
    stages by automatically providing the crop type or growth stage information to
    the irrigation controller. Additionally, existing herbicide or pesticide sprayers
    can get the feedback of the PlantCountNet and InsectNet in the AICropCAM for precision
    spraying. 4. Conclusion and future perspectives This paper outlines the essential
    components of constructing a functional edge image processing framework for real-time
    crop monitoring. From a software standpoint, CropClassiNet can categorize captured
    images according to image quality and detect the presence of specific crop types
    for further processing. CanopySegNet can further quantify the degree of canopy
    coverage; PlantCountNet can count the number of plants and weeds in the image;
    and finally, InsectNet can count the number of insects in the image. These four
    DCNN models, when implemented on edge devices, can extract an array of important
    crop and canopy parameters from field images and enable real-time, low-latency
    decision making and applications. Deep learning-based image processing on the
    edge has excellent potential in PA. Applications of AICropCAM are not limited
    to image classification, segmentation, plant counting, or weed counting. Potential
    future applications include insect classification and crop damage estimation,
    weed classification and pressure estimation, fruit identification and yield estimation,
    decision on replanting (Whigham et al., 2000), and disease identification and
    disease damage estimation in real time using actual field images collected by
    AICropCAM. AICropCAM shows excellent potential in enhancing crop management through
    crop monitoring. However, the current demonstration requires significant improvements
    on both hardware and software fronts. Customized circuitry and modular design
    are required to put AICropCAM in commercial farm applications. The full potential
    of the AICropCAM can be achieved by putting this camera on a moving platform like
    a center pivot with a GPS receiver to generate spatiotemporal data. Crop classification
    must include more crop types, and segmentation models need training data from
    other crop types. The DCNN models for weed and insect identification require the
    capability to identify different weed types, their growth stage, different insect
    types, and their growth stages to generate effective pest control decisions. Additionally,
    improving the models’ accuracy in image classification, segmentation, and object
    detection is crucial. It can be achieved by increasing the number of training
    image data sets. We also planned to expand the research for multiple edge architecture
    evaluation. Architectures such as a high-performance edge computer that accepts
    images from multiple edge devices through short-range, high-speed communication
    (e.g., Wi-Fi) and can run more accurate deep learning models with higher numbers
    of parameters, might be a better solution for the primary objectives addressed
    in this paper. We aim to expand the AICropCAM applications to other crops beyond
    corn and soybean. By making these improvements, AICropCAM will become a more effective
    tool for crop management, potentially revolutionizing how we grow and manage crops.
    Funding This work was supported by the United States Department of Agriculture
    – National Institute of Food and Agriculture grants [Award 2020-68013-32371 to
    YG and GB, Award 2021-67021-34417 to YG]. CRediT authorship contribution statement
    Nipuna Chamara: Methodology, Software, Visualization. Geng Bai: Conceptualization,
    Methodology, Resources. Yufeng Ge: Conceptualization, Resources, Supervision,
    Project administration, Funding acquisition. Declaration of Competing Interest
    The authors declare the following financial interests/personal relationships which
    may be considered as potential competing interests: Nipuna Chamara, Yufeng Ge,
    Geng Bai has patent pending to University of Nebraska-Lincoln. Acknowledgements
    Jianxin Sun assisted in developing the imaging device with Raspberry Pi Zero used
    for image acquisition. David Scoby helped the field management and AICropCAM installation.
    Junxiao Zhang supported the field installation of AICropCAM and smart-phone based
    acquisition of crop images with insects. Data availability Data will be made available
    on request. References Aasen et al., 2020 H. Aasen, N. Kirchgessner, A. Walter,
    F. Liebisch PhenoCams for field phenotyping: using very high temporal resolution
    digital repeated photography to investigate interactions of growth, phenology,
    and harvest traits Front. Plant Sci., 11 (June) (2020), pp. 1-16, 10.3389/fpls.2020.00593
    Google Scholar Anubha et al., 2019 P.S. Anubha, V. Sathiesh Kumar, S. Harini A
    study on plant recognition using conventional image processing and deep learning
    approaches J. Intell. Fuzzy Syst., 36 (3) (2019), pp. 1997-2004, 10.3233/JIFS-169911
    Google Scholar ArduCAM, 2016 ArduCAM ESP8266 UNO board User Guide (pp. 0–9). (2016).
    www.ArduCAM.com. Google Scholar Bai et al., 2019 G. Bai, Y. Ge, D. Scoby, B. Leavitt,
    V. Stoerger, N. Kirchgessner, S. Irmak, G. Graef, J. Schnable, T. Awada NU-Spidercam:
    A large-scale, cable-driven, integrated sensing and robotic system for advanced
    phenotyping, remote sensing, and agronomic research Comput. Electron. Agric.,
    160 (March) (2019), pp. 71-81, 10.1016/j.compag.2019.03.009 View PDFView articleView
    in ScopusGoogle Scholar Barbedo, 2014 J.G.A. Barbedo Using digital image processing
    for counting whiteflies on soybean leaves J. Asia Pac. Entomol., 17 (4) (2014),
    pp. 685-694, 10.1016/j.aspen.2014.06.014 View PDFView articleView in ScopusGoogle
    Scholar Cao et al., 2020 K. Cao, Y. Liu, G. Meng, Q. Sun An Overview on Edge Computing
    Research IEEE Access, 8 (2020), pp. 85714-85728, 10.1109/ACCESS.2020.2991734 View
    in ScopusGoogle Scholar Chamara et al., 2021 N. Chamara, K. Alkhadi, H. Jin, F.
    Bai, A. Samal, Y. Ge A deep convolutional neural network based image processing
    framework for monitoring the growth of soybean crops. 2021 ASABE Annual International
    Meeting, 2100259 (2021), 10.13031/aim.202100259 Google Scholar Chamara et al.,
    2022 N. Chamara, M.D. Islam, G.F. Bai, Y. Shi, Y. Ge Ag-IoT for crop and environment
    monitoring: Past, present, and future Agr. Syst., 203, 103497 (2022), 10.1016/j.agsy.2022.103497
    Google Scholar Chamara, 2021 N. Chamara Development of an Internet of Things (IoT)
    Enabled Novel Wireless Multi-Sensor Network for Infield Crop Monitoring. Master’s
    Thesis, Department of Biological Systems Engineering, University of Nebraska-Lincoln
    (2021) Google Scholar Datasheet Raspberry Pi Model, 2019 Datasheet Raspberry Pi
    Model B, 2019. https://datasheets.raspberrypi.org. Accessed 11 November 2023.
    Google Scholar Firdaus-Nawi et al., 2018 Firdaus-Nawi, M., Noraini, O., Sabri,
    M.Y., Siti-Zahrah, A., Zamri-Saad, M., Latifah, H., 2018. DeepLabv3+_Encoder-Decoder
    with Atrous Separable Convolution for Semantic Image Segmentation. In: Proceedings
    of the European Conference on Computer Vision (ECCV), pp. 801–818. Google Scholar
    Ghorai et al., 2021 A.K. Ghorai, A.R. Barman, B. Chandra, K. Viswavidyalaya, S.
    Jash, B. Chandra, K. Viswavidyalaya, B. Chandra, K. Viswavidyalaya Image processing
    based detection of diseases and nutrient deficiencies in plants SATSA Mukhapatra,
    25 (1) (2021), pp. 1-24 Google Scholar He et al., 2016 He, K., Zhang, X., Ren,
    S., Sun, J., 2016. Deep residual learning for image recognition kaiming. In: Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770–778.
    doi: 10.1002/chin.200650130. Google Scholar LeCun et al., 1998 LeCun, Y., Bottou,
    L., Bengio, Y., Haffner, P., 1998. Gradient-based learning applied to document
    recognition. Proc. IEEE 86(11), 2278–2323. doi: 10.1109/5.726791. Google Scholar
    Liang et al., 2023 Liang, W. Z., Oboamah, J., Qiao, X., Ge, Y., Harveson, B.,
    Rudnick, D. R., Wang, J., Yang, H., Gradiz, A., 2023. CanopyCAM – an edge-computing
    sensing unit for continuous measurement of canopy cover percentage of dry edible
    beans. Comput. Electron. Agric. 204 (January), 107498. https://doi.org/10.1016/j.compag.2022.107498.
    Google Scholar Luis et al., 2020 Luis, S., Filipe, N.S., Paulo, M.O., Pranjali,
    S., 2020. Deep Learning applications in agriculture: a short review. Deep Learning
    Applications in Agriculture: A Short Review, 1092 AISC(January), C1. doi: 10.1007/978-3-030-35990-4.
    Google Scholar Meidas Trail Cameras, 2022 Meidas Trail Cameras, 2022. https://www.meidase.com/product-category/trail-cameras/.
    Accessed 11 November 2023. Google Scholar Mistry, 2016 Mistry, S., 2016. Arduino
    LoRa. MIT License. https://github.com/sandeepmistry/arduino-LoRa. Accessed 11
    November 2023. Google Scholar Park et al., 2007 Y. Park, R.K. Krell, M. Carroll
    Theory, technology, and practice of site-specific insect pest management J. Asia
    Pac. Entomol., 10 (2) (2007), pp. 89-101 View PDFView articleView in ScopusGoogle
    Scholar Paymode and Malode, 2022 A.S. Paymode, V.B. Malode Transfer learning for
    multi-crop leaf disease image classification using convolutional neural network
    VGG Artif. Intell. Agric., 6 (2022), pp. 23-33, 10.1016/j.aiia.2021.12.002 View
    PDFView articleView in ScopusGoogle Scholar Richardson, 2019 A.D. Richardson Tracking
    seasonal rhythms of plants in diverse ecosystems with digital camera imagery New
    Phytol., 222 (4) (2019), pp. 1742-1750, 10.1111/nph.15591 View in ScopusGoogle
    Scholar Sakamoto et al., 2012 T. Sakamoto, A.A. Gitelson, A.L. Nguy-Robertson,
    T.J. Arkebauer, B.D. Wardlow, A.E. Suyker, S.B. Verma, M. Shibayama An alternative
    method using digital cameras for continuous monitoring of crop status Agric. For.
    Meteorol., 154–155 (2012), p. 113, 10.1016/j.agrformet.2011.10.014 View PDFView
    articleView in ScopusGoogle Scholar Sharma et al., 2020 P. Sharma, Y.P.S. Berwal,
    W. Ghai Performance analysis of deep learning CNN models for disease detection
    in plants using image segmentation Inf. Process. Agric., 7 (4) (2020), pp. 566-574,
    10.1016/j.inpa.2019.11.001 View PDFView articleView in ScopusGoogle Scholar Sritarapipat
    et al., 2014 T. Sritarapipat, P. Rakwatin, T. Kasetkasem Automatic rice crop height
    measurement using a field server and digital image processing Sensors (Switzerland),
    14 (1) (2014), pp. 900-926, 10.3390/s140100900 View in ScopusGoogle Scholar Taylor
    and Browning, 2022 S.D. Taylor, D.M. Browning Classification of daily crop phenology
    in phenocams using deep learning and hidden markov models Remote Sens. (Basel),
    14 (2) (2022), pp. 1-22, 10.3390/rs14020286 Google Scholar Tetila et al., 2020a
    Tetila, E.C., Machado, B.B., Astolfi, G., Belete, N.A.S., Amorim, W.P., Roel,
    A.R., Pistori, H., 2020. Detection and classification of soybean pests using deep
    learning with UAV images. Computers and Electronics in Agriculture, 179(May).
    doi: 10.1016/j.compag.2020.105836. Google Scholar Tetila et al., 2020b E.C. Tetila,
    B.B. MacHado, G.V. Menezes, N.A. De Souza Belete, G. Astolfi, H. Pistori A deep-learning
    approach for automatic counting of soybean insect pests IEEE Geosci. Remote Sens.
    Lett., 17 (10) (2020), pp. 1837-1841, 10.1109/LGRS.2019.2954735 View in ScopusGoogle
    Scholar The MathWorks, 2022 The MathWorks, I., 2022. MATLAB Coder - MATLAB. MathWorks.
    https://www.mathworks.com/products/matlab-coder.html. Google Scholar Tian et al.,
    2020 H. Tian, T. Wang, Y. Liu, X. Qiao, Y. Li Computer vision technology in agricultural
    automation—a review Inf. Process. Agric., 7 (1) (2020), pp. 1-19, 10.1016/j.inpa.2019.09.006
    View PDFView articleView in ScopusGoogle Scholar van Dijk et al., 2021 M. van
    Dijk, T. Morley, M.L. Rau, Y. Saghai A meta-analysis of projected global food
    demand and population at risk of hunger for the period 2010–2050 Nat. Food, 2
    (7) (2021), pp. 494-501, 10.1038/s43016-021-00322-9 View in ScopusGoogle Scholar
    Wang et al., 2022b Q. Wang, M. Cheng, S. Huang, Z. Cai, J. Zhang, H. Yuan A deep
    learning approach incorporating YOLO v5 and attention mechanisms for field real-time
    detection of the invasive weed Solanum rostratum Dunal seedlings Comput. Electron.
    Agric., 199 (July) (2022), Article 107194, 10.1016/j.compag.2022.107194 View PDFView
    articleView in ScopusGoogle Scholar Wang et al., 2022a J. Wang, Z. Gao, Y. Zhang,
    J. Zhou, J. Wu, P. Li Real-time detection and location of potted flowers based
    on a ZED camera and a YOLO V4-tiny deep learning algorithm Horticulturae, 8 (1)
    (2022), 10.3390/horticulturae8010021 Google Scholar Wang et al., 2014 Y. Wang,
    D. Wang, P. Shi, K. Omasa Estimating rice chlorophyll content and leaf nitrogen
    concentration with a digital still color camera under natural light Plant Methods,
    10 (3) (2014), pp. 273-286, 10.1016/S0378-4290(99)00063-5 View in ScopusGoogle
    Scholar Wang et al., 2019 A. Wang, W. Zhang, X. Wei A review on weed detection
    using ground-based machine vision and image processing techniques Comput. Electron.
    Agric., 158 (January) (2019), pp. 226-240, 10.1016/j.compag.2019.02.005 View PDFView
    articleView in ScopusGoogle Scholar Whigham et al., 2000 K. Whigham, D. Farnham,
    J. Lundvall, D. Tranel Soybean replant decision, Department of Agronomy, Iowa
    State University (2000) Google Scholar Yasrab et al., 2021 R. Yasrab, J. Zhang,
    P. Smyth, M.P. Pound Predicting plant growth from time-series data using deep
    learning Remote Sens. (Basel), 13 (3) (2021), pp. 1-17, 10.3390/rs13030331 View
    in ScopusGoogle Scholar Yuan et al., 2019 W. Yuan, N.K. Wijewardane, S. Jenkins,
    G. Bai, Y. Ge, G.L. Graef Early prediction of soybean traits through color and
    texture features of canopy RGB imagery Sci. Rep., 9 (2019), p. 14089, 10.1038/s41598-019-50480-x
    View in ScopusGoogle Scholar Zualkernan et al., 2022 I. Zualkernan, S. Dhou, J.
    Judas, A.R. Sajun, B.R. Gomez, L.A. Hussain An IoT system using deep learning
    to classify camera trap images on the edge Computers, 11 (1) (2022), pp. 1-24,
    10.3390/computers11010013 Google Scholar Cited by (1) YOLO performance analysis
    for real-time detection of soybean pests 2024, Smart Agricultural Technology Show
    abstract © 2023 The Authors. Published by Elsevier B.V. Part of special issue
    Agricultural Cybernetics: A New Methodology of Analysis and Development for Modern
    Agricultural Production Systems Edited by Yanbo Huang, Manoj Karkee, Lie Tang,
    Dong Chen View special issue Recommended articles Joint control method based on
    speed and slip rate switching in plowing operation of wheeled electric tractor
    equipped with sliding battery pack Computers and Electronics in Agriculture, Volume
    215, 2023, Article 108426 Qi Wang, …, Yongjie Cui View PDF LSCA-net: A lightweight
    spectral convolution attention network for hyperspectral image processing Computers
    and Electronics in Agriculture, Volume 215, 2023, Article 108382 Ziru Yu, Wei
    Cui View PDF Automatic detection of crop lodging from multitemporal satellite
    data based on the isolation forest algorithm Computers and Electronics in Agriculture,
    Volume 215, 2023, Article 108415 Rui Guo, …, Tingting Liu View PDF Show 3 more
    articles Article Metrics Citations Citation Indexes: 1 Captures Readers: 19 View
    details About ScienceDirect Remote access Shopping cart Advertise Contact and
    support Terms and conditions Privacy policy Cookies are used by this site. Cookie
    settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier
    B.V., its licensors, and contributors. All rights are reserved, including those
    for text and data mining, AI training, and similar technologies. For all open
    access content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Computers and Electronics in Agriculture
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'AICropCAM: Deploying classification, segmentation, detection, and counting
    deep-learning models for crop monitoring on the edge'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Harsh P.
  - Hachinger S.
  - Derquennes M.
  - Edmonds A.
  - Karagoz P.
  - Golasowski M.
  - Hayek M.
  - Martinovič J.
  citation_count: '0'
  description: 'In this contribution, we sketch an application of Earth System Sciences
    and Cloud-/Big-Data-based IT, which shall soon leverage European supercomputing
    facilities: smart viticulture, as put into practice by Terraview. TerraviewOS
    is a smart vineyard “operating system”, allowing wine cultivators to optimise
    irrigation, harvesting dates and measures against plant diseases. The system relies
    on satellite and drone imagery as well as in-situ sensors where available. Clearly,
    processing behind the UI is heavily based on Cloud Computing, with some Edge Computing
    close to the user or High-Performance/GPU Computing components. The substantial
    need for computing power in TerraviewOS, in particular for training AI-based models
    to generate derived data products, makes the further development of some of its
    modules a prime use case for the EU-funded Extreme Data processing project “EXA4MIND”
    (Horizon Europe GA No. 101092944). Two of the strongest academic supercomputing
    centres in Europe take part in EXA4MIND. The collaboration to evolve the “Smart
    Moisture Mapper” subsystem of TerraviewOS in this context is briefly sketched.
    Connecting database systems, High-Performance-/Cloud-Computing systems and European
    Data Spaces with appropriate data access and transfer mechanisms, EXA4MIND shall
    demonstrate competitive advantage in scientific and enterprise data analysis needed
    in complex applications such as TerraviewOS.'
  doi: null
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: Proceedings of Science
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Wine in the Cloud, or: Smart Vineyards with a Distributed “Extreme Data
    Database” and Supercomputing'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Feng A.
  - Vong C.N.
  - Zhou J.
  - Conway L.S.
  - Zhou J.
  - Vories E.D.
  - Sudduth K.A.
  - Kitchen N.R.
  citation_count: '1'
  description: Unmanned aerial vehicle (UAV) based remote sensing has been extensively
    used in precision agriculture applications, such as vegetation growth and health
    monitoring, yield estimation, and irrigation management. Conventional procedures
    for UAV data collection and processing require collecting highly overlapped images,
    stitching images to generate an orthomosaic, and using ground control points (GCPs)
    in the field or UAV onboard real-time-kinematic (RTK) global navigation satellite
    system (GNSS) data to improve position accuracy. For improving efficiency, a previous
    study developed a framework to process individual UAV images for mapping cotton
    emergence. The current study aimed to build a near-real time image processing
    pipeline to further improve the positioning accuracy of single UAV images. The
    improved image processing pipeline comprised feature detection and matching, false
    matches removal, geometric transformation matrix calculation, crop row alignment,
    image position assignment, and mapping. The developed pipeline was tested for
    mapping in both cotton and corn fields. Results showed that the position accuracies
    for measuring the distance between GCPs were 0.32 ± 0.21 m and 0.57 ± 0.28 m in
    a cotton and a corn field, respectively, when compared to ground truth data collected
    with an RTK-GNSS. The developed pipeline did not require GCPs in the field or
    image post-processing steps, such as image mosaicking and feature extraction,
    which allowed processing in near-real time and may possibly be implemented in
    real-time using an onboard edge computing system. The pipeline was used to map
    emergence parameters for cotton and corn fields, including stand count, canopy
    area, mean days to imaging after emergence, and plant spacing standard deviation.
    These maps demonstrated the success of the developed methods in providing a low-cost
    near real-time tool (8.6 and 3.6 s/image for the cotton and corn fields, respectively)
    for mapping emergence parameters at field-scale for use in both research and agricultural
    production.
  doi: 10.1016/j.compag.2023.107650
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    View Open Manuscript Outline Highlight Abstract Keywords 1. Introduction 2. Materials
    and methods 3. Results 4. Discussion 5. Conclusion CRediT authorship contribution
    statement Declaration of Competing Interest Acknowledgements Code availability
    Data availability References Show full outline Cited by (1) Figures (13) Show
    7 more figures Tables (3) Table 1 Table 2 Table 3 Computers and Electronics in
    Agriculture Volume 206, March 2023, 107650 Developing an image processing pipeline
    to improve the position accuracy of single UAV images Author links open overlay
    panel Aijing Feng a b 1, Chin Nee Vong a 1, Jing Zhou c, Lance S. Conway d, Jianfeng
    Zhou a, Earl D. Vories d, Kenneth A. Sudduth d, Newell R. Kitchen d Show more
    Add to Mendeley Share Cite https://doi.org/10.1016/j.compag.2023.107650 Get rights
    and content Highlight • An image processing workflow to geo-reference single UAV
    images. • Field mapping of crop early emergence using individual UAV images. •
    Improved position accuracy of 0.17 and 0.57 m for cotton and corn UAV images.
    • Potential real-time processing UAV images for on-site decision making. Abstract
    Unmanned aerial vehicle (UAV) based remote sensing has been extensively used in
    precision agriculture applications, such as vegetation growth and health monitoring,
    yield estimation, and irrigation management. Conventional procedures for UAV data
    collection and processing require collecting highly overlapped images, stitching
    images to generate an orthomosaic, and using ground control points (GCPs) in the
    field or UAV onboard real-time-kinematic (RTK) global navigation satellite system
    (GNSS) data to improve position accuracy. For improving efficiency, a previous
    study developed a framework to process individual UAV images for mapping cotton
    emergence. The current study aimed to build a near-real time image processing
    pipeline to further improve the positioning accuracy of single UAV images. The
    improved image processing pipeline comprised feature detection and matching, false
    matches removal, geometric transformation matrix calculation, crop row alignment,
    image position assignment, and mapping. The developed pipeline was tested for
    mapping in both cotton and corn fields. Results showed that the position accuracies
    for measuring the distance between GCPs were 0.32 ± 0.21 m and 0.57 ± 0.28 m in
    a cotton and a corn field, respectively, when compared to ground truth data collected
    with an RTK-GNSS. The developed pipeline did not require GCPs in the field or
    image post-processing steps, such as image mosaicking and feature extraction,
    which allowed processing in near-real time and may possibly be implemented in
    real-time using an onboard edge computing system. The pipeline was used to map
    emergence parameters for cotton and corn fields, including stand count, canopy
    area, mean days to imaging after emergence, and plant spacing standard deviation.
    These maps demonstrated the success of the developed methods in providing a low-cost
    near real-time tool (8.6 and 3.6 s/image for the cotton and corn fields, respectively)
    for mapping emergence parameters at field-scale for use in both research and agricultural
    production. Previous article in issue Next article in issue Keywords Crop emergenceImage
    processingMappingReal-time processingUAV imagery 1. Introduction Remote sensing
    (RS) based on unmanned aerial vehicle (UAV) platforms has become a regular tool
    in precision agriculture (PA) for efficient data collection from large areas of
    farm fields. Widely used UAV-based sensing systems for agricultural applications
    include cameras with different spectral bands, such as RGB (red, green, and blue),
    multispectral, hyperspectral, and thermal cameras, as well as light detection
    and ranging (LiDAR) sensors. The UAV-based sensing systems have been used in different
    PA applications, such as weed and disease detection, vegetation growth and health
    monitoring, yield estimation, and irrigation management (Tsouros et al., 2019).
    When compared to other RS platforms such as satellites and manned aircrafts, UAV-based
    sensing systems are lower in cost, more friendly in operation, and flexible in
    data acquisition time and altitude. Furthermore, UAV-based sensing systems can
    collect data at high spatial and temporal resolution, have high image quality,
    and provide immediate access (Vega et al., 2015, Xie and Yang, 2020, Yang et al.,
    2017). Meanwhile, as compared to ground-based sensing platforms, UAV-based sensing
    systems are less time-consuming for fine-scale use and do not cause crop damage
    or soil compaction (Xie and Yang, 2020). The key factors for the successful implementation
    of PA technology include accurate site-specific information collection and timely
    decision making (Delavarpour et al., 2021). Site-specific information from UAV-based
    sensing systems usually relies on geo-referencing of UAV images by one of two
    methods: 1) aerial triangulation (AT) using ground control points (GCPs) or 2)
    direct geo-referencing (DG) based on the position and orientation measurements
    of the capturing camera (Rabah et al., 2018). Nowadays, the DG method based on
    the UAV onboard global navigation satellite system (GNSS) receiver is widely used,
    and location accuracy can be improved by using real-time kinematic (RTK) technology.
    For instance, a previous study showed root mean square error (RMSE) for total
    horizontal errors (easting and northing) of 0.843, 0.034 m, and 0.032 m for non-RTK
    UAV data processed via DG, non-RTK UAV data processed with GCPs, and RTK UAV data
    (Hugenholtz et al., 2016). However, RTK-GNSS is usually expensive (Obanawa et
    al., 2019) and installing sufficient GCPs in fields is a time-consuming, non-real
    time operation. Further, the exercise is sometimes difficult or impossible in
    certain field conditions (Štroner et al., 2021). This could occur, for example,
    when crops are very tall or the canopy has completely closed, when soil is very
    wet, or under narrow-row cropping systems. Moreover, the position accuracy when
    using GCPs depends on the configuration and number of GCPs used throughout the
    field (Sanz-Ablanedo et al., 2018). The conventional method of processing UAV
    images usually requires a substantial image overlap (about 75%) to construct orthomosaic
    images of study fields (Tsouros et al., 2019), which results in low efficiency
    in data collection (more flight passes and slower speed). This is especially noticeable
    for UAV data collected with low altitude (≤20 m) to provide sufficient resolution
    for small crop plants at early stages (Feng et al., 2020a, Vong et al., 2021).
    The collected images are then processed using commercial UAV image processing
    software such as Agisoft Metashape (Agisoft LLC, St. Petersburg, Russia) or Pix4D
    mapper (Pix4D S.A., Lausanne, Switzerland), a process that may require from hours
    to days depending on the size of field, number of images, and image resolution
    (Feng et al., 2020a). In addition, the process of image stitching may require
    extensive computational resources and may cause a substantial delay for field
    decision making (Feng et al., 2020a, Xiang and Tian, 2011). Furthermore, orthomosaic
    images may contain image artifacts and distortions caused by image scenes, lighting
    conditions, camera parameters, flight plans (height, speed, and overlaps), and
    processing parameters (Gross and Heumann, 2016, Iglhaut et al., 2019). These issues
    can degrade the image quality and result in inaccurate results from image post-processing,
    such as for vegetation indices (VI) and canopy cover calculations. Post-image
    processing uses additional software such as Matlab, ArcGIS, and QGIS (Tsouros
    et al., 2019, Yang et al., 2017), which further increases complexity and time
    for data processing (Tsouros et al., 2019). Since consumer-grade UAV imaging systems
    are widely used in research and for these, RTK GNSS is generally not available.
    Therefore, a more cost-effective solution for timely image processing and real-time
    decision making is greatly needed. A previous study by Feng at al. (2020a) developed
    an efficient imagery data processing and analysis framework for timely evaluation
    of cotton emergence using a UAV-based imaging system and deep learning (DL) technology.
    The study introduced an approach of directly processing individual image frames
    rather than generating orthomosaic images, which can reduce the processing time
    and prevent image quality degradation. This framework was successfully tested
    for estimating and mapping cotton emergence (stand count and canopy size) with
    a position accuracy of 1.72 m ± 1.37 m (mean ± standard deviation). However, the
    position accuracy was not satisfactory to acquire site-specific information for
    research in PA. Since conventional plant row spacing of row crops such as cotton,
    corn, and soybean ranges from 0.76 to 1.02 m (Clawson et al., 2006, Elmore and
    Abendroth, 2007, Robinson and Conley, 2007), position accuracy should be improved
    to better than 0.38 – 0.51 m (half of the common row spacings) to generate a more
    accurate and reliable field mapping. This study aimed to develop a real-time image
    processing pipeline to process individual UAV images for improved position accuracy.
    The developed pipeline was then used to create emergence maps for cotton and corn
    at field scale to demonstrate its application. Moreover, the position accuracy
    was compared with the method from previous study to evaluate the performance of
    the developed method. 2. Materials and methods 2.1. UAV imaging system A UAV imaging
    system (Phantom 4 Advanced, DJI, Shenzhen, Guangdong, China) was used to collect
    high resolution RGB images in cotton and corn fields. The resolution of the onboard
    RGB camera was set to 4864 × 3648 pixels, resulting in the calculated spatial
    resolution of 3.0 mm pixel−1 at 10 m above ground level (AGL). Images were taken
    sequentially for both fields at 0.5 frames per second (fps) at a flight height
    of 10 m and flight speeds of 7.5 and 7.2 km h−1 for the cotton and corn field,
    respectively. The UAV flight trajectory and flight parameters were set using the
    control apps Autopilot (Hangar Technology, Austin, TX, USA) or Litchi (VC Technology
    ltd, London, U.K.). The image overlaps in both the sideward and forward directions
    were about 60 – 75 %. During aerial image data collection, the onboard GNSS system
    on the UAV continuously recorded the coordinates and altitude of the imaging system
    and provided geo-referencing for each image as part of the image metadata. Geo-referenced
    images were downloaded after the flight for further processing. 2.2. Experimental
    fields and configurations 2.2.1. Cotton field The cotton field was a research
    field located at the Fisher Delta Research, Extension and Education Center of
    the University of Missouri in the upper portion of the Mississippi River Delta
    region near Portageville, MO, USA (36.411° N, 89.696° W). The field has dimensions
    of 315 m (north–south, NS) × 150 m (east–west, E-W). The cotton cultivar PHY 320
    WRF (Dow Agrosciences, Indianapolis, IN) was planted on bedded soil using a John
    Deere 1700 (Deere & Co., Moline, IL, USA) planter on May 15, 2019. The field was
    seeded in a NS direction at a target seeding rate of 136,000 seeds ha−1 with a
    row spacing of 0.97 m. This resulted in a total of 152 crop rows. Most of the
    cotton emerged by May 22, 2019 and the UAV images were collected on May 31, 2019
    [16 days after planting (DAP)]. Ground truth and reference data including GCPs,
    stand count and seedling size, were collected on the day of the UAV flight. In
    this study, 28 GCPs (Fig. 1) were set in the field, including 16 fence posts (∼1.1
    m in height) each with a white-black polytechnic board (30 × 30 cm) on the top
    and 12 quadrats (53 × 53 cm) made with half-inch polyvinyl chloride (PVC) pipes.
    Two different types of GCP were used to mark different sampling methods for assessment
    of cotton stand count. A ground stake that could be recognized during the growing
    season (Fig. 1c) was placed at each GCP to mark its position so that the GCP could
    be placed at the same locations for each data collection. A RTK survey kit (REACH
    RS+, Emlid ltd., Saint Petersburg, Russia) with a ReachView app (Emlid ltd.) was
    used to obtain the coordinates of the 28 GCPs. At each GCP, six flags were used
    to mark six 1-m intervals of crop seedlings in two cotton rows as shown in Fig.
    1a and Fig. 1b. The number of seedlings in each 1-m interval was counted manually
    to serve as ground truth data for the stand count estimation. Meanwhile, a tape
    measure with a precision scale of 1 mm was placed along the cotton rows. A digital
    camera on a cell phone (iPhone 6 s, Apple Inc., Cupertino, CA, USA) was used to
    take videos of the crop rows while being held manually at a height of about 0.5
    m AGL with the camera facing down. Cotton stands were counted by playing back
    the videos and canopy size (top view) was calculated by comparing the scales of
    the tape measure and number of image pixels. Download : Download high-res image
    (133KB) Download : Download full-size image Fig. 1. Illustration of the cotton
    field setup with a and b showing one of the 28 ground control points (GCPs) that
    include two 6-m crop rows, a fence post (GCP), and red flags marking each 1-m
    interval. The ground videos were taken using a cell phone camera. c) UAV image
    showing a PVC pipe quadrat with one ground stake inside. (For interpretation of
    the references to color in this figure legend, the reader is referred to the web
    version of this article.) 2.2.2. Corn field The corn field was located near Columbia,
    MO, USA (38.946° N 92.133° W) with dimensions of 160 m (NS) by 49 m (E-W). The
    field was planted with corn hybrid Pioneer 0589 (Corteva Agriscience, Wilmington,
    DE, USA) on April 20, 2020 using a custom-built four-row planter equipped with
    MaxEmerge XP row units (Deere & Co., Moline, IL, USA) at a 0.76-m row spacing.
    Four planting depth treatments (3.8, 5,1, 6.4, and 7.6 cm) with two replications
    were implemented to create different emergence dates. Each replication of each
    planting depth had eight rows (6.1 m) of corn along the NS direction of the field
    resulting in a total of 64 corn rows. Seeds were planted at the four defined depths
    at a seeding rate of 81,500 seeds ha−1, which was equivalent to an average plant
    intra-row seed spacing of 16 cm. Five monitoring sites were marked with flags
    for ground data collection with each site consisting of two adjacent corn rows
    6.0 m long (Fig. 2). Corn emergence was checked daily, and colored stakes were
    used to mark the newly emerged plants for each day. The first and last emergence
    checks in the monitoring sites were 2 and 12 May of 2020 (12 and 22 DAP). The
    same RTK survey kit with the ReachView app was used to obtain the GPS coordinates
    of the monitoring sites (a flag at one side of the monitoring site was used as
    the GCP). There was a total of five GCPs. The UAV aerial image data was collected
    on 22 May 2020, which was 32 DAP or 20 days after first emergence. This resulted
    in most plants at the site between vegetative growth stage V2 to V4. Then, plant
    spacing (PS) was measured using a tape measure on 15 June 2020 (56 DAP). Download
    : Download high-res image (298KB) Download : Download full-size image Fig. 2.
    Example image of monitoring site with color stakes marking different emergence
    dates at the corn field and one of the flags used as ground control point (GCP).
    The area in the red box in the upper image is enlarged in the lower image. (For
    interpretation of the references to color in this figure legend, the reader is
    referred to the web version of this article.) 2.3. Single image processing pipeline
    development Fig. 3 illustrates the summary workflow of the image pre-processing
    and image processing pipeline to establish location information for single images.
    The collected images were pre-processed using decorrelation stretch to enhance
    the images and standard Hough transform (SHT) to rotate the images for crop row
    detection and ground sample distance (GSD) determination of each image with the
    detailed procedures described in Feng et al. (2020a, Fig. 3 dashed box). Inside
    the dotted box of Fig. 3 are the procedures of the image processing pipelines
    developed in the present study that improved position accuracy of single image
    frames compared to the methods of Feng et al (2020a). The first three procedures
    (symbols highlighted in blue) were modified based on previous customized image
    alignment and stitching algorithms described in Feng, et al. (2020b), focusing
    on image feature identification and matching followed by removal of false matches.
    The remaining three procedures (symbols highlighted in yellow) were added in this
    study to assign position information of each single image based on E-W (crop rows)
    and NS (position in each crop row) translations. The position information of images
    was then used to develop site-specific maps for parameters of interest (e.g.,
    stand count, canopy size, emergence date). Feng et al. (2020b) generated an orthomosaic
    image based on the matched features of the images for the whole field using post-processing
    method after data collection, which was time consuming. On the other hand, the
    image processing pipeline in this study aligned crop rows using single image frames
    (without image mosaicking) for the whole field, which improved the efficiency
    and made near real-time processing possible. The details of the image processing
    pipeline for single image frames (Fig. 3 dotted box) are described in the following
    sections. Download : Download high-res image (463KB) Download : Download full-size
    image Fig. 3. Workflow of image pre-processing (dashed line box) and image processing
    pipeline (dotted line box) in this study. 2.3.1. Feature detection and matching
    Image features were detected using the method of Speeded-Up Robust Features (SURF),
    a 128-dimension (8 orientation bins for each of the 4 × 4 location bins) local
    feature detector, and a descriptor (Bay et al., 2008). As a scale-invariant feature,
    SURF used image pyramids and different sized box filters to find points of interest
    at different scale spaces (Lowe, 2004). The scale space of SURF was divided into
    octaves and each octave was subdivided into a constant number of scale levels.
    The number of pyramid octaves and octave layers were both set to three in this
    study as suggested by Lowe (2004). After feature detection, the k-nearest neighbors
    (KNN) algorithm was used to match the most similar feature pairs in two successive
    images. The KNN calculated all the Euclidean distances of features to find the
    closest K matches. In this study, K was set to 2 (K = 2) so that the algorithm
    would return the two closest key points for each key point to be matched. 2.3.2.
    Removal of false matches False matches, i.e., the pixels that had the shortest
    Euclidean distance but were different objects in the successive images, would
    occur and needed to be removed. Two methods were used sequentially to remove these
    false matches: 1) distance ratio test; 2) matching line slope and length ratio
    test. The distance ratio test was performed using Eq. (1): (1) where, D1 and D2
    are the Euclidean distance of the closest key point and second-closest key point
    identified by KNN; R is the ratio selected by a trial-and-error approach. It was
    assumed that D1 came from the same object as the key point to be matched, while
    D2 came from another object, which could be noise. The distance ratio test then
    tested whether D1 was sufficiently different from D2 to decide it was a false
    match. If the difference was small, D1 could also represent noise. As suggested
    by Lowe (2004), R > 0.80 was initially used to remove all the false matches and
    less correct matches. However, this ratio still kept some false matches in this
    study, and the ratio was adjusted to R > 0.65 to remove all the false matches.
    The images were collected on a relatively calm day (wind speed ≤ 4 m s−1) and
    the UAV was flown parallel to the ground with minimum variations in roll and pitch.
    In our experiments, variations in UAV yaw angle were noticed and therefore the
    images were pre-processed (as described in Feng et al, 2020a) to align the crop
    rows. However, there was no substantial variation in angles to crop rows between
    two successive images since the heading variation was small during the acquisition
    of two images (2 s). Therefore, the correct matches were expected to have similar
    slopes and length. Hence, by calculating the slopes and lengths of matching lines
    using Eq. (2), (3), the ratio of the slope and the length of one matching line
    to the mean value of all matching lines in two successive images would be close
    to 1. (2) (3) where, (x1, y1) and (x2, y2) are the coordinates of a key point
    and its matching point in two successive images. Those matches with a large ratio
    difference from other matches were false matches and were removed by using the
    thresholds of < 0.9 and > 1.1 (determined by trial-and-error methods). Fig. 4
    shows an example of correct matches remaining (yellow lines) after removing false
    matches using the two methods. Before removing false matches, there were 10,978
    matches and after removing false matches using Method 1 (three example lines shown
    in red), there were 113 matches remaining, including false and correct matches.
    Finally, after removing false matches (three example lines shown in blue) using
    Method 2, the remaining 34 matches were all correct matches. The remaining matches
    were distributed on the bottom of left image and top of the right image as these
    are the areas overlapping between them. Fewer matched lines were found at the
    left corner of the two images (bottom left corner of left image and top left corner
    of the right image) as compared to their right corners, where there were fewer
    notable image features being filtered during the SURF feature detection process
    (Bay et al., 2008, Feng et al., 2019). In addition, it can be seen from Fig. 4
    that less matching features were detected from the left portion of images than
    those from the right portion. The possible reason might be that left portion of
    images was brighter or slightly saturated with less distinction between crops
    and soil background than the right portion, where more distinguished features
    were observed (darker soil background and crop row accompanied by shadow). Download
    : Download high-res image (220KB) Download : Download full-size image Fig. 4.
    Feature detection and matching in two successive images (right image is the next
    successive image after the left image flying in the north to south direction)
    of the cotton field. Yellow lines and blue ID number represent valid matches.
    Red lines and red ID number indicate example matches removed after Method 1 while
    blue lines and red ID number indicate example matches removed after Method 2.
    (For interpretation of the references to color in this figure legend, the reader
    is referred to the web version of this article.) 2.3.3. Calculation of the geometric
    transformation matrix Once the correct matches were identified, transformation
    matrices of each matching pair within the two successive images were calculated.
    In this study, a generic transformation matrix M was used as shown in Eq. (4)
    (Szeliski, 2007): (4) where, tx and ty are the distance in pixels of translation
    in the E-W and NS directions; sx and sy are the scale factors in E-W and NS directions,
    respectively; and θ is the rotation angle. Assuming a pixel value of an image
    coordinate I(x, y) was to be transformed into its previous image coordinate I’(x'',y''),
    Eq. (5) shows the transformation of these two images based on the transformation
    matrix M: (5) where, (x, y) and (x’, y’) are image coordinates of image I(x, y)
    and I’(x'',y''). The images had been rotated to obtain crop rows aligned with
    the vertical axis of the images as stated earlier. Therefore, no rotation was
    needed in the image transformation (i.e., θ = 0). In addition, the GSD of each
    image frame was calculated using row spacing (detailed in Section 2.3.5) and the
    UAV did not have much variation between two images (within 2 s). Therefore, the
    scale factor between two successive images was relatively small in this study.
    This study aimed to develop a near real-time pipeline to process individual UAV
    images for improved position accuracy, which required timely data processing (minimize
    processing time). To reduce the computation time of matching two images, only
    translation was considered in the transformation matrix, i.e., without including
    scale factor and rotation (sx and sy = 1; θ = 0). 2.3.4. Crop row alignment based
    on the geometric transformation matrix After applying the SHT to the original
    images, the images were rotated and each crop row position in the rotated images
    was obtained. Then, crop row alignment was conducted, with Fig. 5 showing this
    process for the first two images of the cotton field. Firstly, the crop row numbers
    of the first image were identified manually. The tx in the geometric transformation
    matrix M controlled the distance in pixels of translation in the E-W direction.
    When each crop row in the second image was translated by tx pixels, they would
    match with the positions of each crop row in the first image and would be assigned
    to the row numbers corresponding with the row numbers in the first image. New
    crop rows that appeared on the right side of the second image would be assigned
    a successively higher number from the last crop row in the first image. This process
    would continue in every-two consecutive images until crop row numbers were assigned
    to all images. Download : Download high-res image (331KB) Download : Download
    full-size image Fig. 5. Crop row alignment. There were 10 cotton rows identified
    manually in the first image from the cotton field. The numbers of 9 cotton rows
    identified by the SHT in the second image frame were aligned with the first image
    frame based on the distance in pixels in the E-W direction (tx) from the geometric
    transformation matrix M. The distance in pixels in the NS direction (ty) determined
    the image position within the entire crop row. 2.3.5. Image positions within each
    entire crop row The ty in the geometric transformation matrix M determined the
    distance in pixels of translation in the NS direction as demonstrated in Fig.
    5 and Eq. (4). When the UAV flew in the north to south direction, the images at
    the north and the images at the south were at the beginning and the end of the
    crop rows, respectively as shown in Fig. 6. The ty value was positive when the
    image sequence was from the beginning to the end (north to south). Similarly,
    when the UAV flew from south to north, the image sequence was from the end to
    the beginning of the crop rows and the ty value was negative. Due to the forward
    image overlaps when taking successive images in the fields, each image would move
    ty pixels from its previous image in the NS direction. Since actual UAV flight
    height was inconsistent due to some uncontrolled factors, resulting in different
    GSD for each image, the translation pixels in the NS directions would misrepresent
    the true translation based on the ground distance (translation in meters) for
    the entire crop rows. Hence, to resolve this problem, translation in meters was
    calculated using the GSD of each image as determined based on the fixed row spacing
    (Eq. (6)): (6) Download : Download high-res image (474KB) Download : Download
    full-size image Fig. 6. Illustration of determining image positions within each
    entire crop row. Black cross in each combined image represents the center position
    for each image in their combined image. where ty_meter is the translation in meters
    in the NS direction, ty is the pixels of translation in the NS directions and
    GSD is the ground sampling distance. The GSD was determined automatically by dividing
    the number of pixels for plant rows (obtained after row detections by Hough transformation)
    by actual row spacing (determined by the planter) as described in Feng et al.,
    2020a. The first image of the data collection (the beginning of the first crop
    rows) was given a value of zero and used as the reference for all other images
    collected in each field (Fig. 6). Then, the position in the NS direction of all
    other images was determined by accumulating the ty_meter from each subsequent
    image as illustrated in Fig. 6. 2.3.6. Emergence mapping based on the image alignment
    Crop emergence is an important agronomic factor for plant development assessment
    and field management at early growth stages, and can be evaluated using plant
    population, stand count, uniformity, and seedling size (Sansone et al., 2002,
    Supak, 1990). Crop emergence mapping of these parameters is important for making
    early field management decisions, assessing yield spatial variability, and studying
    effects of soil and environment on crop emergence (Feng et al., 2020a, Vong et
    al., 2022). In this study, emergence maps of a few parameters including stand
    count and canopy area for the cotton field, and stand count, mean days to imaging
    after emergence (DAEmean), and standard deviation of plant spacing (PSstd) for
    the corn field were created. The created maps were based on a local coordinate
    system consisting of a two-dimensional X-Y plane oriented in the NS (Y axis) and
    E-W directions (X axis) with the center position of the first image in the first
    flight path as the origin point (refer to section 2.3.5). Multiple 1-m seedling
    segment images were cropped from each raw image using the method described by
    Feng et al. (2020a) (Fig. 3 dashed line box) and illustrated in Fig. 7. The previously
    stated emergence parameters were estimated using a Resnet18 model described in
    previous studies (Feng et al., 2020a, Vong et al., 2022). Then, the maps were
    created based on the location of each segmented image as determined by the row
    numbers in E-W direction and ty_meter in NS direction. The row numbers were recognized
    based on the crop row assignment steps delineated above. Since the ty_meter described
    the translation in meters in the NS direction for the geometric center of each
    image frame, the translation in meters of each segmented image could be computed
    by adding (segment images below the geometric center) to or subtracting (segment
    images above the geometric center) from the distance in meters of the ty_meter
    (Fig. 7). If some segmented images from different images were geometrically close
    (<1 m), the average of their estimated emergence parameters was used when generating
    the emergence maps. To further demonstrate the usage of the emergence maps created
    from the developed pipeline, the cotton canopy area and stand count maps were
    compared with a yield map generated from an Ag Leader Insight yield monitor installed
    on a cotton harvester (1996 Case IH 2155, Racine, WI). The details of the harvest
    and yield map generation were described in Feng et al. (2019). Then, a Pearson
    correlation was performed to correlate canopy area and stand count with yield.
    Download : Download high-res image (268KB) Download : Download full-size image
    Fig. 7. Illustration of multiple cropped 1-m segment images and computation of
    their position based on the geometric center of an image, ty_meter. 2.4. Position
    accuracy evaluation using GCPs To evaluate the performance of the developed pipeline
    in improving position accuracy, an RTK GNSS system was used to measure the coordinates
    of GCPs in both fields, as shown in Fig. 8 and denoted as ground measurement.
    Furthermore, coordinates of GCPs were also determined from the GNSS of the UAV,
    DJI Phantom 4 Advanced using the method described by Feng et al. (2020a) and denoted
    as Phantom measurement. Then, the distance between GCPs was calculated using the
    coordinates from the ground and Phantom measurement using the haversine formula
    (Feng et al., 2020a, Naik and Nair, 2019). For the pipeline measurement, the distance
    between GCPs was calculated based on ty_meter for the NS direction and the difference
    in crop rows for the E-W direction (Fig. 8c). Then, the position accuracy was
    computed as the difference in their distances for all the GCPs (Ground vs Pipeline
    and Ground vs Phantom) and represented in a boxplot. Download : Download high-res
    image (688KB) Download : Download full-size image Fig. 8. Location of ground control
    points (GCPs) in a) corn field and b) cotton field as well as demonstration of
    distance comparison between two different kinds of systems for the position accuracy
    evaluation: b) ground RTK measurement and c) pipeline measurement. An analysis
    of variance (ANOVA) test followed by Tukey’s Honest Significant Difference (HSD)
    test was conducted to compare position accuracy means at a 0.05 significance level
    (α = 0.05) for the two sets (Ground vs Pipeline and Ground vs Phantom). The cotton
    field had 28 GCPs as shown in Fig. 8b, with all the GCPs south of p1, p2, p3,
    and p4 in the same row. The comparison of coordinates (latitude and longitude)
    was between every-two GCPs in the same row (e.g., p1 and p5, p1 and p9, p1 and
    p13, p1 and p17, p1 and p21, p1 and p25, p5 and p9, etc.). One of the GCPs (p26)
    was not visible in the UAV image and was excluded from the position accuracy comparison.
    Hence, the total pairs for position accuracy comparison in the cotton field was
    78. On the other hand, the locations of GCPs in the corn field (Fig. 8a) were
    more random (at different rows) compared to those of the cotton field. The position
    accuracy comparison was between every-two GCPs (e.g., p1 and p2, p1 and p3, p1
    and p4, etc.), resulting in ten pairs. 2.5. Processing time comparison The processing
    time needed for the entire workflow in Fig. 3 for both fields was recorded and
    compared with the image stitching time needed from two commercial software packages,
    Agisoft Metashape (ver. 1.8.0) and Pix4D Mapper. A desktop configured as an Intel
    Core i9-9900 K 3.60 GHz, an NVIDIA GeForce RTX 2060 GPU with 6 GB memory, an NVIDIA
    GeForce RTX 2060 Super GPU with 8 GB memory, 32 GB RAM and 3 TB solid-state drive
    (SSD) was used to process the images using the new pipeline in this study and
    for image stitching by the two commercial software packages to make a comparison
    of their processing time. The commercial software packages used GPU resources
    of the desktop during processing while the pipelines did not use the desktop’s
    GPU resources. 3. Results 3.1. Position accuracy evaluation Fig. 9 shows the position
    errors of GCPs in both fields measured by the developed pipeline using single
    images, calculated as the distance difference between the ground RTK GPS coordinates
    and coordinates calculated by the pipeline (Ground vs Pipeline). For comparison,
    Fig. 9 (box plots in red color) also shows distance difference for the raw UAV
    images (Feng et al., 2020a, Ground vs Phantom). It can be seen that the distance
    differences (errors) of the developed pipeline were 0.32 ± 0.21 m and 0.57 ± 0.28
    m (mean ± standard deviation) for cotton and corn fields, which were significantly
    lower than those between ground RTK and the Phantom measurement system (1.98 ±
    1.53 m and 2.13 ± 1.89 m respectively). The position error of the previous study
    (Feng et al., 2020a) was 1.72 ± 1.53 m as they only involved 24 pairs of GCPs,
    i.e., every-two successive GCPs in the same row (e.g., p1 and p5, p5 and p9, p9
    and p13, etc.), compared to 78 pairs of every-two GCPs in this study. Download
    : Download high-res image (93KB) Download : Download full-size image Fig. 9. Position
    error (distance difference) between ground RTK (ground), pipeline measurement
    (pipeline), and DJI Phantom 4 system (Phantom) for both cotton and corn fields.
    Different letters in each boxplot of the two fields show significant differences
    in the means at p < 0.05 for the Tukey HSD test. 3.2. Single image processing
    pipeline assessment (problems and solutions) A total of 2,200 and 517 images were
    collected for the cotton and corn fields, respectively. Some of the images were
    not assigned to the correct crop row numbers due to a low degree of overlap between
    two successive images. This was usually caused by an inconsistent actual AGL flight
    height of the UAV, which may have been due to errors in the UAV elevation sensor,
    field slope, signal noise, or low battery level. Moreover, when flying a UAV over
    a relatively larger field such as the cotton field in our study (5.1 ha) with
    a low flight height (10 m), multiple batteries were needed. When the battery level
    was low, we observed that the pre-set flight height changed (lower flight height),
    which resulted in a larger scale factor for the two successive images (between
    the last image before changing the battery and first image after changing the
    battery). Hence, two approaches were considered to solve these problems: 1) using
    side instead of forward overlapping images. The side overlapping images could
    be found based on the nearest position coordinates of images in the UAV flight
    path next to the target path; 2) manually identifying and assigning the crop row
    numbers of the image by referring to the surrounding images (the previous and
    side overlapping images). Fig. 11 illustrates some example situations encountered
    in the cotton field where one of the two solutions was used to solve the problem.
    For example, the successive images in Fig. 10a had<5 % overlap and crop row numbers
    were only able to be manually identified and assigned. Fig. 10b shows a successful
    example of aligning rows by matching features from side overlapping images. On
    the other hand, Fig. 10c illustrates images before and after changing the UAV
    battery, resulting in large scale factor differences and requiring manual row
    number assignment. In our study, < 0.4 % of images taken needed manual assignment
    of row numbers (7/2,200 for cotton and 2/517 for corn fields). This problem can
    be reduced in future studies by using a higher resolution camera, thus enabling
    a higher and more stable flight height for sufficient image overlaps. Download
    : Download high-res image (478KB) Download : Download full-size image Fig. 10.
    Example illustrations of different problems faced in the cotton field requiring
    additional solutions to align the row numbers. a) successive images with < 5 %
    overlap, where row numbers were assigned manually; b) row number successfully
    assigned using side images; c) images before and after changing battery, where
    row numbers were assigned manually. Download : Download high-res image (571KB)
    Download : Download full-size image Fig. 11. Cotton field emergence maps of a)
    stand count and b) canopy size with full dimension of 152 crop rows × 315 m length
    for each crop row and their down-sampled maps with dimension of 38 × 63 in c and
    d, respectively, where each data point equates to a 4 m × 5 m area. A crop yield
    map with the same 4 m × 5 m cell size is shown in e. 3.3. Crop emergence maps
    To demonstrate the usage of the developed pipeline in creating emergence maps,
    a stand count map (seedlings m−1) and a canopy size map (cm2 seedling−1) were
    generated for the cotton field by calculating the number of plants and their average
    canopy size within each meter of each row (Fig. 12a and b). These maps had a resolution
    of 152 × 315 grids (i.e., 152 crop rows by 315 m in NS direction) and were down-sampled
    to a 38 × 63 grid (Fig. 12c and d) by averaging the stand count and canopy size
    of every 5 m in each four adjacent rows (equal to a 4 m × 5 m area) for matching
    with the four-row harvested yield data (Fig. 11e). The figures confirmed the positive
    correlation between yield and stand count/ canopy size (r = 0.3 for stand count
    and r = 0.35 for the canopy size, both with p-value < 0.001) by displaying the
    similar patterns of field variations in the figures. Higher stand count and canopy
    size corresponded to higher yield. For instance, the northeast portion (red circle
    in Fig. 11) of the field had lower stand counts, canopy sizes, and yield while
    the opposite was shown in the southwest part (black circle in Fig. 11) of the
    field. Download : Download high-res image (673KB) Download : Download full-size
    image Fig. 12. Schematic diagram showing the treatment and non-treatment crop
    rows (a) and their emergence maps of stand count (plant m−1, b), mean days to
    imaging after emergence (DAEmean, days, c), and standard deviation of plant spacing
    (PSstd, cm m−1, d) in corn field. For the corn field, emergence maps of three
    parameters: stand count, DAEmean, and PSstd were generated using the developed
    pipeline as shown in Fig. 12b to 12d. These maps had a resolution of 72 × 160
    grids (i.e., 72 crop rows by 160 m in NS direction). Fig. 12a shows the schematic
    diagram of the crop rows, where there were 64 rows with planting depth treatments
    and the remaining eight rows without planting depth treatments. There was no obvious
    pattern in the stand count and PSstd maps related to planting depth, but DAEmean
    showed trends of higher DAEmean with decreasing depths. Collectively, these results
    suggest that the developed pipeline was able to provide position information for
    each single UAV image and further process those images to obtain the emergence
    maps, which would be beneficial in PA applications, especially in understanding
    the effect of spatial variability of the field on crop emergence and production.
    Furthermore, this method could reduce the time needed for putting GCP in the field
    and for image post-processing (image stitching and feature extraction). 3.4. Processing
    time comparison The workflow and parameters set in Agisoft Metashape and Pix4D
    Mapper to stitch the UAV images collected on both fields are detailed in Table
    1, Table 2. The settings for these parameters were to ensure the software used
    the full-size images (not down-sampled images) since the developed pipeline in
    this study used the original full-size images during processing. The common workflow
    to stitch the image to obtain the orthomosaic in Agisoft Metashape includes ‘align
    photos’, ‘build dense point cloud’, ‘build mesh’, and ‘build orthomosaic’. However,
    with the large number of images collected in the cotton field (2,200 images),
    an error occurred during the ‘build mesh’ step stating, ‘Not enough memory’. Therefore,
    another step, ‘build DEM’ was performed to act as the surface for the ‘build orthomosaic’
    step. For Pix4D Mapper, the stitching process failed and did not produce the final
    orthomosaic for either the cotton or corn field, which might be due to the low
    image overlaps. Image overlap for this software is recommended at least 75 % and
    60 % for forward and side overlaps, respectively (https://pix4d.com). Although
    the UAV flights (height, speed, and flight paths) were set to have 60–70 % image
    overlaps for both fields, the actual overlap changed due to inconsistent AGL flight
    height caused by several factors mentioned previously in section 3.2. Other studies
    also indicated that the image reconstruction process using stitching software
    was not fully completed when a side overlap was smaller than 55 % (Seifer et al.,
    2019). Even with the successful process, the resulting orthomosaic would have
    artifacts such as holes, dislocation, and distortion (Cui et al., 2021). Table
    1. Stitching workflow and parameter set in Agisoft Metashape Professional to stitch
    the UAV images collected on cotton and corn fields. Stitching Workflow Parameter
    Cotton Field Corn Field Align Photos Accuracy: Highest; Generic preselection:
    Yes; Reference preselection: Source Build Dense Point Cloud Quality: Ultra high;
    Depth filtering: mild Build Mesh – Source data: Dense cloud; Surface type: Height
    field; Depth maps quality: Ultra high Build DEM Source data: Dense cloud; Quality:
    Ultra high; Depth filtering: mild – Build Orthomosaic Surface: DEM; Blending mode:
    Mosaic Surface: Mesh; Blending mode: Mosaic Table 2. Stitching workflow and parameter
    set in Pix4D Mapper to stitch the UAV images collected on cotton and corn fields.
    Stitching Workflow Parameter (for both cotton and corn) Initial Processing Keypoints
    Image Scale: Full; Matching Image Pairs: Aerial Grid or Corridor Point Cloud and
    Mesh Point Cloud Densification: Image Scale = 1/1, Point Density = High, Minimum
    Number of Matches = 3; DSM, Orthomosaic and Index Resolution: Automatic The total
    image processing time using the algorithms developed in this study was 10.4 and
    5.7 s/image for the cotton and corn fields (as shown in Table 3). The difference
    in the image processing time between the two fields was mostly due to the time
    used in detecting and matching the image features, which were different in the
    images with different crops, soil conditions, residue backgrounds, and lighting
    conditions. These processing times corresponded to 6.4 h for the 5.1 ha cotton
    field and 0.82 h for the 0.8 ha corn field. Meanwhile, the processing times of
    the pipeline were lower than the image stitching time needed by the commercial
    software, which were 88.7 and 97.4 s/image for cotton and corn fields, respectively.
    Table 3. Processing time comparison between the new method of this study and commercial
    software in stitching the UAV images. Field Processing Time (s/image) Pipeline:
    Fig. 3 dashed line Pipeline: Fig. 3 dotted line Pipeline: Total Time Agisoft Metashape
    Cotton 1.8 s 8.6 s 10.4 s 88.7 s Corn 2.1 s 3.6 s 5.7 s 97.4 s 4. Discussion 4.1.
    Pipeline performance The study developed a near real-time UAV image processing
    pipeline that had higher performance than the method used in the previous study
    and achieved a better position accuracy. Without the need for an RTK unit on the
    UAV, the pipeline was able to produce more accurate field maps with an average
    position accuracy of 0.32 and 0.57 m for the cotton and corn fields, respectively.
    The position accuracy of the cotton field is well within half of the common crop
    row spacing, which is 0.38 to 0.51 m (Clawson et al., 2006). The position accuracy
    of the corn field was not within half of the common row spacing (0.19 to 0.49
    m; Elmore and Abendroth. 2007), and lower than that of the cotton field (higher
    distance difference), which might be caused by human errors. As illustrated in
    Fig. 13, a yellow ground stake, which could be clearly seen from the image (Fig.
    13a) was used to mark the GCPs in the cotton field. However, in the corn field,
    two flags were used to mark each monitoring site, with one of the flags used as
    the GCP. However, the point where the flag was inserted into the ground surface
    could not be seen clearly in the image (Fig. 13b). The location for the insertion
    point of the flag was estimated based on the location of the first color stake
    in each plant row (Fig. 13b). Download : Download high-res image (227KB) Download
    : Download full-size image Fig. 13. Images showing a) ground stake used to mark
    the ground control point (GCP) for cotton field and b) flag used to mark the monitoring
    site and used as the GCP for corn field. The developed pipeline was expected to
    be a low-cost near real-time tool for row crop emergence estimation as it reduced
    the time needed for image stitching compared to the commercial software. Image
    stitching comprises several steps: 1) feature detection and matching between images;
    2) non-linear geometric transformation matrix estimation including translation,
    rotation, and scale; 3) warping transformation for mosaic processing (Brown and
    Lowe, 2007). When data are collected for row crops with fixed row spacing and
    under steady UAV flight conditions, the developed method of only calculating translations
    in the geometric transformation matrices required less processing time than the
    stitching process. The dynamic calibration of GSD for individual images using
    row spacing would make it possible for field mapping without the image mosaic
    process. 4.2. Cotton field emergence mapping The mapping of the cotton field in
    this study showed a low correlation value between emergence and yield, which was
    likely caused by environmental factors, irrigation, and other in-season management
    (Feng et al., 2022). Nonetheless, the finding of positive correlation was still
    consistent with previous studies indicating that higher plant density would have
    higher yields as there were more bolls per unit area (Yang et al., 2014, Zhi et
    al., 2016). Meanwhile, canopy size is one of the critical components of canopy
    structure relating to plant photosynthesis, fruiting, and biomass accumulation
    (Jiang et al., 2018, Jung et al., 2018), and is commonly used as a feature in
    cotton yield estimation (Feng et al., 2020c; Jung et al., 2018). More investigations
    are needed to study the effects of environments and crop development on the final
    yield. 4.3. Pipeline limitations Our pipeline has a few limitations. Firstly,
    the method was developed to be used for row crops with fixed row spacing (such
    as cotton and corn shown in this study) as it highly depends on the crop row detection
    for image rotation and GSD calculation for each image. Therefore, there would
    be large errors if crop rows were not detected. Secondly, the method is limited
    to row crops at early emergence, or the crop growth stages before the crop leaves
    of neighboring rows start to overlap and close the canopy. Once leaf overlaps
    occur, crop rows are hardly detected and the initial steps of rotating images
    and calculating GSD are not feasible. In addition, to ensure the best performance
    of the pipeline (without needing manual identification and assignment of crop
    row numbers as detailed in section 3.2), a stable flight height on a flat field
    is desired. Inconsistent flight heights (especially in the situation of UAVs flown
    at low altitude in fields with substantial slopes) and height differences of two
    different flight missions will cause large scale factor differences in images,
    which is not included in our transform matrix calculation. For studies conducted
    on a windy day with limited processing performance using the methods developed
    in this study, automatic detection and correction of scale differences (row spacing
    could still be used as a clue) will be one of the solutions for this issue, which
    we would include in our future studies. 4.4. Potential application and future
    study The pipeline can be applied in a UAV data processing framework with a graphical
    user interface similar to the framework in Feng et al. (2020a) to process the
    data after a UAV flight, which allows a more user-friendly data processing platform
    for different users such as agronomists, breeders, and farmers to obtain crop
    emergence or early growth maps. Furthermore, the pipeline can also be used as
    a processing unit integrated with the onboard UAV sensor to deliver real-time
    data processing and thus reduce the time data transmission and pre-processing,
    before obtaining the final crop emergence maps. Future studies should include
    modification of the pipeline to other row crops such as soybean and vegetable
    for different emergence parameters estimations on the field scale. These estimations
    can be used by researchers to explore the relationships between crop emergence
    and environmental factors such as soil and weather conditions as well as different
    planting treatments. Meanwhile, this can act as a low-cost near real-time tool
    for small-scale farmers to estimate the early emergence in their fields. For large-scale
    farmers, the method can be used to scout areas within fields with emergence issues
    or biotic stresses impacting stand for further management decisions, or field
    areas that cannot be accessed easily by ground vehicles. 5. Conclusion This paper
    reports the development of a near real-time image processing pipeline to process
    single UAV images with an improved position accuracy algorithm to generate emergence
    maps of row crops including cotton and corn. The emergence parameters included
    stand count and canopy size for cotton as well as stand count, mean days to imaging
    after emergence, and plant spacing standard deviation for corn. The developed
    pipeline procedures included feature detection and matching, false matches removal,
    geometric transformation matrix calculation, crop row alignment, assigning position
    of each single image, and mapping. The results showed that the position accuracies
    for the developed pipeline compared to RTK-GNSS ground-truth measurements were
    0.32 ± 0.21 m and 0.57 ± 0.28 m for the cotton and corn fields, respectively.
    Emergence maps of cotton and corn fields were generated to demonstrate the application
    of this new method. The processing time needed to run the algorithm was 8.6 and
    3.6 s/image for cotton and corn fields, respectively. After adding the time needed
    for image pre-processing, the time needed would be 10.4 and 5.7 s image-1, corresponding
    to 1.3 and 1.0 hr ha−1 for the cotton and corn field, respectively. The developed
    pipeline introduced a new approach in using UAV images to quantify crop early
    emergence in a shorter time and lower cost. The current study demonstrated the
    usage of the pipeline for cotton and corn. CRediT authorship contribution statement
    Aijing Feng: Methodology, Data curation, Formal analysis, Writing – original draft.
    Chin Nee Vong: Methodology, Data curation, Formal analysis, Writing – original
    draft. Jing Zhou: Data curation, Formal analysis, Writing – original draft. Lance
    S. Conway: Investigation, Data curation. Jianfeng Zhou: Supervision, Conceptualization,
    Data curation, Writing – review & editing. Earl D. Vories: Resources, Data curation,
    Writing – review & editing. Kenneth A. Sudduth: Conceptualization, Resources,
    Writing – review & editing. Newell R. Kitchen: Conceptualization, Investigation,
    Data curation, Resources, Writing – review & editing. Declaration of Competing
    Interest The authors declare that they have no known competing financial interests
    or personal relationships that could have appeared to influence the work reported
    in this paper. Acknowledgements The authors would like to give thanks to colleagues
    Huawei Mou and Shengwei Wang from the Precision and Automated Agriculture Lab
    at the University of Missouri for their help in UAV data collection. We also want
    to thank the staff from the USDA-ARS Cropping Systems & Water Quality Research
    Unit for helping to manage the fields. Code availability The code related to this
    study are available at: https://github.com/AJFeng/Emergence_row_alignment. Data
    availability Data will be made available on request. References Bay et al., 2008
    H. Bay, A. Ess, T. Tuytelaars, L. Van Gool Speeded-up robust features (SURF) Computer
    Vision and Image Understanding, 110 (3) (2008), pp. 346-359, 10.1016/j.cviu.2007.09.014
    View PDFView articleView in ScopusGoogle Scholar Brown and Lowe, 2007 M. Brown,
    D.G. Lowe Automatic panoramic image stitching using invariant features International
    Journal of Computer Vision, 74 (1) (2007), pp. 59-73, 10.1007/s11263-006-0002-3
    View in ScopusGoogle Scholar Clawson et al., 2006 E.L. Clawson, J.T. Cothren,
    D.C. Blouin Nitrogen fertilization and yield of cotton in ultra-narrow and conventional
    row spacings Agronomy Journal, 98 (1) (2006), pp. 72-79, 10.2134/agronj2005.0033
    View in ScopusGoogle Scholar Cui et al., 2020 J. Cui, M. Liu, Z. Zhang, S. Yang,
    J. Ning Robust UAV thermal infrared remote sensing images stitching via overlap-prior-based
    global similarity prior model IEEE Journal of Selected Topics in Applied Earth
    Observations and Remote Sensing, 14 (2020), pp. 270-282, 10.1109/JSTARS.2020.3032011
    Google Scholar Delavarpour et al., 2021 N. Delavarpour, C. Koparan, J. Nowatzki,
    S. Bajwa, X. Sun A technical study on UAV characteristics for precision agriculture
    applications and associated practical challenges Remote Sensing, 13 (6) (2021),
    p. 1204, 10.3390/rs13061204 View in ScopusGoogle Scholar Elmore and Abendroth,
    2007 R.W. Elmore, L.J. Abendroth Row spacing alternatives in corn Paper Presented
    at the Proceedings of the Indiana CCA Conference (2007) Google Scholar Feng et
    al., 2019 Feng, A., Sudduth, K. A., Vories, E. D., & Zhou, J. (2019). Evaluation
    of cotton stand count using UAV-based hyperspectral imagery. Paper presented at
    the 2019 ASABE Annual International Meeting, Boston, MA. Google Scholar Feng et
    al., 2020a A. Feng, J. Zhou, E. Vories, K.A. Sudduth Evaluation of cotton emergence
    using UAV-based imagery and deep learning Computers and Electronics in Agriculture,
    177 (2020), Article 105711, 10.1016/j.compag.2020.105711 View PDFView articleView
    in ScopusGoogle Scholar Feng et al., 2020b A. Feng, J. Zhou, E. Vories, K.A. Sudduth
    Evaluation of cotton emergence using UAV-based narrow-band spectral imagery with
    customized image alignment and stitching algorithms Remote Sensing, 12 (11) (2020),
    p. 1764, 10.3390/rs12111764 View in ScopusGoogle Scholar Feng et al., 2020c A.
    Feng, J. Zhou, E.D. Vories, K.A. Sudduth, M. Zhang Yield estimation in cotton
    using UAV-based multi-sensor imagery Biosystems Engineering, 193 (2020), pp. 101-114,
    10.1016/j.biosystemseng.2020.02.014 View PDFView articleView in ScopusGoogle Scholar
    Feng et al., 2022 A. Feng, J. Zhou, E.D. Vories, et al. Quantifying the effects
    of soil texture and weather on cotton development and yield using UAV imagery
    Precision Agric (2022), 10.1007/s11119-022-09883-6 Google Scholar Gross and Heumann,
    2016 J.W. Gross, B.W. Heumann A statistical examination of image stitching software
    packages for use with unmanned aerial systems Photogrammetric Engineering & Remote
    Sensing, 82 (6) (2016), pp. 419-425, 10.1016/S0099-1112(16)82035-2 View PDFView
    articleView in ScopusGoogle Scholar Hugenholtz et al., 2016 C. Hugenholtz, O.
    Brown, J. Walker, T. Barchyn, P. Nesbit, M. Kucharczyk, S. Myshak Spatial accuracy
    of UAV-derived orthoimagery and topography: Comparing photogrammetric models processed
    with direct geo-referencing and ground control points Geomatica, 70 (1) (2016),
    pp. 21-30, 10.5623/CIG2016-102 View in ScopusGoogle Scholar Iglhaut et al., 2019
    J. Iglhaut, C. Cabo, S. Puliti, L. Piermattei, J. O’Connor, J. Rosette Structure
    from motion photogrammetry in forestry: A review Current Forestry Reports, 5 (3)
    (2019), pp. 155-168, 10.1007/s40725-019-00094-3 View in ScopusGoogle Scholar Jiang
    et al., 2018 Y. Jiang, C. Li, A.H. Paterson, S. Sun, R. Xu, J. Robertson Quantitative
    analysis of cotton canopy size in field conditions using a consumer-grade RGB-D
    camera Frontiers in Plant Science, 8 (2018), p. 2233, 10.3389/fpls.2017.02233
    View in ScopusGoogle Scholar Jung et al., 2018 J. Jung, M. Maeda, A. Chang, J.
    Landivar, J. Yeom, J. McGinty Unmanned aerial system assisted framework for the
    selection of high yielding cotton genotypes Computers and Electronics in Agriculture,
    152 (2018), pp. 74-81, 10.1016/j.compag.2018.06.051 View PDFView articleView in
    ScopusGoogle Scholar Lowe, 2004 D.G. Lowe Distinctive image features from scale-invariant
    keypoints International Journal of Computer Vision, 60 (2) (2004), pp. 91-110,
    10.1023/B:VISI.0000029664.99615.94 View in ScopusGoogle Scholar Naik and Nair,
    2019 R.K. Naik, B.B. Nair Improving GPS based distance measurement accuracy using
    machine learning: an empirical study Paper Presented at the 2019 International
    Conference on Communication and Electronics Systems (ICCES) (2019), 10.1109/ICCES45898.2019.9002218
    Google Scholar Obanawa et al., 2019 H. Obanawa, S. Sakanoue, T. Yagi Evaluating
    the applicability of RTK-UAV for field management Paper Presented at the IGARSS
    2019–2019 IEEE International Geoscience and Remote Sensing Symposium (2019), 10.1109/IGARSS.2019.8897895
    Google Scholar Rabah et al., 2018 M. Rabah, M. Basiouny, E. Ghanem, A. Elhadary
    Using RTK and VRS in direct geo-referencing of the UAV imagery NRIAG Journal of
    Astronomy and Geophysics, 7 (2) (2018), pp. 220-226, 10.1016/j.nrjag.2018.05.003
    View PDFView articleGoogle Scholar Robinson and Conley, 2007 A.P. Robinson, S.P.
    Conley Soybean production systems: plant population and seeding rates for soybean
    Purdue Extension, Purdue University, Indiana, USA (2007) Google Scholar Sansone
    et al., 2002 C. Sansone, T. Isakeit, R. Lemon, B. Warrick Texas cotton production:
    Emphasizing integrated pest management Texas Cooperative Extension Service, Texas
    A & M University System, Texas, USA (2002) Google Scholar Sanz-Ablanedo et al.,
    2018 E. Sanz-Ablanedo, J.H. Chandler, J.R. Rodríguez-Pérez, C. Ordóñez Accuracy
    of unmanned aerial vehicle (UAV) and SfM photogrammetry survey as a function of
    the number and location of ground control points used Remote Sensing, 10 (10)
    (2018), p. 1606, 10.3390/rs10101606 View in ScopusGoogle Scholar Štroner et al.,
    2021 M. Štroner, R. Urban, J. Seidl, T. Reindl, J. Brouček Photogrammetry using
    UAV-mounted GNSS RTK: georeferencing strategies without GCPs Remote Sensing, 13
    (7) (2021), p. 1336, 10.3390/rs13071336 View in ScopusGoogle Scholar Supak, 1990
    Supak, J. (1990). Making replant decisions. Paper presented at the 1990 Beltwide
    cotton production conference. Google Scholar Szeliski, 2007 R. Szeliski Image
    alignment and stitching: A tutorial Foundations and Trends® in Computer Graphics
    and Vision, 2 (1) (2007), pp. 1-104, 10.1561/0600000009 Google Scholar Tsouros
    et al., 2019 D.C. Tsouros, S. Bibi, P.G. Sarigiannidis A review on UAV-based applications
    for precision agriculture Information, 10 (11) (2019), p. 349, 10.3390/info10110349
    View in ScopusGoogle Scholar Vega et al., 2015 F.A. Vega, F.C. Ramirez, M.P. Saiz,
    F.O. Rosua Multi-temporal imaging using an unmanned aerial vehicle for monitoring
    a sunflower crop Biosystems Engineering, 132 (2015), pp. 19-27, 10.1016/j.biosystemseng.2015.01.008
    View PDFView articleView in ScopusGoogle Scholar Vong et al., 2021 C.N. Vong,
    L.S. Conway, J. Zhou, N.R. Kitchen, K.A. Sudduth Early corn stand count of different
    cropping systems using UAV-imagery and deep learning Computers and Electronics
    in Agriculture, 186 (2021), Article 106214, 10.1016/j.compag.2021.106214 View
    PDFView articleView in ScopusGoogle Scholar Vong et al., 2022 C.N. Vong, L.S.
    Conway, J. Zhou, N.R. Kitchen, K.A. Sudduth Corn emergence uniformity estimation
    and mapping using UAV imagery and deep learning Computers and Electronics in Agriculture,
    198 (2022), Article 107008, 10.1016/j.compag.2022.107008 View PDFView articleView
    in ScopusGoogle Scholar Xiang and Tian, 2011 H. Xiang, L. Tian Method for automatic
    georeferencing aerial remote sensing (RS) images from an unmanned aerial vehicle
    (UAV) platform Biosystems Engineering, 108 (2) (2011), pp. 104-113, 10.1016/j.biosystemseng.2010.11.003
    View PDFView articleView in ScopusGoogle Scholar Xie and Yang, 2020 C. Xie, C.
    Yang A review on plant high-throughput phenotyping traits using UAV-based sensors
    Computers and Electronics in Agriculture, 178 (2020), Article 105731, 10.1016/j.compag.2020.105731
    View PDFView articleView in ScopusGoogle Scholar Yang et al., 2014 G. Yang, X.
    Luo, Y. Nie, X. Zhang Effects of plant density on yield and canopy micro environment
    in hybrid cotton Journal of Integrative Agriculture, 13 (10) (2014), pp. 2154-2163,
    10.1016/S2095-3119(13)60727-3 View PDFView articleView in ScopusGoogle Scholar
    Yang et al., 2017 G. Yang, J. Liu, C. Zhao, Z. Li, Y. Huang, H. Yu, X. Zhang Unmanned
    aerial vehicle remote sensing for field-based crop phenotyping: current status
    and perspectives Frontiers in Plant Science, 8 (2017), p. 1111, 10.3389/fpls.2017.01111
    View in ScopusGoogle Scholar Zhi et al., 2016 X.-Y. Zhi, Y.-C. Han, Y.-B. Li,
    G.-P. Wang, W.-L. Du, X.-X. Li, F. Lu Effects of plant density on cotton yield
    components and quality Journal of Integrative Agriculture, 15 (7) (2016), pp.
    1469-1479, 10.1016/S2095-3119(15)61174-1 View PDFView articleView in ScopusGoogle
    Scholar Cited by (1) Optimization Methods for UAVs to Search Light Source in VLC
    2023, Faguang Xuebao/Chinese Journal of Luminescence 1 Aijing Feng and Chin Nee
    Vong are joint first authors. View Abstract © 2023 Elsevier B.V. All rights reserved.
    Recommended articles Aerial multispectral imaging for crop hail damage assessment
    in potato Computers and Electronics in Agriculture, Volume 127, 2016, pp. 406-412
    Jianfeng Zhou, …, Sindhuja Sankaran View PDF Calculation method of wilting index
    based on fractal dimension of multispectral images for the soybean canopy Computers
    and Electronics in Agriculture, Volume 206, 2023, Article 107656 Panpan Shen,
    …, Tao Zhang View PDF Estimating characteristic coefficient of vertical leaf nitrogen
    profile within wheat canopy from spectral reflectance Computers and Electronics
    in Agriculture, Volume 206, 2023, Article 107652 Heli Li, …, Chunjiang Zhao View
    PDF Show 3 more articles Article Metrics Citations Citation Indexes: 1 Captures
    Readers: 13 View details About ScienceDirect Remote access Shopping cart Advertise
    Contact and support Terms and conditions Privacy policy Cookies are used by this
    site. Cookie settings | Your Privacy Choices All content on this site: Copyright
    © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved,
    including those for text and data mining, AI training, and similar technologies.
    For all open access content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Computers and Electronics in Agriculture
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Developing an image processing pipeline to improve the position accuracy
    of single UAV images
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Cao S.
  - Chen Y.Q.
  citation_count: '0'
  description: Agriculture in arid areas is often limited by the scarcity of fresh
    water and increasing soil salinization problems. A saltwater greenhouse that uses
    salty water instead of fresh water is a promising solution for agriculture in
    such areas. When used in agriculture irrigation tail water processing, the salt-water
    greenhouse can be an effective tool for salt extraction which is an important
    means to mitigate the salinity accumulation problem. However, to optimize greenhouse
    production and energy efficiency, it is essential to incorporate smartness into
    the system using existing developments in AI/ML, big data, cloud/edge computing,
    etc. Therefore, developing a smart saltwater greenhouse leveraging these emerging,
    cutting edge and groundbreaking technologies becomes a center objective of today’s
    greenhouse development in general and saltwater greenhouse in particular. In this
    overview framework paper, we present a Digital Twin development framework for
    a smart saltwater greenhouse. First, the background of the saltwater greenhouse
    project is introduced together with the basic concept of smart systems and Digital
    Twins. The greenhouse control system is introduced with a Digital Twin in mind.
    We then propose the DT development framework dedicated to the saltwater greenhouse.
    A five-step DT development framework is reviewed and those new smartness features
    that could be enabled by using DT are also explained. Finally, we conclude the
    DT framework with some future research efforts.
  doi: 10.1115/DETC2023-116343
  full_citation: '>'
  full_text: '>

    "Cart 0 University of Nebraska - Lincoln Lib Sign In Latest Proceedings All Years
    Browse by Subject Category All Proceedings Topic Collections About All Content
    All Proceedings Design Engineering IDETC-CIE                              Advanced
    Search ASME 2023 International Design Engineering Technical Conferences and Computers
    and Information in Engineering Conference August 20–23, 2023 Boston, Massachusetts,
    USA Conference Sponsors: Design Engineering Division Computers and Information
    in Engineering Division Volume 7: 19th IEEE/ASME International Conference on Mechatronic
    and Embedded Systems and Applications (MESA) ISBN: 978-0-7918-8735-6 Previous
    Paper Next Paper PROCEEDINGS PAPER A Digital Twin Development Framework for a
    Smart Saltwater Greenhouse Shiang Cao, YangQuan Chen Author Information Paper
    No: DETC2023-116343, V007T07A004; 5 pages https://doi.org/10.1115/DETC2023-116343
    Published Online: November 21, 2023 Share Cite Permissions Abstract Agriculture
    in arid areas is often limited by the scarcity of fresh water and increasing soil
    salinization problems. A saltwater greenhouse that uses salty water instead of
    fresh water is a promising solution for agriculture in such areas. When used in
    agriculture irrigation tail water processing, the salt-water greenhouse can be
    an effective tool for salt extraction which is an important means to mitigate
    the salinity accumulation problem. However, to optimize greenhouse production
    and energy efficiency, it is essential to incorporate smartness into the system
    using existing developments in AI/ML, big data, cloud/edge computing, etc. Therefore,
    developing a smart saltwater greenhouse leveraging these emerging, cutting edge
    and groundbreaking technologies becomes a center objective of today’s greenhouse
    development in general and saltwater greenhouse in particular. In this overview
    framework paper, we present a Digital Twin development framework for a smart saltwater
    greenhouse. First, the background of the saltwater greenhouse project is introduced
    together with the basic concept of smart systems and Digital Twins. The greenhouse
    control system is introduced with a Digital Twin in mind. We then propose the
    DT development framework dedicated to the saltwater greenhouse. A five-step DT
    development framework is reviewed and those new smartness features that could
    be enabled by using DT are also explained. Finally, we conclude the DT framework
    with some future research efforts. Volume Subject Area: 19th IEEE/ASME International
    Conference on Mechatronic and Embedded Systems and Applications (MESA) Keywords:
    saltwater greenhouse, digital twin, smart system Topics: Digital twin This content
    is only available via PDF. Copyright © 2023 by ASME You do not currently have
    access to this content. Sign In Sign In Or Register For Account Sign in via your
    Institution Purchase this Content $25.00 Purchase Learn about subscription and
    purchase options View Metrics Email Alerts Proceedings Paper Activity Alert Latest
    Conference Proceedings Alert Related Proceedings Papers Toward Environmental and
    Structural Digital Twin of Offshore Wind Turbine OMAE2023 Demonstration of a Standalone,
    Descriptive, and Predictive Digital Twin of a Floating Offshore Wind Turbine OMAE2023
    Digital Twin for Autonomous Surface Vessels to Generate Situational Awareness
    OMAE2023 Quality Assurance of Digital Twins OMAE2023 Related Articles Digital
    Twin-Driven Sheet Metal Forming: Modeling and Application for Stamping Considering
    Mold Wear J. Manuf. Sci. Eng (December,2022) Fault Management Architecture Based
    on a Digital Twin Approach J. Energy Resour. Technol (March,2022) Digital Twin
    to Detect Nuclear Proliferation: A Case Study J. Energy Resour. Technol (October,2022)
    Related Chapters Digital Transformation by the Implementation of the True Digital
    Twin Concept and Big Data Technology for Structural Integrity Management Ageing
    and Life Extension of Offshore Facilities ASME Conference Publications and Proceedings
    Conference Proceedings Author Guidelines Indexing and Discovery ASME Journals
    About ASME Journals Information for Authors Submit a Paper Call for Papers Title
    History ASME Conference Proceedings About ASME Conference Publications and Proceedings
    Conference Proceedings Author Guidelines ASME eBooks About ASME eBooks ASME Press
    Advisory & Oversight Committee Book Proposal Guidelines Resources Contact Us Authors
    Librarians Frequently Asked Questions Publication Permissions & Reprints ASME
    Membership Opportunities Faculty Positions Accessibility Privacy Statement Terms
    of Use Get Adobe Acrobat Reader Copyright © 2024 The American Society of Mechanical
    Engineers This site uses cookies. By continuing to use our website, you are agreeing
    to our privacy policy. Accept"'
  inline_citation: '>'
  journal: Proceedings of the ASME Design Engineering Technical Conference
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A DIGITAL TWIN DEVELOPMENT FRAMEWORK FOR A SMART SALTWATER GREENHOUSE
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Rani T.O.G.
  - Goudar S.S.
  - Chethan M.
  - Harshitha M.
  - Shashank Raju K.
  - Sinchana K.R.
  citation_count: '0'
  description: This paper aims to implement a wireless sensor network to automate
    greenhouse operations, with the primary objective of achieving optimal plant growth
    conditions. To effectively monitor crucial micro-climatic parameters such as temperature,
    soil moisture, light, pH, and salinity, the system employs slave unit sensor nodes
    equipped with a diverse array of sensors. Additionally, a mobile application is
    utilized to enable farmers to set customized threshold values for each parameter,
    granting them complete control over the greenhouse environment via their mobile
    devices. These threshold values serve as benchmarks to ensure that the growing
    conditions remain within desired ranges. Multiple slave units have been strategically
    deployed throughout the greenhouse to ensure comprehensive and accurate data collection.
    Each slave unit actively collects sensor data and efficiently transmits it wirelessly
    to the central master unit. The master unit plays a vital role in the automation
    process by receiving the data set by the mobile application and meticulously comparing
    it with the real-time data received from the slave units. This meticulous comparison
    allows the system to precisely assess the current conditions against the desired
    threshold values. Based on this comparison, the system takes prompt actions to
    regulate and maintain the most favorable growing conditions for the plants, optimizing
    their growth potential. An essential aspect of this system's design is the integration
    of edge computing, enabling localized processing and decision-making. This approach
    significantly reduces latency and dependence on constant cloud connectivity, ensuring
    that the system remains responsive and reliable, even in areas with limited network
    coverage. The implementation of this automated greenhouse system brings numerous
    benefits to agriculturists, as it alleviates the burden of manual monitoring and
    control. Instead, farmers can concentrate on strategic planning and overall agricultural
    management, optimizing their efforts for improved productivity. Moreover, the
    system's ability to maintain optimal growing conditions results in maximized crop
    yield while promoting resource-efficient and environmentally sustainable farming
    practices.
  doi: 10.1109/NMITCON58196.2023.10276317
  full_citation: '>'
  full_text: '>

    ""'
  inline_citation: '>'
  journal: 2023 International Conference on Network, Multimedia and Information Technology,
    NMITCON 2023
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Monitoring and Control System for Green House Using Edge Computing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Sakthi U.
  - Thangaraj K.
  - Anuradha M.
  - Kirubakaran M.K.
  citation_count: '1'
  description: With the improvement of Internet of Things (IoT) and edge computing,
    the smart agricultural system is driven by data produced by the different sensors
    and smart computing devices in the agricultural land. A new methodological paradigm
    high-performance edge computing is incorporated with blockchain implemented precision
    agriculture system to improve the data processing operation related with resource
    management. Edge computing nodes collect and analyze the sensor data locally without
    transforming to the remote centralized cloud server, which rises data processing
    speed and reduce the network latency. The blockchain technology is incorporated
    with machine learning algorithm to maintain secured and protected distributed
    database for storing smart farm details like pH, soil moisture, temperature, crop
    management, humidity, and water irrigation level. The proposed system improves
    the productivity of food items and performance of the smart agricultural system
    by providing useful information to the farmers to make time-based decision about
    the land and increase the profit.
  doi: 10.1007/978-981-99-0769-4_35
  full_citation: '>'
  full_text: '>

    ""'
  inline_citation: '>'
  journal: Lecture Notes in Networks and Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Blockchain-Enabled Precision Agricultural System Using IoT and Edge Computing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Zhang Y.
  - Wu J.
  - Yang H.
  - Zhang C.
  - Tang Y.
  citation_count: '1'
  description: Accurately obtaining the length, quantity and distribution of fruit
    branches plays an important role in orchard irrigation management, disease control
    and improving fruits’ yield and quality. Recently, edge computing has been proposed
    for digital orchard management as it can increase computing power for computationally
    intensive applications. However, due to the diversity of fruit tree morphological
    structures and the complexity of the planting environment, the traditional method
    of obtaining fruit tree phenotypes with centralized computing on cloud servers
    faces many challenges in terms of efficiency and accuracy. In this paper, we propose
    a hierarchical growing method (HG) suitable for deployment at the edge to achieve
    semantic segmentation and instance segmentation of fruit tree point clouds at
    the organ scale. Furthermore, extract fruit trees phenotypic trait at the organ
    scale based on the result of point clouds segmentation. Numerous experiment show
    that the proposed HG method can efficiently carry on instance segmentation of
    branches and phenotypic trait extraction by the joint analysis and processing
    of point cloud data. The MAE, RMSE and IOU of the primary branches reach 0.025 m,
    0.113 and 0.720, respectively.
  doi: 10.1007/s11276-023-03385-7
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Log in Find a journal Publish
    with us Track your research Search Cart Home Wireless Networks Article A hierarchical
    growth method for extracting 3D phenotypic trait of apple tree branch in edge
    computing Published: 03 June 2023 (2023) Cite this article Download PDF Access
    provided by University of Nebraska-Lincoln Wireless Networks Aims and scope Submit
    manuscript Yifan Zhang, Jintao Wu , Hao Yang, Chengjian Zhang & Yutao Tang  267
    Accesses 1 Citation Explore all metrics Abstract Accurately obtaining the length,
    quantity and distribution of fruit branches plays an important role in orchard
    irrigation management, disease control and improving fruits’ yield and quality.
    Recently, edge computing has been proposed for digital orchard management as it
    can increase computing power for computationally intensive applications. However,
    due to the diversity of fruit tree morphological structures and the complexity
    of the planting environment, the traditional method of obtaining fruit tree phenotypes
    with centralized computing on cloud servers faces many challenges in terms of
    efficiency and accuracy. In this paper, we propose a hierarchical growing method
    (HG) suitable for deployment at the edge to achieve semantic segmentation and
    instance segmentation of fruit tree point clouds at the organ scale. Furthermore,
    extract fruit trees phenotypic trait at the organ scale based on the result of
    point clouds segmentation. Numerous experiment show that the proposed HG method
    can efficiently carry on instance segmentation of branches and phenotypic trait
    extraction by the joint analysis and processing of point cloud data. The MAE,
    RMSE and IOU of the primary branches reach 0.025 m, 0.113 and 0.720, respectively.
    Similar content being viewed by others Fruit ripeness identification using YOLOv8
    model Article Open access 31 August 2023 Automatic fruit picking technology: a
    comprehensive review of research advances Article Open access 14 February 2024
    Plant disease severity estimated visually: a century of research, best practices,
    and opportunities for improving methods and practices to maximize accuracy Article
    Open access 22 June 2021 1 Introduction In the era of the Internet of Everything,
    edge computing (EC) is often used to solve problems such as Edge User Allocation
    (EUA) and Edge Demand Response (EDR) [1, 2]. At the same time, edge computing
    is also very impressive in solving many optimization problems [3,4,5]. EC can
    boost computing power with compute-intensive applications (like augmented reality)
    [6]. Since the program offloads part of the tasks to the EC server at the edge
    of the network, the edge server is deployed very close to the user, so the network
    with EC can provide more efficient and stable services [7, 8]. In 2019, Yang et
    al. [9] solved the problem of minimizing the total power of UAVs by comprehensively
    considering factors such as power control, computing power allocation, and location
    planning in a mobile edge computing (MEC) network. In the same year, Qiu et al.
    [10] pointed out that in the field of smart health, there is an opportunity to
    use edge computing to complete the processing of massive health data and improve
    service performance. In addition, in 2021, Hu et al. [11] applied edge computing
    to the problem of Internet of Vehicles, and designed a greedy scheduling algorithm
    in the EC network to improve the utilization of vehicle resources. In addition,
    data in an edge computing environment is more secure. In recent years, some researchers
    have successfully developed methods to resist attacks and detect data anomalies
    in an edge environment [12, 13]. We found that there are currently few studies
    on 3D point cloud instance segmentation and fruit tree phenotype information extraction
    in the edge computing environment. However, the above two problems are computationally
    intensive, and most of the existing solutions face the dilemma of high complexity.
    Edge computing can improve computing speed and reduce application response delay
    and network load in solving the problem of phenotypic trait extraction based on
    point cloud data. Unfortunately, although the application of edge computing to
    digital orchards is an unprecedented innovation, the introduction of edge computing
    cannot fully meet the efficiency requirements of high-performance digital orchards.
    How to efficiently solve the problem of instance segmentation and fruit tree phenotype
    extraction based on 3D point cloud is still challenging when the computing job
    is offloaded to the edge server. Since this century, fruit tree planting is becoming
    an important part of agricultural production [14]. Our country is a big producer
    and consumer of fruit, with the planting area and output ranking first in the
    world. However the fruit quality is not the first in the world and the international
    market competitiveness is insufficient. Fruit tree branches are important organs
    of fruit trees to provide water and nutrition for leaves, flowers and fruits.
    From the perspective of a single plant, the structure of fruit tree branches affects
    the leaf area and photosynthetic efficiency of fruit trees. From the perspective
    of organ scale, the essence of fruit tree branch trait is the time-series three-dimensional
    expression of plant gene map, its regional differentiation characteristics and
    intergenerational evolution law [15]. Numerous studies have shown that plant phenotypes
    are depending on complex interactions between genotypes and environmental factors
    [16,17,18,19]. Therefore, timely and accurate acquiring phenotypic trait of fruit
    tree branches can provide important data support for the intelligent orchards
    management. Furthermore, it also plays an important role in orchard irrigation
    management, disease prevention, production increase and fruit quality improvement.
    As the basic data of fruit tree management and scientific research, the phenotypic
    parameters of fruit tree branches mainly include branch type and quantity. At
    present, the conventional methods for obtaining these phenotypic parameters are
    manual measurement and estimation methods. These methods are generally subjective,
    inefficient and destructive, and have high labor costs [20]. Plant phenotype extraction
    based on two-dimensional images usually uses aerial image technology. Due to its
    advantages of large scale and low cost, 2D imaging technology has been widely
    used in field plant phenotype shape extraction [21,22,23,24,25]. However, due
    to the many branches of fruit trees, the complex structure and serious mutual
    occlusion, the technology based on 2D images cannot completely collect point cloud
    information. With the development of 3D point cloud technology, more and more
    researchers have collected 3D point cloud data through laser LiDAR and successfully
    obtained crop phenotype information based on 3D point cloud technology [26,27,28,29,30].
    However, although the given 3D point cloud method has achieved good performance
    on small-scale plants, it is difficult to directly apply it to large-scale fruit
    trees. Existing algorithms for phenotypic extraction of large trees can only succeed
    at the individual plant scale. For example, in recent year, with the development
    of deep learning, Guo et al. [31] have completed the instance segmentation and
    phenotype extraction of large fruit trees. However, their method has a relatively
    low efficiency, and it takes 2.5–3 h to complete the phenotype information extraction
    of a single fruit tree. In contrast, the growing method based on 3D point cloud
    data, although it can only be used on small plants at present, has a much higher
    efficiency than the deep learning method. Existing region growing methods have
    successfully accomplished maize point cloud instance segmentation and phenotype
    information extraction [32]. However, the above method has the problem of error
    transmission and accumulation step by step. If it is directly applied to fruit
    trees with complex morphological structures, it will face problems such as low
    accuracy in the segmentation results of adjacent treetops, and it is difficult
    to select the starting point of branch growth. For this reason, this paper proposes
    a HG method suitable for deployment at the edge, which can well make up for the
    shortcomings of the traditional method that the error accumulates step by step
    and the accuracy of the treetop part is not high. 2 Related works Recently, edge
    computing has been widely used in fields such as Internet of Vehicles and drones
    [9, 11, 33,34,35]. In addition, edge computing has also made a lot of progress
    in smart medical and other fields [10, 36, 37]. It is noteworthy that in 2021,
    Zhou et al. [38] introduced the emerging edge cloud computing paradigm into the
    Internet of Things monitoring system to process a large amount of continuously
    generated monitoring data in an on-site manner. Inspired by the above cases, and
    since there are no successful cases of edge computing in smart orchards, we propose
    to apply edge computing to smart orchards. The traditional cloud server centralized
    computing method has the problems of heavy network load and heavy computing pressure.
    Edge computing technology can process a large amount of data on site, greatly
    improving the above problems. This section will review the work related to this
    paper from plant phenotype information extraction based on images, plant phenotype
    information extraction based on 3D point cloud and 3D point cloud instance segmentation
    method aspects. 2.1 Plant phenotype information extraction based on images In
    recent years, more and more researchers have applied image-based phenotyping techniques
    to the forestry field, which provides a favorable means for obtaining phenotypic
    trait. In 2019, Zhu et al. [24] used the support vector machine (SVM) method to
    process the image sequence based on the image sequence obtained by ground and
    aerial photography, and obtained the individual height, leaf length and maximum
    width of the plant. Since the above methods only provide phenotypic information
    at the individual plant scale. In 2021, Zhou et al. [39] presented a method for
    successfully extracting organ-scale phenotyping information in potato using consumer-grade
    cameras and an automated platform. In the same year, Mishra [40] proposed a model
    developed using point spectrometers, providing technical support for high-throughput
    digital agricultural plant phenotyping. In 2022, ElManawy et al. [41] proposed
    a easy to use platform using HSI-PP to extract and analyze useful plant phenotypic
    trait from hyperspectral images. Furthermore, Zuo et al. [21] proposed a crop
    seedling plant segmentation network, successfully completed semantic segmentation
    and phenotype extraction of outdoor seedlings. Different from the utilization
    of various platforms, Zhao et al. [22] proposed P3ES-Net, which obtains the phenotypic
    parameters of crops from plant images, so as to realize the reconstruction of
    plant 3-D models. However, due to the severe mutual occlusion between the branches
    of large fruit trees, it is difficult to accurately extract the phenotypic information
    of fruit tree branches based on the method of two-dimensional image processing.
    Therefore, directly applying traditional image processing methods to the extraction
    of phenotypic trait of large fruit trees may result in low accuracy and low efficiency.
    2.2 Plant phenotype information extraction based on 3D point cloud In order to
    solve the above problems, more and more scholars focus on LiDAR technology, which
    can effectively solve the problem of incomplete information extraction caused
    by foliage occlusion. In recent years, with the increasing demand for phenotypic
    information extraction, phenotype acquisition platform technology is also developing
    rapidly. For example, In 2019, Guo et al. [31] used Trimble TX8 to obtain 3D point
    cloud of apple tree canopy, proposed a method using density-based applied noise
    spatial clustering (DBSCAN) and layer K-means and median (L-KaM) method to successfully
    extract Leaf Spatial Location (LSL). In 2021, based on ground-based radar point
    cloud data, Wang et al. [42] proposed a new physically-based parameter \"LiDAR
    Biomass Index (LBI)\" to extract phenotypic characteristics at the individual
    plant scale. From 2021, more and more researchers pay attention to the method
    based on skeleton extraction. For example, Wu et al. [43] developed the WoodSKE
    method, successfully extracted skeletons from tree point cloud data collected
    by terrestrial laser scanners (TLS), and completed instance segmentation and phenotypic
    trait extraction. In the same year, based on the ground-based radar plant point
    cloud, Sun et al. [44] proposed a Laplacian ground contraction algorithm to extract
    the skeleton from the original point cloud, and successfully extracted the length
    of the main cotton stem. Coincidentally, Lei et al. [45] proposed a SVM method
    and a structure-based Skeleton Extraction (SE) method based on 3D point cloud
    data and successfully extracted the leaf bottom of corn plants. Angle and inclination.
    In 2022, Yuan et al. [46] developed a UAV LiDAR system and used the color iterative
    closest point (ICP) algorithm to extract phenotypic information of a peach tree.
    However, there are few existing research works that directly apply LiDAR technology
    to the extraction of phenotypic trait at the organ scale of large fruit trees.
    2.3 3D point cloud instance segmentation method The research shows that the accurate
    instance segmentation results can directly reflect the position, shape, contour
    and other information of plant organs, providing an important basis for the fine
    description of plant phenotypic morphological trait. Therefore, how to achieve
    accurate instance segmentation of fruit tree point cloud is the primary problem
    of extracting branch phenotype information. Currently, the extraction of fruit
    tree morphological structure is mainly based on two technologies: skeleton extraction
    and point cloud segmentation. The method based on skeleton extraction first extracts
    skeleton point from the original point cloud, then connects skeleton points to
    obtain the topological structure information of fruit trees, and finally extracts
    the phenotypic trait of fruit trees. For example, in [47,48,49] Authors successfully
    obtained phenotypic information of Toona sinensis and peach trees using skeleton
    extraction technology. In general, the advantage of skeleton extraction method
    is that it is not sensitive to point cloud density. However, the existing methods
    rarely carry out refined research on the extraction of organ scale parameters
    of fruit tree branches, and the extracted phenotypic information only includes
    individual plant scale information (tree height, crown width, etc.) [48, 49].
    Compared with the skeleton extraction method, the method based on point cloud
    segmentation has great potential in extracting phenotypic trait of fruit tree
    branches [50]. The method based on point cloud segmentation usually divides the
    point cloud into several subcategories, and then reconstructs the topology and
    geometry of the fruit tree. For example, k-mean clustering based algorithm and
    octree based algorithm [51, 52]. In recent years, many researchers have successfully
    obtained the phenotypic information of wheat, rice, cucumber, corn and other crops
    by using point cloud segmentation technology [53,54,55,56,57], but few studies
    focus on the quantitative extraction of phenotypic information of fruit tree branches
    [58]. Based on the above analysis, we concluded that it is more beneficial to
    use LiDAR to obtain data and extract apple tree phenotype trait through 3D point
    cloud instance segmentation than image-based methods. Unfortunately, solving the
    problem of 3D point cloud instance segmentation is still challenging in apple
    tree phenotypic trait extraction due to the large number of branches, disordered
    point cloud and huge data volume. In order to better solve the problem of apple
    tree 3D point cloud instance segmentation and obtain its phenotypic trait, the
    next section will give a detailed definition of apple tree 3D point cloud instance
    segmentation and phenotypic trait extraction. 3 Problem definition Existing methods
    have successfully proved that it is a feasible solution to solve the problem of
    phenotype information extraction (Definition 4) based on the results of 3D point
    cloud instance segmentation (Definition 2) [32, 45]. Generally speaking, the current
    mainstream 3D point cloud instance segmentation methods are almost all based on
    the results of the semantic segmentation of 3D point cloud (Definition 1). Definition
    1 Semantic segmentation of 3D point clouds. Given a point set D, find a function
    Seg to classify the point cloud D into n (n = 4) classes, as shown in Eq. 1. $$\\sum\\limits_{i}
    {\\frac{{Q_{i} \\cap Y_{i} }}{{Q_{i} \\cup Y_{i} }} = n}$$ (1) $$Q = Seg(D)$$
    (2) where Seg(.) is a semantic segmentation function that takes 3D point cloud
    data as input and outputs the semantic segmentation result of the point cloud
    (Q). Qi is a point set with semantic segmentation label i. Yi represents the Ground
    Truth semantic segmentation result of D. where InsSeg(.) is a instance segmentation
    function that takes 3D point cloud data and its semantic labels (Q) as input and
    outputs the instance segmentation result of the point cloud (I). Ij is a point
    set with instance segmentation label j. Tj represents the Ground Truth instance
    segmentation result of D. Based on the classification results of semantic segmentation
    for point clouds, instance segmentation clusters each type of point. Definition
    2 Instance segmentation of 3D point clouds. Given a point set D, after the semantic
    segmentation is completed (divided D into n categories), find a function InsSeg
    to cluster each class into mi instances, as shown in Eq. 3. According to the above
    definitions, this paper makes the following additional definitions for the apple
    tree branches under study: $$\\sum\\limits_{i} {\\sum\\limits_{j} {\\frac{{I_{j}
    \\cap T_{j} }}{{I_{j} \\cup T_{j} }}} } = \\sum\\limits_{i} {m_{i} }$$ (3) $$I
    = InsSeg(Q)$$ (4) Definition 3 The levels of branches. The thickest trunk in the
    center of the fruit tree is called the main trunk(MT), the branches branched from
    MT are called first-level branches (1st-B), and the branches branched from the
    1st-B are called second-level branches (2nd-B), and so on. In this paper, the
    MT is called the upper-level branch of 1st-B, 1st-B is the upper-level branch
    of 2nd-B, and so on. Correspondingly, 1st-B is the next-level branch of MT, 2nd-B
    is the next-level branch of 1st-B, and so on. Definition 4 Apple tree phenotype
    trait extraction. Given a point set D, find a method to complete the clustering
    of fruit tree branches and extract their phenotypic information including length,
    angle, etc. 3D point cloud instance segmentation method selection is still a challenging
    research issue in phenotype trait extraction of fruit tree branches from the following
    three aspects. (1) Large amount of branches. Unlike small crops such as corn which
    have no more than 10 instances, fruit trees have more than 300 branches at all
    levels. In other words, a single fruit tree contains more than 300 instance. (2)
    Unordered. Different from pixel arrays in images, 3D point cloud is a point set
    without specific order. (3) Large quantity of data. The 3D point cloud data scale
    is large, including nearly 100,000 points. Many existing methods suffer from low
    efficiency. This study aims to use the HG method to extract fruit tree phenotypic
    traits from LiDAR-based 3D point cloud data of fruit trees. Since the HG method
    has better time complexity than the existing methods, it can effectively overcome
    the problem of large quantity of data and large amount of branches. In addition,
    because the HG method is completely insensitive to the order of point data, it
    can well solve the problem of point cloud data disorder. The specific method will
    be introduced in the next section. 4 Hierarchical growth method The flow chart
    of the HG method proposed in this paper is shown in Fig. 1. The hierarchical growth
    method includes four core steps: the acquisition of seed points, the calculation
    of growth vectors, the update operation, and the selection of starting points.
    HG method has to solve three major problem: where to begin, how to grow, and when
    to stop? In Sect. 4.1, the first problem is solved by using the seed point as
    the starting point of growth. In Sect. 4.2, the second problem is solved by calculating
    the growth vector of the seed point each time. In Sect. 4.3, growth termination
    conditions will be discussed in detail to address the third question. Fig. 1 Hierarchical
    Growth method Full size image 4.1 Acquisition of seed points In 2018, Jin et al.
    [32] proposed the normalized median vector growth(MVNG) method, which successfully
    extracted phenotypic trait at the organ scale of maize. Its method is divided
    into two core steps: selecting seed points and calculating growth vectors. In
    the corn experiment, due to the simple geometric structure of corn, both stem
    growth and leaf growth can directly use the unclassified point with the lowest
    Z coordinate as the seed point. However, fruit trees have complex geometric structures
    and many branches. If the above method is still used, lots of downward or horizontal
    branches will be misclassified. Therefore, MVNG cannot be applied to fruit tree
    datasets. To solve the above problems, the acquisition of seed points will be
    discussed in detail as a core step. In order to correctly and efficiently select
    seed points from the complex fruit tree point cloud and use them in the subsequent
    growth algorithm (Sect. 4.2), we proposes a method based on the neighborhood coverage
    of skeleton points to select the starting point set U (will be described in Sect.
    4.4 in detail). The selection of seed points can be divided into the following
    two cases: Case 1: For the trunk, fruit trees in nature generally present the
    trait of the lowest root height. According to the statistics of the data set in
    this study, the average height of fruit trees is 3–4 m and the average root length
    is 0.2 m. Therefore, this method considers all points in the point cloud whose
    Z coordinate is less than 0.2 m as root. Calculate the average value of the X
    and Y coordinates of all points at the root (denoted as Px, Py) and use the point
    (Px, Py, 0) as the starting point of the trunk growth of the fruit tree. Case
    2: For branches at all levels, randomly select a node that has not been marked
    with an instance label from the set of starting points selected by the upper branch
    as the seed point of the new branch. A seed point can be obtained according to
    the above method, which will be used as the starting point of growth in Sect.
    4.2. 4.2 Calculation of growth vector In the last section, the seed point has
    been successfully obtained as the starting point for the growth of a single branch.
    This subsection will introduce how to extract neighborhood information based on
    seed points and calculate growth vectors. Inspired by the traditional growth method,
    this paper calculates the initial growth vector based on the point cloud density
    information in the R-neighborhood. However, large quantity of experiments show
    that if the initial growth vector is only affected by local information, it is
    very sensitive to fruit tree bifurcation. Facing the multi-fork structure of fruit
    tree branches, it is necessary to find an algorithm that is not sensitive to forks.
    Therefore, this method uses the previous growth vector to modify the initial growth
    vector to reduce the sensitivity of the initial growth vector to fruit tree bifurcation.
    Specific steps are as follows: Step 1: Calculation of the initial growth vector.
    Firstly, the R-neighborhood of the seed point is calculated (Eq. 5) in order to
    extract the density information of the local point cloud and calculate the growth
    vector based on this result. Second, all points in the R-neighborhood are marked
    with instance labels and semantic labels. Furthermore, the vectors from the seed
    point to all points in the neighborhood are calculated. Then, these vectors are
    normalized. Finally, the median vector is calculated as the initial growth vector
    (Eq. 6). $$R_{(s)} = \\{ \\left\\| {(s,q)} \\right\\|_{2} < R,q \\subset D\\}$$
    (5) $$\\vec{m} = {\\text{median}}\\left\\{ {\\frac{{\\vec{P}_{i} }}{{\\left\\|
    {\\vec{P}_{i} } \\right\\|_{2} }},\\vec{P}_{i} \\in D_{P} } \\right\\}$$ (6) where
    D represents the point set of the original point cloud. q represents a point in
    the point cloud. s is a seed point. Dp represents the set of all vectors in the
    R-neighborhood of the seed point.\\(\\vec{P}_{i}\\) is a vector in the R-neighborhood.
    median represents the median of a vector. Liu et al. and Hui et al. [59, 60] have
    proved that calculating the median vector of vectors in the R-neighborhood (Fig.
    2a) is less sensitive to noise in the R-neighborhood and has better robustness
    than the average vector (Fig. 2b). So, this method computes the median vector
    instead of the average vector. On the other hand, due to the multi-branch structure
    of fruit trees, the growth algorithm should be insensitive to forks in order to
    maintain the growth direction. Therefore, the influence of the previous growth
    vector is introduced to correct the initial growth vector (Fig. 3). Fig. 2 Comparison
    of two methods for calculating growth vector Full size image Fig. 3 Modified growth
    vector Full size image Step 2: Calculation of growth vector (Fig. 3). First normalize
    the initial growth vector and the previous growth vector respectively and then
    add them together to obtain a vector (Eq. 7). Then normalize and multiply by the
    size of the current neighborhood to get the weighted growth vector (Eq. 8). $$\\vec{s}
    = \\frac{{\\vec{m}}}{{\\left\\| {\\vec{m}} \\right\\|}} + \\frac{{\\vec{m}_{last}
    }}{{\\left\\| {\\vec{m}_{last} } \\right\\|}}$$ (7) $$\\overrightarrow {{s^{\\prime}}}
    = \\frac{{\\vec{s}}}{{\\left\\| {\\vec{s}} \\right\\|}} \\cdot R$$ (8) where ||•||
    represents the vector module length. \\(\\vec{m}\\) represents initial growth
    vector. \\(\\vec{m}_{last}\\) represents the previous growth vector. \\(\\overrightarrow
    {{s^{\\prime}}}\\) represents growth vector. Note that the growth vector calculated
    in this section is based on a seed point to find the bridge to the next seed point.
    Combining Sect. 4.2 and 4.3 will iteratively complete the growth of a single fruit
    tree branch. 4.3 Update operation Considering that the point cloud of fruit trees
    is discrete data, it shows the trait of few and sparse points at the ends of branches.
    Therefore, it can be judged whether the current branch has grown completely according
    to the degree of sparseness of the neighbor points. However, the fruit tree point
    cloud, which has a small amount of noise points, is not ideal data. To prevent
    the program from misjudging two irrelevant branches as the same branch due to
    noise, HG method takes the number of points in the neighborhood less than the
    threshold as one of the conditions for the end of branch growth. In this study,
    the threshold is set to an empirical value 3 based on lots of experimental verification
    results. On the other hand, considering that most fruit tree branches are long
    and straight, the two adjacent growth vectors (Fig. 4) with an angle greater than
    30° are divided into different branches. Fig. 4 Included angle of growth vector
    Full size image To sum up, Eq. 10 is finally used as the condition for the end
    of the current branch growth. First, add the previous seed point to the growth
    vector obtained in Sect. 4.2 to get a new seed point. Then add the seed point
    to the skeleton point set. Finally, if Eq. 10 is satisfied, the program will go
    to the selection of the starting point. Otherwise, the program will go to the
    calculation of the growth vector. $$\\theta = {\\text{arc}}\\left( {\\frac{{\\vec{m}
    \\cdot \\vec{m}_{last} }}{{\\left\\| {\\vec{m}} \\right\\| \\cdot \\left\\| {\\vec{m}_{last}
    } \\right\\|}}} \\right)$$ (9) $$\\left| {R_{(s)} } \\right| \\le 3 \\vee \\theta
    \\ge \\frac{\\pi }{6}$$ (10) where \\(\\vec{m}\\) represents initial growth vector.
    \\(\\vec{m}_{last}\\) represents the previous growth vector. arc represents arccosine
    function. \\(\\theta\\) is the angle between two growth vectors. ||•|| represents
    the vector module length. |•| indicates the number of points in the set. R(s)
    represents the R-neighborhood of point s. 4.4 Selection of starting point In Sects.
    4.2 and 4.3, the growth method of a single branch has been described in detail.
    To achieve the growth of a single plant, Sect. 4.4 will elaborate on the selection
    of the starting point in detail. Due to the complex geometric structure of fruit
    trees and the large number of branches, the difficulty of semantic segmentation
    and instance segmentation at the single-plant scale of fruit trees is how to obtain
    the starting points of branches at all levels (including primary, secondary, and
    tertiary). The traditional scheme of selecting the lowest point of the Z coordinate
    after removing the classified points is no longer applicable to the selection
    of the second and third branches. Therefore, this paper proposes a method based
    on skeleton point neighborhood coverage. In this method, after the growth of each
    level of branches is completed, the neighborhood union is calculated based on
    all the skeleton points of the level of branches, and the points covered by it
    are recorded as the starting point set for the selection of the next level of
    branches. The detailed steps are as follows: first add 1 to numk, then sequentially
    obtain the neighborhood of each skeleton point with a radius of w (Fig. 5), and
    record the points contained in the neighborhood as a new starting point set U
    (Eq. 11). $$U = \\{ q|\\min (\\left\\| {t,q} \\right\\|_{2} ) < w,t \\subset T,q
    \\subset R_{(s)} \\}$$ (11) where T is a collection of skeleton points. ||•||2
    stands for L2 distance. Fig. 5 Calculate starting point set Full size image 4.5
    Post processing Sections 4.1–4.4 complete the preliminary instance segmentation
    and instance segmentation of the fruit tree point cloud. However, lots of experiments
    have shown that when data sets containing many thick branches, the above segmentation
    will produce few over-segmented instances and unclassified nodes. Thus, post-processing
    is dedicated to correcting the above errors, and then obtaining more accurate
    point cloud segmentation results. Post-processing mainly includes the following
    two steps: deleting over-classified instances and reclassifying unclassified nodes.
    Delete over-classified instances: In fact, the branches of fruit trees have the
    trait of longer (thick) trunks and shorter (thinner) ones step by step. The above
    characteristics are reflected in the LiDAR scanning process, which shows that
    the longer (thicker) branches have more nodes. However, in the results of preliminary
    segmentation, instances with too few points do not meet the above properties.
    Thus, all points in the instance whose number of points is less than the threshold
    of the corresponding level branch are deleted from the semantic label, instance
    label, skeleton label and wait for reclassification. Reclassify unclassified nodes:
    Extensive experiments have shown that due to the limitations of the growing method,
    in preliminary point cloud segmentation, the lenticels on the branches are often
    missed. In semantic segmentation and instance segmentation, the smaller the L2
    distance between two points, the more likely they have the same semantic (instance)
    label. Therefore, to correctly classify unclassified points into their proper
    instances, the nearest neighbor strategy is used to reclassify them. Specifically,
    first calculate the L2 distance from each unclassified point to all skeleton points.
    Then, label each unclassified point with the same strength label and semantic
    label as its nearest skeleton point. The computational complexity of HG method
    depends on the calculation of growth vectors and the extraction of branch length
    information parts. In the first part, the computation is mainly controlled by
    the number of points and the number of seed points, so the computational complexity
    of the first part is O(np) (n is the total number of points in the point cloud
    and p is the number of seed points). Since p = nm−1, where m is the number of
    points in the neighborhood (a large number of experiments show that m is 100 on
    average). In general, the complexity is O(n2m−1). The second part has a computational
    complexity of O(n2). Many experiments have shown that The HG method can complete
    the instance segmentation and phenotypic trait extraction of 100,000-level point
    clouds in a few seconds. All in all, the total complexity of HG method is O(n2).
    Thus, the HG method is actually very fast. 4.6 Extraction of phenotype information
    Sections 4.1–4.5 use the HG method to complete the semantic segmentation and instance
    segmentation of fruit tree point clouds. This section will extract the phenotype
    trait of fruit tree branches based on the instance segmentation results. To extract
    the branch quantity information of fruit trees and carry out quantitative analysis,
    this paper agrees: (1) There is a one-to-one correspondence between fruit tree
    branches and instances. (2) Semantic segmentation results correspond to the classification
    of fruit tree branches. Therefore, to extract the branch quantity information,
    it is only necessary to classify and count the number of instances of different
    semantic labels for each fruit tree (Eq. 12). $$num_{k} = \\left| {P_{{Y_{i} =
    k}} } \\right|$$ (12) where \\(k \\in\\){0, 1, 2, 3}. numk represent quantity
    of k-th branch. Particularly, i = 0 means MT(or main trunk). P represents the
    collection of all instances in the instance segmentation result. \\(Y_{i}\\) stands
    for semantic label. |•| indicates the number of points in the set. Based on the
    result of instance segmentation, in addition to obtaining information about the
    number of fruit tree branches, the length of each branch can also be obtained.
    Considering that in most cases, the branches of fruit trees can be approximated
    as slender cylinders, the length of the branches can be approximated as the height
    of the cylinder (as shown in Fig. 6). According to the above properties, in order
    to simplify the calculation, the length of the fruit tree branch is defined as
    the L2 distance between the two furthest points in the point cloud corresponding
    to the branch. The length of each branch can be obtained by enumerating all point
    pairs in the point set corresponding to each instance to calculate the L2 distance
    and taking the maximum value. 5 Experimental evaluation 5.1 Experiment setup Our
    experimental data were collected from the apple base in Shandong China. In this
    experiment, three orchards with a planting distance of about 4 m were selected
    as research samples. On the one hand, collecting data with a backpack radar when
    the leaves are not falling will result in a lot of leaf noise in the point cloud.
    On the other hand, to exclude the influence of weather factors, this paper chose
    a windless and sunny day in December to use the backpack radar to collect data
    on the fruit trees in the dormant period. Fig. 6 Extract phenotype information
    Full size image In this experiment, eight fruit trees were randomly selected from
    the orchard to use the backpack radar DG50 (STD 16E) for data collection. Due
    to some accuracy limitations of backpack radar (Table 1), the 3D point cloud data
    in this paper only contains coordinate information, while ignoring other information
    such as gloss, brightness, density, etc. Based on the apple tree canopy data collected
    by the backpack laser scanner, we use the KD-trees-ICP algorithm to obtain high-precision
    3D point cloud data of the apple tree canopy. Table 1 Detailed parameters of LiDAR
    Full size table As shown in Fig. 7, in order to facilitate the evaluation of the
    experimental effect, in this experiment, each point of each tree is manually labeled
    with semantic labels and instance labels (Ground Truth). Fig. 7 Semantic segmentation
    and instance segmentation results of manual annotation Full size image We compare
    the performance of the HG method with the MVNG method in 3D instance segmentation
    [32]. The results of this approach were generated with the code they posted. For
    a fair comparison, we implemented fruit tree instance segmentation and phenotypic
    trait extraction using the MVNG method under the same environment. Meanwhile,
    we compare the results obtained with the HG method with those of the MVNG. For
    rigor, we evaluate these methods with the same metrics. For the orchard dataset,
    we compare their performance on semantic segmentation, instance segmentation,
    and phenotypic trait extraction. 5.2 Metrics To evaluate the performance of the
    method proposed in this experiment in instance segmentation and phenotypic trait
    extraction (number and length of branches). This experiment calculates a series
    of metrics based on the point cloud dataset. IoU, Precision and Recall are used
    as indicators to evaluate semantic segmentation, and their definitions are as
    follows: $$Precision = \\frac{TP}{{TP + FP}}$$ (13) $$Recall = \\frac{TP}{{TP
    + FN}}$$ (14) $$IoU = \\frac{{\\left| {P_{b} \\bigcap {G_{b} } } \\right|}}{{\\left|
    {P_{b} \\bigcup {G_{b} } } \\right|}}$$ (15) where Pb and Gb is predicted value
    and Ground Truth of semantic segmentation respectively. IoU is used to determine
    the true positive and false positive in a group of predictions. When and only
    when IoU > 0.6, branches of fruit trees are considered to be detected (i.e. true
    positive). To avoid repeated detection, each predicted value and Ground Truth
    are used only once. If the predicted value and the Ground Truth meet IoU > 0.6,
    the next predicted value will not be evaluated using the Ground Truth. For the
    predicted value, if there is no true value meeting IoU > 0.6, the predicted value
    is considered as a false judgment. All predicted values were evaluated and classified
    as true positive and false positive, and the remaining annotated values were considered
    false negative. The total number of true positive, false positive and false negative
    branches represents TP, FP and FN respectively. In addition to Precision and Recall
    indicators, mCov and mwCov are also used as evaluation indicators for instance
    segmentation. Defined as follows: $$mCov(G,P) = \\frac{1}{\\left| G \\right|}\\sum\\limits_{g
    \\in G} {\\mathop {\\max }\\limits_{p \\in P} IoU(g,p)}$$ (16) $$w_{g} = \\frac{\\left|
    g \\right|}{{\\sum\\nolimits_{{g^{\\prime} \\in G}} {\\left| {g^{\\prime}} \\right|}
    }}$$ (17) $$mCov(G,P) = \\frac{1}{\\left| G \\right|}\\sum\\limits_{g \\in G}
    {\\mathop {w_{g} \\max }\\limits_{p \\in P} IoU(g,p)}$$ (18) where |•| stands
    for the number of elements in the set. G is the set of Ground Truth. g is a instance
    in G. P is the set of predicted values. p is a instance in P. The MAE, RMSE and
    R2 were used to evaluate the phenotypic characteristics (branch length and number)
    of fruit trees. Defined as follows: $$RMSE = \\sqrt {\\frac{1}{m}\\sum\\limits_{i
    = 1}^{m} {(y_{i} - \\hat{y}_{i} )^{2} } }$$ (19) $$MAE = \\frac{1}{m}\\sum\\limits_{i
    = 1}^{m} {\\left| {y_{i} - \\hat{y}_{i} } \\right|}$$ (20) $$R^{2} = 1 - \\frac{{\\sum\\limits_{i}
    {(\\hat{y}_{i} - y_{i} )^{2} } }}{{\\sum\\limits_{i} {(\\overline{y}_{i} - y_{i}
    )^{2} } }}$$ (21) where \\(y_{i}\\) is Ground Truth. \\(\\hat{y}_{i}\\) is predicted
    value. \\(\\overline{y}_{i}\\) is mean value of sample. m stands for the number
    of samples. 5.3 Evaluations on w Compared with traditional MVNG methods, a big
    innovation of this paper is the new starting point selection method (SPNC). The
    core parameter of this method is the neighborhood size w of the skeleton point,
    so this section discusses the selection of w. The SPNC method is based on deleting
    the classificlassified points and finding some points closest to the classified
    points as the starting point set. If w is too small, the w-neighborhood of the
    skeleton point cannot completely cover all the surfaces of the superior branch
    and some starting points will be missed. However, if w is too large, it will affect
    the calculation of the growth vector of the next branch. $$Y = f(Y_{0} ,Y_{1}
    ,Y_{2} ,Y_{3} )$$ (22) $$T = f(T_{0} ,T_{1} ,T_{2} ,T_{3} )$$ (23) $$f(a,b,c,d)
    = 4a + 3b + 2c + d$$ (24) where Yi means the semantic segmentation result(IoU)
    of i-th branches. Ti means the instance segmentation result(mCov) of i-th branches.
    Particularly, i = 0 means MT (or main trunk). To quantitatively evaluate the impact
    of w on the results of semantic segmentation and instance segmentation, this paper
    uses T and Y as metrics (Eqs. 22–23). For the convenience of comparison, T weighted
    and summed the results of branch instance segmentation at all levels. It is worth
    noting that in order to emphasize the accuracy of the trunk and first-level branches,
    the weights are tilted towards it. As shown in Fig. 8 and Table 2, when w is 0.02,
    T takes the largest value, and Y also takes the third largest value. Therefore,
    unless otherwise stated, the parameter w in all subsequent experiments in this
    paper is set to 0.02. Fig. 8 Comparison chart of different w Full size image Table
    2 Overall metrics of different w Full size table 5.4 Semantic segmentation results
    Semantic segmentation results, as the only criterion for defining the branch level
    in this experiment, have a great impact on the credibility of the experimental
    evaluation. The semantic segmentation results are shown in Table 3. Among them,
    the IoU of MT, 1st-B, 2nd-B and 3rd-B reached 95.5%, 72.0%, 54.7%, and 50.3%,
    respectively. Compared with 94.5%, 23.2%, 17.1%, and 7.7% in the comparative experiment,
    it has more than three times the improvement on the first, second, and third-level
    branches. Table 3 Semantic segmentation results Full size table Figure 9 shows
    the confusion matrix for semantic segmentation. In this experiment, a confusion
    matrix with 4 rows and 4 columns is used to correspond to MT, 1st-B, 2nd-B and
    3rd-B respectively. These accuracy indicators reflect the accuracy of semantic
    segmentation from different aspects. Fig. 9 Semantic segmentation confusion matrix
    Full size image The experimental results show that the main diagonal is the highest
    and decreases towards both ends, which is in line with the expectation of the
    algorithm results. Compared with the comparison experiment, this method has significantly
    improved the accuracy of the 1st-B and 2nd-B (from 0.310 and 0.348–0.731 and 0.522).
    Comparing the semantic segmentation results of the two methods shown in Fig. 10
    (The color in Fig. 10 only represents the classification, and the color itself
    has no special meaning), it can be seen that in the comparison experiment, only
    a small part close to the trunk is successfully classified, while most of the
    branches are misclassified. The hierarchical growth method effectively completes
    the semantic segmentation, and the shape of the branches conforms to people''s
    objective cognition of fruit tree branches. Fig. 10 Visual comparison chart of
    semantic segmentation results Full size image 5.5 Instance segmentation results
    Table 4 presents the respective instance segmentation results of the two methods.
    Among them, the accuracy of the first-level branch of the hierarchical growth
    method has been greatly improved compared with the traditional method (mCov increased
    from 24.5 to 76.2%, and mwCov increased from 21.1 to 73.8%). On the other hand,
    the mCov and mwCov of the second and third branches were successfully increased
    from less than 10% to more than 30%. Table 4 Instance segmentation results Full
    size table A single fruit tree in the fruit tree data set used in this experiment
    contains about 100,000 points. A single fruit tree can be divided into 300 instances
    on average, including 1 trunk, about 10 primary branches, and hundreds of secondary
    and tertiary branches. To clearly and intuitively demonstrate the effect of instance
    segmentation, Fig. 11 zooms in on three parts (spheres with a radius of 0.14 m),
    including branches, crowns, and treetops. Combining the quantitative data in Table
    4 and the visualization results in Fig. 11, the instance segmentation based on
    the hierarchical growth method has good robustness in the trunk and first-level
    branches. Fig. 11 Example results of instance segmentation Full size image 5.6
    Phenotypic trait extraction results The basis of quantitative analysis of fruit
    tree branches is to determine the number of fruit tree branches and the grade
    of each branch. Table 5 shows the metrics of MT, 1st-B, 2nd-B and 3rd-B. It is
    worth noting that the R2 of MT, 1st-B and 2nd-B reached 1.000, 0.946, and 0.924,
    respectively. Since the extraction of the number of trunks is 100% accurate, the
    specific situation will not be shown. The specific branch quantity information
    of 1st-B, 2nd-B and 3rd-B is shown in Fig. 12, where the horizontal axis is the
    Ground Truth marked manually, and the vertical axis is the predicted value extracted
    by the HG method. Table 5 Accuracy of branch number extraction Full size table
    Fig. 12 Extraction results of branch quantity information of fruit trees Full
    size image The evaluation of branch length of fruit trees is divided into two
    parts: the evaluation of branches at all levels at the individual plant scale
    and the evaluation of branches at all levels at the orchard scale. Since the length
    prediction value of branches with too low IoU is obviously an error, only branches
    with IoU above 0.6 are shown in this experiment. The evaluation of the branch
    length of a single fruit tree is shown in Fig. 13, and the length extraction of
    the primary branch (Fig. 13a) R2 reached 0.99. The R2 of secondary and tertiary
    branches (Fig. 13b, c) reached 0.66 and 0.65 respectively. It is worth noting
    that the length prediction of most branches satisfies the linear relationship
    very well, and only one noise point appears Seriously affected R2. Fig. 13 Extraction
    results of branch length information of single tree Full size image The evaluation
    of the length information extraction of all fruit trees is shown in Table 6. The
    trunk and primary branches reached 0.797 and 0.821. The MAE reached 0.145 and
    0.025, and the RMSE reached 0.234 and 0.113. It is worth noting that there is
    a small amount of noise in Fig. 14c, d, making the R2 of the secondary and tertiary
    branches relatively low. Table 6 Accuracy of branch length extraction Full size
    table Fig. 14 Extraction results of branch length information of all trees Full
    size image 6 Conclusions In this paper, edge computing is applied to digital orchard
    management, and a hierarchical growth method suitable for deployment at the edge
    is proposed, which realizes the 3D point cloud instance segmentation and phenotypic
    trait extraction of fruit trees concisely and efficiently. Experiments show that
    HG method can achieve excellent performance in various fruit tree 3D point cloud
    instance segmentation scenes, which is helpful for tasks such as 3D semantic segmentation,
    instance segmentation, and phenotypic trait extraction. In future research we
    will focus on how to solve the problem of layer-by-layer error transmission faced
    by the growing method in the field of fruit trees. References Cui, G., He, Q.,
    Xia, X., et al. (2021). Demand response in NOMA-based mobile edge computing: A
    two-phase game-theoretical approach. IEEE Transactions on Mobile Computing, 22(3),
    1449–1463. Google Scholar   Cui, G., He, Q., Xia, X., et al. (2021). OL-EUA: Online
    user allocation for NOMA-based mobile edge computing. IEEE Transactions on Mobile
    Computing, 22(4), 2295–2306. https://doi.org/10.1109/TMC.2021.3112941 Article   Google
    Scholar   Zhou, X., Yang, X., Ma, J., et al. (2021). Energy-efficient smart routing
    based on link correlation mining for wireless edge computing in iot. IEEE Internet
    of Things Journal, 9(16), 14988–14997. Article   Google Scholar   Li, Y., Liao,
    C., Wang, Y., et al. (2015). Energy-efficient optimal relay selection in cooperative
    cellular networks based on double auction. IEEE Transactions on Wireless Communications,
    14(8), 4093–4104. Article   Google Scholar   Li, Y., Liu, J., Cao, B., et al.
    (2018). Joint optimization of radio and virtual machine resources with uncertain
    user demands in mobile cloud computing. IEEE Transactions on Multimedia, 20(9),
    2427–2438. Article   Google Scholar   Mao, Y. Y., You, C. S., Zhang, J., et al.
    (2017). A survey on mobile edge computing: the communication perspective. IEEE
    Communications Surveys & Tutorials, 19(4), 2322–2358. Article   Google Scholar   Al-Shuwaili,
    A., & Simeone, O. (2017). Energy-efficient resource allocation for mobile edge
    computing-based augmented reality applications. IEEE Wireless Communications Letters,
    6(3), 398–401. Article   Google Scholar   Tian, H., Xu, X., Lin, T., et al. (2022).
    DIMA: Distributed cooperative microservice caching for internet of things in edge
    computing by deep reinforcement learning. World Wide Web, 25(5), 1769–1792. Article   Google
    Scholar   Yang, Z. H., Pan, C. H., Wang, K. Z., et al. (2019). Energy efficient
    resource allocation in UAV-Enabled mobile edge computing networks. IEEE Transactions
    on Wireless Communications, 18(9), 4576–4589. Article   Google Scholar   Qiu,
    Y., Wang, C., Qi, K., et al. (2020). A survey of smart health: System design from
    the cloud to the edge. Journal of Computer Research and Development, 57(1), 53–73.
    Google Scholar   Hu, S. H., Li, G. H., & Shi, W. S. (2021). LARS: A latency-aware
    and real-time scheduling framework for edge-enabled internet of vehicles. IEEE
    Transactions on Services Computing, 16(1), 398–411. https://doi.org/10.1109/TSC.2021.3106260
    Article   Google Scholar   Yang, Y., Yang, X., Heidari, M., et al. (2022). ASTREAM:
    Data-stream-driven scalable anomaly detection with accuracy guarantee in IIoT
    environment. IEEE Transactions on Network Science and Engineering. https://doi.org/10.1109/TNSE.2022.3157730
    Article   Google Scholar   Zhou, X., Liang, W., Li, W., et al. (2021). Hierarchical
    adversarial attacks against graph neural network based IoT network intrusion detection
    system. IEEE Internet of Things Journal, 9(12), 9310–9319. https://doi.org/10.1109/JIOT.2021.3130434
    Article   Google Scholar   Wu, S., Wen, W. L., Wang, C. Y., et al. (2021). Research
    progress of digital fruit trees and its technology system. Transactions of the
    Chinese Society of Agricultural Engineering, 37(9), 350–360. Google Scholar   Hickey,
    L. T., Hafeez, A. N., Robinson, H., et al. (2019). Breeding crops to feed 10 billion.
    Nature Biotechnology, 37, 744–754. Article   Google Scholar   Sarić, R., Nguyen,
    V. D., Burge, T., et al. (2022). Applications of hyperspectral imaging in plant
    phenotyping. Trends in Plant Science, 27(3), 301–315. Article   Google Scholar   Moreau,
    C., Warren, F. J., Rayner, T., et al. (2022). An allelic series of starch-branching
    enzyme mutants in pea (Pisum sativum L.) reveals complex relationships with seed
    starch phenotypes. Carbohydrate Polymers on ScienceDirct, 288, 119386. Article   Google
    Scholar   Johannsen, W. (2014). The genotype conception of heredity. International
    Journal of Epidemiology, 43(4), 989–1000. Article   Google Scholar   Rossi, R.,
    Costafreda-Aumedes, S., Leolini, L., et al. (2022). Implementation of an algorithm
    for automated phenotyping through plant 3D-modeling: A practical application on
    the early detection of water stress. Computers and Electronics in Agriculture
    on Science, 197, 106937. Article   Google Scholar   Zhao, C. J. (2019). Big data
    of plant phenomics and its research progress. Journal of Agricultrual Big Data,
    1(2), 5–18. Google Scholar   Zuo, X., Lin, H., Wang, D., et al. (2022). A method
    of crop seedling plant segmentation on edge information fusion model. IEEE Transactions
    on Geoscience and Remote Sensing, 10, 95281–95293. Google Scholar   Zhao, G. P.,
    Cai, W. T., Wang, Z. W., et al. (2022). Phenotypic parameters estimation of plants
    using deep learning-based 3-D reconstruction from single RGB image. IEEE Geoscience
    and Remote Sensing Letters, 19, 1–5. Google Scholar   Mishra, P., & Nordon, A.
    (2020). Close-range hyperspectral imaging of whole plants for digital phenotyping:
    Recent applications and illumination correction approaches. Computers and Electronics
    in Agriculture on ScienceDirct, 178, 105780. Article   Google Scholar   Xhu, B.
    L., Liu, F. S., & Che, Y. P., et al (2018). Three-dimensional quantification of
    intercropping crops in field by ground and aerial photography. In 2018 6th International
    Symposium on Plant Growth Modeling, Simulation, Visualization and Applications
    (PMA), 8–12. https://doi.org/10.1109/PMA.2018.8611616. Rehman, T. U., & Jin, J.
    (2022). Deep adversarial domain adaptation for hyperspectral calibration model
    transfer among plant phenotyping systems. Biosystems Engineering on ScienceDirct,
    224, 246–258. Article   Google Scholar   Du, R. M., Cen, H. Y., et al. (2023).
    PST: Plant segmentation transformer for 3D point clouds of rapeseed plants at
    the podding stage. ISPRS Journal of Photogrammetry and Remote Sensing on ScienceDirct,
    195, 380–392. Article   Google Scholar   Wang, L. H., Zheng, L. H., & Wang, M.
    J. (2022). 3D point cloud instance segmentation of lettuce based on PartNet. In:
    Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    1647–1655. Li, D. W., Jin, S. C., Li, J. S., et al. (2022). PlantNet: A dual-function
    point cloud segmentation network for multiple plant species. ISPRS Journal of
    Photogrammetry and Remote Sensing on ScienceDirct, 184, 243–263. Article   Google
    Scholar   Pan, R. Y., & Huang, C. M. (2021). Accuracy improvement of deep learning
    3D point cloud instance segmentation. In: IEEE International Conference on Consumer
    Electronics-Taiwan. https://doi.org/10.1109/ICCE-TW52618.2021.9603064. Wang, P.
    Z., & Yao, W. (2022). A new weakly supervised approach for ALS point cloud semantic
    segmentation. ISPRS Journal of Photogrammetry and Remote Sensing on ScienceDirct,
    188, 237–254. Article   Google Scholar   Guo, C. L., & Feng, J. (2019). Apple
    tree canopy leaf spatial location automated extraction based on point clou6d data.
    Computers and Electronics in Agriculture on ScienceDirct, 166, 104975. Article   Google
    Scholar   Jin, S., Su, Y. J., Wu, F. F., et al. (2019). Stem-leaf segmentation
    and phenotypic trait extraction of individual maize using terrestrial LiDAR data.
    IEEE Transactions on Geoscience and Remote Sensing, 57(3), 1336–1346. Article   Google
    Scholar   Xu, X., Liu, Z., Bilal, M., et al. (2022). Computation Offloading and
    service caching for intelligent transportation systems with digital twin. IEEE
    Transactions on Intelligent Transportation Systems, 23(11), 20757–20772. Article   Google
    Scholar   Xu, X., Shen, B., Ding, S., et al. (2022). Service offloading with deep
    Q-network for digital twinning empowered internet of vehicles in edge computing.
    IEEE Transactions on Industrial Informatics, 18(2), 1414–1423. Article   Google
    Scholar   Xu, X. Q., Zhang, P., et al. (2022). Game theory for distributed IoV
    task offloading with fuzzy neural network in edge computing. IEEE Transactions
    on Fuzzy Systems, 30(11), 4593–4604. Article   Google Scholar   Kong, L., Wang,
    L., Gong, W., et al. (2021). LSH-aware multitype health data prediction with privacy
    preservation in edge environment. World Wide Web, 25, 1793–1808. https://doi.org/10.1007/s11280-021-00941-z
    Article   Google Scholar   Zhou, X., Li, Y., & Liang, W. (2020). CNN-RNN based
    intelligent recommendation for online medical pre-diagnosis support. IEEE/ACM
    Transactions on Computational Biology and Bioinformatics, 18(3), 912–921. Article   Google
    Scholar   Zhou, X., Xu, X., Liang, W., et al. (2021). Deep-learning-enhanced multitarget
    detection for end-edge-cloud surveillance in smart IoT. IEEE Internet of Things
    Journal, 8(16), 12588–12596. Article   Google Scholar   Zhou, S. Q., Nguyen, H.
    T., et al. (2021). Development of an automated plant phenotyping system for evaluation
    of salt tolerance in soybean. Computers and Electronics in Agriculture on ScienceDirct,
    182(3), 106001. Article   Google Scholar   Mishra, P. (2021). Chemometric approaches
    for calibrating high-throughput spectral imaging setups to support digital plant
    phenotyping by calibrating and transferring spectral models from a point spectrometer.
    Analytica Chimica Acta, 1187, 339154. Article   Google Scholar   Ahmed, I. E.,
    Dawei, S., Alwaseela, A., et al. (2022). HSI-PP: A flexible open-source software
    for hyperspectral imaging-based plant phenotyping. Computers and Electronics in
    Agriculture on ScienceDirct, 200, 107248. Article   Google Scholar   Wang, Q.,
    Pang, Y., Chen, D., et al. (2021). Lidar biomass index: A novel solution for tree-level
    biomass estimation using 3D crown information. Forest Ecology and Management,
    499(2), 119542. Article   Google Scholar   Wu, B. X., Yu, D. S., et al. (2021).
    Assessing inclination angles of tree branches from terrestrial laser scan data
    using a skeleton extraction method. International Journal of Applied Earth Observation
    and Geoinformation, 104, 102589. Article   Google Scholar   Sun, S. P., Li, C.
    Y., Chee, P. W., et al. (2021). High resolution 3D terrestrial LiDAR for cotton
    plant main stalk and node detection. Computers and Electronics in Agriculture
    on ScienceDirct, 187, 106276. Article   Google Scholar   Lei, L., Li, Z. H., Wu,
    J. T., et al. (2022). Extraction of maize leaf base and inclination angles using
    terrestrial laser scanning (TLS) data. IEEE Transactions on Geoscience and Remote
    Sensing, 60, 1–17. Google Scholar   Yuan, W. N., Daeun, C., & Dimitrios, B. (2022).
    GNSS-IMU-assisted colored ICP for UAV-LiDAR point cloud registration of peach
    trees. Computers and Electronics in Agriculture on ScienceDirct, 197, 106966.
    Article   Google Scholar   Xiang, L., Bao, Y., Tang, L., et al. (2019). Automated
    morphol ogical traits extraction for sorghum plants via 3D point cloud data analysis.
    Computers and Electronics in Agriculture on ScienceDirct, 162, 951–961. Article   Google
    Scholar   Li, R., Bu, G., & Wang, P. (2017). An automatic tree skeleton extracting
    method based on point cloud of terrestrial laser scanner. International Journal
    of Optics, 2017, 5408503. https://doi.org/10.1155/2017/5408503 Article   Google
    Scholar   Verroust, A., & Lazarus, F. (1999). Extracting skeletal curves from
    3D scattered data. In Proceedings Shape Modeling International ''99. International
    Conference on Shape Modeling and Applications, 194–201. Ye, N., Leeuwen, L. V.,
    & Nyktas, P. (2019). Analysing the potential of UAV point cloud as input in quantitative
    structure modelling for assessment of woody biomass of single trees—ScienceDirect.
    International Journal of Applied Earth Observation and Geoinformation, 81, 47–57.
    Article   Google Scholar   Bucksch, A., Lindenbergh, R., & Menenti, M. (2010).
    Robust skeleton extraction from imperfect point clouds. The Visual Computer, 26(10),
    1283–1300. Article   Google Scholar   Hackenberg, J., Spiecker, H., Calders, K.,
    et al. (2015). simpletree-an efficient open source tool to build tree models from
    TLS clouds. Forests, 6(11), 4245–4294. https://doi.org/10.1007/s00371-010-0520-4
    Article   Google Scholar   Li, Y. L., Wen, W. L., Miao, T., et al. (2022). Automatic
    organ-level point cloud segmentation of maize shoots by integrating high-throughput
    data acquisition and deep learning. Computers and Electronics in Agriculture on
    ScienceDirct, 193, 106702. Article   Google Scholar   Boogaard, F. P., Henten,
    E. J. V., Kootstra, G., et al. (2021). Boosting plant-part segmentation of cucumber
    plants by enriching incomplete 3D point clouds with spectral data. Biosystems
    Engineering on ScienceDirct, 211, 167–182. Article   Google Scholar   Zhou, J.,
    Fu, X. Q., Zhou, S. Q., et al. (2019). Automated segmentation of soybean plants
    from 3D point cloud using machine learning. Computers and Electronics in Agriculture
    on ScienceDirct, 162, 143–153. Article   Google Scholar   Elnashef, B., Filin,
    S., & Lati, R. N. (2019). Tensor-based classification and segmentation of three-dimensional
    point clouds for organ-level plant phenotyping and growth analysis. Computers
    and Electronics in Agriculture on ScienceDirct, 156, 51–61. Article   Google Scholar   Ghahremani,
    M., Williams, K., Corke, F., et al. (2021). Direct and accurate feature extraction
    from 3D point clouds of plants using RANSAC. Computers and Electronics in Agriculture
    on ScienceDirct, 187, 106240. Article   Google Scholar   Kaasalainen, M., Akerblom,
    M., Kaasalainen, S., et al. (2013). Fast automatic precision tree models from
    terrestrial laser scanner data. Remote Sensing, 5(2), 491–520. Article   Google
    Scholar   Huang, H., Wu, S. H., Cohen-Or, D., et al. (2013). L1-medial skeleton
    of point cloud. ACM Transactions on Graphics, 32(4), 1–8. MATH   Google Scholar   Liu,
    Y. K. (2013). Noise reduction by vector median filtering. Geophysics: Journal
    of the Society of Exploration Geophysicists, 78(3), 79–87. Download references
    Acknowledgements This research was supported by the National Natural Science Foundation
    of China (No. 92267104), the Natural Science Foundation of Jiangsu Province of
    China (No. BK20211284), and the Financial and Science Technology Plan Project
    of Xinjiang Production and Construction Corps (No. 2020DB005). Author information
    Authors and Affiliations School of Software, Nanjing University of Information
    Science & Technology, Nanjing, Jiangsu, China Yifan Zhang & Jintao Wu National
    Engineering and Technology Center for Information Agriculture, Beijing, China
    Jintao Wu, Hao Yang & Chengjian Zhang The York School, Toronto, Canada Yutao Tang
    Corresponding author Correspondence to Jintao Wu. Additional information Publisher''s
    Note Springer Nature remains neutral with regard to jurisdictional claims in published
    maps and institutional affiliations. Rights and permissions Springer Nature or
    its licensor (e.g. a society or other partner) holds exclusive rights to this
    article under a publishing agreement with the author(s) or other rightsholder(s);
    author self-archiving of the accepted manuscript version of this article is solely
    governed by the terms of such publishing agreement and applicable law. Reprints
    and permissions About this article Cite this article Zhang, Y., Wu, J., Yang,
    H. et al. A hierarchical growth method for extracting 3D phenotypic trait of apple
    tree branch in edge computing. Wireless Netw (2023). https://doi.org/10.1007/s11276-023-03385-7
    Download citation Accepted 11 May 2023 Published 03 June 2023 DOI https://doi.org/10.1007/s11276-023-03385-7
    Share this article Anyone you share the following link with will be able to read
    this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing
    initiative Keywords Edge computing Backpack LiDAR Instance segmentation Phenotypic
    trait extraction Hierarchical growth method Use our pre-submission checklist Avoid
    common mistakes on your manuscript. Sections Figures References Abstract Introduction
    Related works Problem definition Hierarchical growth method Experimental evaluation
    Conclusions References Acknowledgements Author information Additional information
    Rights and permissions About this article Advertisement Discover content Journals
    A-Z Books A-Z Publish with us Publish your research Open access publishing Products
    and services Our products Librarians Societies Partners and advertisers Our imprints
    Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage
    cookies Your US state privacy rights Accessibility statement Terms and conditions
    Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA)
    (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Wireless Networks
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A hierarchical growth method for extracting 3D phenotypic trait of apple
    tree branch in edge computing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Majumdar P.
  - Mitra S.
  - Bhattacharya D.
  citation_count: '1'
  description: Massive technological advancements in the IoT is contributing a lot
    to make our day-to-day life smarter but this also leads to e-waste production,
    energy use, and toxic emissions. The Green IoT (GIoT) is gradually reducing the
    detrimental effects of IoT. The significance for IoT-based smart and efficient
    agricultural methods is increasing very rapidly for getting a maximum good quality
    harvest by controlling irrigation based on automated environment parameter prediction
    and the enhancement of IoT to GIoT aims at reducing carbon footprints and promotes
    usage of energy-efficient methods. The edge-cloud platform and machine learning
    (ML) algorithms in a smart irrigation and monitoring system provide real-time
    insights into the crops of the farmers. Edge computing process data at the edge
    of network to conserve bandwidth and also helps to reduce the processing load
    over the cloud. A ML process makes an intelligent prediction by correlating the
    sensor originated raw data with weather predictions which enables a farmer to
    make an informed decision for the actuation of irrigation pumps. This study aims
    to describe the recent advancements in energy-saving practice and strategy for
    achieving a strong vision of GIoT-enabled smart farming coupled with ML provided
    prediction intelligence. A GIoT prototype is formulated using ML to determine
    the outline of irrigation conditional to non-linear weather changes. The core
    aspect of this review article consists of surveys and discussions of the vital
    topics in GIoT-based smart farming and their enabler technologies. .
  doi: 10.1002/9781119792642.ch29
  full_citation: '>'
  full_text: '>

    "UNCL: University Of Nebraska - Linc Acquisitions Accounting Search within Login
    / Register Handbook of Intelligent Computing and Optimization for Sustainable
    Development Chapter 29 Full Access Green IoT for Smart Agricultural Monitoring:
    Prediction Intelligence With Machine Learning Algorithms, Analysis of Prototype,
    and Review of Emerging Technologies Parijata Majumdar,  Sanjoy Mitra,  Diptendu
    Bhattacharya Book Editor(s):Mukhdeep Singh Manshahia,  Valeriy Kharchenko,  Elias
    Munapo,  J. Joshua Thomas,  Pandian Vasant First published: 11 February 2022 https://doi.org/10.1002/9781119792642.ch29Citations:
    1 PDF TOOLS SHARE Summary Massive technological advancements in the IoT is contributing
    a lot to make our day-to-day life smarter but this also leads to e-waste production,
    energy use, and toxic emissions. The Green IoT (GIoT) is gradually reducing the
    detrimental effects of IoT. The significance for IoT-based smart and efficient
    agricultural methods is increasing very rapidly for getting a maximum good quality
    harvest by controlling irrigation based on automated environment parameter prediction
    and the enhancement of IoT to GIoT aims at reducing carbon footprints and promotes
    usage of energyefficient methods. The edge-cloud platform and machine learning
    (ML) algorithms in a smart irrigation and monitoring system provide real-time
    insights into the crops of the farmers. Edge computing process data at the edge
    of network to conserve bandwidth and also helps to reduce the processing load
    over the cloud. A ML process makes an intelligent prediction by correlating the
    sensor originated raw data with weather predictions which enables a farmer to
    make an informed decision for the actuation of irrigation pumps. This study aims
    to describe the recent advancements in energy-saving practice and strategy for
    achieving a strong vision of GIoT–enabled smart farming coupled with ML provided
    prediction intelligence. A GIoT prototype is formulated using ML to determine
    the outline of irrigation conditional to non-linear weather changes. The core
    aspect of this review article consists of surveys and discussions of the vital
    topics in GIoT–based smart farming and their enabler technologies. References
    Citing Literature Handbook of Intelligent Computing and Optimization for Sustainable
    Development References Related Information Recommended IoT/cloud‐enabled smart
    services: A review on QoS requirements in fog environment and a proposed approach
    based on priority classification technique Amel Ksentini,  Maha Jebalia,  Sami
    Tabbane International Journal of Communication Systems Cloud IoT Ruchi Bhatnagar,  Rawat
    Prof (Dr.) Paramjeet,  Garg Dr. Amit Emerging Computing Paradigms: Principles,
    Advances and Applications, [1] Metropolitan intelligent surveillance systems for
    urban areas by harnessing IoT and edge computing paradigms Rustem Dautov,  Salvatore
    Distefano,  Dario Bruneo,  Francesco Longo,  Giovanni Merlino,  Antonio Puliafito,  Rajkumar
    Buyya Software: Practice and Experience LoRa based intelligent soil and weather
    condition monitoring with internet of things for precision agriculture in smart
    cities Dushyant Kumar Singh,  Rajeev Sobti,  Anuj Jain,  Praveen Kumar Malik,  Dac-Nhuong
    Le IET Communications Green IoT and Machine Learning for Agricultural Applications
    Keshavi Nalla,  Seshu Vardhan Pothabathula Green Internet of Things and Machine
    Learning: Towards a Smart Sustainable World, [1] Additional links ABOUT WILEY
    ONLINE LIBRARY Privacy Policy Terms of Use About Cookies Manage Cookies Accessibility
    Wiley Research DE&I Statement and Publishing Policies Developing World Access
    HELP & SUPPORT Contact Us Training and Support DMCA & Reporting Piracy OPPORTUNITIES
    Subscription Agents Advertisers & Corporate Partners CONNECT WITH WILEY The Wiley
    Network Wiley Press Room Copyright © 1999-2024 John Wiley & Sons, Inc or related
    companies. All rights reserved, including rights for text and data mining and
    training of artificial technologies or similar technologies."'
  inline_citation: '>'
  journal: Handbook of Intelligent Computing and Optimization for Sustainable Development
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Green IoT for smart agricultural monitoring: Prediction intelligence with
    machine learning algorithms, analysis of prototype, and review of emerging technologies'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Rahmouni M.
  - Hanifi M.
  - Savaglio C.
  - Fortino G.
  - Ghogho M.
  citation_count: '3'
  description: The rapid development of AI and IoT recently resulted in the Artificial
    Intelligence of Things (AIoT), whose applications in many areas are already boosting
    enormous business potential. In particular, AIoT promises a disruptive impact
    in the agriculture domain, promoting efficiency and autonomy through the synergistic
    exploitation of modern technologies such as smart sensors, image processing, Cloud
    computing, data analytics, network communication, etc. In this paper, we present
    our AIoT framework, showcasing how AIoT could impact modern agriculture by implementing
    data-driven solutions based on low-cost devices and open source technologies,
    empowered by Edge Intelligence. AIoT will help not only in increasing the quantity
    and quality of food production, but also in enhancing the efficiency of agricultural
    operations.
  doi: 10.1109/DASC/PiCom/CBDCom/Cy55231.2022.9927989
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2022 IEEE Intl Conf on Depend... An AIoT
    Framework for Precision Agriculture Publisher: IEEE Cite This PDF Mouad Rahmouni;
    Majdoulayne Hanifi; Claudio Savaglio; Giancarlo Fortino; Mounir Ghogho All Authors
    2 Cites in Papers 216 Full Text Views Abstract Document Sections I. Introduction
    II. Background and related work III. The AIoT Framework for Precision Agriculture
    IV. Conclusions and future development Authors Figures References Citations Keywords
    Metrics Abstract: The rapid development of AI and IoT recently resulted in the
    Artificial Intelligence of Things (AIoT), whose applications in many areas are
    already boosting enormous business potential. In particular, AIoT promises a disruptive
    impact in the agriculture domain, promoting efficiency and autonomy through the
    synergistic exploitation of modern technologies such as smart sensors, image processing,
    Cloud computing, data analytics, network communication, etc. In this paper, we
    present our AIoT framework, showcasing how AIoT could impact modern agriculture
    by implementing data-driven solutions based on low-cost devices and open source
    technologies, empowered by Edge Intelligence. AIoT will help not only in increasing
    the quantity and quality of food production, but also in enhancing the efficiency
    of agricultural operations. Published in: 2022 IEEE Intl Conf on Dependable, Autonomic
    and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl
    Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology
    Congress (DASC/PiCom/CBDCom/CyberSciTech) Date of Conference: 12-15 September
    2022 Date Added to IEEE Xplore: 13 December 2022 ISBN Information: DOI: 10.1109/DASC/PiCom/CBDCom/Cy55231.2022.9927989
    Publisher: IEEE Conference Location: Falerna, Italy SECTION I. Introduction Food
    security is considered one of the most important threats we are facing in the
    21st century: almost 690 million people (8.9% of the global population) were undernourished
    by the end of 2019 (and this number will exceed 840M by 2030 [1]) while a gradual
    reduction in the area of cultivated lands has been also recorded [2], [3]. In
    addition, the increased transboundary pests and diseases, the decreasing soil
    quality and productivity, not to mention the climate change effects and unpredictable
    weather conditions [4], make the global scenario even more complicated. As already
    done in other sectors, such as healthcare and Industry 4.0, modern technologies
    and digitization can contribute to Precision Agriculture (PA) [5]. It considers
    a data-driven form of farming, mainly pivoted around analytics to inform and support
    decision-making in farming systems [6] [7]: this allows applying advanced agronomic
    knowledge based on infield measurement and observations (e.g. temperature, humidity,
    soil moisture, leaf wetness etc.) for eventually improving food system outcomes
    such as crop yields, profits, environ-mental sustainability, and food security.
    PA leverages low-cost IoT systems (comprising sensing units, controllers, networking
    modules, and power management systems [8]) which are versatile enough for implementing
    different AI-based solutions according to the field size. In such a way, also
    smallholders can manage and operate production systems more simply than big landowners,
    since large fields demand for advanced automation and mechanization technologies,
    decision-making processes and large-scale information systems [9]. Several works
    recently focused on the enhancement of corps productivity and optimization of
    food production systems, ensuring optimal conditions to enhance crops growth is
    the cornerstone for reaching such target. The factors they have considered are
    multiple, for example, hydric stress [10], soil compactness [11], soil salination
    [12], lack of nutriment elements. However, they share relevant limitations about
    scalability, versatility and usability. On these considerations, in this paper
    we propose the development of an AIoT-based framework for PA aimed to fully support
    both the irrigation management and water needs assessment. To this end, the system
    gets key real-time data from multiple sources (about soil, environment, micro-
    and macro-weather, etc.) and analyzes them with AI capabilities for time-series
    prediction on the Edge-level, by exclusively leveraging on low-cost, Edge-devices
    (ST-microelectronics and Raspberry single board computer) orchestrated by widely
    adopted open-source protocols and frameworks (e.g. Mbed OS, Raspberry Pi Debian
    OS, Node-Red, MQTT). Overall, we showcase, at a small scale, the advantage of
    such IoT devices’ integration into agriculture, and the advantages of AI at the
    Edge, making it accessible for both smallholders and developing countries or large-scale
    deployments. By extension, the same AIoT framework can be exploited for various
    agriculture-related domains such as Controlled Environment Agriculture (CEA),
    where the process of growing takes place in a closed ecosystem while controlling
    a variety of variables [13], as well as opening the doors for further optimizations
    of its sub-components. The rest of the paper is organized as follows. Section
    II provides an overview of the background and related works. Section III presents
    the prototype architecture, design and functionalities of the AIoT framework.
    Final remarks and future work conclude the paper in Section IV. SECTION II. Background
    and related work The shift toward digitization and the larger introduction of
    ICT (Information and Communications Technology) [14] has recently involved also
    the agriculture domain, by promising many advantages to farmers and final customers
    such as product traceability, production efficiency improvement, and lower hard-labor
    tasks [15]. In particular, PA takes advantage of technologies that have been not
    yet fully exploited so far, such as aerial imagery [16], agricultural robotics
    [2], satellite imagery and massive wireless sensor networks (WSN) deployment [17].
    The in-field data offered by the PA enable growth condition monitoring and data-driven
    decision-making in order to maximize yield: such practices, which until recently
    have been associated mainly with farming practices in high-income countries [18],
    can now be within reach also of developing countries thanks to the spread of low-cost
    IoT technologies [19]. In particular IoT-based PA solutions are increasingly becoming
    integral components of systems for identifying, monitoring, decision making, and
    early warnings of globally important crop pests and diseases, which are relevant
    factors impacting crop productivity. A. Existing precision agriculture frameworks
    In the last few years, a growing interest related to IoT solutions for PA [20]
    has been recorded, mainly targeted at automatic irrigation systems [21], [22],
    [23]. More oriented to Edge Intelligence, Udutalapally et al. developed sCrop
    [24], a PA Framework exploiting a Convolutional Neural Network (CNN) computer
    vision model for disease detection, while Talluri et al. [25] presented a smart
    system able to ensure and remotely control the watering and fertilization operations.
    A Cloud-based robotic solution, Agrobot [26], was developed for the sowing of
    the seed, by automatically adjusting according to remote sensing data (the soil
    reflectance, temperature and, humidity, etc.) The shared limitation among all
    these works is their narrowed scalability and their poor generality, added to
    the lack of standardized data formatting, which is crucial for data transfer among
    sub-systems: indeed, these monolith PA systems raise several challenges as scalability,
    testing and rebuild the deployment, especially at scale. Furthermore, they are
    focused on a particular use case, usually within the bounds of a single plant
    type or a narrowly defined farming sector. As a result, the scope of these frameworks
    is constrained: they do not provide transferable functionality and, given the
    complexity of deployed AI models, they cannot operate without the connectivity
    to the Cloud. Therefore, in this context, our proposal seeks to address such limitations
    considering, by design, issues such as interoperability (for handling, for example,
    different data sources), distributed computing and flexibility (i.e., our distributed
    application approach is organized as a collection of micro-services independently
    designed, implemented, and executed). More details are reported in the following
    Section. SECTION III. The AIoT Framework for Precision Agriculture We consider
    an AIoT Framework for PA integrating (i) an in-field sensor network for precise
    micro-weather monitoring and (ii) weather stations for macro-climate monitoring.
    Fused at the Edge level and then integrated with external sources (i.e., historical
    time-series from the Cloud), those data ensure a wider view of growth conditions
    and provide the farmer with an advanced Irrigation Decision Support System (DSS).
    This section presents the proposed AIoT framework: first main framework goals
    are reported in Section III-A; then, the overall architecture is introduced in
    Section III-B and the outlined micro-services in Section III-C. Some implementation
    details for the realization of our AIoT framework are reported in Section III-D
    and, finally, hints about AI integration find place in Section III-E. A. Main
    framework goals Typical PA frameworks aim at supporting farmers in key operations
    such as efficient irrigation, soil continuous monitoring, etc., often targeting
    near no-downtime, integration of heterogeneous sensors types (ranging from soil
    moisture to complex sensors such as leaf wetness), security and scalability [19]).
    In addition, our AIoT framework aims at the following goals: Low energy consumption.
    Given the limited access to energy sources in an agricultural context, where devices
    are operating in remote locations, we made the design choice of employing ultra-low-leakage
    technology by exploiting Micro-controller Units (MCU) and Low-Power Wide-Area
    Network (LPWAN) technologies [27]. Edge integration and low network usage. Data
    processing in external Cloud is kept limited as much as possible: thanks to emerging
    technologies such as TinyML [28], the whole processing (including complex calculation
    involved in AI algorithms) is ensured at Edge level and, as a consequence, the
    Cloud cost and the bandwidth utilization are both drastically reduced. Granular
    deployment and Micro-services oriented architecture. Software components of the
    server-side are decomposed into smaller units: such granular architecture [29]
    offers many advantages in comparison with a monolithic application (e.g., isolation
    ensures that new features deployment or changes impact only the concerned service)
    and each software component could scale separately, depending on the application
    need. B. IoT Architecture The design of the system follows the commonly adopted
    IoT architecture [30], which is composed of 4 stages and 3 domain layers, as illustrated
    in Fig. 1: Fig. 1. IoT Architecture and Domain layers Show All IoT Sensing Domain:
    it comprises IoT Devices, namely Sensing Nodes provided with sensing and basic
    processing capability, and IoT Network components, e.g., the IoT Gateway, shared
    with the upper layer, which ensure data exchange and support connectivity, e.g.,
    in the case of drones. IoT Fog Domain: it includes the Weather Station and components
    shared between the IoT Sensing Domain and the IoT Cloud Domain. The former is
    the IoT Gateway, provided with networking and medium computational capabilities;
    in the case of dense or large deployment, we can consider multiple cooperating
    IoT Gateway devices, which are connected with each other. The latter are IoT Services
    Platform, namely building block components able to implement multi-protocol messaging
    systems for the sake of interoperability and to support the management (lifecycle,
    operation status, etc.) of the framework devices. IoT Cloud Domain: it is the
    upper layer of the IoT Domain and it is composed of multiple servers hosting the
    IoT Applications. These applications leverage the IoT Services Platform and are
    responsible for heavy computational tasks, data dashboarding, and third-party
    access management through APIs, thus enabling a seamless communication and data
    exchange over the framework elements. C. Micro-Services architecture In order
    to deploy the presented architecture, the AIoT Framework contains several micro-services,
    deployed at multiple levels as shown in Fig. 2. At the IoT Cloud Domain level,
    we deploy end-user inter-active end-points such as Irrigation DSS services, persistent
    data-storage services, user interface, and security services. The latter manages
    the encryption paradigms and secure communication with third-party systems. Additional
    heavy-weight and time-insensitive services, for example related to computer vision
    (crop diseases detection, selective herbicide applications, etc.), can find place
    also at this level. At the IoT Fog/Edge Domain, we deploy services aimed at data
    exchange with the Cloud and at Sensing Nodes monitoring, from both hardware (battery
    life monitoring, devices location, and alert management, actuators supervision,
    etc.) and software (AI Algorithms performance monitoring, clustering analysis,
    networking and re-connection management, etc.) points of view. Finally, at the
    IoT Sensing Domain, a set of thin services for efficient deployment (starting
    with data-aggregation, adaptive sampling to limit the used bandwidth, data filtering,
    and time series prediction) is locally provided. In such a way, without resorting
    to the remote Cloud, sensors are able to face failure, outliers, data noise, missing
    data, etc. D. Implementation details The proposed AIoT framework is designed to
    be implemented through low-cost hardware, as shown in Fig. 4. The sensing node
    reported in Fig. 3 is composed of a board based on Arm® Cortex® -M4 core-based
    STM32L4 MCU: B-L475E-IOT01A Discovery kit, three soil moisture probes (capacitive
    Soil moisture sensor v1.2) and a temperature sensor, a 1-Wire interface Temperature
    sensor manufactured by Dallas Semiconductor Corp, with a protective casing enabling
    its usage on the soil. For this work, we focused on the following board’s components:
    Core processing unit: an ultra-low-power processor, with 1 Mbyte of Flash memory
    and 128 Kbytes of Static random-access memory (SRAM). Ambient temperature and
    humidity sensor: capacitive digital sensor for relative humidity and temperature
    (HTS221). Air pressure sensor: absolute digital output barometer (LPS22HB). Communication
    Interface: data are sent to the IoT Gate-way using the Bluetooth® V4.1 module
    (SPBTLE-RF), which offers a very low power consumption compared to the previous
    generations of Bluetooth. Sensing nodes are in charge of soil moisture, temperature,
    humidity and barometric pressure measurement, and data exchange with the IoT Gateway
    through LPAWN networking technologies. For the IoT Gateway, instead, we considered
    a Raspberry Pi 3 Model B board (1Gb of RAM and 16Gb of storage) with its three
    networking modules: Bluetooth, Wi-Fi, and Ethernet. Upon this hardware and an
    MQTT Broker for the Publish/Subscribe messaging system, the IoT Gateway enables
    the data exchange between sensing nodes, the Weather Station (by means of JSON
    Objects), and the Cloud (through API over UDP/TCP IP) as well as the operation
    of the services proposed in the previous section. Once tested and validated, the
    proposed implementation of the AIoT framework is able to support further Deep
    Learning model enhancement and optimization techniques as well as it is versatile
    enough for supporting polyculture. Fig. 2. Micro-services deployment Show All
    Fig. 3. Discovery kit for IoT Sensing Node Show All E. AI Integration into AIoT
    Framework In order to complete the micro-services high level architectural design,
    established both data ingestion and storage, we outline some AI capabilities for
    our framework to be developed at both Cloud and Edge level, depending on the complexity
    of the task to be ensured. These include a deep learning set of algorithms, able
    to ensure weather irrigation scheduling or spatio-temporal sampling frequency
    adjustment, as well as data completion based on prediction techniques and additional
    technique related to the computer vision. For irrigation related tasks, Support
    Vector Machine (SVM) [31], Support Vector Regressions (SVR) [32], K Nearest Neighbor
    (KNN) [33], and Random Forest (RF) regressors are suitable candidates to be implemented
    over the AIoT Framework. Indeed, they showed significant outcomes for assessing
    the Evapotranspiration within irrigation scheduling tasks [34], for enabling the
    anticipated response to weather dynamics, and for quantitative prediction of irrigation
    needs and scheduling, yield, and soil moisture and nutriment content [35]. Besides
    processing Sensing Nodes’ time series, cameras can be also embedded within the
    AIoT framework, opening the door to computer vision techniques for image processing.
    The convolutional neural networks (CNNs) can be used to process agricultural images
    taken by cameras, installed at crop level, or from aerial footage captured using
    unmanned aerial vehicles (UAVs) and satellites. The classification function of
    plant images can be applied to detecting various plant diseases [36], cropland
    delineation [37], [38], and wilt detection caused by inadequate irrigation [39].
    SECTION IV. Conclusions and future development The limited connectivity of rural
    zones [40] [41], the cost of Cloud-based infrastructures and the need for customized
    smart solutions are three main factors limiting the development of PA. In this
    perspective, we proposed a low-cost, decentralized AIoT Framework for an agricultural
    data-based decisions support system, aimed at replacing the traditional approaches
    based on farmer common sense and inherited practices. Lever-aging on Edge computing
    principles, the proposed framework supports customizable deployment, thus potentially
    covering the full agricultural processes of heterogeneous crops; moreover, the
    use of Ultra-low consumption MCUs, with AI capability and LPWAN communication
    technologies, promises not only to reduce the overall cost considerably, but also
    to improve security, efficiency, and integration with third party services. Fig.
    4. Overall AIoT Framework Deployment Show All A prototype following the proposed
    framework is under development and will be included as part of an extended version
    of the current paper, including adaptive sampling algorithms as part of the Edge
    deployed AI and spatio-temporal prediction for watering needs estimation and scheduling.
    Future research direction will be focused on the Edge-based implementation of
    a collaborative AIoT Networks of spatio-temporal patterns analysis, based on historical
    data and completed with satellite data (Earth Observations): these techniques
    are currently implemented at the Cloud level, thus resulting unsuitable for isolated
    rural areas, where internet access is not always granted. Moreover, to connect
    the whole agricultural cycle with advanced automation and decision-making systems,
    a superior level of integration would be reached, so to open the doors for satisfactorily
    large-scale deployments. Authors Figures References Citations Keywords Metrics
    More Like This Grassland Data Analysis and Calculation Based on the Internet of
    Things and Cloud Computing 2022 Second International Conference on Artificial
    Intelligence and Smart Energy (ICAIS) Published: 2022 Internet of Things and Edge
    Cloud Computing Roadmap for Manufacturing IEEE Cloud Computing Published: 2016
    Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT
    OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: Proceedings of the 2022 IEEE International Conference on Dependable, Autonomic
    and Secure Computing, International Conference on Pervasive Intelligence and Computing,
    International Conference on Cloud and Big Data Computing, International Conference
    on Cyber Science and Technology Congress, DASC/PiCom/CBDCom/CyberSciTech 2022
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: An AIoT Framework for Precision Agriculture
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Gutierrez-Gnecchi J.A.
  - Yang W.
  - Reyes-Archundia E.
  - Tellez-Anguiano A.D.C.
  - Olivares-Rojas J.C.
  - Fregoso-Tirado L.E.
  citation_count: '0'
  description: Current trends in distributed computing facilitate data processing
    near the end user through Cloud-Fog-Edge architectures. Agricultural instrumentation
    applications can greatly benefit from edge computing signal processing, to provide
    detailed information about soil hydraulic conductivity towards improving irrigation
    planning and scheduling. A multimodal instrumentation scheme is constructed with
    a combination of field infiltrometer and wetting front detection to measure soil
    saturated hydraulic conductivity. Measurements were performed on a test lysimeter
    using sandy loam soil. The results indicate that the combined instrumentation
    can provide detailed information of the soil hydraulic conductivity which has
    important implications for irrigation scheduling.
  doi: 10.1109/INISTA55318.2022.9894139
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2022 International Conference... Edge Computing
    Multimodal Instrumentation For Measurement And Modelling of Soil Hydraulic Conductivity
    Publisher: IEEE Cite This PDF Jose Antonio Gutierrez-Gnecchi; Wuqiang Yang; Enrique
    Reyes-Archundia; Adriana Del Carmen Tellez-Anguiano; Juan Carlos Olivares-Rojas;
    Luis Enrique Fregoso-Tirado All Authors 40 Full Text Views Abstract Document Sections
    I. Introduction II. Edge Computing Instrumentation Scheme III. Experimental Setup
    IV. Results and Discussion V. Conclusion Authors Figures References Keywords Metrics
    Footnotes Abstract: Current trends in distributed computing facilitate data processing
    near the end user through Cloud-Fog-Edge architectures. Agricultural instrumentation
    applications can greatly benefit from edge computing signal processing, to provide
    detailed information about soil hydraulic conductivity towards improving irrigation
    planning and scheduling. A multimodal instrumentation scheme is constructed with
    a combination of field infiltrometer and wetting front detection to measure soil
    saturated hydraulic conductivity. Measurements were performed on a test lysimeter
    using sandy loam soil. The results indicate that the combined instrumentation
    can provide detailed information of the soil hydraulic conductivity which has
    important implications for irrigation scheduling. Published in: 2022 International
    Conference on INnovations in Intelligent SysTems and Applications (INISTA) Date
    of Conference: 08-12 August 2022 Date Added to IEEE Xplore: 23 September 2022
    ISBN Information: ISSN Information: DOI: 10.1109/INISTA55318.2022.9894139 Publisher:
    IEEE Conference Location: Biarritz, France Funding Agency: SECTION I. Introduction
    Over the last three decades, there has been increasing concern, worldwide, regarding
    sustainable development. In general, agricultural activities require the largest
    amount of water available for consumptive use. For instance, in Mexico, 76% of
    consumptive water is used in agriculture and Mexico’s National Water Commission
    (Spanish: Comision Nacional del Agua: CONAGUA) [1] estimates that more than half
    of the water used for irrigation is wasted; evapotranspiration, runoff and poor
    irrigation practices greatly cause water waste that amounts to (more than) 4 times
    the total water used for domestic purposes. Amongst the policies stated in Mexico’s
    National Water Programme 2020-2024 there is a target reduction of water stress
    level of 3.33%, equivalent to 2.38 km3/y, in order to favour sustainable development
    and improve aquifer recharge. Thus, water resources management plays an essential
    role towards planning water usage and allocation for irrigation. Planning and
    allocation of water resources require accurate knowledge of the soil hydraulic
    conductivity values. However, accurate measurement of soil water content is not
    trivial; soil hydraulic conductivity properties depend on a number of variables
    ranging from soil type, soil texture and content, up to tillage and agricultural
    management. In addition, surface or volume measurements do not provide detailed
    information about the soil hydraulic conductivity properties down to the root
    location. The authors present a multimodal approach for measuring soil hydraulic
    conductivity properties which combines to types of instruments: field infiltrometer
    and electronics wetting front detector. The field infiltrometer is used to measure
    saturated hydraulic conductivity from surface-type measurements, whereas the wetting
    front detector allows measuring changes of water content down to the root location,
    as irrigation is applied. The combination of both instruments, permits comparing
    real-time measurements from both techniques for modelling soil hydraulic conductivity
    properties. The resulting information is compiled through an edge computing instrumentation
    architecture to provide digital signal processing and modelling capabilities.
    Fig 1. Information flow diagram of the prototype Show All SECTION II. Edge Computing
    Instrumentation Scheme The increasing capabilities of IoT and signal processing
    hardware components have benefited the introduction of edge computing architectures
    for real-time, on-line data analytics near the process in study. Thus, the edge
    computing approach offers opportunities for developing highly-efficient smart
    instrumentation [2]-[3]. Pre-processed data from the edge layer may be transferred
    to a fog layer for further processing and also to provide interaction with a cloud
    platform to allow widespread access for big data analytics. In this work, the
    authors focus on the edge layer to develop a soil hydraulic conductivity measurement
    and modelling platform directed to optimize water resources management. A. Prototype
    A proof-of-concept prototype was developed to obtain soil hydraulic conductivity
    data based on two types of instruments: field infiltrometer and wetting front
    detector (Fig. 1). B. Field Infiltrometer One of the parameters used for soil
    crop characterization is saturated soil hydraulic conductivity (Kfs), as an indicator
    of the soil properties which in turn relate to water propagation and retention
    properties. Soil hydraulic conductivity depends on many factors such as soil type,
    content and usage. For instance, the small porous size of clay-type soils results
    in a low Kfs due to the small particle size, but has a large capacity for holding
    water. In contrast large particles contained in sandy soils result in a high Kfs
    but retain less water. Thus, measurement of Kfs for particular crops has important
    implications for planning irrigation scheduling. The soil Kfs can be estimated
    using a field infiltrometer, which allows applying a known volume of water, flowing
    steadily, into a borehole constrained by a known volume. The instrument consists,
    first, of a reservoir (also known as Mariotte tube) that holds the water used
    in the experiment (Fig 2.) [4]. To constrain the measurement area, a metallic
    ring is inserted in the soil. Water is transferred from the reservoir to the metallic
    ring through a pipe hose fitted with a valve to control the start of the experiment.
    Fig 2. Field Infiltrometer Show All The experiment starts by allowing water into
    the metallic ring and the water consumption is measured as the experiment progresses.
    Since the area of the Mariotte tube is fixed, the water consumption is measured
    by recording the change in water height inside the Mariotte tube. Manual recording
    of the water consumption is a time-consuming task, since field experiments may
    take, from a few minutes for sandy soils, up to hours for clay-type soils. In
    addition, it is necessary to conduct several experiments to obtain a representative
    Kfs values for particular fields. An automated field infiltrometer was constructed
    to record the experiment results and calculate the resulting Kfs. The reservoir
    is fitted with a pressure sensor located at the bottom of the reservoir to measure
    the changes in water content. The data acquisition system is based on a low-power
    microcontroller (MSP430F5529, Texas Instruments®) which records the experiment
    data and calculates the Kfs. The resulting data is transferred to the host via
    Bluetooth. C. Wetting front detector Field infiltrometers deliver estimates of
    the Kfs from surface measurements as water propagates into the soil. As irrigation
    starts, water begins to propagate down the soil depth, creating a water front
    moving downwards. Since water content changes the electrical impedance properties
    of the soil, it is possible to measure soil impedance changes to infer the water
    content [5]. In order to get more detailed information about the propagation dynamics
    along the soil depth, an electronic wetting front detection system, based on impedance
    measurements, was developed. The instrument sensing principle uses a linear array
    of 16 rectangular electrodes mounted on a 60 cm long plastic container, which
    is inserted into the soil (Fig 3). The electrodes are used to measure the soil
    impedance change as a function of the water content. Impedance measurements are
    performed between pairs of electrodes, separated 25mm, and the resulting impedance
    information is used to calculate the water content. Fig. 3. Electrode and temperature
    sensor location in the Wetting Front Detection (WFD) instrument. Show All Continuous
    data acquisition allows to calculate the water propagation time, which in turn
    can be used to model the soil hydraulic conductivity properties. Temperature sensors
    located between each electrode pair allows recording the soil temperature, which
    is used for temperature compensation of impedance data using a backpropagation
    neural network. The instrument is essentially a multichannel impedance analyser,
    based on a low-power microcontroller (MSP430F5529). The microcontroller acquires
    the impedance data, performs the temperature compensation operations and transfers
    the results to the host via Bluetooth. D. Instrument firmware Since both instruments
    are designed ad hoc the associated firmware was developed using the Code Composer
    Studio (Texas instruments) software. At present, firmware update is carried out
    using the in-system programming interface. The microcontroller processing capabilities
    allow updating the system to include further processing signal processing operations,
    as well as calibration routines. E. Data persistence Modelling soil hydraulic
    conductivity properties derived from infiltrometer and wetting front data, requires
    data persistence of measurement data as well as other information related to the
    experiments. A structured database is implemented in a Rapsberry 3 device (Raspbian
    V4) using MariaDB (based on MySQL) and Database Management is implemented using
    phpMyAdmin. The relational database consists of several tables for data storage
    including data from other sensors such as external hygrometers and weather information.
    Here the discussion focuses on 7 tables (Fig. 4) for data storage related to modelling
    soil hydraulic conductivity: experiment, date, calibration details, wetting front
    calibration, infiltrometer calibration, infiltrometer data and wetting front data.
    F. Data processing The main functions (Fig. 1) are included in two modules: Information
    management and Server. The information management module acquires sensor data
    via Bluetooth and stores the results in the database. The Server module is developed
    as MVC (Model-View-Controller) and takes charge of retrieving information from
    the database, digital processing and presents the results in a web site that can
    be accessed by the user. SECTION III. Experimental Setup The experimental setup
    consists of a lysimeter filled with sandy loam soil. Fig 4. Relational database
    Show All The infiltrometer is placed at the top of the lysimeter and the wetting
    front detector is located beneath the infiltrometer ring to detect the resulting
    wetting front (Fig. 5). SECTION IV. Results and Discussion Fig. 6 shows a comparison
    of the test results for both instruments: infiltrometer and wetting front detector.
    Fig. 5. Experimental setup. Show All Fig. 6. Summary of results. Comparison between
    A) surface (field infiltrometer) data and B) - E) wetting front detection measurements.
    Show All A. Infiltrometer data Fig. 6A shows the saturated hydraulic conductivity
    calculated from the Mariotte tube water content change, measured by the pressure
    transducer. The initial water intake is large, since the starting soil water moisture
    is ~18%. As the experiment progresses, the water content increases at the surface,
    saturating the soil at the top which gradually reduces the water consumption until
    it reaches a steady-state. The instrumentation system measures the changes in
    water column height to calculate the saturated hydraulic conductivity, which corresponds
    to performing data analytics at the edge. A linear approximation of infiltration
    data is calculated using the Wu2 method [6] where Kfs is given by: K fs = A a((
    H+ 1 α d+ r 2 )+1) =162.37( mm h ) (1) View Source where A is the slope, c is
    the intercept from the linear regression of measured data, a is a dimensionless
    constant (a = 0.9084), H is the ponded depth in the ring, d is the insertion depth
    of the ring, r is the ring radius˛α= Kfs/ϕm and ϕm is the matric flux potential.
    B. Wetting front detector (WFD) data During the initial stages of the experiment,
    the water content along the depth of the soil sample, calculated by the WFD measurement
    system, remains unchanged (Fig. 6B-Fig. 6E), because the water takes a few minutes
    to propagate down the soil sample. As water continues to be applied, a wetting
    front starts to form, and propagates downwards, until it begins to reach the electrodes’
    sensing fields. Fig. 6B shows that the wetting front reaches the first electrode
    pair at the 10-minute mark approximately, where the water content commences to
    increase. Maintaining the water flow into the ring, causes the wetting front to
    continue moving downwards until the soil between electrode pair 1-2 saturates.
    TABLE I. 2nd Order model parameters The wetting front continues to move towards
    the bottom of the container where the rest of the electrode pairs detect the progression
    of the wetting front. Data derived from the WFD instrument can be used to obtain
    a state-space model [7] for the soil hydraulic conductivity at each individual
    measurement depths: x ˙ (t)=Ax(t)+Bu(t) y(t)=Cx(t)+Du(t) x(0)= x 0 (2) View Source
    where x is the state vector, u is the input vector, y is the output vector and
    x(0) contains the initial states. The resulting second-order linear-approximation
    model for a 1-gallon of water step-input is: H 0 +( H max − H 0 )U(t− T D )(1+
    k 1 e ( −t+ T D T P1 ) + k 2 e ( −t+ T D T P2 ) ) (3) View Source where the calculated
    parameters are shown in Table 1. Fig. 7 shows a comparison of the measured water
    content change at the location of electrode pair 1-2, with the results of the
    time-domain system identification procedure. The saturated hydraulic conductivity
    can then be calculated from the model parameters. The model is a critically-damped,
    second-order function, with damping factor, ξ=1.00, and natural frequency, ωn=0.0078618.
    Fig. 7. Results of the system identification procedure for modelling in-depth
    soil hydraulic conductivity for electrode pair 1-2. Show All Thus, the estimated
    hydraulic conductivity, calculated from WFD data, Kfs_WFD, and considering that
    the wetting front has to travel 25mm to reach the electrode pair 1-2, is: K fS_WFD
    = 25 ( 5 ξ ω n ) ( mm s )=0.039031( mm s ) =141.52( mm h ) (4) View Source The
    difference could be attributed to the nature of both measurements, and also that
    the compactness of the soils increases down the soil sample. However, there is
    agreement between both measurements and are consistent for sandy loam soils. The
    linear approximation of the model falls within the capabilities of the edge computing
    device to obtain a 2-pole transfer function with delay. SECTION V. Conclusion
    The edge computing approach offers opportunities to combine the information from
    different types of measurements to yield detailed soil hydraulic conductivity
    information along the soil depth. Data from the field infiltrometer can be processed
    in real-time for fast qualification of soil properties. WFD measurements can be
    used for obtaining models of the properties using system identification procedures.
    One the advantages of using WFD measurements is that the model can be updated
    for controlling irrigation scheduling accounting for changes in the soil properties.
    The values obtained for soil saturated hydraulic conductivity are consistent with
    values reported for similar types of soils. In addition, the second-order model
    obtained can be calculated in the edge which offers unique opportunities for developing
    control strategies for time variant systems (i. e. soil) with large lag. ACKNOWLEDGMENT
    The authors acknowledge the support from the British Council- Newton Fund Impact
    Scheme No. 540323618 to carry out this work. Authors Figures References Keywords
    Metrics Footnotes More Like This Soiling measurement station to evaluate anti-soiling
    properties of PV module coatings 2016 IEEE 43rd Photovoltaic Specialists Conference
    (PVSC) Published: 2016 Enhancing Soil Measurements with a Multi-Depth Sensor for
    IoT-based Smart Irrigation 2020 IEEE International Workshop on Metrology for Agriculture
    and Forestry (MetroAgriFor) Published: 2020 Show More IEEE Personal Account CHANGE
    USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile
    Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS
    Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT
    Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use |
    Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy
    A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: 16th International Conference on INnovations in Intelligent SysTems and
    Applications, INISTA 2022
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Edge Computing Multimodal Instrumentation For Measurement And Modelling of
    Soil Hydraulic Conductivity
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Premkumar S.
  - Sigappi A.N.
  citation_count: '9'
  description: Precision agriculture is a breakthrough in digital farming technology,
    which facilitates the application of precise and exact amount of input level of
    water and fertilizer to the crop at the required time for increasing the yield.
    Since agriculture relies on direct rainfall than irrigation and the prediction
    of rainfall date is easily available from web source, the integration of rainfall
    prediction with precision agriculture helps to regulate the water consumption
    in farms. In this work, an edge computing model is developed for predicting soil
    moisture in real time and managing the water usage in accordance with rain prediction.
    A soil moisture prediction hybrid algorithm (SMPHA) has been developed that revolves
    around the decision-making techniques with live environmental parameters including
    weather parameters for the prediction of soil moisture through the impact of precipitation.
    Numerous algorithms with the combination of regression + clustering are estimated,
    and it is inferred that XGBoost + k-means outperforms other algorithmic combinations
    that is deployed in edge model. This model is used as an intermediary between
    the end IoT devices and cloud that results in the saving of computationally intensive
    processing performed on cloud servers. The servers located on a local edge network
    perform the developed algorithmic computations. Avoiding transmission over the
    cloud results in significant latency, response time, and computation power savings
    and therefore increases the efficiency of data transfer. The proposed edge computing
    model is implemented in Raspberry Pi as an edge, Heroku as cloud, and edge nodes
    as the combination of Pi with actuators and sensors. The monitored data from Pi
    are stored in MongoDB webserver that is controlled by Web dashboard. Finally,
    the developed model is implemented in cloud and edge where the edge server implementation
    performs better in terms of latency, bandwidth, throughput, response time, and
    CPU memory usage.
  doi: 10.1515/jisys-2022-0046
  full_citation: '>'
  full_text: '>

    "Skip to content Authenticated with University of Nebraska - Lincoln What does
    this mean? $ USD € EUR - Euro £ GBP - Pound $ USD - Dollar EN 0 University of
    Nebras... SUBJECTS FOR AUTHORS SERVICES PUBLICATIONS ABOUT Open Access Published
    by De Gruyter May 27, 2022 IoT-enabled edge computing model for smart irrigation
    system S. Premkumar and AN. Sigappi From the journal Journal of Intelligent Systems
    https://doi.org/10.1515/jisys-2022-0046 Cite this Share this 10 Abstract Precision
    agriculture is a breakthrough in digital farming technology, which facilitates
    the application of precise and exact amount of input level of water and fertilizer
    to the crop at the required time for increasing the yield. Since agriculture relies
    on direct rainfall than irrigation and the prediction of rainfall date is easily
    available from web source, the integration of rainfall prediction with precision
    agriculture helps to regulate the water consumption in farms. In this work, an
    edge computing model is developed for predicting soil moisture in real time and
    managing the water usage in accordance with rain prediction. A soil moisture prediction
    hybrid algorithm (SMPHA) has been developed that revolves around the decision-making
    techniques with live environmental parameters including weather parameters for
    the prediction of soil moisture through the impact of precipitation. Numerous
    algorithms with the combination of regression + clustering are estimated, and
    it is inferred that XGBoost + k-means outperforms other algorithmic combinations
    that is deployed in edge model. This model is used as an intermediary between
    the end IoT devices and cloud that results in the saving of computationally intensive
    processing performed on cloud servers. The servers located on a local edge network
    perform the developed algorithmic computations. Avoiding transmission over the
    cloud results in significant latency, response time, and computation power savings
    and therefore increases the efficiency of data transfer. The proposed edge computing
    model is implemented in Raspberry Pi as an edge, Heroku as cloud, and edge nodes
    as the combination of Pi with actuators and sensors. The monitored data from Pi
    are stored in MongoDB webserver that is controlled by Web dashboard. Finally,
    the developed model is implemented in cloud and edge where the edge server implementation
    performs better in terms of latency, bandwidth, throughput, response time, and
    CPU memory usage. Keywords: smart irrigation; edge-based irrigation; edge computing;
    precision agriculture; soil moisture prediction; irrigation management system;
    IoT; offloading mechanism 1 Introduction It is evident that agriculture always
    has a specialized role in the anthrophonic evolution and has been serving as an
    important economic factor for the growth of a country [1]. Around 58% of the population
    depend on agriculture as the chief source of livelihood in India. The quality
    and productivity of agricultural products have declined over these years as several
    factors have influenced the crop productivity both directly and indirectly. Some
    major factors that affect the crop production are climatic changes, global warming,
    and water scarcity [2]. The agricultural land’s productivity is affected by the
    direct and indirect changes in climate [3,4]. The crop growth has been already
    affected by the changes in climate incurred by global warming. The nutrition quality
    of soil, ground water level, sea, and ocean are affected by the modifications
    in average temperature, rainfall, and extreme weather conditions such as hail
    storms, dust storms, heatwaves, etc. due to global warming [5,6]. Degradation
    of soil is primarily created by various methods including 93.7% by water erosion,
    9.5% by wind erosion, 5.9% by salinity and alkalinity, etc. Further changes in
    climate would influence adversely the crop production [7]. Since water is an indispensable
    requirement for plants and cultivation, the high level of soil is eroded and thereby
    the fertility is also declined. Due to the ever-changing climate, water scarcity
    has become a huge problem. Drought-like conditions is already formed in several
    areas and thereby the present and conventional farming practices are not suitable.
    New and unique environment preserving techniques are the need of the hour [8].
    The conventional approaches in agriculture are enhanced by the advent of several
    advancements in technology [9]. These new improved methodologies ensure optimized
    utilization of resources, accurate forecast of water needs and environmental parameters,
    reduction of human intervention, etc. [10]. Consequently, the outcomes of crops
    in terms of yield and quality are higher with cost-effective methods. One such
    booming technology is the Internet of things (IoT) [11]. IoT is the collection
    of components embedded in the sensor for measuring and transferring data via network
    devices as sensed from pumps and tractors to weather stations. Primarily, IoT
    deals with the transmission and reception of data related to farms through devices
    using the Internet for prediction and providing decisions to the farmers. IoT-based
    methodologies has brought a changeover in agricultural patterns and farming approaches
    [12]. IoT devices can gather information about soil moisture, chemical properties,
    dam levels, livestock health, and weather details in real time. The information
    acquired from IoT devices facilitates the farmers in tracking farms periodically.
    Farmers can save time and money by responding faster to farm conditions. Cloud
    computing models integrated with on-field agricultural sensors need to be incorporated
    for tackling the issue of processing huge voluminous data. One of the major challenges
    of IoT is the processing of huge datasets in a sequential way. Some of the key
    factors that need to be focused on this process are as follows: information about
    the type and nature of data, the way of acquiring the data, etc. The preliminary
    stage comprises acquiring the data and ingesting the data to the system. Substantial
    cognizance of data are achieved as the data pass through all the gateways where
    it is cleansed and transformed before entering into the system. In the near future,
    dynamic prediction of soil moisture and precipitation techniques are to be developed
    for smart irrigation systems. Therefore, a system is developed for efficient and
    optimal utilization of fresh water in irrigation along with drip irrigation system.
    It aids in finding which one of the plants fails to get sufficient water. When
    the water supply is provided the next day, this delay should not disturb the system.
    It becomes important for the farmers to understand the optimal usage of water
    and fertilizers to bring out sustenance in the agricultural industry. Therefore,
    processing must be done for analyzing the data, so that patterns can be analyzed
    and planning can be done for the long term, accordingly. Hence, it gives a broad
    vision in deciding where the processing is to be done exactly. Therefore, it is
    obvious that not all data are crucial, and it provides a clear view of which data
    need to be stored, discarded, and retained for both long-term and short-term purposes.
    Thus, all these challenging issues require to be addressed and that is where storage
    technologies are actually highlighted. The poor quality of Internet access in
    developing nations makes the implementation quite challenging. An applicable solution
    to solve this problem is through edge computing where the essential data could
    be offloaded from the cloud over the edge of the cloud, and this is the exact
    point where the approach of smart sensing with edge computing gets in. With the
    purpose of broadening the potential of edge computing and using it in the agriculture
    domain, a novel approach using machine learning (ML) methods is proposed for analyzing
    the data acquired by the IoT devices deployed at the farm. Here, the data acquired
    from IoT components undergo preprocessing and ML models on the edge nodes to analyze
    and assess the appropriate results for providing the best instructions for controlling
    the actuators (e.g., light, pumps at different locations) in the farms. This article
    presents an automated system, as shown in Figure 1, to predict the soil moisture
    using the field information acquired from the self-designed sensor node deployed
    at the field and the forecast information of weather via Internet. A unique algorithm
    has been developed that revolves around the machine learning techniques for the
    prediction of soil moisture. Here, many algorithms with the combination of regression
    + clustering was estimated, and it is inferred that XGBoost + k-means outperforms
    other algorithmic combinations, and therefore, it is deployed for the prediction
    of soil moisture in the proposed work. The proposed algorithm makes effective
    irrigation decisions with optimized usage of water in a more accurate and reliable
    manner. The effective decision-making refers to the process of predicting the
    rainfall, thereby reducing the water usage in advance by the proposed algorithm
    in accordance with the predicted rainy days. Through this automatic decision-making,
    over watering is avoided by saving the soil. The server-side software is developed
    with node-side connectivity using the information for visualization and decision
    support features. This proposed algorithm is implemented in edge to prove the
    efficiency of the edge server handling the automated system better than the cloud
    control. The performance of the decentralized edge-based architecture has been
    evaluated for downloading the hybrid algorithm from cloud in real time execution.
    The performance can be enhanced by adopting edge computing architecture and measured
    with the help of network parameters like latency, bandwidth, and response time.
    Edge computing capacity is also estimated using the CPU processor and memory consumption
    while executing the proposed algorithm with irrigation scheduling. Figure 1 Architecture
    of the proposed system. 2 Related work In ref. [13], a smart irrigation system
    not affected by communication disconnection and delay is developed using edge
    nodes deployed at the farms. Environmental parameters have an intricate impact
    on the plant growth. It becomes necessary for evaluating multiple AI models simultaneously
    in an actual cultivation environment for comparing AI models under the same conditions.
    Due to the working of existing irrigation systems on the cloud, communication
    is instable in the concurrent evaluation of AI models. However, the instability
    does not induce an edge node in its performance. The factors such as type of plant,
    soil, climate, humidity, temperature, and soil moisture need to be considered
    for the irrigation system packed with potential smart decisions. The nature and
    type of plant, soil, and climate are queried by ontology (branch of metaphysics
    dealing with the nature of being), whereas other factors such as temperature,
    humidity, and soil moisture are sensed by the sensor network. The trained ML model
    predicts the watering decisions based on ontology and other factors as mentioned
    earlier. Smart irrigation has three modules: (i) sensor network modules that sense
    the parameters impacting the water requirement by using sensors DHT22, light sensor
    BH1750, and HL-69 hygrometer for sensing the temperature, soil moisture, light,
    and humidity in air. (ii) Edge and IoT server’s module to send and receive data
    through HTTP requests. (iii) Training module in which KNN is applied on the sample
    dataset for training and decision-making regarding the water needs. Based on the
    input values, the trained model categorizes the input into five possible classes:
    highly not needed, not needed, average, needed, and highly needed [14]. A decentralized
    smart irrigation approach is proposed for strawberry greenhouses in contrast to
    conventional cloud-based solutions for keeping the agricultural data at the edge
    of the network. A full-scale smart irrigation system in an actual strawberry greenhouse
    environment is developed after a small-scale smart irrigation networking prototype
    system and a reference architecture targeting edge data distribution for strawberry
    greenhouse applications are framed. A three-step industrial approach is formed
    for designing, implementing, and validating a solution for smart strawberry irrigation
    in greenhouses and keeping the corresponding data at the edge of the network at
    the same time: (i) A small-scale smart irrigation prototype solution with off-the-shelf
    hardware and software equipment is tested and evaluated on various types of plants
    for gaining useful insights for deployments on a large scale. (ii) A reference
    network architecture is designed for targeting smart irrigation and edge data
    distribution specifically for strawberry greenhouses. (iii) A large-scale system
    in an actual strawberry greenhouse environment is developed in Greece, incorporating
    the proposed reference architecture [15]. Edge computing is proposed for addressing
    the issues by taking advantage of computing resources in the edge of the network.
    The issues such as an edge mobile device make it easier to achieve low end-to-end
    latency, high bandwidth, and low jitter to services located on the edge network.
    An edge can enforce the privacy policies of its owner prior to the release of
    the data to the cloud through edge analytics. If a cloud service becomes unavailable
    due to network failure, cloud failure, or a denial-of-service attack, a fallback
    service on a nearby edge can temporarily mask the failure. Cloud services, partial
    analysis, and control functions are extended to the edge nodes from the cloud
    data center. Edge nodes facilitate the timely monitoring of sensors in smart farming
    by the reduced latency and enhanced data transmission. Due to these factors, edge
    computing is applied through farming [16,17]. A three-tier open-source software
    platform we proposed by authors, and the platform enhanced the precision agriculture
    by introducing edge computing and fog computing. An network functions virtualization
    (NFV)-based approach is deployed for performing the local operational decisions
    at the edge level for mitigating the influence of network failures while using
    cloud data centers [18]. For control processing in smart farming, a platform enabling
    cost-effective sensor/actuator network based on IoT, utilizes edge computing [19,20].
    The authors in ref. [21] predicted the soil moisture using a mathematical model
    that measures the values given by a sensor matrix on the ground. Due to the huge
    interval in measurements (10 minutes), the model presented estimated error by
    more than 10%. This methodology has incorporated the online approach by making
    the sensors to send data every minute to edge devices without time-based interruption.
    The authors of ref. [22] applied a combinative approach of using field sensor
    network’s data along with weather forecast station’s data for the management of
    optimality in water conditions for the enhanced growth of grapes. The generated
    data are forwarded to a web server, which displays graphics without statistical
    analysis of such data. The analysis must be performed a posteriori by the user.
    The watering mechanism for a plant via IoT methodology is devised by the proposed
    smart irrigation model without acquiring any pre-processed data. A prototype application
    is developed, which gets adapted to the parameters needed in irrigation after
    a couple of human-made irrigations. With the usage of various ML algorithms, several
    tests are devised for manual and automated irrigations for the performance evaluation.
    After the evaluation using four different ML algorithms such as logistic regression
    (LR), K-nearest neighbors (KNN), Gaussian naive Bayes (GNB), and gradient boosting
    regression trees (GBRT), it is found that GBRT outperforms other algorithms. To
    analyze the overall performance, a test bed for the sensor edge, mobile client,
    and the decision service on the cloud is established. Two different indoor species
    are selected as test items for the prototype, namely, Peace lily and Sardinia.
    The outcomes were quite good, and it is inferred that the prototype has learned
    the patterns of irrigation and making decisions automatically with a high rate
    of accuracy [23]. The authors from ref. [24] adopted the deep learning methodology
    for detecting the type and the category of the plant using an automated plant
    irrigation system. The water necessity of the plant is determined using the recognition
    of predefined set of plant images and data set acquired from farm. It utilizes
    the database for fetching the irrigation information after the recognition process
    is completed. Modeling the training processes are time consuming as voluminous
    set of images needs to be stored. The authors in refs [25,26] incorporated ML
    methods in the irrigation decision support model using a pre-processed irrigation
    data set. A model is developed for learning the irrigation needs of any plants
    progressively rather than using a readily available dataset. Several ML algorithms
    are evaluated with their precision for concluding the irrigation decisions. Manual
    irrigations are performed two times before making precise decisions. Due to the
    dynamicity in model, data processing is done progressively, and it can be applied
    to several plants having varying irrigation conditions. There is a need for the
    learning model that can be trained by itself using a comparatively lighter learning
    process using environmental parameters that do not need larger storage in the
    system but need higher computation. From the aforementioned survey for making
    a precise decision with instant computation locally, edge computing needs to be
    integrated into the irrigation system. This article is directed towards presenting
    a platform that implies IoTs and edge computing in monitoring soil moisture via
    sensors, data communication between sensors and edge devices, and an Analytics-as-a-Service
    cloud. It analyzes the collected data in the form of a density map of soil moisture
    for denoting the areas in need of greater or lesser frequency of irrigation. Here,
    density map does not refer to the geographical point data by satellite mapping,
    and it actually denotes the point of dry area and watery area through soil moisture
    detection point. This point is averaged among areas of irrigation to be done and
    the irrigation process is controlled with prediction of rainfall using the proposed
    system. 3 The proposed system The proposed learning model for irrigation is implemented
    in a prototype IoT system that has four components: (i) Edge node layer – This
    layer consists of sensors, actuator, and two microcontrollers. In this layer,
    edge node acquires the sensor data from the surroundings and controls the actuator
    for actuating water pumps to start irrigation. (ii) Edge server layer – This layer
    consists of Raspberry Pi that act as edge server and capable of multitask processing.
    Here, edge server controls the edge nodes for sending signal and receiving data
    at regular interval of time. It is also connected to the cloud server for receiving
    developed and trained machine learning model to be deployed and make irrigation
    decision for controlling edge nodes. (iii) Edge service layer – This layer is
    deployed in the edge server and it is responsible for controlling the whole system
    through a developed web dashboard. The dashboard has live feed data, control of
    edge nodes, and cloud services access. This service layer also has the control
    access of the proposed machine learning model. (iv) Cloud server layer – This
    layer composed of cloud services and cloud storage where its role is to train
    the machine learning model and store the data in database. It sends the trained
    proposed model to the edge server for decision-making regarding irrigation scheduling.
    The comprehensive interconnections in the system are shown in Figure 2. The proposed
    IoT-based smart irrigation system includes five major components: field deployed
    module, Web-based interface, Web API weather input, soil moisture prediction mechanism,
    and edge communication model. Figure 2 Components of the proposed system. 3.1
    Field deployed module In the field requirements, a wireless sensor network of
    the sensor nodes needs to be deployed as shown in Figure 3. Here, field data collection
    device accommodates four different sensors: Capacitive Soil Moisture Sensor V2.0,
    DS18B20 Water Proof Temperature Sensor Probe for soil temperature, ultraviolet
    (UV) Light Radiation, DHT11 – Temperature and Humidity Sensor Module, and GYML8511
    Analog Output Ultra-Violet Light Sensor Module. An Arduino Mega connected to Raspberry
    Pi 4 Model-B read, the output of these sensors where the program is developed
    in Python for the Pi model to fetch the hourly data from sensors and store the
    data in MongoDB [27] database. It is then synchronized with the server database
    using the developed web service. A Wi-Fi-enabled Arduino controls the water pump
    connected to a relay switch. Figure 3 Real-time prototype of the proposed edge
    model. For the real time monitoring, a trigger is made for controlling the web
    service from the responsive web-based interface. The irrigation decisions are
    checked periodically by the proposed model performed in the server. The water
    pump is actuated, and irrigation process is started only if the server makes any
    irrigation decision. A wireless sensor network (WSN) [28] scenario with ZigBee
    [29] technology can be implemented for a large farming area in which several sensor
    nodes can be affixed in the specified area and every sensor node possesses sensors
    similar to a standalone device. Then, the Arduino Mega reads the sensor output
    connected to ZigBee for transferring data to Gateway Node for aggregating the
    received data and storing it in MongoDB locally and also for transferring the
    data via web service to the edge server. 3.2 Web-based interface The proposed
    framework consists of a web-based application to allow farmers visualize the growing
    data and interacting with the garden in real time. In addition, users can also
    be able to examine and analyze the historical growing data, if needed, through
    functionalities such as irrigation control, motor control prediction model deployment,
    and manual data entry implemented in this web application. Here, Node.js was chosen
    for developing the web application [30,31], while MongoDB [27] was utilized as
    the database system. Data stored in the database, which is deployed in the cloud,
    will be used for further data analysis in the future. The web application’s functions
    are designed following a software design pattern called model-view-controller
    (MVC) as shown in Figure 4. In the frontend, ChartJS is used to represent data
    through dynamic charts. The web application is also used as an interface to manage
    all the physical devices/actuators in the garden. To deploy the web-server to
    the cloud, a cloud platform as a service (PaaS), namely, Heroku, had been utilized.
    Heroku is a cloud platform that provides platform as a service (PaaS), facilitates
    the creation of applications and deploying these online rapidly [32,33]. It also
    enhances scalability and functionality by integrating several add-on services.
    The field data are sent to the server by Raspberry Pi using this web service.
    This web service manages the network outage/fluctuation during data synchronization
    from the field device to the server by taking the help of flag settings at the
    database level. The interface facilitates the scheduling of irrigation along with
    visualizing real time sensors and predicted soil moisture for upcoming days and
    precipitation information. By using the denoted threshold value of soil moisture
    suggested by agronomists, the irrigation can be scheduled by the user. The system
    maintains the threshold value depending on the predicted pattern of soil moisture
    and precipitation information. The process of irrigation is initiated automatically
    and stopped after the specified threshold value generated from the proposed algorithm
    of soil moisture when it is reached. Figure 4 Web interface for the irrigation
    system. 3.3 Web API weather input The weather prediction data are collected by
    a web service developed in Python. The forecast data such as humidity, temperature,
    ultra violet index, precipitation, and cloudiness of web forecasting portals like
    Open Weather API are aggregated by the developed web service [34]. These portals
    provide the forecasted information in HTML, XML, or JSON format. The predicted
    data with JSON format are read by the developed web and stored in database at
    the edge server, which is concerned in the prediction algorithm. Also, these data
    are utilized as testing dataset in the ML model for predicting the soil moisture.
    3.4 Soil moisture prediction mechanism An algorithm for predicting the soil moisture
    based on data derived from field sensors and weather forecasting using the combination
    of supervised and unsupervised machine learning techniques has been developed
    underpinned by regression algorithms and k-means clustering for estimating the
    difference/change in soil moisture owing to weather conditions. Many regression
    algorithms are compared against each other and infusing each of them with k-means
    to check the preciseness in mean square error (MSE), R2, accuracy and mean absolute
    percentage error (MAPE) for prediction of soil moisture of upcoming days with
    the help of sensor data and weather forecasting days. The information about soil
    moisture for the upcoming days and suggestions for irrigation in accordance with
    the prescribed levels of soil moisture and predicted precipitation values, thereby
    saving energy and water, is presented by the algorithm. The information generated
    from the device and the predicted values from the algorithm soil moisture prediction
    hybrid algorithm (SMPHA) are stored in the server. 3.5 Edge communication model
    The communication protocols in the proposed framework are flexible and transparent
    in nature for accepting both wired and wireless methodologies. For the maximum
    utilization of potentiality in edge computing components, the communication among
    various components in the edge-IoT system requires intense probing by using the
    versatility among the devices in network edges. For transferring the data gathered
    from pivot sensors, a communication technology such as Zigbee [35] is needed for
    the irrigation systems. Therefore, the communication component in the proposed
    work is classified into three main areas as shown in Figure 5. The Message Query
    Telemetry Transport (MQTT) protocol is used for the communication in the proposed
    system. The analysis in ref. [36] presented seven IoT messaging protocols (MQTT,
    CoAP, XMPP, AMQP, DDS, REST-HTTP, and WebSocket) as communication protocols that
    play a major role in smart farming. The authors have concluded that MQTT proved
    to be the most secure protocol after probing all the protocols with respect to
    latency, energy and bandwidth requirements, throughput, reliability, and security.
    Moreover, MQTT is secure in both end-to-end architecture and gateway server architecture.
    In an MQTT setup, a MQTT server termed as MQTT broker executes on the IoT solution
    [37]. Under a common identifier, a “publisher” and a “subscriber” link among themselves
    to this broker. In the IoT solution, publishers and subscribers are the IoT devices
    and IoT hubs or control devices, respectively. When the publishers have new data
    for recording, the data are published to the broker. The broker then flags that
    it has new publisher data, and the corresponding data are read by the subscriber.
    Then, the subscriber analyzes the data and reacts accordingly. Figure 5 Proposed
    edge communication model. The first level accomplishes with connecting the end
    users to system with the help of mobile or web-based applications through the
    Internet. The next level (cloud computing server) deals with the connection of
    web server and MQTT broker for directing the user requests and other components
    at the edge landscape or from the farms to the right cloud-based services like
    displaying the real time status of the farm for the users, triggering a new deployment
    of the updated ML model to the corresponding edge node. The third level (farming
    area) is directed toward the deployment of sensors and IoT devices (actuators)
    for communicating with other components in the entire system. 4 Deployment of
    soil moisture prediction hybrid algorithm The watering mechanism of the plant
    has different approaches in the proposed model. Primarily, the system is trained
    with manual irrigations datasets during the process of learning with respect to
    suggestions defined by agronomists. The model is trained to learn the needs of
    irrigation in the first level of deployment in cloud without the inclusion of
    pre-processed data. After acquiring the required data and training, the proposed
    system is initiated to grasp the plant’s watering needs by undergoing plenty of
    manual irrigations. Thereafter, manual irrigation is not required and the system
    makes automated decisions in watering using the gathered data and the application
    of ML methods. The proposed model then decides the irrigation strategies automatically
    using ML methods without the need including collected datasets in the automatic
    irrigation process. The proposed model can be improved through the learning process
    when the number of precise irrigation inputs is provided to the model at each
    stage of training. The decision-making procedure is developed with two modules
    for irrigation strategies according to the soil moisture prediction for upcoming
    days. The first module deals with training the model in cloud with manual irrigation
    datasets through steps such as data collection, data preprocessing, training,
    and model development. The system acquires values of air temperature (TH), soil
    temperature (SMT), soil moisture (SM), humidity (HU), and ultraviolet rays (UV)
    periodically from the physical environment in the data collection stage, which
    is essentially required for arriving at the watering decisions. Also, the time
    of performing the manual irrigation is recorded in the database. These data are
    timestamped and stored in as datasets to aid in making decisions for knowing the
    time of irrigation. In the next step of pre-processing, inconsistencies are eliminated
    and outliers caused by sensor errors are detected from the irrigation dataset,
    thereby helping in the removal of broken data. The training stage involves the
    application of supervised machine learning (ML) algorithms. Here the regression
    algorithms such as support vector regression (SVR), multiple linear regression
    (MLR), lasso regression (LR), decision tree regressor (DTR), random forest regressor
    (RF), and XG-boost regressor (XB) techniques are used for the deployment. The
    regression algorithms are trained using the collected datasets. Finally, through
    training, regression models are created, namely, SVR model, MLR model, LR model,
    DTR model, RF model, and XB model that are been combined with the second module
    for decision-making. The second module caters to the prediction of irrigation
    for upcoming days by infusing the weather data as an input to the regression trained
    models. The live datasets from the weather API for future prediction of soil moisture
    variable are used. The dependent variables from weather forecast data like temperature
    (TH), humidity (HU), ultraviolet (UV), and precipitation (PC) are tested in the
    aforementioned model for soil moisture prediction. Then, the regression trained
    model is evaluated and deployed using the weather testing data for the prediction
    of soil moisture in accordance with the precipitation. After the prediction of
    data for the upcoming days, these developed regression models are combined with
    unsupervised ML algorithm named k-means clustering for estimating the changes
    incurred in soil moisture prediction due to the impact of weather conditions.
    Further, each regression models with k-means algorithm are evaluated for performances
    in terms of irrigation decision-making process as shown in Table 1. The combined
    algorithms are estimated through MAPE, MSE, R2, execution speed, power consumption,
    and accuracy. The estimation and computation of these parameters are detailed
    by the authors in ref. [38]. Table 1 Comparison of performance metrices obtained
    from various ML algorithms Algorithms used Accuracy R 2 MSE MAPE (%) Execution
    time Power (J) SVR + k-means 0.96 0.96 0.25 1.98 0.06078 1164.85 MLR + k-means
    0.94 0.88 0.31 2.15 0.02075 429.30 LR + k-means 0.95 0.94 0.32 2.23 0.02482 351.35
    DTR + k-means 0.93 0.95 0.29 1.62 0.15687 914.70 RF + k-means 0.95 0.91 0.27 1.57
    0.16745 1475.13 XB + k-means 0.97 0.98 0.20 1.08 0.03547 537.87 XGBoost + k-means
    (XB+k-means) approach provides more accuracy with less MSE comparatively and also
    the R2 with 98% in soil moisture prediction using combined approach is given in
    Table 1. It is evident that the proposed combination performs better when compared
    to other regression + k-means-based approaches. XB + k-means-based hybrid machine
    learning algorithm is applied in irrigation planning module on account of aforementioned
    performance metrices of ML. Although it performs moderately in terms of execution
    time and power usage, it is selected for the deployment in edge computing as it
    has better performed in terms of accuracy, R2, MSE, and MAPE metrices. It is observed
    that the prediction of soil moisture for the upcoming days from the proposed algorithm
    (XB+k-means) is nearer to the actual value as shown in Table 2, and hence, XB+k-means
    is selected for the implementation of SMPHA in edge-based irrigation scheduling.
    Table 2 Comparison of predicted SM value with actual SM value Date Average SM
    value from sensor Average predicted SM value (XB+k-means) 28-09-2021 35.23 34.04
    29-09-2021 36.41 37.20 30-09-2021 31.57 30.46 01-10-2021 34.66 33.15 02-10-2021
    36.73 37.12 03-10-2021 32.88 33.01 4.1 Hardware setup IoT system is crucial to
    handle, collect, and transfer the data to the computing nodes at the edge or in
    the cloud. These devices are connected to the edge nodes through wireless communication
    protocols like ZigBee. It is used in reducing the latency and loss of data. An
    Arduino micro-control unit controls the combined IoT sensors and actuators at
    the same part of a field into a cluster, each connected to a Raspberry Pi that
    acts as an edge node in processing the gathered data and controlling the actuators.
    For example, Figure 2 shows an edge architecture with a Raspberry Pi connected
    to two components: Arduino Uno and Arduino Mega units via ZigBee connection. The
    first Arduino Mega node is responsible for collecting data from sensors and the
    second one is for controlling the actuators in the field. Depending on the sensor
    type with collecting Arduino unit, the sensors are connected via analog or digital
    PWM pins while controlling Arduino uno joins with actuators in the field and controls
    (turn on/off) them in accordance with upper layers (from the edge web server).
    The trained (cloud) and deployed ML model in edge nodes provides the necessary
    instructions to the edge nodes. 4.2 Web layer setup The deployment of web server
    assists the user in planning and managing the irrigation system. It visualizes
    the crucial information of factors like temperature of air and soil, UV, humidity,
    and soil moisture in live irrigation with real time updates in the form of various
    charts. In accordance with the selected field, the web application redirects the
    user to the field’s dashboard as shown in Figure 4. The dashboard consists of
    field parameters as well as control signals for activating all the physical devices/actuators
    at the garden layer. These signals are denoted as switch buttons, and each switch
    controls (turn on/off) a particular kind of actuator (for instance, water pump
    to start and stop the irrigation). The user interface facilitates remote controlling
    of the field by just clicking on the buttons as shown in Figure 4. 4.3 Edge layer
    setup The edge node acts as a computing center where incoming data are analyzed
    and fed as the input vector to the ML model for processing and to return the control
    signals for activating or deactivating the actuators placed at the farm. Edge
    node processes the physical data (real time) at every end device such as the collected
    and processed data via the Raspberry Pi nodes presented in the proposed scheme.
    The prediction model is designed using TensorFlow API and trained, tested on Google
    Colab in this work. Amazon Web Service (AWS) offers a library named Boto3 having
    many APIs to upload and download objects. After the development of model, it is
    transferred to Amazon S3, a service provided by AWS. The edge node utilizes the
    trained model from S3 for analyzing the sensed data acquired from garden’s sensors.
    The decision is delivered based on real time data analysis at the edge node and
    transmitted to Arduino nodes in the fields landscape immediately for controlling
    the actuators. In another flow, the data collected from sensors are filtered so
    as to keep only the modified data at the edge node before being sent back for
    mitigating the communication cost to the database in the cloud. These data are
    used in the updation of the ML model to enhance its efficiency. 4.4 Analytics
    setup The main goal of this experiment lies in gathering the various physical
    parameters of a farming land via sensors and utilizing the fetched data along
    with weather forecast information for developing an algorithm using hybrid machine
    learning approach to infuse higher accuracy in predicting the soil moisture for
    the upcoming days. As discussed in Section 4, for the proper planning and provisioning
    of optimal irrigation, the algorithm provides a predictable estimate of soil moisture
    with the assistance of various statistical measures as shown in Table 1. The measures
    are adopted for estimating the appropriateness and error rate of the proposed
    algorithm. It is inferred from the experiment that, optimal irrigation is feasible
    using a good estimation (close to the actual value) of the soil moisture (Table
    2), with the support of field data and forecast information, thereby utilizing
    the natural rain efficiently. The SMPHA ML model is interdependent on dynamic
    changes in weather environment where the models deployed on edge nodes need to
    change the controls accordingly after model gets trained continuously. For the
    process of retraining, the trained model needs to be updated. The parameters such
    as TM, HU, ST, UV, SM about grown plants are logged for the training purpose,
    and these generated datasets are recorded from the already developed manual mode
    system [39]. The growth of the Indian Mundu Chilli [40] is taken for the observation
    from the first stage to the last grown stage for 95 days. While retraining the
    model, the training is carried in cloud without causing effect to the functionalities
    at edge nodes. A signal is transferred to the corresponding edge server for triggering
    the task of updating the SMPHA model from the web server. At that time, the newly
    trained model is downloaded to replace the existing one at the considering edge
    server. From then, the ML model at the edge server is called to be updated with
    the real-world knowledge and is ready for its garden controlling tasks (to apply
    in the next farming season). 4.5 Work flow The flowchart in Figure 6 depicts the
    working of the proposed system based on the decision support system that is beneficial
    for irrigation needed for the growth of vegetables. The chilli plant is grown
    in a growbag attached with sensors and Pi as shown in Figure 3 and monitored for
    95 days of data collection. To bring out optimality in the irrigation system,
    features relating to climate, soil, crop, and field infrastructure are to be considered.
    To provide several recommendations in the production of vegetables, decision support
    systems (DSSs) are designed, which process voluminous information [39]. This proposed
    work is the extension of soil moisture differences (SMD) model [41] developed
    for soil moisture prediction. The threshold values of soil moisture are used in
    the SMD model where the system schedules the irrigation date based on the predicted
    soil moisture and weather forecast (precipitation) information automatically using
    SVR+ k-means modeling. Therefore, in the extension of the aforementioned work,
    further more number of sensors are used to log soil moisture value, which is averaged
    in the proposed model. This model is developed in two divisions of flowchart as
    shown in Figure 7, where both are interconnected. It is observed that the prediction
    of XB + k-mean approach provides better results as presented in Table 2. Figure
    6 Flow chart of the proposed edge model. Figure 7 Average response time with 10
    test scenarios. The first phase of the flowchart describes the hybrid algorithm
    for the soil moisture prediction (SMPHA) using the combination of XB + k-means
    algorithm. During the data collection step, the sensor data for the parameters,
    namely, TM, HU, ST, UV, and SM, are collected. During preprocessing, null values
    and outliers are removed and the preprocessed data are used to train the XG-Boost
    model. The developed model is then trained with variables of live weather features
    (TM, HU, UV, PC) obtained from Weather API for the prediction of SM data. These
    data are given as input to k-means clustering algorithm to predict the soil moisture,
    which is defined as SMPHA value to be infused in the next phase of the flowchart.
    The second phase of the flowchart defines the automatic irrigation planning setup.
    The setup starts obtaining the soil moisture maximum (SMMax) and soil moisture
    minimum (SMMin) values in the dashboard for setting the maximum and minimum level
    of soil moisture. Then, the current soil moisture (CuSM) is sensed and compared
    against the threshold SMMin. If the resulting value is less than SMMin, the process
    proceeds with SMPHA. On the contrary, it stops the irrigation process by sending
    0 to the relay. In SMPHA, the nearest precipitation date is selected and it is
    assigned to the predicted soil moisture (PSM). The SMMax is decided by finding
    the minimum of (PSM + SMMin, SMMax), and the predicted SMMax is further checked
    against CuSM with a condition if SMMax is greater the CuSM then it sends 1 to
    the relay as a signal to start irrigation. If the condition fails, then it sends
    0 to stop irrigation. The process of automatic irrigation ends by forecasting
    the irrigation schedule in accordance with the live weather parameters. 5 Experimental
    setup and evaluation The test bed is developed and deployed, and the data are
    collected for the analysis in irrigation management. Here, Heroku cloud platform
    is used to deploy the cloud web server. The same cloud is also installed at a
    local edge that is at two Raspberry Pi units equipped with Wi-Fi 802.11n connections
    to denote the edge nodes. JMeter application is used to get sequential accesses
    to the web page from various users for evaluating the network parameters. The
    specification of these servers is given in Tables 3 and 4. Table 3 Configuration
    of raspberry Pi CPU Broadcom BCM2711, Quad core Cortex-A72 (ARM v8) 64-bit SoC
    @ 1.5 GHz RAM 8 GB LPDDR4-3200 SDRAM Network 2.4 GHz and 5.0 GHz IEEE 802.11ac
    wireless, Bluetooth 5.0, BLE, Gigabit Ethernet Pinboard 8 GB LPDDR4-3200 SDRAM
    Operating system, language Raspbian , Python 3 Table 4 Configuration of Heroku
    cloud Country United states Service Amazon web service S3 Processor 2.4 GHz Intel
    Xeon E5-2676 v3 Processor CPU Power 8 GB Virtual CPUs 3–5 We evaluated the performance
    of the proposed IoT-based smart farm on two different platforms, namely, in the
    cloud and on the local computer to show the feasibility and the benefit of the
    edge computing scheme. Further many parameters are considered for evaluation and
    discussed in the next section to show that edge deployment is better than cloud.
    5.1 Evaluation A hybrid machine learning methodology is used in evaluating the
    first stage of the proposed model. The predicted value of the soil moisture is
    better in terms of their accuracy and error rate. From the comparison of the other
    ML algorithms as shown in Table 2, XB + k-means performs better and taken further
    to be deployed in edge and cloud to check its efficiency with each other. Therefore,
    for analyzing the efficiency of the edge server in accordance with the proposed
    hybrid algorithm SMPHA is evaluated in terms of the time taken to train the ML
    model in edge and cloud. In this experiment Raspberry Pi is used to train the
    SMPHA model with 196,400 rows, that is, input data sample size and takes around
    1,710,000 ms (approximately 28.5 min). The same model when it is trained in Google
    Colab cloud environment, it takes 204,000 ms (approximately 3.4 min) as depicted
    in Table 5. The main purpose is to run the trained model on edge not to train
    the model at edge. So due to the lack of computing capability at the edge, it
    takes more time to train the model, but it can be ignored as it does not affect
    the purpose of the proposed model. Here, edge is introduced to obtain the task
    of computing from the cloud (i.e., offloading the task) by making the system more
    edge-oriented deployment. It can be accomplished rapidly as it requires only 14
    s to download a trained SMPHA model from the cloud to the edge node with a size
    of 3,101 kb as given in Table 5. The time to download varies according to the
    size of the trained model. So, from this process it can be inferred that downloading
    the trained model saves time when compared to training the model at the edge.
    Through this in real time, deployment of the trained SMPHA model in edge is better
    compared to deployment in cloud services. Furthermore, network parameters like
    latency, throughput, bandwidth, and response time are adopted to measure the performance
    improvements in edge computing. Table 5 Comparison of model training time Edge
    Cloud Model training time 28.4 min 3.4 min Downloading time Not applicable 14
    s The performance metrices taken into account are latency, bandwidth, and response
    time [42]. The latency of an application is the product of two factors: computing
    latency and transmission latency. The time spent on data processing and transmission
    between end devices to cloud servers is termed as computing latency and transmission
    latency, respectively. The computational capacity of the system decides the computing
    latency as the network servers possess a considerable amount of capacity to make
    the data processing faster, whereas the sensors come with limited computing capacity.
    The latency in transmission is increased by the end devices and cloud servers.
    Bandwidth: As large number of sensors are deployed in IoT, data generated would
    be huge that consumes an intense range of bandwidth and leads to several problems
    such as delay in transmission and loss of packets. It becomes unacceptable for
    the data to be transferred directly to cloud servers without applying compression.
    Therefore, data preprocessing and aggregation are needed for IoT gateways before
    redirecting them to remote cloud servers. Then, the issue to be confronted is
    to control the traffic flow by migrating data processing and aggregation tasks
    optimally to decrease the bandwidth needs of the end users while maintaining the
    data quality. Response time: The total response time is calculated by adding up
    transmission and processing time. The local deployment of the proposed model for
    controlling IoT-based irrigation are deployed on two modes: (i) Cloud mode: The
    developed SMPHA model is implemented in the cloud communicating with IoT sensors
    nodes directly to manage the irrigation process. The data are stored and processed
    at the cloud server itself where it uses Heroku platform. (ii) Edge mode – Raspberry
    Pi is deployed as an edge server that involves in processing of the SMPHA model
    controlling the IoT sensor nodes. Here, the data are stored and processed locally
    within the edge servers. This SMPHA model from both the edge and cloud does the
    job of controlling the actuators to initiate and quit the working of water flow
    motors. Through this deployment in both the environments, performance of edge
    server and cloud server can be checked in terms of latency, throughput, bandwidth,
    and response time is shown in aforementioned graphs in Figures 6, 8, and 9. This
    performance metrices is not feasible to calculate while deploying in real time,
    so the aforementioned scenarios of two modes are virtually created by generating
    many request and response threads between the servers. This sampling, load test,
    and distributed testing are conducted through JMeter application [43] and also
    verified with Wireshark [44] in cloud servers. The test scenario is created here
    by data of sending and receiving sampling data between cloud to IoT sensors and
    between Edge to IoT sensors. The sampling data considered in this work refer to
    the approximate number of requests generated by Arduino to cloud and Arduino to
    Raspberry Pi that are calculated in real time. The test scenario is divided into
    10 days of sampling data collected for each day. The evaluation results are depicted
    for latency and response times in 10 days perspective. In latency parameter, edge
    service has decreased by an average of 77.85% time compared to the with cloud.
    In the same manner, the response time of edge service is also decreased by 74.09%
    time compared to cloud service. In throughput calculation, sampling data are calculated
    for an hourly basis for the 10 hours data in a day. From the hourly comparisons
    of throughput value, edge outperforms with 67.17% high Mbps usage. Through this
    analysis as shown in Table 6, it is evident that the proposed edge computing methodology
    deployed in Raspberry Pi or in local computers outperforms the cloud-oriented
    approach. Figure 8 Average latency with 10 test scenarios. Figure 9 Average throughput
    value with 10 h test scenarios. Table 6 Performance metrices for cloud and edge
    services Performance metrices Cloud service Edge service Throughput (Mbps) 0.04944
    0.08265 Latency (ms) 1415.8 313.6 Response time (ms) 1519.6 393.8 Bandwidth (bps)
    86 1,365 Finally, to illustrate the efficiency of resource management in edge
    computing, CPU and memory utilization are considered for the analysis as both
    factors rely on the service execution model and the computational needs of the
    services being fired from off-loaders. Figure 10 depicts the utilization of CPU
    and RAM on the Raspberry Pi acting as an edge node in two cases: with and without
    the deployment of SMPHA model on it. As shown in Figure 10, the SMPHA model affects
    the CPU of the Raspberry Pi node significantly as it consumed around 41.2% of
    the CPU compared to only 3.5% when it does not host the SMPHA model. However,
    the memory (RAM) utilization in both the cases (with and without deployment of
    an SMPHA model) is nearly the same which is around 31%. Comparatively RAM utilization
    does not have much difference in with and without SMPHA. It is worthwhile to note
    that, the CPU utilization is still much lower than the 50% of total CPU capacity
    in Raspberry Pi. Therefore, it becomes feasible for adopting edge server implementation
    in the proposed irrigation system. Figure 10 CPU and memory utilization with and
    without SMPHA. 6 Conclusion This article proposed a novel approach to edge-based
    irrigation system to facilitate decision-making on watering the plants on scheduled
    time. The proposed approach applying IoT with an edge computing framework enables
    the farming system to adapt to the changes in environmental conditions automatically
    and efficiently. The process of automatic irrigation regulates irrigation according
    to the live weather parameters for forecasting the irrigation process. Soil moisture
    prediction was performed using major regression algorithms that are again combined
    with k-means clustering for estimating the changes incurred in soil moisture prediction.
    These techniques were compared through metrics such as MAPE, MSE, speed, and power
    consumption from which XB + k-means was found to perform better. The XB + k-means
    algorithm was further used for the implementation of decision mechanism on the
    developed edge computing model. The proposed edge model saves the data communication
    cost and reduces the response time of IoT services. It can be deployed on existing
    devices on the network edges serving as edge nodes, thereby reducing the overall
    implementation cost of a large-scale IoT system. The edge-based approach was found
    to perform better than the cloud-based approach in terms of response time, latency,
    throughput, and bandwidth usage. Finally, the edge model was analyzed through
    CPU and memory usage while running with and without the algorithm. In both cases,
    the memory utilization is almost lower to total available resource of the edge
    device. From this, edge device can allocate its remaining resource for other computing
    services, which increases the efficiency of edge computing device. The number
    of end edge nodes can be increased according to the field area and then to check
    the potency of the system. Conflict of interest: The authors declare no conflict
    of interest. Data availability statement: All data that support the findings of
    this study are included within the article. References [1] India: Issues and Priorities
    for Agriculture, The World Bank, May 17, 2012. https://www.worldbank.org/en/news/feature/2012/05/17/india-agriculture-issues-priorities.Search
    in Google Scholar [2] India at a glance in Agriculture, FAO in India. https://www.fao.org/india/fao-in-india/india-at-a-glance/en/.Search
    in Google Scholar [3] Cavicchioli R, Ripple WJ, Timmis KN, Azam F, Bakken LR,
    Baylis M, et al. Scientists’ warning to humanity: Microorganisms and climate change.
    Nature Rev Microbiol. 2019;17(9):569–86. 10.1038/s41579-019-0222-5. Search in
    Google Scholar PubMed PubMed Central [4] Huong NTL, Bo YS, Fahad S. Economic impact
    of climate change on agriculture using Ricardian approach: A case of Northwest
    Vietnam. J Saudi Society Agricult Sci. 2019;18(4):449–457. 10.1016/j.jssas.2018.02.006.
    Search in Google Scholar [5] Fagodiya RK, Pathak H, Bhatia A, Jain N, Kumar A,
    Malyan SK. Global warming impacts of nitrogen use in agriculture: An assessment
    for India since 1960. Carbon Management. 2020;11(3):291–301. 10.1080/17583004.2020.1752061.
    Search in Google Scholar [6] Sarkar S, Chatterjee S, Misra S. Assessment of the
    suitability of fog computing in the context of internet of things. IEEE Trans
    Cloud Comput. 2018;6(1):46–59. 10.1109/TCC.2015.2485206. Search in Google Scholar
    [7] Porter JR, Xie L, Challinor AJ, Cochrane K, Howden SM, Iqbal MM, et al. Food
    security and food production systems. In: Field CB, Barros VR, Dokken DJ, Mach
    KJ, Mastrandrea MD, Bilir TE, et al., editors. Climate Change 2014: Impacts, Adaptation,
    and Vulnerability. Part A: Global and Sectoral Aspects. Contribution of Working
    Group II to the Fifth Assessment Report of the Intergovernmental Panel on Climate
    Change Cambridge, United Kingdom: Cambridge University Press and New York, NY,
    USA; 2014. p. 485–533.Search in Google Scholar [8] Lal R. Adaptation and mitigation
    of climate change by improving agriculture in India. In: S. SherazMahdi (Ed.),
    Climate Change and Agriculture in India: Impact and Adaptation. Cham: Springer
    International Publishing; 2019. p. 217–27. 10.1007/978-3-319-90086-5_17Search
    in Google Scholar [9] Saravanan K, Julie G, Robinson H. (Eds.), Handbook of research
    on implementation and deployment of IoT projects in smart cities. Hershey: IGI
    global, 2019. 10.4018/978-1-5225-9199-3Search in Google Scholar [10] Baylis A.
    Advances in precision farming technologies for crop protection. Outlooks Pest
    Manag. 2017;28(4):158–61. 10.1564/v28_aug_04Search in Google Scholar [11] Mulla
    D, Khosla R. Historical evolution and recent advances in precision farming. Soil-Specific
    Farming Precision Agriculture. Boca Raton: CRC Press; 2015. 10.1201/b18759-2Search
    in Google Scholar [12] Dutta L, and Basu TK. Extraction and optimization of leaves
    images of mango tree and classification using ANN. IJRAET 2013;1(3):46–51. Search
    in Google Scholar [13] Kawai T, Mineno H. Evaluation environment using edge computing
    for artificial intelligence-based irrigation system. 2020 16th International Conference
    on Mobility, Sensing and Networking (MSN). Tokyo, Japan: IEEE; 2020. p. 214–9.
    10.1109/MSN50589.2020.00046Search in Google Scholar [14] Munir MS, Bajwa IS, Ashraf
    A, Anwar W, Rashid R. Intelligent and smart irrigation system using edge computing
    and IoT. Complexity. 2021;2021:1–16. 10.1155/2021/6691571Search in Google Scholar
    [15] Angelopoulos CM, Filios G, Nikoletseas S, Raptis TP. Keeping data at the
    edge of smart irrigation networks: A case study in strawberry greenhouses. Comput
    Netw. 2020;167:107039. 10.1016/j.comnet.2019.107039Search in Google Scholar [16]
    Satyanarayanan M. The emergence of edge computing. Computer. 2017;50(1):30–9.
    10.1109/MC.2017.9Search in Google Scholar [17] Shi W, Dustdar S. The promise of
    edge computing. Computer. 2016;49(5):78–81. 10.1109/MC.2016.145Search in Google
    Scholar [18] Ramirez Izolan PL, Diniz Rossi F, Hohemberger R, Konzen MP, da Cunha
    Rodrigues G, Saquette LR, et al. Low-cost fog computing platform for soil moisture
    management. In: 2020 International Conference on Information Networking (ICOIN).
    Barcelona, Spain: IEEE; 2020. p. 499–504. 10.1109/ICOIN48656.2020.9016572Search
    in Google Scholar [19] Ferrandez-Pastor F, Garcia-Chamizo, J, Nieto-Hidalgo, M,
    Mora-Pascual, J, Mora-Martínez, J. Developing ubiquitous sensor network platform
    using internet of things: application in precision agriculture. Sensors. 2016;16(7):1141.
    10.3390/s16071141Search in Google Scholar PubMed PubMed Central [20] Xu X, Liu
    X, Xu Z, Dai F, Zhang X, Qi L. Trust-oriented IoT service placement for smart
    cities in edge computing. IEEE Internet Things J. 2020;7(5):4084–91. 10.1109/JIOT.2019.2959124Search
    in Google Scholar [21] Wu X, Liu M. In-situ soil moisture sensing: Measurement
    scheduling and estimation using compressive sensing. In: 2012 ACM/IEEE 11th International
    Conference on Information Processing in Sensor Networks (IPSN). Beijing, China:
    IEEE; 2012. p. 1–11. 10.1145/2185677.2185679Search in Google Scholar [22] Kameoka
    T, Nishioka K, Motonaga Y, Kimura Y, Hashimoto A, Watanabe N. Smart sensing in
    a Vineyard for advanced viticultural management. In: Proceedings of the 2014 International
    Workshop on Web Intelligence and Smart Sensing. Saint Etienne France; 2014. p.
    1–4. 10.1145/2637064.2637091Search in Google Scholar [23] Cagri Serdaroglu K,
    Onel C, Baydere S. IoT-based smart plant irrigation system with enhanced learning.
    In: 2020 IEEE Computing, Communications and IoT Applications (ComComAp.) Beijing,
    China: IEEE; 2020. p. 1–6. 10.1109/ComComAp51192.2020.9398892Search in Google
    Scholar [24] Kwok J, Sun Y. A smart IoT-based irrigation system with automated
    plant recognition using deep learning. In: Proceedings of the 10th International
    Conference on Computer Modeling and Simulation - ICCMS2018. Sydney, Australia:
    ACM Press; 2018. p. 87–91. 10.1145/3177457.3177506Search in Google Scholar [25]
    Goldstein A, Fink L, Meitin A, Bohadana S, Lutenberg O, Ravid G. Applying machine
    learning on sensor data for irrigation recommendations: Revealing the agronomist’s
    tacit knowledge. Precision Agricult. 2018;19(3):421–44. 10.1007/s11119-017-9527-4Search
    in Google Scholar [26] Vij A, Vijendra S, Jain A, Bajaj S, Bassi A, Sharma A.
    IoT and machine learning approaches for automation of farm irrigation system.
    Proc Comput Sci. 2020;167:1250–7. 10.1016/j.procs.2020.03.440Search in Google
    Scholar [27] Krishnan H, Scholar R. MongoDB – a comparison with NoSQL databases.
    Int J Scientific Eng Res. 2016;7(5):1035–7. Search in Google Scholar [28] Ojha
    T, Misra S, Raghuwanshi NS. Wireless sensor networks for agriculture: The state-of-the-art
    in practice and future challenges. Comput Electr Agricult. 2015;118:66–84. 10.1016/j.compag.2015.08.011Search
    in Google Scholar [29] Gutierrez J, Villa-Medina JF, Nieto-Garibay A, Porta-Gandara
    MA. Automated irrigation system using a wireless sensor network and GPRS module.
    IEEE Trans Instrument Measurement. 2014;63(1):166–76. 10.1109/TIM.2013.2276487Search
    in Google Scholar [30] Chanthakit S, Keeratiwintakorn P, Rattanapoka C. An IoT
    system design with real time stream processing and data flow integration. In:
    2019 Research, Invention, and Innovation Congress (RI2C.) Bangkok, Thailand: IEEE;
    2019. p. 1–5. 10.1109/RI2C48728.2019.8999968Search in Google Scholar [31] Lv H,
    Wang S. Design and application of IoT microservices based on Seneca. USA: DEStech
    Transactions on Computer Science and Engineering, (icte.). 2016. 10.12783/dtcse/icte2016/4814Search
    in Google Scholar [32] Lee B-H, Dewi EK, Wajdi MF. Data security in cloud computing
    using AES under HEROKU cloud. In: 2018 27th Wireless and Optical Communication
    Conference (WOCC). Hualien: IEEE; 2018. p. 1–5. 10.1109/WOCC.2018.8372705Search
    in Google Scholar [33] Lopez Pena MA, Munoz Fernandez I. SAT-IoT: An architectural
    model for a high-performance fog/edge/cloud IoT platform. In: 2019 IEEE 5th world
    forum on internet of things (WF-IoT.) Limerick, Ireland: IEEE; 2019. p. 633–8.
    10.1109/WF-IoT.2019.8767282Search in Google Scholar [34] Weather API. Retrieved
    from https://openweathermap.org/api.Search in Google Scholar [35] Drew Gislason.
    Zigbee wireless networking, 1st ed. Newnes, London: Elsevier Publisher; 2008.
    Search in Google Scholar [36] Tanabe K, Tanabe Y, Hagiya M. Model-based testing
    for MQTT applications. In: Virvou M, Nakagawa H, Jain LC. (Eds.), Knowledge-Based
    Software Engineering: 2020. Cham: Springer International Publishing; 2020. p.
    47–59. 10.1007/978-3-030-53949-8_5Search in Google Scholar [37] Babun L, Denney
    K, Celik ZB, McDaniel P, Uluagac AS. A survey on IoT platforms: Communication,
    security, and privacy perspectives. Comput Netw. 2021;192:108040. 10.1016/j.comnet.2021.108040Search
    in Google Scholar [38] Rastogi K, Lohani D. Edge computing-based internet of things
    framework for indoor occupancy estimation. Int J Ambient Comput Intell. 2020;11(4):16–37.
    10.4018/978-1-6684-5700-9.ch031Search in Google Scholar [39] Premkumar S, Sigappi
    AN. Functional framework for edge-based agricultural system. In: AI, Edge and
    IoT-based Smart Agriculture, 1st ed. USA: Academic Press, Elsevier; 2021. p. 71–100.
    10.1016/B978-0-12-823694-9.00029-3Search in Google Scholar [40] Phani Kumar J,
    Paramaguru P, Arumugam T, Manikanda Boopathi N, Venkatesan K. Genetic divergence
    among Ramnad mundu chilli (Capsicum annuum L.) genotypes for yield and quality.
    Electr J Plant Breeding. 2021;12(1):228–34. Search in Google Scholar [41] Goap
    A, Sharma D, Shukla AK, Rama Krishna C. An IoT-based smart irrigation management
    system using Machine learning and open source technologies. Comput Electronic
    Agricult. 2018;155:41–9. 10.1016/j.compag.2018.09.040Search in Google Scholar
    [42] Aslanpour MS, Gill SS, Toosi AN. Performance evaluation metrics for cloud,
    fog and edge computing: A review, taxonomy, benchmarks and standards for future
    research. Internet Things. 2020;12:100273. 10.1016/j.iot.2020.100273Search in
    Google Scholar [43] Sunardi A, Suharjito MVC architecture: a comparative study
    between Laravel framework and slim framework in freelancer project monitoring
    system web based. Proc Comput Sci. 2019;157:134–41. 10.1016/j.procs.2019.08.150Search
    in Google Scholar [44] Robert Shimonski. The wireshark field guide, 1st ed. New
    York: Syngress Press, Elsevier; 2013. 10.1016/B978-0-12-410413-6.00001-2Search
    in Google Scholar Received: 2022-01-10 Revised: 2022-02-28 Accepted: 2022-03-16
    Published Online: 2022-05-27 © 2022 S. Premkumar and AN. Sigappi, published by
    De Gruyter This work is licensed under the Creative Commons Attribution 4.0 International
    License. Download article (PDF) From the journal Journal of Intelligent Systems
    Volume 31 Issue 1 Submit manuscript Journal and Issue This issue All issues Articles
    in the same Issue Research Articles Construction of 3D model of knee joint motion
    based on MRI image registration Evaluation of several initialization methods on
    arithmetic optimization algorithm performance Application of visual elements in
    product paper packaging design: An example of the “squirrel” pattern Deep learning
    approach to text analysis for human emotion detection from big data Cognitive
    prediction of obstacle''s movement for reinforcement learning pedestrian interacting
    model The application of neural network algorithm and embedded system in computer
    distance teach system Machine translation of English speech: Comparison of multiple
    algorithms Automatic control of computer application data processing system based
    on artificial intelligence A secure framework for IoT-based smart climate agriculture
    system: Toward blockchain and edge computing Application of mining algorithm in
    personalized Internet marketing strategy in massive data environment On the correction
    of errors in English grammar by deep learning Research on intelligent interactive
    music information based on visualization technology Extractive summarization of
    Malayalam documents using latent Dirichlet allocation: An experience Conception
    and realization of an IoT-enabled deep CNN decision support system for automated
    arrhythmia classification Masking and noise reduction processing of music signals
    in reverberant music Cat swarm optimization algorithm based on the information
    interaction of subgroup and the top-N learning strategy State feedback based on
    grey wolf optimizer controller for two-wheeled self-balancing robot Research on
    an English translation method based on an improved transformer model Short-term
    prediction of parking availability in an open parking lot PUC: parallel mining
    of high-utility itemsets with load balancing on spark Image retrieval based on
    weighted nearest neighbor tag prediction A comparative study of different neural
    networks in predicting gross domestic product A study of an intelligent algorithm
    combining semantic environments for the translation of complex English sentences
    A study on automatic correction of English grammar errors based on deep learning
    A novel fingerprint recognition method based on a Siamese neural network A hidden
    Markov optimization model for processing and recognition of English speech feature
    signals Crime reporting and police controlling: Mobile and web-based approach
    for information-sharing in Iraq CRNet: Context feature and refined network for
    multi-person pose estimation Improving the efficiency of intrusion detection in
    information systems Research on reform and breakthrough of news, film, and television
    media based on artificial intelligence An optimized solution to the course scheduling
    problem in universities under an improved genetic algorithm An adaptive RNN algorithm
    to detect shilling attacks for online products in hybrid recommender system Computing
    the inverse of cardinal direction relations between regions An improved Jaya optimization
    algorithm with ring topology and population size reduction Review Articles A review
    on voice pathology: Taxonomy, diagnosis, medical procedures and detection techniques,
    open challenges, limitations, and recommendations for future directions An extensive
    review of state-of-the-art transfer learning techniques used in medical imaging:
    Open issues and challenges Special Issue: Explainable Artificial Intelligence
    and Intelligent Systems in Analysis For Complex Problems and Systems Tree-based
    machine learning algorithms in the Internet of Things environment for multivariate
    flood status prediction Evaluating OADM network simulation and an overview based
    metropolitan application Radiography image analysis using cat swarm optimized
    deep belief networks Comparative analysis of blockchain technology to support
    digital transformation in ports and shipping IoT network security using autoencoder
    deep neural network and channel access algorithm Large-scale timetabling problems
    with adaptive tabu search Eurasian oystercatcher optimiser: New meta-heuristic
    algorithm Trip generation modeling for a selected sector in Baghdad city using
    the artificial neural network Trainable watershed-based model for cornea endothelial
    cell segmentation Hessenberg factorization and firework algorithms for optimized
    data hiding in digital images The application of an artificial neural network
    for 2D coordinate transformation A novel method to find the best path in SDN using
    firefly algorithm Systematic review for lung cancer detection and lung nodule
    classification: Taxonomy, challenges, and recommendation future works Special
    Issue on International Conference on Computing Communication & Informatics Edge
    detail enhancement algorithm for high-dynamic range images Suitability evaluation
    method of urban and rural spatial planning based on artificial intelligence Writing
    assistant scoring system for English second language learners based on machine
    learning Dynamic evaluation of college English writing ability based on AI technology
    Image denoising algorithm of social network based on multifeature fusion Automatic
    recognition method of installation errors of metallurgical machinery parts based
    on neural network An FCM clustering algorithm based on the identification of accounting
    statement whitewashing behavior in universities Emotional information transmission
    of color in image oil painting College music teaching and ideological and political
    education integration mode based on deep learning Behavior feature extraction
    method of college students’ social network in sports field based on clustering
    algorithm Evaluation model of multimedia-aided teaching effect of physical education
    course based on random forest algorithm Venture financing risk assessment and
    risk control algorithm for small and medium-sized enterprises in the era of big
    data Interactive 3D reconstruction method of fuzzy static images in social media
    The impact of public health emergency governance based on artificial intelligence
    Optimal loading method of multi type railway flatcars based on improved genetic
    algorithm Special Issue: Evolution of Smart Cities and Societies using Emerging
    Technologies Data mining applications in university information management system
    development Implementation of network information security monitoring system based
    on adaptive deep detection Face recognition algorithm based on stack denoising
    and self-encoding LBP Research on data mining method of network security situation
    awareness based on cloud computing Topology optimization of computer communication
    network based on improved genetic algorithm Implementation of the Spark technique
    in a matrix distributed computing algorithm Construction of a financial default
    risk prediction model based on the LightGBM algorithm Application of embedded
    Linux in the design of Internet of Things gateway Research on computer static
    software defect detection system based on big data technology Study on data mining
    method of network security situation perception based on cloud computing Modeling
    and PID control of quadrotor UAV based on machine learning Simulation design of
    automobile automatic clutch based on mechatronics Research on the application
    of search algorithm in computer communication network Special Issue: Artificial
    Intelligence based Techniques and Applications for Intelligent IoT Systems Personalized
    recommendation system based on social tags in the era of Internet of Things Supervision
    method of indoor construction engineering quality acceptance based on cloud computing
    Intelligent terminal security technology of power grid sensing layer based upon
    information entropy data mining Deep learning technology of Internet of Things
    Blockchain in distribution network faults Optimization of shared bike paths considering
    faulty vehicle recovery during dispatch The application of graphic language in
    animation visual guidance system under intelligent environment Iot-based power
    detection equipment management and control system Estimation and application of
    matrix eigenvalues based on deep neural network Brand image innovation design
    based on the era of 5G internet of things Special Issue: Hybrid Fuzzy Systems
    for Mobile Robots and Their Applications IoT-enabled edge computing model for
    smart irrigation system Convex optimization for additive noise reduction in quantitative
    complex object wave retrieval using compressive off-axis digital holographic imaging
    Special Issue: Cognitive Cyber-Physical System with Artificial Intelligence for
    Healthcare 4.0. Auxiliary diagnosis study of integrated electronic medical record
    text and CT images A hybrid particle swarm optimization with multi-objective clustering
    for dermatologic diseases diagnosis An efficient recurrent neural network with
    ensemble classifier-based weighted model for disease prediction Design of metaheuristic
    rough set-based feature selection and rule-based medical data classification model
    on MapReduce framework Special Issue: Human-Centred Artificial Intelligence for
    Web 4.0 Construction of an IoT customer operation analysis system based on big
    data analysis and human-centered artificial intelligence for web 4.0 Human-centered
    artificial intelligence-based ice hockey sports classification system with web
    4.0 Subjects Architecture and Design Arts Asian and Pacific Studies Business and
    Economics Chemistry Classical and Ancient Near Eastern Studies Computer Sciences
    Cultural Studies Engineering General Interest Geosciences History Industrial Chemistry
    Islamic and Middle Eastern Studies Jewish Studies Law Library and Information
    Science, Book Studies Life Sciences Linguistics and Semiotics Literary Studies
    Materials Sciences Mathematics Medicine Music Pharmacy Philosophy Physics Social
    Sciences Sports and Recreation Theology and Religion Services For Journal Authors
    For Book Authors For Librarians Rights & Permissions Publications Publication
    types Open Access About Contact Career About De Gruyter Partnerships Press FAQs
    Social Facebook Instagram LinkedIn Twitter YouTube Winner of the OpenAthens Best
    Publisher UX Award 2022  Help/FAQ Privacy policy Cookie Policy Accessibility Terms
    & Conditions Legal Notice © Walter de Gruyter GmbH 2024 Consent to website analysis
    We use cookies and other technologies. Some of them are necessary for the website
    to function and are always set. Cookies for website analysis are not required
    and are set only with your consent. Some services for analysis process personal
    data in the USA. With your consent to use these services, you also consent to
    the processing of your data in the USA. Your consent is voluntary and can be revoked
    at any time. For more information, please see our Cookie Policy. Accept optional
    analytics cookies Reject non-essential cookies"'
  inline_citation: '>'
  journal: Journal of Intelligent Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: IoT-enabled edge computing model for smart irrigation system
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Premkumar S.
  - Sigappi A.N.
  citation_count: '2'
  description: 'Internet of Things (IoT) provide a promising Smart irrigation facilitator
    for continual monitoring and control of environmental parameters, thereby leading
    to a huge volume of data to be efficiently collected, transferred, processed and
    stored. The deployment of cloud-based infrastructure with on-field connectedness,
    allowing information exchange among IoT nodes, and the usage of energy scavenging
    (e.g., solar power) in feeding them, become necessary, since agricultural fields
    are in lack of wired energy supply and, often, a reliable (Internet) network coverage.
    Therefore, these issues can be addressed through the integration of Edge computing
    in IoT scenarios. An efficient strategy is required to select the best communication
    technology with a motive of increasing the network performance between the IoT
    devices, Edge device and cloud. Application Specific Infrastructure Selection
    (ASIS) is an edge computing model developed to select the appropriate communication
    protocols according to the infrastructure requirements of three different real
    time scenarios namely: Assembly line automation, Smart parking system and Automatic
    irrigation system are deployed to get the most suitable application specific protocol
    from ZigBee, LoRa (Long Range) and LoWPAN (Low-Power Wireless Personal Area Network)
    to implement in real-time basis. ASIS model is proposed as a network resource
    manager that is capable of sensing, acting, signal processing, and/or communication
    abilities to perform a protocol selection according to their physical and technological
    limitations. Further Edge based ASIS model is developed to enhance the network
    performance even better when compared with cloud-based model. Automatic irrigation
    system is extended in the Edge based ASIS model. The overall ASIS system is evaluated
    by means of network parameters such as network usage, network delay and power
    consumption. The ASIS model and Edge based ASIS model is deployed in iFogSim simulator
    that compares each protocol used in the above IoT scenarios. Finally, the scenario
    of Automatic irrigation system is modeled using Edge based ASIS model where ZigBee
    with edge performs better compared with cloud-based model. Experimental results
    show that ASIS based Edge implementation lessen the overall network parameters
    in contrast to non-edge deployment in automatic irrigation scenario.'
  doi: 10.13052/jmm1550-4646.18321
  full_citation: '>'
  full_text: '>

    "Journal of Mobile Multimedia Submit Article River Publishers Journals View All
    Issues Editorial Team Author Guidelines About Submissions Contact Search Journal
    HOME Register Login Home / Archives / 2022: Vol 18 Iss 3 / Computer Vision and
    its Application in Agriculture ASIS Edge Computing Model to Determine the Communication
    Protocols for IoT Based Irrigation S. Premkumar Department of Computer Science
    & Engineering, Faculty of Engineering & Technology, Annamalai University, Tamilnadu,
    India .st0{fill:#A6CE39;} .st1{fill:#FFFFFF;} https://orcid.org/0000-0001-9350-3819
    AN. Sigappi Department of Computer Science & Engineering, Faculty of Engineering
    & Technology, Annamalai University, Tamilnadu, India .st0{fill:#A6CE39;} .st1{fill:#FFFFFF;}
    https://orcid.org/0000-0002-2166-8312 DOI: https://doi.org/10.13052/jmm1550-4646.18321
    Keywords: Internet of things, Edge computing, Irrigation system, Smart farming,
    Networkprotocol, cloud infrastructure, Zigbee, LoRa, LoWPAN, iFOGSIM Abstract
    Internet of Things (IoT) provide a promising Smart irrigation facilitator for
    continual monitoring and control of environmental parameters, thereby leading
    to a huge volume of data to be efficiently collected, transferred, processed and
    stored. The deployment of cloud-based infrastructure with on-field connectedness,
    allowing information exchange among IoT nodes, and the usage of energy scavenging
    (e.g., solar power) in feeding them, become necessary, since agricultural fields
    are in lack of wired energy supply and, often, a reliable (Internet) network coverage.
    Therefore, these issues can be addressed through the integration of Edge computing
    in IoT scenarios. An efficient strategy is required to select the best communication
    technology with a motive of increasing the network performance between the IoT
    devices, Edge device and cloud. Application Specific Infrastructure Selection
    (ASIS) is an edge computing model developed to select the appropriate communication
    protocols according to the infrastructure requirements of three different real
    time scenarios namely: Assembly line automation, Smart parking system and Automatic
    irrigation system are deployed to get the most suitable application specific protocol
    from ZigBee, LoRa (Long Range) and LoWPAN (Low-Power Wireless Personal Area Network)
    to implement in real-time basis. ASIS model is proposed as a network resource
    manager that is capable of sensing, acting, signal processing, and/or communication
    abilities to perform a protocol selection according to their physical and technological
    limitations. Further Edge based ASIS model is developed to enhance the network
    performance even better when compared with cloud-based model. Automatic irrigation
    system is extended in the Edge based ASIS model. The overall ASIS system is evaluated
    by means of network parameters such as network usage, network delay and power
    consumption. The ASIS model and Edge based ASIS model is deployed in iFogSim simulator
    that compares each protocol used in the above IoT scenarios. Finally, the scenario
    of Automatic irrigation system is modeled using Edge based ASIS model where ZigBee
    with edge performs better compared with cloud-based model. Experimental results
    show that ASIS based Edge implementation lessen the overall network parameters
    in contrast to non-edge deployment in automatic irrigation scenario. Downloads
    Author Biographies S. Premkumar, Department of Computer Science & Engineering,
    Faculty of Engineering & Technology, Annamalai University, Tamilnadu, India S.
    Premkumar Research Scholar, Computer Science and Engineering, Annamalai University,
    India. He has finished Master of Engineering (CSE) in Annamalai University. Currently
    he is also serving as a Project fellow (CSE) under UGC India granted DST-PURSE
    scheme at Annamalai University. His interested areas are Artificial Intelligence,
    Internet of Things, Edge computing and Cloud computing. AN. Sigappi, Department
    of Computer Science & Engineering, Faculty of Engineering & Technology, Annamalai
    University, Tamilnadu, India AN. Sigappi, Received her Ph.D in Computer Science
    and Engineering from Annamalai University in 2013. She did her Master Degree in
    Computer science and engineering from Anna University. Currently she is serving
    as a Professor in the Department of Computer Science and Engineering, Annamalai
    University, India. Her areas of interest include Image Processing, Machine Learning,
    Data Analytics and Internet of things. She has published more than 25 research
    articles in international journals and conferences. References J. Lin, W. Yu,
    N. Zhang, X. Yang, H. Zhang, and W. Zhao, “A Survey on Internet of Things: Architecture,
    Enabling Technologies, Security and Privacy, and Applications,” IEEE Internet
    Things J., vol. 4, no. 5, pp. 1125–1142, Oct. 2017, doi: 10.1109/JIOT.2017.2683200.
    L. Bajer and O. Krejcar, “Design and Realization of Low Cost Control for Greenhouse
    Environment with Remote Control,” IFAC-PapersOnLine, vol. 48, no. 4, pp. 368–373,
    2015, doi: 10.1016/j.ifacol.2015.07.062. J. A. Stankovic, “Research Directions
    for the Internet of Things,” IEEE Internet Things J., vol. 1, no. 1, pp. 3–9,
    Feb. 2014, doi: 10.1109/JIOT.2014.2312291. L. Lou, Q. Li, Z. Zhang, R. Yang, and
    W. He, “An IoT-Driven Vehicle Detection Method Based on Multisource Data Fusion
    Technology for Smart Parking Management System,” IEEE Internet Things J., vol.
    7, no. 11, pp. 11020–11029, Nov. 2020, doi: 10.1109/JIOT.2020.2992431. V. Chauhan,
    M. Patel, S. Tanwar, S. Tyagi, and N. Kumar, “IoT Enabled Real-Time urban transport
    management system,” Computers & Electrical Engineering, vol. 86, p. 106746, Sep.
    2020, doi: 10.1016/j.compeleceng.2020.106746. H. M. Khan, A. Khan, F. Jabeen,
    and A. U. Rahman, “Privacy preserving data aggregation with fault tolerance in
    fog-enabled smart grids,” Sustainable Cities and Society, vol. 64, p. 102522,
    Jan. 2021, doi: 10.1016/j.scs.2020.102522. W. Yang et al., “EdgeKeeper: a trusted
    edge computing framework for ubiquitous power Internet of Things,” Front Inform
    Technol Electron Eng, Jan. 2021, doi: 10.1631/FITEE.1900636. E. Saavedra, G. del
    Campo, and A. Santamaria, “Smart Metering for Challenging Scenarios: A Low-Cost,
    Self-Powered and Non-Intrusive IoT Device,” Sensors, vol. 20, no. 24, p. 7133,
    Dec. 2020, doi: 10.3390/s20247133. M. Kumar, K. S. Raju, D. Kumar, N. Goyal, S.
    Verma, and A. Singh, “An efficient framework using visual recognition for IoT
    based smart city surveillance,” Multimed Tools Appl, Jan. 2021, doi: 10.1007/s11042-020-10471-x.
    F. B. Poyen, A. Ghosh, P. Kundu, S. Hazra, and N. Sengupta, “Prototype Model Design
    of Automatic Irrigation Controller,” IEEE Trans. Instrum. Meas., vol. 70, pp.
    1–17, 2021, doi: 10.1109/TIM.2020.3031760. N. Abdullah et al., “Towards Smart
    Agriculture Monitoring Using Fuzzy Systems,” IEEE Access, vol. 9, pp. 4097–4111,
    2021, doi: 10.1109/ACCESS.2020.3041597. W. Yu et al., “A Survey on the Edge Computing
    for the Internet of Things,” IEEE Access, vol. 6, pp. 6900–6919, 2018, doi: 10.1109/ACCESS.2017.2778504.
    M. Capra, R. Peloso, G. Masera, M. R. Roch, and M. Martina, “Edge Computing: A
    Survey On the Hardware Requirements in the Internet of Things World,” Future Internet,
    vol. 11, no. 4, p. 100, Apr. 2019, doi: 10.3390/fi11040100. H. Bangui, S. Rakrak,
    S. Raghay, and B. Buhnova, “Moving to the Edge-Cloud-of-Things: Recent Advances
    and Future Research Directions,” Electronics, vol. 7, no. 11, p. 309, Nov. 2018,
    doi: 10.3390/electronics7110309. J. Kang and D.-S. Eom, “Offloading and Transmission
    Strategies for IoT Edge Devices and Networks,” Sensors, vol. 19, no. 4, p. 835,
    Feb. 2019, doi: 10.3390/s19040835. M. Syafrudin, N. Fitriyani, G. Alfian, and
    J. Rhee, “An Affordable Fast Early Warning System for Edge Computing in Assembly
    Line,” Applied Sciences, vol. 9, no. 1, p. 84, Dec. 2018, doi: 10.3390/app9010084.
    K. S. Awaisi et al., “Towards a Fog Enabled Efficient Car Parking Architecture,”
    IEEE Access, vol. 7, pp. 159100–159111, 2019, doi: 10.1109/ACCESS.2019.2950950.
    A. Goap, D. Sharma, A. K. Shukla, and C. Rama Krishna, “An IoT based smart irrigation
    management system using Machine learning and open source technologies,” Computers
    and Electronics in Agriculture, vol. 155, pp. 41–49, Dec. 2018, doi: 10.1016/j.compag.2018.09.040.
    M. Chernyshev, Z. Baig, O. Bello, and S. Zeadally, “Internet of Things (IoT):
    Research, Simulators, and Testbeds,” IEEE Internet Things J., vol. 5, no. 3, pp.
    1637–1647, Jun. 2018, doi: 10.1109/JIOT.2017.2786639. E. Sisinni, A. Saifullah,
    S. Han, U. Jennehag, and M. Gidlund, “Industrial Internet of Things: Challenges,
    Opportunities, and Directions,” IEEE Trans. Ind. Inf., vol. 14, no. 11, pp. 4724–4734,
    Nov. 2018, doi: 10.1109/TII.2018.2852491. C. Del-Valle-Soto, L. J. Valdivia, R.
    Velázquez, L. Rizo-Dominguez, and J.-C. López-Pimentel, “Smart Campus: An Experimental
    Performance Comparison of Collaborative and Cooperative Schemes for Wireless Sensor
    Network,” Energies, vol. 12, no. 16, p. 3135, Aug. 2019, doi: 10.3390/en12163135.
    A. H. Alavi and W. G. Buttlar, “An overview of smartphone technology for citizen-centered,
    real-time and scalable civil infrastructure monitoring,” Future Generation Computer
    Systems, vol. 93, pp. 651–672, Apr. 2019, doi: 10.1016/j.future.2018.10.059. A.
    de M. Del Esposte et al., “Design and evaluation of a scalable smart city software
    platform with large-scale simulations,” Future Generation Computer Systems, vol.
    93, pp. 427–441, Apr. 2019, doi: 10.1016/j.future.2018.10.026. A. Medela, B. Cendón,
    L. González, and R. Crespo, “IoT Multiplatform Networking to Monitor and Control
    Wineries and Vineyards,” p. 10, 2013. Y. Song, J. Ma, X. Zhang, and Y. Feng, “Design
    of Wireless Sensor Network-Based Greenhouse Environment Monitoring and Automatic
    Control System,” JNW, vol. 7, no. 5, pp. 838–844, May 2012, doi: 10.4304/jnw.7.5.838-844.
    G. V. Satyanarayana and S. Mazaruddin, “Wireless Sensor Based Remote Monitoring
    System for Agriculture Using ZigBee and GPS,” p. 5. N. Sakthipriya, “An Effective
    Method for Crop Monitoring Using Wireless Sensor Network,” p. 6, 2014. D. Rajesh,
    “Application of Spatial Data mining for Agriculture,” IJCA, vol. 15, no. 2, pp.
    7–9, Feb. 2011, doi: 10.5120/1922-2566. Yue Shaobo et al., “The appliacation of
    bluetooth module on the agriculture expert system,” in 2010 2nd International
    Conference on Industrial and Information Systems, Dalian, China, Jul. 2010, pp.
    109–112. doi: 10.1109/INDUSIS.2010.5565902. M. Haefke, S. C. Mukhopadhyay, and
    H. Ewald, “A Zigbee based smart sensing platform for monitoring environmental
    parameters,” in 2011 IEEE International Instrumentation and Measurement Technology
    Conference, Hangzhou, China, May 2011, pp. 1–8. doi: 10.1109/IMTC.2011.5944154.
    PG Student, Department of ME, MCE, Hassan, India., P. D. S, and M. S. Srinath,
    “GSM based Automatic Irrigation Control System for Efficient Use of Resources
    and Crop Planning by Using an Android Mobile,” IOSRJMCE, vol. 11, no. 4, pp. 49–55,
    2014, doi: 10.9790/1684-11414955. P. Sarwade, N. Shinde, and S. Tingre, “FPGA
    Based Real Time Monitoring System for Agricultural Field,” vol. 3, no. 3, p. 9,
    2017. R. Castañeda-Miranda, E. Ventura-Ramos, R. del Rocío Peniche-Vera, and G.
    Herrera-Ruiz, “Fuzzy Greenhouse Climate Control System based on a Field Programmable
    Gate Array,” Biosystems Engineering, vol. 94, no. 2, pp. 165–177, Jun. 2006, doi:
    10.1016/j.biosystemseng.2006.02.012. K. P. Ferentinos, N. Katsoulas, A. Tzounis,
    C. Kittas, and T. Bartzanas, “A climate control methodology based on wireless
    sensor networks in greenhouses,” Acta Hortic., no. 1107, pp. 75–82, Dec. 2015,
    doi: 10.17660/ActaHortic.2015.1107.9. J.-S. Lee, Y.-W. Su, and C.-C. Shen, “A
    Comparative Study of Wireless Protocols: Bluetooth, UWB, ZigBee, and Wi-Fi,” in
    IECON 2007 – 33rd Annual Conference of the IEEE Industrial Electronics Society,
    Taipei, Taiwan, 2007, pp. 46–51. doi: 10.1109/IECON.2007.4460126. C. Saad, B.
    Mostafa, E. Ahmadi, and H. Abderrahmane, “Comparative Performance Analysis of
    Wireless Communication Protocols for Intelligent Sensors and Their Applications,”
    IJACSA, vol. 5, no. 4, 2014, doi: 10.14569/IJACSA.2014.050413. A. Paventhan, S.
    K. Allu, S. Barve, V. Gayathri, and N. M. Ram, “Soil Property Monitoring Using
    6LoWPAN-enabled Wireless Sensor Networks,” p. 7, 2012. Z. Suryady, M. H. M. Shaharil,
    K. A. Bakar, R. Khoshdelniat, G. R. Sinniah, and U. Sarwar, “Performance evaluation
    of 6LoWPAN-based precision agriculture,” in The International Conference on Information
    Networking 2011 (ICOIN2011), Kuala Lumpur, Malaysia, Jan. 2011, pp. 171–176. doi:
    10.1109/ICOIN.2011.5723173. A. Augustin, J. Yi, T. Clausen, and W. Townsley, “A
    Study of LoRa: Long Range & Low Power Networks for the Internet of Things,” Sensors,
    vol. 16, no. 9, p. 1466, Sep. 2016, doi: 10.3390/s16091466. M. A. Ertürk, M. A.
    Aydın, M. T. Büyükakkaşlar, and H. Evirgen, “A Survey on LoRaWAN Architecture,
    Protocol and Technologies,” Future Internet, vol. 11, no. 10, p. 216, Oct. 2019,
    doi: 10.3390/fi11100216. F. Adelantado, X. Vilajosana, P. Tuset-Peiro, B. Martinez,
    J. Melia-Segui, and T. Watteyne, “Understanding the Limits of LoRaWAN,” IEEE Commun.
    Mag., vol. 55, no. 9, pp. 34–40, 2017, doi: 10.1109/MCOM.2017.1600613. S.-C. Hung,
    H. Hsu, S.-Y. Lien, and K.-C. Chen, “Architecture Harmonization Between Cloud
    Radio Access Networks and Fog Networks,” IEEE Access, vol. 3, pp. 3019–3034, 2015,
    doi: 10.1109/ACCESS.2015.2509638. S. Kitanov, E. Monteiro, and T. Janevski, “5G
    and the Fog—Survey of related technologies and research directions,” in 2016 18th
    Mediterranean Electrotechnical Conference (MELECON), Lemesos, Apr. 2016, pp. 1–6.
    doi: 10.1109/MELCON.2016.7495388. T. X. Tran, A. Hajisami, P. Pandey, and D. Pompili,
    “Collaborative Mobile Edge Computing in 5G Networks: New Paradigms, Scenarios,
    and Challenges,” IEEE Commun. Mag., vol. 55, no. 4, pp. 54–61, Apr. 2017, doi:
    10.1109/MCOM.2017.1600863. A. Greasley and C. Owen, “Modelling people’s behaviour
    using discrete-event simulation: a review,” IJOPM, vol. 38, no. 5, pp. 1228–1244,
    May 2018, doi: 10.1108/IJOPM-10-2016-0604. S. Svorobej et al., “Towards Automated
    Data-Driven Model Creation for Cloud Computing Simulation,” presented at the Eighth
    EAI International Conference on Simulation Tools and Techniques, Athens, Greece,
    2015. doi: 10.4108/eai.24-8-2015.2261129. T. Ojha, S. Misra, and N. S. Raghuwanshi,
    “Wireless sensor networks for agriculture: The state-of-the-art in practice and
    future challenges,” Computers and Electronics in Agriculture, vol. 118, pp. 66–84,
    Oct. 2015, doi: 10.1016/j.compag.2015.08.011. K. L. Krishna, J. Madhuri, and K.
    Anuradha, “A ZigBee based energy efficient environmental monitoring alerting and
    controlling system,” in 2016 International Conference on Information Communication
    and Embedded Systems (ICICES), Chenai, Tamilnadu, India, Feb. 2016, pp. 1–7. doi:
    10.1109/ICICES.2016.7518849. J. Gutierrez, J. F. Villa-Medina, A. Nieto-Garibay,
    and M. A. Porta-Gandara, “Automated Irrigation System Using a Wireless Sensor
    Network and GPRS Module,” IEEE Trans. Instrum. Meas., vol. 63, no. 1, pp. 166–176,
    Jan. 2014, doi: 10.1109/TIM.2013.2276487. S. Premkumar and A. Sigappi, “A Survey
    of Architecture, Framework and Algorithms for Resource Management in Edge Computing,”
    EAI Endorsed Transactions on Energy Web, p. 167788, Jul. 2018, doi: 10.4108/eai.23-12-2020.167788.
    Y. Mao, J. Zhang, and K. B. Letaief, “Joint Task Offloading Scheduling and Transmit
    Power Allocation for Mobile-Edge Computing Systems,” in 2017 IEEE Wireless Communications
    and Networking Conference (WCNC), San Francisco, CA, USA, Mar. 2017, pp. 1–6.
    doi: 10.1109/WCNC.2017.7925615. H. Gupta, A. Vahid Dastjerdi, S. K. Ghosh, and
    R. Buyya, “iFogSim: A toolkit for modeling and simulation of resource management
    techniques in the Internet of Things, Edge and Fog computing environments: iFogSim:
    A toolkit for modeling and simulation of internet of things,” Softw. Pract. Exper.,
    vol. 47, no. 9, pp. 1275–1296, Sep. 2017, doi: 10.1002/spe.2509. PDF HTML Published
    2022-02-04 How to Cite Premkumar, S. ., & Sigappi, A. . (2022). ASIS Edge Computing
    Model to Determine the Communication Protocols for IoT Based Irrigation. Journal
    of Mobile Multimedia, 18(03), 885–916. https://doi.org/10.13052/jmm1550-4646.18321
    More Citation Formats Issue 2022: Vol 18 Iss 3 Section Computer Vision and its
    Application in Agriculture Pavlos Lazaridis and Philippa Jefferies discuss his
    work in beyond 5G research, what we can expect from future 6G technologies, and
    the issues we face with security and privacy 2020 Best Paper Award SNR-Based Early
    Warning Message Scheme for VANETs - MuathObaidat, IhsasnShahwan, Ahmed Hassebo,
    SuhaibObeidat, Mohamed Ali and MatlubaKhodjaeva User-Friendly Privacy-Preserving
    Photo Sharing on Online Social Networks - Khalid Alemerien ISSN: 1550-4646 (Print
    Version) ISSN: 1550-4654 (Online Version) Hybrid Journal Make a Submission Subscription
    Indexed in: BFI Google Scholar CrossREF DBLP SCOPUS EI Compendex SCMAGO  "'
  inline_citation: '>'
  journal: Journal of Mobile Multimedia
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: ASIS Edge Computing Model to Determine the Communication Protocols for IoT
    Based Irrigation
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Majumdar P.
  - Mitra S.
  - Bhattacharya D.
  citation_count: '13'
  description: 'Purpose: The main focus is to concisely cover contemporary methods
    of IoT-oriented agriculture automation using weather monitoring. In this article,
    IoT components, communication protocols, data analysis and prediction methods
    are studied to reveal scientific and commercial perspectives like security vulnerabilities
    of communication protocols, cost of IoT hardware, data repository comparison,
    and dependency analysis of weather parameters. Reasons for striving towards Agriculture
    4.0 are discussed to outline challenges for researchers to adjust irrigation schedules
    as per non-linear weather changes for developing an economically viable, real-time
    monitoring method. Methods: Weather monitoring using IoT technologies for data
    processing and storage are extensively surveyed. Besides, we also reviewed how
    these approaches are enhanced using Agriculture 4.0 for different crops. Results:
    Extensive survey reveals shortcomings of existing approaches and shows that temperature
    and humidity are most commonly monitored in IoT technologies. Cost analysis shows
    minimum cost incurred for hardware is 1–10$ for machine learning and edge computing
    and 10–20$ for cloud computing. Conclusions: Cost analysis helps to identify cheaper
    sensors and micro-controllers for prediction of weather changes. Weather parameters
    that were given least importance in existing literature needs consideration to
    understand how its non-linearity impacts the accuracy of irrigation schedule prediction
    to maximize soil fertility and crop yield.'
  doi: 10.1007/s42853-021-00118-6
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Log in Find a journal Publish
    with us Track your research Search Cart Home Journal of Biosystems Engineering
    Article IoT for Promoting Agriculture 4.0: a Review from the Perspective of Weather
    Monitoring, Yield Prediction, Security of WSN Protocols, and Hardware Cost Analysis
    Review Published: 25 November 2021 Volume 46, pages 440–461, (2021) Cite this
    article Journal of Biosystems Engineering Aims and scope Submit manuscript Parijata
    Majumdar, Sanjoy Mitra & Diptendu Bhattacharya  519 Accesses 10 Citations Explore
    all metrics Abstract Purpose The main focus is to concisely cover contemporary
    methods of IoT-oriented agriculture automation using weather monitoring. In this
    article, IoT components, communication protocols, data analysis and prediction
    methods are studied to reveal scientific and commercial perspectives like security
    vulnerabilities of communication protocols, cost of IoT hardware, data repository
    comparison, and dependency analysis of weather parameters. Reasons for striving
    towards Agriculture 4.0 are discussed to outline challenges for researchers to
    adjust irrigation schedules as per non-linear weather changes for developing an
    economically viable, real-time monitoring method. Methods Weather monitoring using
    IoT technologies for data processing and storage are extensively surveyed. Besides,
    we also reviewed how these approaches are enhanced using Agriculture 4.0 for different
    crops. Results Extensive survey reveals shortcomings of existing approaches and
    shows that temperature and humidity are most commonly monitored in IoT technologies.
    Cost analysis shows minimum cost incurred for hardware is 1–10$ for machine learning
    and edge computing and 10–20$ for cloud computing. Conclusions Cost analysis helps
    to identify cheaper sensors and micro-controllers for prediction of weather changes.
    Weather parameters that were given least importance in existing literature needs
    consideration to understand how its non-linearity impacts the accuracy of irrigation
    schedule prediction to maximize soil fertility and crop yield. This is a preview
    of subscription content, log in via an institution to check access.  Similar content
    being viewed by others Precision Agriculture: Methodologies, Practices and Applications
    Chapter © 2021 A Review on Advances in IoT-Based Technologies for Smart Agricultural
    System Chapter © 2022 A Review of Precision Agriculture Methodologies, Challenges,
    and Applications Chapter © 2022 Data Availability Data sharing not applicable
    to this article as no datasets were generated or analyzed during the current study.
    Code Availability As this is a review article, availability of code is not applicable.
    References Adafruit.DHT11 Humidity & Temperature Sensor. Retrieved September 16
    2021, from https://media.digikey.com/pdf/Data%20Sheets/Adafruit%20PDFs/DHT11_HumidityTempSensor.pdf
    Adafruit.DHT11, DHT22 and AM2302 Sensors. Retrieved September 15 2021, from https://www.mouser.com/datasheet/2/737/dht-932870.pdf
    Aosong. Your specialist in innovating humidity & temperature sensors. Retrieved
    September 15 2021, from https://www.mouser.com/datasheet/2/758/DHT11-Technical-Data-Sheet-Translated-Version-1143054.pdf
    Aosong. Digital-output relative humidity & temperature sensor/module DHT22 (DHT22
    also named as AM2302). Retrieved September 15 2021, from https://drive.google.com/file/d/1tCdHqpqrSVxErr2hDKtHlwJCxdQX4jC/view
    Apogee. APOGEE PYRANOMETERS Silicon-cell & Thermopile Series.Retrieved September
    15 2021, from https://www.apogeeinstruments.com/content/SP-100-200-spec-sheet.pdf
    Apogee. BMP180 Sensor: Pinout, Feature, Specification [Video]. Retrieved September
    14 2021, from https://www.apogeeweb.net/pdf/circuitry/bmp180-pinout-feature-specification.pdf
    Angelopoulos, C. M., Filios, S., Nikoletseas, T. P., Raptis 2020 Keeping data
    at the edge of smart irrigation networks: A case study in strawberry greenhouses
    Computer Networks 167 107039 https://doi.org/10.1016/j.comnet.2019.107039 Article   Google
    Scholar   Araújo, S. O., Peres, R. S., Barata, J., Lidon, F., & Ramalho, J. C.
    (2021). Characterising the Agriculture 4.0 Landscape—Emerging Trends, Challenges
    and Opportunities. Agronomy, 11(4), 667. Arko, A. R., Khan, S. H., Biswas, M.
    H., Imran, A., Kafi, A. H., & Antara, R. S. I. (2019). IOT Based Smart Water And
    Environment Management System Of Paddy Rice At Different Growth Stages. In: Proceedings
    of IEEE International Conference on Internet of Things and Intelligence System
    (IoTaIS), pp.154-160, Bali, Indonesia. https://doi.org/10.1109/IoTaIS47347.2019.8980424
    BHARATHI ELECTRONICS. HUMIDITY & TEMPERATURE SENSOR (HRT393). RETRIEVED SEPTEMBER
    14 2021, FROM https://www.indiamart.com/proddetail/humidity-temperature-sensor-hrt393-7138775788.html
    BOSCH.BMP 180 Digital, barometric pressure sensor. Retrieved September 14 2021,
    from https://ae-bst.resource.bosch.com/media/_tech/media/product_flyer/BST-BMP180-FL000.pdf
    Brito, R C., Favarim, F., Calin, G., Todt, E. (2017). Development of a low cost
    weather station using free hardware and software. In: Proceedings of Latin American
    Robotics Symposium (LARS) and Brazilian Symposium on Robotics (SBR), pp. 1–6,
    Curitiba, Brazil. https://doi.org/10.1109/SBR-LARS-R.2017.8215292 Chawla, A.,
    Bangera, T., Kolwalkar, C., & Bhat, M. Bluetooth based weather station. (2015).
    International Journal of Engineering Trends and Technology (IJETT), 28(2). Chu,
    Z., Yu, J. 2020 An end-to-end model for rice yield prediction using deep learning
    fusion Computers and Electronics in Agriculture 174 105471 https://doi.org/10.1016/j.compag.2020.105471
    Article   Google Scholar   de Araujo Zanella, A. R., da Silva, E., & Albini, L.
    C. P.( (2020). Security challenges to smart agriculture: Current state, key issues,
    and future directions. Array, 100048. Divya Vani, P., Raghavendra Rao, K. (2016).
    Measurement and Monitoring of Soil Moisture using Cloud IoT and Android System.
    Indian Journal of Science and Technology, 9(31), 1–5. https://doi.org/10.17485/ijst/2016/v9i31/95340
    De Medeiros, A. D., Capobiango, N. P., da Silva, J. M., da Silva, L. J., da Silva,
    C. B., Santos Dias dos, D. C. F. 2020 Interactive machine learning for soybean
    seed and seedling quality classification Scientific Reports 10 1 1 10 https://doi.org/10.1038/s41598-020-68273-y
    Article   Google Scholar   Feng, P., Wang, B., Li Liu, D., Waters, C., Xiao, D.,
    Shi, L., Yu, Q. 2020 Dynamic wheat yield forecasts are improved by a hybrid approach
    using a biophysical model and machine learning technique Agricultural and Forest
    Meteorology 285 107922 https://doi.org/10.1016/j.agrformet.2020.107922 Article   Google
    Scholar   Goap, A., Sharma, D., Shukla, A. K., Krishna, C. R. 2018 An IoT based
    smart irrigation management system using Machine learning and open source technologies
    Computers and Electronics in Agriculture 155 41 49 Article   Google Scholar   Gia,
    T N., Qingqing, L., Queralta, J P., Zou, Z., Tenhunen, H., Westerlund, T. (2019).
    Edge AI in Smart Farming IoT: CNNs at the Edge and Fog Computing with LoRa. In:
    Proceedings of IEEE AFRICON, pp. 1–6, Accra, Ghana. https://doi.org/10.1109/AFRICON46755.2019.9134049
    Goeschel, K.( 2016). Reducing false positives in intrusion detection systems using
    data-mining techniques utilizing support vector machines, decision trees, and
    naive Bayes for off-line analysis. In: South east Con, pp. 1-6. IEEE. Guillén,
    M. A., Llanes, A., Imbernón, B., Martínez-España, R., Bueno-Crespo, A., Cano,
    J. C., Cecilia, J. M. 2021 Performance evaluation of edge-computing platforms
    for the prediction of low temperatures in agriculture using deep learning Journal
    of Supercomputing 77 1 818 840 https://doi.org/10.1007/s11227-020-03288-w Article   Google
    Scholar   Halder, S., Sivakumar, G. (2017). Embedded based remote monitoring station
    for live streaming of temperature and humidity. In: Proceedings of International
    Conference on Electrical, Electronics, Communication, Computer, and Optimization
    Techniques (ICEECCOT), pp. 284–287, Mysuru, India. https://doi.org/10.1109/ICEECCOT.2017.8284683
    HANWEI. Technical data MQ-135 gas sensor. Retrieved September 17 2021, from https://www.rhydolabz.com/documents/MQ135_datasheet_m.pdf
    HANWEI. Technical data MQ-7 gas sensor. Retrieved September 17 2021, from http://
    edge. rit. edu/edge/R13401/public/FinalDocuments/Monitor/Appendix%20B%20Sensors.pdf
    Han, G., Xiao, L., & Poor, H. V. (2017). Two-dimensional anti-jamming communication
    based on deep reinforcement learning. In: IEEE international conference on acoustics,
    speech and signal processing (ICASSP), pp. 2087-2091. IEEE. Herrero-Huerta, M.,
    Rodriguez-Gonzalvez, P., & Rainey, K. M. (2020). Yield prediction by machine learning
    from UAS-based multi-sensor data fusion in soybean. Plant Methods, 16, 1-16. https://doi.org/10.21203/rs.3.rs-16958/v2
    Juan Carlos, A. D., Estrada, L. R., Cesar Augusto, C. R. C., Patricia, A. C. P.,
    Alberto, P. M. M., Enrique, R. G. R., Morales-Ortega, R. C., Ovallos-Gazabon,
    D. A., Andrés, C. M. C. 2020 Monitoring system of environmental variables for
    a strawberry crop using IoT tools Procedia Computer Science 170 1083 1089 https://doi.org/10.1016/j.procs.2020.03.067
    Article   Google Scholar   Kaewwongsri, K., & Silanon, K. (2020). Design and implement
    of a weather monitoring station using CoAP on NB-IoT network. In: 17th International
    Conference on Electrical Engineering/Electronics, Computer, Telecommunications
    and Information Technology (ECTI-CON), 230-233. IEEE. Kamir, E., Waldner, F.,
    Hochman, Z. 2020 Estimating wheat yields in Australia using climate records, satellite
    image time series and machine learning methods Isprs Journal of Photogrammetry
    and Remote Sensing 160 124 135 https://doi.org/10.1016/j.isprsjprs.2019.11.008
    Article   Google Scholar   KEMET.DHT11–Temperature and Humidity Sensor. Retrieved
    September 17 2021, from https://components101.com/sensors/dht11-temperature-sensor
    Keswani, B., Mohapatra, A. G., Keswani, P., Khanna, A., Gupta, D., Rodrigues,
    J. 2020 Improving weather dependent zone specific irrigation control scheme in
    IoT and big data enabled self driven precision agriculture mechanism Enterprise
    Information Systems 14 9–10 1494 1515 https://doi.org/10.1080/17517575.2020.1713406
    Article   Google Scholar   Kodali, R. K., Sahu, A. (2016). An IoT based weather
    information prototype using WeMos. In 2nd International Conference on Contemporary
    Computing and Informatics (IC3I), pp. 612–616, Greater Noida, India. https://doi.org/10.1109/IC3I.2016.7918036
    Kulkarni, S., Mandal, S. N., Sharma, G. S., & Mundada, M. R. (2018). Predictive
    analysis to improve crop yield using a neural network model. In: Proceedings of
    IEEE International Conference on Advances in Computing, Communications and Informatics(ICACCI),pp.74-79,Bangalore,India.
    https://doi.org/10.1109/ICACCI.2018.8554851 Lee, S. Y., Wi, S. R., Seo, E., Jung,
    J. K., & Chung, T. M. (2017). ProFiOt: Abnormal Behavior Profiling (ABP) of IoT
    devices based on a machine learning approach. In: 27th International Telecommunication
    Networks and Applications Conference (ITNAC), pp.1-6. IEEE. Maimaitijiang, M.,
    Sagan, V., Sidike, P., Hartling, S., Esposito, F., & Fritschi, F.B. (2020). Soybean
    yield prediction from UAV using multimodal data fusion and deep learning. Remote
    sensing of environment, 237, 111599. Micron .Technical data MQ-135 gas sensor.
    Retrieved September 19, 2021, from https://pdf.indiamart.com/impdf/20922240373/MY-9380557/mq-135-air-quality-hazardous-gas-sensor-module.pdf
    Micron. Technical data MQ-7 gas sensor. Retrieved September 17 2021, from https://
    pdf.indiamart.com/impdf/11396433388/MY-1833510/mq-7-carbon-monoxide-gas- sensors.pdf
    MICRON. DHT 22 SENSOR. RETRIEVED SEPTEMBER 15 2021, FROM https://www.indiamart.com/proddetail/dht-22-sensor-20917848512.html
    Narudin, F. A., Feizollah, A., Anuar, N. B., Gani, A. 2016 Evaluation of machine
    learning classifiers for mobile malware detection Soft Computing 20 1 343 357
    Article   Google Scholar   Nevavuori, P., Narra, N., Lipping, T. 2019 Crop yield
    prediction with deep convolutional neural networks Computers and Electronics in
    Agriculture 163 104859 https://doi.org/10.1016/j.rse.2019.111599 Article   Google
    Scholar   Palle, D., Kommu, A., Kanchi R.R. (2016). Design and development of
    CC3200-based CloudIoT for measuring humidity and temperature. In: Proceedings
    of International Conference on Electrical, Electronics and Optimization Techniques
    (ICEEOT), pp. 3116–3120, Chennai, India. https://doi.org/10.1109/ICEEOT.2016.7755275
    Parashar, A. (2019) IoT Based Automated Weather Report Generation and Prediction
    Using Machine Learning. In: Proceedings of 2nd International Conference on Intelligent
    Communication and Computational Techniques (ICCT), pp. 339–344, Jaipur, India.
    https://doi.org/10.1109/ICCT46177.2019.8968782 Pathak., A., AmazUddin, M., Abedin,
    M. J., Andersson, K., Mustafa, R., Hossain, M. S. 2019 IoT based Smart System
    to Support Agricultural Parameters: A Case Study Procedia Computer Science 155
    648 653 https://doi.org/10.1016/j.procs.2019.08.092 Article   Google Scholar   Patil,
    P., & Desai, B. L., (2013). Intelligent irrigation control system by employing
    wireless sensor networks. International Journal of Computer Applications, 79(11).
    Photon System Instruments.TECHNICAL SPECIFICATION SpectraPen SP 110 UVIS SpectraPen
    SP 110 NIR. Retrieved September 15 2021, from https://handheld.psi.cz/documents/specifications/SP.pdf
    Rahmat, R. F., Lini, T. Z., & Hizriadi, A. (2019). Implementation of real-time
    monitoring on agricultural land of rice plants using smart sensor. In: Proceedings
    of Conference on Electrical, Telecommunication and Computer Engineering (ELTICOM),
    pp. 40-43, Medan, Indonesia. https://doi.org/10.1109/ELTICOM47379.2019.8943912
    Raj, M., Gupta, S., Chamola, V., Elhence, A., Garg, T., Atiquzzaman, M., & Niyato,
    D. (2021). A survey on the role of internet of things for adopting and promoting
    agriculture 4.0. Journal of Network and Computer Applications, 187, 1–29. https://doi.org/10.1016/j.jnca.2021.103107.
    Ruano, A.E., Mestre, G., Duarte, H. (2015). A neural-network based intelligent
    weather station. In: Proceedings of IEEE 9th International Symposium on Intelligent
    Signal Processing (WISP), pp. 1–6, Siena, Italy. https://doi.org/10.1109/WISP.2015.7139169
    Sabharwal, N., Kumar, R., Thakur, A., & Sharma, J. A. (2014). Low Cost Zigbee
    Basedautomatic Wireless Weather Station With Gui And Web Hosting Facility. International
    Journal of Electrical and Electronics Engineering, 1. Sahay, M.R, Sukumaran, M.K,
    Amarnath, S., Palani, TND. (2019). Environmental Monitoring System Using IoT and
    Cloud Service at Real-Time. Easy Chair, 968. Saini, H., Thakur, A., Ahuja, S.
    Sabharwal, N., & Kumar, N. (2016). Arduino based automatic wireless weather station
    with remote graphical application and alerts. In: Proceedings of 3rd International
    Conference on Signal Processing and Integrated Networks (SPIN), pp. 605–609, Noida,
    India. https://doi.org/10.1109/SPIN.2016.7566768 Savic, T., Radonjic, M. (2015).
    One approach to weather station design based on Raspberry Pi platform. In: Proceedings
    of 23rd Telecommunications Forum Telfor, pp. 623–626, Belgrade, Serbia. https://doi.org/10.1109/TELFOR.2015.7377544
    Shang, C., Chen, W. H., Stroock, A. D., You, F. 2019 Robust model predictive control
    of irrigation systems with active uncertainty learning and data analytics IEEE
    Transactions on Control Systems Technology 28 4 1493 1504 Article   Google Scholar   Shaout,
    A., Yulong, Li., Zhou, M., Awad, S. (2014). Low cost embedded weather station
    with intelligent system. In: Proceedings of 10th International Computer Engineering
    Conference(ICENCO),pp.100–106,Giza,Cairo,Egypt. https://doi.org/10.1109/ICENCO.2014.7050439
    Singh Debabrata, Pal Pushparaj, Mishra, M.K, Lamba, A. (2020). Shrabanee Swagatika
    Security threats and issues in automation IoT. International Journal of Scientific
    & Technology Research, 9(4). SKYPOWER INTERNATIONALS.SP 110 FI TS. Retrieved September
    15 2021, from https:// skypower.online/produkt/sp-110-fi-ts/ Solano, G., Lama,
    F., Terrazos, J., Tarrillo, J. (2017). Weather station for educational purposes
    based on Atmega8L. In: Proceedings of IEEE XXIV International Conference on Electronics,
    Electrical Engineering and Computing (INTERCON), pp. 1–4, Cusco, Peru. https://doi.org/10.1109/INTERCON.2017.8079728
    Sowah, R. A., Ofori-Amanfo, K. B., Mills, G. A., & Koumadi, K. M.( 2019). Detection
    and prevention of man-in-the-middle spoofing attacks in MANETs using predictive
    techniques in Artificial Neural Networks (ANN). Journal of Computer Networks and
    Communications. Stas, M., Van Orshoven, J., Dong, Q., Heremans, S., & Zhang, B.
    (2016). A comparison of machine learning algorithms for regional wheat yield prediction
    using NDVI time series of SPOT-VGT. In: Proceedings of IEEE Fifth International
    Conference on Agro-Geoinformatics(Agro-Geoinformatics),pp.1-5,Tianjin,China. https://doi.org/10.1109/Agro-Geoinformatics.2016.7577625
    Tahsien, S. M., Karimipour, H., Spachos, P. 2020 Machine learning based solutions
    for security of Internet of Things (IoT): A survey Journal of Network and Computer
    Applications 161 102630 https://doi.org/10.1016/j.jnca.2020.102630 Article   Google
    Scholar   TekParks. COLLECTION Home / MODULES / SENSOR MODULES / HUMIDITY SENSOR
    MODULE (HRT393). Retrieved September 14 2021, from http://www.tekparts.in/product/humidity-sensor-module-hrt393/
    Texas Insruments. BOOSTXL-SENSHUBSensorHubBoosterPack. Retrieved September 14
    2021, from https://pdf1.alldatasheet.com/datasheet-pdf/view/514264/TI1/BMP180.html
    Tenzin, S., Siyang, S., Pobkrut, T., Kerdcharoen, T. (2017). Low cost weather
    station for climate smart agriculture. In: Proceedings of 9th International Conference
    on Knowledge and Smart Technology (KST), pp.172–177, Chonburi, Thailand.https://doi.org/10.1109/KST.2017.7886085
    Wei, M. C. F., Molin, J. P. 2020 Soybean Yield Estimation and Its Components:
    A Linear Regression Approach Agriculture 10 8 348 https://doi.org/10.3390/agriculture10080348
    Article   Google Scholar   Winsen. Air Quality gas Sensor (Model: MQ135). Retrieved
    September 18, 2021, from https://www.winsen-sensor.com/d/files/PDF/Semiconductor%20Gas%20Sensor
    /MQ135%20(Ver1.4)%20-%20Manual.pdf Winsen. Carbon Monoxide Gas Sensor(Model:MQ-7B).
    Retrieved September 17 2021, from https://www.winsensensor.com/d/files/PDF/Semiconductor%20Gas%20Sensor/MQ-7B%20(Ver1.4)%20-%20Manual.pdf
    Zamora-Izquierdo, M. A., Santa, J., Martínez, J. A., Martínez, V., Skarmeta, A.
    F. 2019 Smart farming IoT platform based on edge and cloud computing Biosystems
    Engineering 177 4 17 https://doi.org/10.1016/j.biosystemseng.2018.10.014 Article   Google
    Scholar   Zhai, Z., Martínez, J. F., Beltran, V., & Martínez, N. L. (2020). Decision
    support systems for agriculture 4.0: Survey and challenges. Computers and Electronics
    in Agriculture, 170, 105256. https://doi.org/10.1016/j.compag.2020.105256 Download
    references Acknowledgement None of the Authors received any financial support
    from any funding agency to carry out this research work. Computing Infrastructure
    of Tripura Institute of Technology, Agartala as well as National Institute of
    Technology, Agartala, was used to prepare this review article. Funding This research
    is not supported or sponsored by any funding agency. (i) The authors have no relevant
    financial or non-financial interests to disclose. (ii) The authors have no conflicts
    of interest to declare that are relevant to the content of this article. (iii)
    All authors certify that they have no affiliations with or involvement in any
    organization or entity with any financial interest or non-financial interest in
    the subject matter or materials discussed in this manuscript. (iv) The authors
    have no financial or proprietary interests in any material discussed in this article.
    Author information Authors and Affiliations National Institute of Technology,
    Agartala, West Tripura, 799046, India Parijata Majumdar & Diptendu Bhattacharya
    Tripura Institute of Technology, Agartala, West Tripura, 799009, India Sanjoy
    Mitra Contributions (i) Conceptualization of idea of the article: P.M. and S.M.
    (ii) Literature search and data analysis: S.M. and P.M. (iii) Resources: D.B and
    S.M. (iv) Writing—original draft preparation: P.M. and S.M. (v) Writing—review
    and editing: P.M., S.M. and D.B. (vi) Critical revision of the work: D.B. and
    S.M. (vii) Supervision: D.B., S.M. Corresponding author Correspondence to Sanjoy
    Mitra. Ethics declarations Ethics Approval This article does not contain any studies
    with human participants or animals performed by any of the authors. Consent to
    Participate Not applicable since the article does not contain any studies with
    human participants. Consent to Publication Not applicable since the article does
    not contain any images, or videos relating to an individual person. Conflict of
    Interest The authors have no conflicts of interest to declare that are relevant
    to the content of this article. The authors declare that they have no known competing
    financial interests or personal relationships that could have appeared to influence
    the work reported in this paper. It is given in detail in declaration section
    of this manuscript. Additional information Publisher’s Note Springer Nature remains
    neutral with regard to jurisdictional claims in published maps and institutional
    affiliations. Rights and permissions Reprints and permissions About this article
    Cite this article Majumdar, P., Mitra, S. & Bhattacharya, D. IoT for Promoting
    Agriculture 4.0: a Review from the Perspective of Weather Monitoring, Yield Prediction,
    Security of WSN Protocols, and Hardware Cost Analysis. J. Biosyst. Eng. 46, 440–461
    (2021). https://doi.org/10.1007/s42853-021-00118-6 Download citation Received
    07 June 2021 Revised 23 September 2021 Accepted 18 October 2021 Published 25 November
    2021 Issue Date December 2021 DOI https://doi.org/10.1007/s42853-021-00118-6 Keywords
    Agriculture 4.0 Cloud Edge Machine learning Weather Access this article Log in
    via an institution Buy article PDF USD 39.95 Price excludes VAT (USA) Tax calculation
    will be finalised during checkout. Instant access to the full article PDF. Rent
    this article via DeepDyve Institutional subscriptions Sections Figures References
    Abstract Data Availability Code Availability References Acknowledgement Funding
    Author information Ethics declarations Additional information Rights and permissions
    About this article Advertisement Discover content Journals A-Z Books A-Z Publish
    with us Publish your research Open access publishing Products and services Our
    products Librarians Societies Partners and advertisers Our imprints Springer Nature
    Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your
    US state privacy rights Accessibility statement Terms and conditions Privacy policy
    Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814)
    - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Journal of Biosystems Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'IoT for Promoting Agriculture 4.0: a Review from the Perspective of Weather
    Monitoring, Yield Prediction, Security of WSN Protocols, and Hardware Cost Analysis'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Solioz B.
  - Mudry P.A.
  citation_count: '0'
  description: In this paper, we present a novel non-invasive water flow metering
    technique that is cheap and exhibits decent performance. Targeting mainly irrigation
    monitoring, the technique has been applied to create a prototype measuring apparatus
    consisting of a small, battery operated board that includes both a vibration and
    an acceleration sensor. Data acquired from those sensors is then processed on-board
    via a neural-network that has been pre-trained and calibrated in the lab. The
    inferred water flow rate is then transmitted via LoRaWAN to a data back-end for
    further processing. With this device, we demonstrated that for a total cost of
    less than 18 €, our prototype communicating sensor could run for a complete irrigation
    season on 2 AAA batteries with data sent every 20 minutes. Regarding the performance
    of this AI-augmented sensor, the results exhibit less than 10% of error for most
    flow rates when compared to a fully calibrated, lab-grade water flow meter, with
    potential for improvement.
  doi: null
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: CEUR Workshop Proceedings
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A Low-Cost Water Flow Meter on the Edge using Machine Learning
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Gueye Y.
  - Mbaye M.
  citation_count: '1'
  description: 'Agronomists deal with challenges to determinate ideal parameters (e.g.,
    soil moisture, temperature, etc.) to grow each variety of plants according to
    the nature of soil and climate zone. Traditional method consists in having experimental
    farms in which different conditions are created to discover which environmental
    and chemical conditions enable maximizing yield for each variety of seed. This
    process is fastidious and accuracy of results is difficult to evaluate. In this
    paper, we propose an Edge AI Internet of Things (IoT) framework for agronomic
    experimentations and will the solution be cost efficient, easy to deploy, low
    maintenance, and robust, which makes it very appealing in the African context.
    Our proposal is composed of three segments: experimental farm zone (Lab) where
    sensors and actuators network are deployed, a set of data collection and processing
    gateways called Edge AI-IoT Nodes which implements Edge Machine Learning Models,
    and Cloud and Fog segment that provides a social network and services for agronomic
    experts. Social network is an interface for agronomic experts that allow them
    to follow data collected from experimental farms and for cross validation of results
    around the world. For the purpose of illustration two use cases are presented:
    plant leaf disease detection using machine learning; and smart automated irrigation
    with IoT framework.'
  doi: 10.1007/978-3-030-90556-9_9
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart International Conference on Research
    in Computer Science and its Applications CNRIA 2021: Research in Computer Science
    and Its Applications pp 101–112Cite as Home Research in Computer Science and Its
    Applications Conference paper eFarm-Lab: Edge AI-IoT Framework for Agronomic Labs
    Experiments Youssouph Gueye & Maïssa Mbaye   Conference paper First Online: 04
    November 2021 146 Accesses 1 Citations Part of the book series: Lecture Notes
    of the Institute for Computer Sciences, Social Informatics and Telecommunications
    Engineering ((LNICST,volume 400)) Abstract Agronomists deal with challenges to
    determinate ideal parameters (e.g., soil moisture, temperature, etc.) to grow
    each variety of plants according to the nature of soil and climate zone. Traditional
    method consists in having experimental farms in which different conditions are
    created to discover which environmental and chemical conditions enable maximizing
    yield for each variety of seed. This process is fastidious and accuracy of results
    is difficult to evaluate. In this paper, we propose an Edge AI Internet of Things
    (IoT) framework for agronomic experimentations and will the solution be cost efficient,
    easy to deploy, low maintenance, and robust, which makes it very appealing in
    the African context. Our proposal is composed of three segments: experimental
    farm zone (Lab) where sensors and actuators network are deployed, a set of data
    collection and processing gateways called Edge AI-IoT Nodes which implements Edge
    Machine Learning Models, and Cloud and Fog segment that provides a social network
    and services for agronomic experts. Social network is an interface for agronomic
    experts that allow them to follow data collected from experimental farms and for
    cross validation of results around the world. For the purpose of illustration
    two use cases are presented: plant leaf disease detection using machine learning;
    and smart automated irrigation with IoT framework. Keywords AI-IoT Edge computing
    Smart-agriculture Smart-irrigation Machine learning Experimental farms Plant Leaf
    Disease Detection ICT4D Access provided by University of Nebraska-Lincoln. Download
    conference paper PDF 1 Introduction Internet of Things (IoT) based Smart-Agriculture
    is a fast-emerging research and development field with wide range of applications.
    It consists in using in farming sensors or Unmanned Aerial Vehicles (UAV) to collect
    data on farm’s physical environment (soil moisture, pH., temperature, wind speed,
    electrical conductivity, etc.) and actuators connected to communication system.
    The result can be a decision-support systems (such as proper amount of nitrogen,
    phosphorus, potassium, etc.), optimization system of farming resources (water,
    fertilizers, insecticides, etc.) [5], farming monitoring systems (such as detecting
    plant stress, wheat diseases, pests, and weeds), automated irrigation system.
    However, the optimizing tasks and early agronomic research are less addressed
    by IoT in specific areas in Africa. Indeed, African agronomic researchers and
    engineers have less opportunities to experiment with a large variety of Farms-Labs
    environments a large variety of Farms-Labs environments. IoT and AI tools on the
    edge can be very valuable [13, 17]. For instance, an IoT based automated irrigation
    system wouldn’t be efficient without taking into account threshold of dry and
    moisture that can be supported by plants in the field. Agronomic Engineers might
    need systems that assist them to monitor their testing farms and provide support
    in analyzing produced data. This is even more relevant in the African context
    where there is a lack of agronomists experts and an inefficiency due to outdated
    and/or out of context data. Traditional IoT architectures composed of IoT Core
    network and cloud computing resources are not suitable in the Sub-Saharan Africa
    area. The main reasons include the followings: firstly these architectures require
    centralization in a Cloud as well as good network coverage in the experimental
    fields [14]. Secondly, rural areas in Sub-Saharan Africa suffers from low network
    coverage and available bandwidth. This makes it very difficult to consider developing
    centralized architecture. Finally, national agronomic research structures do not
    have much means to support large scale tests over a long period of time. In this
    paper we propose an Edge AI-IoT framework for experimental agriculture that we
    call eFarm-Lab. Basically, the use of IoT, Edge, and AI in agriculture is not
    new [7, 16]. However, in our knowledge, using a framework for studying agronomic
    conditions in experimental farms is something new as far as we know. The general
    principle is that the framework is designed to allow, on the fly, machine learning
    modelling and deployment of models on Edge Nodes to assist local agronomic researchers
    in their experimental labs. So the outcome of this proposal targets experimentation
    farms, not production ones. For instance, to study growth phases of a plant, sensors
    (cameras, humidity sensors, etc.) can be deployed to monitor the height of the
    plant and other agronomic parameters, and use machine learning models to better
    know the needs of the plant. eFarm-Lab is composed of three segments : Simple
    IoT sensors and actuators network; a set of Edge-AI-IoT nodes implementing machine
    learning models for experimentation; and finally Cloud architecture. A social
    network of agronomic experts as oracles can help labelling data and enhance quality
    of learning. Social network is an interface for agronomic experts that allow them
    to follow plants evolution using pictures captured by platform and for cross validation
    of results by agronomist community. 2 Related Works There are several works in
    the field of smart agriculture based on IoT eventually with AI. Topics covers
    from Smart Irrigation systems [3, 9, 12], Monitoring and information collection
    systems [9, 11], Crops Protection systems and data analysis [15] and plan disease
    detection [4]. Main network technologies are WiFi, WiMAX, LR-WPAN, GSM-Based,
    Bluetooth, LoRa, SigFox, NB-IoT. Bu et al. [6] use deep Reinforcement learning
    in IoT network for Smart agriculture. In this work, computations are centralized
    on the cloud. Angelopoulos et al. in [2] propose an Edge computing architecture
    to reduce the traffic between the IoT network and cloud. Ahmed Imteaj et al. proposed
    a system that is able to detect the appropriate time to water the field according
    to the soil moisture and the intensity of light. The system can also monitor irrigation
    level to prevent accumulation of water around tree roots and send a text message
    to the farmer in case of lack of water [12]. In [3], authors presents different
    technologies that can be used in the implementation of an automatic irrigation
    system for saving water using the Internet of Things. In this article, authors
    use Zigbee for communication between the sensors and the actuator. Authors of
    paper [9] designed a basic system based on the Internet and the cloud technologies.
    LI-FI technology is used to provide communication between the sensors and the
    data collection server. It is used to collect all the information on the field
    and to send on the cloud using GPRS or WIMAX as a transmission medium.  [1] has
    proposed smart farming using automation and IoT technology. The authors have implemented
    a GPS-based remote-controlled vehicle that will perform several tasks in the field
    and in the warehouse. Her tasks include scaring birds and animals, detecting soil
    moisture, spraying fertilizers and pesticides, weeding, detecting soil moisture,
    and so on. If we sum up, all these papers about smart agriculture try to enhance
    agriculture inside production farms. However, before automating irrigation, or
    detecting plant disease, thresholds must be tested out by agronomist engineers.
    Our objective in this paper is to design an Edge AI-IoT framework for experimenting
    farm conditions for development of varieties of plants in an uncontrolled environment.
    This point is very relevant for Sub-Saharan Africa since there is not enough agronomist
    experts to realise this kind of experimentation. A second aspect of our proposal
    is it includes a social network of experts in agronomy in order to test different
    conditions of farming and remotely validated the best ones. 3 Our Proposition
    3.1 General Architecture of Proposed Framework eFarmLab is composed of three segments
    (Fig. 1): Experimentation farm domain that contains sensors and actuators network,
    Edge AI-IoT Nodes for small AI training and model deployment and Cloud/Fog for
    larger machine learning models training and dataset storage. The experimentation
    farm area contains a set of plant squares, each corresponding to a specific agronomic
    experience (seed selection, disease study, plant need, etc.). The different squares
    can reproduce the same conditions or environment for experimenting and/or monitoring
    plant evolution (Fig. 2). These area contains plants and network of end nodes
    (sensors and actuators network). Sensor and actuator network is a set of nodes
    that embed sensors for collecting data or modifying environmental conditions via
    actuator to create different conditions in experimental field (such as starting
    watering). This network collects data about plant environment parameters like
    thresholds, soil moisture, plant appearance with camera, and communicate with
    Edge AI-IoT Nodes. Fig. 1. General architecture for Edge AI-IoT framework Full
    size image These sensor-actuator-nodes can manage multiple sensors depending on
    the need of monitoring. More concretely, if expert wants to explore the stress
    level of the plant according to the aridity conditions on the maps, it would be
    possible to use one or more cameras to monitor the general appearance of the plant.
    Fig. 2. Example of experimental farm captured at Saint-Louis/Senegal Full size
    image The Edge AI-IoT Nodes (Gateway) act as interface between the sensor and
    actuator network, and the agronomic experts web based interface through the Internet.
    These nodes have the role of hosting the intelligence of the network. Intelligence
    is represented by training lightweight machine learning models but also receiving
    the deployment of models that come from the fog computing part. This can be implemented
    by existing Edge AI platforms (Raspberry Pi, Nvidia Jetson Nano, etc.) with or
    without a GPU. Tiny Machine Learning models can be trained directly on Edge AI-IoT
    Node for ROI (Region of Interest) detection (KNN, KMeans, etc.). We will provide
    an example of directly trained machine learning model on Edge Node. To allow the
    deployment of more complex models these nodes host environment containers so that
    they do not have compatibility issues in running or deployed models. This enables
    hot deployment and programming of the AI-IoT Edge node. Finally the Fog/Cloud
    segment has more computing and storage resources to store larger datasets and
    train more complex/greedy machine learning algorithms such as CNN. The output
    models can be deployed on the Edge AI-IoT Nodes. Agronomists experts use web based
    interface (social network) to evaluate the result of the machine learning services
    or enhancing them. With this platform, it could be allowed expert to participate
    in experimentations by comparing aspects of the plants at different moment. In
    this way, they can indicate to platform if it is doing well or not. Access devices
    could be tablets, smartphones and computers. The aim of this overall architecture
    is to automate testing and monitoring for agronomist while giving them possibility
    to participate on model enhancement. 3.2 Machine Learning Deployment on the Edge
    IoT Machine learning tools are deployed in different places in the network. On
    the Cloud-Computing/fog part where there are more storage and computing resources
    available, machine learning algorithms are trained on large data sets in order
    to produce the best models according to what the agronomist expert seeks to study.
    For example, if the objective of the platform is to detect the presence or absence
    of disease of a plant from leaves in the Fog part, we will have a dataset of leaves
    of diseased or healthy plants. These models are created using well-known machine
    learning algorithms such as SVM, KNN, KMeans, CNN Machine learning models are
    mainly represented as classifiers, decisions trees, equations, inference rules,
    etc. Once the model is validated, it can be deployed to any Edge node it has enough
    resources. Deployment can be done using containers instead of traditional virtual
    machines because they are lighter to deploy and consume less computing and storage
    resources. This functionality makes it possible to deploy machine models in any
    equipment, knowing that the context. In the next session we will illustrate use
    cases of the deployment. 3.3 AI on the Edge for Experimental Fields Edge KMeans
    Kernel-Learning for Plant Leaf Disease Detection. Plant diseases result in an
    alteration of the plant which modifies or interrupts its vital functions such
    as photosynthesis, transpiration, pollination, fertilization, germination, etc.
    Manifestations of the disease are usually seen on the leaves, fruits and stems
    of the plant. This can have a very big impact on the yield of the plant. In this
    use case we consider the context of an agronomist who wants to study a disease
    that manifests itself in the leaves automatically. Edge AI-IoT Node, in this case
    embed a KMeans Kernel-Learning model to assist agronomic expert for plant leaf
    disease detection after a short number of interactions with the system. The principle
    of KMeans Kernel Learning consists in creating KMeans models trained with selected
    images (Kernel Images). The clusters resulting from these Kernel Images are called
    Kernel Clusters and are then labelled diseased zones or healthy zones [8]. This
    would help the expert extracting diseased area even if it is almost visible (Fig.
    3). Fig. 3. KMeans Kernel learning clustering Full size image More formally, considering
    \\(\\textit{I}_{k0}\\) a Kernel Image chosen we have the Eq. (1): $$\\begin{aligned}
    KMeans(I_{k0} ) = \\big \\{ \\varphi _{k0}, \\varOmega _{k0} \\big \\} \\end{aligned}$$
    (1) Where \\(\\varphi _{k0}\\) is the KMeans Kernel Model clustering model based
    on the \\(\\textit{I}_{k0}\\) kernel image and \\(\\varOmega _{k0}\\) is the set
    of cluster centroids and their labels as a healthy or disease regions of the plant
    leaf. \\(\\varOmega _{k0}\\) is defined by Eq. (2): $$\\begin{aligned} \\varOmega
    _{k0} = \\big \\{( \\omega _{i,k0},label )/i \\in [0-3], label \\in \\big \\{health,
    diseased\\big \\} \\big \\} \\end{aligned}$$ (2) Where \\(\\omega _{i,k0}\\) is
    the centroid of the cluster number i (related to \\(I_{k0}\\)) and the label indicates
    if the cluster formed from this centroid belongs to a diseased region or healthy.
    We make the assumption that by taking the one cluster that contains most significant
    disease region we can make decision about the health of the plant leave. So only
    one cluster is labelled diseased and we always refer to it by \\(\\omega _{2},_{k0}\\).
    The framework uses Kernel Image \\(\\textit{I}_{k0}\\) which is supposed to have
    representative features of a diseased plant leaf. This Kernel Image is used to
    build a KMean Kernel Model \\(\\varphi _{k0}\\) and Kernel Clusters \\(\\omega
    _{i},_{k0};\\mathrm{i}\\in [0,3]\\). Each cluster can be labelled healthy or diseased.
    In our context we orient KMeans algorithm so the cluster that contains most of
    diseased region is always named \\(\\omega _{2},_{k0}\\). KMean Kernel Models
    are just classifiers based on KMean that have been trained with data composed
    by Kernel Image pixels components (Fig. 4). We limited the number of clusters
    to 4 because we observed that the number of empty clusters increases when \\(K\\ge
    4\\). Fig. 4. Segmented plant leaf with four clusters Full size image The KMean
    algorithm identifies the cluster containing the largest diseased part. Agronomic
    experts can at this stage tag a few clusters of a few plants to indicate which
    ones represent a diseased part. The system can present in the social network clusters
    such as in Fig. 4 so they can retag them if necessary. As experimentation we use
    Plant Village DataSet [10] wich is composed of plant leaf images that are segmented.
    The aim was to design a model for plant leaf disease detection based on Kernel
    KMeans. We selected 1474 images of diseased plant leaves and 1129 images of healthy
    plant leaves. For the training/testing split we used 80%/20%. For implementation
    of Kernel KMeans we used popular Sci-kitLearn, Pandas, openCV and matplotlib.
    The results of the test on multiple samples of plant leaf images is presented
    by the following table.   Precision Recall F1-score Support Diseased leaves 0.93
    0.95 0.94 1474 Healthy leaves 0.93 0.90 0.91 1129 The model is fast and accurate
    without much help from experts. The precision is about 95% while accuracy is 93%.
    It exists machine learning models that are more accurate and the purpose was not
    to compete in term of accuracy. However it can be a decision support and monitoring
    tool for agronomic expert. 3.4 Use Case: Smart Irrigation Experimental Farm Fig.
    5. Architecture for Edge AI-IoT network smart irrigation experimentation Full
    size image Each plant has its ideal environmental conditions for instance for
    tomatoes soil moisture should be between 60% and 80%. To discover this kind of
    information, agronomic tests are done in specialized experimentation farms where
    different environment conditions can reproduced. Challenging task is to reproduce
    results for a large number of plant varieties in uncontrolled outdoor environment.
    To address this problem, as a second use case we propose that experimentation
    fields are divided into five numbered zones (Fig. 5): \\(Z_0\\) to \\(Z_4\\).
    In each zone, we have a sensors and actuators network that help to learn thresholds
    for ideal conditions. All zones are connected to one gateway. With this layout,
    system should learn four thresholds (Fig. 5): \\(Z_0\\): this is the reference
    zone of our field with a soil moisture threshold that can ensure a good development
    of the plant. We will therefore compare this zone (\\(Z_0\\)) with the other zones
    (\\(Z_1, Z_2, Z_3, Z_4\\)) to see which zones have a humidity that favors or alters
    the appearance of the plant; \\(Z_1\\): the minimum threshold that negatively
    affects the appearance of the plant with a humidity of 40% compared to \\(Z_0\\);
    \\(Z_2\\): in \\(Z_2\\) the minimum moisture threshold that retains the same appearance
    of the plant as that found in the reference zone; \\(Z_3\\): the limit threshold
    which makes it look better than that of the reference plant; \\(Z_4\\): the optimal
    threshold which gives a very good appearance and a better qualitative transformation
    of the plant compared to \\(Z_0\\); Figure 6 below illustrates the result that
    our algorithm should provide after the experimental phase of studying our plant.
    The experimentation is done almost remotely. Fig. 6. Example of expected result
    in the case of tomato Full size image In this use case, model is an algorithm
    executed by Edge node and that have double inputs: one from sensor network, other
    from social network of agronomic experts. The algorithm collects data from sensor
    network and makes decisions according to feedback events from experts in social
    network part. Indeed, when sensor network does an action (start watering for instance),
    after a while, it needs to get feedback from agronomic experts which are considered
    as oracles to tell if this action has positives effect or not. Algorithm 1 executes
    a main loop. First step is the IoT node takes a picture of plant and send it to
    social network of experts. Agronomic experts give a feedback that is actually
    of an appreciation of the action of gateway regarding to plant development. The
    possible feedback events are: \\(State_1\\)- plant with the same appearance as
    the reference \\(Z_0\\) \\(State_2\\)- plant in a state of degradation in comparison
    to \\(Z_0\\) \\(State_3\\)- better appearance of the plant in comparison to \\(Z_0\\)
    \\(State_4\\)- Substantial improvement in the appearance of the plant in comparison
    to \\(Z_0\\). As an example, when gateway sends a picture of plants in all zones
    to experts’ social network. Experts answer with feedbacks that are represented
    by \\(Z_i\\) and notifies to the gateway that all plants have the same aspect
    in all zones (\\(state_1\\)). This is to say that the plants have the same appearance
    in comparison to \\(Z_0\\) and thus watering is stopped in zones \\(Z_1\\) and
    \\(Z_2\\), but continues \\(Z_3\\) and \\(Z_4\\). 4 Conclusion and Future Works
    In this paper we proposed an Edge AI-IoT framework for experimental agriculture
    that we call eFarm-Lab. The general principle is that the framework is designed
    to allow, on the fly machine learning model training and deployment of models
    on Edge nodes to asssist agronomic experts in their experimental labs. eFarm-Lab
    is composed of three kind of nodes: IoT (sensors and actuators) network; a set
    of Edge-AI-IoT nodes implementing machine learning models; and finally Cloud architecture.
    A social network of agronomic experts as oracles can help labelling data and enhance
    quality of learning. We exhibited two use cases where this framework can be deployed
    for agronomic experimentation. The first is related to plant leaf disease detection
    and we implemented it to show the proof of concept. And finally the smart irrigation
    use case to illustrate how the social network of expert can be used to enhance
    remote testing. The next step is to deploy a real testbed to see the behavior
    of deploying an Edge node with controllers encapsulating machine learning models.
    References Amandeep et al.: Smart farming using IOT. In: 2017 8th IEEE Annual
    Information Technology, Electronics and Mobile Communication Conference (IEMCON),
    Vancouver, BC, pp. 278–280 (2017). https://doi.org/10.1109/IEMCON.2017.8117219
    Angelopoulos, C.M., Filios, G., Nikoletseas, S., Raptis, T.P.: Keeping data at
    the edge of smart irrigation networks: a case study in strawberry greenhouses.
    Comput. Netw., 107039 (2019). https://doi.org/10.1016/j.comnet.2019.107039 Anjana,
    S., Sahana, M.N., Ankith, S., Natarajan, K., Shobha, K.R.: An IoT based 6LoWPAN
    enabled experiment for water management. In: IEEE ANTS 2015 1570192963, Bangalore,
    India, pp. 1–6 (2015) Google Scholar   Ashok, S., Kishore, G., Rajesh, V., Suchitra,
    S., Sophia, S.G.G., Pavithra, B.: Tomato Leaf disease detection using deep learning
    techniques. In: 2020 5th IEEE, International Conference on Communication and Electronics
    Systems (ICCES), Coimbatore, India, pp. 979–983 (2020) Google Scholar   Boursianis,
    A.D., Papadopoulou, M.S., et al.: Internet of Things (IoT) and agricultural unmanned
    aerial vehicles (UAVs) in smart farming: a comprehensive review. Internet Things,
    100187 (2020). https://doi.org/10.1016/j.iot.2020.100187 Bu, F., Wang, X.: A smart
    agriculture IoT system based on deep reinforcement learning. Futur. Gener. Comput.
    Syst. (2019). https://doi.org/10.1016/j.future.2019.04.041 Article   Google Scholar   Calo,
    S.B., Touna, M., Verma, D.C., Cullen, A.: Edge computing architecture for applying
    AI to IoT. In: 2017 IEEE International Conference on Big Data (Big Data) (2017).
    https://doi.org/10.1109/bigdata.2017.8258272 Gueye, Y., Mbaye, M., et al.: KMeans
    Kernel-learning based AI-IoT framework for plant leaf disease detection. In: Hacid,
    H. (ed.) ICSOC 2020. LNCS, vol. 12632, pp. 549–563. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-76352-7_49
    Chapter   Google Scholar   Mekala, M.S., Viswanathan, P.: A novel technology for
    smart agriculture based on IoT with cloud computing. In: 2017 International Conference
    on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), Palladam, pp.
    75–82 (2017). https://doi.org/10.1109/I-SMAC.2017.8058280 Pandian, J.A., Geetharamani,
    G.: Data for: identification of plant leaf diseases using a 9-layer deep convolutional
    neural network. Mendeley Data, V1 (2019). https://doi.org/10.17632/tywbtsjrjv.1
    Prathibha, SR., Hongal, A.: IoT based monitoring system in smart agriculture.
    In: 2017 International Conference on Recent Advances in Electronics and Communication
    Technology, pp. 81–84 (2017) Google Scholar   Ahmed, I.T., Rahman, M.K.: IoT based
    autonomous percipient irrigation system using Raspberry Pi. In: 19th International
    Conference on Computer and Information Technology, North South University, Dhaka,
    Bangladesh, 18–20 December 2016, pp. 563–568 (2016) Google Scholar   Ran, X.,
    Chen, H., Zhu, X., Liu, Z., Chen, J.: DeepDecision: a mobile deep learning framework
    for edge video analytics. In: 2018 IEEE Conference on Computer Communications
    (INFOCOM 2018), pp. 1421–1429 (2018) Google Scholar   Roopaei, M., Rad, P., Choo,
    K.-K.R.: Cloud of things in smart agriculture: intelligent irrigation monitoring
    by thermal imaging. IEEE Cloud Comput. 4(1), 10–15 (2017). https://doi.org/10.1109/mcc.2017.5
    Article   Google Scholar   Sarjerao, R.K.: a low cost smart irrigation system
    using MQTT protocol. In: 2017 IEEE Region 10 Symposium (TENSYMP) (2017) Google
    Scholar   Shi, W., Cao, J., Zhang, Q., Li, Y., Xu, L.: Edge computing: vision
    and challenges. IEEE Internet Things J. 3(5), 637–646 (2016). https://doi.org/10.1109/jiot.2016.2579198
    Huang, Y., Ma, X., Fan, X., et al.: When deep learning meets edge computing. In:
    IEEE 25th International Conference on Network Protocols (ICNP 2017), pp. 1–2 (2017)
    Google Scholar   Download references Author information Authors and Affiliations
    LANI (Laboratoire D’Analyse Numérique et Informatique), Université Gaston Berger
    de Saint-Louis, Saint-Louis, Senegal Youssouph Gueye & Maïssa Mbaye Corresponding
    author Correspondence to Maïssa Mbaye . Editor information Editors and Affiliations
    Université Assane Seckde, Ziguinchor, Senegal Youssou Faye Carnegie Mellon University
    Africa, Kigali, Rwanda Assane Gueye Université Cheikh Anta Diop, Dakar, Senegal
    Bamba Gueye Université Gaston Berger de Saint Louis, Saint Louis, Senegal Dame
    Diongue École Supérieure Polytechnique (ESP), Dakar, Senegal El Hadji Mamadou
    Nguer Université Virtuelle du Sénégal (UVS), Dakar, Senegal Mandicou Ba Rights
    and permissions Reprints and permissions Copyright information © 2021 ICST Institute
    for Computer Sciences, Social Informatics and Telecommunications Engineering About
    this paper Cite this paper Gueye, Y., Mbaye, M. (2021). eFarm-Lab: Edge AI-IoT
    Framework for Agronomic Labs Experiments. In: Faye, Y., Gueye, A., Gueye, B.,
    Diongue, D., Nguer, E.H.M., Ba, M. (eds) Research in Computer Science and Its
    Applications. CNRIA 2021. Lecture Notes of the Institute for Computer Sciences,
    Social Informatics and Telecommunications Engineering, vol 400. Springer, Cham.
    https://doi.org/10.1007/978-3-030-90556-9_9 Download citation .RIS.ENW.BIB DOI
    https://doi.org/10.1007/978-3-030-90556-9_9 Published 04 November 2021 Publisher
    Name Springer, Cham Print ISBN 978-3-030-90555-2 Online ISBN 978-3-030-90556-9
    eBook Packages Computer Science Computer Science (R0) Share this paper Anyone
    you share the following link with will be able to read this content: Get shareable
    link Provided by the Springer Nature SharedIt content-sharing initiative Publish
    with us Policies and ethics Download book PDF Download book EPUB Sections Figures
    References Abstract Introduction Related Works Our Proposition Conclusion and
    Future Works References Author information Editor information Rights and permissions
    Copyright information About this paper Publish with us Discover content Journals
    A-Z Books A-Z Publish with us Publish your research Open access publishing Products
    and services Our products Librarians Societies Partners and advertisers Our imprints
    Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage
    cookies Your US state privacy rights Accessibility statement Terms and conditions
    Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA)
    (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Lecture Notes of the Institute for Computer Sciences, Social-Informatics
    and Telecommunications Engineering, LNICST
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'eFarm-Lab: Edge AI-IoT Framework for Agronomic Labs Experiments'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Alharbi H.A.
  - Aldossary M.
  citation_count: '51'
  description: The current agriculture systems compete to take advantage of industry
    advanced technologies, including the internet of things (IoT), cloud/fog/edge
    computing, artificial intelligence, and agricultural robots to monitor, track,
    analyze and process various functions and services in real-time. Additionally,
    these technologies can make the agricultural processes smarter and more cost-efficient
    by using automated systems and eliminating any human interventions, hence enhancing
    agricultural production to meet future expectations. Although the current agriculture
    systems that adopt the traditional cloud-based architecture have provided powerful
    computing infrastructure to distributed IoT sensors. However, the cost of energy
    consumption associated with transferring heterogeneous data over the multiple
    network tiers to process, analyze and store the sensor's information in the cloud
    has created a huge load on information and communication infrastructure. Besides,
    the energy consumed by cloud data centers has an environmental impact associated
    with using non-clean fuels, which usually release carbon emissions (CO2) to produce
    electricity. Thus, to tackle these issues, we propose a new integrated edge-fog-cloud
    architectural paradigm that promises to enhance the energy-efficient of smart
    agriculture systems and corresponding carbon emissions. This architecture allows
    data collection from several sensors to process and analyze the agriculture data
    that require real-time operation (e.g., weather temperature, soil moisture, soil
    acidity, irrigation, etc.) in several layers (edge, fog, and cloud). Thus, the
    real-time processing could be held by the edge and fog layers to reduce the load
    on the cloud layer, which will help to enhance the overall energy consumption
    and process the agriculture applications/services efficiently. Mathematical modeling
    is conducted using mixed-integer linear programming (MILP) for a smart agriculture
    environment, where the proposed architecture is implemented, and results are analyzed
    and compared to the traditional implementation. According to the results of thousands
    of agriculture sensors, the proposed architecture outperforms the traditional
    cloud-based architecture in terms of reducing the overall energy consumption by
    36% and the carbon emissions by 43%. In addition to these achievements, the results
    show that our proposed architecture can reduce network traffic by up to 86%, which
    can reduce network congestion. Finally, we develop a heuristic algorithm to validate
    and mimic the presented approach, and it shows comparable results to the MILP
    model.
  doi: 10.1109/ACCESS.2021.3101397
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 9 Energy-Efficient
    Edge-Fog-Cloud Architecture for IoT-Based Smart Agriculture Environment Publisher:
    IEEE Cite This PDF Hatem A. Alharbi; Mohammad Aldossary All Authors 50 Cites in
    Papers 5123 Full Text Views Open Access Comment(s) Under a Creative Commons License
    Abstract Document Sections I. Introduction II. Proposed Architecture for Smart
    Agriculture System III. MILP Model IV. MILP Model Design V. Results and Discussion
    Show Full Outline Authors Figures References Citations Keywords Metrics Abstract:
    The current agriculture systems compete to take advantage of industry advanced
    technologies, including the internet of things (IoT), cloud/fog/edge computing,
    artificial intelligence, and agricultural robots to monitor, track, analyze and
    process various functions and services in real-time. Additionally, these technologies
    can make the agricultural processes smarter and more cost-efficient by using automated
    systems and eliminating any human interventions, hence enhancing agricultural
    production to meet future expectations. Although the current agriculture systems
    that adopt the traditional cloud-based architecture have provided powerful computing
    infrastructure to distributed IoT sensors. However, the cost of energy consumption
    associated with transferring heterogeneous data over the multiple network tiers
    to process, analyze and store the sensor''s information in the cloud has created
    a huge load on information and communication infrastructure. Besides, the energy
    consumed by cloud data centers has an environmental impact associated with using
    non-clean fuels, which usually release carbon emissions (CO 2 ) to produce electricity.
    Thus, to tackle these issues, we propose a new integrated edge-fog-cloud architectural
    paradigm that promises to enhance the energy-efficient of smart agriculture systems
    and corresponding carbon emissions. This architecture allows data collection from
    several sensors to process and analyze the agriculture data that require real-time
    operation (e.g., weather temperature, soil moisture, soil acidity, irrigation,
    etc.) in several layers (edge, fog, and cloud). Thus, the real-time processing
    could be held by the edge and fog layers to reduce the load on the cloud layer,
    which will help to enhance the overall energy consumption and process the agriculture
    applications/services efficiently. Mathematical modeling is conducted using mixed-integer
    linear programming (MILP) for a smart agriculture environment, where the proposed
    architecture is imp... (Show More) An IoT-based edge-fog-cloud architecture for
    smart agriculture system. Published in: IEEE Access ( Volume: 9) Page(s): 110480
    - 110492 Date of Publication: 30 July 2021 Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2021.3101397
    Publisher: IEEE Funding Agency: CCBY - IEEE is not the copyright holder of this
    material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/
    to obtain full-text articles and stipulations in the API documentation. SECTION
    I. Introduction The Internet of Things (IoT) is one of the emerging technologies
    that promise to transform the way on how people work and live. The term IoT refers
    to a network of physical objects “things” that contain embedded systems with connectivity
    and computing power to exchange data with other devices and systems over the Internet.
    By 2025, the number of IoT devices connected to the Internet is projected to be
    100 billion, with an economic impact of more than $ 11 trillion [1]. The recent
    development of IoT devices presents a new dimension in the agriculture field,
    where the IoT has become an ideal choice for smart agriculture due to its highly
    scalable and ubiquitous architecture. Moreover, the IoT-based smart agriculture
    value is estimated to reach $ 18.45 billion in 2022, and 75 million IoT devices
    are used for the agricultural sector in 2020 [2]. Furthermore, smart farms are
    projected to have 12 million IoT points by 2023 [3]. Smart agriculture has started
    incorporating IoT solutions to improve operational efficiency, maximize yield,
    and minimize wastage through real-time field data collection, data analysis, and
    deployment of control mechanisms. Also, the diverse of IoT-based applications
    such as precision farming and smart irrigation is very helpful to the enhancement
    of agricultural processes. Thus, the IoT is considered as one of the promising
    solutions for embracing connected farms to address agriculture-based issues and
    increase the quality and quantity of agricultural production. IoT solutions are
    highly associated with cloud computing to process the huge amount of heterogeneous
    data sent or received by agriculture sensors/actuators [4]. Although cloud computing
    can handle smart agriculture applications, some of the applications and services
    produce a large amount of data and need to be processed in a real-time manner,
    which may cause a heavy load on the network, long response time, and poor quality
    of service, due to limited bandwidth [5]. Therefore, using the traditional cloud-based
    architecture may not be efficient to support these applications, which may also
    result in high energy consumption due to the transfer of agriculture data to and
    from the cloud. The Information and Communication Technology (ICT) industry is
    projected to account for 20% of the global electricity demand by 2025 [5]–[8],
    [9]. Usually, consuming electricity is accompanied by carbon emissions (CO2).
    fossil fuel usage is the primary source of CO2 [10]. Consequently, this causes
    the growth of carbon dioxide emissions. According to [11], ICT uses 730 Million
    ton (Mt) CO2 equivalents (CO2e) or 1.4% of worldwide carbon emissions. To overcome
    the above shortcomings, edge and fog computing architecture are introduced to
    process the real-time IoT applications and services at the proximity of data sources
    in an efficient way, which have several benefits (e.g., reduce energy consumption,
    network traffic and improve quality of service) compared to traditional cloud-based
    architecture, that does not exploit the latest paradigms such as fog and edge
    in the agriculture system [4], [6]. However, edge and fog computing are not a
    replacement for cloud computing, as cloud computing will still be preferable and
    suitable for analyzing and processing heavy tasks, as well as storing data in
    a long term. The collaboration between edge, fog, and cloud computing is the best
    practice to achieve smart agriculture solutions. Several related works in the
    literature, (e.g. in [12], [13]), have discussed various architectures, techniques,
    and methods applied for smart agriculture systems considering different technologies
    such as IoT, big data analytics, and cloud computing. However, none of the existing
    works focused on the edge-fog-cloud architecture intending to reduce the energy
    consumption, CO2 emission, and network traffic as considering the three computing
    layers (edge, fog, and cloud). Therefore, this paper presents a new approach for
    smart agriculture systems to develop an energy-efficient offloading of IoT agriculture
    applications over an edge-fog-cloud computing architecture, according to the resource
    requirements of each agriculture task. Also, this approach could help to enhance
    the solutions of many traditional agriculture issues by taking the advantage of
    edge and fog computing, which will improve the overall energy efficiency and reduce
    CO2 emission, network traffic of smart agriculture systems. The major contributions
    of this paper are summarized as follows: ∙ Develop an energy-efficient architecture
    based on mathematical modeling and heuristic algorithm to study the offloading
    of IoT applications from agriculture sensors to edge, fog, and geo-distributed
    cloud, while considering minimization of the overall power consumption of networking
    and processing of the IoT agriculture services. ∙ Optimize the offloading of IoT
    agriculture applications over an edge-fog-cloud architecture, which connected
    to the access network, metro area network, and wide area network, respectively,
    thus eliminating the associated power consumption and telecommunication network
    traffic. ∙ Evaluate the usability and the capability of the proposed architecture
    and its models, using the mixed-integer linear programming (MILP) model, and compared
    the results to the traditional approach. The remainder of this paper is organized
    as follows: Section II introduces the edge-fog-cloud system architecture and its
    interaction layers. Section III presents the mixed-integer linear programming
    (MILP) model for optimizing the offloading of IoT agriculture applications in
    the edge-fog-cloud architecture. The model’s design, scenarios, and the input
    parameters of the models are presented in Section IV. This is followed by discussing
    the optimization model results and analysis in Section V. In Section VI, we introduce
    energy-efficient agriculture IoT applications distribution heuristic over the
    edge-fog-cloud architecture (EEAIOT-EFC). Finally, Section VII concludes the paper
    and discusses future work. SECTION II. Proposed Architecture for Smart Agriculture
    System Today, the traditional cloud-based architecture for agriculture systems
    is inefficient to satisfy all the requirements of the current scenarios [4], [5],
    [7], [8], as it lacks the essential efficiency prerequisites such as energy consumption,
    CO2 emission, network traffic, and so on [6]. Consequently, there is a need to
    develop an energy-efficient architecture for a smart agriculture system to fulfill
    these requirements. This section provides an outline of the proposed edge-fog-cloud
    architecture and its role in providing dynamicity and efficiency based on different
    IoT agriculture applications. The proposed architecture of the smart agriculture
    system is shown in Fig. 1; and it consists of four essential layers, namely, IoT
    sensor layer, edge layer, fog layer, and cloud layer. The description of each
    layer of the proposed architecture is presented as follow: FIGURE 1. An IoT-based
    edge-fog-cloud architecture for smart agriculture system. Show All A. IoT Sensor
    Layer IoT sensors generate massive heterogeneous data to the gateways by using
    various sensors deployed in different areas of the agriculture field. Also, this
    layer can receive decisions from to control actuators (e.g., turning on/off irrigation
    system) [14]. In smart agriculture, there is a range of IoT sensor nodes used
    to identify several phenomena over the urban areas including but not limited to
    soil pH, soil temperature, soil moisture, soil electrical conductivity, and ambient
    temperature [15]. In the IoT agriculture system, low power wide area (LPWA) technologies
    have paved the way due to their low power consumption and wide area coverage.
    Long range (LoRa) is proved its efficiency, as a transmission protocol for IoT
    sensors. Besides its low power consumption, it ensures an extent of 10 kilometers
    coverage or more. In addition to LoRa, multiple wireless technologies can be used
    for smart agriculture urban areas such as narrowband (NB)-IoT, WiFi, Zigbee, and
    the 5G. The Zigbee technology has been successfully used in the field of agriculture
    at a low power cost. However, the limited distance coverage for wireless data
    transferring (about 20 meters) is reducing its efficiency. A comprehensive comparison
    of different IoT wireless network technologies (Zigbee, LoRa, NB-IoT, and 5G),
    is presented in Table 1. TABLE 1 IoT Wireless Network Technologies Comparison
    B. Edge Layer Edge computing refers to a new computing model that implements the
    computation of sensors/actuators data at the edge of the network. With this concept,
    some applications and services that do not require a lot of computing resources
    can be processed in the edge layer (close to the data source) and no longer need
    to traverse the network to be processed by the fog or the cloud. Thus, edge computing
    can improve data transmission performance, ensure real-time processing, and reduce
    the computational load as well as the amount of data transmitted to and from the
    fog or cloud data centers [8]. However, in case of unavailability/unsuitability
    of the resources in the edge layer, the sensors will automatically request to
    process their data in the fog or the cloud, and this will be done hierarchically.
    C. Fog Layer The fog computing concept was initially proposed by Cisco in 2014
    to expand the resources of cloud computing to the edge of the telecommunications
    network. In this context, the fog layer has the responsibility to process and
    analyze data sent from IoT sensors, which helps to minimize the latency for agriculture
    applications and services. Also, the fog layer has the ability to process and
    analyze complex data more than the edge layer. Both fog and edge can provide computation,
    networking, and storage services in between the sensor layer and the cloud layer.
    It means that instead of executing all processing at the cloud layer, the fog
    and edge layers can process and analyze agricultural data locally and close to
    the sensor layer (based on their ability) to reduce latency and cost [5], [7].
    D. Cloud Layer At the same level of importance as edge and fog, cloud computing
    is a vital enabler for the growth of IoT agriculture applications. It offers on-demand
    computing resources and services (e.g., storage, networking, and processing) in
    a scalable way. The cloud layer handles the agriculture data received from the
    sensor layer or the fog layer to process, analyze and store them into the cloud.
    Cloud computing can process and analyze heavy data, that requires more complex
    operations (e.g., big data processing and predictive analysis like weather forecasting,
    fire warning, and soil droughting), which exceeds the fog computing capability
    [6]. Also, it could provide a large-scale secure platform and cheap data storage
    services for the IoT agriculture applications [5], [8]. E. Telecommunication Networks
    The traditional telecommunication network architecture consists of three layers
    [16]: the core layer, the metro layer, and the access network layer. The wide
    area network (WAN) is the key network infrastructure that provides interconnection
    between different regions and cities. The Internet protocol (IP) over wavelength
    division multiplexing (WDM) is widely implemented in the core network as it can
    provide high scalability, large capacity, and fast communication network transfer
    speeds. Based on the reference hierarchy in Fig. 1, every core network has a direct
    connection with a metro area network (MAN), which covers a metropolitan area.
    Metro Ethernet is the technology commonly used in the metro network. It offers
    connectivity between the core network and users located in the access network.
    The local area network (LAN) supports Internet access to numerous user premises.
    We adopted the passive optical networks (PONs) which considered as the leading
    networking in the LAN network. SECTION III. MILP Model In this section, a new
    approach is developed based on mathematical mixed-integer linear programming (MILP)
    optimization model to study the energy-efficiency of offloading IoT agriculture
    applications over an edge-fog-cloud architecture, considering the three telecom
    network layers: LAN equipped with an edge layer, MAN equipped with a fog layer
    and the WAN equipped with a cloud layer. In the following, we introduce the parameters
    and variables of our proposed architecture. The architecture consists of the IoT
    sensor, edge, fog, and cloud layers. Then, we provide the mathematical model to
    find the optimum distribution of IoT agriculture applications to serve the offloaded
    requests from the IoT sensor layer based on their energy consumption over an edge-fog-cloud
    architecture. A. IoT Sensor Layer The parameters and variables that represent
    the IoT sensor layer, are shown in Tables 2 and 3. TABLE 2 IoT Parameters TABLE
    3 IoT Variables IoT sensor layer power consumption (IoT) is composed of: ( ∑ s∈i
    IoT (number) s IoT (power) ) +( ∑ s∈i GW (number) s IoT (power) ) (1) View Source
    Equation (1) calculates the total power consumption of the IoT sensor layer, including
    IoT sensors and gateway devices. B. Edge, Fog, and Cloud Layers The following
    parameters and variables (in Tables 4 and 5) represent the IoT agriculture applications
    that will be placed in the edge, fog, or cloud layers, as well as the resulted
    traffic and power consumption. TABLE 4 Cloud, Fog, and Edge Networking and Processing
    Parameters TABLE 5 Cloud, Fog and Edge Networking and Processing Variables The
    power consumption of cloud/fog/edge nodes consist of: Cloud layer power consumption
    (Cloud): PUE (cloud) ( ∑ s∈N MIPS iot i,s PPMIPS (cloud) + ∑ s∈N PPbits (cloud)
    TU s,d )∀s=c (2) View Source Power consumption of fog layer (Fog): PUE (fog) (
    ∑ s∈N MIPS iot i,s PPMIPS (fog) + ∑ s∈N PPbits (fog) TU s,d )∀s=f (3) View Source
    Power consumption of edge layer (Edge): PUE (edge) ( ∑ s∈N MIPS iot i,s PPMIPS
    (edge) + ∑ s∈N PPbits (edge) TU s,d )∀s=e (4) View Source Equations (2, 3, and
    4) calculate cloud, fog, and edge computing layers total power consumption, including
    processing, and networking devices, taking into consideration the power usage
    effectiveness (PUE) of cloud, fog, and edge layers, respectively. C. Communication
    Networks As described in Section II-E, a typical telecom network is considered
    including WAN, MAN, and LAN networks. The traffic traverse through these layers
    as well as the corresponding power consumption are represented by the parameters
    and variables described below. 1) Local Area Network (LAN) The parameters and
    variables that define the LAN network are shown in Tables 6 and 7. TABLE 6 LAN
    Network Parameters TABLE 7 LAN Network Variables Local area networks power consumption
    (LAN) consists of: Total power consumption of LAN network: PUE (network) ( ∑ s∈N
    ONU (number) s ONU (power) ) +( ∑ s∈N OLT (number) s OLT (power) ) (5) View Source
    Equation (5) calculates the total power consumption of the LAN network, including
    Optical Network Units (ONU) and Optical Line Terminals (OLTs) devices, taking
    into consideration the network PUE. 2) Metro Area Network (MAN) The parameters
    and variables introduced to define the MAN are shown in Tables 8 and 9. TABLE
    8 MAN Parameters TABLE 9 MAN Variables The metro area network power consumption
    (MAN) consists of: PUE (network) (( MR (number) s MR (power) s ) +( MS (number)
    s MS (power) s ))∀s=N (6) View Source Equation (6) calculates the total power
    consumption of the MAN network, including router ports and switch devices, taking
    into consideration the network PUE. 3) Wide Area Network (WAN) The parameters
    and variables introduced to define WAN network are shown in Tables 10 and 11.
    TABLE 10 WAN Network Parameters TABLE 11 WAN Network Variables The wide area network
    ( WAN ) [17] power consumption consists of: PUE (network) ( ∑ d∈N r (power) r
    d + ∑ m∈N ∑ n∈ Nm m :n≠m ∑ s∈N ∑ d∈N:s≠d r s,d m,n t (power) + ∑ m∈N ∑ n∈ Nm m
    :n≠m E (power) F m,n A m,n + ∑ d∈N S (power) d ) (7) View Source Equation (7)
    calculates the total power consumption of the WAN network, including core router
    ports, transponders, amplifiers, and switch devices, taking into consideration
    the network PUE. The MILP model, considering the equations from (1-7), represented
    by the following: The objective: Minimize total power consumption: WAN+MAN+LAN+IoT+Cloud+Fog+Edge
    (8) View Source Expression (8) calculates the power consumption of our proposed
    architecture as the sum of the power consumption of the WAN network, the MAN network,
    the LAN network, IoT, cloud, fog, and edge. Subject to the following constraints:
    IoT offloading constraints: ∑ s,d∈N UI i,s,d = ∑ s,d∈N T iot i,s,d ∀i∈I (9) View
    Source Constraint (9) guarantees that all the IoT offloaded traffic is processed
    at a cloud, fog, or edge destination node. IoT application in edge/fog/cloud constraints:
    ∑ s∈N T iot i,s,d ≥ Ψ i,d ∀d∈N,i∈I ∑ s∈N T iot i,s,d ≤ω Ψ i,d ∀d∈N, i∈I (10) (11)
    View Source Constraints (10) and (11) make sure that the binary variable Ψ i,d
    =1 if processing node d∈N is powered on to place the IoT application i∈I , otherwise
    Ψ i,d =0 . Physical link-activated: L s,d m,n ≥ L s,d m,n ≤ r s,d m,n ∀s,d, m,
    n∈N r s,d m,n ∀s,d, m, n∈N (12) (13) View Source Constraints (12) and (13) ensure
    that the physical link m,n∈c is activated if there is a traffic flow between the
    nodes s,d∈c transmitting through the physical links m,n∈c. Edge, fog, and cloud
    processing requirements: MIPS iot i,d = Ψ i,d MIPS iot i,d ∀d∈N,i∈I MIPS iot d
    = ∑ i∈I MIPS iot i,d ∀d∈N (14) (15) View Source Constraints (14) gives the processing
    requirements of IoT application i∈I in a cloud, a fog, and an edge layer. Constraint
    (15) gives the total processing of a cloud, a fog, and an edge layer d∈N . Traffic
    demand on WAN network: TU s,d = ∑ i∈I T iot i,s,d ∀s,d∈c (16) View Source Constraint
    (16) calculates the demand between WAN nodes due to the IoT applications placed
    in the clouds. Flow conservation constraint: ∑ m∈N:m≠n L s,d m,n − ∑ n∈N:m≠n L
    s,d m,n = ⎧ ⎩ ⎨ L s,d − L s,d 0 i=s i=d otherwise ∀s, d∈N:s≠d (17) View Source
    Constraint (17) define the flow conservation of WAN network. It ensures that the
    total inbound / outbound traffic in all WAN nodes is identical; apart from the
    source/sink nodes. Physical link capacity: ∑ s∈N ∑ d∈N:i≠j L s,d m,n ≤WB F m,n
    ∀m, n∈N (18) View Source Constraints (18) gives the physical link capacity by
    ensuring that the traffic in a link does not exceed the maximum capacity of fibers.
    Total number of router ports in a WAN network node: r d ≥ ∑ s∈c TU s,d B ∀d∈c
    (19) View Source Constraint (19) gives the router ports count at every WAN node.
    Total number of IoT gateways: GW (number) s ≥ IoT (number) s GW (users) ∀s∈i (20)
    View Source Constraint (20) gives the number of used gateways in each farm. Total
    number of ONU terminals: ONU (number) s ≥ ∑ i∈i ∑ d∈N UI i,s,d ONU (bitrate) ∀s∈N
    (21) View Source Constraint (21) gives the number of used ONU terminals in each
    farm. Total number of OLT: OLT (number) s ≥ ∑ i∈I ∑ d∈N UI i,s,d OLT (bitrate)
    ∀s∈N (22) View Source Constraint (22) gives the number of used OLT in node s .
    Total number of MAN routers: MR (number) s ≥2 ∑ i∈i ∑ d∈(f∩c) UI i,s,d MR (bitrate)
    ∀s∈N (23) View Source Constraint (21) gives the number of used routers in each
    MAN network s . Total number of MAN switches: MS (number) s ≥ ∑ i∈i ∑ d∈(f∩c)
    UI i,s,d MS (bitrate) ∀s∈N (24) View Source Constraint (22) gives the number of
    used switches in each MAN network s . Total Traffic in communication network:
    T d = ∑ i∈i ∑ d∈N UI i,s,d ∀s∈N (25) View Source Constraint (23) gives the total
    traffic in each node s . 4) Carbon Emissions (CO2) of IoT-Edge-FOG-Cloud Layers
    Carbon emissions [18] can be defined as the carbon emission intensity per an energy
    consumption and the unit of carbon emission intensity is kgCO2e / kWh. The research
    found that using solar, wind or nuclear plants creates a low carbon footprint
    compared with fossil fuels [19]. However, there are multiple limitations to the
    usage of low carbon sources including but not limited to the cost of installing
    these clean plants. Thus, in this work, we assume that only the IoT sensor layer
    and edge layer are powered by low carbon sources (i.e., solar plants panels) to
    reduce the power consumption of the proposed architecture. In the following Tables
    12 and 13, we define parameters and variables related to carbon emissions. TABLE
    12 Emission Parameters TABLE 13 Emission Variables Total carbon emission (CO)
    is composed of: (WAN O)+(MAN O)+(LAN O)+(IoT S) +(Cloud O)+(Fog O)+(Edge S) (26)
    View Source Considering that IoT sensors, gateway, and edge processing layers
    are powered by solar energy sources. While others are powered by oil energy sources.
    SECTION IV. MILP Model Design In this section we explain the scenarios and the
    design of the model conducted in order to evaluate the proposed architecture.
    A. Scenarios As shown in Fig. 1, different scenarios can be implemented with this
    proposed architecture to show its effectiveness. In this work, the following scenarios
    are considered in a hierarchical order based on the edge, fog, and cloud ability.
    Edge/fog layers can be deployed in the proposed architecture according to the
    resources required by the agriculture tasks. Essentially, all tasks from heterogeneous
    IoT devices/sensors in the agriculture field, using different IoT wireless network
    technologies will be offloaded to the network gateways and then directed to edge/fog
    or cloud layer. Each layer has pros and cons. For example, processing the tasks
    within the edge layer will save the power and traffic cost of request transmission
    from/to the fog or cloud layer. However, handling all types of tasks within the
    edge layer is not possible, as it has limited capacity. Therefore, fog and cloud
    layers can be the choice for processing heavy tasks (e.g., resource-intensive
    applications). In our model, we assume that a scheduler in the gateway of the
    IoT layer checks if the edge node has available resources and can handle the request
    of IoT applications (e.g., CPU capability - the number of million instructions
    per second (MIPS)), the tasks will then pass to the edge layer to process them.
    In case of insufficient/unavailability of processing the tasks in the edge layer,
    the request will be transferred to the fog layer and check if there is enough
    capacity. Otherwise, the tasks will be forwarded to the cloud layer for processing,
    which supports resource-intensive applications. Also, we have assumed that the
    cloud has enough resources and capability to handle all kinds of tasks. B. Input
    Parameters of the Models In the MILP model, we have configured four layers in
    a smart agriculture system, which is composed of the IoT sensor layer, edge layer,
    fog layer, and cloud layer. The configuration of edge, fog, and cloud layers depend
    on the type of tasks (e.g., number of MIPS) requested by each IoT sensor/device
    at the IoT sensor layer. The model input parameters of different layers (IoT sensor,
    edge, fog, and cloud layers), in addition to networks and carbon emissions parameters,
    are shown in Tables 14, 15, 16, 17, and 18, respectively. TABLE 14 IoT Sensor
    Layer Input Parameters TABLE 15 Cloud, Fog, and Edge Input Parameters TABLE 16
    LAN, MAN, WAN Network Input Parameters TABLE 17 Carbon Emission Inputs for Each
    Fuel Type [17], [22] In our model, we assume that there are 100,000 sensors distributed
    in each farm The sensors task requirements are divided into three types (sensing
    60%, processing 30%, heavy processing 10%). The sensing processing task is usually
    limited to handling offloaded reading data sent by the sensors (e.g., temperature
    reading or send control commands for the irrigation system). The processing task
    is the requirement of light processing (e.g., soil analytics and event detection).
    The heavy processing task is the requisite of higher processing power and resources
    (e.g., weather prediction and analysis). SECTION V. Results and Discussion In
    this section, we discuss the proposed energy-efficient edge-fog-cloud architecture.
    In addition to its energy efficiency, we evaluate our model to find the consequence
    CO2 emission, and network traffic compared to the traditional cloud-based architecture.
    We have evaluated the proposed architecture and models using MILP optimizer based
    on the AT&T network topology, as shown in Fig. 2. To solve the MILP model, we
    use the CPLEX solver over a laptop with an Intel Core i7–7660U CPU, running at
    2.50 GHz, with 16 GB RAM. FIGURE 2. AT&T WAN network topology. Show All As shown
    in Table 1, we have categorized all IoT wireless network technologies used in
    this work based on their data rate, range, number of devices, power consumption
    of both gateway/base-station, and sensors. This work has identified that the power
    consumption of different IoT wireless network technologies almost the same, as
    shown in Fig. 3. The Zigbee technology delivers connectivity with low power consumption
    compared to other technologies. However, using Zigbee in the urban area is not
    the best choice as it only covers 20 meters, thus, hundreds or thousands of gateways
    are required to cover a large area. FIGURE 3. Comparison of different IoT wireless
    network technologies based on their energy consumption. Show All Since we aim
    to use a technology that covers a large area with the least amount of energy consumption.
    Therefore, LoRa has been chosen as an IoT wireless communication technology between
    the IoT sensors and the gateway, that covers long-distance communication, with
    low power consumption, and considers one of the most suitable technology for IoT
    agriculture applications, as shown in Fig. 3. A. Energy Consumption Fig. 4 illustrates
    the power consumptions of different tasks in the proposed edge-fog-cloud architecture
    versus the traditional cloud-based architecture. Also, it shows the placement
    location of each task/application in edge-fog-cloud architecture, as well as the
    power consumption values of each task individually. FIGURE 4. The energy consumption
    of the proposed architecture vs. the traditional cloud-based architecture, considering
    the IoT LoRa technology. Show All The results showed that the sensing tasks are
    offloaded to the edge layer, as it has enough capacity (i.e., sensing requires
    500 MIPS, and the edge layer has the capability to process up to 1800 MIPS). The
    normal processing tasks are offloaded to the fog respectively, as the fog layer
    has sufficient resources (i.e., 4000 MIPS) to process the tasks (i.e., 2000 MIPS).
    All remaining requests are offloaded to the cloud layer as there is no capacity
    in edge neither fog layers to accommodate heavy processing tasks. Fig. 5 shows
    the power consumption of our proposed architecture compared to the traditional
    cloud-based architecture, considering different IoT wireless technologies. Also,
    the figure displays power saving achieved by the proposed architecture. It is
    clearly shown that our proposed architecture outperforms the traditional cloud-based
    architecture by up to 36% of the total power consumption. However, the power savings
    have slightly ranged between 33.6% and 35.6% based on the different IoT wireless
    technologies. The Zigbee shows a higher power saving as it capable of offloading
    sensor data with lower power consumption. FIGURE 5. The energy saving of the proposed
    architecture vs. the traditional cloud-based architecture, using different IoT
    wireless technologies. Show All B. CO2 Emission Fig. 6 illustrates the total carbon
    emissions of the proposed edge-fog-cloud architecture versus the traditional cloud-based
    architecture, considering powering the IoT sensor layer and edge layer by a solar
    power source. FIGURE 6. The total carbon footprint emission of the proposed architecture
    vs. the traditional cloud-based architecture. Show All It shows that our proposed
    architecture can reduce up to 42% of CO2 emission, for real-time IoT applications
    in agriculture systems. The results also show a comparable carbon emission using
    different IoT wireless technologies. The power consumption of these technologies
    has been eliminated, as all IoT sensors and gateways are power by a solar plant,
    that emits very low carbon footprints (solar plants emit only 0.048 kgCO2/kWh).
    C. Network Traffic Fig. 7 shows the total traffic in each network tier in our
    proposed architecture versus the traditional cloud-based architecture. The results
    showed that our proposed architecture is capable to reduce the total traffic by
    14% and 86% in MAN and WAN tiers, respectively, compared to a cloud-based approach.
    FIGURE 7. The network traffic of the proposed architecture vs. the traditional
    cloud-based architecture. Show All In the traditional cloud-based architecture,
    the process of sending/retrieving the data to/from the cloud in real-time requires
    high-capacity bandwidth, which may cause a burden on the three network tiers.
    Thus, employing edge and fog computing has allowed processing most requests locally
    in edge or fog layers, which significantly decreases the flow of data traverse
    to the cloud and reduces network traffic, as shown in Fig. 7. SECTION VI. Energy
    Efficient Agriculture IoT Edge/Fog/Cloud Architecture Heuristic The problem over
    energy-efficient offloading of IoT applications in edge-fog-cloud architecture
    for smart agriculture environment is a non-deterministic polynomial (NP)-hard
    problem. For instance, if i is IoT applications count and n is the count of locations
    in edge-fog-cloud architecture, then we will have ( ∑ z=1 n n! (n−z)! ) combinations
    of possible applications locations to find the optimum locations that result in
    optimal power consumption. Thus, applying MILP to large-size problems is not feasible.
    Therefore, heuristic provides a simple and fast real-time implementation. Also,
    the optimal solution provided by the heuristic can provide validation to results
    obtained from MILP. To provide that, a heuristic algorithm was developed, referred
    to as energy-efficient agriculture IoT applications distribution heuristic over
    the edge-fog-cloud architecture (EEAIOT-EFC). In the EEAIOT-EFC heuristic, IoT
    application i is checked based on their total MIPS processing requirements. Firstly,
    the algorithm tries to place and run the application on the edge layer. If there
    is not enough MIPS capacity at the edge layer, then, agriculture IoT application
    is placed in the fog layer, if it has enough capacity. In case of unavailability
    resources in both edge and fog layers, the cloud layer will host the IoT application,
    as it has enough processing capability to handle all types IoT applications. After
    distributing all IoT applications, the power consumption of EEAIOT-EFC is determined.
    The heuristic flowchart process is shown in Fig. 8. FIGURE 8. Flowchart of EEAIOT-EFC
    heuristic. Show All The heuristic is assessed using a PC with an Intel Core i7–7660U
    CPU, running at 2.50 GHz, with 16 GB RAM. Similar to MILP, the AT&T network is
    considered a WAN network example. The heuristic took 5 seconds to evaluate the
    EEAIOT-EFC, and the MILP and EEAIOT-EFC show a comparable result, as shown in
    Fig. 9. The gaps between them are limited to 0.7% and 4.7% of the total power
    consumption under the proposed and the traditional cloud-based, respectively.
    FIGURE 9. Difference between the MILP model vs. EEAIOT-EFC heuristic. Show All
    SECTION VII. Conclusion and Future Works In this paper, the concept of an edge-fog-cloud
    architecture is introduced in the smart agriculture system, which solved existing
    real-time processing issues in terms of reducing energy consumption, CO2 emission,
    and network traffic, compared to the traditional cloud-based architecture. The
    proposed architecture employed the edge and fog layers, which are placed close
    to the agriculture fields to collect heterogeneous data from various kinds of
    IoT agriculture sensors and process them at these layers. Although the proposed
    architecture was significantly reduced the computational load and the amount of
    transmitted data to and from the cloud due to the use of edge and fog layers,
    however, the cloud layer is inevitably used to process the heavy and complex data/task
    requested by IoT agriculture devices/sensors. Most of the processing tasks are
    completed on the edge and fog layers, while few tasks are offloaded to the cloud
    layer for processing. In the paper, different metrics have been taken into consideration,
    including energy consumption, CO2 emission, and network traffic to study the performance
    and the outcomes of the proposed architecture. Using mathematical modeling, the
    proposed architecture is compared with the traditional cloud-based architecture.
    The model results showed that our proposed architecture can reduce the overall
    power consumption, carbon footprints, and network traffic by up to 43%, 36%, 86%,
    respectively. Moreover, we developed energy-efficient agriculture IoT applications
    distribution heuristic over the edge-fog-cloud architecture (EEAIOT-EFC) algorithm,
    which showed comparable results to the MILP model. Though this proposed solution
    is based on the idea of smart agriculture, it also can be suitable for other IoT
    applications and sectors, such as e-healthcare, smart city, and smart home. In
    the future, we intend to extend the proposed approach in a distributed real agricultural
    environment, considering machine-learning and decision-making algorithms to further
    understand the capability of the proposed work. ACKNOWLEDGMENT The authors would
    like to acknowledge the Deanship of Scientific Research, Taibah University, Medina,
    Saudi Arabia, for providing research resources and equipment. This work was supported
    by the Deanship of Scientific Research, Prince Sattam Bin Abdulaziz University,
    Al-Kharj, Saudi Arabia. Authors Figures References Citations Keywords Metrics
    More Like This IoT Farm: A Robust Methodology Design to Support Smart Agricultural
    System Using Internet of Things with Intelligent Sensors Association 2023 7th
    International Conference on Electronics, Communication and Aerospace Technology
    (ICECA) Published: 2023 Smart Agriculture Wireless Sensor Routing Protocol and
    Node Location Algorithm Based on Internet of Things Technology IEEE Sensors Journal
    Published: 2021 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase
    Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS
    PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA:
    +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE
    Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Energy-Efficient Edge-Fog-Cloud Architecture for IoT-Based Smart Agriculture
    Environment
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Munir M.S.
  - Bajwa I.S.
  - Ashraf A.
  - Anwar W.
  - Rashid R.
  citation_count: '48'
  description: Smart parsimonious and economical ways of irrigation have build up
    to fulfill the sweet water requirements for the habitants of this world. In other
    words, water consumption should be frugal enough to save restricted sweet water
    resources. The major portion of water was wasted due to incompetent ways of irrigation.
    We utilized a smart approach professionally capable of using ontology to make
    50% of the decision, and the other 50% of the decision relies on the sensor data
    values. The decision from the ontology and the sensor values collectively become
    the source of the final decision which is the result of a machine learning algorithm
    (KNN). Moreover, an edge server is introduced between the main IoT server and
    the GSM module. This method will not only avoid the overburden of the IoT server
    for data processing but also reduce the latency rate. This approach connects Internet
    of Things with a network of sensors to resourcefully trace all the data, analyze
    the data at the edge server, transfer only some particular data to the main IoT
    server to predict the watering requirements for a field of crops, and display
    the result by using an android application edge.
  doi: 10.1155/2021/6691571
  full_citation: '>'
  full_text: '>

    "Journals Publish with us Publishing partnerships About us Blog Complexity Journal
    overview For authors For reviewers For editors Table of Contents Special Issues
    Complexity/ 2021/ Article On this page Abstract Introduction Related Works Results
    and Discussion Conclusion Data Availability Conflicts of Interest References Copyright
    Related Articles Special Issue Artificial Intelligence for Smart System Simulation
    View this Special Issue Research Article | Open Access Volume 2021 | Article ID
    6691571 | https://doi.org/10.1155/2021/6691571 Show citation Intelligent and Smart
    Irrigation System Using Edge Computing and IoT M. Safdar Munir ,1Imran Sarwar
    Bajwa ,1Amna Ashraf ,1Waheed Anwar ,1and Rubina Rashid 1 Show more Academic Editor:
    Abd E.I.-Baset Hassanien Received 17 Dec 2020 Revised 08 Feb 2021 Accepted 18
    Feb 2021 Published 28 Feb 2021 Abstract Smart parsimonious and economical ways
    of irrigation have build up to fulfill the sweet water requirements for the habitants
    of this world. In other words, water consumption should be frugal enough to save
    restricted sweet water resources. The major portion of water was wasted due to
    incompetent ways of irrigation. We utilized a smart approach professionally capable
    of using ontology to make 50% of the decision, and the other 50% of the decision
    relies on the sensor data values. The decision from the ontology and the sensor
    values collectively become the source of the final decision which is the result
    of a machine learning algorithm (KNN). Moreover, an edge server is introduced
    between the main IoT server and the GSM module. This method will not only avoid
    the overburden of the IoT server for data processing but also reduce the latency
    rate. This approach connects Internet of Things with a network of sensors to resourcefully
    trace all the data, analyze the data at the edge server, transfer only some particular
    data to the main IoT server to predict the watering requirements for a field of
    crops, and display the result by using an android application edge. 1. Introduction
    Agriculture is the major resource of living wage in Pakistan. A smart, intelligent,
    and fully automated agricultural system was required and extremely desirable in
    some last decades when our population grew exponentially in comparison to the
    natural resources we have in our country, Pakistan. For this purpose, an IoT-based
    smart watering system has been achieved in the recent years of constant threat
    of losing water. This agricultural industry has two particulars. The plastic tunnel
    farming is divided into low, high, and walk-in tunnels. It is convenient to sow,
    spray, and harvest in the high tunnel than in low and walk-in tunnels due to its
    broader size. Traditional farming, on the contrary, is the most unpredictable
    and becomes the cause of more water wastage. The issue we are going to deal with
    in this paper regarding smart irrigation is any application designed and used
    for the smart watering system still needs to be more efficient and timely. Technically,
    it means that just cloud computing is not enough for a large-scale IoT application.
    There should be something like more efficient and fast application using a better
    architecture to handle different types of data coming from different sources (sensors).
    The main purpose of a quick and smart irrigation system is the consumption of
    water so frugally to execute the need of water more timely for a field of plants
    and to save inadequate sweet water reservoirs. To handle this rigorous matter,
    many sensor-based smart irrigation systems with their mobile applications have
    been designed in different times, but still, there is a question on their reliability
    when data grow and thus the latency rate of IoT devices. Like in preceding papers,
    the input parameters humidity, temperature, soil moisture, and light intensity
    were used, and a decision of watering plants or not was made on the basis of a
    fuzzy logic [ 1]. The same fuzzy logic has been applied to many healthcare systems,
    in which use of biosensors helped monitoring temperature, blood pressure, oxygen,
    and infection status of the wound [ 2]. Similarly, in fire alarming applications,
    this technology helped a lot in 2018 [ 3] and 2019 [ 4]. Now, we come up with
    a new technology that is the combination of machine learning technique and semantics
    for some input parameters such as climate type, crop type, and soil type with
    the sensors’ output: temperature, humidity, and soil moisture. A smart irrigation
    system with the application of edge computing is required because the research
    studies on irrigation systems until now are not much efficient that they could
    not be implemented on large-scale systems and have less efficiency due to overburdenized
    sensors for all sensing data. So, a new intelligent and smart system should be
    designed. Our research found some grounds due to which improvements in the existing
    system are mandatory: (i) Existing smart irrigation systems either spotlighting
    on lesser parameters like soil moisture, air moisture/humidity or they are presenting
    a fuzzy logic (implemented in matlab) to produce an output decision or some are
    using simple machine learning algorithm to predict about water need for plants.
    A system which does not encounter the latency rate cannot provide the reliable
    solution. (ii) Skipping important parameters such as soil strata and crop type
    can lead to an imperfect watering system for plants. (iii) Unwanted data loading
    on the IoT server due to continuous throw of sensor data becomes a cause of less
    efficiency of the IoT server. An intelligent irrigation system should never halt
    due to overburden of data. (iv) As newest expertise has come into sight due to
    progression in each and every field, therefore, we also have to change our classical
    method of irrigation to advanced, smart, and perfect and simple knowledge database
    for plant’s data to powerful ontology-based semantics. There are some main aspects,
    which we are going to concentrate on in our anticipated approach: (i) Three sensors
    are used in our approach: a soil moisture sensor, humidity and temperature sensor,
    and light sensor. Furthermore, ontology is used for plant species data, different
    soil types, and different climate types. (ii) This approach focuses on an intelligent
    technique, i.e., machine learning, to decide watering requirements for a particular
    plant, and by considering many other suitable parameters for the plant growth,
    i.e., climate, weather, and soil type, we are going to design a smart irrigation
    system in a different and more efficient way. (iii) Our proposed smart system
    by design focuses on system reliability as if a sensor for some reason is not
    working at a particular time and was working an hour before, then the value it
    measured before an hour will be used by our trained model to produce the result
    because no drastic change can occur in other parameters in just an hour. It makes
    our system user friendly and more efficient. (iv) The proposed approach is structured
    to come upon the problems of the obsolete irrigation method smartly. 2. Related
    Works Traditional tunnel farms, all over the world, use drip irrigation or a sprinkler
    irrigation method. These are better than normal flooding methods. Various irrigation
    methods provide different water consumption levels and energy competence [ 5].
    The surface irrigation and level irrigation methods provide low water and energy
    efficiency. The subirrigation, overhead irrigation, and sprinkler irrigation methods
    provide low-to-medium efficiency. The sprinkler and drip irrigation methods provide
    similar energy efficiency, but drip irrigation is more water efficient than sprinkler
    irrigation [ 6]. To increase crop production and decrease costs efficiently, the
    management of freshwater smartly is indispensable. The powerful use of technologies
    provides the precise amount of water required for plants. The SWAMP project [
    7] in Europe has developed an IoT-based smart water management platform for ideal
    irrigation with a proactive approach on four pilots in Brazil and Europe. The
    SWAMP architecture, the platform, and the system deployed presented by the European
    people include a performance analysis of FIWARE components. They aim to reengineer
    some of its components to provide greater scalability by using less number of
    computational assets. The amount of land irrigated in the US is approximately
    the same as their farmers used to irrigate ten years earlier, but the important
    thing is water they are using nowadays for this purpose is quite less than previously
    used. They are growing plenty of fruits, vegetables, nuts, and whole grains that
    fulfill their inhabitant’s requirements whole year. Two types of irrigation traditional
    technologies have been used in the US since 2013 [ 8]. First one is used in the
    gravity systems; it makes up 35 to 42% of irrigation systems in the United States.
    It delivers water from its source to a crop area by flooding through land-forming
    measures, including canals, waterways, basins, and furrows. Examples are the furrow
    system controlled flooding systems and uncontrolled flooding systems. The second
    type of irrigation technology is used by the pressure systems. In pressure systems,
    tubing or pipes are used to pump water, and irrigation is done through an applicator
    such as a sprinkler or perforated pipe. China’s development has been affected
    by three major issues regarding agriculture, landscape, and farmers [ 9]. The
    solution to these glitches is agricultural transformation. Though this transformation
    is not so easy and quick, introducing the cloud computing with Internet of Things
    to their agriculture is going to help them in solving the issue. However, cloud
    computing, IoT, and SOA technologies, are helping in the they have built huge
    data involved agricultural harvesting. Cloud computing is linked to IoT, and both
    collectively can enhance the agricultural production to solve the matters regarding
    agriculture, landscape, and farmers. In India, different traditional methods are
    designed and applied regionally in India over the past decades to cope up the
    necessities of their people in a sustainable way. The three irrigation methods
    that exist in India are diversion channels, small-scale water bodies such as tanks
    to store rainwater, and wells to collect groundwater. These methods are for small-scale
    as well as large-scale applications. As the population of India is increased enough,
    the needs on the water increase for various drives such as irrigation, domestic,
    hydroelectricity, industrial, mining, and regeneration. However, India has the
    largest irrigated area in the whole world, and the irrigated area is only about
    40% of the cropped area [ 10]. One of the main reasons for this low irrigated
    land is the major use of traditional irrigation methods, which leads to low water
    use efficiency of about 35–40% [ 11]. The use of traditional methods without the
    reach of cloud computing and edge computing causes the unstable watering system
    for the plants. Consequently, a well-organized and judicious watering system is
    the major intention. During some last decades, irrigation systems with the use
    of some sensor networks with different IoT approaches are initiated which basically
    provides the solution but still they need some improvements. Table 1 shows their
    water-saving percentages, techniques used by them, and the sensors used by them.
    Table 1  Sensor-based solutions. In 2008, Bernard used the rain sensor and estimated
    the eminence of pasture with and without the sensor. He tried to figure out irrigation
    water use. He experienced common Bermuda grass to achieve 34% water saving. Xiao
    et al. [ 13] self-designed the sensor network for the irrigation system, and they
    achieved water saving of about 65.22%. Dukes [ 20] described that water saving
    of about 40% to 70% can be achieved by using smart controllers but for real-world
    scenarios of bigger fields; this value can be lessened to 10% [ 19]. Gutiérrez
    et al. [ 14] designed and tried to implement a mechanized irrigation system to
    use water efficiently. They used a wireless network of some sensors to manage
    water saving of about 90% as compared to conventional irrigation methods. Similarly,
    Kumar et al. [ 5] presented a similar work in the same year and Parameswaran and
    Sivaprasath [ 6] and Rawal [ 16] latterly introduced a few similar sensor-based
    solutions. Nelson in 2015 used a few sensor data such as temperature and soil
    moisture and WSAN to automate the irrigation process with decreased water consumption.
    Saab et al. [ 17] tried and thrived an on-field survey of a smart phone irrigation
    setting up. He investigated and tested that application in Mediterranean environments
    achieved 25% of water saving. Recently, another input to these contributions was
    made by Saqib (2020), i.e., a network system for the HC12 module is intended to
    improve the communication range. 3. Architecture of the Proposed System The anticipated
    irrigation system is entrenched with the potential smart decisions taking capability
    to water plants by considering the factors such as crop type, soil type, climate
    type, temperature, humidity, and soil moisture. Ontology is implanted to query
    about the decision for a particular plant type, climate type, and soil type, while
    remaining factors such as temperature, humidity, and soil moisture are sensed
    by our sensor network. Final decision for watering plants or not relies 50% on
    the ontology result, and the other 50% is based on our trained machine learning
    model. The smart architecture of our watering system is given in Figure 1.    Figure
    1  Proposed architecture for smart irrigation. Our proposed architecture of IoT
    has four layers, application layer, processing layer, transport layer, and the
    perception layer, rather than basic IoT architecture which consists of three layers
    (application layer, network layer, and perception layer). The perception layer
    is known as the physical layer, which means it has sensors for assembling data.
    It senses temperature, soil moisture, and humidity from air. The transport layer
    is the source of transferring sensed data collected previously to the processing
    layer through networks such as wireless, 2G, 3G, and LAN. The processing layer
    stores, scrutinizes, and processes huge amounts of data coming from the transport
    layer. It utilizes technologies such as databases, cloud computing, and edge computing.
    The application layer is for providing application-specific services to the end
    user. Our system deals with the sensors, GSM module, edge server + IoT server,
    and additionally an android application. These are the perception layer, transport
    layer, processing layer (cloud computing and intelligent computing), and the application
    layer, respectively. 3.1. Sensor Data At first, data are gathered by the sensors
    as presented in Figure 2. Soil moisture, humidity, and temperature data are collected
    in this phase. The perception layer has all sensors, actuators, and the microcontroller.
    Rest is the part of remaining three layers. Transport and processing layers collectively
    provide schedule for watering crops, their supervision, and other suggestions.
    After gathering the data, the next stage is to accumulate data at data centers
    for analyses.    Figure 2  Hardware design for the integrated system. The detailed
    design inspection of the physical components used is presented in the figure.
    All the components are with no trouble available in the market and cheap also.
    So, the device to be deployed in the real environment can be made easily available.
    This implantable device has the layer of sensors used, i.e., humidity, light,
    and moisture sensors. The microcontroller fixed in the Arduino board receives
    the analog signals from these sensors, and after every 30 seconds, these values
    are transferred to the data center through GSM module SIM808. The final results
    from our decision-making process can be visualized by the user all the way through
    an android application, after which the user can direct our system’s actuators,
    and finally, water is released from the valve or closed. The next section briefs
    the working of our ML smart decision system deployed at the IoT server which speedily
    timetables the watering plan for plants. This setting up also evolves the soil
    type, climate type, and crop type. In our smart system, ontology inhabits in these
    parameters for better competence and precision. By means of these technologies,
    we have prepared our system to be fully functionally automatic. The subsequent
    section describes the semantic knowledge base for our smart irrigation system.
    3.2. Semantic Knowledge Base The semantic data model (SDM) is designed for incorporating
    and handling of the real-world data. In the semantic data model, the logical levels
    are applied for the categorizing of concepts and evaluation of the information.
    On the basis of the results extracted from propositional logic systems set in
    the ontology, one can make a smart decision. There are concepts in our ontology
    to make prediction of the level of water need on the basis of crop type, climate
    type, and soil type. These parameters collectively constitute the structured data
    that why we can query decision on their bases from the given ontology. The sensed
    data and the decision resulted in SPARQL (RDF query language) together comprise
    the full ground vital to make a watering system run. For instance, if, due to
    the climate type and soil strata type, a particular plant requires water, it would
    be contingent to water the plant. This action of watering crops is the consequence
    of the actuation that is performed on the valve. Likewise, it could be turned
    off as directed by the field specification. Sensor data are pulled together at
    different levels of a large area. The observed properties or the sensed data such
    as temperature, humidity, and luminance are measured at the yard level, while
    soil moisture (superficial and deep) is measured at the quadrant level. These
    data in the form of RDF and the desired knowledge (crop species, climate types,
    and soil types) from ontology are sent to the control agent. The control agent
    also receives data about plant requirement for quantity of water in specific soil
    texture. The ontology on which our system depends is vast and complex due to the
    wide range of factors/features engaged in taking decision for watering plants
    or not (Appendix A). An abstract view of ontology is shown in Figure 3. There
    are different climate zones of Pakistan, and they are distinguished into four
    different types such as highland zone, arid zone, lowland zone, and coastal zone.
    As the humidity level is diverse in diverse areas, irrigation in these climatic
    zones has wide-ranging water needs.    Figure 3  Ontology: an abstract view. In
    addition to temperature and humidity, another feature, soil type, also influences
    the level of water need to be given. The clay which is known as well-drained like
    loamy soils is the excellent soil type for wheat [ 21]. There are four to five
    different types of soil considering their structure and texture. In the same way,
    each crop has its some specific water needs as some require more water such as
    sugarcane and rice than others such as wheat and cotton. The architecture of our
    decision support system is shown in Figure 4. The information about crop types
    is giving the watering requirements of the crop by utilizing plant ontology. Then,
    data sensed from pasture/crop land, soil type, and climate type is used for depiction
    on the actual watering supplies for the field. Water instructions or suggestions
    will be shown as recommendations on the mobile phone via an android app, and as
    a resultant of a button click from the farmer’s smart phone, actuations will be
    executed on the valves positioned in the field.    Figure 4  Inference rule schema.
    3.3. Used Analysis Technique Water requirement level can be predicted by any machine
    learning approach such as random forest, decision trees, KNN, naive Bayes, and
    support vector machine as all of these are classification dilemma-handling algorithms.
    The modeling practice we are using lies underneath supervised machine learning,
    known as KNN (with k = 5). It uses the whole dataset to predict an unseen data
    instance. It searches through the whole dataset to find “k” number of neighbors
    which are the most close neighbors to that data instance. This is done by actually
    finding the correspondence between the instance data with the whole dataset, where
    “k” is the number of neighbors found closer to instant data. If the value of “k”
    is set to 3, then three most similar neighbors will take part in assigning class
    label to instant data. It then allocates the most common class label (among those
    k-training instances) to the test data. Shemim et al. utilized three feature selection
    algorithms, CBFS, FPRS, and KFRS, for the dataset, and then KNN is used to classify
    featured classes [ 21]. Bzdok et al. also discussed about supervised learning
    algorithms including KNN in 2018 [ 22]. 3.3.1. Algorithm for KNN Step 1: calculate
    the Euclidean distance between new data X (4 features involved to predict the
    resultant class, A, B, C, and D) and each existing point Pn in the input dataset
    S: Step 2: choose the value of “k,” i.e., no of nearest neighbors to new data
    X: Step 3: count the ballots of all the “k” neighbors to predict the class of
    test data X. Step 4: assign that class to the test data X, which won more votes.
    4. Application of the Proposed Architecture Our system to be implemented uses
    an Arduino UNO (ATmega328P) controller. The data sensed by the sensors (perception
    layer) are received by the microcontroller, they are transferred to the edge server
    (1st processing layer) via GSM SIM808 (transport layer), in which basic scrutiny
    occurs, and just the immediate data required to predict the resultant water level
    are transferred to the main IoT server (2nd processing layer) where our trained
    machine learning model is deployed. This model, after detailed analysis, tells
    the rank of water need for a field. The following section elaborates the hardware
    setting. 4.1. Hardware Setting for the User Embedded sensors used in the IoT-based
    system are the source of sensing inventively and cost-effectively, and they can
    record and analyze real-time data (Sarwar, Bajwa, Ramzan et al. 2018 and Munir,
    Bajwa and Cheema 2019) [ 23]. The proposed smart IoT system as shown in Figure
    5 employs some sensors to gather data from the environment, and a GSM module SIM808
    is used to transfer the values to the edge server. A data SIM card is inserted
    in it to get facilitated by the real-time data transportation. As we can see in
    Figure 6, a hygrometer sensor is used for soil moisture, while for the moisture
    from air, AM2302 DHT22 (temperature/humidity) sensor is used. Their details are
    described in the following.    Figure 5  Hardware prototype.    Figure 6  Sensors
    used. 4.1.1. HL-69 Soil Hygrometer Sensor For the detection of the humidness of
    the soil, we used HL-69 soil hygrometer moisture sensor. The basic purpose for
    using the HL-69 soil hygrometer moisture sensor is to provide better reading than
    other soil moisture sensors. This sensor is used for real-time monitoring soil
    moisture of plants in a tunnel farm. The voltages of the sensor output change
    accordingly to the water content in the soil. There are some key factors of HL-69
    soil hygrometer sensor. If soil moisture is greater, then the output voltage decreases,
    but if the soil is dry, then the output voltage increases. The hygrometer soil
    moisture sensor provides an analog signal as an output which has to be converted
    to digital by Arduino. This sensor includes two pieces: one is an electronic board
    and another one is two pads that detect the water content. LM393 comparator chip
    is located on the electronic board. The electronic board of the HL-69 soil hygrometer
    sensor has a fixed bolt hole used for easy installation. It contains two lights:
    red and green; red light shows the power indicator, and the green light shows
    the digital switching output indicator. 4.1.2. AM2302 DHT11 Sensor The DHT22 sensor
    is a common temperature-humidity sensor that is used to determine temperature
    and humidness in air. The DHT22 sensors are made up of two parts: a humidity sensor
    and a thermistor. There are some key factors of the DHT22 sensor which are as
    follows: the cost of the DHT22 sensor is low. DHT22 sensor is good for 0–50% temperature
    readings with 2–5% accuracy and a humidity range from 20 to 80% with 5% accuracy.
    The I/O voltage for the DHT22 sensor is between 3 V and 5 V. While requesting
    data, the maximum current use during conversion is 2.5 mA. DHT22 sensor contains
    4 pins with 0.1 spacing between them. The body size of the DHT22 sensor is approximately
    15.1 mm 25 mm 7.7 mm. 4.1.3. BH1750 FVI Light Sensor BH1750 is a common digital
    light sensor that can determine the light intensity. BH1750 is a calibrated digital
    light sensor, and it can measure even small traces of light and can convert it
    into a 16-digit numeric value. It is commonly used in mobile phones to exploit
    the screen brightness based on the environmental lighting. BH1750 measures the
    light intensity in the range of 0 to 65,535 lux (L). In the smart irrigation system
    for tunnel farming, we used the H-resolution mode of the BH1750 sensor. There
    are some key factors of BH1750 sensor which are as follows: the chip of the BH1750
    sensor is BH1750FVI. The power supply of the BH1750 sensor is 3.3 V to 5 V. The
    BH1750 sensor is a built-in 16 bit AD converter that converts detection of light
    into a 16-digit numeric value. The range of light intensity in the BH1750 sensor
    is 0 to 65,535 lux. The size (LW) of the BH1750 sensor is approximately 3.2 cm1.5 cm.
    5. Results and Discussion The proposed watering system for tunnel farming is so
    smart that develops and employs the assistance of true decision-making capability
    of machine learning. The architecture and the hardware details of the system are
    given in the preceding section. All the sensors (temperature and humidity, light
    sensor, and the soil moisture sensors) were deployed to the actual field to analyze
    the reaction of the proposed system. The data transferred to the edge server through
    the GSM module and through an Android application whereas the results can also
    be seen by a farmer. A user can then perform some actuation to open or close the
    valve. 5.1. Preparing the Training Dataset The system is completely automated
    as the sensor data receiving from the field are processed according to our trained
    model of machine learning, i.e., trained by the characteristic sensor values shown
    in the following. Table 2 shows five classes: highly needed, needed, average,
    not needed, and highly not needed for various levels of soil moisture sensed by
    the HL-69 hygrometer sensor and temperature and humidity sensed by AM2302 DHT22.
    The output of a HL-69 hygrometer varies from 0 to 870, while the humidity level
    of the AM2302 DHT11 sensor varies in the air from 20 to 80%, and its temperature
    value ranges from 0 to 50. Table 2  Classes of sensor data. Here is our sampled
    training dataset shown in Figure 7 based on our rules set in Table 2, which we
    have provided to our machine learning algorithm to predict water needs for the
    given crop types.    Figure 7  Sampled training dataset. 5.2. Training of the
    KNN Model We have implemented the code in Anaconda, created for python programs,
    and have trained our model on the fact that, on a particular temperature, water
    requirements of different crops, which we are taking into consideration, can be
    given. Rice > sugarcane > maize > cotton > wheat. This general rule can be elaborated
    more specifically by identifying ranges for temperature, humidity, and soil moisture
    for all the given types of crops to recognize its class. Here is the rule summary
    in Table 3. Table 3  Working rules for different crops. In Table 3, labels “HN,”
    “N,” “A,” “NN,” and “HNN” are second hand for classes highly needed, needed, average,
    not needed, and highly not needed correspondingly. Likewise, working rules for
    watering considering climate and soil are given in the following. Sand and gravel > clay > silt > loam > organic
    soil. Hot and dry > hot and humid > cold and humid. 5.3. Deploying the Trained
    Model Our trained model has been developed using Scikit-learn. To make it available
    to production and to make it useful for end users so that they could extract real
    values from it, we have deployed it. In this regard, we need to have three components
    shown in Figure 8.    Figure 8  Components required in deployment. The developed
    and trained model for predicting the water level as a “model.pkl” file is ready,
    and model evaluation is provided in the results section. The web service we have
    used for this purpose is the Flask API. Lastly, we need cloud as a service provider,
    and Heroku server fulfilled our requirement in this proposed system. 5.4. Implementation
    Using Edge Computing In the process of deploying the trained model through Flask
    API, we actually define routes to where an HTTP request handles. One route is
    for handling one HTTP request. The data are travelled in the system from one side
    (perception layer) to other (edge server). The piece of code in Figure 9 is responsible
    for sending the sensor data from the sensor-Arduino side (i.e., perception layer)
    to edge server Firebase (i.e., processing layer). Second last line of the code
    is establishing a link to which data (temperature, humidity, soil moisture, and
    phone no.) are transferred. These data are received by our edge server by a route
    “/submit” defined in the application of Flask API as shown in Figure 10. Whenever
    data from sensors send to the established link of HTTP request, it triggers the
    following piece of code to run. In this piece of code, the sensor values and the
    SIM card no. (phone no.) are inserted in our database server (Firebase).    Figure
    9  HTTP request sending to store sensor data.    Figure 10  Route defined for
    inserting values to the database. As we can see in Figure 11, each phone no. is
    representing a different device. Any data coming from a particular device are
    stored under the hierarchy of its phone no. Each record under a device has a key
    value associated with it, which actually contains the sensor data values. Whenever
    a particular record arrives at the edge server, its key value stores in the parameter
    “latestKey” under its phone no. When another entry of record happens, its key
    value replaces the previous one. In this way, our database is designed to have
    the record of most recent data entered in it.    Figure 11  Edge server handling
    data from sensors via the HTTP request. Firebase can be omitted from the system,
    and data can directly be sent to the Heroku server (IoT server), i.e., cloud computing.
    That is really a bad practice due to overburden of the IoT server with useless
    data. Since sensors are sending each and every instant value to the IOT server
    and IOT server is responsible for scrutiny of data coming from a device (which
    means three sensors values every 30 seconds), and then applying model to predict
    value for water requirement. It will definitely affect the speed and efficiency
    of the system. This is the main concept of introducing edge computing. The piece
    of code in Figure 12 is triggered by the smart mobile/tab when the user clicks
    to predict results for water requirements. It utilizes the trained model to predict
    the water requirements and return the value to the server. This value is sent
    to the user, and he/she can see the result on his/her phone via the app.    Figure
    12  Data transfer from edge server to IoT server with prediction results. 5.5.
    Android Application An android platform is provided to the farmers. The input
    parameters (crop type, climate type, and soil type) are put on view in a dropdown,
    and users can select from these and can send the command to the device implanted
    to the field. Codes for crop types, soil types, and climate types are transferred
    from the mobile app interface in Figure 13(a) to the server to which ontology
    is attached. Decision extracted from the ontology section along with the sensor
    values then reaches the main IoT server where our machine learning algorithm is
    installed. Our training dataset also contains the encoded values for labels for
    different classes which are converted to the text (class label) at the front end
    in the android app as in Figure 13(c). These codes are shown in Table 4.   (a)       (a)  (b)  (c)       Figure
    13  Android app different interfaces (a, b, and c). For example, we choose, from
    the dropdowns in the user input screen shown in Figure 13(a), sugarcane as a crop
    type, hot and dry as a climate type, and loam as a soil type. After clicking the
    button “Send” from the Figure 13(b) interface, the sensor readings come across
    to the server. The values for humidity, temperature, and soil moisture and the
    encoded result for soil type, climate type, and crop type values are considered
    by our trained ML model to recognize the watering need for the specific crop.
    So, with the 50% result coming from ontology and the sensor values, our system
    foretells to water the crops and displays a note on the farmer’s mobile screen
    as shown in Figure 13(c). The highlighted text “Highly need water” is mainly the
    output of our machine learning algorithm already discussed in the previous section.
    As shown in Table 4, our training dataset holding the labels ranges from −1 to
    3. These are effectively the degree of water necessity to a specific plant at
    specific time. Table 4  Codes for class labels. 5.6. Performance Evaluation We
    have performed tests on our sample data, which we have obtained randomly from
    about 500 instances. We provided these instances to train our KNN model for the
    proposed system to forecast class labels. We used two statistical measures to
    estimate the performance of our KNN model, i.e., precision and recall. Figure
    14 shows the accuracy report of the results of the KNN model providing k = 5.    Figure
    14  Accuracy report with “k = 5.” The accuracy report of the trained model is
    given in Figure 1 and also presented graphically. Predicted results for class
    label “Needed” are lacking in precision. This performance is dependent on the
    “k” value that is the no. of nearest neighbors involved in the predicting class.
    Figure 15 shows the confusion matrices without normalization and with normalization.    Figure
    15  Confusion matrices without normalization for “k = 5.” To increase accuracy,
    we should choose the “k” value precisely. As per general rules for the KNN algorithm,
    the value of “k” for the problem of two classes should be an odd value, and for
    more than two classes, the “k” value should not be the multiple of the number
    of the resultant classes. As in our case, we have five labeled classes to be predicted,
    so we will choose “k” accordingly. In order to choose a suitable value for “k”,
    we have to plot “k value versus mean error” graph to identify the error trend.
    So, we plot it by using “matplotlib.pyplot” in Figure 16.    Figure 16  Error
    rate with respect to the k value. As we can see, the mean error initially increases
    up to 0.5 as the “k” value increases, but there is a sudden fall which occurs
    after that to the value of 0.3 when the “k” value reaches 10 to 11. After that,
    rise in error rate starts, and it continues to increase with the increase in the
    “k” value. It means that our “k” value should be “11” that is the maximum value
    of ‘k’ for which mean error remains lowest. So, for the value of k = 11, we again
    find the accuracy report to check if the performance of our model is getting better
    or not. Figure 17 shows the significant improvement in the performance of the
    model as accuracy rate increases when we set the “k” value to 11. The precision
    value for class “Not Needed” is increased from 0.33 to 1.0 which means accuracy
    rate increases from 33% to 100%. Similarly, for class “Average,” the precision
    value increases from 0.25 to 0.33 which means that accuracy rate increases from
    25% to 33%. This is how tuning of the model can be possible. By tuning training
    data values and by adjusting the “k” value, we can have a better model for our
    system. This is the main reason why we choose KNN algorithm for our proposed system.    Figure
    17  Accuracy report with “k = 11.” 6. Conclusion and Future Work Our proposed
    solution for smart irrigation constitutes three modules: first module is the sensor
    network, which is required to sense parameters influencing the water need. We
    have used sensors DHT22, light sensor BH1750, and HL-69 hygrometer to sense temperature,
    soil moisture, light, and humidity in air. In the third module, we use edge and
    main IoT servers to transfer and receive data via HTTP requests. In the second
    module, we applied KNN on the sample dataset to train the model and used it for
    efficient decision-making of water requirements. Our trained model classifies
    the input into five possible classes based on input values such as highly not
    required, not required, average, required, and highly required. We have fully
    implemented the proposed system in Anaconda. Currently, our system employs KNN
    for decision-making, but other intelligent data-extracting techniques can also
    be used for decision-making. So, the presented irrigation system can reproduce
    in future by using other decision-making techniques such as random forest. Moreover,
    the edge computing architecture can be further improved by making the edge server
    responsible for processing data and depicting the result from the machine learning
    algorithm. In other words, the trained model for KNN can be deployed at the edge
    server so that nearby devices to a particular edge can get facilitated by that
    edge server. It will improve latency rate remarkably. Data Availability The data
    used to support the findings of this study are available from the corresponding
    author upon request. Conflicts of Interest The authors declare no conflicts of
    interest. References M. S. Munir, I. S. Bajwa, M. A. Naeem, and B. Ramzan, “Design
    and implementation of an IoT system for smart energy consumption and smart irrigation
    in tunnel farming,” Energies, vol. 11, no. 12, p. 3427, 2018. View at: Publisher
    Site | Google Scholar H. Sattar, I. S. Bajwa, R. U. Amin et al., “An IoT-based
    intelligent wound monitoring system,” IEEE Access, vol. 7, pp. 144500–144515,
    2019. View at: Publisher Site | Google Scholar B. Sarwar, I. Bajwa, S. Ramzan,
    B. Ramzan, and M. Kausar, “Design and application of fuzzy logic based fire monitoring
    and warning systems for smart buildings,” Symmetry, vol. 10, no. 11, p. 615, 2018.
    View at: Publisher Site | Google Scholar B. Sarwar, I. S. Bajwa, N. Jamil, S.
    Ramzan, and N. Sarwar, “An intelligent fire warning application using IoT and
    an adaptive neuro-fuzzy inference system,” Sensors, vol. 19, no. 14, p. 3150,
    2019. View at: Publisher Site | Google Scholar A. Kumar, K. Kamal, M. O. Arshad,
    S. Mathavan, and T. Vadamala, “Smart irrigation using low-cost moisture sensors
    and XBee-based communication,” in Proceedings of the Global Humanitarian Technology
    Conference (GHTC), San Jose, CA, USA, October 2014. View at: Google Scholar G.
    Parameswaran and K. Sivaprasath, “Arduino based smart drip irrigation system using
    internet of things,” International Journal of Engineering Science, vol. 6, p.
    5518, 2016. View at: Google Scholar C. Kamienski, J.-P. Soininen, M. Taumberger
    et al., “Smart water management platform: iot-based precision irrigation for agriculture,”
    Sensors, vol. 19, no. 2, p. 276, 2019. View at: Publisher Site | Google Scholar
    M. Stubbs, Irrigation in US Agriculture: On-Farm Technologies and Best Management
    Practices, Congressional Research Service, Washington, DC, USA, 2016. F. TongKe,
    “Smart agriculture based on cloud computing and IOT,” Journal of Convergence Information
    Technology, vol. 8, no. 2, 2013. View at: Google Scholar A. Narayanamoorthy, “Economics
    of drip irrigation in sugarcane cultivation: case study of a farmer from Tamil
    Nadu,” Indian Journal of Agricultural Economics, vol. 60, pp. 235–248, 2005. View
    at: Google Scholar M. W. Rosegrant, X. Cai, and S. A. Cline, “Global water outlook
    to 2025: averting an impending crisis,” Tech. Rep., International Food Policy
    Research Institute, Washington, DC, USA, 2002, 572-2016-39087. View at: Google
    Scholar B. Cardenas-Lailhacar, M. D. Dukes, and G. L. Miller, “Sensor-based automation
    of irrigation on Bermuda grass, during dry weather conditions,” Journal of Irrigation
    and Drainage Engineering, vol. 134, pp. 184–193, 2008. View at: Publisher Site
    | Google Scholar K. Xiao, D. Xiao, and X. Luo, “Smart water-saving irrigation
    system in precision agriculture based on wireless sensor network,” Transactions
    of the Chinese Society of Agricultural Engineering, vol. 26, pp. 170–175, 2010.
    View at: Google Scholar J. Gutiérrez, J. F. Villa-Medina, A. Nieto-Garibay, and
    M. A. Porta-Gandara, “Automated irrigation system using a wireless sensor network
    and GPRS module,” IEEE Transactions on Instrumentation and Measurement, vol. 63,
    no. 1, pp. 166–176, 2014. View at: Publisher Site | Google Scholar N. Sales, O.
    Remédios, and A. Arsenio, “Wireless sensor and actuator system for smart irrigation
    on the cloud,” in 2015 IEEE 2nd World Forum on Internet of Things (WF-IoT), pp.
    693–698, IEEE, Milan, Italy, December 2015. View at: Google Scholar S. Rawal,
    “IOT based smart irrigation system,” International Journal of Computer Applications,
    vol. 159, no. 8, pp. 7–11, 2017. View at: Publisher Site | Google Scholar A. Saab,
    M. Therese, I. Jomaa, S. Skaf, S. Fahed, and M. Todorovic, “Assessment of a smartphone
    application for real-time irrigation scheduling in Mediterranean environments,”
    Water, vol. 11, p. 252, 2019. View at: Google Scholar M. Saqib, T. A. Almohamad,
    and R. M. Mehmood, “A low-cost information monitoring system for smart farming
    applications,” Sensors, vol. 20, no. 8, p. 2367, 2020. View at: Publisher Site
    | Google Scholar M. J. OGrady, D. Langton, and G. M. P. O’Hare, “Edge computing:
    a tractable model for smart agriculture?” Artificial Intelligence in Agriculture,
    vol. 3, pp. 42–51, 2019. View at: Publisher Site | Google Scholar M. D. Dukes,
    “Water conservation potential of landscape irrigation smart controllers,” Transaction
    ASABE, vol. 55, pp. 563–569, 2012. View at: Google Scholar M. S. Munir, I. S.
    Bajwa, and S. M. Cheema, “An intelligent and secure smart watering system using
    fuzzy logic and blockchain,” Computers & Electrical Engineering, vol. 77, pp.
    109–119, 2019. View at: Publisher Site | Google Scholar D. Bzdok, M. Krzywinski,
    and N. Altman, “Machine learning: supervised methods,” Nature Methods, vol. 15,
    pp. 5-6, 2018. View at: Google Scholar M. Safdar Malik, I. Sarwar Bajwa, and S.
    Munawar, “An intelligent and secure IoT based smart watering system using fuzzy
    logic and blockchain,” Computers and Electrical Engineering, vol. 77, no. 1, pp.
    109–119, 2018. View at: Google Scholar Copyright Copyright © 2021 M. Safdar Munir
    et al. This is an open access article distributed under the Creative Commons Attribution
    License, which permits unrestricted use, distribution, and reproduction in any
    medium, provided the original work is properly cited. More related articles Design
    and Implementation of Smart Hydroponics Farming Using IoT-Based AI Controller
    with Mobile Application System S. V. S. Ramakrishnam Raju | Bhasker Dappuri |
    ... | Manoj Kumar Mishra A Real-Time Data Monitoring Framework for Predictive
    Maintenance Based on the Internet of Things Mudita Uppal | Deepali Gupta | ...
    | Jaeun Choi A Novel Portable Soil Water Sensor Based on Temperature Compensation
    Hao Tian | Chongchong Yu | ... | Mei Sun Cloud Computing and Networking for SmartFarm
    AgriTech Meenakshi L. Rathod | A. Shivaputra | ... | Selvakumar Periyasamy PDF
    Download Citation Download other formats Order printed copies Views 15319 Downloads
    4484 Citations 53 Related articles Developing a Hybrid Irrigation System for Smart
    Agriculture Using IoT Sensors and Machine Learning in Sri Ganganagar, Rajasthan
    Amritpal Kaur | Devershi Pallavi Bhatt | Linesh Raja Application of IoT and Cloud
    Computing in Automation of Agriculture Irrigation Khongdet Phasinam | Thanwamas
    Kassanuk | ... | Abdul Wahab Rahmani Development of a Wireless Sensor Network
    and IoT-based Smart Irrigation System Juliana Ngozi Ndunagu | Kingsley Eghonghon
    Ukhurebor | ... | Robert Birundu Onyancha About Us Contact us Partnerships Blog
    Journals Article Processing Charges Print editions Authors Editors Reviewers Partnerships
    Hindawi XML Corpus Open Archives Initiative Fraud prevention Follow us: Privacy
    PolicyTerms of ServiceResponsible Disclosure PolicyCookie PolicyCopyrightModern
    slavery statementCookie Preferences"'
  inline_citation: '>'
  journal: Complexity
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Intelligent and Smart Irrigation System Using Edge Computing and IoT
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Debauche O.
  - Mahmoudi S.
  - Elmoulat M.
  - Mahmoudi S.A.
  - Manneback P.
  - Lebeau F.
  citation_count: '28'
  description: Overcoming population growth dilemma with less resources of soil and
    water, the irrigated agriculture allows us to increase the yield and the production
    of several crops in order to meet the high requirements of demands of food and
    fibers. Efficiently, an irrigation system should correctly evaluate the amount
    of water and also the timing, when applying certain irrigation doses. Global warming
    of the planet, to which is added in some regions an irregular regime of precipitation
    and a scarcity of available water resources, requires precision irrigation systems.
    The rational use of water and inputs (mainly fertilizers and pesticides) is crucial
    in some areas of the planet suffering from a deficiency of water. Hence, in these
    regions where the environmental conditions are harsh to ensure an efficient crop
    growth. Moreover, plant diseases and pests impact the yields of crops. For these
    reasons is it why an early detection gives us the opportunity to treat the disease
    or pest as quickly and effectively as possible, in order, to reduce the impact
    of these latter. Nowadays, the identification of plant diseases and pest with
    Artificial Intelligence algorithms on video flow in real conditions with variable
    exposition are still being a very challenging problem. Researchers classically
    develop algorithms that are trained on calibrated exposition images, which does
    not perform well in real conditions. Furthermore, the processing of a video in
    real time needs specialized computing resources close to the pivot-center irrigation
    trained with AI algorithms on real images and then analyzes rapidly, detects problem,
    and then react accordingly. In this paper, we complete our previous proposed IoT
    system to optimize the water use and we displaced the computing of data at the
    edge level in order to be able to process videos locally, event the Internet connection
    is limited. This local computing power also allows us to manage the supply of
    fertilizers and the treatment of plant diseases, and pests.
  doi: 10.1016/j.procs.2020.10.009
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Abstract Keywords References Cited by (29) Procedia Computer Science Volume
    177, 2020, Pages 40-48 Edge AI-IoT Pivot Irrigation, Plant Diseases, and Pests
    Identification Author links open overlay panel Olivier Debauche a b, Saïd Mahmoudi
    a, Meryem Elmoulat b c, Sidi Ahmed Mahmoudi a, Pierre Manneback a, Frédéric Lebeau
    d Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.procs.2020.10.009
    Get rights and content Under a Creative Commons license open access Abstract Overcoming
    population growth dilemma with less resources of soil and water, the irrigated
    agriculture allows us to increase the yield and the production of several crops
    in order to meet the high requirements of demands of food and fibers. Efficiently,
    an irrigation system should correctly evaluate the amount of water and also the
    timing, when applying certain irrigation doses. Global warming of the planet,
    to which is added in some regions an irregular regime of precipitation and a scarcity
    of available water resources, requires precision irrigation systems. The rational
    use of water and inputs (mainly fertilizers and pesticides) is crucial in some
    areas of the planet suffering from a deficiency of water. Hence, in these regions
    where the environmental conditions are harsh to ensure an efficient crop growth.
    Moreover, plant diseases and pests impact the yields of crops. For these reasons
    is it why an early detection gives us the opportunity to treat the disease or
    pest as quickly and effectively as possible, in order, to reduce the impact of
    these latter. Nowadays, the identification of plant diseases and pest with Artificial
    Intelligence algorithms on video flow in real conditions with variable exposition
    are still being a very challenging problem. Researchers classically develop algorithms
    that are trained on calibrated exposition images, which does not perform well
    in real conditions. Furthermore, the processing of a video in real time needs
    specialized computing resources close to the pivot-center irrigation trained with
    AI algorithms on real images and then analyzes rapidly, detects problem, and then
    react accordingly. In this paper, we complete our previous proposed IoT system
    to optimize the water use and we displaced the computing of data at the edge level
    in order to be able to process videos locally, event the Internet connection is
    limited. This local computing power also allows us to manage the supply of fertilizers
    and the treatment of plant diseases, and pests. Previous article in issue Next
    article in issue Keywords Center-pivot IrrigationConnected IrrigationSmart IrrigationWater
    RequirementIntelligent Irrigation View PDF References 1 Ait abdelouahid, R., Debauche,
    O., Mahmoudi, S., Abdelaziz, M., Manneback, P., Lebeau, F., 2020. Smart nest box:
    IoT based nest monitoring in artificial cavities, in: 2020 3rd International Conference
    on Advanced Communication Technologies and Networking (CommNet) (CommNet’20),
    Morocco. pp. 1-8. Google Scholar 2 Ait Abdelouhahid, R., Debauche, O., Mahmoudi,
    S., Marzak, A., Manneback, P., Lebeau, F., 2020. Open phytotron: A new iot device
    for home gardening, in: 2020 5th International Conference on Cloud Computing Technologies
    and Applications (Cloudtech), pp. 1-7. Google Scholar 3 Debauche, O., Ait abdelouahid,
    R., Mahmoudi, S., Moussaoui, Y., Abdelaziz, M., Manneback, P., 2020a. Revo campus:
    a distributed open source and low-cost smart campus, in: 2020 3rd International
    Conference on Advanced Communication Technologies and Networking (Comm-Net) (CommNet’20),
    Morocco. pp. 1-10. Google Scholar 4 Debauche, O., El Moulat, M., Mahmoudi, S.,
    Manneback, P., Lebeau, F., 2018. Irrigation pivot-center connected at low cost
    for the reduction of crop water requirements, in: 2018 International Conference
    on Advanced Communication Technologies and Networking (CommNet), pp. 1-9. doi:10.1109/COMMNET.2018.8360259.
    Google Scholar 5 Debauche, O., Mahmoudi, S., Andriamandroso, A., Manneback, P.,
    Bindelle, J., Lebeau, F., 2018. Cloud services integration for farm animals’ behavior
    studies based on smartphones as activity sensors. Journal of Ambient Intelligence
    and Humanized Computing URL: https://doi.org/10.1007/s12652-018-0845-9, doi:10.1007/s12652-018-0845-9.
    Google Scholar 6 Debauche, O., Mahmoudi, S., Andriamandroso, A., P., M., J., B.,
    Lebeau, F., 2017. Web-based cattle behavior service for researchers based on the
    smartphone inertial central. Procedia Computer Science 110, 110 - 116. URL: http://www.sciencedirect.com/science/article/
    pii/S1877050917313066, doi: https://doi.org/10.1016/j.procs.2017.06.127. 14th
    International Conference on Mobile Systems and Pervasive Computing (MobiSPC 2017)/12th
    International Conference on Future Networks and Communications (FNC 2017) / Affiliated
    Workshops. Google Scholar 7 Debauche, O., Mahmoudi, S., Belarbi, M.A., El Adoui,
    M., Mahmoudi, S.A., 2018a. Internet of things: Learning and practices. application
    to smart home, in: 2018 International Conference on Advanced Communication Technologies
    and Networking (CommNet), pp. 1-6. doi:10. 1109/COMMNET.2018.8360247. Google Scholar
    8 Debauche, O., Mahmoudi, S., Mahmoudi, S.A., 2018b. Internet of things: learning
    and practices. application to smart city, in: 2018 4th International Conference
    on Cloud Computing Technologies and Applications (Cloudtech), pp. 1-7. doi:10.1109/CloudTech.2018.8713337.
    Google Scholar 9 Debauche, O., Mahmoudi, S., Mahmoudi, S.A., Manneback, P., Bindelle,
    J., Lebeau, F., 2020b. Edge computing and artificial intelligence for real-time
    poultry monitoring. Procedia Computer Science 175, 534 - 541. URL: http://www.sciencedirect.com/science/article/
    pii/S1877050920317762, doi: https://doi.org/10.1016/j.procs.2020.07.076. the 17th
    International Conference on Mobile Systems and Pervasive Computing (MobiSPC),
    The 15th International Conference on Future Networks and Communications (FNC),
    The 10th International Conference on Sustainable Energy Information Technology.
    Google Scholar 10 Debauche, O., Mahmoudi, S., Mahmoudi, S.A., Manneback, P., Bindelle,
    J., Lebeau, F., 2020c. Edge computing for cattle behavior analysis, in: 2020 Second
    international conference on Embedded Distributed Systems (EDiS), pp. 1-5. Google
    Scholar 11 Debauche, O., Mahmoudi, S., Mahmoudi, S.A., Manneback, P., Lebeau,
    F., 2020d. Edge computing and artificial intelligence semanti-cally driven. application
    to a climatic enclosure. Procedia Computer Science 175, 542 - 547. URL: http://www.sciencedirect.com/
    science/article/pii/S1877050920317774, doi: https://doi.org/10.1016/j.procs.2020.07.077.
    the 17th International Conference on Mobile Systems and Pervasive Computing (MobiSPC),
    The 15th International Conference on Future Networks and Communications (FNC),
    The 10th International Conference on Sustainable Energy Information Technology.
    Google Scholar 12 Debauche, O., Mahmoudi, S., Mahmoudi, S.A., Manneback, P., Lebeau,
    F., 2020e. A new edge architecture for ai-iot services deployment. Procedia Computer
    Science 175, 10-19. URL: http://www.sciencedirect.com/science/article/pii/S1877050920316859,
    doi: https://doi.org/10.1016/j.procs.2020.07.006. the 17th International Conference
    on Mobile Systems and Pervasive Computing (MobiSPC), The 15th International Conference
    on Future Networks and Communications (FNC), The 10th International Conference
    on Sustainable Energy Information Technology. Google Scholar 13 Debauche, O.,
    Mahmoudi, S., Manneback, P., Assila, A., 2019. Fog iot for health: A new architecture
    for patients and elderly monitoring. Procedia Computer Science 160, 289 - 297.
    URL: http://www.sciencedirect.com/science/article/pii/S1877050919317880, doi:
    https://doi.org/10.1016/j.procs.2019.11.087. the 10th International Conference
    on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN-2019) / The 9th International
    Conference on Current and Future Trends of Information and Communication Technologies
    in Healthcare (ICTH-2019) / Affiliated Workshops. Google Scholar 14 Debauche,
    O., Mahmoudi, S., Manneback, P., Massinon, M., Tadrist, N., Lebeau, F., Mahmoudi,
    S.A., 2017. Cloud architecture for digital phenotyping and automation, in: 2017
    3rd International Conference of Cloud Computing Technologies and Applications
    (CloudTech), pp. 1-9. doi:10.1109/CloudTech.2017.8284718. Google Scholar 15 Debauche,
    O., Mahmoudi, S., Manneback, P., Tadrist, N., Bindelle, J., Lebeau, F., 2017.
    Improvement of battery life of iphones inertial measurement unit by using edge
    computing application to cattle behavior, in: 2017 Symposium International sur
    les Sciences Informatiques et Applications (ISCSA2017), pp. 1-4. Google Scholar
    16 Debauche, O., Mahmoudi, S., Moussaoui, Y., 2020. Internet of things learning:
    a practical case for smart building automation, in: 2020 5th International Conference
    on Cloud Computing Technologies and Applications (Cloudtech), pp. 1-7. Google
    Scholar 17 Debauche O., Mahmoudi S.A., De Cock N., Mahmoudi S., Manneback P.,
    Lebeau F. Cloud architecture for plant phenotyping research Concurrency and Computation:
    Practice and Experience, 32 (2020), p. e5661 URL: https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.5661,
    doi:10.1002/cpe.5661, arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.5661.
    e5661 cpe.5661. View in ScopusGoogle Scholar 18 Debauche, O., Mahmoudi, S.A.,
    Mahmoudi, S., Manneback, P., 2018a. Cloud platform using big data and hpc technologies
    for distributed and parallels treatments. Procedia Computer Science 141, 112 -
    118. URL: http://www.sciencedirect.com/science/article/pii/ S1877050918318064,
    doi: https://doi.org/10.1016/j.procs.2018.10.156. the 9th International Conference
    on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN-2018) / The 8th International
    Conference on Current and Future Trends of Information and Communication Technologies
    in Healthcare (ICTH-2018) / Affiliated Workshops. Google Scholar 19 Debauche,
    O., Moulat, M.E., Mahmoudi, S., Boukraa, S., Manneback, P., Lebeau, F., 2018b.
    Web monitoring of bee health for researchers and beekeepers based on the internet
    of things. Procedia Computer Science 130, 991 - 998. URL: http://www.sciencedirect.com/
    science/article/pii/S1877050918304654, doi: https://doi.org/10.1016/j.procs.2018.04.103.
    the 9th International Conference on Ambient Systems, Networks and Technologies
    (ANT 2018) / The 8th International Conference on Sustainable Energy Information
    Technology (SEIT-2018) / Affiliated Workshops. Google Scholar 20 Elmoulat, M.,
    Debauche, O., Mahmoudi, S., Mahmoudi, S.A., Manneback, P., Lebeau, F., 2020. Edge
    computing and artificial intelligence for landslides monitoring. Procedia Computer
    Science The 11th International Conference on Emerging Ubiquitous Systems and Pervasive
    Networks (EUSPN 2020) / The 10th International Conference on Current and Future
    Trends of Information and Communication Technologies in Healthcare (ICTH 2020)
    / Affiliated Workshops. Google Scholar 21 Gavali, M., Dhus, B., Vitekar, A., 2016.
    A smart irrigation system for agriculture based on wireless sensors. International
    Journal of Innovative Research in Science, Engineering and Technology, 6893-6899.
    Google Scholar 22 González-Briones, A., Castellanos-Garzón, J.A., Mezquita Martín,
    Y., Prieto, J., Corchado, J.M., 2018. A framework for knowledge discovery from
    wireless sensor networks in rural environments: a crop irrigation systems case
    study. Wireless Communications and Mobile Computing 2018. Google Scholar 23 Jimenez,
    A.F., Herrera, E.F., Ortiz, B.V., Ruiz, A., Cardenas, P.F., 2018. Inference system
    for irrigation scheduling with an intelligent agent, in: International Conference
    of ICT for Adapting Agriculture to Climate Change, Springer. pp. 1-20. Google
    Scholar 24 Mendes W.R., Araújo F.M.U., Dutta R., Heeren D.M. Fuzzy control system
    for variable rate irrigation using remote sensing Expert systems with applications,
    124 (2019), pp. 13-24 View PDFView articleView in ScopusGoogle Scholar 25 Moulat,
    M.E., Debauche, O., Mahmoudi, S., Brahim, L.A., Manneback, P., Lebeau, F., 2018.
    Monitoring system using internet of things for potential landslides. Procedia
    Computer Science 134, 26 - 34. URL: http://www.sciencedirect.com/science/article/pii/
    S1877050918311037, doi: https://doi.org/10.1016/j.procs.2018.07.140. the 15th
    International Conference on Mobile Systems and Pervasive Computing (MobiSPC 2018)
    / The 13th International Conference on Future Networks and Communications (FNC-2018)
    / Affiliated Workshops. Google Scholar 26 Vatsavai R.R., Shekhar S., Burk T.E.,
    Lime S. Umn-mapserver: A high-performance, interoperable, and open source web
    mapping and geo-spatial analysis system Raubal M., Miller H.J., Frank A.U., Goodchild
    M.F. (Eds.), Geographic Information Science, Springer, Berlin Heidelberg, Berlin,
    Heidelberg (2006), pp. 400-417 CrossRefView in ScopusGoogle Scholar 27 Villarrubia
    G., Paz J.F.D., Iglesia D.H., Bajo J. Combining multi-agent systems and wireless
    sensor networks for monitoring crop irrigation Sensors, 17 (2017), p. 1775 CrossRefView
    in ScopusGoogle Scholar Cited by (29) A comprehensive survey on IoT and AI based
    applications in different pre-harvest, during-harvest and post-harvest activities
    of smart agriculture 2024, Computers and Electronics in Agriculture Show abstract
    A novel autonomous irrigation system for smart agriculture using AI and 6G enabled
    IoT network 2023, Microprocessors and Microsystems Show abstract Cloud and distributed
    architectures for data management in agriculture 4.0: Review and future trends
    2022, Journal of King Saud University - Computer and Information Sciences Citation
    Excerpt : The MAS simultaneously manages pivot irrigation, plant diseases and
    pests'' detection, and their curation. The data is partially transmitted to the
    cloud to improve the detection of diseases and pests and retrain AI algorithms
    before their redeployment at the edge level (Debauche et al., 2020). Debauche
    et al. described a fog architecture in which a Gated Recursive Unit (GRU) algorithm
    is deployed on NVIDIA Jetson Nano for real-time poultry monitoring. Show abstract
    A smart agriculture framework for IoT based plant decay detection using smart
    croft algorithm 2022, Materials Today: Proceedings Citation Excerpt : Researches
    have been conducted considering only the color component of leaves which leaves
    out some important climatic conditions using python and OpenCV [11]. While the
    researches that use machine, learning have to use python programming to implement
    their system, we’ve used c language to program Arduino[12]. The same observations
    have been made by researchers by using Raspberry pi integrated with machine learning
    [14]. Show abstract Edge computing and artificial intelligence for landslides
    monitoring 2020, Procedia Computer Science Show abstract INTEGRATION OF IOT-ENABLED
    TECHNOLOGIES AND ARTIFICIAL INTELLIGENCE IN DIVERSE DOMAINS: RECENT ADVANCEMENTS
    AND FUTURE TRENDS 2024, Journal of Theoretical and Applied Information Technology
    View all citing articles on Scopus © 2020 The Author(s). Published by Elsevier
    B.V. Part of special issue The 11th International Conference on Emerging Ubiquitous
    Systems and Pervasive Networks (EUSPN 2020) / The 10th International Conference
    on Current and Future Trends of Information and Communication Technologies in
    Healthcare (ICTH 2020) / Affiliated Workshops Edited by Elhadi M. Shakshuki, Ansar
    Yasar Download full issue Other articles from this issue The 11th International
    Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN 2020)
    2020 View PDF Identifying Users with Wearable Sensors based on Activity Patterns
    2020 Muhammad Ehatisham-ul-Haq, …, Mustansar Ali Ghazanfar View PDF A Partial
    Pre-composing Method for Composition of Web Services 2020 Jing Li, …, Yifei Wang
    View PDF View more articles Recommended articles Article Metrics Citations Citation
    Indexes: 27 Captures Readers: 89 View details About ScienceDirect Remote access
    Shopping cart Advertise Contact and support Terms and conditions Privacy policy
    Cookies are used by this site. Cookie settings | Your Privacy Choices All content
    on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply."'
  inline_citation: '>'
  journal: Procedia Computer Science
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Edge AI-IoT pivot irrigation, plant diseases, and pests identification
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors: []
  citation_count: '0'
  description: 'The proceedings contain 124 papers. The special focus in this conference
    is on Advanced Design and Manufacturing Technologies, Technology and Method for
    Measurement, Detection and Monitoring, Applied Materials and Materials Processing
    Technology, Control System and Automation, Sensor Technology, Computer Science
    and Applications and Applied Mechatronics. The topics include: Microhardness analysis
    of laser cladding CBN coating on the surface of titanium alloy; research on the
    dilution rate of laser-clad CBN based on titanium alloy substrate; evaluation
    of light protective properties of high performance aramid fabrics; development
    of desulfurization agent in RH refining process; statistical analysis of dynamic
    properties of solid carbide end mill; discussion on calculation method of internal
    force of bending beam in mechanics of materials; study on surface roughness of
    milling based on the elastic-plastic deformation; deformation analysis of the
    net surface of the mesh antennas under the gravity action; theoretical stress
    concentration factor for spatial helix gear; FE modeling for load distribution
    analysis of multi-bolt composite joints; quasi-static contact analysis of an inchworm-type
    piezoelectric-driven rotary actuator via finite element method; research on vibration
    characteristics of horn with longitudinal bending vibration; vessel traffic flow
    distribution model of bridge area waterway in the middle stream of Yangtze river;
    development of humanoid robot teaching system based on a RGB-D sensor; filter
    design of power battery resistance measuring for new energy vehicle; transient
    vibration analysis of impact ripper; dynamic model of spindle-holder taper joint
    of BT40 holder; theoretical analysis and experimental study on the vibration of
    the bimorph piezoelectric vibrator for piezoelectric pump; study on stress state
    of low-frequency vibration cutting process based on finite element simulation;
    the life evaluation to determine remanufacturing access period of telescopic boom
    for mobile crane; research on failure criterion of lattice jib structural system
    reliability; a rotary spiral array applied in near-field acoustical holography;
    a new type of accelerometer based on fiber Bragg grating; development of aircraft
    used wires for general purpose and a study on the application; reliability design
    for automobile rear axle by perturbation method; optimization of double pivot
    suspension kingpin axis during steering; research on the EDM equipment and the
    machining technology of the precision micro-hole; a study on design principle
    of the knee rehabilitation device with two degrees of freedom; a simple red tide
    warning device; noise transfer function refinement of commercial vehicle cab based
    on the vibro- acoustic model; discussion on the application of activity-based
    costing in virtual manufacturing cell mode; comprehensive parameters adaption
    of rolling force model based on objective function in tandem cold mill; simulation
    study on coupling effect under HEMP of shielding control box; experimental study
    on diesel engine intake ports with reverse engineering technology; research on
    general interface model suitable for electromechanical transient simulation; research
    on general interface model suitable for electromechanical transient simulation;
    research on the new missile actuation system with dual independent closed-loop;
    a method of the detection of marine pollution based on the measurement of refractive
    index; measuring influence and impact by complex network; ground penetrating radar
    technology and its application in civil engineering; analysis of temperature field
    on combining friction discs of wet clutch; studies on novel satellite navigation
    and positioning system anti-jamming architecture; water resources allocation of
    China based on the projection pursuit cluster; surface roughness measuring based
    on the theory of fractal geometry; study and calculation of geomagnetic induced
    current in power grid; an adaptive time delay alignment technique based on equalizer
    taps in a sensor array; modeling and simulating of PMSM space vector PWM drive
    system based on fuzzy immune PI control method; hydraulic leveling technology
    for electro-hydraulic proportional control based on fuzzy PID; the design of motor
    energy-saving controller based on the frequency converter; review of ejection
    seat electronic program controller; cost control of the marine diesel based on
    value engineering; research on the new missile electro-hydraulic actuation system
    based on two-stage speed control mode; experimental study of micro milling burr
    control based on process parameters optimization; the lateral shift of refraction
    Sh-wave on an interface of two media; research on optimal configuration of the
    filter in distribution network with distributed power; data conversion from BPA
    and PSASP to the third party software based on template matching algorithm; optimization
    algorithm study for multiple-constrained and multiple-objective job-shop tool
    dynamic distribution; research and evaluation of bionics shape design based on
    cases; a study on the intelligent bladder irrigation technology; on two first
    order reliability methods for computing the non-probabilistic reliability index;
    research and application of the key technologies of open-architecture auxiliary
    systems for monitoring the operation and maintenance of the information system;
    design and implementation of online shopping system based on J2EE; design and
    implementation of online shopping system based on J2EE; traffic jam prediction
    through Elman neural network based on Monte Carlo simulation; the application
    of IBE encryption scheme in grid environments; rectangular paper scraps recovery
    based on a new edge detection; research of the wheat modeling problems based on
    creator; a complex network analysis of the top college coaches; the characteristics
    analysis about objects of corporate blog marketing in China and coach evaluation
    method based on AHP.'
  doi: null
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: Applied Mechanics and Materials
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 2014 International Conference on Design, Manufacturing and Mechatronics,
    ICDMM 2014
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

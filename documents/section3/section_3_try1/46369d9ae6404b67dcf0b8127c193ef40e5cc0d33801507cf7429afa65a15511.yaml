- analysis: '>'
  authors:
  - Zhang F.
  - Feng J.
  - Liu Y.
  - Shao W.
  - Li Y.
  - Wang S.
  - Lv J.
  citation_count: '0'
  description: Obtaining information on cotton yields and creating a spatial map of
    cotton production is the starting point for implementing precision agriculture.
    Microwave technology has been used for yield estimation in China for crops such
    as corn and soybeans and has shown strong applicability. However, research on
    cotton yield estimation using microwave technology is weak. Therefore, this paper
    proposes a method for seed cotton mass estimation based on the microwave Doppler
    method and designs bench tests to prove the feasibility of the method. First,
    a seed cotton speed estimation model was established based on the microwave Doppler
    effect and fast Fourier transform. On this basis, a seed cotton velocity estimation
    experiment was designed to study the effects of sensor installation angle and
    position, pipe collision friction, air resistance, and the interaction force between
    the seed cotton on the seed cotton movement velocity. The power spectral density
    (PSD) of the acquired microwave data is then estimated using the modified periodogram
    method. The least squares method was used to establish a linear regression model
    between seed cotton mass and the corresponding PSD, and finally the free-fall
    mass experiment and pneumatic conveying mass experiment yielded that the estimation
    errors of seed cotton mass were 7.30% and 6.17%, respectively. The experimental
    results show that the estimation error is small when using microwave technology
    for seed cotton mass estimation, which meets the requirements of actual operation.
  doi: 10.1088/1361-6501/ad23c2
  full_citation: '>'
  full_text: '>

    "We value your privacy Clicking the \"Accept All\" button means you are accepting
    analytics and third-party cookies. We use cookies to optimise site functionality
    and give you the best possible experience. To control which cookies are set, click
    \"Customize\". Privacy and Cookies policy Customize Accept All Skip to content
    IOP Science home Accessibility Help Search Journals Books Publishing Support Login
    Measurement Science and Technology PAPER A novel microwave Doppler method for
    mass estimation of machine-picked seed cotton Feng Zhang1, Jingan Feng3,1, Ya
    Liu2, Wenping Shao1, Yuhang Li1, Shu Wang1 and Jiangfeng Lv1 Published 29 February
    2024 • © 2024 IOP Publishing Ltd Measurement Science and Technology, Volume 35,
    Number 5 Citation Feng Zhang et al 2024 Meas. Sci. Technol. 35 055126 DOI 10.1088/1361-6501/ad23c2
    Download Article PDF Figures References Open science   Article metrics 26 Total
    downloads Submit Submit to this Journal MathJax Turn on MathJax Permissions Get
    permission to re-use this article Share this article Article and author information   Abstract
    Obtaining information on cotton yields and creating a spatial map of cotton production
    is the starting point for implementing precision agriculture. Microwave technology
    has been used for yield estimation in China for crops such as corn and soybeans
    and has shown strong applicability. However, research on cotton yield estimation
    using microwave technology is weak. Therefore, this paper proposes a method for
    seed cotton mass estimation based on the microwave Doppler method and designs
    bench tests to prove the feasibility of the method. First, a seed cotton speed
    estimation model was established based on the microwave Doppler effect and fast
    Fourier transform. On this basis, a seed cotton velocity estimation experiment
    was designed to study the effects of sensor installation angle and position, pipe
    collision friction, air resistance, and the interaction force between the seed
    cotton on the seed cotton movement velocity. The power spectral density (PSD)
    of the acquired microwave data is then estimated using the modified periodogram
    method. The least squares method was used to establish a linear regression model
    between seed cotton mass and the corresponding PSD, and finally the free-fall
    mass experiment and pneumatic conveying mass experiment yielded that the estimation
    errors of seed cotton mass were 7.30% and 6.17%, respectively. The experimental
    results show that the estimation error is small when using microwave technology
    for seed cotton mass estimation, which meets the requirements of actual operation.
    Export citation and abstract BibTeX RIS Previous article in issue Next article
    in issue 1. Introduction Agricultural production methods in countries around the
    world are gradually transitioning to modern agriculture. Precision agriculture
    (PA), as the development direction of modern agriculture, has attracted the attention
    of many scholars [1]. How to quickly and accurately obtain the spatial distribution
    of crops is of great significance for the implementation of PA and the improvement
    of economic efficiency. In China, the application of yield monitoring technology
    for corn, wheat and other grain crops is driving the development of PA, but yield
    monitoring technology for cotton in China is still in its infancy. The main factors
    for cotton yield estimation are the collection time and the mass of cotton collected
    per unit of time, so the estimation of cotton mass is a prerequisite for yield
    estimation. At present, machine picking seed cotton operations commonly use pipeline
    pneumatic conveying seed cotton. If the traditional form of contact measurement
    is used it can easily lead to physical contact between the sensor and the cotton,
    which in turn can cause damage to the sensor or inaccuracy of the measurement
    data [2]. Therefore, estimating seed cotton mass using non-contact methods has
    become an important element in the field of cotton yield estimation [3]. Optical
    methods are commonly used in the estimation of seed cotton mass and flow rate.
    In addition to this, some scholars have also studied estimation methods such as
    the capacitance method and the line pressure difference method [4, 5]. Using near-infrared
    light as a light source, An et al established a cotton fiber mass density model
    using regression analysis by measuring the attenuation rate of light intensity
    through cotton fibers and combining it with the measured quality of cotton fibers,
    and the average error of the measurement results reached 6.1% [6]. Wang et al
    designed a wireless sensor-based laser and sensor flow estimation device and proposed
    a three-dimensional image out processing algorithm to accurately calculate the
    cotton flow rate, and the accuracy of cotton flow estimation reached 97% [7].
    However, this sensor installation process is cumbersome. During rainy days, the
    cotton absorbs water and deforms, causing the yield monitoring effect of this
    detection system to deviate from the real value. Lin et al introduced a generalized
    regression neuron network to establish a real-time cotton flow dynamic detection
    calibration model based on the photoelectric sensing principle, and the comparison
    of the actual training and application results showed that the established calibration
    model has good regression capability and measurement accuracy [8]. Since the optical
    method reflects the weight and flow information of seed cotton by measuring the
    attenuation of light intensity transmitted or reflected after passing through
    the cotton, this method is susceptible to the influence of ambient temperature,
    scattered light, fallen leaves, and soil covering on the surface of the device,
    which reduces the estimation accuracy [9]. Zhou designed a capacitive sensor with
    a differential structure that can well eliminate the ambient temperature interference,
    and the relative error of the measured seed cotton mass flow rate is 5.16% [10].
    However, this method requires the use of electrodes to contact the surface of
    the seed cotton for measurement, which is easy to damage the integrity of the
    seed cotton, and the installation process of the capacitor is cumbersome. Mailander
    and Moriasi [11] used air flow pressure to measure cotton mass flow rate. The
    sensors were tested on a stationary cotton picker and the moisture content of
    seed cotton was 5.9% and 8.5%. Regression analysis of the mean values of the data
    signals yielded a coefficient of determination of 0.43 for low moisture content
    and 0.84 for higher moisture content. The results suggest that air flow pressure
    has the potential to be used as an alternative method for cotton yield estimation.
    However, this method has an estimation error of more than 40% at cotton moisture
    contents below 6% and is not applicable to variable field conditions. Although
    the above methods are feasible, they require modification of the cotton transport
    pipeline, are troublesome to install sensors, and are sensitive to the specific
    properties of cotton and environmental conditions, which need to be adjusted and
    calibrated according to different situations. As a non-contact measurement method,
    the microwave method is not only easy to install, but also less affected by external
    environmental factors [12]. For the complex environment in the field has a stronger
    anti-interference ability, has been applied to soybeans, corn and other crops
    in the mass estimation and fertilization flow detection. Sun and Liu [13] used
    a microwave Doppler sensor to design a solid mass flow measurement system based
    on LABVIEW. Taking soybean as the experimental object, the linear relationship
    between its power spectral density (PSD) and mass flow rate was established, and
    the measured solid mass flow rate was calculated based on this linear relationship.
    The experiment proves that the system has good real-time performance and the measured
    mass flow rate has practical application. Duan and Zhang [14] used the least squares
    method to fit a model of the PSD of the measured soybeans with the corresponding
    mass flow rate. By comparing the fit of dual microwave sensors with that of a
    single sensor, it is concluded that the microwave field covered by flow detection
    using multiple sensors is more uniform, and the accuracy of the system is improved,
    which is of practical significance for the study of the measurement of gas–solid
    two-phase flow. Ma et al designed a microwave yield sensor to model the relationship
    between the microwave PSD and the corresponding soybean quality by analyzing the
    microwave echo signals, which was experimentally verified to have a low average
    measurement error of 8% [15]. Yang et al obtained the velocity and concentration
    of fertilizer particles through the Doppler signal processed by the fast Fourier
    transform (FFT), defined the product of velocity and concentration as the output
    value of the sensor, and used the least squares method to establish the relationship
    between the output value of the sensor and the mass flow rate of the fertilizer,
    and the model was verified by the experiment, and the relative error was not more
    than 10.04% [2]. Zou et al [16] designed a microwave sensor to measure the velocity
    of solid particles from the Doppler effect, and then use the velocity measurement
    process to get the power signal, analyze the power and weight relationship and
    fit the equation. Through the test, verify how the antenna installation position
    affects the measured power, and propose measures to improve the problem. The above
    studies have shown that the use of microwave sensors to measure the mass of solids
    has the advantages of easy installation of the sensors in harsh environments,
    low detection errors, and low price. However, mass measurement using microwave
    sensors has not yet been applied to seed cotton quality estimation in China. Aiming
    at the phenomenon that microwave technology has not been used for seed cotton
    quality estimation in China, this paper proposes a seed cotton quality estimation
    method based on the microwave Doppler method and designs a bench test to verify
    the feasibility of the method. The Doppler frequency was obtained by fast Fourier
    transforming the microwave signals with the seed cotton transport velocity. Then,
    experiments were designed to investigate the factors affecting seed cotton conveying
    speed. Finally, PSD estimation was performed on the spectrum after FFT to establish
    a model of seed cotton mass and corresponding PSD, and the model accuracy was
    verified. The paper is structured as follows: section 2 describes the principles
    of seed cotton speed measurement and mass estimation. In section 3, a bench test
    was designed to verify the feasibility of the proposed method by seed cotton velocity
    estimation test and mass estimation test. The conclusions are presented in section
    4. Section 5 is a discussion of the future application of the proposed methodology.
    2. System working principle 2.1. Principle of velocity estimation Because the
    Doppler frequency is generated on the condition that there is relative motion
    of the object, the Doppler frequency can provide velocity information and the
    Doppler frequency is proportional to the velocity of the object''s motion [17–19].
    The Doppler frequency schematic is shown in figure 1. Zoom In Zoom Out Reset image
    size Figure 1. The Doppler frequency schematic. Download figure: Standard image
    High-resolution image As shown in figure 1, a wave source is given with a moving
    object S. Considering the condition that the microwave sensor needs to be fixedly
    installed in this experiment, the relationship between the Doppler frequency and
    the speed of the moving object is illustrated by taking the example that the wave
    source is stationary and the moving object is close to the microwave antenna.
    From figure 1, when the moving object and the microwave source are in the same
    line, the receiving frequency of the moving object is as follows: Since the wave
    source is stationary, the wave source emits the same frequency as the microwave
    frequency in the air, , then: where is the microwave speed, the microwave wave
    speed in the air is approximated to the speed of light. The received frequency
    is defined as the number of complete waves that pass through the moving object
    continuously in 1 s. When calculating the receiving frequency of the microwave
    sensor, the moving object acts as the microwave transmitting end with the transmitting
    frequency , and the microwave sensor acts as the receiving end with the receiving
    frequency as follows: Further, the Doppler frequency of the microwave sensor can
    be obtained as: The plus and minus signs in the Doppler frequency represent the
    proximity and distance of a moving object and do not affect the calculation of
    the velocity value, which is uniformly taken as an absolute value in the following
    for ease of calculation. When the direction of motion of the moving object has
    a certain angle with the direction of microwave emission, equation (4) is adjusted
    to: where is the angle between the moving object''s direction of motion and the
    microwave sensor''s main beam axis. From equation (5), the microwave Doppler frequency
    and the measured object velocity are one-to-one correspondence, which can be obtained
    . However, in the machine picking process, the seed cotton is continuously transported
    through the pipeline, and the interaction between the seed cotton and the friction
    of the pipeline wall will affect the transport velocity of the seed cotton, so
    the Doppler signal is an overlap of multiple frequency signals. The microwave
    emission signal is reflected and absorbed by the moving seed cotton to obtain
    the superimposed microwave echo equation: where is the number of seed cotton reflecting
    microwaves, is the ith seed cotton, is the Doppler signal of single seed cotton,
    and is a fixed reflected wave such as the reflection of microwaves by the pipe
    wall. The superimposed echo signals are mixed and filtered to obtain the superimposed
    Doppler signal as: where is the amplitude of the ith seed-cotton echo, is the
    frequency of the ith seed-cotton echo, is the phase of the ith seed-cotton echo,
    and W is the noise, which is assumed to be Gaussian white noise in this paper.
    From the above analysis, it can be seen that when the seed cotton is continuously
    conveyed, the average conveying speed of seed cotton is as follows: where is the
    average Doppler frequency, with the spectral amplitude squared as the weighting
    factor. The average Doppler frequency is obtained after the weighted average of
    the frequency amplitudes of the aliased Doppler signals after FFT: where is the
    frequency value at each point of the Doppler signal after FFT and is the frequency
    amplitude at each point of . 2.1.1. Spectrum analysis algorithm. From equations
    (5) and (8), the estimation of velocity requires the acquisition of the Doppler
    frequency of the seed cotton. Since the characteristics of the acquired time domain
    signals were not obvious, the Doppler signals were transformed to the frequency
    domain, and their spectra were statistically and analytically analyzed to obtain
    the Doppler frequency of seed cotton transport. For the velocity measurement of
    single cotton, firstly, the collected time domain signal is transformed to the
    frequency domain, and according to the FFT algorithm, the peak Doppler frequency
    of the seed cotton is found out, and the frequency of the point is taken out as
    the Doppler frequency of the seed cotton, which is then brought into the equation
    (5) to calculate the instantaneous velocity of the single seed cotton. For the
    continuous conveying of seed cotton speed measurement, the average frequency after
    FFT of the aliased Doppler signal is obtained according to equation (9), and the
    average speed of seed cotton conveying is calculated in equation (8). In this
    paper, the time domain extracted basis 2FFT algorithm (DIT-FFT) is selected for
    spectrum analysis, and the principle is as follows: (1)   The microwave signals
    obtained from the microwave sensors are converted into discrete digital quantities
    and the sequence is divided into odd and even groups according to : where is a
    sequence of discrete numbers, is a sequence of even numbers, and is a sequence
    of odd numbers. (2)   Using the approximability of the rotation factor, the discrete
    Fourier transform (DFT) of x is performed as in equation (11), and the DFT of
    the first N/2 points is obtained as in equation (12): where is the Fourier transformed
    value of , is the number of DFT transform points, in this paper N = 1024, is the
    rotation factor, (3)   Use periodicity to find the last N/2 points of the DFT:
    Then the result of one time-domain extraction of the DFT at N points is as follows:
    Figure 2 shows the schematic diagram of the butterfly operation of equation (14).
    (4)   Obtained by quadratic decomposition of and : The decomposition continues
    according to equation (15) until a single-point DFT is performed. The principle
    of seed cotton ptspeed estimation is shown in figure 3. Zoom In Zoom Out Reset
    image size Figure 2. Schematic diagram of butterfly operation. Download figure:
    Standard image High-resolution image Zoom In Zoom Out Reset image size Figure
    3. Principle of seed cotton velocity estimation. Download figure: Standard image
    High-resolution image In summary, it can be seen that the DIT-FFT algorithm is
    accelerated compared to the traditional DFT algorithm for complex multiplication
    by and complex addition by . The computational complexity of the DIT-FFT algorithm
    and the DFT algorithm is shown in table 1. Table 1. The computational complexity
    of DIT-FFT and DFT. Algorithms Complex multiplication Complex addition DFT DIT-FFT
    2.2. Principle of mass estimation When using the Doppler effect for velocity estimation,
    the Doppler signal generated by the microwave sensor not only contains the Doppler
    frequency information of the seed cotton movement but also includes the strength
    of the seed cotton echo signal, which is manifested as the PSD. When the microwave
    sensor emits microwaves, a microwave measurement field is formed inside the sensor
    and the cotton delivery pipeline. If there is no seed cotton passing through the
    pipeline, the strength of the reflected echo signal remains unchanged. However,
    when seed cotton passes through the pipeline, the emitted wave is reflected and
    absorbed by the seed cotton, resulting in signal attenuation relative to the emitted
    wave. This signal attenuation can be expressed using PSD. When the quantity of
    seed cotton increases, the presence of multiple seed cotton reflections in the
    microwave signal results in an increase in the strength of the echo signal, manifested
    as an increase in PSD. Therefore, there should be a positive correlation between
    seed cotton mass and PSD. Due to its high robustness and strong applicability
    in fitting functions, the least squares method was employed to establish a linear
    regression model between seed cotton mass and PSD, aiming to estimate the seed
    cotton mass. The details of this establishment are presented in section 3.3. In
    this paper, the modified periodogram method (MPM) is chosen for PSD estimation,
    which is based on the following principle: (1)   The number of segments K is given
    by segmenting with overlap and each segment is of length M: where denotes the
    rounding operation and is the overlap rate between each segment of data and the
    neighboring data, which is generally taken as . In this paper, is chosen. (2)   For
    the ith segment of data plus the Hanning window for: (3)   Calculate the PSD of
    the ith segment of data : where is the normalization operator. (4)   The estimated
    value of PSD is obtained by summing and averaging the power spectrum of each segment:
    (5)   Finally, the relationship between seed cotton mass and PSD is obtained through
    the least squares method as follows: where m is the seed cotton mass, x is the
    PSD corresponding to the seed cotton mass, and a, b, c, d are the optimal parameters
    estimated by the least squares method. The seed cotton mass estimation scheme
    proposed in this paper is shown in figure 4. The collected microwave Doppler signals
    were sent to the computer after A/D conversion by the data acquisition instrument,
    and the cotton mass model was obtained by MPM. Finally, the accuracy of the model
    was verified by comparing the actual weight of seed cotton with the estimated
    mass. Zoom In Zoom Out Reset image size Figure 4. Seed cotton mass estimation
    scheme. Download figure: Standard image High-resolution image 3. Bench experiment
    3.1. Materials and equipment 3.1.1. Experimental materials. The bench experiment
    selected seed cotton as the measurement object. The main components of seed cotton
    for cellulose, fat, protein and water, of which water is a polar molecule, which
    absorbs energy when it moves in the magnetic field generated by microwaves, so
    the loss of water to microwaves is greater than that of cellulose and other substances,
    which is the main factor affecting the accuracy of the estimation system. In summary,
    the moisture content of the test seed cotton needs to be determined prior to bench
    testing. The moisture content of seed cotton was determined using the drying method
    [20], the measurement principle is shown in equation (21) where is the weight
    of seed cotton before drying and is the weight of seed cotton after drying. The
    results of the seed cotton moisture content test were obtained using an MA100
    rapid moisture meter with 0.01% accuracy as shown in table 2. Table 2. Determination
    of moisture content of seed cotton. Serial number Wet weight (g) Dry weight (g)
    Moisture content (%) 1 0.403 0.391 2.98 2 0.424 0.413 2.59 3 0.358 0.348 2.80
    4 0.493 0.479 2.84 5 0.394 0.382 3.05 6 0.459 0.440 4.14 7 0.406 0.393 3.20 8
    0.306 0.297 2.94 9 0.401 0.393 2.00 10 0.360 0.350 2.77 The substance flowing
    in the pipeline is a composite of seed cotton, moisture, and air. Its composite
    magnetic conductivity [21] can be represented as: where are the volume of the
    mixture, seed cotton, water and air, respectively, are the relative composite
    permeability of the mixture, seed cotton, water and air respectively. In practical
    production, the relative permittivity of seed cotton and air in the mixture are
    denoted as respectively. As for water, it can be expressed as: where the permittivity
    of the water in the microwave band of 24.125 GHz is [22]; is the loss angle of
    the water and . When microwaves propagate through seed cotton, the propagation
    equation is as follows [23]: where is the attenuation coefficient, is the phase
    shift coefficient, reflecting the attenuation and phase shift per unit length
    as microwaves propagate through the seed cotton. Substituting and equation (23)
    into equation (22) yields the relationship between the composite magnetic conductivity
    of the mixture and the concentration of each phase. By then combining this with
    equation (24), the real part and the imaginary part can be obtained as: where
    is the angular frequency of microwave emission, the vacuum permittivity is , and
    the vacuum permeability is [24]. According to equation (25), the microwave attenuation
    value is linearly correlated with the volume concentration of water. This article
    assumes that seed cotton adheres to an ideal model, satisfying conditions such
    as uniform mixing, minimal dilution effects, and stable temperature and pressure.
    Through the aforementioned simplifications, the volume concentration of water
    in the seed cotton can be approximated as the moisture content. In the experiment,
    microwaves pass through a pipeline containing seed cotton, thus the microwave
    transmission distance is equivalent to the width of the pipeline, denoted as B
    = 80 mm. This relationship provides an equation describing the microwave loss
    in relation to the moisture content M of the seed cotton The microwave losses
    corresponding to different moisture contents of the seed cotton are obtained from
    equation (27) as shown in table 3. Table 3. The relationship between microwave
    loss and moisture content. Frequency (GHz) Moisture content (%) Microwave loss
    (dB) 24.125 5 0.077 24.125 8 0.123 24.125 10 0.154 24.125 12 0.185 24.125 15 0.231
    From table 3, the fitted equation for the relationship between microwave loss
    and moisture content, as given by equation (28), where the coefficient of determination
    is , demonstrates a good fit As the essence of microwave loss is power dissipation,
    and PSD represents the magnitude of power within each hertz frequency range, both
    are expressions reflecting power. Hence, PSD can be expressed in decibels. By
    comparing the difference between microwave loss and PSD, if the microwave loss
    is far smaller than the PSD, then the influence of moisture on system accuracy
    can be neglected. By selecting the highest moisture content of seed cotton from
    table 2 and substituting it into equation (28), the microwave loss is calculated
    to be 0.064 dB. The minimum PSD from tables 8–11 is expressed in decibels as .
    Through the above analysis, it is evident that the minimum PSD of the measured
    seed cotton in the experiment is far greater than the microwave loss. Therefore,
    this study can neglect the influence of moisture on the system accuracy. 3.1.2.
    Experimental equipment. 3.1.2.1. Microwave Doppler sensor module. The microwave
    sensor module consists of a microwave probe and a signal conditioning circuit.
    The microwave probe is used to send and receive microwaves and is the pre-processing
    link of this sensor. Most of the microwave Doppler sensors in the literature utilizing
    the Doppler effect for velocity detection and mass detection operate in the C-band
    at 5.8 GHz, the X-band at 10.525 GHz, and the K-band at 24.125 GHz [25, 26]. The
    C-band and X-band frequencies are low, the beam main lobe width is wide, and the
    anti-interference performance is poor. The K-band frequency is high, the beam
    main lobe width is narrow, and the directivity is better, which is conducive to
    data sampling and analysis. Therefore, the system uses a 24.125 GHz K-band planar
    microstrip microwave probe. The schematic diagram of the planar microstrip microwave
    probe is shown in figure 5. Zoom In Zoom Out Reset image size Figure 5. Schematic
    diagram of a planar microstrip microwave probe. Download figure: Standard image
    High-resolution image Due to the microwave probe output signal bandwidth is too
    large, and the signal amplitude is weak, it is necessary to design a signal conditioning
    circuit to adjust the output signal bandwidth and amplify the signal amplitude.
    The transmission speed range of seed cotton in the cotton pipe is 0.2 Km–360 Km
    h−1, so the circuit bandwidth range is determined to be 8 Hz–16 KHz, and the maximum
    voltage gain does not exceed 60 dB. The signal conditioning circuit is shown in
    figure 6. Zoom In Zoom Out Reset image size Figure 6. Signal conditioning circuit
    diagram. Download figure: Standard image High-resolution image 3.1.2.2. Experimental
    stand for seed cotton mass estimation. The bench experiment rig consists of a
    microwave Doppler sensor module, a data collector and PVC piping. When the seed
    cotton moves in the pipeline, the sensor transmits the collected signals to the
    data acquisition instrument for A/D conversion and finally uses MATLAB to write
    algorithms to process and analyze the data to obtain the seed cotton velocity
    and mass information. The schematic structure of the bench experiment system is
    shown in figure 7. Zoom In Zoom Out Reset image size Figure 7. Schematic diagram
    of the structure of the bench experiment system. Download figure: Standard image
    High-resolution image 3.2. Velocity estimation experiment In the velocity measurement
    experiment, it is necessary to perform a Fourier transform on the time-domain
    signals collected by the data acquisition instrument to obtain the signal spectrum.
    The specific process for the statistical analysis of the signal spectrum for a
    single seed cotton and a large quantity of seed cotton is as follows: For the
    spectrum of a single seed cotton, the method involves using peak searching to
    identify the frequency range where the microwave Doppler signal peaks. The frequency
    at the peak point is then chosen as the Doppler frequency of a single seed cotton,
    after which equation (5) is utilized to estimate the velocity of the single seed
    cotton. When a large quantity of seed cotton passes through the cotton pipeline,
    the resulting Doppler signal consists of multiple frequency signals superimposed.
    According to the analysis in section 2.1, for the spectrum of continuously conveyed
    seed cotton, this experiment utilizes FFT to extract the amplitude of the frequency
    signals at each point. Subsequently, by employing equation (9) for weighted averaging,
    the average Doppler frequency for the large quantity of seed cotton is obtained.
    Finally, equation (8) is used to derive the average velocity of the continuously
    conveyed seed cotton. 3.2.1. A seed cotton falling angle experiment. Before the
    experiment, to better determine the signal sampling frequency, the sensor''s installation
    position was set at a distance of 400 mm from the pipe''s mouth, with the sensor''s
    main axis beam positioned at a 0° angle to the descent of the cotton. Considering
    the short descent distance and the small mass of the seed cotton, they experience
    minimal air resistance. Thus, we can approximate the descent of the seed cotton
    as free-fall motion, assuming a gravitational acceleration of 9.8 m s−1. Applying
    the formula for free fall velocity, we determine that the theoretical velocity
    of the seed cotton passing through the microwave sensor is 2.80 m s−1. Equation
    (5) yields the system''s maximum Doppler frequency as , which allows us to establish
    a sampling frequency of 1500 Hz based on the Shannon sampling theorem. In this
    experiment, the angle between the main axis beam of the control sensor and the
    direction of movement of the seed cotton was 10°, 30°, 45° and 60°, and a single
    seed cotton was manually released at each angle, and the same angle was repeated
    for 5 times, which resulted in the maximum Doppler frequencies and velocities
    measured at different installation angles of the sensor as shown in table 4. The
    average Doppler frequency measured by the sensor at different installation angles
    and the average velocity are depicted in figure 8. Zoom In Zoom Out Reset image
    size Figure 8. The average Doppler frequency measured by the sensor at different
    installation angles and the average velocity. Download figure: Standard image
    High-resolution image Table 4. Correspondence between different mounting angles
    of the sensor and velocity. Category Measurement angle 1 2 3 4 5 Average value
    Standard deviation Theoretical velocity Estimation error Frequency (Hz) 10° 306.396
    300.293 299.072 300.293 297.852 300.781 3.2979 — — 30° 288.086 286.865 286.865
    289.307 288.086 287.842 1.0216 45° 281.982 278.320 277.100 278.320 277.100 278.564
    2.0055 60° 275.879 278.320 275.879 274.658 272.217 275.391 2.2174 Velocity (m
    s−1) 10° 1.934 1.896 1.888 1.896 1.880 1.899 0.0208 2.80 32.18% 30° 2.068 2.060
    2.060 2.077 2.068 2.067 0.0071 26.18% 45° 2.480 2.447 2.437 2.447 2.437 2.450
    0.0177 12.50% 60° 3.431 3.461 3.431 3.415 3.385 3.425 0.0277 22.32% From table
    4 and figure 8, it can be observed that as the installation angle increases, the
    measured Doppler frequency values by the sensor decrease, while the calculated
    velocity values increase. When the installation angle is 45°, the propagation
    path of the microwave signal forms the best relative motion relationship with
    the direction of the moving object, resulting in the smallest measurement error
    for the velocity of the seed cotton. To validate the adaptability of the 45° installation
    angle for different velocities, the following two theoretical velocities are considered
    for validation: 1.   When the distance between the sensor''s installation position
    and the mouth of the pipe is 150 mm, then the theoretical velocity of the seed
    cotton when freely falling and passing through the microwave sensor is 1.715 m
    s−1. 2.   When the distance between the sensor''s installation position and the
    mouth of the pipe is 400 mm, seed cotton is transported by wind at an actual speed
    of 7.86 m s−1. Due to the short transportation distance and small mass of the
    seed cotton, the theoretical velocity of the seed cotton when passing through
    the microwave sensor can be approximated as the wind speed of 7.86 m s−1. The
    measured results of the sensor under different theoretical velocities are shown
    in table 5. Figure 9 depicts the average Doppler frequency and average velocity
    measured under the aforementioned two theoretical velocities. Zoom In Zoom Out
    Reset image size Figure 9. The average Doppler frequency and average velocity
    measured under the two theoretical speeds. (a) The measurement results for the
    theoretical velocity of 1.715 m s−1. (b) The measurement results for the theoretical
    velocity of 7.860 m s−1. Download figure: Standard image High-resolution image
    Table 5. Correspondence between different mounting angles of the sensor and velocity.
    Measurement angle Theoretical velocity (m s−1) 1.715 7.860 Average velocity (m
    s−1) Standard deviation (m s−1) Estimation error Average velocity (m s−1) Standard
    deviation (m s−1) Estimation error 10° 1.235 0.027 27.99% 5.128 0.034 34.76% 30°
    1.341 0.023 21.81% 5.804 0.016 26.16% 45° 1.614 0.030 5.89% 7.066 0.020 10.10%
    60° 2.016 0.044 17.55% 9.878 0.050 25.67% Based on table 5, it is evident that
    when measuring different speeds of seed cotton, setting the microwave sensor''s
    installation angle to 45° consistently yields the smallest velocity estimation
    error and a smaller standard deviation. This result indicates that the signal
    measured by the microwave sensor is more reliable when the main axis of the microwave
    beam is at a 45° angle to the direction of the seed cotton''s movement. Therefore,
    for subsequent speed estimation and mass estimation experiments, the installation
    angle of the microwave sensor is set to 45°. 3.2.2. A seed cotton drop position
    experiment. Five positions were selected on the inner diameter of the cotton delivery
    tube and labeled as No. 1–5. A schematic diagram of the different drop positions
    of the seed cotton is shown in figure 10. Zoom In Zoom Out Reset image size Figure
    10. Schematic diagrams at different drop positions of seed cotton. Download figure:
    Standard image High-resolution image In this experiment, the single seed cotton
    was manually released at each position, and the experiment was repeated 5 times
    at the same position, and the measured values of the velocity, theoretical velocity
    and relative errors of the different drop positions of the single seed cotton
    are shown in table 6. The results of the velocity measurements at different falling
    positions of a seed cotton are shown in figure 11. Zoom In Zoom Out Reset image
    size Figure 11. Measurement results of the velocity of a seed cotton at different
    drop positions. Download figure: Standard image High-resolution image Table 6.
    Measurement results of the velocity of a seed cotton at different drop positions.
    Drop position V1 (m s−1) V2 (m s−1) V3 (m s−1) V4 (m s−1) V5 (m s−1) Average velocity
    (m s−1) Standard deviation (m s−1) Theoretical velocity (m s−1) Estimation error
    1 2.512 2.533 2.544 2.522 2.544 2.531 0.014 2.80 9.61% 2 3.127 2.544 3.117 2.522
    2.544 2.771 0.321 1.04% 3 2.447 2.458 2.458 2.437 2.469 2.454 0.012 12.34% 4 2.437
    2.458 2.490 2.490 2.522 2.479 0.033 11.46% 5 2.512 2.522 2.522 2.501 2.522 2.516
    0.001 10.14% Analysis of table 6 and figure 11 shows that the seed cotton has
    the highest average velocity of 2.771 m s−1 at position 2. This is mainly because
    position 2 is located in the center of the pipe, the pipe is perpendicular to
    the ground, the seed cotton falling process does not collision and friction with
    the pipe wall, the external factors have less impact on its movement, and therefore
    the closest to the theoretical velocity. However, due to the influence of air
    resistance, the measured average velocity is slightly lower than the theoretical
    velocity. Additionally, we observe that the average velocities at positions 1,
    3, 4, and 5 are all lower than the average velocity at position 2. This is because
    positions 1, 3, 4, and 5 are all close to the pipeline wall, significantly increasing
    the likelihood of collision between the seed cotton and the pipeline wall, thus
    affecting the direction and magnitude of the cotton''s movement. Through the analysis
    of the average velocities at different drop positions, we find that the descent
    speed of the seed cotton is less affected by air resistance and more affected
    by collisions with the pipeline. Based on the characteristics of the Doppler signal,
    the closer the distance to the microwave sensor, the higher the echo voltage and
    consequently a stronger signal. Therefore, the average velocity at position 1
    is slightly higher than at positions 3, 4, and 5, although the difference is not
    significant. Consequently, we conclude that the installation position of the sensor
    has a minor impact on the motion velocity of the seed cotton, whereas the drop
    position of the seed cotton has a greater impact. 3.2.3. Experiment on the falling
    velocity of large quantities of seed cotton. Experimental steps: Take the experimental
    object seed cotton, from 10 g start to take, each time the mass increases 10 g,
    and finally take to 70 g, the same mass seed cotton for 3 experiments, a total
    of 21 experiments. The mass and corresponding velocity values were recorded for
    each experiment and the experimental data are shown in table 7. The results of
    the average velocity measurements for different mass are shown in figure 12. Zoom
    In Zoom Out Reset image size Figure 12. Measurement results of the average velocity
    of different mass. Download figure: Standard image High-resolution image Table
    7. Velocity values for different mass of seed cotton. Mass (g) V1 (m s−1) V2 (m
    s−1) V3 (m s−1) Vaverage (m s−1) Standard deviation (m s−1) Vtheory (m s−1) Estimation
    error 10 1.405 1.684 1.523 1.537 0.140 2.80 45.12% 20 2.196 1.848 2.116 2.053
    0.182 26.68% 30 1.360 1.028 1.182 1.190 0.166 57.50% 40 1.082 1.090 0.869 1.014
    0.125 63.79% 50 1.379 1.006 1.581 1.322 0.292 52.79% 60 0.602 0.995 0.833 0.810
    0.196 71.07% 70 1.194 1.001 1.329 1.175 0.165 58.04% From figure 12, when the
    number of seed cotton increases, the velocity decreases significantly, and the
    average velocity of seed cotton is between 0.80 m s−1 and 2.06 m s−1, which is
    much smaller than the theoretical velocity of 2.80 m s−1. The experimental results
    indicate that compared with the pipe collision and air resistance, the interaction
    force between seed cotton has a greater impact on the movement velocity of seed
    cotton. In the discussion section, improvement strategies for enhancing the accuracy
    of large quantities of seed cotton velocity estimation will be proposed. 3.3.
    Mass estimation experiment 3.3.1. Mass estimation experiments under free-fall
    condition. In this experiment, 10 g of seed cotton was taken first, and each time
    the mass was increased by 10 g, and finally 70 g was taken for 7 groups of different
    mass of seed cotton. Each group of seed cotton fell freely in the pipe and the
    experiment was repeated 10 times for a total of 70 experiments. The time-domain
    signal of a portion of the third group signal for 70 g of seed cotton from table
    8 is depicted in figure 13. The PSD of the acquired time-domain signal was estimated
    using the MPM in section 2.2. The PSD data and the corresponding mass are shown
    in table 8. Zoom In Zoom Out Reset image size Figure 13. Partial time-domain signal
    plot. Download figure: Standard image High-resolution image Table 8. PSD and corresponding
    mass data for free-fall experiment. Mass (g) Power spectral density (W/Hz) PSD1
    PSD2 PSD3 PSD4 PSD5 PSD6 PSD7 PSD8 PSD9 PSD10 PSDaverage 10 11.354 60 12.603 53
    9.746 56 10.164 56 13.117 84 14.291 45 11.206 44 11.948 30 10.515 93 13.249 09
    11.819 83 20 15.373 49 19.104 34 12.053 81 13.884 22 16.617 88 11.129 71 15.862
    49 16.628 90 18.035 54 14.938 27 15.362 87 30 42.360 07 43.362 20 42.895 37 46.284
    16 38.314 35 39.631 94 45.472 23 44.790 82 42.966 89 40.259 88 42.633 79 40 66.896
    48 63.743 14 67.112 61 64.207 55 70.321 67 65.022 35 68.530 92 69.653 89 67.116
    23 70.855 74 67.346 06 50 91.679 32 90.652 31 86.789 65 93.342 87 95.761 86 92.554
    84 90.447 09 89.893 19 87.401 81 90.431 88 90.895 48 60 98.365 87 97.781 29 99.104
    76 102.607 38 104.004 77 99.428 51 105.338 49 100.554 84 103.554 84 97.7089 100.844
    96 70 102.3754 99.189 14 105.956 96 103.677 78 100.367 89 104.028 13 102.489 63
    105.073 93 101.255 29 106.152 11 103.056 63 The least square method is used to
    linearly fit the data in table 8, and the relationship between the falling mass
    of seed cotton and the corresponding PSD is shown in figure 14. The fitting equation
    is given by equation (29), and the coefficient of determination for this fitting
    equation is , indicating a good fit of the data Zoom In Zoom Out Reset image size
    Figure 14. Seed cotton mass model for free-fall experiment. Download figure: Standard
    image High-resolution image where y is the seed cotton falling mass and x is the
    corresponding PSD. Before validating the accuracy of the above model, it is necessary
    to determine the mass of the seed cotton used. Gao [27] established a soybean
    mass model using soybeans mass between 100 g and 1000 g, and randomly selected
    mass ranging from 200 g to 1000 g to validate the model. Zou et al [16] randomly
    selected green beans within the range of 2–3 kg for mass model validation. Yang
    et al [2] randomly selected fertilizers ranging from 1.3 kg to 2.7 kg for flow
    model validation by controlling the turning speed of the manure spreader axis.
    Following the mass selection method used by the aforementioned scholars, the PSD
    of seed cotton with a mass less than 100 g was measured and substituted into equation
    (29) to obtain the measured value of the mass of the falling seed cotton, the
    actual mass value and the average error rate as shown in table 9. Table 9. Results
    of the free-fall experiment. Mass (g) PSD (W/Hz) Mass estimation (g) Estimation
    error Average error 15.3 13.642 98 14.682 05 4.04% 7.30% 25.2 33.570 08 29.282
    56 16.20% 36 55.861 95 34.954 41 2.90% 60.3 100.687 10 63.070 60 4.59% 82.5 107.997
    19 75.274 27 8.76% Analyzing table 9, it can be seen that the average error rate
    of the seed cotton mass model is 7.30%, which is a low measurement error and has
    a certain degree of accuracy. 3.3.2. Mass estimation experiment under pneumatic
    conveying condition. In this experiment, 30 g of seed cotton were taken first,
    and each time the mass was increased by 10 g, and finally 70 g were taken for
    five groups of different mass of seed cotton. A 1200 W small fan was used to convey
    the seed cotton at a wind speed of 7.86 m s−1. Each group of experiments was conducted
    10 times, and a total of 50 experiments were carried out. The measured PSD of
    seed cotton and the corresponding mass are shown in table 10. Table 10. PSD and
    corresponding mass data for pneumatic conveying experiment. Mass (g) Power spectral
    density (W/Hz) PSD1 PSD2 PSD3 PSD4 PSD5 PSD6 PSD7 PSD8 PSD9 PSD10 PSDaverage 10
    12.567 89 8.327 93 11.987 65 9.345 67 13.234 56 7.773 78 10.876 54 11.789 01 10.456
    78 12.123 45 10.848 33 20 26.112 34 20.031 53 22.825 68 24.001 23 19.820 15 25.718
    49 23.765 43 21.998 87 23.585 62 24.887 76 23.274 71 30 33.589 63 28.561 53 31.876
    54 29.031 43 27.2461 32.474 61 30.369 87 28.648 35 30.630 61 31.744 77 30.417
    34 40 46.371 69 41.986 89 44.3463 42.641 45 40.490 56 45.392 56 43.648 51 41.405
    11 43.828 13 44.898 75 43.501 00 50 90.263 57 95.639 34 92.878 95 94.032 96 91.433
    82 94.717 58 93.442 53 90.555 37 93.815 88 92.434 51 92.921 45 60 91.267 89 96.856
    97 93.796 52 94.929 04 90.085 56 95.196 29 96.958 74 92.648 37 93.985 47 95.188
    23 94.091 31 70 136.8857 131.274 54 134.956 04 132.023 53 130.081 06 135.999 15
    133.304 23 131.825 63 133.523 69 134.258 03 133.319 29 The relationship between
    the mass of seed cotton and the PSD under pneumatic conveying is obtained by linear
    fitting of the data in table 10 as shown in figure 15. The fitting equation is
    given by equation (30), and the coefficient of determination for this fitting
    equation is , indicating a good fit of the data Zoom In Zoom Out Reset image size
    Figure 15. Seed cotton mass model for pneumatic conveying experiment. Download
    figure: Standard image High-resolution image The model is validated using five
    sets of actual masses from table 9. Table 11 showing the measured seed cotton
    mass, actual mass value, and average error rate for pneumatic conveying, obtained
    using equation (30). Table 11. Results of pneumatic conveying experiment. Mass
    (g) PSD (W/Hz) Mass estimation (g) Estimation error Average error 15.3 15.342
    87 15.986 45 4.49% 6.17% 25.2 27.761 86 26.890 79 6.71% 36 38.554 84 34.373 44
    4.52% 60.3 92.708 90 55.322 60 8.25% 82.5 145.318 89 76.832 26 6.87% Analysis
    of the free-fall experiment and the pneumatic conveying experiment shows that
    mass estimation using the PSD has some accuracy. However, under different wind
    velocity conditions, the mass model obtained has large differences, and the actual
    wind velocity should be determined in practical applications to establish an accurate
    cotton mass model. Additionally, due to differing signal strengths at different
    sensor positions and the stochastic nature of seed cotton transportation within
    the pipeline, each measurement carries uncertainty. This leads to a relatively
    poor generalization of the model. To address this issue, the discussion section
    will propose improvements to ensure the model''s universality. 4. Conclusions
    The advantages of microwave sensors in measuring the mass of solids under gas–solid
    two-phase flow conditions, such as low detection error, low price, and easy installation
    of the sensors in harsh environments, are illustrated through the relevant literature.
    Aiming at the phenomenon that microwave technology has not been used for seed
    cotton mass estimation in China, this paper proposes a method for seed cotton
    mass estimation based on the microwave Doppler method and designs a bench test
    to verify the feasibility of the method. In this paper, the instantaneous velocity
    of a single seed cotton flow and the average velocity of a large number of seed
    cottons flow are measured by using the Doppler principle and FFT with seed cotton
    as the experimental object, and the factors affecting the motion state of seed
    cotton are explored. By measuring the instantaneous velocity of single seed cotton
    at different sensor mounting angles, it can be obtained that as the sensor mounting
    angle becomes larger, the estimated value of the velocity of the seed cotton also
    becomes larger. However, the relative error between the estimated speed and the
    theoretical speed at a mounting angle of 45° was minimized, so the sensor mounting
    angle of 45° was selected. On this basis to verify the factors affecting the flow
    rate of seed cotton, release seed cotton at different locations in the pipeline,
    and observe its velocity measurements can be concluded that the impact of collision
    friction on the wall of the pipe on the speed of the seed cotton is greater than
    the impact of air resistance. Finally, the design of a large number of seed cottons
    conveying speed test, found that the average velocity of a large number of seed
    cottons is much smaller than the theoretical speed. From this experiment, it can
    be concluded that the effect of the interaction force between the seed cotton
    on the seed cotton speed is much larger than the effect of pipe wall friction
    and air resistance. In the estimation of seed cotton mass using PSD, free-fall
    mass experiment and wind-driven mass experiment were designed respectively, and
    the relative errors of measurement were obtained to be 7.30% and 6.17%, respectively.
    The results show that seed cotton mass estimation using PSD has certain accuracy,
    but different wind velocity conditions correspond to different mass models, and
    the corresponding seed cotton mass models should be determined according to different
    wind velocities in practical applications. 5. Discussion In this paper, the feasibility
    of seed cotton mass estimation using microwave sensors is verified by bench experiments.
    The analysis from section 3.2.2 reveals that the signal strength of the microwave
    sensor varies at different positions within the pipeline, and the descent of seed
    cotton is stochastic, resulting in uncertainty with each measurement and affecting
    the system''s reliability and repeatability. When there is a large quantity of
    seed cotton, most of the microwave signals are reflected by the seed cotton close
    to the microwave sensor. Therefore, when estimating the velocity of a large amount
    of seed cotton, due to mutual occlusion of the seed cotton, the measured velocity
    represents the average speed of the seed cotton close to the microwave sensor.
    To address this issue, we propose a multi-sensor measurement approach in order
    to uniformly measure the signal strength at various points across the pipeline
    cross-section, thereby reducing errors caused by the stochastic descent of the
    seed cotton and ensuring more precise and reliable measurements. The schematic
    of the multi-sensor measurement approach is illustrated in figure 16. Zoom In
    Zoom Out Reset image size Figure 16. The schematic of the multi-sensor measurement
    approach. Download figure: Standard image High-resolution image As depicted in
    figure 16, the microwave sensors are installed around the pipeline, with the primary
    measurement area for each sensor outlined by a dashed ellipse. The four microwave
    sensors compensate for each other, and the measured Doppler signal is an accumulation
    of the signals from all four microwave sensors. This design ensures a more uniform
    distribution of the Doppler signal within the pipeline, thereby making the measured
    Doppler frequency shift and PSD closer to the actual values, serving the purpose
    of reducing errors [12, 28]. Based on section 3.2.2, wall friction is also a factor
    influencing velocity estimation. To bring the seed cotton as close as possible
    to position 2, in subsequent studies, the inlet of the pipeline will be designed
    as a funnel shape, as shown in figure 17, to gather the seed cotton towards the
    center of the pipeline, thereby reducing the likelihood of friction between the
    seed cotton and the pipeline. Additionally, an automatic cotton feeding device
    needs to be designed for the system to conduct mass estimation experiments with
    a large quantity of seed cotton, in order to better simulate the process of cotton
    harvesting and achieve more accurate results. Zoom In Zoom Out Reset image size
    Figure 17. The schematic of cotton inlet pipeline structure. Download figure:
    Standard image High-resolution image The development of an online yield monitoring
    system for cotton pickers based on microwave sensors is also required for future
    application to actual cotton pickers. The system includes the design of the communication
    network [29, 30], the construction of the in-vehicle intelligent terminal [31]
    and the development of the remote monitoring platform [32]. The information interaction
    between microwave sensors and vehicle-mounted intelligent terminals is established
    through short-range wireless communication technology (e.g., Zigbee). The state
    information of the cotton picker (such as picking head lifting and lowering, fan
    speed and traveling speed) is transmitted to the cotton picker vehicle-mounted
    intelligent terminal using the CAN bus. Remote monitoring platform through remote
    wireless communication technology (such as Beidou short message communication)
    to obtain the vehicle-mounted intelligent terminal transmitted by the cotton mass
    information and cotton picking machine status information, drawing cotton picking
    machine harvesting area yield distribution map, and complete the cotton picking
    machine cluster operation scheduling [33]. Acknowledgments This work was supported
    by ''Cross-Disciplinary Research Program of Shihezi University'' (Grant No. JCYJ202312).
    Data availability statements The data cannot be made publicly available upon publication
    because no suitable repository exists for hosting data in this field of study.
    The data that support the findings of this study are available upon reasonable
    request from the authors. Show References Abstract 1. Introduction 2. System working
    principle 3. Bench experiment 4. Conclusions 5. Discussion Acknowledgments Data
    availability statements References You may also like JOURNAL ARTICLES Development
    of an ultrasonic void fraction profiler Investigation on vector Doppler method
    for carotid artery wall with focused transmit beams produced from a cross-shaped
    probe A dealiasing method for use with ultrasonic pulsed Doppler in measuring
    velocity profiles and flow rates in pipes Multi-wave ultrasonic Doppler method
    for measuring high flow-rates using staggered pulse intervals High-frequency ultrasonic
    airborne Doppler method for noncontact elasticity measurements of living tissues
    Deduction of two-dimensional blood flow vector by dual angle diverging waves from
    a cardiac sector probe Postdoctoral Researcher- Cloud microphysics and aerosol-cloud
    interactions Lawrence Livermore National Laboratory Technicians & Engineers CEA-Irfu
    More jobs Post a job IOPSCIENCE Journals Books IOP Conference Series About IOPscience
    Contact Us Developing countries access IOP Publishing open access policy Accessibility
    IOP PUBLISHING Copyright 2024 IOP Publishing Terms and Conditions Disclaimer Privacy
    and Cookie Policy PUBLISHING SUPPORT Authors Reviewers Conference Organisers This
    site uses cookies. By continuing to use this site you agree to our use of cookies.
    IOP Publishing Twitter page IOP Publishing Facebook page IOP Publishing LinkedIn
    page IOP Publishing Youtube page IOP Publishing WeChat QR code IOP Publishing
    Weibo page"'
  inline_citation: '>'
  journal: Measurement Science and Technology
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A novel microwave Doppler method for mass estimation of machine-picked seed
    cotton
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Bai Y.
  - Yang W.
  - Wang Z.
  - Cao Y.
  - Li M.
  citation_count: '0'
  description: Accurate estimation of soil organic matter (SOM) content is of great
    significance for advancing precision agriculture and assessing carbon storage.
    Proximal sensing techniques, such as near-infrared spectroscopy (NIR) and Raman
    spectroscopy, provide effective means for rapidly acquiring soil information.
    However, quantitative estimation of soil parameters using Raman spectroscopy has
    been challenged by inaccurate estimation results, which has restricted the widespread
    application of Raman spectroscopy in SOM estimation. The fusion of complementary
    information from multi-sensor data has been considered as one of the feasible
    solutions to address the poor results of single-sensor estimation. Therefore,
    the study on SOM estimation based on spectral data fusion was carried out by evaluating
    the effects on estimation performance under different fusion strategies. In this
    study, 258 soil samples from the North China, along with their corresponding near-infrared
    spectra and Raman spectra were collected and the spectral data was fused by two
    strategies involved direct concatenation (DC) and outer-product analysis (OPA).
    The SOM estimation performance of random forest (RF) and partial least squares
    (PLS) models constructed based on independent spectra data (NIR spectra, Raman
    spectra before baseline correction, Raman spectra after baseline correction),
    spectral data fused by DC, and spectral data fused by OPA were evaluated, respectively.
    The results indicated that the fusion of near-infrared spectroscopy and Raman
    spectroscopy could improve the poor performance of using Raman spectroscopy independently
    for quantitative estimation of SOM; Furthermore, OPA was a more effective fusion
    strategy compared with DC, significantly improving the estimation accuracy of
    the model. In addition, the PLS model constructed based on OPA fused spectral
    data achieved the best estimation accuracy, with R2, RMSE, and RPD of 0.903, 2.594
    g/kg, and 3.061 on the validation set, respectively. This study can provide a
    technical support for accurately estimating the content of SOM using proximal
    spectroscopy technologies, contributing to the improvement of soil management
    practices in the context of precision agriculture.
  doi: 10.1016/j.compag.2024.108760
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Materials and methods
    3. Results 4. Discussion 5. Conclusion CRediT authorship contribution statement
    Declaration of competing interest Acknowledgements Data availability References
    Show full outline Figures (8) Show 2 more figures Tables (3) Table 1 Table 2 Table
    3 Computers and Electronics in Agriculture Volume 219, April 2024, 108760 Improving
    the estimation accuracy of soil organic matter based on the fusion of near-infrared
    and Raman spectroscopy using the outer-product analysis Author links open overlay
    panel Yu Bai, Wei Yang, Zhaoyang Wang, Yongyan Cao, Minzan Li Show more Add to
    Mendeley Share Cite https://doi.org/10.1016/j.compag.2024.108760 Get rights and
    content Highlights • The fusion of NIR and Raman spectroscopy was used to estimate
    SOM. • The advanced fusion strategy was used for spectral data fusion. • The accurate
    and robust machine learning model of SOM estimation was construction. • The coevolution
    and interaction between two spectra were analyzed and application potential was
    explored. Abstract Accurate estimation of soil organic matter (SOM) content is
    of great significance for advancing precision agriculture and assessing carbon
    storage. Proximal sensing techniques, such as near-infrared spectroscopy (NIR)
    and Raman spectroscopy, provide effective means for rapidly acquiring soil information.
    However, quantitative estimation of soil parameters using Raman spectroscopy has
    been challenged by inaccurate estimation results, which has restricted the widespread
    application of Raman spectroscopy in SOM estimation. The fusion of complementary
    information from multi-sensor data has been considered as one of the feasible
    solutions to address the poor results of single-sensor estimation. Therefore,
    the study on SOM estimation based on spectral data fusion was carried out by evaluating
    the effects on estimation performance under different fusion strategies. In this
    study, 258 soil samples from the North China, along with their corresponding near-infrared
    spectra and Raman spectra were collected and the spectral data was fused by two
    strategies involved direct concatenation (DC) and outer-product analysis (OPA).
    The SOM estimation performance of random forest (RF) and partial least squares
    (PLS) models constructed based on independent spectra data (NIR spectra, Raman
    spectra before baseline correction, Raman spectra after baseline correction),
    spectral data fused by DC, and spectral data fused by OPA were evaluated, respectively.
    The results indicated that the fusion of near-infrared spectroscopy and Raman
    spectroscopy could improve the poor performance of using Raman spectroscopy independently
    for quantitative estimation of SOM; Furthermore, OPA was a more effective fusion
    strategy compared with DC, significantly improving the estimation accuracy of
    the model. In addition, the PLS model constructed based on OPA fused spectral
    data achieved the best estimation accuracy, with R2, RMSE, and RPD of 0.903, 2.594
    g/kg, and 3.061 on the validation set, respectively. This study can provide a
    technical support for accurately estimating the content of SOM using proximal
    spectroscopy technologies, contributing to the improvement of soil management
    practices in the context of precision agriculture. Previous article in issue Next
    article in issue Keywords Soil organic matterNear-infrared spectroscopyRaman spectroscopyData
    fusionOuter-product analysis 1. Introduction Soil organic matter (SOM) is a key
    indicator for evaluating fertility and the overall health condition of the soil,
    which plays a crucial role in ensuring biomass production (Zhao et al., 2023),
    maintaining soil biodiversity (Jia et al., 2023), carbon sequestration and influencing
    global climate change (Lal, 2004, Zhao et al., 2022). The rapid and accurate determination
    of SOM content holds significant importance for understanding the spatial distribution
    of soil nutrients. Most of the traditional methods for determining SOM content
    rely on combustion, including dry combustion (Nelson and Sommers, 1983) and wet
    combustion (Walkley and Black, 1934), which usually involve complex sample processing
    and physicochemical analysis, and the measured sample size is limited, making
    it difficult to quickly obtain spatial differences in SOM distribution on a large-scale
    farmland scale. Therefore, in the current context of developing precision agriculture,
    achieving efficient and accurate estimation of SOM content is necessary for monitoring
    soil fertility and improving soil management levels. In the past decades, various
    proximal soil sensing techniques have become reliable methods for acquiring soil
    information due to their advantages of high throughput and non-destructive (Bellon-Maurel
    and Alex, 2011, Mohamed et al., 2018). Among them, benefiting from the development
    of Raman spectroscopy technology, the application of Raman spectrometers in soil
    analysis has gradually increased (Sharma et al., 2021). Raman spectroscopy is
    a technique based on inelastic scattering of light. By analyzing the scattered
    spectra with frequencies different from the incident light, the information about
    molecular vibrations and rotational information can be obtained, which is useful
    for characterizing molecular structures (Tao and Liu, 2015, Smith and Dent, 2019).
    Previous studies have shown that Raman spectroscopy can effectively characterize
    carbon in soil (Francioso et al., 2000). Furthermore, substances such as humins
    and humic acid, which are the main components of SOM (Kononova, 2013), contain
    detectable characteristic spectral bands in Raman spectroscopy (Roldan et al.,
    2011, Ma et al., 2023). These sensitive bands provide a basis for identifying
    soil components, making Raman spectroscopy a great potential for characterizing
    soil organic matter information. However, due to fluorescence quenching, most
    of the studies enhanced the Raman signals by pre-treatments (such as oxidation,
    surface enhancement) of the soil samples (Fleischmann et al., 1974, Edwards et
    al., 2012) and only involved qualitative analyses of soil information. In addition,
    the complex heterogeneity of soil (Argyraki et al., 1997) further limits the application
    of Raman spectroscopy in SOM estimation. Recently, the fusion of multiple sensor
    data has been considered a potential and feasible solution to address the poor
    performance of single sensor estimation and improve the accuracy of soil parameter
    assessment (dos Santos Teixeira et al., 2022, Horta et al., 2015, Zhao et al.,
    2022). In spectral analysis, near-infrared spectroscopy (NIR) is considered as
    another spectroscopic technique complementary to Raman spectroscopy, and both
    of them are usually used in a complementary way (Wang et al., 1987). NIR is based
    on energy level transitions caused by molecular vibration and rotation, and its
    spectral region is consistent with the combined frequencies of stretching vibrations
    of hydrogen containing groups (O-H, N-H, C-H) in organic molecules, as well as
    the absorption regions at all harmonic levels (Cheng et al., 2010, Chen et al.,
    2019). The successful application of NIR in SOM estimation has been widely reported
    (Conforti et al., 2018, Padarian et al., 2019, Da Silva-Sangoi et al., 2022, Wang
    et al., 2023, Wang et al., 2024). The effectiveness of their complementary use
    is reflected in the information that can be obtained. The π bonds of symmetric
    molecules (such as C=C in olefins and aromatic rings) exhibit stronger performance
    in Raman spectroscopy. However, σ bonds between atoms with different electronegativity
    (such as O-H, C-N and C-O) have weak polarization change rate of molecular bonds
    (Sharma, 2004), and these asymmetric bonds have stronger response in NIR. The
    ability of the two to provide complementary information makes them effective tools
    in soil science, thereby making the fusion of two spectra for SOM estimation widely
    feasible. In general, multi-sensor fusion can be achieved by concatenating the
    data from various independent sensors. This method has been employed in several
    studies for the fusion of data from different sensors to estimate soil parameters
    (Benedet et al., 2020, Wan et al., 2020, Xu et al., 2020). For instance, the fusion
    of visible-near-infrared (vis-NIR) and portable X-ray fluorescence (pXRF) data
    has been used to estimate soil total carbon and nitrogen, showing acceptable improvements
    in the accuracy of the estimated parameters (Wang et al., 2015). However, there
    is still no consensus on the optimal sensor data fusion strategy, and some studies
    used concatenating to fuse multi-sensor data, but the reported results were not
    completely satisfactory (Knox et al., 2015, Xing et al., 2021). Moreover, for
    the group of technologies such as Raman spectroscopy and NIR, it remains to be
    further determined how to fully explore and utilize their complementary information
    at the data level. Another spectral data fusion method is outer-product analysis
    (OPA), which creates a matrix for each sample, encompassing all potential blends
    of intensities derived from both spectrum types. This matrix emerges from the
    outer products of vectors, where the values are contingent upon the intensities
    observed in the initial spectra. Compared to direct concatenation, OPA emphasizes
    the mixing of all potential signal intensities derived from independent spectra,
    allowing for the observation of the co-evolution trend of spectral signals obtained
    from two different domains or even the same domain (Jaillais et al., 2005). This
    method was originally used in food engineering (Jaillais et al., 2006), and its
    application in soil science has gradually increased in recent years (Terra et
    al., 2019). Relevant studies indicated that OPA can thoroughly explore and utilize
    the different properties of various spectral data as well as the complementary
    information between them (Ng et al., 2019, Xu et al., 2019). However, there have
    been no reported studies on whether the fusion of NIR and Raman spectral data
    through OPA can improve the accuracy of SOM estimation, and this gap needs further
    confirmation. In summary, the overall objective of this study is to utilize various
    spectroscopic techniques for SOM accurate estimation. This includes exploring
    the potential of fusing Raman spectroscopy and NIR to improve the accuracy of
    SOM estimation, determining the impact of different spectral data fusion strategies
    on SOM estimation performance, and selecting the optimal estimation model. The
    specific research questions are as follows: 1. Can the fusion of complementary
    data from multiple sensors (Raman spectroscopy and NIR) address the problem of
    poor performance of data from single sensor (Raman spectroscopy) in SOM quantitative
    estimation? 2. Which fusion strategy specifically can fully exploit the complementarity
    of Raman spectroscopy and NIR from the perspective of spectral data? What is its
    effectiveness? 3. How to establish the optimal performance model for SOM estimation
    in the context of data fusion? 2. Materials and methods 2.1. Study area and soil
    sampling This study was conducted in Haidian District, Beijing, China, with a
    specific experimental area range of 116°03′-116° 23′E and 39°52′ -40°09 ′N. This
    region is located in North China and belongs to a continental monsoon climate.
    The average annual precipitation is 628 mm, with a daily minimum temperature of
    8 °C and a maximum temperature of 19 °C. Affected by long-term natural environment
    and human activities, the soil types in the region are mainly brown soil and cinnamon
    soil, with loam soil as the main texture, which is a common and representative
    soil in northern China. The field investigation and soil samples collection of
    this study were conducted from 2022 to 2023. In order to ensure the wide representativeness
    of the collected samples and the robustness of the estimation model, the experimental
    design of this study includes the following steps. Firstly, the study area was
    divided into several sub-regions, and different weights of organic fertilizers
    were applied in sub-regions, which were L1: 0 kg/m2, L2: 0.25 kg/m2, L3: 0.3 kg/m2,
    and L4: 0.5 kg/m2. The specific sub-area division and fertilization scheme are
    shown in Fig. 1; Secondly, the analytical sample for each sub-region was obtained
    by mixing six sub-samples from each sub-region, which were randomly distributed
    in a circle with a radius of 2 m around the center of the sub-region (NY/T 395-2012,
    2012). During field collection, plant residues and surface soil were removed,
    and each sampling depth was 10–20 cm from the ground. All analytical samples were
    sent back to the laboratory for air drying and coarse sieving (2 mm) and divided
    into two parts. One part was ground and then passed through a 0.6 mm sieve for
    near-infrared and Raman spectrum measurement, and the other part was ground and
    passed through a 0.25 mm sieve for laboratory chemical measurement of SOM (HJ/T166-2004,
    2004). Finally, a total of 258 soil samples for analysis were obtained. Download
    : Download high-res image (444KB) Download : Download full-size image Fig. 1.
    Study areas and sub-regions division. Fig. 2 showed the overall method flowchart
    of this study, with specific details described in subsequent sections. The first
    part was the collection of raw data, including soil near-infrared spectra, Raman
    spectra and organic matter content measurement; The second part was data processing,
    including preprocessing spectral data and spectral data fusion by different strategies;
    The last part was the construction and evaluation of the model. Different machine
    learning algorithms were used to establish the estimation model of SOM, the model
    performance was tested and the best model was selected. Download : Download high-res
    image (404KB) Download : Download full-size image Fig. 2. Method flow of this
    study. 2.2. Laboratory analysis of SOM In this study, the wet combustion was used
    for determination of SOM (Lamichhane et al., 2019). Superfluous K2Cr2O7 solution
    was used to oxidize organic carbon in soil. The remaining K2Cr2O7 was titrated
    with standard FeSO4 solution. The content of organic carbon was calculated from
    the amount of K2Cr2O7 consumed, and then the content of SOM was obtained. 2.3.
    Measurement of NIR and Raman spectra The NIR-Quest 512 (Ocean Optics, USA) was
    used for soil near-infrared spectra measurements. This near-infrared spectrometer
    is equipped with a light source, integrating sphere, and optical fiber, and can
    collect spectra in the range of 900 to 1700 nm. Before collection, the spectrometer
    was corrected with a black and white board, and the integration time was set to
    10 ms. The final spectra of each sample were obtained by averaging after measuring
    10 times. Raman spectra of soil samples were acquired using a micro-Raman spectrometer
    (HORIBA HR Evolution, HORIBA, Japan) with a focal length of 800 mm. The optical
    collection system collects scattered light through backscattering. The collection
    was conducted at room temperature of 25 °C, and the instrument''s various parameters
    were set as follows: the wavelength of the excitation light source was 532 nm,
    the laser power was 100 mw, the grating was set to 600 l/mm, the collected wavenumber
    range was 300-3500 cm−1, and the actual spectral resolution was 3 cm−1. For a
    single sample, the integration time for each scan was 1000 ms, and the final analysis
    spectrum was obtained by averaging the Raman spectra of three randomly sampled
    positions. 2.4. Spectra preprocessing Artifacts are commonly found in spectral
    data, and proper pretreatment is crucial as the initial step before conducting
    stoichiometric bilinear modeling (Rinnan et al., 2009). To improve the signal-to-noise
    ratio of the spectrum, the Savitzky-Golay algorithm with a window size of 13 and
    polynomial of order 2 was used to smooth and preprocess the near-infrared and
    Raman spectra of soil samples after multiple experimental comparisons (Chen et
    al., 2011, Engel et al., 2013, Yang et al., 2020). Furthermore, in order to remove
    the strong fluorescence background in the soil Raman spectra, the adaptive iterative
    reweighted penalty least squares (air-PLS) algorithm was used to correct the baseline
    of the soil Raman spectra (Zhang et al., 2010). To avoid data redundancy during
    modeling, the resolution of NIR and Raman spectra were down sampled to 10 nm and
    20 cm−1, respectively. 2.5. Methods of spectral data fusion 2.5.1. Direct concatenation
    The full near-infrared spectrum (Eq. (1)) and Raman spectrum (Eq. (2)) data were
    simply concatenated (NIR + Raman) (Eq. (3)). Among them, represents the sample
    , and represent the number of bands sampled for NIR and Raman spectra, respectively,
    and is the number of samples. (1) (2) (3) 2.5.2. Outer-product analysis Outer-product
    analysis (OPA) is a method that combines two kinds of spectra and uses their combinations
    to emphasize coevolution of spectral regions. In this study, OPA was used to fuse
    near-infrared spectrum (Eq. (1)) and Raman spectrum (Eq. (2)) to obtain a matrix
    as shown in Eq. (4) (NIR ⊗ Raman), which is in the form of p rows and q columns.
    The n samples will generate n outer product matrices, and each outer product matrix
    was unfolded into a row vector of length p × q (Eq. (5)). These n row vectors
    were used as the input factor of the estimation model for SOM. (4) (5) 2.6. Models
    construction and evaluation Before constructing the estimation model, all 258
    samples were divided into training set and validation set using the Kennard Stone
    algorithm (Li et al., 2021), where the training set contained 194 samples for
    constructing and training the model, and the validation set contained 64 samples
    for testing and evaluating the model performance. Among several machine learning
    algorithms, partial least squares (PLS) and random forest (RF) were used to construct
    SOM estimation models. PLS is the most widely used modeling method in the field
    of spectra analysis. This algorithm finds a linear regression model by projecting
    the estimation variable and observation variable into a new space, respectively.
    Its advantage is that it can overcome the problem of multicollinearity of independent
    variables (Qiao et al., 2022). RF is a machine learning model based on ensemble
    learning which makes regression prediction by constructing multiple decision trees
    and integrating their estimation results. The implementation of the above algorithms
    was completed in Matlab 2018b. In this study, the coefficient of determination
    (R2), root mean square error (RMSE), and residual prediction deviation (RPD) of
    validation set were selected as the evaluation indexes of the model. The above
    evaluation indexes were calculated as shown in Eq. (6), (7) and (8): (6) (7) (8)
    Among these, , and represent measured value, predicted value and the mean value
    of measured values, is the number of soil samples. The R2 reflects the degree
    of fitting of the model to the data and the closer R2 is to 1 indicates that the
    estimation model is more explanatory of the data. The RMSE reflects the accuracy
    of the model, and a lower RMSE indicates a higher accuracy of the estimation model.
    The RPD is used to indicate the robustness of the constructed model, and it is
    generally believed that the RPD of a satisfactory model should be greater than
    3. If the RPD is between 2 and 3, it indicates that the results obtained from
    the model can serve as a reference and be used for approximate estimation; while
    an RPD less than 2 means that the estimation model is not robust and the estimation
    results are not reliable. 3. Results 3.1. Statistical analysis of SOM Table 1
    listed the descriptive statistics of SOM content under different application levels
    of organic fertilizer. After applying different weights of organic fertilizers,
    the organic matter content of soil samples showed obvious differences, which was
    beneficial to the applicability and robustness of the model. Table 1. Descriptive
    statistics of organic matter content of soil samples under different application
    levels of organic fertilizer. Level Minimum value(g/kg) Max value(g/kg) Mean value(g/kg)
    L1 10.310 19.826 16.304 L2 19.947 31.860 25.487 L3 31.928 39.980 35.392 L4 40.135
    41.514 40.646 Table 2 listed the descriptive statistics of SOM content in the
    training set, validation set and total samples in this study, the organic matter
    content of the soil samples was widely distributed with a minimum value of 10.310
    g/kg and a maximum value of 41.514 g/kg. The mean values of SOM content in the
    training set and validation set were 22.891 and 24.063 g/kg, respectively, and
    the coefficients of variation were 0.350 and 0.331. It can be seen that the distribution
    of the training and validation sets is similar to the total dataset, indicating
    that the partitioning method is reasonable and the divided data can represent
    the total dataset to a certain extent and is suitable for modeling analysis. Table
    2. Descriptive statistics of organic matter content of soil samples in total samples,
    training set and validation set. Dataset Minimum value(g/kg) Max value(g/kg) Mean
    value(g/kg) Standard deviation(g/kg) Skewness Coefficient of variation Kurtosis
    Total samples 10.310 41.514 23.468 8.047 0.450 0.343 −1.053 Training set 10.310
    41.514 22.891 8.019 0.534 0.350 −0.935 Validation set 12.016 40.135 24.063 7.939
    0.246 0.331 −1.284 3.2. Qualitative description of soil NIR and Raman spectra
    The mean NIR reflectance of soil samples at four different organic fertilizer
    application levels and the NIR spectra of the organic fertilizer in this study
    were shown in Fig. 3. In the full spectral range, the spectral curves exhibited
    roughly the same trend, with the spectral reflectance of soil samples showing
    a slow increase followed by a decrease. The inflection point at which it begins
    to significantly decrease appeared around 1650 nm; Among them, there were shoulder
    peaks roughly between 1360 and 1390 nm, representing some weak spectral absorption
    characteristics. A high reflectivity platform appeared between 1450 and 1650 nm
    due to the complex interaction between the incident radiation and the internal
    structure of soil molecules. In addition, the spectral reflectance was roughly
    negatively correlated with SOM content in the same wavelength range. Different
    near-infrared spectral reflectance characterized the near-infrared spectral response
    characteristics of soil under different organic matter content, which made subsequent
    machine learning modeling and estimation possible. Download : Download high-res
    image (250KB) Download : Download full-size image Fig. 3. (a)Mean NIR spectra
    of soil samples under different organic matter fertilizer application levels.
    L1: 0 kg/m2, L2: 0.25 kg/m2, L3: 0.3 kg/m2, and L4: 0.5 kg/m2, (b) NIR spectra
    of the organic fertilizer. Fig. 4 (a) showed the Raman spectra of organic fertilizer
    and soil samples in the range of 300 to 3500 cm−1 under different levels of organic
    fertilizer application. Different from the near-infrared spectra of soil, there
    were enormous number of colloidal substances formed after the decomposition of
    organic matter by microorganisms in the soil, and the color of colloidal substances
    was usually brown, leading to the Raman response peaks related to SOM were mostly
    submerged in the fluorescent background, which was difficult to be directly observed
    (Yang and Chase, 1998). Therefore, the air-PLS algorithm was selected to remove
    fluorescence background and correct baseline. The processed spectral curves are
    shown in Fig. 4 (b), (c) and (d). According to existing literature and information,
    the Raman response characteristic peaks appeared in the corrected curve were summarized
    as follows: The Raman peaks near 458 cm−1 were mainly generated by the vibration
    of C-H bonds in organic matter; 1000-2000 cm−1 is the main Raman response interval
    of humus molecules such as fulvic acid in SOM, and a part of research also focused
    on this wavenumber range (Xing et al., 2016, Xing et al., 2021). In this study,
    two main peaks were detected within this range, located at 1020 and 1060 cm−1,
    respectively, which were generally considered as the results caused by the stretching
    motion of the C-C and C-O bonds in the aliphatic structure (Perumal et al., 2023);
    In addition, a significant Raman peak was also detected near 3160 cm−1, which
    may be the result of O-H bond stretching vibration in soil organic matter (Parikh
    et al., 2014). Download : Download high-res image (737KB) Download : Download
    full-size image Fig. 4. The mean Raman spectra of soil samples and organic matter
    fertilizer. (a) before baseline correction, (b, c, d) after correction. b, c and
    d respectively display the Raman responses detected in the soil samples of this
    study within the range of 300-800, 1000-1500, and 3100-3200 cm−1. (e) organic
    matter fertilizer. 3.3. Quantification estimation of SOM based on NIR spectra,
    Raman spectra and their fusion The SOM content estimation models based on PLS
    and RF were constructed respectively by using NIR spectra, Raman spectra and spectral
    data fused by two different fusion strategies (NIR + Raman, NIR ⊗ Raman) as input
    factor and the SOM content as output factor, the estimation results are shown
    in Fig. 5. Fig. 5 (a) and (f) demonstrated that RF and PLS models could obtain
    good results when using near-infrared spectra only to estimate SOM. Compared with
    RF (R2 = 0.793, RMSE = 3.832 g/kg, RPD = 2.072), the PLS model had better performance
    (R2 = 0.849, RMSE = 3.119 g/kg, RPD = 2.545). The results suggested that the SOM
    content could be estimated to a certain extent by using NIR, but the RPD of both
    models was less than 3, and the robustness of the models was still low. For the
    Raman spectra before baseline correction, the estimation results of RF and PLS
    were not satisfactory (Fig. 5 (b), (g)). This may be because the Raman response
    that can characterize the differences in SOM properties were submerged in the
    strong fluorescent background, resulting in the algorithm''s inability to establish
    the mathematical relationship between spectral data and the true value of SOM
    at the data level. For Raman spectra after baseline correction, the estimation
    accuracy of the model established based on RF and PLS algorithms had slightly
    improved (Fig. 5 (c), (h)). Among them, the performance of the PLS model was little
    better than RF, but the RPD of the PLS model was 1.740, indicating that its estimation
    results were still not reliable, and the Raman spectra could not effectively and
    accurately characterize the content of SOM, which is similar to the previous research
    conclusions (Xing et al., 2016). This result further proved the limitations of
    Raman spectra in quantitative analysis and estimation of SOM. According to the
    Fig. 5 (d) and (i), the fusion strategy of direct concatenation of spectral data
    was not significant in improving the accuracy of SOM estimation. The modeling
    results of RF and PLS were equivalent to that of using the near-infrared spectra.
    Regarding the results obtained from data fusion by using OPA (Fig. 5 (e), (j)),
    the estimation performance of RF and PLS models had significantly improved on
    the basis of using the direct concatenation fusion strategy. Among them, R2 increased
    by 10.323 % and 4.878 % respectively, RMSE decreased by 21.287 % and 14.923 %
    respectively, and RPD increased by 27.069 % and 17.550 % respectively. Download
    : Download high-res image (795KB) Download : Download full-size image Fig. 5.
    Estimation results of SOM based on single-sensor data and multi-sensor data fusion:
    a-e represent the estimation results of using near-infrared spectral data, Raman
    spectral data before baseline correction, Raman spectral data after baseline correction,
    spectral data fused by direct concatenation, and spectral data fused by OPA in
    the RF model；f-j represent the estimation results of using near-infrared spectral
    data, Raman spectral data before baseline correction, Raman spectral data after
    baseline correction, spectral data fused by direct concatenation, and spectral
    data fused by OPA in the PLS model. From the results in Fig. 5, it can be observed
    that the preprocessing method of electronic data has improved the accuracy of
    SOM estimation, that is, the effect of quantitative estimation of SOM only by
    Raman spectroscopy was improved by processing artifacts. The application of data
    fusion technology has obviously further improved the model performance, significantly
    reduced the estimation error of SOM content, and then obtained more accurate prediction
    of soil properties, which is crucial for accurate soil management decisions. In
    summary, when using the same model, the accuracy and robustness of SOM estimation
    models based on data fused by OPA were the best; When using the same input factor,
    the evaluation indicators obtained by using the PLS model were superior to RF.
    In other words, the estimation model of SOM based on OPA fusion data and PLS algorithm
    had the best performance on the validation set, and achieved R2 = 0.903, RMSE
    = 2.594 g/kg and RPD = 3.061. These results emphasized the potential applications
    of computer and electronic technology in improve management level of precision
    agriculture. 4. Discussion 4.1. Variable importance projection analysis in PLS
    According the results from Section 3, PLS achieved better estimation accuracy
    and robustness of SOM than RF. The possible reasons are as follows: (1) When dealing
    with quantitative analysis task, RF was unable to make estimation results beyond
    the range of training set, which may lead to poor performance of RF in regression
    analysis. (2) Instead of directly considering the regression modeling of the total
    dependent variables and the total independent variables, the PLS model extracted
    a number of new variables in the independent variables that had the best explanatory
    ability for the output factors, which solved the problem of independent variable
    collinearity in the spectral data well. Therefore, based on PLS as the optimal
    model, the variable importance in projection (VIP) was introduced to analyze contribution
    of the spectra variables in different bands in the modeling estimations, which
    is conducive to further discussion of the interpretability of the model. In general,
    the bands with VIP scores greater than 1 are considered as variables that play
    an important role in the PLS model. This study mainly discussed the VIP scores
    of NIR, Raman spectra after baseline correction, and spectral data fused by OPA
    in the PLS model. Fig. 6 showed the VIP scores of NIR and Raman spectra in PLS
    model. It can be seen that 898-1015, 1450-1657, and 1691-1711 nm in the NIR were
    important response bands, with VIP scores greater than 1. Among these, peaks were
    observed at around 918、1382、1494、1632、1672 nm. In terms of Raman spectra, VIP
    scores obtained at 300-500, 575-650, 1062-1109, 1486-1599, 2709-2931 cm−1 were
    greater than 1. Among them, 397, 459, 622, 1081, 1539, and 2835 cm−1 were key
    features, and there were obvious peaks in the VIP score curve of Raman spectra.
    Overall, for the spectral data from single sensor, there was a certain correspondence
    between the important bands selected based on VIP scores and the characteristic
    responses in the spectral curve, specifically manifested in the weak absorption
    peak near 1382 nm in NIR (Fig. 4), and the Raman response near 459 and 1081 cm−1
    in the Raman spectra (Fig. 5 (b) and (c)), which may be determined by the molecular
    information contained in the spectral data itself. Furthermore, some additional
    key characteristic wavenumbers of the Raman response were obtained based on the
    VIP scores. For example, the Raman response located near 1539 cm−1 may be due
    to the vibration of the C=C (Edwards et al., 2012), and the response at 2835 cm−1
    may correspond to the asymmetric stretching of CH2 (Yang and Chase, 1998). VIP
    score, as one of the widely used features selection methods in PLS, comprehensively
    reflects the importance of each independent variable in all independent variables
    and its contribution in the estimation of dependent variables (Shi et al., 2023),
    which may be beneficial to improve the accuracy of quantitative estimation of
    SOM content using Raman spectra. Download : Download high-res image (193KB) Download
    : Download full-size image Fig. 6. The VIP score of spectral data from single
    sensor in the PLS model. (a) NIR, (b) Raman spectra after baseline correction.
    When discussing and analyzing the VIP scores of spectra fused by OPA, the row
    vectors (Eq. (5)) used for modeling and their related modeling parameters in PLS
    were folded back to the matrix with p rows and q columns. Through this step, the
    interaction between the two spectral data were clearly explained. The contribution
    of each variable in the fused spectra in the PLS model was represented in the
    form shown in Fig. 7. It can be seen from the figure that almost all the NIR bands
    were considered to have important contribution to the estimation of SOM. And the
    important bands of Raman spectra after OPA fusion existed in the range of 500-1700
    cm−1. The intersection area of the above two parts was the red area on the left
    side of Fig. 7. The bands with high VIP score of the Raman spectra in the spectral
    data fused by OPA had a similar trend to the Raman spectra used alone, but more
    bands of the NIR had been determined to be important bands, which may be because
    OPA had further explored the NIR characteristics highly related to SOM and it
    was the result of their interaction with the Raman spectra (Barros et al., 2008,
    Terra et al., 2019). Download : Download high-res image (408KB) Download : Download
    full-size image Fig. 7. VIP scores of spectral data from various bands after OPA
    fusion in the PLS model. The x-axis represents the wavenumber range of Raman spectra,
    the y-axis represents the wavelength range of NIR. 4.2. Comparison of SOM prediction
    with previous studies and effectiveness of OPA fusion strategy Raman spectroscopy
    is sensitive to the existence and structure of the carbonaceous phase, enabling
    it to provide efficient, mineral-specific identification information (Fries and
    Steele, 2010). Its application in soil type identification has been reported (Xing
    et al., 2016). On the other hand, fluorescence interference also leads to the
    limited application of Raman spectroscopy in quantitative determination of soil
    parameters. Table 3 summarized the existing research on using Raman spectroscopy
    for SOM estimation. Table 3. Summary of research on quantitative estimation of
    SOM using Raman spectroscopy. Reference Sensors Baseline correction Fusion strategy
    Statistical method RMSE (g/kg) Discussion on model interpretability Xing et al.,
    2016 Raman Air-PLS – PLS 8.16 No Xing et al., 2016 Raman + FTIR-PAS Air-PLS DC
    PLS 6.74 No Xing et al., 2021 Raman + FTIR-ATR Air-PLS DC PLS 4.35 No Notes: FTIR-PAS,
    Fourier-transform infrared photoacoustic; FTIR-ATR, mid-infrared attenuated total
    reflection; RMSE refers to the values in the validation set. Previous study identified
    that it is costly and unrealistic to reduce the fluorescence interference by sample
    pretreatment (such as oxidation or surface enhancement) to improve the resolution
    of Raman spectrum in the face of large-scale farmland under the current demand
    of precision agriculture. The modern chemometric methods provide another possibility,
    in which the air-PLS algorithm adaptively adjusts the sum of squared errors between
    the fitted baseline and the original signal during the iteration process, and
    realizes the baseline adaptive correction of Raman spectrum. Baseline correction
    improved the performance of Raman spectroscopy in SOM estimation, but overall,
    the estimation results using only Raman spectroscopy were not entirely reliable.
    The RPD values reported in the previous studies were moderate, and the results
    obtained in this study were consistent with the above results. Furthermore, the
    fusion of multiple sensors including Raman spectrum was another effective scheme
    to improve the estimation performance. From the results, compared with the previous
    studies, this study achieved higher precision estimation results (RMSE = 2.594
    g/kg, RPD = 3.061), which may be due to the differences brought by different data
    fusion strategies. But we also know that it is unconvincing to discuss and compare
    the estimation accuracy separately without considering the differences of samples,
    spectral data types and processing flow. Therefore, in our study, we compared
    the estimation performance of the DC and OPA fusion strategies in different models
    to further validate the effectiveness of OPA. The results also demonstrated that
    the spectral data fusion based on OPA, whether in the RF or PLS models, yielded
    superior SOM estimation accuracy compared to the DC. In summary, the distinctive
    feature of this study compared to existing research lies in the exploration of
    fusion strategies to identify the most effective approach in fully exploiting
    and utilizing the complementary information between the two types of spectral
    data. The key factor of OPA''s superior performance compared with DC is that it
    can capture the complex relationship and interaction between the spectral characteristics
    of two data sets. OPA not only considered the independent spectra, but also considered
    their interaction, thus producing an abundant data representation. This is particularly
    critical in the context of SOM estimation, because the spectral characteristics
    of organic matter are intertwined with other soil components and emphasizing the
    useful spectral information through appropriate fusion strategies is beneficial
    for multivariate analysis in estimation models. In addition, because soil is a
    complex composite, it is reflected in the complexity of soil composition and the
    heterogeneity of organic matter distribution. Therefore, there is a need for a
    method that can effectively extract relevant information from diverse spectral
    data. In this respect, OPA''s ability to find information and correlations in
    data has proved to be advantageous（Xu et al., 2019）, which may be ignored by direct
    concatenation. In a word, the superiority of OPA in improving the accuracy of
    SOM estimation is attributed to its ability to capture spectral interactions and
    discover hidden information. These advantages are particularly critical when dealing
    with complex and heterogeneous soil samples. 4.3. Uncertainty analysis This study
    used two different spectral sensors and fused their data for SOM estimation. Although
    the results were encouraging, the spectral processing process involved in this
    study still needs to be explained and discussed as follows: the spectral preprocessing
    of this study included multiple steps, and each step dealt with different types
    of artifacts, including noise removal and baseline correction. However, the results
    of this study were based on a specific pretreatment sequence, which suggests that
    changing the preprocessing steps may alter the final results (Engel et al., 2013).
    Additionally, there is a potential uncertainty of underestimating the baseline
    area and overestimating potential feature peaks when using the air-PLS algorithm
    to process spectra significantly affected by artifacts. ArPLS has been proposed
    as a potential solution to mitigate this drawback, which efficacy necessitates
    more testing (Baek et al., 2015). 4.4. Application potential and limitation This
    study confirmed that the integration of multiple spectral technologies could provide
    valuable insights for estimation SOM content. By making full use of the diversity
    of spectral data and the advantages of electronic data processing, more reliable
    and accurate soil estimation results were obtained. These results are beneficial
    for reliable soil fertility monitoring and mapping, thereby providing support
    for agricultural management decisions. Fig. 8 (a) and (b) respectively illustrated
    the actual distribution of SOM content in the study area and the estimated distribution
    obtained from PLS model based on the fused spectral data using the OPA. It can
    be observed that the estimated spatial distribution of SOM was similar to the
    actual spatial distribution and it should be noted that the actual measured SOM
    spatial distribution didn’t strictly follow the trend of fertilization levels,
    which was caused by the spatial discrepancy in organic matter already existing
    in the soil before fertilization. According to the actual value and the estimation
    value of SOM, the SOM content error distribution map was drawn and shown in Fig.
    8 (c). It can be observed that the areas with higher organic matter content exhibited
    larger estimation errors. One possible reason is that the soil with high organic
    matter content usually presents darker color, which leads to more intense interference
    of fluorescence effect and makes it more difficult to extract Raman spectral information
    and multivariate analysis (Parikh et al., 2014, Yang and Chase, 1998). In addition,
    according to the nutrient grading standard stipulated in the technical regulations
    for the Second National Soil Survey of China, the soil was divided into 6 grades
    based on the differences in organic matter content (China soil survey office,
    1979, Huang et al., 2022). Fig. 8 (d) presented the soil distribution map drawn
    based on this standard. Rapid understanding of soil grading in the field, which
    in turn serves government agricultural decision-making, may be another application
    in addition to providing technical support for variable fertilization. Download
    : Download high-res image (703KB) Download : Download full-size image Fig. 8.
    (a) The actual distribution map of SOM; (b) The estimated distribution map of
    SOM obtained from PLS model based on the fused spectral data using OPA; (c)The
    error distribution map of SOM; (d) The distribution map of soil grade. Grade 1:
    SOM>40 g/kg, Grade 2: 40 g/kg>SOM>30 g/kg, Grade 3: 30 g/kg>SOM>20 g/kg, Grade
    4: 20 g/kg>SOM>10 g/kg. In this study, various soil spectral data were collected,
    and advanced data fusion strategies were employed, achieving promising results.
    However, it must be admitted that the use of two different sensors has higher
    hardware costs and requires more data processing and analysis methods. Meanwhile,
    this study utilized full spectral data from NIR and Raman spectroscopy, without
    involving feature selection before constructing the model. The OPA may bring about
    the problem of too many variables when fusing spectral data (Barros et al., 2008),
    which was avoided in this study by down sampling the spectra (Xu et al., 2019).
    Additionally, it should be noted that the soil samples in this study were all
    from northern China, and their types were all loam soil. Further testing is needed
    to determine whether the model parameters established based on the above experimental
    samples are applicable to a wider range of experimental areas and soil types.
    Therefore, future work will include: (1) Developing integrated sensors with the
    advantages of portability and low-cost; (2) Obtaining higher quality spectral
    data and employing different feature selection algorithms to further improve the
    estimation accuracy of SOM; (3) Expanding the soil sample dataset by collecting
    samples from a broader range of regions and soil types. The above content will
    be further explored in next stage research. 5. Conclusion This study investigated
    the fusion of Raman spectroscopy and near-infrared spectroscopy from the perspective
    of electronic data fusion for SOM estimation, aiming to improve estimation performance
    and obtain accurate SOM distribution. In this study, 258 soil samples from northern
    China were collected, and two data fusion strategies along with two modeling algorithms
    were employed. By comparing the estimation performance of SOM based on NIR, Raman
    spectrum, fused spectral data by DC, and fused spectral data by OPA in RF and
    PLS models, respectively, the study generated SOM distribution maps for the research
    area and the following conclusions were drawn:(1) In the quantitative evaluation
    of SOM, the fusion of NIR and Raman spectroscopy hold the promising potential
    of obtaining more accurate estimation results than each technique individually.
    (2) Compared to DC, the OPA was proved to be a more effective spectral data fusion
    strategy. (3) On the basis of data fusion, the model based on PLS outperformed
    RF in SOM estimation. This study demonstrated the possibility of integrating multiple
    spectral technologies to improve the accuracy of SOM estimation. It is expected
    that this study will be beneficial for soil fertility monitoring and soil mapping
    in precision agriculture, and thus provide valuable reference for fertilization
    decision-making. In our future endeavors, we are committed to developing a portable
    SOM estimation sensor tailored for in-situ field measurements, building upon the
    methods and insights gained from this research. This initiative aims to further
    improve soil management practices within the field of precision agriculture. CRediT
    authorship contribution statement Yu Bai: Conceptualization, Data curation, Formal
    analysis, Methodology, Software, Visualization, Writing – original draft. Wei
    Yang: Funding acquisition, Supervision, Writing – review & editing. Zhaoyang Wang:
    Investigation. Yongyan Cao: Investigation. Minzan Li: Funding acquisition, Project
    administration, Supervision. Declaration of competing interest The authors declare
    that they have no known competing financial interests or personal relationships
    that could have appeared to influence the work reported in this paper. Acknowledgement
    Acknowledgements This work was supported by the Key Research and Development Program
    of Shandong Province (Major Science and Technology Innovation Project, 2022CXGC020708)
    and the National Key Research and Development Program (2019YFE0125500). Data availability
    The data that has been used is confidential. References Argyraki et al., 1997
    A. Argyraki, M.H. Ramsey, P.J. Potts Evaluation of portable X-ray fluorescence
    instrumentation for in situ measurements of lead on contaminated land Analyst,
    122 (8) (1997), pp. 743-749, 10.1039/A700746I View in ScopusGoogle Scholar Baek
    et al., 2015 S.J. Baek, A. Park, Y.J. Ahn, J. Choo Baseline correction using asymmetrically
    reweighted penalized least squares smoothing Analyst, 140 (1) (2015), pp. 250-257,
    10.1039/C4AN01061B Google Scholar Barros et al., 2008 A.S. Barros, R. Pinto, D.
    Jouan-Rimbaud Bouveresse, D.N. Rutledge Principal component transform–outer product
    analysis in the PCA context Chemom. Intell. Lab., 93 (2008), pp. 43-48, 10.1016/j.chemolab.2008.03.009
    View PDFView articleView in ScopusGoogle Scholar Bellon-Maurel and Alex, 2011
    Bellon-Maurel, V., Alex. M., 2011. Near-infrared (NIR) and mid-infrared (MIR)
    spectroscopic techniques for assessing the amount of carbon stock in soils–Critical
    review and research perspectives. Soil Biology and Biochemistry 43.7 (2011): 1398-1410.
    https://doi.org/10.1016/j.soilbio.2011.02.019. Google Scholar Benedet et al.,
    2020 L. Benedet, W.M. Faria, S.H.G. Silva, M. Mancini, J.A.M. Dematt̂e, L.R.G.
    Guilherme, N. Curi Soil texture prediction using portable X-ray fluorescence spectrometry
    and visible near-infrared diffuse reflectance spectroscopy Geoderma, 376 (2020),
    Article 114513, 10.1016/j.geoderma.2020.114553 Google Scholar Chen et al., 2019
    J. Chen, F. Li, R. Wang, Y. Fan, M.A. Raza, Q. Liu, Z. Wang, Y. Cheng, X. Wu,
    F. Yang, W. Yang Estimation of nitrogen and carbon content from soybean leaf reflectance
    spectra using wavelet analysis under shade stress Comput. Electron. Agric., 156
    (2019), pp. 482-489, 10.1016/j.compag.2018.12.003 View PDFView articleView in
    ScopusGoogle Scholar Chen et al., 2011 H. Chen, T. Pan, J. Chen, Q. Lu Waveband
    selection for NIR spectroscopy analysis of soil organic matter based on SG smoothing
    and MWPLS methods Chemom. Intel. Lab. Syst., 107 (1) (2011), pp. 139-146, 10.1016/j.chemolab.2011.02.008
    View PDFView articleView in ScopusGoogle Scholar Cheng et al., 2010 C. Cheng,
    J. Liu, C. Zhang, M. Cai, H. Wang, W. Xiong An overview of infrared spectroscopy
    based on continuous wavelet transform combined with machine learning algorithms:
    application to Chinese medicines, plant classification, and cancer diagnosis Appl.
    Spectrosc. Rev., 45 (2) (2010), pp. 148-164, 10.1080/05704920903435912 View in
    ScopusGoogle Scholar China soil survey office, 1979 China soil survey office,
    The National Second Soil Survey Nutrient Grading Standards. 1979 Beijing: China
    Agricultural Press. Google Scholar Conforti et al., 2018 M. Conforti, G. Matteucci,
    G. Buttafuoco Using laboratory Vis-NIR spectroscopy for monitoring some forest
    soil properties J. Soil. Sediment., 18 (2018), pp. 1009-1019, 10.1007/s11368-017-1766-5
    View in ScopusGoogle Scholar Da Silva-Sangoi et al., 2022 D.V. Da Silva-Sangoi,
    T.Z. Horst, J.M. Moura-Bueno, R.S.D. Dalmolin, E. Sebem, L. Gebler, M. da Silva
    Santos Soil organic matter and clay predictions bylaboratory spectroscopy: Data
    spatial correlation Geoderma Reg., 28 (2022), p. e00486 Google Scholar dos Santos
    Teixeira et al., 2022 A.F. dos Santos Teixeira, R. Andrade, M. Mancini, S.H.G.
    Silva, D.C. Weindorf, S. Chakraborty, L.R.G. Guilherme, N. Curi Proximal sensor
    data fusion for tropical soil property prediction: Soil fertility properties J.
    S. Am. Earth Sci., 116 (2022), Article 103873, 10.1016/j.jsames.2022.103873 Google
    Scholar Edwards et al., 2012 H. Edwards, T. Munshi, I. Scowen, A. Surtees, G.T.
    Swindles Development of oxidative sample preparation for the analysis of forensic
    soil samples with near-IR Raman spectroscopy J. Raman Spectrosc., 43 (2) (2012),
    pp. 323-325, 10.1002/jrs.3031 View in ScopusGoogle Scholar Engel et al., 2013
    Engel, J., Gerretzen J., Szymańska E., J.Jansen J., Downey G., Blanchet L., M.C.Buydens
    L., 2013. Breaking with trends in pre-processing? TrAC Trends in Analytical Chemistry,
    50: 96-106. https://doi.org/10.1016/j.trac.2013.04.015. Google Scholar Fleischmann
    et al., 1974 M. Fleischmann, P.J. Hendra, A.J. McQuillan Raman spectra of pyridine
    adsorbed at a silver electrode Chem. Phys. Lett., 26 (2) (1974), 10.1016/0009-2614(74)85388-1
    Google Scholar Francioso et al., 2000 O. Francioso, C. Ciavatta, S. Sànchez-Cortés,
    V. Tugnoli, L. Sitti, C. Gessa Spectroscopic characterization of soil organic
    matter in long-term amendment trial Soil Sci., 165 (6) (2000), pp. 495-504, 10.1097/00010694-200006000-00005
    View in ScopusGoogle Scholar Fries and Steele, 2010 Fries, M., Steele, A., 2010.
    Raman spectroscopy and confocal Raman imaging in mineralogy and petrography. Confocal
    Raman Microscopy. Berlin, Heidelberg: Springer Berlin Heidelberg, 2010: 111-135.
    https://doi.org/10.1007/978-3-319-75380-5_10. Google Scholar HJ/T 166-2004, 2004
    HJ/T 166-2004, 2004. Technical specification for soil environmental monitoring.
    Google Scholar Horta et al., 2015 A. Horta, B. Malone, U. Stockmann, B. Minasny,
    T.F.A. Bishop, A.B. McBratney, R. Pallasser, L. Pozza Potential of integrated
    field spectroscopy and spatial analysis for enhanced assessment of soil contamination:
    A prospective review Geoderma, 241 (2015), pp. 180-209, 10.1016/j.geoderma.2014.11.024
    View PDFView articleView in ScopusGoogle Scholar Huang et al., 2022 X. Huang,
    Q. Dai, W. Liang, Z. Zhao, Z. Yang, D. Xie, J. Liao Analysis and evaluation of
    soil nutrient content in chestnut orchards in Northwest Guangxi Southwest China
    J. Agric. Sci., 35 (12) (2022), pp. 2827-2835 Google Scholar Jaillais et al.,
    2005 B. Jaillais, R. Pinto, A.S. Barros, D.N. Rutledge Outer-product analysis
    (OPA) using PICA to study the influence of temperature on NIR spectra of water
    Vib. Spectrosc., 39 (2005), pp. 50-58, 10.1016/j.vibspec.2004.10.008 View PDFView
    articleView in ScopusGoogle Scholar Jaillais et al., 2006 B. Jaillais, M.A. Ottenhof,
    I.A. Farhat, D.N. Rutledge Outer-product analysis (OPA) using PLS regression to
    study the retrogradation of starch Vib. Spectrosc., 40 (1) (2006), pp. 10-19,
    10.1016/j.vibspec.2005.06.001 View PDFView articleView in ScopusGoogle Scholar
    Jia et al., 2023 J. Jia, J. Zhang, Y. Li, L. Koziol, L. Podzikowski, M. Delgado-Baquerizo,
    G. Wang, J. Zhang Relationships between soil biodiversity and multifunctionality
    in croplands depend on salinity and organic matter Geoderma, 429 (2023), Article
    116273, 10.1016/j.geoderma.2022.116273 View PDFView articleView in ScopusGoogle
    Scholar Knox et al., 2015 N.M. Knox, S. Grunwald, M.L. McDowell, G.L. Bruland,
    D.B. Myers, W.G. Harris Modelling soil carbon fractions with visible near-infrared
    (VNIR) and mid-infrared (MIR) spectroscopy Geoderma, 239–240 (2015), pp. 229-239,
    10.1016/j.geoderma.2014.10.019 View PDFView articleView in ScopusGoogle Scholar
    Kononova, 2013 M.M. Kononova Soil organic matter: its nature, its role in soil
    formation and in soil fertility Elsevier (2013) Google Scholar Lal, 2004 R. Lal
    Soil carbon sequestration impacts on global climate change and food security Science,
    304 (2004), pp. 1623-1627, 10.1126/science.1097396 View in ScopusGoogle Scholar
    Lamichhane et al., 2019 S. Lamichhane, L. Kumar, B. Wilson Digital soil mapping
    algorithms and covariates for soil organic carbon mapping and their implications:
    A review Geoderma, 352 (2019), pp. 395-413, 10.1016/j.geoderma.2019.05.031 View
    PDFView articleView in ScopusGoogle Scholar Li et al., 2021 T. Li, Y. Wu, F. Wu,
    S. Mohammed, R.K. Wong, K.L. Ong Sleep pattern inference using IoT sonar monitoring
    and machine learning with Kennard-stonebalance algorithm Comput. Electr. Eng.,
    93 (2021), Article 107181, 10.1016/j.compeleceng.2021.107181 View PDFView articleView
    in ScopusGoogle Scholar Ma et al., 2023 Q. Ma, K. Fu, J. Zhang, M. Li, X. Han,
    Z. Chen, L. Ma, C. Chang New bio-based polyurethane (PU) foams synthesized using
    crude glycerol-based biopolyol and humin-based byproducts from biomass hydrolysis
    Ind. Crop. Prod., 205 (2023), Article 117548, 10.1016/j.indcrop.2023.117548 View
    PDFView articleView in ScopusGoogle Scholar Mohamed et al., 2018 E.S. Mohamed,
    A.M. Saleh, A.B. Belal, A.A. Gad Application of near-infrared reflectance for
    quantitative assessment of soil properties Egypt. J. Remote Sens. Space Sci.,
    21 (1) (2018), pp. 1-14, 10.1016/j.ejrs.2017.02.001 View PDFView articleView in
    ScopusGoogle Scholar Nelson and Sommers, 1983 Nelson, D., Sommers, L., 1983. Total
    Carbon, Organic Carbon, and Organic Matter. Methods Soil Analy.: Part 2 Chem.
    Microbiol. Properties 9, 539–579.https://doi.org/10.2134/agronmonogr9.2.2ed.c29.
    Google Scholar Ng et al., 2019 W. Ng, B. Minasny, M. Montazerolghaem, J. Padarian,
    R. Ferguson, S. Bailey, A. McBratney Convolutional neural network for simultaneous
    prediction of several soil properties using visible/near-infrared, mid-infrared,
    and their combined spectra Geoderma, 352 (2019), pp. 251-267, 10.1016/j.geoderma.2019.06.016
    View PDFView articleView in ScopusGoogle Scholar NY/T 395-2012, 2012 NY/T 395-2012,
    2012. Technical Rules for Monitoring of Environmental Quality of Farmland Soil.
    Google Scholar Padarian et al., 2019 J. Padarian, B. Minasny, A.B. McBratney Using
    deep learning to predict soil properties from regional spectral data Geoderma
    Reg., 16 (2019), p. e00198 View PDFView articleView in ScopusGoogle Scholar Parikh
    et al., 2014 S.J. Parikh, K.W. Goyne, A.J. Margenot, F.N.D. Mukome, F.J. Calderón
    Soil chemical insights provided through vibrational spectroscopy Adv. Agron.,
    126 (2014), pp. 1-148, 10.1016/B978-0-12-800132-5.00001-8 View PDFView articleView
    in ScopusGoogle Scholar Perumal et al., 2023 A.B. Perumal, R.B. Nambiar, X.L.
    Luo, Z.Z. Su, X.L. Li, Y. He Exploring dynamic changes of fungal cellular components
    during nanoemulsion treatment by multivariate microRaman imagin Talanta, 261 (2023),
    Article 124666, 10.1016/j.talanta.2023.124666 View PDFView articleView in ScopusGoogle
    Scholar Qiao et al., 2022 L. Qiao, D. Gao, R. Zhao, W. Tang, L. An, M. Li, H.
    Sun Improving estimation of LAI dynamic by fusion of morphological and vegetation
    indices based on UAV imagery Comput. Electron. Agric., 192 (2022), Article 106603,
    10.1016/j.compag.2021.106603 View PDFView articleView in ScopusGoogle Scholar
    Rinnan et al., 2009 Rinnan. Å., Van Den Berg F., Engelsen S., B., 2009. Review
    of the most common pre-processing techniques for near-infrared spectra. TrAC Trends
    in Analytical Chemistry, 2009, 28(10): 1201-1222. https://doi.org/10.1016/j.trac.2009.07.007.
    Google Scholar Roldan et al., 2011 M.L. Roldan, G. Corrado, O. Francioso, S. Sanchez-Cortes
    Interaction of soil humic acids with herbicide paraquat analyzed by surface-enhanced
    Raman scattering and fluorescence spectroscopy on silver plasmonic nanoparticles
    Anal. Chim. Acta, 699 (2011), pp. 87-95, 10.1016/j.aca.2011.05.001 View PDFView
    articleView in ScopusGoogle Scholar Sharma, 2004 B.K. Sharma Instrumental Methods
    of Chemical Analysis Goel Publishing House, Meerut, India (2004) Google Scholar
    Sharma et al., 2021 V. Sharma, R. Chauhan, R. Kumar Spectral characteristics of
    organic soil matter: A comprehensive review Microchem. J., 171 (2021), Article
    106836, 10.1016/j.microc.2021.106836 View PDFView articleView in ScopusGoogle
    Scholar Shi et al., 2023 X. Shi, J. Song, H. Wang, X. Lv, Y. Zhu, W. Zhang, W.
    Bu, L. Zeng Improving soil organic matter estimation accuracy by combining optimal
    spectral preprocessing and feature selection methods based on pXRF and vis-NIR
    data fusion Geoderma, 430 (2023), Article 116301, 10.1016/j.geoderma.2022.116301
    View PDFView articleView in ScopusGoogle Scholar Smith and Dent, 2019 E. Smith,
    G. Dent Modern Raman spectroscopy: a practical approach John Wiley & Sons (2019),
    10.1016/B978-0-12-800132-5.00001-8 Google Scholar Tao and Liu, 2015 S. Tao, G.
    Liu Modern Spectroscopy, Science Press (2015) Google Scholar Terra et al., 2019
    F.S. Terra, R.A. Viscarra Rossel, J.A.M. Demattê Spectral fusion by Outer Product
    Analysis (OPA) to improve predictions of soil organic C Geoderma, 335 (2019),
    pp. 35-46, 10.1016/j.geoderma.2018.08.005 View PDFView articleView in ScopusGoogle
    Scholar Walkley and Black, 1934 A. Walkley, I.A. Black An examination of the degtjareff
    method for determining soil organic matter, and a proposed modification of the
    chromic acid titration method Soil Sci., 37 (1934), pp. 29-38, 10.1097/00010694-193401000-00003
    View in ScopusGoogle Scholar Wan et al., 2020 M. Wan, W. Hu, M. Qu, W. Li, C.
    Zhang, J. Kang, Y. Hong, Y. Chen, B. Huang Rapid estimation of soil cation exchange
    capacity through sensor data fusion of portable XRF spectrometry and Vis-NIR spectroscopy
    Geoderma, 363 (2020), Article 114163, 10.1016/j.geoderma.2019.114163 View PDFView
    articleView in ScopusGoogle Scholar Wang, 1987 Z. Wang Optical Technology Handbook
    Mechanical Industry Press (1987) Google Scholar Wang et al., 2015 D. Wang, S.
    Chakraborty, D.C. Weindorf, B. Li, A. Sharma, S. Paul, M.N. Ali Synthesized use
    of VisNIR DRS and PXRF for soil characterization: total carbon and total nitrogen
    Geoderma, 243–244 (2015), pp. 157-167, 10.1016/j. geoderma.2014.12.011 View PDFView
    articleGoogle Scholar Wang et al., 2024 Wang, Z., Chen, S., Lu, R., Zhang, X.,
    Ma, Y., Shi, Z., 2024. Non-linear memory-based learning for predicting soil properties
    using a regional vis-NIR spectral library. Geoderma, 441: 116752. https://doi.org/10.1016/j.geoderma.2023.116752.
    Google Scholar Wang et al., 2023 X. Wang, M. Zhang, Q. Guo, H. Yang, H. Wang,
    X. Sun Estimation of soil organic matter by in situ Vis-NIR spectroscopy using
    an automatically optimized hybrid model of convolutional neural network and long
    short-term memory network Comput. Electron. Agric., 214 (2023), Article 108350,
    10.1016/j.compag.2023.108350 View PDFView articleView in ScopusGoogle Scholar
    Xing et al., 2016 Z. Xing, C. Du, K. Tian, F. Ma, Y. Shen, J. Zhou Application
    of FTIR-PAS and Raman spectroscopies for the determination of organic matter in
    farmland soils Talanta, 158 (2016), pp. 262-269, 10.1016/j.talanta.2016.05.076
    View PDFView articleView in ScopusGoogle Scholar Xing et al., 2021 Z. Xing, C.
    Du, Y. Shen, F. Ma, J. Zhou A method combining FTIR-ATR and Raman spectroscopy
    to determine soil organic matter: Improvement of prediction accuracy using competitive
    adaptive reweighted sampling (CARS) Comput. Electron. Agric., 191 (2021), Article
    106549, 10.1016/j.compag.2021.106549 View PDFView articleView in ScopusGoogle
    Scholar Xing et al., 2016 Xing, Z., Du, C., W., Zeng, Y., Ma, F., Zhou, J., M.,
    2016. Characterizing typical farmland soils in China using Raman spectroscopy.
    Geoderma 268, 147-155. https://doi.org/10.1016/j.geoderma.2016.01.029. Google
    Scholar Xu et al., 2019 D. Xu, S. Chen, R.A. Viscarra Rossel, A. Biswas, S. Li,
    Y. Zhou, Z. Shi X-ray fluorescence and visible near infrared sensor fusion for
    predicting soil chromium content Geoderma, 352 (2019), pp. 61-69, 10.1016/j.geoderma.2019.05.036
    View PDFView articleView in ScopusGoogle Scholar Xu et al., 2020 D. Xu, S. Chen,
    H. Xu, N. Wang, Y. Zhou, Z. Shi Data fusion for the measurement of potentially
    toxic elements in soil using portable spectrometers Environ. Pollut., 263 (2020),
    Article 114649, 10.1016/j.envpol.2020.114649 View PDFView articleView in ScopusGoogle
    Scholar Yang and Chase, 1998 Y. Yang, H.A. Chase Applications of Raman and surface-enhanced
    Raman scattering techniques to humic substances Spectrosc. Lett., 31 (4) (1998),
    pp. 821-848, 10.1080/00387019808007402 View in ScopusGoogle Scholar Yang et al.,
    2020 B. Yang, Z. Zhu, M. Gao, X. Yan, X. Zhu, W. Guo A portable detector on main
    compositions of raw and homogenized milk Comput. Electron. Agric., 177 (2020),
    Article 105668, 10.1016/j.compag.2020.105668 View PDFView articleView in ScopusGoogle
    Scholar Zhang et al., 2010 Z. Zhang, S. Chen, Y. Liang Baseline correction using
    adaptive iteratively reweighted penalized least squares Analyst, 135 (5) (2010),
    pp. 1138-1146, 10.1039/B922045C View in ScopusGoogle Scholar Zhao et al., 2022
    L. Zhao, Q. Fang, H. Hong, T.J. Algeo, A. Lu, K. Yin, C. Wang, C. Liu, L. Chen,
    S. Xie Pedogenic-weathering evolution and soil discrimination by sensor fusion
    combined with machine-learning-based spectral modeling Geoderma, 409 (2022), Article
    115648, 10.1016/j.geoderma.2021.115648 View PDFView articleView in ScopusGoogle
    Scholar Zhao et al., 2023 Y. Zhao, X. Wang, F. Chen, J. Li, J. Wu, Y. Sun, Y.
    Zhang, T. Deng, S. Jiang, X. Zhou, H. Liu Soil organic matter enhances aboveground
    biomass in alpine grassland under drought Geoderma, 433 (2023), Article 116430,
    10.1016/j.geoderma.2023.116430 View PDFView articleView in ScopusGoogle Scholar
    Zhao et al., 2022 D. Zhao, Y. Zhu, S. Wu, Q. Lu Simulated response of soil organic
    carbon density to climate change in the Northern Tibet permafrost region Geoderma,
    405 (2022), Article 115455, 10.1016/j.geoderma.2021.115455 View PDFView articleView
    in ScopusGoogle Scholar Cited by (0) View Abstract © 2024 Published by Elsevier
    B.V. Part of special issue Advanced Technologies in Sustainable Agriculture 4.0:
    Future Farming, Monitoring, Harvesting and Preservation Edited by Yunchao Tang,
    Spyros Fountas, Yiannis Ampatzidis, Lei Shu View special issue Recommended articles
    Comparative analysis of different machine learning algorithms for predicting trace
    metal concentrations in soils under intensive paddy cultivation Computers and
    Electronics in Agriculture, Volume 219, 2024, Article 108772 Mehmet Taşan, …,
    Elif Öztürk View PDF Automated segmentation of individual leafy potato stems after
    canopy consolidation using YOLOv8x with spatial and spectral features for UAV-based
    dense crop identification Computers and Electronics in Agriculture, Volume 219,
    2024, Article 108795 Hanhui Jiang, …, Longsheng Fu View PDF An improved target
    detection method based on YOLOv5 in natural orchard environments Computers and
    Electronics in Agriculture, Volume 219, 2024, Article 108780 Jiachuang Zhang,
    …, Longlian Zhao View PDF Show 3 more articles About ScienceDirect Remote access
    Shopping cart Advertise Contact and support Terms and conditions Privacy policy
    Cookies are used by this site. Cookie settings | Your Privacy Choices All content
    on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply."'
  inline_citation: '>'
  journal: Computers and Electronics in Agriculture
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Improving the estimation accuracy of soil organic matter based on the fusion
    of near-infrared and Raman spectroscopy using the outer-product analysis
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Kong J.
  - Fan X.
  - Zuo M.
  - Yan W.
  - Jin X.
  citation_count: '0'
  description: Smart agricultural decision support systems (DSS) leverage big data
    technology to generate efficient decision recommendations. However, missing values
    in sensor data can lead to cumulative errors and reduced accuracy in data analysis,
    compromising the precision of these decision systems. To address this issue, we
    propose an intelligent multi-factor prediction framework for smart agriculture
    environments. This framework utilizes fuzzy Bayesian data imputation to minimize
    filling errors and provide a reliable data foundation for decision systems. The
    framework includes a fuzzy Bayesian module for imputing missing data, resulting
    in complete datasets and enhancing interpretability. Additionally, a multi-factor
    prediction model is established within an encode-decode framework, incorporating
    dimension-temporal cross-attention layers to capture and extract correlations
    among multiple factors. Extensive experiments demonstrate that our proposed model
    outperforms single-factor prediction, achieving a 13.6&#x0025; increase in correlation.
    These results validate the effectiveness of the imputation module in enhancing
    forecasting precision and reliability, thereby assisting agricultural DSS in meeting
    evolving demands.
  doi: 10.1109/TFUZZ.2024.3363213
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Transactions on Fuzzy Sy...
    >Early Access FICformer: A Multi-factor Fuzzy Bayesian Imputation Cross-former
    for Big Data-driven Agricultural Decision Support Systems Publisher: IEEE Cite
    This PDF Jianlei Kong; Xiaomeng Fan; Min Zuo; Wenjing Yan; Xuebo Jin All Authors
    7 Full Text Views Abstract Authors Keywords Metrics Abstract: Smart agricultural
    decision support systems (DSS) leverage big data technology to generate efficient
    decision recommendations. However, missing values in sensor data can lead to cumulative
    errors and reduced accuracy in data analysis, compromising the precision of these
    decision systems. To address this issue, we propose an intelligent multi-factor
    prediction framework for smart agriculture environments. This framework utilizes
    fuzzy Bayesian data imputation to minimize filling errors and provide a reliable
    data foundation for decision systems. The framework includes a fuzzy Bayesian
    module for imputing missing data, resulting in complete datasets and enhancing
    interpretability. Additionally, a multi-factor prediction model is established
    within an encode-decode framework, incorporating dimension-temporal cross-attention
    layers to capture and extract correlations among multiple factors. Extensive experiments
    demonstrate that our proposed model outperforms single-factor prediction, achieving
    a 13.6% increase in correlation. These results validate the effectiveness of the
    imputation module in enhancing forecasting precision and reliability, thereby
    assisting agricultural DSS in meeting evolving demands. Published in: IEEE Transactions
    on Fuzzy Systems ( Early Access ) Page(s): 1 - 12 Date of Publication: 26 February
    2024 ISSN Information: DOI: 10.1109/TFUZZ.2024.3363213 Publisher: IEEE Authors
    Keywords Metrics More Like This Dynamic processes forecasting and risk estimation
    under uncertainty using decision support systems 2017 IEEE First Ukraine Conference
    on Electrical and Computer Engineering (UKRCON) Published: 2017 Dealing with location
    uncertainty in mobile networks using contextual fuzzy cognitive maps as spatial
    decision support systems Vehicular Technology Conference Fall 2000. IEEE VTS Fall
    VTC2000. 52nd Vehicular Technology Conference (Cat. No.00CH37152) Published: 2000
    Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT
    OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Transactions on Fuzzy Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'FICformer: A Multi-factor Fuzzy Bayesian Imputation Cross-former for Big
    Data-driven Agricultural Decision Support Systems'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Qi J.
  - Wang K.
  - Bao Z.
  - Zhang W.
  - Guo H.
  - Liu X.
  - Li N.
  citation_count: '0'
  description: Accurate, real-time, and in-situ acquisition of soil electrical conductivity
    can provide effective data support for the precise management of agricultural
    production. The current-voltage four-terminal approach as an invasive technology
    has considerable performance in the in-situ measurement of soil electrical conductivity
    on a large scale. This study aims to improve the accuracy of soil electrical conductivity
    measured by the traditional current-voltage four-terminal approach. A systematic
    analysis was made to determine the constant current source and electrode spacing
    in the three measurement arrays. The soil bin test was carried out to explore
    the influence of the main factors (soil moisture content, electrode embedded depth,
    soil compaction, and soil texture) on the measurement accuracy of three measurement
    arrays at different levels. The results showed that two measurement arrays of
    Wenner and Schlumberger were better applied to different soil environmental conditions.
    The measured values of soil electrical conductivity were further used as the inputs
    into the model. The regression model of soil electrical conductivity was constructed
    using the BP neural network. The R2 of the model fit was 0.99762 in the training
    set, and the RMSE of the model between the calculated and standard value was 0.12
    μS/mm in the testing set, indicating the smaller than that of individual measurement.
    All RMSE values were smaller than those in the individual array measurements.
    The measurement device of dual-array fusion soil electrical conductivity was designed
    using a regression model. The components of the device included the touchable
    LCD display, electrode sockets, switches, differential amplifier module, constant
    current source module, power supply, STM32 microcontroller data acquisition module,
    JESTON nano, and sensor. The soil electrical conductivity was then optimized using
    the measured values. The working stability test showed that the standard deviation
    of measured data was less than 0.43 μS/mm under different soil electrical conductivity
    gradient conditions. The comparative field-site performance test showed that the
    absolute, relative error range, and RMSE of measured soil electrical conductivity
    were-2.1-1.8 μS/mm,-8.0%-5.8%, 0.18 μS/mm respectively. The RMSE of 0.18 μS/mm
    was smaller than that of the traditional individual measurement array and the
    commonly used soil conductivity meters in the market. The measurement device can
    be expected to rapidly and accurately detect the soil's electrical conductivity,
    indicating better working stability and higher accuracy. The finding can provide
    high-precision detection and technical means for the real-time in situ collection
    of soil information in the field.
  doi: 10.11975/j.issn.1002-6819.202306199
  full_citation: '>'
  full_text: '>

    "首页 > 过刊浏览>2024年第40卷第1期 >90-99. DOI:10.11975/j.issn.1002-6819.202306199 PDF HTML阅读
    XML下载 导出引用 引用提醒 基于Wenner和Schlumberger双组态融合的土壤电导率测量装置 DOI: 10.11975/j.issn.1002-6819.202306199
    作者: 齐江涛      王凯晨      包志远      张伟荣      郭慧      刘向南      李宁      中图分类号: S15 基金项目:
    国家重点研发计划课题（2021YFD2000201）；国家自然科学基金项目（32271988）  Measuring soil electrical conductivity
    using dual-array fusion of Wenner and Schlumberger Author: QI Jiangtao      WANG
    Kaichen      BAO Zhiyuan      ZHANG Weirong      GUO Hui      LIU Xiangnan      LI
    Ning      摘要 | | 访问统计 | 参考文献 [34] | | | | 文章评论 摘要: 土壤电导率的准确、实时和原位获取可为农业生产精准管理提供有效的数据支撑，为提高传统电流-电压四端法测量精度，该研究基于电流-电压四端法3种测量组态，开展土壤电导率主要影响因素（土壤含水率、电极入土深度、土壤坚实度和土壤处理方式）对电流-电压四端法的3种测量组态测量精度影响的试验。结果表明，Wenner和Schlumberger两种测量组态可较好的适用于不同土壤环境条件。进一步以Wenner和Schlumberger两种测量组态所测土壤电导率值为输入量，基于BP神经网络构建了双组态融合的土壤电导率回归模型，并在此基础上设计了一种土壤电导率测量装置，该装置主要包括JESTON
    nano、STM32单片机数据采集模块、传感器、激励源及差分放大模块等组件。工作稳定性试验结果显示，该装置在不同土壤电导率梯度条件下测量数据的标准偏差均小于0.43
    μS/mm，田间性能对比试验结果显示，该装置测量数据的均方根误差值为0.18 μS/mm，测量精度优于传统单独测量组态和市面常用土壤电导率测量仪，以上结果表明所研制的土壤电导率测量装置具有较好的工作稳定性和测量精度。该研究可为田间土壤信息的实时原位采集提供一种高精度的检测工具和技术手段。
    关键词:土壤;电导率;测量组态;BP神经网络;模型;测量装置 Abstract: Accurate, real-time, and in-situ acquisition
    of soil electrical conductivity can provide effective data support for the precise
    management of agricultural production. The current-voltage four-terminal approach
    as an invasive technology has considerable performance in the in-situ measurement
    of soil electrical conductivity on a large scale. This study aims to improve the
    accuracy of soil electrical conductivity measured by the traditional current-voltage
    four-terminal approach. A systematic analysis was made to determine the constant
    current source and electrode spacing in the three measurement arrays. The soil
    bin test was carried out to explore the influence of the main factors (soil moisture
    content, electrode embedded depth, soil compaction, and soil texture) on the measurement
    accuracy of three measurement arrays at different levels. The results showed that
    two measurement arrays of Wenner and Schlumberger were better applied to different
    soil environmental conditions. The measured values of soil electrical conductivity
    were further used as the inputs into the model. The regression model of soil electrical
    conductivity was constructed using the BP neural network. The R2 of the model
    fit was 0.99762 in the training set, and the RMSE of the model between the calculated
    and standard value was 0.12 μS/mm in the testing set, indicating the smaller than
    that of individual measurement. All RMSE values were smaller than those in the
    individual array measurements. The measurement device of dual-array fusion soil
    electrical conductivity was designed using a regression model. The components
    of the device included the touchable LCD display, electrode sockets, switches,
    differential amplifier module, constant current source module, power supply, STM32
    microcontroller data acquisition module, JESTON nano, and sensor. The soil electrical
    conductivity was then optimized using the measured values. The working stability
    test showed that the standard deviation of measured data was less than 0.43 μS/mm
    under different soil electrical conductivity gradient conditions. The comparative
    field-site performance test showed that the absolute, relative, RMSE and error
    range of measured soil electrical conductivity were -2.1-1.8 μS/mm, -8%-5.5%,
    0.18-1.8 μS/mm, and -8%~5.5%, respectively. The RMSE of t 0.18 μS/mm was smaller
    than that of the traditional individual measurement array and the commonly used
    soil conductivity meters in the market. The measurement device can be expected
    to rapidly and accurately detect the soil''s electrical conductivity, indicating
    better working stability and higher accuracy. The finding can provide high-precision
    detection and technical means for the real-time in situ collection of soil information
    in the field. Key words:soil;electrical conductivity;measurement array;BP neural
    network;model;measurement device 引用本文 齐江涛,王凯晨,包志远,张伟荣,郭慧,刘向南,李宁.基于Wenner和Schlumberger双组态融合的土壤电导率测量装置[J].农业工程学报,2024,40(1):90-99.
    DOI:10.11975/j. issn.1002-6819.202306199  QI Jiangtao, WANG Kaichen, BAO Zhiyuan,
    ZHANG Weirong, GUO Hui, LIU Xiangnan, LI Ning. Measuring soil electrical conductivity
    using dual-array fusion of Wenner and Schlumberger[J]. Transactions of the Chinese
    Society of Agricultural Engineering (Transactions of the CSAE),2024,40(1):90-99.
    DOI:10.11975/j. issn.1002-6819.202306199 复制 分享 0 文章指标 点击次数:29 下载次数: 32 HTML阅读次数:
    0 历史 收稿日期:2023-06-28 最后修改日期:2023-12-13 在线发布日期: 2024-01-27 您是第39579540位访问者 ICP:京ICP备06025802号-3
    农业工程学报 ® 2024 版权所有 技术支持：北京勤云科技发展有限公司 请使用 Firefox、Chrome、IE10、IE11、360极速模式、搜狗极速模式、QQ极速模式等浏览器，其他浏览器不建议使用!"'
  inline_citation: '>'
  journal: Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural
    Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Measuring soil electrical conductivity using dual-array fusion of Wenner
    and Schlumberger
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Scudiero E.
  - Corwin D.L.
  - Markley P.T.
  - Pourreza A.
  - Rounsaville T.
  - Bughici T.
  - Skaggs T.H.
  citation_count: '0'
  description: On-the-go soil apparent electrical conductivity (ECa) sensors are great
    tools for mapping and monitoring soil properties such as water content, texture,
    and salinity. ECa maps and surveys are most useful and reliable when obtained
    in uniformly wet fields. However, soil moisture in micro-irrigated (e.g., drip
    or micro-sprinklers) orchards is typically non-uniform, with moist soil along
    tree and irrigation lines, and dry soil between tree rows. We developed a mobile
    platform and data post-processing algorithm to facilitate geospatial ECa measurements
    along or near driplines. Gamma-ray (γ-ray) spectrometry is commonly used for clay
    content and type mapping. Fusion between ECa and γ-ray is often reported to increase
    the accuracy of field-scale soil maps. However, contrarily to ECa, γ-ray spectrometry
    is best suited for sensing soils in dry conditions. Micro-irrigated orchards are
    ideal environments for the combined application of these two sensor technologies.
    The fusion of topsoil (top 0.5 m) ECa (measured along the driplines) and γ-ray
    total counts (TC) (measured between the tree rows) data was tested at a 0.4-ha
    sandy loam citrus orchard in Southern California. Here, we discuss sensor data
    acquisition, data processing, sensor-directed sampling scheme delineation, and
    characterization of field-scale soil particle size fraction (0–0.4 m soil profile)
    spatial variability. Pearson correlation coefficients between sand and silt content
    with both ECa and TC were significant (p < 0.05). A principal component analysis
    biplot suggested strong positive relationship with TC and clay content. Backwards
    stepwise multiple linear regression predicted sand content using TC, elevation,
    and spatial coordinates as explanatory variables with mean absolute error (MAE)
    of 3.06 %. Silt content was predicted (MAE=1.55 %) using ECa, elevation, and spatial
    coordinates. The development of this platform enables better characterization
    of soil properties in micro-irrigated orchard systems using on-the-go sensing
    technology.
  doi: 10.1016/j.still.2023.105899
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Materials and methods
    3. Results and discussion 4. Conclusions Declaration of Competing Interest Acknowledgements
    Appendix A. – Post-processing coordinate-shift algorithm Data availability References
    Show full outline Figures (7) Show 1 more figure Tables (3) Table 1 Table 2 Table
    3 Soil and Tillage Research Volume 235, January 2024, 105899 A system for concurrent
    on-the-go soil apparent electrical conductivity and gamma-ray sensing in micro-irrigated
    orchards Author links open overlay panel Elia Scudiero a b, Dennis L. Corwin b,
    Paul T. Markley a, Alireza Pourreza c, Tait Rounsaville b, Theodor Bughici a,
    Todd H. Skaggs b Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.still.2023.105899
    Get rights and content Highlights • A novel platform for reliable ECa surveys
    in micro-irrigated orchards is presented. • ECa measurements are reliable along
    or near the driplines, where soil is moist. • The developed platform enables accurate
    ECa surveys along or near driplines. • Dry condition of soil in the orchard alleyways
    is optimal for gamma-ray sensing. • Gamma-ray and ECa data fusion was used to
    map soil texture in a micro-irrigated citrus orchard. Abstract On-the-go soil
    apparent electrical conductivity (ECa) sensors are great tools for mapping and
    monitoring soil properties such as water content, texture, and salinity. ECa maps
    and surveys are most useful and reliable when obtained in uniformly wet fields.
    However, soil moisture in micro-irrigated (e.g., drip or micro-sprinklers) orchards
    is typically non-uniform, with moist soil along tree and irrigation lines, and
    dry soil between tree rows. We developed a mobile platform and data post-processing
    algorithm to facilitate geospatial ECa measurements along or near driplines. Gamma-ray
    (γ-ray) spectrometry is commonly used for clay content and type mapping. Fusion
    between ECa and γ-ray is often reported to increase the accuracy of field-scale
    soil maps. However, contrarily to ECa, γ-ray spectrometry is best suited for sensing
    soils in dry conditions. Micro-irrigated orchards are ideal environments for the
    combined application of these two sensor technologies. The fusion of topsoil (top
    0.5 m) ECa (measured along the driplines) and γ-ray total counts (TC) (measured
    between the tree rows) data was tested at a 0.4-ha sandy loam citrus orchard in
    Southern California. Here, we discuss sensor data acquisition, data processing,
    sensor-directed sampling scheme delineation, and characterization of field-scale
    soil particle size fraction (0–0.4 m soil profile) spatial variability. Pearson
    correlation coefficients between sand and silt content with both ECa and TC were
    significant (p < 0.05). A principal component analysis biplot suggested strong
    positive relationship with TC and clay content. Backwards stepwise multiple linear
    regression predicted sand content using TC, elevation, and spatial coordinates
    as explanatory variables with mean absolute error (MAE) of 3.06 %. Silt content
    was predicted (MAE=1.55 %) using ECa, elevation, and spatial coordinates. The
    development of this platform enables better characterization of soil properties
    in micro-irrigated orchard systems using on-the-go sensing technology. Previous
    article in issue Next article in issue Keywords Micro-irrigated soilApparent electrical
    conductivityGamma-raySoil sensingPrecision agriculture 1. Introduction High-resolution
    soil maps generated from near-ground soil sensing can be used to improve agricultural
    management, especially in precision agricultural operations (Viscarra Rossel et
    al., 2011). On-the-go measurements of soil apparent electrical conductivity (ECa),
    either from electrical resistivity (ER) or electromagnetic induction (EMI) instruments,
    are among the most common sensor measurements used in agricultural applications
    (Corwin and Lesch, 2003, Corwin and Lesch, 2005b). Maps of a target soil property
    can be generated from geospatial ECa measurements if a correlation between ECa
    and the soil property can be established via laboratory analyses of ground-truth
    soil samples. As discussed in detail by Corwin and Lesch (2003) and Corwin and
    Lesch (2005b), ECa is influenced by a variety of soil properties, including water
    content, soil-solution electrical conductivity (i.e., soil salinity), porosity,
    temperature, and texture. In the soil, electricity can flow through the liquid,
    the solid, and the solid-liquid pathways (Rhoades et al., 1989). The influence
    of each pathway is determined by soil physical and chemical properties, making
    ECa measurements highly site-specific. According to Archie’s Law (Archie, 1942)
    and similar models (Rhoades et al., 1989, Rhoades et al., 1976), pore-water salinity
    (ECp), soil water content, and other soil-specific parameters all contribute to
    ECa: (1) where ϕ is the soil porosity, S is the relative saturation, and k, m,
    and n are fitting parameters that depend on soil texture, organic carbon content,
    and other physical and chemical properties (Allred et al., 2008, Scudiero et al.,
    2012). In dry soils, the liquid conductance pathways are broken, and consequently,
    a simple, universal calibration of Eq. (1) for a given soil is generally not possible,
    thus limiting the utility of Eq. (1) in practical correlation analysis and soil
    mapping. Lesch and Corwin (2008) argued that linear modeling (linear regression,
    kriging, regression kriging) is often adequate for generating soil maps from geospatial
    ECa measurements without resorting to the parameterization of Eq. (1). For this
    method to be reliable, it is recommended that EMI and ER surveys be conducted
    when the soil water content at the study site is greater than 70 % of field capacity
    throughout the field (Corwin and Lesch, 2003, Corwin and Lesch, 2005b). EMI and
    ER surveys in dry soil can result in ECa data of reduced practical value. For
    example, Pedrera-Parrilla et al. (2016) reported that the ECa correlation with
    clay content was twice as strong when EMI sensor measurements were carried out
    in wet soil conditions as compared to dry conditions. Other geospatial sensor
    data (e.g., visible, near-infrared, gamma-ray spectrometry) were used by researchers
    as stand-alone sensing solutions or for sensor-data fusion with ECa to characterize
    the spatial variability of soil and soil-plant relationships (Castrignanò et al.,
    2012, Corwin and Scudiero, 2019, Li et al., 2019, Scudiero et al., 2013). In particular,
    gamma-ray (γ-ray) spectrometers detect radiation emitted from the soil due to
    naturally occurring radioisotopes of elements such as Potassium, Cesium, Thorium,
    and Uranium. Geospatial γ-ray spectrometry has been used to generate highly accurate
    soil surface texture and clay mineralogy maps (Dierke and Werban, 2013, Heggemann
    et al., 2017, Minty, 1997, Petersen et al., 2012, Priori et al., 2014, Reinhardt
    and Herrmann, 2019, Viscarra-Rossel et al., 2007). The noteworthy paper by Heggemann
    et al. (2017) demonstrates how machine learning (i.e., support vector machines)
    can be used to calibrate γ-ray spectrometry data to highly accurate soil texture
    predictions using calibration data from multiple fields. Although γ-ray is typically
    used to map soil properties in soil surface (typically the first few centimeters),
    under certain conditions (e.g., dry soil with low bulk density), it may be used
    to map soil profiles as deep as 1 m (Reinhardt and Herrmann, 2019). Minty (1997)
    and Reinhardt and Herrmann (2019) reviewed the fundamentals of γ-ray spectrometry.
    Gamma-ray spectrometry is a viable candidate for data fusion with ECa because
    it provides information on soil texture and clay mineralogy, which can help improve
    the understanding of ECa measurements as described in Eq. (1) and discussed by
    Allred et al. (2008), Scudiero et al. (2012), and many other authors. Because
    γ-ray data mostly captures surface soil processes, it cannot be reliably used
    to map subsoil properties. On the other hand, ECa sensors typically provide a
    characterization of topsoil and subsoil simultaneously. Combining ECa data γ-ray
    spectrometry can generate soil maps with superior accuracy than when ECa alone
    is used (Castrignanò et al., 2012, Li et al., 2019). Castrignanò et al. (2012)
    combined EMI-ECa measurements with γ-ray spectrometry to characterize soil texture
    spatial variability at an 80-ha site in Western Australia. The slightly hilly
    site featured a variety of sandy soils and was prone to salinity in low-lying
    areas due to waterlogging. In such a complex site, Castrignanò et al. (2012) found
    that combining ECa and γ-ray spectrometry allowed for characterizing texture with
    higher accuracy than ECa alone. In that study, ECa and γ-ray spectrometry data
    fusion was necessary because salinity, water content, and texture were not collinear.
    Li et al. (2019) observed that the fusion of γ-ray and ECa data was optimal to
    create maps of exchangeable calcium and magnesium (which followed the spatial
    variability of soil classes) in a sugarcane field in Burdekin, Australia, compared
    to the use of a single sensor. Mahnkopp et al. (2018) combined geospatial ECa
    and γ-ray to improve the spatial characterization of apple replant disease (ARD)
    and provide novel insights into the nature of plant-disease-soil interconnections.
    1.1. ECa sensing in micro-irrigated orchards: recent advances, recommended standard
    operation procedures, and industry practices. In many arid and semi-arid regions
    such as California (Taylor and Zilberman, 2017, Tindula et al., 2013), water management
    in recent decades has shifted from flood and sprinkler irrigation towards micro-irrigation
    (e.g., micro-sprinklers, drip or “trickle”). Micro-irrigation is becoming prevalent
    also in orchards in more temperate areas. For example, the majority of pecan orchards
    planted after 2010 in Georgia (a state with a humid subtropical climate), USA,
    are equipped with drip or micro-sprinkler systems (Wells, 2014, Wells, 2017).
    Mapping soil spatial variability in micro-irrigated trees and vines, including
    texture and soil moisture, is often necessary to understand field-scale variability
    in crop yield and quality performance (Mann et al., 2011, Priori et al., 2013,
    Yu et al., 2020, Yu et al., 2021). Moreover, single and repeated (time-lapse)
    measurements of ECa (near the trees) can be used to understand soil-root relationships,
    tree root architecture, and root water uptake (Martínez et al., 2021, Vanella
    et al., 2018). Repeated ECa measurements with Electrical Resistivity Tomography
    along the drip lines were used by Vanella et al. (2022) to identify and monitor
    drip-irrigation wet bulbs and areas with likely clogged drip emitters in an almond
    orchard in California. Recent advances in micro-irrigation systems made site-specific
    (i.e., management-zone-based) irrigation possible (Bali and Culumber, 2018, Sanchez
    et al., 2017). Because of the opportunity to increase water use efficiency with
    site-specific irrigation (Sanchez et al., 2017), growers will likely increasingly
    rely on soil mapping services to characterize soil spatial variability and delineate
    management zones at their micro-irrigated orchards in the near-future. For many
    cropping and irrigation systems (e.g., flood, sprinkler) where ECa surveys are
    common, the variability of water within the soil volume influencing individual
    ECa readings is expected to be essentially one-dimensional, varying only in the
    vertical direction. In micro-irrigated orchards, that is not likely the case,
    even in the vicinity of driplines. Micro-irrigated sites are often characterized
    by large variations in soil moisture over short distances (Bresler, 1978). Water
    infiltration and redistribution around driplines depend on the site-specific irrigation
    system and soil factors, as described in detail by Skaggs et al. (2004, 2010).
    In orchards, where water emitters are generally located along the tree lines,
    the difference in soil water content near the trees and between tree rows can
    be considerable. Corwin and Lesch (2013) provided the first guidelines and protocols
    for ECa surveys and ECa-directed soil sampling for drip-irrigated vineyards and
    other drip-irrigated systems. They showed data from a drip-irrigated vineyard
    in Napa Valley, California, where in-row (i.e., along the driplines) ECa was around
    50 % higher than between-row (between driplines) ECa because of the difference
    in moisture. Corwin and Lesch (2013) recommended both in-row and between-row ECa
    measurement traverses, where ECa-directed soil sampling refers to the methodology
    developed by Corwin and Lesch, 2003, Corwin and Lesch, 2005b for mapping soil
    properties influencing the ECa measurement. In arid areas, between-row soil is
    generally too dry for ECa measurements to be reliably interpreted. In such dry
    conditions, measuring ECa along the driplines where the soil is wet due to irrigation
    is a viable option for obtaining trustworthy soil spatial variability information.
    Alternatively, one could take the in-row and between-row ECa measurements when
    the entire field is at field capacity following a substantial rainfall or series
    of rainfall events, which is, however, difficult to anticipate for ECa-survey
    planning purposes. Furthermore, in water-scarce environments, the most relevant
    ECa measurements with respect to crop yield are those ECa measurements taken where
    water is available to the crop throughout the growing season (i.e., along or near
    the driplines). Unfortunately, especially in orchards with trees with large and
    low canopies (e.g., almond, citrus, pistachio), it is impractical to expeditiously
    and safely measure ECa along or near the driplines with most of the equipment
    solutions currently used by private consultants, farmers, and scientists. Such
    commercially available ECa-sensing platforms are generally towed directly behind
    a field vehicle with collocated geolocation devices (i.e., the GPS receivers located
    above the sensor). Various commonly used ECa on-the-go sensors are discussed by
    many authors (Corwin and Scudiero, 2016, Sudduth et al., 2010). One solution devised
    to map ECa in orchard systems in which the space along the dripline is not easily
    accessible because of low and wide tree canopies is to use small (semi-) autonomous
    robots, such as the robot presented by Campbell et al. (2021). It should also
    be possible to retrofit current commercial systems to measure ECa in otherwise
    inaccessible in-row space, by towing the ECa sensors laterally or slantwise from
    a field vehicle driving between tree rows. In this research, we present such an
    application. An additional hurdle to consider when measuring on-the-go ECa (and
    other soil and plant sensors) is that dense tree canopies obscure satellite signals.
    Because of that, the geolocation accuracy of most GPS and GNSS devices is decreased,
    especially when on-the-go (dynamic) measurements are carried out (Edson and Wing,
    2012). Although methods exist to correct the position of static geolocation measurements
    under tree canopies, such as presented by Naesset and Jonmeister (2002), it is
    very hard to obtain accurate positioning in on-the-go conditions. Min et al. (2008)
    tested the accuracy of six commercially available GPS receivers in dynamic conditions
    in citrus orchards in Florida. Min et al. (2008) concluded that an unobstructed
    sky was the necessary condition to obtain accurate positioning information. Advanced
    positioning systems currently available from several manufacturers are accurate
    to the cm-scale even when placed in proximity to buildings and under trees. Note
    that the reported accuracies for such advanced (and very costly) systems are for
    static positioning applications. When such systems are not available to the soil
    scientist, the GPS/GNSS receiver should be placed away from the canopies of trees.
    The offset between a sensor dragged under tree canopies and the GPS/GNSS system
    placed on top of a field vehicle driving between the tree rows can be calculated
    by analyzing the direction vectors of multiple geospatial records and trigonometry.
    The above reviewed research combining ECa and γ-ray measurements to improve soil
    mapping did not discuss surveys in Mediterranean, semi-arid, arid micro-irrigated
    environments. The naturally dry conditions of soils in these climate are no ideal
    for reliable ECa measurements, but are ideal for γ-ray measurements (Reinhardt
    and Herrmann, 2019). Cook et al.''s (1996) rule of thumb indicates that a 1 %
    increase in volumetric soil moisture results in almost a 1 % reduction in the
    γ-ray emitted by the soil. In micro-irrigated orchards, soil in the alleyways
    is usually not irrigated. Therefore, it is reasonable to expect that fusion of
    ECa measured along the driplines and γ-radiation measured in the alleyway should
    be a good means to accurately characterize soil spatial variability in these agricultural
    systems. The objectives of this research are to i) discuss the need for ECa measurements
    along the tree lines.; ii) describe a platform designed for ECa surveys along
    the driplines in micro-irrigated orchards; and iii) test the developed platform
    for concurrent ECa and γ-ray sensing to characterize spatial variability of soil
    particle size fraction. 2. Materials and methods Data from three field tests at
    two farm operations (Table 1) are presented to i) discuss the need for ECa measurements
    along the tree lines and ii) develop and test the presented soil sensing platform,
    and iii) map soil particle size fraction with the novel ECa platform and γ-ray
    spectrometry. Table 1. Description of the three experimental sites. Field USDA
    Soil Series Soil Order Size (Ha) Location Coordinates Crop Site A (Farm 1) Panoche
    Aridisols 60 Lost Hill, CA, USA Not available* Pistachio Site B (Farm 2) Monserate
    Alfisols 0.06 Riverside, CA, USA 33°58′27.2″N 117°19′09.5″W Fallow Site C (Farm
    2) Monserate Alfisols 0.4 Riverside, CA, USA 33°58′20.5″N; 117°19′08.8″W Navel
    orange * Coordinates not available per request of the orchard owner. 2.1. Soil
    ECa on-the-go measurements in drip-irrigated soil profiles Following protocols
    for ECa-directed soil sampling by Corwin and Lesch (2013), a non-saline 60-ha
    drip-irrigated privately-owned pistachio (Pistacia vera L.) orchard (Site A) near
    Lost Hills, CA, USA (Fig. 1a) was surveyed in December 2012. Tree rows were approximately
    7 m apart. Along the rows, neighboring trees were about 5-m apart. We carried
    out a hand-held EMI survey with the EM38 Dual Dipole (Geonics Ltd., Mississauga,
    Ontario, Canada). The ECa measurements were taken in the horizontal (EMh-ECa)
    and vertical (EMv-ECa) dipole modes to provide ECa over the 0–0.75 and 0–1.5 m
    depth intervals, respectively. This survey was made to compare ECa measurements
    over wet and dry soil conditions analogously to Corwin and Lesch (2013) and Pedrera-Parrilla
    et al. (2016). ECa was surveyed in dry soil between the tree rows (BR) and wet
    soil along the dripline (AD). The two surveys were carried out by hand on two
    consecutive days. ECa was measured at 2051 locations in the BR survey and 1793
    locations in the AD survey. The BR surveys were carried out approximately 3 m
    away from the driplines, which were approximately 0.3 m away from the tree trunks
    (Fig. 1.b). The average distance between neighboring BR points was 7.5 m. The
    AD survey was carried out right next to the dripline. The average distance between
    neighboring AD points was 8.4 m. Two ECa-directed sampling schemes were generated
    using the Response Surface Sampling Design (Lesch, 2005) method consisting of
    12 soil sampling locations per ECa survey (Fig. 1a). Disturbed soil cores were
    sampled in 0.3 m increments down to 1.5 m. Soil samples were analyzed for gravimetric
    water content (WC, g g−1) at the time of sampling and saturation percentage (SP,
    %) following the methodology of Corwin and Yemoto (2017). SP is the ratio of water
    to soil in a saturated paste multiplied by 100 (U.S. Salinity Laboratory Staff,
    1954). SP correlates strongly with soil texture and can be used as a means of
    quantifying soil texture variability (Fulton, 2009, Stiven and Khan, 1966; U.S.
    Salinity Laboratory Staff, 1954). Download : Download high-res image (889KB) Download
    : Download full-size image Fig. 1. a) Site A: pistachio orchard near Lost Hills,
    CA, USA where soil apparent electrical conductivity (ECa) was measured along the
    dripline (AD, square filled black symbols) and between the tree rows (BR, round
    unfilled symbols). Orthophoto obtained from USDA Farm Service Agency. ECa-directed
    soil sampling schemes for the AD and BR surveys are shown as blue and red symbols,
    respectively. A selection of the field is presented at a larger map scale to better
    visualize the different surveys and soil sampling schemes; the schematics (not
    to scale) of the ECa surveys; and c) gravimetric water content and d) saturation
    percentage by depth interval for AD and BR soil cores. 2.2. Mobile platform setup
    and procedures for site-specific adjustments To measure on-the-go soil properties
    over wet soil in micro-irrigated orchards, an all-terrain utility vehicle (model
    2014 Ranger 800EFI 6 ×6; Polaris Industries Inc., Medina, MN, USA) was fitted
    with a multi-sensor and power soil sampling system (Fig. 2). We will refer to
    this unit as the mobile platform. Download : Download high-res image (600KB) Download
    : Download full-size image Fig. 2. The developed mobile platform for on-the-go
    soil characterization in micro-irrigated orchards: a) rear view showing the heavy-duty
    non-conductive sled housing an electromagnetic induction (EMI) sensor; b) picture
    from above the sled depicting the EMI set-up with the CMD Mini Explorer 6 L with
    the CMD-C controller (during operation, the controller is located in the driver
    cabin and connected to the sensor with a 10-m cable), which connects via Bluetooth
    with the Trimble R2 integrated GNSS system (or another geolocation device), located
    on top of the driver’s cabin; and c) front view showing the gamma-ray detector
    placed on a front cargo basket and connected to a spectrometer, laptop, and deep
    cycle battery, which are located in the driver cabin of the all-terrain vehicle.
    The mobile platform consists of: i) a heavy-duty plastic sled (Trek 75; Pelican
    International Inc., Laval, QC, Canada) carrying the CMD Mini Explorer 6 L or ME6L
    (GF Instruments, S.R.O.; Brno, Czech Republic) or the EM38-DD. Other EMI instruments,
    up to 1.9-m long, can also be used with the set-up in Fig. 2. The sled is dragged
    by a rope attached to a retracting hardwood plank that is mounted on the ATV’s
    rear tow-hitch and can be extended laterally (sled offset range 0–4 m away from
    the ATV center) and vertically (0.3–0.6 m above ground); ii) a cargo basket mounted
    on the front hitch of the ATV supports the RSX-1 detector for the RS-701 γ-ray
    spectrometer (Radiation Solutions Inc.; Mississauga, ON, Canada); and iii) a 9100
    ATV power soil sampler (AMS, Inc.; American Falls, ID, USA). In Fig. 2, the ME6L
    is secured with non-static Velcro to a bed of non-static foam inside the plastic
    sled. The ME6L is equipped with six EMI receivers, allowing for simultaneous ECa
    measurement over six depth layers. The sensor can be oriented horizontally (ME6L-EMh)
    or vertically (ME6L-Emv). The nominal depth ranges in the ME6L-Emh configuration
    are: 0.15, 0.25, 0.4, 0.5, 0.8, and 1.1 m. The ranges in the ME6L-Emv configuration
    are: 0.3, 0.5, 0.8, 1.1, 1.6, and 2.3 m. Using a 10-m long 5-pin DIN connector
    cable, the ME6L is connected to the controller and data logging unit (CMD/C) which
    is in the driver cabin during operation. The CMD/C sits in the sled and is connected
    via Bluetooth (2.4 GHz) to an R2 Integrated GNSS System (Trimble, Inc.; Sunnyvale,
    CA, USA) which measures spatial coordinates with a horizontal and vertical maximum
    precision of 0.07 m when using the Trimble CenterPoint RTX (Chen et al., 2011).
    An equivalent set-up is used for the EM38-DD paired with a Trimble Pro-XRT 2 (sub-meter
    geolocation accuracy) for data logging. The Trimble R2 is mounted on the center
    of the roof of the ATV driving cabin to minimize the GNSS signal interference
    from tree canopies. Before analyzing sensor data, it is necessary to correct the
    coordinate offsets that exist between the GNSS antenna and the sensor, which is
    positioned behind and to the side of the antenna, near the tree line. It is relatively
    straightforward to calculate sensor X and Y coordinates from GNSS X and Y coordinates
    given a platform’s fixed sensor offsets and the heading direction of the mobile
    platform at the time of each measurement. The challenge in developing an automated
    data post-processing procedure is that headings are not available, only GNSS coordinates.
    It is therefore necessary to infer the platform heading at each GNSS coordinate,
    which complicates automated data processing considerably. We developed a general-purpose
    Python module for correcting GNSS coordinates for sensor offsets, which is available
    at https://github.com/usda-ars-ussl/sensoff/ and detailed in Appendix A. The RS-701
    γ-ray spectrometer is placed on a wooden board on the passenger seat. The radiometer
    uses an RSX-1 detector (i.e., a four-liter thallium-doped sodium iodide scintillator),
    which is located on a cargo basket in front of the vehicle. A deep-cycle battery
    that powers the RS-701 is also placed in the driver cabin of the ATV. A GPS (the
    RS-701 integrated internal GPS or, e.g., Trimble Pro-XRT 2 with disc antenna)
    receiver placed on top of the ATV cabin and connected to the RS-701 with a SubMiniature
    Version A connector cable. An Ethernet cable connects the RS-701 to a laptop computer
    (Toughbook CF-30, Panasonic corporation, Ltd., Osaka, Japan) in which georeferenced
    γ-ray data are logged with the RadAssist v6.2.3.0 software (Radiation Solutions).
    The 9100 ATV power soil sampler can be used for shallow direct push or for hammering
    (122-N-m hydraulic hammer) soil coring. 2.2.1. Testing (site-specific) optimal
    distance of EMI sensors to ATV Proximity to conductive material influences EMI
    sensor measurements (Corwin and Lesch, 2005b). The minimum lateral distance from
    the ATV needed to obtain unbiased EMI measurements was tested for the EM38-EMv
    in August 2019, and the ME6L-EMv in October 2019, at a bare soil plot (Site B)
    at the University of California Riverside Agricultural Experimental Station (Riverside,
    CA, USA). The US National Cooperative Soil Survey classifies the soil at Site
    B as Monserate sandy loam. For both tests, a 20-m long drip-irrigation line with
    0.30 m emitter spacing was set up on a flat soil surface. The soil was irrigated
    abundantly twice using non-saline water (electrical conductivity ∼ 0.5 dS m−1)
    before each EMI test. Between the two tests, the soil was bare and non-irrigated.
    Approximately 48 h after the last irrigation cycle, EMI measurements were recorded
    at the dripline with the ATV idling at 1.8, 2.1, 2.4, 2.7, 3.0, and at least 10 m
    away (i.e., control) from the sensors. The measurements were replicated at ten
    locations along the dripline. All measurements were taken within 20 min. The experiments
    were carried out in the middle of the day to ensure minimal soil temperature changes.
    The EMI sensors were covered with a blanket to minimize sensor temperature fluctuations
    (Robinson et al., 2004). After the EM38-Emv test was carried out in August 2019,
    the soil was sampled at two locations along the dripline at the 0–0.4, 0.4–0.8,
    and 0.8–1.2 m depths. Laboratory analyses included SP, WC, saturated paste electrical
    conductivity (ECe) and pH (Corwin and Yemoto, 2017), and particle size determination
    using the hydrometer method (Gee and Bauder, 1986). To evaluate differences between
    EMI measurements with and without (i.e., control) the presence of the ATV, a paired
    sample t-test was carried out. Significant (p < 0.05) t-tests are an indication
    of the likely influence of the ATV metal body on the EMI measurements. The paired
    sample t-tests were carried out using Excel 2019′s Data Analysis tools (Microsoft
    Corporation, Redmond, Washington, USA). 2.3. Estimation of particle size fraction
    using ECa and TC To illustrate the use of the mobile platform, a 0.4-ha navel
    orange (Citrus sinensis L.) orchard (Site C) was first surveyed in August 2019.
    Site C (Fig. 3) was less than 200 m away from Site B. Site B and C share the same
    soil type (Monserate sandy loam) according to the US National Cooperative Soil
    Survey. Using the mobile platform, at a speed slower than 5 miles per hour (8 km
    per hour or 2.2 m s−1), γ-ray spectrometry total counts (TC, counts per second
    or cps, ranging from 0.4 to 2.81 MeV) and ECa for the 0–1.5 m soil profile 2 (hereafter
    EMv-ECa, dS m−1), with the EM38 in the vertical mode, were measured at the site.
    Download : Download high-res image (1006KB) Download : Download full-size image
    Fig. 3. Site C: the 0.4-ha navel orange (Citrus sinensis L.) orchard located at
    the University of California, Riverside Agricultural Experimental Station, Riverside,
    California. Subfigure a) shows the recorded and shifted locations of the apparent
    electrical conductivity (ECa) taken with the EM38 sensor in the vertical (EMv)
    mode. Subfigure b) shows the gamma-ray sensor survey, a total count map, and the
    estimated total count values at locations with available EM38 measurements. Subfigure
    c) shows the output of the response surface sampling design (RSSD) delineation.
    Subfigure d) shows box plots comparing minimum, maximum, and 25th, 50th, and 75th
    percentiles for the population (entire survey) and sample (RSSD locations) of
    ECa and gamma-ray total counts. The EM38 sensor was about 2.7 m away from the
    ATV during the survey. The EMv-ECa survey consisted of 244 measurements along
    the irrigation driplines, located under the orange trees. The average distance
    between neighboring ECa measurements was 2.4 m. The GPS recorded coordinates were
    corrected to actual EM38 sensor coordinates (Fig. 3a) following the procedure
    described in section “Appendix A”. The γ-ray spectrometry survey comprised 1563
    measurements. The average distance between neighboring γ-ray measurements was
    0.4 m. On-the-go γ-ray sensor measurements are usually characterized by a high
    signal-to-noise ratio (Minty, 1997, Viscarra-Rossel et al., 2007). Spatial interpolation
    was used to reduce the noise from the γ-ray survey data. The TC data were interpolated
    using simple kriging with the Geostatistical Analyst toolbox in ArcMap 10.5.1
    (ESRI, Redlands, CA, USA). The kriging interpolation was carried out on Normal
    Score transformed data, with a first-order trend removal, based on exponential
    semivariogram models. The semivariogram coefficients (nugget= 36 %, partial sill=
    64 %, and range = 39.2 m) were selected using the Optimize Model tool in Geostatistical
    Analyst. The quality of the interpolation was assessed with leave-one-out cross-validation
    (R2 =0.75). The interpolation was exported to a raster with 2 × 2-m block support.
    TC estimations located with the EMv-ECa measurements were then extracted from
    the TC map. Subsequently, the Response Surface Sampling Design (RSSD) package
    in ESAP (Lesch et al., 2000) was used to identify 20 sampling locations. The RSSD
    package selects sampling sites that best represent the frequency statistics of
    the ancillary geospatial sensor data (i.e., EMv-ECa and TC) and, at the same time,
    spaces the sampling locations as far apart as possible to decrease spatial autocorrelation
    between sampling points. Sensor-directed RSSD strategy is described in detail
    by Lesch et al. (1995) and Lesch (2005). The sampling scheme was evaluated by
    comparing EMv-ECa and TC of the selected locations (i.e., the sample) with the
    entire dataset (i.e., the population) using the Kolmogorov-Smirnov Two-Sample
    Test in STATISTICA (version 12, StatSoft Inc., Tulsa, OK, USA). To demonstrate
    the use of ECa and γ-ray data fusion to create soil maps in micro-irrigated orchards,
    Site C was surveyed again in October 2021 with the ME6L-Emh paired with a Trimble
    R2 GNSS receiver with a Trimble CenterPoint RTX correction. The ECa survey was
    carried out following the recommendations of Corwin and Lesch (2005b). The survey
    was carried out 2 days after an irrigation event. The sled containing the sensor
    was dragged 3.9 m behind and 3.5 m to the right of the GNSS receiver. These measurements
    were used to shift the coordinates measured by the GNSS to the location of the
    ME6L sensor. ECa maps (1 ×1 m resolution) for the six ME6L-Emh layers were generated
    using the default settings for simple kriging in the Geostatistical Analyst toolbox
    in ArcMap 10.5.1. The simple kriging models had low cross-validation (leave-one-out)
    root mean square errors: 0.010 (Layer 1), 0.015 (Layer 2), 0.018 (Layer 3), 0.018
    (Layer 4), 0.019 (Layer 5), 0.017 (Layer 6) dS m−1. On the same day of the ECa
    survey (October 12), soil cores were collected for the 0–0.4 m soil profile at
    the 20 locations identified in August 2019 (Fig. 3.c). The composite 0–0.4-m soil
    samples were dried and sieved at 2 mm and analyzed for particle size fraction
    (sand, silt, and clay contents) using the hydrometer method. The ME6L-Emh measurements
    for the 0–0.15, 0.25, 0.4, and 0.5 m were tested as predictors for soil texture.
    Additional geospatial predictors that were tested were: latitudinal and longitudinal
    WGS84 UTM 11 N projected coordinates, elevation, and the TC measured at the site
    in August 2019. The Pearson correlations between the measured values of sand,
    silt, and clay contents and available geospatial predictors were investigated.
    Principal component analysis (PCA) was performed to visually assess similarities
    and differences between the particle size fraction data and the available geospatial
    predictors (Abdi and Williams, 2010). Subsequently, using a backward stepwise
    procedure, multiple linear regressions to predict sand and silt contents were
    developed according to Lesch and Corwin (2008). In the regressions, TC and ECa
    sensor data and geographical coordinates (i.e., to represent potential spatial
    trends) were used as explanatory variables. The above statistical analyses were
    carried out in STATISTICA. Clay content was estimated as 100 – sand content –
    silt content. 3. Results and discussion 3.1. Water content small scale spatial
    variability in drip-irrigated soil profiles At Site A, the BR survey had average
    EMv-ECa of 0.33 dS m−1 (standard deviation or SD = 0.07 dS m−1) and average EMh-ECa
    of 0.24 dS m−1 (standard deviation or SD = 0.05 dS m−1). The AD survey had average
    EMv-ECa of 0.33 dS m−1 (standard deviation or SD = 0.09 dS m−1) and average EMh-ECa
    of 0.22 dS m−1 (standard deviation or SD = 0.09 dS m−1). Fig. 1.c shows the differences
    in water content, by depth interval, for the BR and AD sampling schemes at the
    pistachio orchard site (Site A). Near the soil surface, water content was greater
    at AD locations than at BR ones. The differences in water content between BR and
    AD locations decreased with increasing depth. As we detail below, saturation percentage
    was very similar through all soil profiles, indicating that the increasing similarity
    in observed WC with depth was not due to contrasting soil texture but to water
    redistribution from the irrigated AD locations toward the BR locations. For the
    BR ECa survey, no significant (p < 0.05) Pearson correlation coefficients (r)
    were observed between WC and EMv-ECa. For EMh-ECa, significant correlations with
    WC were observed only for the 0–0.3 (r = 0.65), 0.3–0.6 (r = 0.72), and 0.9–1.2
    (r = 0.67) m depth increments. For the AD ECa dataset, significant Pearson correlations
    were observed for WC at all depth intervals with both EMh-ECa and EMv-ECa. The
    r values for these relationships averaged 0.80 (minimum = 0.65, maximum = 0.93).
    Saturation percentage values were practically the same at BR and AD locations
    (Fig. 1.d). For the BR-ECa survey, correlations between SP and ECa were mostly
    non-significant. Significant r values were observed for EMv-ECa at 0.9–1.2 (r = 0.61)
    m; and for EMh-ECa at 0.3–0.6 (r = 0.65) and 0.9–1.2 (r = 0.77) m. For the AD-ECa
    significant r were observed between EMv-ECa and SP at 0.3–0.6 (r = 0.59) m; and
    between EMh-ECa and SP at 0–0.3 (r = 0.62) and 0.3–0.6 (r = 0.58) m. Soil moisture
    variability in micro-irrigated orchards can be very dramatic in the short scale
    because of a complex mix of factors (Polak and Wallach, 2001), including, local
    soil properties, irrigation type and wetting regime, and water demand (i.e., potential
    evapotranspiration). Martínez et al. (2021) studied soil moisture variability
    in the proximity of olive trees in southern Spain. They concluded that, because
    of the high short-scale variability in these systems, sensors such as EMI should
    be able to accurately describe the overall moisture levels close to a tree because
    of the sensor’s larger footprint in comparison to in situ fixed sensors such as
    time-domain reflectometry or capacitance sensors. In micro-irrigated almond orchards
    located in California, Vanella et al. (2022) found that the majority of root water
    uptake activity happened in the upper 0.5 m of the soil profile in the areas where
    the soil was wetted by the micro-irrigated systems. This indicates that soil moisture
    should be measured close to the driplines in order to understand soil water dynamics
    in such agricultural systems. It is important to note that such need conflicts,
    however, with operational safety. Indeed injuries (e.g., eye injuries) from contact
    with tree branches and thorns are a serious concern for the agricultural workforce
    (Lacey et al., 2007). 3.2. Mobile platform site-specific setup: determining the
    optimal placement of EMI sensors The soil samples from the test area (Site B)
    were all classified as sandy-loam. The information from the soil sampled at Site
    B is reported in Table 2. Table 2. Sand, silt, clay, and gravimetric water content
    information from the 0–0.4 m soil samples collected at Sites B and C at the Agricultural
    Experimental Station of the University of California, Riverside. Empty Cell Site
    B Empty Cell Site C Empty Cell Soil property (Unit) Average (Standard deviation)
    Average (Standard deviation) Sand (%) 64 (6.5) 58.3 (5.9) Silt (%) 22.2 (4.2)
    30.1 (4.0) Clay (%) 13.8 (3.5) 12.0 (3.2) GWC (g g−1) 0.10 (0.02) 0.09 (0.03)
    The average control ECa for the EM38-EMv was 0.33 dS m−1 (standard deviation =
    0.05 dS m−1). The paired sample t-tests indicated significantly different ECa
    measurements when the ATV was at 1.8, 2.1, and 2.4 m away from the EM38-EMv. The
    average difference in ECa between control and with-ATV measurements in significant
    paired sample t-tests was − 0.04dS m−1. Following the results of this field test,
    the EM38-EMv has been placed at least 2.7 m away from the ATV when operating the
    mobile platform. The average control ECa measurements for the ME6L-EMv were 0.17
    (Layer 1; standard deviation = 0.03 dS m−1), 0.22 (Layer 2; standard deviation
    = 0.02 0 S m−1), 0.27 (Layer 3; standard deviation = 0.03 dS m−1), 0.25 (Layer
    4; standard deviation = 0.02 dS m−1), 0.21 (Layer 5, standard deviation = 0.02
    dS m−1), and 0.18 dS m−1 (Layer 6, standard deviation = 0.02 dS m−1). The paired
    sample t-tests returned non-significant differences for all Layer 1 measurements;
    significant differences for Layers 2, 4, 5, and 6 when the ATV was at or closer
    than 2.7 m from the ME6L-EMv; and significant differences for Layer 3 when the
    ATV was at or closer than 2.4 m from the ME6L-EMv. Subsequent to this field test,
    the ME6L-EMv has been placed at least 3 m away from the ATV when operating the
    mobile platform. It is important to notice that these tests were conducted to
    set up the mobile platform for EM38 and ME6L vertical measurements. With different
    coil configuration and/or different soil types, the results of the tests are likely
    to be different. At any new site, analogous soil tests can be rapidly carried
    out to calculate the optimal distance of the EMI sensor from the ATV. Because
    the sensor offset is likely site-specific, the side arm on the mobile platform
    presented here is retractable (Fig. 2a), allowing for senor-to-vehicle offsets
    up to 4 m. Once the minimum offset distance between the EMI sensor and the field
    vehicle is determined, a decision on EMI sensor placement (i.e., distance from
    the water emitter) and timing of the survey (e.g., hours after irrigation event)
    should be made. This determination may be the case that areas with moist soil
    are easily identifiable via visual inspection and by “feel and appearance of the
    soil” from some exploratory soil cores. Alternatively, if the irrigation schedule
    and rate are known and information about the soil physical properties are available,
    then numerical simulations of wetting dynamics can provide guidance on ECa sensor
    placement and timing of the survey. The distance and timing would depend on several
    factors, including soil type, soil management, irrigation type, scheduling, time
    after an irrigation event, evapotranspiration, and water quality. We repeated
    the methods detailed by Skaggs et al., 2004, Skaggs et al., 2010 with HYDRUS-2D
    to identify soil with moisture exceeding 70 % of field capacity in the 0–0.4 m
    profile. For the soil at our study sites at the Agricultural Experimental Station
    of the University of California, Riverside (Table 2) and with several water application
    scenarios (20–60 liter per meter per irrigation) with subsurface drip, sufficiently
    moist soil was only expected to be at 0.5 m away (or closer) to the dripline.
    After running HYDRUS-2D or similar simulations, the ECa survey operator may add
    the distance of the dripline from the tree (e.g., typically 0.3–0.6 m in many
    applications in California) to the modeling outputs to identify the proper offset
    of the EMI sensor from the tree lines at the University of California, Riverside
    sites. Other commonly used micro-irrigation systems, such as surface drip tape,
    above-ground drip emitter, micro-sprinkler (fanjet) (Gärdenäs et al., 2005) and
    field practices (e.g., raised beds) (Holt et al., 2019) can also be modeled to
    identify the size of the area below the trees with sufficient moisture for reliable
    ECa surveys. It is worth noting that the soil at Site B (and at the other sites
    discussed here) were non saline. Additional considerations on sensor placement
    are in order when conducting EMI surveys in salt-affected micro irrigated orchards.
    Hanson and Bendixen (1995) showed that drip irrigation created a localized wetting
    pattern characterized by both vertical and lateral flows, in which salts were
    transported away from the wetting source and mainly accumulated at the fringe
    of the wetted zone. Berezniak et al. (2018) and Yang et al. (2019) also discussed
    salt distribution in micro-irrigated soils more recently. Characterizing the spatial
    variability of soil salinity and water content in salt-affected micro-irrigated
    systems using EMI is challenging (Burt and Isbell, 2005). Corwin et al. (2022)
    and Bughici et al. (2022) discuss EMI sensor placement and field protocols for
    conducting soil salinity surveys with EMI in micro-irrigated farmland. 3.3. Estimation
    of particle size fraction using ECa and TC Fig. 3 shows the EM38-EMv and γ-ray
    sensor measurements obtained by the mobile platform at the navel orange test site
    (Site C). Fig. 3.a depicts recorded and shifted coordinates for all ECa measurements.
    Soil ECa ranged between 0.31 and 1.44 dS m−1. All values above 0.61 dS m−1 were
    observed in the second row to the west of the orchard. A buried irrigation water
    pipe runs along that tree row, which is likely the reason for the outlying ECa
    measurements. The ECa data for that tree row were removed from further analyses
    (Fig. 3.c), resulting in a dataset ranging between 0.31 and 0.52 dS m−1, with
    average = 0.41 dS m−1, and standard deviation = 0.04 dS m−1. The γ-ray TC measurements
    ranged between 3051.4 and 3780.2 cps, with average = 3447.6 cps and standard deviation
    = 139.5 cps. The TC data were spatially interpolated into a 2 × 2-m grid (Fig.
    3.b) and extracted at the EM38-EMv measurement locations to obtain collocated
    ECa and TC data (Fig. 3.b). The collocated multi-sensor dataset had TC ranging
    between 3217.8 and 3635.8 cps, and averaging 3483.8 cps (standard deviation =
    96.4 cps). The collocated TC and EMv-ECa data (Fig. 3.c) did not show a significant
    Pearson correlation, which was likely an indication that distinct soil spatial
    patterns were being sensed by the two sensors. This was possibly due to the differences
    in depth of investigation between the two sensors: the soil at site C is classified
    by the US National Cooperative Soil Survey in the Monserate series, with topsoil
    (0–0.25 m) in the sandy loam class and subsoil (0.25–0.71 m) in the sandy clay
    loam texture class. The collocated multi-sensor dataset was used to select a subsample
    of 20 locations (Fig. 3.c). These locations had an average ECa of 0.41 dS m−1
    (standard deviation = 0.05 dS m−1) and an average TC of 3477.3 cps (standard deviation
    = 93.5 cps) (Fig. 3.d). The Kolmogorov-Smirnov Two-Sample Test indicated that
    the ECa and TC values from the 20 selected locations were not significantly different
    (p > 0.05) from those of the entire collocated multi-sensor dataset. The particle
    size fraction information from Site C is reported in Table 2. At the 20 soil sampling
    locations, the ECa from the ME6L-EMh measurements for the 0–0.15, 0.25, 0.4, and
    0.5 m had an average (standard deviation) of 0.07 (0.02), 0.11 (0.3), 0.18 (0.3),
    and 0.22 (0.04) dS m−1, respectively. Site C is located on a gentle slope, the
    average elevation at the 20 locations was 351.8 m above average sea level with
    a standard deviation of 1.3 m. The average (standard deviation) Easting was 470,514.7
    (23.5) m and Northing 3,759,139.0 (19.8) m. As reported in Table 3, ECa showed
    a negative correlation with sand content, which is expected based on previously
    reported research and soil ECa theory (Corwin and Lesch, 2005a, Friedman, 2005).
    TC also showed a negative correlation with sand content. Similar relationships
    were reported for soils in Australia (Viscarra-Rossel et al., 2007), Germany (Heggemann
    et al., 2017), and Italy (Priori et al., 2014). Silt showed significant positive
    Pearson correlation coefficients with ECa and TC. Pearson correlation coefficients
    between sensors and other geospatial predictors were non-significant, although
    the biplot (Fig. 4.a) for the PCA on the dataset clustered clay content and TC
    in both Factor 1 (which explained 49.0 % of the dataset variance) and Factor 2
    (which explained 20.2 % of the dataset variance). Table 3. Pearson correlation
    coefficients between measured sand, silt, and clay contents (0–0.4 m soil profile)
    and apparent soil electrical conductivity (ECa) at the 0–0.15, 0.25, 0.4, and
    0.5 m, gamma-ray total counts (TC), elevation, and geographical coordinates. Correlations
    in red and bold front are significant at p < 0.05. Empty Cell Sand Silt Clay ECa-0.15 m
    -0.52 0.53 0.33 ECa-0.25 m -0.54 0.57 0.32 ECa-0.4 m -0.54 0.57 0.32 ECa-0.5 m
    -0.55 0.59 0.32 TC -0.58 0.63 0.33 Elevation -0.07 -0.01 0.09 Easting -0.07 -0.01
    0.09 Northing 0.42 -0.42 -0.30 Download : Download high-res image (273KB) Download
    : Download full-size image Fig. 4. a) The bi-plot of selected variables (soil
    apparent electrical conductivity [ECa] at four depth ranges, gamma-radiation total
    counts [TC], elevation, geographical coordinates, and sand, silt, and clay content)
    on the two larger factors in the principal components analysis for locations sampled
    at Site C. b) the observed vs. estimated relationships for sand, silt, and clay
    contents. Sand content was estimated using Eq. (2). Silt content was estimated
    using Eq. (3). Clay content was estimated as 100 % - sand % - silt %. The use
    of ECa (best prediction was using ECa values for the 0–0.5 m depth) predicted
    sand content with a Coefficient of Determination (R2) = 0.31 and a Mean Absolute
    Error (MAE) = 3.88 % and silt content with R2 = 0.35 and MAE = 2.37 %. Equations
    [2] and [3] show how higher goodness-of-fit was achieved when TC and other geospatial
    predictors were used together in addition to the ECa data. The backward-stepwise
    multiple linear regressions to estimate sand content: (2) employed TC, elevation,
    and easting coordinates as predictors. The regression had R2 = 0.56 and MAE = 3.06
    %. The regression was significant at p < 0.01 and had independent residuals. The
    model to estimate silt content: (3) used ECa for the 0–0.4 and 0–0.5 m layers,
    elevation, and easting and northing coordinates as explanatory variables. The
    regression’s R2 was 0.72 and MAE was 1.55 %. The regression was significant at
    p < 0.01 and had independent residuals. Fig. 4.b shows the observed vs. estimated
    relationships for sand, silt, and clay content. Clay content was estimated as
    100 % - sand % - silt %. The observed vs. predicted clay content relationship
    was not significant, yet it had a fairly low MAE (2.33 %). According to the backward
    stepwise multiple regression approach used in this study, TC was a better predictor
    than ECa for sand content whereas the contrary was true for silt content. The
    use of one sensor measurements over the other (ECa vs. TC) resulted in more accurate
    soil mapping models than if a single sensor was available. Nonetheless, both ECa
    and TC were significantly correlated with sand and silt content. In non-salt-affected
    soils, both TC and ECa are expected to be good predictors for soil texture spatial
    variability. These results indicated that the ECa measurements obtained with the
    proposed mobile platform were accurate. Correlations with deeper soil physical
    properties may not be viable with the γ-ray surface soil measurements, whereas
    they are possible with most ECa sensors, as they have deeper sensing abilities
    (e.g., 0–1.5 m). The benefits of concurrent use of ECa and γ-ray observed in this
    research echoed what was reported by others (Rodrigues et al., 2015). Examples
    and discussion of the use of these on-the-go techniques in orchards are limited
    (Caruso et al., 2022, Mahnkopp et al., 2018), especially when dealing with micro-irrigated
    orchards in arid and semi-arid environments. The results from this study indicate
    that γ-ray may be a useful addition to the more commonly used ECa. However, evaluation
    of this tool in a more comprehensive setting (e.g., over several fields and soil
    types), is needed to comprehensively understand the performance of γ-ray for soil
    mapping (Heggemann et al., 2017, Rodrigues et al., 2015). 4. Conclusions Theoretical
    understanding of ECa measurements, experimental ECa data, and soil wetting patterns
    in non-saline micro-irrigated orchards all indicate that ECa surveys in micro-irrigated
    orchards should be carried out along or near the dripline, where the soil is sufficiently
    moist across the entire sensed soil profile (e.g., 0–1.5 m). On the other hand,
    dry soil is the ideal condition for γ-ray spectrometry. Micro-irrigated orchards
    are, therefore, ideal environments for data fusion from these two sensor technologies.
    The novel mobile multi-sensor platform enables new opportunities to increase our
    understanding of i) geospatial measurements of ECa in soils characterized by high
    short-range variability of water content; ii) the use of ECa to better quantify
    tree-root zone water content; and iii) the potential use of ECa and γ-ray data
    fusion for spatial assessment of water content, texture, and other soil properties.
    Declaration of Competing Interest The authors declare the following financial
    interests/personal relationships which may be considered as potential competing
    interests: Alireza Pourreza reports financial support was provided by California
    Department of Food and Agriculture. Elia Scudiero reports financial support was
    provided by US Department of Agriculture. Acknowledgements This research was supported
    by the California Department of Food and Agriculture’s Specialty Crop Block Grant
    Program project: “Decision Support Tools for Spatiotemporal Integration of Citrus
    Virtual Orchard and Soil Sensing” (Award number #18-0001-030-SC) and USDA NIFA
    AFRI project: “Agricultural Salinity Management via an Integration of Proximal
    and Remote Sensing with Big Geodata Modeling” (Grant Number: 2019-67022-29696).
    The authors are particularly grateful to Abdul-Salam Aderounmu, Wesley Clary,
    Matthew Lesiecki, and Paul Walker for the extremely valuable support in collecting
    field data, and in the development and testing of the mobile sensor platform.
    The mentioning of firm names or trade products does not imply that they are endorsed
    or recommended by the U. S. Department of Agriculture over other firms or similar
    products not mentioned. Appendix A. – Post-processing coordinate-shift algorithm
    The GNSS (or GPS) on an on-the-go platform records its position coordinates (xg,
    yg) each time a sensor reading is taken. When a sensor is offset from the GNSS
    antenna on the on-the-go platform, it is necessary to calculate the corresponding
    sensor position coordinates (xs, ys) for each reading before analyzing sensor
    data. The situation is illustrated in Figs. A1a and A1b, where a sensor is offset
    from the GNSS by a lateral distance A and inline distance B. Download : Download
    high-res image (89KB) Download : Download full-size image Fig. A1. Illustration
    of an on-the-go platform with the sensor offset from the GNSS/GPS antenna by fixed
    lateral and inline distances A and B, respectively . If the platform heading (direction
    of travel in GNSS coordinates) is known at the time of each reading, the sensor
    coordinates can be calculated as: (A1a) (A1b) where , , and α is the platform
    heading expressed as a standard position trigonometric angle relative to the GNSS
    coordinate x-axis, positive counterclockwise, (Figs. A1a,c). The two-argument
    arctan function is a “quadrant aware” computation of , returning β as a standard
    trigonometric angle relative to the positive B-axis, positive counterclockwise,
    (Figs. A1a,b). The challenge in developing an automated data post-processing procedure
    is that the headings are generally not available, only GNSS coordinates. It is
    therefore necessary to infer the platform heading at each GNSS coordinate. We
    developed a general-purpose Python module called “sensoff” for correcting GNSS
    coordinates for sensor offsets. The module is available from the Python Package
    Index (PyPI) repository (https://pypi.org/project/sensoff) and also on github
    (https://github.com/usda-ars-ussl/sensoff). The sensoff code estimates the platform
    heading at each coordinate based on the bearings of the prior and subsequent legs
    of the transect, weighting the two legs according to their relative length. Specifically,
    the heading angle α at the ith GNSS coordinate ( , is estimated as: (A2) where,
    (A3a,b) (A4a,b) (A5a,b) (A6a,b) and where if and otherwise. The latter adjustment
    to ensures the calculated average splits the acute angle formed by the terminal
    sides of the bearing angles and . Note in Eq. (A2) the bearing angles are weighted
    in proportion to the length of the other leg, so shorter legs are given more weight.
    Fig. A2 shows example applications of the sensoff module on synthetic data. Download
    : Download high-res image (150KB) Download : Download full-size image Fig. A2.
    Examples of corrections of GNSS/GPS coordinates for sensor offsets on synthetic
    data for a) different combinations of inline and lateral offsets . Fig. A3 shows
    an application of the sensoff module to GPS coordinates taken from a small survey
    in a micro-irrigated orchard. The inline offset is − 0.5 m and the lateral offset
    is − 1.5 m. The sensoff module can be invoked at the command line or imported
    and used in a python program. The command line invocation for this example is:
    python -m sensoff --ioff − 0.5 --loff − 1.5 --skiprows 1 sensor_survey_GAMMA.csv.
    where “sensor_survey_GAMMA.csv” is a delimited text file containing the GPS coordinates
    and the first row of the file contains column headings (skiprows = 1). The equivalent
    programmatic invocation, along with the survey coordinate data and full code used
    to generate Fig A3, can be found at https://github.com/usda-ars-ussl/sensoff/tree/master/example.
    Download : Download high-res image (248KB) Download : Download full-size image
    Fig. A3. Sensor offset coordinate corrections for a transect survey at a small
    micro-irrigated orchard . Data availability Data will be made available on request.
    References Abdi and Williams, 2010 H. Abdi, L.J. Williams Principal Component
    Analysis 2, Wiley Interdisciplinary Reviews: Computational Statistics (2010),
    pp. 433-459 CrossRefView in ScopusGoogle Scholar Allred et al., 2008 Allred, B.J.,
    Groom, D., Ehsani, M.R., Daniels, J.J., 2008. Resistivity methods, In: Allred,
    B.J., Daniels, J.J., Ehsani, M.R. (Eds.), Handbook of Agricultural Geophysics,
    85–108. Google Scholar Archie, 1942 G.E. Archie The electrical resistivity log
    as an aid in determining some reservoir characteristics Transactions of the American
    Institute of Mining and Metallurgical Engineers, 146 (1942), pp. 54-61 View in
    ScopusGoogle Scholar Bali and Culumber, 2018 K.M. Bali, C. Culumber S. Sea (Ed.),
    Variable Rate Irrigation Practices on Almond, Almond Board of California, Sacramento,
    CA (2018) Google Scholar Berezniak et al., 2018 A. Berezniak, A. Ben-Gal, Y. Mishael,
    U. Nachshon Manipulation of Soil Texture to Remove Salts from a Drip-Irrigated
    Root Zone Vadose Zone Journal, 17 (2018), pp. 1-11 CrossRefGoogle Scholar Bresler,
    1978 E. Bresler Analysis of trickle irrigation with application to design problems
    Irrig. Sci., 1 (1978), pp. 3-17 View in ScopusGoogle Scholar Bughici et al., 2022
    T. Bughici, T.H. Skaggs, D.L. Corwin, E. Scudiero Ensemble HYDRUS-2D modeling
    to improve apparent electrical conductivity sensing of soil salinity under drip
    irrigation Agricultural Water Management, 272 (2022), Article 107813 View PDFView
    articleView in ScopusGoogle Scholar Burt and Isbell, 2005 C. Burt, B. Isbell Leaching
    of accumulated soil salinity under drip irrigation Transactions of the ASAE, 48
    (2005), Article 2115 View in ScopusGoogle Scholar Campbell et al., 2021 Campbell,
    M., Ye, K., Scudiero, E., Karydis, K., 2021. A portable agricultural robot for
    continuous apparent soil electrical conductivity measurements to improve irrigation
    practices, In: Proceedings of the Seventeenth International Conference on Automation
    Science and Engineering (CASE), IEEE, 2228–2234. Google Scholar Caruso et al.,
    2022 G. Caruso, G. Palai, R. Gucci, S. Priori Remote and proximal sensing techniques
    for site-specific irrigation management in the olive orchard Appl. Sci. (2022)
    Google Scholar Castrignanò et al., 2012 A. Castrignanò, M.T.F. Wong, M. Stelluti,
    D. De Benedetto, D. Sollitto Use of EMI, gamma-ray emission and GPS height as
    multi-sensor data for soil characterisation Geoderma, 175–176 (2012), pp. 78-89
    View PDFView articleView in ScopusGoogle Scholar Chen et al., 2011 Chen, X., Allison,
    T., Cao, W., Ferguson, K., Grunig, S., Gomez, V., Kipka, A., Kohler, J., Landau,
    H., Leandro, R., 2011. Trimble RTX, an innovative new approach for network RTK.
    In: Proceedings of the Twenty Fourth International Technical Meeting of the Satellite
    Division of the Institute of Navigation (ION GNSS 2011), 2214–2219. Google Scholar
    Cook et al., 1996 S. Cook, R. Corner, P. Groves, G. Grealish Use of airborne gamma
    radiometric data for soil mapping Soil Res., 34 (1996), pp. 183-194 View in ScopusGoogle
    Scholar Corwin and Lesch, 2003 D.L. Corwin, S.M. Lesch Application of soil electrical
    conductivity to precision agriculture: theory, principles, and guidelines Agron.
    J., 95 (2003), pp. 455-471 View in ScopusGoogle Scholar Corwin and Lesch, 2005a
    D.L. Corwin, S.M. Lesch Apparent soil electrical conductivity measurements in
    agriculture Comput. Electron. Agric., 46 (2005), pp. 11-43 View PDFView articleView
    in ScopusGoogle Scholar Corwin and Lesch, 2005b D.L. Corwin, S.M. Lesch Characterizing
    soil spatial variability with apparent soil electrical conductivity I. Survey
    protocols Comput. Electron. Agric., 46 (2005), pp. 103-133 View PDFView articleView
    in ScopusGoogle Scholar Corwin and Lesch, 2013 D.L. Corwin, S.M. Lesch Protocols
    and guidelines for field-scale measurement of soil salinity distribution with
    ECa-directed soil sampling J. Environ. Eng. Geophys., 18 (2013), pp. 1-25 View
    in ScopusGoogle Scholar Corwin and Scudiero, 2016 D.L. Corwin, E. Scudiero Field-scale
    apparent soil electrical conductivity S. Logsdon (Ed.), Methods of Soil Analysis,
    Soil Science Society of America, Madison, WI, USA (2016) Google Scholar Corwin
    and Yemoto, 2017 D.L. Corwin, K. Yemoto Salinity: electrical conductivity and
    total dissolved solids Methods Soil Anal., 2 (2017) Google Scholar Corwin and
    Scudiero, 2019 D.L. Corwin, E. Scudiero Chapter One - Review of soil salinity
    assessment for agriculture across multiple scales using proximal and/or remote
    sensors D.L. Sparks (Ed.), Advances in Agronomy, Academic Press (2019), pp. 1-130
    View PDFView articleView in ScopusGoogle Scholar Corwin et al., 2022 D.L. Corwin,
    E. Scudiero, D. Zaccaria Modified ECa – ECe protocols for mapping soil salinity
    under micro-irrigation Agricultural Water Management, 269 (2022), Article 107640
    View PDFView articleView in ScopusGoogle Scholar Dierke and Werban, 2013 C. Dierke,
    U. Werban Relationships between gamma-ray data and soil properties at an agricultural
    test site Geoderma, 199 (2013), pp. 90-98 View PDFView articleView in ScopusGoogle
    Scholar Edson and Wing, 2012 C. Edson, M.G. Wing Tree location measurement accuracy
    with a mapping-grade GPS receiver under forest canopy For. Sci., 58 (2012), pp.
    567-576 CrossRefView in ScopusGoogle Scholar Friedman, 2005 S.P. Friedman Soil
    properties influencing apparent electrical conductivity: a review Comput. Electron.
    Agric., 46 (2005), pp. 45-70 View PDFView articleView in ScopusGoogle Scholar
    Fulton, 2009 A. Fulton Interpreting Soil pH and Saturation Percentage Measurements,
    University of California, Agricultural and Natural Resources, Tehama County, Red
    Bluff, CA, USA (2009) Google Scholar Gärdenäs et al., 2005 A.I. Gärdenäs, J.W.
    Hopmans, B.R. Hanson, J. Šimůnek Two-dimensional modeling of nitrate leaching
    for various fertigation scenarios under micro-irrigation Agric. Water Manag.,
    74 (2005), pp. 219-242 View PDFView articleView in ScopusGoogle Scholar Gee and
    Bauder, 1986 G.W. Gee, J.W. Bauder Particle-sizE analysis A. Klute (Ed.), Methods
    of Soil Analysis, Soil Science Society of America, Madison, WI, USA (1986), pp.
    383-411 Google Scholar Hanson and Bendixen, 1995 B.R. Hanson, W.E. Bendixen Drip
    irrigation controls soil salinity under row crops California Agriculture, 49 (1995),
    pp. 19-23 CrossRefGoogle Scholar Heggemann et al., 2017 T. Heggemann, G. Welp,
    W. Amelung, G. Angst, S.O. Franz, S. Koszinski, K. Schmidt, S. Pätzold Proximal
    gamma-ray spectrometry for site-independent in situ prediction of soil texture
    on ten heterogeneous fields in Germany using support vector machines Soil Tillage
    Res., 168 (2017), pp. 99-109 View PDFView articleView in ScopusGoogle Scholar
    Holt et al., 2019 N. Holt, R.P. Sishodia, S. Shukla, K.M. Hansen Improved water
    and economic sustainability with low-input compact bed plasticulture and precision
    irrigation J. Irrig. Drain. Eng., 145 (2019), Article 04019013 View in ScopusGoogle
    Scholar Lacey et al., 2007 E. Lacey, S. S. Forst, L., E. Petrea, R., M. Conroy,
    L Eye injury in migrant farm workers and suggested hazard controls J. Agric. Saf.
    Health, 13 (2007), pp. 259-274 View in ScopusGoogle Scholar Lesch, 2005 S.M. Lesch
    Sensor-directed response surface sampling designs for characterizing spatial variation
    in soil properties Comput. Electron. Agric., 46 (2005), pp. 153-179 View PDFView
    articleView in ScopusGoogle Scholar Lesch and Corwin, 2008 S.M. Lesch, D.L. Corwin
    Prediction of spatial soil property information from ancillary sensor data using
    ordinary linear regression: model derivations, residual assumptions and model
    validation tests Geoderma, 148 (2008), pp. 130-140 View PDFView articleView in
    ScopusGoogle Scholar Lesch et al., 1995 S.M. Lesch, D.J. Strauss, J.D. Rhoades
    Spatial prediction of soil-salinity using electromagnetic induction techniques.2.
    An efficient spatial sampling algorithm suitable for multiple linear-regression
    model identification and estimation Water Resour. Res., 31 (1995), pp. 387-398
    View in ScopusGoogle Scholar Lesch et al., 2000 S.M. Lesch, J.D. Rhoades, D.L.
    Corwin ESAP-95 Version 2.10R: User Manual and Tutorial Guide. USDA-ARS, U.S. Salinity
    Laboratory,, Riverside, CA, USA (2000) Google Scholar Li et al., 2019 N. Li, X.
    Zhao, J. Wang, M. Sefton, J. Triantafilis Digital soil mapping based site-specific
    nutrient management in a sugarcane field in Burdekin Geoderma, 340 (2019), pp.
    38-48 View PDFView articleView in ScopusGoogle Scholar Mahnkopp et al., 2018 F.
    Mahnkopp, M. Simon, E. Lehndorff, S. Pätzold, A. Wrede, T. Winkelmann Induction
    and diagnosis of apple replant disease (ARD): a matter of heterogeneous soil properties?
    Sci. Hortic., 241 (2018), pp. 167-177 View PDFView articleView in ScopusGoogle
    Scholar Mann et al., 2011 K.K. Mann, A.W. Schumann, T.A. Obreza Delineating productivity
    zones in a citrus grove using citrus production, tree growth and temporally sy
    soil data Precis. Agric., 12 (2011), pp. 457-472 CrossRefView in ScopusGoogle
    Scholar Martínez et al., 2021 G. Martínez, A.M. Laguna, J.V. Giráldez, K. Vanderlinden
    Concurrent variability of soil moisture and apparent electrical conductivity in
    the proximity of olive trees Agric. Water Manag., 245 (2021), Article 106652 View
    PDFView articleView in ScopusGoogle Scholar Min et al., 2008 M. Min, R. Ehsani,
    M. Salyani Dynamic accuracy of GPS receivers in citrus orchards Appl. Eng. Agric.,
    24 (2008), pp. 861-868 Google Scholar Minty, 1997 B.R.S. Minty Fundamentals of
    airborne gamma-ray spectrometry AGSO J. Aust. Geol. Geophys., 17 (1997), pp. 39-50
    View in ScopusGoogle Scholar Naesset and Jonmeister, 2002 E. Naesset, T. Jonmeister
    Assessing point accuracy of DGPS under forest canopy before data acquisition,
    in the field and after postprocessing Scand. J. For. Res., 17 (2002), pp. 351-358
    View in ScopusGoogle Scholar Pedrera-Parrilla et al., 2016 A. Pedrera-Parrilla,
    E. Van de Vijver, M. Van Meirvenne, A.J. Espejo-Perez, J.V. Giraldez, K. Vanderlinden
    Apparent electrical conductivity measurements in an olive orchard under wet and
    dry soil conditions: significance for clay and soil water content mapping Precis.
    Agric., 17 (2016), pp. 531-545 CrossRefView in ScopusGoogle Scholar Petersen et
    al., 2012 H. Petersen, T. Wunderlich, S.A. al Hagrey, W. Rabbel Characterization
    of some Middle European soil textures by gamma-spectrometry J. Plant Nutr. Soil
    Sci., 175 (2012), pp. 651-660 CrossRefView in ScopusGoogle Scholar Polak and Wallach,
    2001 A. Polak, R. Wallach Analysis of soil moisture variations in an irrigated
    orchard root zone Plant Soil, 233 (2001), pp. 145-159 View in ScopusGoogle Scholar
    Priori et al., 2014 S. Priori, N. Bianconi, E.A.C. Costantini Can γ-radiometrics
    predict soil textural data and stoniness in different parent materials? A comparison
    of two machine-learning methods Geoderma, 226–227 (2014), pp. 354-364 View PDFView
    articleView in ScopusGoogle Scholar Priori et al., 2013 S. Priori, E. Martini,
    M.C. Andrenelli, S. Magini, A.E. Agnelli, P. Bucelli, M. Biagi, S. Pellegrini,
    E.A.C. Costantini Improving wine quality through harvest zoning and combined use
    of remote and soil proximal sensing Soil Sci. Soc. Am. J., 77 (2013), pp. 1338-1348
    CrossRefView in ScopusGoogle Scholar Reinhardt and Herrmann, 2019 N. Reinhardt,
    L. Herrmann Gamma-ray spectrometry as versatile tool in soil science: a critical
    review J. Plant Nutr. Soil Sci., 182 (2019), pp. 9-27 CrossRefView in ScopusGoogle
    Scholar Rhoades et al., 1976 J.D. Rhoades, P.A.C. Raats, R.J. Prather Effects
    of liquid-phase electrical conductivity, water content, and surface conductivity
    on bulk soil electrical conductivity Soil Sci. Soc. Am. J., 40 (1976), pp. 651-655
    CrossRefGoogle Scholar Rhoades et al., 1989 J.D. Rhoades, N.A. Manteghi, P.J.
    Shouse, W.J. Alves Soil electrical conductivity and soil salinity: new formulations
    and calibrations Soil Sci. Soc. Am. J., 53 (1989), pp. 433-439 CrossRefView in
    ScopusGoogle Scholar Robinson et al., 2004 D.A. Robinson, I. Lebron, S.M. Lesch,
    P. Shouse Minimizing drift in electrical conductivity measurements in high temperature
    environments using the EM-38 Soil Sci. Soc. Am. J., 68 (2004), pp. 339-345 CrossRefView
    in ScopusGoogle Scholar Rodrigues et al., 2015 F.A. Rodrigues, R.G.V. Bramley,
    D.L. Gobbett Proximal soil sensing for precision agriculture: simultaneous use
    of electromagnetic induction and gamma radiometrics in contrasting soils Geoderma,
    243–244 (2015), pp. 183-195 View PDFView articleView in ScopusGoogle Scholar Salinity
    Laboratory Staff, 1954 U.S. Salinity Laboratory Staff USDA Handbook No. 60: Diagnosis
    and Improvement of Saline and Alkali Soils, U.S. Government Printing Office,,
    Washington, DC (1954) Google Scholar Sanchez et al., 2017 L.A. Sanchez, B. Sams,
    M.M. Alsina, N. Hinds, L.J. Klein, N. Dokoozlian Improving vineyard water use
    efficiency and yield with variable rate irrigation in California Adv. Anim. Biosci.,
    8 (2017), pp. 574-577 View PDFView articleGoogle Scholar Scudiero et al., 2012
    E. Scudiero, A. Berti, P. Teatini, F. Morari Simultaneous monitoring of soil water
    content and salinity with a low-cost capacitance-resistance probe Sensors, 12
    (2012), pp. 17588-17607 CrossRefView in ScopusGoogle Scholar Scudiero et al.,
    2013 E. Scudiero, P. Teatini, D.L. Corwin, R. Deiana, A. Berti, F. Morari Delineation
    of site-specific management units in a saline region at the Venice Lagoon margin,
    Italy, using soil reflectance and apparent electrical conductivity Comput. Electron.
    Agric., 99 (2013), pp. 54-64 View PDFView articleView in ScopusGoogle Scholar
    Skaggs et al., 2010 T.H. Skaggs, T.J. Trout, Y. Rothfuss Drip irrigation water
    distribution patterns: effects of emitter rate, pulsing, and antecedent water
    Soil Sci. Soc. Am. J., 74 (2010), pp. 1886-1896 CrossRefView in ScopusGoogle Scholar
    Skaggs et al., 2004 T.H. Skaggs, T.J. Trout, J. Šimůnek, P.J. Shouse Comparison
    of HYDRUS-2D simulations of drip irrigation with experimental observations J.
    Irrig. Drain. Eng., 130 (2004), pp. 304-310 View in ScopusGoogle Scholar Stiven
    and Khan, 1966 G.A. Stiven, M.A. Khan Saturation Percentage as a measure of soil
    texture in the lower Indus Basin J. Soil Sci., 17 (1966), pp. 255-273 CrossRefView
    in ScopusGoogle Scholar Sudduth et al., 2010 K.A. Sudduth, N.R. Kitchen, D.B.
    Myers, S.T. Drummond Mapping depth to argillic soil horizons using apparent electrical
    conductivity J. Environ. Eng. Geophys., 15 (2010), pp. 135-146 View in ScopusGoogle
    Scholar Taylor and Zilberman, 2017 R. Taylor, D. Zilberman Diffusion of drip irrigation:
    the case of California Appl. Econ. Perspect. Policy, 39 (2017), pp. 16-40 CrossRefView
    in ScopusGoogle Scholar Tindula et al., 2013 G.N. Tindula, M.N. Orang, R.L. Snyder
    Survey of irrigation methods in California in 2010 J. Irrig. Drain. Eng., 139
    (2013), pp. 233-238 View in ScopusGoogle Scholar Vanella et al., 2022 D. Vanella,
    S.R. Peddinti, I. Kisekka Unravelling soil water dynamics in almond orchards characterized
    by soil-heterogeneity using electrical resistivity tomography Agric. Water Manag.,
    269 (2022), Article 107652 View PDFView articleView in ScopusGoogle Scholar Vanella
    et al., 2018 D. Vanella, G. Cassiani, L. Busato, J. Boaga, S. Barbagallo, A. Binley,
    S. Consoli Use of small scale electrical resistivity tomography to identify soil-root
    interactions during deficit irrigation J. Hydrol., 556 (2018), pp. 310-324 View
    PDFView articleView in ScopusGoogle Scholar Viscarra Rossel et al., 2011 R.A.
    Viscarra Rossel, V.I. Adamchuk, K.A. Sudduth, N.J. McKenzie, C. Lobsey Chapter
    five - proximal soil sensing: an effective approach for soil measurements in space
    and time D.L. Sparks (Ed.), Advances in Agronomy, Academic Press (2011), pp. 243-291
    View PDFView articleView in ScopusGoogle Scholar Viscarra-Rossel et al., 2007
    R.A. Viscarra-Rossel, H.J. Taylor, A.B. McBratney Multivariate calibration of
    hyperspectral γ‐ray energy spectra for proximal soil sensing Eur. J. Soil Sci.,
    58 (2007), pp. 343-353 CrossRefGoogle Scholar Wells, 2017 L. Wells Response of
    young Pecan trees to irrigation in a humid climate HortScience Horts, 52 (2017),
    p. 457 View in ScopusGoogle Scholar Wells, 2014 M.L. Wells Pecan planting trends
    in Georgia HortTechnology, 24 (2014), pp. 475-479 CrossRefView in ScopusGoogle
    Scholar Yang et al., 2019 T. Yang, J. Šimůnek, M. Mo, B. McCullough-Sanden, H.
    Shahrokhnia, S. Cherchian, L. Wu Assessing salinity leaching efficiency in three
    soils by the HYDRUS-1D and -2D simulations Soil and Tillage Research, 194 (2019),
    Article 104342 View PDFView articleView in ScopusGoogle Scholar Yu et al., 2020
    R. Yu, L. Brillante, J. Martínez-Lüscher, S.K. Kurtural Spatial variability of
    soil and plant water status and their cascading effects on grapevine physiology
    are linked to berry and wine chemistry Front. Plant Sci., 11 (2020) Google Scholar
    Yu et al., 2021 R. Yu, L. Brillante, N. Torres, S.K. Kurtural Proximal sensing
    of vineyard soil and canopy vegetation for determining vineyard spatial variability
    in plant physiology and berry chemistry OENO One, 55 (2021), pp. 315-333 CrossRefView
    in ScopusGoogle Scholar Cited by (0) View Abstract © 2023 Elsevier B.V. All rights
    reserved. Recommended articles Roots are the key for soil C restoration: A comparison
    of land management in the semiarid Argentinean Pampa Soil and Tillage Research,
    Volume 235, 2024, Article 105918 Ileana Frasier, …, Silvina Vargas-Gil View PDF
    Ammonia volatilization measured with the IHF method in a rainfed arable crop:
    Evaluation of tillage intensity and the number of experimental replicates Soil
    and Tillage Research, Volume 235, 2024, Article 105892 Guillermo Guardia, …, Antonio
    Vallejo View PDF Effect of filling materials on reconstructed soil phosphorus
    adsorption and desorption in mining area Soil and Tillage Research, Volume 235,
    2024, Article 105895 Kexin Jing, …, Xinju Li View PDF Show 3 more articles Article
    Metrics Captures Readers: 5 View details About ScienceDirect Remote access Shopping
    cart Advertise Contact and support Terms and conditions Privacy policy Cookies
    are used by this site. Cookie settings | Your Privacy Choices All content on this
    site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights
    are reserved, including those for text and data mining, AI training, and similar
    technologies. For all open access content, the Creative Commons licensing terms
    apply."'
  inline_citation: '>'
  journal: Soil and Tillage Research
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A system for concurrent on-the-go soil apparent electrical conductivity and
    gamma-ray sensing in micro-irrigated orchards
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Sassu A.
  - Motta J.
  - Deidda A.
  - Ghiani L.
  - Carlevaro A.
  - Garibotto G.
  - Gambella F.
  citation_count: '1'
  description: Input optimization is a distinguishing characteristic of Precision
    Agriculture approaches, helping reduce the environmental impact and costs and
    increase vegetable production quality. Thanks to the high automation evolution
    of Unmanned Aerial Systems (UAS), a new approach derived from their combination
    with Deep Learning techniques is leading to significant improvements in agricultural
    management practices. The study aims at artichoke plants detection and georeferencing
    as a first step for an on-the-fly, real time, UAS spraying system, and use the
    gathered information to monitor crop development through a multi-temporal approach.
    A commercial UAS, equipped with an RGB sensor, acquired images of the artichoke
    field located in Sardinia (Italy) during the 2021–2022 season in different crop
    growth stages. The FPN (Feature Pyramid Network), trained and compared with the
    YOLOv5 (You Only Look Once) network, showed a high detection level with an average
    F1 score of around 90%, and satisfactory off-line performances on the Nvidia Jetson
    Nano board. YOLOv5 achieved the best overall result. The FPN recorded a lower
    recall, which is desirable to achieve a minimum number of detection errors and
    limit the leakage of agrochemicals on false-positive targets. The multi-temporal
    approach influenced detection performances, with an inverse response of precision
    and recall metrics. The growing index trend showed a distinct value in October,
    peaking at the beginning of December as expected. The proposed approach contributes
    to designing future automatic and reliable site-specific UAS agrochemicals application
    and the classification of management zones.
  doi: 10.1016/j.compag.2023.108185
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Materials and methods
    3. Results 4. Discussions 5. Conclusions CRediT authorship contribution statement
    Declaration of Competing Interest Acknowledgement Data availability References
    Show full outline Cited by (1) Figures (13) Show 7 more figures Tables (9) Table
    1 Table 2 Table 3 Table 4 Table 5 Table 6 Show all tables Computers and Electronics
    in Agriculture Volume 213, October 2023, 108185 Artichoke deep learning detection
    network for site-specific agrochemicals UAS spraying Author links open overlay
    panel Alberto Sassu a, Jacopo Motta b, Alessandro Deidda a, Luca Ghiani a, Alberto
    Carlevaro b c, Giovanni Garibotto b, Filippo Gambella a d Show more Add to Mendeley
    Share Cite https://doi.org/10.1016/j.compag.2023.108185 Get rights and content
    Under a Creative Commons license open access Highlights • Development of a machine
    learning approach for artichoke plant detection intended for real-time UAS spraying
    applications. • Creation of an automatic multi-temporal tracking procedure for
    crop monitoring and UAS path planning development. • Optimization of agrochemicals
    distribution operation from UAS. • Detection performances comparison between the
    Feature Pyramid and YOLOv5 SSD networks for plant detection. Abstract Input optimization
    is a distinguishing characteristic of Precision Agriculture approaches, helping
    reduce the environmental impact and costs and increase vegetable production quality.
    Thanks to the high automation evolution of Unmanned Aerial Systems (UAS), a new
    approach derived from their combination with Deep Learning techniques is leading
    to significant improvements in agricultural management practices. The study aims
    at artichoke plants detection and georeferencing as a first step for an on-the-fly,
    real time, UAS spraying system, and use the gathered information to monitor crop
    development through a multi-temporal approach. A commercial UAS, equipped with
    an RGB sensor, acquired images of the artichoke field located in Sardinia (Italy)
    during the 2021–2022 season in different crop growth stages. The FPN (Feature
    Pyramid Network), trained and compared with the YOLOv5 (You Only Look Once) network,
    showed a high detection level with an average F1 score of around 90%, and satisfactory
    off-line performances on the Nvidia Jetson Nano board. YOLOv5 achieved the best
    overall result. The FPN recorded a lower recall, which is desirable to achieve
    a minimum number of detection errors and limit the leakage of agrochemicals on
    false-positive targets. The multi-temporal approach influenced detection performances,
    with an inverse response of precision and recall metrics. The growing index trend
    showed a distinct value in October, peaking at the beginning of December as expected.
    The proposed approach contributes to designing future automatic and reliable site-specific
    UAS agrochemicals application and the classification of management zones. Previous
    article in issue Next article in issue Keywords Single shot detectorMulti-target
    object detectionMulti-temporal monitoringPlant detectionSite-specific managementPrecision
    agriculture 1. Introduction Food sustainability and consumer protection are relevant
    issues today, as demonstrated by growing consumer interest in vegetable production
    and distribution on the market (Kriflik and Yeatman, 2005). Because of the increasing
    food demands and the high impact of plant diseases on the global annual yield
    losses, chemical input in agriculture is still mandatory to protect crops against
    insects, pests, and fungi (Iriti and Vitalini, 2020). Agrochemical distribution
    is a dangerous operation with a high impact on consumers'' safety and the environment.
    Often misapplied with considerable risks for consumers, agrochemical residues
    can be found in food, feed, water bodies, and non-target organisms (Chavarri et
    al., 2004). Conventional spraying mechanization, deployed by ground machinery,
    is essential to reduce human and environmental harm and labor intensity. However,
    more effective and efficient application techniques are required to reduce the
    environmental impact of agrochemicals (Van den Berg et al., 2020). Agricultural
    aerial spraying by airplanes and helicopters, often considered an economical and
    rapid method for agrochemical application, is known for covering large fields
    without any physical impact on crops or soil structure and causing high product
    overdose and losses due to poor distribution accuracy (Popp et al., 2013). Agrochemicals
    are considered toxic products that affect the safety of food and ecosystems. The
    resulting concerns are reflected in policy initiatives, legislative regulations,
    and the growing demand for environmentally compatible management methods. Innovative
    smart variable-dose sprayers development for agrochemical dosage will bring a
    significant contribution, leading to economic and environmental benefits crucial
    for their implementation. Such operations, combined with decision support systems
    (DSS), should support farmers in applying control treatments, avoiding product
    waste and total energy demand, acting at the most appropriate time and place,
    and helping to reduce labor costs (De Bortoli et al., 2022). In particular, the
    application of site-specific herbicides can help reduce costs by 50 percent (GERHARDS
    and OEBEL, 2006). However, the high cost of precision spraying technology and
    the associated complexity of these systems result in farmers opting for chemical
    control (Gerhards et al., 2022). Unmanned aerial systems (UAS), as well as allowing
    the acquisition of images and data from a different perspective, have recently
    gained attention for pesticide spraying operations (Lan et al., 2017). They can
    follow complex patterns, fly at low altitudes, adapt to different terrains, perform
    vertical take-offs and landings, and perform low-volume and site-specific agrochemical
    applications with low risks for operators'' health (Sarri et al., 2019). Despite
    regulations and restrictions on aerial agrochemicals spraying, as is in Europe
    (European Parliament, 2009), multi-rotor UASs are under study for spraying applications
    worldwide, and they are the best candidates to replace conventional aerial vehicles.
    The globe artichoke Cynara cardunculus L. var. scolymus Fiori, also known as Spinoso
    Sardo, is a Mediterranean native crop diffused in Sardinian Island (Italy) that
    strongly contributes to the agricultural economy of the region (Fadda et al.,
    2020, Spanu et al., 2018). Artichoke plants are attacked by several insects and
    pests like aphids, thrips, leaf miners, etc., which require agrochemicals application,
    easily deployable through UASs (Tabikha and Draz, 2022). UAS spraying operations
    planning, performed by defining target area borders, flight height Above Ground
    Level (AGL), speed, spray width, flow rate, etc., is easily applicable to cover
    crops like rice, corn, and wheat, but not to horticultural crops like artichoke.
    Site-specific spraying distribution, essential to reduce the amount of chemical
    product released on the soil surface, requires the coordinate references of each
    plant, obtainable by using an RTK GNSS station or indirectly by UAS images (Xue
    et al., 2016). A fast and real-time approach is crucial to optimize UAS spraying
    operations, reduce the overall operation time, and execute accurate distributions
    over target plants. In this scenario, the Deep Learning approach represents a
    valid and effective solution for real-time recognition and the consequent execution
    of a task (Kamilaris and Prenafeta-Boldú, 2018). Previous work has been carried
    out on the combination of UAS spraying technique and deep learning object detection
    in agricultural scenarios for an accurate real-time recognition system for spraying
    areas (Khan et al., 2021) or to determine pests'' position in real-time on the
    orchard and plan the optimal pesticide spraying route for the agricultural UAS
    (Chen et al., 2021). The Feature Pyramid Network (FPN) is a particular type of
    CNN but the algorithm proposed in this paper is a customized version that works
    as a Singles Shot Detector (SSD) (Liu et al., 2016). A CNN backbone is used to
    extract the informative features that will be used by the classical FPN for detection.
    These types of algorithms work in a single forward pass of the network, locating
    and classifying objects at the same time. The basic concepts of these networks
    imply the use of a grid that divides the image into cells responsible for detecting
    objects in that region of the image and the use of priors and predefined boxes
    responsible for detecting objects of specific sizes and shapes within a grid cell.
    In the FPN, it is possible to recall that the main structure of the architecture
    is composed of a bottom-up pathway for feature extraction and a top-down path
    for position detection on the image. The combination of these two phases allows
    the network to detect objects of different scales with a good level of location
    precision in rapid training times. In this work, the FPN performance was compared
    to a well know network, the YOLOv5. YOLO (You Only Look Once) is an algorithm
    for object detection developed in 2016 (Redmon et al., 2015) based on regression:
    instead of selecting the part of the interest of an image, it predicts classes
    and bounding boxes in one run of the algorithm (for this, Once), so it belongs
    to the SSDs class as the custom FPN explained before. YOLOv5 is about 88% smaller
    than YOLOv4 (27 MB vs. 244 MB), 180% faster than YOLOv4 (140 FPS vs. 50 FPS),
    and it is roughly as accurate as YOLOv4 on the same task (0.895 mAP vs. 0.892
    mAP). The main problem is that there is no official document for the YOLOv5 version,
    except the concept paper of YOLOv4 (Bochkovskiy et al., 2020) and references therein.
    Deep learning based networks are generally applied in agricultural scenarios for
    counting and detecting plants and plantation rows, crucial for plant health monitoring
    or plantation gaps identification after the seedling process (Osco et al., 2021).
    Multi-temporal UAS imagery incorporation could significantly boost the accuracy
    and compensate for the low spectral resolution of RGB imagery (Feng et al., 2020).
    Such approach could be applied to different crops for plant counting, crop health
    monitoring, yield estimation, and to plan optimized fertilizer, pesticide, and
    other input distribution within farm management (Aeberli et al., 2021). The work
    aims at developing a machine learning approach based on FPN for artichoke plant
    detection intended for real-time UAS spraying applications and an automatic multi-temporal
    procedure for crop monitoring and UAS path planning development. In addition,
    to obtain a reliable model that can adapt to real-world applications and agricultural
    needs, the custom network was compared to the state-of-the-art YOLOv5 model. 2.
    Materials and methods 2.1. Study site and survey date Experiments took place in
    an Artichoke cultivation (cv. Spinoso sardo) on a 3000 m2 surface in Uri (the
    area surveyed by the UAS was 4586 m2 to include the field borders and avoid orthomosaics’
    distortion because of the reduced amount of images of that area), North-west Sardinia,
    Italy (Long. 8.472029, Lat. 40.623619; WGS84, EPSG 4326) at 125 m above sea level.
    Fig. 1 shows an overall view of the artichoke field object of the study planted
    on 15 July 2021. Download : Download high-res image (306KB) Download : Download
    full-size image Fig. 1. The artichoke field object of the study (a) and the study
    site location represented by the red dot within Italy mainland in gray color and
    specifically in Sardinia region in blue color (b). (For interpretation of the
    references to color in this figure legend, the reader is referred to the web version
    of this article.) The surveys were performed following the phenological development
    of the culture with two weeks frequency in the first part of the growth and one
    month in the last phases, for a total of seven days (Table 1, Table 2). Table
    1. UAS’s flight settings and dataset’s details. Flight settings Dataset details
    flight route length (m) 667 survey dates (n) 7 flight height AGL (m) 15 photos
    (n/date) 232 flight time (min.sec) 10.21 total dataset photos (n) 1624 course
    angle (°) 51 sensor model DJI Phantom 4 Pro RGB CMOS 1″ take-off speed (m/s) 55
    FOV (°) 84 flight speed (m/s) 59 lens’s focal length (mm) 8.8/24 area (m2) 4586
    image width (px) 5472 side overlap ratio (%) 70 image height (px) 3648 frontal
    overlap ratio (%) 80 GSD (cm/px) 0.41 Table 2. Performance measure of the FPN
    Detection at each individual date of the test. Date BBCH1 TP FP FN Precision Recall
    F1score SR SP 7 Sept 14 474 11 72 0.97 0.86 0.91 0.87 0,95 14 Sept 16 533 22 53
    0.96 0.91 0.93 0.91 0,96 1 Oct 35 541 39 66 0.93 0.89 0.91 0.90 0,98 15 Oct 47
    544 18 57 0.96 0.90 0.93 0.94 0,96 9 Nov 51 460 32 141 0.93 0.76 0.84 0.90 0,98
    3 Dec 55 450 73 125 0.86 0.78 0.82 0.92 0,98 23 Dec 59 509 71 95 0.87 0.84 0.86
    0.92 0,98 1 BBCH stages derived by (Archontoulis et al., 2010). 2.2. UAS platform
    and implemented sensors Remote image acquisitions were performed by a DJI Phantom
    4 Pro (DJI, Shenzhen, China) UAS equipped with RGB CMOS 1″ sensor of 21 megapixels
    resolution, Field of View (FOV) 84 degrees, 8.8 mm/24 mm (35 mm format equivalent),
    f/2.8-f/11 autofocus 1 m to ∞. A RTK GNSS Reach RS+ (Emlid, Budapest, Hungary)
    connected to a NTRIP correction system was used to record the geographic coordinates
    of 12 Ground Control Points (GCPs), to obtain high accuracy orthomosaics and perform
    the temporal monitoring process described in the next chapters. 2.3. UAS images
    acquisition campaign During the 2021–2022 season, several images of the artichoke
    field in different growth stages were acquired by the DJI Phantom 4 Pro RGB sensor
    in nadiral position (perpendicular to the ground). Automatic flights were performed
    using the android based DJI pilot app, able to guarantee the execution of standardized
    photos and videos acquisition by following a constant path at a specific height
    above ground level (AGL). All flights for the orthomosaics creation were performed
    at 15 m height AGL to obtain high quality images (232 photos for each flight).
    The speed was one m/s, the flight duration was 10 min 21 s, 70% side overlap ratio
    and 80% frontal overlap ratio, the ground sampling distance (GSD) was 0.41 cm/px.
    A flight of 80 m was performed to test the networks performances on a previous
    flight of the entire field. The weather conditions were generally sunny and with
    clear sky; different lighting conditions in the photo-set were mainly due to the
    changing inclination of the incident radiation during the growing season. Table
    1 summarizes the flight settings and the dataset’s details. 2.4. Deep learning
    plant detection Nowadays, it is increasingly easy to find predefined neural networks
    suitable for addressing various deep learning tasks, especially in object detection
    (Kang et al., 2022). However, the ability to build, train and test a custom neural
    network allows to better adapt the algorithm to the problem faced, giving more
    significance to the scientific work. With this aim, this section of the paper
    is devoted to explaining the network structure used in the detection phase, namely
    a custom FPN (Lin et al., 2017). In the state of the art, there is a wide range
    of possible detection networks (Jiao et al., 2019), each of which has its own
    strengths depending on the problem to be addressed. In our application scenario,
    which involves the use of a UAS capable of flying at different heights, the choice
    of the network had to consider its ability to detect objects at different scales.
    This is a peculiarity of FPN and the main reason this network was implemented
    for this work. The organization of the implementation (Fig. 2) of the object detector
    were made according to the following scheme: • Data preprocessing • Network building
    • Network training – FPN training – YOLOv5 training • Network testing and performance
    evaluation • Offline detection Download : Download high-res image (497KB) Download
    : Download full-size image Fig. 2. The deep learning plant detection flowchart
    (left gray color column) and the partial output of each step (right blue color
    column). (For interpretation of the references to color in this figure legend,
    the reader is referred to the web version of this article.) Where “offline detection”
    refers to the application of the trained model on a real scenario (i.e., on video
    and images collected by the UAS of the test area) but not in real-time. 2.4.1.
    Data processing The preprocessing phase was common to both networks. Once the
    UAS acquisition phase was carried out, the images collected during the flight
    were merged to form a single orthorectified and high-resolution image called orthomosaic
    (Fig. 3). The orthomosaics construction was made using OpenDroneMap, an application
    and API for UASs image processing capable of constructing an orthomosaics from
    a group of individual georeferenced images. Download : Download high-res image
    (2MB) Download : Download full-size image Fig. 3. RGB orthomosaics (left column)
    and some artichoke plants details (right column) derived by 15 m flight altitude
    of three different surveying dates: 7 September 2021 (a), 15 October 2021 (b),
    and 23 November 2021 (c). Seven orthomosaics corresponding to UAS flights in the
    months between September and December 2021 were generated, and an image dataset
    was extracted from each of them for the network training. After an initial phase
    of manual labeling performed using the software VGG Image Annotator (VIA) to obtain
    the ground truth of the data, the dataset generation was performed by randomly
    cropping orthomosaics and applying data-augmentation algorithms (rotation, blurring,
    saturation, etc.) to the obtained images to produce representative samples. The
    resulting dataset was then divided into training and test sets and provided as
    input to the detection network. 2.4.2. FPN building As far as the implementation
    of the network is concerned, the input parameters are as follow: • Grid Sizes:
    (4 × 4, 8 × 8, 16 × 16) px2 • Priors Sizes: (1 × 1, 16 × 9, 9 × 16) px2 • Input
    Size: (512 × 512) px2 • Total parameters: 2.8 M. Where px refers to one pixel
    size (0.5 cm). Regarding the specifics of Python, 3.10.5 opencv-python 3.4.11.43,
    NumPy 1.21.2, SciPy 1.21.2, and matplotlib 3.4.3 were used. The approach is totally
    in the spirit of Meng et al., 2022, where FPN was used to improve the information
    power of feature extraction. Specifically, the proposed network (Fig. 4) consists
    of a convolutional backbone to extract the essential features, then the FPN structure
    is used as a neck to enhance the information and extract the features at different
    scales, and finally the outputs (boxiness and box coordinates) are extracted as
    usual with softmax and a final convolutional layer. Download : Download high-res
    image (192KB) Download : Download full-size image Fig. 4. The proposed classification
    analysis process network flow diagram. 2.4.3. FPN training The FPN network model
    has been trained from scratch, by designing and customizing all input parameters.
    This means that the network was initialized with random weights and biases, and
    then trained on a subset of the dataset of artichoke images, constructed in the
    preprocessing phase by dividing them into training and testing sets with a proportion
    of 70% and 30% respectively. The test set was used to get initial feedback on
    the network detection performance before applying the model for offline detection,
    as further explained in section 2.4.6. Recalling that the Location loss is the
    mismatch between the ground truth box and the predicted boundary box and that
    the Boxiness loss measures how confident the network is of the objectness of the
    computed bounding box, the specific training inputs, common to all the trainings,
    are as follows: • Loss Function: Boxiness loss + Location loss. • IoU: 50% • Batch
    Size: 8 • Learning Rate: 1e-4 • Optimizer: Adam Where IoU is the usual acronym
    for the Intersection over Union rate. IoU is used to evaluate the object detection
    performance and consists of the percentage of the ground truth bounding box covered
    by the prediction bounding box. By varying the dataset, the training time and
    the number of epochs are affected. Each new orthomosaic was merged with the training
    dataset. Therefore, the results obtained on the last dataset are the most complete,
    the dataset having consisted of all previous orthomosaics. Generally, each network
    was trained for about 72–80 h to obtain satisfactory results. 2.4.4. YOLOv5 training
    Transfer learning has been used to train the YOLOv5n network, the smallest version
    of YOLOv5. A pre-trained YOLOv5n model, which had already been trained on a large
    dataset of images (80 classes), was fine-tuned and re-trained on a dataset of
    artichoke images. Specifically, the backbone of the YOLOv5 network was used, which
    consists of the convolutional layers responsible of feature extractions and froze
    these layers. Only the last few layers of the network were trained, which are
    responsible for making object detections, on the artichoke dataset. In general,
    nano models maintain the YOLOv5 depth multiple of 0.33 but reduce the YOLOv5 width
    multiple from 0.50 to 0.25, resulting in about 25% fewer parameters, from 7.5
    M to 1.9 M, ideal for mobile and CPU solutions. The training phase included a
    preprocessing phase in which data-images were obtained from the cropped orthomosaics
    of the various UAS flights (from September to December 2021) and then provided
    to the network for training. The training included 2000 epochs and the batch dimension
    was 8. 2.4.5. Network performance testing and evaluation For both networks, before
    applying the model for offline detection, a test was performed for each training
    phase to evaluate the network performance and to maximize the networks’ detection
    capabilities. As already pointed out, in the training phase of the network 30%
    of the datasets were used to test the network, extracting the measures of mAP,
    recall, precision and F1 score that are the usual metrics adopted for the evaluation
    of a machine learning model (Padilla et al., 2020): (1) (2) (3) (4) (5) Where,
    as usual, TP, FP, and FN indicate the number of true positive (intended as the
    correctly detected artichoke plants), false positive (weeds or other objects incorrectly
    detected as artichokes), and false negative (the undetected artichoke plants)
    respectively. Recall (sometimes called sensitivity) is a measure of the detection
    efficiency of the network to minimize the number of missed objects. Precision
    is a measure of the network accuracy to achieve the minimum number of detection
    error. F1 score is the weighted average of Recall and Precision including both
    false positives and false negatives. To effectively analyze the detection results,
    it is appropriate to dwell on the fact that the target application (UAS sprayer)
    has two main objectives: maximizing the number of plants to be sprayed and minimizing
    fertilizer waste (on the ground or on weeds). Unfortunately, the classical indexes
    (precision and recall) are only based on the number of object-box intersections,
    irrespective of the actual shape and size of the plants. For this purpose, two
    additional indexes were introduced, namely SR (Surface-Recall) and SP (Surface-Precision),
    defined in equation (4) and (5), where GT_Area (px) corresponds to the number
    of image-pixels covered by the ground-Truth-boxes (any pixel overlap is counted
    only once). DET_Area (px) corresponds to the number of the image-pixels covered
    by the detected-boxes and Matched_Area (px) is the number of image-pixels where
    both GT-boxes and DET-boxes overlap each other. In some way they simulate the
    behaviour of the UAS-Sprayer, by predicting the expected performance of a real-time
    implementation. At first, network parameters have been optimized to achieve the
    best possible results in the detection process. Afterwards, the designed network
    configurations have been applied to off-line multi-temporal monitoring and analysis.
    2.4.6. Offline detection The step prior to the application of the model in a real-time
    scenario is the evaluation of its offline behavior, since both offline processing
    and real-time application are dealing with the same videos and image data, whether
    they have been collected and stored beforehand or transmitted directly from a
    camera. In particular, the Nvidia Jetson Nano board (Santa Clara, California,
    USA) was selected, a small and powerful computer for embedded and AI IoT applications,
    to install the trained and tested networks for the evaluation phase. As explained
    in the discussion section, in the future operational online detection phase with
    the UAS, only YOLOv5 will be loaded on the Jetson board: this is because YOLOv5
    has proved to be a lighter network than the custom feature pyramid FPN, and it
    achieved better results in detection and hardware performance (power consumption,
    storage memory, etc.). A comparison between FPN and YOLOv5 network performance
    is briefly referred in 3.2 and some data on the implementation of YOLOv5 on the
    Jetson board are reported in Section 3.3. 2.4.7. Temporal monitoring and data
    integration To correctly reconstruct the complete time history of each plant,
    a temporal monitoring algorithm has been developed. The first step of this process
    is a spatial registration of the consecutive pairs of orthomosaics (Hartley and
    Zisserman, 2004). 12 ground control points (GCP) (e.g., in Fig. 5) have been placed
    on the ground by recording their georeferenced position (longitude, latitude,
    altitude), according to WGS84 (EPSG 4326) geographic projection model. As such,
    all the centers of gravity of the DL detected boxes can be always remapped in
    world coordinates with an affine transformation, to support optimal UAS-sprayer
    mission planning before, in real-time crop operations. Download : Download high-res
    image (759KB) Download : Download full-size image Fig. 5. One of the 12 GCPs (0.5
    × 0.5 m) used for image referencing. The adopted solution for orthomosaics registration
    at different recording times is an automatic registration process, based on the
    information provided by the box-plants detected by the Neural Network. Such an
    automatic registration is implemented in two following steps: • search for the
    overall translation (dx, dy) that maximizes the IoU (Intersection over Union)
    between the boxes detected in the two consecutive orthomosaic images. • selection
    of the boxes with IoU above a predetermined threshold (greater than 50%) and computation
    of the relative homographic transform between the centers of mass. It is worthy
    to underline that, in this case, the homographic transformation is computed between
    the centers of mass of the boxes detected in two consecutive orthomosaic images.
    The transformation allows mapping the positions of the boxes from one image to
    the other, aligning them spatially. By estimating the homography, the algorithm
    can reconstruct the complete time history of each plant by aligning and registering
    the detected boxes in the consecutive orthomosaic images. The mean square deviation
    of the homographic transformation is varying between 9 and 12 cm, which roughly
    corresponds to the actual spread of the center of gravity positions of the matched
    boxes, in two consecutive time frames. The automatic registration allows to perform
    a spatial prediction between the coordinates of the orthomosaic at time t0 (past)
    with those at time t1 (next) and vice versa. It represents the basis of the time
    monitoring process (Kalal et al., 2010), which, in turn, is implemented in two
    phases: • monitoring forward: for each box detected at time t0, the best match
    is searched (in terms of max IoU) among all the boxes detected at time t1; if
    an acceptable match is not found (IoU threshold), a new hypothesis (prediction)
    is generated and added to the list of the boxes available at time t1, thus ensuring
    the propagation and continuity of the current track. • monitoring backward: when
    the last available orthomosaic map has been reached, the process is repeated in
    reverse, generating backward predictions for all the boxes that do not have yet
    connections with the previous stages of the crop. The result of this monitoring
    process is a series of complete traces, from the first orthomosaic image recorded,
    up to the last available, for all the box-plants that have been detected by the
    Neural Network. The total number of traces inevitably includes some errors that
    can be classified as: • missed-box-plants, mainly due to low image contrast, interference
    with other elements of the scene, etc. • multiple box instances for the same ground
    truth, due to localization and size errors in forward–backward matching. • new-phantom-boxes,
    which may appear in areas where there are no plants, often due to the presence
    of weeds, scattered leaves, etc. As such, forward–backward allows the complete
    reconstruction of the plant development from the beginning to the end of the crop.
    2.4.8. Artichoke crop field analysis The output list of the box-plants from the
    temporal integration is re-organized by ordering them both in vertical and horizontal
    positions along the plant rows in the field. Fig. 6 shows a subset of the crop
    field (the full size is 14112 × 9072 px), with the overlap of the detected and
    time-tracked box-plants. Download : Download high-res image (790KB) Download :
    Download full-size image Fig. 6. A partial view of the RGB orthomosaic, with the
    box-plants detected and tracked over time–space (blue) and connected along each
    row of the crop. (For interpretation of the references to color in this figure
    legend, the reader is referred to the web version of this article.) In a real-time
    application, on-board of the UAS, the best network configuration should be able
    to achieve a high recall rate, to cover the maximum amount of the plant targets''
    surface and drive the direction of the sprayer towards the actual position of
    the plants in the field. A high precision rate would also be desirable, to minimize
    the amount of spraying outside the actual crop. Given the potentially real-world
    application, it is worth noting how much the detected boxes differ from the ground
    truth: minimal variations on detection can drastically affect the UAS’s spraying
    positioning over the target plant and the operation planning, so the deviation
    between the centers of the detected boxes and their respective truth boxes to
    apply appropriate countermeasures was estimated. We identified the L2 norm (the
    Euclidean distance) as the most representative measure for estimating the distance
    between the centers of the boxes, since it considers deviations along all directions
    of the plane. Calling and with the centers of the i-th detected box and ground-truth
    box, respectively, we calculated the distance di for all pairs of detected and
    ground-truth boxes as: (4) From this data representation it is possible to achieve
    an automatic segmentation of each plant row with corresponding parameters (number
    of plants/rows, vegetation-mass index and density of the plants) which provide
    a clear view of the health status of the crop. Another important feature output
    of the multitemporal analysis is the Growing index related to the seasonal development
    of the crop size. It is computed as the ratio between the average size (width
    and height) of the bounding box of the plants detected at the different times
    of the experiment: (5) Where and are, respectively, the width and the height of
    the j bounding boxes of the orthomosaic i and N is the number of the bounding
    boxes in the orthomosaic, which, thanks to the temporal monitoring algorithm,
    is the same for each orthomosaic (N = 1419 for FP network and N = 1351 for YOLOv5
    network). 3. Results 3.1. Deep learning plant detection 3.1.1. FPN performance
    analysis During the evaluation phase the FPN was tested on the portion of the
    dataset not used for training. Table 2 shows the performances of the network in
    the detection of the artichoke plants. TP is the number of the boxes correctly
    identified by the network, with an overlap measure IoU of more than 50% over the
    ground truth boxes that were selected during the manual annotation process. FP
    is the number of boxes detected by the network which do not correspond to ground
    truth boxes, or the IoU is lower than the 50% threshold. FN is the number of ground
    truth boxes (in the annotation list) that have been missed by the detection network.
    Detection performance was also tested with different values of IoU, from 0.5 to
    0.25. Of course, a slight improvement of both recall and precision was found,
    but always below 0.5%. Hence the entire performance test was carried on with the
    standard threshold IoU = 0.5. It is worth noting that surface indexes (SR and
    SP) are independent of the IoU value. Table 2 and Table 3 compare the performance
    measures obtained before and after the Forward-Backward monitoring process. Table
    3. Performance measures of the FPN network after multi-temporal monitoring. Date
    BBCH TP FP FN Precision Recall F1score SR SP 7 Sept 14 487 146 59 0.76 0.89 0.83
    0.89 0.88 14 Sept 16 531 95 55 0.84 0.91 0.88 0.91 0.92 1 Oct 35 555 102 52 0.85
    0.91 0.88 0.90 0.96 15 Oct 47 550 82 51 0.87 0.92 0.89 0.94 0.96 9 Nov 51 517
    124 84 0.8 0.86 0.83 0.91 0.98 3 Dec 55 499 121 76 0.81 0.87 0.84 0.93 0.97 23
    Dec 59 519 106 85 0.83 0.86 0.85 0.92 0.97 Table 2 shows how precision is slowly
    decreasing with time, in accordance with the crop development process. In fact
    artichoke plants reach their maximum growth around December, and as the plants
    become larger, they often interfere each other with partial overlapping which
    makes it difficult to distinguish artichoke plants in the field. Such an irregular
    distribution of the plant-boxes is also affecting the behavior of the recall index.
    The lower values measured in the very early stage of the test (7 Sept.), are due
    to the presence, in the ground-truth list, of very small target-plants which are
    often barely visible also by the human eye. On the other hand, the two surface
    indexes SR and SP are much more stable all along the full development period.
    They better describe the network performance within the context of UAS-spraying
    application and demonstrate that more than 90% of the plant foliage can be reached
    by the spraying process, with less than 5% of the spraying product falling outside
    of the actual crop field. Forward-backward tracking allows to improve the recall
    index, by recovering some of the plant-boxes which were missed by the network
    at a certain stage of the development, but inevitably it also determines a reduction
    of the precision measure, due to the generation of multiple hypotheses, for very
    close or partial overlapping plants. Table 3 (for network FPN) and Table 5 (for
    YOLOv5) confirm this trend but do not contribute to determine the best network,
    since performance after tracking is almost identical for both. Table 4 shows the
    metrics extracted from di to evaluate the deviation between the centers of the
    predicted boxes and those of ground truth. Statistics were first calculated per
    pixel and then reported in cm with the equivalence that one px = 0.5 cm. Table
    4. Statistics of the deviation between the centers of the predicted boxes and
    those of ground truth. Date BBCH Min (cm) Max (cm) Mean (cm) Mode (cm) Median
    (cm) Std (cm) 7 Sept 14 0.00 21.82 4.89 1.11 4.30 3.24 14 Sept 16 0.00 30.56 6.17
    3.53 4.74 4.99 1 Oct 35 0.50 40.05 8.99 1.80 6.40 7.40 15 Oct 47 0.50 44.77 8.10
    2.50 6.51 6.35 9 Nov 51 0.70 47.16 14.11 4.03 12.06 9.73 3 Dec 55 0.70 51.24 12.30
    4.03 9.92 9.02 23 Dec 59 0.00 56.64 12.08 1.11 9.48 9.51 Table 5. Performance
    measures of the YOLOv5 at each individual date of the test. Date BBCH TP FP FN
    Precision Recall F1 score SR SP 7 Sept 14 437 1 109 0.99 0.8 0.88 0.91 0,96 14
    Sept 16 469 2 117 0.99 0.8 0.88 0.91 0,97 1 Oct 35 534 3 73 0.99 0.88 0.93 0.94
    0,98 15 Oct 47 543 7 58 0.98 0.9 0.94 0.94 0,97 9 Nov 51 522 7 79 0.98 0.86 0.92
    0.95 0,99 3 Dec 55 494 5 81 0.99 0.85 0.92 0.95 0,98 23 Dec 59 509 3 95 0.99 0.84
    0.91 0.95 0,98 3.1.2. YOLOv5 performance analysis The same performance evaluation
    carried out for the custom FPN was also repeated on the YOLOv5 network for each
    orthomosaic of the dataset. The results, in Table 5, demonstrate a high level
    of precision, which is confirmed also by the SP index. On the contrary the recall
    index is slightly low during the early stages of the plant growth. Anyway, the
    SR index, reporting the actual ground plant coverage, is high (greater than 90%)
    and stable for the whole analysis period. Even in this case the detection performance
    was measured after multi-temporal forward–backward integration, to receive confirmation,
    in Table 6, of a greater coverage of the foliar plant at the expense of a slightly
    lower precision. These performances are very suitable for multi temporal analysis
    of the crop, to faithfully reproduce the growth development of each plant in the
    field. Table 6. Performance measures of the YOLOv5 network designed to achieve
    the lower number of detection errors. Date BBCH TP FP FN Precision Recall F1 score
    SR SP 7 Sept 14 475 127 71 0.78 0.87 0.82 0.96 0.80 14 Sept 16 492 105 94 0.82
    0.84 0.83 0.96 0.85 1 Oct 35 567 56 40 0.91 0.93 0.92 0.96 0.94 15 Oct 47 554
    46 47 0.92 0.92 0.92 0.96 0.95 9 Nov 51 557 51 44 0.91 0.92 0.92 0.95 0.98 3 Dec
    55 530 61 45 0.89 0.92 0.9 0.95 0.97 23 Dec 59 550 44 54 0.92 0.91 0.91 0.95 0.97
    Finally, Table 7 shows the deviation between the centres of the predicted and
    ground truth boxes for the output of the YOLOv5 network. The reported values of
    the minimum (Min), maximum (Max), mean (Mean), mode (Mode), median (Median) and
    standard deviation (Std) demonstrate that the detected boxes are fairly well overlapping
    the ground truth, and this is an indication of the goodness of the network prediction.
    3.2. FPN and YOLOv5 comparison Fig. 7 reports the detection of the whole study
    area with the two different networks: both showed to be able to detect a high
    number of plants (detection of the whole orthomosaic is an onerous task for one
    network) but with a better prevalence of YOLOv5, which, as mentioned, tends to
    minimize false positives (identified by the bigger red squares in the top-right
    and bottom-right parts of Fig. 7a). Both network models show appropriate performance
    for the problem at hand, and the area indexes (SR and SP) demonstrate a high leaf
    area coverage of the plants and a minimum amount of detection area outside them.
    Download : Download high-res image (869KB) Download : Download full-size image
    Fig. 7. Detection of the entire crop area with both nets. It is possible to see
    in the upper right part of the image (a) how the FPN detects several false positives
    of the artichoke plant. In contrast, the YOLOv5 network performs approximately
    perfect detection of the entire field (b). Anyway, YOLOv5 achieves a greater level
    of precision as compared to FPN whose training data included also a significant
    amount of small object-plants. On the contrary, YOLOv5 has been trained on wider
    and more diversified datasets, with the tendency to generalize to larger object
    shapes. The statistics in Table 7 also indicate that YOLOv5 performs better in
    the detection of artichoke plants. In particular, the columns of mean and standard
    deviation show that the YOLOv5 model is more robust and was not affected by plant
    growth over the months. Table 7. Statistics of the deviation between the centers
    of the predicted boxes and those of ground truth for the YOLOv5. Date BBCH min
    max mean mode median std 7 Sept 14 0.00 16.86 2.54 1.11 2.61 2.15 14 Sept 16 0.00
    13.41 2.83 1.11 2.12 2.19 1 Oct 35 0.00 33.63 3.94 1.11 2.69 3.84 15 Oct 47 0.00
    34.05 4.66 1.11 3.35 4.16 9 Nov 51 0.00 59.03 5.70 1.58 3.60 5.88 3 Dec 55 0.00
    45.02 7.05 1.58 4.52 7.24 23 Dec 59 0.00 41.50 5.84 2.23 4.03 5.55 As a last metric
    to compare the two networks, Fig. 8 reports the mAP index for each orthomosaic.
    Download : Download high-res image (85KB) Download : Download full-size image
    Fig. 8. The mean Average precision index for the two networks across all datasets.
    There is no doubt that YOLOV5 performs better than the custom FPN, as highlighted
    by mAP results showed in Fig. 8. The reasons for such a performance disparity
    can be attributed to various factors. Firstly, the model architecture plays a
    crucial role as YOLOv5 and FPN have different underlying architectures that can
    impact their performance. While FPN achieves lower performance results, it is
    also less complex than Yolov5, with a different number of parameters to be trained.
    Secondly, training strategies are significant factors to consider. Finding the
    optimal hyperparameters (learning rate, optimizers, train-test split, etc.) can
    be a challenging task that requires a considerable amount of time and energy.
    YOLOv5 is a state-of-the-art technology, and it is assumed that the hyperparameters
    have been properly tuned. Thirdly, post-processing steps applied to the model''s
    output can have an impact on the final detection results. Techniques such as non-maximum
    suppression to remove duplicate detections, thresholding for confidence scores,
    and bounding box refinement can vary in implementation and affect the performance
    disparity between YOLOv5 and FPN if not consistently applied. In summary, the
    performance disparity can be attributed to several factors, including data availability,
    choice of optimal hyperparameters, and post-processing considerations, but what
    is worthy to note is that custom training of neural networks (like the FPN in
    question) can result in comparable performance with state-of-the-art techonology.
    3.3. On-board network detection As mentioned in subsection 2.4.6, during the next
    operational phase only the YOLOv5 network will be mounted on the Nvdia Jetson
    board. Table 8 shows some statistics of the Jetson board when the YOLOv5 network
    is running on it in the test phase. The statistics were obtained from jetson-stats,
    a package for monitoring and controlling NVIDIA Jetson [Orin series, Xavier series,
    Nano, TX1, TX2]. The performance statistics were evaluated in two different power
    modes of the board: 5W mode, in which the board operates at low power consumption
    and uses only two of the four CPUs, and MAXN mode, which uses all available power
    up to a maximum of 15W. Fig. 9 shows the number of FPS evaluated by the board
    in the two different power modes. The computed statistics are composed by different
    parameters: CPU usage, GPU usage, RAM usage, temperature, and power consumption,
    each of them divided in two different power modes: energy consumption mode (5
    W mode) and maximum consumption mode (MAXN mode). Specifically: ▪ The “Min” and
    “Max” columns show the minimum and maximum values for each parameter during the
    detection process. ▪ The “Std” columns show the standard deviation for each parameter,
    which gives an idea of how much the values fluctuate during the detection process.
    ▪ The”CPUs” rows show the percentage usage of the four CPUs on the board. ▪ The
    “GPU” row shows the percentage usage of the GPU on the board. ▪ The “RAM” row
    shows the usage of the RAM on the board. ▪ The “TempCPU” and “TempGPU” rows show
    the temperature of the CPUs and GPU, respectively. ▪ The “PowerAvg” row shows
    the average power consumption during the detection process. Table 8. Table of
    statistics of the Nvdia Jetson Nano board when running the trained YOLOv5 network.
    Empty Cell 5 W mode MAXN mode Empty Cell Min Max Mean Std Min Max Men Std CPU1
    (%) 10.00 100.00 66.08 23.13 2 81 38.14 11.82 CPU2 (%) 12.00 100.00 66.39 22.77
    1 81 36.48 10.89 CPU3 (%) \\ \\ \\ \\ 0 53 35.52 11.33 CPU4 (%) \\ \\ \\ \\ 0
    54 35.98 11.58 GPU (%) 7.00 99.00 56.36 44.65 0 99 79.48 34.82 RAM 2,067,900 2,101,352
    2,087,900 13,757 2,084,768 2,104,596 2,099,000 59,371 TempCPU (°) 28.50 33.00
    30.87 1.36 32.00 38.5 35.65 1.63 TempGPU (°) 28 32.5 30.28 1.49 32 37 35.76 1.36
    PowerAvg (mW) 1945 3035 2553 551.1 3435 4722 4237 383.93 Download : Download high-res
    image (91KB) Download : Download full-size image Fig. 9. FPS in the different
    power modes. It is evident that by using the total power of the Nvidia Jetson
    board, the performance in terms of FPS increases dramatically. It is clear from
    the table that YOLOv5 model uses most of the available resources of the Jetson
    Nanon board, with the GPU usage being the highest at 99%. The standard deviation
    values are relatively low, indicating that the performance of the model is consistent.
    The temperature of the CPU and GPU are relatively high, with the hottest value
    reached by the GPU in MAXN mode at 38.5 degrees. The power consumption is also
    relatively high with the highest consumptions reached in the MAXN mode. Fig. 9
    shows the number of FPS evaluated by the board in the two different power modes.
    3.4. Multi-temporal analysis The graphics in Fig. 10 shows the evolution of the
    Growing Index (GI) for each network. The figure shows the range of variations
    on a differential scale (between consecutive maps) as well as the cumulative value
    during time. Download : Download high-res image (193KB) Download : Download full-size
    image Fig. 10. Graphic plots of the growing index (GI) evolution for the FPN (a)
    and the YOLOv5 (b) networks. The whisker plot shows the range of variations between
    two consecutive dates of the experiment. The GI is measured as the ratio between
    the sizes of the bounding box collected at the different times of the experiment.
    The blue line represents the cumulative average index. (For interpretation of
    the references to color in this figure legend, the reader is referred to the web
    version of this article.) To address the issue of the uniform or uneven distribution
    of the growing rate, it is possible to display a heat-map (as in Fig. 11) where
    the spatial distribution of the growing index value for each tracked plant, is
    shown (according to the color scale) over the full crop field. Download : Download
    high-res image (564KB) Download : Download full-size image Fig. 11. The heat-map
    of the GI (from 1 October to 15 October of the dataset). The color scale (from
    red to green) is shown with the range values (from a minimum of 0.55 to the maximum
    of 1.8). (For interpretation of the references to color in this figure legend,
    the reader is referred to the web version of this article.) Fig. 12 shows the
    temporal evolution of two sample artichoke plants (detected with the YOLOv5 network,
    the behavior with the FPN being quite the same) in a simple isolated case (a)
    and a quite common situation (b) where the growing of nearby plants is quickly
    reaching a size of mutual interference and partial overlaps. Download : Download
    high-res image (597KB) Download : Download full-size image Fig. 12. History-map
    for each individual artichoke plant, over the full data-set; (a) simple case of
    an isolated plant; (b) more common case of multiple plants and their growing process
    (yellow boxes correspond to prediction results of the monitoring process). (For
    interpretation of the references to color in this figure legend, the reader is
    referred to the web version of this article.) Another important result is reported
    in Table 9. It shows the occupancy rate (i.e., the percentage of the field occupied
    by the detected boxes), and the average size of the detected boxes measured for
    each available set. Not surprisingly, the occupancy rate increases with the growth
    of the artichoke plants and reaches its highest value in December (maximum plant
    growth). A similar observation can be made for the average plant size. If we compare
    FPN and YOLOv5, we can see that the results are almost the same. This is certainly
    due to the similar performance of the two network models, but it is mainly due
    to multi-temporal integration, which, through forward–backward propagation, tends
    to recover all missing plants and provide a reliable representation of plant evolution
    throughout the whole growing season. Table 9. Occupancy rate and average size
    of the box-plants along the rows during the development of the crop for each network.
    Empty Cell Empty Cell FPN YOLOv5 Date BBCH Occupancy rate (%) Avg. plant size
    (cm) Occupancy rate (%) Avg. plant size (cm) 7 Sept 14 30.03 53 28.37 57 14 Sept
    16 40.38 65 39.31 71 1 Oct 35 52.34 85 52.36 93 15 Oct 47 57.90 95 56.78 97 9
    Nov 51 65.59 122 66.52 127 3 Dec 55 66.06 119 66.21 125 23 Dec 59 61.60 107 61.95
    115 4. Discussions The results obtained on the various datasets show that the
    network performs satisfactorily on artichoke plants detection, irrespective of
    the date of the test. It is worth reminding that the same trained network was
    used for the whole experimental season, without any optimization for the individual
    datasets. This time independence is particularly important for an industrial application
    of this technology in precision agriculture because it can be applied to different
    scenarios in a small amount of time for different crop applications. In general,
    the detection rate (recall) is higher in the early period of the crop when the
    plants are smaller and isolated and is lower in the late period of the year. This
    behavior highlights the increasing difficulties to detect and distinguish plants
    in the last phases due to the mutual overlap of the bigger plants within the rows
    (Fig. 11). A similar trend is also visible for the measure of precision which
    is over 90% in the early dates. Missing plants tend to decrease during the experimental
    dates, except on 9 November 2021. The different illumination condition derived
    by a different angle of the incident radiation, and the presence of Oxalis pes-caprae
    L., one of the most abundant alien species in artichoke fields during the last
    days of winter, could have given a higher contrast helping the detection system
    to distinguish artichoke plants more easily from weed or other elements in the
    latest surveys dates (Fig. 13). Download : Download high-res image (1MB) Download
    : Download full-size image Fig. 13. Two different date acquisitions of the same
    field portion. The Oxalis pes-caprae invasive plants on 23 December 2021 (b) determined
    a stronger contrast compared to the 9 November 2021 survey (a). Results obtained
    on frailejones plants (family of Asteraceae) by a novel Scale Sequence Residual
    U-Net deep learning method showed Precision, Recall, and F1 results similar to
    the one reported in this work. It is worth noting that the obtained results refer
    to a spontaneous plant with geometric and colors (higher contrast between plants
    and soil background) features different from the monitored artichoke plants, which
    could have positively influenced plant detection. The work by (Fan et al., 2018)
    illustrates a three stages plant detection Convolutional Neural Network (CNN)
    algorithm from UAS images. The proposed methodology relies on tobacco plants identification
    inside candidate regions, previously identified in the first stage through image
    morphological operations and watershed segmentation techniques. This procedure
    allowed the algorithm to focus on specific areas of interest over the rows, excluding
    the inter-row and the surrounding soil and spontaneous plants influence, differently
    from the methodology proposed in this work which operates a detection on the entire
    field on a multitemporal scale, and with inter-rows covered by spontaneous plants.
    The bare soil, high contrast, and the color difference between the target plants
    and the soils are crucial aspects of plant detection, as reported by (Etienne
    et al., 2021). The YOLOv3-based weed detection system implementation helped detect
    monocot and dicot weeds within corn and soybean fields, especially when the emergent
    crops were of similar color and size. The real-time peanut counting model proposed
    by (Lin et al., 2022) based on a video analysis by an improved YOLOv5 algorithm
    showed a 98.08% precision, with a seedling detection five times faster than the
    one obtained by the operator. A similar on the fly approach by (James and Bradshaw,
    2020) showed invasive plant detection feasibility in the field with a commercially
    available drone integrated with a deep learning model and its applicability to
    other plant species. As compared to the performance detection analysis carried
    out individually for each stage of the crop, significant improvements can be obtained
    by using a multi-temporal analysis, with the aggregation of information from all
    stages of the crop. As such we may obtain a complete history of the evolution
    of the plant starting from the first observation acquired. For example, it is
    possible to compensate for a possible lack of detection on a certain date, thanks
    to the availability of new detection data, as well as to manage the partial overlaps
    of neighboring plants, and correct some evident errors of localization and size.
    From the availability of the complete temporal traces of each plant it is possible
    to obtain useful indicators on the evolution of the crop which can be used by
    the expert agronomist to properly plan irrigation and fertilization interventions
    and improve plant productivity and health. In addition to the overall estimates
    on the evolution of the crop (vegetative mass, growth indices), averaged over
    the entire observed field, some detailed spatial maps can also be provided to
    highlight any anomalies or non-uniformities in the different areas of the field.
    The result of monitoring all the detected box-plants over time increases the number
    of instances by filling most missing data (with box-prediction), and allows a
    remarkable improvement of recall, at the expense of a reduced level of precision
    (i.e., more candidates for nearby plants). Moreover, the spatial ordering of all
    plant- boxes along each individual row of the crop field allows additional measures
    like the occupancy rate of the plants as shown in Table 9. The number of plants
    is progressively increasing, with respect to the background (terrain and weed),
    by reaching a maximum value at the beginning of December, in accordance with the
    growing index. The field consists of 25 rows of plants with an initial estimated
    planting of 3000 samples. The number of detected plants during the seven experimental
    campaigns reveals a strong reduction of plants (more than 60%) during the very
    early stages of development, with a progressive stabilization. The multitemporal
    analysis allowed the obtainment of a more efficient net that, if applied to the
    same crop in the next years will achieve better performance to the first, more
    balanced network. This approach, after the first year of image acquisition and
    network training, can be applied regularly for crop analysis, without the need
    of repeating the training process. As stated in the materials and methods section,
    the detection process involved the conversion of the WGS84 georeferenced images
    in a XY coordinate system to easily perform the detection process. The artichoke
    plants detector has been developed not only to later create a real time detection
    system implemented on board of a spraying UAS, but also to hypothesize the future
    creation of a path planning system useful to define the borders of the field and
    the optimized route the UAS will follow, adapting the flight course to maintain
    the position of the nozzles over the plants. The use of the RTK positioning system
    is a mandatory equipment to perform such operations, but as frequently happens,
    these systems face low accuracy problems, especially in remote zones characterized
    by poor correction signal cover. Any error in the positioning related to the frequent
    low accuracy of GPS systems implemented on board of UASs will be solved by using
    the real-time plant detector system. From Table 2, Table 5, it can be said that
    the network predictions do not deviate overly (on average) from the ground truth,
    confirming the good detection performance reported in Table 1, Table 4. So, apparently,
    the evidence does not imply taking countermeasures to align the UAS and properly
    control the detected artichoke, but further analysis will need to be done when
    the model will be tested in real scenarios. Based on the representation reported
    in Fig. 6, it will be possible to perform path-planning optimization for spraying
    operations (by UAS or Unmanned Ground Vehicle). Moreover, a full history of the
    vegetation process is obtained, for each individual plant (Fig. 12), at the different
    stages of the development process. This detection system’s ability will open new
    scenarios for plant detection, easily allowing the operator to monitor the entire
    field and evaluate the condition of each plant, specifically for those that show
    different conditions respect to the rest of the field. Once the net is trained
    to detect a specific crop, a first explorative flight should be performed each
    year after plants’ emergence to identify the exact field borders (which also match
    the operations limits), create an optimized flying route based on the size and
    positions of nozzles, and have a time zero status of the field. To maintain a
    low waste of agrochemicals products, intermediate monitoring flights should be
    performed to verify the exact number, the size of plants and, in case of missing
    plants, adapt the flight parameters and the required agrochemical amount to distribute.
    From the performance analysis carried out in section 3, it has been proved that
    the two considered network models (FPN and YOLOv5) satisfy the general requirements
    of our application. In both cases the surface indexes (SR and SP) demonstrate
    a high leaf area coverage of the plants and a minimum amount of detection area
    outside them. Anyway, we concluded YOLOv5 to be the preferred solution, especially
    in terms of higher precision. Moreover, considering a possible on-board real-time
    implementation, significant advantages were found using YOLOv5 instead of FPN,
    as shown in Fig. 8. This real-time implementation, even if characterized by a
    preliminary complex and time-consuming process of data processing and training,
    represents a fundamental means to optimize operations of UAS agrochemicals spraying.
    The entire proposed procedure is a first step towards the development of a detector
    system finalized to perform real-time spraying operation over horticultural plants
    (in this case artichoke) but mostly to identify the process workflow, highlight
    the potentialities and, most of all, discover the related limits. The rising application
    of UASs in precision agriculture scenarios relies on the optimization of operations
    regarding spot/site-specific input application, path planning and quick response
    obtainment. Future works will involve the use of possible explainable AI techniques,
    like safety regions (Carlevaro and Mongelli, 2022) and counterfactual explanation
    (Carlevaro et al., 2022), to improve plant detection and give more strength to
    the multitemporal analysis framework. 5. Conclusions A machine learning approach
    for artichoke plant identification for UAS real-time spraying applications was
    developed. The FPN showed satisfactory detection performances in testing and offline
    phases, processing images through the Nvidia Jetson Nano board, and showing comparable
    results with the YOLOv5 network. Tests showed a marked mAP disparity between the
    two networks, delineating YOLOv5 as consistently performing better throughout
    the growing season. The proposed automatic multitemporal monitoring and analysis
    procedure showed the possibility of developing a UAS path planning procedure for
    flight optimization, needed to execute accurate and precise agrochemicals distribution.
    Such procedure allowed crop monitoring over the entire season, showing important
    results related to the growing heterogeneity of the field. The next steps, on
    the strength of the encouraging obtained results, will be to incorporate the Nvidia
    Jetson Nano board directly on the UAS to perform real-time detection and spraying
    application, giving a potentially strong and significant scope to this work. Moreover,
    multi-temporal analysis allows the exploration of crucial information to improve
    detection reliability and develop an automatic procedure for crop development
    monitoring. CRediT authorship contribution statement Alberto Sassu: Methodology,
    Validation, Investigation, Writing – original draft, Writing – review & editing.
    Jacopo Motta: Methodology, Software, Data curation. Alessandro Deidda: Methodology,
    Validation, Writing – review & editing, Visualization. Luca Ghiani: Methodology,
    Software. Alberto Carlevaro: Methodology, Software, Investigation, Writing – original
    draft. Giovanni Garibotto: Methodology, Data curation. Filippo Gambella: Investigation,
    Writing – original draft, Writing – review & editing, Resources, Supervision,
    Project administration, Funding acquisition, Methodology, Validation. Declaration
    of Competing Interest The authors declare that they have no known competing financial
    interests or personal relationships that could have appeared to influence the
    work reported in this paper. Acknowledgement The authors thank the Sarciofo Company
    (Uri, Sardinia, Italy), site of the surveys during the 2021-2022 season. Funding
    This work was supported by the ECSEL JU-funded project COMP4DRONES [grant number
    826610] and ATLANTIDE project - Advanced Technologies for LANds management and
    Tools for Innovative Development of an EcoSustainable agriculture, Interdepartmental
    Center IA - INNOVATIVE AGRICULTURE Loc. Surigheddu, 07041 Alghero (SS), SS 127
    bis, Km 28,500 - CUP: J88D20000070002. Data availability The data that has been
    used is confidential. References Aeberli et al., 2021 A. Aeberli, K. Johansen,
    A. Robson, D.W. Lamb, S. Phinn Detection of Banana Plants Using Multi-Temporal
    Multispectral UAV Imagery Remote Sens. (Basel), 13 (2021), 10.3390/rs13112123
    Google Scholar Archontoulis et al., 2010 S.V. Archontoulis, P.C. Struik, J. Vos,
    N.G. Danalatos Phenological growth stages of Cynara cardunculus: codification
    and description according to the BBCH scale Ann. Appl. Biol., 156 (2010), pp.
    253-270, 10.1111/j.1744-7348.2009.00384.x View in ScopusGoogle Scholar Bochkovskiy
    et al., 2020 Bochkovskiy, A., Wang, C.-Y., Liao, H.-Y.M., 2020. YOLOv4: Optimal
    Speed and Accuracy of Object Detection. https://doi.org/10.48550/ARXIV.2004.10934.
    Google Scholar Carlevaro et al., 2022 A. Carlevaro, M. Lenatti, A. Paglialonga,
    M. Mongelli Counterfactual Building and Evaluation via eXplainable Support Vector
    Data Description IEEE Access, 10 (2022), pp. 60849-60861, 10.1109/ACCESS.2022.3180026
    View in ScopusGoogle Scholar Carlevaro and Mongelli, 2022 A. Carlevaro, M. Mongelli
    A New SVDD Approach to Reliable and Explainable AI IEEE Intell. Syst., 37 (2022),
    pp. 55-68, 10.1109/MIS.2021.3123669 View in ScopusGoogle Scholar Chavarri et al.,
    2004 M.J. Chavarri, A. Herrera, A. Ariño Pesticide residues in field-sprayed and
    processed fruits and vegetables J. Sci. Food Agric., 84 (2004), pp. 1253-1259,
    10.1002/jsfa.1791 View in ScopusGoogle Scholar Chen et al., 2021 C.-J. Chen, Y.-Y.
    Huang, Y.-S. Li, Y.-C. Chen, C.-Y. Chang, Y.-M. Huang Identification of Fruit
    Tree Pests With Deep Learning on Embedded Drone to Achieve Accurate Pesticide
    Spraying IEEE Access, 9 (2021), pp. 21986-21997, 10.1109/ACCESS.2021.3056082 View
    in ScopusGoogle Scholar De Bortoli et al., 2022 L. De Bortoli, S. Marsi, F. Marinello,
    S. Carrato, G. Ramponi, P. Gallina Structure from Linear Motion (SfLM): An On-the-Go
    Canopy Profiling System Based on Off-the-Shelf RGB Cameras for Effective Sprayers
    Control Agronomy (2022), 10.3390/agronomy12061276 Google Scholar Etienne et al.,
    2021 A. Etienne, A. Ahmad, V. Aggarwal, D. Saraswat Deep Learning-Based Object
    Detection System for Identifying Weeds Using UAS Imagery Remote Sens. (Basel),
    13 (2021), 10.3390/rs13245182 Google Scholar European Parliament, C. of the E.,
    2009 European Parliament, C. of the E. Directive 2009/128/EC of the European Parliament
    and Of the Council of 21 October 2009 establishing a framework for Community action
    to achieve the sustainable use of pesticides (Text with EEA relevance) Off. J.
    Eur. Union, 1–16 (2009) Google Scholar Fadda et al., 2020 A. Fadda, A. Virdis,
    A. Barberis, L. Ledda, S. Melito Impact of different photoperiodic treatments
    on “Spinoso Sardo” globe artichoke (Cynara cardunculus L. var. scolymus Fiori)
    head traits and elementary composition Acta Hortic., 1284 (2020), pp. 131-136,
    10.17660/ActaHortic.2020.1284.17 View in ScopusGoogle Scholar Fan et al., 2018
    Z. Fan, J. Lu, M. Gong, H. Xie, E.D. Goodman Automatic Tobacco Plant Detection
    in UAV Images via Deep Neural Networks IEEE J. Sel. Top. Appl. Earth Obs. Remote
    Sens., 11 (2018), pp. 876-887, 10.1109/JSTARS.2018.2793849 View in ScopusGoogle
    Scholar Feng et al., 2020 Q. Feng, J. Yang, Y. Liu, C. Ou, D. Zhu, B. Niu, J.
    Liu, B. Li Multi-Temporal Unmanned Aerial Vehicle Remote Sensing for Vegetable
    Mapping Using an Attention-Based Recurrent Convolutional Neural Network Remote
    Sens. (Basel), 12 (2020), 10.3390/rs12101668 Google Scholar Gerhards and Oebel,
    2006 R. Gerhards, H. Oebel Practical experiences with a system for site-specific
    weed control in arable crops using real-time image analysis and GPS-controlled
    patch spraying Weed Res., 46 (2006), pp. 185-193, 10.1111/j.1365-3180.2006.00504.x
    View in ScopusGoogle Scholar Gerhards et al., 2022 R. Gerhards, D. Andújar Sanchez,
    P. Hamouz, G.G. Peteinatos, S. Christensen, C. Fernandez-Quintanilla Advances
    in site-specific weed management in agriculture—A review Weed Res., 62 (2022),
    pp. 123-133, 10.1111/wre.12526 View in ScopusGoogle Scholar Hartley and Zisserman,
    2004 Hartley, R.I., Zisserman, A., 2004. Multiple View Geometry in Computer Vision,
    Second. ed. Cambridge University Press, ISBN: 0521540518. Google Scholar Iriti
    and Vitalini, 2020 M. Iriti, S. Vitalini Sustainable Crop Protection, Global Climate
    Change, Food Security and Safety—Plant Immunity at the Crossroads Vaccines, 8
    (2020), 10.3390/vaccines8010042 Google Scholar James and Bradshaw, 2020 K. James,
    K. Bradshaw Detecting plant species in the field with deep learning and drone
    technology Methods Ecol. Evol., 11 (2020), pp. 1509-1519, 10.1111/2041-210X.13473
    View in ScopusGoogle Scholar Jiao et al., 2019 L. Jiao, F. Zhang, F. Liu, S. Yang,
    L. Li, Z. Feng, R. Qu A Survey of Deep Learning-Based Object Detection IEEE Access,
    7 (2019), pp. 128837-128868, 10.1109/ACCESS.2019.2939201 View in ScopusGoogle
    Scholar Kalal et al., 2010 Z. Kalal, K. Mikolajczyk, J. Matas Forward-backward
    error: Automatic detection of tracking failures 2010 20th international conference
    on pattern recognition, IEEE (2010), pp. 2756-2759, 10.1109/ICPR.2010.675 View
    in ScopusGoogle Scholar Kamilaris and Prenafeta-Boldú, 2018 A. Kamilaris, F.X.
    Prenafeta-Boldú Deep learning in agriculture: A survey Comput. Electron. Agric.,
    147 (2018), pp. 70-90, 10.1016/j.compag.2018.02.016 View PDFView articleView in
    ScopusGoogle Scholar Kang et al., 2022 J. Kang, S. Tariq, H. Oh, S.S. Woo A Survey
    of Deep Learning-Based Object Detection Methods and Datasets for Overhead Imagery
    IEEE Access, 10 (2022), pp. 20118-20134, 10.1109/ACCESS.2022.3149052 View in ScopusGoogle
    Scholar Khan et al., 2021 S. Khan, M. Tufail, M.T. Khan, Z.A. Khan, J. Iqbal,
    A. Wasim Real-time recognition of spraying area for UAV sprayers using a deep
    learning approach PLoS One, 16 (2021), pp. 1-17, 10.1371/journal.pone.0249436
    View in ScopusGoogle Scholar Kriflik and Yeatman, 2005 L.S. Kriflik, H. Yeatman
    Food scares and sustainability: A consumer perspective Health Risk Soc., 7 (2005),
    pp. 11-24, 10.1080/13698570500042439 View in ScopusGoogle Scholar Lan et al.,
    2017 Y.B. Lan, S.D. Chen, B.K. Fritz Current status and future trends of precision
    agricultural aviation technologies Int. J. Agric. Biol. Eng., 10 (2017), pp. 1-17,
    10.3965/j.ijabe.20171003.3088 View in ScopusGoogle Scholar Lin et al., 2022 Y.
    Lin, T. Chen, S. Liu, Y. Cai, H. Shi, D. Zheng, Y. Lan, X. Yue, L. Zhang Quick
    and accurate monitoring peanut seedlings emergence rate through UAV video and
    deep learning Computers and Electronics in Agriculture, 197 (2022), Article 106938,
    10.1016/j.compag.2022.106938 View PDFView articleView in ScopusGoogle Scholar
    Lin et al., 2017 T.-Y. Lin, P. Dollár, R. Girshick, K. He, B. Hariharan, S. Belongie
    Feature Pyramid Networks for Object Detection 2017 IEEE Conference on Computer
    Vision and Pattern Recognition (CVPR), IEEE (2017), pp. 936-944, 10.1109/CVPR.2017.106
    View in ScopusGoogle Scholar Liu et al., 2016 W. Liu, D. Anguelov, D. Erhan, C.
    Szegedy, S. Reed, C.-Y. Fu, A.C. Berg SSD: Single Shot MultiBox Detector B. Leibe,
    J. Matas, N. Sebe, M. Welling (Eds.), Computer Vision – ECCV 2016, Springer International
    Publishing, Cham (2016), pp. 21-37 View in ScopusGoogle Scholar Meng et al., 2022
    J. Meng, P. Jiang, J. Wang, K. Wang A MobileNet-SSD Model with FPN for Waste Detection
    J. Electr. Eng. Technol., 17 (2022), pp. 1425-1431, 10.1007/s42835-021-00960-w
    View in ScopusGoogle Scholar Osco et al., 2021 L.P. Osco, J.M. Junior, A.P.M.
    Ramos, L.A. de Castro Jorge, S.N. Fatholahi, J. de Andrade Silva, E.T. Matsubara,
    H. Pistori, W.N. Gonçalves, J. Li A review on deep learning in UAV remote sensing
    Int. J. Appl. Earth Obs. Geoinf., 102 (2021), Article 102456, 10.1016/j.jag.2021.102456
    View PDFView articleView in ScopusGoogle Scholar Padilla et al., 2020 Padilla,
    R., Netto, S.L., Silva, E.A.B. da, 2020. A Survey on Performance Metrics for Object-Detection
    Algorithms. 2020 International Conference on Systems, Signals and Image Processing
    (IWSSIP) 237–242. Google Scholar Popp et al., 2013 J. Popp, K. Pető, J. Nagy Pesticide
    productivity and food security. A review Agron. Sustain. Dev., 33 (2013), 10.1007/s13593-012-0105-x
    Google Scholar Redmon et al., 2016 J. Redmon, S. Divvala, R. Girshick, A. Farhadi
    You only look once: Unified, real-time object detection Proceedings of the IEEE
    conference on computer vision and pattern recognition (2016), pp. 779-788, 10.48550/ARXIV.1506.02640
    Google Scholar Sarri et al., 2019 D. Sarri, L. Martelloni, M. Rimediotti, R. Lisci,
    S. Lombardo, M. Vieri Testing a multi-rotor unmanned aerial vehicle for spray
    application in high slope terraced vineyard J. Agric. Eng., 50 (2019), pp. 38-47,
    10.4081/jae.2019.853 View in ScopusGoogle Scholar Spanu et al., 2018 E. Spanu,
    P.A. Deligios, E. Azara, G. Delogu, L. Ledda Effects of alternative cropping systems
    on globe artichoke qualitative traits J. Sci. Food Agric., 98 (2018), pp. 1079-1087,
    10.1002/jsfa.8558 View in ScopusGoogle Scholar Tabikha and Draz, 2022 R.M. Tabikha,
    A.K. Draz Population Dynamics of Capitophorus Elaeagni (Hemiptera: Aphididae)
    and Its Associated Predators on Artichoke Plants in El-Behera Alex. Sci. Exch.
    J., 43 (2022), pp. 187-197, 10.21608/asejaiqjsae.2022.230544 View in ScopusGoogle
    Scholar Van den Berg et al., 2020 H. Van den Berg, B. Gu, B. Grenier, E. Kohlschmid,
    S. Al-Eryani, H.S. da Silva Bezerra, B.N. Nagpal, E. Chanda, E. Gasimov, R. Velayudhan,
    R.S. Yadav Pesticide lifecycle management in agriculture and public health: Where
    are the gaps? Sci. Total Environ., 742 (2020), Article 140598, 10.1016/j.scitotenv.2020.140598
    View PDFView articleView in ScopusGoogle Scholar Xue et al., 2016 X. Xue, Y. Lan,
    Z. Sun, C. Chang, W.C. Hoffmann Develop an unmanned aerial vehicle based automatic
    aerial spraying system Comput. Electron. Agric., 128 (2016), pp. 58-66, 10.1016/j.compag.2016.07.022
    View PDFView articleView in ScopusGoogle Scholar Cited by (1) Drone-Assisted Plant
    Disease Identification Using Artificial Intelligence: A Critical Review 2023,
    International Journal of Computing and Digital Systems © 2023 The Authors. Published
    by Elsevier B.V. Recommended articles A distributed agroecosystem model (RegWHCNS)
    for water and N management at the regional scale: A case study in the North China
    Plain Computers and Electronics in Agriculture, Volume 213, 2023, Article 108216
    Hao Liang, …, William D. Batchelor View PDF Development and testing of a ground
    recognition system for tractor field operations Computers and Electronics in Agriculture,
    Volume 213, 2023, Article 108190 Chang-kai Wen, …, Zhi-jun Meng View PDF Numerical
    study on the performance of circular juvenile fish breeding ponds Computers and
    Electronics in Agriculture, Volume 213, 2023, Article 108206 Atefeh Moghbeli,
    …, Mohammad Zounemat-Kermani View PDF Show 3 more articles Article Metrics Citations
    Citation Indexes: 1 Captures Readers: 38 View details About ScienceDirect Remote
    access Shopping cart Advertise Contact and support Terms and conditions Privacy
    policy Cookies are used by this site. Cookie settings | Your Privacy Choices All
    content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply."'
  inline_citation: '>'
  journal: Computers and Electronics in Agriculture
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Artichoke deep learning detection network for site-specific agrochemicals
    UAS spraying
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Raju K.L.
  - Vijayaraghavan V.
  citation_count: '2'
  description: Nowadays, the agriculture decision-making system has become essential
    for field monitoring. In that aspect, the Internet of Things (IoT) and Machine
    Learning (ML) are the most emerging technologies which can provide precision,
    intelligence, and agriculture decision-making system to yield better results.
    These technologies help in increasing agricultural production and enhancing operational
    efficiency. Due to sudden changes in weather conditions studying various parameters
    are either affected or influenced, the prediction analysis has been impractical
    and difficult. In such cases, using few intelligent systems like IoT and ML can
    provide feasible alternative solutions. In this paper, a novel architecture development
    is being proposed for agricultural decision-making systems using IoT and ML. The
    performance metrics of various ML algorithms in the field of agriculture are examined
    and analyzed in this study. Decision Tree (DT) has shown superior performance
    over the conventional methods like Support Vector Machine (SVM), and Random Forest
    (RF) about agriculture sensor data. Simulation results show that the proposed
    development of architectural measurement index for agriculture decision-making
    system has a maximum accuracy value of 98%, minimum Mean Absolute Error (MAE)
    of 0.07%, Mean Square Error (MSE) of 0.06%, R-Squared parameter of 99%, and Root
    Mean Square Error (RMSE) of 0.002% for detecting crop production in IoT-ML agriculture
    decision-making system. Also, significant experiments have been carried out to
    evaluate Measurement Index (MI) with less error rate for agriculture decision-making
    system.
  doi: 10.1007/s11042-023-14957-2
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Home Multimedia Tools and Applications
    Article Architecture development with measurement index for agriculture decision-making
    system using internet of things and machine learning Published: 15 March 2023
    Volume 82, pages 36119–36142, (2023) Cite this article Download PDF Access provided
    by University of Nebraska-Lincoln Multimedia Tools and Applications Aims and scope
    Submit manuscript K. Lova Raju & V. Vijayaraghavan  388 Accesses 2 Citations 1
    Altmetric Explore all metrics Abstract Nowadays, the agriculture decision-making
    system has become essential for field monitoring. In that aspect, the Internet
    of Things (IoT) and Machine Learning (ML) are the most emerging technologies which
    can provide precision, intelligence, and agriculture decision-making system to
    yield better results. These technologies help in increasing agricultural production
    and enhancing operational efficiency. Due to sudden changes in weather conditions
    studying various parameters are either affected or influenced, the prediction
    analysis has been impractical and difficult. In such cases, using few intelligent
    systems like IoT and ML can provide feasible alternative solutions. In this paper,
    a novel architecture development is being proposed for agricultural decision-making
    systems using IoT and ML. The performance metrics of various ML algorithms in
    the field of agriculture are examined and analyzed in this study. Decision Tree
    (DT) has shown superior performance over the conventional methods like Support
    Vector Machine (SVM), and Random Forest (RF) about agriculture sensor data. Simulation
    results show that the proposed development of architectural measurement index
    for agriculture decision-making system has a maximum accuracy value of 98%, minimum
    Mean Absolute Error (MAE) of 0.07%, Mean Square Error (MSE) of 0.06%, R-Squared
    parameter of 99%, and Root Mean Square Error (RMSE) of 0.002% for detecting crop
    production in IoT-ML agriculture decision-making system. Also, significant experiments
    have been carried out to evaluate Measurement Index (MI) with less error rate
    for agriculture decision-making system. Similar content being viewed by others
    AI-big data analytics for building automation and management systems: a survey,
    actual challenges and future perspectives Article Open access 15 October 2022
    Plant disease detection using drones in precision agriculture Article Open access
    28 March 2023 Enhancing crop recommendation systems with explainable artificial
    intelligence: a study on agricultural decision-making Article Open access 11 January
    2024 1 Introduction Agriculture is a long-term feasibility to ensure food safety,
    security, and hunger elimination for the world’s rapidly expanding population.
    By 2050, it is anticipated [18] that global food production needs to grow by 60–110%
    to feed 9–10 billion people. To meet the global challenges as expected, the automation
    is required for agriculture field monitoring. In agricultural practices, the Internet
    of Things (IoT), Machine Learning (ML), Wireless Sensor Networks (WSN), Cloud
    Computing (CC), Big Data (BD), and Data Analytics (DA) play a major role while
    addressing the issues regarding [10] Smart Agriculture (SA). In this paper, the
    main focus is on agriculture and environment optimization with the installation
    of IoT, WSN and ML for improving the efficiency and effectiveness of the farmers.
    The evaluation of agricultural parameters such as air temperature, air humidity,
    and soil moisture by using these emerging technologies. Additionally, IoT and
    ML are used for monitoring and controlling issues that influence agriculture crops
    [11] and heath growth. It determines the optimum time required for harvesting
    so that, the farmer could take appropriate actions in their agriculture field.
    A. IoT in Agriculture In traditional agriculture farming, farmers are facing problems
    that lead to low crop growth production. In order to ensure high yield and production,
    IoT automation [7] is required for agricultural practices and it is stated as
    smart agriculture or precision agriculture. IoT plays an important role in various
    agriculture field applications such as crop monitoring, management of water, soil,
    and pest control as shown in Fig. 1. IoT can provide better solutions for increasing
    agricultural productivity by using various deployment and environmental sensors.
    Once sensors collect the field information, it is transmitted to embedded hardware
    platforms for data processing and then sent directly to the cloud (ThingSpeak)
    for storage through various wireless technologies and IoT protocols. Fig. 1 IoT
    in various agriculture field applications Full size image B. ML in Agriculture
    ML is a branch of Computer Science that enables computers to learn without having
    openly programmed. ML plays a crucial role in various agricultural [19] field
    applications like crop monitoring, crop production, soil management, soil analysis,
    data processing, field monitoring, seeding, soil health, decision-making, and
    fertilization as shown in Fig. 2. There are three types of machine learning algorithms-
    supervised learning, unsupervised learning, and reinforcement learning as shown
    in Fig. 3. Supervised Learning is classified into two parts like regression and
    classification. In regression, it includes Simple Linear Regression (SLR), Multiple
    Linear Regression (MLR), Polynomial Regression (PR), and Logistic Regression (LR).
    Meanwhile, the classification includes K-Nearest Neighbour (K-NN), Decision Tree
    (DT), Support Vector Machine (SVM), Bayes Classifier (BC), and Random Forest (RF).
    In unsupervised learning, the clustering technique includes three parts like Partitioning
    Method (PM), Hierarchical Method (HM), and Density Method (DM). Three parts have
    come under reinforcement learning such as Q-Learning (Q-L), Sarsa, and Markov
    Decision Model (MDM). Fig. 2 ML in various agriculture field applications Full
    size image Fig. 3 Classification of various ML algorithms Full size image 2 Existing
    works Agriculture is currently reliant on emerging technologies, with smart agriculture,
    precision agriculture, and irrigation systems all based on automation and a range
    of design techniques. A considerable amount of agricultural research is being
    carried out. A few developed works are listed below. In [12], the authors proposed
    a system for sprinkler irrigation with the use of a WSN and it is fully automated
    for controlling the water pumps and dripper valves. To enable optimal water supply
    control and surveillance, soil and irrigation monitoring systems equipped with
    sensors may be computerized and handled through remotely. In this article, to
    calculate water content, soil temperature, and pH for crops, as well as how to
    use motor systems to provide adequate water and to optimally monitor for a healthy
    and sufficient harvest. The data from the humidity, temperature, and soil pH sensors
    is used to regulate the water usage of the soil. For sensor data transformation,
    the system employs a low-cost, energy-efficient ZigBee module, a GPRS long-range
    communication system for storage of information and analysis, and energy harvesting
    capabilities to power the entire system, making it self-sustaining. Agriculture
    and farming have [16] recently evolved into precision sensor network connectivity
    with an innovative level of Internet of things. The agriculture and farming industry
    in a remote area can be benefited from cloud computing and a WSN-based on an extensive
    distance network of IoT. In this paper, the authors suggest a scalable wireless
    sensor network architecture for agricultural farming in a remote location monitoring
    and controlling via IoT. Water resource irrigation and efficient water resource
    utilization are two important aspects of Precision Agriculture and Farming (PAF).
    Irrigation management can be improved by integrating WSN technology and the Internet
    of Things. IoT is used in PAF to process the effective communication of numerous
    wireless sensors to boost farm productivity. Additionally, focus on metrics such
    as throughput maximization, delay minimization, high signal-to-noise ratio (SNR),
    minimal mean square error (MMSE), and improved coverage area should be addressed.
    When compared to existing methods, the proposed method performs better, according
    to the experimental data. The authors of [17] suggested a method that can be used
    to meet the needs of massive agricultural farms in terms of data processing. In
    this study, the authors used a low-cost WSN as a model for collecting data from
    field sensors across a large area. Furthermore, certain WSN-based agricultural
    data monitoring systems are currently available, but one main disadvantage of
    this system is that they suffer extremely high deployment costs as the number
    of devices increases. A tree-based communication technique is used in this system
    to increase the communication range by adding intermediary nodes. A solar panel,
    a rechargeable cell, a microcontroller, a moisture sensor, and a communication
    device are all included in every sensor node. The associated sensor collects field
    data through the sensor node, which is then transferred to the gateway through
    a half-duplex wireless serial communication module in two or more distinct hops.
    The central node gets field data from sensor nodes, collects weather data from
    the API, and uses the GSM/GPRS module to communicate limited data to the cloud.
    The network is transformed from a centralized to a decentralized topology using
    a GSM-based technique, in which each node has a GSM technology and delivers its
    sensor data directly to the cloud. The author of [15] presented a unique architecture
    for assessing the thermal comfort of services as a key enabler for real-time MISSENARD
    index monitoring. The author employed only one sensor (DHT11) and interfaced it
    with an Arduino Uno and a Wi-Fi shield in this paper. Several clouds are used
    to view data in the proposed system, which provides a new methodology of smarter
    integration of sensor-operated data through cloud visualisation at the same time
    as output step. In [8], the authors have stated a methodology for the farmer that
    by sensing the moisture of soil and temperature, it provides the information to
    farmers for suitable crop growth and knowing the nature of their soil by CMM index.
    In this paper, the author used one sensor only (DHT11) and interfaced it with
    an Arduino Uno with a Wi-Fi shield, and addressed the importance of a moisture
    sensor. Here, the layered architecture is used to convey messages to farmers of
    the specific agricultural field information through e-mail alerts and SMS. In
    [9], the authors proposed a methodology that considers field parameters like temperature,
    humidity, and soil moisture. The THAM index measurement and makes smart decision-making
    to increase the yield rate of the crop up to 75% with a reduction of unwanted
    data resource less rate and increase the production yield rate. In addition to
    this, a regulation model for NPK fertilizer is used to ensure that the right nutrition
    rate is accessible in the soil and also discussed the number of optimum sensors
    that should be installed to cover the entire agricultural land. In [20], the authors
    demonstrated Agrinex: smart irrigation system with a low-cost design and WSN based
    mesh topology. Precision agriculture uses wireless sensor networks to utilize
    natural resources better way by gathering real-time data on different farms and
    assisting farmers in making informed decisions. The farmers may use this technology,
    to successfully use the provided information to produce increased yields and increase
    their profits. In agricultural regions, existing monitoring methods can be replaced
    with the usage of a Wireless Sensor and Actuator Network (WSAN) as well as an
    irrigation mechanism that supports in increasing resource-saving measures. Agrinex
    uses a mesh-like architecture of in-field nodes that function as a soil moisture,
    temperature, and humidity sensor as well as a drip irrigation solenoid valve.
    When changes in the network occur, the mesh-based network dynamically designed
    allows sensor nodes to self-reorganize. The resulting Agrinex system offers a
    potential begin for WSAN architecture with a wide range of applications in the
    agricultural sector. In [5], proposed energy-efficient IoT and WSN-based systems
    are for smart agriculture applications. In this article, IoT and WSN are utilized
    to perceive crop conditions and using numerous IoT sensors installed in agriculture
    field, automated smart farming, to boost crop yield output using a smart farming
    decision-making system and to collect sensor data on crops and plants. This proposed
    system focus on few key metrics such as communication range, signal-to-noise ratio
    (SNR), system throughput, power consumption, and packet drop ratio. In [1], suggesting
    an IoT-based system to measure thermal insulation efficiency, which is used to
    reduce the consequences of environmental conditions. This thermal insulation effect
    can be measured by IoT-based sensor networks. In this article, the proposed system
    consists of hardware and software components such as Arduino microcontroller,
    DHT11 sensor (Temperature and Humidity sensors), Wi-Fi module (MKR1000), and ThingSpeak
    cloud open-source platform respectively. But the author did not discuss the proper
    thermal measurement system for agriculture applications. In [4], suggested a smart
    irrigation system based on machine learning and future technologies. The importance
    of soil moisture in the deployment of a smart irrigation system was discussed
    in this article. The soil moisture is primarily affected by environmental elements
    such as air, temperature, humidity and UV radiation. The accuracy of weather forecasting
    has been improved by upgrading with the latest technologies, and data can easily
    be predicted if any changes in soil moisture occurred. In this paper, the architecture
    of smart irrigation employing hybrid machine learning and IoT for soil moisture
    prediction is presented. From the existing works, we found that some of the issues
    such as improper measurement indexes, latency in data transmission, the hardware
    is not cost-effective, and so on. To correct these issues, we came up with a proposed
    new architecture. In this architecture, the main emphasis is on error rate function,
    measurement index for the farmers take suitable actions in agriculture fields,
    the hardware used is cost-effective and accurate in measurement index calculations
    with less execution time, less error rate, and so forth. 3 Development of experimental
    setup (DES) This section presents the selection of emerging technologies, hardware
    platforms, and sensors (environmental and deployment sensors). 3.1 Emerging technologies
    (ET) Various emerging technologies [2, 13] are present like Machine to Machine
    (M2M), Wireless Sensor Networks (WSN), Internet of Things (IoT), Machine Learning
    (ML), Artificial Intelligence (AI), Deep Learning (DL) and so forth. Each technology
    is examined to see which is the most capable and appropriate for the architecture
    in concern. M2M and WSN are subsets of IoT in general, as seen in Fig. 4. All
    related communication devices in IoT technology can be controlled by a centralised
    system, although this may not be possible with M2M and WSN. M2M technology is
    more frequently connected than IoT technology, although it has less scalability.
    As a result, IoT technology surpasses M2M technology today. Fig. 4 Relation between
    IoT with M2M and WSN Full size image In the case of data analysis, machine learning,
    artificial intelligence, and deep learning are playing a key role and the relation
    among themselves as shown in Fig. 5. The ML is less complex and cost-effective
    when compared to AI and DL so that ML is more suitable for the proposed architecture.
    Finally, IoT and ML have been selected technologies for the implementation of
    the proposed architecture in this article. Fig. 5 Relation between AI with ML
    and DL Full size image 3.2 Hardware platforms Several hardware platforms [6, 21]
    are available to implement the proposed architecture for the development of an
    intelligent agriculture decision-making system as shown in Table 1. Raspberry
    pi is one of them, and it has been chosen for the development of the proposed
    architecture. Table 1 Various hardware platforms for agricultural applications
    Full size table 3.3 Sensors Different types of sensors are used in agricultural
    applications [14] such as humidity and temperature sensor (DHT11), soil temperature
    sensor, soil moisture, wind sensor, rain sensor, pH of the soil, and so on. The
    proposed architecture intends to provide an affordable and simply accessible method
    that rural low-educated farmers could be used to make their agriculture decision-making
    system more effective. Hence, only soil moisture sensor, DHT11 (temperature and
    humidity sensor), soil pH, and pi camera are chosen to create an agriculture decision-making
    system in the proposed architecture. The installation of additional sensors, on
    the other hand, will raise the overall system cost. The below-mentioned Table
    2 provides different types of sensors that were used in the agriculture decision-making
    system. Table 2 Different sensors related to agriculture applications Full size
    table 4 Proposed architecture The proposed architecture for the development of
    an intelligent agricultural decision-making system using IoT and ML. It consists
    of two parts like user system and the cloud system as shown in Fig. 6 below. Fig.
    6 Proposed architecture for intelligent decision making system Full size image
    The user system is for monitoring the agricultural field and gathering data (agriculture
    parameters) from environmental and deployment sensors (agriculture sensors). So,
    the physical layer comes into the picture, sensing all parameters of agriculture
    via sensors such as temperature, humidity, and wetness, among others. It transmits
    the digital signal to a higher level. Data acquisition refers to the collection
    of information from sensors used in agriculture. Data processing refers to the
    process of completing data gathering and processing the data, which is defined
    as hardware embedded platforms (IoT gateway) and wireless communication technologies
    for IoT, relying on the conceptual and communication layers. Only messages are
    sent from client to server via communication protocols [3] like MQTT and CoAP,
    which used a set of rules for data in formats like XML, JSON, and CSV. These events
    occurred while the internet was available at the farmer’s location and was covered
    by the internet layer. The cloud system is responsible for the agricultural field
    data saved in a cloud server repository (IoT-cloud) with the help of IoT security
    features such as Application Programming Interface (API keys). As a result, present
    devices such as mobile phones, computers, and other devices can access data from
    the cloud repository. The storage layer manages to access data from the cloud
    via a farmer’s mobile phone for agricultural purposes. The application layer is
    designed to provide fully automated data visualization through graphical representation,
    real-time monitoring, and statistical analysis. The data is stored and analyzed
    in IoT cloud. Some machine learning methods are applied to data analysis in IoT
    applications. Finally, the IoT cloud system offers cloud data storage and analysis
    services. These cloud platforms are used to provide cloud services and are linked
    to IoT architecture. 5 Measurement index (MI) calculations In this section, the
    mathematical model of Measurement Index (MI) has been evaluated. It is used to
    evaluate the optimal values and they are classified into three types; such as
    Normal (healthy growth), Alert, and Emergency as shown in Fig. 7. By using optimal
    values, notifications are sent to the farmers so that farmers can take appropriate
    measures in their agricultural fields. The measurement index is used to identify
    the optimum level of field monitoring comfort. The typical determined values like
    A = 1.5 and B = 32, which are satisfied all abnormal conditions by using Eq. (1).
    $$ \\mathrm{MI}=\\left(\\mathrm{T}\\times \\mathrm{A}+\\mathrm{B}\\right)-\\frac{1}{2}\\times
    \\left(\\left(1-\\frac{\\mathrm{H}}{100}\\right)\\times \\left(1-\\frac{\\mathrm{S}}{100}\\right)\\times
    \\left(\\left(1-\\frac{\\mathrm{pH}}{14}\\right)\\right)\\right)\\times \\left(\\mathrm{T}\\times
    \\mathrm{A}-28\\right) $$ (1) Fig. 7 Measurement Index (MI) calculations for an
    intelligent decision-making system Full size image Where T: Temperature, H: Humidity,
    S: Soil moisture, Soil pH value and A, B-Standard constants. 6 Performance metrics
    for ML on agriculture sensors data Machine Learning techniques are used to analyze
    sensor data [22] in the agricultural field, so that performance metrics are measured.
    These are evaluated in the experimental for the performance analyses are mentioned
    below. In the prediction technique, the accuracy value, RMSE, MAE, and R-Squared
    parameter are all performance metrics. Furthermore, we present how to evaluate
    the current performance characteristics True Positive (TP), True Negative (TN),
    False Positive (FP), and False Negative (FN) using numerical ways. a) Accuracy
    value Accuracy provides the classification with the necessary records. The accuracy
    performance is always improving. $$ \\mathrm{Accuracy}\\ \\mathrm{value}=\\frac{\\mathrm{TN}+\\mathrm{TP}}{\\mathrm{TN}+\\mathrm{FN}+\\mathrm{TP}+\\mathrm{FP}}
    $$ (2) b) RMSE Root Mean Square Error, which was obtained using Eq. (3), was the
    first function used to measure prediction performance and accuracy for sensor
    network performance. The performance of a sensor network with a smaller RMSE is
    greater. $$ \\mathrm{RMSE}=\\sqrt{\\frac{1}{\\mathrm{N}}{\\sum}_{\\mathrm{i}=1}^{\\mathrm{N}}{\\left({\\mathrm{y}}_{\\mathrm{i}}-{\\mathrm{y}}_{\\mathrm{i}}^{\\hat{\\mkern6mu}}\\right)}^2}
    $$ (3) Where yi = Real value, yi^ = Predicted value, N = Total number of data
    points. c) MAE The model with higher accuracy and lower RMSE and MAE has more
    desirability. $$ \\mathrm{MAE}=\\frac{1}{\\mathrm{N}}{\\sum}_{\\mathrm{i}=1}^{\\mathrm{N}}\\left|{\\mathrm{x}}_{\\mathrm{i}}-{\\mathrm{y}}_{\\mathrm{i}}\\right|
    $$ (4) Where xi = Prediction, yi = True value, N = Total number of data points.
    d) MSE The MSE measures how near a regression line is to a set of points. $$ \\mathrm{MSE}=\\frac{1}{\\mathrm{N}}{\\sum}_{\\mathrm{i}=1}^{\\mathrm{N}}{\\left({\\mathrm{y}}_{\\mathrm{i}}-{\\mathrm{y}}_{\\mathrm{i}}^{\\hat{\\mkern6mu}}\\right)}^2
    $$ (5) Where yi = Observed value, yi^ = Predicted value, N = Total number of data
    points. e) R-Squared parameter The R-squared statistic indicates how close the
    data are to the fitted regression line. The R-square is a calculation that compares
    the residual sum of squares (SSres) to the total sum of squares (SStot). $$ {\\mathrm{R}}^2=1-\\frac{{\\mathrm{SS}}_{\\mathrm{res}}}{{\\mathrm{SS}}_{\\mathrm{tot}}}
    $$ (6) 7 Workflow of measurement index (MI) In this section, once collecting data
    from environmental sensors (temperature and humidity) and a deployment sensor
    (soil moisture sensor and pH sensor) for computing measurement index, the execution
    process flow of the measurement index has been addressed in this part. Finally,
    based on the MI values, the results have been divided into four groups, as shown
    in Fig. 8. Fig. 8 Workflow of Measurement Index (MI) Full size image 8 Algorithm
    of measurement index (MI) This algorithm focuses on the ThingSpeak cloud connection
    with raspberry pi 3. The data collection process has been performed using the
    environmental and deployment sensors such as DHT11 (Temperature and Humidity sensors),
    soil moisture sensor, and soil pH value. MI algorithm 9 Hardware and software
    requirements In this section, hardware and software implementations have been
    discussed. The hardware section consists of a raspberry pi 3 module, DHT11 sensor,
    soil moisture sensor, soil pH sensor, and MCP3008 analog to digital converter.
    All the digital and analog sensors are interfaced to raspberry pi 3 through MCP3008
    (ADC) and a portable power bank is used to provide the supply voltage (3.3 V to
    5.5 V) to the circuit as shown in Fig. 9. In addition, the pi camera module is
    connected with the raspberry pi 3 for agricultural field monitoring as well as
    avoiding the disease effect of crops. In the agricultural field, soil moisture
    and pH sensors are deployed in the soil. The data collected by this DHT11 sensor,
    soil moisture, and soil pH sensors are transmitted to the cloud server. Based
    on the sensor data, a measurement index has been calculated. The software section
    consists of raspberry pi 3, raspbian operating system, and SD card (Security Digital).
    Firstly, download and install the raspbian OS as well balenaEtcher and then flash
    OS images inserted into the SD card. Secondly, a minimum 16 GB memory chip with
    an SD card and is inserted into the memory card slot in raspberry pi 3 as shown
    in Fig. 10. This raspberry pi hardware platform supports Python Language (Thonny
    Python IDE) and ThingSpeak cloud (server) services for data visualization. Finally,
    the practical implementation has been developed as a prototype module in the field
    as shown in Fig. 11. Fig. 9 Schematic diagram for connecting the necessary components
    Full size image Fig. 10 Process of raspbian OS installation on raspberry pi 3
    Full size image Fig. 11 Upper portion shows the prototype deployment (a) temperature
    and humidity sensor (DHT11), (b) soil pH sensor, (c) soil moisture sensor, (d)
    power bank`, (e) MCP3008: Analog to digital converter with raspberry pi 3. The
    below portion shows the block diagram of the prototype deployment Full size image
    10 Results and discussion The results have been classified into six ways A. Performance
    metrics of ML on sensor data output B. Serial monitoring output through python
    shell C. ThingSpeak output D. ThingView mobile application output E. User interface
    output F. Comparative analysis. These are explained by graphical representations
    as shown given below. A. Performance metrics of ML on sensor data output To predict
    climatic conditions and to monitor agricultural fields to increase crop yield
    production by using IoT and ML, develop an architecture with a Measurement Index
    (MI) for an agriculture decision-making system. As a result, certain ML techniques
    such as SVM, RF, DT, and Hybrid are being evaluated for prediction models in the
    agriculture field to achieve decision making and crop yield production or healthy
    plant growth. The proposed architecture gives an insight on the performance metrics
    like accuracy value, RMSE, MAE, MSE, and R-Squared parameter are being evaluated
    for improvising the model which is used to find more accurate decisions could
    be taken by the farmers regarding their agricultural fields. Figure 12 shows the
    values of DT, RF, SVM, and Hybrid metrics for different error parameters. Also,
    the accuracy parameter has been plotted for different metrics values. Fig. 12
    Performance of metrics (a) Decision Tree value, (b) Random Forest value, (c) Support
    Vector Machine value, and (d) Hybrid value Full size image Figure 13 shows histogram
    representations of environmental and deployment sensor values for agricultural
    parameters like temperature, humidity, pH value, moisture, and light intensity.
    Fig. 13 Histogram representation of agricultural parameters Full size image Figure
    14 shows the data pre-processing of environmental and deployment sensor values
    for agricultural parameters. Fig. 14 Data pre-processing of agricultural parameters
    Full size image B. Serial monitoring output In this process, the result is observed
    by the user at the serial port which is monitored using Python Shell as shown
    in Fig. 15. Fig. 15 Serial monitoring results from Python Shell Full size image
    C. ThingSpeak cloud platform output In this section, the result has been observed
    through the ThingSpeak cloud platform using the Application Programming Interface
    (API Key). Figure 16 shows the variations of different sensor parameters viz.
    temperature, humidity, moisture, and pH value with respect to time. This figure
    also contains the values of the Measurement Index (MI) plotted against time. The
    gauge meter representation of MI is also included. Fig. 16 Execution results from
    the ThinkSpeak (a) Temperature sensor value, (b) Humidity sensor value, (c) pH
    sensor value, (d) Moisture sensor value, (e) Measurement Index (MI) value, (f)
    Gauge meter indication of MI value, (g) Motor ON condition, and (h) Motor OFF
    condition Full size image D. ThingView mobile application ThingView is a mobile
    app for Internet of Things (IoT) devices. It allows the ThingSpeak cloud platform
    to visualize and present agricultural sensor data received over ThingSpeak channels,
    as shown in Fig. 17. Fig. 17 Implementation results from the ThingView mobile
    app (a) Temperature sensor value vs time, (b) Humidity sensor value vs time, (c)
    pH sensor value vs time, (d) Moisture sensor value vs time, (e) Measurement Index
    (MI) value vs time Full size image E. User interface output In this section, the
    user interface (UI) has been created in Python IDE. A user can select the dataset,
    enter the values and see the results. A user can select an ML technique from a
    number of technical tabs provided at the bottom of this GUI as shown in Fig. 18.
    Fig. 18 User interface based on the agriculture sensors data Full size image F.
    Comparative analysis The proposed system gives better results when compared to
    existing systems in terms of development cost, architecture development and data
    analysis with IoT and ML, power usage, user interface, mobile app, and cloud services
    used as shown in Table 3. Table 3 compares the proposed system against current
    systems in terms of parameters Full size table The ET, CMM, and THAM measurement
    indexes are experiencing issues such as incorrect measurements. As a result, false
    decisions, expensive hardware platforms, power consumption, error rate (%), and
    so on are taking place. The proposed architecture with measurement index (MI)
    for smart agriculture decision making system integrating IoT and ML can solve
    these problems as shown in Table 4. Figure 19 illustrates the proposed architectural
    development with MI when compared existing systems in terms of error rate values.
    Table 4 The categories of the Measurement Index (MI) are used in the smart agriculture
    decision-making system Full size table Fig. 19 Error Rate values of the proposed
    architecture compare with existing systems Full size image 11 Conclusion This
    article gives a detailed evaluation of the application idea of IoT and ML techniques
    in the field of agriculture. A novel architectural development with Measurement
    Index values for agricultural decision-making system using IoT and ML is being
    proposed. By employing suitable measurement indexes, this proposed architecture
    allows for the optimal growth of the agricultural crops as well as increase in
    the agricultural produce. By combining of Wi-Fi technology with the automation
    of the raspberry pi 3 controller and interfacing of environmental and deployment
    sensors, agriculture crop production can be increased by effective monitoring
    and detection of disease-affected crops. For decision-making systems, a few major
    machine learning approaches have been applied to agriculture sensor data. Conventional
    methods such as Support Vector Machine (SVM), Random Forest (RF), and Hybrid have
    demonstrated less efficiency than Decision Tree (DT) technique. Finally, this
    article gives an insight on measurement index with less error rate, low power
    consumption, architecture development with IoT and ML, user interface, cloud services
    used, mobile application, data analysis by IoT and ML, and hardware is used in
    this technology is more cost-effective. Data availability Related to the work,
    every data has been provided in the manuscript. Code availability Not required
    for this work. References Abdalgader K, Al Ajmi R, Saini D (2020) IoT-based system
    to measure thermal insulation efficiency. J Ambient Intell Humaniz Comput. https://doi.org/10.1007/s12652-020-02459-0
    de Souza P, Rubin F, Hohemberger R, Ferreto T, Lorenzon A, Luizelli M, Rossi F
    (2020) Detecting abnormal sensors via machine learning: an IoT farming WSN-based
    architecture case study. Measurement 164:108042. https://doi.org/10.1016/j.measurement.2020.108042
    Article   Google Scholar   Farooq M, Riaz S, Abid A, Abid K, Naeem M (2019) A
    survey on the role of IoT in agriculture for the implementation of smart farming.
    IEEE Access 7:156237–156271. https://doi.org/10.1109/access.2019.2949703 Article   Google
    Scholar   Goap A, Sharma D, Shukla A, Rama Krishna C (2018) An IoT based smart
    irrigation management system using machine learning and open source technologies.
    Comput Electron Agric 155:41–49. https://doi.org/10.1016/j.compag.2018.09.040
    Article   Google Scholar   Haseeb K, Ud Din I, Almogren A, Islam N (2020) An energy
    efficient and secure IoT-based WSN framework: an application to smart agriculture.
    Sensors 20(7):2081. https://doi.org/10.3390/s20072081 Article   Google Scholar   Kour
    V, Arora S (2020) Recent developments of the internet of things in agriculture:
    a survey. IEEE Access 8:129924–129957. https://doi.org/10.1109/access.2020.3009298
    Article   Google Scholar   Lova Raju K, Vijayaraghavan V (2020) IoT Technologies
    in Agricultural Environment: a survey. Wirel Pers Commun 113(4):2415–2446. https://doi.org/10.1007/s11277-020-07334-x
    Article   Google Scholar   Mekala M, Viswanathan P (2019) CLAY-MIST: IoT-cloud
    enabled CMM index for smart agriculture monitoring system. Measurement 134:236–244.
    https://doi.org/10.1016/j.measurement.2018.10.072 Article   Google Scholar   Mekala
    M, Viswanathan P (2019) (t,n): Sensor Stipulation with THAM Index for Smart Agriculture
    Decision-Making IoT System. Wirel Pers Commun 111(3):1909–1940. https://doi.org/10.1007/s11277-019-06964-0
    Article   Google Scholar   Morais R, Silva N, Mendes J, Adão T, Pádua L, López-Riquelme
    J et al (2019) mySense: A comprehensive data management environment to improve
    precision agriculture practices. Comput Electron Agric 162:882–894. https://doi.org/10.1016/j.compag.2019.05.028
    Article   Google Scholar   Muangprathub J, Boonnam N, Kajornkasirat S, Lekbangpong
    N, Wanichsombat A, Nillaor P (2019) IoT and agriculture data analysis for smart
    farm. Comput Electron Agric 156:467–474. https://doi.org/10.1016/j.compag.2018.12.011
    Article   Google Scholar   Nagarajan G, Minu R (2017) Wireless soil monitoring
    sensor for sprinkler irrigation automation system. Wirel Pers Commun 98(2):1835–1851.
    https://doi.org/10.1007/s11277-017-4948-y Article   Google Scholar   Podder A,
    Bukhari A, Islam S, Mia S, Mohammed M, Kumar N et al (2021) IoT based smart agrotech
    system for verification of urban farming parameters. Microprocess Microsyst 82:104025.
    https://doi.org/10.1016/j.micpro.2021.104025 Article   Google Scholar   Raju KL,
    Vijayaraghavan V (2021) Internet of Agriculture Things (IoAT): a novel architecture
    design approach for open research issues. In Green Engineering and Technology.
    CRC Press, pp 35–56. https://doi.org/10.1201/9781003176275-3 Ray P (2016) Internet
    of things cloud enabled MISSENARD index measurement for indoor occupants. Measurement
    92:157–165. https://doi.org/10.1016/j.measurement.2016.06.014 Article   Google
    Scholar   Sanjeevi P, Prasanna S, Siva Kumar B, Gunasekaran G, Alagiri I, Vijay
    Anand R (2020) Precision agriculture and farming using internet of things based
    on wireless sensor network. Trans Emerg Telecommun Technol 31(12). https://doi.org/10.1002/ett.3978
    Saqib M, Almohamad T, Mehmood R (2020) A low-cost information monitoring system
    for smart farming applications. Sensors 20(8):2367. https://doi.org/10.3390/s20082367
    Article   Google Scholar   Sharma R, Kamble S, Gunasekaran A, Kumar V, Kumar A
    (2020) A systematic literature review on machine learning applications for sustainable
    agriculture supply chain performance. Comput Oper Res 119:104926. https://doi.org/10.1016/j.cor.2020.104926
    Article   MathSciNet   MATH   Google Scholar   Sharma A, Jain A, Gupta P, Chowdary
    V (2021) Machine learning applications for precision agriculture: a comprehensive
    review. IEEE Access 9:4843–4873. https://doi.org/10.1109/access.2020.3048415 Article   Google
    Scholar   Tiglao N, Alipio M, Balanay J, Saldivar E, Tiston J (2020) Agrinex:
    a low-cost wireless mesh-based smart irrigation system. Measurement 161:107874.
    https://doi.org/10.1016/j.measurement.2020.107874 Article   Google Scholar   Tzounis
    A, Katsoulas N, Bartzanas T, Kittas C (2017) Internet of things in agriculture,
    recent advances and future challenges. Biosyst Eng 164:31–48. https://doi.org/10.1016/j.biosystemseng.2017.09.007
    Article   Google Scholar   Wang P, Hafshejani B, Wang D (2021) An improved multilayer
    perceptron approach for detecting sugarcane yield production in IoT based smart
    agriculture. Microprocess Microsyst 82:103822. https://doi.org/10.1016/j.micpro.2021.103822
    Article   Google Scholar   Download references Funding In this work, no funding
    is involved of any agency or organizations. Author information Authors and Affiliations
    Electronics and Communication Engineering, Vignan’s Foundation for Science, Technology
    & Research, Vadlamudi, Guntur, Andhra Pradesh, 522213, India K. Lova Raju & V.
    Vijayaraghavan Corresponding author Correspondence to K. Lova Raju. Ethics declarations
    Conflict of interest There is no conflicts of interest with any person or body
    regarding this work. Additional information Publisher’s note Springer Nature remains
    neutral with regard to jurisdictional claims in published maps and institutional
    affiliations. Rights and permissions Springer Nature or its licensor (e.g. a society
    or other partner) holds exclusive rights to this article under a publishing agreement
    with the author(s) or other rightsholder(s); author self-archiving of the accepted
    manuscript version of this article is solely governed by the terms of such publishing
    agreement and applicable law. Reprints and permissions About this article Cite
    this article Raju, K.L., Vijayaraghavan, V. Architecture development with measurement
    index for agriculture decision-making system using internet of things and machine
    learning. Multimed Tools Appl 82, 36119–36142 (2023). https://doi.org/10.1007/s11042-023-14957-2
    Download citation Received 26 February 2022 Revised 26 February 2022 Accepted
    22 February 2023 Published 15 March 2023 Issue Date September 2023 DOI https://doi.org/10.1007/s11042-023-14957-2
    Share this article Anyone you share the following link with will be able to read
    this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing
    initiative Keywords Internet of things Machine learning Measurement index ThingSpeak
    cloud platform Agriculture sensors Decision-making system Use our pre-submission
    checklist Avoid common mistakes on your manuscript. Sections Figures References
    Abstract Introduction Existing works Development of experimental setup (DES) Proposed
    architecture Measurement index (MI) calculations Performance metrics for ML on
    agriculture sensors data Workflow of measurement index (MI) Algorithm of measurement
    index (MI) Hardware and software requirements Results and discussion Conclusion
    Data availability Code availability References Funding Author information Ethics
    declarations Additional information Rights and permissions About this article
    Advertisement Discover content Journals A-Z Books A-Z Publish with us Publish
    your research Open access publishing Products and services Our products Librarians
    Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC
    Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy
    rights Accessibility statement Terms and conditions Privacy policy Help and support
    129.93.161.222 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Multimedia Tools and Applications
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Architecture development with measurement index for agriculture decision-making
    system using internet of things and machine learning
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Gené-Mola J.
  - Ferrer-Ferrer M.
  - Gregorio E.
  - Blok P.M.
  - Hemming J.
  - Morros J.R.
  - Rosell-Polo J.R.
  - Vilaplana V.
  - Ruiz-Hidalgo J.
  citation_count: '9'
  description: The detection and sizing of fruits with computer vision methods is
    of interest because it provides relevant information to improve the management
    of orchard farming. However, the presence of partially occluded fruits limits
    the performance of existing methods, making reliable fruit sizing a challenging
    task. While previous fruit segmentation works limit segmentation to the visible
    region of fruits (known as modal segmentation), in this work we propose an amodal
    segmentation algorithm to predict the complete shape, which includes its visible
    and occluded regions. To do so, an end-to-end convolutional neural network (CNN)
    for simultaneous modal and amodal instance segmentation was implemented. The predicted
    amodal masks were used to estimate the fruit diameters in pixels. Modal masks
    were used to identify the visible region and measure the distance between the
    apples and the camera using the depth image. Finally, the fruit diameters in millimetres
    (mm) were computed by applying the pinhole camera model. The method was developed
    with a Fuji apple dataset consisting of 3925 RGB-D images acquired at different
    growth stages with a total of 15,335 annotated apples, and was subsequently tested
    in a case study to measure the diameter of Elstar apples at different growth stages.
    Fruit detection results showed an F1-score of 0.86 and the fruit diameter results
    reported a mean absolute error (MAE) of 4.5 mm and R2 = 0.80 irrespective of fruit
    visibility. Besides the diameter estimation, modal and amodal masks were used
    to automatically determine the percentage of visibility of measured apples. This
    feature was used as a confidence value, improving the diameter estimation to MAE
    = 2.93 mm and R2 = 0.91 when limiting the size estimation to fruits detected with
    a visibility higher than 60%. The main advantages of the present methodology are
    its robustness for measuring partially occluded fruits and the capability to determine
    the visibility percentage. The main limitation is that depth images were generated
    by means of photogrammetry methods, which limits the efficiency of data acquisition.
    To overcome this limitation, future works should consider the use of commercial
    RGB-D sensors. The code and the dataset used to evaluate the method have been
    made publicly available at https://github.com/GRAP-UdL-AT/Amodal_Fruit_Sizing.
  doi: 10.1016/j.compag.2023.107854
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Materials and methods
    3. Results 4. Discussion 5. Conclusions Declaration of Competing Interest Acknowledgements
    Data availability References Show full outline Cited by (11) Figures (12) Show
    6 more figures Tables (4) Table 1 Table 2 Table 3 Table 4 Computers and Electronics
    in Agriculture Volume 209, June 2023, 107854 Looking behind occlusions: A study
    on amodal segmentation for robust on-tree apple fruit size estimation Author links
    open overlay panel Jordi Gené-Mola a b, Mar Ferrer-Ferrer a, Eduard Gregorio a,
    Pieter M. Blok c, Jochen Hemming c, Josep-Ramon Morros d, Joan R. Rosell-Polo
    a, Verónica Vilaplana d, Javier Ruiz-Hidalgo d Show more Add to Mendeley Share
    Cite https://doi.org/10.1016/j.compag.2023.107854 Get rights and content Under
    a Creative Commons license open access Referred to by AmodalAppleSize_RGB-D dataset:
    RGB-D images of apple trees annotated with modal and amodal segmentation masks
    for fruit detection, visibility and size estimation Data in Brief, Volume 52,
    February 2024, Pages 110000 Jordi Gené-Mola, Mar Ferrer-Ferrer, Jochen Hemming,
    Pieter van Dalfsen, Dirk de Hoog, Ricardo Sanz-Cortiella, Joan R. Rosell-Polo,
    Josep-Ramon Morros, Verónica Vilaplana, Javier Ruiz-Hidalgo, Eduard Gregorio View
    PDF Highlights • A CNN for simultaneous modal and amodal instance segmentation
    was implemented. • Amodal segmentation was applied to predict visible and occluded
    apple regions. • Modal and amodal masks were used to estimate the % of visibility
    of apples. • The method was robust for detection and sizing of partially occluded
    fruits. • Results showed an F1 = 0.86 and a MAE = 2.93 mm for detection and sizing,
    respectively. Abstract The detection and sizing of fruits with computer vision
    methods is of interest because it provides relevant information to improve the
    management of orchard farming. However, the presence of partially occluded fruits
    limits the performance of existing methods, making reliable fruit sizing a challenging
    task. While previous fruit segmentation works limit segmentation to the visible
    region of fruits (known as modal segmentation), in this work we propose an amodal
    segmentation algorithm to predict the complete shape, which includes its visible
    and occluded regions. To do so, an end-to-end convolutional neural network (CNN)
    for simultaneous modal and amodal instance segmentation was implemented. The predicted
    amodal masks were used to estimate the fruit diameters in pixels. Modal masks
    were used to identify the visible region and measure the distance between the
    apples and the camera using the depth image. Finally, the fruit diameters in millimetres
    (mm) were computed by applying the pinhole camera model. The method was developed
    with a Fuji apple dataset consisting of 3925 RGB-D images acquired at different
    growth stages with a total of 15,335 annotated apples, and was subsequently tested
    in a case study to measure the diameter of Elstar apples at different growth stages.
    Fruit detection results showed an F1-score of 0.86 and the fruit diameter results
    reported a mean absolute error (MAE) of 4.5 mm and R2 = 0.80 irrespective of fruit
    visibility. Besides the diameter estimation, modal and amodal masks were used
    to automatically determine the percentage of visibility of measured apples. This
    feature was used as a confidence value, improving the diameter estimation to MAE
    = 2.93 mm and R2 = 0.91 when limiting the size estimation to fruits detected with
    a visibility higher than 60%. The main advantages of the present methodology are
    its robustness for measuring partially occluded fruits and the capability to determine
    the visibility percentage. The main limitation is that depth images were generated
    by means of photogrammetry methods, which limits the efficiency of data acquisition.
    To overcome this limitation, future works should consider the use of commercial
    RGB-D sensors. The code and the dataset used to evaluate the method have been
    made publicly available at https://github.com/GRAP-UdL-AT/Amodal_Fruit_Sizing.
    Previous article in issue Next article in issue Keywords Fruit detectionFruit
    measurementYield estimationFruit visibilityDeep learningPrecision agriculture
    1. Introduction In modern fruit production optimization of the use of all inputs
    is desired. Instead of a treatment or application per field or plot, fruit trees
    should get precisely the treatment they need. This approach is commonly known
    as precision fruticulture/horticulture. The goal is to produce more with less,
    to reduce the inputs such as labour, water, fertilizer and chemicals, and by doing
    so, reduce potential environmental pollution. The latest sensor developments and
    data technology allow continuous monitoring of the chosen field and tree parameters
    with high spatial and temporal resolution. These data provide better information
    for management decisions. The research and development of systems for fruit detection
    has been carried out for a considerable time given its enormous importance for
    the management of fruit farms (Slaughter and Harrell, 1987). One of the first
    and main applications is crop yield prediction. An accurate estimate, weeks or
    months in advance, of the fruit production allows optimal planning of the operations
    necessary for the management of the crop, as well as its collection, conservation
    and marketing (Anderson et al., 2019). Another application of fruit detection
    systems consists in mapping the predicted yield. These maps allow to analyse how
    the yield is distributed throughout the orchard in order to optimize the management
    based on the spatial variability (Longchamps et al., 2022). Automated harvesting
    is another field of application of fruit detection systems. It is a line of research
    and development whose beginnings go back a few decades (Moltó et al., 1992). However,
    the technological advances of the last ten years, together with the greater economic
    accessibility of components, have contributed to the fact that, at present, it
    is a very intense research field (Kootstra et al., 2021). The evolution of fruit
    detection systems should not only focus on detection but also on estimation of
    the size (and weight) of the detected fruit (Tijskens et al., 2016, Zhou et al.,
    2012). This allows estimation of the future yield in mass (kg or tons) and can
    also provide relevant information such as fruit quality and the optimal time to
    start harvesting. When measured several times during the growing season, size
    information can also be used to calculate the fruit growth rate and, together
    with models and decision support systems, improve orchard management by better
    managing the irrigation, nutrition and other agricultural tasks such as thinning
    (Robinson et al., 2008). The automated harvesting of fruit crops is another domain
    where fruit size estimation is relevant (Gongal et al., 2018). It opens up the
    possibility of selective harvesting of the fruits according to their size and
    quality. In addition, harvesting robots need to measure the fruits for more careful
    and gentler handling (Wang et al., 2017). Traditionally, fruit sizing on the tree
    has been carried out manually by means of Vernier callipers or sizing rings. These
    manual procedures are error-prone, labour-intensive and time-consuming, which
    in practice limits measurements to a few samples (trees) of the orchard. To overcome
    these limitations, several optical-based methodologies have been developed for
    automatic in-field fruit sizing. Thermography and colour cameras have been used
    to estimate fruit diameters (Stajnko et al., 2004, Wang et al., 2018), but they
    require the use of calibration targets next to the measured fruits in order to
    perform image calibration (Lu et al., 2022). To avoid the need for calibration
    targets, currently there is a trend towards 3D-based sensing methodologies such
    as light detection and ranging (LiDAR) systems, RGB-D cameras and photogrammetry
    techniques (Gregorio and Llorens, 2021). LiDAR systems are insensitive to prevailing
    lighting conditions and advantage can be taken of their radiometric capabilities
    to estimate fruit size, as demonstrated by Tsoulias et al. (2020). RGB-D cameras
    are affordable sensors that simultaneously provide colour and depth data, but
    their performance is affected by high lighting conditions (Gené-Mola et al., 2020).
    With RGB-D cameras, Wang et al. (2017) were able to estimate the length and width
    of mangoes with RMSE values of 4.9 and 4.3 mm, respectively. The advent of low-cost
    photogrammetric software along with advances in computing power are driving the
    use of structure-from-motion (SfM) and multi-view stereo (MVS) for fruit size
    estimation (Grilli et al., 2021). In our previous work (Gené-Mola et al., 2021),
    we proposed a new apple fruit sizing methodology based on SfM and MVS which showed
    an MAE value of 3.7 mm and a coefficient of determination (R2) of 0.91. However,
    it presented high processing times due to the intensive operations on which SfM
    is based. One of the major challenges that sensor-based fruit sizing methods need
    to overcome is the measurement of partially occluded fruits. In addition, fruit
    occlusions also affect the performance of harvesting robots estimating the 3D
    grasping point for a robotic gripper. To overcome this challenge, we propose to
    estimate the shape of partially occluded fruits by means of amodal instance segmentation,
    which aims to predict the visible and occluded parts of each object of interest
    in an image (Li and Malik, 2016). To date, the task of fruit instance segmentation
    has been applied to mask the visible region of fruits (Santos et al., 2020, Wang
    and He, 2022), which is known as modal instance segmentation. An example of modal
    segmentation is illustrated in Fig. 1b (Modal Mask). Alternatively, with the hypothesis
    that occluded regions are important to estimate the fruit size, we propose to
    mask not only the visible but also the occluded regions of the apples, as shown
    in Fig. 1c (Amodal Masks). Amodal instance segmentation has been mainly applied
    in the field of mobile robotics and autonomous driving (Qi et al., 2019), while
    in the agriculture field it has been applied to predict the complete shape of
    broccoli heads (Blok et al., 2021) and occluded piglets in animal husbandry (Gan
    et al., 2022). Download : Download high-res image (239KB) Download : Download
    full-size image Fig. 1. Example of modal and amodal segmentation masks in a Fuji
    apple image. In this work we implemented a convolutional neural network (CNN)
    for simultaneous modal and amodal instance segmentation. The main contributions
    of this work are: 1) for the first time, simultaneous modal and amodal instance
    segmentation is applied to fruit images; 2) a robust method for fruit sizing and
    visibility estimation is proposed, based on the combination of modal and amodal
    segmentation in RGB-D images; 3) an analysis of the method performance depending
    on the amount of fruit visibility and the detection confidence is presented; 4)
    a performance evaluation in different apple varieties (Fuji and Elstar) and growth
    stages (green and ripe) is provided; and 5) the implemented code and the generated
    dataset with ground truth annotations are provided. After this introduction, the
    rest of the paper is structured as follows. Section 2 provides detailed information
    about the generated dataset, the architecture and training details of the implemented
    CNN and explains the method to estimate fruit diameter from amodal masks. Section
    3 presents the fruit detection and sizing results, analyses the fruit sizing performance
    at different levels of fruit visibility, different detection confidences and different
    growth stages, and evaluates a case study which aims to estimate the mean fruit
    diameter per tree in a different apple variety and different growth stages. Section
    4 discusses the results and compares them to other methods from the state of the
    art. Finally, the main conclusions and future works are commented on in Section
    5. 2. Materials and methods 2.1. Dataset Two different datasets were collected
    and used in this work. The first set was used to train, validate and test the
    proposed method, while the second was used as a case study carried out in a different
    orchard and under different conditions to those used to develop the method. The
    first set consisted of 3925 annotated RGB-D images acquired in a Fuji apple orchard
    located in Agramunt (Catalonia, Spain). Data was collected at two different growth
    stages: in mid-July, corresponding to growth stage BBCH77 (Meier, 2001) when apples
    were green and about 70% of their final size (Fig. 2a.left); and in the first
    week of October, corresponding to growth stage BBCH85 when apples were at an advanced
    ripening stage (Fig. 2a.right). Raw images were taken with a handheld EOS 60D
    DSLR camera (Canon Inc. Tokyo, Japan) equipped with a 5184 3456 pixels CMOS APS-C
    sensor. Consecutive photographs were taken with an overlap higher than 75% to
    facilitate camera alignment and subsequently estimate the images depth maps (Fig.
    3b) by applying SfM and MVS using Agisoft Metashape software (Agisoft LLC, St.
    Petersburg, Russia, v1.6.4.). After generating the depth maps, the RGB-D images
    used in this work were generated by cropping raw image patches of 1024 1024 pixels
    (Fig. 3), obtaining a total of 1560 images from the BBCH77 growth stage and 2365
    images from the BBCH85 growth stage. Download : Download high-res image (678KB)
    Download : Download full-size image Fig. 2. a) Sample images from the dataset
    used to train, validate and test the methodology. Data acquired in a Fuji apple
    orchard at two growth stages: BBCH77 and BBCH85. b) Sample images from the case
    study carried out in an Elstar apple orchard at four different growth stages:
    BBCH75, BBCH77, BBCH78 and BBCH85. Download : Download high-res image (372KB)
    Download : Download full-size image Fig. 3. Example of an RGB-D image from the
    Fuji dataset. a) Colour image (RGB). b) Depth image (D). All apple instances visible
    in the images were annotated with two ground truth masks: modal and amodal. Modal
    masks include the pixels of the images belonging to the visible, modal, part of
    each apple (Fig. 1b), while the amodal masks refer to the visible and occluded
    part of each apple (Fig. 1c). The modal segmentation ground truth was manually
    annotated using the VIA annotator software (Dutta and Zisserman, 2019). The amodal
    ground truth annotation was based on the 3D tree models generated using SfM and
    MVS (same procedure than the explained for generating depth images). The complete
    3D model of partially occluded apples was obtained by fitting a sphere of diameter
    equal to the apple size following the procedure described in Gené-Mola et al.
    (2021). This complete 3D representation of apples was projected onto the image
    plane following the pinhole camera model, obtaining the corresponding amodal masks.
    Finally, the projected masks were manually corrected and refined (if necessary)
    using the VIA annotator software (Dutta and Zisserman, 2019). Apple ground truth
    diameter was manually measured in the field using a Vernier calliper. Since apples
    are not perfectly spherical, the ground truth diameter was considered the major
    axis. Each apple measure was assigned to an apple identification number (appleID)
    to have a pairwise correspondence between the measurements and the image annotations.
    This data annotation resulted in a total of 5837 apple instances annotated in
    BBCH77 images with a mean apple diameter of 54.0 mm (from 26.9 mm to 71.0 mm)
    and a total of 9498 apple instances annotated in BBCH85 images with a mean apple
    diameter of 77.4 mm (from 43.6 mm to 94.8 mm) (Fig. 4a). This dataset was randomly
    split into training (2304 images, of which 1036 from BBCH77 and 1268 from BBCH85),
    validation (814 images, of which 275 from BBCH77 and 539 from BBCH85) and test
    (807 images, of which 249 from BBCH77 and 558 from BBCH85) sets, obtaining approximately
    60%, 20% and 20% of apples instances on each set, respectively. As it can be observed
    in Fig. 4, all dataset splits (training, validation and test) contain data from
    both maturity stages, of different fruit size and with different fruit visibilities.
    The dataset split was performed randomly, obtaining in each partition a similar
    distribution of diameters (Fig. 4.b) and apples visibilities (Fig. 4.d) than in
    the original dataset. The dataset has been made publicly available at https://github.com/GRAP-UdL-AT/Amodal_Fruit_Sizing.
    Download : Download high-res image (638KB) Download : Download full-size image
    Fig. 4. a) Stacked histogram of apple diameters at different growth stages. b)
    Stacked histogram of apple diameters at different dataset splits. c) Stacked histogram
    of apple visibilities at different growth stages. d) Stacked histogram of apple
    visibilities at different dataset splits. Growth stages: BBCH85 (red) and BBCH77
    (green). Dataset splits: training (blue), validation (orange) and test (yellow).
    (For interpretation of the references to colour in this figure legend, the reader
    is referred to the web version of this article.) The data used for the case study
    was acquired in an Elstar apple orchard located in Randwijk (the Netherlands).
    Five different trees were imaged at four different dates (Table 1), obtaining
    data at different growth stages: BBCH75, BBCH77, BBCH78 and BBCH85 (Fig. 2b).
    To have a complete representation of trees, images were acquired from both sides
    of the row of trees. This allowed to evaluate the performance of the method (presented
    in Section 3.3) depending on the side from which images were acquired. The RGB-D
    images were obtained following the same procedure as for the previous dataset,
    but this time a Nikon Z6 camera (24.5 MP) was used. This case study consisted
    in measuring the mean diameter of the apples grown in each imaged tree. To evaluate
    the results, the mean diameter ground truth of each tree at each measured date
    was computed by averaging the manual measurement (with a Vernier calliper) of
    15 apple samples randomly selected on each tree. Table 1. Data used in the case
    study: number of trees measured and mean diameter measured at different growth
    stages. Measurement date Growth stage Num. of measured trees Mean diameter 21/06/2019
    BBCH75 2 40.2 mm 03/07/2019 BBCH77 5 46.1 mm 16/07/2019 BBCH78 5 55.3 mm 23/08/2019
    BBCH85 5 72.3 mm 2.2. Deep neural network architecture and training details The
    convolutional neural network (CNN) used in this work is the one implemented by
    Blok et al. (2021). This CNN has the same network architecture as Mask R-CNN (He
    et al., 2017), except that an additional mask head branch was added to perform
    the amodal segmentation task (Fig. 5). Download : Download high-res image (494KB)
    Download : Download full-size image Fig. 5. Architecture of the convolutional
    neural network used for simultaneous modal and amodal mask segmentation. The code
    baseline was the Mask R-CNN architecture from the Detectron2 library (Wu et al.,
    2019). ResNet-101 (He et al., 2016) was used as a backbone network, followed by
    the feature pyramid network (FPN) to extract feature maps at different scales.
    These feature maps were fed into the region proposal network (RPN) to identify
    promising regions of interest (ROIs) that were likely to contain an apple. The
    number of region proposals to be produced by the RPN was set to 512, which proved
    to yield better detection performance than the original number of 256. These ROIs
    were refined by means of the ROI align layer before sending it to the Box Head,
    which performed a regression to obtain the final corners of each bounding box.
    The L1-loss was used to calculate the regression error using the bounding box
    that encapsulated the amodal mask as detection ground truth. This was done because
    the amodal region is, by definition, equal to or larger than the visible region.
    Thus, the modal and the amodal segmentation were applied inside the same amodal
    bounding box. The main contribution of the Mask R-CNN architecture of Blok et
    al. (2021) was the implementation of the two parallel segmentation branches: one
    for the modal (visible) mask and one for the amodal mask. To train the network,
    we applied transfer-learning by initializing the network with the weights of the
    Mask R-CNN network pre-trained on the Microsoft Common Objects in Context (COCO)
    dataset (Lin et al., 2014). Then, the CNN was fine-tuned on the apple dataset
    (Section 2.1) using the stochastic gradient descent optimiser with a momentum
    of 0.9, a weight decay of 0.0001 and a learning rate of 0.02. The image batch
    size was set to 4, limited by the memory capabilities of the GPU that was used
    (NVIDIA GeForce GTX 1080 Ti) which has 11 Gb of memory. Data augmentation was
    applied with random horizontal flip with a probability of 0.5. After the training,
    the validation loss curve was inspected and the weights-file trained at the 3,000th
    iteration was selected to prevent overfitting (the network trained at this iteration
    had the lowest validation loss). Fruit detection performance was evaluated in
    terms of precision (P), recall (R), F1-score and average precision (AP). A detection
    was considered positive if the detection confidence provided by the CNN was higher
    than the confidence threshold set after analyzing the validation results (Section
    3.1). Then, a positive detection was classified as true positive (TP) if the intersection
    over union (IoU) between the ground truth and the detection bounding box was >
    0.5. Following the standard definition of these metrics, P was computed as the
    ratio of TP and the total number of detections and R was computed as the ratio
    of TP with respect to the total number of ground truth annotated apples. The F1-score
    was computed as the harmonic mean of P and R, while the AP was computed as the
    area under the PR curve. The software was written in Python (version 3.0) with
    Pytorch (version 1.12) and Torchvision (version 0.13) as the deep learning libraries.
    The code has been made publicly available jointly with the dataset at https://github.com/GRAP-UdL-AT/Amodal_Fruit_Sizing.
    2.3. From amodal masks to fruit diameter The fruit diameter is extracted using
    both the modal and amodal segmentation of each detected apple. The modal segmentation
    was used to compute the distance from the camera to the fruit (excluding the occluded
    pixels, such as leaves, so that these did not interfere with the distance estimation).
    The distance from the camera to the fruit in millimetres (mm), , is computed as
    the average of the corresponding distances for all pixels in the modal segmentation
    (Eq. (1), where is the value of pixel in the depth image (Fig. 3b). (1) The amodal
    segmentation was used to compute the fruit diameter in pixels. Given the area,
    , as the sum of all pixels in the mask that correspond to each apple in the amodal
    segmentation, the fruit diameter in pixels, , can be calculated from Eq. (2) as:
    (2) The relationship between the fruit diameter in the 2D image (expressed in
    pixels) and the corresponding diameter in the real 3D world (expressed in mm)
    is estimated using a pinhole camera model. Fig. 6 shows a graphical example of
    the pinhole camera model. Let be a representation of a 3D point, the homogeneous
    coordinates of this point on the 2D image using the pinhole camera, and the 3x3
    camera matrix that represents the intrinsic pinhole camera parameters. The relation
    between them is expressed as Eq. (3): (3) Download : Download high-res image (259KB)
    Download : Download full-size image Fig. 6. Representation of image capturing
    using a pinhole camera. The 3D point cloud of an apple tree branch with four apples
    is imaged with a pinhole camera illustrated as a box. The parameters used to convert
    the diameter in pixels (d [px]) into millimetres (D [mm]) are represented: camera
    focal length (f [px]) and distance from the camera to the measured apple (z [mm]).
    In our case, we consider the world origin to be located at the pinhole with no
    rotation and, therefore, the camera matrix can be expressed as Eq, 4, where is
    the focal length (in pixels) and , the pixel coordinates of the centre of the
    image: (4) Knowing the estimated distance from the camera to the apple, , it is
    possible to back project any point in the 2D image to obtain the 3D coordinates
    as Eq.5: (5) From Eq. (5), the fruit diameter in mm, , can be computed from the
    estimation of the diameter of the fruit in pixels in the amodal segmentation:
    (6) The fruit size estimation performance was evaluated in terms of the mean absolute
    error (MAE), the mean bias error (MBE), the mean absolute percentage error (MAPE),
    the root mean square error (RMSE) and the coefficient of determination (R2). The
    MAE was computed by averaging the absolute differences between ground truth and
    estimated diameter. The MBE was computed similarly but without the absolute operator.
    Thus, the MBE sign indicates if the measurement overestimates or underestimates
    the ground truth. To measure the MAPE, first the percentage error committed in
    each estimation was calculated and then all percentage errors were averaged. The
    RMSE was calculated by applying the root square to the average square differences.
    Due to the square operation, this metric penalizes bigger errors. Finally, the
    R2 was measured with the linear regression obtained between the ground truth and
    the estimated diameters. The predicted modal and amodal masks were not only used
    to estimate the diameter, but also to estimate fruit visibility (V) by computing
    the ratio of visible pixels (modal mask area) with respect to the total apple
    pixels (amodal mask area). This feature is used in Section 3.2 to evaluate the
    fruit size estimation at different levels of visibility. 3. Results 3.1. Fruit
    detection and visibility estimation Precision, Recall and F1-score at different
    detection confidence levels in the validation set were used to select the minimum
    detection confidence in order to maximise the F1-score, which was reported for
    a confidence of 0.2 with an F1-score of 0.86 (validation set). Based on these
    validation results, the detection performance in the test dataset was also evaluated
    setting the minimum confidence value of 0.2 (Table 2). Test results were similar
    to the ones obtained in the validation set (F1-score = 0.86 in both cases). The
    model performed slightly better for detection of ripe apples (APBBCH85 = 0.51;
    F1BBCH85 = 0.87) than for detection of green apples (APBBCH77 = 0.44; F1BBCH77
    = 0.84), probably due to the larger colour contrast and the higher portion of
    BBCH85 apples in the training set. Table 2. Fruit detection performance in the
    test dataset in terms of Precision (P), Recall (R), F1-score and average precision
    (AP) at different maturity stages: BBCH77, BBCH85 and BBCH77 + BBCH85. A minimum
    confidence of 0.2 was set to consider a positive detection. Empty Cell BBCH77
    BBCH85 BBCH77 + BBCH85 P 0.90 0.94 0.92 R 0.79 0.80 0.80 F1-score 0.84 0.87 0.86
    AP 0.44 0.51 0.47 The predicted modal and amodal masks were used not only for
    fruit sizing, but also to estimate fruit visibility. Fig. 7 evaluates the linear
    correlation between the ground truth visibility (computed using ground truth masks)
    and the predicted one (computed using fruit detections). Results show a high correlation
    between ground truth and predicted visibility (R2 = 0.93), showing that the proposed
    deep learning model can be used as a reliable method to estimate fruit visibility.
    Download : Download high-res image (369KB) Download : Download full-size image
    Fig. 7. Linear correlation between ground truth (GT) and estimated visibility.
    3.2. Fruit size estimation The fruit size estimation performance was evaluated
    with respect to the visibility percentage and the detection confidence score.
    Fig. 8 represents the 3D plot of the MAE (Z axis) obtained in the validation set
    at different combinations of visibility (Y axis) and detection confidence scores
    (X axis). Results show that both features affected the performance of the measurement,
    with the percentage of visibility having more influence on the measured errors.
    When measuring the size of all detections irrespective of the visibility (Visibility
    > 0%), the detection confidence was useful to identify apples that were likely
    to be wrongly measured. In consequence, the MAE decreased with confidence, from
    MAE = 4.5 mm (confidence > 0) to MAE = 3.0 mm (confidence > 0.99). However, the
    visibility feature showed a higher influence on the MAE, achieving optimal results
    for visibilities higher than 80%, reporting an MAE of 2.2 mm in the validation
    set. Diameter errors increased for visibilities close to 100%. We attribute this
    effect to the low number of samples with visibilities of about 100%, which meant
    that the presence of outliers in this range of visibilities had a high influence
    on MAE results. Download : Download high-res image (253KB) Download : Download
    full-size image Fig. 8. Diameter estimation mean absolute error (MAE) obtained
    in the validation set measuring apples detected with a confidence or visibility
    higher than the specified values in the X and Y axis. Fig. 9 represents fruit
    size distributions obtained at different visibility levels using the validation
    set. In general, even if all the visibility levels are considered (V > 0%), the
    predicted distribution for both datasets fits well to the actual ground truth,
    which shows that the system is already robust with no need for further filtering.
    Nonetheless, higher visibility ensures optimal results, resulting in almost full
    overlaps between predicted and ground truth distributions when the minimum visibility
    threshold is increased. The most accurate overlap between ground truth and the
    automatically measured fruit size distribution was achieved when measuring fruits
    with a visibility higher than 60%. This contrasts with the MAE evaluation, which
    achieved optimal results for visibilities higher than 80%. The authors attribute
    the better distribution for visibilities higher than 60% to the fact that, although
    having a higher MAE, the number of fruits measured is higher and, in consequence,
    better fruit distributions are obtained when having more samples measured. Download
    : Download high-res image (748KB) Download : Download full-size image Fig. 9.
    Comparison between the ground truth diameter distribution (dotted line) and that
    automatically estimated in the validation dataset (solid line) at different visibility
    values: 0% (a), 20% (b), 40% (c), 60% (d) and 80% (e). Green curves refer to the
    diameter distributions at BBCH77 growth stage and red curves refer to the diameter
    distributions at BBCH85 growth stage. (For interpretation of the references to
    colour in this figure legend, the reader is referred to the web version of this
    article.) Table 3 presents the test results after automatically measuring the
    visibility and discarding the measurement of fruits detected with an estimated
    visibility lower than 60%, which was the visibility percentage that obtained the
    best fruit size distributions in the validation set (Fig. 9). The proposed method
    reported an MAE of 2.93 mm. The negative MBE in all columns denotes that the model
    has a tendency to underestimate the final diameter. However, even the highest
    error (−0.54 mm) is small enough to be negligible for all practical purposes.
    The mean error was proportional to the fruit size, obtaining lower errors for
    smaller apples. In consequence, the percentage error reported similar results
    (MAPE ∼ 4%) at both maturity stages. This linear error propagation is explained
    by Eq. (6), which applies a linear operation to convert the diameter from pixels
    to mm. Table 3. Evaluation of the fruit diameter estimation in the test dataset
    in terms of MAE, MBE, MAPE and RMSE obtained at different growth stages (BBCH77
    and BBCH85). Results were obtained by measuring apples automatically detected
    with a visibility higher than 60%. Empty Cell BBCH77 BBCH85 BBCH77 + BBCH85 MAE
    (mm) 2.05 3.34 2.93 MBE (mm) −0.54 −0.02 −0.19 MAPE (%) 3.79 4.27 4.19 RMSE (mm)
    2.80 4.59 4.14 Fig. 10 shows that good correlations (R2 > 0.8) between predicted
    and ground truth diameters were achieved for all levels of visibility, but even
    higher correlations were reported when the minimum visibility was increased. At
    very high visibility values the coefficient of determination started to decrease.
    This effect is a consequence of the small number of samples evaluated at high
    visibility intervals, because the presence of outlier estimations on which the
    diameter or visibility was wrongly predicted has more influence to the correlation
    when evaluating a small number of samples (as it is the case in high visibility
    intervals). Download : Download high-res image (140KB) Download : Download full-size
    image Fig. 10. Evolution of the coefficient of determination (R2) (black line,
    left axis) and the percentage of measured apples (blue dashed line, right axis)
    depending on the visibility threshold used to discard the most occluded apples
    in the validation set. (For interpretation of the references to colour in this
    figure legend, the reader is referred to the web version of this article.) Fig.
    11 plots the linear correlation between the predicted diameter and the ground
    truth diameter for all apples detected in the test dataset (Fig. 11a) and for
    apples detected with a visibility higher than 60% (Fig. 11b). The predicted samples
    fit better to the ground truth when limiting the measurement to apples detected
    with a visibility higher than 60% (R2 = 0.91), although strong correlation (R2
    = 0.81) was also obtained when measuring all detected samples. Close visual inspection
    shows two main clusters, which correspond to the different datasets (ripe and
    not ripe apples). Download : Download high-res image (457KB) Download : Download
    full-size image Fig. 11. Scatter plot and linear correlation between the ground
    truth (GT) diameter and the automatically measured diameter. (a) All apples detected
    in the test set. (b) Apples detected in the test set with a visibility higher
    than 60%. In terms of computational speed, the average processing time per image
    in the test set was 0.830 s/img (frame rate of 1.205 img/s) using a NVIDIA GeForce
    GTX 1080 Ti GPU. This processing time was distributed as follows: 30.2% of the
    time was allocated for fruit detection (0.251 s/img), 32.5% for fruit sizing (0.270
    s/img), and 37.3% (0.309 s/img) for other processing tasks such as image reading,
    CPU and GPU data transferring and saving results. For a qualitative evaluation,
    Fig. 12 presents fruit detection and size estimation results in image examples
    from the test set. Modal masks are solid coloured while amodal masks are coloured
    with a certain amount of transparency. The fruit visibility was automatically
    estimated based on modal and amodal detections, and only those fruits presenting
    a visibility higher than 60% were measured. Estimated diameters are written in
    white, while the ground truth is written above in green. The images included in
    this figure were selected in order to show when the method succeeds and when it
    fails: the first row (images a and b) contains the two highest scoring images
    (MAE < 1 mm), the second (images c and d) presents two intermediate scoring images
    (MAE of 2.2 mm) and the final row (images e and f) the two worst (MAE > 5 mm).
    In all cases almost all the apples were detected, but the highest diameter errors
    were obtained for those detections with errors in the modal and amodal mask shapes,
    or apple clusters that were detected with a unique detection. Download : Download
    high-res image (837KB) Download : Download full-size image Fig. 12. Fruit detection
    and sizing results. Predicted diameters are provided for detections with an estimated
    visibility higher than 60%. Fruit size predictions are written in white and the
    ground truth in green. First row (a, b) contains examples of the best size estimation
    result, the second row (c, d) shows two intermediate scoring images and the third
    row (e, f) shows the two images with the worst estimations. (For interpretation
    of the references to colour in this figure legend, the reader is referred to the
    web version of this article.) 3.3. Case study: Testing the trained model in a
    different apple variety and for different growth stages To evaluate the robustness
    of the method in a different scenario, the model trained with the Fuji dataset
    was used to monitor the fruit growth of 5 Elstar trees at different growth stages.
    The apple mean diameter per tree was estimated on different dates using the presented
    method, and the results were compared to the measures carried out by the farmer.
    Table 4 presents the differences between the manual estimation, carried out by
    the farmer, and our predictive method when measuring the fruits from the east,
    west and both (east and west) sides of the row of trees. Although the neural network
    was not trained with the same apple variety as the one used in this case study,
    the model generalised well and was able to estimate the mean diameter with an
    MAE of 3.09 mm and 5.23 mm from the west and east row side, respectively, resulting
    in an average MAE of 4.17 mm. This error is 1.24 mm higher than the one obtained
    in the Fuji dataset (Section 3.2). The authors attribute this difference to three
    main reasons: 1) the network was not trained on images with Elstar apples, and
    consequently the detection performance is less accurate; 2) the Elstar trees had
    a denser foliage, which increases the chance of fruit occlusions; 3) part of the
    error was committed with the manual measurement, due to the small number of samples
    that were manually measured with respect to the total amount of fruits in the
    trees. In terms of bias error, the MBE was negative, confirming that the method
    tends to underestimate the actual fruit diameter. The authors attribute this underestimation
    of the diameter to the fact that the ground truth was obtained by measuring the
    major axis, whereas the method estimates the average apple diameter. Finally,
    in terms of R2, the results showed a similar performance to those for the Fuji
    dataset, which shows that, despite a higher error in terms of MAE, there is still
    a high correlation between the manual measurements and the estimated predictions.
    Table 4. MAE, MBE, MAPE, RMSE, R2 obtained in the case study dataset when measuring
    apple mean diameter per tree using images from the west, east, and west + east
    sides of the row of trees. Empty Cell East West East + West MAE (mm) 5.23 3.09
    4.17 MBE (mm) −4.05 −2.73 −3.50 MAPE (%) 9.55 5.65 7.61 RMSE (mm) 6.27 4.48 5.15
    R2 (mm) 0.86 0.92 0.91 This case study was processed in a computing server equipped
    with an NVIDIA GeForce GTX 1080 Ti GPU. The total processing time per image was
    0.865 s/img (processing frame rate of 1.156 img/s), of which 37.8% of this time
    (0.327 s/img) was allocated for fruit detection, modal and amodal segmentation
    tasks, 26.7% (0.231 s/img) was required for fruit sizing and occlusion estimation,
    and the other 35.5% (0.307 s/img) was required for other image processing tasks
    such as RGB and depth images reading, data transfer between CPU and GPU and saving
    the results. These processing times are similar to those reported in Section 3.2
    for Fuji apple detection and sizing. 4. Discussion Regarding the fruit detection
    task, the results showed a similar performance to other state-of-the-art works
    based on deep learning methods which reported F1-score results between 0.73 and
    0.97 (Koirala et al., 2019). Fruit detection results were robust at different
    growth stages, although slightly better for ripe apples (F1-score = 0.87) than
    for green apples (F1-score = 0.84). The authors attribute the better detection
    of ripe fruits to the fact that they are bigger and with a different colour to
    the background (green leaves), which makes ripe fruits easy to differentiate.
    Tian et al. (2019) also experienced this behaviour, obtaining an F1-score of 0.78
    and 0.81 when detecting young and ripe apples, respectively. The main contribution
    and novelty of this work is the use of amodal instance segmentation to predict
    the apple shapes (masks) even in the presence of occlusions. The results show
    that the CNN was able to robustly estimate the actual shape of fruits that were
    partially occluded by other elements such as leaves, trunks or branches, or that
    were placed at the image edges (Fig. 11). Amodal masks were used to estimate fruit
    diameter, giving an MAE error lower than 4.5 mm in the validation set irrespective
    of fruit visibility and the detection confidence. In addition, the modification
    of the Mask R-CNN architecture to simultaneously predict modal and amodal masks
    allowed the method to estimate the percentage of occlusion of each detected apple,
    showing a coefficient of determination of R2 = 0.93 between the predicted and
    the ground truth visibility. These results are comparable with those obtained
    in Gené-Mola et al. (2021) using shape fitting methods in 3D point clouds. However,
    the method presented in the present paper has the advantage of being designed
    for 2D images, which allow higher data acquisition and inference speeds. In previous
    research, Wang et al. (2017) demonstrated that fruits from the inner and outer
    part of the canopy had similar mass. This fact suggests that, to measure the fruit
    size distribution and the average size it is sufficient to measure a representative
    sample of fruits, instead of measuring all fruits on the tree. Thus, to select
    the best candidate detections to be measured two approaches were tested: 1) only
    measure the fruits that were detected with higher detection confidence; 2) only
    measure the fruits that were detected with higher visibility. When measuring the
    fruits detected with higher detection confidence (confidence > 0.99) the MAE error
    decreased to 3.0 mm. Better results were reported when limiting the measurement
    to fruits detected with higher visibility (V > 80%), which gave MAE errors of
    2.2 mm in the validation set. While the best MAE results were reported when limiting
    the measurement to the most visible fruits (V > 80%), the best fruit distribution
    estimations were achieved for visibility percentages higher than 60% (Fig. 9).
    This happened because the small number of fruits with visibilities higher than
    80% was not as representative as the number of fruits visible with a percentage
    higher than 60%. Validation results allowed us to identify the optimal parameters
    to be used. These parameters were applied to evaluate the method using the test
    dataset, which showed an MAE of 2.93 mm measuring fruit diameters. This is considered
    an accurate result compared with other state-of-the-art results that measured
    fruit size in similar conditions and achieved MAE values of between 3.7 mm and
    12.4 mm (Gené-Mola et al., 2021, Rakun et al., 2019, Tsoulias et al., 2020). Other
    works from the literature have also reported similar performances, or even better,
    but were studied under different conditions. For instance, Wang et al. (2020)
    reported an MAE error of 0.9 mm, but their study was limited to fully visible
    fruits that were manually selected. Grilli et al. (2021) obtained an RMSE of <
    1 mm and 4 mm when measuring fruits of a synthetic and a laboratory dataset, respectively,
    but they did not provide results of their fruit sizing method evaluated in commercial
    orchard conditions. Finally, the proposed method was tested in a case study to
    measure the mean apple diameters of different trees at different growth stages.
    Although this case study was carried out in a different field and with a different
    apple variety to the one used to train the CNN, the network was able to generalise
    and successfully detect and measure Elstar apples at different growth stages.
    An MAE of 4.17 mm and an R2 of 0.91 were obtained between the mean diameters measured
    by the farmer and those automatically measured with our method. The results show
    better predictions measuring fruits with images acquired from the west side of
    the row of trees than from the east side. The authors attribute this difference
    to the fact that fruits from the west side were more visible than fruits grown
    on the east side. This higher visibility could be an effect of different canopy
    structure in both sides due to the different light interception capacity between
    east and west canopy sides (Rom, 1991). Future works should analyse if this behaviour
    is general for other orchards or it is a characteristic of the field where the
    measurements were carried out. The depth images used in this work were obtained
    with SfM and MVS techniques, which limits the data acquisition efficiency due
    to the number of images required to generate high quality depth maps and the computational
    cost of SfM and MVS algorithms. The use of commercial RGB-D sensors would facilitate
    data acquisition. However, a further performance assessment of the proposed method
    would be required since RGB-D sensors usually provide depth images with lower
    accuracy (Gené-Mola et al., 2020). In terms of inference speed, the CNN had an
    inference speed of 0.251 s/img (processed with an NVIDIA GeForce GTX 1080 Ti GPU),
    while the sizing task was performed in 0.270 s/img. These results show that, even
    with the addition of the amodal head to the Mask R-CNN architecture (Fig. 5),
    the CNN remains computationally efficient, and the method could be deployed in
    commercial orchards for fruit detection, robotic fruit picking and sizing tasks.
    5. Conclusions This work presented a novel approach to estimate the size of partially
    occluded apples by combining modal and amodal instance segmentation in RGB-D images.
    The results show that the method is efficient and robust for fruit detection and
    size estimation tasks at different growth stages and with different apple varieties
    (Fuji and Elstar). The fruit detection task performed slightly better for ripe
    apples than for green ones as ripe apples are larger and have a different colour
    to the background. In contrast, the fruit sizing task reported lower errors for
    green apples than for ripe ones as the sizing error is proportional to apple size
    due to the linear error propagation when converting the estimated diameter from
    pixels to mm. Besides the fruit detection and sizing tasks, the method was also
    effective for estimating the percentage of visibility of fruits, presenting a
    coefficient of determination of R2 = 0.93 between ground truth and estimated visibility.
    From these results, an analysis of the fruit sizing performance at different visibility
    intervals showed that the percentage of visibility is a good confidence parameter
    of diameter estimation. Thus, the estimated visibility allowed to discard highly
    occluded apples and estimate the fruit size by only considering those that are
    likely to be better measured (the most visible). In consequence, the diameter
    MAE error decreased from 4.5 mm to 2.93 mm when discarding the most occluded apples.
    A case study carried out in a different orchard than the one used for training
    the CNN showed that the model generalizes well with another apple variety and
    other growth stages, obtaining a coefficient of determination of R2 = 0.91 between
    the ground truth and the estimated diameter irrespective of the fruit variety
    and growth stage. In terms of processing time, the fruit detection and sizing
    task required an average of 0.521 s/image. From this, it is concluded that the
    method is computationally efficient to be applied in commercial orchards. The
    main limitation of this study is that it was carried out with depth images acquired
    with photogrammetry, which limit the data acquisition efficiency. Future works
    should evaluate the performance of the method with commercial RGB-D sensors, which
    would facilitate data collection. In addition, future works should consider extending
    this research to measuring the size of non-spherical fruits such as pears. CRediT
    authorship contribution statement Jordi Gené-Mola: Conceptualization, Methodology,
    Software, Formal analysis, Investigation, Data curation, Writing – original draft,
    Visualization. Mar Ferrer-Ferrer: Methodology, Software, Investigation, Data curation,
    Writing – original draft. Eduard Gregorio: Investigation, Writing – original draft,
    Supervision, Project administration. Pieter M. Blok: Software, Writing – original
    draft. Jochen Hemming: Supervision, Writing – original draft. Josep-Ramon Morros:
    Conceptualization, Methodology, Software, Writing – original draft. Joan R. Rosell-Polo:
    Investigation, Data curation, Writing – original draft. Verónica Vilaplana: Conceptualization,
    Writing – review & editing. Javier Ruiz-Hidalgo: Conceptualization, Methodology,
    Formal analysis, Writing – original draft, Supervision. Declaration of Competing
    Interest The authors declare that they have no known competing financial interests
    or personal relationships that could have appeared to influence the work reported
    in this paper. Acknowledgements This work was partly funded by the Departament
    de Recerca i Universitats de la Generalitat de Catalunya (grant 2021 LLAV 00088),
    the Spanish Ministry of Science, Innovation and Universities (grants RTI2018-094222-B-I00
    [PAgFRUIT project], PID2021-126648OB-I00 [PAgPROTECT project] and PID2020-117142GB-I00
    [DeeLight project] by MCIN/AEI/10.13039/501100011033 and by “ERDF, a way of making
    Europe”, by the European Union). The work of Jordi Gené Mola was supported by
    the Spanish Ministry of Universities through a Margarita Salas postdoctoral grant
    funded by the European Union - NextGenerationEU. We would also like to thank Nufri
    (especially Santiago Salamero and Oriol Morreres) for their support during data
    acquisition, and Pieter van Dalfsen and Dirk de Hoog from Wageningen University
    & Research for additional data collection used in the case study. Data availability
    The code and the dataset used to evaluate the method have been made publicly available
    at https://github.com/GRAP-UdL-AT/Amodal_Fruit_Sizing. References Anderson et
    al., 2019 N.T. Anderson, J.P. Underwood, M.M. Rahman, A. Robson, K.B. Walsh Estimation
    of fruit load in mango orchards: tree sampling considerations and use of machine
    vision and satellite imagery Precis. Agric., 20 (2019), pp. 823-839, 10.1007/s11119-018-9614-1
    View in ScopusGoogle Scholar Blok et al., 2021 P.M. Blok, E.J. van Henten, F.K.
    van Evert, G. Kootstra Image-based size estimation of broccoli heads under varying
    degrees of occlusion Biosyst. Eng., 208 (2021), pp. 213-233, 10.1016/J.BIOSYSTEMSENG.2021.06.001
    View PDFView articleView in ScopusGoogle Scholar Dutta and Zisserman, 2019 Dutta,
    A., Zisserman, A., 2019. The VIA Annotation Software for Images, Audio and Video,
    in: Proceedings of the 27th ACM International Conference on Multimedia. ACM, New
    York, NY, USA. https://doi.org/10.1145/3343031.3350535. Google Scholar Gan et
    al., 2022 H. Gan, M. Ou, C. Li, X. Wang, J. Guo, A. Mao, M. Camila Ceballos, T.D.
    Parsons, K. Liu, Y. Xue Automated detection and analysis of piglet suckling behaviour
    using high-accuracy amodal instance segmentation Comput. Electron. Agric., 199
    (2022), Article 107162, 10.1016/j.compag.2022.107162 View PDFView articleView
    in ScopusGoogle Scholar Gené-Mola et al., 2020 J. Gené-Mola, J. Llorens, J.R.
    Rosell-Polo, E. Gregorio, J. Arnó, F. Solanelles, J.A. Martínez-Casasnovas, A.
    Escolà Assessing the performance of rgb-d sensors for 3d fruit crop canopy characterization
    under different operating and lighting conditions Sensors (Switzerland), 20 (2020),
    p. 7072, 10.3390/s20247072 Google Scholar Gené-Mola et al., 2021 J. Gené-Mola,
    R. Sanz-Cortiella, J.R. Rosell-Polo, A. Escolà, E. Gregorio In-field apple size
    estimation using photogrammetry-derived 3D point clouds: comparison of 4 different
    methods considering fruit occlusions Comput. Electron. Agric., 188 (2021), Article
    106343, 10.1016/j.compag.2021.106343 View PDFView articleView in ScopusGoogle
    Scholar Gongal et al., 2018 A. Gongal, M. Karkee, S. Amatya Apple fruit size estimation
    using a 3D machine vision system Inf. Process. Agric., 5 (2018), pp. 498-503,
    10.1016/j.inpa.2018.06.002 View PDFView articleView in ScopusGoogle Scholar Gregorio
    and Llorens, 2021 Gregorio, E., Llorens, J., 2021. Sensing Crop Geometry and Structure,
    in: Kerry, R., Escola, A. (Eds.), Sensing Approaches for Precision Agriculture.
    Progress in Precision Agricuture. Springer, Cham. https://doi.org/10.1007/978-3-030-78431-7_3.
    Google Scholar Grilli et al., 2021 E. Grilli, R. Battisti, F. Remondino An advanced
    photogrammetric solution to measure apples Remote Sens., 13 (2021), 10.3390/rs13193960
    Google Scholar He et al., 2017 He, K., Gkioxari, G., Dollar, P., Girshick, R.,
    2017. Mask R-CNN. Proc. IEEE Int. Conf. Comput. Vis. 2017-Octob, 2980–2988. https://doi.org/10.1109/ICCV.2017.322.
    Google Scholar He et al., 2016 K. He, X. Zhang, S. Ren, J. Sun Deep residual learning
    for image recognition Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit.,
    770–778 (2016), 10.1109/CVPR.2016.90 Google Scholar Koirala et al., 2019 A. Koirala,
    K.B. Walsh, Z. Wang, C. McCarthy Deep learning – Method overview and review of
    use for fruit detection and yield estimation Comput. Electron. Agric., 162 (2019),
    pp. 219-234, 10.1016/j.compag.2019.04.017 View PDFView articleView in ScopusGoogle
    Scholar Kootstra et al., 2021 G. Kootstra, X. Wang, P.M. Blok, J. Hemming, E.
    van Henten Selective Harvesting Robotics: Current Research, Trends, and Future
    Directions Curr. Robot. Reports, 2 (2021), pp. 95-104, 10.1007/s43154-020-00034-1
    Google Scholar Li and Malik, 2016 Li, K., Malik, J., 2016. Amodal Instance Segmentation,
    in: Leibe, B., Matas, J., Sebe, N., Welling, M. (Eds.), ECCV 2016. Lecture Notes
    in Computer Science, Vol 9906. Springer, Cham. Springer, pp. 677–693. https://doi.org/10.1007/978-3-319-46475-6_42.
    Google Scholar Lin et al., 2014 T.Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona,
    D. Ramanan, P. Dollár, C.L. Zitnick Microsoft COCO: Common objects in context
    European Conference on Computer Vision. (2014), pp. 740-755, 10.1007/978-3-319-10602-1_48
    View in ScopusGoogle Scholar Longchamps et al., 2022 L. Longchamps, B. Tisseyre,
    J. Taylor, L. Sagoo, A. Momin, S. Fountas, L. Manfrini, Y. Ampatzidis, J.K. Schueller,
    R. Khosla Yield sensing technologies for perennial and annual horticultural crops:
    a review Precis. Agric., 23 (2022), pp. 2407-2448, 10.1007/s11119-022-09906-2
    View in ScopusGoogle Scholar Lu et al., 2022 S. Lu, W. Chen, X. Zhang, M. Karkee
    Canopy-attention-YOLOv4-based immature/mature apple fruit detection on dense-foliage
    tree architectures for early crop load estimation Comput. Electron. Agric., 193
    (2022), Article 106696, 10.1016/J.COMPAG.2022.106696 View PDFView articleView
    in ScopusGoogle Scholar Meier, 2001 U. Meier Growth stages of mono- and dicotyledonous
    plants BBCH Monograph (2001), 10.5073/bbch0515 Google Scholar Moltó et al., 1992
    E. Moltó, F. Plá, F. Juste Vision systems for the location of citrus fruit in
    a tree canopy J. Agric. Eng. Res., 52 (1992), pp. 101-110, 10.1016/0021-8634(92)80053-U
    View PDFView articleView in ScopusGoogle Scholar Qi et al., 2019 Qi, L., Jiang,
    L., Liu, S., Shen, X., Jia, J., 2019. Amodal instance segmentation with kins dataset.
    Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. 2019-June, 3009–3018.
    https://doi.org/10.1109/CVPR.2019.00313. Google Scholar Rakun et al., 2019 J.
    Rakun, D. Stajnko, D. Zazula Plant size estimation based on the construction of
    high-density corresponding points using image registration Comput. Electron. Agric.,
    157 (2019), pp. 288-304 View PDFView articleView in ScopusGoogle Scholar Robinson
    et al., 2008 Robinson, T., Osborne, J., Fargione, M., 2008. Pruning, fertilization,
    chemical thinning and irrigation affect “Gala” apple fruit size and crop value.
    Acta Hortic. 772, 135–141. https://doi.org/10.17660/ActaHortic.2008.772.16. Google
    Scholar Rom, 1991 C.R. Rom Light Thresholds for Apple Tree Canopy Growth and Development
    HortScience, 26 (1991), pp. 989-992, 10.21273/hortsci.26.8.989 Google Scholar
    Santos et al., 2020 T.T. Santos, L.L. de Souza, A.A. dos Santos, S. Avila Grape
    detection, segmentation, and tracking using deep neural networks and three-dimensional
    association Comput. Electron. Agric., 170 (2020), Article 105247, 10.1016/j.compag.2020.105247
    View PDFView articleView in ScopusGoogle Scholar Slaughter and Harrell, 1987 D.C.
    Slaughter, R.C. Harrell Color vision in robotic fruit harvesting Trans. ASAE,
    30 (4) (1987), pp. 1144-1148 Google Scholar Stajnko et al., 2004 D. Stajnko, M.
    Lakota, M. Hocevar, M. Hočevar Estimation of number and diameter of apple fruits
    in an orchard during the growing season by thermal imaging Comput. Electron. Agric.,
    42 (2004), pp. 31-42, 10.1016/S0168-1699(03)00086-3 View PDFView articleView in
    ScopusGoogle Scholar Tian et al., 2019 Y. Tian, G. Yang, Z. Wang, H. Wang, E.
    Li, Z. Liang Apple detection during different growth stages in orchards using
    the improved YOLO-V3 model Comput. Electron. Agric., 157 (2019), pp. 417-426,
    10.1016/j.compag.2019.01.012 View PDFView articleView in ScopusGoogle Scholar
    Tijskens et al., 2016 L.M.M. Tijskens, T. Unuk, R.C.O. Okello, A.M. Wubs, V. Šuštar,
    D. Šumak, R.E. Schouten From fruitlet to harvest: Modelling and predicting size
    and its distributions for tomato, apple and pepper fruit Sci. Hortic. (Amsterdam),
    204 (2016), pp. 54-64, 10.1016/j.scienta.2016.03.036 View PDFView articleView
    in ScopusGoogle Scholar Tsoulias et al., 2020 N. Tsoulias, D.S. Paraforos, G.
    Xanthopoulos, M. Zude-Sasse Apple shape detection based on geometric and radiometric
    features using a LiDAR laser scanner Remote Sens., 12 (2020), p. 2481, 10.3390/RS12152481
    View in ScopusGoogle Scholar Wang and He, 2022 D. Wang, D. He Fusion of Mask RCNN
    and attention mechanism for instance segmentation of apples under complex background
    Comput. Electron. Agric., 196 (2022), Article 106864, 10.1016/j.compag.2022.106864
    View PDFView articleView in ScopusGoogle Scholar Wang et al., 2018 Z. Wang, A.
    Koirala, K. Walsh, N. Anderson, B. Verma In field fruit sizing using a smart phone
    application Sensors (Switzerland), 18 (2018), 10.3390/S18103331 Google Scholar
    Wang et al., 2020 D. Wang, C. Li, H. Song, H. Xiong, C. Liu, D. He Deep learning
    approach for apple edge detection to remotely monitor apple growth in orchards
    IEEE Access, 8 (2020), pp. 26911-26925, 10.1109/ACCESS.2020.2971524 View in ScopusGoogle
    Scholar Wang et al., 2017 Z. Wang, K.B. Walsh, B.B. Verma On-tree mango fruit
    size estimation using RGB-D images Sensors, 17 (2017), p. 2738, 10.3390/s17122738
    View in ScopusGoogle Scholar Wu et al., 2019 Y. Wu, A. Kirillov, F. Massa, W.-Y.
    Lo, R. Girshick Detectron2 [WWW Document] GitHub Repos. (2019) accessed 2.10.22
    Google Scholar Zhou et al., 2012 R. Zhou, L. Damerow, Y. Sun, M.M. Blanke Using
    colour features of cv. “Gala” apple fruits in an orchard in image processing to
    predict yield Precis. Agric., 13 (2012), pp. 568-580, 10.1007/s11119-012-9269-2
    View in ScopusGoogle Scholar Cited by (11) AmodalAppleSize_RGB-D dataset: RGB-D
    images of apple trees annotated with modal and amodal segmentation masks for fruit
    detection, visibility and size estimation 2024, Data in Brief Show abstract A
    plum selection system that uses a multi-class Convolutional Neural Network (CNN)
    2023, Journal of Agriculture and Food Research Show abstract Assessing automatic
    data processing algorithms for RGB-D cameras to predict fruit size and weight
    in apples 2023, Computers and Electronics in Agriculture Show abstract Simultaneous
    fruit detection and size estimation using multitask deep neural networks 2023,
    Biosystems Engineering Show abstract Artificial Marker to Predict (Banganapalle)
    Mango Fruit Size at Multi-Targets of an Image Using Semantic Segmentation 2024,
    IEEE Access Analysis of Fruit Images With Deep Learning: A Systematic Literature
    Review and Future Directions 2024, IEEE Access View all citing articles on Scopus
    © 2023 The Author(s). Published by Elsevier B.V. Recommended articles Relationship
    between yield and tree growth in almond as influenced by nitrogen nutrition Scientia
    Horticulturae, Volume 321, 2023, Article 112353 Leire Sandonís-Pozo, …, Miquel
    Pascual View PDF Wizard: Unsupervised goats tracking algorithm Computers and Electronics
    in Agriculture, Volume 209, 2023, Article 107831 Jehan-Antoine Vayssade, …, Mathieu
    Bonneau View PDF Obscured tree branches segmentation and 3D reconstruction using
    deep learning and geometrical constraints Computers and Electronics in Agriculture,
    Volume 210, 2023, Article 107884 Eugene Kok, …, Chao Chen View PDF Show 3 more
    articles Article Metrics Citations Citation Indexes: 7 Captures Readers: 28 View
    details About ScienceDirect Remote access Shopping cart Advertise Contact and
    support Terms and conditions Privacy policy Cookies are used by this site. Cookie
    settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier
    B.V., its licensors, and contributors. All rights are reserved, including those
    for text and data mining, AI training, and similar technologies. For all open
    access content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Computers and Electronics in Agriculture
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Looking behind occlusions: A study on amodal segmentation for robust on-tree
    apple fruit size estimation'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Li Q.
  - Li M.
  - Yang W.
  - Sun H.
  - Zhang Y.
  citation_count: '1'
  description: The current measurement of soil properties can be limited in the variable-rate
    fertilizer application using soil analysis, due to the labor-intensive and time-consuming
    in the laboratory. Rapid, non-destructive soil detection is highly required to
    be developed using visible-infrared spectroscopy. Among them, Raman spectroscopy
    can be used to detect the vibrational properties of molecules, due to the fast,
    non-invasive, small sample treatment, and free interference from water in various
    fields. Nevertheless, incident light is also required to induce the Raman scattering,
    in order to compensate for the information with infrared spectroscopy. Therefore,
    the Raman scattering measurement can be widely used in the composition and dynamic
    process of soil minerals, bacteria colonies, and humic fraction in soil sensing.
    However, it is still lacking on the fluorescence effect of soil in the sensing
    of soil nutrients, which can weaken the Raman signals and the information extraction
    for the quantitative analysis. Raman spectroscopy has been introduced into some
    novel measurement techniques to improve the signal-to-noise ratio in recent years,
    including the shifted excitation Raman difference spectroscopy (SERDS), confocal
    Raman microscope, and surface-enhanced Raman spectroscopy (SERS). Meanwhile, both
    aliphatic and aromatic compounds are Raman active in the quantitative and qualitative
    detection of soil organic matter (SOM). Moreover, many phosphorous compounds in
    soil are also Raman active, leading to low prediction accuracy using visible-near
    infrared spectroscopy. In this review, the research progress was proposed on the
    Raman spectroscopy in the rapid detection of soil nutrients, together with the
    technical means in suppressing soil fluorescence interference to obtain high-resolution
    Raman signals. In the detection of SOM, the fusion of infrared and Raman spectral
    data significantly improved the prediction accuracy of 43% in the root mean square
    error (RMSE). In addition, the SERDS technique was used to detect the SOM of 33
    soil samples. The reconstructed Raman peaks of soil minerals and organic materials
    obtained an excellent prediction accuracy of the SOM, with the determination of
    coefficient R2=0.82, and the residual prediction deviation RPD=1.81. Raman spectroscopy
    was used to detect the water-soluble nitrogen in the soil solution, whereas, the
    SERS was to enhance the Raman peaks. An excellent correlation was obtained between
    the concentration of water-soluble nitrogen and the SERS data (R2=0.91). Research
    showed that Raman spectroscopy can be an effective tool to identify the different
    phosphate species in soil. Wavelet packet decomposition of Raman spectra was used
    to predict the phosphorus concentration in the phosphate-mixed soil with the SOM
    leached, where the accuracy of the regression model reached R2=0.94. Since the
    measurement area of Raman spectroscopy depended mainly on the spot size of the
    laser that irradiated on the sample surface, the spatial variability of the soil
    sample can be difficult to focus on the target substance. The effective Raman
    signal of soil nutrients can be obtained with high spatial resolution while suppressing
    the interferences from the background light. The combination of SERDS and micro-Raman
    technologies can be expected to serve as an in-situ measurement of soil nutrients.
    Reducing the redundant variables is crucial when applying spectral fusion since
    interpretability and reproducibility of the prediction model are paramount in
    the sensor development using Raman spectroscopy.
  doi: 10.11975/j.issn.1002-6819.202205006
  full_citation: '>'
  full_text: '>

    "EI CSA CABI 卓越期刊 CA Scopus CSCD 核心期刊 首页 关于我刊 编委会 投稿指南 期刊浏览 获奖文章 农业工程期刊 期刊订阅 联系我们
    EI收录本刊数据 English 文章导航 >  农业工程学报  > 2023  >  39(7) : 1-9.  > DOI: 10.11975/j.issn.1002-6819.202205006
    引用本文: 李奇辰, 李民赞, 杨玮, 孙红, 张瑶. 拉曼光谱在精细农业土壤成分快速检测中的研究进展[J]. 农业工程学报, 2023, 39(7): 1-9.
    DOI: 10.11975/j.issn.1002-6819.202205006 Citation: LI Qichen, LI Minzan, YANG
    Wei, SUN Hong, ZHANG Yao. Research progress on the rapid detection of soil components
    using Raman spectroscopy: A review[J]. Transactions of the Chinese Society of
    Agricultural Engineering (Transactions of the CSAE), 2023, 39(7): 1-9. DOI: 10.11975/j.issn.1002-6819.202205006
    拉曼光谱在精细农业土壤成分快速检测中的研究进展 李奇辰1,2,  李民赞1,2,  杨玮1,3,  孙红1,3,  张瑶1 1. 中国农业大学智慧农业系统集成研究教育部重点实验室，北京
    100083 2. 中国农业大学烟台研究院，烟台 264003 3. 中国农业大学农业农村部农业信息获取技术重点实验室，北京 100083 基金项目: 国家重点研发计划项目（2022YFD2001501）；国家自然科学基金项目（31971785）；烟台市校地融合发展项目（2020XDRHXMPT35）
    Research progress on the rapid detection of soil components using Raman spectroscopy:
    A review LI Qichen1,2,  LI Minzan1,2,  YANG Wei1,3,  SUN Hong1,3,  ZHANG Yao1
    1. Key Laboratory of Smart Agriculture System Integration of Ministry of Education,
    China Agricultural University, Beijing 100083, China 2. Yantai Institute of China
    Agricultural University, Yantai 264003, China 3. Key Laboratory of Agricultural
    Information Acquisition Technology, Ministry of Agriculture and Rural Affairs,
    China Agricultural University, Beijing 100083, China 摘要 摘要 HTML全文 图(0) 表(0) 参考文献(58)
    相关文章 施引文献(1) 资源附件(0) 摘要: 拉曼光谱利用分子运动对入射光产生非弹性散射的原理对分子成分进行检测，具有受水分干扰小、样本预处理小、与红外光谱信息互补等特点，在土壤成分快速分析方面展现了很大的优势。但是拉曼光谱信号弱，受荧光干扰强，为土壤拉曼信号的有效获取带来困难。为了分析拉曼光谱在土壤成分检测中的应用潜力，该研究综述了移频激发差分拉曼光谱技术、共焦显微拉曼技术以及表面增强技等基于拉曼光谱的土壤成分检测技术，分析了土壤成分拉曼光谱检测的研究进展，并提出进一步研究建议。结果表明：1）脂肪族化合物以及芳香族化合物都具有拉曼活性，为基于拉曼光谱的土壤有机质含量的定性、定量分析提供了理论依据。为了弥补拉曼光谱对有机质整体定量预测精度的不足，采用红外-拉曼光谱融合方式补偿单独拉曼光谱数据中缺失的土壤有机质信息，可显著改善预测精度。2）利用表面增强技术可以增强土壤溶液中可溶性氮与土壤有效氮拉曼特征波峰的强度，获得了良好的定量预测效果，回归模型决定系数R2达到0.91～0.99。3）土壤中很多含磷的化合物都具有拉曼活性，拉曼光谱是识别土壤中不同磷酸盐形态的极其有效的工具，在土壤磷素含量的分析中，应用小波包分解的拉曼光谱对滤除有机质的磷酸盐参杂土壤中磷素浓度进行预测，回归模型精度R2达到0.94。拉曼光谱检测的样本范围取决于激发光照射在样本上的光点尺寸，而土壤样本的空间变异性为聚焦目标物质带来困难。因此，实现现场高分辨率检测的关键是获取有效拉曼信号、同时降低背景信号的干扰。移频激发技术与显微拉曼技术为农田土壤养分的原位测量提供了技术保障。建议：1）采用光谱融合方法提升回归模型的预测精度。2）降低冗余变量，提升模型的可解读性与重现性。3）充分考虑土壤对拉曼光谱的影响，为开发农田现场土壤成分快速监测技术提供参考。   关键词:
    土壤  /  拉曼光谱  /  红外光谱  /  移频激发  /  共焦显微拉曼  /  表面增强拉曼  /  精细农业   Abstract: The current
    measurement of soil properties can be limited in the variable-rate fertilizer
    application using soil analysis, due to the labor-intensive and time-consuming
    in the laboratory. Rapid, non-destructive soil detection is highly required to
    be developed using visible-infrared spectroscopy. Among them, Raman spectroscopy
    can be used to detect the vibrational properties of molecules, due to the fast,
    non-invasive, small sample treatment, and free interference from water in various
    fields. Nevertheless, incident light is also required to induce the Raman scattering,
    in order to compensate for the information with infrared spectroscopy. Therefore,
    the Raman scattering measurement can be widely used in the composition and dynamic
    process of soil minerals, bacteria colonies, and humic fraction in soil sensing.
    However, it is still lacking on the fluorescence effect of soil in the sensing
    of soil nutrients, which can weaken the Raman signals and the information extraction
    for the quantitative analysis. Raman spectroscopy has been introduced into some
    novel measurement techniques to improve the signal-to-noise ratio in recent years,
    including the shifted excitation Raman difference spectroscopy (SERDS), confocal
    Raman microscope, and surface-enhanced Raman spectroscopy (SERS). Meanwhile, both
    aliphatic and aromatic compounds are Raman active in the quantitative and qualitative
    detection of soil organic matter (SOM). Moreover, many phosphorous compounds in
    soil are also Raman active, leading to low prediction accuracy using visible-near
    infrared spectroscopy. In this review, the research progress was proposed on the
    Raman spectroscopy in the rapid detection of soil nutrients, together with the
    technical means in suppressing soil fluorescence interference to obtain high-resolution
    Raman signals. In the detection of SOM, the fusion of infrared and Raman spectral
    data significantly improved the prediction accuracy of 43% in the root mean square
    error (RMSE). In addition, the SERDS technique was used to detect the SOM of 33
    soil samples. The reconstructed Raman peaks of soil minerals and organic materials
    obtained an excellent prediction accuracy of the SOM, with the determination of
    coefficient R2=0.82, and the residual prediction deviation RPD=1.81. Raman spectroscopy
    was used to detect the water-soluble nitrogen in the soil solution, whereas, the
    SERS was to enhance the Raman peaks. An excellent correlation was obtained between
    the concentration of water-soluble nitrogen and the SERS data (R2=0.91). Research
    showed that Raman spectroscopy can be an effective tool to identify the different
    phosphate species in soil. Wavelet packet decomposition of Raman spectra was used
    to predict the phosphorus concentration in the phosphate-mixed soil with the SOM
    leached, where the accuracy of the regression model reached R2=0.94. Since the
    measurement area of Raman spectroscopy depended mainly on the spot size of the
    laser that irradiated on the sample surface, the spatial variability of the soil
    sample can be difficult to focus on the target substance. The effective Raman
    signal of soil nutrients can be obtained with high spatial resolution while suppressing
    the interferences from the background light. The combination of SERDS and micro-Raman
    technologies can be expected to serve as an in-situ measurement of soil nutrients.
    The spectral fusion can be reduced the redundant variable since the interpretability
    and reproducibility of the prediction model are paramount in the sensor development
    using Raman spectroscopy.   Keywords: soil  /  Raman spectroscopy  /  infrared
    spectroscopy  /  shifted excitation Raman difference spectroscopy  /  confocal
    Raman microscope  /  surface-enhanced Raman spectroscopy  /  precision agriculture   We
    recommend Prediction of soil organic matter and cation exchange capacity based
    on spectral similarity measuring Wei Changlong et al., Transactions of the Chinese
    Society of Agricultural Engineering, 2013 Rapid detection of the physicochemical
    properties of honey based on infrared spectroscopy ZHANG Guangqi et al., Transactions
    of the Chinese Society of Agricultural Engineering, 2023 Rapid detection of salbutamol
    in fresh muscle tissues based on surface enhanced Raman spectroscopy Zhai Chen
    et al., Transactions of the Chinese Society of Agricultural Engineering, 2016
    Wavelength variable selection methods for estimation of soil organic matter content
    using hyperspectral technique Yu Lei et al., Transactions of the Chinese Society
    of Agricultural Engineering, 2015 Non-destructive detecting fructose and glucose
    content of honey with Raman spectroscopy Li Shuifang et al., Transactions of the
    Chinese Society of Agricultural Engineering, 2013 Determination of Lead (II) Concentration
    Using Iminodiacetic Acid-Modified Silver Nanoparticles by Highly Sensitive SERS
    Technique Na Li et al., World Scientific Book, 2017 Diffuse transmitted spectroscopy
    in conjunction with spectral peak averaging as a potential tool for noninvasive
    creatinine screening Zvi Hai Barnea et al., World Scientific Book, 2020 Facile
    electrochemical surface-alloying and etching of Au wires to enable high-performance
    substrates for surface enhanced Raman scattering Yawen Zhan et al., Nano Materials
    Science, 2023 A new rapid synthesis of potassium borates by microwave irradiation
    Sibel İla et al., Main Group Chemistry, 2020 Noncovalently copper-porphyrin functionalized
    reduced graphene oxide for sensitive electrochemical detection of dopamine Dong-Lan
    Huang et al., Journal of Porphyrins and Phthalocyanines, 2018 Powered by PDF下载
    ( 1321 KB) XML下载 导出引用 点击查看大图 计量 文章访问数:  262 HTML全文浏览量:  5 PDF下载量:  218 被引次数: 1
    出版历程 收稿日期:  2022-04-30 修回日期:  2022-09-13 发布日期:  2023-04-14 分享 友情链接> Industrial
    Crops and Products Biomass & Bioenergy Biosystems Engineering Aquacultural Engineering
    International Journal of Agricultural and Biological Engineering 版权所有 © 农业工程学报
    京ICP备06025802号-3 地址：北京朝阳区麦子店街41号（100125） 电话：010-59197078/7077/7076 邮箱：tcsae@tcsae.org
    邮件订阅 RSS 今日头条 抖音号 视频号 淘宝 微店 本系统由北京仁和汇智信息技术有限公司开发  "'
  inline_citation: '>'
  journal: Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural
    Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Research progress on the rapid detection of soil components using Raman
    spectroscopy: A review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Adhitya Y.
  - Mulyani G.S.
  - Köppen M.
  - Leu J.S.
  citation_count: '1'
  description: Farming is a fundamental factor driving economic development in most
    regions of the world. As in agricultural activity, labor has always been hazardous
    and can result in injury or even death. This perception encourages farmers to
    use proper tools, receive training, and work in a safe environment. With the wearable
    device as an Internet of Things (IoT) subsystem, the device can read sensor data
    as well as compute and send information. We investigated the validation and simulation
    dataset to determine whether accidents occurred with farmers by applying the Hierarchical
    Temporal Memory (HTM) classifier with each dataset input from the quaternion feature
    that represents 3D rotation. The performance metrics analysis showed a significant
    88.00% accuracy, precision of 0.99, recall of 0.04, F_Score of 0.09, average Mean
    Square Error (MSE) of 5.10, Mean Absolute Error (MAE) of 0.19, and a Root Mean
    Squared Error (RMSE) of 1.51 for the validation dataset, 54.00% accuracy, precision
    of 0.97, recall of 0.50, F_Score of 0.66, MSE = 0.06, MAE = 3.24, and = 1.51 for
    the Farming-Pack motion capture (mocap) dataset. The computational framework with
    wearable device technology connected to ubiquitous systems, as well as statistical
    results, demonstrate that our proposed method is feasible and effective in solving
    the problem’s constraints in a time series dataset that is acceptable and usable
    in a real rural farming environment for optimal solutions.
  doi: 10.3390/s23062951
  full_citation: '>'
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                 Deny Allow selection
    Allow all    Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Sensors All Article Types Advanced   Journals
    Sensors Volume 23 Issue 6 10.3390/s23062951 Submit to this Journal Review for
    this Journal Propose a Special Issue Article Menu Academic Editors Rongxing Lu
    Sajjad Dadkhah Jianting Ning Show more... Subscribe SciFeed Recommended Articles
    Related Info Links More by Authors Links Article Views 1433 Citations 1 Table
    of Contents Abstract Introduction Related Works Problem Definition Materials and
    Methods Results Discussion Conclusions Author Contributions Funding Institutional
    Review Board Statement Informed Consent Statement Data Availability Statement
    Acknowledgments Conflicts of Interest References share Share announcement Help
    format_quote Cite question_answer Discuss in SciProfiles thumb_up Endorse textsms
    Comment first_page settings Order Article Reprints Open AccessArticle IoT and
    Deep Learning-Based Farmer Safety System by Yudhi Adhitya 1,*, Grathya Sri Mulyani
    1, Mario Köppen 1 and Jenq-Shiou Leu 2 1 Department of Computer Science and Systems
    Engineering (CSSE), Graduate School of Computer Science and Systems Engineering,
    Kyushu Institute of Technology, 680-4 Kawazu, Iizuka-shi 820-8502, Fukuoka, Japan
    2 Department of Electronic and Computer Engineering(ECE), National Taiwan University
    of Science and Technology, Taipei City 106, Taiwan * Author to whom correspondence
    should be addressed. Sensors 2023, 23(6), 2951; https://doi.org/10.3390/s23062951
    Submission received: 14 February 2023 / Revised: 2 March 2023 / Accepted: 3 March
    2023 / Published: 8 March 2023 (This article belongs to the Special Issue Security
    and Privacy of the Internet of Things for Industrial Applications) Download keyboard_arrow_down     Browse
    Figures Review Reports Versions Notes Abstract Farming is a fundamental factor
    driving economic development in most regions of the world. As in agricultural
    activity, labor has always been hazardous and can result in injury or even death.
    This perception encourages farmers to use proper tools, receive training, and
    work in a safe environment. With the wearable device as an Internet of Things
    (IoT) subsystem, the device can read sensor data as well as compute and send information.
    We investigated the validation and simulation dataset to determine whether accidents
    occurred with farmers by applying the Hierarchical Temporal Memory (HTM) classifier
    with each dataset input from the quaternion feature that represents 3D rotation.
    The performance metrics analysis showed a significant 88.00% accuracy, precision
    of 0.99, recall of 0.04, F_Score of 0.09, average Mean Square Error (MSE) of 5.10,
    Mean Absolute Error (MAE) of 0.19, and a Root Mean Squared Error (RMSE) of 1.51
    for the validation dataset, 54.00% accuracy, precision of 0.97, recall of 0.50,
    F_Score of 0.66, MSE = 0.06, MAE = 3.24, and = 1.51 for the Farming-Pack motion
    capture (mocap) dataset. The computational framework with wearable device technology
    connected to ubiquitous systems, as well as statistical results, demonstrate that
    our proposed method is feasible and effective in solving the problem’s constraints
    in a time series dataset that is acceptable and usable in a real rural farming
    environment for optimal solutions. Keywords: time series dataset; quaternion;
    hierarchical temporal memory; cascade classifier; probability prediction; farming
    activity monitoring; smart farming 1. Introduction Within the past two decades,
    the Internet of Things (IoT) concept has evolved. IoT-connected devices can exchange
    information, commands, and decisions independently through intelligent networks
    within their ecosystem. The rapid development of IoT is opening up exceptional
    opportunities for various implementation sectors, including agriculture, healthcare,
    and manufacturing [1]. Implementing IoT infrastructure is expected to improve
    efficiency, reduce costs, and save energy, as well as prevent loss and accidents
    and open up new business opportunities. Agriculture sectors frequently disregarded
    business cases for IoT implementation as it requires adapting to well-known farming
    activity [2,3,4]. Nevertheless, due to the remoteness of farming operations, IoT
    implementation proposes the possibility of transforming farmers’ practices. Even
    though this concept has yet to gain widespread acceptance, it is one of the IoT-based
    applications that must be acknowledged. Smart farming will become a significant
    application field in agriculturally-based countries [5,6,7]. Smart farming involves
    applying data and information technology in a complex farming system to be maximized.
    Data, information, and communication technologies are implemented to utilize machinery,
    equipment, and installation of sensors used in agricultural production systems.
    By leveraging the above-mentioned technologies, IoT [8] and cloud computing can
    strengthen the effectiveness and efficiency even further, one with innumerable
    sophisticated sensors, including the implementation of artificial intelligence
    into agriculture [9,10,11,12]. Work involving the management of livestock, tractors,
    and heavy agricultural equipment, exposure to toxic chemicals, or laboring in
    open fields under the sun’s heat or in a closed chamber, all have significant
    risks [13,14,15]. Employment in agriculture requires farm workers to work at elevations
    to finish their jobs. Falls from these elevations are the most expected agricultural
    casualties. Falling from a certain altitude can cause fractures, brain damage,
    and additional severe injuries. Falls, as the leading causes of unintentional
    injuries worldwide, with 37.3 million cases of falls each year, require medical
    attention [16]. Wearable technology appliances that use accelerometers and gyroscopes
    datasets have developed ecosystems and consumers [12,17,18,19,20]. Advanced technology
    gadgets that are linked to specific devices have become ubiquitous in our daily
    lives, ushering in a new trend in the mobile industry. These devices enable data
    generation, enabling the collection of massive quantities of data and information.
    Three angles can represent the 3D rotation [21,22] in studies using the Euler
    angle, which decomposes the rotation within three separate angles. Although using
    Euler angles is a natural step in the process of representing 3D rotations [23,24],
    it can cause difficulties in performing calculations, such as rounding errors
    in the conversion results, which can lead to distortion. More importantly, the
    Euler angle representation needs to be more linear. Farmers are recognizing the
    benefits of advancements in wearable technology, which have promising applications
    in healthcare products, monitoring, and personal health. Wearable technology can
    also be utilized in agriculture [25,26,27] and is expected to prepare preventative
    measurements for diverse categories of casualties in agriculture. Deep learning
    can take advantage of IoT technology implementation. IoT sensors that can provide
    the input data of farmers’ positions and heart rates can be analyzed utilizing
    intelligent algorithms, combining data collected with previous data and training
    models to identify patterns and make predictions about the safety conditions of
    farmers in working environments, as depicted in Figure 1. Figure 1. The Proposed
    farmer safety system in a smart farming environment. To overcome this problem,
    we proposed a quaternion to represent 3D rotation [28] as an input feature. While
    most of the current literature studies use three-dimensional data from accelerometer
    data and gyroscope data for activity prediction, we exploited quaternion as four-dimensional
    data (as a feed input for the Hierarchical Temporal Memory (HTM) classifier).
    We evaluated the approaches of large-scale egocentric datasets and farming pack
    mocap datasets; our proposed method is practical for computational efficiency
    and results. As a result, the primary goal of this study was to evaluate extracted
    quaternion features for hierarchical temporal memory input for accurate activity
    prediction. The general framework for farmer safety systems in the smart farming
    environment is proposed in Figure 1. The farmer’s use of wearable sensor devices
    as an IoT subsystem has the potential to improve data readability in today’s medical
    systems, which can provide substantial sensor tracking of multiple physiological
    functions within the body, as well as cost-effective and high-efficiency services
    in a wide range of fields. These wearable devices generally use the battery as
    their power source and implement various power management strategies to extend
    battery life [29]. Most wearable devices can connect to the internet via Wi-Fi,
    and some even have their own cellular services. Accelerometer data and gyroscope
    data are collected on the device for local processing and transferred to the cloud
    by using the long-range (LoRa) network for decisions. This type of network has
    a distance range that can cover rural areas from the farm itself. The output of
    this computational process is then sent to the paramedics at the hospital. With
    these details, the caregiver can determine the proper action for preventing and
    following medical treatment measures [30,31,32] on what actions to take next;
    for example, sending an ambulance to the farmer, sending information to the farmer’s
    family about what happened to the farmer, and applying medical procedures at the
    hospital. The goal is to exploit quaternion as four-dimensional data as the feed
    input for the classifier and compare the proposed algorithm to the other algorithm
    based on their strengths and vulnerabilities. In accordance with the findings
    from this study, the proposed framework significantly outperformed the others.
    The contributions of the proposed work are as follows: We utilized a quaternion
    as an input feature to represent 3D rotation. We evaluated the approaches on both
    large-scale egocentric datasets and farming pack mocap datasets, and demonstrate
    that our proposed method is practical regarding computational efficiency and result.
    Using the proposed algorithm, we determined the optimal solutions for the proposed
    system. With the same train test data, the proposed algorithm, HTM classifier,
    and (k-Nearest Neighbor) kNN classifier were compared. The performances of the
    two algorithms were compared using different performance metrics. The rest of
    this paper is structured as follows: as this study is an IoT and deep learning-based
    farmer safety system, the related research on the farming activity monitoring
    method and the smart farming application include work on human motion classification
    and hierarchical classification algorithms, as introduced in Section 2. Section
    3 presents the problem definition and clarifies the challenges behind the hierarchical
    temporal classification problem and its specificity. In Section 4, the material
    is proposed, i.e., in Section 4.1. Section 4.2, the proposed method and our proposed
    framework are formulated. The experimental results are presented in Section 5.
    Section 6 presents the discussion, and several studies that were compared to the
    existing ones are reported with numerical computations. Section 7 discusses future
    research directions and draws several conclusions. 2. Related Works Health is
    a crucial priority [33], despite being the top revenue earner for numerous countries.
    Each country is exploring innovative practices to deliver quality healthcare [34,35].
    The use of technology, particularly the internet, is essential to manage solutions
    effectively and efficiently. One such technology is machine learning algorithms
    combined with wearable healthcare devices [36]. Data and medical records can be
    collected to form a model that could be earlier by applying a machine learning
    algorithm [37,38]. Xiao Guo et al. [39] researched human motion prediction. The
    applied Skeleton Network (SkelNet) for local structure representation on different
    body components was used as input. The Skeleton Temporal Network (Skel-TNet) and
    Recurrent Neural Network (RNN) were used o apply the learning spatial and temporal
    dependencies. The final result was with the Residual Recurrent Neural Network
    (RRNN) and Convolutional Sequence to Sequence (CSS). Regardless, the analysis
    primarily focused on predicting short-term human motion. The study by Judith Bütepage
    et al. [40] focuses on the use of the Deep Learning (DL) framework architecture
    to analyze human motion capture data. The study comprehends a generic representation
    and generalizes the motion capture data from generative models of 3D human motion.
    These feature representations of human motion are extracted via an encoding–decoding
    network that quantifies learned features from the current history, representing
    various output layers for action classification. Three proposed methods, i.e.,
    the Symmetric Temporal Encoder (S-TE), Convolutional Temporal Encoder (C-TE),
    and Hierarchical Temporal Encoder(H-TE) were compared with data point feature
    classification and Principal Component Analysis (PCA). The study covered long-term
    predictions, which are more accurate with sliding windows. However, it needs further
    investigation concerning the parameter number and each network structure. Pham
    The Hai et al. [41] developed a Human Action Recognition System (HARS) in both
    indoor and outdoor environments. Their approach involves observation sequences
    to train the Hidden Markov Model (HMM) and differentiate between seven activities.
    They extracted preferred features from a separate sequence of a human skeletal
    joint mapping, which involved Baum–Welch and the forward–backward algorithm to
    discover the optimal parameter of the individual HMM model. An automatic database
    update is needed to execute the system based on infrared light and time-of-flight
    technology from Kinect V2. In different applications and domains, linear combination
    approaches across multiple levels of the hierarchy are suggested by Evangelos
    Spiliotis et al. [42]. Their strategy enables a more general non-linear combination
    of the reference prediction, which combines the accuracy and coherence of continued-to-optimize
    post-sample evidence-based forecasting, combined in a straightforward and appropriate
    model, without the need for comprehensive information for each series and level
    of the reconciled forecast, and using accuracy and bias as an evaluation method.
    The study was evaluated with Mean Absolute Scaled Error (MASE), Root Mean Squared
    Scaled Error (RMSSE), and Absolute Mean Scaled Error (AMSE). Correspondingly,
    the study enclosed several alternative paths (by focusing on cross-sectional hierarchical
    structures cases), did not generalize optimization objectives to each aggregation
    level, and did not maintain forecast uncertainty or computational complexity.
    Alaa Sagheer et al. [43] developed the Deep Long Short-Term Memory (DLSTM) model
    in autoencoder. They applied transfer learning to mitigate the need to update
    each Long Short-Term Memory (LSTM) cell’s weight vector in hierarchical architectures
    and involve transfer learning methods to reduce the time-consuming and substantial
    quantity of data from various dimensions. The learned features are redistributed
    to the higher levels of the hierarchy for concurrent training to obtain more detailed
    conclusions and produce better forecasting models. The DLSTM was applied to publicly
    available datasets for Brazilian electrical power generation and Australian domestic
    tourism traveler nights. However, the study evaluated two criteria: forecasting
    accuracy and producing a coherent forecast but did not ensure forecast coherency
    at all hierarchy levels on a cross-temporal framework. The author also focused
    on the tourism and energy domains as examples. Eduardo P. Costa et al. [44] is
    a machine learning technique used to address hierarchical classification problems
    in molecular biology related to proteins (organized hierarchically). They experimented
    with four hierarchical classification variant models (i.e., flat classification
    based on leaves, flat classification for all levels, top-down classification,
    and big-bang models) by using the G-protein-CouPled Receptor (GCPR) and enzyme
    protein families to predict protein functions by utilizing signature-generated
    protein sequences. The system requires a considerable level of detail for performance
    evaluation at the deepest classification level for each assessment, which is a
    system-automated procedure. Yuliang Xiu et al. [45] developed a pose-tracking
    system for multi-person articulated poses by building associations between cross-frame
    and form poses. The system uses pose flows and non-maximum suppression to reduce
    redundant pose flows and re-link temporal disjoint. Nevertheless, the authors
    analyzed the proposed pose tracker’s short-term action recognition and scene understanding.
    Hao-Shu Fang et al. [46] identified a subtle error in localization and recognition
    in the single-person pose estimator. By proposing a regional multi-person pose
    estimation framework, inaccurate human bounding boxes can be reduced. It has three-segment
    approaches and can deal with incorrect bounding boxes and redundant detections.
    Their research focused on human bounding box poses rather than the human detector
    and had difficulty distinguishing between overlapped people and similar objects
    when using human detection, resulting in undetected human poses. Wojke et al.
    [47] proposed an approach to multi-object tracking. Their method integrates the
    appearance of simple online and real-time tracking. They applied offline pre-training
    and online application techniques to establish measurements to track associations
    using nearest neighbor queries in visual appearance spaces, which could track
    objects through more prolonged periods of occlusion. The study does not observe
    track jumping, which frequently occurs between false alarms. Martinez et al. [48]
    proposed a method for predicting 3D positions from a 2D joint location. This system
    employs a simple deep feed-forward network to demonstrate the large portion of
    errors in a modern deep 3D pose estimation based on a visual analysis similar
    to a multi-layer perceptron. The approach needs more direct connections to visual
    evidence, which would also result in lower performance. Hierarchical temporal
    memory has been linked to a Long Short-Term Memory (LSTM) network and cascade
    classifier [49,50,51]. There are principal distinctions, which is why LSTM ’gating’
    is not proper because of the neuron model complexity of the HTM model, enforcing
    straightforward Hebbian learning rules locally and unsupervised, without utilizing
    back-propagation. Procedures in HTM are based on the activation and connectivity
    between neurons, utilizing binary units and weights. Several HTM use cases in
    the research studies [52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69] and
    practices that have already been commercially tested include server anomaly detection
    using Grok [70], stock volume anomalies [71], rogue human behavior [72], natural
    language prediction [73], and geospatial tracking [74]. 3. Problem Definition
    This section clarifies some of the fundamental challenges behind hierarchical
    classification, including the motivations for evaluating significance or merit.
    It also explains the formal definition of classification, temporal classification,
    and hierarchical temporal classification to better comprehend this study. Furthermore,
    these detailed aspects make up the complete structure of an HTM network (as shown
    in Figure 2). Figure 2. Hierarchical Temporal Memory (HTM) algorithm flowchart.
    3.1. Classification Classification challenges have already traditionally been
    considered as core components of deep learning, which would include supervised
    and semi-supervised learning problems. A fundamental classification problem can
    be defined as producing an estimated label y from the K-dimensional of the input
    vector x, where: 𝑥∈𝑋⊆ 𝐑 𝐾 K (1) For most of the common machine learning algorithms,
    the specific input variables must be of real value with the following: 𝑦∈𝑌={ 𝐶
    1 , 𝐶 2 ,..., 𝐶 𝑞 } (2) This task employs the following classification rule or
    function: 𝑔:𝑋→𝑌 (3) to predict new pattern labels [75,76]. 3.2. Temporal Classification
    For temporal classification terminology [77,78,79], there are several terms defined:
    channel, stream, and frame. The channel formally can be defined as a function
    c, which maps from a set of timestamps T to a set of values, V, denoted as: 𝑐:𝑇→𝑉
    (4) where T can be the set of times at which the value of channel c is defined,
    assume that: 𝑇=[0,1,⋯, 𝑡 𝑚𝑎𝑥 ] (5) The stream involves all of the values of the
    channels at once (collectively). A stream as a channel s sequence, for the same
    domain in each channel, is expressed as follows: 𝑠=[ 𝑐 1 , 𝑐 2 ,⋯, 𝑐 𝑛 ]s.t.domain(
    𝑐 1 )=domain( 𝑐 2 )=⋯=domain( 𝑐 𝑛 ) (6) where the number of channels in stream
    s can be noted as n. The frame can be referred to as the values of all channels
    at a specific given point of time; formally, a frame can be defined as a function
    on an s stream and a t time. For a given stream, 𝑠=[ 𝑐 1 , 𝑐 2 ,⋯, 𝑐 𝑛 ] , function
    𝑓𝑟 is denoted as: 𝑓𝑟:domain( 𝑐 1 )→range( 𝑐 1 )×range( 𝑐 2 )×⋯×range( 𝑐 𝑛 ) (7)
    𝑓𝑟(𝑠,𝑡)=[ 𝑐 1 (𝑇), 𝑐 2 (𝑇),⋯, 𝑐 𝑛 (𝑇)] (8) For the temporal classification, let
    S be a training example set from a fixed distribution 𝐷 𝑥×𝑧 , input space 𝑋=(
    𝐑 𝑚 )* as a set of all sequences in m dimensional real-valued vectors, and the
    target space 𝑥=𝑙* involves all sequences over the alphabet L of labels. Each example
    in s consists of a pair of sequences (𝑥,𝑧) . The target sequence 𝑦=( 𝑌 1 , 𝑌 2
    ,⋯, 𝑌 𝑢 ) is, at most, as long as the input sequence of 𝑥=( 𝑋 1 , 𝑥 2 ,⋯, 𝑥 𝑇
    ) , so 𝑈≤𝑇 . The aim is to use s to train a temporal classifier 𝑔:𝑋→𝑌 [80]. 3.3.
    Hierarchical Temporal Classification As an example of the biologically inspired
    theories of machine intelligence, the Hierarchical Temporal Memory (HTM) theory
    was developed in 2008 by Jeff Hawkins [81,82]. The HTM Cortical Learning Algorithm
    (CLA), or simply, the HTM learning algorithm, is a type of HTM learning algorithm.
    In [83,84], the authors look at the neocortex theory and its principles. HTM simulates
    the architecture and processes of the neocortex in the biological components of
    the brain. Comprehensive presentation of information about the main components
    of CLA, including the encoder, Spatial Pooler (SP) algorithm, and Temporal Memory
    (TM), which are classification and prediction algorithms, are listed below. The
    hierarchical temporal classification task can be simplified as classifying a stream
    of data into a class hierarchy. Stream classification can be formalized as learning
    instances from a stream s appearing incrementally as sequences of examples labeled
    as { 𝑥 𝑡 , 𝑦 𝑡 } for 𝑡=1,2,⋯,𝑡 , where x is a vector of attribute values and y
    is a class label 𝑦∈{𝐾1,⋯, 𝐾 𝑙 }) . The result in example 𝑥 𝑡 is classified by
    classifier C, which predicts its class label [85,86]. A hierarchical classification
    task can be formulated as input 𝑋:𝑠 , where s can be denoted as the input stream.
    The category tree is denoted as T with the hierarchical layer as L. Categories
    as classes to be predicted are denoted by Y. 4. Materials and Methods 4.1. Materials
    When conducting this research, the proposed framework for prediction probability
    was evaluated by considering two datasets. The dataset includes both a live validation
    experiment dataset and a farmer mocap dataset for practical evaluability assessment.
    The dataset analyzed is described as follows. 4.1.1. Validation Dataset Using
    accelerometer and gyroscope datasets obtained from [87], a large-scale egocentric
    vision dataset was created. The dataset consists of 20 daily activities with the
    following details: it is egocentric, non-scripted, uses a native environment,
    has 11.5 M frames, with 432 sequences, 39.596 action segments, 149 action classes,
    454.255 object bounding boxes, 323 object classes, created by 32 participants,
    with 32 environments [88]. We utilized this dataset to calibrate and validate
    the gyroscope and accelerometer data, which were then implemented into quaternion
    calculations. The dataset representations are visualized in Figure 3. Figure 3.
    Example of the accelerometer and gyroscope data visualization for the validation
    dataset. 𝐴𝑐𝑐𝑙𝑋 , 𝐴𝑐𝑐𝑙𝑌 , and 𝐴𝑐𝑐𝑙𝑍 denote the 𝑥− , 𝑦− , and 𝑧− axis of the 3D
    accelerometer, respectively. Correspondingly, 𝐺𝑦𝑟𝑜𝑋 , 𝐺𝑦𝑟𝑜𝑌 , and 𝐺𝑦𝑟𝑜𝑍 denote
    the 𝑥− , 𝑦− , and 𝑧− axis of the 3D-gyroscope sensor, respectively. (a) Accelerometer
    dataset. (b) Gyroscope dataset. Figure 3a shows the plot record for the accelerometer
    dataset. The blue color indicates the accelerometer coordinate for the X-axis.
    The green color indicates the accelerometer coordinate for the Z-axis, and the
    orange color indicates the accelerometer coordinate for Y-axis. Figure 3b shows
    the plot record for the gyroscope dataset; the blue color indicates the gyroscope
    coordinate for the X-axis, the green color indicates the gyroscope coordinate
    for the Z-axis, and the orange color indicates the gyroscope coordinate for the
    Y-axis. 4.1.2. Farming-Pack Mocap Dataset This dataset [89] is the Farming-Pack
    mocap animation, as shown in Figure 4. It contains in total 24 mocap datasets
    with related farming activity source for Figure 4, e.g., working with a wheelbarrow
    (5 mocap datasets), picking fruit (3 mocap dataset), milking a cow (1 mocap dataset),
    watering a plant (1 mocap dataset), holding activity (4 mocap datasets), planting
    (1 mocap dataset), planting a tree (1 mocap dataset), pull out (2 mocap datasets),
    digging and plant seeds (1 mocap dataset), kneeling (1 mocap dataset), and working
    with a box (4 mocap datasets). Based on [90,91,92,93,94,95] for the sensor attachment,
    we evaluated the extracted rotation dataset for the rotation position. Figure
    4. Farming-Pack mocap dataset [89]. (a) Wheelbarrow walk. (b) Wheelbarrow dump.
    (c) Picking fruit. (d) Milking cow. (e) Watering Plant. (f) Planting. (g) Pull
    plant. (h) Box walk. (i) Plant seeds. (j) Dig. 4.2. Method Classification is one
    of the tasks performed by machine learning. It is defined as the process of making
    predictions about the class or category of observed values or relevant data provided.
    In this investigation, information was collected from wearable devices that could
    read motion data and afterward perform a classification process depicted in Figure
    5. Another tracking sensor developed by Sony, “mocopi [96]” uses a small light
    sensor that allows anyone to easily conduct full-body tracking in 3D. Vive [97]
    created another tracking sensor for full-body tracking. Figure 5. How to train
    the classifier. Then, as a comparison, additional classification was performed
    to see how the outcome performances were compared to the mocap dataset. Regarding
    local processing in a wearable device, we proposed several stages of the classification
    process, as shown in Figure 6. Figure 6. Proposed framework for prediction probability.
    4.2.1. Feature Extraction This section differentiates the visible components of
    the accelerometer and gyroscope to simplify the computation of input data interpretation.
    Two types of data received, i.e., the accelerometer and gyroscope dataset, were
    previously pre-processed by extracting quaternion [21,98,99,100] data from each
    dataset. Quaternion is a comprehensive way of describing a complex number; it
    was discovered by William Rowan Hamilton in the mid-19th century in 1843 [101].
    The quaternion is a parameter representation of spatial rotation in three dimensions,
    extended to four dimensions. The representation of the quaternion calculation
    is described in Figure 7 [102], representing a wearable device in a smartwatch
    to read the accelerometer and gyroscope data. Figure 7. Quaternion visualization
    between axes (X, Y, Z) on a smartwatch-embedded gyroscope sensor and accelerometer
    sensor. The quaternion formula is denoted as follows [103]: 𝑞= 𝑞 𝑤 + 𝑞 𝑥 𝑖+ 𝑞
    𝑦 𝑗+ 𝑞 𝑧 𝑘 (9) 𝑖 2 = 𝑗 2 = 𝑘 2 =𝑖𝑗𝑘=−1,𝑖𝑗=−𝑗𝑖=𝑘,𝑘𝑖=−𝑖𝑘=𝑗,𝑗𝑘=−𝑘𝑗=𝑖 (10) It is applied
    to x, y, z as follows, with 𝜃 being the rotation angle with vector e = ( 𝑒 𝑥 ,
    𝑒 𝑦 , 𝑒 𝑧 ). 𝑞= ⎛ ⎝ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ 𝑞 𝑤 𝑞 𝑥 𝑞 𝑦 𝑞 𝑧 ⎞ ⎠ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟
    ⎟ = ⎛ ⎝ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ cos𝜃/2 𝑒 𝑥 sin𝜃/2 𝑒 𝑦 sin𝜃/2 𝑒 𝑧 sin𝜃/2 ⎞ ⎠ ⎟ ⎟ ⎟ ⎟
    ⎟ ⎟ ⎟ ⎟ ⎟ (11) where w is denoted as the angle of rotation, and x, y, z are vectors
    representing the axes of rotation. Quaternions are good choices for representing
    internal object rotations due to their efficiency in interpolation and single-orientation
    representation. However, the user interface presentation of quaternions is less
    intuitive compared to Euler angles, which are more familiar, intuitive, and predictable.
    Euler angles suffer from singularity and code-level issues, such as sequential
    rotation order storage, performance, and permutation support. The matrix rotation
    contains nine elements with three rotational degrees of freedom, making this rotation
    matrix redundant. This matrix can illustrate the orientation of the reference
    frame, which is a more compact and intuitive way to define an orientation. Furthermore,
    the most convenient performance for reliable interpolation is represented by a
    quaternion. 4.2.2. Encoding Data Using a sparse pattern for input data on Hierarchical
    Temporal Memory (HTM), called Sparse Distributed Representation (SDR) [104], we
    used two types of encoders, i.e., CategoryEncoder and RandomDistributedScalarEncoder.
    CategoryEncoder is used to convert activity category values, as follows: [’P04’,
    ’P35’, ’P30’, ’P25’, ’P26’, ’P12’, ’P23’, ’P28’, ’P22’, ’P36’, ’P03’, ’P06’, ’P33’,
    ’P09’, ’P11’, ’P07’, ’P01’, ’P37’, ’P02’, ’P27’] for the first datasets (EPIC-KITCHEN-100
    dataset). “P ♯♯ ” (e.g., “P01”) is a participant or activity for each person.
    For the numbering of category data, we do not sort the data, but still use the
    category based on the dataset from [87,88]. For the Farming-Pack mocap dataset,
    CategoryEncoder is as follows: [M01, M02, M03, M04, M05, M06, M07, M08, M09, M10,
    M11], as shown in Table 1. Table 1. CategoryEncoder for the Farming-Pack mocap
    dataset. Moreover, for other data, for example, quaternions, we used the encoder,
    namely RandomDistributedScalarEncoder to encode numeric values in the form of
    floating-point values into an array of bits (in this case, sparse patterns). 4.2.3.
    Spatial Pooling The second step for the classifier is spatial pooling. In this
    step, we run the spatial pooler, which handles the column in a region and the
    input bit relation. The spatial pooler process returns a list of activeColumns
    columns. 4.2.4. Temporal Memory The next step for the classifier is sequence memory,
    temporal pooler, or temporal memory. In this step, we perform one step of the
    temporal memory algorithm for learning purposes, based on the computation of temporal
    memory to obtain the next time step prediction by identifying patterns that transition
    over time and recognizing spatial patterns across temporal sequences. 4.2.5. Sparse
    Distributed Representation (SDR) Classifier The classification algorithm used
    for the classification and prediction tasks in this experiment uses the SDR classifier.
    SDR is a data structure whose elements are binary, 1, or 0, representing the brain
    activity and, in the context of HTM, is a biologically-realistic model of neurons.
    The classifier receives input from the temporal memory algorithm’s SDR output,
    also known as the activation pattern. Furthermore, additional encoder information
    describes the target’s actual input. The SDR classifier performs this classification
    task similar to implementing a single-layered feedforward neural network. There
    are three detailed stages in the SDR classification model: initialization, inference,
    and learning. All classes are initialized with zero values to equalize the probability
    values before learning in the initialization stage. In the next stage of inference,
    they calculate the probability distribution by applying the activation function
    at the activation level by performing calculations in the form of class prediction
    probabilities for each received input pattern. The final step of this classification
    is learning, which proportionally adjusts the weight to the gradient, calculates
    the error value for each output unit, and adds it to the appropriate element weight
    matrix. 4.2.6. Performance Metrics Evaluation The quaternion dataset as input
    data in this paper is a continuous value. In order to achieve reliability and
    validate the prediction of our suggested methodology, we applied related performance
    metrics. We used the following metrics to assess our prediction error rates and
    model the performance metrics: accuracy, precision, recall, F-score, Mean Absolute
    Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE). In
    classification problems, accuracy is used to calculate the percentage of correct
    predictions made by a model. In machine learning, the accuracy score is an evaluation
    metric that compares the number of correct predictions made by a model to the
    total number of predictions made. We calculate it by dividing the total number
    of predictions by the number of correct predictions. 𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦= 𝑇𝑃+𝑇𝑁 𝑇𝑃+𝐹𝑃+𝑇𝑁+𝐹𝑁
    (12) Precision is calculated as the percentage of correct predictions for a specific
    class out of all predictions made for that class. 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛= 𝑇𝑃 𝑇𝑃+𝐹𝑃 (13) In
    the case of binary classification, where we have an imbalanced classification
    problem, recall is calculated using the following equation: 𝑅𝑒𝑐𝑎𝑙𝑙= 𝑇𝑃 𝑇𝑃+𝐹𝑁 (14)
    where True Positives ( 𝑇𝑃 ) are positive classes that are correctly predicted
    to be positive. False Positives ( 𝐹𝑃 ) are negative classes that are incorrectly
    predicted to be positive. True Negatives ( 𝑇𝑁 ) are negative classes that are
    predicted to be negative. False Negatives ( 𝐹𝑁 ) are positive classes that are
    incorrectly predicted to be negative. The F -score (also referred to as the F1
    score or F-measure) is a performance metric for machine learning models. It is
    a single score that combines precision and recall. 𝐹−𝑠𝑐𝑜𝑟𝑒=2× (𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛×𝑟𝑒𝑐𝑎𝑙𝑙)
    (𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛+𝑟𝑒𝑐𝑎𝑙𝑙) (15) MAE represents the difference between the initial input
    data and predicted results extracted by averaging the absolute difference over
    the dataset. 𝑀𝐴𝐸= 1 𝑁 ∑ 𝑖=1 𝑁 | 𝑦 𝑖 − 𝑦 ̂ | (16) MSE represents the difference
    between the initial input data and predicted results extracted by squaring the
    average difference over the dataset, which can evaluate the degree of change in
    the data. 𝑀𝑆𝐸= 1 𝑁 ∑ 𝑖−1 𝑁 ( 𝑦 𝑖 − 𝑦 ̂ ) 2 (17) The error rate multiplied by the
    square root of the MSE, or the average size of the error, is denoted by RMSE.
    It is the square root of the average squared difference between the predicted
    and observed values. 𝑅𝑀𝑆𝐸= 𝑀𝑆𝐸 − − − − √ = 1 𝑁 ∑ 𝑖−1 𝑁 ( 𝑦 𝑖 − 𝑦 ̂ ) 2 − − − −
    − − − − − − − − −  ⎷   (18) where 𝑦 𝑖 is the observed value, 𝑦 ̂ is the predicted
    value of 𝑦 𝑖 , 𝑦 ̲ is the average of the observed value of 𝑦 𝑖 , and N is the
    number of samples. 5. Results Data from the validation dataset and the Farming-Pack
    mocap dataset are time-series-based because they are sequential (temporal) or
    continuous data. The first step of our framework is feature extraction. We extracted
    the accelerometer and gyroscope data from the validation dataset and convert it
    to quaternions based on these values. We also applied the same process to the
    Farming-Pack mocap dataset, where we extracted the position of the bones from
    the included (.bvh) file. The (.bvh) file is a text file that contains motion
    data. We converted the resulting positions to quaternions. The quaternion results
    from the two datasets were then processed into the classifier in the following
    stages: data encoding, spatial pooling, temporal memory, and then classified using
    the Hierarchical Temporal Memory (HTM) classifier, and k-Nearest Neighbor (kNN)
    classifier. At first, the HTM classifier did not learn the data patterns, resulting
    in poor performance. When learning runs, the classifier learns data patterns and
    makes reasonably accurate predictions. After learning for a while, the classifier
    can adapt to new patterns and make better predictions. After running the experiment
    and achieving the results for specific data, we evaluated performance evaluation
    metrics in machine learning and statistics for this experiment. The evaluation
    performances of the HTM classifier with accuracy, precision, recall, F_Score,
    MSE, MAE, and RMSE are shown in Table 2. The rate of the performance metric is
    proportional to the percentage of the correct classification patterns applied
    to the dataset. We focused on solving hierarchical classification problems rather
    than specific algorithm problems due to the limited options for performance comparisons.
    We used the kNN algorithm in correlation with our validation and Farming-Pack
    mocap datasets. Table 2. Performance metrics evaluation for the validation dataset
    and Farming-Pack mocap dataset. The HTM can predict the data value in the next
    step based on previously stored patterns based on the structure of the HTM classifier
    system. When new data arrives and is processed, HTM compares it to the predicted
    value and calculates the difference. Considering HTM as a continuous learning
    theory, there is no training, validation, or test set against the input data [105].
    Data are learned and predicted continuously across all of the datasets. 6. Discussion
    From our experiment, HTM can achieve 88.00% accuracy, precision of 0.99, recall
    of 0.04, and a F_Score of 0.09 for the validation dataset; it can achieve 54.00%
    accuracy, precision of 0.97, recall of 0.50, and a F_Score of 0.66 for the Farming-Pack
    mocap dataset. Moreover, for the lower value of the average, we achieve an MSE
    = 5.10, MAE = 0.19, and RMSE = 0.38 for the validation dataset, and MSE = 0.06,
    MAE = 3.24, and RMSE = 1.51 for the Farming-Pack mocap dataset, which implies
    the higher performance of the prediction model. When compared with other methods
    proposed in Table 3 and Table 4, our method achieves the following results: on
    the Human3.6M dataset, the RRNN method achieves an average of 0.97 and 0.23 for
    standard deviation, while CSS results in an average of 0.77 and 0.21 for standard
    deviation. The SkelNeT method achieves an average of 0.76 and 0.21 for standard
    deviation and our Skel-TNet method achieves an average of 0.73 and 0.21 for standard
    deviation. With the CMU mocap dataset, the CSS method results in an average of
    0.61 and standard deviation of 0.18, the SkelNet method achieves an average of
    0.60, and a standard deviation of 0.21, and our Skel-TNet method results in an
    average of 0.55 and standard deviation of 0.21. Table 3. The evaluation results
    of our proposed method compared with those of similar methods applied to the Mocap
    databases. Table 4. Comparison evaluation results with a similar method applied
    on the time series and enzyme dataset. The Carnegie Mellon University (CMU) mocap
    dataset was also evaluated by [40], who achieved classification rate results using
    various methods, i.e., data point = 0.76, PCA = 0.73, Deep Sparse Autoencoder
    (DSAE) = 0.72, S-TE = 0.78, C-TE = 0.78, and H-TE = 0.77. Another study by [41]
    used the HMM method with a training database and achieved accuracy results for
    activities such as stand = 88.67, walk = 86.20, run = 82.70, jump = 76.30, fall
    = 72.03, lie = 86.23, and sit = 92.70. In the time-series dataset, [42] applied
    the xGBoost method on a tourism dataset and achieved MASE = 0.92, RMSSE = 1.16,
    and AMSE = 0.49. They also applied the random forest method and achieved MASE
    = 0.45, RMSSE = 0.67, and AMSE = 0.30. [43] applied the DLSTM method to the Brazilian
    electrical power generation dataset and achieved RMSE levels of 0 = 0.60, 1 =
    1.02, and 2 = 2.91. They also applied the method to the Australian visitor nights
    or domestic tourism dataset and achieved RMSE levels of 0 = 2.27, 1 = 5.26, 2
    = 6.34, and 3 = 8.07. The study by [44] used hierarchical classification on two
    datasets. For the tourism dataset, they achieved the following accuracies: flat
    (leaves) = 61.33, flat (all levels) = 87.80, top-down = 87.80, and big-bang =
    91.13. For the enzyme protein families dataset, they achieved the following accuracies:
    flat (leaves) = 62.73, flat (all levels) = 89.78, top-down = 89.78, and big-bang
    = 96.36. Overall, this research represents the most dependable implementation
    with the optimum results. Wearable devices are used as IoT subsystem technology
    to collect motion sensor data, which are then processed locally and transferred
    to the cloud via the long-range (LoRa) network for decision-making. Our statistical
    results confirm that our proposed method is both feasible and effective in addressing
    the constraints of time series datasets, and it is suitable for implementation
    in real rural farming environments for optimal solutions. 7. Conclusions With
    the demand for farming activity monitoring in rural farming environments, this
    paper presents a classification prediction method for hierarchical temporal memory
    using the quaternion feature for farming safety activity monitoring. The obtained
    results support the proposed method’s ability to classify multiple activity classes.
    With 88.00% accuracy, precision of 0.99, recall of 0.04, F_Score of 0.09, MSE
    = 5.10, MAE = 0.19, and RMSE = 0.38 for the validation dataset, and 54.00% accuracy,
    precision of 0.97, recall of 0.50, F_Score of 0.66, MSE = 0.06, MAE = 3.24, and
    RMSE = 1.51 for the Farming-Pack mocap dataset, which implies the higher performance
    of a prediction model. Nevertheless, it would be exciting to look into the possibility
    of combining, extending, and evaluating other datasets and machine learning methods,
    which could be an interesting research direction. Examining computational complexity
    will be another future direction to maximize the proposed method further. Author
    Contributions Conceptualization, Y.A., M.K. and J.-S.L.; data curation, G.S.M.;
    formal analysis, Y.A.; investigation, Y.A. and G.S.M.; methodology, Y.A. and M.K.;
    project administration, Y.A.; resources, G.S.M.; supervision, M.K. and J.-S.L.;
    validation, M.K. and J.-S.L.; visualization, Y.A.; writing—original draft, Y.A.;
    writing—review and editing, M.K. and J.-S.L. All authors have read and agreed
    to the published version of the manuscript. Funding This study was supported by
    a collaborative research project between the Kyushu Institute of Technology (Kyutech)
    and the National Taiwan University of Science and Technology (Taiwan-Tech). Institutional
    Review Board Statement Not applicable. Informed Consent Statement Not applicable.
    Data Availability Statement Not applicable. Acknowledgments The authors gratefully
    acknowledge the support from the Kyushu Institute of Technology—National Taiwan
    University of Science and Technology Joint Research Program, under grant Kyutech-NTUST-111-04.
    Conflicts of Interest The authors declare no conflict of interest. References
    Martin, G.; Martin-Clouaire, R.; Duru, M. Farming system design to feed the changing
    world: A review. Agron. Sustain. Dev. 2013, 33, 131–149. [Google Scholar] [CrossRef]
    [Green Version] United Nations Department of Economic and Social Affairs. Growing
    at a Slower Pace, World Population is Expected to Reach 9.7 Billion in 2050 and
    Could Peak at Nearly 11 Billion Around 2100. Available online: https://www.un.org/development/desa/en/news/population/world-population-prospects-2019.html
    (accessed on 1 June 2021). Alexandratos, N.; Bruinsma, J. World Agriculture towards
    2030/2050: The 2012 Revision; ESA Working Paper No.12-03.; Agricultural Development
    Economics Division, Food and Agriculture Organization of the United Nations: Rome,
    Italy, 2012. [Google Scholar] Food and Agriculturre Organization of the United
    Nations, How to Feed the World 2050: Proceedings of a Technical Meeting of Experts,
    Rome, Italy, 24–26 June 2009; Food and Agriculturre Organization of the United
    Nations (FAO): Rome, Italy, 2009. Walter, A.; Robert Finger, R.H.; Buchmann, N.
    Smart farming is key to developing sustainable agriculture. Proc. Natl. Acad.
    Sci. USA 2017, 114, 6148–6150. [Google Scholar] [CrossRef] [Green Version] Mohamed,
    E.S.; Belal, A.A.; Abd-Elmabod, S.K.; El-Shirbeny, M.A.; Gad, A.; Zahran, M.B.
    Smart farming for improving agricultural management. Egypt. J. Remote. Sens. Space
    Sci. 2021, 24, 971–981. [Google Scholar] [CrossRef] Rose, D.C.; Chilvers, J. Agriculture
    4.0: Broadening Responsible Innovation in an Era of Smart Farming. Front. Sustain.
    Food Syst. 2018, 2, 87. [Google Scholar] [CrossRef] [Green Version] Kumar, D.;
    Shen, K.; Case, B.; Garg, D.; Alperovich, G.; Kuznetsov, D.; Kuznetsov, D.; Gupta,
    R.; Durumeric, Z. All Things Considered: An Analysis of IoT Devices on Home Networks.
    In Proceedings of the 28th USENIX Conference on Security Symposium, Santa Clara,
    CA, USA, 14–16 August 2019; USENIX Association: Berkeley, CA, USA, 2019; pp. 1169–1185.
    [Google Scholar] Swaroop, K.N.; Chandu, K.; Gorrepotu, R.; Deb, S. A health monitoring
    system for vital signs using IoT. Internet Things 2019, 5, 116–129. [Google Scholar]
    [CrossRef] Saminathan, S.; Geetha, K. A Survey on Health Care Monitoring System
    Using IoT. Int. J. Pure Appl. Math. 2017, 117, 249–254. [Google Scholar] Saranya,
    M.; Preethi, R.; Rupasri, M.; Veena, S. A Survey on Health Monitoring System by
    using IOT. Int. J. Res. Appl. Sci. Eng. Technol. 2018, 6, 778–782. [Google Scholar]
    [CrossRef] Fukatsu, T.; Nanseki, T. Farm Operation Monitoring System with Wearable
    Sensor Devices Including RFID; IntechOpen: London, UK, 2011. [Google Scholar]
    Health and Safety Executive. Fatal Injuries in Agriculture, Forestry and Fishing
    in Great Britain (1 April 2021 to 31 March 2022); Health and Safety Executive:
    London, UK, 2022. [Google Scholar] Thibaud, M.; Chi, H.; Zhou, W.; Piramuthu,
    S. Internet of Things (IoT) in high-risk Environment, Health and Safety (EHS)
    industries: A comprehensive review. Decis. Support Syst. 2018, 108, 79–95. [Google
    Scholar] [CrossRef] Bergen, G.; Chen, L.H.; Warner, M.; Fingerhut, L.A. Injury
    in the United States: 2007 Chartbook (March 2008); National Center for Health
    Statistics: Hyattsville, MD, USA, 2008. [Google Scholar] World Health Organization.
    Falls. Available online: https://www.who.int/news-room/fact-sheets/detail/falls
    (accessed on 1 June 2021). Fukatsu, T.; Nanseki, T. Monitoring system for farming
    operations with wearable devices utilized sensor networks. Sensors 2009, 9, 6171.
    [Google Scholar] [CrossRef] [PubMed] [Green Version] Delahoz, Y.S.; Labrador,
    M.A. Survey on Fall Detection and Fall Prevention Using Wearable and External
    Sensors. Sensors 2014, 14, 9806. [Google Scholar] [CrossRef] [PubMed] [Green Version]
    Rungnapakan, T.; Chintakovid, T.; Wuttidittachotti, P. Fall Detection Using Accelerometer,
    Gyroscope & Impact Force Calculation on Android Smartphones. In Proceedings of
    the CHIuXiD ’18: Proceedings of the 4th International Conference on Human-Computer
    Interaction and User Experience in, Indonesia, Yogyakarta, Indonesia, 23–29 March
    2018; Association for Computing Machinery: New York, NY, USA, 2018; pp. 49–53.
    [Google Scholar] Lim, D.; Park, C.; Kim, N.H.; Kim, S.H.; Yu, Y.S. Fall-Detection
    Algorithm Using 3-Axis Acceleration:Combination with Simple Threshold and Hidden
    Markov Model. J. Appl. Math. 2014, 2014, 896030. [Google Scholar] [CrossRef] [Green
    Version] EuclideanSpace. EuclideanSpace—Maths-Quaternion. Available online: https://www.euclideanspace.com/maths/algebra/realNormedAlgebra/quaternions/index.htm
    (accessed on 1 June 2021). Yannick Millot, P.P.M. Active and passive rotations
    with Euler angles in NMR. Concepts Magn. Reson 2022, 40A, 215–252. [Google Scholar]
    [CrossRef] Allgeuer, P.; Behnke, S. Fused Angles and the Deficiencies of Euler
    Angles. In Proceedings of the 2018 IEEE/RSJ International Conference on Intelligent
    Robots and Systems (IROS), Madrid, Spain, 1–5 October 2018; pp. 5109–5116. [Google
    Scholar] Janota, A.; Šimák, V.; Nemec, D.; Hrbček, J. Improving the precision
    and speed of Euler angles computation from low-cost rotation sensor data. Sensors
    2015, 15, 7016. [Google Scholar] [CrossRef] Tastan, M. IoT Based Wearable Smart
    Health Monitoring System. Celal Bayar Univ. Fen Bilim. Derg. 2018, 14, 343–350.
    [Google Scholar] Wcislik, M.; Pozoga, M.; Smerdzynski, P. Wireless Health Monitoring
    System. IFAC-PapersOnLine 2015, 48, 312–317. [Google Scholar] [CrossRef] Yacchirema,
    D.; de Puga, J.S.; Palau, C.; Esteve, M. Fall detection system for elderly people
    using IoT and Big Data. Procedia Comput. Sci. 2018, 130, 603–610. [Google Scholar]
    [CrossRef] Challis, J.H. Quaternions as a solution to determining the angular
    kinematics of human movement. BMC Biomed. Eng. 2020, 2, 5. [Google Scholar] [CrossRef]
    [Green Version] Rong, G.; Zheng, Y.; Sawan, M. Energy Solutions for Wearable Sensors:
    A Review. Sensors 2021, 21, 3806. [Google Scholar] [CrossRef] Wu, F.; Wu, T.;
    Yuce, M.R. An Internet-of-Things (IoT) Network System for Connected Safety and
    Health Monitoring Applications. Sensors 2019, 19, 21. [Google Scholar] [CrossRef]
    [PubMed] [Green Version] Khojasteh, S.B.; Villar, J.R.; Chira, C.; González, V.M.;
    De la Cal, E. Improving Fall Detection Using an On-Wrist Wearable Accelerometer.
    Sensors 2018, 18, 1350. [Google Scholar] [CrossRef] [PubMed] [Green Version] Wu,
    F.; Zhao, H.; Zhao, Y.; Zhong, H. Development of a Wearable-Sensor-Based Fall
    Detection System. Int. J. Telemed. Appl. 2015, 2015, e576364. [Google Scholar]
    [CrossRef] [PubMed] [Green Version] United Nations. The Sustainable Development
    Goals Report 2022; United Nations: New York, NY, USA, 2022. [Google Scholar] Banerjee,
    A.; Chakraborty, C.; Kumar, A.; Biswas, D. Chapter 5—Emerging trends in IoT and
    big data analytics for biomedical and health care technologies. Handbook of Data
    Science Approaches for Biomedical Engineering; Academic Press: Cambridge, MA,
    USA, 2020; pp. 121–152. [Google Scholar] [CrossRef] Pawar, M.V.; Pawar, P.; Pawar,
    A.M. Chapter 2—HealthWare telemedicine technology (HWTT) evolution map for healthcare.
    Wearable Telemedicine Technology for the Healthcare Industry; Academic Press:
    Cambridge, MA, USA, 2022; pp. 17–32. [Google Scholar] [CrossRef] Ranganathan Chandrasekaran,
    V.K.; Moustakas, E. Patterns of Use and Key Predictors for the Use of Wearable
    Health Care Devices by US Adults: Insights from a National Survey. J. Med. Internet
    Res. 2020, 22, e22443. [Google Scholar] [CrossRef] Rezayi, S. Chapter 5—Controlling
    vital signs of patients in emergencies by wearable smart sensors. Wearable Telemedicine
    Technology for the Healthcare Industry; Academic Press: Cambridge, MA, USA, 2022;
    pp. 71–86. [Google Scholar] [CrossRef] Perez-Pozuelo, I.; Spathis, D.; Clifton,
    E.A.; Mascolo, C. Chapter 3—Wearables, smartphones, and artificial intelligence
    for digital phenotyping and health. Digital Health; Elsevier: Amsterdam, The Netherlands,
    2021; pp. 33–54. [Google Scholar] [CrossRef] Guo, X.; Choi, J. Human Motion Prediction
    via Learning Local Structure Representations and Temporal Dependencies. Proc.
    AAAI Conf. Artif. Intell. 2019, 33, 2580–2587. [Google Scholar] [CrossRef] [Green
    Version] Bütepage, J.; Black, M.J.; Kragic, D.; Kjellström, H. Deep Representation
    Learning for Human Motion Prediction and Classification. In Proceedings of the
    2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu,
    HI, USA, 21–26 July 2017; pp. 1591–1599. [Google Scholar] Hai, P.T.; Kha, H.H.
    An efficient star skeleton extraction for human action recognition using hidden
    Markov models. In Proceedings of the 2016 IEEE Sixth International Conference
    on Communications and Electronics (ICCE), Novotel, Ha Long, Vietnam, 27–29 July
    2016; pp. 351–356. [Google Scholar] [CrossRef] Spiliotis, E.; Abolghasemi, M.;
    Hyndman, R.J.; Petropoulos, F.; Assimakopoulos, V. Hierarchical forecast reconciliation
    with machine learning. Appl. Soft Comput. 2021, 112, 107756. [Google Scholar]
    [CrossRef] Sagheer, A.; Hamdoun, H.; Youness, H. Deep LSTM-Based Transfer Learning
    Approach for Coherent Forecasts in Hierarchical Time Series. Sensors 2021, 21,
    4379. [Google Scholar] [CrossRef] [PubMed] Costa, E.P.; Lorena, A.C.; Carvalho,
    A.C.P.L.F.; Freitas, A.A.; Holden, N. Comparing Several Approaches for Hierarchical
    Classification of Proteins with Decision Trees. In Advances in Bioinformatics
    and Computational Biology: Second Brazilian Symposium on Bioinformatics, Proceedings
    of the Advances in Bioinformatics and Computational Biology, Angra dos Reis, Brazil,
    29–31 August 2007; Sagot, M.F., Walter, M.E.M.T., Eds.; Springer: Berlin/Heidelberg,
    Germany, 2007; pp. 126–137. [Google Scholar] Xiu, Y.; Li, J.; Wang, H.; Fang,
    Y.; Lu, C. Pose Flow: Efficient Online Pose Tracking. In British Machine Vision
    Conference 2018, BMVC 2018, Newcastle, UK, 3–6 September 2018; BMVA Press, 2018;
    p. 53. [Google Scholar] Fang, H.; Xie, S.; Tai, Y.; Lu, C. RMPE: Regional Multi-person
    Pose Estimation. In Proceedings of the 2017 IEEE International Conference on Computer
    Vision (ICCV), Venice, Italy, 22–29 October 2017; IEEE Computer Society: Los Alamitos,
    CA, USA, 2017; pp. 2353–2362. [Google Scholar] [CrossRef] [Green Version] Wojke,
    N.; Bewley, A.; Paulus, D. Simple online and realtime tracking with a deep association
    metric. In Proceedings of the 2017 IEEE International Conference on Image Processing
    (ICIP), Beijing, China, 17–20 September 2017; pp. 3645–3649. [Google Scholar]
    Martinez, J.; Hossain, R.; Romero, J.; Little, J.J. A Simple Yet Effective Baseline
    for 3d Human Pose Estimation. In Proceedings of the 2017 IEEE International Conference
    on Computer Vision (ICCV), Venice, Italy, 22–29 October 2017; IEEE Computer Society:
    Los Alamitos, CA, USA, 2017; pp. 2659–2668. [Google Scholar] [CrossRef] [Green
    Version] Cascade Classification—Opencv 2.4.13.7 Documentation. Available online:
    https://docs.opencv.org/2.4/modules/objdetect/doc/cascade_classification.html?highlight=cascadeclassifier#cascadeclassifier
    (accessed on 1 June 2021). Viola, P.; Jones, M. Rapid object detection using a
    boosted cascade of simple features. In Proceedings of the 2001 IEEE Computer Society
    Conference on Computer Vision and Pattern Recognition, Kauai, HI, USA, 8–14 December
    2001; p. I. Volume 1. [Google Scholar] [CrossRef] Obukhov, A. Chapter 33—Haar
    Classifiers for Object Detection with CUDA. In GPU Computing Gems Emerald Edition;
    Hwu, W.-m.W., Ed.; Applications of GPU Computing Series; Morgan Kaufmann: Boston,
    MA, USA, 2011; pp. 517–544. [Google Scholar] [CrossRef] Monakhov, V.; Thambawita,
    V.; Halvorsen, P.; Riegler, M.A. GridHTM: Grid-Based Hierarchical Temporal Memory
    for Anomaly Detection in Videos. Sensors 2023, 23, 2087. [Google Scholar] [CrossRef]
    [PubMed] Luo, J.; Tjahjadi, T. Gait Recognition and Understanding Based on Hierarchical
    Temporal Memory Using 3D Gait Semantic Folding. Sensors 2020, 20, 1646. [Google
    Scholar] [CrossRef] [PubMed] [Green Version] Zhang, K.; Zhao, F.; Luo, S.; Xin,
    Y.; Zhu, H.; Chen, Y. Online Intrusion Scenario Discovery and Prediction Based
    on Hierarchical Temporal Memory (HTM). Appl. Sci. 2020, 10, 2596. [Google Scholar]
    [CrossRef] [Green Version] Nguyen, T.V.; Pham, K.V.; Min, K.S. Hybrid Circuit
    of Memristor and Complementary Metal-Oxide-Semiconductor for Defect-Tolerant Spatial
    Pooling with Boost-Factor Adjustment. Materials 2019, 12, 2122. [Google Scholar]
    [CrossRef] [Green Version] Nguyen, T.V.; Pham, K.V.; Min, K.S. Memristor-CMOS
    Hybrid Circuit for Temporal-Pooling of Sensory and Hippocampal Responses of Cortical
    Neurons. Materials 2019, 12, 875. [Google Scholar] [CrossRef] [PubMed] [Green
    Version] Perea-Moreno, A.J.; Aguilera-Ureña, M.J.; Meroño-De Larriva, J.E.; Manzano-Agugliaro,
    F. Assessment of the Potential of UAV Video Image Analysis for Planning Irrigation
    Needs of Golf Courses. Water 2016, 8, 584. [Google Scholar] [CrossRef] [Green
    Version] Ding, N.; Gao, H.; Bu, H.; Ma, H.; Si, H. Multivariate-Time-Series-Driven
    Real-time Anomaly Detection Based on Bayesian Network. Sensors 2018, 18, 3367.
    [Google Scholar] [CrossRef] [PubMed] [Green Version] Van-Horenbeke, F.A.; Peer,
    A. NILRNN: A Neocortex-Inspired Locally Recurrent Neural Network for Unsupervised
    Feature Learning in Sequential Data. Cogn. Comput. 2023. [Google Scholar] [CrossRef]
    Dzhivelikian, E.; Latyshev, A.; Kuderov, P.; Panov, A.I. Hierarchical intrinsically
    motivated agent planning behavior with dreaming in grid environments. Brain Inform.
    2022, 9, 1–28. [Google Scholar] [CrossRef] [PubMed] Dobric, D.; Pech, A.; Ghita,
    B.; Wennekers, T. On the Importance of the Newborn Stage When Learning Patterns
    with the Spatial Pooler. SN Comput. Sci. 2022, 3, 179. [Google Scholar] [CrossRef]
    Chakraborty, P.; Bhunia, S. BINGO: Brain-inspired learning memory. Neural Comput.
    Appl. 2022, 34, 3223–3247. [Google Scholar] [CrossRef] Ding, C.; Zhao, J.; Sun,
    S. Concept Drift Adaptation for Time Series Anomaly Detection via Transformer.
    Neural Process. Lett. 2022. [Google Scholar] [CrossRef] Teng, S.Y.; Máša, V.;
    Touš, M.; Vondra, M.; Lam, H.L.; Stehlík, P. Waste-to-energy forecasting and real-time
    optimization: An anomaly-aware approach. Renew. Energy 2022, 181, 142–155. [Google
    Scholar] [CrossRef] Rodkin, I.; Petr Kuderov, A.I.P. Stability and Similarity
    Detection for the Biologically Inspired Temporal Pooler Algorithms. Procedia Comput.
    Sci. 2022, 213, 570–579. [Google Scholar] [CrossRef] Melnykova, N.; Kulievych,
    R.; Vycluk, Y.; Melnykova, K.; Melnykov, V. Anomalies Detecting in Medical Metrics
    Using Machine Learning Tools. Procedia Comput. Sci. 2022, 198, 718–723. [Google
    Scholar] [CrossRef] Rodríguez-Flores, T.C.; Palomo-Briones, G.A.; Robles, F.;
    Ramos, F. Proposal for a computational model of incentive memory. Cogn. Syst.
    Res. 2023, 77, 153–173. [Google Scholar] [CrossRef] George, A.M.; Dey, S.; Banerjee,
    D.; Mukherjee, A.; Suri, M. Online time-series forecasting using spiking reservoir.
    Neurocomputing 2023, 518, 82–94. [Google Scholar] [CrossRef] Thill, M.; Konen,
    W.; Wang, H.; Bäck, T. Temporal convolutional autoencoder for unsupervised anomaly
    detection in time series. Appl. Soft Comput. 2021, 112, 107751. [Google Scholar]
    [CrossRef] Numenta. Numenta Releases Grok for IT Analytics on AWS. Available online:
    https://numenta.com/press/2014/03/25/numenta-releases-grok-for-it-analytics-on-aws/
    (accessed on 1 June 2021). Numenta. Detect Anomalies in Publicly Traded Stocks
    Using Trading and Twitter Data. Available online: https://numenta.com/assets/pdf/apps/htmforstocks.pdf
    (accessed on 1 June 2021). Numenta. Rogue Behavior Detection. Available online:
    https://numenta.com/assets/pdf/whitepapers/Rogue%20Behavior%20Detection%20White%20Paper.pdf
    (accessed on 1 June 2021). Numenta. The Path to Machine Intelligence. Available
    online: https://numenta.com/assets/pdf/whitepapers/Numenta%20-%20Path%20to%20Machine%20Intelligence%20White%20Paper.pdf
    (accessed on 1 June 2021). Numenta. Geospatial Tracking. Available online: https://numenta.com/assets/pdf/whitepapers/Geospatial%20Tracking%20White%20Paper.pdf
    (accessed on 1 June 2021). Bifet, A.; Gavalda, R.; Holmes, G.; Pfahringer, B.
    Machine Learning for Data Streams with Practical Examples in MOA; MIT Press: Cambridge,
    MA, USA, 2018; Available online: https://moa.cms.waikato.ac.nz/book/ (accessed
    on 1 June 2021). Pérez-Ortiz, M.; Jiménez-Fernández, S.; Gutiérrez, P.A.; Alexandre,
    E.; Hervás-Martínez, C.; Salcedo-Sanz, S. A Review of Classification Problems
    and Algorithms in Renewable Energy Applications. Energies 2016, 9, 607. [Google
    Scholar] [CrossRef] [Green Version] Cotofrei, P.; Stoffel, K. Classification Rules
    + Time = Temporal Rules. In Proceedings of the Computational Science, ICCS 2002,
    Amsterdam, The Netherlands, 21–24 April 2002; Sloot, P.M.A., Hoekstra, A.G., Tan,
    C.J.K., Dongarra, J.J., Eds.; Springer: Berlin/Heidelberg, Germany, 2002; pp.
    572–581. [Google Scholar] Kadous, M.W. Temporal Classification: Extending the
    Classification Paradigm to Multivariate Time Series. Ph.D. Thesis, School of Computer
    Science and Engineering, The University of New South Wales, Kensington, Australia,
    2002. [Google Scholar] Kadous, M.W.; Sammut, C. Classification of Multivariate
    Time Series and Structured Data Using Constructive Induction. Mach. Learn. 2005,
    58, 179–216. [Google Scholar] [CrossRef] [Green Version] Graves, A.; Fernández,
    S.; Gomez, F.; Schmidhuber, J. Connectionist Temporal Classification: Labelling
    Unsegmented Sequence Data with Recurrent Neural Networks. In Proceedings of the
    23rd International Conference on Machine Learning, Pittsburgh, PA, USA, 25–29
    June 2006; Association for Computing Machinery: New York, NY, USA, 2006; pp. 369–376.
    [Google Scholar] [CrossRef] Hawkins, J.; Blakeslee, S. On Intelligence: Times
    Books; Henry Holt and Company: New York, NY, USA, 2008. [Google Scholar] Hawkins,
    J.; Lewis, M.; Klukas, M.; Purdy, S.; Ahmad, S. A Framework for Intelligence and
    Cortical Function Based on Grid Cells in the Neocortex. Front. Neural Circuits
    2019, 12, 121. [Google Scholar] [CrossRef] [PubMed] Hawkins, J.; Ahmad, S.; Cui,
    Y. A Theory of How Columns in the Neocortex Enable Learning the Structure of the
    World. Front. Neural Circuits 2017, 11, 81. [Google Scholar] [CrossRef] [PubMed]
    [Green Version] Lewis, M.; Purdy, S.; Ahmad, S.; Hawkins, J. Locations in the
    Neocortex: A Theory of Sensorimotor Object Recognition Using Cortical Grid Cells.
    Front. Neural Circuits 2019, 13, 22. [Google Scholar] [CrossRef] [PubMed] [Green
    Version] Stefanowski, J.; Brzezinski, D. Stream Classification. In Encyclopedia
    of Machine Learning and Data Mining; Sammut, C., Webb, G.I., Eds.; Springer: Boston,
    MA, USA, 2016; pp. 1–9. [Google Scholar] [CrossRef] Cerri, R.; Barros, R.C.; de
    Carvalho, A.C. Hierarchical multi-label classification using local neural networks.
    J. Comput. Syst. Sci. 2014, 80, 39–56. [Google Scholar] [CrossRef] Damen, D.;
    Doughty, H.; Farinella, G.M.; Fidler, S.; Furnari, A.; Kazakos, E.; Moltisanti,
    D.; Munro, J.; Perrett, T.; Price, W.; et al. Scaling Egocentric Vision: The EPIC-KITCHENS
    Dataset. In Proceedings of the European Conference on Computer Vision (ECCV),
    Munich, Germany, 8–14 September 2018. [Google Scholar] Damen, D.; Doughty, H.;
    Farinella, G.; Fidler, S.; Furnari, A.; Kazakos, E.; Moltisanti, D.; Munro, J.;
    Perrett, T.; Price, W.; et al. The EPIC-KITCHENS Dataset: Collection, Challenges
    and Baselines. IEEE Trans. Pattern Anal. Mach. Intell. 2020, 43, 4125–4141. [Google
    Scholar] [CrossRef] Adobe Mixamo-Farming Pack. Available online: https://www.mixamo.com/#/?page=1&query=farming+pack&type=Motion%2CMotionPack
    (accessed on 12 August 2022). Abdulla, U.A.; Taylor, K.; Barlow, M.; Naqshbandi,
    K.Z. Measuring Walking and Running Cadence Using Magnetometers. In Proceedings
    of the 2013 12th IEEE International Conference on Trust, Security and Privacy
    in Computing and Communications, Melbourne, VIC, Australia, 16–18 July 2013; pp.
    1458–1462. [Google Scholar] [CrossRef] Gjoreski, H.; Lustrek, M.; Gams, M. Accelerometer
    Placement for Posture Recognition and Fall Detection. In Proceedings of the 2011
    Seventh International Conference on Intelligent Environments, Nottingham, UK,
    25–28 July 2011; pp. 47–54. [Google Scholar] [CrossRef] [Green Version] Cleland,
    I.; Kikhia, B.; Nugent, C.; Boytsov, A.; Hallberg, J.; Synnes, K.; McClean, S.;
    Finlay, D. Optimal placement of accelerometers for the detection of everyday activities.
    Sensors 2013, 13, 9183. [Google Scholar] [CrossRef] [PubMed] [Green Version] Pannurat,
    N.; Thiemjarus, S.; Nantajeewarawat, E.; Anantavrasilp, I. Analysis of Optimal
    Sensor Positions for Activity Classification and Application on a Different Data
    Collection Scenario. Sensors 2019, 17, 774. [Google Scholar] [CrossRef] [PubMed]
    [Green Version] Nguyen, N.D.; Bui, D.T.; Truong, P.H.; Jeong, G.M. Position-Based
    Feature Selection for Body Sensors regarding Daily Living Activity Recognition.
    J. Sensors 2018, 2018, 9762098. [Google Scholar] [CrossRef] [Green Version] Arvidsson,
    D.; Fridolfsson, J.; Börjesson, M. Measurement of physical activity in clinical
    practice using accelerometers. J. Intern. Med. 2019, 286, 137–153. [Google Scholar]
    [CrossRef] [PubMed] [Green Version] Sony. Mocopi. Available online: https://www.sony.jp/mocopi/
    (accessed on 2 March 2023). HTC Corporation. Vive Tracker. Available online: https://www.vive.com/jp/accessory/vive-tracker/
    (accessed on 2 March 2023). Unity Documentation. Unity Documentation: Quaternion
    2021. Available online: https://docs.unity3d.com/ScriptReference/Quaternion-w.html
    (accessed on 1 June 2021). OpenGL. OpenGL-Tutorial: Tutorial 17: Rotation. Available
    online: https://www.opengl-tutorial.org/intermediate-tutorials/tutorial-17-quaternions/
    (accessed on 1 June 2021). OpenGL. Wiki SecondLife: Quaternion. Available online:
    https://wiki.secondlife.com/wiki/Quaternion (accessed on 1 June 2021). Jia, Y.-B.
    Quaternions and Rotations. Available online: https://web.cs.iastate.edu/cs577/handouts/quaternion.pdf
    (accessed on 1 June 2021). Wikipedia. Quaternion. Available online: https://en.wikipedia.org/wiki/Quaternion
    (accessed on 1 June 2021). Kou, K.I.; Xia, Y.H. Linear Quaternion Differential
    Equations: Basic Theory and Fundamental Results. Stud. Appl. Math. 2018, 141,
    3–45. [Google Scholar] [CrossRef] Wu, J.; Zeng, W.; Yan, F. Hierarchical Temporal
    Memory method for time-series-based anomaly detection. Neurocomputing 2018, 273,
    535–546. [Google Scholar] [CrossRef] Sousa, R.; Lima, T.; Abelha, A.; Machado,
    J. Hierarchical Temporal Memory Theory Approach to Stock Market Time Series Forecasting.
    Electronics 2021, 10, 1630. [Google Scholar] [CrossRef] Disclaimer/Publisher’s
    Note: The statements, opinions and data contained in all publications are solely
    those of the individual author(s) and contributor(s) and not of MDPI and/or the
    editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to
    people or property resulting from any ideas, methods, instructions or products
    referred to in the content.  © 2023 by the authors. Licensee MDPI, Basel, Switzerland.
    This article is an open access article distributed under the terms and conditions
    of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).
    Share and Cite MDPI and ACS Style Adhitya, Y.; Mulyani, G.S.; Köppen, M.; Leu,
    J.-S. IoT and Deep Learning-Based Farmer Safety System. Sensors 2023, 23, 2951.
    https://doi.org/10.3390/s23062951 AMA Style Adhitya Y, Mulyani GS, Köppen M, Leu
    J-S. IoT and Deep Learning-Based Farmer Safety System. Sensors. 2023; 23(6):2951.
    https://doi.org/10.3390/s23062951 Chicago/Turabian Style Adhitya, Yudhi, Grathya
    Sri Mulyani, Mario Köppen, and Jenq-Shiou Leu. 2023. \"IoT and Deep Learning-Based
    Farmer Safety System\" Sensors 23, no. 6: 2951. https://doi.org/10.3390/s23062951
    Note that from the first issue of 2016, this journal uses article numbers instead
    of page numbers. See further details here. Article Metrics Citations Scopus   1
    Google Scholar   [click to view] Article Access Statistics Article access statistics
    Article Views 29. Dec 8. Jan 18. Jan 28. Jan 7. Feb 17. Feb 27. Feb 8. Mar 18.
    Mar 0 500 1000 1500 2000 For more information on the journal statistics, click
    here. Multiple requests from the same IP address are counted as one view.   Sensors,
    EISSN 1424-8220, Published by MDPI RSS Content Alert Further Information Article
    Processing Charges Pay an Invoice Open Access Policy Contact MDPI Jobs at MDPI
    Guidelines For Authors For Reviewers For Editors For Librarians For Publishers
    For Societies For Conference Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org
    Scilit SciProfiles Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook
    Twitter Subscribe to receive issue release notifications and newsletters from
    MDPI journals Select options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless
    otherwise stated Disclaimer Terms and Conditions Privacy Policy"'
  inline_citation: '>'
  journal: Sensors
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: IoT and Deep Learning-Based Farmer Safety System
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Sortino A.
  - De Leo G.
  - Caruso T.
  - Zinnai A.
  - Beltrame F.
  citation_count: '0'
  description: In an international and constantly evolving market, the agri-food is
    an important economic sector for countries, like Italy, that are in the Mediterranean
    region. In recent years, smart digital technologies, machine learning, and big
    data have been playing an important role in improving the physical production
    of goods and the quality of operations of the agriculture sector. For example,
    sensors that a few decades ago were available only in small research greenhouses,
    now can be deployed in agricultural fields. The information they can transmit
    over the internet can be used to make real time adjustments to the various steps
    needed to harvest an agriculture product. Ultimately, the digital solutions applied
    to agriculture aim to limit waste while minimizing human labour. The “From farm
    to fork” strategy of the European Green Deal identifies digital technologies as
    the tools to achieve greater agricultural sustainability. In order to guarantee
    greater profitability, once a quality agriculture product has been harvested,
    it is necessary to enhance it by certifying its origin and by disclosing the methods
    used to produce it and by reporting on the safeguard systems adopted. For these
    reasons, it is vital to follow agricultural standards that can give the product
    a certification of quality. For example, data analysis, smart labels, blockchain
    and smart contracts, that follow standardized protocols, are tools that, in addition
    to certifying the origin of a product, can reduce brokerage costs, improve deliver
    time, maintain persistent quality while minimizing human errors. In this study
    we conducted a literature review on the articles published in last two International
    Symposia on Mechanization, Precision Horticulture, and Robotics with a focus on
    innovative technologies and their fields of application developed for the agri-food
    sector. An overview of the impact of implementing and following standardization
    practices is presented as well.
  doi: 10.17660/ActaHortic.2023.1360.15
  full_citation: '>'
  full_text: '>

    "Acta Horticulturae Home  Login Logout Status  Help  ISHS Home  ISHS Contact  Consultation
    statistics index  Search   ISHS Acta Horticulturae 1360: XXXI International Horticultural
    Congress (IHC2022): III International Symposium on Mechanization, Precision Horticulture,
    and Robotics: Precision and Digital Horticulture in Field Environments Agri-food:
    which technologies to guarantee our health? Authors:   A. Sortino, G. De Leo,
    T. Caruso, A. Zinnai, F. Beltrame Keywords:   agri-food, sustainability, sensors,
    standardization DOI:   10.17660/ActaHortic.2023.1360.15 Abstract: In an international
    and constantly evolving market, the agri-food is an important economic sector
    for countries, like Italy, that are in the Mediterranean region. In recent years,
    smart digital technologies, machine learning, and big data have been playing an
    important role in improving the physical production of goods and the quality of
    operations of the agriculture sector. For example, sensors that a few decades
    ago were available only in small research greenhouses, now can be deployed in
    agricultural fields. The information they can transmit over the internet can be
    used to make real time adjustments to the various steps needed to harvest an agriculture
    product. Ultimately, the digital solutions applied to agriculture aim to limit
    waste while minimizing human labour. The “From farm to fork” strategy of the European
    Green Deal identifies digital technologies as the tools to achieve greater agricultural
    sustainability. In order to guarantee greater profitability, once a quality agriculture
    product has been harvested, it is necessary to enhance it by certifying its origin
    and by disclosing the methods used to produce it and by reporting on the safeguard
    systems adopted. For these reasons, it is vital to follow agricultural standards
    that can give the product a certification of quality. For example, data analysis,
    smart labels, blockchain and smart contracts, that follow standardized protocols,
    are tools that, in addition to certifying the origin of a product, can reduce
    brokerage costs, improve deliver time, maintain persistent quality while minimizing
    human errors. In this study we conducted a literature review on the articles published
    in last two International Symposia on Mechanization, Precision Horticulture, and
    Robotics with a focus on innovative technologies and their fields of application
    developed for the agri-food sector. An overview of the impact of implementing
    and following standardization practices is presented as well. Article - full text
    (enhanced PDF format, 331772 bytes) Article sharing - repository deposits - copyright
    questions References How to cite this article Translate Select Language Afrikaans
    Albanian Amharic Arabic Armenian Assamese Aymara Azerbaijani Bambara Basque Belarusian
    Bengali Bhojpuri Bosnian Bulgarian Catalan Cebuano Chichewa Chinese (Simplified)
    Chinese (Traditional) Corsican Croatian Czech Danish Dhivehi Dogri Dutch Esperanto
    Estonian Ewe Filipino Finnish French Frisian Galician Georgian German Greek Guarani
    Gujarati Haitian Creole Hausa Hawaiian Hebrew Hindi Hmong Hungarian Icelandic
    Igbo Ilocano Indonesian Irish Italian Japanese Javanese Kannada Kazakh Khmer Kinyarwanda
    Konkani Korean Krio Kurdish (Kurmanji) Kurdish (Sorani) Kyrgyz Lao Latin Latvian
    Lingala Lithuanian Luganda Luxembourgish Macedonian Maithili Malagasy Malay Malayalam
    Maltese Maori Marathi Meiteilon (Manipuri) Mizo Mongolian Myanmar (Burmese) Nepali
    Norwegian Odia (Oriya) Oromo Pashto Persian Polish Portuguese Punjabi Quechua
    Romanian Russian Samoan Sanskrit Scots Gaelic Sepedi Serbian Sesotho Shona Sindhi
    Sinhala Slovak Slovenian Somali Spanish Sundanese Swahili Swedish Tajik Tamil
    Tatar Telugu Thai Tigrinya Tsonga Turkish Turkmen Twi Ukrainian Urdu Uyghur Uzbek
    Vietnamese Welsh Xhosa Yiddish Yoruba Zulu Powered by Translate Download Adobe
    Acrobat Reader (free software to read PDF files)         URL www.actahort.org      Hosted
    by KU Leuven LIBIS      © ISHS"'
  inline_citation: '>'
  journal: Acta Horticulturae
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Agri-food: which technologies to guarantee our health?'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Ilyas Q.M.
  - Ahmad M.
  - Mehmood A.
  citation_count: '9'
  description: Agriculture is the backbone of any country, and plays a viable role
    in the total gross domestic product (GDP). Healthy and fruitful crops are of immense
    importance for a government to fulfill the food requirements of its inhabitants.
    Because of land diversities, weather conditions, geographical locations, defensive
    measures against diseases, and natural disasters, monitoring crops with human
    intervention becomes quite challenging. Conventional crop classification and yield
    estimation methods are ineffective under unfavorable circumstances. This research
    exploits modern precision agriculture tools for enhanced remote crop yield estimation,
    and types classification by proposing a fuzzy hybrid ensembled classification
    and estimation method using remote sensory data. The architecture enhances the
    pooled images with fuzzy neighborhood spatial filtering, scaling, flipping, shearing,
    and zooming. The study identifies the optimal weights of the strongest candidate
    classifiers for the ensembled classification method adopting the bagging strategy.
    We augmented the imagery datasets to achieve an unbiased classification between
    different crop types, including jute, maize, rice, sugarcane, and wheat. Further,
    we considered flaxseed, lentils, rice, sugarcane, and wheat for yield estimation
    on publicly available datasets provided by the Food and Agriculture Organization
    (FAO) of the United Nations and the Word Bank DataBank. The ensemble method outperformed
    the individual classification methods for crop type classification on an average
    of 13% and 24% compared to the highest gradient boosting and lowest decision tree
    methods, respectively. Similarly, we observed that the gradient boosting predictor
    outperformed the multivariate regressor, random forest, and decision tree regressor,
    with a comparatively lower mean square error value on yield years 2017 to 2021.
    Further, the proposed architecture supports embedded devices, where remote devices
    can adopt a lightweight classification algorithm, such as MobilenetV2. This can
    significantly reduce the processing time and overhead of a large set of pooled
    images.
  doi: 10.3390/bioengineering10020125
  full_citation: '>'
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                 Deny Allow selection
    Allow all   Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Bioengineering All Article Types Advanced   Journals
    Bioengineering Volume 10 Issue 2 10.3390/bioengineering10020125 Submit to this
    Journal Review for this Journal Propose a Special Issue Article Menu Academic
    Editors Siuly Siuly Enamul Kabir Smith Kashiram Khare Show more... Subscribe SciFeed
    Recommended Articles Related Info Links More by Authors Links Article Views 3634
    Citations 9 Table of Contents Abstract Introduction Related Work Methodology Results
    and Discussion Conclusions Author Contributions Funding Institutional Review Board
    Statement Informed Consent Statement Data Availability Statement Conflicts of
    Interest References share Share announcement Help format_quote Cite question_answer
    Discuss in SciProfiles thumb_up Endorse textsms Comment first_page settings Order
    Article Reprints Open AccessArticle Automated Estimation of Crop Yield Using Artificial
    Intelligence and Remote Sensing Technologies by Qazi Mudassar Ilyas 1, Muneer
    Ahmad 2,* and Abid Mehmood 3,* 1 Department of Information Systems, College of
    Computer Sciences and Information Technology, King Faisal University, Al Ahsa
    31982, Saudi Arabia 2 Endicott College of International Studies, Woosong University,
    Daejeon 34606, Republic of Korea 3 Department of Management Information Systems,
    College of Business Administration, King Faisal University, Al Ahsa 31982, Saudi
    Arabia * Authors to whom correspondence should be addressed. Bioengineering 2023,
    10(2), 125; https://doi.org/10.3390/bioengineering10020125 Submission received:
    13 December 2022 / Revised: 1 January 2023 / Accepted: 12 January 2023 / Published:
    17 January 2023 Download keyboard_arrow_down     Browse Figures Versions Notes
    Abstract Agriculture is the backbone of any country, and plays a viable role in
    the total gross domestic product (GDP). Healthy and fruitful crops are of immense
    importance for a government to fulfill the food requirements of its inhabitants.
    Because of land diversities, weather conditions, geographical locations, defensive
    measures against diseases, and natural disasters, monitoring crops with human
    intervention becomes quite challenging. Conventional crop classification and yield
    estimation methods are ineffective under unfavorable circumstances. This research
    exploits modern precision agriculture tools for enhanced remote crop yield estimation,
    and types classification by proposing a fuzzy hybrid ensembled classification
    and estimation method using remote sensory data. The architecture enhances the
    pooled images with fuzzy neighborhood spatial filtering, scaling, flipping, shearing,
    and zooming. The study identifies the optimal weights of the strongest candidate
    classifiers for the ensembled classification method adopting the bagging strategy.
    We augmented the imagery datasets to achieve an unbiased classification between
    different crop types, including jute, maize, rice, sugarcane, and wheat. Further,
    we considered flaxseed, lentils, rice, sugarcane, and wheat for yield estimation
    on publicly available datasets provided by the Food and Agriculture Organization
    (FAO) of the United Nations and the Word Bank DataBank. The ensemble method outperformed
    the individual classification methods for crop type classification on an average
    of 13% and 24% compared to the highest gradient boosting and lowest decision tree
    methods, respectively. Similarly, we observed that the gradient boosting predictor
    outperformed the multivariate regressor, random forest, and decision tree regressor,
    with a comparatively lower mean square error value on yield years 2017 to 2021.
    Further, the proposed architecture supports embedded devices, where remote devices
    can adopt a lightweight classification algorithm, such as MobilenetV2. This can
    significantly reduce the processing time and overhead of a large set of pooled
    images. Keywords: precision agriculture; sensory images; data augmentation; feature
    extraction; deep learning; data analysis Graphical Abstract 1. Introduction The
    United Nations estimates that the world population reached the eight billion mark
    on 15 November 2022 [1]. It is expected to reach 8.5 billion in 2030 and 9.7 billion
    in 2050. This increase in population has motivated many countries to prioritize
    food security in their strategic plans [2,3]. The recent global crises of the
    COVID-19 pandemic and the Russia–Ukraine war have further complicated the situation
    due to supply chain disruptions. Owing to a harsh climate in most parts of the
    country, a lack of fertile land, and scarce water resources, Saudi Arabia relies
    on imports for over 80% of its food needs [4]. Hence, it is no surprise that Saudi
    Vision 2030 makes food security one of its priorities [5]. The ultimate objective
    of food security can be achieved through several means, such as increasing arable
    land, reducing food wastage, using advanced technologies in agriculture, improving
    resource utilization, and effective planning. Planning and policy-making play
    a vital role in achieving food security for a country such as Saudi Arabia, which
    lacks the essential ingredients of agricultural produce, namely land and water.
    The planning for food security in Saudi Arabia involves reducing food waste and
    optimizing indigenous growth to reduce reliance on imports. Several initiatives
    have been proposed, and the government is actively working to reduce food loss
    and waste [6,7,8]. The scope of this study is limited to the second aspect of
    planning, related to local agricultural produce. Recent technological advancements,
    improved awareness, and reduced costs have galvanized the adoption of precision
    agriculture in the last few years [9]. One of the active areas of research in
    precision agriculture is automatic crop yield estimation using artificial intelligence
    and remote sensing technologies [10]. While the manual methods for crop yield
    estimation are laborious and unscalable, automatic estimation is cost-effective
    and highly efficient. With high accuracy and minimal cost, real-time crop yield
    estimates can help farmers and government entities manage existing supplies, plan
    imports, and support strategic planning for the future [11]. These techniques
    have proven effective for estimating field- and region-level crop yield [12].
    Automatic crop yield estimation typically relies on sensory data provided by satellite
    or unmanned aerial vehicles. The researchers have developed several indices based
    on this imagery to assess vegetation in an area. At the heart of these indices
    is spectral reflectance measurement in visible (Red) and near-infrared (NIR) bands.
    Healthy vegetation reflects more solar radiation in the NIR than in the Red band
    [13]. In addition, vegetation stress has a direct relationship with the Red band
    and an inverse relationship with the NIR band. This relationship is expressed
    by the normalized difference vegetation index (NDVI), one of the most commonly
    used indices for vegetation measurement, is given in Equation (1) [13]. 𝑁𝐷𝑉𝐼=
    𝑁𝐼𝑅−𝑅𝑒𝑑 𝑁𝐼𝑅+𝑅𝑒𝑑 (1) A higher value of NDVI shows the presence of green vegetation
    in an area. The vegetation condition index (VCI) compares the current NDVI value
    to the respective values observed in the previous years to identify favorable
    vegetation conditions. A value of zero for VCI indicates the most unfavorable
    conditions for vegetation, while a value of 100 represents the best conditions.
    The VCI can be calculated by Equation (2) [13]. 𝑉𝐶𝐼= 𝑁𝐷𝑉𝐼−𝑁𝐷𝑉 𝐼 𝑚𝑖𝑛 𝑁𝐷𝑉 𝐼 𝑚𝑎𝑥
    −𝑁𝐷𝑉 𝐼 𝑚𝑖𝑛 ×100 (2) Due to the limitation of NDVI, Gitelson proposed the wide
    dynamic range vegetation index (WDRVI) by incorporating crops’ physiological and
    phenological characteristics [14]. The index can be calculated using Equation
    (3) [14]. 𝑊𝐷𝑅𝑉𝐼= 𝑎× 𝜌 𝑁𝐼𝑅 − 𝜌 𝑅𝑒𝑑 𝑎× 𝜌 𝑁𝐼𝑅 + 𝜌 𝑅𝑒𝑑 (3) where 𝜌 𝑁𝐼𝑅 and 𝜌 𝑅𝑒𝑑 are
    values of reflectance in near-infrared and visible bands, while 𝑎 is a weighing
    coefficient whose value ranges between 0.1 and 0.2. We have provided a brief exposé
    of the primary vegetation indices. After critically reviewing over 100 vegetation
    indices, Xue and Su argue that these indices must be used with great caution [15].
    It is also worth noting that, in addition to vegetation indices, crop yield estimation
    depends on a diverse set of factors, such as soil characteristics, canopy, rainfall,
    subsurface water, environment, and air temperature. As remote sensing technologies
    are widely used in all these domains, a massive amount of sensory data is collected
    from various resources. The primary sources of sensory data include field surveillance
    cameras, temperature sensors, humidity sensors, fire-alert sensors, flood-warning
    sensors, and weather monitoring sensors. Manual analysis and processing of such
    large amounts of diverse data for crop yield estimation are time-consuming, inaccurate,
    and prone to errors. In recent years, machine learning technologies have successfully
    used such data to solve prediction problems [16,17,18,19]. The current study addresses
    various issues involved in crop yield estimation using machine learning. First,
    the performance of machine learning algorithms for crop yield estimation is adversely
    affected by the low quality of pooled images used as input. Manual feature extraction
    is another issue that needs to be addressed because of its laborious nature. While
    many techniques focus on the tasks of crop classification and yield estimation
    individually, combining these tasks adds to the complexity of this study. Lastly,
    the limited capabilities of lightweight embedded devices used for real-time crop
    monitoring with remote sensors pose another challenge in the study. In the following,
    we briefly overview some salient works related to these issues. The presence of
    noise in the form of clouds or natural aerosols in the images acquired by satellites
    or unmanned aerial vehicles remains an open challenge in smart farming [20]. Tsouros
    et al. stress the need for image quality enhancement for crop yield estimation
    [21]. Wang et al. reviewed various filters for image contrast enhancement [22].
    Li et al. used the image fusion technique to enhance image contrast [23]. Manual
    feature extraction is a limitation of conventional machine learning methods [24].
    Deep learning techniques are used for crop yield estimation to overcome this limitation
    [25,26,27]. However, a limitation of deep learning algorithms is the high computational
    requirements, making them unsuitable for lightweight devices. Few studies have
    proposed machine learning pipelines for crop classification and yield production.
    Meraj et al. proposed a masking technique to classify images with different crops
    [28] and predicted wheat yield based on the images classified as belonging to
    the wheat crop. Lastly, some studies have implicitly addressed the suitability
    of proposed models to be deployed on lightweight embedded devices for real-time
    monitoring [29,30,31]. Hence, there is a need to develop crop yield estimation
    techniques suitable for lightweight devices. To overcome the limitations of existing
    work, we proposed a hybrid ensemble method to signify a variety of crops’ yield
    estimation and classification. The main contributions of this study are as follows.
    The proposed hybrid ensemble method is based on intensive image preprocessing
    inspired by fuzzy neighborhood spatial filtering, scaling, flipping, shearing,
    and zooming. Considering different use cases of convolutional neural networks
    (CNNs) simulated on multiple sensory data, we evaluated the performance of the
    visual geometry group (VGG) with defined/customized image kernels. Although the
    performance of state-of-the-art (SOTA) methods is architecture-dependent, the
    performance of VGG-16 was noted to be better with relatively faster training time.
    It ultimately helped to achieve better classification accuracy by empowering the
    weaker classifiers. The ensemble model outperforms individual classifiers with
    the help of the best feature extractor, VGG-16, among other convolution networks,
    including Inception V3, VGG-19, DeepLoc, and SqueezeNet, simulated on larger sets
    of sensory imaging data. The proposed ensemble method lays the foundation to work
    with embedded devices efficiently by adopting VGG-16 (in general) and MobileNetV2
    (in particular) for remote sensory data. The rest of the manuscript is organized
    as follows. Section 2 provides the limitations of related work. Section 3 presents
    the proposed methodology with a description of the essential components of the
    architecture. Section 4 discusses the significant results, and Section 5 concludes
    the research work. 2. Related Work This section reviews the recent research focused
    on machine learning approaches combined with remote sensing technologies for crop
    yield prediction of various types of crops. The crop yield prediction has been
    carried out using traditional and deep learning-based methods. In general, the
    methods of the former type execute with low computational resources but provide
    comparatively lower performance. On the other hand, the latter kind of methods
    has generally achieved superior performance with high computational costs. Several
    studies have performed a detailed comparison of the use of each of the approaches.
    Oikonomidis et al. [32] presented the state-of-the-art application of deep learning
    in crop yield prediction. They discovered that the most frequently used algorithm,
    Convolutional Neural Network (CNN), performs the task best. One of the most significant
    issues is the lack of datasets of larger size, which increases the likelihood
    of overfitting and, as a result, worse model performance. Rashid et al. [33] reviewed
    the use of machine learning techniques in palm oil yield prediction. The study
    found that the most commonly used traditional machine learning models are logistic
    regression, random forest, and neural networks. Most of the recent works are found
    to be focusing on deep learning models. Further, the study reports that because
    of the minimal utilization of feature sets in palm oil yield prediction, the state-of-the-art
    suffices for neither the selection of the best feature set nor the prediction
    model. Another comprehensive literature assessment identifies existing research
    gaps in the specific area of deep learning approaches combined with remote sensing
    [34]. The study aids in understanding the impact of vegetation indices and environmental
    conditions on crop yield. According to this study, the most extensively used deep
    learning algorithms for crop yield prediction are long short-term memory and convolutional
    neural networks. Satellite remote sensing technology is the most often utilized
    remote sensing technology. Furthermore, the study suggests that vegetation indices
    are the most used factor for predicting agricultural productivity. However, it
    has been discovered that the most utilized properties in the literature may not
    always apply to all techniques. Table 1 provides a summary of the recent works
    in the domain of the current study. The focus areas listed in the table highlight
    the coverage of the challenges facing the machine learning approaches for crop
    yield estimation described in the introduction section. Table 1. Summary of works
    related to crop yield estimation using machine learning methods. 2.1. Traditional
    Methods Several approaches have appeared in the literature that address the estimation
    of yield for more than one crop simultaneously. However, wheat yield is most typically
    predicted jointly with other crops in these studies. Paudel et al. [29] proposed
    an approach for forecasting yield for five crops (soft wheat, spring barley, sunflower,
    sugar beet, and potatoes) in large-scale production scenarios. For this purpose,
    they coupled crop modeling agronomic principles with machine learning and provided
    a baseline workflow focused on correctness, modularity, and reusability. The approach
    enhanced the correctness by developing features based on different data sources,
    including crop simulation outputs, meteorological, remote sensing, and soil data
    from the MCYFS dataset. They provided a reusable workflow to suit diverse crops
    and regions. The reported case studies estimated yield at the regional levels
    for the five crops in three countries (the Netherlands, Germany, and France) with
    high accuracy. Meroni et al. [30] predicted barley, soft wheat, and durum wheat
    yields in Algeria. They used a suite of machine algorithms in different settings
    to determine the best model compared to the benchmarks set by the study. The study
    used public satellite and climate data from the European Commission Joint Research
    Center. One limitation of this study is that it relies extensively on the continuous
    calibration of various models, and does not determine a single model or a combination
    of features that can deliver consistently high performance. The problem of inconsistent
    forecasts across spatial levels is effectively addressed by Paudel et al. [35].
    At the heart of their approach is the idea of forecasting yield at a regional
    level. The proposed generic workflow is used to predict the yields of six crops
    (wheat, barley, sunflower, grain maize, sugar beets, and potatoes) across nine
    European countries. The study shows that a model working on various spatial levels
    of regional-level data instead of the national level can provide substantially
    better performance. Some studies have focused on predicting the yield of a single
    crop. Unsurprisingly, wheat yield prediction dominates among these studies. Zhou
    et al. [31] proposed a model to predict wheat yield at the national level in China.
    For this purpose, the study analyzed the effect of nine climate variables, along
    with three remote sensing-specific metrics. The prediction was carried out by
    adopting random forest, support vector machine, and least absolute shrinkage and
    selection operator. The study integrated climate and remote sensing data. In addition
    to obtaining higher accuracy for country-level predictions, the study has highlighted
    some other interesting findings. For instance, climate data from the entire growing
    season offered more information for yield prediction than remote sensing data.
    Further, compared to remote sensing data, the additional contribution for yield
    prediction in winter wheat planting zones that benefited from climate data declined
    from sowing to maturity. In a similar study, climate records and satellite image
    time-series data were used to predict wheat yields in Australia [36]. The study
    adopted nine base learners and two ensembles to train on high-resolution yield
    maps, NDVI time series data, and climate records comprising rainfall and maximum
    temperature data. The predictions made by non-linear models were more accurate
    than those of linear models. At the same time, support vector regression with
    radial base functions outperformed the other models in making pixel-level predictions.
    Furthermore, ensemble approaches did not indicate a substantial advantage over
    the single best model in the study’s specific setting. Bian et al. [37] used multi-spectral
    remote sensing data from UAV platforms to develop a field-level prediction model
    for wheat crops in China. They extracted ten vegetarian indices from images of
    wheat acquired from a UAV at five different growth stages and used them for tuning
    the model variables of six other machine learning models. The study compared the
    prediction results of the adopted models between the single and multiple growth
    stages. They found Gaussian process regression to outperform the other models
    in both settings. However, they have not compared the performance of their proposed
    model with the other existing works in the domain that work on similar data. A
    hybrid approach was also developed to forecast wheat yield in China that couples
    machine learning and a global dynamical atmospheric prediction system [38]. The
    approach used three machine algorithms, i.e., XGBoost, random forest, and support
    vector regression, along with the multiple regression model. Four types of data
    were utilized: crop yield data, satellite data, observational climate data, and
    atmospheric prediction data. sThe study discovered that XGBoost outperforms all
    other models when trained on atmospheric forecast data. Some works have conducted
    acreage classification and yield estimation simultaneously. Meraj et al. [28]
    first used random forest and support vector machine classifiers to perform a supervised
    classification aimed at acreage assessment for wheat in India. Then, they used
    the Carnegie–Ames–Stanford Approach (CASA) model to estimate the wheat crop. Later,
    the estimation results of CASA were verified using 30 observational points. Barley
    is one of the world’s strategic agricultural products, and its yield prediction
    is critical for guaranteeing food security. Sharifi [39] integrated remote sensing
    and climate data to build a machine learning model that can accurately predict
    barley yield in Iran. To this end, the estimation model was trained using four
    machine learning techniques, including backpropagation neural network, decision
    tree, gaussian process regression, and K-nearest neighbor regression. The study
    also used the proposed model to investigate the correlation between the time intervals
    of the year and the location regarding the accuracy of yield prediction. It shows
    that the accuracy of the prediction is affected by location and time interval.
    However, the limitation that this model benefits from a relatively smaller set
    of features in the modeling process may have affected the prediction accuracy
    in the current setting. So far as the characteristics of the above works relative
    to the focus areas of the current study are concerned, different approaches have
    covered the requirements in various ways and to a variety of extents. The image
    quality enhancement is carried out by processing the input image in a way that
    improves the distinctive features of the images, thus positively impacting the
    prediction results. Kamir et al. have explicitly addressed the issue of improving
    the input image data. To this end, a region of interest is determined from the
    dataset images, and within that region, all distorted pixels are masked and filled
    using linear temporal interpolation. Bian et al. improved the quality of multi-spectral
    UAV images used as input by employing a multi-stage process involving radiometric
    calibration of images, their empirical linear correction, and obtaining a high-resolution
    orthophoto of the crop. A similar method for image correction and enhancement
    was used by Meraj et al. to remove atmospheric errors. In addition, the images
    obtained in various scenes were mosaicked. Optimization of the technique applied
    for feature extraction refers to studying the impact of various feature extraction
    techniques and using the best among the investigated methods for obtaining features
    for training the model. To this end, Paudel et al. [29,35] provided an approach
    to design features comprising physical meaning relative to their impact on crop
    development. However, other possibilities for feature development, e.g., the use
    of a more effective model for automatic feature extraction, have not been addressed.
    Similarly, Meroni et al. optimized the feature selection process using an approach
    that ensures minimum redundancy and maximum relevance, but without investigating
    the selected feature set’s impact on the estimation model’s overall performance.
    In contrast with most recent works, Meraj et al. have also performed the classification
    of acreage to be used for wheat based on the crop’s specific details with a unique
    spectral signature. The traditional machine learning approaches for yield estimation,
    in contrast with their deep learning-based counterparts, might be viewed as inherently
    lightweight and more suitable for deployment on small, embedded devices. However,
    none of the approaches has explicitly addressed the containment of the computational
    expense involved in the estimation using the proposed methods. 2.2. Deep Learning-Based
    Methods Qiao et al. [25] used a combination of 3D convolutional and recurrent
    neural networks to predict wheat and corn yields from China. The proposed model
    is trained first on features obtained from the multi-spectral images, and then
    on the temporal data from the long time-series images. The study adopted two sensor
    datasets, i.e., the surface reflectance dataset (MOD09A1), and MODIS (moderate
    resolution imaging spectroradiometer) Annual Land Cover dataset (MYD11), acquired
    with the MODIS sensor. One of the prominent features of this work is its ability
    to handle multi-temporal and multi-spectral data simultaneously. YieldNet [26]
    is a deep learning framework that adopts transfer learning to make corn and soybean
    yield predictions for up to four months before the harvest in various counties
    of the United States. The model uses a common feature extractor, which reduces
    the number of network parameters and reuses the common parameters for both crops,
    contributing to an increase in prediction efficiency. YieldNet could provide higher
    performance on different datasets related to yield performance and satellite images
    compared to the traditional machine learning models. Cotton provides the raw material
    for the cotton textile industry. It is one of the most important crops around
    the world. It is crucial to the industrial and agricultural economies of various
    countries. Xu et al. [40] estimated the cotton yield using time series UAV remote
    sensing data. They used a neural network based on the Bayesian regularization
    backpropagation to predict the cotton yield for both large-area and small-scale
    settings. Soybean is a good source of protein, fiber, and oil. Some studies have
    focused on the estimation of soybean yield. DeepYield [27] proposed to integrate
    the use of convolutional short-term memory (ConvLSTM) with a three-dimensional
    convolutional neural network (3D-CNN) to enhance the prediction accuracy of soybean
    yield in the US. We can see a significant contribution of this study to how it
    handles remote sensing images. Most existing approaches convert the spatial dimension
    of remote sensing images into histograms of pixel intensities. This results in
    the discarding of the spatial dimensions of the images. In contrast, this model
    has utilized the spatial dimension to determine the important crop variables (e.g.,
    soil properties and elevation), and thus improved the model’s forecasting ability.
    The performance of the proposed model was compared to other models, such as decision
    trees, CNN combined with the Gaussian process, and CNN-LSTM. DeepYield outperformed
    these techniques and each of the ConvLSTM and 3D-CNN models when those were used
    individually. Regarding the focus areas addressed in the current study, Qiao et
    al. have comprehensively addressed the issue of input image quality enhancement.
    The irregular data from images taken from variously shaped fields are transformed
    into a cubic to achieve tractability by employing a dimension-transform technique.
    For this purpose, an optimal crop pixel threshold is determined, and all pixels
    lying exceedingly higher or lower than the threshold are considered noise, and
    are thus eliminated. Similarly, Khaki et al. developed an optimized set of dataset
    images by creating compact histogram representations of the sequences of multi-spectral
    images. Xu et al. provide the neural network model used for prediction with a
    fusion of the high-resolution images and the cotton bolls opening pixels extracted
    using a U-Net semantic segmentation network. Images are enhanced by time series
    data fusion. One of the distinctive features of this approach is the model’s simplicity,
    which is achieved by optimizing the input variables using sensitivity analysis.
    Qiao et al. optimized the feature extraction by using a 3D CNN that jointly captures
    and fuses the spatial and spectral information found in both types of features.
    Then, a temporal dependency capturing module is used for temporal dependencies
    obtained from different multi-spectral images. The features obtained using this
    process are more comprehensive, and eventually improve the prediction performance.
    Khaki et al. implemented a CNN-based feature extractor to obtain relevant features
    from input data, and used it as a common backbone feature extractor to decrease
    the network parameters. 3. Methodology The agricultural field sensors, i.e., field
    surveillance cameras, temperature sensors, humidity sensors, fire-alert sensors,
    flood-warning sensors, and weather monitoring sensors, provide imagery and field-sensed
    data. These remote devices glimpse useful information about the status of different
    crops, estimate the crop yield, and notify about potential crop hazards. The remote
    visionary and sensory algorithms depend on the quality of images and field data
    for optimal crop classification and yield prediction. Figure 1 glimpses the general
    architecture of our proposed solution. Figure 1. Block diagram of the proposed
    solution. The enhancement of images is an essential step before feeding the inputs
    to deep learning algorithms for classifying different crops. The receiving server
    receives and archives the remotely captured images of crops under various parametric
    conditions. The database server contains multiple pools of acquired images as
    a sequence of time-series data. The architecture selects a pool of images and
    preprocesses for image classification. The preprocessed feature vector contains
    the features of images filtered image embedder. As a first instance, we identified
    the robust classifiers and achieved the classification outcomes with classification
    weights adjustment, so that our proposed ensemble classification method outperforms
    the weak classification methods on all images processed as per the time-stamped
    sequence of images from the image database server. The proposed architecture is
    equally supportive for embedded devices, where remote devices can adopt a lightweight
    classification algorithm, such as MobilenetV2. This can significantly reduce the
    processing time and overhead of a large pooled image. We apply the fuzzy technique
    for spatial filtering for input image enhancement in the spatial domain based
    on neighborhood consideration. We take the neighborhood span of 3 × 3 by focusing
    central pixel intensity around all its neighboring dimensions. Let us consider
    p1, p2, p3, …, p9 image pixels in a 3 × 3 grid with corresponding intensity difference
    d1, d2, d3, …, d9. We calculate the intensity difference of pi, (for i ≤ 9) with
    its neighbors, and present the intensity variations following the following fuzzy
    rules. If pixels at corresponding locations shown are zero, then pi, (for i ≤
    9) is set to white; otherwise, black. The correspondence membership function is
    shown in Figure 2. Figure 2. Intensity differences with the application of fuzzy
    rules. Figure 2 demonstrates the difference in intensities with the application
    of fuzzy rules at fuzzy space {0, Black, White}. The intensity level of “Black”
    gradually decreases within the total gray level span of 0 to T-1. Similarly, the
    intensity level of “White” gradually increases with the total gray level span
    of 0 to T-1. The fuzzy memberships provide a significant contour of images, later
    leading to viable extraction of image features. To achieve the contrast enhancement
    of pooled images, we performed the necessary application of scaling, flipping,
    shearing, and zoom filters. Algorithm 1 describes the ensemble classification
    of pooled images, and Algorithm 2 depicts yield estimation. Algorithm 1: Ensemble
    Classification of pooled images 1: Inputs: Preprocessed feature vector FE 2: Outputs:
    Classification outcomes C1, and C2 3:   Let us us take a collection P = {P1, P2,
    P3, Pi} of image vector space, where i ≤ N 4:     Let us apply scaling, flipping,
    shearing, and zooming filters to n images from collection P∀ n ≤ N 5:     Let
    us extract the features by applying image embedding to extract F = {F1, F2, F3,
    Fi} features of images∀ i ≤ N 6:       Analyze Pi instances with features FE using
    AdaBoost classifier where each Pi in P 7:       Analyze Pi instances with features
    FE using the Decision tree classifier, each Pi in P 8:       Analyze Pi instances
    having features FE using Naïve Bayes classifier, each Pi in P 9:       Analyze
    Pi instances having features FE using Random Forest classifier, each Pi in P 10:
          Analyze Pi instances with features FE using Logistic regression where each
    Pi in P 11:       Analyze the individual performance of all classifiers on Pi
    attributes of P for i ≤ N 12:       Output the classification as a result Y (Y
    ≤ 5) classifiers 13:     End 14:   End The image embedder here convolves the image
    vector P in a series of convolution operations described AP → BP → CQ → DQ → ……
    AZ → BZ → CT. Let us consider vector I as an input image. The first layer of the
    embedder incorporates a weight B (a vector numerically applied to I, and the outcome
    serves as the input for the next layer). Similarly, we take vector CQ as an output
    of the first layer. Let us say the weight DQ of the second layer, the convolution
    operation of CQ and DQ produces another vector, and the process keeps moving for
    a specific defined number of layers. Algorithm 2: yield estimation 1: Inputs:
    Preprocessed feature vector F 2: Outputs: Estimation outcome E 3:   Let us take
    a collection P = {P1, P2, P3, Pi} of field sensors data, where i ≤ N 4:     Let
    us apply preprocessing filters to n sensed data items from collection P∀ n ≤ N
    5:     Let us extract the features of sensed data as vector F = {F1, F2, F3, Fi}∀
    i ≤ N 6:       Analyze Pi instances with features F using Linear Regressor where
    each Pi in P 7:       Analyze Pi instances with features F using GradientBoosting
    where each Pi in P 8:       Analyze Pi instances with features F using Tree Regressor
    where each Pi in P 9:       Analyze Pi instances with features F using Random
    Forest regressor, each Pi in P 10:       Analyze the individual performance of
    all estimators on Pi attributes of P for i ≤ N 11:       Output the estimation
    as an estimation vector E 12:     End 13:   End Consider a pool of remotely collected
    images as a collection 𝑃={ 𝑃 1 , 𝑃 2 ,  𝑃 3 ,  𝑃 4 ,…., 𝑃 𝑛 }, 𝑛≤𝑁 of “n” images
    ϵ N images. The image-vector P of image space P is considered a “D” dimensional
    vector ∀ P ϵ RD. Moreover, let us take P ϵ RXxYxZ; each X, Y, and Z depict the
    row, column, and color vectors, respectively. We can further demonstrate these
    vectors with precise indices a, b, and c, ∀ 0 ≤ a ≤ D, 0 ≤ b ≤ D, and 0 < c ≤
    3. If we represent the width and height of an image with “w” and “h”, the scaling
    filter provides a scaled image P′ (w′, h′) ∀ (w′, h′) = T, where T is the maximum
    value as shown in Equation (4), ( w ′ ,  h ′ )= 𝑇 max(𝑤, ℎ) (𝑤, ℎ). (4) 2. Correspondingly,
    the vertical and horizontal shearing defined for image vector P having coordinates
    p and q can be written as, ( 𝑝′ 𝑞′ )=( 𝑝+𝑚𝑞 𝑞 )=( 1  𝑚 0   1 )( 𝑝 𝑞 ) (5) ( 𝑝′
    𝑞 ′ )=( 𝑝 𝑚𝑥+𝑞 )=( 1  0 𝑚   1 )( 𝑝 𝑞 ) (6) Equations (5) and (6) present the horizontal
    and vertical shearing of image vector P, thus relocating the required data points
    in shearing the image P. 3. Next, we apply the zooming to image vector P to seek
    a zoomed image vector P’, such that P’ is nearly (r * 10%) of P. The “r” here
    refers to a particular point of interest in image P having coordinates x and y.
    This zooming provides a zoomed vector of points (zx, zy) as a displacement of
    “r”. Since zooming is a trial-and-error-based process requiring the best compromise,
    the enhanced image vector should serve the desired purpose. 4. Further, the horizontal
    flip of an image vector P having coordinates x and y gives us an image P’ with
    coordinates x’ and y’ ∀ x’ = width (vector I) − x − 1 while y’ = y. Repeat (1):
    x in range (width of vector P) Repeat (2): y in range (height of vector P) x′
    = width (vector P) − x − 1 End Repeat (2): We identified the potentially strong
    classification methods to process our pooled images. The ensembled architecture
    contains Logistic Regression for describing the relationship between the predictor
    and target variables. The target variable is a multi-classified variable having
    values 1 to 6 referring to different crops (shown in Equations (7)–(12)). 𝑃(𝑦=1|𝑥)=
    ℎ 𝜃 (𝑥)= 1 1+𝑒𝑥𝑝(− 𝜃 𝑇 𝑥) ≡𝜎( 𝜃 𝑇 𝑥) (7) 𝑃(𝑦=2|𝑥)= ℎ 𝜃 (𝑥)= 1 1+𝑒𝑥𝑝(− 𝜃 𝑇 𝑥) ≡𝜎(
    𝜃 𝑇 𝑥) (8) 𝑃(𝑦=3|𝑥)= ℎ 𝜃 (𝑥)= 1 1+𝑒𝑥𝑝(− 𝜃 𝑇 𝑥) ≡𝜎( 𝜃 𝑇 𝑥) (9) 𝑃(𝑦=4|𝑥)= ℎ 𝜃 (𝑥)=
    1 1+𝑒𝑥𝑝(− 𝜃 𝑇 𝑥) ≡𝜎( 𝜃 𝑇 𝑥) (10) 𝑃(𝑦=5|𝑥)= ℎ 𝜃 (𝑥)= 1 1+𝑒𝑥𝑝(− 𝜃 𝑇 𝑥) ≡𝜎( 𝜃 𝑇 𝑥)
    (11) 𝑃(𝑦=6|𝑥)= ℎ 𝜃 (𝑥)= 1 1+𝑒𝑥𝑝(− 𝜃 𝑇 𝑥) ≡𝜎( 𝜃 𝑇 𝑥) (12) To keep the value of
    𝜃 𝑇 𝑥 within 1 and 6, we use the Sigmoid function. The value of 1 is adjusted
    such that 𝑃 (𝑦=1|𝑥)= ℎ 𝜃  (𝑥) is large when 𝑥 belongs to 1, else small when 𝑥
    belongs to other values. The sigmoid function (Equation (13)) is, 𝜎(𝑡)= 1 (1+
    𝑒 −𝑡 )  (13) Further, we identified the support vector machine as another potential
    contributor to enhance the accuracy of the ensemble classification method. The
    basic idea was to find a hyperplane 𝜔 → that not only separates the data point
    from different classes, but also has a margin as large as possible. Equation (14)
    explains the parameters for creating a hyperplane, 𝜔 → = ∑ 𝑗 𝛼 𝑗 𝑦 𝑗 𝑑 𝑗 → (14)
    where, 𝑦 𝑗 ∈ {1, 2, 3, 4, 5, 6}, which is the correct class of document dj corresponding
    to the image class of the respective crop, and 𝛼 𝑗 is derived by solving dual
    optimization problems. 4. Results and Discussion 4.1. Results We adopted publicly
    available datasets for yield prediction from the Food and Agriculture Organization
    (FAO) of the United Nations (available online http://www.FAO.org, accessed on
    5 December 2022) and the Word Bank DataBank (available online https://databank.worldbank.org/home.aspx,
    accessed on 5 December 2022). We also augmented the imagery datasets before preprocessing
    to achieve an unbiased and fair classification between different crop types. We
    covered the diversity of various crops, for instance, jute, maize, rice, sugarcane,
    and wheat, for classification aspects, and flaxseed, lentils, rice, sugarcane,
    and wheat for yield estimation. This study investigated the performance of different
    classifiers using the following evaluation metrics (shown in Equations (15)–(18)).
    True Positive (TP): The outcome of the model when the model correctly predicts
    the positive class False Positive (FP): The outcome of the model when the model
    incorrectly predicts the positive class True Negative (TN): The outcome of the
    model when the model correctly predicts the negative class False Negative (FN):
    The outcome of the model when the model incorrectly predicts the negative class
    (a) Accuracy: The proportion of true results to the total number of cases examined,
    Classification Accuracy (CA)= TP+TN TP+FP+FN+TN ×100% (15) (b) Precision: Determines
    the proportion of predicted positives to be truly positive, Precision= TP TP+FP
    ×100% (16) (c) Recall: Identifies the proportion of actual positives correctly
    classified, Recall= TP TP+FN ×100% (17) (d) AUC: Indicates how well the probabilities
    from the positive classes are separated from the negative classes. (e) F1-Score:
    The overall performance of the model is measured F1−Score= 2TP 2TP+FP+FN ×100%
    (18) Figure 3 depicts the performance achievement of different classification
    methods. The proposed ensemble classification method outperforms the other individual
    classifiers, since the study identified the strong classifiers that boosted the
    performance of the ensemble method. Since AUC is a good measure that provides
    a fair ratio between sensitivity and specificity, the area under the curve shows
    larger peaks of the ensemble classification method. Similarly, the F1 score is
    also an unbiased harmonic evaluation metric, and the ensemble method outperforms
    the other classifiers significantly. Figure 3. Performance analysis of classification
    methods. Figure 4 presents the comparative analysis of classification methods
    based on confusion Metrix. The ensemble method correctly identified the crops
    as compared to other methods. For instance, the algorithm classified the jute
    crop with 78% accuracy and maize with 59% accuracy, while the classification of
    rice, sugarcane, and wheat remained at 44%, 53%, and 72%, respectively. These
    performance measures are significantly better than the individual classification
    methods for all crop types. We identified the poor performance of the decision
    tree classification method that depicted only 50% accuracy for jute, 37% for maize,
    20% for rice, 32% for sugarcane, and 51% for the wheat crop. Figure 4. Confusion
    metric analysis of classifiers. Table 2 shows that the ensemble method has a pronounced
    degree of significance compared to decision trees, random forests, Naïve Bayes,
    gradient boosting, and AdaBoost classification methods. There is a slight difference
    in the classification performance of gradient boost and random forest classifiers.
    The decision tree classification method underperforms compared to other classification
    methods. The ROC curve in Figure 5 also demonstrates the significant performance
    of the ensemble classification method. Figure 5. ROC curve analysis. Table 2.
    Cross-tabulation analysis of classifiers. Table 3 presents the year-wise yield
    estimation of different crops under this study. We covered the yield years 2017
    to 2021 relevant to the available data of crops shown in the table. We considered
    a random forest, gradient boosting, linear regression, and tree regressors to
    predict yield estimates. We discuss the yield estimation in the subsequent discussion
    section. Table 3. Yield estimation of different crops. 4.2. Discussion Modern
    precision tools are the backbone of industry 4.0-based agriculture growth, adding
    considerable value to countries’ gross domestic product (GDP). We proposed a hybrid
    ensemble method investigating the limitations of existing similar works. The convolution
    operation of convolution neural networks (CNNs) is critical in determining strong
    feature vectors of remote sensory images and impacting classification methods’
    performance. The classification methods become computationally intensive for larger
    sets of high-dimensional data to achieve better performance. The proposed hybrid
    ensemble method exploited VGG-16, among several other available state-of-the-art
    (SOTA) feature extraction methods. We compared the performance of VGG-16, Inception-V3,
    DeepLoc, SqueezeNet, and VGG-19 on a considerably larger set of remote sensory
    augmented images of different crop types. The component variance and cumulative
    variance in terms of proportion of variance in principle component analysis are
    given below. Figure 6 presents the proportion of variance of the first ten principal
    components of four SOTA feature extraction methods. The Inception-V3, VGG-16,
    VGG-19, DeepLoc, and SqueezeNet depicted an explained variance of 36%, 60%, 59%,
    73%, and 71%, respectively, on the first 20 normalized variables. The VGG-16’s
    explained variance, i.e., 60%, fell close to the mean-variance (59.8%) of the
    SOTA methods in consideration. Further, we simulated the performance of SOTA convolution
    methods on five larger random datasets of remote sensory images. The cumulative
    performance analysis is given below. Figure 6. (a) Proportion of variance for
    Inception V3, (b) Proportion of variance for SqueezeNet, (c) Proportion of variance
    for VGG-16, (d) Proportion of variance for VGG-19, (e) Proportion of variance
    for DeepLoc. Figure 7 presents the performance metric of the SOTA convolution
    methods. The VGG-16 described the best feature extraction on target data, achieving
    significant classification accuracy, the area under the curve, F1-score, precision,
    and recall. Based on this performance analysis, we employed VGG-16 as a prominent
    feature extractor for the proposed ensemble method. Figure 7. Performance of SOTA
    convolution methods. It is well known that convolution neural networks significantly
    impact the performance of many state-of-the-art classification and prediction
    methods. The enhanced performance of our proposed ensemble method relies heavily
    on feature extraction methods. We identified VGG-16 as the best feature extractor
    in this problem domain. In addition, considering different use cases of CNNs,
    simulated on multiple sensory data, we evaluated the performance of VGG with image
    kernels. Although the performance of SOTA methods is architecture-dependent, the
    performance of VGG-16 was noted to be better with relatively faster training time.
    It ultimately helped to achieve better classification accuracy on a bunch of enriching
    weak classifiers (discussed in the proposed ensemble method). Figure 8 compares
    the needed time to achieve the accuracy of the network. The VGG was found significant,
    and trained faster than the baseline. The training time per epoch reduces significantly
    in the middle of the training. Figure 8. Accuracy by Time-VGGs—Training. Figure
    9 shows that the VGG reaches high accuracy significantly faster than the baseline.
    However, the acceleration is due to faster training time per epoch rather than
    achieving higher accuracy with a lower number of epochs. Figure 9. Accuracy by
    Time-VGGs—Validation. As shown in Figure 10, the VGG and baseline loss function
    values had almost identical behavior on training samples. However, as Figure 11
    demonstrates, the baseline loss has more fluctuation in the case of the validation
    dataset. Figure 10. Loss Value-VGGs—Training. Figure 11. Loss Value-VGGs—Validation.
    Both networks have a smooth decrease in loss function with no signs of overfitting.
    However, the VGG had less fluctuation compared to the baseline. This behavior
    reappears in other experiments. Since we noticed a comparable performance of VGG-16,
    and VGG-19, Figure 12 presents the features’ rank criteria of both networks. We
    considered information gain, gain-ratio, Gini-index, and ANOVA as good qualifiers
    to identify the strongest features of data. The qualifiers have higher to lower
    values, corresponding to strongest to weakest features. Since the cumulative component
    variance VGG-16 was better than VGG-19, we employed VGG-16 as the best convolution
    network for feature extraction of remote sensory data. Figure 12. Features’ rank
    criteria of both networks. Further, we considered random forest, gradient boosting,
    linear regression, and tree regressor to predict yield estimates, as shown in
    Table 4. Table 4. Performance analysis of yield predictors. We normalized the
    yield data to fit well for prediction algorithms. The normalized actual yield
    is 0.123177. We can see that the gradient boosting algorithm outperforms the other
    predictors and achieves negligible residual compared with the actual yield. Figure
    13 depicts the yield and error terms. Figure 13. Analysis of yield versus residual.
    Further, we performed the analysis of variance (ANOVA) test on our simulated results
    (including both SOTA and machine learning methods), and we achieved the following
    outcomes. In Table 5, chosen on a 95% confidence interval (α = 0.05), the F value
    is 3.36, which is significantly larger than the F-critical value of 2.62, achieving
    a p-value of 0.01, which is significantly smaller than 0.05. Table 5. ANOVA: Statistical
    significance of outcomes of classification methods (α = 0.05). Similarly, we performed
    the ANOVA test on the outcomes of SOTA methods used for feature extraction of
    remote sensory images. Here are the findings. In Table 6, chosen on 95% confidence
    interval (α = 0.05), the F value is 3.07, which is significantly larger than the
    F-critical value of 2.866, achieving a p-value of 0.03, significantly smaller
    than 0.05. Table 6. ANOVA: Statistical significance of outcomes of feature extraction
    methods (α = 0.05). 5. Conclusions Remote data analysis is immensely important
    for today’s precision agriculture. This study presented a fuzzy hybrid ensembled
    classification and estimation of crop yields using remote sensory data. The proposed
    architecture enhanced the pooled images with a fuzzy neighborhood filter and image
    preprocessing. The study identified the optimal weights of the strongest candidate
    classifiers for the ensembled classification method adopting the bagging strategy.
    The study achieved unbiased classification on augmented imagery datasets for jute,
    maize, rice, sugarcane, and wheat. Considering the diversity of crops, the study
    exploited yield estimation of flaxseed, lentils, rice, sugarcane, and wheat on
    publicly available datasets. The ensemble method outperformed the individual classification
    methods for crop type classification on an average of 13% and 24%, compared to
    gradient boosting and decision tree methods, respectively. Similarly, we observed
    that the gradient boosting predictors outperformed the multivariate regressor,
    random forest, and tree regressor, with a comparatively lower mean square error
    value on yield years 2017 to 2021. Prospectively, the proposed architecture can
    be used for embedded devices with lightweight CNN, i.e., MobilenetV2. This can
    greatly reduce the processing time and overhead of a large set of pooled images.
    Author Contributions Conceptualization, Q.M.I.; methodology, Q.M.I., A.M. and
    M.A.; formal analysis, Q.M.I., A.M. and M.A.; investigation, Q.M.I., A.M. and
    M.A.; resources, Q.M.I.; data curation, Q.M.I., A.M. and M.A.; writing—original
    draft preparation, Q.M.I., A.M. and M.A.; project administration, Q.M.I.; funding
    acquisition, Q.M.I. All authors have read and agreed to the published version
    of the manuscript. Funding The authors extend their appreciation to the Deputyship
    for Research and Innovation, Ministry of Education in Saudi Arabia for funding
    this research work through the project number INST025. Institutional Review Board
    Statement Not applicable. Informed Consent Statement Not applicable. Data Availability
    Statement Not applicable. Conflicts of Interest The authors declare no conflict
    of interest. References Gaigbe-Togbe, V.; Bassarsky, L.; Gu, D.; Spoorenberg,
    T.; Zeifman, L. World Population Prospects. 2022. Available online: https://www.un.org/development/desa/pd/sites/www.un.org.development.desa.pd/files/wpp2022_summary_of_results.pdf
    (accessed on 10 December 2022). Nodin, M.N.; Mustafa, Z.; Hussain, S.I. Assessing
    rice production efficiency for food security policy planning in Malaysia: A non-parametric
    bootstrap data envelopment analysis approach. Food Policy 2022, 107, 102208. [Google
    Scholar] [CrossRef] van der Berg, S.; Patel, L.; Bridgman, G. Food insecurity
    in South Africa: Evidence from NIDS-CRAM wave 5. Dev. S. Afr. 2022, 1, 1–16. [Google
    Scholar] [CrossRef] Al-Khateeb, S.A.; Hussain, A.; Lange, S.; Almutari, M.M.;
    Schneider, F. Battling Food Losses and Waste in Saudi Arabia: Mobilizing Regional
    Efforts and Blending Indigenous Knowledge to Address Global Food Security Challenges.
    Sustainability 2021, 13, 8402. [Google Scholar] [CrossRef] Government of Saudi
    Arabia. Vision 2030 Kingdom of Saudi Arabia. 2020. Available online: https://vision2030.gov.sa/download/file/fid/417
    (accessed on 10 December 2022). Mu’azu, N.D.; Blaisi, N.I.; Naji, A.A.; Abdel-Magid,
    I.M.; AlQahtany, A. Food waste management current practices and sustainable future
    approaches: A Saudi Arabian perspectives. J. Mater. Cycles Waste Manag. 2019,
    21, 678–690. [Google Scholar] [CrossRef] Alshabanat, Z.; Alkhorayef, A.; Ben Haddad,
    H.; Mezghani, I.; Gouider, A.; Tlili, A.; Allouche, M.A.; Gannouni, K.A. Quantifying
    Food Loss and Waste in Saudi Arabia. Sustainability 2021, 13, 9444. [Google Scholar]
    [CrossRef] Baig, M.B.; Gorski, I.; Neff, R.A. Understanding and addressing waste
    of food in the Kingdom of Saudi Arabia. Saudi J. Biol. Sci. 2019, 26, 1633–1648.
    [Google Scholar] [CrossRef] Ilyas, Q.M.; Ahmad, M. Smart farming: An enhanced
    pursuit of sustainable remote livestock tracking and geofencing using IoT and
    GPRS. Wirel. Commun. Mob. Comput. 2020, 2020, 26–28. [Google Scholar] [CrossRef]
    Chlingaryan, A.; Sukkarieh, S.; Whelan, B. Machine learning approaches for crop
    yield prediction and nitrogen status estimation in precision agriculture: A review.
    Comput. Electron. Agric. 2018, 151, 61–69. [Google Scholar] [CrossRef] Wang, A.X.;
    Tran, C.; Desai, N.; Lobell, D.; Ermon, S. Deep transfer learning for crop yield
    prediction with remote sensing data. In Proceedings of the 1st ACM SIGCAS Conference
    on Computing and Sustainable Societies, COMPASS 2018, San Jose, CA, USA, 20–22
    June 2018. [Google Scholar] [CrossRef] Sakamoto, T.; Gitelson, A.A.; Arkebauer,
    T.J. MODIS-based corn grain yield estimation model incorporating crop phenology
    information. Remote Sens. Environ. 2013, 131, 215–231. [Google Scholar] [CrossRef]
    Kogan, F.N. Application of vegetation index and brightness temperature for drought
    detection. Adv. Sp. Res. 1995, 15, 91–100. [Google Scholar] [CrossRef] Gitelson,
    A.A. Wide Dynamic Range Vegetation Index for Remote Quantification of Biophysical
    Characteristics of Vegetation. J. Plant Physiol. 2004, 161, 165–173. [Google Scholar]
    [CrossRef] [PubMed] [Green Version] Xue, J.; Su, B. Significant remote sensing
    vegetation indices: A review of developments and applications. J. Sens. 2017,
    2017, e01752. [Google Scholar] [CrossRef] [Green Version] Tantalaki, N.; Souravlas,
    S.; Roumeliotis, M. Data-driven decision making in precision agriculture: The
    rise of big data in agricultural systems. J. Agric. Food Inf. 2019, 20, 344–380.
    [Google Scholar] [CrossRef] Akhter, R.; Sofi, S.A. Precision agriculture using
    IoT data analytics and machine learning. J. King Saud Univ. Inf. Sci. 2022, 34,
    5602–5618. [Google Scholar] [CrossRef] Bu, F.; Wang, X. A smart agriculture IoT
    system based on deep reinforcement learning. Futur. Gener. Comput. Syst. 2019,
    99, 500–507. [Google Scholar] [CrossRef] Magomadov, V.S. Deep learning and its
    role in smart agriculture. J. Phys. Conf. Ser. 2019, 1399, 44109. [Google Scholar]
    [CrossRef] Shafi, U.; Mumtaz, R.; García-Nieto, J.; Hassan, S.A.; Zaidi, S.A.R.;
    Iqbal, N. Precision agriculture techniques and practices: From considerations
    to applications. Sensors 2019, 19, 3796. [Google Scholar] [CrossRef] [PubMed]
    [Green Version] Tsouros, D.C.; Bibi, S.; Sarigiannidis, P.G. A review on UAV-based
    applications for precision agriculture. Informatics 2019, 10, 349. [Google Scholar]
    [CrossRef] [Green Version] Wang, A.; Zhang, W.; Wei, X. A review on weed detection
    using ground-based machine vision and image processing techniques. Comput. Electron.
    Agric. 2019, 158, 226–240. [Google Scholar] [CrossRef] Li, P.; He, D.; Qiao, Y.;
    Yang, C. An application of soft sets in weed identification. Am. Soc. Agric. Biol.
    Eng. Annu. Int. Meet. 2013, 5, 4279–4288. [Google Scholar] [CrossRef] Bashar,
    D.A. Survey on Evolving Deep Learning Neural Network Architectures. J. Artif.
    Intell. Capsul. Networks 2019, 2019, 73–82. [Google Scholar] [CrossRef] Qiao,
    M.; He, X.; Cheng, X.; Li, P.; Luo, H.; Zhang, L.; Tian, Z. Crop yield prediction
    from multi-spectral, multi-temporal remotely sensed imagery using recurrent 3D
    convolutional neural networks. Int. J. Appl. Earth Obs. Geoinf. 2021, 102, 102436.
    [Google Scholar] [CrossRef] Khaki, S.; Pham, H.; Wang, L. Simultaneous corn and
    soybean yield prediction from remote sensing data using deep transfer learning.
    Sci. Rep. 2021, 11, 11132. [Google Scholar] [CrossRef] [PubMed] Gavahi, K.; Abbaszadeh,
    P.; Moradkhani, H. DeepYield: A combined convolutional neural network with long
    short-term memory for crop yield forecasting. Expert Syst. Appl. 2021, 184, 115511.
    [Google Scholar] [CrossRef] Meraj, G.; Kanga, S.; Ambadkar, A.; Kumar, P.; Singh,
    S.K.; Farooq, M.; Johnson, B.A.; Rai, A.; Sahu, N. Assessing the Yield of Wheat
    Using Satellite Remote Sensing-Based Machine Learning Algorithms and Simulation
    Modeling. Remote Sens. 2022, 14, 3005. [Google Scholar] [CrossRef] Paudel, D.;
    Boogaard, H.; de Wit, A.; Janssen, S.; Osinga, S.; Pylianidis, C.; Athanasiadis,
    I.N. Machine learning for large-scale crop yield forecasting. Agric. Syst. 2021,
    187, 103016. [Google Scholar] [CrossRef] Meroni, M.; Waldner, F.; Seguini, L.;
    Kerdiles, H.; Rembold, F. Yield forecasting with machine learning and small data:
    What gains for grains? Agric. For. Meteorol. 2021, 308–309, 108555. [Google Scholar]
    [CrossRef] Zhou, W.; Liu, Y.; Ata-Ul-Karim, S.T.; Ge, Q.; Li, X.; Xiao, J. Integrating
    climate and satellite remote sensing data for predicting county-level wheat yield
    in China using machine learning methods. Int. J. Appl. Earth Obs. Geoinf. 2022,
    111, 102861. [Google Scholar] [CrossRef] Oikonomidis, A.; Catal, C.; Kassahun,
    A. Deep learning for crop yield prediction: A systematic literature review. N.
    Z. J. Crop Hortic. Sci. 2022, 1–26. [Google Scholar] [CrossRef] Rashid, M.; Bari,
    B.S.; Yusup, Y.; Kamaruddin, M.A.; Khan, N. A Comprehensive Review of Crop Yield
    Prediction Using Machine Learning Approaches with Special Emphasis on Palm Oil
    Yield Prediction. IEEE Access 2021, 9, 63406–63439. [Google Scholar] [CrossRef]
    Muruganantham, P.; Wibowo, S.; Grandhi, S.; Samrat, N.H.; Islam, N. A Systematic
    Literature Review on Crop Yield Prediction with Deep Learning and Remote Sensing.
    Remote Sens. 2022, 14, 1990. [Google Scholar] [CrossRef] Paudel, D.; Boogaard,
    H.; de Wit, A.; van der Velde, M.; Claverie, M.; Nisini, L.; Janssen, S.; Osinga,
    S.; Athanasiadis, I.N. Machine learning for regional crop yield forecasting in
    Europe. Field Crop. Res. 2022, 276, 108377. [Google Scholar] [CrossRef] Kamir,
    E.; Waldner, F.; Hochman, Z. Estimating wheat yields in Australia using climate
    records, satellite image time series and machine learning methods. ISPRS J. Photogramm.
    Remote Sens. 2020, 160, 124–135. [Google Scholar] [CrossRef] Bian, C.; Shi, H.;
    Wu, S.; Zhang, K.; Wei, M.; Zhao, Y.; Sun, Y.; Zhuang, H.; Zhang, X.; Chen, S.
    Prediction of Field-Scale Wheat Yield Using Machine Learning Method and Multi-Spectral
    UAV Data. Remote Sens. 2022, 14, 1474. [Google Scholar] [CrossRef] Cao, J.; Wang,
    H.; Li, J.; Tian, Q.; Niyogi, D. Improving the Forecasting of Winter Wheat Yields
    in Northern China with Machine Learning–Dynamical Hybrid Subseasonal-to-Seasonal
    Ensemble Prediction. Remote Sens. 2022, 14, 1707. [Google Scholar] [CrossRef]
    Sharifi, A. Yield prediction with machine learning algorithms and satellite images.
    J. Sci. Food Agric. 2021, 101, 891–896. [Google Scholar] [CrossRef] Xu, W.; Chen,
    P.; Zhan, Y.; Chen, S.; Zhang, L.; Lan, Y. Cotton yield estimation model based
    on machine learning using time series UAV remote sensing data. Int. J. Appl. Earth
    Obs. Geoinf. 2021, 104, 102511. [Google Scholar] [CrossRef]   Disclaimer/Publisher’s
    Note: The statements, opinions and data contained in all publications are solely
    those of the individual author(s) and contributor(s) and not of MDPI and/or the
    editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to
    people or property resulting from any ideas, methods, instructions or products
    referred to in the content.  © 2023 by the authors. Licensee MDPI, Basel, Switzerland.
    This article is an open access article distributed under the terms and conditions
    of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).
    Share and Cite MDPI and ACS Style Ilyas, Q.M.; Ahmad, M.; Mehmood, A. Automated
    Estimation of Crop Yield Using Artificial Intelligence and Remote Sensing Technologies.
    Bioengineering 2023, 10, 125. https://doi.org/10.3390/bioengineering10020125 AMA
    Style Ilyas QM, Ahmad M, Mehmood A. Automated Estimation of Crop Yield Using Artificial
    Intelligence and Remote Sensing Technologies. Bioengineering. 2023; 10(2):125.
    https://doi.org/10.3390/bioengineering10020125 Chicago/Turabian Style Ilyas, Qazi
    Mudassar, Muneer Ahmad, and Abid Mehmood. 2023. \"Automated Estimation of Crop
    Yield Using Artificial Intelligence and Remote Sensing Technologies\" Bioengineering
    10, no. 2: 125. https://doi.org/10.3390/bioengineering10020125 Note that from
    the first issue of 2016, this journal uses article numbers instead of page numbers.
    See further details here. Article Metrics Citations Crossref   8 Web of Science   8
    Scopus   9 Google Scholar   [click to view] Article Access Statistics Article
    access statistics Article Views 29. Dec 8. Jan 18. Jan 28. Jan 7. Feb 17. Feb
    27. Feb 8. Mar 18. Mar 0k 1k 2k 3k 4k For more information on the journal statistics,
    click here. Multiple requests from the same IP address are counted as one view.   Bioengineering,
    EISSN 2306-5354, Published by MDPI RSS Content Alert Further Information Article
    Processing Charges Pay an Invoice Open Access Policy Contact MDPI Jobs at MDPI
    Guidelines For Authors For Reviewers For Editors For Librarians For Publishers
    For Societies For Conference Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org
    Scilit SciProfiles Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook
    Twitter Subscribe to receive issue release notifications and newsletters from
    MDPI journals Select options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless
    otherwise stated Disclaimer Terms and Conditions Privacy Policy"'
  inline_citation: '>'
  journal: Bioengineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Automated Estimation of Crop Yield Using Artificial Intelligence and Remote
    Sensing Technologies
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Lincy C.T.
  - Lenin F.A.
  - Jalbin J.
  citation_count: '0'
  description: 'Background: Farmers need information regarding soil fertility at every
    location of their fields to attain a higher level of precision in nutrient management.
    Nonetheless, the acquisition and processing of soil samples are labor-intensive
    and time-utilizing, and the related cost remains high-priced to farmers. Artificial
    intelligence is the most speedily growing area combined into approximately all
    aspects of human life. Soil macronutrients like nitrogen (N), phosphorous (P),
    and potassium (K) have a significant role in precision agriculture. There is a
    huge need for powerful and rapid measurement systems to measure accurately the
    macronutrients in the soil for optimal crop productivity, especially in site-specific
    crop management system, where the application of fertilizer can be regulated spatially
    with respect to crop demand. Nevertheless, it can present a research direction
    to design an advanced scheme in order to predict the properties of soil. A portable
    sensor device is a basic need of an agriculture system for the accurate and rapid
    monitoring of soil macronutrients. Aim: In this research, the soil nutrients identified
    from the collected soil samples using optical sensors are evaluated for their
    accuracy using a deep learning approach. Methods: A deep residual network is exploited
    for the soil nutrient prediction after augmenting the gathered soil data. Finally,
    various performance evaluation measures, like mean squared error (MSE), mean absolute
    error (MAE), and root mean squared error (RMSE), are calculated to detect how
    accurately the sensor predicted the soil nutrients. Results: From the experimental
    analysis, it is stated that the proposed model attained low MSE value of 4.59 e−09,
    the low RMSE value of 6.78 e−05, and the low MAE value of 4.66 e−05 for N prediction.
    Likewise, the proposed model attained the least MSE value of 1.41 e−05, the least
    RMSE value of 0.0003, and the least MAE value of 0.0001 for P prediction. Conclusion:
    Finally, for K prediction, the proposed model achieved the least MSE value of
    1.54 e−06, least RMSE value of 1.24 e−03, and the least MAE value of 1.38 e−05.'
  doi: 10.1002/jpln.202300310
  full_citation: '>'
  full_text: '>

    "UNCL: University Of Nebraska - Linc Acquisitions Accounting Search within Login
    / Register Journal of Plant Nutrition and Soil Science RESEARCH ARTICLE Full Access
    Deep residual network for soil nutrient assessment using optical sensors C. T.
    Lincy,  Fred A. Lenin,  J. Jalbin First published: 29 November 2023 https://doi.org/10.1002/jpln.202300310
    This article has been edited by Thomas Scholten SECTIONS PDF TOOLS SHARE Abstract
    Background Farmers need information regarding soil fertility at every location
    of their fields to attain a higher level of precision in nutrient management.
    Nonetheless, the acquisition and processing of soil samples are labor-intensive
    and time-utilizing, and the related cost remains high-priced to farmers. Artificial
    intelligence is the most speedily growing area combined into approximately all
    aspects of human life. Soil macronutrients like nitrogen (N), phosphorous (P),
    and potassium (K) have a significant role in precision agriculture. There is a
    huge need for powerful and rapid measurement systems to measure accurately the
    macronutrients in the soil for optimal crop productivity, especially in site-specific
    crop management system, where the application of fertilizer can be regulated spatially
    with respect to crop demand. Nevertheless, it can present a research direction
    to design an advanced scheme in order to predict the properties of soil. A portable
    sensor device is a basic need of an agriculture system for the accurate and rapid
    monitoring of soil macronutrients. Aim In this research, the soil nutrients identified
    from the collected soil samples using optical sensors are evaluated for their
    accuracy using a deep learning approach. Methods A deep residual network is exploited
    for the soil nutrient prediction after augmenting the gathered soil data. Finally,
    various performance evaluation measures, like mean squared error (MSE), mean absolute
    error (MAE), and root mean squared error (RMSE), are calculated to detect how
    accurately the sensor predicted the soil nutrients. Results From the experimental
    analysis, it is stated that the proposed model attained low MSE value of 4.59
    e−09, the low RMSE value of 6.78 e−05, and the low MAE value of 4.66 e−05 for
    N prediction. Likewise, the proposed model attained the least MSE value of 1.41
    e−05, the least RMSE value of 0.0003, and the least MAE value of 0.0001 for P
    prediction. Conclusion Finally, for K prediction, the proposed model achieved
    the least MSE value of 1.54 e−06, least RMSE value of 1.24 e−03, and the least
    MAE value of 1.38 e−05. 1 INTRODUCTION One of the significant nutrients is the
    soil nutrient that plants absorb from the soil and it makes it easy for nutrient
    absorption and crop growth. Directly, soil fertility affects the yield and growth
    of crops, and it is associated with the sustainable advancement of agriculture.
    Thus, precise soil nutrient prediction not only directly impacts the production
    of food and accurate fertilization but is also important for the effectiveness
    of agriculture production and precision agriculture. The complete development
    and growth processes of crops can be classified into various sub-growth cycles
    each of which needs diverse nutrients. Research has developed the idea of soil
    nutrient time series in order to evaluate the soil nutrients demand in crop growth
    as well as to explain the temporal variations in soil nutrients. The development
    of soil nutrients in an area over a particular period is predicted by the soil
    nutrient time series. It is on the basis of the enormous soil data of the area
    (Liu, Xie, et al., 2023). Accordingly, with the particular crops grown in areas
    and the established soil nutrient time evolution approach, real soil nutrient
    needs for particular crops are computed and used as a guide for the accurate fertilization
    of the crop growing procedures (Liu, Xie, et al., 2023). IoT is the technology
    that improves internet connectivity from digital devices to physical devices and
    initiates communication between them. In the cloud, the data gathered are managed,
    stored, and shared among persons, person to machine, or machine to machine (Kaiser,
    2001). By using the IoT, the monitoring of soil temperature, weather forecast,
    soil temperature level, humidity, pest control, and water valves could be linked
    and information collected from the sensors is transmitted to the farmers through
    mobile phones. Subsequently, the ensuing data can be used to optimize farming
    operations, recognize trends, and make slight changes to conditions to increase
    crop production and quality (Artigas et al., 2001; Schepers & Schlemmer, 1998;
    Vadas et al., 2004). In agriculture, the utilization of IoT is called smart farming
    (or smart agriculture), and IoT acts as a central module of precision farming
    (Kodali & Sahu, 2016). Precise agriculture is an important segment of agriculture,
    wherein transmission of data technology is significant (Daniel et al., 2003; Kim
    et al., 2009). By performing the soil testing, the soil minerals can be ascertained,
    either by using the sensors or in a lab. The utilization of several sensors permits
    the gathering of real-time data (Kim et al., 2020). The factors impacting are
    weather conditions, soil properties, water availability, sunlight, soil temperature,
    pollution level, wind, and so on to have better crop production and prediction
    (Lajili et al., 1997). Thus, by using the sensors, region-wise soil properties
    are to be gathered for N, P and K, temperature, pH value, water level, moisture,
    water pollution, and so on. On the basis of their perfect requirements, these
    data permit the crop''s recommendation (Loreto & Morgan, 1996). Nevertheless,
    in order to handle the sensors, huge investments and expertise are needed, and
    periodic maintenance is required (Senapaty et al., 2023). It is extremely suggested
    to have a soil nutrient calculating systems like AAS, HPLC, AES, NMRS, and GC
    integrated with MS, ICPs, and Lachat Flow Injection Analyzer to evaluate the sufficiency
    of the nutrient availability in the techniques to analyze the soil nutrients (Kim
    et al., 2009). Such techniques are complex, as those techniques include pretreatment,
    sample extraction, utilization of time, and endeavor (Adamchuk et al., 2005; Christy
    et al., 2003). Additionally, they are sophisticated instruments, high-priced,
    and require skilled people for their operation (Kim et al., 2009). For this case,
    the solution is to design an in situ and on-the-go soil sensing system that must
    be able to sense the soil properties on a much finer unique resolution than manual
    and or traditional laboratory techniques (Birrell & Hummel, 2001; Shibusawa, 2003).
    Devices for rapid on-site analysis of soil nutrients are thus under demanding
    research (He et al., 2007; Smolka et al., 2017). Recently, the current introduction
    of ML approaches can be used in the design of soil-related classification techniques.
    Several ML techniques are used to predict the soil nutrient content, soil moisture,
    and soil types. A set of 20 classifiers, such as bagging, AdaBoost, RF, NN, and
    SVM, were used for classifying the soil nutrient levels and nutrient levels of
    diverse villages, and the class label was estimated on a scale of medium, low,
    and high in accordance with their numerical value. To generate the transfer function,
    a wide range of regression techniques were used that directly forecast the numerical
    value of the fertility index for each village. Here, this work aims to develop
    a cost-effective IoT-enabled portable optical sensor system to accurately quantify
    the N, P, and K nutrient contents in the soil to cater to the needs of technologically
    ignorant rural farmers. The main objectives of this article are as follows: To
    implement a portable optical sensor system, to predict the N, P, and K nutrient
    contents in the soil, and to evaluate its effectiveness by comparing the lab test
    results; To employ a deep learning model, called deep residual network (DRN),
    to evaluate the accurateness in identifying the soil nutrients from the collected
    soil samples using the sensors; To evaluate the efficiency of the DRN model in
    prediction, the metrics, such as MSE, RMSE, and MAE, are used. The article is
    arranged as follows: Section 6 summarizes information regarding the conventional
    models used for soil nutrient evaluation; Section 8 explains the materials and
    methods; Section 17 illustrates the result section, whereas Section 20 describes
    the conclusion. 1.1 Related works This section explains the conventional studies
    related to soil nutrient prediction. Trontelj ml and Chambers (2021) developed
    the hypothesis using ML methodology to enhance soil properties prediction. By
    using optical spectroscopy sensors, the correlations achieved were significant
    in understanding the overall scheme for the prediction of soil properties. Although
    a multi-component scheme was used, the impact of selected group for nutrient classification
    was examined and showed better prediction. Conversely, the single component soil
    properties prediction was minimal precise. Additionally, category level influence
    was not as important as expected while selecting among 3-, 5-, or 13-level nutrient
    characterization from a few nutrients that can be used for a more accurate nutrient
    characterization scheme. The soil test report values were used by Suchithra and
    Pai (2020) for classifying various important soil features, and soil fertility
    indices of P, OC, K, B, and pH are ascertained on a village-wise basis. The classification
    and prediction of these soil parameters for each village aid in minimizing wasteful
    expenditure on fertilizer inputs. Moreover, the aforementioned five classification
    issues were resolved by using the fast learning classification approach, called
    ELM with diverse activation functions, namely, triangular basis, Gaussian radial
    basis, hyperbolic tangent, sine-squared, as well as hard limit. Wang et al. (2022)
    developed a hyperspectral soil nutrient evaluation approach on the basis of the
    BA-AdaBoost approach. The first derivative of reflectance, spectral reflectance,
    as well as reciprocal logarithm of the reflectance was examined on the basis of
    800 field soil samples as well as their hyperspectral data gathered. By using
    correlation coefficient approach, the sensitive band and first derivative of reflectance
    reciprocal logarithm were extracted as well as soil organic matter content correlation,
    potassium, and phosphorus were resolved. The BA-Adaboost approach was designed
    on the basis of the objective function value in order to calculate the soil organic
    matter, as well as potassium, and phosphorus contents. Blesslin Sheeba et al.
    (2022) worked on a fast learning classification model, called ELM, which was trained
    by using the data in order to recognize the micronutrients present in the soil.
    The nutrients were classified, and the best soil conditions were presented on
    the basis of analysis performed for diverse areas. On the basis of the study performed,
    it was found that the soils in Tamil Nadu are red in color and have normal electrical
    conductivity. ABPNN model optimized by IGA was developed by Liu, Jiang et al.
    (2023) to predict soil nutrient time series with maximum accuracy. Initially,
    the mutation and crossover operations of the GA were enhanced. Subsequently, to
    optimize the BPNN approach, the IGA was employed. From China, by using the soil
    nutrient data, an empirical analysis was carried out. Total nitrogen, soil pH,
    fast-acting potassium, organic matter, and effectual phosphorus were chosen as
    assessment indicators. Raman and Chelliah (2023) developed an ERSOCAE-SNC approach
    to classify and predict fertility indices. The technique mainly concentrated on
    soil test reports. CAE approach was used for the classification that precisely
    ascertains nutrient levels, like B, K, P, and OC, as well as soil pH level. The
    ERSO approach was used which in turn improved the performance of the classification
    as a trial-and-error approach for hyperparameter tuning of the CAE approach was
    an erroneous and tedious process. Moreover, the ERSO approach was derived by integrating
    chaotic ideas into RSO approach. Escorcia-Gutierrez et al. (2022) developed an
    intelligent soil nutrient and pH classification utilizing the weighted voting
    ensemble DL (ISNpHC-WVE) model. The main aim of ISNpHCWVE approach is to classify
    the subsistence of pH levels and nutrients in the soil. For the predictive analysis,
    three DL techniques, such as DBN, GRU, as well as BiLSTM, were used. In addition,
    a weighted voting ensemble approach was used that permitted a weight vector on
    each DL approach of ensemble based on the obtained accuracy in every class. In
    addition, by using MRFO approach, the hyperparameters optimization of the three
    DL approaches was carried out. A DLMLP approach was developed by Tripathi et al.
    (2022), in order to address crop yield forecast-related issues. For crop yield
    prediction, the methods utilized till now with remotely sensed data were concentrated,
    which depends on the vegetation indices created from the optical data. The objective
    of this research aspired to used remotely sensed microwave satellite data from
    Sentinel-1, along with optical data from Sentinel-2. Finally, the experiment was
    performed to estimate the wheat crop yield. 2 MATERIALS AND METHODS This section
    clearly describes the calorimetric sensing mechanism, preparation of testing agent,
    system configuration, and deep learning assessment. 2.1 Colorimetric sensing mechanism
    The colorimetric sensing mechanism measures the wavelength and the electromagnetic
    radiation intensity in the visible region of spectrum. It includes compound measurement
    or a group of compounds available in a multifaceted mixture. In a colored solution,
    to ascertain the concentration or intensity of the compounds, the property of
    colorimetric analysis is used. This is performed by transmitting the light of
    a particular wavelength of the observable spectrum via solution in a photoelectric
    colorimeter instrument and viewing galvanometric reading of reflection sensitizing
    light quantity absorbed. Detailed light filters are used on the basis of the color
    compounds’ nature. Three kinds of filters are present, like red, blue, and green
    with equivalent light wavelength transmission rays from 500 to 530, 470 to 490,
    and 620 to 680 nm, correspondingly. For absorption, two basic laws are extremely
    significant in colorimetric estimation. These are Beer''s law as well as Lambert''s
    law, whereas Lambert''s law states that although monochromatic light transmits
    via a solution of constant concentration, absorption by solution is directly proportional
    to solution length. Conversely, Beer''s law states that although monochromatic
    light transmits via a constant-length solution, absorption by solution is directly
    proportional to solution concentration: (1) (2) where I refers to the intensity
    of the transmitted light (light parting a solution); I0 represents incident light
    intensity (light inward a solution); and K1 and K2 refer to the constants. In
    order to get the expression transmittance (T), both Beer–Lambert laws are integrated
    together: (3) where M0 represents incident radiation intensity, and M represents
    transmitted radiation intensity. A 100% value of T indicates a completely transparent
    substance, with no radiation being terminated. Conversely, a zero value of T specifies
    a completely opaque substance that indicates it absorbs all radiation. For the
    in-between value, absorbance (Ab) or extinction (E) is calculated as a logarithm
    (to base 10) of the reciprocal of transmittance as (4) Initially, the absorption
    spectrum of the analyte must be examined before the sensor fabrication. Although
    the sample concentration is very low, highest absorption waveband is selected
    as the light source to preserve a high absorption rate, and more absorption light
    intensity changes, superior recognition accuracy is obtained. Thus, in this article,
    the phosphorous test solution is indicated as colorless, the nitrogen test solution
    is indicated as light blue, as well as the potassium test solution indicates turbidity.
    Subsequent to the analysis of the absorption spectrum, a red light is chosen as
    incident radiation to recognize phosphorus and nitrogen, as well as a blue light
    is used to recognize the potassium. 2.2 Preparation of testing agents This section
    describes the preparation of universal soil extracting solution as well as its
    procedure to perform the test is stated as follows. 2.2.1 Preparation of universal
    soil extracting solution Add 25 g of sodium acetate (NaC2H3O2 ∙ 3H2O) to 125 mL
    of distilled water. Once it is dissolved, add 7.5 g of glacial acetic acid and
    make 250 mL of water. Ammonia Nitrogen Reagent: In 15 mL of distilled water, the
    5 g of potassium iodide is dissolved. Until a small precipitation happens, add
    a saturated solution of mercuric chloride. Then, 40% of a 50% solution of potassium
    hydroxide is added and diluted to 100 mL. Permit it to settle for 1 week, decant,
    and then remain it in a glass bottle. Two drops of this reagent are added to four
    drops of the “Universal” leaching solution to give analmost colorless spot. Phosphorus
    reagent “A”: An amount of 12.5 g of sodium molybdate is dissolved by mild heating
    of 100 mL of distilled water. In a 600 mL beaker, mix 350 mL of distilled water
    and 50 mL of acetic acid. Add aforesaid solution of sodium molybdate gradually
    with constant stirring and store in a glass bottle. Phosphorus reagent “B”: This
    must be freshly prepared on the day of use as follows: in a one-ounce dropper
    bottle place mL of extraction solution. Add 0.005–0.01 g of stannous oxalate and
    shake systematically. Potassium reagent “A”: Dissolve 5 g of Co (No3)2 and 30
    g of NaNO2 in 50 mL of distilled water, acidify the solution by adding 25 mL of
    glacial acetic acid, and makeup to 100 mL with distilled water. Allow the mixture
    to stand undisturbed for 24 h and filter. Potassium Reagent “B”: Isopropyl alcohol.
    2.2.2 Procedure to conduct the test Ammonia nitrogen test: For the analysis of
    NH3, 1.6 mL of nitrogen soil extract is filled in the glass cuvette in 8.4 s with
    a flow rate of 0.18 mL s−1 and 0.8 mL of nitrogen reagent in 7.3 s with a flow
    rate of 0.11 mL s−1. Phosphorus test: For phosphate analysis, 2 mL of PSE is filled
    in the glass cuvette in 10.5 s with the flow rate of 0.19 mL s−1, 0.2 mL of phosphorus
    reagent A(PRA), and 0.4 mL of phosphorus reagent B (PRB) in 1.5 and 2.9 s, respectively,
    with the flow rate 0.13 for PRA and 0.14 for PRB. Potassium test: For potassium
    analysis, 1.5 mL of PSE is filled in the glass cuvette in 7.9 s with a flow rate
    of 0.19 mL s−1 and 0.15 mL of potassium reagent A(KRA) and 1.2 mL of potassium
    reagent B (KRB) in 1.3 and 9.2 s, respectively, with the flow rate 0.12 for KRA
    and 0.13 for KRB. Peristaltic pumps are used for the transportation of samples
    and reagents from various bottles to glass cuvettes. 12 V voltage is supplied
    to run the peristaltic pumps. A water level sensor is placed inside a glass cuvette.
    It consists of two leads. One lead is used to send the electrical signal from
    the sensor to the solution. The other lead is used to read the electrical signal.
    The flow rate of the pump varies from 0.11 to 0.18 mL s−1. It extracts soil samples
    from three different bottles. The flow rate of the motor is determined with two
    parameters, called time and fill quantity. (5) (6) 2.3 System configuration The
    sensing consists of a sensor probe, LED, LDR, electromagnets, display, and signal
    conditioning circuits. The brightness of LEDs of different colors is used as a
    light source. LEDs emit narrow wavelength bands. The colored light transmits via
    the aqueous solution of the soil. Different soil extracts are filled in different
    bottles, that is, the bottles are filled with water, potassium reagent A, potassium
    reagent B, phosphorus reagent A and phosphorus reagent B. An LDR is used to measure
    nitrogen, phosphorus, and potassium (NPK) from the soil. LED is connected with
    three resistors RR, RB, RG, and ground. LDR is connected with one resistor (10k)
    and the Vcc 5v, where the 10k resistor is ground. Figure 1 illustrates the circuit
    diagram of the NPK sensor NutriTest. FIGURE 1 Open in figure viewer PowerPoint
    Circuit diagram. Figure 2a demonstrates the system configuration of the developed
    NPK sensor NutriTest, whereas Figure 2b shows the developed portable NPK sensor
    NutriTest. A glass cuvette is placed between LED and LDR. Inside the glass cuvette,
    a coated magnetic bar is placed. Both the ends of the glass cuvette Electro Magnets
    1&2 are fixed. An electromagnet is a kind of magnet in that magnetic field is
    generated by an electric current. An electromagnet comprises a coil of wire around
    an iron core. For each nutrient, to fit the absorption band, the LED wavelength
    is selected. The light is absorbed by the nutrients from the LED. Often, LDR is
    used as light sensors. These resistors are mostly used when there is a requirement
    to sense the presence and absence of light. Solenoid valves are used to close,
    mix, or disturb the glow of a liquid or gas in a pipe. The main function of a
    solenoid valve is indicated by its circuit function. Here, a 2/2-way valve presents
    two positions, such as open or closed, as well as has two ports, like outlet and
    inlet. The chemical solutions and soil extract are fed into a valve-enabled cylindrical
    glass cuvette. PTFE-coated magnet and two electromagnets are used to stir the
    solution. Depending on the mode N, P, or K, a suitable wavelength of light is
    switched from the RGB LED. The solution absorbs the light energy depending on
    the color developed, and the remaining light falls on the LDR. The corresponding
    voltage rise is measured using the ATMEL ATMEGA 2560 processor. Node MCU (ESP
    8266) is used to make the device smart. FIGURE 2 Open in figure viewer PowerPoint
    Soil nutrient test (A) system and (B) portable nitrogen, phosphorus, and potassium
    (NPK) sensor NutriTest configuration of NPK sensor NutriTest. Peristaltic pumps
    are used to transfer the soil extract. The soil extract is subjected to the determination
    of the quantity of NPK. The RGB LED is switched to red to determine ammonia-N
    and potassium, which is switched to blue to determine phosphorus. Figure 3 demonstrates
    the soil testing analysis. FIGURE 3 Open in figure viewer PowerPoint Flowchart
    of the soil testing analysis. 2.4 Deep learning for assessment The sensors are
    deployed to gather the data from the agriculture fields, which generally involves
    several parameters, like temperature, soil nutrients, and macronutrient levels
    (N, P, and K). These gathered sensor data are subsequently used to train the predictive
    model and thereby, estimate the nutrient levels in the soil. Furthermore, the
    nutrient prediction models can provide insights into the nutrient status of the
    soil, which allows farmers to make informed decisions about crop selection. By
    analyzing the soil NPK levels, farmers can identify suitable crops that align
    with the nutrient requirements of their fields. This information can help optimize
    crop production strategies and maximize agricultural productivity. Figure 4 shows
    the proposed DRN model for soil nutrient prediction. FIGURE 4 Open in figure viewer
    PowerPoint Schematic diagram of soil nutrient prediction using the proposed deep
    residual network (DRN) model. 2.4.1 Data preprocessing and augmentation Initially,
    the data collected are preprocessed to increase the efficiency of DL. The preprocessing
    phase is used to enhance the data quality as well as it deals with the transformation
    and preparation of the initial data. In this work, the data preprocessing is performed
    using the data normalization method. The major purpose of data normalization is
    to assure the data quality before it is subjected to any learning approach. There
    are numerous kinds of data normalization. It can be used to scale data in a similar
    range of values for each input to decrease bias within the NN from one feature
    to another. Moreover, the data normalization is used to speedup training time
    by commencing training procedures for each feature within a similar scale. It
    is chiefly helpful for designing applications wherein the inputs are usually on
    extensively diverse scales (Nayak et al., 2014). Here, the data normalization
    is performed using the min–max normalization. Min–max normalization: In this min–max
    normalization, the data inputs are mapped into a predefined range [−1, 1] or [0,
    1]. Moreover, the min–max normalizes the attribute values B of data on the basis
    of the maximum and minimum values. It transforms a value b of the attribute B
    to in the range (high, low) by calculating: (7) The most important issue of utilizing
    the min–max normalization technique in prediction is that the maximum and minimum
    values out of samples are unknown. An easy method to overcome this issue is to
    consider the minimal minB and the maximal maxB values developed in the sample
    dataset and subsequently map all sample values below minB and above maxB values
    to low and high correspondingly. Oversampling for augmentation: To generate new
    data points from traditional data, data augmentation represents a set of methods
    to artificially raise the number of data. This involves making small changes to
    data or utilizing DL approaches to create new data points. Augmentation is helpful
    to get better performance and results of the learning approaches by forming new
    and diverse examples to train an approach. Here, the oversampling approach is
    used for the augmentation. It indicates the arbitrary duplication of samples from
    the minority class as well as it enhances the bias to the minority class instances.
    2.4.2 DRN for prediction The ResNets designed in Liu, Xie et al. (2023) are modularized
    frameworks that stack building blocks of the same connecting. The advantages of
    networks with large numbers (even thousands) of layers can be trained simply without
    raising the training error percentage. Figure 5 demonstrates the architectural
    model of DRN. FIGURE 5 Open in figure viewer PowerPoint Architectural model of
    deep residual network (DRN) model. Convolutional layer: In convolutional layers,
    the convolutional kernels are used for the convolutional operations. The operations
    are performed as long traverse in input in vertical and horizontal directions,
    that is, carry out the convolutional operation. The following formulation specifies
    the convolutional layer operation: (8) Activation layer: Following convolutional
    operation, each neuron on the output features map will append a parameter, which
    can be adjusted and trained that is referred to as bias. Subsequent to adding
    the bias, the activation function will carry out a nonlinear transformation on
    each output value as Equation (9). Most generally used activation function enhances
    linear unit ReLU: (9) Pooling layer: The pooling layer function is to minimize
    hidden layer dimension, and its mathematical basis is pooling operation. The general
    pooling operations are average pooling and global pooling as stated in the following:
    (10) (11) Fully connected layer: The role of fully connected layer is to extend
    model by the network into a one-dimensional vector as classification outcome,
    subsequently forming a fully connected neural network among input and output,
    as well as the activation of output layer utilizing the soft max function. The
    forward propagation technique of full connection is exhibited as (12) 3 RESULTS
    AND DISCUSSION This section explains about experimentation analysis of the proposed
    DRN model over the conventional methods, such as weighted voting ensemble deep
    learning (Tripathi et al., 2022), DLMLP (Escorcia-Gutierrez et al., 2022), and
    BPNN-IGA model (Liu, Xie, et al., 2023). The experimentation was performed by
    using the metrics, such as MSE, RMSE, and MAE by conducting the experiments in
    both optical sensor and lab prediction. Moreover, the LDR output Vout was measured
    with the help of Arduino (analog read pin). Here, 10 different soils that were
    already tested (NPK) in the soil testing center were examined using the spot NPK
    Sensor in Table 2. The voltage (Vout) measurement for the different soils is mentioned
    in Table 1. Before testing each soil sample, Vout for blank solution was also
    considered. The difference between blank and sample reading was used to compare
    the different results. TABLE 1. Nitrogen, phosphorus, and potassium (NPK) lab
    test reading. Soil sample N PPM Classification P PPM Classification K PPM Classification
    A 58.64 Low 8.93 High 6.06 Low B 59.66 Low 33.06 High 39.66 Medium C 106.26 Medium
    6.55 Medium 114.233 High D 84.03 Low 3.87 Medium 33.9 Low E 104 Medium 27.4 High
    142.3 High F 68.16 Low 10.12 High 75.833 Medium G 69.2 Low 31.28 High 66.43 Medium
    H 63.2 Low 4.76 Medium 110.03 High I 87.2 Low 27.4 High 98.03 High J 111.56 Medium
    52.43 High 141.866 High TABLE 2. Nitrogen, phosphorus, and potassium (NPK) sensor
    reading. NPK sensor reading Sample N PPM P PPM K PPM A 9.32 55.6 9.01 B 9.74 64.2
    30.07 C 21.3 30.72 118.88 D 16.81 7.98 20.6 E 19.7 66.2 167.4 F 12.69 51 61.91
    G 11.53 39.4 40.88 H 10.61 15.7 138.13 I 18.42 82 73.44 J 28.73 80.2 167.41 3.1
    Performance metrics MSE: It is a metric used to determine the square difference
    between predicted and actual values. RMSE: It refers to the square root of the
    average squared difference between actual and predicted values. MAE: It refers
    mean absolute difference between actual and predicted values. 3.2 Comparative
    analysis Figure 6 portrays a comparative evaluation of the models about N-prediction
    for sensor data with respect to MSE, RMSE, and MAE. Figure 6a illustrates an analysis
    of models regarding MSE. With respect to the training data 90, the proposed DRN
    attained a low MSE value of 4.59 e−09, whereas the weighted voting ensemble deep
    learning had a high MSE value of 7.80 e−05 and DLMLP achieved an even higher MSE
    value of 1.80 e−05. Figure 6b portrays the analysis of models regarding RMSE.
    In regard to the training data 90, the proposed DRN attained a low RMSE value
    of 6.78 e−05, whereas the weighted voting ensemble deep learning had a higher
    RMSE value of 0.008 and BPNN-IGA achieved a higher RMSE value of 0.003. The analysis
    of models regarding MAE is demonstrated in Figure 6c. The proposed DRN attained
    a low MAE value of 4.66 e−05, whereas the weighted voting ensemble deep learning
    had a higher MAE value of 0.003 and BPNN-IGA achieved a higher MAE value of 0.0002
    in regard to training data 90. FIGURE 6 Open in figure viewer PowerPoint Analysis
    of the proposed models regarding N-prediction for sensor data: (A) mean squared
    error (MSE), (B) root mean squared error (RMSE), and (C) mean absolute error (MAE).
    Figure 7 shows a comparative evaluation of models in regard to P-prediction for
    sensor data with respect to MSE, RMSE, and MAE. Figure 7a illustrates the analysis
    of models regarding MSE. In terms of the training data 80, the proposed DRN attained
    a low MSE value of 2.40 e−05, whereas the weighted voting ensemble deep learning
    had a higher MSE value of 4.30 e−05. Figure 7b demonstrates the analysis of models
    in regard to RMSE. With respect to the training data 70, the proposed DRN had
    a low RMSE value of 0.003, whereas the BPNN-IGA attained a higher RMSE value of
    0.002. The analysis of models regarding MAE is displayed in Figure 7c. The proposed
    DRN attained a low MAE value of 0.003, whereas the weighted voting ensemble deep
    learning only had a higher MAE value of 0.005 in regard to training data 60. FIGURE
    7 Open in figure viewer PowerPoint Analysis of the proposed models regarding P-prediction
    for sensor data: (A) mean squared error (MSE), (B) root mean squared error (RMSE),
    and (C) mean absolute error (MAE). Figure 8 presents the comparative analysis
    of the different models in regard to K-prediction for sensor data that focus on
    MSE, RMSE, and MAE. In Figure 8a, the models are compared based on MSE. For the
    training data 90, the proposed DRN attained a low MSE value of 1.54 e−06, whereas
    the weighted voting ensemble deep learning achieved a higher MSE value of 4.69
    e−05 and DLMLP achieved a higher MSE value of 3.82 e−05. Figure 8b analyses the
    models regarding RMSE. With respect to the training data 90, the proposed DRN
    achieved a low RMSE value of 1.24 e−03; in contrast, the weighted voting ensemble
    deep learning achieved a higher RMSE value of 0.006 and DLMP achieved an RMSE
    value of 0.006. Figure 8c focuses on the analysis of models regarding MAE. The
    proposed DRN achieved a low MAE value of 1.38 e−05, whereas the weighted voting
    ensemble deep learning achieved a higher MAE value of 0.004 and BPNN-IGA achieved
    a higher RMSE value of 0.001 with regard to training data 90. FIGURE 8 Open in
    figure viewer PowerPoint Analysis of the proposed models regarding K-prediction
    for sensor data: (A) mean squared error (MSE), (B) root mean squared error (RMSE),
    and (C) mean absolute error (MAE). Figure 9 demonstrates the comparative analysis
    of the models in regard to N-prediction for lab results with respect to the MSE,
    RMSE, and MAE. Figure 9a illustrates the analysis of models regarding MSE. Regarding
    the training data 90, the proposed DRN attained a low MSE value of 5.58 e−07,
    whereas the weighted voting ensemble deep learning achieved a higher MSE value
    of 1.24 e−04 and DLMLP achieved an even higher MSE value of 1.17 e−04. Figure
    9b demonstrates the analysis of models regarding RMSE. With respect to the training
    data 90, the proposed DRN achieved a lower RMSE value of 0.0007, whereas the weighted
    voting ensemble deep learning only achieved a higher RMSE value of 0.011 and BPNN-IGA
    achieved an even higher RMSE value of 0.010. The analysis of models regarding
    MAE is displayed in Figure 9c. The proposed DRN achieved a lower MAE value of
    1.67 e−04, whereas the weighted voting ensemble deep learning achieved a high
    MAE value of 0.014 and BPNN-IGA achieved a higher RMSE value of 0.008 as regards
    the training data. FIGURE 9 Open in figure viewer PowerPoint Analysis of the proposed
    models regarding N-prediction for lab result: (A) mean squared error (MSE), (B)
    root mean squared error (RMSE), and (C) mean absolute error (MAE). Figure 10 exhibits
    a comparative evaluation of models as regards P-prediction for lab results with
    respect to the MSE, RMSE, and MAE. Figure 10a illustrates the analysis of models
    regarding MSE. In terms of the training data 80, the DRN attained a low MSE value
    of 2.94 e−03, whereas the weighted voting ensemble deep learning had a high MSE
    value of 0.019. Figure 10b demonstrates the analysis of models regarding RMSE.
    With respect to the training data 70, the DRN attained a low RMSE value of 0.108,
    whereas the BPNN-IGA attained a higher RMSE value of 0.150. The analysis of models
    regarding MAE is displayed in Figure 10c. The DRN achieved a low MAE value of
    0.005, whereas the weighted voting ensemble deep learning attained a higher MAE
    value of 0.008 as regards training data 60. FIGURE 10 Open in figure viewer PowerPoint
    Analysis of the proposed models regarding P-prediction for lab result: (A) mean
    squared error (MSE), (B) root mean squared error (RMSE), and (C) mean absolute
    error (MAE). Figure 11 presents a comparative evaluation of different models regarding
    K-prediction for lab results that focus on MSE, RMSE, and MAE. In Figure 11a,
    the models are compared based on MSE. For the training data 90, the proposed DRN
    achieved a low MSE value of 1.54 e−04, whereas the weighted voting ensemble deep
    learning only achieved a high MSE value of 1.47 e−03 and DLMLP achieved a higher
    MSE value of 1.12 e−03. Figure 11b analyses the models regarding RMSE. With respect
    to the training data 90, the proposed DRN achieved a low RMSE value of 0.012;
    conversely, the weighted voting ensemble deep learning only achieved a high RMSE
    value of 0.038 and DLMP achieved an even high RMSE value of 0.0335. Figure 11c
    focuses on the analysis of models regarding MAE. The proposed DRN achieved a low
    MAE value of 1.19 e−04, whereas the weighted voting ensemble deep learning only
    achieved an MAE value of 0.005 and BPNN-IGA achieved a higher RMSE value of 0.003
    with respect to the training data 90. FIGURE 11 Open in figure viewer PowerPoint
    Analysis of the proposed models regarding K-prediction for lab result: (A) mean
    squared error (MSE), (B) root mean squared error (RMSE), and (C) mean absolute
    error (MAE). Table 3 summarizes the comparative analysis of the models with respect
    to the MSE, RMSE, and MAE for N, P, and K prediction. The overall analysis states
    that the DRN model attains minimal MSE, RMSE, and MAE values than weighted voting
    ensemble deep learning, DLMLP, and BPNN-IGA. It also exhibits that deep learning
    evaluates the amount of NPK soil content accurately, where it finds that the optical
    sensor had attained minimum error than that of the lab test. Thus, it is obvious
    that the soil nutrients determined using the sensor are accurate and are recommended
    to the farmers. TABLE 3. Comparative discussion. N prediction Metrics Weighted
    voting ensemble deep learning DLMLP BPNN-IGA Proposed model MSE 7.80 e−05 1.80
    e−05 1.43 e−05 4.59 e−09 RMSE 0.008 0.004 0.004 6.78 e−05 MAE 0.004 0.003 0.0002
    4.66 e−05 P prediction Metrics Weighted voting ensemble deep learning DLMLP BPNN-IGA
    Proposed model MSE 3.215 e−05 2.90 e−05 1.74 e−05 1.41 e−05 RMSE 0.003 0.002 0.001
    0.0003 MAE 0.003 0.005 0.001 0.0001 K prediction Metrics Weighted voting ensemble
    deep learning DLMLP BPNN-IGA Proposed model MSE 4.69 e−05 3.82 e−05 2.05 e−05
    1.54 e−06 RMSE 0.006 0.006 0.004 1.24 e−03 MAE 0.005 0.003 0.002 1.38 e−05 Abbreviations:
    MAE, mean absolute error; MSE, mean squared error, RMSE, root mean squared error.
    Table 4 summarizes the computational time of the proposed and conventional models.
    Here, the overall analysis states that the proposed technique had low computational
    time than the conventional approaches, thus, proving that the proposed method
    takes less time to evaluate the efficiency of the sensor. TABLE 4. Computational
    time. Methods Computational time (s) BPNN-IGA 296.609 DLMLP 392.474 Weighted voting
    ensemble deep learning 484.061 Proposed deep residual network 279.674 4 CONCLUSIONS
    In this work, the soil nutrients recognized from the soil properties of soil collected
    by using the optical sensors were analyzed for their accuracy by using a deep
    learning algorithm, the DRN model. This DRN model was used for the prediction
    of soil nutrients subsequent to augmenting the collected soil data. Ultimately,
    the experimentation was performed by considering various measures, such as MSE,
    MAE and RMSE in order to recognize how precisely the sensor predicts the soil
    nutrients. The overall analysis states that testing several samples of soils exhibited
    that the optical sensor evaluates the amounts of NPK soil content in an accurate
    manner rather than the lab test. In the near future, the integration of advanced
    optimization algorithms can be integrated to train the deep learning model in
    order to improve the soil nutrient prediction accuracy. Moreover, it can be done
    by optimizing the parameters and identifying the most significant parameter variable
    to predict the soil properties. ACKNOWLEDGMENTS I would like to express my very
    great appreciation to the co-authors of this manuscript for their valuable and
    constructive suggestions during the planning and development of this research
    work. Correction added on 11 December 2023, after first online publication: e-mail
    contact for the corresponding author has been updated. Open Research REFERENCES
    Early View Online Version of Record before inclusion in an issue Figures References
    Related Information Recommended Nutrient uptake and use efficiency in co‐occurring
    plants along a disturbance and nutrient availability gradient in the boreal forests
    of the southwest Yukon, Canada Craig R. Nitschke,  Patrick O. Waeber,  Jan W.
    Klaassen,  Julia Dordel,  John L. Innes,  Cristina Aponte Journal of Vegetation
    Science N, P, AND K BUDGETS ALONG NUTRIENT AVAILABILITY AND PRODUCTIVITY GRADIENTS
    IN WETLANDS H. Olde Venterink,  N. M. Pieterse,  J. D. M. Belgers,  M. J. Wassen,  P.
    C. de Ruiter Ecological Applications Experimental investigation of the importance
    of litterfall in lowland semi‐evergreen tropical forest nutrient cycling Emma
    J. Sayer,  Edmund V. J. Tanner Journal of Ecology Development of an express method
    for measuring soil nitrate, phosphate, potassium, and pH for future in‐field application
    Elena Najdenko,  Frank Lorenz,  Hans-Werner Olfs,  Klaus Dittert Journal of Plant
    Nutrition and Soil Science Faba bean (Vicia faba L.) varieties reveal substantial
    and contrasting organic phosphorus use efficiencies (PoUE) under symbiotic conditions
    Frank K. Amoako,  Ghulam Jillani,  Saad Sulieman,  Karl H. Mühling Journal of
    Plant Nutrition and Soil Science Download PDF Additional links ABOUT WILEY ONLINE
    LIBRARY Privacy Policy Terms of Use About Cookies Manage Cookies Accessibility
    Wiley Research DE&I Statement and Publishing Policies Developing World Access
    HELP & SUPPORT Contact Us Training and Support DMCA & Reporting Piracy OPPORTUNITIES
    Subscription Agents Advertisers & Corporate Partners CONNECT WITH WILEY The Wiley
    Network Wiley Press Room Copyright © 1999-2024 John Wiley & Sons, Inc or related
    companies. All rights reserved, including rights for text and data mining and
    training of artificial technologies or similar technologies."'
  inline_citation: '>'
  journal: Journal of Plant Nutrition and Soil Science
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Deep residual network for soil nutrient assessment using optical sensors
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Fuentes A.
  - Yoon S.
  - Park J.
  - Lee J.
  - Lee M.H.
  - Park D.S.
  citation_count: '0'
  description: Monitoring plant growth is critical for sustainable agriculture. Traditionally,
    this complex analysis has been done manually as a trial and error or by growers'
    perception. Encouraged by the recent advances in precision agriculture and deep
    learning, we sought further improvements to facilitate the efficient use of resources
    and avoid losses caused by internal or external conditions that affect the growth
    process. In this work, we proposed a learnable approach based on deep learning
    techniques to understand the influence of these factors and automatically determine
    the appropriate conditions of crop growth in the spatio-temporal domain using
    multi-category data. To demonstrate the performance of our research, we collected
    data from various sensors installed in controlled tomato greenhouse environments
    in South Korea. Our model enables plant growth prediction based on the measured
    variables and formalizes a systematic and learnable way to analyze the growing
    conditions of crops by combining spatio-temporal characterization of multi-category
    data with existing deep learning-based research. The result of this research could
    potentially help farmers and researchers to understand the changes in the behavior
    of plants and thus achieve maximum productivity and avoid losses caused during
    the growth process.
  doi: 10.17660/ACTAHORTIC.2023.1377.6
  full_citation: '>'
  full_text: '>

    "Acta Horticulturae Home  Login Logout Status  Help  ISHS Home  ISHS Contact  Consultation
    statistics index  Search   ISHS Acta Horticulturae 1377: XXXI International Horticultural
    Congress (IHC2022): International Symposium on Innovative Technologies and Production
    Strategies for Sustainable Controlled Environment Horticulture Spatio-temporal
    characterization of crop growth with multi-category data based on deep learning
    Authors:   A. Fuentes, S. Yoon, J. Park, J. Lee, M.H. Lee, D.S. Park Keywords:   deep
    learning, plant growth modeling, tomato plant, smart agriculture DOI:   10.17660/ActaHortic.2023.1377.6
    Abstract: Monitoring plant growth is critical for sustainable agriculture. Traditionally,
    this complex analysis has been done manually as a trial and error or by growers’
    perception. Encouraged by the recent advances in precision agriculture and deep
    learning, we sought further improvements to facilitate the efficient use of resources
    and avoid losses caused by internal or external conditions that affect the growth
    process. In this work, we proposed a learnable approach based on deep learning
    techniques to understand the influence of these factors and automatically determine
    the appropriate conditions of crop growth in the spatio-temporal domain using
    multi-category data. To demonstrate the performance of our research, we collected
    data from various sensors installed in controlled tomato greenhouse environments
    in South Korea. Our model enables plant growth prediction based on the measured
    variables and formalizes a systematic and learnable way to analyze the growing
    conditions of crops by combining spatio-temporal characterization of multi-category
    data with existing deep learning-based research. The result of this research could
    potentially help farmers and researchers to understand the changes in the behavior
    of plants and thus achieve maximum productivity and avoid losses caused during
    the growth process. Article - full text (enhanced PDF format, 1411270 bytes) Article
    sharing - repository deposits - copyright questions References How to cite this
    article Translate Select Language Afrikaans Albanian Amharic Arabic Armenian Assamese
    Aymara Azerbaijani Bambara Basque Belarusian Bengali Bhojpuri Bosnian Bulgarian
    Catalan Cebuano Chichewa Chinese (Simplified) Chinese (Traditional) Corsican Croatian
    Czech Danish Dhivehi Dogri Dutch Esperanto Estonian Ewe Filipino Finnish French
    Frisian Galician Georgian German Greek Guarani Gujarati Haitian Creole Hausa Hawaiian
    Hebrew Hindi Hmong Hungarian Icelandic Igbo Ilocano Indonesian Irish Italian Japanese
    Javanese Kannada Kazakh Khmer Kinyarwanda Konkani Korean Krio Kurdish (Kurmanji)
    Kurdish (Sorani) Kyrgyz Lao Latin Latvian Lingala Lithuanian Luganda Luxembourgish
    Macedonian Maithili Malagasy Malay Malayalam Maltese Maori Marathi Meiteilon (Manipuri)
    Mizo Mongolian Myanmar (Burmese) Nepali Norwegian Odia (Oriya) Oromo Pashto Persian
    Polish Portuguese Punjabi Quechua Romanian Russian Samoan Sanskrit Scots Gaelic
    Sepedi Serbian Sesotho Shona Sindhi Sinhala Slovak Slovenian Somali Spanish Sundanese
    Swahili Swedish Tajik Tamil Tatar Telugu Thai Tigrinya Tsonga Turkish Turkmen
    Twi Ukrainian Urdu Uyghur Uzbek Vietnamese Welsh Xhosa Yiddish Yoruba Zulu Powered
    by Translate Download Adobe Acrobat Reader (free software to read PDF files)         URL
    www.actahort.org      Hosted by KU Leuven LIBIS      © ISHS"'
  inline_citation: '>'
  journal: Acta Horticulturae
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Spatio-temporal characterization of crop growth with multi-category data
    based on deep learning
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Hanopol G.L.
  - Dela Cruz J.C.
  citation_count: '0'
  description: The color of plant leaves is used as an indicator to detect leaf blight
    disease in plants using digital image processing. Early detection of leaf blight
    disease in plants allows proper protection to avoid the widespread of the disease.
    The general objective of this study was to design and develop a leaf blight detection
    system using image processing and a motion sensor with a laser tripwire alert
    system to detect intrusion and send SMS alerts. The data were randomly divided
    into three portions, with 75% being allocated as the training dataset, 22% as
    validation, and 3% as testing. The YOLOv5 object detection model was trained to
    detect leaf blight disease, resulting in a mean average precision of 38.80% (mAP
    0.5) and 13.3% (mAP 0.5:0.95), with a precision of 56% and a recall of 37.90%.
    The low performance can be attributed to the low number of datasets involved,
    also, there were no essential steps carried out in image analysis that helped
    enhance the data in images namely, noise reduction, contrast enhancement, image
    resizing, color correction, and segmentation. To improve the performance of the
    system, an additional data enhancement in images may be implemented to simplify
    the image and easier to analyze namely, preprocessing, feature extraction, feature
    selection, and classification. Also, the use of additional prevailing algorithms
    namely, SVM + Deep Features, ANN, and Fast R-CNN can help improve the accuracy
    of results. In addition, the motion sensor and laser tripwire for detecting intrusions,
    have high accuracy rates of 90% and 95%, respectively. Furthermore, the motion
    sensor and GSM module responsiveness has an average of 6.54 seconds out of 20
    trials while the tripwire sensor and GSM module responsiveness has an average
    of 6.53 seconds out of 20 trials as well.
  doi: 10.1109/ICSGRC57744.2023.10215447
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2023 IEEE 14th Control and Sy... Design
    and Development of a Leaf Blight Detection System Using Image Processing with
    Intrusion Notification via SMS Publisher: IEEE Cite This PDF Gina L. Hanopol;
    Jennifer C. Dela Cruz All Authors 76 Full Text Views Abstract Document Sections
    I. Introduction II. Methodology III. Results and Discussion IV. Conclusion V.
    Recommendation Authors Figures References Keywords Metrics Abstract: The color
    of plant leaves is used as an indicator to detect leaf blight disease in plants
    using digital image processing. Early detection of leaf blight disease in plants
    allows proper protection to avoid the widespread of the disease. The general objective
    of this study was to design and develop a leaf blight detection system using image
    processing and a motion sensor with a laser tripwire alert system to detect intrusion
    and send SMS alerts. The data were randomly divided into three portions, with
    75% being allocated as the training dataset, 22% as validation, and 3% as testing.
    The YOLOv5 object detection model was trained to detect leaf blight disease, resulting
    in a mean average precision of 38.80% (mAP 0.5) and 13.3% (mAP 0.5:0.95), with
    a precision of 56% and a recall of 37.90%. The low performance can be attributed
    to the low number of datasets involved, also, there were no essential steps carried
    out in image analysis that helped enhance the data in images namely, noise reduction,
    contrast enhancement, image resizing, color correction, and segmentation. To improve
    the performance of the system, an additional data enhancement in images may be
    implemented to simplify the image and easier to analyze namely, preprocessing,
    feature extraction, feature selection, and classification. Also, the use of additional
    prevailing algorithms namely, SVM + Deep Features, ANN, and Fast R-CNN can help
    improve the accuracy of results. In addition, the motion sensor and laser tripwire
    for detecting intrusions, have high accuracy rates of 90% and 95%, respectively.
    Furthermore, the motion sensor and GSM module responsiveness has an average of
    6.54 seconds out of 20 trials while the tripwire sensor and GSM module responsiveness
    has an average of 6.53 seconds out of 20 trials as well. Published in: 2023 IEEE
    14th Control and System Graduate Research Colloquium (ICSGRC) Date of Conference:
    05-05 August 2023 Date Added to IEEE Xplore: 16 August 2023 ISBN Information:
    ISSN Information: DOI: 10.1109/ICSGRC57744.2023.10215447 Publisher: IEEE Conference
    Location: Shah Alam, Malaysia SECTION I. Introduction Several studies have shed
    light upon the use of digital image processing for different range of purposes,
    such as water content of forest lichens [1] and soil [2] , photoplethysmography
    [3] , canopy light interception [4] , anthocyanin in lettuce leaf [5] , the green
    color of vegetables [6] , image segmentation [7] , and blight detection in potato
    and tomato [8] . In this study, the color of plant leaves is used as an indicator
    to detect leaf blight disease in plants using digital image processing [9] [10]
    . Early detection of leaf blight disease in plants allows proper protection to
    avoid the widespread of the disease. The following enumerates the various traditional
    methods of detecting leaf blight disease in plants, namely: visual observation,
    microscopy, and mycological analysis [11] , among others. However, to ensure the
    reliability of diagnostics, it is necessary to undergo appropriate screening procedures
    using antibody-based detection and enzyme-linked immunosorbent assay (ELISA) [11]
    . ELISA is a valuable tool in detecting plant viruses and is popular due to its
    high-efficiency potential. Among the major drawback of ELISA involves a sensitive
    process, thus, expensive and labor-intensive preparation is needed. However, with
    the advancement in technology, leaf blight disease detection can be implemented
    by remote sensing technology using digital image processing applications [12]
    . In this process, the leaf blight disease sample can be analyzed in the absence
    of physical contact. An image of the leaf blight disease sample will be captured
    by the camera module and the image can be trained on various healthy and diseased
    plant image datasets using the YOLOv5 model. Although many versions of YOLO were
    considered before the conduct of this study, the researchers decided to use YOLOv5.
    According to [13] , when the two versions of YOLO, YOLOv5 and YOLOv7, were compared
    in terms of precision, recall, and mAP, the experiment conducted showed that YOLOv5
    gave a better result than YOLOv7. In terms of accuracy and speed, according to
    [14] [15] , it was found that YOLOv5 performs better than previous YOLO versions
    (YOLOv3 and YOLOv4). Also, a motion sensor and laser tripwire were connected to
    the system to detect intrusion in the perimeter area when an animal or object
    passes the sensor and tripwire; and an intrusion notification via SMS with a buzzer
    was added to enhance the efficiency of the overall system. The general objective
    of this study was to design and develop a leaf blight detection system using image
    processing and a motion sensor with a laser tripwire alert system to detect intrusion
    and send SMS alerts. Specifically, the study aims to: (1) develop a machine learning
    system and apply YOLOv5 to detect leaf blight disease and intrusion using images;
    (2) design and develop the prototype; and (3) test and evaluate the prototype.
    The following were the delimitations of this study: (1) The system was tested
    in a controlled setting; (2) The visual information was provided by the camera
    and the tripwire; (3) The system was limited by the range and accuracy of the
    sensors and other hardware components, as well as the availability and reliability
    of GSM and other communication technologies. The prototype was developed using
    the following essential components: a camera, laser tripwire, Arduino microcontroller,
    and GSM module. SECTION II. Methodology This section describes the methods used
    to design and develop a leaf blight detection system using image processing and
    a motion sensor with a laser tripwire alert system to detect intrusion and send
    SMS alerts. Figure 1 outlines the processes involved in the conduct of this study
    namely: healthy and diseased plant image acquisition, YOLO algorithm, program
    development, hardware assembly, testing, and evaluation of prototype. Fig. 1 Process
    diagram of design and development of a leaf blight detection system using image
    processing and animal intrusion notification via sms. Show All A. Healthy and
    Diseased Plant Images Acquisition In this study, a random sample of 50 healthy
    and unhealthy plant images were acquired either through the use of a camera module
    connected to an Arduino microcontroller and a computer or through the use of plant
    images available on the internet. The images were processed using an image processing
    algorithm to analyze the plant’s health and identify potential intrusion threats.
    B. YOLO Algorithm YOLO (You Only Look Once) algorithm was used for image processing
    in the design and development of a leaf blight detection system. The YOLO algorithm
    is a machine learning-based method for identifying and classifying objects within
    images and has been demonstrated to achieve high accuracy rates with low computational
    cost, according to [16] . This makes it well-suited for real-time monitoring applications,
    such as the leaf blight detection system. The YOLO algorithm will be used to process
    images taken by the camera module, dividing the images into a grid and using machine
    learning techniques to identify and classify objects within each grid cell. By
    incorporating the YOLO algorithm into the system, the researchers will be able
    to efficiently and accurately analyze images of plants to determine their health
    and identify potential issues. C. Program Development Fig. 2 shows how the system
    was designed to detect intrusions on the perimeter area and monitor the health
    of plants. It uses a combination of a motion sensor and a tripwire system to detect
    animal or object movements. The tripwire system consists of a light sensor, a
    laser emitter, and a buzzer. When an intrusion is detected, the device will activate
    the buzzer alarm and send a notification via the GSM module. For plant monitoring,
    the device uses a camera to capture real-time images of the plants. The captured
    images will be processed using an algorithm that classifies the plants based on
    a dataset of plants with various diseases. This will allow the device to monitor
    the health of the plants. The device was programmed using the Python programming
    language and will use an Arduino Uno microcontroller to control the sensors and
    other components. Fig. 2 Program Flowchart. Show All D. Leaf Blight Detection
    and Tripwire Alarm Prototype The system prototype was comprised of four (4) major
    components: an Arduino Uno microcontroller, a camera module, a tripwire system,
    and a GSM module. The Arduino Uno microcontroller is responsible for controlling
    the various components of the system and processing the data collected. The camera
    module is used to capture images of the plants, which will be transferred to a
    computer for image processing and analysis using Arduino. The condition of the
    plants will be displayed on the computer using a desktop application. The tripwire
    system (consisting of a light sensor, a laser emitter, a power source, and a buzzer)
    or motion sensor is used to detect intrusions and trigger an alarm. Finally, the
    GSM module is used to send a notification whenever an intrusion is detected. E.
    Testing and Evaluation To test and evaluate the performance of the system, the
    researchers conducted a test using a trained dataset fed to the system. A random
    sample of 50 healthy and unhealthy plants was used as a test to check if the system
    will predict the status of the plant. The researchers used a multiclass classification
    model to calculate the model’s accuracy as the number of correct predictions divided
    by the total number of predictions made. This allowed them to determine the effectiveness
    of the system in accurately predicting the health of plants. On the other hand,
    to evaluate the accuracy of the system for animal intrusion detection, the researchers
    conducted an initial test before the final evaluation of the prototype. During
    the initial test, all components, including the tripwire and motion sensor, were
    evaluated to ensure proper functionality with the GSM module and buzzer by conducting
    10 trials. In the final testing, the researchers simulated 20 triggers of the
    tripwire and motion sensor with the full set-up system, to assess whether the
    system would activate the alarm and send notifications to the designated number
    through the provided desktop application. The accuracy of the multiclass classification
    model (1) was also calculated, using the formula of the number of correct predictions
    divided by the total number of predictions made [17] . ( y i , z i )= 1 n Σ n
    1 [ y i == z i ]] (1) View Source where, n is the number of plant samples Iverson
    bracket (“[[ ]]”) that return 1 if true and 0 if false y i and z i are the true
    and predicted output labels of the given plant samples. SECTION III. Results and
    Discussion A. Healthy and Diseased Plant Images The collected plant images were
    classified into two categories: healthy plants and those with leaf blight diseases.
    The image acquisition process involved a combination of manual capturing, using
    a high-resolution digital camera to randomly select and photograph plants. Also,
    internet browsing to supplement the collection with additional images related
    to leaf blight diseases and healthy plants. The categorization was based on visual
    inspection of the images and the presence or absence of leaf blight disease symptoms,
    and the resulting collection of images is presented in Figure 3 . This process
    ensured a diverse range of plant specimens were captured and analyzed, providing
    a comprehensive representation of the diversity of the specimens and the nature
    of the disease symptoms. Fig. 3 (a) Healthy Plants; (b) Plants with Leaf Blight
    Disease Show All B. YOLO Algorithm The study utilized the YoloV5 algorithm to
    train a model for detecting leaf blight disease in images of plants. The training
    dataset consisted of 400 images, with 10 images serving as background and 390
    images depicting leaf blight disease. The data were randomly divided into three
    portions, with 75% being allocated as the training dataset, 22% as validation,
    and 3% as testing. Computing the Mean Average Precision (mAP) and the Precision
    and Recall values were performed to evaluate the model. Figure 4 , indicates the
    model achieved an overall mAP of 38.80% (mAP 0.5) and 13.3% (mAP 0.5:0.95), a
    Precision of 56%, and a Recall of 37.90%. While these results demonstrate the
    capability of the trained model in detecting leaf blight disease, the low performance
    can be attributed to the low number of datasets involved, also, there were no
    essential steps carried out in image analysis that helped enhance the data in
    images namely, noise reduction, contrast enhancement, image resizing, color correction,
    and segmentation. However, the results indicated that the system was able to detect
    both healthy and diseased plants with a degree of accuracy. Fig. 4 Performance
    Metrics of the Trained Model. Show All C. Leaf Blight Detection and Tripwire Alarm
    Prototype The schematic diagram in Figure 5 displays the connections between the
    main components, including the PIR sensor, laser sensor, photoresistor, buzzer,
    power supply, and Arduino Uno R3. Fig. 5 Schematic Diagram of Leaf Blight Detection
    and Tripwire Alarm. Show All The dimension of the prototype shown in Figure 6
    was 230cm × 205cm × 168cm. The enclosure of the prototype was made of cardboard
    to easily modify and organize the wirings of the sensors. Figure 7 displays the
    desktop application for the prototype, which displays the status of both the plant
    and security. Fig. 6 Leaf Blight Disease Detection and Tripwire Alarm Prototype.
    Show All Fig. 7 Leaf Blight Disease Detection and Tripwire Alarm Desktop Application.
    Show All D. Testing and Evaluation Based on the results of the evaluation where
    50 healthy and 50 diseased plants were tested, the accuracy of the detection system
    for healthy plants improved which was 80%, with 40 out of 50 accurately identified.
    On the other hand, the accuracy for diseased plants also rose which was 72%, with
    36 out of 50 correctly identified as shown in Fig. 8 . Fig. 8 Detection for Healthy
    and Diseased Plants. Show All All components of the prototype were functioning
    properly during the initial test of the motion sensor and tripwire alarm. The
    device was tested 10 times for the motion sensor and the camera module, which
    was mounted at a 45-degree angle and aimed towards the perimeter area where the
    possible intrusion is expected to occur. It has a 70% accuracy where it accurately
    predicted 7 out of 10 times. The tripwire alarm was also tested 10 times and was
    placed near the entrance. The laser and LDR had their enclosure to avoid any interference
    from other light sources. The tripwire alarm has an accuracy of 80% and accurately
    predicted 8 out of 10. Fig. 9 Detection of Motion Sensor and Tripwire Alarm. Show
    All The final evaluation of the intrusion detection system, using the motion sensor
    and tripwire alarm, was conducted 20 times. Figures 8 and Table 1 demonstrate
    that the motion sensor achieved an accuracy rate of 90%, with an average time
    delay of 6.54 seconds after the SMS was sent to the user by the GSM module. The
    tripwire alarm, on the other hand, had a higher accuracy rate of 95% and an average
    time delay of 6.53 seconds after the SMS was sent to the user by the GSM module
    based on Figure 9 and Table 2 . TABLE I Motion sensor and GSM module responsiveness
    TABLE II Tripwire alarm and GSM module responsiveness SECTION IV. Conclusion The
    development of a leaf blight detection system using image processing and animal
    intrusion notification via sms was the focus of this study. The study used the
    YOLOv5 algorithm to train a model for detecting leaf blight disease in images
    of plants and achieved an overall mean average precision of 38.80% (mAP 0.5) and
    13.3% (mAP 0.5:0.95), a Precision of 56%, and a Recall of 37.90%. The low performance
    can be attributed to the low number of datasets involved, also, there were no
    essential steps carried out in image analysis that helped enhance the data in
    images namely, noise reduction, contrast enhancement, image resizing, color correction,
    and segmentation. To improve the performance of the system, an additional data
    enhancement in images may be implemented to simplify the image and easier to analyze
    namely, preprocessing, feature extraction, feature selection, and classification.
    Also, the use of additional prevailing algorithms namely, SVM + Deep Features,
    ANN, and Fast R-CNN can help improve the accuracy of results. The results of the
    initial testing for the motion sensor and tripwire alarm showed that the prototype
    was functioning well, with the final evaluation achieving an accuracy rate of
    90% for the motion sensor and 95% for the tripwire alarm. Furthermore, the motion
    sensor and GSM module responsiveness has an average of 6.54 seconds out of 20
    trials while the tripwire sensor and GSM module responsiveness has an average
    of 6.53 seconds out of 20 trials as well. SECTION V. Recommendation Further testing
    with a larger sample size may be required to improve accuracy. Implement additional
    data enhancement in images to simplify the image and easier to analyze namely,
    preprocessing, feature extraction, feature selection, and classification. Also,
    the use of additional prevailing algorithms namely, SVM + Deep Features, ANN,
    and Fast R-CNN can help improve the accuracy of results. Authors Figures References
    Keywords Metrics More Like This A TS Fuzzy System Learned Through a Support Vector
    Machine in Principal Component Space for Real-Time Object Detection IEEE Transactions
    on Industrial Electronics Published: 2012 Enhanced feature extraction method for
    hand gesture recognition using support vector machine 2013 IEEE 8th International
    Conference on Industrial and Information Systems Published: 2013 Show More IEEE
    Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW
    PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: 2023 IEEE 14th Control and System Graduate Research Colloquium, ICSGRC
    2023 - Conference Proceeding
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Design and Development of a Leaf Blight Detection System Using Image Processing
    with Intrusion Notification via SMS
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Rodríguez C.
  - Moscol I.
  citation_count: '0'
  description: Wireless communication in recent years has managed to open doors to
    change the quality of life in society. Its impact has influenced multiple areas,
    such as the energy field, health, buildings, and agriculture, among others, making
    the management of activities practically automatic and less risky. This chapter
    aims to give an overview of the most common and current applications of WSNs,
    as well as to mention the main problems and disadvantages when implementing them.
    WSNs are powerful tools that provide access to large amounts of data in remote
    conditions; however, the way to increase their period of activity associated with
    electric power is still under study. For this purpose, the possibility of combining
    them with renewable energies is being evaluated. The solution to the requirements
    of WSNs will boost their performance in solving time-critical and precision problems,
    mainly in fields such as agriculture and medicine. In addition, this chapter mentions
    previous methods for the correct implementation of WSNs, such as simulators, specifically
    network simulators (NS2 and NS3 versions), which are tools that are commonly used
    to test WSNs since they verify the performance of the network and allow corrections
    to be made prior to its manufacture. Each communication technology is classified
    according to different attributes, mainly by communication range and data transfer
    rate. In conclusion, WSNs provide advantages in multiple social areas, whose criticality
    makes use of well-implemented and secure networks, that transmit data reliably,
    in real-time, and with the required accuracy to support the monitoring and control
    of industrial plants or medical analysis.
  doi: 10.1201/9781003326205-6
  full_citation: '>'
  full_text: '>

    "Access Provided By:University of Nebraska-Lincoln T&F eBooks ‍ Advanced Search
    Login About Us Subjects Browse Products Request a trial Librarian Resources What''s
    New!! HomeComputer ScienceSystems & Computer ArchitectureNetworksAdvanced Wireless
    Communication and Sensor NetworksAdvanced Wireless Communication and Sensor Networks
    Chapter Advanced Wireless Communication and Sensor Networks Applications and Simulations
    ByCiro Rodríguez, Isabel Moscol Book Advanced Wireless Communication and Sensor
    Networks Edition 1st Edition First Published 2023 Imprint Chapman and Hall/CRC
    Pages 8 eBook ISBN 9781003326205 Share ABSTRACT Wireless communication in recent
    years has managed to open doors to change the quality of life in society. Its
    impact has influenced multiple areas, such as the energy field, health, buildings,
    and agriculture, among others, making the management of activities practically
    automatic and less risky. This chapter aims to give an overview of the most common
    and current applications of WSNs, as well as to mention the main problems and
    disadvantages when implementing them. WSNs are powerful tools that provide access
    to large amounts of data in remote conditions; however, the way to increase their
    period of activity associated with electric power is still under study. For this
    purpose, the possibility of combining them with renewable energies is being evaluated.
    The solution to the requirements of WSNs will boost their performance in solving
    time-critical and precision problems, mainly in fields such as agriculture and
    medicine. In addition, this chapter mentions previous methods for the correct
    implementation of WSNs, such as simulators, specifically network simulators (NS2
    and NS3 versions), which are tools that are commonly used to test WSNs since they
    verify the performance of the network and allow corrections to be made prior to
    its manufacture. Each communication technology is classified according to different
    attributes, mainly by communication range and data transfer rate. In conclusion,
    WSNs provide advantages in multiple social areas, whose criticality makes use
    of well-implemented and secure networks, that transmit data reliably, in real-time,
    and with the required accuracy to support the monitoring and control of industrial
    plants or medical analysis. Previous Chapter Next Chapter Your institution has
    not purchased this content. Please get in touch with your librarian to recommend
    this.  To purchase a print version of this book for personal use or request an
    inspection copy  GO TO ROUTLEDGE.COM  Policies Privacy Policy Terms & Conditions
    Cookie Policy Journals Taylor & Francis Online Corporate Taylor & Francis Group
    Help & Contact Students/Researchers Librarians/Institutions Connect with us Registered
    in England & Wales No. 3099067 5 Howick Place | London | SW1P 1WG © 2024 Informa
    UK Limited"'
  inline_citation: '>'
  journal: 'Advanced Wireless Communication and Sensor Networks: Applications and
    Simulations'
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Advanced Wireless Communication and Sensor Networks: Applications and Simulations'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Tharzeen A.
  - Munikoti S.
  - Prakash P.
  - Kim J.
  - Natarajan B.
  citation_count: '1'
  description: Many applications from precision agriculture, environmental monitoring
    and transportation networks rely on data collected across space and time over
    a large geographic area. Missing data can be a significant issue in these spatiotemporal
    databases, as it can reduce the accuracy of downstream data analysis, inferencing
    and control algorithms. Data imputation or the estimation of missing data can
    help fill these gaps by utilizing inherent spatial relationships and temporal
    patterns. However, existing approaches for estimating this missing information
    do not effectively capture all dimensions of the spatiotemporal data structure,
    resulting in erroneous predictions and poor performance. In this paper, we introduce
    a general framework that leverages a spatiotemporal graph constructed from the
    sensor network graph and temporal sensor data to capture the joint space-time
    dependencies. Specifically, we propose a graph neural network-based model in conjunction
    with a recurrent neural network to impute missing information and demonstrate
    the effectiveness of our approach for downstream tasks. Experiments on a traffic
    sensor network reveal enhanced imputation accuracy and up to 69% reduction in
    mean absolute error and 61% reduction in root mean square error compared to state-of-the-art
    imputation frameworks.
  doi: 10.1109/CAI54212.2023.00032
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2023 IEEE Conference on Artif... A General
    Spatiotemporal Imputation Framework for Missing Sensor Data Publisher: IEEE Cite
    This PDF Aabila Tharzeen; Sai Munikoti; Punit Prakash; Jungkwun Kim; Balasubramaniam
    Natarajan All Authors 184 Full Text Views Abstract Document Sections I. Introduction
    II. Problem Statement III. Proposed G-LSTM Framework IV. Results V. Conclusions
    and Future Work Authors Figures References Keywords Metrics Abstract: Many applications
    from precision agriculture, environmental monitoring and transportation networks
    rely on data collected across space and time over a large geographic area. Missing
    data can be a significant issue in these spatiotemporal databases, as it can reduce
    the accuracy of downstream data analysis, inferencing and control algorithms.
    Data imputation or the estimation of missing data can help fill these gaps by
    utilizing inherent spatial relationships and temporal patterns. However, existing
    approaches for estimating this missing information do not effectively capture
    all dimensions of the spatiotemporal data structure, resulting in erroneous predictions
    and poor performance. In this paper, we introduce a general framework that leverages
    a spatiotemporal graph constructed from the sensor network graph and temporal
    sensor data to capture the joint space-time dependencies. Specifically, we propose
    a graph neural network-based model in conjunction with a recurrent neural network
    to impute missing information and demonstrate the effectiveness of our approach
    for downstream tasks. Experiments on a traffic sensor network reveal enhanced
    imputation accuracy and up to 69% reduction in mean absolute error and 61% reduction
    in root mean square error compared to state-of-the-art imputation frameworks.
    Published in: 2023 IEEE Conference on Artificial Intelligence (CAI) Date of Conference:
    05-06 June 2023 Date Added to IEEE Xplore: 02 August 2023 ISBN Information: DOI:
    10.1109/CAI54212.2023.00032 Publisher: IEEE Conference Location: Santa Clara,
    CA, USA Funding Agency: SECTION I. Introduction The emergence of IoT-based systems
    empowered by advances in sensing, communication and control has triggered a wealth
    of applications that rely on data collected across space and time. Examples of
    applications that rely on spatiotemporal data from sensor networks include power
    systems, traffic networks, air quality monitoring, and precision agriculture.
    While the integrated spatial and temporal information can lead to more efficient
    data analysis, the spatiotemporal data often contain missing observations due
    to various factors such as malfunctioning sensors or communication errors [1].
    The presence of missing data can significantly reduce the accuracy of downstream
    tasks such as classification, clustering, and forecasting, leading to unreasonable
    inferences. Therefore there is a need to develop effective missing data imputation
    strategies that can be used in the preprocessing step or develop models that are
    robust to missing data. A. Related work A variety of spatiotemporal imputation
    models have been developed to address missing data in spatiotemporal datasets.
    Some of the classic statistical methods involve interpolation-based methods that
    use linear interpolation to estimate missing values based on the values from the
    neighboring time/spatial points [2], [3]. However, these classical methods rely
    on the assumption that the underlying data follows a smooth trend and fail to
    provide accurate estimates when there is a large number of missing points in the
    data. Yet another method to impute the missing data is by estimating/assuming
    the correlation between multiple variables in the dataset [4]. This approach requires
    a high degree of statistical expertise and can be computationally expensive [5].
    Multilinear tensor completion that uses a low-rank tensor approximation based
    on observed entries to reconstruct the missing values is proposed in [6]. While
    the approach in [6] effectively captures multi-dimensional structural dependencies,
    it is unsuitable for complex interactions and diverse data missing patterns. A
    convolutional neural network based tensor completion (CoSTCo) method was proposed
    in [7]. While CoSTCo captures the non-linear relationships in the dataset, the
    transductive nature makes the algorithm less scalable. Imputation techniques based
    on machine learning algorithms use k-nearest neighbors [8] or support vector machines
    to estimate missing values based on patterns in the data [9]. These methods do
    not attempt to capture the complex relationships inherent in the spatiotemporal
    data and only rely on data similarity metrics. Recently, deep learning-based approaches
    have been proposed to impute missing data. Denoising stacked autoencoder (DSAE)
    [10], is a typical deep learning model that combines denoising and autoencoders
    for imputation. However, DSAE does not account for the underlying spatial correlations.
    To leverage the spatial correlations, [11] proposes a multi-range convolutional
    neural network (CNN) to model spatial correlations and impute missing information.
    Though the method proposed in [11] effectively handles correlations in Euclidean
    space, they are inefficient in modeling relationships in non-Euclidean spaces.
    Recently, graph structures for relational reasoning have been utilized in Graph
    Convolutional Networks (GCN) [12], [1]. Though GCN is effective in modeling topological
    relationships, it is not tailored to capture temporal dependencies. Alternatively,
    recurrent neural network-based models can impute time series with missing values.
    Specifically, long short-term memory (LSTM) networks can capture and maintain
    long-term dependencies [13]. B. Contributions In this work, we propose a novel
    inductive framework (GLSTM) for missing data imputation that integrates a graph
    neural network with LSTMs to effectively capture both spatial and temporal dependencies.
    We use GraphSAGE [14] as a GNN module which is an inductive method and computationally
    efficient compared to GCN. Furthermore, GraphSAGE allows for incorporating node
    features in the embedding generation process, which can be useful for tasks where
    node attributes are essential. The proposed general framework can be used for
    both data imputation and prediction. The performance of the proposed framework
    is highlighted using comprehensive case studies on real-world traffic datasets.
    The case studies include missing rates ranging from 10 % to 90%. Experimental
    results demonstrate that the proposed GNN integrated with the LSTM framework achieves
    improved imputation and maintains steady performance even when there are extreme
    missing conditions in comparison with the state-of-the-art imputation framework
    CoSTCo. The simulation results on the traffic network show up to 69% reduction
    in mean absolute error and 61% reduction in root mean square error when compared
    to state-of-the-art imputation framework. The remainder of this paper is structured
    as follows. Section III introduces the imputation problem description and the
    required background. The proposed approach is explained in section IV and the
    results are discussed in section V. Finally, section VI concludes the paper. SECTION
    II. Problem Statement We represent the spatiotemporal dataset as an undirected
    graph G = (A, E, Xt), where A ∈ ℝℕ × ℕ denotes the spatial adjacency matrix; N
    denotes the number of sensors and the element ai,j ∈ A is 1 if the sensors i and
    j are adjacent; Edge E represents the spatial relationship between the sensors,
    and X t ∈ R N×D is the set of D dimensional dynamic features measured at each
    sensor placed at various locations at time t. Given the incomplete feature values
    from each sensor at different time instances, the goal is to impute the missing
    feature values by considering spatial and temporal dependencies. The observability
    of the feature values/measurements is captured by a binary mask matrix Mt ∈ {0,1}N×D
    with elements as 1 if X (i,j) t is observed and 0 otherwise. Given the incomplete
    sensor measurements Yt = Mt ⊙ Xt,, the objective is to reconstruct the missing
    sensor measurements and estimate the complete matrix Ŷt. Analysis of spatiotemporal
    data becomes harder due to complicated underlying patterns. The use of a network
    topology aids in explicitly modeling and capturing the underlying complex spatiotemporal
    connections. SECTION III. Proposed G-LSTM Framework The proposed spatiotemporal
    imputation framework is depicted in figure 1. The framework consists of a spatial
    module integrated with a temporal module to estimate Ŷt. These modules are described
    next. Spatial Module: The spatial module in our framework captures the spatial
    relationships within the data. The module consists of multiple stacked layers
    of GraphSAGE (SAmple and aggreGatE) [14]. Each node in the graph is represented
    by a node embedding vector that helps capture the structural information. GraphSAGE
    is an inductive approach in which the algorithm learns a mapping (aggregator)
    function instead of the node embedding vector. The two primary steps associated
    with GraphSAGE are aggregate and update. Each node in the graph is uniquely represented
    by a feature vector. The aggregate step aggregates the neighboring node representations
    (feature vectors) for our target node. After obtaining an aggregated representation
    for node v based on its neighbors, the feature representation of the current node
    v is updated using a combination of its previous representation. GraphSAGE’s inductive
    nature allows it to infer the node embedding vector for nodes not encountered
    during training, making it suitable for our imputation framework. The GNN module
    takes the spatial adjacency matrix and the observed feature values at each time
    instance. It captures the spatial information using the message-passing mechanism
    of a Graph Neural Network. The GNN output, which consists of features learned
    from spatial dependencies, is then passed on to the temporal module described
    next. Temporal Module: Temporal modules are used for capturing the temporal relations
    in the data. In this work, the temporal module is driven by Long Short Term Memory
    (LSTM) memory networks [15] for our imputation framework. LSTMs have been shown
    to perform well on sequence-based tasks with long-term dependencies, assisting
    in capturing temporal associations. The reconstruction loss calculated during
    the training is on the entire observation and helps to learn the inherent relationships
    among the entire spatiotemporal dataset. The patterns learned and propagated help
    update/ impute data at the missing location and time instants. The spatiotemporal
    data is loaded and punctured to create missing values (the missing locations are
    given zero values). Then, the data is split temporally into training and testing
    segments. Finally, the ST block is trained and the recovered values are used for
    evaluation by comparison with the original input data. The loss function used
    for evaluation corresponds to the following: L(θ)= ∑ v=1 N ∑ t=1 T ( x v t − x
    ^ v t ) 2 − − − − − − − − − − − − − −  ⎷   (1) View Source where L(θ) is the
    reconstruction error on both observed and missing data. x v t and x ^ v t are
    the actual and estimated values respectively for node v and time t. A. Complexity
    Analysis: In this subsection, we discuss the computational complexities of the
    proposed algorithm. The computing cost of the G-LSTM is concentrated on the GraphSAGE
    layers and the LSTM layers. Suppose for a graph that is being considered there
    are n number of nodes, r number of neighbors being sampled for each node and m
    the total number of edges and K number of layers. The computational complexity
    of the GraphSAGE can be represented as O( r K n d 2 ) . For an LSTM with h as
    the hidden layer dimension and b as the input feature, the computational complexity
    is O(4h(b+2+h)) . Thus the computational complexity of the G-LSTM framework can
    be approximated as O( r K n d 2 +4h(b+2+h)) . Fig. 1. Structure of proposed spatiotemporal
    imputation network Show All SECTION IV. Results In this section, we evaluate the
    performance of the proposed imputation method on a real-world traffic dataset.
    We introduce the dataset and explain the experimental settings first. Then various
    missing data scenarios are considered. The imputation performance of the proposed
    method is compared with Costco, a neural tensor completion-based imputation framework
    as the baseline. A. Traffic-State dataset: PeMSD7 is a traffic dataset collected
    from Caltrans Performance Measurement System (PeMS) and describes the speed detectors
    covering the freeway system in all major California urban centers. Among the 1000
    sensors placed on the arterial roads of District 7 in California, we chose 228
    sensors for our study, similar to [16]. The dataset consists of 5-min average
    traffic speed data collected from May 1, 2012, to June 30, 2012, and has 11232
    time points. The graphical representation of the PEMS dataset was created in a
    manner similar to [16]. The nodes correspond to each sensor in the network and
    the initial node features are the speed values concatenated with the singular
    value decomposition (SVD) of the weighted adjacency matrix. The SVD values concatenated
    with the speed values aid in uniquely identifying the nodes [17]. For computational
    purposes, the data is normalized. The imputation performance is evaluated using
    two metrics, root mean square error (RMSE) and mean absolute error (MAE) defined
    as, RMSE= 1 n ∑ i=1 n ( x i − x i ˆ ) 2 − − − − − − − − − − − − − √ MAE= 1 n ∑
    i=1 n | x i − x i ˆ | (2) (3) View Source where, n is the number of missing values,
    xi is the ith missing value and x i ˆ is the imputed value of xi. B. Experimental
    Results: For training and testing purposes, the dataset is split temporally. The
    initial 80% of time instances are used for training purposes and the remaining
    20% is used for testing. The data is scaled to be between 0 and 1 before imputation
    and the output of the proposed approach is rescaled back to the original values.
    It is assumed that the sensors at specific locations were absent across all time
    instances to simulate the missing values. The proposed imputation framework model
    is trained by Adam optimizer [18]. The learning rate is set at 0.001 with the
    ReLu activation function after the GNN layers. The time window for the LSTM is
    set as one in order to maintain an end-to-end training framework and the temporal
    information is captured by the hidden and the cell states. All experiments are
    implemented with PyTorch and conducted on an NVIDIA GeForce RTX 3070 GPU. To evaluate
    the performance of the proposed approach, we compare its performance with CoSTCo
    [7], a state-of-the-art convolution neural network-based tensor completion approach.
    CoSTCo tries to address the inability of multilinear models to generate a low-rank
    representation of non-linear data. It utilizes the activation functions in a convolutional
    neural network to capture non-linear relationships. Table I summarizes the experimental
    results using our proposed approach compared with CoSTCo as the baseline. The
    imputation errors are calculated with various missing ratios for a single time
    instant. The results are averaged over five random missing scenarios for each
    of the missing ratios. It can be seen that the proposed approach (G-LSTM) outperforms
    the baseline and as the percentage of missing information increases, the imputation
    error metrics remain steady and sometimes show improvement. This surprising observation
    can be attributed to the possibility that at a lower percentage of missing data,
    the GNN may be overfitting. As fewer data are available (or the missing percentage
    increases), the overfitting behavior is less likely. The G-LSTM is trained with
    50% of missing data and the pre-trained model is used for imputing the data with
    10%, 30%, 70% and 90% of missing information. From the results shown in table
    I, it can be seen that for missing percentages lesser than 50%, the pre-trained
    G-LSTM model gives improved results compared to the corresponding G-LSTM model
    and CoSTCo. For missing percentages greater than 50%, the pre-trained G-LSTM outperforms
    CoSTCo. However, the pre-trained model shows slightly inferior performance with
    respect to G-LSTM. The results indicate that the model trained for higher missing
    percentages can impute the data with lower missing information more efficiently
    and thus possess the inductive capability. Relative to the baseline CoSTCo method,
    the proposed framework offers approximately 69% reduced MAE and 61% reduced RMSE
    on the imputed values. TABLE I Error metrics for missing data imputation The speed
    values at each sensor for a single time step as predicted by G-LSTM and CoSTCo
    when 50% of information is missing are shown in figures 2 and 3, respectively.
    It can be seen that our framework outperforms the baseline in prediction with
    missing information. Fig. 2. Speed values estimated for each node for a single
    time instant using G-LSTM framework Show All Fig. 3. Speed values estimated for
    each node for a single time instant using CosTCo Show All SECTION V. Conclusions
    and Future Work In this paper, we propose a general spatiotemporal framework for
    data imputation. The traffic sensor network is formulated as an undirected graph
    with speed values as a time-varying feature. The proposed imputation framework
    consists of a spatial and a temporal module that helps capture the spatiotemporal
    relationships within the data and thereby helps to impute the missing information.
    Comprehensive case studies are conducted to evaluate the imputation accuracy of
    the proposed model for a wide missing rate range. Experimental results show that
    the proposed method outperforms the neural tensor completion method, CoSTCo and
    maintains steady performance in extreme missing scenarios. In future studies,
    we plan to improve imputation accuracy by employing an attention mechanism instead
    of LSTM and incorporating model information instead of a purely data-driven approach.
    ACKNOWLEDGEMENT The research was funded by National Science Foundation (NSF) CNS
    2039014 Authors Figures References Keywords Metrics More Like This State of Health
    Estimation of Lithium Ion Batteries using Recurrent Neural Network and its Variants
    2021 IEEE International Conference on Electronics, Computing and Communication
    Technologies (CONECCT) Published: 2021 Recurrent Neural Network based Data-Driven
    SOC Estimation in Lithium-Ion Battery 2023 International Conference on Distributed
    Computing and Electrical Circuits and Electronics (ICDCECE) Published: 2023 Show
    More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: Proceedings - 2023 IEEE Conference on Artificial Intelligence, CAI 2023
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A General Spatiotemporal Imputation Framework for Missing Sensor Data
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Zhou X.
  - Wu Y.
  - Meng H.
  - Han S.
  - Kan Z.
  - Li Y.
  - Zhang J.
  citation_count: '0'
  description: Efficient furrow fertilization is extremely critical for fertilizer
    utilization, fruit yield, and fruit quality. The precise determination of trench
    quality necessitates the accurate measurement of its characteristic parameters,
    including its shape and three-dimensional structure. Some existing algorithms
    are limited to detecting only the furrow depth while precluding the tridimensional
    reconstruction of the trench shape. In this study, a novel method was proposed
    for three-dimensional trench shape reconstruction and its parameter detection.
    Initially, a low-cost multi-source data acquisition system with the 3D data construction
    method of the trench was developed to address the shortcomings of single-sensor
    and manual measurement methods in trench reconstruction. Subsequently, the analysis
    of the original point cloud clarified the “coarse-fine” two-stage point cloud
    filtering process, and then a point cloud preprocessing method was proposed based
    on ROI region extraction and discrete point filtering. Furthermore, by analyzing
    the characteristics of the point cloud, a random point preselection condition
    based on the variance threshold was designed to optimize the extraction method
    of furrow side ground based on RANSAC. Finally, a method was established for extracting
    key characteristic parameters of the trench and trench reconstruction based on
    the fitted ground model of the trench side. Experimental results demonstrated
    that the point cloud pretreatment method could eliminate 83.8% of invalid point
    clouds and reduce the influence of noise points on the reconstruction accuracy.
    Compared with the adverse phenomena of fitting ground incline and height deviation
    of the original algorithm results, the ground height fitted by the improved ditch
    surface extraction algorithm was closer to the real ground, and the identification
    accuracy of inner points of the ground point cloud was higher than that of the
    former. The error range, mean value error, standard deviation error, and stability
    coefficient error of the calculated ditch width were 0 ~ 5.965%, 0.002 m, 0.011
    m, and 0.37%, respectively. The above parameters of the calculated depth were
    0 ~ 4.54%, 0.003 m, 0.017 m, and 0.47%, respectively. The results of this research
    can provide support for the comprehensive evaluation of the quality of the ditching
    operation, the optimization of the structure of the soil touching part, and the
    real-time control of operation parameters.
  doi: 10.3389/fsufs.2023.1201994
  full_citation: '>'
  full_text: '>

    "Top bar navigation About us All journals All articles Submit your research Search
    Login Frontiers in Sustainable Food Systems Sections Articles Research Topics
    Editorial Board About journal Download Article  350 Total views 98 Downloads View
    article impact View altmetric score SHARE ON Edited by Abdo Hassoun Sustainable
    AgriFoodtech Innovation & Research (Safir), France Reviewed by Seyed-Hassan Miraei
    Ashtiani Department of Engineering, Faculty of Agriculture, Dalhousie University,
    Canada Ferdaous Boughattas UniLaSalle, France TABLE OF CONTENTS Abstract 1. Introduction
    2. Materials and methods 3. System and algorithm description 4. Experimental results
    and discussion 5. Discussion 6. Conclusion Data availability statement Author
    contributions Funding Conflict of interest Publisher’s note Supplementary material
    References Open supplemental data Export citation Check for updates People also
    looked at Estimation of greenhouse gas emissions from Japanese healthy meals with
    different protein sources Himeno Sameshima, Rie Akamatsu, Fumi Hayashi and Yukari
    Takemi Physicochemical properties of rainbow trout (Oncorhynchus mykiss) filet
    treated with high-voltage electrostatic field under different storage temperatures
    Yu-Tsung Cheng, Ping-Hsiu Huang, Wen-Chien Lu, Sheng-Che Chu, Pei-Ming Wang, Wen-Chien
    Ko and Po-Hsien Li Effects of precipitation variability and conservation tillage
    on soil moisture, yield and quality of silage maize Lili Niu, Wangfei Qin, Yongliang
    You, Qishun Mo, Jie Pan, Lihua Tian, Guang Xu, Chao Chen and Zhou Li Digital transformation
    in the agri-food industry: recent applications and the role of the COVID-19 pandemic
    Abdo Hassoun, Hans J. P. Marvin, Yamine Bouzembrak, Francisco J. Barba, Juan Manuel
    Castagnini, Noelia Pallarés, Roshina Rabail, Rana Muhammad Aadil, Sneh Punia Bangar,
    Rajeev Bhat, Janna Cropotova, Sajid Maqsood and Joe M. Regenstein Unstructured
    road extraction and roadside fruit recognition in grape orchards based on a synchronous
    detection algorithm Xinzhao Zhou, Xiangjun Zou, Wei Tang, Zhiwei Yan, Hewei Meng
    and Xiwen Luo ORIGINAL RESEARCH article Front. Sustain. Food Syst., 21 July 2023
    Sec. Nutrition and Sustainable Diets Volume 7 - 2023 | https://doi.org/10.3389/fsufs.2023.1201994
    This article is part of the Research Topic Food Sustainability and Food Industry
    4.0: Unveiling the Relationship View all 4 Articles Three-dimensional reconstruction
    of the furrow shape in orchards using a low-cost lidar Xinzhao Zhou1,2,3,4 Yanfeng
    Wu1,2,3 Hewei Meng1,2,3 Shujie Han1,2,3 Za Kan1,2,3 Yaping Li1,2,3*† Jie Zhang5*†
    1College of Mechanical and Electrical Engineering, Shihezi University, Shihezi,
    China 2Key Laboratory of Northwest Agricultural Equipment, Ministry of Agriculture
    and Rural Affairs, Shihezi, China 3Engineering Research Center for Production
    Mechanization of Oasis Characteristic Cash Crop, Ministry of Education, Shihezi,
    China 4Foshan-Zhongke Innovation Research Institute of Intelligent Agriculture,
    Foshan, China 5Research Institute of Agricultural Mechanization, Xinjiang Academy
    of Agricultural Sciences, Urumqi, China Efficient furrow fertilization is extremely
    critical for fertilizer utilization, fruit yield, and fruit quality. The precise
    determination of trench quality necessitates the accurate measurement of its characteristic
    parameters, including its shape and three-dimensional structure. Some existing
    algorithms are limited to detecting only the furrow depth while precluding the
    tridimensional reconstruction of the trench shape. In this study, a novel method
    was proposed for three-dimensional trench shape reconstruction and its parameter
    detection. Initially, a low-cost multi-source data acquisition system with the
    3D data construction method of the trench was developed to address the shortcomings
    of single-sensor and manual measurement methods in trench reconstruction. Subsequently,
    the analysis of the original point cloud clarified the “coarse-fine” two-stage
    point cloud filtering process, and then a point cloud preprocessing method was
    proposed based on ROI region extraction and discrete point filtering. Furthermore,
    by analyzing the characteristics of the point cloud, a random point preselection
    condition based on the variance threshold was designed to optimize the extraction
    method of furrow side ground based on RANSAC. Finally, a method was established
    for extracting key characteristic parameters of the trench and trench reconstruction
    based on the fitted ground model of the trench side. Experimental results demonstrated
    that the point cloud pretreatment method could eliminate 83.8% of invalid point
    clouds and reduce the influence of noise points on the reconstruction accuracy.
    Compared with the adverse phenomena of fitting ground incline and height deviation
    of the original algorithm results, the ground height fitted by the improved ditch
    surface extraction algorithm was closer to the real ground, and the identification
    accuracy of inner points of the ground point cloud was higher than that of the
    former. The error range, mean value error, standard deviation error, and stability
    coefficient error of the calculated ditch width were 0 ~ 5.965%, 0.002 m, 0.011 m,
    and 0.37%, respectively. The above parameters of the calculated depth were 0 ~ 4.54%,
    0.003 m, 0.017 m, and 0.47%, respectively. The results of this research can provide
    support for the comprehensive evaluation of the quality of the ditching operation,
    the optimization of the structure of the soil touching part, and the real-time
    control of operation parameters. 1. Introduction Fruit cultivation and production
    have emerged as critical components of global agriculture and economy. According
    to the Food and Agriculture Organization of the United Nations (FAO), the total
    value of fruit production has increased steadily, as shown in Figure 1 (FAO, 2023).
    In the planting and management of perennial fruit trees such as grapes, pears,
    oranges, apples, and so on, furrow fertilization is an important link affecting
    fruit quality and yield. However, furrow fertilization in orchards is characterized
    by limited working cycles as well as being labor-intensive and time-consuming.
    figure 1 Figure 1. World gross production value of fruits. With the rapid progress
    of industrialization and the aging of the population, the rural labor force is
    rapidly dwindling (Wu et al., 2021; Zhou et al., 2023b). This has led to an increasing
    conflict between labor demand and labor cost, which is having a significant adverse
    impact on traditional manual ditch fertilization methods (Akdemir et al., 2022).
    In response to these challenges, research into ditching fertilizer machines and
    related fields has been actively pursued (Babu et al., 2020; Zhan et al., 2022;
    Aikins et al., 2023; Han et al., 2023). In the process of mechanical ditching
    fertilization, the quality of ditching operation has a crucial impact on the depth
    of fertilization and the utilization rate of fertilizer, which directly affects
    the nutrient absorption and root growth of fruit trees and is crucial for the
    improvement of fruit yield and quality. Reasonable ditching depth is an important
    measure to ensure the root growth, yield increase, and quality of fruit trees
    (Zeng et al., 2008). However, achieving a high-quality trench fertilization operation
    at the optimum depth is a challenging task, as soil resistance changes affect
    the depth of the trench cutters, resulting in variations in the trench depth.
    Traditionally, the depth of a field trenching operation is adjusted based on the
    operator’s experience, and the quality of the operation is evaluated by manually
    sampling the trenching depth at random. This measurement method is easily affected
    by subjective consciousness, and it is difficult to reflect the overall furrow
    situation. All of the above factors present a great challenge for high-quality
    discarding fertilization in orchards. With the rapid development of precision
    agriculture and modern information technology, Smart sensors and the intelligent
    ditching depth monitoring system have gained widespread attention among scholars
    (Hassoun et al., 2022, 2023). Lou et al. (2021a,b) proposed an independent control
    method for single-row tillage depth based on ultrasonic sensor detection and hydraulic
    adjustment, which significantly improved the stability of tillage depth between
    rows and within rows in deep tillage operation of subsoilers. Kirkegaard Nielsen
    et al. (2018) measured the current seeding depth using a plow position sensor
    combined with an ultrasonic soil surface sensor. Luo et al. (2022) proposed a
    Remote Monitoring System for Agricultural Machinery Operation in Conservation
    Tillage, which realized tillage depth measurement based on the dual attitude compound
    of a tractor body and three-point hitch mechanism with a lower pull rod. Zhao
    et al. (2022) established a mathematical model of rotation Angle and terrain height
    by using the encoder feedback of the rotation Angle of the sensing trailboard
    (STB) and realized the measurement of contact terrain height. Zhang et al. (2021)
    designed the mechanical structure of the equipment and then used the inclination
    sensor to build a control system to realize the automatic adjustment of the ditching
    depth of the double-row ditching fertilizer machine in orchards. Du et al. (2019)
    built a tillage depth measurement model with an error compensation coefficient
    based on the analysis of the influence of structural deformation and wheel sag
    on the measurement accuracy of the hanging rototiller set, which improved the
    measurement accuracy of the system. In our previous study, ultrasonic sensors
    were used to monitor the depth of ditching, and a wavelet denoising and Kalman
    filtering algorithm was proposed to reduce the noise of the ditching depth data,
    which improved the reliability of the data (Zhou et al., 2021, 2022, 2023a). The
    research mentioned above has shown that conventional sensor measurement methods
    are effective in monitoring the furrow depth, which lays a solid foundation for
    improving the quality of mechanized ditch operations. However, to make a comprehensive
    judgment of the ditch operation quality, it is necessary to obtain the other parameters,
    such as ditch width, furrow shape, and additional indicators. The methods based
    on ultrasonic and tilt sensors still have some shortcomings in the acquisition
    of 3D data and the construction of furrow shapes. Lidar overcomes the shortcoming
    of traditional sensors in obtaining spatial information and can work all day long
    to obtain the point cloud data of real trench spatial information. Lidar has been
    widely used in obstacle detection (Qin et al., 2023; Shang et al., 2023), terrain
    mapping (Kim and Choi, 2021; García-López et al., 2023), map construction (Su
    et al., 2021; Ao et al., 2022; Eisoldt et al., 2022; Rivera et al., 2023), agricultural
    information monitoring, and plant model reconstruction (Perez et al., 2018; Tsoulias
    et al., 2019; Campbell et al., 2023). Therefore, in view of the challenges associated
    with measuring the feature parameters of ditches, reconstruction of ditches by
    conventional sensors, and comprehensive evaluation of the quality of ditches by
    depth data of individual ditches after field operation by ditchers, a lidar-based
    3D reconstruction method for orchard ditches was proposed in this paper. The main
    contributions of this paper were as follows: 1. Currently, numerous studies have
    focused on monitoring of tillage depth without considering the reconstruction
    of a three-dimensional furrow shape, which is detrimental to the real-time control
    of the ditching operation and the overall quality evaluation of the operation.
    Motivated by the measurement requirements for 3D trench shape and characteristic
    parameters for quality evaluation of the ditching operation, this study proposed
    a framework for a 3D reconstruction method of orchard trenches based on low-cost
    lidar. This framework lays a foundation for evaluating the working quality of
    the ditching fertilizer machine, thereby enabling improvement and optimizing the
    structure and operating parameters of the soil-touching parts of the equipment.
    2. A low-cost multi-source data acquisition system with a trench 3D data construction
    method was developed in this paper, which not only reduced the system cost but
    also realized real-time collection of multi-source data and the construction and
    storage of the 3D point cloud. 3. Due to the irrelevant objects and environmental
    disturbance factors in orchard, the original point cloud included a lot of noise
    and background points. Based on the “coarse-fine” two-stage filtering process,
    this paper proposed a method of ROI extraction and discrete point preprocessing
    for the orchard gully point cloud. The algorithm effectively reduced the influence
    of irrelevant background on gully reconstruction, the calculation amount of gully
    reconstruction. Simultaneously, this approach improved the quality of gully reconstruction,
    and further enhanced the adaptability of the reconstruction system to interference
    factors in the field complex environment. 4. A Furrow side ground surface model
    and feature parameter extraction algorithm were constructed. On the basis of point
    cloud noise reduction, the characteristics of the point cloud were analyzed, and
    a random point preselection condition based on variance threshold was designed.
    Subsequently, an improved extraction method of the ground surface model based
    on random sample consistency (RANSAC) was proposed to improve the extraction efficiency
    of the model. Finally, based on the fitted ground, a method was proposed to extract
    the key characteristic parameters of the trench shape and reconstruct the gully
    shape. The key parameters such as depth and width were extracted, and the trench
    shape reconstruction was realized. This study establishes a foundation for achieving
    real-time control of mechanized trench fertilization. It is of great significance
    for the comprehensive evaluation of the quality of trench operation, the detection
    and monitoring of the trend of trench shape change, and the exploration of the
    optimal combination of mechanical structure and operation parameters. The rest
    of this report is organized as follows. Section 2 introduced the methods and materials.
    Section 3 explained the structure of the system and algorithms. Section 4 presented
    the experimental results and discussion. Finally, Section 5 summarized the study
    and plans for future work. 2. Materials and methods 2.1. Experimental platform
    for orchard trench shape 3D reconstruction The experimental platform of orchard
    trench shape 3D reconstruction in this research is shown in Figure 2A. The platform
    was mainly composed of a portable computer, lidar, bracket, encoder, elastic coupling,
    etc. The system power was provided by Beeste AS300 Mobile Power Supply (Shenzhen
    Beeste Technology Co., LTD., China). The lidar used in this study was LMS141-15100
    two-dimensional lidar (SICK AG, Germany), as shown in Figure 2B. The protection
    class is IP67, with good dust-proof and waterproof performance. To sum up, the
    lidar can be adapted to a ditching operation environment. figure 2 Figure 2. Overall
    layout of test platform and key modules. (A) Overall layout of test platform.
    Computer power conversion module, 1; Portable computer, 2; Lidar, 3; Encoder fixed
    frame, 4; Coupling, 5; Encoder, 6; Removable power socket, 7; JOHN DEERE 454 45HP
    Wheel Tractor, 8. (B) LMS141-15100 two-dimensional Lida. (C) OidEncoder Absolute
    encoder. (D) Beeste AS300 mobile power. The OidEncoder absolute encoder (Oid Technology
    Co., LTD., China) was used to provide forward distance data, as shown in Figure
    2C. The resolution of the encoder is 4,096 P/R, and the protection level is IP68.
    Compared with the photoelectric encoder, the encoder was more adaptable to vibration,
    shock, water, gas, oil, and other interference factors. 2.2. The overall flow
    of the reconstruction method The reconstruction method content of this research
    was primarily divided into four parts: original point cloud acquisition, point
    cloud pretreatment, trench side ground model and characteristic parameter extraction,
    and 3D trench shape reconstruction method, as illustrated in Figure 3. The original
    point cloud was acquired jointly by lidar and encoder. However, due to sensor
    system errors, unstructured environmental interference factors, and other reasons,
    many discrete points and background point clouds were generated in the original
    point cloud. To improve the reliability and reduce the computational cost of trench
    reconstruction, point cloud ROI region extraction and point cloud filtering technology
    were utilized for point cloud pretreatment to reduce the influence of irrelevant
    objects and point cloud noise on the reconstruction result. Based on this, the
    trench ground model was fitted, and the characteristic parameters of the groove
    shape were calculated. Finally, the construction of the three-dimensional furrow
    was completed. figure 3 Figure 3. Schematic diagram of the data processing flow.
    3. System and algorithm description 3.1. Multi-source data acquisition and three-dimensional
    data construction system To obtain the point cloud information, Microsoft Visual
    Studio.NET 2019 was used as the development platform for building a multi-source
    data acquisition and 3D data construction system. This system primarily completed
    the collection, analysis, and conversion of lidar and encoder data and realized
    the construction and preservation of three-dimensional point cloud data. The system
    interface is shown in Figure 4A. figure 4 Figure 4. The system interface and operation
    process. (A) The system interface. (B) The operation process. During system operation,
    initialization parameters were initially set followed by sending startup instructions
    to the lidar and encoder. The system then analyzed the received data to complete
    the calculation of the traveling distance and the conversion of the lidar coordinate
    system, which laid the foundation for the construction of 3D data. Subsequently,
    2D Lidar data and encoder data were integrated to achieve the construction and
    preservation of 3D point cloud data, completing a single cycle of system operation.
    The system repeated the above operation process according to the set scanning
    frequency until the system stopped running. The system operation process is shown
    in Figure 4B. The resolution of the angular step width of the lidar was 0.5°,
    the scanning field of vision was −45 ~ 225°, and the lidar was 1.3 m from the
    ground. The raw data output of the lidar was given in polar coordinates, with
    the angle denoted as θ and the detected distance as r . To realize the calculation
    of 3D point cloud coordinates, polar coordinate data were converted into a rectangular
    coordinate system using the conversion formula shown in Eq. (1) (Li and Liu, 2013):
    { X lidar =r∗sin(θ) Y lidar =r∗cos(θ)     (1) where ( X lidar , Y lidar ) is the
    point coordinates of the converted cartesian coordinate system, r is the distance
    scanned by the lidar, and θ is the angle value corresponding to r . When calculating
    the trench depth data, the current trench depth data is usually calculated according
    to Eq. (2) based on the reference plane of the trench surface, as shown in Figure
    5: D B = D M − D S     (2) where DB is the trench depth, DM is the distance between
    the lidar and the trench bottom, and DS is the distance between the radar and
    the trench surface, DS = 1.3 m. figure 5 Figure 5. The platform coordinate system.
    As evidenced by Eq. 2, different from the reconstructed objects above the ground
    such as buildings and trees, the research focus of this paper was the point clouds
    on both sides and below the trench ground, while most of the point clouds above
    the ground were considered as background noise. Therefore, when constructing point
    cloud data, the origin of the coordinate system reconstructed was placed below
    the ground to improve Eq. 1. The improved lidar data conversion method is shown
    in Eq. 3: { X S =r∗sin(θ) Z S = D O −r∗cos(θ)     (3) where DO is the distance
    between the lidar and the origin of the reconstructed coordinate system. Typically,
    the depth and width of ditching fertilization in orchards range from 20 to 40 cm
    (Liu et al., 2020). Considering the range of trench depth and width, the distance
    between lidar and ground DS, DO was set as 1.60 m in this paper. Before the operation
    of the 3D reconstruction platform, the current position was set as the zero point
    of the encoder, and the walking distance was obtained in real time during the
    operation of the platform. The forward distance of the platform is calculated
    as follows (Lee et al., 2020; Oid Technology Co., LTD., 2023a,b): Y=πL∗M/4096     (4)
    where L is the diameter of the tractor wheel, and M is the encoder value. The
    winding number of the encoder is 16. When the driving distance of the platform
    is too long and exceeds the winding number range of the encoder, the encoder value
    will return to zero and recalculate the winding number. Therefore, this paper
    improved the calculation method of platform advance distance, as shown in Eq.
    5: Y S =16πnL+πL∗M/4096     (5) where n is the number of times the coded value
    returns to zero. Following data conversion, the point cloud data were assembled
    by utilizing the lidar data as the X and Z axes coordinates and further incorporating
    the encoder data as the Y axis coordinates. The platform coordinate system is
    shown in Figure 5. CL was the coordinate system of the lidar, and CS was the 3D
    coordinate system of the furrow point cloud. The X-axis of the CS was the same
    as the CL, the z-axis of the CS was provided by the Y-axis of the CL, and the
    Y-axis data of the CS was provided by the encoder. 3.2. Orchard gully point cloud
    ROI region extraction and discrete point pretreatment method In this paper, the
    pretreatment of the point cloud in orchards was mainly divided into two steps:
    rough and fine treatment. Initially, the rough processing of the original point
    cloud was achieved by extracting the regions of interest (ROI) of the orchard
    point cloud and subsequently removing a significant number of irrelevant background
    noise points. On this basis, the influence of environmental noise and other adverse
    factors on the quality of the cloud was further reduced by the second removal
    of discrete points, thereby enhancing the overall quality of the point cloud.
    3.2.1. ROI extraction of original point cloud Due to the large field of view of
    lidar, many irrelevant targets, such as carports, trees and pedestrians, were
    present in the original point cloud data, leading to a significant increase in
    processing time for trench reconstruction. Furthermore, the critical region point
    cloud occupied a finite fraction of the original point cloud data. When reconstructing
    the prototype point cloud directly, a plethora of irrelevant interference details
    would be introduced, as depicted in Figure 6A. Therefore, a pass-through filter
    was used to select the ROI of the furrow to restrict the direction range of the
    X and Z axes of the point cloud. figure 6 Figure 6. Comparison of original point
    cloud and ROI extraction results. (A) Original point cloud. (B) ROI extraction
    results. (C) Point cloud quantity comparison. According to the range of the ditching
    depth and width as well as the value of DR, the conditional constraints for the
    ROI in this paper are shown in Eq. 6: ( X ROI , Y ROI , Z ROI )= ⎧ ⎩ ⎨ ⎪ ⎪ X ROI
    , X ROI ∈[−0.6,0.6] Y ROI , Y ROI ∈[0,∞] Z ROI , Z ROI ∈[−∞,0.5]     (6) The original
    point cloud consisted of 96,298 data points, while the ROI only contained 15,603
    point clouds. This resulted in the elimination of 83.8% of invalid data points,
    thereby significantly reducing the computational load for subsequent algorithms,
    as shown in Figure 6. 3.2.2. Discrete point pretreatment To eliminate noise points
    on the ground, statistical filtering (Jin et al., 2021) was employed in this study,
    and the filtering range was {(x<−0.3)∪(x<−0.3)} . The principle is as follows:
    d i = ∑ k i=1 ( x j − x i ) 2 + ( y j − y i ) 2 + ( z j − z i ) 2 √ k     (7)
    1. Creating a point set of neighborhoods for each point using kd-tree 2. Traversing
    the point cloud to calculate the average distance d i between the current point
    P i ( x i , y i , z i ) and its neighboring points P j ( x j , y j , z j )(j=1,2,…,k)
    , where k = 5 1. Points in the point cloud whose d i is greater than the threshold
    T are defined as outlier noise points and removed from the data. The formula for
    calculating the threshold T is as follows: T∈(μ−3σ,μ+3σ)     (8) where μ and σ
    are the mean and standard deviation of the mean distance in all point clouds,
    respectively. When comparing the average distance of the point clouds, it was
    observed that statistical filtering retained the details of the furrow and effectively
    removed outliers, as shown in Figures 7A,B. figure 7 Figure 7. Effect of statistical
    filtering. (A) The di value before statistical filtering. (B) The di value after
    statistical filtering. (C) The contrast result of the red area on the left of
    the point cloud. (D) The trench shape before statistical filtering. (E) The trench
    shape after statistical filtering. (F) The contrast result of the red area on
    the right of the point cloud. 3.3. Extraction of trench side ground model and
    characteristic parameters 3.3.1. Improved furrow side ground model extraction
    method based on RANSAC The ground model of the trench served as the reference
    surface for determining the depth and width of the trench, thereby playing a critical
    role in the calculation of the characteristic parameters. The quality of the trench
    surface model directly affected the accuracy of the calculation of the trench
    characteristic parameters. The mathematical equations are as follows: ax+by+cz+d=0     (9)
    where (x, y, z) are the three-dimensional space coordinates of the points on the
    plane and (a, b, c) are the normal vector in the plane. In addition, since the
    trench ground has a certain thickness, as shown in Figure 8A, the thickness of
    the ground at the trench side was set as 2β in this paper. figure 8 Figure 8.
    Schematic diagram of ground point cloud structure and characteristic parameter
    calculation method. (A) Schematic diagram of the selection of ground point clouds
    on the trench side. (B) Calculation diagram of ditch depth and width. The steps
    of ground detection at the ditch side of the orchard based on the RANSAC algorithm
    (Fischler and Bolles, 1981) are as follows: d p = |a x i +b y i +c z i +d| a 2
    + b 2 + c 2 √     (10) 1. Randomly selected three points ⟨ p 1 ( x 1 , y 1 , z
    1 ) p 2 ( x 2 , y 2 , z 2 ) p 3 ( x 3 , y 3 , z 3 )⟩ from the point cloud in the
    filtered ROI region to construct the initial trench surface L, and the parameter
    values of a, b, and c are calculated according to Eq. (9). 2. Calculate the distance
    dp from point pi(xi, yi, zi) to ground L according to Eq. (10), with a threshold
    of ground point cloud range q. When dp < β, point pi(xi, yi, zi) is labeled as
    an inlier and Ci the number of inliers. 1. Repeat steps 1 and 2 for M times to
    obtain the ground L* containing the largest inlier set Cimax as the best ditch
    side ground model. However, the aforementioned method necessitates the traversal
    of all point cloud data at each iteration, leading to a rapid increase in computational
    cost with an increase in point cloud data. Moreover, the selection quality of
    the three random points significantly influences the efficiency of optimal model
    extraction. The orchard ground, unlike the cement road, is typically rough and
    undulating, thereby presenting a challenge for the selection of random points
    and reducing the speed of the best trench side ground model extraction. To improve
    the computational efficiency of the optimal trench side ground model, the characteristics
    of point clouds were analyzed, and the RANSAC algorithm-based detection method
    for orchard furrow side ground was refined. As can be seen from Figure 7E, the
    ground point clouds exhibited small spacing and a tightly packed distribution,
    whereas the non-ground point clouds were widely spaced and sparsely distributed.
    Leveraging these distinctive features, an enhanced RANSAC algorithm was developed,
    which involved the construction of a variance threshold preselection condition
    to evaluate the discretization level among the randomly selected points. The steps
    of the optimized method are as follows: 1. Randomly selected three points ⟨ p
    1 ( x 1 , y 1 , z 1 ) p 2 ( x 2 , y 2 , z 2 ) p 3 ( x 3 , y 3 , z 3 )⟩ from the
    point cloud in the filtered ROI region. Calculate the variance γ of the three
    points on the z-axis according to Eq. (11). γ= 1 3 ∑ 3 i=1 ( z i − z ¯ ) 2     (11)
    where z ¯ is the average value of the three points on the z-axis. 1. Set the height
    variance threshold γ*. When γ ≥ γ*, discard the current three points and repeat
    step 1, otherwise go to Step 3. 2. Construct the initial trench surface L, and
    calculate the parameter values of a, b, and c according to Eq. (9). Then, calculated
    the distance dp from point pi(xi, yi, zi) to ground L according to Eq. (10), with
    a threshold of ground point cloud range q. When dp < β, point pi(xi, yi, zi) is
    labeled as an inlier and Ciwas the number of inliers. 3. Repeat steps 3 for M
    times to obtain the ground L* containing the largest inlier set Cimax as the best
    ditch side ground model. 3.3.2. Calculation method of trench characteristic parameters
    Based on the selected optimum trench side ground model and combined with the coordinate
    system of the trench point cloud, a calculation diagram of the trench depth and
    width is shown in Figure 8B. Equation (2) was improved by taking the optimum ground
    model as the reference surface for the calculation of trench depth. The calculation
    method of trench depth is shown in Eq. (12): D C = D L ∗ − D min     (12) where
    DC is the trench depth, D L ∗ is the value of Z-axis of the selected optimum trench
    side ground model in the CS, and Dmin is the minimum value of Z-axis in the CS.
    The inliers region of the ground model was designated as the candidate area for
    computing the trench width. Subsequently, the distance between point I i ( x Ii
    , y Ii , z Ii ,) and its adjacent point I i+1 ( x Ii+1 , y Ii+1 , z Ii+1 ) on
    the X-axis was iteratively traversed. The maximum distance between two adjacent
    point clouds was considered as the ditch width under the current scanning. The
    calculation method is illustrated in Eq. (13), and the definition of point cloud
    candidate region is shown in Eq. (14): W C = ( x Ii − x Ii+1 ) MAX     (13) I
    Ii , I Ii+1 ∈{(x,z)|x∈[−0.6,0.6],z∈[ D T∗ −β, D T∗ +β]}     (14) 3.4. Trench reconstruction
    The Delaunay triangulation algorithm has a sound geometrical concept and strong
    theoretical basis, and this makes it ubiquitously used in various fields, such
    as surface reconstruction, digital terrain model, finite element analysis, and
    so on. Therefore, in this paper, a point-by-point insertion method was used to
    construct a Delaunay triangulation network to reconstruct the trench surface.
    Furthermore, the Laplace algorithm was used to smooth the furrow and enhance the
    reconstruction effect to make it more accurate and closer to the actual effect.
    4. Experimental results and discussion 4.1. Experiment To assess the performance
    of the trench reconstruction platform and evaluate the efficacy of the system,
    a field performance test was conducted in the experimental field located in the
    North district of Shihezi University. A ditching operation was carried out in
    the test field, with a total length of 10 m. The ditch depth range was 30 ± 5 cm
    and the width range 30 ± 10 cm, as shown in Figure 9A. Due to the phenomenon of
    soil collapse and accumulation at the beginning and end of the trench after ditching
    operation, a 0.5 m-wide zone on both sides of the trench was deemed invalid, thereby
    resulting in an effective trench length of 9 m, as illustrated in Figure 10B.
    figure 9 Figure 9. Schematic diagram of the performance test. (A) Image of the
    partial ditch. (B) Schematic diagram of test area and driving direction. figure
    10 Figure 10. Comparison of ground model extraction results. (A) Extraction results
    of ditch side ground model. (B) Schematic diagram of the spatial relationship
    between the ground model and the point cloud of the ditch. (C) Histogram of distance
    between the ground model and point clouds in the ROI region. (D) Variation trend
    of distance between point cloud and ground model in ROI region. 4.2. Evaluation
    index In this study, the correlation coefficient (R), root mean square error (RMSE),
    and coefficient of variation of stability (V) were used as the evaluation indices
    of extraction performance of characteristic parameters and the calculation equations
    of each evaluation index expressed in Eqs. 15–18 (Wang et al., 2018; Fu et al.,
    2020; Kim et al., 2023): R= ∑ n i=1 ( x i − x ¯ )( y i − y ¯ ) ∑ n i=1 ( x i −
    x ¯ ) 2 ∑ n i=1 ( y i − y ¯ ) 2 √     (15) RMSE= ∑ n i=1 ( y i − x i ) 2 n − −
    − − − − − − − √     (16) S= ∑ ( y i − y ¯ ) 2 n−1 − − − − − − − √     (17) V=
    S y ¯ ×100%     (18) where xi is the artificially measured value, x ¯ is the mean
    value of manual measurement, yi is the calculated value of groove characteristic
    parameter, y ¯ is the calculated mean value of groove characteristic parameters,
    S is the standard deviation of the calculated value of the groove characteristic
    parameter, V is the variation coefficient of the stability of the calculated value
    of the groove characteristic parameter, and n is the number of measuring points.
    4.3. Extraction results of ditch side ground model To verify the performance of
    the improved trench side ground model extraction method, a comparison was conducted
    between the results obtained from the original algorithm and the improved algorithm.
    The preprocessed point cloud was taken as input, and the two algorithms were compared
    with the same parameter settings, including 1,000 iterations (M), the ground point
    cloud range threshold (β) of 0.05, and the height variance threshold (γ*) of 0.001.
    The comparison results of the ground model extraction are presented in Figure
    10. To evaluate the fitting performance of the ground surface model, this paper
    mainly evaluates based on the following two aspects: 1. Whether the model can
    determine the ditch side ground point cloud as the inliers 2. Whether the extracted
    ground model exists with a tilt phenomenon The results in Row (a) were generated
    using the original orchard ditch side-ground extraction algorithm, while the images
    in Row (b) were obtained using the optimized orchard ditch side-ground extraction
    algorithm. In the first and second column images, the purple plane depicts the
    ground model of the extracted ditch side. The red point cloud denotes the inner
    point of the ditch side ground that was extracted by the algorithm, while the
    remaining colored points represent the outer point of the ground. Furthermore,
    it is worth noting that some models identify most of the ground surface clouds
    as internal points, which can lead to a significant impact on the accuracy and
    reliability of subsequent feature parameters when the model is tilted. To evaluate
    the tilt degree of the model, the leftmost point cloud in the ROI region was taken
    as the starting position, and the distance variation trend of dp was described
    in the order from left to right, as shown in the fourth column in Figure 10. The
    optimized algorithm produced a well-fitted model for the ground point cloud, where
    a majority of the ground point cloud was correctly classified as internal points.
    In contrast, while the original algorithm demonstrated good performance, it generated
    more points that were identified as incorrect results (Figure 10A). The optimized
    algorithm produced a model that was located at the midpoint of the ground point
    cloud, while the model fitted by the original algorithm was located at the lower
    middle part of the ground point cloud. Consequently, a portion of the ground point
    cloud was erroneously classified as outer points, while some of the trench wall
    point cloud was improperly identified as an internal point, thus increasing the
    number of point cloud misclassifications (Figure 10B). The dp mainly fell within
    the range of 0–0.1 and 0.25–0.37. This portion of the point cloud was mainly distributed
    in the ground and trench bottom, which was consistent with the actual situation.
    By comparison, it was observed that within the range of 0–0.1 point clouds, the
    number of point clouds in the range of 0–0.05 was more in the optimized algorithm,
    while the distribution of point clouds in the range of 0.05–0.1 was higher in
    the non-optimized algorithm. This phenomenon further indicated that the plane
    fitted by the optimized algorithm was closer to the actual furrow (Figure 10C).
    As depicted in Figure 10D, the abscissa extent of 5,000–10,000 corresponded to
    the part of the ditch, whereas the remaining extent correspond to the ground on
    both sides of the ditch. Moreover, the fluctuation of the distance variation trend
    of the original algorithm was more prominent and the dp of the right side of the
    ground was larger than that of the left side of the ground, indicating that the
    ground model fitted by the algorithm was skewed. Instead, the point cloud distance
    variation trend of the optimized algorithm was relatively smooth, and the distance
    distribution of the left and right ground points were relatively uniform, which
    can also be proved by Figure 10B. 4.4. Furrow reconstruction result The furrow
    was reconstructed using the point-by-point insertion method, which effectively
    depicted the contour, width, and depth of the trench while retaining many features
    of the actual furrow shape. Nonetheless, as shown in Figures 11A,C, the reconstructed
    results were uneven and had many burrs compared to the real trench. Therefore,
    it is necessary to conduct further processing on the reconstructed results. After
    smoothing the reconstructed grooves with the Laplace algorithm, the results retained
    the main features, while the overall contours became smoother and the burrs disappeared.
    Additionally, the roughness of the mesh was significantly reduced, resulting in
    a more realistic reconstruction (Figures 11B,D). figure 11 Figure 11. Furrow reconstruction
    results. (A) Frontal view of the result of furrow reconstruction using point-by-point
    insertion method. (B) Frontal view of the result of smoothing the groove using
    Laplace’s algorithm. (C) Side view of the result of furrow reconstruction using
    point-by-point insertion method. (D) Side view of the result of smoothing the
    groove using Laplace’s algorithm. After real-time data acquisition using the multi-source
    data acquisition and three-dimensional data construction system, the single running
    time of all steps, including reading the original point cloud, pre-processing
    the point cloud, extracting the trench side ground model and characteristic parameters,
    and reconstructing the trench, was approximately 13.1 s. It is important to note
    that the duration of the program’s information processing may vary depending on
    the volume of data being processed. Larger datasets may require additional time
    for processing and analysis. 4.5. Extraction results of furrow characteristic
    parameters To analyze the accuracy of the calculations, random sample points were
    selected, and the calculated values of the furrow characteristic parameters were
    compared with the measured values. The measured values were obtained using a tape
    measure with a measuring accuracy of 1 mm. To reduce the error in manual measurement,
    the depth and width of each sample point were measured three times, and the average
    value of the three measurements was used as the measured value for that sample
    point. The measured depth DT and the measured width WT were calculated by the
    following formula: D T = ∑ 3 i=1 D Mi 3     (19) W T = ∑ 3 i=1 W Mi 3     (20)
    where DMi is the depth measurement for the ith time, and WMi is the width measurement
    for the ith time. The comparison results are shown in Figure 12 and Table 1. figure
    12 Figure 12. Comparison result between system calculated value and real value.
    (A) Results of comparison between measured and calculated values of furrow width.
    (B) Results of comparison between measured and calculated values of furrow depth.
    (C) Results of comparison of statistical parameters for measured and calculated
    values of furrow width. (D) Results of comparison of statistical parameters for
    measured and calculated values of furrow depth. table 1 Table 1. Measurement results
    and evaluation parameter results of characteristic parameters. In most cases,
    WC was smaller than WT. However, the difference in the mean value between them
    was not significant, with an error of only 2 mm. Similarly, most of DC were smaller
    than DT. And the average values of them were also not significantly different,
    with an error of 3 mm. However, the overall errors of DC were larger WC, as shown
    in Figure 12B. Furthermore, the error range of WC was 0% ~ 5.965%, while the error
    range of DC was 0% ~ 4.54%. The error of WC at the maximum value of trench width
    was 2.394%, while the error of WC at the minimum value calculation of trench was
    0.699%. The error of DC at the maximum value of furrow depth was 0.847%, and the
    error of DC at the minimum value was 4.912%. As shown in Table 1, the mean error,
    standard deviation error, and stability coefficient error of WC were, respectively,
    0.002 m, 0.011 m, and 0.37%, while the mean error, standard deviation error, and
    stability coefficient error of DC were, respectively, 0.003 m, 0.017 m, and 0.47%.
    In contrast, DC has a larger mean value error and more violent fluctuations, while
    WC has better data quality. To further explore the correlation between measured
    and calculated values, WC and WT, DC and DT were fitted, respectively, (Figure
    13). figure 13 Figure 13. Fitting results of calculated values and true values.
    (A) The fitting model of measured and calculated values of furrow width. (B) The
    fitting model of measured and calculated values of furrow depth. (C) R value and
    RMSE value of furrow depth and furrow width. (D) R2 value and SSR value of furrow
    depth and furrow width. The fitting model for WC and WT was y = 0.8718x + 0.0440,
    the R2 was 0.8332, the p value was significantly less than 0.0001, and the residual
    sum of squares (SSR) was 0.0032, all of which demonstrate a good fitting effect
    for the model. In addition, R was 0.9128, and RSME was 0.0088, indicating a strong
    positive correlation between WC and WT. The fitting model for DC and DT was y = 0.9529x + 0.017,
    the R2 was 0.7537, the p value was also significantly less than 0.0001, and the
    SSR was 0.0038. Furthermore, R was 0.9128, and RSME was 0.0088, proving a strong
    correlation between DC and DT. Although there are some errors in the calculation
    results, the furrow parameter extraction method proposed in this paper has a good
    effect. 5. Discussion Although the low-cost three-dimensional reconstruction method
    of the furrow shape in orchards proposed in this study showed a good performance,
    it also had some limitations. First, compared with WC, DC had a larger range of
    data errors and the overall data quality was inferior to the former. Moreover,
    the correlation between DC and DT was not as strong as that between WC and WT.
    The reason for this phenomenon was that the soil surface roughness in furrow bottom
    region B was more serious than that in ground region A and region C, which reduced
    the quality of furrow bottom point cloud data (Huang et al., 2021), as shown in
    Figure 14A. figure 14 Figure 14. Adverse conditions. (A) Different regions of
    the ground. (B) The problem of reconstruction result. Furthermore, the tractor
    was tilted due to the presence of asymmetric and irregular regions on both sides
    of the trench, such as region D in Figure 14A, which led to a decline in the quality
    of the trench reconstruction. Moreover, manual control of the direction during
    data acquisition failed to ensure a strictly linear progression, thus engendering
    Y-axis bending of the reconstructed trench, as depicted in Figure 14B. 6. Conclusion
    This study developed a data acquisition system that was both multi-source and
    cost-effective, with the objective of collecting, constructing point clouds, and
    storing data related to the trench. To alleviate the computational burden of trench
    reconstruction, a novel methodology was developed to extract the point cloud of
    the orchard trench and preprocess the discrete points. This approach led to an
    enhancement in the quality of three-dimensional point clouds. Through a comprehensive
    analysis of the characteristics of the trench point cloud, a variance threshold-based
    random point preselection criterion was implemented. Subsequently, the trench-side
    ground model extraction method based on RANSAC was optimized. This optimization
    aimed to enhance the accuracy and reliability of the ground model extraction,
    leading to improved results in representing the ditch side ground. Utilizing the
    fitted ground model of the trench sides, a novel approach was proposed to extract
    key feature parameters and reconstructing the trench. Experimental results demonstrated
    that the calculated width exhibited an error range of 0–5.965%, a mean value error
    of 0.002 m, a standard deviation error of 0.011 m, and a stability coefficient
    error of 0.37%. Similarly, the calculated depth of the trench exhibited an error
    range of 0–4.54%, a mean value error of 0.003 m, a standard deviation error of
    0.017 m, and a stability coefficient error of 0.47%. Overall, this study provides
    a foundation for the realization of real-time control in mechanized trench fertilization
    and offers a basis for the optimal combination of mechanical structure and operational
    parameters. The findings of this study serve as a valuable reference for enhancing
    the efficiency and benefits of agricultural operations. In future research, there
    will be a specific focus on developing tilt error correction algorithms and groove
    alignment control algorithms. These advancements aim to further enhance the accuracy
    and quality of groove reconstruction. Data availability statement The original
    contributions presented in the study are included in the article/Supplementary
    material, further inquiries can be directed to the corresponding authors. Author
    contributions XZ: conceptualization, methodology, software, writing—original draft
    preparation, formal analysis, and writing—review and editing. YW: validation and
    investigation. HM and ZK: data curation and resources. SH: visualization. YL:
    project administration and funding acquisition. JZ: supervision. All authors contributed
    to the article and approved the submitted version. Funding This study was supported
    by the Key research and development project of Xinjiang Autonomous Region, China
    (Approval No. 2022B02028-2), Shihezi University high-level talents research start-up
    fund project, China (Approval No. RCZK2018C35), Shihezi University youth innovative
    talent Cultivation project, China (Approval No. CXPY202118), and Science and technology
    innovation talent Program, China (Approval No. 2022CB002-03). Conflict of interest
    The authors declare that the research was conducted in the absence of any commercial
    or financial relationships that could be construed as a potential conflict of
    interest. Publisher’s note All claims expressed in this article are solely those
    of the authors and do not necessarily represent those of their affiliated organizations,
    or those of the publisher, the editors and the reviewers. Any product that may
    be evaluated in this article, or claim that may be made by its manufacturer, is
    not guaranteed or endorsed by the publisher. Supplementary material The Supplementary
    material for this article can be found online at: https://www.frontiersin.org/articles/10.3389/fsufs.2023.1201994/full#supplementary-material
    References Aikins, K. A., Ucgul, M., Barr, J., Awuah, E., Antille, D., Jensen,
    T., et al. (2023). Review of discrete element method simulations of soil tillage
    and furrow opening. Agriculture 13:541. doi: 10.3390/agriculture13030541 CrossRef
    Full Text | Google Scholar Akdemir, B., Saglam, C., Atar, E. S., Türen, N., and
    Özyürüyen, L. C. (2022). Development of a multi-fertilizer spreader machine and
    variable rate controller for olive orchards. Erwerbs-Obstbau. doi: 10.1007/s10341-022-00800-9
    CrossRef Full Text | Google Scholar Ao, Z., Wu, F., Hu, S., Sun, Y., Su, Y., Guo,
    Q., et al. (2022). Automatic segmentation of stem and leaf components and individual
    maize plants in field terrestrial LiDAR data using convolutional neural networks.
    Crop J. 10, 1239–1250. doi: 10.1016/j.cj.2021.10.010 CrossRef Full Text | Google
    Scholar Babu, T., Ravinthiran, A., Krishnan, S., Ananda, P., and Pavitharan, V.
    (2020). A modern low-cost furrow cutting machine. AIP Conf. Proc. 2283:020001.
    doi: 10.1063/5.0025075 CrossRef Full Text | Google Scholar Campbell, M. J., Eastburn,
    J. F., Mistick, K. A., Smith, A. M., and Stovall, A. E. L. (2023). Mapping individual
    tree and plot-level biomass using airborne and mobile lidar in piñon-juniper woodlands.
    Int. J. Appl. Earth Obs. Geoinf. 118:103232. doi: 10.1016/j.jag.2023.103232 CrossRef
    Full Text | Google Scholar Du, X., Yang, X., Pang, J., Ji, J., Tao, J., and Chen,
    L. (2019). Design and test of tillage depth monitoring system for suspended rotary
    tiller. Trans. Chinese Soc. Agric. Machin. 50, 43–51. doi: 10.6041/j.issn.1000-1298.2019.08.005
    CrossRef Full Text | Google Scholar Eisoldt, M., Gaal, J., Wiemann, T., Flottmann,
    M., Rothmann, M., Tassemeier, M., et al. (2022). A fully integrated system for
    hardware-accelerated TSDF SLAM with LiDAR sensors (HATSDF SLAM). Robot. Auton.
    Syst. 156:104205. doi: 10.1016/j.robot.2022.104205 CrossRef Full Text | Google
    Scholar FAO (2023). Value of Agricultural Production. Available at: https://www.fao.org/faostat/en/#data/QV/visualize
    [Accessed April 7, 2023]. Google Scholar Fischler, M., and Bolles, R. (1981).
    Random sample consensus: a paradigm for model fitting with applications to image
    analysis and automated cartography. Commun. ACM 24, 381–395. doi: 10.1145/358669.358692
    CrossRef Full Text | Google Scholar Fu, T., Tang, X., Cai, Z., Zuo, Y., Tang,
    Y., and Zhao, X. (2020). Correlation research of phase angle variation and coating
    performance by means of Pearson’s correlation coefficient. Prog. Org. Coat. 139:105459.
    doi: 10.1016/j.porgcoat.2019.105459 CrossRef Full Text | Google Scholar García-López,
    S., Vélez-Nicolás, M., Zarandona-Palacio, P., Curcio, A. C., Ruiz-Ortiz, V., and
    Barbero, L. (2023). UAV-borne LiDAR revolutionizing groundwater level mapping.
    Sci. Total Environ. 859:160272. doi: 10.1016/j.scitotenv.2022.160272 PubMed Abstract
    | CrossRef Full Text | Google Scholar Han, S., Li, Y., Zhou, X., Kan, Z., Meng,
    H., and Qi, J. (2023). DEM simulation and experimental validation of the performance
    of an orchard deep applicator for manure. Appl. Sci. 13:3709. doi: 10.3390/app13063709
    CrossRef Full Text | Google Scholar Hassoun, A., Jagtap, S., Trollman, H., Garcia-Garcia,
    G., Abdullah, N. A., Goksen, G., et al. (2023). Food processing 4.0: Current and
    future developments spurred by the fourth industrial revolution. Food Control
    145:109507. doi: 10.1016/j.foodcont.2022.109507 CrossRef Full Text | Google Scholar
    Hassoun, A., Prieto, M. A., Carpena, M., Bouzembrak, Y., Marvin, H. J. P., Pallarés,
    N., et al. (2022). Exploring the role of green and Industry 4.0 technologies in
    achieving sustainable development goals in food sectors. Food Res. Int. 162:112068.
    doi: 10.1016/j.foodres.2022.112068 PubMed Abstract | CrossRef Full Text | Google
    Scholar Huang, S., Lu, C., Li, H., He, J., Wang, Q., Yuan, P., et al. (2021).
    Transmission rules of ultrasonic at the contact interface between soil medium
    in farmland and ultrasonic excitation transducer. Comput. Electron. Agric. 190:106477.
    doi: 10.1016/j.compag.2021.106477 CrossRef Full Text | Google Scholar Jin, Y.,
    Yuan, X., Wang, Z., and Zhai, B. (2021). Filtering Processing of LIDAR Point Cloud
    Data. IOP Conf. Series: Earth Environ. Sci. 783:012125. doi: 10.1088/1755-1315/783/1/012125
    CrossRef Full Text | Google Scholar Kim, H., and Choi, Y. (2021). Location estimation
    of autonomous driving robot and 3D tunnel mapping in underground mines using pattern
    matched LiDAR sequential images. Int. J. Min. Sci. Technol. 31, 779–788. doi:
    10.1016/j.ijmst.2021.07.007 CrossRef Full Text | Google Scholar Kim, S., Seo,
    Y., Malik, A., Kim, S., Heddam, S., Yaseen, Z. M., et al. (2023). Quantification
    of river total phosphorus using integrative artificial intelligence models. Ecol.
    Indic. 153:110437. doi: 10.1016/j.ecolind.2023.110437 CrossRef Full Text | Google
    Scholar Kirkegaard Nielsen, S., Munkholm, L. J., Lamandé, M., Nørremark, M., Edwards,
    G. T. C., and Green, O. (2018). Seed drill depth control system for precision
    seeding. Comput. Electron. Agric. 144, 174–180. doi: 10.1016/j.compag.2017.12.008
    CrossRef Full Text | Google Scholar Lee, K., Gu, T., and Bang, Y. B. (2020). Analysis
    of Accuracy and Measuring Range of Dual Absolute Encoder System. IEEE Sensors
    J. 20, 2997–3004. doi: 10.1109/JSEN.2019.2955381 CrossRef Full Text | Google Scholar
    Li, B., and Liu, D. (2013). Research and realization of coordinate conversion
    in radar video display. Ninth Int. Conf. Comp. Intellig. Secur. 2013, 277–279.
    doi: 10.1109/CIS.2013.65 CrossRef Full Text | Google Scholar Liu, S., Xu, C.,
    Zhang, H., Jiang, H., Quan, Z., and Wang, J. (2020). Research status and development
    analysis of base-fertilizer application equipment of orchard. Trans. Chinese Soc.
    Agric. Machin. 51, 99–108. doi: 10.6041/j.issn.1000-1298.2020.S2.012 CrossRef
    Full Text | Google Scholar Lou, S., He, J., Li, H., Wang, Q., Lu, C., Wu, Y.,
    et al. (2021a). DESIGN and test evaluation of the subsoiler equipped with tillage
    depth monitoring and control subsoiling assemblies. Inmateh-Agric. Eng. 2022,
    1–15. doi: 10.1155/2022/7344498 CrossRef Full Text | Google Scholar Lou, S., He,
    J., Lu, C., Liu, P., Li, H., and Zhang, Z. (2021b). A tillage depth monitoring
    and control system for the independent adjustment of each subsoiling shovel. Actuators
    10:250. doi: 10.3390/act10100250 CrossRef Full Text | Google Scholar Luo, C.,
    Chen, J., Guo, S., An, X., Yin, Y., Wen, C., et al. (2022). Development and application
    of a remote monitoring system for agricultural machinery operation in conservation
    tillage. Agriculture 12:1460. doi: 10.3390/agriculture12091460 CrossRef Full Text
    | Google Scholar Oid Technology Co., LTD. (2023a). Relation between encoder value
    and Angle. Available at: https://oidencoder.com/faq/ [Accessed April 7, 2023].
    Google Scholar Oid Technology Co., LTD. (2023b). RS485 multi-turn absolute encoder
    details. Available at: https://fanyi.youdao.com/index.html#/ [Accessed April 7,
    2023]. Google Scholar Perez, R. P. A., Costes, E., Théveny, F., Griffon, S., Caliman,
    J.-P., and Dauzat, J. (2018). 3D plant model assessed by terrestrial LiDAR and
    hemispherical photographs: A useful tool for comparing light interception among
    oil palm progenies. Agric. For. Meteorol. 249, 250–263. doi: 10.1016/j.agrformet.2017.11.008
    CrossRef Full Text | Google Scholar Qin, J., Sun, R., Zhou, K., Xu, Y., Lin, B.,
    Yang, L., et al. (2023). Lidar-based 3D obstacle detection using focal voxel R-CNN
    for farmland environment. Agronomy 13:650. doi: 10.3390/agronomy13030650 CrossRef
    Full Text | Google Scholar Rivera, G., Porras, R., Florencia, R., and Sánchez-Solís,
    J. P. (2023). LiDAR applications in precision agriculture for cultivating crops:
    A review of recent advances. Comput. Electron. Agric. 207:107737. doi: 10.1016/j.compag.2023.107737
    CrossRef Full Text | Google Scholar Shang, Y., Wang, H., Qin, W., Wang, Q., Liu,
    H., Yin, Y., et al. (2023). Design and Test of Obstacle Detection and Harvester
    Pre-Collision System Based on 2D Lidar. Agronomy 13:388. doi: 10.3390/agronomy13020388
    CrossRef Full Text | Google Scholar Su, Y., Wang, T., Shao, S., Yao, C., and Wang,
    Z. (2021). GR-LOAM: LiDAR-based sensor fusion SLAM for ground robots on complex
    terrain. Robot. Auton. Syst. 140:103759. doi: 10.1016/j.robot.2021.103759 CrossRef
    Full Text | Google Scholar Tsoulias, N., Paraforos, D. S., Fountas, S., and Zude-Sasse,
    M. (2019). Estimating Canopy Parameters Based on the Stem Position in Apple Trees
    Using a 2D LiDAR. Agronomy 9:740. doi: 10.3390/agronomy9110740 CrossRef Full Text
    | Google Scholar Wang, S., Li, S., Zhang, Y., Zhang, C., Chen, H., and Meng, L.
    (2018). Design and optimization of inclined helical ditching component for mountain
    orchard ditcher. Trans. Chin. Soc. Agric. Eng. 34, 11–22. doi: 10.11975/j.issn.1002-6819.2018.23.002
    CrossRef Full Text | Google Scholar Wu, F., Duan, J., Chen, S., Ye, Y., Ai, P.,
    and Yang, Z. (2021). Multi-target recognition of bananas and automatic positioning
    for the inflorescence axis cutting point. Front. Plant Sci. 12:705021. doi: 10.3389/fpls.2021.705021
    PubMed Abstract | CrossRef Full Text | Google Scholar Zeng, S.-C., Su, Z.-Y.,
    Chen, B.-G., Wu, Q.-T., and Ouyang, Y. (2008). Nitrogen and phosphorus runoff
    losses from orchard soils in south china as affected by fertilization depths and
    rates. Pedosphere 18, 45–53. doi: 10.1016/S1002-0160(07)60101-5 CrossRef Full
    Text | Google Scholar Zhan, C., Ding, W., Han, Y., Jiang, Q., Zhao, Y., Zhao,
    L., et al. (2022). Design and experiments of an automatic depth-adjusting double
    screw trencher and fertiliserning. PLoS One 17:e0277824. doi: 10.1371/journal.pone.0277824
    PubMed Abstract | CrossRef Full Text | Google Scholar Zhang, H., Xu, C., Shuangxi,
    L., Jiang, H., Zhang, C., and Wang, J. (2021). Design and experiment of orchard
    double row ditching-fertilizer machine with automatic depth adjustment. Trans.
    Chinese Soc. Agric. Machin. 52, 62–72. doi: 10.6041/j.issn.1000-1298.2021.01.007
    CrossRef Full Text | Google Scholar Zhao, L., Jiao, S., Wang, C., and Zhang, J.
    (2022). Research on terrain sensing method and model prediction for height adjustment
    of sugarcane harvester base cutter. Wirel. Commun. Mob. Comput. 2022, 1–15. doi:
    10.1155/2022/7344498 CrossRef Full Text | Google Scholar Zhou, X., Kan, Z., Meng,
    H., and Li, Y. (2023a). Research on trenching data correction method based on
    wavelet denoising-kalman filtering algorithm. Arab. J. Sci. Eng. 48, 1097–1117.
    doi: 10.1007/s13369-022-06729-1 CrossRef Full Text | Google Scholar Zhou, X.,
    Kan, Z., Meng, H., Qi, J., Wu, Y., Zhao, X., et al. (2022). Design and experiment
    of orchard ditch depth monitoring system based on lab view. J. Agric. Mechan.
    Res. 44, 164–170. doi: 10.13427/j.cnki.njyi.2022.04.028 CrossRef Full Text | Google
    Scholar Zhou, X., Kan, Z., Meng, H., Qi, J., Zhao, X., and Li, Y. (2021). Design
    and experiment of monitoring equipment for orchard ditching depth and width. J.
    Chin. Agric. Mech. 42, 37–473. doi: 10.13733/j.jcam.issn.2095-5553.2021.12.06
    CrossRef Full Text | Google Scholar Zhou, X., Zou, X., Tang, W., Yan, Z., Meng,
    H., and Luo, X. (2023b). Unstructured road extraction and roadside fruit recognition
    in grape orchards based on a synchronous detection algorithm. Front. Plant Sci.
    14:1103276. doi: 10.3389/fpls.2023.1103276 PubMed Abstract | CrossRef Full Text
    | Google Scholar Keywords: furrow characteristic parameter detection, lidar, furrow
    reconstruction, quality of ditching operation, precision agriculture Citation:
    Zhou X, Wu Y, Meng H, Han S, Kan Z, Li Y and Zhang J (2023) Three-dimensional
    reconstruction of the furrow shape in orchards using a low-cost lidar. Front.
    Sustain. Food Syst. 7:1201994. doi: 10.3389/fsufs.2023.1201994 Received: 07 April
    2023; Accepted: 04 July 2023; Published: 21 July 2023. Edited by: Abdo Hassoun,
    Sustainable AgriFoodtech Innovation & Research (Safir), France Reviewed by: Seyed-Hassan
    Miraei Ashtiani, Ferdowsi University of Mashhad, Iran Ferdaous Boughattas, UniLaSalle,
    France Copyright © 2023 Zhou, Wu, Meng, Han, Kan, Li and Zhang. This is an open-access
    article distributed under the terms of the Creative Commons Attribution License
    (CC BY). The use, distribution or reproduction in other forums is permitted, provided
    the original author(s) and the copyright owner(s) are credited and that the original
    publication in this journal is cited, in accordance with accepted academic practice.
    No use, distribution or reproduction is permitted which does not comply with these
    terms. *Correspondence: Yaping Li, liyaping425@163.com; Jie Zhang, xjwszj0230@sina.com
    †These authors have contributed equally to this work Disclaimer: All claims expressed
    in this article are solely those of the authors and do not necessarily represent
    those of their affiliated organizations, or those of the publisher, the editors
    and the reviewers. Any product that may be evaluated in this article or claim
    that may be made by its manufacturer is not guaranteed or endorsed by the publisher.
    Download Footer Guidelines Author guidelines Editor guidelines Policies and publication
    ethics Fee policy Explore Articles Research Topics Journals Outreach Frontiers
    Forum Frontiers Policy Labs Frontiers for Young Minds Connect Help center Emails
    and alerts Contact us Submit Career opportunities Follow us © 2024 Frontiers Media
    S.A. All rights reserved Privacy policy | Terms and conditions We use cookies
    Our website uses cookies that are necessary for its operation and other cookies
    to track its performance or to improve and personalize our services. To manage
    or reject non-essential cookies, please click \"Cookies Settings\". For more information
    on how we use cookies, please see ourCookie Policy Cookies Settings Accept Cookies"'
  inline_citation: '>'
  journal: Frontiers in Sustainable Food Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Three-dimensional reconstruction of the furrow shape in orchards using a
    low-cost lidar
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Padilla-Quimbiulco D.
  - Morales-Garcia J.
  - Cantabella M.
  - Ayuso B.
  - Munoz A.
  - Cecilia J.M.
  citation_count: '0'
  description: Greenhouses are complex systems where many variables are involved in
    order to optimize crops in an intensive agriculture framework. Therefore, monitoring
    and visualization of all these variables in real-time is mandatory to meet the
    trade-off between natural resource consumption and production maximization. In
    this article, we introduce an intelligent warning system to efficiently control
    agricultural activity in an operational greenhouse to increase productivity by
    optimizing crop production and energy consumption. The system includes a web application
    that allows the graphical and statistical representation of data measured by several
    sensors located inside a greenhouse. These sensors are located in strategic points
    that allow the reading of real-time data in a more accurate manner, therefore
    allowing the generation of information with the minimum percentage of error. In
    addition, the web application offers different data representations to allow a
    more exhaustive analysis of the data obtained. As a result, this warning system
    may help greenhouse managers to anticipate abnormal situations affecting their
    crops.
  doi: 10.1109/IE57519.2023.10179105
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2023 19th International Confe... Greenhouse
    intelligent warning system for precision agriculture Publisher: IEEE Cite This
    PDF Diego Padilla-Quimbiulco; Juan Morales-García; Magdalena Cantabella; Belén
    Ayuso; Andrés Muñoz; José M. Cecilia All Authors 46 Full Text Views Abstract Document
    Sections I. Introduction II. Related Works III. System Architecture IV. Evaluation
    V. Conclusions and Future Work Authors Figures References Keywords Metrics Abstract:
    Greenhouses are complex systems where many variables are involved in order to
    optimize crops in an intensive agriculture framework. Therefore, monitoring and
    visualization of all these variables in real-time is mandatory to meet the trade-off
    between natural resource consumption and production maximization. In this article,
    we introduce an intelligent warning system to efficiently control agricultural
    activity in an operational greenhouse to increase productivity by optimizing crop
    production and energy consumption. The system includes a web application that
    allows the graphical and statistical representation of data measured by several
    sensors located inside a greenhouse. These sensors are located in strategic points
    that allow the reading of real-time data in a more accurate manner, therefore
    allowing the generation of information with the minimum percentage of error. In
    addition, the web application offers different data representations to allow a
    more exhaustive analysis of the data obtained. As a result, this warning system
    may help greenhouse managers to anticipate abnormal situations affecting their
    crops. Published in: 2023 19th International Conference on Intelligent Environments
    (IE) Date of Conference: 29-30 June 2023 Date Added to IEEE Xplore: 14 July 2023
    ISBN Information: ISSN Information: DOI: 10.1109/IE57519.2023.10179105 Publisher:
    IEEE Conference Location: Uniciti, Mauritius SECTION I. Introduction Agriculture
    is an activity of great importance in society. It has undergone many changes in
    terms of techniques and instruments that have been used, but the most significant
    transformation has been thanks to technology. In this area, one of the most relevant
    lines of research is focused on providing assistance in the management of greenhouses
    [1]. In recent years, greenhouse agriculture has been steadily increasing almost
    everywhere on the planet. It is a fact that this type of agriculture is an important
    pillar in today’s society by providing food resources to millions of people around
    the world and allowing the development of countries [2]. For this reason, great
    importance is taken in greenhouse maintenance where several variables come into
    play such as outside temperature, heating temperature, ventilation temperature,
    etc. [3] These variables are obtained by means of specific sensors. In this context,
    this work provides a personalized interactive web application that allows visualizing
    the data collected from the sensors inside a greenhouse to be exposed in a simple
    manner and to alert on abnormal situations. The problems faced by a greenhouse
    manager are climatic problems. Ventilation and air circulation are of great importance
    for the growth and well-being of plants. Greenhouses normally have ventilation
    systems that help control humidity and temperature, but these systems can occasionally
    fail, either because they need maintenance or simply because of a one-off failure.
    If a greenhouse is not being controlled by sensors, this type of failure would
    be very difficult to recognize and repair quickly before it causes damage to the
    plants. Based on this premise, our system aims to help greenhouse managers to
    get an overview of what is happening in the greenhouse with just one click. Also,
    with real-time notifications, the greenhouse manager can act quickly on random
    changes. Thus preventing the greenhouse from being damaged by such a changing
    factor, the weather. Currently, there are not many tools that allow comprehensive
    management of a greenhouse because it is a very specific and changing sector in
    terms of variables such as the type of crop, season, etc. Therefore, the need
    arises to create an application that allows a user to manage a greenhouse from
    a web page without the need to check each sensor individually. The alert system
    proposed in this paper provides the ability to set an optimal measurement range
    for each sensor. This allows the user to receive real-time notifications if any
    measurement is outside the previously established range, thus allowing the user
    to have a quick reaction time. The rest of the paper is structured as follows.
    Section II shows related work that focuses on showing other greenhouse monitoring
    systems already available and how they differ. Section III shows all the tools
    used for the development of this proposal as well as its architecture. Section
    IV the section shows the results obtained and the discussion of these results.
    Finally, Section V presents the main conclusions and discusses future works. SECTION
    II. Related Works Several examples of greenhouse monitoring software development
    can be found in the literature. Some of the proposals are based on wireless sensor
    networks (WSNs) connected to a local network for data collection [4]. WSNs also
    provide benefits such as battery-powered devices that can sense information, process
    it locally and transmit it to the destination using low-power ad hoc wireless
    technologies [5]. These solutions need expert knowledge of programming and chip
    management, which do not make them friendly to users who have basic knowledge
    and want a quick solution. Moreover, they usually are implemented as desktop applications,
    therefore being limited to running on certain types of devices. There are other
    approaches that consider the implementation of a complete IoT system based on
    Raspberry Pi boards and sensors able to connect directly to the board in order
    to have a global system that can monitor a specific plant. Generally, these solutions
    tend to be developed for a specific type of problem-related to the greenhouse.
    In addition, the web implementation of this solution is quite basic in terms of
    the way in which the data is displayed, as the main effort is carried in the technical
    part of hardware rather than in the development of software that can complement
    the data collected by the system [6]. Moreover, it must be taken into account
    that many of the systems currently developed are focused on a certain type of
    crop since in the world of agriculture each crop is special and must be treated
    in a different manner. Some solutions even tend to use cameras to be able to analyze
    crops in a more comprehensive way through the use of neural networks. This development
    is very specific to crop research and would be very difficult to replicate on
    a large scale and would require a great deal of development to handle all the
    data obtained. It is worth noting that not only tools have been developed to check
    the state of a greenhouse, but the tools, when based on a crop, focus on notifying
    the user if the crop is ready to be cultivated [7]. Other implementations like
    GRETAs [8] focus more on building fully intelligent greenhouses. This option is
    interesting as it provides the user with full control over the greenhouse. His
    vision is based on offering the user a full view of the crops and the greenhouse
    through an augmented reality application. This offers the analysis of the plants,
    their form of growth, and tips for pests or to help the growth of the plant. But
    being augmented reality, it takes a lot of resources to build the app and to turn
    the greenhouse into a smart home that communicates with the device and gives it
    the correct readings. It also has a web interface that allows you to get an overview
    of the greenhouse and different sections that show sensor data. This approach
    is interesting, but it must be taken into account that it is a tailor-made development,
    so the addition of new greenhouses or new clients that would like to use the application
    would entail a large cost of management and resources. All of these solutions
    show interesting proposals as each one has a different approach to the data they
    want to collect and how they deal with it. Most of them consist in the creation
    of an ad-hoc sensor system with its respective programming in order to obtain
    the data. Likewise, a network system is needed to communicate the central board
    with all the sensors. Continuing with this line, this paper focuses on the fact
    that the user can obtain certain types of sensor data that are already built and
    do not need to be programmed at the computer level but only configured in order
    to send data to be processed later. In addition, it uses modern frameworks to
    build web applications that allow faster processing and loading of the site as
    many of the current solutions do not offer a friendly interface to the end user
    who is not computer literate and just needs to see the data in an understandable
    way to make decisions. It also allows the addition of new technologies in the
    future and the opportunity to use the application everywhere on all devices that
    have an Internet connection. Finally, an important feature of our system is the
    notification of measurement changes in real-time which very few applications implement
    due to the complexity it encompasses which lies in the fact that it is not easy
    to communicate directly between the server and the client, in addition to the
    fact that a bad implementation would lead to a waste of resources by both the
    server and the client. The client and the server speak in HTTP, a connection language
    that is stateless, therefore the web application must be constantly listening
    if the server has issued a message in order to proceed to update only a part of
    the entire application, implementing in a certain way reactive programming. SECTION
    III. System Architecture A. Background Tools 1) React JS It is a front-end JavaScript
    library that employs a development logic of reusable UI components. It allows
    visual development for large and complex web applications that need to display
    data changes without the need to refresh the page. In addition, it generates good
    performance compared to other libraries that consume a lot of computer and server
    resources [9]. This library will be the core of the application since all the
    data collected from the sensors will be shown here and, in addition, it will be
    in charge of connecting with the server to obtain notifications. 2) Node JS It
    is a JavaScript execution environment that allows handling asynchronous events
    within a server in real time. In addition, it allows the creation of fast web
    applications, since it allows the handling of many simultaneous connections without
    losing performance [10]. It will be in charge of executing the server that will
    collect the data from the sensors and will also perform tasks for data formatting
    and internal comparison of values to generate alerts. 3) MongoDB It is a NoSQL
    database system that is oriented to document management that stores data in a
    JSON-like format called documents. This type of database is really useful in applications
    where large amounts of data are expected to be received, as they are easier to
    process compared to a relational database [11]. It will be the main database where
    a history of the sensor readings will be kept and where all the sensor and application
    configurations will be stored. 4) Express JS It is a Node JS framework that allows
    better manage of requests within a server. What Express allows is to handle HTTP
    requests from a client and return a response which means it can communicate with
    any device that speaks the language of the internet [12]. Thanks to its ease of
    implementation, Express will allow the creation of an API so that the client is
    able to obtain the necessary data. 5) Socket.IO It is a library that allows low
    latency bidirectional communication between client and server. Socket.IO has more
    functionality than an easy to use Web-Sockets API as it provides the ability to
    use other real-time protocols if sockets are not available as some browsers may
    not support Web-Sockets [13]. It is the most important technology since it is
    what allows a real-time connection between the server and client. Therefore, it
    allows the notification of alerts to the user. 6) MQTT It is a M2M (machine-to-machine)
    communication protocol based on TCP/IP as the basis for communication. MQTT is
    a standardized publish/subscribe protocol that was developed with the idea of
    sending accurate data over a slow connection network. The protocol is based on
    users subscribing to topics to receive messages published by a client [14].This
    technology will be used to send data from the sensors to the server. The connection
    of the sensors will provide a subscription to read data periodically. 7) Mailjet
    It is a mailing platform that allows a fast integration in different web projects
    to send web mails to users in a fast and secure way. It is used to send notifications
    to the user through the mail. This platform will allow the sending of emails to
    the user within the platform and the default user. Fig. 1: Web Flow Schema Show
    All Figure 1 shows the architecture of the proposed alert system for monitoring
    greenhouses. It results in an application that can be used in any device regardless
    of its operating system that connects to a database and sensors in order to provide
    real-time data awareness of the actual state of a greenhouse. Everything is connected
    through the internet. The main actor is the server since it is in charge of receiving
    the data from the sensors, processing it and sending it to the database. Likewise,
    the server is in charge of managing the HTTP requests from the client to obtain
    the latest measurements and the history of each sensor. Finally, there is a direct
    connection between the client and the server because the client must be actively
    listening if the server issues a message about an alarm, when the client receives
    the alarm, it notifies the server that it has been received and avoids a double
    propagation of alerts. The system has a landing dashboard that allows a quick
    overview of all the sensors data in a glance as shown in Figure 2. On this home
    page the latest measurements of the different sensors that the greenhouse has
    are shown. Each measurement has its specific unit, for example: Outdoor humidity
    “HumedadExterior” is shown as a percentage since this is how this measurement
    is measured. Likewise, sensors such as the rain alarm “AlarmaLluvia” are shown
    as on or off since they only collect data on the possibility of rain. A message
    is also displayed showing how long ago that measurement was obtained “Last Updated”
    in order to notify the user about the time that has passed since the last time
    a measurement was received in any sensor. Fig. 2: Home Page Show All Figure 3
    shows data representation is an important part of the application as it allows
    visualization in different ways to help the user understand more about the data
    that has been collected over a period of time. Within the table the user can find
    two columns date and the measurement accompanied by the respective unit of that
    sensor. This table allows filtering of the data and adds a listing perspective
    that is more familiar to the user. Likewise, it offers the functionality to search
    both by measurement or by date. As a second data representation, there is a linear
    graph that shows the evolution of the measurements over time. This graph shows
    the date as the horizontal axis and the measure as the vertical axis. When the
    user has only selected one day, the history is shown for each record on that day,
    which are usually records obtained every five minutes by the sensor. If the user
    chooses several days, the form of representation will be changed and the data
    grouped by day will be displayed. Likewise, if the user decides to filter between
    two months, it is grouped by each month. Fig. 3: Data Page Show All SECTION IV.
    Evaluation A. Real-Time alerts Notifications are one of the most important features
    of the system as the user needs to know the status of the greenhouse in real time.
    This means that any changes that happen must be informed to the user. The notifications
    are shown as a list in a page as a historic of all the alerts that have happened,
    as shown in Figure 4. In this section called recent, a list with the history of
    all the notifications that have been generated by the application is shown. Here
    all the alarms are shown, both for increase and decrease of measurements such
    as alert in the CajaMedida1.DH sensor where a decrease in the measurement was
    detected. The date on which the alarm occurred is also displayed. On the other
    hand, the user is offered the ability to delete the notification from the history
    in case he considers the alert resolved. Fig. 4: Notification List Show All Notification
    alerts are displayed as a floating modal dialog box at the top of the page and
    their color depends on whether the measurement that generated the alert is higher
    or lower than the range set in the settings, as seen in Figure 5 which displays
    the text “Warning, the CajaMedida1.DH sensor has detected a value increase over
    the established limit” which informs the user that the sensor has detected that
    a measure has increased in value and the greenhouse manager must address this
    alert. Notifications are red when the value exceeds the upper limit and green
    when the value falls below the lower limit. Notifications are shown across all
    the web application no matter in which web page the user is working on. Fig. 5:
    Overheating Notification Show All Another feature of the system is the ability
    to log-in as shown in the Figure 6 to perform certain types of management actions.
    The user management is implemented with Google’s Firebase which allows an easy
    authorization integration. Due to this implementation, the user can use his email
    or his google account to access the application. Likewise, a basic login system
    is provided where the user can register and even recover his password if he has
    forgotten it. Fig. 6: Login Page Show All The configuration section shown in Figure
    7 is only shown to authenticated users in the web application. A list of all the
    sensors available to configure is displayed. Within this section the user will
    have control over the sensor limits and can also configure the email to which
    the notifications are to be sent, as shown in the Figure 8. It is important to
    note that the notifications will be both for the user who is logged in and for
    the user defined in the email field “Default email notifications”. Fig. 7: Configuration
    Page Show All The user will receive within the email all the notifications that
    have been generated, thus avoiding an overload of emails for the users. The email
    message shown in Figure 9, “Notifications: Warning, the CajaMedida1.DH sensor
    has detected a decrease of the value −1.04 over the established limit.” is a warning
    about the decrease of the value above the previously established limit. It has
    a brief summary of which sensor has received the alert, whether it has been an
    increase or decrease of the set value and the value itself that has caused the
    alert to be triggered. Fig. 8: Email Configuration Section Show All Fig. 9: Email
    with the notification alert Show All Another relevant feature of the system is
    the configuration for the generation of these notifications. The application allows
    the ability to edit an optimal range of measurements for each of the sensors.
    There are only two data, minimum value and maximum value for each sensor as shown
    in Figure 10. This enables the generation of notifications because when new measurements
    are received, the server starts to check if the measurement is out of the established
    ranges and generates the notification for each sensor. Then, these notifications
    are grouped and sent by mail to the user. Fig. 10: Sensors Configurations Sections
    Show All This functionality requires direct communication between the client (web
    page) and the server (Node JS). The server is constantly reading the data from
    the servers and comparing if each measurement is within a range to know if the
    measurement is above or below a range. When a measurement presents an anomaly,
    the server sends a communication to all the clients connected to the server so
    a notification is shown inside the web application, and also an email is sent
    to a predefined user, allowing real-time communication of changes. All this is
    achieved thanks to the use of sockets that allows the server to send a communication
    to all clients that are connected at that moment as seen in Figure 11. Even if
    there is no user connected at that moment, the server will continue to check the
    measurements and notify the user by email. B. Running Example A use case for the
    application could be that the greenhouse is located in an arid zone, where the
    summer is very strong and the temperatures are too high. The greenhouse must have
    the air conditioning system working correctly to keep the crops at a perfect temperature
    and humidity to avoid damage. Within the application, it has been established
    that the value of the internal temperature of the greenhouse must be between twenty
    (20) and twenty-five (25) degrees Celsius. The greenhouse is stable but suddenly
    the air conditioning system begins to fail, the farmers are doing other tasks
    and are not in the greenhouse to perceive that the temperature is increasing slightly
    inside the greenhouse. The sensor that is responsible for obtaining the temperature
    reading collects a measurement of thirty (30) degrees Celsius that is later sent
    via the Internet and MQTT to the application server. The server is in charge of
    receiving this data, saving it, and later comparing the measurement with the range
    established for that sensor, as it detects that the measurement is greater than
    the maximum value, it proceeds to send a notification to all connected clients
    and generates an email that it will reach the default user who will be the greenhouse
    manager. Upon receiving the mail, this manager will go to the greenhouse and begin
    to check if the machines are working well. In this way, you can observe the operation
    of the application to prevent damage to crops due to non-human failures. Fig.
    11: Socket Communication Between the Server and Different Clients Show All SECTION
    V. Conclusions and Future Work Greenhouse monitoring systems are a key element
    in the agricultural sector as it provides a platform for farmers to manage their
    plantations easily and efficiently by streamlining the monitoring process. In
    this paper, we have introduced an alternative based on a simple and intuitive
    web application. With the help of this application, the user can observe greenhouse
    data in real-time from the comfort of any device with an internet connection.
    In addition, the user receives real-time alerts on the status of the greenhouse
    allowing a quick reaction to unwanted changes of a specific measure, thus helping
    the conservation of one of the most important food source and development tools
    in the world. The most promising future work of this paper would be: (1) The creation
    of a predictive system that allows forecasting of what will happen inside the
    greenhouse; (2) The creation of predictive measurement alarms which monitors the
    output of the Artificial Intelligence models and capable of warning of anomalous
    situations that will occur in the future so that they can be prevented; (3) Allow
    the user to take full control of its sensors and their behavior; (4) Implement
    new data analytics to help the user understand better what is happening in the
    greenhouse and how he can take action over that. ACKNOWLEDGMENTS This work is
    derived from R&D projects RYC2018-025580-I, RTC2019-007159-5, “FSE invest in your
    future” and “ERDF A way of making Europe”. Financial support for this research
    has been also provided under grant PID2020-112827GB-I00 funded by MCIN/AEI/10.13039/501100011033.
    Authors Figures References Keywords Metrics More Like This Experimental high speed
    CMOS image sensor system and applications SENSORS, 2002 IEEE Published: 2002 Method
    for Modeling and Visualization of Agricultural Crops Growth Based on Augmented
    Reality Technology in Terms of the Greenhouse Effect Dynamics 2023 International
    Russian Smart Industry Conference (SmartIndustryCon) Published: 2023 Show More
    IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: 2023 19th International Conference on Intelligent Environments, IE 2023
    - Proceedings
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Greenhouse intelligent warning system for precision agriculture
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Cremona J.
  - Civera J.
  - Kofman E.
  - Pire T.
  citation_count: '0'
  description: The accelerating pace in the automation of agricultural tasks demands
    highly accurate and robust localization systems for field robots. Simultaneous
    Localization and Mapping (SLAM) methods inevitably accumulate drift on exploratory
    trajectories and primarily rely on place revisiting and loop closing to keep a
    bounded global localization error. Loop closure techniques are significantly challenging
    in agricultural fields, as the local visual appearance of different views is very
    similar and might change easily due to weather effects. A suitable alternative
    in practice is to employ global sensor positioning systems jointly with the rest
    of the robot sensors. In this paper we propose and implement the fusion of global
    navigation satellite system (GNSS), stereo views, and inertial measurements for
    localization purposes. Specifically, we incorporate, in a tightly coupled manner,
    GNSS measurements into the stereo-inertial ORB-SLAM3 pipeline. We thoroughly evaluate
    our implementation in the sequences of the Rosario data set, recorded by an autonomous
    robot in soybean fields, and our own in-house data. Our data includes measurements
    from a conventional GNSS, rarely included in evaluations of state-of-the-art approaches.
    We characterize the performance of GNSS-stereo-inertial SLAM in this application
    case, reporting pose error reductions between 10% and 30% compared to visual–inertial
    and loosely coupled GNSS-stereo-inertial baselines. In addition to such analysis,
    we also release the code of our implementation as open source.
  doi: 10.1002/rob.22232
  full_citation: '>'
  full_text: '>

    "UNCL: University Of Nebraska - Linc Acquisitions Accounting Search within Login
    / Register Journal of Field Robotics RESEARCH ARTICLE Full Access GNSS-stereo-inertial
    SLAM for arable farming Javier Cremona,  Javier Civera,  Ernesto Kofman,  Taihú
    Pire First published: 24 July 2023 https://doi.org/10.1002/rob.22232 [Correction
    added on 1 August 2023, after first online publication: In “Data availiability
    Statement” section, the URL “https://github.com/CIFASIS/gnss-visual-inertial-fusion”
    has been changed to “https://github.com/CIFASIS/gnss-stereo-inertial-fusion” in
    this version.] SECTIONS PDF TOOLS SHARE Abstract The accelerating pace in the
    automation of agricultural tasks demands highly accurate and robust localization
    systems for field robots. Simultaneous Localization and Mapping (SLAM) methods
    inevitably accumulate drift on exploratory trajectories and primarily rely on
    place revisiting and loop closing to keep a bounded global localization error.
    Loop closure techniques are significantly challenging in agricultural fields,
    as the local visual appearance of different views is very similar and might change
    easily due to weather effects. A suitable alternative in practice is to employ
    global sensor positioning systems jointly with the rest of the robot sensors.
    In this paper we propose and implement the fusion of global navigation satellite
    system (GNSS), stereo views, and inertial measurements for localization purposes.
    Specifically, we incorporate, in a tightly coupled manner, GNSS measurements into
    the stereo-inertial ORB-SLAM3 pipeline. We thoroughly evaluate our implementation
    in the sequences of the Rosario data set, recorded by an autonomous robot in soybean
    fields, and our own in-house data. Our data includes measurements from a conventional
    GNSS, rarely included in evaluations of state-of-the-art approaches. We characterize
    the performance of GNSS-stereo-inertial SLAM in this application case, reporting
    pose error reductions between 10% and 30% compared to visual–inertial and loosely
    coupled GNSS-stereo-inertial baselines. In addition to such analysis, we also
    release the code of our implementation as open source. 1 INTRODUCTION Over the
    last decades, several agricultural tasks such as sowing, weed detection, and removal
    or harvesting are being progressively automated targeting sustainable and environmentally
    friendly production. The use of autonomous robots in an agricultural environment
    has gained relevance, as it enables an efficient use of resources (Auat Cheein
    & Carelli, 2013; Bac et al., 2014). In general, to fully automate these and other
    agricultural tasks, the robot needs to know its pose relative to the environment
    in which it is navigating. A localization system must have a very high degree
    of robustness and accuracy for a mobile robot to navigate safely without damaging
    the environment or itself. For most environments and tasks, a single sensor may
    not offer a sufficiently reliable robot pose estimate. As a few illustrative examples,
    global navigation satellite system (GNSS) sensors in outdoor environments do not
    accumulate error (drift) but they present considerable variance in their global
    position readings and may suffer frequent signal loss. State-of-the-art methods
    based on visual sensors perform badly if images have insufficient or repetitive
    textures, which is common in agricultural environments. Lighting can also be a
    problem if it is insufficient or excessive, and abrupt robot motion can cause
    image blur that degrades the estimation performance. Finally, interoceptive sensors
    that measure the internal state of the robot, such as the encoders in the wheel
    motors or inertial measurement units (IMUs), are accurate for short-term motion
    estimation but drift after a few meters. Summing up, as all sensors have different
    and complementary advantages and disadvantages, it is essential for field robotics
    to properly fuse the measurements of multiple sensors to achieve robust and accurate
    pose estimates. This is particularly relevant to allow the robot to navigate over
    long periods of time (long-term navigation) and to keep the error bounded locally
    and globally. SLAM, standing for Simultaneous Localization and Mapping, stands
    for the set of methods targeting global localization and mapping from a set of
    onboard sensors in a mobile agent (Cadena et al., 2016). A large number of visual–inertial
    SLAM pipelines have been proposed in the last decade (Campos et al., 2021; Mur-Artal
    & Tardós, 2017a; Qin et al., 2018). Many of them demonstrate high accuracy and
    robustness in indoor and urban environments. However, when it comes to the agricultural
    environment, they present problems in correctly estimating the pose of the robot.
    Among others, agricultural environments are challenging for visual navigation
    due to insufficient and/or repetitive texture and direct sunlight. Adding inertial
    measurements provides a slight improvement in the estimation. Nevertheless, as
    shown in Cremona et al. (2022), state-of-the-art visual–inertial systems accumulate
    significant errors after navigating a few minutes on arable lands. Robust SLAM
    systems such as oriented fast and rotated brief (ORB)-SLAM3 (Campos et al., 2021)
    can eliminate drift when revisiting already mapped places, but the so-called loop
    closing offers a poor performance on agricultural fields due to insufficiently
    discriminative visual appearances. A reasonable alternative, that we use in this
    work, is to employ measurements from global positioning sensors such as GNSS to
    allow the robot to navigate for long periods without accumulating drift. This
    paper presents a GNSS-stereo-inertial SLAM implementation that fuses GNSS, visual,
    and inertial measurements using a tightly coupled approach. Specifically, we extend
    the state-of-the-art ORB-SLAM3 (Campos et al., 2021) with GNSS factors. The global
    positioning measurements are incorporated into the mapping thread, so that it
    performs periodic corrections in the local map and hence also corrects the current
    camera pose in the tracking thread. In this manner, we can achieve drift-less
    trajectories without depending on the ability of the system to close loops based
    on visual appearance. We evaluated our implementation on the agricultural data
    set known as Rosario data set (Pire et al., 2019) and an additional in-house data
    set, which contains data from a wheeled robot in a soybean field (see Figure 1a,b
    for a picture of our robot). In both cases, we show how our implementation is
    able to effectively fuse GNSS readings outperforming the original stereo-inertial
    ORB-SLAM3. The contribution of the work can be summarized as follows: Implementation
    of a GNSS-stereo-inertial framework. Evaluation of our GNSS-stereo-inertial framework
    tightly coupled fusion in agricultural environments, incorporating real conventional
    GNSS measurements instead of simulated ones, which are rarely included in evaluations
    of state-of-the-art approaches. Public release of our implementation as open-source,1
    to facilitate its usage, extensions and comparisons, and evaluations by the robotics
    community. Figure 1 Open in figure viewer PowerPoint (a, b) Frontal and back views
    of our field robot and the arable field environment in which we navigate. (c)
    Trajectory estimated by our GNSS-stereo-inertial SLAM framework, along with GNSS-RTK
    ground-truth, visual–inertial ORB-SLAM3 (Campos et al., 2021) and VINS-Fusion
    (Qin et al., 2019). GNSS, global navigation satellite system; ORB, oriented fast
    and rotated brief; RTK, real-time kinematics; SLAM, Simultaneous Localization
    and Mapping; VINS, visual–inertial state. [Color figure can be viewed at wileyonlinelibrary.com]
    The article is organized as follows: Section 2 discusses related work on multimodal
    sensor fusion. In Section 3, we describe the proposed GNSS-stereo-inertial framework.
    In Section 7, we present and discuss the experimental results of our GNSS-stereo-inertial
    implementation on real data in an agricultural field. Finally, we present our
    conclusions in Section 11. 2 RELATED WORK Sensor fusion methods can be broadly
    divided into two groups, loosely coupled and tightly coupled. Loosely coupled
    methods are those that omit correlations between measurements from different sensors.
    This simplifies the fusion, as the estimation from each sensor can run separately
    and the estimates be fused afterwards. Most of these approaches are based on filters,
    such as the Extended Kalman Filter (EKF), that sequentially updates the system
    state integrating previous information. This is however suboptimal compared to
    tightly coupled methods (Strasdat et al., 2012), which model the correlations
    between state variables and sensor measurements. In this last case, the measurements
    from all sensors are jointly integrated in the same optimization problem. As a
    drawback, tightly coupled solutions generally have a higher computational cost
    than loosely coupled ones. In the rest of the section, we refer to the most related
    works to ours, from the loosely coupled to the tightly coupled ones. Weiss et
    al. (2012) propose an EKF-based estimation method for Micro Air Vehicles (MAVs).
    Its contribution is a modular loosely coupled method that is capable of fusing
    visual, inertial, and external positioning sensor (such as global positioning
    system [GPS] or a laser telemetry tracking system) information. The results show
    that the proposed method allows state predictions to be made up to 1 kHz for MAV
    control tasks, being robust to low-frequency measurements of 1 Hz, delays of up
    to 500 ms in the measurements and noise with standard deviations up to 20 cm.
    Shen et al. (2014) present a similar loosely coupled approach but using an Unscented
    Kalman Filter, to better address the nonlinearities in the sensor models. Wei
    et al. (2011) use stereo cameras to estimate the motion of a ground robot, considering
    motions only in the horizontal plane, and using an EKF to fuse global GPS measurements
    in a loosely coupled manner, reducing the drift. Won, Lee, Heo, Lee et al. (2014)
    and Won, Lee, Heo, Sung et al. (2014) propose a selective integration method for
    GNSS, visual, and inertial measurements to improve localization accuracy under
    GNSS-challenged environments. The authors introduced a new performance index to
    recognize poor environments based on the geometrical distribution of the satellites
    and the local image features. Li et al. (2019) present a multistate constraint
    Kalman filter (MSCKF) approach to fuse monocular, inertial, and raw GNSS-RTK measurements.
    The MSCKF makes use of a measurement model that does not require to include the
    feature landmarks in the state vector of the EKF, improving the robustness and
    computational complexity of the system. Salehi et al. (2017) use a mixture of
    tightly coupled and loosely coupled techniques for the fusion of visual and GPS
    measurements. An exhaustive optimization restricted to a temporal window of recent
    visual measurements is used, while measurements outside the window are marginalized
    by obtaining estimates of relative motion between poses. This allows for improving
    computational times, preventing the computational complexity to scale. Yu et al.
    (2019) present a GPS-assisted visual–inertial estimation framework for omnidirectional
    platforms. It extends the monocular visual–inertial state (VINS-MONO) (Qin et
    al., 2018) to support multiple cameras, fuses visual and inertial information
    in a tightly coupled manner, combined with a loosely coupled approach to incorporate
    the measurements provided by GPS. Later, the same authors present GVINS (Cao et
    al., 2022), a framework based on nonlinear optimization. GVINS tightly fuses GNSS
    raw measurements with visual and inertial information for state estimation. The
    GNSS pseudorange and Doppler shift measurements are modeled under a probabilistic
    factor graph framework along with visual and inertial constraints. The same approach
    is applied in Liu et al. (2021). Lynen et al. (2013) present MultiSensor Fusion
    (MSF), a modular sensor fusion system based on an EKF filter where inertial information
    is used at the prediction step. The information coming from the different sensors
    is modeled in a general manner as relative and/or absolute pose estimates, thus
    allowing to fuse measurements coming from a large number of sensors using a loosely
    coupled approach. The work places particular emphasis on modeling the temporal
    arrival of the measurements by applying a technique known as Stochastic Cloning
    able to address asynchronous sensor fusion. Mascaro et al. (2018) present the
    graph-optimization-based MSF framework which solves the fusion of pose estimates
    in different coordinate systems. Visual–inertial estimates from the MSF in local
    coordinates are merged with measurements in global coordinates from a GPS. Lee
    et al. (2020) present a GPS-VIO system that fuses visual–inertial data with intermittent
    GPS measurements. The authors proposed a GPS-IMU online calibration approach for
    the time offset and extrinsics estimation. In Boche et al. (2022) a tightly coupled
    visual–inertial-GPS system is presented. The system is based on OKVIS2 (Leutenegger,
    2022). In the work a new global reference frame initialization has been introduced.
    It incorporates measurement uncertainties to decide whether the extrinsic transformation
    between the global and visual–inertial reference frame becomes observable. Han
    et al. (2022) implement a system that integrates GNSS measurements into ORB-SLAM3
    (Campos et al., 2021). In contrast to our research, their approach defines a residual
    that combines GNSS and IMU preintegration measurements, along with implementing
    online calibration for the GNSS-IMU extrinsic. Remarkably, their system was evaluated
    within indoor and urban environments, where the GNSS signal can be susceptible
    to disruptions, but without facing the visual challenges typically present in
    agricultural fields. In contrast to the previously mentioned works, this paper
    presents a tightly coupled GNSS-stereo-inertial SLAM to tackle localization in
    agricultural environments. The proposed framework extends the visual–inertial
    SLAM system ORB-SLAM3 (Campos et al., 2021) with GNSS measurements. We built on
    top of ORB-SLAM3 since it has a fair performance in agricultural environments
    (Cremona et al., 2022). Our implementation is publicly released as open source
    to facilitate its use, extension, and reproduction of the results by the robotics
    community. 3 PROPOSED GNSS-STEREO-INERTIAL FRAMEWORK This section presents the
    technical aspects of our implementation. First, we introduce the notation and
    conventions adopted that are necessary to fully detail the model of our GNSS factor.
    Later, we briefly introduce ORB-SLAM3 (Campos et al., 2021), the state-of-the-art
    framework visual–inertial SLAM that we use in our method. We refer the reader
    to the original ORB-SLAM3 publication for the full details on such framework.
    Finally, we describe the formulation of our GNSS factor. 3.1 Notation Figure 2
    shows the coordinate frames used in this work. represents the world frame and
    represents the body frame, that we place in the IMU sensor. represents the coordinates
    of a geometry entity with respect to the reference frame . refers to the rotation
    of with respect to , and represents the translation of the reference frame expressed
    in the frame . The rigid transformation formed by the rotation and the translation
    is denoted as , and transforms points in homogeneous coordinates from the reference
    frame to the reference frame . For global positioning measurements, is the position
    of the GNSS antenna in the body frame, and is assumed to be known from a calibration
    stage. All GNSS measurements are transformed to the local Cartesian frame that
    we denote as . We detail below how we choose such reference frame. Figure 2 Open
    in figure viewer PowerPoint Reference frames used in this work. represents the
    world frame and represents the body frame at time . corresponds to time of the
    arrival of the first GNSS measurement. is an East-North-Up (ENU) local Cartesian
    frame whose position is given by this first GNSS measurement, that is, the position
    of the antenna at time . The position of the GNSS antenna in the body frame is
    represented with a translation and shown with a blue line, and can be obtained
    from the calibration of the system. The red line represents the estimated translation
    of the GNSS antenna from time to time . This 3D vector is compared with the GNSS
    measurements in the GNSS error residual . Both vectors are expressed in frame.
    GNSS, global navigation satellite system. [Color figure can be viewed at wileyonlinelibrary.com]
    3.2 ORB-SLAM3 ORB-SLAM3 is a state-of-the-art visual–inertial SLAM framework evolved
    from ORB-SLAM2 (Mur-Artal & Tardós, 2017b) and ORB-SLAM-VI (Mur-Artal & Tardós,
    2017a). With respect to ORB-SLAM-VI, ORB-SLAM3 proposes a substantially more robust
    inertial initialization based on maximum-a-posteriori estimates. As it is common
    in current SLAM systems, the processing is split into multiple threads to exploit
    multicore architectures. Specifically, ORB-SLAM3 implements a tracking thread,
    a local mapping thread, and a loop closure and map merging thread. The tracking
    thread estimates the pose of the current frame by minimizing the reprojection
    error and incorporating IMU constraints into the optimization by preintegration
    (Forster et al., 2017). It also contains the heuristics for deciding whether a
    frame becomes a keyframe. The mapping thread main task is a visual–inertial bundle
    adjustment on a sliding window of keyframes, although it also performs auxiliary
    map management tasks, such as point and keyframe culling. Finally, the loop closure
    and map merging thread ensure the global consistency of large maps by recognizing
    revisited places and correcting the drift, and joining separate maps if a common
    overlap is detected. From the results in Cremona et al. (2022), ORB-SLAM3 presents
    an acceptable accuracy in arable lands for short camera trajectories, but long-term
    navigation is still challenging. The authors propose a novel loop closure algorithm
    to correct the drift. However, even with such improvement, loop closure keeps
    being challenging due to the similarity in appearance of the local visual features.
    As a result, visual SLAM systems may accumulate drift when loop closures are not
    detected or the estimation may be corrupted by false loop detections. 3.3 GNSS-stereo-inertial
    fusion In this work, we formulate a tightly coupled approach for fusing visual,
    inertial, and GNSS data. First, GNSS measurements are associated with the timestamp
    of a keyframe according to their temporal proximity. If there is a keyframe with
    a temporal difference under a specific threshold, the GNSS constraint is set to
    this keyframe. GNSS readings that are not close in time to any keyframe are discarded
    (see an illustration of this approach in Figure 3). While this is an approximation,
    we found that, given the high variance of conventional GNSS, a sufficiently small
    threshold and appropriate keyframe management policy make its effect negligible.
    Figure 3 Open in figure viewer PowerPoint Representation of the temporal association
    between keyframes and GNSS measurements. Keyframes are depicted with blue crosses
    on the temporal line and GNSS measurements are depicted with green arrows. The
    dotted box represents the association between a keyframe and a measurement. Note
    that there are keyframes without a corresponding GNSS measurement and that GNSS
    measurements can be discarded if they are further than a specific temporal threshold
    from any keyframe. GNSS, global navigation satellite system. [Color figure can
    be viewed at wileyonlinelibrary.com] The first GNSS reading that is associated
    with a keyframe determines the position of , the Cartesian frame for our global
    position measurements (see Figure 2). We choose as an East-North-Up (ENU) local
    Cartesian frame. The subsequent GNSS measurements are transformed to be expressed
    in , and we refer to them as , where is the timestamp of the corresponding keyframe.
    This is done once the IMU is initialized. If the map is reset, the process of
    selecting is repeated. Our GNSS-stereo-inertial fusion is done in the local bundle
    adjustment of a sliding window of keyframes and 3D points observed from them.
    Figure 4 shows the factor graph corresponding to such optimization. The state
    variables to optimize are , where is the set of sensor states for a window covering
    the last keyframes and is the set of landmarks states that were measured during
    those last keyframes. The sensor state at the time instant is (1) which contains
    the sensor rigid transformation with respect to the world frame , its local velocity
    and the accelerometer and gyroscope bias and . Landmarks are represented by their
    Euclidean coordinates in the world frame, that is, . Figure 4 Open in figure viewer
    PowerPoint Factor graph corresponding to the local bundle adjustment of our GNSS-stereo-inertial
    SLAM. In comparison to ORB-SLAM3, a GNSS factor (in red) is added to the cost
    function. The local window is composed of the last keyframes. The fixed window
    contains keyframes outside the local window that are connected in the covisibility
    graph to any local keyframe. These keyframes remain fixed during optimization.
    Additionally, the keyframe N + 1 is included in the fixed window as it constrains
    the IMU states. GNSS, global navigation satellite system; IMU, inertial measurement
    unit; ORB, oriented fast and rotated brief; SLAM, Simultaneous Localization and
    Mapping. [Color figure can be viewed at wileyonlinelibrary.com] In comparison
    to ORB-SLAM3, a GNSS error term is added to the cost function. Note that, as shown
    in Figure 3, some keyframes may not have an associated GNSS measurement. Then,
    our GNSS-stereo-inertial mapping optimization can be stated as follows: (2) where
    is the set of keyframes that have an associated GNSS measurement. The three addends
    correspond, respectively, to the inertial, visual, and GNSS constraints. For the
    sake of completeness, we will detail the three of them, although the first two
    are used exactly as proposed in ORB-SLAM3 and the third one is our novel contribution.
    The inertial residual is defined as follows: (3) where , and correspond to orientation,
    velocity, and position residuals that have the following form: (4) The terms denoted
    as , and come from the preintegration of the IMU readings between the time instants
    and , and are computed together with their on-manifold covariance according to
    Forster et al. (2017). stands for the gravity direction, which is set at the system
    bootstrapping. The visual residual is (5) where stands for the homogeneous representation
    of the landmark, for the pinhole projection model of a 3D point in homogeneous
    coordinates in a stereo image, and the measured image coordinates of the landmark
    in the stereo keyframe. The visual covariance of image landmarks is set to the
    standard 1-px standard deviation isotropic Gaussian. Finally, the GNSS error residual
    is (6) The second term represents the translation vector of the global sensor
    (in this case, the GNSS antenna) at time instant in the reference frame , as can
    be seen in Figure 2. and , which are the relative rotation and translation between
    the body and the world frame at time , are kept constant during the optimization.
    is computed by aligning the first 20 GNSS measurements with the poses estimated
    by ORB-SLAM3 in the same time period using Umeyama''s method (Umeyama, 1991).
    After estimating this rotation, it is kept fixed during the whole optimization
    process. The covariance matrix is set from the specifications sheet of our GNSS
    device in each Cartesian axis (7) This covariance matrix is defined relative to
    a tangential plane through the GNSS-reported position. The values are expressed
    in the ENU frame. Finally, the Jacobian with respect to the pose error state is
    defined as (8) where indicates that the derivative is computed with respect to
    a right perturbation in the pose. 4 EXPERIMENTAL EVALUATION This section shows
    the experimental results of the implementation proposed in Section 3. The framework
    is evaluated on the Rosario data set (Pire et al., 2019), a set of agricultural
    data captured by a weed removal robot. Later, an evaluation of the system in a
    soybean field is presented, using the same weed removal robot. The difference
    between the latter test and the evaluation on the Rosario data set is that new
    sensors are available, including measurements from a conventional GNSS. For the
    temporal association between keyframes and GNSS measurements explained in Section
    5, a threshold of 0.035 s is chosen in all experiments. 4.1 Rosario data set The
    Rosario data set (Pire et al., 2019) is a set of data captured by the sensors
    of a weed removal robot developed by the CIFASIS Institute (CONICET-UNR) in Rosario,
    Argentina. It is composed of six sequences captured in a soybean field. The sequences
    contain stereo images of px captured at 15 Hz, measurements from an IMU with a
    frequency of 142 Hz including gyroscope and accelerometer, wheel odometry obtained
    at 10 Hz and GNSS-RTK measurements at 5 Hz. The GNSS-RTK data are used as positional
    ground-truth. Since the Rosario data set does not have conventional GNSS measurements,
    we simulate noisy GNSS measurements by corrupting the ground-truth with zero-mean
    Gaussian noise, as in Cioffi and Scaramuzza (2020). We use isotropic Gaussian
    noise , with a standard deviation m. We selected this value by observing the covariance
    of the conventional GNSS used in the experiments in Section 8. We compared our
    GNSS-stereo-inertial implementation against Stereo-Inertial ORB-SLAM3 and a loosely
    coupled GNSS-stereo-inertial system known as VINS-Fusion (Qin et al., 2019). VINS-Fusion
    was chosen because it is a state-of-the-art system that takes as input the same
    GNSS measurements as our system, that is, latitude, longitude, and altitude. Each
    system was run five times in each of the Rosario sequences, and Table 1 presents
    the lowest Absolute Trajectory Error (ATE) error of the five executions for each
    framework. ATE has been computed after the estimated trajectories were aligned
    with the ground-truth GNSS readings using Umeyama''s method (Umeyama, 1991). The
    corresponding trajectories are presented in Figure 5. Table 1. Mean (standard
    deviation) of the Absolute Trajectory Error (m) for stereo-inertial ORB-SLAM3
    (Campos et al., 2021), a loosely coupled GNSS-stereo-inertial system (Qin et al.,
    2019), and our tightly coupled GNSS-stereo-inertial framework in the six sequences
    of the Rosario data set. Sequence Stereo-inertial GNSS-stereo-inertial GNSS-stereo-inertial
    (Campos et al., 2021) (Qin et al., 2019) (Ours) 01 0.90 (0.34) 1.44 (2.06) 0.86
    (0.26) 02 1.33 (0.75) 0.90 (0.40) 0.94 (0.56) 03 1.12 (0.65) 1.34 (1.91) 0.99
    (0.56) 04 1.09 (0.65) 1.42 (1.20) 1.04 (0.60) 05 0.89 (0.55) 1.43 (1.91) 0.76
    (0.38) 06 2.48 (1.40) 1.81 (0.87) 1.23 (0.70) Note: Best results are in bold.
    Abbreviations: GNSS, global navigation satellite system; ORB, oriented fast and
    rotated brief; SLAM, Simultaneous Localization and Mapping. Figure 5 Open in figure
    viewer PowerPoint Results from stereo-inertial ORB-SLAM3 (Campos et al., 2021),
    a loosely coupled GNSS-stereo-inertial system (Qin et al., 2019), and our tightly
    coupled GNSS-stereo-inertial system on the Rosario data set. The estimated trajectories
    are aligned with the ground-truth using Umeyama''s method (Umeyama, 1991). (a)
    Sequence 01, (b) Sequence 02, (c) Sequence 03, (d) Sequence 04, (e) Sequence 05,
    and (f) Sequence 06. GNSS, global navigation satellite system; ORB, oriented fast
    and rotated brief; SLAM, Simultaneous Localization and Mapping. [Color figure
    can be viewed at wileyonlinelibrary.com] 4.2 Data with conventional GNSS in soybean
    fields In the experiments from Section 7, noisy GNSS measurements had to be simulated
    from GNSS-RTK ones, as the data set does not contain conventional GNSS measurements.
    In this section we present an evaluation with conventional GNSS measurements.
    For this, we equipped our weed removal robot with such sensor and deployed it
    again in a soybean field. On board the robot there is a ZED stereo camera which
    captures images px at 15 Hz, an Emlid Reach GNSS operating at a frequency of 5 Hz,
    and an InvenSense MPU-9250 IMU set at 200 Hz. The covariance of the conventional
    GNSS measurements is offered by the driver of the GNSS receiver. In addition,
    GNSS-RTK provides positional ground-truth. Figure 6 shows the robot configuration
    in the soybean field. We commanded the robot to record three data sequences. The
    corresponding GNSS-RTK trajectories are shown in Figure 7 and images samples captured
    by the ZED camera can be seen in Figure 8. Figure 6 Open in figure viewer PowerPoint
    Weed removal robot used in our in-house data set in a soybean field. We equipped
    the robot with a ZED stereo camera, an Emlid Reach GNSS receiver, and an InvenSense
    MPU-9250 IMU. Furthermore, wheel odometry can be obtained from the wheel encoders.
    GNSS, global navigation satellite system; IMU, inertial measurement unit; WiFi,
    wireless fidelity. [Color figure can be viewed at wileyonlinelibrary.com] Figure
    7 Open in figure viewer PowerPoint GNSS-RTK trajectories for the sequences A (orange),
    B (green), and C (purple) of our in-house recordings in the soybean field. GNSS,
    global navigation satellite system; RTK, real-time kinematics. [Color figure can
    be viewed at wileyonlinelibrary.com] Figure 8 Open in figure viewer PowerPoint
    Sample images from our in-house data set. Note the repetitive textures, a challenge
    for visual Simultaneous Localization and Mapping. [Color figure can be viewed
    at wileyonlinelibrary.com] On this data we ran the three frameworks mentioned
    in the previous experiment. The results of this experiment are shown in Table
    2, while the trajectories can be seen in Figure 9. Estimated trajectories were
    aligned again with the ground-truth using Umeyama''s method. Finally, the reconstructed
    map and the trajectory estimated by our tightly coupled GNSS-stereo-inertial SLAM
    for sequence B are shown in Figure 10, as a qualitative illustration of the mapping
    capability of our framework. Table 2. Mean (standard deviation) of the Absolute
    Trajectory Error (m) for stereo-inertial ORB-SLAM3 (Campos et al., 2021), a loosely
    coupled GNSS-stereo-inertial system (Qin et al., 2019), and our tightly coupled
    GNSS-stereo-inertial framework in the in-house recordings in soybean fields. Sequence
    Stereo-inertial GNSS-stereo-inertial GNSS-stereo-inertial (Campos et al., 2021)
    (Qin et al., 2019) (Ours) A 0.64 (0.33) 1.08 (0.78) 0.44 (0.16) B 0.43 (0.18)
    5.58 (3.57) 0.36 (0.13) C 0.46 (0.12) 16.90 (7.67) 0.39 (0.12) Note: Best results
    are in bold. Abbreviations: GNSS, global navigation satellite system; ORB, oriented
    fast and rotated brief; SLAM, Simultaneous Localization and Mapping. Figure 9
    Open in figure viewer PowerPoint Results from stereo-inertial ORB-SLAM3 (Campos
    et al., 2021), the loosely coupled GNSS-stereo-inertial system of Qin et al. (2019),
    and our tightly coupled GNSS-stereo-inertial implementation on our in-house recordings
    in soybean fields, using conventional GNSS. Estimated trajectories are aligned
    with the ground-truth using Umeyama''s method. Note the smaller errors of tightly
    coupled approaches, and how our GNSS fusion improves over the stereo-inertial
    baseline. (a) Sequence A, (b) Sequence B, and (c) Sequence C. GNSS, global navigation
    satellite system; ORB, oriented fast and rotated brief; SLAM, Simultaneous Localization
    and Mapping. [Color figure can be viewed at wileyonlinelibrary.com] Figure 10
    Open in figure viewer PowerPoint Map estimated by our tightly coupled GNSS-stereo-inertial
    SLAM for sequence B of our in-house data set, seen from tilted and top views.
    The black points correspond to the tracked visual features, and the blue line
    to the estimated trajectory. GNSS, global navigation satellite system; SLAM, Simultaneous
    Localization and Mapping. [Color figure can be viewed at wileyonlinelibrary.com]
    4.3 Discussion As can be seen in the results, our implementation clearly outperforms
    the stereo-inertial configuration of ORB-SLAM3 and the loosely coupled approach
    in Qin et al. (2019). As a very relevant note, we ran the full stereo-inertial
    ORB-SLAM3 in our configuration sequences with loop closure capabilities and, with
    its configuration by default, it was unable to detect previously visited locations
    and hence close loops due to insufficiently discriminative visual appearances
    of the agricultural environment (perceptual aliasing). Although the default configuration
    for the loop closure parameters might be loosened to detect a higher number of
    loop closures, that would also produce a higher number of false positives (due
    again to perceptual aliasing) that would corrupt the estimation. These challenges
    are the main motivation for incorporating global positioning sensors in agricultural
    environments, allowing to reduce the drift without depending on visual features.
    Very interestingly, we found in our experiments that only one-third of the optimized
    keyframes had associated GNSS measurements. This may indicate that high-frequency
    GNSS measurements are not necessary to improve the estimation of visual–inertial
    SLAM, and a sparse subset of them might suffice to offer a reasonable performance.
    Unlike the loosely coupled system, our implementation returns smoother trajectories.
    Moreover, since the fusion is loosely coupled, the global position measurements
    correct the estimate without considering the continuous motion of the robot and
    act as an interpolation between the underlying visual–inertial system and the
    GNSS measurement. Even though in sequence 02 of the Rosario data set, the loosely
    coupled fusion system obtains a lower error, in the trajectory of Figure 5 it
    can be observed that the estimation looks bumpy. Smooth pose estimation, like,
    the one offered by our tightly coupled approach, is more suitable for use in a
    navigation control algorithm. Regarding the experiment with conventional GNSS
    measurements, it should be pointed out that the loosely coupled system lost the
    visual–inertial tracking in the three sequences. This indicates that it is important
    not only to focus on global measurements, but also to have a robust visual–inertial
    fusion. In our case, we use ORB-SLAM3 as the underlying system, as a result of
    having analyzed the performance of different visual–inertial systems in previous
    research (Cremona et al., 2022). As a conclusion, in addition to a tight coupling
    of the sensor data, the robustness of the visual–inertial estimates are also relevant
    for practical implementations in agricultural applications. An important consideration
    is the modeling of the noise of GNSS measurements. On the basis of previous works
    (Boche et al., 2022; Cioffi & Scaramuzza, 2020), the uncertainty was modeled as
    additive isotropic Gaussian noise. This is a simple model that arises naturally
    from the GNSS device data, as the device drivers generally provide a covariance
    of the position. Other ways of modeling the noise of GNSS measurements in the
    context of pose estimation are worth studying, as when comparing the simulated
    signal in the Section 7 experiment with the conventional GNSS signal used in the
    field experiments, differences in their behavior were observed. When the conventional
    GNSS signal was inspected in detail, a bias was found, mainly at altitude, which
    could be verified by the GNSS-RTK. Therefore, this topic should be addressed in
    future work. 5 CONCLUSIONS This work presents a GNSS-stereo-inertial SLAM framework
    that fuses in a tightly coupled manner the information from a stereo camera, an
    IMU, and a conventional GNSS sensor. To report the most competitive results, we
    implement our GNSS factor on top of the ORB-SLAM3 framework, the top performer
    in the evaluation of Cremona et al. (2022). As we are motivated by long-term autonomous
    navigation in arable farms, we present results in the Rosario data set and in-house
    sequences from an agricultural robot. Very importantly, several works in the literature
    evaluate GNSS-stereo-inertial SLAM methods by emulating conventional GNSS measurements
    while we use a real sensor, so we are the first ones in reporting results in realistic
    conditions in agricultural scenes. Our results show that there is a consistent
    gain in accuracy if GNSS measurements are tightly fused with visual and inertial
    ones in the local mapping optimization of a SLAM system. Very importantly, not
    only the localization errors are reduced but also their variance between runs,
    indicating a looser dependence from the visual features used. As an additional
    contribution to this work, we release our implementation for the benefit of the
    agricultural robotics community. ACKNOWLEDGMENTS This work was partially supported
    by CONICET (Argentina) (PUE 0015-2016), by the Santa Fe Province (Argentina) Government
    under Grant PEICID-2021-170, by the Spanish Government under Grants PGC2018-096367-B-I00
    and PID2021-127685NB-I00, and by the Aragon Government under Grant DGA T45 17R/FSE.
    Open Research Supporting Information REFERENCES Early View Online Version of Record
    before inclusion in an issue Figures References Related Information Recommended
    Experimental evaluation of Visual‐Inertial Odometry systems for arable farming
    Javier Cremona,  Román Comelli,  Taihú Pire Journal of Field Robotics Mechanisation
    For Sustainable Arable Farming Systems: A Precision Farming Perspective Fabio
    R. Leiva,  Joe Morris Proceedings of the Third International Conference on Precision
    Agriculture, [1] GNSS and Robot Localization Roi Yozevitch,  Boaz Ben-Moshe Autonomous
    Mobile Robots and Multi‐Robot Systems: Motion‐Planning, Communication, and Swarming,
    [1] A high-resolution, multimodal data set for agricultural robotics: A Ladybird''s-eye
    view of Brassica Asher Bender,  Brett Whelan,  Salah Sukkarieh Journal of Field
    Robotics MVS‐SLAM: Enhanced multiview geometry for improved semantic RGBD SLAM
    in dynamic environment Qamar Ul Islam,  Haidi Ibrahim,  Pan Kok Chin,  Kevin Lim,  Mohd
    Zaid Abdullah Journal of Field Robotics Download PDF Additional links ABOUT WILEY
    ONLINE LIBRARY Privacy Policy Terms of Use About Cookies Manage Cookies Accessibility
    Wiley Research DE&I Statement and Publishing Policies Developing World Access
    HELP & SUPPORT Contact Us Training and Support DMCA & Reporting Piracy OPPORTUNITIES
    Subscription Agents Advertisers & Corporate Partners CONNECT WITH WILEY The Wiley
    Network Wiley Press Room Copyright © 1999-2024 John Wiley & Sons, Inc or related
    companies. All rights reserved, including rights for text and data mining and
    training of artificial technologies or similar technologies."'
  inline_citation: '>'
  journal: Journal of Field Robotics
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: GNSS-stereo-inertial SLAM for arable farming
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Chen Q.
  - Zheng B.
  - Chenu K.
  - Chapman S.C.
  citation_count: '1'
  description: 'It is valuable to develop a generic model that can accurately estimate
    the leaf area index (LAI) of wheat from unmanned aerial vehicle-based multispectral
    data for diverse soil backgrounds without any ground calibration. To achieve this
    objective, 2 strategies were investigated to improve our existing random forest
    regression (RFR) model, which was trained with simulations from a radiative transfer
    model (PROSAIL). The 2 strategies consisted of (a) broadening the reflectance
    domain of soil background to generate training data and (b) finding an appropriate
    set of indicators (band reflectance and/or vegetation indices) as inputs of the
    RFR model. The RFR models were tested in diverse soils representing varying soil
    types in Australia. Simulation analysis indicated that adopting both strategies
    resulted in a generic model that can provide accurate estimation for wheat LAI
    and is resistant to changes in soil background. From validation on 2 years of
    field trials, this model achieved high prediction accuracy for LAI over the entire
    crop cycle (LAI up to 7 m2 m−2) (root mean square error (RMSE): 0.23 to 0.89 m2
    m−2), including for sparse canopy (LAI less than 0.3 m2 m−2) grown on different
    soil types (RMSE: 0.02 to 0.25 m2 m−2). The model reliably captured the seasonal
    pattern of LAI dynamics for different treatments in terms of genotypes, plant
    densities, and water–nitrogen managements (correlation coefficient: 0.82 to 0.98).
    With appropriate adaptations, this framework can be adjusted to any type of sensors
    to estimate various traits for various species (including but not limited to LAI
    of wheat) in associated disciplines, e.g., crop breeding, precision agriculture,
    etc.'
  doi: 10.34133/plantphenomics.0055
  full_citation: '>'
  full_text: '>

    "ADVERTISEMENT Journals Science.org GET OUR E-ALERTS Submit Manuscript Table of
    Contents About Guidelines HOME PLANT PHENOMICS TABLE OF CONTENTS A GENERIC MODEL
    TO ESTIMATE WHEAT LAI OVER GROWING SEASON REGARDLESS OF THE SOIL-TYPE BACKGROUND
    OPEN ACCESS RESEARCH ARTICLE Share on A Generic Model to Estimate Wheat LAI over
    Growing Season Regardless of the Soil-Type Background QIAOMIN CHEN , BANGYOU ZHENG,
    KARINE CHENU, AND SCOTT C. CHAPMAN Authors Info & Affiliations PLANT PHENOMICS
    23 May 2023 Vol 5 Article ID: 0055 DOI: 10.34133/plantphenomics.0055 1,712 Abstract
    Introduction Materials and Methods Results Discussion Acknowledgments Supplementary
    Materials References Information & Authors Metrics & Citations View Options References
    Media Tables Share Abstract It is valuable to develop a generic model that can
    accurately estimate the leaf area index (LAI) of wheat from unmanned aerial vehicle-based
    multispectral data for diverse soil backgrounds without any ground calibration.
    To achieve this objective, 2 strategies were investigated to improve our existing
    random forest regression (RFR) model, which was trained with simulations from
    a radiative transfer model (PROSAIL). The 2 strategies consisted of (a) broadening
    the reflectance domain of soil background to generate training data and (b) finding
    an appropriate set of indicators (band reflectance and/or vegetation indices)
    as inputs of the RFR model. The RFR models were tested in diverse soils representing
    varying soil types in Australia. Simulation analysis indicated that adopting both
    strategies resulted in a generic model that can provide accurate estimation for
    wheat LAI and is resistant to changes in soil background. From validation on 2
    years of field trials, this model achieved high prediction accuracy for LAI over
    the entire crop cycle (LAI up to 7 m2 m−2) (root mean square error (RMSE): 0.23
    to 0.89 m2 m−2), including for sparse canopy (LAI less than 0.3 m2 m−2) grown
    on different soil types (RMSE: 0.02 to 0.25 m2 m−2). The model reliably captured
    the seasonal pattern of LAI dynamics for different treatments in terms of genotypes,
    plant densities, and water–nitrogen managements (correlation coefficient: 0.82
    to 0.98). With appropriate adaptations, this framework can be adjusted to any
    type of sensors to estimate various traits for various species (including but
    not limited to LAI of wheat) in associated disciplines, e.g., crop breeding, precision
    agriculture, etc. Introduction The estimation of leaf area index (LAI) has long
    been intensively studied in plant sciences, agronomy, and remote sensing communities.
    The LAI sets the canopy capacity for crop photosynthesis and transpiration and
    can be used as an indicator of crop health condition and crop growth rate. The
    direct measurement of LAI is destructive, labor-intensive, and time-consuming
    but more accurate; thus, it is commonly used to provide ground truth for developing
    indirect methods [1,2]. With the rapid development in technologies related to
    imaging and geopositioning, as well as data management, processing, and analysis,
    many indirect methods have been proposed and validated to retrieve LAI from sensing
    data (e.g., RGB, multispectral, and hyperspectral) captured from various phenotyping
    platforms including satellites, drones, ground-based stations, or vehicles [3–5].
    In most studies, LAI refers to green LAI, but when retrieved from spectral images,
    it may represent the green area index (GAI), i.e., corresponding to all green
    parts of plants including leaves, stems, and heads [6,7]. Retrieval methods to
    predict crop traits (e.g., LAI) from sensing data are independent from cameras
    (or sensors) and platforms used to capture sensing data. According to the means
    to establish the relationship between spectral signal and crop trait, these methods
    can be divided into 3 main categories: (a) empirical methods, when a relationship
    between the crop trait and the raw sensing data or/and their derived vegetation
    indices (VIs) is established with experimental data; (b) physical methods, when
    this relationship corresponds to the cause–effect relationship built within a
    radiative transfer model (RTM) (for LAI estimation in particular, including Beer–Lambert’s
    Law based on gap fraction theory that is the theoretical basic of the indirect
    estimation of LAI [5]); and (c) hybrid methods, when this relationship is built
    from RTM simulations [8,9]. The hybrid method is a 2-step method that is to generate
    a synthetic dataset by running the RTM in a forward mode and then using this dataset
    to train a predictive model to predict crop traits from sensing data [1,10,11].
    There is an increasing interest in developing hybrid methods as they can balance
    general applicability and computational efficiency. The general applicability
    of the predictive model in the hybrid methods results from the synthetic dataset
    (including diverse canopy structures and observation conditions) used for training
    [12,13]. As reviewed in the literature, different algorithms used to establish
    the predictive model in hybrid methods have advantages and limitations with no
    obvious global solution, but machine learning algorithms are assumed to utilize
    sensing data more sufficiently and flexibly than methods do based on look-up table
    or numeric optimization [14–17]. The soil background has a substantial effect
    on plot reflectance for sparse canopies with LAI less than 2 m2 of leaf per m−2
    of land area [18]. In the hybrid method, the soil reflectance used to generate
    synthetic training data is commonly customized with local soil reflectance to
    improve the prediction accuracy in local environments [19,20]. In practice, this
    means that, first, the soil background of each environment needs to be characterized
    and, second, a soil-specific model needs to be trained to achieve accurate prediction
    for low LAI. This impedes usage of the method at large scales or across large
    numbers of sites, even if the local soil reflectance can be easily calibrated
    from reflectance of soil pixels in images, e.g., using the calibration method
    proposed by Chen et al. [8]. In addition, soil-specific models are typically less
    stable when predicting LAI across growing season [20,21] as the background changes
    over time, e.g., with rainfall (or irrigation) changing the spectral properties
    of the surface and senescent (non-green) vegetation and plant residues masking
    the soil toward the end of the season. Soil-specific models are also likely to
    be less accurate in large fields with high soil-type spatial variability. In synthetic
    data, the soil reflectance is also assumed to be associated with a pure soil background
    [22,23], while the actual background pixel might be a mixture of soil, plant residues,
    and weeds. In practice, this results in differences between simulation and observation
    and reduces the prediction accuracy. This problem can be addressed with an image
    background correction to replace the actual mixed soil background with the pure
    soil background and keep the vegetation fraction consistent [8]. However, the
    success of this background correction method relies on the image spatial resolution
    (or pixel size) and the accuracy of the binary classification of vegetation versus
    background. Degradation of image spatial resolution theoretically will increase
    the mixed pixels and decrease the pure vegetation and soil background pixels,
    hindering the accurate classification of vegetation and background [24]. In practice,
    whether degradation of image spatial resolution increases the number of mixed
    pixels depends on the homogeneity within the original image and new resolution
    after degradation. In particular, degradation in a homogeneous region will not
    generate mixed pixels. From this aspect, it is challenging to accurately estimate
    low LAI from drone-based data at centimeter resolution and nearly impossible from
    satellite-based data at meter resolution. Although the “background-resistant model”
    concept has not been explicitly proposed, previous studies have attempted to improve
    LAI prediction by (a) considering multiple soil reflectance when generating synthetic
    training data [10,25] and (b) developing better VIs resistant to chlorophyll and
    background changes [1,26]. In theory, a background-resistant model should effectively
    address problems mentioned above to achieve stable and accurate LAI prediction
    over growing season under different soil backgrounds. Furthermore, such a background-resistant
    model should estimate LAI even from low spatial resolution images, in which canopy
    reflectance of pixels are equivalent to reflectance comprising a mixture of soil
    background and vegetation. Such a background-resistant model is particularly useful
    for LAI estimation in dryland regions such as in Australia, where the crop LAI
    may rarely exceed 5 m2 m−2, and the wheat canopy has LAI less than 2 m2 m−2 for
    1 to 3 months after sowing. In sandy soils, the LAI may rarely exceed 2 m2 m−2
    during the whole growing season under low-rainfall rainfed conditions, e.g., in
    Western Australia. The stable estimation of LAI retrieved with sensing technologies
    is strongly affected by the spatiotemporal variations in background caused by
    spatial variability of soil, seasonal senescence of vegetation, and mixed pixel
    issues of images. To improve previous work focusing on soil-specific model for
    predicting wheat LAI at pre-anthesis vegetative stages [8], this research aims
    to develop a generic machine learning-based prediction model that supports accurate
    estimation of LAI across diverse soil backgrounds for the entire growth season
    in field conditions. Research objectives include the following: (a) developing
    different strategies (i.e., soil reflectance domain extension and canopy-spectral
    indicator selection) to improve generalization of the prediction model, (b) evaluating
    performance of the established prediction model under diverse conditions (including
    different soil backgrounds, LAI levels, and growing stages) using both simulation
    and experimental data, and (c) accounting for the varying model performance in
    different conditions. Materials and Methods Overview The research flow map of
    this study is presented in Fig. 1. This study proposes a background-resistant
    predictive model to predict wheat LAI through investigating the setting of (a)
    soil reflectance used in synthetic training data (strategy 1) and/or (b) canopy-spectral
    inputs of random forest regression (RFR) model (strategy 2). In total, 21 RFR
    models (3 sets of training soil backgrounds × 7 sets of RFR canopy-spectral inputs)
    were developed. These models were first tested on synthetic test data to evaluate
    the model’s simulation performance of LAI prediction under different test soil
    backgrounds (representing the diversity of soil surface reflectance in Australia)
    for varying LAI levels. Subsequently, these models were tested on experimental
    and augmented unmanned aerial vehicle (UAV)-based multispectral data representing
    different soil backgrounds to evaluate model’s practical performance of predicting
    low LAI at early stage. Finally, these models were also tested on experimental
    data to evaluate model’s practical performance of predicting LAI at different
    growing stages and the dynamics of LAI during the whole growing season. Fig. 1.
    Research flow map. PROSAIL is a radiative transfer model, coupling a leaf optical
    property model (PROSPECT-D) and a canopy bidirectional reflectance model (4SAIL).
    The reflectance of the test soil background and the reflectance boundaries of
    the training soil background are presented in Fig. 3. Both synthetic training
    sets and synthetic test sets are generated from PROSAIL with the same parameter
    ranges. The synthetic training sets were used to develop random forest regression
    (RFR) models, while the synthetic test sets were used to evaluate the simulation
    performance of RFR models. The practical performance of RFR models was evaluated
    on experimental data collected from field experiments. Compared to our previous
    work that can produce reliable LAI estimation for wheat under a specific soil
    background based on local soil calibration and image background correction [8],
    the study provided an improved solution to develop a generic predictive model
    that can be applied in varying soil backgrounds. The workflow of generating synthetic
    datasets and training RFR models was adapted from our previous work [8], as were
    the field experiments for validation. Method details related to these parts (in
    the “Field experiments,” “Simulating synthetic datasets with PROSAIL model,” and
    “Developing a baseline model” sections) are more thoroughly explained in the previous
    paper [8]. Field experiments Two wheat experiments were conducted at Gatton, Queensland
    (27.55°S, 152.33°E) in 2016 (Exp16) and 2019 (Exp19), and UAV-based phenotyping
    was undertaken along with field measurements (for more details, see Chen et al.
    [8]). Different genotypes, irrigation, and fertilization regimes were applied
    to create contrasting canopy structures. In summary, the whole field was split
    into 4 treatment blocks based on irrigation and fertilization regimes, i.e., irrigation
    and high nitrogen (IHN), irrigation and low nitrogen (ILN), rainfed and high nitrogen
    (RHN), as well as rainfed and low nitrogen (RLN). Each block was split into small
    plots of ~14 m2 (2 × 7 m), each with 7 rows and a 25-cm row spacing. For Exp16,
    the sowing occurred on 2016 May 21 and plant emergence occurred approximately
    10 d after sowing. For Exp19, the sowing occurred on 2019 May 15 and plant emergence
    occurred approximately 5 d after sowing. The phenology of each plot on each UAV-based
    phenotyping date was recorded using a decimal Zadoks score (Fig. 2) [27]. Fig.
    2. Observed phenology (characterized by Zadoks score) for each plot on each UAV-based
    phenotyping dates expressed as days after sowing (DAS). The experiments Exp16
    and Exp19 were conducted in 2016 and 2019, respectively. The texts above the symbols
    denote the corresponding growth stage: seedling growth (SG), tillering (T), stem
    elongation (SE), booting (B), heading (H), flowering (F), milk development (MD),
    dough development (DD), and ripening (R). LAI was measured from quadrat harvests
    that comprised 0.5 m of length of 4 inner rows (~0.5 m2) and were taken in 84
    plots (including 7 genotypes, 1 sowing densities, 4 water–nitrogen treatments,
    and 3 replicates) for Exp16 and 72 plots (including 3 genotypes, 3 sowing densities,
    4 water–nitrogen treatments, and 2 replicates) for Exp19. Within each block (defined
    by water and nitrogen application), all treatments (genotype or genotype × density)
    were randomized using the corDiGGer method provided in a free R package, DiGGer.
    For Exp16, quadrat harvest and UAV phenotyping did not always occur within 3 d
    of each other. Unmatching LAI measurements on UAV phenotyping dates were interpolated
    with a fitted piecewise function based on all observed LAI from quadrat harvests
    across growing season (7 or 8 harvesting times were used for each selected plots
    from leave development to end of grain filling). The piecewise function is consisting
    of using a logistic function and beta function before and after LAI reaching its
    maxima, respectively. A detailed description for the implementation of this method
    can refer to the Supplementary Materials in our previous work [8]. For Exp19,
    all 4 quadrat harvests (days after sowing (DAS) = 36, 64, 90, and 111) were taken
    within 2 d after the corresponding UAV phenotyping. Hence, each ground-estimated
    LAI for each selected plot had one UAV-based estimation. It should be noticed
    that the UAV-based estimation can represent LAI (only leaves presented in images)
    or GAI (all green parts including stems and heads except for leaves presented
    in images), and these terms are used variously in published papers. All UAV flights
    were undertaken to capture multispectral data from 10:00 AM to 2:00 PM in clear
    days without strong wind effects in both Exp16 (DAS = 18, 40, 59, 72, 80, 88,
    100, 115, 122, 129, and 139) and Exp19 (DAS = 26, 36, 42, 62, 76, 83, 90, 97,
    103, 110, 121, and 124). The flight height was set to 20 m (with a ground sampling
    distance (GSD) of 1.3 cm) for the first 4 flight in Exp16, and in the first 3
    flights in Exp19, 40 m (with a GSD of 2.7 cm) only for the fourth flight in Exp19,
    as well as 30 m (with a GSD of 2 cm) for the remaining flights in both experiments.
    The multispectral camera used in this study was a MicaSense RedEdge camera (https://www.micasense.com),
    with 5 bands in the visible near-infrared (VNIR) range, i.e., blue (475 nm of
    center wavelength, 20 nm of bandwidth), green (560 nm, 20 nm), red (668 nm, 10
    nm), NIR (840 nm, 40 nm), and red edge (717 nm, 10 nm). Raw multispectral images
    were processed in Pix4Dmapper software (version 4.3.4) (https://www.pix4d.com)
    to generate the calibrated reflectance map of each band for the whole field, using
    images of the calibrated reference panel for calibration. According to the field
    experimental design, each reflectance map was segmented into individual plots.
    Marginal areas from adjacent plots and plot gaps were trimmed from individual
    plots by a percentage of 10% along 4 sides. The Exp16 followed a double-plot design
    (one was used for destructive harvest and an adjacent plot for UAV-based phenotyping),
    so the UAV-based estimated LAI was retrieved from the phenotyping plot (with an
    area of approximately 8.96 m2). However, the same plot was used for both destructive
    harvest and UAV-based phenotyping for Exp19. To predict LAI from the same area
    for each flight in Exp19, the harvested areas were clipped from individual plot
    images, and the remaining area (approximately 2.24 m2) was used to retrieve UAV-based
    estimated LAI. After processing, each plot image included about 53,444 or 22,400
    pixels in Exp16 and 13,392, 5,600, or 3,120 pixels for Exp19, depending on GSD
    at specific flight height. Finally, the pixel-scale reflectance from the trimmed
    plot was averaged to generate the plot-scale reflectance and derived plot-scale
    VIs that were used in predictive models to predict LAI. In this case, the predicted
    value corresponded to GAI as the green parts contributed from stems and heads
    were not separated from those of leaves. At the early stage before appearance
    of heads, the LAI was close to GAI because of the marginal view of stems from
    the nadir view. For the remainder of this paper, the value retrieved with the
    predictive model was named as predicted LAI, although in the case of wheat in
    later stages of growth, this value might be more accurately termed as GAI. Simulating
    synthetic datasets with the PROSAIL model The PROSAIL model [23] was used to simulate
    canopy reflectance for given input parameters and soil reflectance. The current
    version, PROSAIL-D (coupling PROSPECT-D with 4SAIL), used in this study is available
    online (http://teledetection.ipgp.jussieu.fr/prosail/). To represent possible
    canopy structures of wheat and observation conditions, 13 input parameters were
    defined on the basis of our previous work [8]. The parameters and ranges (obey
    a uniform distribution) were the following: leaf mesophyll structure parameter
    (Ns; unitless; range [1, 2.5]), leaf chlorophyll content (Cab; μg cm−2; [0, 90]),
    leaf carotenoid content (Car; μg cm−2; [0, 20]), leaf water content or leaf equivalent
    water thickness (Cw; g cm−2; [0.001, 0.03]), leaf dry matter content (Cm; g cm−2;
    [0.001, 0.01]), average leaf inclination angle (ALA; degree; [20, 70]), leaf area
    index (LAI; m2 m-2; [0, 7]), hot spot parameter (hspot; m m−1; [0.01, 0.5]), solar
    zenith angle (SZA; degree; [20, 70]), and relative azimuth angle (RAA; degree;
    [−90, 90]). Parameters for the leaf anthocyanins content (Cant; μg cm−2), leaf
    brown pigment (Cbrown; unitless), and viewing zenith angle (VZA; degree) were
    fixed to 0. A subset consisting of 40,000 combinations (training: 30,000 samples;
    test: 10,000 samples) of input parameter values was randomly sampled from the
    defined parameter space and then further combined with soil reflectance from defined
    soil backgrounds to run PROSAIL and simulate canopy reflectance. The soil reflectance
    of the soil background used in the training set was simulated with the default
    soil reflectance provided in PROSAIL by adjusting 2 soil factors (i.e., psoil
    and asoil), while that used in the test set was corresponding to a specific measured
    soil reflectance of test soils (see details in the “Improving the baseline model
    with “strategy 1”” section). The soil reflectance and the combination of parameter
    values were combined randomly in each training set. To mimic measurements from
    the sensor mounted on the UAV platform, the output bidirectional reflectance from
    400 to 2,500 nm at 1-nm interval was resampled into band reflectance of the 5
    bands based on spectral response coefficient provided by MicaSense (for more details,
    refer to Chen et al. [8]). The related band reflectance was then used to calculate
    related VIs (see details in the “Improving the baseline model with “strategy 2””
    section). The band reflectance of 5 bands or/and derived VIs were coupled with
    known LAI (i.e., input used for PROSAIL) to generate paired data and define the
    synthetic dataset. The synthetic training data (representing a broad range of
    canopy structures and observation conditions in a specific soil background consisting
    of single or multiple soil reflectance) were used to train the predictive model
    that was then tested in diverse situations including multiple “new” soil backgrounds
    (see details in the “Validation on synthetic data generated with new test soils”
    section). Developing and improving RFR models Developing a baseline model In this
    study, the RFR was chosen as the predictive model to predict LAI, as RFR is less
    prone to overfitting than some non-ensemble methods and can provide robust predictions
    because of its attributes, i.e., ensemble mechanism, sample disturbance, and attribute
    disturbance [28]. Three key hyperparameters were identified in the literature
    [29,30]: (a) the number of trees or base learners (n_estimators = 200), (b) the
    number of features to consider finding out the best split (max_features = log2(n_features),
    where n_features represents the number of predictive variables of the RFR model),
    and (c) the minimum number of samples required at a leaf node (min_samples_leaf
    = 1). The values of these 3 hyperparameter were determined on the basis of grid
    search and cross-validation as described in our previous work [8]. Both input
    (i.e., band reflectance or/and VIs) and output variables (i.e., LAI) of the RFR
    model were normalized with the mean–standard deviation normalization (also called
    standardization) approach to prevent any scaling issues. The MSE was used to evaluate
    the model performance during training. The RFR model was implemented with Python
    3.7.2 using the scikit-learn open-source machine learning library (version 0.24.2;
    https://scikit-learn.org/stable/). The baseline RFR model was trained on synthetic
    data using the soil background with a single soil reflectance (“defaultSingle”)
    and using the 5 band reflectance as model inputs (“Ref”) (see details in the “Improving
    the baseline model with “strategy 1”” and “Improving the baseline model with “strategy
    2”” sections for definitions of “defaultSingle” and “Ref,” respectively). Improving
    the baseline model with “strategy 1” The strategy 1 (i.e., broadening the reflectance
    domain of the training soil background) was first investigated to improve the
    baseline model to perform robustly in different soil backgrounds. PROSAIL provides
    a default soil with standard soil reflectance under wet (Rsoilwet) and dry (Rsoildry)
    conditions. In PROSAIL, possible variation of soil reflectance can be accounted
    for by a wetness factor (psoil) (used to mix the wet and dry soil) and a multiplicative
    brightness factor (asoil) [31]. The reflectance of a particular soil (Rsoil) with
    specific wetness and brightness relative to the default soil provided in PROSAIL
    can be calculated from the following equation: Rsoil = asoil × (psoil × Rsoildry
    + (1 − psoil) × Rsoilwet) [8]. For strategy 1, 3 sets of soil backgrounds were
    used in the synthetic training set (i.e., “defaultSingle,” “defaultMulti1,” and
    “defaultMulti2”). The 3 boundaries of soil reflectance in training soil backgrounds
    were generated with the equation mentioned above by specifying psoil and asoil:
    sim1 (psoil = 0, asoil = 1), sim2 (psoil = 1, asoil = 1), and sim3 (psoil = 0.9,
    asoil = 2) (Fig. 3). The “defaultSingle” soil background corresponded to a single
    soil reflectance profile equivalent to “sim2.” The “defaultMulti1” soil background
    corresponded to multiple soil reflectance profiles within the domain between “sim1”
    (lower boundary) and “sim2” (upper boundary). These soil reflectance profiles
    were generated by fixing asoil to 1 and changing psoil from 0 to 1. The “defaultMulti2”
    soil background corresponded to multiple soil reflectance profiles within the
    domain between “sim1” (lower boundary) and “sim2” (upper boundary). These soil
    reflectance profiles were generated by changing both psoil (between 0 and 1) and
    asoil (between 0.5 and 2). The soil reflectance profiles included in each soil
    background were randomly combined with the combination of parameter values to
    generate the corresponding training set. Fig. 3. Soil reflectance profiles of
    the selected soil samples and possible boundaries of the training soil reflectance.
    The solid lines indicate the soil reflectance used in test tests, while the dashed
    lines indicate the boundaries of soil reflectance used in training sets. The black
    segments indicate the actual soil reflectance of 5 bands derived from UAV multispectral
    images in Exp16. Improving the baseline model with “strategy 2” The strategy 2
    (i.e., improving canopy-spectral indicators used as model inputs) was then investigated
    to improve the baseline model to make it insensitive to changes in soil backgrounds.
    In this study, in addition to the 5 band reflectance, 7 VIs (Table 1) were considered
    as canopy-spectral inputs for LAI prediction from multispectral data. For example,
    the normalized difference vegetation index (NDVI) was selected as it has been
    intensively used to retrieve LAI despite that it easily saturates for high LAI.
    The other 6 VIs (i.e., red edge chlorophyll index (CIre), red edge modified simple
    ratio (MSRre), red edge normalized difference vegetation index (NDVIre), enhanced
    vegetation index 2 (EVI2), modified chlorophyll absorption ratio index 2 (MCARI2),
    and modified triangular vegetation index 2 (MTVI2)) were selected as they have
    been reported or proven to be well correlated to LAI and less sensitive to variations
    in background, pigment, and canopy structure in the literature [1,26]. Vegetation
    index Equation Reference Normalized difference vegetation index (NDVI) NDVI =
    (NIR − R)/(NIR + R) [32] Red edge chlorophyll index (CIre) CIre = NIR/RE − 1 [33]
    Red edge modified simple ratio (MSRre) MSR re = NIR / RE − 1 NIR / RE + 1 [34]
    Red edge normalized difference vegetation index (NDVIre) NDVI = (NIR − RE)/(NIR
    + RE) [35] Expand for more Table 1. Vegetation indices used in this study. The
    NIR, R, RE, and G represent the top-of-canopy reflectance in near-infrared, red,
    red edge, and green bands of the MicaSense RedEdge camera, respectively. Given
    the defined ranges of input parameters in PROSAIL, a global sensitivity analysis
    was conducted on the basis of the extended Fourier amplitude sensitivity test
    (EFAST) [37] to calculate the effects of each input parameter on each band reflectance
    and each VI for varying LAI levels simulated by PROSAIL. The EFAST was performed
    using package “sensitivity” (version 1.15.2) in R 3.6.0. Subsequently, the relative
    contribution of soil background variation on each band reflectance and each VI
    was calculated from the EFAST results (Fig. 4). Overall, in the full range of
    LAI (0 < LAI < 7), the reflectance of blue and red bands was more sensitive to
    variations in soil reflectance than the other 3 bands (i.e., green, NIR, and red
    edge). The sensitivities of these 3 bands were similar to that of NDVI, while
    the other 6 VIs were less sensitive than NDVI to soil reflectance variations.
    The high impacts of soil reflectance variation on canopy reflectance for the 5
    bands sharply dropped with increasing LAI for LAI < 2, and its effects were negligible
    for LAI > 3. The effects of soil reflectance variation on these VIs were relatively
    small and stable, especially for MSRre, EVI2, MCARI2, and MTVI2 (relative contribution
    within 3% under all LAI levels). Fig. 4. Relative contribution of soil background
    variation on each band reflectance and vegetation index for varying LAI levels
    based on an EFAST analysis using data generated by PROSAIL. For strategy 2, 7
    sets of canopy-spectral inputs were considered to combine band reflectance and
    VIs based on sensitivity results, i.e., Ref, RefVI, VI, VIc1, VIc2, VIc3, and
    VIc4. The “Ref” corresponded to the reflectance of the 5 bands in RedEdge camera.
    The “RefVI” corresponded to the reflectance of the 5 bands in addition to 7 VIs.
    The “VI” corresponded to the 7 VIs. The NDVI, NDVIre, CIre, and MSRre were excluded
    from the 7 VIs step by step to determine the most effective combination of VIs
    for LAI predictions, resulting in another 4 input sets: VIc1 (i.e., CIre, MSRre,
    NDVIre, EVI2, MCARI2, and MTVI2), VIc2 (i.e., CIre, MSRre, EVI2, MCARI2, and MTVI2),
    VIc3 (i.e., MSRre, EVI2, MCARI2, and MTVI2), and VIc4 (i.e., EVI2, MCARI2, and
    MTVI2). The lower number of features simplifies a predictor and reduces possible
    combinations leading to a same output, which in turn will reduce the prediction
    uncertainties. Therefore, we intended to choose a predictor with lower number
    of features on the basis of maintaining good prediction as the others. The 21
    RFR models with and without adoption of any of 2 strategies On the basis of different
    combinations of 2 strategies, 21 synthetic training sets (with 30,000 samples
    each) were generated in total (Table 2). This resulted in 21 different RFR models
    being considered. The RFR model was named by the soil background and the input
    set that were used in the training set; for example, model “defaultSingle.Ref”
    represents the model trained over the synthetic dataset with the “defaultSingle”
    soil background and the “Ref” canopy-spectral input set. No. Strategy 1 Strategy
    2 No. Strategy 1 Strategy 2 1 defaultSingle Ref 12 defaultMulti2 VIc1 2 defaultMulti1
    Ref 13 defaultSingle VIc2 3 defaultMulti2 Ref 14 defaultMulti1 VIc2 4 defaultSingle
    RefVI 15 defaultMulti2 VIc2 Expand for more Table 2. Combinations of strategy
    1 and strategy 2 used to generate the synthetic training sets. Strategy 1 stands
    for different sets of training soil background. Strategy 2 stands for different
    sets of canopy-spectral inputs. Notes: “Strategy 1” considers 3 sets of soil background:
    defaultSingle, a unique soil background including singl esoil reflectance equal
    to sim2; defaultMulti1, a composite soil background including multiple soil reflectance
    in the space between sim1 and sim2; defaultMulti2, a composite soil background
    including multiple soil reflectance in the space between sim1 and sim3. The soil
    reflectance of sim1, sim2, and sim3 refers to Fig. 3. “Strategy 2” considers 7
    sets of canopy-spectral inputs: Ref, including 5 bands (i.e., blue, green, red,
    NIR, and red edge); RefVI, including 5 bands and 7 VIs (i.e., blue, green, red,
    NIR, and red edge, as well as NDVI, CIre, MSRre, NDVIre, EVI2, MCARI2, and MTVI2);
    VI, including 7 VIs (i.e., NDVI, CIre, MSRre, NDVIre, EVI2, MCARI2, and MTVI2);
    VIc1, including 6 VIs (i.e., CIre, MSRre, NDVIre, EVI2, MCARI2, and MTVI2); VIc2,
    including 5 VIs (i.e., CIre, MSRre, EVI2, MCARI2, and MTVI2); VIc3, including
    4 VIs (i.e., MSRre, EVI2, MCARI2, and MTVI2); and VIc4, including 3 VIs (i.e.,
    EVI2, MCARI2, and MTVI2). Evaluating prediction accuracy of RFR models A series
    of statistical metrics were used to evaluate the RFR model’s performance from
    3 aspects: correlation, fitness, and bias. The Pearson correlation coefficient
    (r) measures the correlation between the observation and its prediction, which
    is useful to evaluate the degree to which the movement of observed (or known)
    LAI is captured in predicted LAI, especially in predicting seasonal dynamics of
    LAI. The determination coefficient (R2) measures the proportion of the variance
    in observed (or known) LAI explained by predicted LAI in the linear regression
    setting, which is suitable to account for the ability of the RFR model to predict
    LAI for a wide range of conditions. Both root mean square error (RMSE) and RRMSE
    (a ratio of RMSE divided by the mean of observed (or known) LAI) evaluate the
    prediction bias of the RFR model, measuring the average absolute and relative
    error between the known (or observed) LAI and its prediction estimated with the
    RFR model, respectively. The empirical cumulative density distribution (ECDF)
    of prediction bias (i.e., the difference of the observed LAI subtracted from the
    predicted LAI) as well as the derived percentage of samples overestimated (POE)
    and mean bias error (MBE) were also calculated for bias uncertainty analysis.
    The POE is a ratio of the number of samples with positive prediction bias divided
    by the total sample number, presenting in percentage format by times 100. All
    metrics were calculated in R 3.6.0. Validation on synthetic data generated with
    new test soils The soil reflectance of 10 soil samples from the Biomes of Australian
    Soil Environment (BASE) project [38] was selected on the basis of K-means clustering
    analysis to represent soil reflectance variations in Australia. The BASE soil
    reflectance data (695 soil samples in total) were clustered into 10 clusters and
    then the soil reflectance closest to each of the cluster center was chosen, resulting
    in 10 selected soil reflectance used in this study. The BASE soil reflectance
    data are available online (https://zenodo.org/record/6265730). These soil samples
    vary in color (from dark to white) and texture (different ratios of sand, silt,
    and clay) (Table S1), and detailed soil attributes are available at the BASE database
    (https://data.bioplatforms.com/organization/australian-microbiome). The soil reflectance
    profile (from 350 to 2,500 nm with 1-nm interval) of each soil samples was measured
    with an ASD spectrometer (PaNalytic, Boulder, Colorado, USA) after a standard
    preprocessing (e.g., grinding, drying, and preparing on standard plates) in the
    laboratory [39]. For this study, we focused on representing the possible domain
    of soil reflectance using a few soil types. Thus, the selection is conducted on
    the basis of the soil reflectance rather than soil attributes, because different
    combinations of attributes will result in the same reflectance. Soil10 was selected
    as an extreme case, although few crops grow on such white and sandy soils. In
    the current study, the soil reflectance of the 10 selected BASE soils was used
    to generate synthetic test set characterized by a reflectance spectrum in the
    range of 400 to 2,500 nm (i.e., soil1 to soil10 in Fig. 3). To evaluate the model’s
    simulation performance on “new” soils (i.e., not used during the training) without
    considering the gap between simulated and measured reflectance caused by uncertainties
    related to model simplification and measurement error, each RFR model was tested
    on 10 synthetic test sets varying in soils. The 70 test sets (7 canopy-spectral
    input sets × 10 test soils) were generated in the same way to synthetic training
    sets with the same canopy-spectral input sets but different soil backgrounds,
    and each test set has 10,000 samples. Validation on augmented data for early growth
    stages under different soil backgrounds In Exp16, all wheat canopies were at seedling
    stage on June 8 (DAS = 18; flight height of 20 m) when the first flight was conducted.
    Destructive quadrat harvests were conducted for 84 selected plots on the same
    date to obtain ground-truth LAI (i.e., observed LAI). At this stage, the LAI was
    not more than 0.3 m2 m−2, and a high proportion of soil background was exposed
    in the UAV-based multispectral images. To evaluate the RFR model’s practical performance
    for different soil backgrounds, we used the background correction method proposed
    by Chen et al. [8] (renamed as the “background adjustment” method in the current
    study) to generate augmented multispectral images under different soil backgrounds.
    As so, the augmented image does not need to perfectly represent the actual image,
    as long as this method can create the variability of reflectance images obtained
    from different soil backgrounds. This was done by replacing the original band
    value of background pixels with the corresponding soil reflectance of the 10 test
    soils but keeping the values of vegetation pixels consistent (Fig. 5). Different
    to the original image with local variation among background pixels, background
    pixels on augmented image have exactly the same value to the test soil used for
    background adjustment. The background vegetation classification was realized with
    an NDVI threshold method, and details can be found in [8]. The red, green, and
    blue bands of the MicaSense RedEdge camera were composited to generate the RGB
    image to visualize the augmented images with background adjustment (Fig. 5). The
    color of these narrow-band RGB composite images is a false color (or pseudo-color)
    instead of a true color, so they look different from images captured with an RGB
    camera or what we see with our eyes. Each RFR model was then evaluated on the
    84 studied plots with 11 different soil backgrounds (1 original background from
    UAV and 10 test soil backgrounds presented in Fig. 3). Fig. 5. Schematics of using
    a background adjustment method to generate augmented images presented in RGB composite
    format. Only a 1-m2 area of interest (AOI) was clipped from the field map for
    presentation to simplify the illustration. The NDVI threshold classification was
    applied on the NDVI map generated from 2 reflectance bands (i.e., red and NIR)
    to generate the vegetation background binary mask. This binary mask was used to
    locate the background pixels to conduct background adjustment on each band reflectance
    map. Three bands (i.e., red, green, and blue) were composite to create the RGB
    images to visualize the canopies with and without background adjustment. The “original”
    has the actual soil background of the AOI. The “soil1” to “soil10” have the soil
    backgrounds corresponding to the 10 test soils (Fig. 3 and Table S1). The color
    of these RGB composite images is a false color (or pseudo-color). Validation on
    experimental data in the whole growing season The RFR models were further tested
    on all experimental data collected in 2 field experiments to evaluate the prediction
    accuracy of (a) LAI at different growing stages, (b) the spatiotemporal variation
    of LAI across the growing season, and (c) the dynamics of genotype-specific LAI
    along growing season and related heritability under different treatments. On the
    basis of analysis for experimental data described above, there were 11 (in Exp16)
    and 4 (in Exp19) observed LAI for each studied plot in the whole growing season.
    The observed LAI and their predicted values were reorganized on the basis of phenology
    to evaluate the model’s performance in predicting LAI at different growth stages.
    On the basis of UAV-based phenotyping dates, the spatiotemporal variation of observed
    and predicted LAI was mapped in sequence across growing season. In addition, the
    best linear unbiased prediction (BLUP) model was applied to fit the genotype-specific
    predictions of LAI (both observed and predicted), which were then used to evaluate
    model’s performance in predicting the seasonal dynamics of LAI for each treatment
    varying in genotype, plant density, and water–nitrogen management. According to
    BLUP analysis results, related heritability and variance components were calculated
    for each date under different treatments. The BLUP analysis was conducted with
    the free R package, statgenHTP, available online (https://biometris.github.io/statgenHTP).
    Results Model simulation performance on LAI prediction tested on independent synthetic
    data The RFR models trained on the synthetic training set were first tested on
    the unseen synthetic test sets to evaluate their simulation performance. In the
    VNIR range of 400 to 900 nm, the soil reflectance of soil5 is nearest to that
    of the defaultSingle soil background; and the reflectance of test soils differs
    increasingly to that of the defaultSingle soil background from soil5 to soil1
    and from soil5 to soil10 (Fig. 3). In the same range of VNIR, the reflectance
    of the first 5 test soils (i.e., soil1 to soil5) are within the domain of the
    defaultMulti1 soil background, while all test soils (except for soil10) are inside
    the domain of the defaultMulti2 soil background (Fig. 3). The baseline model defaultSingle.Ref
    achieved a high R2 of 0.8 when tested on test sets with similar soil reflectance
    as defaultSingle (i.e., sim2) after mean–standard deviation normalization (i.e.,
    soil2 to soil7). The R2 dropped to 0.7 (soil1 and soil8), 0.4 (soil9), and 0.2
    (soil10) (Fig. 6) as the difference of soil reflectance between defaultSingle
    soil background and test soil background increased (Fig. 3). Fig. 6. Simulation
    performance of RFR models for predicting LAI in the range of 0 to 7 m2 m−2. These
    RFR models varied in training soil backgrounds (i.e., defaultSingle, defaultMulti1,
    and defaultMulti2) or/and canopy-spectral input types (i.e., Ref, RefVI, VI, VIc1,
    VIc2, VIc3, and VIc4). Each RFR model was tested on 10 synthetic test sets corresponding
    to a specific soil background (i.e., soil1 to soil10). For RFR models using Ref
    (i.e., the 5 bands; see Table 2) as canopy-spectral inputs, broadening the reflectance
    domain of the training soil background can improve model’s robustness for LAI
    prediction in different soil backgrounds. Compared with the defaultSingle.Ref
    model, the defaultMulti1.Ref model obtained better performance when tested on
    soil1 (increased R2 from 0.7 to 0.8) but did not improve the performance when
    tested on soil8 to soil10, while the defaultmulti2.Ref model achieved similarly
    good performance (R2 = 0.8) when tested on soil1 to soil9 and less accurate prediction
    (R2 = 0.6) when tested on soil10 (Fig. 6). For RFR models trained over the synthetic
    training set with the defaultSingle soil background (Fig. 6), improving canopy-spectral
    inputs reduced the model’s sensitivity to changes in soil background for LAI prediction.
    The defaultSingle.RefVI model slightly improved R2 when tested on soil backgrounds
    (i.e., soil1, soil8, soil9, and soil10), which were poorly predicted by the defaultSingle.Ref
    model (Fig. 6). All RFR models using input sets that were only consisting of VIs
    (i.e., VI, VIc1, VIc2, VIc3, and VIc4) had a similar accuracy for LAI prediction
    for different test soil backgrounds, with a slightly higher accuracy for soils
    similar to the defaultSingle soil background. The main difference of prediction
    accuracy between these VI-based models lay in the magnitude rather than the pattern
    when tested on different soil backgrounds. Compared with broadening the reflectance
    domain of training soil background (Fig. 6), improving canopy-spectral inputs
    allowed more stable LAI prediction across soil backgrounds, especially when tested
    on soil background highly dissimilar to the training soil background. After improving
    inputs, adjusting the training soil background further resulted in a slight improvement
    of prediction accuracy for all tested soils. Overall, 3 models (i.e., defaultMulti2.VIc1,
    defaultMulti2.VIc2, and defaultMulti2.VIc3) stably achieved reliable LAI estimation
    for all test soil backgrounds. The simulation performance was further evaluated
    for 8 LAI levels: 0 < LAI ≤ 0.5, 0.5 < LAI ≤ 1, 1 < LAI ≤ 2, 2 < LAI ≤ 3, 3 <
    LAI ≤ 4, 4 < LAI ≤ 5, 5 < LAI ≤ 6, and 6 < LAI ≤ 7 (Fig. S1). As expected, for
    LAI < 2, both Ref-based and RefVI-based models achieved apparently different prediction
    accuracy when tested on different soil backgrounds not limited to extreme soils
    (i.e., soil1, soil8, soil9, and soil10), with RMSE changing in a wide range of
    0 to 5 m2 m−2 (Fig. S1). This was likely due to variations in soil backgrounds
    presenting a dominant effect on the 5 band reflectance (Fig. 4). Compared with
    performance of Ref-based and RefVI-based models, the VI-based models performed
    better across soil types, resulting in a stable prediction accuracy (similar RMSE)
    for LAI < 2 under different soil backgrounds. Among these VI-based models, further
    analysis indicated that 3 canopy-spectral input sets (i.e., VIc1, VIc2, and VIc3)
    were less sensitive to soil variation than the other 2 (i.e., VI and VIc4) across
    LAI levels (Fig. S2). The defaultMulti2.VIc3 model was selected for further evaluation
    as (a) the VIc3 input was most stable across soils, especially for extreme soils,
    although it was slightly more sensitive than VIc1 and VIc2 in general (Fig. S2),
    and (b) the number of input variables in VIc3 (4 variables) was less than in VIc1
    (6 variables) and VIc2 (5 variables). Overall, the defaultMulti2.VIc3 model can
    achieve similarly good estimation accuracy of LAI for different soil backgrounds,
    with r of 0.84 to 0.88, R2 of 0.70 to 0.77, RMSE of 0.96 to 1.12 m2 m−2, and RRMSE
    of 27% to 32%, but tended to overestimate LAI for 2 < LAI < 5 and underestimate
    LAI for LAI > 5 irrespective of the soil background tested (Fig. 7). Fig. 7. Known
    LAI against predicted LAI on different synthetic test sets (n = 10,000). These
    synthetic test sets were varied in soil backgrounds (i.e., soil1 to soil10). The
    predicted LAI was retrieved with the best RFR model (defaultMulti2.VIc3). The
    known LAI corresponds to LAI values used as inputs in PROSAIL to generate the
    synthetic datasets. Predicting LAI on experimental and augmented data at early
    growth stage for different soil backgrounds The established RFR models trained
    over synthetic training sets were tested on experimental and augmented data for
    different soil backgrounds. The augmented data were generated from the original
    experimental data collected at the early growth stage (here, seedling growth with
    LAI less than 0.3 m2 m−2) via background soil adjustment as described above. The
    performance of 4 models was compared to investigate improvements on LAI prediction
    contributed from 2 proposed strategies (i.e., broadening reflectance domain of
    the training soil background and improving canopy-spectral inputs). The 4 models
    (i.e., defaultSingle.Ref, defaultMulti2.Ref, defaultSingle.VIc3, and defaultMulti2.VIc3)
    were combined from the baseline and best set of training soil background as well
    as canopy-spectral inputs. The performance comparison of these models was presented
    in Table 3 and Fig. S3. Model prediction accuracy (RMSE/RRMSE) Test soil background
    defaultSingle.Ref defaultMulti2.Ref defaultSingle.VIc3 defaultMulti2.VIc3 Original
    2.25/2,317% 0.13/117% 0.15/134% 0.23/212% soil1 2.38/2,190% 0.12/114% 0.12/108%
    0.19/173% soil2 1.43/1,315% 0.12/113% 0.07/61% 0.09/66% soil3 1.22/1,122% 0.14/126%
    0.08/77% 0.10/88% Expand for more Table 3. Model prediction accuracy for low LAI
    (0.01 < LAI < 0.22) in different soil backgrounds. The model accuracy was characterized
    with root mean square error (RMSE; m2 m−2) and relative RMSE (RRMSE). The predicted
    LAI was retrieved using different RFR models (i.e., defaultSingle.Ref, defaultMulti2.Ref,
    defaultSingle.VIc3, and defaultMulti2.VIc3) from experimental and augmented multispectral
    data for different soil backgrounds at the early growth stage (i.e., seedling
    growth stage; DAS = 18 in Exp16). The “original” stands for the experimental multispectral
    images with an original background, while “soil1” to “soil10” represent the augmented
    multispectral images with test soil backgrounds. For the defaultSingle.Ref model,
    substantial differences existed in prediction accuracy (RMSE changing from 0.5
    to 2.99 m2 m−2) when tested on different soil backgrounds (Table 3). Consistent
    to simulation performance, the defaultSingle.Ref achieved higher accuracy in predicting
    LAI for soil backgrounds with a high similarity to the training soil background.
    For example, the defaultSingle.Ref model achieved more accurate LAI prediction
    when tested on backgrounds from soil4 to soil7 (with RMSE within 1 m2 m−2 and
    maximum bias within 1.5 m2 m−2) than the other backgrounds (with RMSE over 1 m2
    m−2 and maximum bias up to 5 m2 m−2) (Table 3 and Fig. S3). The soil reflectance
    of the original background was closest to the soil reflectance of soil1 among
    the 10 test soils (Fig. 3), so the model’s prediction accuracy was similar for
    these 2 backgrounds (Table 3). From the 2 proposed strategies to improve the RFR
    model, strategy 2 (i.e., improving canopy-spectral inputs) was more effective
    at predicting LAI across soil types than strategy 1 (i.e., broadening reflectance
    domain for training soil background). Compared with defaultSingle.Ref, the defaultMulti2.Ref
    model reduced the range of RMSE from 0.5–2.99 to 0.12–0.59 m2 m−2, while the defaultSingle.VIc3
    model reduced to a smaller range of 0.04 to 0.22 m2 m−2 (Table 3). After improving
    canopy-spectral inputs used in RFR models, broadening the reflectance domain for
    training soil background appeared not to further improve prediction accuracy,
    with RMSE from the defaultMulti2.VIc3 model ranging from 0.03 to 0.25 m2 m−2 (Table
    3). Although the defaultSingle.VIc3 model appeared to perform slightly better
    than the defaultMult2.VIc3 model at this seedling growth stage for LAI < 0.3,
    the latter was further tested in the following sections as it appeared more stable
    across LAI levels in simulation analysis. Predicting LAI at different growth stages
    for the whole growing season The baseline model (i.e., defaultSingle.Ref) and
    the model with the best simulation performance (i.e., defaultMulti2.VIc3) were
    further tested on experimental data collected in 2 field experiments to evaluate
    the model’s practical performance in predicting LAI at different growth stages
    across the growing season. Compared with the defaultSingle.Ref model, the improvement
    of LAI prediction from the defaultMulti2.VIc3 model mainly occurred in LAI < 2
    irrespective of growth stage (Fig. S4), which was consistent with the results
    from teh simulation analysis. For the defaultSingle.Ref model, the calculated
    ECDF presented a plausible seasonal changing pattern in both proportion (expressed
    in POE) and magnitude (expressed in MBE) of prediction bias: decreasing from seedling
    growth to stem elongation, maintaining a relative low value until flowering, and
    increasing from flowering to ripening (Fig. 8). This seasonal changing pattern
    synchronized with seasonal changes in the fraction of non-green background, which
    decreased before it started to increase along with vegetation development and
    senescence (Fig. 2). Compared with the defaultSingle.Ref model, the defaultMulti2.VIc3
    model presented a similar changing pattern in the proportion of overestimation
    but a much smaller magnitude of overestimation, especially at early (i.e., seedling
    growth and tillering) and late stages (i.e., milk development, dough development,
    and ripening) (Fig. 8) of which there was a high percentage of samples with observed
    LAI less than 2 m2 m−2 (Fig. S4). The substantial improvement in prediction at
    early and late stages indicated that the defaultMuti2.VIc3 model was unaffected
    by changes in soil and dead leaf backgrounds. Fig. 8. Empirical cumulative density
    distribution (ECDF) for LAI prediction bias at different growth stages. The bias
    indicates the difference of observed LAI subtracted from LAI predicted by RFR
    models (i.e., defaultSingle.Ref and defaultMulti2.VIc3) from real multispectral
    data captured at different growth stages (i.e., seedling growth, tillering, stem
    elongation, booting, heading, flowering, milk development, dough development,
    and ripening) in 2 field experiments (i.e., Exp16 and Exp19). The defaultMulti2.VIc3
    model provided prediction of LAI strongly correlated to observed LAI (r of 0.77
    to 89) during growing season except at the seedling growth stage (r = 0.59) (Fig.
    9). The model tended to overestimate LAI (POE of 62% to 100%), but the possibility
    of overestimation reduced at stem elongation (POE = 62%) and booting stage (POE
    = 66%) as LAI approached its peak value. As expected, the RMSE (0.23 to 0.62 m2
    m−2) was smaller for sparse canopies at early (i.e., seedling growth and tillering)
    and late stages (i.e., dough development and ripening) but was larger for dense
    canopies from stem elongation to milk development (RMSE of 0.69 to 0.89 m2 m−2).
    By contrast, the RRMSE was larger for sparse canopies and smaller for dense canopies.
    Fig. 9. Observed LAI against predicted LAI at different growth stages in 2 field
    experiments with different genotypes and management practices. Predicted LAI was
    obtained with the best RFR model (i.e., defaultMulti2.VIc3) that used real multispectral
    data captured at different growth stages under different water–nitrogen managements
    (i.e., IHN, ILN, RHN, and RLN) in 2 field experiments (i.e., Exp16 and Exp19).
    Mapping the spatiotemporal variation of LAI across growing season The defaultMulti2.VIc3
    model was used to map the spatiotemporal variation of LAI within/between 4 blocks
    across growing season for 2 experiments, as shown in Fig. 10 (for Exp16) and Fig.
    S5 (for Exp19). Within each map, the 4 blocks are corresponding to the 4 water–nitrogen
    treatments, i.e., IHN (top left), RHN (top right), ILN (bottom left), and RLN
    (bottom right). Same with the spatiotemporal pattern presented in the observed
    LAI, the predicted LAI can reliably capture the increasing trend of plot-scale
    LAI along with time and the water–nitrogen effects on LAI across growing season
    in both field experiments (Fig. 10 and Fig. S5). At the beginning of the growing
    season, the differences among treatments were small. The LAI values under high
    nitrogen treatments (IHN and RHN) were substantially higher than those under low
    nitrogen treatments (ILN and RLN) despite applying irrigation or not, with tillers
    developing and leaves expanding. Approaching the end of the season, the difference
    among treatments diminished as senescence of green parts began to increase. In
    most situations, the predicted LAI can correctly identify the negative or positive
    symbol of between-group difference among water–nitrogen treatments at different
    UAV-based phenotyping dates even under varying sowing densities, although the
    magnitude of difference of group means might be different (Figs. S6 and S7). Fig.
    10. Predicted LAI for different phenotyping dates in Exp16. The predicted LAI
    was retrieved with the best RFR model (defaultMulti2.VIc3) using experimental
    multispectral data captured with the UAV platform. The plots with numbers at the
    top indicate those designed for UAV-based phenotyping, while the number denotes
    the observed LAI from the corresponding plots used for destructive harvests. For
    each subfigure, only 84 plots have observed LAI as biophysical measurements were
    only conducted in these plots. Rows and columns are used to locate the position
    of the plot in the field. The 4 blocks correspond to the 4 water–nitrogen treatments,
    i.e., IHN, ILN, RHN, and RLN. Predicting the dynamics of genotype-specific LAI
    and related heritability during the whole growing season The defaultMulti2.VIc3
    model was tested on experimental data to evaluate its ability in predicting the
    seasonal dynamics of LAI in 2 field experiments. Observed LAI measured from destructive
    harvests and LAI predictions from the RFR model using UAV-based multispectral
    images are presented for the different genotypes, plant densities, and irrigation–fertilization
    managements in Fig. 11 (Exp16) and Fig. S8 (Exp19). Over the growing season, the
    observed LAI gradually increased before reaching its peak value and then started
    to decrease with leaf senescence. The difference in LAI dynamics among genotypes
    and plant densities was relatively small, while the difference among irrigation–fertilization
    managements was relatively obvious, especially between the high-nitrogen and low-nitrogen
    treatments. Fig. 11. The dynamics of the genotype-specific observed LAI and predicted
    LAI over the growing season for Exp16. The red symbols indicate the genotype-specific
    observed LAI obtained from the destructive harvest. The blue symbols correspond
    to the genotype-specific predicted LAI retrieved with the best RFR model (defaultMulti2.VIc3)
    using experimental multispectral data captured with the UAV platform. The genotype-specific
    values of LAI were calculated with the best linear unbiased prediction (BLUP)
    model. The 4 water–nitrogen treatments include IHN, ILN, RHN, and RLN. The genotype-specific
    value of LAI predicted with defaultMulti2.VIc3 model using multispectral data
    presented remarkable consistency of the temporal dynamics compared with the observed
    LAI, with a value of r over 0.9 for 49 of 64 treatments in the 2 field experiments
    (Fig. 11 and Fig. S8). The r value of the remaining 15 treatments in Exp19 slightly
    reduced from 0.82 to 0.89 (Fig. S8). Further analysis for Exp16 indicated that
    the predicted value can reliably characterize the heritability of 7 genotypes
    under high nitrogen treatments (i.e., IHN and RHN; Fig. S9). However, the heritability
    under low nitrogen treatments (i.e., ILN and RLN; Fig. S9) was low from either
    observed or predicted values because the genotypic variance under ILN and RLN
    was close to the residual variance (Fig. S10). For Exp19, only the heritability
    under IHN was well characterized by predicted values (Fig. S11). The inconsistent
    heritability calculated from observed and predicted LAI under the other treatments
    was mainly due to (a) the genotypic variance not being large enough than residual
    variance to distinguish genotypes (Fig. S12), and (b) the defaultMulti2.VIc3 model
    tended to underestimate high LAI (Figs. 7 and 9). Discussion Two strategies to
    improve LAI predictions from UAV-based imagery irrespective of soil backgrounds
    This study developed a background-resistant model to predict LAI that used 2 strategies,
    i.e., an extended reflectance domain of the training soil background and an improved
    set of canopy-spectral indicators as model inputs. In theory, this background-resistant
    model can provide accurate LAI prediction for different LAI levels and for diverse
    soil backgrounds (Fig. 7), because high accuracies were achieved for a predictive
    model trained and tested with the similar synthetic data across a wide range of
    LAI [8,9,13]. By contrast, the baseline model (defaultSingle.Ref) made better
    prediction for some soil backgrounds than others (Fig. 6) depending on the similarity
    between the training and the test soil backgrounds. Extending the reflectance
    domain of the training soil background increased the diversity of the training
    dataset (i.e., changing defaultSingle to defaultMulti1 and to defaultMulti2),
    potentially making the test set a subset of the overall distribution represented
    by the training set. This improved the model’s robustness for LAI prediction in
    different soil backgrounds. Previous studies also used multiple soil reflectance
    instead of a single soil reflectance to generate synthetic training data when
    applying predictive models for LAI prediction from satellite images in a large
    region, but they did not compare the performance of models trained over single
    and multiple soil reflectance [10,27]. Improving canopy-spectral inputs essentially
    corresponds to extracting the common features correlated to LAI in different soil
    backgrounds, leading to a generic relationship between LAI and spectral signals.
    Our study found that Ref-based and RefVI-based models were able to achieve accurate
    LAI prediction except for some extreme soils that were highly dissimilar to training
    soils. By contrast, the VI-based models achieved much more accurate LAI prediction
    for these extreme soils (i.e., very white and sandy) (Fig. 6), which was consistent
    with a similar study about comparison of LAI predicted from reflectance or VIs
    [40]. Although few crops grow in these extreme soils, the consideration on these
    situations might be worth for vegetation monitor in other disciplines (e.g., ecology).
    Previous studies indicated that compared to visible-based VIs, red edge-based
    VIs were less sensitive to canopy structures (e.g., average leaf angle) and were
    more effective for medium to high LAI estimation [26]. It was also reported that
    VIs such as EVI2, MCARI2, and MTVI2 were stable across soil and pigment variations
    and were less prone to saturation at high LAI [1,41]. In addition, we found that
    the sensitivity to changes in soil background varied across both LAI levels and
    VIs, with varying sensitivity among LAI levels for NDVI substantially higher than
    others (Fig. 4). These highlighted the importance of an appropriate combination
    of VIs to achieve accurate prediction of LAI in diverse soils. Although several
    models achieved similarly good performance, the defaultMulti2.VIc3 model with
    fewer input variables was finally selected for detailed analysis in the current
    study. Difference between the simulation and practical performances of the model
    It is common for predictive model trained over synthetic data to achieve different
    or less accurate LAI prediction when tested on real experimental data [13]. The
    essential reason may come from simplifications embedded in RTMs that result in
    inherent differences between observed and simulated canopy reflectance under given
    conditions [19]. Another reason is the difference of soil backgrounds, which is
    assumed to be pure soil in RTM simulations but was a mixed of soil and plant residues
    in actual observations in the field. This issue was reported to be effectively
    addressed by (a) adding noise to synthetic training data [10], (b) conducting
    background correction on spectral images [8], (c) establishing a relationship
    between LAI and VI less sensitive to soil variation [1], or (d) developing a background-resistant
    model as presented in current study. Additionally, the model performance when
    tested against synthetic data can also be, at times, reduced by the large bias
    from outliers that were predicted by the model, which may yet have a high overall
    accuracy [8,12]. For example, in the current study, the defaultMulti2.VIc3 model
    stably achieved a good prediction of LAI on both synthetic test data with different
    soil backgrounds (R2 of 0.70 to 0.77 and RRMSE of 27% to 32%; Fig. 7) and experimental
    data (R2 of 0.73 to 0.89 and RRMSE of 41%; Fig. S13). However, the prediction
    bias on synthetic data was symmetrically distributed in 2 sides of zero, ranging
    from −5.67 to 4.51 m2 m−2, while on experimental data, the prediction bias fluctuated
    in a smaller range (−1.84 to 2.53 m2 m−2), with more samples overestimated (about
    75%) than underestimated (about 25%) (Fig. S13). The outliers might be due to
    the less-accurate relationships established from the training data containing
    some unrealistic samples whose combinations of values of crop traits cannot be
    observed in the real world, and this issue can somehow be addressed by introducing
    biological constraints in training data as presented by Chen et al. [9]. Different
    performances of the model at different growth stages Most studies estimating LAI
    based on multispectral imagery were undertaken during the crop vegetative stages
    to not consider the effects of heads or senescent vegetation. Such studies typically
    achieve different prediction accuracies for LAI of wheat depending on sites and
    growth stages [1,8,11,40,42]. During the wheat growing cycle, the fraction of
    green vegetation (fcover) gradually increases over time and maintains a high value
    (with the consecutive development of leaves, stems, and heads) before it starts
    to decrease because of tissue senescence [43]. Accordingly, the opposite seasonal
    pattern occurs for the fraction of non-green background (1 − fcover). The change
    over time in the bias of LAI predicted with the baseline RFR model (i.e., defaultSingle.Ref)
    in this study (Fig. 8) can be explained from (a) the seasonal changing pattern
    of the fraction of non-green background (i.e., soil and senesced tissues) and
    (b) effects of background variations on canopy reflectance in the VNIR range at
    different LAI levels (Fig. 4). The improved RFR model (i.e., defaultMulti2.VIc3)
    reduced the effects of background variations (Fig. 8) and resulted in relatively
    stable predictions of LAI across growth stages (Fig. 9), which proved the effectiveness
    of the proposed strategies in developing a background-resistant model. In growing
    crops, the canopy reflectance captured using sensors results from the characteristics
    of the canopy, which consist of all aboveground components including leaves, stems,
    and reproductive organs (i.e., heads, ears, and tassels) [44]. The predicted LAI
    from the real spectral image based on PROSAIL simulations did not correspond to
    LAI but GAI that included other green organs (e.g., stems and heads) in addition
    to leaves. As the growing season progresses, there is a temporal shift between
    the GAI and LAI as described by Duveiller et al. [7]. This explains a quasi-systematic
    overestimation of “LAI” (i.e., GAI in reality) predicted with the RFR model in
    this study (Fig. 8). The high proportion of a slight overestimation at early stages
    (i.e., seedling growth and tillering) was due to ignoring of the stem area in
    the observed LAI. For stem elongation to booting, effects from the saturation
    for dense canopy were offset by impacts from the appearance of heads, resulting
    in a lower proportion of overestimation during growing season. From heading onwards,
    the occurrence of senescence affected prediction accuracy of LAI through changing
    the co-distribution of green components. The prediction accuracy could be improved
    by establishing a transformation between GAI and LAI based on the proportion of
    stems, leaves, and heads [7]. Because of the simplification of canopy description
    in 1-dimensional (1D) RTM such as PROSAIL, the hybrid methods based on 1D canopy
    simulations generally result in underestimation of LAI at a high value as presented
    in the current study (Fig. 7) and others [8,12]. More realistic reflectance simulations
    using 3D canopy models could effectively address this underestimation issue as
    presented by Jiang et al. [45]. These authors also indicated that the effective
    GAI (GAIeff) can be better estimated from canopy reflectance than GAI or LAI.
    A method that captures seasonal changes in LAI Previous studies have confirmed
    the temporal consistence of predicted LAI dynamics from multisource data collected
    from different satellites [10,25]. However, to our knowledge, the quantification
    of seasonal dynamics of the predicted LAI has not yet been properly characterized
    and validated at plot scale because of the lack of sufficient measurements for
    ground truthing. Only a few studies at the field or region scale have used coarse
    satellite images together with ground measurements [46–48]. The current study
    investigated model performance in capturing seasonal LAI dynamics at plot scale
    over a sufficient dataset consisting of 2 growing seasons for different treatments
    (i.e., genotypes, plant densities, and water–nitrogen managements). The established
    background-resistant model provided reliable alignment to the observed seasonal
    changing pattern of genotype-specific values (Fig. 11 and Fig. S8). Importantly,
    this background-resistant model was sensor-specific and can be established in
    advance without using any ground calibration. This means that this single ready-to-use
    model can predict the LAI dynamics at plot scale irrespective of the soil background,
    thus providing a friendly LAI high-throughput phenotyping method that could potentially
    benefit in-season phenology identification and crop growth rate assessment [49].
    Limitations and perspectives The reflectance profiles of the different soils used
    in the defaultMulti2 training soil background were linearly correlated. Incorporating
    multiple soil reflectance without linear correlation is possible to further improve
    the robustness of model performance by increasing the diversity of the soil training
    set. In addition to the approach used to simulate diverse soil reflectance spectra,
    some soil reflectance models, such as the Price model [50] and GSV model [51],
    can be used to create the variability of soil reflectance spectra. Moreover, additional
    efforts could be put to develop better VIs and VI combinations to further improve
    the background-resistant model and enhance prediction accuracy for LAI and other
    traits for other species in the future. In the practical validation of this study,
    the prediction was computed from plot reflectance and derived VIs. The plot area
    (approximate 8.96 m2 for Exp16) used for aggregation was similar to the resolution
    of satellites such as CubeSat (3 m × 3 m). Hence, this method could be used with
    UAV-based images to produce ground truths of LAI to validate satellite-based estimates.
    Furthermore, this generic model is theoretically able to produce reliable prediction
    of wheat LAI directly from high-resolution satellite images given its background-resistant
    attribute, which should be able to deal with mixed pixels (i.e., aggregation of
    vegetation and soil in each pixel). The increasing spatial resolution enables
    a more accurate capture of details in the canopy, but the RTM-based method is
    not suitable to apply to make prediction directly on pixels, unless the pixel
    size is big enough to represent a canopy. On the basis of our understanding, the
    minimum area is 50 cm × 50 cm for wheat canopy. This is the reason that we applied
    our RFR model trained on PROSAIL simulations on plot mean reflectance to predict
    plot-scale LAI. To enhance the advantage of images with sub-centimeter resolution,
    different non-RTM-based approaches were investigated to estimate LAI with pixel
    values [52]. For utilization of satellite images with big-enough pixels, the spatial
    resolution did not show a substantial difference of LAI estimation retrieved with
    linear models regardless of VIs used to build the LAI–VI relationship [53]. However,
    effects of spatial resolution on LAI estimation retrieved with RTM-based LUT (look-up
    table) did not reach an agreement [53,54]. That is likely because LUT-based estimation
    of LAI is based on the similarity between spectral data instead of the relationship
    between spectral data and LAI. Another study for LAI estimation using machine
    learning methods indicated that there was no substantial difference between LAI
    estimations retrieved from satellite imagery-derived canopy spectral information
    or UAV-based canopy structure information, but prediction accuracy was boosted
    by integration of spectral and structure information as the integration reduced
    background soil effect and asymptotic saturation issue to some extent [55]. The
    proposed background-resistant model is sensor specific, but it can be updated
    for other sensors. In this case, simulated canopy reflectance needs to be resampled
    into band reflectance in accordance with the spectral response function of the
    target sensor. The idea of developing a background-resistant model is not limited
    to wheat LAI and can be applied to predict other traits and for other species
    in associated research areas (e.g., breeding, agriculture, ecology, vegetation
    remote sensing, etc.), provided that appropriate PROSAIL input parameters and
    effective VIs are defined for the target trait and/or the target species. Conclusion
    In this study, we applied a hybrid method to establish the predictive model to
    predict wheat LAI by training RFR models over synthetic data simulated by PROSAIL
    without any ground calibration. Two strategies (i.e., broadening the reflectance
    domain of the training soil background and improving canopy-spectral indicators
    as model inputs) were investigated to reduce the sensitivity of the RFR model
    to background variation for LAI prediction. Both strategies presented to improve
    the robustness of prediction accuracy on unseen synthetic data in different soil
    backgrounds, while improving canopy-spectral inputs appeared to be more effective
    and robust. The improved RFR model (i.e., defaultMulti2.VIc3), which adopted an
    extended reflectance domain of training soil background and a soil-insensitive
    input set with fewer canopy-spectral indicators, was proved to be resistant to
    background variation on synthetic data. On the basis of validation in field experiments,
    this defaultMulti2.VIc3 model presented stable prediction accuracy for low LAI
    retrieved from the original image and augmented images even in extreme soil background.
    In addition, this model achieved similar prediction accuracy for LAI at different
    growth stages, with relatively larger RMSE in mid-season from stem elongation
    to milk development (dense canopies) and smaller RMSE at early and late stages
    (sparse canopies). Moreover, this model produced predicted LAI strongly correlated
    to their observations, reliably capturing the seasonal pattern of LAI dynamics
    under different treatments in terms of genotypes, sowing densities, and water–nitrogen
    managements. As discussed above, the prediction retrieved from spectral images
    generally corresponds to GAI (all green parts included) and only represents LAI
    in the case that green leaves are separated from the other green organs (e.g.,
    stems and heads). This explains a quasi-systematic overestimation of “LAI” (i.e.,
    GAI in reality) predicted with the RFR models in this study. Overall, the good
    prediction of the defaultMulti2.VIc3 model obtained from synthetic, augmented,
    and experimental data indicated that a background-resistant model can be established
    using simulation data. This ready-to-use background-resistant model can enable
    a stable and accurate GAI prediction from isolated UAV-based multispectral images
    over wheat growing season for diverse soil backgrounds in field conditions. Acknowledgments
    Funding: Q.C. received a scholarship co-funded by the China Scholarship Council
    and the University of Queensland and has been awarded a top-up scholarship by
    CSIRO as a visiting student. The field experiment and ongoing research were supported
    by the Grains Research and Development Corporation (grant numbers CSP00179 and
    UOQ2003-011RTX). Author contributions: Q.C. implemented this research and wrote
    the draft of the manuscript. S.C.C. helped formulate research ideas and highlighted
    research objectives. B.Z. provided guidance for technical issues especially in
    image processing. K.C. provided constructive suggestions to clarify the expression
    of ideas. All authors engaged in reviewing and editing this manuscript. Competing
    interests: The authors declare that they have no conflict of interest. Supplementary
    Materials Figs. S1 to S13. Table S1. DOWNLOAD 3.87 MB References 1 Haboudane D,
    Miller JR, Pattey E, Zarco-Tejada PJ, Strachan IB. Hyperspectral vegetation indices
    and novel algorithms for predicting green LAI of crop canopies: Modeling and validation
    in the context of precision agriculture. Remote Sens Environ. 2004;90(3):337–352.
    GOOGLE SCHOLAR 2 Potgieter AB, George-Jaeggli B, Chapman SC, Laws K, Suárez Cadavid
    LA, Wixted J, Watson J, Eldridge M, Jordan DR, Hammer GL. Multi-spectral imaging
    from an unmanned aerial vehicle enables the assessment of seasonal leaf area dynamics
    of sorghum breeding lines. Front Plant Sci. 2017;8:Article 1532. GO TO REFERENCE
    GOOGLE SCHOLAR 3 Araus JL, Cairns JE. Field high-throughput phenotyping: The new
    crop breeding frontier. Trends Plant Sci. 2014;19(1):52–61. GO TO REFERENCE CROSSREF
    GOOGLE SCHOLAR 4 Pauli D, Chapman SC, Bart R, Topp CN, Lawrence-Dill CJ, Poland
    J, Gore MA. The quest for understanding phenotypic variation via integrated approaches
    in the field environment. Plant Physiol. 2016;172(2):622–634. GOOGLE SCHOLAR SHOW
    ALL REFERENCES     Latest Articles   PLANT PHENOMICS22 MAR 2024 Handling the Challenges
    of Small-Scale Labeled Data and Class Imbalances in Classifying the N and K Statuses
    of Rubber Leaves Using Hyperspectroscopy Techniques BY WENFENG HU WEIHAO TANG
    ET AL. PLANT PHENOMICS22 MAR 2024 Mitigating Illumination-, Leaf-, and View-Angle
    Dependencies in Hyperspectral Imaging Using Polarimetry BY DANIEL KRAFFT CLIFTON
    G. SCARBORO ET AL. PLANT PHENOMICS20 MAR 2024 Time-Series Field Phenotyping of
    Soybean Growth Analysis by Combining Multimodal Deep Learning and Dynamic Modeling
    BY HUI YU LIN WENG ET AL. VIEW MORE Recommended Articles from TrendMD Revealing
    Tissue Heterogeneity and Spatial Dark Genes from Spatially Resolved Transcriptomics
    by Multi-view Graph Networks Ying Li et al., Research Comprehensive, Continuous,
    and Vertical Measurements of Seawater Constituents with Triple-Field-of-View High-Spectral-Resolution
    Lidar Kai Zhang et al., Research Access to Axially Chiral Aryl Aldehydes via Carbene-Catalyzed
    Nitrile Formation and Desymmetrization Reaction Yuanlin Cai et al., Research Mitigating
    Illumination-, Leaf-, and View-Angle Dependencies in Hyperspectral Imaging Using
    Polarimetry Daniel Krafft et al., Plant Phenomics Layering theory and human abstract
    thinking Danesi, M. et al., Cybernetics & Human Knowing, 2001 BAG6 supports stress
    fiber formation by preventing the ubiquitin-mediated degradation of RhoA Maho
    Miyauchi et al., Molecular Biology of the Cell, 2023 A walk through the city with
    John Chrysostom : psychogeography, virtue and the urban ascetic in the homilies
    On Ephesians 15 and On Hebrews 28 Chris L. De Wet, Neotestamentica, 2020 NIETZSCHE''S
    NAPOLEON: A RENAISSANCE MAN Author: Regent et al., History of Political Thought
    Powered by ADVERTISEMENT View full text|Download PDF About Us About SPJ About
    AAAS Science family of journals Work at AAAS Help FAQ Email Alerts and RSS Feeds
    Follow Us © 2024 American Association for the Advancement of Science. All rights
    Reserved. AAAS is a partner of HINARI, AGORA, OARE, CHORUS, CLOCKSS, CrossRef
    and COUNTER. Terms of Service Privacy Policy Accessibility"'
  inline_citation: '>'
  journal: Plant Phenomics
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A Generic Model to Estimate Wheat LAI over Growing Season Regardless of the
    Soil-Type Background
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Tace Y.
  - Elfilali S.
  - Tabaa M.
  - Leghris C.
  citation_count: '2'
  description: Water management is crucial for agriculture, as it is the primary source
    of irrigation for crops. Effective water management can help farmers to improve
    crop yields, reduce water waste, and increase resilience to drought. This can
    include practices such as precision irrigation, using sensors and technology to
    deliver water only where and when it is needed, and conservation tillage, which
    helps to reduce evaporation and retain moisture in the soil. Additionally, farmers
    can implement water-saving techniques such as crop selection, crop rotation, and
    soil conservation to reduce their water use. Thus, studies aimed at saving the
    use of water in the irrigation process have increased over the years. This research
    suggests using advanced technologies such as IoT and AI to manage irrigation in
    a way that maximizes crop yield while minimizing water consumption, in line with
    Agriculture 4.0 principles. Using sensors in controlled environments, data on
    plant growth was quickly collected. Thanks to the analysis and training of these
    data between several models among them, we find the K-Nearest Neighbors (KNN),
    Support Vector Machine (SVM) and Naive Bayes (NB), the KNN has shown interesting
    results with 98.4 accuracy rate and 0.016 root mean squared error (RMSE).
  doi: 10.23939/mmc2023.02.575
  full_citation: '>'
  full_text: '>

    "Skip to main content Academic Journals and Conferences Login Укр MMC All Volumes
    and Issues Volume 10, Number 2, 2023 Implementation of smart irrigation using
    IoT and Artificial Intelligence Implementation of smart irrigation using IoT and
    Artificial Intelligence MMC. 2023; Volume 10, Number 2 : pp. 575–582 https://doi.org/10.23939/mmc2023.02.575
    Received: January 29, 2023  Accepted: May 10, 2023 Mathematical Modeling and Computing,
    Vol. 10, No. 2, pp. 575–582 (2023) Authors: Y. Tace S. Elfilali M. Tabaa C. Leghris
    1Laboratory of Information Technology and Modeling, Faculty of Sciences Ben M''Sik;
    Pluridisciplinary Research and Innovation Laboratory (LPRI) 2Laboratory of Information
    Technology and Modeling, Faculty of Sciences Ben M''Sik 3Pluridisciplinary Research
    and Innovation Laboratory (LPRI) 4Computer Science Department, RTM Team, FST Mohammedia
    Water management is crucial for agriculture, as it is the primary source of irrigation
    for crops.  Effective water management can help farmers to improve crop yields,
    reduce water waste, and increase resilience to drought.  This can include practices
    such as precision irrigation, using sensors and technology to deliver water only
    where and when it is needed, and conservation tillage, which helps to reduce evaporation
    and retain moisture in the soil.  Additionally, farmers can implement water-saving
    techniques such as crop selection, crop rotation, and soil conservation to reduce
    their water use.  Thus, studies aimed at saving the use of water in the irrigation
    process have increased over the years.  This research suggests using advanced
    technologies such as IoT and AI to manage irrigation in a way that maximizes crop
    yield while minimizing water consumption, in line with Agriculture 4.0 principles.  Using
    sensors in controlled environments, data on plant growth was quickly collected.  Thanks
    to the analysis and training of these data between several models among them,
    we find the K-Nearest Neighbors (KNN), Support Vector Machine (SVM) and Naive
    Bayes (NB), the KNN has shown interesting results with 98.4 accuracy rate and
    0.016 root mean squared error (RMSE). artificial intelligenceAgriTechInternet
    of thingssmart agriculturesmart irrigation Madakam S., Uchiya T.  Industrial Internet
    of Things (IIoT): Principles, Processes and Protocols.  The Internet of Things
    in the Industrial Sector. Computer Communications and Networks. Springer, Cham.
    (2019). Eli-Chukwu N. C.  Applications of artificial intelligence in agriculture:
    A review.  Engineering, Technology & Applied Science Research.  9 (4), 4377–4383
    (2019). Rehman T. U., Mahmud M. S., Chang Y. K., Jin J., Shin J.  Current and
    future applications of statistical machine learning algorithms for agricultural
    machine vision systems.  Computers and electronics in agriculture.  156, 585–605
    (2019). Lowry G. V., Avellan A., Gilbertson L. M.  Opportunities and challenges
    for nanotechnology in the agri-tech revolution.  Nature Nanotechnology.  14 (6),
    517–522 (2019). Mahmood Khan Pathan S., Firoj Ali M.  Implementation of Faster
    R-CNN in Paddy Plant Disease Recognition System.  2019 3rd International Conference
    on Electrical, Computer & Telecommunication Engineering (ICECTE), Rajshahi, Bangladesh.
    189–192 (2019). Gore S., Nagtilak S., Joshi A., Kulkarni S., Labade N.  Smart
    Irrigation System for Agriculture using IOT and ML.  International Journal of
    Contemporary Architecture The New ARCH.  8 (2), 1200–1206 (2021). Goap A., Sharma
    D., Shukla A. K., Rama Krishna C.  An IoT based smart irrigation management system
    using Machine learning and open source technologies.  Computers and Electronics
    in Agriculture. 155, 41–49 (2018). Soliman M., Usami T., Imamura S., Yano K.,
    Ballal H., Abbas A. M., Abdel Fattah T., El-Kafrawy S., El-Sayed H., El-Shafie
    A.  Synthesis of Geospatial Database and Interdisciplinary to Achieve NSDS for
    Downtown Alexandria, Egypt Vision 2030.  Proceedings of the International Cartographic
    Association.  4, 101 (2021). Belgiu M., Drăguţ L.  Random forest in remote sensing:
    A review of applications and future directions.  ISPRS Journal of Photogrammetry
    and Remote Sensing.  114, 24–31 (2016). Sharif M., Khan M. A., Iqbal Z., Azam
    M. F., Ikram U. L. M., Javed M. Y.  Detection and classification of citrus diseases
    in agriculture based on optimized weighted segmentation and feature selection.
    Computers and Electronics in Agriculture.  150, 220–234 (2018). Käfer P., Souza
    da Rocha N., Ribeiro Diaz L., Kaiser E., Santos D., Veeck G., Robárti D., Rolim
    S., Oliveira G.  Artificial neural networks model based on remote sensing to retrieve
    evapotranspiration over the Brazilian Pampa.  Journal of Applied Remote Sensing.  14
    (3), 038504 (2020). Maimaitijiang M., Ghulam A., Sidike P., Hartling S., Maimaitiyiming
    M., Peterson K., Kadam S., Burken J., Fritschi F. Unmanned Aerial System (UAS)-based
    phenotyping of soybean using multi-sensor data fusion and extreme learning machine.  ISPRS
    Journal of Photogrammetry and Remote Sensing.  134, 43–58 (2017). Kumar S., Mishra
    S., Khanna P., Pragya.  Precision Sugarcane Monitoring Using SVM Classifier.  Procedia
    Computer Science.  122, 881–887 (2017). Thanh Noi P., Kappas M.  Comparison of
    Random Forest, k-Nearest Neighbor, and Support Vector Machine Classifiers for
    Land Cover Classification Using Sentinel-2 Imagery.  Sensors.  18 (1), 18 (2018).
    Chlingaryan A., Sukkarieh S., Whelan B.  Machine learning approaches for crop
    yield prediction and nitrogen status estimation in precision agriculture: A review.  Computers
    and Electronics in Agriculture.  151, 61–69 (2018). Yassin M. A., Alazba A. A.,
    Mattar M. A.  Modelling daily evapotranspiration using artificial neural networks
    under hyper arid conditions.  Pakistan Journal of Agricultural Sciences.  53 (3),
    695–712 (2016). Choi Y., Kim M., O''Shaughnessy S., Jeon J., Kim Y., Song W. J.  Comparison
    of Artificial Neural Network and Empirical Models to Determine Daily Reference
    Evapotranspiration.  Journal of The Korean Society of Agricultural Engineers.  60
    (6), 43–54 (2018). Wu M., Feng Q., Wen X., Deo R. C., Yin Z., Yang L., Sheng D.  Random
    forest predictive model development with uncertainty analysis capability for the
    estimation of evapotranspiration in an arid oasis region.  Hydrology Research.  51
    (4), 648–665 (2020). Nalepa J., Kawulok M.  Selecting training sets for support
    vector machines: a review.  Artificial Intelligence Review.  52 (2), 857–900 (2019).
    Rish I.  An empirical study of the naive Bayes classifier.  IJCAI 2001 workshop
    on empirical methods in artificial intelligenc.  3 (22), 41–46 (2001). Cunningham
    P., Delany S. J.  k-Nearest neighbour classifiers – A Tutorial.  ACM computing
    surveys.  54 (6), 1–25 (2021). https://science.lpnu.ua/sites/default/files/journal-paper/2023/may/30379/2023102575582_0.pdf
    Share This Issue Volume 10, Number 2, 2023 Download article   Views 228 Related
    Design of the system of automated generation of poetry works Development of the
    System Is for the Selection of Films With the Use of Client-server Architecture
    Computational approach to law: compatibility with human rights and current regulation
    © Academic Journals and Conferences, 2024."'
  inline_citation: '>'
  journal: Mathematical Modeling and Computing
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Implementation of smart irrigation using IoT and Artificial Intelligence
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Reyana A.
  - Kautish S.
  - Karthik P.M.S.
  - Al-Baltah I.A.
  - Jasser M.B.
  - Mohamed A.W.
  citation_count: '6'
  description: 'Sensors are now used by farmers and agronomists to help them improve
    their operations. They use sensor data transmitted via IoT to remotely monitor
    their crops. Farmers today manage crops in a controlled environment to increase
    yields in the name of modern farming. Crop productivity, on the other hand, is
    influenced by the severity of the weather and disease variations. The primary
    objective of this paper is to present a novel Multisensor Machine-Learning Approach
    (MMLA) for classifying multisensor data. The fusion strategy supports high-quality
    data analysis in agricultural contexts for cultivation recommendations. Based
    on the proposed recommendation system, eight crops were classified: cotton, gram,
    groundnut, maize, moong, paddy, sugarcane, and wheat. Crop species were classified
    using three machine learning algorithms: J48 Decision Tree, Hoeffding Tree, and
    Random Forest. To evaluate the performance of the proposed multi-text classifier,
    only the top eight classes were investigated. The classifier''s performance is
    measured in terms of precision, recall, F-measure, MCC, ROC Area, and PRC Area
    class, and the results are compared with the state-of-the-art classifiers. The
    Random forest algorithm has the lowest error measure of RMSE at 13%, RAE at 38.67%,
    and RRSE at 44.21%, demonstrating effectiveness in classifying the agriculture
    text. Thus, the use of a multisensor data fusion approach based on crop recommendation
    provides greater precision in prediction, resulting in a significant increase
    in crop yield while also creating awareness in the condition-based environmental
    monitoring system.'
  doi: 10.1109/ACCESS.2023.3249205
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 11 Accelerating
    Crop Yield: Multisensor Data Fusion and Machine Learning for Agriculture Text
    Classification Publisher: IEEE Cite This PDF A. Reyana; Sandeep Kautish; P. M.
    Sharan Karthik; Ibrahim Ahmed Al-Baltah; Muhammed Basheer Jasser; Ali Wagdy Mohamed
    All Authors 1 Cites in Paper 3038 Full Text Views Open Access Comment(s) Under
    a Creative Commons License Abstract Document Sections I. Introduction II. Related
    Works III. Methodology IV. Results and Discussion V. Conclusion Authors Figures
    References Citations Keywords Metrics Abstract: Sensors are now used by farmers
    and agronomists to help them improve their operations. They use sensor data transmitted
    via IoT to remotely monitor their crops. Farmers today manage crops in a controlled
    environment to increase yields in the name of modern farming. Crop productivity,
    on the other hand, is influenced by the severity of the weather and disease variations.
    The primary objective of this paper is to present a novel Multisensor Machine-Learning
    Approach (MMLA) for classifying multisensor data. The fusion strategy supports
    high-quality data analysis in agricultural contexts for cultivation recommendations.
    Based on the proposed recommendation system, eight crops were classified: cotton,
    gram, groundnut, maize, moong, paddy, sugarcane, and wheat. Crop species were
    classified using three machine learning algorithms: J48 Decision Tree, Hoeffding
    Tree, and Random Forest. To evaluate the performance of the proposed multi-text
    classifier, only the top eight classes were investigated. The classifier’s performance
    is measured in terms of precision, recall, F-measure, MCC, ROC Area, and PRC Area
    class, and the results are compared with the state-of-the-art classifiers. The
    Random forest algorithm has the lowest error measure of RMSE at 13%, RAE at 38.67%,
    and RRSE at 44.21%, demonstrating effectiveness in classifying the agriculture
    text. Thus, the use of a multisensor data fusion approach based on crop recommendation
    provides greater precision in prediction, resulting in a significant increase
    in crop yield while also creating awareness in the condition-based environmental
    monitoring system. GA_Multisensor, Machine-Learning Approach (MMLA) framework
    for Agriculture Context. Published in: IEEE Access ( Volume: 11) Page(s): 20795
    - 20805 Date of Publication: 27 February 2023 Electronic ISSN: 2169-3536 DOI:
    10.1109/ACCESS.2023.3249205 Publisher: IEEE SECTION I. Introduction A large portion
    of Asian countries is reliant on agriculture. The expansion of agricultural-based
    enterprises lacks quality assurance [1]. In the name of modern farming, farmers
    today manage crops in a controlled atmosphere to increase yield. However, the
    severity of the weather and the variability in disease are impacted by crop productivity.
    Consequently, a novel monitoring and information technology-based application,
    such as the Internet of Things (IoT), is required. Decisions about irrigation,
    climate change, soil nutrition, etc., may be managed once the precise status of
    crops is understood. This significantly raises the production of crops whose quality
    deteriorated as a result of environmental effects [2]. Farmers and agronomists
    employ a sensor today, which helps them improve their operations. They remotely
    monitor their crops using sensor data that is transmitted via IoT. The machinery
    is controlled, and depending on its condition, the robots are given instructions
    to perform the necessary agricultural chores [3]. The advent of the Green Revolution
    has advanced agricultural methods. The usages of fertilizer and irrigation management
    are examples of this. The amount of agricultural produce has doubled despite the
    expansion of agricultural fields. Farmers’ involvement in croplands has increased
    by 12% and there is dependable irrigation [4]. The main consumption, as mentioned
    before, is the use of freshwater resources. The water was taken out of the aquifers
    of groundwater. The need for food is growing as the world’s population expands.
    Even stranger things are happening in arid and semi-arid areas. Although modern
    agricultural practices have improved food production, they have nonetheless harmed
    the environment. This encompasses areas including global food security, climate
    change, and water exchange. Concerns about finding a solution to the world’s rising
    food demands have emerged. The food crisis is largely predicted by these economic
    and societal factors. There must be one billion hectares of additional croplands
    by the year 2050. Because of this, the growth of forests is constrained, which
    presents a challenge for farmers. To fit into socially approved production systems,
    farmers are trying [5]. Accurate monitoring and sustainable crop production are
    needed to meet the growing demand. Monitoring seasonal crop growth is part of
    monitoring vegetation dynamics [6]. However, it requires the delivery of products
    that promote environmental sustainability. Additionally, the developed crop inventories
    must be dependable and regular. To solve this problem, it is essential to gather
    very accurate crop status information and make reasonable decisions about how
    to control irrigation, change climate variables, or improve soil nutrition in
    agricultural settings. With the use of machine learning the current study provides
    an effective approach to facilitate intelligent management and decision-making
    in crop categorization for healthy and quality crop growing [7]. Moreover, there
    is increasing agricultural success with the use of machine learning as it takes
    advantage of the availability of varied sensors, cameras, and smartphones. The
    classification and mapping of agricultural plants are extremely valuable for agricultural
    monitoring and food security [8]. Although it has been discovered that optical
    data collected later in the growing season offers the best overall classification
    accuracy, operational crop mapping is faced with two difficulties as a result
    [9]. One is that cloud cover may prevent late-season optical data from being available.
    The other issue is that crop identification at an earlier stage of the growing
    season is hindered by the dependence on late-season photography. Hence it is necessary
    to unravel, quantify, and understand data-intensive processes in agricultural
    operational environments [10]. Agriculture-based data are inadequate, for this
    purpose it is inevitable to use the data obtained from multiple sensors to gain
    more knowledge of the cultivation environment. The primary objective of this paper
    is to present an innovative Multisensor, Machine-Learning Approach (MMLA) to classify
    multi-sensor data before applying the fusion strategy to support high-quality
    data analysis in agricultural contexts for cultivation recommendation [11]. Thus
    accelerating the yield of crops, more specifically crop recommender systems. The
    correctness of the recommendation depends on the type and the amount of data fed.
    The main input here is the multisensor data sources; the way of collecting these
    data sources contributes to a major theme in the proposed framework. The frameworks
    discussed focus on the use of different machine learning algorithms to multi-sensor
    data. Popular machine learning algorithms such as J48 Decision Tree, Hoeffding
    Tree, and Random Forest. The performances of the three algorithms are measured
    based on their classification accuracy. The contributions of the paper are herewith
    described below: To investigate the combined use of multisensor data fusion with
    machine learning technique as a novel approach. To use popular machine learning
    algorithms such as the J48 Decision Tree, Hoeffding Tree, and Random Forest for
    classification. To analyze crop cultivation in terms of variety, season, and zone.
    To measure the performance of the algorithms in terms of Precision, Recall, F-measure,
    MCC, ROC area, and PRC area class. Identification of the best classification algorithm
    for multisensor data. To generate classification for eight agriculture crops,
    namely cotton, gram, groundnut, maize, moong, paddy, sugarcane, and wheat-based
    on the proposed recommendation system. Identifying the algorithm with the least
    error measure in classifying the agriculture text. A high accuracy measure can
    lead to a significant increase in the crop yield and avoids the wastage of seeds,
    time, and drastic loss in productivity, etc. Enhancing the multisensor data fusion
    approach by providing a recommendation of crop variety based on season and zone
    for cultivation. Finally, the multisensor data fusion strategy is applied for
    creating awareness in the condition-based environment monitoring system. The rest
    of the paper is organized as follows. Section II describes the various literature
    review related to this study; Section III presents the description of the proposed
    framework Multisensor, Machine-Learning Approach (MMLA) for Agriculture Context.
    Section IV presents the experimental results and discussions verifying the application
    performance. Finally, Section V presents the conclusion and future scope of the
    study. SECTION II. Related Works The experts concentrated primarily [12] on rice
    agriculture monitoring. The open-access Sentinel-1 C-band data that runs for a
    dense time series is used in this technique. The region under consideration is
    southern and southeast Asia. Rice is the main food crop in these areas. And these
    are grown when there is a lot of cloud cover during the rainy season. The photos
    were taken in Myanmar, which has heavy rice cropping throughout the crop year.
    Land cover map images from Sentinel-1, Landsat-8 OLI, and PALSAR-2 were fused
    and integrated. The random forest algorithm was used to further classify the data.
    With kappa statistics of more than 90%, approximately 186,701 km2 of cropland
    was considered. Thus, a phonological time series analysis was carried out, taking
    into account its dynamic range, inundation, and growth stages. Although the outcome
    was positive for assessing and monitoring rice production, it was only on a moderate
    scale, and more geographic region-based forecasting of production remains a challenge
    for food security solutions. Due to sensor imaging limitations, Siok [13] highlighted
    environmental studies and the need for techniques that combine data from different
    platforms. The authors combined multispectral aerial and satellite imagery to
    create a more spectrally accurate image. The primary objective is to process the
    image using segmentation and classification. The study took into account environmental
    factors such as soil, meadows, and forests. Pen sharpening is traditionally used
    to indicate spectral quality values with less distortion. Obtaining a high-quality
    image on a cloudy day is difficult. In this case, multi-sensor data fusion integrates
    various sensor data to produce enhanced images. Thus, the fusion process results
    in a partial loss of information while improving image spectral quality. This
    inspired the current study, which includes a multisensor data fusion technique.
    The authors assessed the accuracy [14] of the agriculture information monitoring
    system using a big data approach. Thus, the major challenges in crop analysis
    are identified. The Hadoop framework was used to handle massive amounts of agricultural
    data. The information considered includes crop types and soil content to improve
    productivity. Hadoop’s MapReduce programming was combined with the random forest
    algorithm. Agriculture datasets were initially collected and stored in the cloud.
    This is followed by the classification phase. It has been reported that, when
    compared to SVM, the random forest algorithm provides higher accuracy in agricultural
    data classification. This has prompted the current investigation into the random
    forest algorithm. Finally, the predicted results support the farmer in improving
    productivity. However, the authors state that forecasting agricultural productivity
    in terms of growth, atmospheric, and soil parameters for farmland remains a challenge.
    Another study used a mobile robot [15] to collect sensor data from agricultural
    scenes. The authors concentrated on recording repetitive, reflected, and burned
    images caused by sunlight and rough terrain in soybean fields. Although the recording
    was done for a large agricultural environment, there is a lack of texture. In
    addition, Han [4] concentrated on the agricultural sector’s aging and decreasing
    skilled labor. The authors emphasized the importance of automation and mechanization
    to maximize efficiency and reduce costs. Sensor technology advancements have accelerated
    the development of self-driving agricultural vehicles. Improving performance while
    taking into account a wide range of operating conditions remains a challenge in
    the agricultural environment. Sirsat concentrated on the soil’s reduced fertility
    [16]. Crop productivity can be predicted by evaluating the physical, chemical,
    and biological properties of the soil. The advancement of machine learning technologies
    has opened up new opportunities in agriculture and may aid in data evaluation
    for decision-making. The authors considered the state of Maharashtra’s Marathwada
    region. The soil in the area is made of scarlet, blackish, and yellowish basalt
    rock. The primary objective was to perform soil classification. Soil classification
    should increase productivity, prevent soil degradation, and mitigate environmental
    damage. Thus, the current study was motivated by the fact that increasing crop
    yield is a major challenge in solving the global food security problem. However,
    changing temperature and rainfall trends, insufficient water and light, agricultural
    practices, and nutrient deficiency all have a negative impact on soil quality
    and crop yield. Thus, forecasting to increase production for Indian agriculture
    is critical. Experts proposed a novel multisensor [17], multitemporal machine-learning
    approach to forecasting changes in water availability as well as the rise and
    fall of the Indus Civilization. The authors used a classifier algorithm to determine
    the region’s archaeological significance. Although the study presented a machine-learning
    approach, it is limited to detecting archaeological mounds. Katarya used various
    AI techniques [18] to increase crop yield. These algorithms take into account
    a variety of external factors such as meteorological data, temperature, and others
    such as soil profile and texture to provide the best recommendations that not
    only result in higher yields but also the most efficient use of resources and
    capital. However, focusing on soil properties and nutrients, which are important
    factors in crop recommendation, remains difficult. López and other experts [19]
    concentrated on the recommendation of new crops based on changing conditions.
    In this sense, having reliable decision-making tools and information is critical
    in adapting to new agricultural productivity scenarios. The preceding assumes
    having enough relevant data sources to reduce uncertainty in decision-making processes.
    When implementing a suitable solution to support data analysis tasks in agricultural
    contexts, data fusion tasks have been immersed in a variety of applications and
    approached from various points of view. Moreover, the multisensor data fusion
    strategy responds appropriately to agricultural-related queries. This has inspired
    the current study. Moreover, the authors emphasize that there is no single evaluation
    metric that is appropriate for all classification problems. The current study
    compared different classification models on a specific dataset and different metrics.
    Crop diseases are a serious problem in agriculture, as stated in [25]. This affects
    the quality of production. Technological advancements like sensors and artificial
    intelligence yield promising results. For this, the wide literature on the state-of-the-art
    machine learning techniques utilized in agriculture is discussed in [25]. The
    study examined the role of data fusion in disease identification. It has been
    observed that a surveillance system has been developed for grape disease using
    temperature and humidity sensors. Similarly, environment and soil information
    was extracted using SVM and the random forest algorithm, achieving an accuracy
    of 99.6% and 99.5%, respectively. However, it seems combining multiple data sources
    from different sensors remains a challenge. With data fusion techniques in agriculture
    remaining a challenge, there is a need for advanced models. According to their
    review, assessing healthy and diseased crops using machine learning techniques
    can provide better accuracy. Another study [26] performed precision irrigation
    management in water-limited regions using root zone soil moisture estimation.
    It has been pointed out that there are no accurate spatial resolutions. The technique
    combined optical reflectance with physical and hydraulic soil information using
    automated machine learning. Thus, it is evident that machine learning algorithms
    are capable of identifying complex relationships. The results concerning physical
    and hydraulic properties yielded an RMSE value of above 0.90. However, improving
    crop management remains a challenge. The use of intelligent flow meters is now
    widely used in society [27]. Despite its convenience, the privacy of public and
    industry data is exposed to high-security risks. Therefore, it has introduced
    a multi-sensor data fusion and AI-driven flow meter. However, stability and reliability
    are very low in changing environmental conditions. Thus, it requires the continuous
    progress of new AI technologies for its integration of sensor fusion, which is
    highly necessary. In [28], attempted to evaluate and compare the performance of
    various machine learning classifiers. The multiband input datasets from multiple
    sensor layers were utilized. The results showed improvement in spatial resolution;
    the accuracy for KNN was 75% and for Nave Bayes, 64%. However, the fusion of multiple
    sensor values with accuracy enhancement remains a challenge. Experts [29] proposed
    a deep learning method to perform semantic segmentation of fused data. The method
    combined texture and geometrical features. Further, the imbalance class was efficiently
    trained using 3D segmentation. The experiments showed that an unstructured and
    noisy point cloud achieved an accuracy of only 86.2%. However, the investigation
    of feature fusion under imbalanced class conditions needs to be addressed. In
    [30], the agricultural vulnerability due to climate change impacts were assessed.
    The processing, integration, and analysis require accurate and on-time responses.
    To address this study, researchers introduced a data fusion technique to identify
    crops. Climate, soil, and water quality were investigated. Multi-label learning
    and classification were performed based on binary relevance and random forest
    application, obtaining only 67% similarity. Although the results were acceptable,
    the use of predicted ranking to prove crop recommendations relevant to other constraints
    remain a challenge. Reference [31] investigated multisensory data fusion for rice
    disease detection. Changes in production affect the farmers, and early detection
    is necessary to ensure quality and an adequate supply. The dataset of 3200 categories
    was collected from sensors. The proposed rice model framework provided only an
    accuracy of 91.25%. Thus, from this wide literature on state-of-the-art machine
    learning techniques, it is evident that machine learning techniques with multi-sensor
    data fusion have been utilized in the agriculture domain to enhance the image
    quality of the data collected from agricultural scenes. Most of the authors have
    concentrated on images of agricultural fields. However, the forecasting of agricultural
    productivity in terms of growth, atmospheric, and soil parameters for farmland
    remains a challenge. And the presented work seems to be the first work on generating
    the classification for crops to provide a recommendation of crop variety based
    on season and zone for cultivation. Few of the experts applied a multisensor machine-learning
    approach to forecasting changes in water availability. Moreover, past researchers
    have emphasized that there is no single evaluation metric that is appropriate
    for all classification problems. According to their review, assessing agriculture
    issues using machine learning techniques can provide better accuracy and more
    reliable decision-making in adaptation to new agricultural productivity scenarios.
    Thus, the current study was motivated by this fact and tries to solve the global
    food security problem of increasing crop yield. SECTION III. Methodology The farming
    industry is changing as a result of the Internet of Things (IoT)-based events
    that reduce human labor. The use of specific sensors and software retrieves real
    data about soil, crops, and weather. Meeting the future demands of a growing population
    is challenging with limited resources. The sensors in the current study collect
    physical parameters and transmit them to the cloud [20]. As shown in Figure 1,
    the most important data sources are soil information, crop type, and weather patterns.
    The crop’s requirements vary depending on the land and weather conditions. FIGURE
    1. Data sources include the information collected from the air and soil. Show
    All For example, the non-contact of plant growth can be monitored using an infrared
    sensor. The sensor measures the plant height, width, and stem diameter for identifying
    growth. Further to this, the measured values are transmitted to the remote server
    using GSM technology. For instance, if an area space is considered, just by mapping
    the area to the object being detected the corresponding measurements can be calculated.
    Thus measuring the height, width, and stem diameter gets stored in the memory.
    In addition to this, the environmental conditions like temperature and humidity
    near the plant are recorded. Wireless nodes in agriculture are connected to tiny
    sensor devices. This node collects information from the air and soil, such as
    temperature, humidity, and moisture, and transmits it to the gateway node. The
    collected data is sent to a cloud platform for analysis. Before constructing the
    agricultural database, the collected data is subjected to multi-sensor fusion.
    Wireless nodes in agriculture are connected to tiny sensor devices. This node
    collects information from the air and soil, such as temperature, humidity, and
    moisture, and transmits it to the gateway node. Figure 2 depicts the proposed
    system framework. The multi-sensor data fusion technique is used here to combine
    information from multiple sensors to improve the accuracy of the results [21].
    This technique allows for the processing of a wide range of data. FIGURE 2. Multisensor,
    machine-learning approach (MMLA) framework for agriculture context. Show All The
    availability of a wide range of real-time information allows for the discovery
    of relationships between various types of data and the recognition of useful patterns
    [22]. The fusion process begins in the early stages. This significantly reduces
    the amount of noisy and incomplete data obtained from a single sensor. The important
    text must be identified before classification. These serve as attributes, and
    the pre-processing stage includes normalization and word removal. These are special
    characters, conjunctions, etc. Once pre-processed, the vector components represent
    the associated words and their weights [23]. The number of attributes (words)
    in the document remains high after pre-processing, and this high number of attributes
    is indicative of the classification problem. However, this large number of attributes
    is unnecessary because most of the words in the document do not describe them.
    As a result, it is critical to choose a subset comprised of the most significant
    terms. Furthermore, the text classification is performed based on three machine
    learning algorithms. Decision Tree, Hoeffding Tree, and Random Forest are the
    three types of trees. The text classification method organizes available information
    into appropriate categories in a systematic manner. The classification, in this
    case, is based on a three-class approach. These are the seasons, the varieties,
    and the recommended zone. A. Decision Tree Algorithm The most widely used data
    mining algorithm forecasts the target data based on the input. It allows for the
    classification of real-time data. The tree is then cultured and divided into subsets
    based on the attribute values tested. For each recursion, the process is repeated.
    This process is repeated until the split value no longer corresponds to the prediction
    [24]. It is a combination of mathematical and computational techniques. The tree
    used is the J48 classifier. This produces a binary tree. Once constructed, it
    is applied to each tuple in the database, resulting in classification. As a result,
    the attribute predicts the value of that item. B. Hoeffding Tree Algorithm The
    algorithm is based on decision trees as well as stream data classification. The
    tree selects an optimal splitting attribute based on a small sample size. It is
    based on the Hoeffding-bound theory. For instance, suppose there are N independent
    observations of a random variable r with a range of R, where r is a measure of
    attribute selection. Here, r represents information gain, and for r to be true,
    it must have at least r with probability 1, which is user-specified as expressed
    in equation (1). ϵ= R 2 ln 1 δ 2N − − − − − − √ (1) View Source Build ( ∗T ) {
    d=∅ d= Create (); //Creation of root node and label with split attribute d =Add
    art t For each split predicate and label; For each t do T=Create splitting T to
    predicate d ′ = Create leaf for the appropriate class Else d’=Td Built(T) d=add
    d ′ to t; } C. Random Forest Algorithm The random forest computes the mean decrease
    in classification accuracy to provide a criterion for each attribute. It is made
    up of a set of base classifiers. The random forest mathematical model is given
    as expressed in equation (2) {h(x,θk),k=1,2,….} (2) View Source Here x is the
    input variable and θk is the independently distributed random vector. The primary
    objective is to examine crop cultivation in terms of variety, season, and recommended
    zone. This will enable crop management and the matching of crop supply with demand,
    resulting in increased productivity. As a result, labor requirements in manual
    harvesting and handling operations are reduced. The study predicted recommended
    zones to help farmers choose the right crop and avoid losses in farming. Soil
    properties, such as the estimation of soil drying, condition, temperature, and
    moisture content, aid in understanding the dynamics of ecosystems and agricultural
    impingement. Accurate estimation leads to accurate analysis of a region’s climate
    change effects and eco-environmental conditions. Furthermore, the algorithms’
    performance was evaluated in terms of Precision, Recall, F-measure, MCC, ROC area,
    and PRC area. To obtain a higher accuracy measure and increase the crop yield
    the performance was evaluated in comparison to the different classification models.
    Recall (R) is the most widely employed machine learning metric that defines the
    measure of the “completeness” of the system as expressed in equation (3). If the
    recall is 100%, no prohibitions have been classified as obligations. R= tp tp+fp
    (3) View Source Precision (P) is another widely used metric that provides a measure
    of the “soundness” of the system. The precision decreases if the number of obligations
    misclassified as prohibitions increases as expressed in equation (4). P= tp tp+fn
    (4) View Source Finally, the F measure combines precision and recall to provide
    a single metric for algorithm comparison, as shown in equation (5). F= 2∗P∗R P+R
    (5) View Source SECTION IV. Results and Discussion This Section presents the text-based
    classification results. The classification was performed for eight crops, namely
    cotton, gram, groundnut, maize, moong, paddy, sugarcane, and wheat, based on the
    proposed recommendation system. The species of crops were classified using three
    machine learning algorithms J48 Decision Tree, Hoeffding Tree, and Random Forest
    algorithms. The study utilized the weka tool for machine learning algorithms to
    perform data preparation, classification, and visualization. Thus, fulfilling
    the objective of the proposed study, to identify the best classification algorithm
    for multi-sensor data. A. Data Collection The dataset for the study was collected
    in real-time using the smart agricultural monitoring and management platform as
    presented in Figure 2. The sensors provided measurements on soil, crops, and weather,
    this includes the physical parameters such as temperature, humidity, soil nutrients,
    growth in days, etc. The dataset comprises 85 classes with 6789 training data
    and 3210 testing data. The study was conducted for only the top eight classes
    to evaluate the performance of the proposed multi-text classifier. The performance
    of the classifier is measured in terms of precision, recall, F-measure, MCC, ROC
    Area, and PRC Area class, and the results are compared with the state-of-the-art
    classifiers. The classification results of the top eight agricultural crop classes
    are shown in Table 1. Precision, recall, F-measure, and MCC are all presented.
    In terms of precision, recall, F-measure, and MCC, the random forest algorithm
    outperform the other two algorithms, the J48 decision tree, and the Hoeffding
    tree. TABLE 1 Classification Results Figure 3 compares the precision of the three
    algorithms, the J48 decision tree, Hoeffding tree, and Random Forest, for the
    eight classes. The results show that the random forest algorithm outperforms the
    other two classifier algorithms. Cotton, gram, groundnut, maize, moong, paddy,
    sugarcane, and wheat have perfect precision when using the random forest algorithm.
    This demonstrates the effectiveness of the proposed method. For cotton, gram,
    groundnut, maize, moong, paddy, sugarcane, and wheat, the Hoeffding tree algorithm
    yields 100%, 75%, 80%, 100%, 100%, 100%, 100%, 100%, and 66.7%, respectively.
    Similarly, the cotton, gram, groundnut, maize, moong, paddy, sugarcane, and wheat
    values are 40%, 25%, 50%, 66.7%, 50%, 66.7%, and 50%, and 33.3 percent for the
    J48 decision tree. It has been discovered that the random forest algorithm works
    efficiently for multi-sensor data. FIGURE 3. Performance comparison-based on precision.
    Show All Figure 4 shows the recall comparison for the eight classes using the
    three algorithms J48 decision tree, Hoeffding tree, and Random Forest algorithms.
    The result shows that the random forest algorithm performs better than the other
    two classifier algorithms. The precision for cotton, gram, groundnut, maize, moong,
    paddy, sugarcane, and wheat using the random forest algorithm is 100%. This demonstrates
    the efficiency of the proposed approach. For the Hoeffding tree algorithm, it
    is 80%, 60%, 100%, and 100% for cotton, gram, groundnut, maize, moong, paddy,
    sugarcane, and wheat, respectively. Similarly, for the J48 decision tree, the
    values for cotton, gram, groundnut, maize, moong, paddy, sugarcane, and wheat
    are 80%, 40%, 40%, 20%, and 40%, 20%, and 50%, respectively. It is observed that
    the random forest algorithm works efficiently for multi-sensor data. FIGURE 4.
    Performance comparison-based on recall. Show All Figure 5 shows the F-measure
    comparison for the eight classes using the three algorithms as the J48 decision
    tree, Hoeffding tree, and Random Forest algorithms. The result shows that the
    random forest algorithm performs better than the other two classifier algorithms.
    The precision for cotton, gram, groundnut, maize, moong, paddy, sugarcane, and
    wheat using the random forest algorithm is 100%. This demonstrates the efficiency
    of the proposed approach. For the Hoeffding tree algorithm, it is 88.9%, 66.7%,
    80%, 88.9%, 88.9%, 75%, 100%, and 80% for cotton, gram, groundnut, maize, moong,
    paddy, sugarcane, and wheat respectively. Similarly, for the J48 decision tree,
    the values for gram, groundnut, maize, moong, paddy, sugarcane, and wheat are
    30.8%, 44.4%, 50%, 28.6%, 50%, 28.6%, and 40%. It is observed that the random
    forest algorithm works efficiently for multi-sensor data. FIGURE 5. Performance
    comparison-based on F-measure. Show All Figure 6 compares the MCC for the eight
    classes using three algorithms: the J48 decision tree, the Hoeffding tree, and
    Random Forest. The results show that the random forest algorithm outperforms the
    other two classifier algorithms. Cotton, gram, groundnut, maize, moong, paddy,
    sugarcane, and wheat have perfect precision when using the random forest algorithm.
    This demonstrates the effectiveness of the proposed method. Cotton, gram, groundnut,
    maize, moong, paddy, sugarcane, and wheat have 88.4 %, 63.8 %, 77.7 %, 88.4 %,
    88.4 %, 75.8 %, 100 %, and 79.5 % for the Hoeffding tree algorithm, respectively.
    Similarly, the cotton, gram, groundnut, maize, moong, paddy, sugarcane, and wheat
    values are 40%, 25%, 50%, 66.7 %, 50%, 66.7 %, 50%, and 33.33% for the J48 decision
    tree. It has been discovered that the random forest algorithm works well with
    multi-sensor data. Table 2 compares the results of the ROC and the PRC Area. It
    has been discovered that Random Forest produces the best crop classification results.
    TABLE 2 Comparative Results of ROC and PRC Area Class FIGURE 6. Performance comparison-based
    on MCC. Show All Table 3 presents the proposed recommendation system’s zone and
    variety-based results. Cotton crops of two varieties, i) CNH012, and ii) CICR-3,
    take 165 and 150 days, respectively, and are suitable for the zones of i) Gujarat,
    Maharashtra, and Madhya Pradesh, and ii) Punjab, Haryana, and Uttar Pradesh. The
    110-day-long gram varieties of I PKV Kabuli-4 and ii) CRIDALATHA are suitable
    for i) Maharashtra, Madhya Pradesh, and ii) other rain-fed regions in South India.
    Karnataka, Maharashtra, Jharkhand, and Manipur are among the states. HSCI, HQPM-4,
    and MCH-36 with a maturity period of 80–99 days are suitable for Kharif-affected
    states. Paddy varieties CR Dhan-401, CR Dhan-601, CR Dhan-501, IET 20193, and
    IET 19140 with maturities of 150, 160, 152, and 135 days are suitable for shallow
    rainfed conditions. Wheat varieties such as MPO 1215, MACS 6222, PDW 314, DBW39,
    and VL 907 are recommended for the various zones. Thus, crop variety recommendations
    based on zone and season are provided to raise awareness of the condition-based
    environmental monitoring system. Figures 7–9 show the classification based on
    variety, season, and recommendation zone. TABLE 3 Zones and Variety-Based Recommendation
    FIGURE 7. Classifications– variety. Show All FIGURE 8. Classifications– season.
    Show All FIGURE 9. Classifications– recommendation zone. Show All The error measure
    is depicted in Figure 10. The MAE, RMSE, RAE, and RRSE were used to evaluate the
    error measure. The MAE value for the J48 decision tree, Hoeffding tree, and Random
    Forest algorithm is 12%, 5%, and 7%, respectively. The RMSE values for the J48
    decision tree, Hoeffding tree, and Random Forest algorithm are 25%, 17%, and 13%,
    respectively. The J48 decision tree, Hoeffding tree, and Random Forest algorithm
    RAE values are 65.78 %, 29.03 %, and 38.67 %, respectively. Likewise, the RRSE
    values for the J48 decision tree, Hoeffding tree, and Random Forest algorithm
    are 82.55 %, 58.12 %, and 44.21 %, respectively. Random forest algorithms have
    the lowest error measures of 13%, 38.67%, and 44.21%, respectively. As a result,
    the random forest algorithm has the lowest error measure in classifying agricultural
    text. Thus, the use of a multisensor data fusion approach based on crop recommendation
    provides greater precision in prediction, resulting in a significant increase
    in crop yield while also raising awareness of the condition-based environment
    monitoring system. FIGURE 10. Comparison of error measure. Show All SECTION V.
    Conclusion Agriculture is a major sector of the Indian economy, and it is being
    impacted by changing temperature and rainfall patterns, a lack of water, and other
    poor agricultural practices. The current study assists farmers in making decisions
    about increasing crop production. Experiments on the benchmark dataset show that
    the random forest algorithm has the lowest error measure in classifying the agriculture
    text, with RMSE 13%, RAE 38.67%, and RRSE 44.21%. Thus, the use of a multisensor
    data fusion approach based on crop recommendation provides greater precision in
    prediction, resulting in a significant increase in crop yield while also raising
    awareness of the condition-based environment monitoring system. Future research
    should consider methods that take into account all parameters in the agricultural
    field to improve the prediction process. As a result, the random forest algorithm
    classifies the agricultural dataset with high accuracy and a low error rate. Authors
    Figures References Citations Keywords Metrics More Like This IoT-Enabled Crop
    Recommendation in Smart Agriculture Using Machine Learning 2023 14th International
    Conference on Information, Intelligence, Systems & Applications (IISA) Published:
    2023 AI-enabled Crop Health Monitoring and Nutrient Management in Smart Agriculture
    2023 6th International Conference on Contemporary Computing and Informatics (IC3I)
    Published: 2023 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase
    Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS
    PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA:
    +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE
    Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Accelerating Crop Yield: Multisensor Data Fusion and Machine Learning for
    Agriculture Text Classification'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Zhao W.
  - Wang M.
  - Pham V.T.
  citation_count: '6'
  description: The geospatial analysis provides high potential for modeling, understanding,
    and visualizing artificial and natural ecosystems, utilizing big data analytics
    and the Internet of things as a pervasive sensing infrastructure. Precision agriculture,
    weed control, fertilizer distribution, and field management benefit from unmanned
    ariel vehicles (UAVs). Reduced production costs and improved crop quality are
    some of the benefits of using this method. Smart farming denotes geographical
    data utilization to identify field variability, guarantee optimal inputs, and
    enhance a farm's output. Hence, in this paper, an IoT-assisted Smart Farming Framework
    (IoT-SFF) with big data analytics has been proposed using geospatial analysis.
    The use of wireless sensors in IoT devices and communication methods in agricultural
    applications is thoroughly examined. IoT sensors are available for particular
    agriculture applications, such as crop status, soil preparation, insect, pest
    detection, and irrigation scheduled. It is now possible to view our regions in
    various ways and make accurate agrotechnological decisions, thanks to a computer-generated
    geographic information system (GIS) for crop irrigation and monitoring. Analytical
    and monitoring processes that yield timely and accurate decision-making add value
    to big data, which is a key component for intelligently managing and operating
    farms. Still, it is constrained by both technical and socioeconomic variables.
    The simulation findings show that the proposed IoT-SFF model improves the crop
    yield ratio by 92.4%, prediction ratio by 97.7%, accuracy ratio by 94.5%, the
    average error by 38.3%, and low-cost rate by 34.4%.
  doi: 10.1155/2023/4213645
  full_citation: '>'
  full_text: '>

    "This website stores data such as cookies to enable essential site functionality,
    as well as marketing, personalization, and analytics. By remaining on this website
    you indicate your consent. Cookie Policy Journals Publish with us Publishing partnerships
    About us Blog Mobile Information Systems Journal overview For authors For reviewers
    For editors Table of Contents Special Issues Mobile Information Systems/ 2023/
    Article On this page Abstract Conclusion Data Availability Conflicts of Interest
    References Copyright Related Articles Special Issue Big Data-Driven Mobile IoT
    Intelligence View this Special Issue Research Article | Open Access Volume 2023
    | Article ID 4213645 | https://doi.org/10.1155/2023/4213645 Show citation Unmanned
    Aerial Vehicle and Geospatial Analysis in Smart Irrigation and Crop Monitoring
    on IoT Platform Wei Zhao,1Meini Wang ,2and V. T. Pham 3 Show more Academic Editor:
    R. Mo Received 08 Sept 2022 Revised 22 Sept 2022 Accepted 29 Sept 2022 Published
    20 Feb 2023 Abstract The geospatial analysis provides high potential for modeling,
    understanding, and visualizing artificial and natural ecosystems, utilizing big
    data analytics and the Internet of things as a pervasive sensing infrastructure.
    Precision agriculture, weed control, fertilizer distribution, and field management
    benefit from unmanned ariel vehicles (UAVs). Reduced production costs and improved
    crop quality are some of the benefits of using this method. Smart farming denotes
    geographical data utilization to identify field variability, guarantee optimal
    inputs, and enhance a farm’s output. Hence, in this paper, an IoT-assisted Smart
    Farming Framework (IoT-SFF) with big data analytics has been proposed using geospatial
    analysis. The use of wireless sensors in IoT devices and communication methods
    in agricultural applications is thoroughly examined. IoT sensors are available
    for particular agriculture applications, such as crop status, soil preparation,
    insect, pest detection, and irrigation scheduled. It is now possible to view our
    regions in various ways and make accurate agrotechnological decisions, thanks
    to a computer-generated geographic information system (GIS) for crop irrigation
    and monitoring. Analytical and monitoring processes that yield timely and accurate
    decision-making add value to big data, which is a key component for intelligently
    managing and operating farms. Still, it is constrained by both technical and socioeconomic
    variables. The simulation findings show that the proposed IoT-SFF model improves
    the crop yield ratio by 92.4%, prediction ratio by 97.7%, accuracy ratio by 94.5%,
    the average error by 38.3%, and low-cost rate by 34.4%. 1. Introduction of Smart
    Farming Using IoT and Big Data As a new term, “smart farming” refers to farm management
    that incorporates information technology with modern information and communication
    technologies, which increases production quantity and quality while optimizing
    the required human labor [ 1]. The objective of smart research in agriculture
    is to establish the farm management support decision-making system. Smart farming
    believes that population growth, climate change, and work must be resolved from
    planting and watering crops to health and harvesting [ 2]. This study aims to
    develop an IoT-based smart farming method for dealing with difficult situations
    by UAV. High-precision crop control and data collection can be achieved through
    the use of smart farming techniques for the optimization of irrigation and monitoring
    crops. An intelligent agricultural field monitoring system that measures soil
    moisture and temperature is presented here. The need to efficiently utilize natural
    resources, the growing use and sophistication of information and communication
    technologies, and the increasing demands of climate change make smart agriculture
    increasingly important [ 3]. Sustainable, smart farming methods lead to a greater
    diversity of feed, more efficient facilities for water preservation and drought-tolerant
    crops, and improved animal health. Farmers are leading advocates against climate
    change risks [ 4]. Geospatial analytics collect, manipulate, and display data
    and images, including GPS and satellite photographs, in geographic information
    systems (GISs) [ 5]. They are used to create geographical patterns and visualizations
    of data for more precise modeling and trend prediction [ 6]. Geospatial forecasting
    may help companies, due to shifting space environments or locality-based incidents,
    predict and plan future changes [ 7]. To avoid risk and disease using UAV, this
    smart farming sensor-based technology monitors water, monitors normal and dangerous
    animals through sensors, and saves and improves the farm’s production time, production
    costs, and health for irrigation and monitoring crops. Site-based testing may
    help politicians understand why strategies that succeed at one location frequently
    fail at another [ 8]. It helps to consider the adequacy of soil for different
    land-use practices, and it is important to avoid the degradation of the atmosphere
    in connection with land violence [ 9]. GIS promotes identifying soil types and
    the concept of soil borders in a region [ 10]. The combination of GPS and GIS
    allows data to be correctly obtained in real-time [ 11]. This helps farmers use
    mapping devices to chart the farm’s precise use of resources to improve water
    use and production [ 12]. Farmers can consider farmers’ site-specific needs using
    remote sensing, GPS, and GIS [ 13]. They can devise and execute management strategies
    with this knowledge that ensure the optimum utilization of inputs to optimize
    production and income [ 14]. GIS will analyze soil data to assess when and how
    to manage soil nutrients to support the plants’ growth. GIS has the potential
    to use plants [ 15]. GIS assists farmers in agriculture in increasing productivity
    and lowering costs by having better land resource management [ 16]. GIS encourages
    farmers in agriculture to boost productivity and cut costs by allowing enhanced
    land resource management [ 17]. Using Geomatics Technology Agricultural Geographical
    Information Systems, crops, precipitation, and temperatures can be mapped and
    forecasted by farmers [ 18]. Intelligent farming is a high-technology and capital-intensive,
    cleanly, and environmentally responsible food processing [ 19]. With an Internet
    of Things (IoT) sensors’ aid (light, humidity, temperature, and soil humidity)
    and an automatic irrigation device, a system is developed for IoT-based intelligent
    agriculture to track crop area [ 20]. The industry will improve operating efficacy,
    lower costs, minimize waste, and increase its returns in the latest applications
    in smart agriculture and precision IoT [ 21]. In addition to helping farmers conserve
    energy and water, IoT-based systems for precise cultivation often help make agriculture
    greener; they greatly reduce pesticide and fertilizer use [ 22] in contrast to
    conventional farming practices, obtaining a healthier and more organic end product
    [ 23]. Trade-in agricultural and food products can be supported by digital technologies
    based on UAV for optimizing irrigation, which open up new markets for private
    sector suppliers and give governments new tools for monitoring and ensuring standard
    compliance, as well as providing more rapid and efficient border procedures for
    crop monitoring, which is critical for agricultural foods. Big data can have an
    important effect on intelligent agriculture and the entire supply chain [ 24].
    Smart capabilities, data ownership and protection, and market models are the major
    concerns that need to be addressed in future research in order to harness the
    vast quantities of data that deliver unparalleled decision-making capabilities.
    The major contribution of the paper is as follows: (i) IoT-SFF is implemented
    to collect revenue from developed agricultural fields using UAVs (ii) Crop monitoring,
    irrigation, and agricultural requirements can all be better understood with the
    help of big data (iii) IoT-SFF can better plan out what crops they will be planting
    and harvesting times The rest of the paper structure is as follows: Section 1
    discusses the introduction of smart farming using UAV for irrigation and crop
    monitoring process, and Section 2 discusses literature works. In Section 3, IoT-SFF
    has been proposed for improved smart farming productivity. Finally, Section 4
    concludes the research paper. 2. Literature Works Saqib et al. [ 25] suggest smart
    farming applications using a low-cost information monitoring system. A low-data
    and low-cost solution are proposed to meet the necessity to track information
    on real, large-scale farmers. A small farm can be handled quickly. Measurement
    of sensor-based soil characteristics plays a central role in designing and delivering
    fully integrated agricultural farms. Remote sensing, global positioning, and geographic
    information systems can help farmers better understand the unique characteristics
    of their land. They can use these data to develop and commit to strategies that
    maximize their outcome and earnings by making the best use of their resources.
    Sarker et al. [ 26] discussed sustainable farm management and digital agriculture
    through big data. Although it is a long-term debate on the applicability of the
    big data technology in agriculture, it seeks to investigate how broad data technology
    leads to sustainable agriculture. The research shows many available large-scale
    agricultural technology and methods for addressing existing and potential problems
    on the ground. The study showed that big data technology, that is increasing in
    agriculture, is still relatively poor. The study indicates that the comprehensive
    introduction of agricultural big data technology calls for state programs, public-private
    collaborations, data transparency, financial commitments, and research work on
    a regional basis. Santos et al. [ 27] introduced a wireless sensor technology
    for cloud-based smart farming for crop production suitability. Agriculture plays
    a dominant role in the Philippines’ economic growth. With more than 6% of overall
    exports, a total of 25% is nonconstrained, and about 75% has several problem soils,
    such as steep slopes, low drainage, ground texture, hard cracking clays, extreme
    fertility constraints, acidic sulfate soils, featuring soils, mining tailing,
    and contaminated fields. Integration of the wireless sensor network (WSN) technology
    is required to measure soil’s moisture content, wetness, temperature, and pH,
    and evaluate its current geographic positions in 3D and 3,600 satellite views
    using the Global Position System (GPS). Farmers can use big data to get granular
    information on precipitation patterns, watercourses, fertilizer criteria, and
    many more. Knowing UAVs for optimizing irrigation when to plant and harvest certain
    crops can make more informed decisions about their business. As a result of the
    right decisions, farm yields will increase over time from crop monitoring. Munz
    et al. [ 28] explored the farm management information systems (FMIS) in Germany,
    exploring the characteristics and utilization. Agriculture digitization is one
    of Germany’s most ongoing trends today to address rising commercial, social, and
    ecological needs in the agriculture and food field. UAV for optimizing irrigation
    has already become a common practice in the agricultural sector, which uses ICT
    to collect, share, and analyze data from and within the various stakeholders and
    structures for crop monitoring at various stages. Based on defined characteristics
    and features, this paper aims to assign two stages of the digital evolution model
    to the “one-product” model. Trilles et al. [ 29] initialized cloud computing for
    smart farming and a microservices-based IoT platform. This paper suggests an agnostic
    architecture of IoT, which emphasizes the IoT platform’s role in a larger integrated
    environment to increase scalability, reliability, interoperability, and reusability.
    This idea is validated in the IoT scenario of intelligent agriculture, which deploys
    five IoT devices (SEnviro nodes) to improve wine production. A rigorous performance
    review guarantees a flexible, secure network. Maimaitijiang et al. [ 30] discussed
    smart farming and plant morphological characteristics, as well as grain policy
    and food production decisions, which can benefit greatly from nondestructive crop
    management over huge areas with high performance. In this study, the purpose was
    to assess the possibility of incorporating shade structure spectral data with
    a tree crown individual system for crop management using unmanned aerial vehicle
    (UAV) big data and advanced analytics. Sinha [ 31] deliberated the enhancing farmers’
    net benefit and aerial robot for smart farming. The developing, evaluating, and
    managing essential time and space factors for farming to optimize profitability,
    productivity, and environmental conservation is a time-consuming process of knowledge
    and new electronic technical advancement of the agricultural production system.
    In this respect, it may play an important function for the robot (aerial, land,
    and underwater). The existing constraints of aerial robot for the management of
    agricultural production are being discussed, and potential requirements and technology
    advancement recommendations are expected. Based on the survey, there are some
    challenges in the existing model. This paper proposes the IoT-SFF model to implement
    smart farming and improve productivity with geospatial analysis and big data to
    overcome these issues using UAVs for irrigation and crop monitoring process. Section
    3 discusses the proposed model briefly which is as follows. 3. IoT-Assisted Smart
    Farming Framework (IoT-SFF) This paper discussed the IoT-SFF model to enhance
    crop yield. Intelligent agricultural research aims to develop an agricultural
    management decision support system [ 32– 35]. Smart agriculture finds it appropriate
    to solve the population’s concerns, climate change, and labor from seed planting
    and watering to health and harvesting, which has attracted significant interest.
    Based on UAV applications for optimizing irrigation, chemicals and fertilizers
    are commonly used to increase the yield of genetically modified crops in conventional
    farming. Management levels are a key difference between precision farming and
    traditional farming. Small areas within fields are managed rather than the entire
    field as a whole. This increased management level highlights the need for crop
    monitoring practices. Geographic information system (GIS) [ 36, 37] is a technology
    that promotes current agricultural precision methods that ensure the agricultural
    analytics degree and GIS implementations. This research considers GIS applications
    such as land adaptability, site search, discovery, allocation of services, impact
    measurement, land allocation, and information systems. The Internet of things
    (IoT) gathers geographical information from multiple sources and thus creates
    connectivity through the Internet to the entire world. It has been reported that
    a UAV-enabled process for irrigation and crop monitoring for a wide range of salinity
    assessment methods have been utilized, including modern electrostatic EM38, electro-optic
    section, and particle micrograph techniques. The knowledge would help manage the
    land using the appropriate quantity of fertilizers at the correct place. Figure
    1 shows the application of GIS in smart farming. Food producers compete for land,
    water, and energy supplies and limit food production’s detrimental environmental
    effects. The modification moved manufacturers from conventional farming (CA) to
    precision farming (PA). PA is introduced to adapt the tractors and machines with
    GPS sensors for knowledge management [ 38– 40]. In the process of crop irrigation
    for UAV based on least squares, regression’s loss function is the MSE. RMSE, the
    squared loss function, from which MSE is derived, penalizes larger errors more
    severely because it is formulated for monitoring crops. The PA extension is the
    major driving force in big data analysis (BDA) agriculture. The key priority of
    PA is to collect, handle, and use data for decision-making. PA requires a range
    of synchronizing technology to capture and interpret data. Although Figure 1 shows
    the Geographic Positioning System (GPS), remote sensor (RS), and geomapping sensors,
    the environmental geography division studies the geographical distribution of
    agriculture and its influences and laws. The geographical distribution of agriculture
    is subject to a set of laws indicative of its life support system. From the process
    of crop irrigation for UAV and crop monitoring, the measurement of erosion can
    be done in one of four ways: (1) modification in mass, (2) modification in the
    atmospheric boundary layer, (3) transformation in channel flow, and (4) depositional
    collection from corrosion plot lines and water sources. Agricultural geography
    is a field of physical science that focuses on the spatial interactions between
    agriculture and humans. In other words, the study of the phenomena and results
    in various areas contribute to creating the planet’s top surface. Agricultural
    geographical maps reflect the distinction of the soil. They represent the ties
    between farming, nature, and economic conditions. Remote sensing provides soil
    humidity data, which helps measure soil moisture. Water resource mapping: remote
    sensing is important in mapping water supplies and can be used on a given piece
    of land for agriculture. The IoT is used in an agricultural environment to translate
    all elements and activities involved in agriculture into data through sensors,
    cameras, and other technologies. Big data provide farmers with granular data on
    precipitation levels, water cycles, and nutrient needs. This encourages them to
    make intelligent choices, such as cultivating and harvesting plants for better
    profitability. Ultimately the right choices raise agricultural yields. The production
    and execution of correct agriculture or site-specific agricultural practices have
    been enabled by integrating the Global Positioning System (GPS) and GIS. Millimeters
    (mm) per hour is the unit of measure for evapotranspiration. Water loss from a
    cropped area is measured using water depth units. Time can be measured in terms
    of an hour, a day, a decade, a month, or even an entire growing year in UAV for
    optimization and crop monitoring. In poor visibility field conditions, GPS helps
    farmers operate, for example, in mud, gravel, fog, and darkness. The VRT technology
    permits the application of fertilizers, pesticides, calcium, rinsing water, drainage,
    and other agricultural inputs at varying rates around the field without increasing
    the rate on machines manually or making multiple crossings [ 41, 42].    Figure
    1  Application of GIS in smart farming. 3.1. Case 1: Big Data-Based Smart Farming
    Figure 2 shows the big data and GIS-based smart farming. Due to its unique capacity
    to visually reflect data, descriptive GIS analytics, tools, and applications can
    execute effective research with elaborated knowledge and transparency. Data filtering
    methods increase productivity. As of now, it is assisting in the analysis of decades’
    worth of climate and crop data, looking for trends that will allow farmers to
    forecast better crop yields and use UAV-enabled processes for irrigation and crop
    monitoring. Data extraction in farming operations can now benefit from the predictive
    capabilities generated by large datasets, as well as the proper operating decisions
    and process redesigns that these datasets allow, all thanks to the development
    of game-changing marketing strategies. Increased farm productivity, commercial
    viability, and stronger economic ties are part of agricultural development. There
    are a few key areas where agricultural change needs to be prioritized under transformation.
    The GIS analytics deals with internal device problems daily using spatial online
    analytical processing or surface-down approaches to assess soil and water consistency
    by implementing surface energy balance applications for soil and digital image
    processing. The economic and environmental efficiency of precision farming is
    assessed using pattern analysis to estimate the evapotranspiration rate needed
    for soil salination assessment. RS data are used for long-term acquisition, validation,
    and calculation of parameters to explain land cover change and measure soil erosion
    using unmanned area vehicles for optimization and crop monitoring. The topographic
    shuttle radar mission data serve as a baseline for testing the landscape characteristics.
    Agricultural greenhouse gas emissions are studied using economic and environmental
    models. GIS analytics uses hardware and programming to identify graphic and predictive
    trends within data and is primarily used to model future events. Various predictive
    analytics have been used, such as database mining, text mining, and forecasting.
    An adequate prediction approach is developed for the risks and uncertainty of
    supply chains for agriculture [ 43– 45]. The crop monitoring uses spatial online
    analytical processing or surface-down approaches to assess soil and water consistency
    by implementing surface energy balance applications for soil and digital image
    processing in the GIS. UAV for optimizing irrigation is used to estimate the evapotranspiration
    rate required for soil salinity assessment in precision farming. The cost is minimized,
    and farmers and other interested parties are likely to obtain highly accurate
    knowledge of climate prediction and take advantage of favorable weather. In this
    analysis, we categorize GIS analyses’ particular applications. The predictive
    GIS analytics applications is categorized into water/irrigation, soil, plant/agricultural,
    and fertilization systems.    Figure 2  Big data and GIS-based smart farming.
    Further experiments in water/irrigation and crops and agricultural systems have
    been carried out. Predictive GIS analytics are used when the data are forwarded
    to the spatially complex event processing engine after filtering and reprocessing.
    Figure 3 shows the average error. The typical day of data gathered from different
    sensors is processed as part of the data preprocessing in the cloud network. The
    mean of the data is considered since it may include missing and noisy values.
    Since the data include multiple measuring units (categorical and numerical), standardization
    is carried out before using the proposed model. In addition to the aforementioned
    micromeasures and macromeasures, the resulting method defines the error as root
    mean squared error (RMSE) and mean squared error (MSE). GIS, or geographic information
    systems, is a relatively new field of study in the information technology in unmanned
    area vehicles for optimization and crop monitoring. Natural resources used in
    food production, such as land, weather, hydrogeology, and a wide range of socioeconomic
    factors, can now be examined and analyzed with greater ease. To transmit data
    to GPS receivers on the ground, satellites in orbit around the Earth are used.
    Geographic information systems (GIS) are computer programs that make it possible
    to use data collected by GPS satellites.    Figure 3  Average error. Nevertheless,
    it should be noted that during testing, the stochastic descent of gradients does
    not require MSE or RMSE. Rather, the error term is expected between an altered
    sample and its prediction for big data nodes’ weights. MSE and RMSE determine
    the average model absorption error as Here, is the overall number of data samples,
    is the target and th instance, and is the output or product of the learning model’s
    th data instance. Figure 4 shows the ratio for prediction. Decision-making calls
    for accurate information from sensor results. The big data from the sensor provide
    learning opportunities in a continuously evolving climate. Such decision-making
    can be short-term, medium-term, or long-term. When those requirements are met,
    automatic decisions from big data may be taken that require little to no human
    involvement. These automatic decisions could vary from temperature management
    to water supply control irrigation systems. Geospatial analysis and the agriculture
    stick are combined in this paper. It can be accessed electronically via a mobile
    phone and combined with various sensors and live data streams in unmanned area
    vehicles for optimization and crop monitoring. Testing on actual farmland ensures
    that the data feeds are accurate in various soil conditions. The use of big data
    in greenhouses will lead to the identification of ideal conditions for crop cultivation
    by observing data from the sensors on nutrients, yield, growth, perspiration,
    color, taste, transplantation, levels of light pest temperatures, and air quality.
    The precision, conciseness, completeness, and timeliness of data are critical.
    Several programs have been developed to enable farmers to decide on farms and
    animals in a cultivated way.    Figure 4  Ratio for prediction. 3.2. Case 2: IoT-Based
    Smart Farming Figure 5 shows the IoT-based effective communication in agriculture.
    Smart agriculture based on IoT sensors monitors the environmental state of fields,
    soil, and crop development for professionals and growers. Sensors, drones, satellite
    systems, GPS systems, actuators, gateways, cloud servers, the Internet, and android
    cell phones are all part of the smart farming system. The actuator provides the
    central coordinator’s response to an order, which powers the driving systems in
    smart farming in crop irrigation for UAV and crop monitoring. A central coordinator
    measures ground moisture and the actuators based on agricultural field sensor
    readings. The presented software and hardware led to the progress of these innovations
    in crop production. Big data, practical guidance, and recommendations from online
    expert guidance systems for farmers, pests, and disease management are described
    in [ 46, 47].    Figure 5  IoT-based effective communication in agriculture. Figure
    6 shows the crop yield level. The IoT-enabled precision farming technology ensures
    that farm efficiency increases and demand grows to satisfy the growing population’s
    food requirements. Surface-down approaches to assess soil and water consistency
    by implementing surface energy balance applications for soil and digital image
    processing are two ways GIS analytics which are used daily to solve internal device
    issues. To prevent soil salinization, farmers use UAVs to monitor crops and analyze
    irrigation patterns to determine the evapotranspiration rate. Using IoT to boost
    weather consistency influences crop yields greatly, and one-way IoT has a positive
    effect on yield. The higher the precision it achieves, the less likely the crop
    will be damaged by unexpected circumstances, thus improving productivity. A connected
    farm IoT network has been conducted and found to increase yields by decreasing
    energy costs per acre for the average farm with IoT-enabled technology and water
    usage for irrigation. Food farmers drench their crops, limiting growth and yield
    and increasing the probability that fungal diseases emerge in the soil. Water
    can be processed, and overwatering challenges are avoided when the farmer has
    access to the data. It may indicate whether irrigation is inadequate and needs
    to be increased to optimize cultivation output. There are two types of formats
    stored: organized and curated. These are based on the smart farming analytics
    (SFA) data model. Here, the analytical system finds its reference point for reality
    in UAVs for optimization and crop monitoring. Files in the raw zones must be removed
    until new data is placed here to avoid undesirable outcomes. There are two types
    of zones: those containing raw data and those containing processed data.    Figure
    6  Crop yield level. Figure 7 shows the water management system based on big data
    and IoT. In several areas of agriculture, IoT is now a feasible database. A study
    has been conducted to use big data to tackle the large volume of data in many
    agriculture fields. The formats are stored based on the smart farming analytics
    (SFA) data model and include organized and curated data. This region becomes the
    analytical system’s center of reality. The files placed under the raw zones should
    be removed until data are brought into this zone to avoid results. Based on unmanned
    aerial vehicles for irrigation and crop monitoring, the six steps of multicriteria
    decision-making include the following: (1) formulation of the problem, (2) identifying
    the necessities, (3) setting goals, (4) identifying various alternatives, and
    (5) developing criteria. Verifications of QC and “farming” laws are made at the
    tables. We provide a single source of truth/access to all main key performance
    indicators (KPI) for agricultural research. Data are saved in a format that data
    scientists and data visualization software can process. Promoting healthy water-based
    relations between biophysical and human processes and maintaining water control
    to minimize water leakage and recommend emergency measures. The water pressure
    is within acceptable bounds based on the analysis and simulation of water use
    patterns. They gather this knowledge, called historical usage data, and offer
    other data that can be used to predict the potential consumption of water. Multicriteria
    decision analyses are used in the prescriptive GIS analysis to gather knowledge
    about large and complex datasets in crop irrigation for UAV and crop monitoring.
    The MCDA method has been the method of choice for most researchers in their quest
    to identify the most important factors affecting agricultural productivity. Smart
    water dripping for farmers can help the automatic and productive use of soil-based
    irrigation methods based on soil temperature. The approach includes integrating
    smart farming big data technology into the next granularity stage, offering an
    infrastructure tailored to fulfill the SFA criteria for smart farm analytics.    Figure
    7  Water management system based on big data and IoT. GIS analytics are used daily
    to solve internal device issues using spatial online analytical processing or
    surface-down approaches to assess soil and water consistency by implementing surface
    energy balance applications for soil and digital image processing in Figure 8.
    Farming with precision is evaluated using UAVs in crop monitoring and irrigation
    pattern analysis to determine the evapotranspiration rate required to prevent
    soil salinization. The suggested approach includes multiple data sources, data
    modeling, elements of applications, and technological limitations in UAVs. Our
    proposal for enhancing the efficiency of the work schedule, mastering the quality
    of the data from smart farms, and including the irrigation systems to promote
    agriculture is still being worked on.    Figure 8  Crop monitoring ratio. Figure
    9 shows the IoT-based smart farming. The earliest accuracy relied on satellites
    to pass seed knowledge to a central hub. Wi-Fi is available to link data directly
    to a farmer’s smartphone from on-site instruments. Many farms that use precise
    farming use mesh networks that send Wi-Fi signals over several acres. Agriculture’s
    key performance indicators (KPIs) stay updated on feed consumption for irrigation
    and monitoring, production, and costs in the UAV process. Agriculture and its
    output are impacted by making more money and being more productive. Time is money
    when it comes to farming programs based on IoT features. In the measurement of
    gain and loss, computers are used as records for the cost of manufacturing, shipping,
    farm processing, and details. The Internet allows farmers and traders to connect
    with experts in agriculture. In the cloud database, the storage of soil and water
    resources data and the network management of farm data are realized. In the agriculture
    knowledge system, multilevel decision-making information and climate growth are
    important. Developers may use this platform to visually determine how APIs function,
    the quantity and consistency of data, request processing speed, and resources’
    availability. The dashboard makes getting actual samples, which IoT offers via
    our agricultural applications, easier to enlighten rural areas, service water
    pumps, and run the computer system and telecommunications.    Figure 9  IoT-based
    smart farming. Figure 10 shows the accuracy ratio. A lack of awareness of the
    importance of climate in agriculture can significantly impact crop production
    and efficiency. However, when it comes to the Internet of things (IoT), it is
    possible to monitor the situation in real-time accuracy ratio irrigation and monitoring
    of crops using UAV. In and out of the agricultural sector, sensors have been installed
    to select the best cultivars for various climates, using environmental data. Environmental
    sensors, such as those measuring moisture, rainfall, temperature, and other variables
    in real-time, make up the IoT ecosystem. Many sensors are needed to monitor and
    optimize all of these parameters to serve the needs of smart farming. In adverse
    weather conditions, the need for human intervention increases productivity and
    yields greater returns on investment for farmers.    Figure 10  Accuracy ratio.
    Figure 11 shows the cost ratio. The invention of numerous IoT-based devices for
    intelligent farming transforms every day, leading to crop production by enhancing
    it, reducing waste, and making it cost-effective. This paper is intended for farmers
    to generate live data on temperature and soil moisture. Other variables for accurate
    environmental monitoring are to improve their total production and the quality
    of products. In utilizing the UAV process for irrigation and monitoring, the robotics
    in farming GIS can provide accurate maps that include all the necessary information
    about crops in the field. Task maps and application maps are examples of task
    maps by precision methods that will use them to maintain the field. This paper
    combines the agriculture stick with geospatial analysis, and it can be accessed
    electronically by mobile telephone and combined with different sensors and live
    data stream. The proposed product is tested on live farming fields to ensure high
    precision in data feeds in various soil circumstances.    Figure 11  Cost ratio.
    In the prescriptive GIS analysis, statistical algorithms , simulations , and multipronged
    decision analyses are used to collect knowledge of high-volume and complex data
    in crop irrigation for UAVs and crop monitoring with values obtained using binomial
    equations (2) and (3) with trigonometric values. For the most part, researchers
    have turned to the MCDA method when attempting to pinpoint critical variables
    that influence agricultural productivity. The UAV process in irrigation and crop
    monitoring can collect operational data and impact operations more than manual
    practices shown in Figure 12. As a result, the use of robots in manufacturing
    can be further reduced, and the accuracy and effectiveness of the inputs to the
    operation can increase. Agriculture is transforming with UAV is a term used to
    describe the ability of physical devices to communicate with each other over the
    Internet. With an IoT, devices all over a farm can collect data remotely and send
    it to the farmworker in real-time for crop irrigation and monitoring activities.    Figure
    12  UAV in irrigation ratio. The proposed model is analyzed using sample smart
    farming implementation to measure various parameters and achieve high crop yield,
    accuracy ratio, prediction ratio, low cost, and average error; automation of greenhouses,
    crops, cattle, and livestock monitoring and management; farming with precision,
    smart farming with drones, and predictive analytics; systems for the complete
    management of a farm are examples of devices used with UAV-enabled processes for
    irrigation and crop monitoring. 4. Conclusion This paper discussed the IoT and
    big data based smart farming technology to improve crop production. Hence, this
    paper proposed the IoT-SFF with GIS analysis to increase crop yield and fertilize
    inland smart agriculture. UAV-enabled irrigation and crop monitoring process can
    get information on soil moisture using remote sensing. This information is then
    used to determine the crops grown in the area. Farmers can use this information
    to determine how much water their soil needs by comparing its moisture content
    with other soils. The Internet of things (IoT) is illuminating agricultural management
    in a big way, which is why smart farming is becoming increasingly important. Sensors,
    power transmission, and feelings all contribute to the generation of enormous
    amounts of data. Big data tracking, evaluation, and value stream from such big
    data are crucial for smartly coordinating and managing farms. Even though this
    research, IoT-SFF, is focused on the existence in agricultural production of big
    data technology, IoT, and data management in the context of agriculture, these
    constraints are relevant to this research. This IoT-SFF recognizes large-scale
    analysis to play a major role in enhancing the efficiency of GIS implementation.
    In farms, the Internet of things enables the system across a farm to collect and
    transmit real-time data on a wide range of metrics to the farmer. Moisture content,
    contaminant application, dam thresholds, livestock wellbeing, irrigation, and
    monitoring can all be monitored by UAV devices, which can then be used to monitor
    barricades, automobiles, and snow conditions. They provide researchers, agriculture
    experts, and officials with recommendations for efficient management of large
    GIS data to increase farm productivity. The simulation findings show that the
    proposed IoT-SFF model improves crop yield ratio by 92.4%, prediction ratio by
    97.7%, accuracy ratio by 94.5%, average error by 38.3%, and low-cost rate by 34.4%.
    Data Availability The dataset used to support the findings of the study is available
    from the corresponding author upon request. Conflicts of Interest The authors
    declare that they have no conflicts of interest. References A. Vangala, A. K.
    Das, N. Kumar, and M. Alazab, “Smart secure sensing for iot-based agriculture:
    blockchain perspective,” IEEE Sensors Journal, vol. 21, no. 16, pp. 17591–17607,
    2021. View at: Publisher Site | Google Scholar V. Higgins and M. Bryant, “Framing
    agri‐digital governance: industry stakeholders, technological frames and smart
    farming implementation,” Sociologia Ruralis, vol. 60, no. 2, pp. 438–457, 2020.
    View at: Publisher Site | Google Scholar P. K. R. Maddikunta, S. Hakak, M. Alazab
    et al., “Unmanned aerial vehicles in smart agriculture: applications, requirements,
    and challenges,” IEEE Sensors Journal, vol. 21, no. 16, p. 1, 2020. View at: Publisher
    Site | Google Scholar N. Tantalaki, S. Souravlas, and M. Roumeliotis, “Data-Driven
    decision making in precision agriculture: the rise of big data in agricultural
    systems,” Journal of Agricultural & Food Information, vol. 20, no. 4, pp. 344–380,
    2019. View at: Publisher Site | Google Scholar K. Sekaran, M. N. Meqdad, P. Kumar,
    S. Rajan, and S. Kadry, “Smart agriculture management system using internet of
    things,” Telkomnika, vol. 18, no. 3, pp. 1275–1284, 2020. View at: Publisher Site
    | Google Scholar D. S. Bullock, M. Boerngen, H. Tao et al., “The data‐intensive
    farm management project: changing agronomic research through on‐farm precision
    experimentation,” Agronomy Journal, vol. 111, no. 6, pp. 2736–2746, 2019. View
    at: Publisher Site | Google Scholar T. C. Hsu, H. Yang, Y. C. Chung, and C. H.
    Hsu, “A Creative IoT agriculture platform for cloud fog computing,” Sustainable
    Computing: Informatics and Systems, vol. 28, Article ID 100285, 2018. View at:
    Publisher Site | Google Scholar A. Anwer and G. Singh, “Geo-spatial technology
    for plant disease and insect pest management,” Bulletin of Environment, Pharmacology
    and Life Sciences, vol. 8, no. 12, pp. 1–12, 2019. View at: Google Scholar M.
    W. Convolbo, J. Chou, C. H. Hsu, and Y. C. Chung, “GEODIS: towards the optimization
    of data locality-aware job scheduling in geo-distributed data centers,” Computing,
    vol. 100, no. 1, pp. 21–46, 2018. View at: Publisher Site | Google Scholar M.
    S. Farooq, S. Riaz, A. Abid, K. Abid, and M. A. Naeem, “A survey on the role of
    IoT in agriculture for the implementation of smart farming,” IEEE Access, vol.
    7, pp. 156237–156271, 2019. View at: Publisher Site | Google Scholar K. T. Liu,
    S. J. Chang, and S. Wu, “Fabrication and characterization of GaN ultraviolet photodetector
    prepared by growing on geometrical patterned sapphire substrate,” in Proceedings
    of the 2016 International Conference on Advanced Materials for Science and Engineering
    (ICAMSE), pp. 401–403, IEEE, Tainan, Taiwan, November 2016. View at: Google Scholar
    A. T. Balafoutis, F. K. V. Evert, and S. Fountas, “Smart farming technology trends:
    economic and environmental effects, labor impact, and adoption readiness,” Agronomy,
    vol. 10, no. 5, p. 743, 2020. View at: Publisher Site | Google Scholar F. Farivar,
    M. S. Haghighi, A. Jolfaei, and M. Alazab, “Artificial intelligence for detection,
    estimation, and compensation of malicious attacks in nonlinear cyber-physical
    systems and industrial IoT,” IEEE Transactions on Industrial Informatics, vol.
    16, no. 4, pp. 2716–2725, 2020. View at: Publisher Site | Google Scholar P. Paul,
    P. S. Aithal, A. Bhuimali, and T. Kalishankar, “Environmental informatics vis-à-vis
    big data analytics: the geo-spatial & sustainable solutions,” International Journal
    of Applied Engineering and Management Letters (IJAEML), vol. 4, no. 2, pp. 31–40,
    2020. View at: Google Scholar A. Kumari, S. Tanwar, S. Tyagi, N. Kumar, M. Maasberg,
    and K. K. R. Choo, “Multimedia big data computing and Internet of Things applications:
    a taxonomy and process model,” Journal of Network and Computer Applications, vol.
    124, pp. 169–195, 2018. View at: Publisher Site | Google Scholar A. Wąs, P. Sulewski,
    E. Majewski, and P. Kobus, “Use of big data for assessment of environmental pressures
    from agricultural production,” in Management in the Era of Big Data, pp. 137–152,
    Auerbach Publications, Boca Raton, Fla., USA, 2020. View at: Google Scholar S.
    Garg, K. Kaur, N. Kumar, G. Kaddoum, A. Y. Zomaya, and R. Ranjan, “A hybrid deep
    learning-based model for anomaly detection in cloud datacenter networks,” IEEE
    Transactions on Network and Service Management, vol. 16, no. 3, pp. 924–935, 2019.
    View at: Publisher Site | Google Scholar A. Kirkaya, “Smart farming-precision
    agriculture technologies and practices,” Journal of Scientific Perspectives, vol.
    4, no. 2, pp. 123–136, 2020. View at: Publisher Site | Google Scholar K. Kaur,
    S. Garg, G. Kaddoum, F. Gagnon, N. Kumar, and S. H. Ahmed, “An energy-driven network
    function virtualization for multi-domain software defined networks,” in Proceedings
    of the IEEE INFOCOM 2019-IEEE Conference on Computer Communications Workshops
    (INFOCOM WKSHPS), pp. 121–126, IEEE, Paris, France, April 2019. View at: Google
    Scholar A. Farouk, J. Batle, M. Elhoseny et al., “Robust general N user authentication
    scheme in a centralized quantum communication network via generalized GHZ states,”
    Frontiers of Physics, vol. 13, no. 2, Article ID 130306, 2018. View at: Publisher
    Site | Google Scholar K. G. Orjuela, P. A. Gaona-García, and C. E. M. Marin, “Towards
    an agriculture solution for product supply chain using blockchain: case study
    Agro-chain with BigchainDB,” Acta Agriculturae Scandinavica Section B Soil and
    Plant Science, vol. 71, pp. 1–16, 2020. View at: Publisher Site | Google Scholar
    S. Sankar, P. Srinivasan, A. K. Luhach, R. Somula, and N. Chilamkurti, “Energy-awaregrid-based
    data aggregation scheme in routing protocol for agricultural internet of things,”
    Sustainable Computing: Informatics and Systems, vol. 28, Article ID 100422, 2020.
    View at: Publisher Site | Google Scholar P. Hemalatha, K. Dhanalakshmi, S. Matilda,
    and M. BalaAnand, “Farmbot-a smart agriculture assistor using internet of things,”
    International Journal of Pure and Applied Mathematics, Special Issue, vol. 119,
    no. 10, pp. 557–566, 2018. View at: Google Scholar S. Balamurugan, B. A. Muthu,
    S. L. Peng, and M. H. A. Wahab, “Call for special issue papers: big data analytics
    for agricultural disaster management: deadline for manuscript submission: december
    12, 2020,” Big Data, vol. 8, no. 5, pp. 450-451, 2020. View at: Publisher Site
    | Google Scholar M. Saqib, T. A. Almohamad, and R. M. Mehmood, “A low-cost information
    monitoring system for smart farming applications,” Sensors, vol. 20, no. 8, p.
    2367, 2020. View at: Publisher Site | Google Scholar M. N. I. Sarker, M. S. Islam,
    M. A. Ali, M. S. Islam, M. A. Salam, and S. H. Mahmud, “Promoting digital agriculture
    through big data for sustainable farm management,” International Journal of Innovation
    and Applied Studies, vol. 25, no. 4, pp. 1235–1240, 2019. View at: Google Scholar
    M. D. Santos, L. L. Lacatan, and F. G. Balazon, “Cloudbased smart farming for
    crop production suitability using wireless sensor technology,” Test Engineering
    and Management, vol. 81, no. 11-12, pp. 5043–5052, 2019. View at: Google Scholar
    J. Munz, N. Gindele, and R. Doluschitz, “Exploring the characteristics and utilisation
    of farm management information systems (FMIS) in Germany,” Computers and Electronics
    in Agriculture, vol. 170, Article ID 105246, 2020. View at: Publisher Site | Google
    Scholar S. Trilles, A. González-Pérez, and J. Huerta, “An IoT platform based on
    microservices and serverless paradigms for smart farming purposes,” Sensors, vol.
    20, no. 8, p. 2418, 2020. View at: Publisher Site | Google Scholar M. Maimaitijiang,
    V. Sagan, P. Sidike, A. M. Daloye, H. Erkbol, and F. B. Fritschi, “Crop monitoring
    using satellite/UAV data fusion and machine learning,” Remote Sensing, vol. 12,
    no. 9, p. 1357, 2020. View at: Publisher Site | Google Scholar J. P. Sinha, “Aerial
    robot for smart farming and enhancing farmers’ net benefit,” Indian Journal of
    Agricultural Sciences, vol. 90, no. 2, pp. 258–267, 2020. View at: Publisher Site
    | Google Scholar T. Qureshi, M. Saeed, K. Ahsan, A. A. Malik, E. S. Muhammad,
    and N. Touheed, “Smart agriculture for sustainable food security using internet
    of things (IoT),” Wireless Communications and Mobile Computing, vol. 2022, Article
    ID 9608394, 10 pages, 2022. View at: Publisher Site | Google Scholar K. N.-E.-A.
    Siddiquee, Md. S. Islam, N. Singh et al., “Development of algorithms for an IoT-based
    smart agriculture monitoring system,” Wireless Communications and Mobile Computing,
    vol. 2022, Article ID 7372053, 16 pages, 2022. View at: Publisher Site | Google
    Scholar L. H. Li, J. C. Hang, and Y. Gao, “Using an integrated group decision
    method based on SVM, TFN-RS-AHP, and TOPSIS-CD for cloud service supplier selection,”
    Mathematical Problems in Engineering, vol. 2017, Article ID 3143502, 14 pages,
    2017. View at: Publisher Site | Google Scholar Y. Li and L. H. Li, “Enhancing
    the optimization of the selection of a product service system scheme: a digital
    twin-driven Framework,” STROJNISKI VESTNIK-JOURNAL OF MECHANICAL ENGINEERING,
    vol. 66, no. 9, pp. 534–543, 2020. View at: Publisher Site | Google Scholar L.
    H. Li and H. G. Wang, “A VVWBO-BVO-based GM (1,1) and its parameter optimization
    by GRA-IGSA integration algorithm for annual power load forecasting,” PLoS One,
    vol. 13, no. 5, Article ID e0196816, May. View at: Publisher Site | Google Scholar
    J. Tian, D. Li, and X. Jia, “IoT smart agriculture and agricultural product income
    insurance participant behavior based on fuzzy neural network,” Computational Intelligence
    and Neuroscience, vol. 2022, Article ID 4778975, 12 pages, 2022. View at: Publisher
    Site | Google Scholar E. Ramirez-Asis, A. Bhanot, V. Jagota et al., “Smart logistic
    system for enhancing the farmer-customer corridor in smart agriculture sector
    using artificial intelligence,” Journal of Food Quality, vol. 2022, Article ID
    7486974, 8 pages, 2022. View at: Publisher Site | Google Scholar L. Li, C. Mao,
    H. Sun, Y. Yuan, and B. Lei, “Digital twin driven green performance evaluation
    methodology of intelligent manufacturing: hybrid model based on fuzzy rough-sets
    AHP, multistage weight synthesis, and PROMETHEE II,” Complexity, vol. 2020, no.
    6, Article ID 385392, 24 pages, 2020. View at: Publisher Site | Google Scholar
    L. Li, J. Hang, H. Sun, and L. Wang, “A conjunctive multiple-criteriadecision-making
    approach for cloud service supplier selection of manufacturing enterprise,” Advances
    in Mechanical Engineering, vol. 9, no. 3, Article ID 168781401668626, 2017. View
    at: Publisher Site | Google Scholar K. Phasinam, T. Kassanuk, P. P. Shinde et
    al., “Application of IoT and cloud computing in automation of agriculture irrigation,”
    Journal of Food Quality, vol. 2022, Article ID 8285969, 8 pages, 2022. View at:
    Publisher Site | Google Scholar A. H. Adow, M. K. Shrivas, H. F. Mahdi et al.,
    “Analysis of agriculture and food supply chain through blockchain and IoT with
    light weight cluster head,” Computational Intelligence and Neuroscience, vol.
    2022, Article ID 1296993, 11 pages, 2022. View at: Publisher Site | Google Scholar
    L. Li, B. Lei, and C. Mao, “Digital twin in smart manufacturing,” Journal of Industrial
    Information Integration, vol. 26, no. 9, Article ID 100289, 2022. View at: Publisher
    Site | Google Scholar R. Sharma, S. Rani, and S. J. Nuagh, “RecIoT: a deep insight
    into IoT-based smart recommender systems,” Wireless Communications and Mobile
    Computing, vol. 2022, Article ID 9218907, 15 pages, 2022. View at: Publisher Site
    | Google Scholar L. Li, T. Qu, Y. Liu et al., “Sustainability assessment of intelligent
    manufacturing supported by digital twin,” IEEE Access, vol. 8, pp. 174988–175008,
    2020. View at: Publisher Site | Google Scholar L. Li and C. Mao, “Big data supported
    PSS evaluation decision in service-oriented manufacturing,” IEEE Access, vol.
    8, no. 99, pp. 154663–154670, 2020. View at: Publisher Site | Google Scholar Y.
    Wang, H. Li, B. S.-X. Teo, A. A. Jaharadak, and A. Adam, “Image detection system
    based on smart sensor network and ecological economy in the context of fine agriculture,”
    Journal of Sensors, vol. 2022, Article ID 8953914, 12 pages, 2022. View at: Publisher
    Site | Google Scholar Copyright Copyright © 2023 Wei Zhao et al. This is an open
    access article distributed under the Creative Commons Attribution License, which
    permits unrestricted use, distribution, and reproduction in any medium, provided
    the original work is properly cited. PDF Download Citation Download other formats
    Order printed copies Views 1194 Downloads 614 Citations 6 About Us Contact us
    Partnerships Blog Journals Article Processing Charges Print editions Authors Editors
    Reviewers Partnerships Hindawi XML Corpus Open Archives Initiative Fraud prevention
    Follow us: Privacy PolicyTerms of ServiceResponsible Disclosure PolicyCookie PolicyCopyrightModern
    slavery statementCookie Preferences"'
  inline_citation: '>'
  journal: Mobile Information Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Unmanned Aerial Vehicle and Geospatial Analysis in Smart Irrigation and Crop
    Monitoring on IoT Platform
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Hachimi C.E.
  - Belaqziz S.
  - Khabba S.
  - Sebbar B.
  - Dhiba D.
  - Chehbouni A.
  citation_count: '9'
  description: 'Smart management of weather data is an essential step toward implementing
    sustainability and precision in agriculture. It represents an important input
    for numerous tasks, such as crop growth, development, yield, and irrigation scheduling,
    to name a few. Advances in technology allow collecting this weather data from
    heterogeneous sources with high temporal resolution and at low cost. Generating
    and using these data in their raw form makes no sense, and therefore implementing
    adequate infrastructure and tools is necessary. For that purpose, this paper presents
    a smart weather data management system evaluated using data from a meteorological
    station installed in our study area covering the period from 2013 to 2020 at a
    half-hourly scale. The proposed system makes use of state-of-the-art statistical
    methods, machine learning, and deep learning models to derive actionable insights
    from these raw data. The general architecture is made up of four layers: data
    acquisition, data storage, data processing, and application layers. The data sources
    include real-time sensors, IoT devices, reanalysis data, and raw files. The data
    are then checked for errors and missing values using a proposed method based on
    ERA5-Land reanalysis data and deep learning. The resulting coefficient of determination
    (R2) and Root Mean Squared Error (RMSE) for this method were 0.96 and 0.04, respectively,
    for the scaled air temperature estimate. The MongoDB NoSQL database is used for
    storage thanks to its ability to deal with real-world big data. The system offers
    various services such as (i) weather time series forecasts, (ii) visualization
    and analysis of meteorological data, and (iii) the use of machine learning to
    estimate the reference evapotranspiration (ET0) needed for efficient irrigation.
    To this, the platform uses the XGBoost model to achieve the precision of the Penman–Monteith
    method while using a limited number of meteorological variables (air temperature
    and global solar radiation). Results for this approach give R2 = 0.97 and RMSE
    = 0.07. This system represents the first incremental step toward implementing
    smart and sustainable agriculture in Morocco.'
  doi: 10.3390/agriculture13010095
  full_citation: '>'
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                 Deny Allow selection
    Allow all     Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Agriculture All Article Types Advanced   Journals
    Agriculture Volume 13 Issue 1 10.3390/agriculture13010095 Submit to this Journal
    Review for this Journal Propose a Special Issue Article Menu Academic Editor Bin
    Gao Subscribe SciFeed Recommended Articles Related Info Link More by Authors Links
    Article Views 7214 Citations 10 Table of Contents Abstract Introduction State
    of the Art Study Area System Architecture Results and Discussions Conclusions
    Author Contributions Funding Data Availability Statement Acknowledgments Conflicts
    of Interest References share Share announcement Help format_quote Cite question_answer
    Discuss in SciProfiles thumb_up Endorse textsms Comment first_page settings Order
    Article Reprints Open AccessArticle Smart Weather Data Management Based on Artificial
    Intelligence and Big Data Analytics for Precision Agriculture by Chouaib El Hachimi
    1,*, Salwa Belaqziz 1,2, Saïd Khabba 1,3, Badreddine Sebbar 1,4, Driss Dhiba 5
    and Abdelghani Chehbouni 1,5 1 Center for Remote Sensing Applications (CRSA),
    Mohammed VI Polytechnic University (UM6P), Ben Guerir 43150, Morocco 2 LabSIV
    Laboratory, Department of Computer Science, Faculty of Science, UIZ University,
    Agadir 80000, Morocco 3 LMFE, Department of Physics, Faculty of Sciences Semlalia,
    Cadi Ayyad University, Marrakesh 40000, Morocco 4 Centre d’Etudes Spatiales de
    la Biosphère (CESBIO), Université de Toulouse, 31400 Toulouse, France 5 International
    Water Research Institute (IWRI), Mohammed VI Polytechnic University (UM6P), Ben
    Guerir 43150, Morocco * Author to whom correspondence should be addressed. Agriculture
    2023, 13(1), 95; https://doi.org/10.3390/agriculture13010095 Submission received:
    6 December 2022 / Revised: 22 December 2022 / Accepted: 23 December 2022 / Published:
    29 December 2022 (This article belongs to the Special Issue Selected Papers from
    1st International Online Conference on Agriculture - Advances in Agricultural
    Science and Technology (IOCAg2022)) Download keyboard_arrow_down     Browse Figures
    Review Reports Versions Notes Abstract Smart management of weather data is an
    essential step toward implementing sustainability and precision in agriculture.
    It represents an important input for numerous tasks, such as crop growth, development,
    yield, and irrigation scheduling, to name a few. Advances in technology allow
    collecting this weather data from heterogeneous sources with high temporal resolution
    and at low cost. Generating and using these data in their raw form makes no sense,
    and therefore implementing adequate infrastructure and tools is necessary. For
    that purpose, this paper presents a smart weather data management system evaluated
    using data from a meteorological station installed in our study area covering
    the period from 2013 to 2020 at a half-hourly scale. The proposed system makes
    use of state-of-the-art statistical methods, machine learning, and deep learning
    models to derive actionable insights from these raw data. The general architecture
    is made up of four layers: data acquisition, data storage, data processing, and
    application layers. The data sources include real-time sensors, IoT devices, reanalysis
    data, and raw files. The data are then checked for errors and missing values using
    a proposed method based on ERA5-Land reanalysis data and deep learning. The resulting
    coefficient of determination (R2) and Root Mean Squared Error (RMSE) for this
    method were 0.96 and 0.04, respectively, for the scaled air temperature estimate.
    The MongoDB NoSQL database is used for storage thanks to its ability to deal with
    real-world big data. The system offers various services such as (i) weather time
    series forecasts, (ii) visualization and analysis of meteorological data, and
    (iii) the use of machine learning to estimate the reference evapotranspiration
    (ET0) needed for efficient irrigation. To this, the platform uses the XGBoost
    model to achieve the precision of the Penman–Monteith method while using a limited
    number of meteorological variables (air temperature and global solar radiation).
    Results for this approach give R2 = 0.97 and RMSE = 0.07. This system represents
    the first incremental step toward implementing smart and sustainable agriculture
    in Morocco. Keywords: artificial intelligence; big data analytics; smart agriculture;
    evapotranspiration; ERA5-Land; time series forecasting; anomaly detection; MongoDB
    1. Introduction Advances in technology and industry have helped humanity to increase
    life quality and expectancy. This includes delegating laborious processes traditionally
    performed by hand to machines that can perform these tasks more efficiently. However,
    it has brought with it several problems as well [1] relating to the overexploitation
    and nonrational use of Earth’s natural resources, which in turn causes disruption
    of the natural balance expressed by climate change effects, such as global warming
    and severe climate events (droughts, flooding, storms, hurricanes, etc.). In response
    to this alarming situation, humanity is asked more than ever to rethink and reconsider
    its way of dealing with the environment, especially in the context of a world
    population that grows at a higher rate [2]. This puts a lot of pressure on our
    food systems to meet the increasing demand and feed the planet. Agriculture is
    the sector that must be addressed, and agricultural management practices need
    to be optimized and become more efficient and sustainable to address these challenges.
    With water resources as an example, agriculture comes in as the largest consumer
    of this resource, with about an average of 70% in use around the world [3]. In
    this sector, water resources are used mainly in irrigation activities that still
    follow unsustainable methods such as gravity irrigation, the most widely used
    type of irrigation globally [4,5]. Additionally, even when using modern methods
    of irrigation, such as drip irrigation, they can be inefficient in the absence
    of good management [6]. The crucial step to achieving an efficient irrigation
    system, whatever the type of irrigation system used, is to know the proper amount
    of water to supply and the time to apply it (when and how much). To this end,
    we need to monitor either the soil, the crop, or the weather. Monitoring the weather
    enables the estimation of evapotranspiration (ET), which is the sum of transpiration
    from plants and soil surface evaporation. Accurately estimating this parameter
    allows compensation of the lost water quantity to the atmosphere. There are two
    methods of estimating the evapotranspiration of a crop. One uses a single crop
    coefficient (Kc) that incorporates all physiological and physical variations between
    the crops and the second where the Kc is split into two separate coefficients:
    Kcb for crop transpiration and Ke for soil evaporation. The Kc coefficient, then,
    is multiplied by the reference evapotranspiration (ET0), which reflects the rate
    of evapotranspiration for a specific crop (grass). It is obtained by monitoring
    various meteorological parameters (air temperature, solar radiation, air relative
    humidity, wind speed, etc.). Therefore, weather monitoring is a key step toward
    implementing efficient irrigation systems and ensuring sustainable agriculture.
    Today, we are able to collect weather data with high spatial and temporal resolution
    thanks to advances in science and technology, including advances in remote sensing
    such as the availability of Unmanned Aerial Vehicle (UAV) [7] equipped with cutting-edge
    sensors with affordable prices, satellite imagery with different spatio-temporal
    resolutions, open-access reanalysis data such as European ReAnalysis data [8],
    MERRA [9], the JRA-55 [10] or NCEP–DOE AMIP-II Reanalysis data [11]. Additionally,
    advances in the Internet of Things (IoT) field have enabled cost-effective sensor
    data acquisition [12,13,14,15,16]. This huge amount of data raised issues regarding
    the efficiency, complexity, interfaces, dynamics, robustness, and interaction
    between these new types of peer-to-peer connected systems that need to be re-examined
    on a large scale, as discussed in [17]. This unprecedented amount of generated
    data is also contributing to what is known as big data, which needs adequate infrastructure
    to be stored and gain insights for assisting agricultural decision making. This
    work aligns with this objective and is intended to provide intelligent ways to
    deal with these abundant data by applying the concepts of big data analytics and
    leveraging the potential applications of artificial intelligence in agriculture
    to help farmers minimize their risks, or at least make them more manageable, which
    represents a step towards the development of smart and precision agriculture.
    2. State of the Art Several researchers have tried to leverage the challenges
    and opportunities of the big data wave in the agricultural field and how it can
    be the driver of sustainability and precision in this sector by gaining insights
    from massive volumes of data that can be used to assist decision making. As surveyed
    in [18], big data analytics is leading to advances in various industries, but
    it has not yet been widely applied in agriculture. The work presents a range of
    suggested solutions, tools, algorithms, and data, including how they were used
    and their impact upon the sector as a whole. It also emphasizes the enormous potential
    of big data analytics in agriculture for smarter farming, demonstrating how the
    accessibility of big data analytics tools, methods, and software, as well as the
    growing openness of heterogeneous data sources (the “open data wave”), will encourage
    more academic research, public sector initiatives, and business ventures in the
    agricultural sector. The paper concludes that the adoption of big data practices
    in agriculture is still challenging and faces several obstacles when applied to
    real-world applications. In the paper [19], the authors developed a system composed
    of three components: (i) hardware to capture crop data, (ii) a web application
    for crop data and field information manipulation, and (iii) a mobile application
    to control irrigation via mobiles. The objective of this work is to analyze the
    suitability of crops in terms of air temperature, air relative humidity, and soil
    moisture to optimize future plans and strategies. The authors of the work [20]
    propose a solution to be adopted in India to help farmers face the unpredictable
    nature and variability of climate and weather circumstances. They built a system
    for managing local weather stations in real time that would keep farmers well-informed
    about the current weather conditions in advance, allowing them to make the right
    decisions at the right time and prevent crop loss. High-speed internet infrastructure
    available even in rural areas is the main motivation for conducting this work.
    It facilitates the communication of collected data to remote servers. Once received
    and analyzed, the information derived from these data gives farmers a way to automate
    their agricultural management practices (irrigation, fertilization, and harvesting)
    by triggering the right action at the right time. Article [21] also presented
    a smart weather station management system intended to be used in agriculture and
    to manage meteorological stations. It is based on Internet of Things technology
    (IoT) to minimize costs. The connected sensors measure air temperature, humidity,
    light intensity, air pressure, and wind speed. It then sends the collected data
    to the server part of the system through the Global System for Mobile Communications
    (GSM) module. The application layer is powered by the ThingSpeak platform, which
    offers standard services to the proposed system such as data visualization and
    data analysis. In regards to dealing with the challenges related to handling huge
    amounts of data generated by sensors, the paper [22] proposed a standard architecture
    for a data infrastructure platform called WALLeSMART, which is a cloud-based solution
    that provides a general architecture to handle the difficulties of gathering,
    processing, storing, and visualizing extremely large amounts of data in batch
    and real-time modes. An initial prototype has been developed and tested at various
    farms in the Wallonia region of Belgium, showing prominent results. This proposed
    system can be used as the basis for developing customized smart agricultural services
    to meet our needs. Our contributions not only propose an architecture containing
    some of the standard pipelines used in the literature to build data platforms,
    namely data acquisition, storing, visualizing, and analysis, but a complete system
    with the aim of going from data to decision making. The proposed system provides
    services such as weather time series forecasting, missing values handling using
    a multisource approach (reanalysis and situ data), and estimating important parameters
    needed in the day-to-day life of farmers, such as the evapotranspiration (ET).
    3. Study Area The study area is situated 40 km east of Marrakesh in the semiarid
    Haouz plain in the heart of Morocco (Figure 1). About 2800 ha of this area is
    irrigated, and it is nearly flat. Cereal crops such as wheat and barley are the
    main dominant crops. The region’s climate is typically Mediterranean semiarid,
    with an average annual rainfall of about 250 mm [23,24], temperatures that range
    from hot in the summer (38 °C in July) to cool in the winter (5 °C in February),
    significant daily and monthly variations that are concentrated primarily from
    autumn to spring, and an average annual ET0 of 1600 mm [25]. Figure 1. R3 district
    study area in Morocco and a Photo of the meteorological station installed. 4.
    System Architecture The proposed system is designed to enable the smart management
    of weather data, which represents the key to implementing smart agriculture. By
    monitoring and analyzing the weather effectively, we can optimize various agricultural
    management practices such as irrigation scheduling and choosing the appropriate
    crop to sow [26]. The design of the platform follows a service-oriented architecture
    (Figure 2) to offer services that address each of the four categories of big data
    analytics. As part of a descriptive data analysis that tries to understand what
    happened in the past, a scenario would be: rainfall declined, and the frequency
    changed over the last decade. The answer to why this happened, in turn, is very
    important, and it takes us to the diagnostic data analysis, where the focus is
    to identify anomalies in data to explain the reasons behind events, such as linking
    this event with long-term shifts in temperatures and weather patterns observed
    in weather evolution charts. The third type covered by the platform is predictive
    data analysis. It looks beyond the present and tries to predict the future using
    statistical methods and machine learning algorithms that learn from historical
    data in an iterative approach, trying to identify the optimal way to predict the
    future. One such service is weather forecasting. The output of the forecasting
    service can be used to support decision making about what actions to take that
    aim to prevent severe events from occurring in the future. This is carried out
    through the last type, which is prescriptive data analysis. Figure 2. General
    architecture of the platform. The platform can be decomposed into four main layers:
    the data acquisition layer, the data storage layer, the processing layer, and
    the application layer. 4.1. Data Acquisition Layer Heterogeneous data from a variety
    of sources, including meteorological station data, IoT weather sensors, reanalysis
    data, third-party meteorological services, and raw files (CSV, Excel, etc.), are
    used as the input for this layer. The concept of big data is introduced to the
    field by the volume, velocity, and variety that characterize these data. Missing
    values are handled in this layer using the method developed in Section 4.4.1 prior
    to being stored in the NoSQL MongoDB database. 4.1.1. Weather Station Data The
    weather dataset used in this study was collected from a meteorological station
    installed in the study area (Figure 1) at the half-hour scale from 2013 to 2020.
    The used tower is equipped with different sensors [27,28] to measure: Incoming
    solar radiation using (Kipp and Zonen CM5 Pyranometer, Delft, The Netherlands).
    Air temperature in Kelvin, relative humidity (R3_Hr, as a fraction between 0 and
    1) and vapor pressure by using (HMP45C, Vaisala, Helsinki, Finland). Wind speed
    using (A100R Anemometer, R.M. Young Company, Traverse City, MI, USA). Rainfall
    using (FSS500 Tipping Bucket Automatic Rain Gauge, Campbell Scientific Inc., Logan,
    UT, USA). Next, records are stored in data loggers before being collected manually
    by agents or sent to a centralized server via a cellular connection. A full description
    of these data is shown in Table 1, which also includes statistics for missing
    values. Table 1. Meteorological station data description. 4.1.2. ERA5-Land Reanalysis
    Data Advances in measurement technologies have enabled us to use various observation
    methods to monitor the Earth’s weather, including weather stations, weather balloons,
    and satellite imagery, to name a few. However the distribution of these observation
    methods does not cover the entire globe, they may have overlapping footprints
    between covered areas, and fewer of them were available in the past, which makes
    it challenging to conduct studies of past years. To deal with this, climate reanalysis
    emerges as a new way of trying to deliver a complete picture of the past and of
    the entire globe by combining the laws of physics, modern weather models, and
    available weather sources. Such data, if accurate, are crucial and will certainly
    assist decision making in several domains such as smart cities, smart management
    of renewable energy stations, sustainable and climate-smart agriculture [29,30],
    climate change assessments, hydrology [31], and much more. In our study, we used
    the fifth generation of European ReAnalysis (ERA5-Land) [32] available to be downloaded
    for free through the Climate Data Store (CDS) web platform [33]. ERA5-Land is
    the successor to ERA5 [8], which in turn is the successor to ERA-Interim [34].
    This new product covers the period from 1950 to the present. ERA5-Land has the
    benefit over the predecessors of its high horizontal resolution (9 km against
    31 km for ERA5 and 80 km for ERA-Interim). These strengths were achieved thanks
    to the integration of the ECMWF land surface model forced by the ERA5 climate
    reanalysis with corrected elevation for the thermodynamic near-surface state and
    then applied to Numerical Weather Prediction (NWP) models. The data used in this
    study concern the two pixels that cover our study area (Figure 3). We downloaded
    ERA5-Land weather data from 2013 to 2020. Since the cloud service Climate Data
    Store API (cdsapi) has a limit of 100,000 records per request, we downloaded each
    year separately and combined them all at the end. The downloaded data were then
    converted to a pandas dataframe data structure using the Python language. We also
    developed a function called “get_era5_land_grib_as_dataframe”, available as a
    part of the GIS class of the public library Data Science Toolkit (DST) [35] that
    accepts an ERA5-Land grip file as a parameter and returns a pandas dataframe,
    which is the most commonly used data structure in the data science field. The
    full description of the downloaded parameters is described in Table 2. Figure
    3. The projection of ERA5-Land pixels over the study area. Table 2. ERA5-Land
    downloaded data description. 4.2. Data Storage Layer In our system, most of the
    collected data are time series (meteorological data, reanalysis data, satellite
    data, etc.). This type is characterized mainly by variety (multisource), volume,
    and velocity (each half-hour). To deal with this, the system uses MongoDB, a big-data-driven
    database for storing and retrieving meteorological data. The choice of using the
    MongoDB database comes after several strengths it presents and its suitability
    for our use case, including that it was designed to replace or enhance the classic
    Relational Database Management Systems (RDBMS), providing it with a variety of
    additional characteristics such as scalability being schema-less. It is also powerful
    at handling large amounts of real-time data and efficiently handling memory, as
    it is written using the C++ programming language. Not to mention the geospatial
    indexing feature, which makes it perfect for real-time geospatial data collection
    and analysis. Figure 4 shows the Entity Relationship Diagram of the weather data
    subcomponent. Figure 4. The Entity Relationship Diagram used in the climate database
    design; ta: air temperature (R3_Tair), rg: global solar radiation (R3_Rg), hr:
    air relative humidity (R3_Hr), p: rainfall (R3_P), ws: wind speed (R3_Vv), wd:
    wind direction (R3_Dv). 4.3. Data Processing Layer The data processing layer takes
    the data from the data storage layer as input and applies the statistical, machine
    learning, and deep learning models to gain insights from the data and turn that
    into services (Figure 2). 4.3.1. Statistical Models Statistical models are used
    in this platform for forecasting purposes. Initially, the model Facebook Prophet
    [36] was used to conduct long-term weather time series forecasting, since it was
    tested on the same data in previous work. 4.3.2. Machine Learning Models The system
    also makes use of machine learning models, given the fact that they can perform
    well on small datasets, for example, the XGBoost [37] model for reference evapotranspiration
    estimation based on stored metrological data [38]. 4.3.3. Deep Learning Models
    Deep learning models or neural networks have gained success in solving complex
    tasks that were previously human-specific and have required some level of human
    intelligence to be solved in different fields. They derive their power by trying
    to mimic the way the human brain works. They are composed of neurons able to process
    huge amounts of data in order to map the output from a set of inputs using internal
    mathematical operations. These neurons are organized into groups called layers
    and, during the propagation of signals between layers in two senses (Forward and
    backpropagation), the deep learning network learns to perform tasks. In our case,
    this is a regression task, where the input is ERA5-Land reanalysis data and the
    output is meteorological station data. 4.4. Application Layer The application
    layer contains multiple services related to weather times series. 4.4.1. Time
    Series Data Imputation Service It is common in real-world meteorological data
    to have missing values for various reasons. Missing values can be due to a network
    error or due to technical issues with certain measurement sensors, etc. These
    missing data can affect the performance of any type of model (machine learning,
    numerical, physical, etc.). As such, they need to be identified and handled efficiently
    during the exploratory data analysis (EDA) and preprocessing stages. There are
    several techniques for dealing with missing data depending on the use case: Deletion:
    Deleting rows or columns with missing values will remove this unwanted type of
    data from our dataset, but it may drastically reduce the size of the dataset,
    especially in the context of data scarcity. Imputation in time series data: In
    the case of a time series with a trend and seasonality, missing data can be replaced
    using seasonal adjustment, such as using the data from the same period of the
    previous year, which is the case for most weather data. However, this method may
    not be as efficient due to changes in weather patterns around the world. In contrast,
    if the time series do not present a trend or a seasonality, it can be treated
    the same way as imputation for a normal dataset. Imputation in normal datasets:
    Replacing it using statistical measures of central tendencies such as the mean,
    median, or mode of a given window of data that require some assumptions about
    the distribution type of the data to be efficient. This service proposes an approach
    based on reanalysis data and artificial intelligence to build models that can
    learn rules to map ERA5-Land reanalysis data to station meteorological data, which
    is also useful for the surrounding regions of our study area (Section 3), since
    we are in relatively homogeneous areas in terms of elevation and climate. We use
    the ERA5-Land data presented in Section 4.1.2 and two different architectures
    of deep learning models. The steps to implement the method workflow are shown
    in Figure 5. Figure 5. The flowchart of the deep learning approach. a. Exploratory
    data analysis Before implementing the proposed machine learning approach, exploratory
    data analysis (EDA) was the first exercise we conducted. It enabled us to understand
    our collected data, as well as to create hypotheses for further analysis and investigation.
    In this step, we made no underlying assumptions about the variables, and we were
    guided only by the observed data. We first calculated the correlation matrix (Figure
    6). This matrix allowed us to choose potential estimators for each target variable.
    Table 3 shows in the second column the potential estimators based on correlation
    coefficients (|r| > 0.5 means high relationships between variables). In the third
    column are the estimators that are used in the literature. Figure 6. The correlation
    heatmap and hierarchical clustering of the station and ERA5-Land parameters. Table
    3. Potential estimators of meteorological parameters. The variable 𝑒𝑟𝑎5_ℎ𝑟 in
    the matrix is calculated using the rule of thumb (Equation (1)), which uses both
    air temperature ( 𝑡2𝑚 ) and dewpoint temperature ( 𝑑2𝑚 ) to estimate air relative
    humidity efficiently for moist air (relative humidity above 50 percent) [39].
    According to the matrix, 𝑅3_𝐻𝑟 has a high negative correlation with 𝑡2𝑚 but a
    very weak correlation with 𝑑2𝑚 . Despite this, using the latter ( 𝑑2𝑚 ) combined
    with 𝑡2𝑚 gives a correlation of 0.87 for 𝑒𝑟𝑎5_ℎ𝑟 instead of −0.77, if we take
    only 𝑡2𝑚 into consideration. This motivated us to take both variables as input
    to neural networks for the estimation of 𝑅3 _ 𝐻𝑟 . This is also a confirmation
    for other rule-based (physics-based) approximations that use the same variables
    for air relative humidity estimation derived from the Magnus formula [40] (Equation
    (2)). 𝑒𝑟𝑎5_ℎ𝑟=100−5(𝑡2𝑚−𝑑2𝑚) (1) 𝑑2𝑚= 𝜆(ln( 𝑒𝑟𝑎5_ℎ𝑟 100 ))+ 𝛽.𝑡2𝑚 𝜆+𝑡2𝑚 𝛽−(ln(
    𝑒𝑟𝑎5_ℎ𝑟 100 )+ 𝛽.𝑡2𝑚 𝜆+𝑡2𝑚 ) (2) Equation (2) is valid for air temperatures ranging
    from −45 to 60 degrees Celsius, the Magnus parameters are, in this case, 𝛽 = 17.62
    and 𝜆 = 243.12 degrees Celsius. For global solar radiation ( 𝑅3_𝑅𝑔 ), the study
    uses the surface solar radiation downwards (ssrd) as estimator. Since the objective
    is to predict meteorological station data based only on ERA5-Land data, we evaluated
    the performance of two deep learning models, namely a Feed Forward Neural Network
    (FFNN) and a Long Short-Term Memory (LSTM), to predict 𝑅3_𝑇𝑎𝑖𝑟 given 𝑡2𝑚 , 𝑅3_𝑅𝑔
    given the ssrd, and 𝑅3_𝐻𝑟 given 𝑡2𝑚 and 𝑑2𝑚 . b. Feed Forward Neural Network (FFNN):
    In this type of neural network, the input signals (ERA5-Land data) are fed into
    the input layer composed of 100 neurons. In each neuron, the data are processed,
    taking the weighted sum of inputs plus a bias and then applying an activation
    function (Figure 7), before forwarding the output to the next layer. The activation
    function introduces nonlinearity to the output. The choice of this function has
    a real impact on the training process and performance of models and must be chosen
    according to the problem at hand. For example, sigmoid and hyperbolic tangent
    activation functions (Equations (3) and (4)) can be used to capture nonlinearity
    that may exist between inputs and outputs. Figure 7. A single neuron model. For
    our case, and given the fact that moving from ERA5-Land reanalysis data to meteorological
    station data is the inverse of inference in statistics, that is, estimating the
    mean of an individual (station data) given the mean of the population (ERA5-Land
    pixels), the error with this assumption is supposed to be linear (polynomial of
    degree one); that said, we used the Rectified Linear Unit function (ReLU) (Equation
    (5)) as the activation function in our neural network layers, which is true for
    both proposed architectures (FFNN and LSTM). 𝑦=𝑓(𝑥)= 1 1+ 𝑒 𝑥 (3) 𝑦=𝑓(𝑥)=tanh(𝑥)=
    𝑒 𝑥 − 𝑒 −𝑥 𝑒 𝑥 + 𝑒 −𝑥 (4) 𝑦=𝑓(𝑥)=𝑚𝑎𝑥(0,𝑥)={ 0, x, if𝑥<0 if𝑥≥0 (5) c. Long Short-Term
    Memory (LSTM): The choice behind using this neural network as a comparison is
    due to its ability to deal with data that have long-term dependency, which is
    the case for climate data. LSTM belongs to the Recurrent Neural Networks family
    (RNN), and therefore also has an internal recurrence, that is, during the learning
    process, a signal is fed back to a neuron or layer that has already received and
    processed it (Figure 8), as well as its ability to remember data through gated
    cells, which are a kind of memory that accept values in the interval [0, 1] and
    are used to decide when the flow of a signal passes through the corresponding
    neuron. LSTM was first developed to resolve the limitations of the vanishing [41]
    and exploding gradient problems that may occur during the training phase. This
    problem stops the learning of the neural network because the updates to the various
    weights become very small. Figure 8. Architectures of FFNN and LSTM used in the
    approach. These two architectures (Figure 8) are trained using the Mean Squared
    Error (MSE) as a loss or cost function that enables calculating the error of a
    network at the end of a forward pass. To optimize the network weights, we used
    the adaptive moment estimation optimization algorithm (Adam), which is characterized
    by fast convergence to the optimal solution and combines the strengths of other
    optimization algorithms such as Stochastic Gradient Descent (SGD) and RMSProp
    during the training phase. Like most other optimization algorithms, Adam uses
    the partial derivative during backward propagation to calculate the error function
    with respect to each weight within the network (Equation (6)). The Adam algorithm
    then updates the network weights for a minimized loss or cost function using rules
    in Equations (7), (8) and (9), respectively. 𝑔𝑟𝑎𝑑= ∂𝐽 ∂𝜃 (6) 𝑚 𝑡 = 𝛽 1 𝑚 𝑡−1 +(1−
    𝛽 1 )𝑔𝑟𝑎𝑑 (7) 𝑣 𝑡 = 𝛽 2 𝑣 𝑡−1 +(1− 𝛽 2 )𝑔𝑟𝑎𝑑 (8) 𝜃=𝜃−𝛼 𝑚 𝑡 𝑣 𝑡 +𝜖 − − − − − √
    (9) d. Data normalization Data normalization is performed as part of the data
    preprocessing step and is the process of bringing data to a similar scale. The
    process is also known as feature scaling. In some cases, such as for statistical
    machine learning models, it may not be beneficial, but for deep learning models,
    it is proven to help models to perform better [42,43] in terms of faster convergence,
    reduced training time, and improved stability (preventing models from oscillating
    or divergence). There are multiple methods for data normalization: Min–max standardization:
    Min–max scales the feature values between [0, 1], with 0 being the feature’s minimum
    value and 1 being its maximum value, while maintaining the original distribution
    (Equation (10)). 𝑥 𝑛𝑒𝑤 = 𝑥−𝑚𝑖𝑛(𝑥) 𝑚𝑎𝑥(𝑥)−𝑚𝑖𝑛(𝑥) (10) Decimal scaling: This form
    of scaling is used where values of different decimal ranges are present. For example,
    two features with different bounds can be brought to a similar scale using decimal
    scaling (Equation (11)) 𝑥 𝑛𝑒𝑤 = 𝑥 10 𝑛 (11) Such that n is an integer representing
    the order of the scalings. Z-score: This transformation scales the value toward
    a normal distribution with a zero mean and unit variance using the z-score formula
    (Equation (12)). 𝑥 𝑛𝑒𝑤 = 𝑥−𝜇 𝜎 (12) such that 𝜇 is the mean and 𝜎 is the standard
    deviation of the features’ distribution. This method is very efficient for datasets
    with a Gaussian distribution. In our case, we applied the min–max method (Equation
    (10)). Next, we initialize the hyperparameters of the two proposed architectures
    (Table 4). These parameters are not updated during the learning phase. Table 4.
    Hyperparameters used during the training of FFNN and LSTM models. e. Dataset splitting
    Before training begins, we split our dataset into three sets: training, validation,
    and test sets. The validation set is used to assess the performance of the model
    during each epoch of the training phase. Next, the test set is used to evaluate
    the final trained model. We used 80–20% splitting for the training–test sets,
    respectively, and took 20% of the 80% for the validation set. f. Evaluation Metrics
    To evaluate the trained deep learning models’ performance on the test dataset,
    we employed the most commonly used metrics for regression tasks (Equations (13)–(16)):
    Training time: The time it takes for the model to complete 20 epochs. R2 score
    or R2: The coefficient of determination informs about how well the unknown samples
    will be predicted by our model. It ranges between 0 and 1, but it can be negative
    as well (Equation (13)). R 2 =1− ∑ 𝑛 1 ( 𝑦 𝑖 − 𝑦 ̂ 𝑖 ) 2 ∑ 𝑛 1 ( 𝑦 𝑖 − 𝑦 ̲ 𝑖 )
    2 (13) The Pearson correlation coefficient (R): It measures the linear relationship
    between two normal distributed variables (Equation (14)). R= ∑ 𝑛 𝑖=1 ( 𝑥 𝑖 − 𝑥
    ̲ )( 𝑦 𝑖 − 𝑦 ̲ ) ∑ 𝑛 𝑖=1 ( 𝑥 𝑖 − 𝑥 ̲ ) 2 ( 𝑦 𝑖 − 𝑦 ̲ ) 2 − − − − − − − − − − −
    − − − − − − − − √ (14) Root Mean Squared Error (RMSE): The average of the squares
    of the errors between real and predicted values by the model (Equation (15)).
    RMSE= 1 𝑛 ∑ 1 𝑛 ( 𝑦 𝑖 − 𝑦 ̂ 𝑖 ) 2 − − − − − − − − − − − − −  ⎷   (15) Mean
    Absolute Error (MAE): This is the average of absolute errors between real and
    predicted values (Equation (16)). MAE= ∑ 𝑛 1 | 𝑦 𝑖 − 𝑦 ̂ 𝑖 | 𝑛 (16) Given the
    fact that we applied the scaling in our data using the formula in Equation (10),
    all metrics (from Equations (13) to (16)) are unitless. 4.4.2. Forecasting Service
    The forecasting service helps make projections of the future state of the atmosphere
    (air temperature, air relative humidity, global solar radiation, etc.) by performing
    a univariate time series forecasting task. The Facebook Prophet model is used
    according on the performance it has provided when trained and evaluated using
    the same meteorological dataset to perform long-term weather forecasting tasks.
    4.4.3. Climatic Parameters Calculation and Estimation Service One of the most
    important agricultural practices in the day-to-day life of a farmer is irrigation.
    To achieve efficiency, we need to accurately estimate crops’ water needs at each
    phase of crop growth throughout the agricultural season. This can be performed
    through several methods, among others is the estimation of the evapotranspiration
    (ET). It indicates the amount of water loss caused by transpiration from the crop
    and soil surface evaporation. We can obtain the ET of a crop (ETc) by multiplying
    the reference evapotranspiration (ET0) and crop coefficient Kc, which holds all
    the physical and physiological differences of a given crop. This service proposes
    to estimate the ET0 using machine learning, namely the XGBoost model constrained
    by the physical model FAO Penman–Monteith. The proposed approach follows the steps
    presented in Figure 9. First, we resampled the air temperature, global solar radiation,
    air relative humidity, and wind speed to the daily average, and precipitation
    to the cumulative daily values, and then the missing values were deleted. Figure
    9. The flowchart of the proposed method. To select the most important contributor
    variables to the ET0 estimate, the method uses a random-forest-based technique
    that ranks the importance of features based on their occurrences in nodes across
    all trees: the bar chart (Figure 10) shows sorted meteorological variables’ importance
    scores. Next, the dataset containing meteorological data and the corresponding
    FAO Penman–Monteith ET0 estimated values are split and fed into the XGBoost model,
    and the model is then evaluated. Figure 10. The features’ importance bar chart
    of meteorological parameters. The objective of this service is to provide an alternative
    to the FAO Penman–Monteith calculation procedure by learning the behavior of this
    procedure using a limited number of climatic variables (Figure 11). It is either
    suitable for stations that lack the necessary hardware and sensors to provide
    the entire set of meteorological data required for FAO Penman–Monteith or in the
    case of technical problems with sensors, among other things. Figure 11. The logic
    of the Evapotranspiration estimation component. 4.4.4. Weather Data Analysis and
    Visualization Service It is well-known that data in their raw form are useless,
    but the information, knowledge, and wisdom derived from them are not. Moving from
    one state of data to another is known as Knowledge Discovery in Databases (KDD),
    which is a subset of the modern data science field and can be performed using
    various methods, such as CRISP-DM [44], which stands for CRoss-Industry Standard
    Process for Data Mining, or the proposed standard method in [45]. One example
    of insights data visualization and analysis which can be given in our use case
    is shown in Figure 12. This is achieved by following a hybrid methodology that
    includes the following steps: collecting, storing, cleaning, visualizing, analyzing,
    and mining. Figure 12. An example of the data analysis scenario. The first three
    steps are common for all other services available on the platform. The added value
    of this service is providing different types of visualization options, including
    comparison plots (line charts of weather time series), relationship plots (scatter
    plot of weather data), and automatically generating correlation heat maps, which
    are important steps in the data analysis phase to study how one variable affects
    another. 4.4.5. Custom Early Warning Alerts Service This service is classified
    as an outlier or anomaly detection problem. These special types of data can be
    detected in time series by using, among others, rule-based methods, in which case
    the service alerts administrators via SMS and email once the given condition is
    satisfied. An example of such a condition is a threshold of temperature or rainfall.
    The second method of sending warnings is to identify sequences that are notably
    different from the rest of the historical time series data. These sequences can
    be the result of measurement error or noise and can inform administrators about
    the status of the different sensors installed in the meteorological station and
    inform them about events that could require urgent action. To perform this, we
    use unsupervised machine learning methods that do not require an annotated series
    of anomalies to be trained, in contrast to supervised machine learning algorithms.
    The unsupervised method we used is Local Outlier Factor ( 𝐿𝑂𝐹 ) [46]. It uses
    the KNN algorithm principle to calculate the distance of a point with respect
    to its neighbors. This distance is used, in turn, to obtain the Reachability Density
    ( 𝑅𝐷 ) (Equation (17)). 𝑅𝐷( 𝑥 𝑖 , 𝑥 𝑗 )=𝑚𝑎𝑥(𝐾−𝑑𝑖𝑠𝑡𝑎𝑛𝑐𝑒( 𝑥 𝑗 ),𝑑𝑖𝑠𝑡𝑎𝑛𝑐𝑒( 𝑥 𝑖 ,
    𝑥 𝑗 )) (17) Next is measuring the local deviation of the density of a given point
    using Local Reachability Density ( 𝐿𝑅𝐷 ) (Equation (18)), which tells us how far
    the point is from the nearest dense cluster of points. 𝐿𝑅 𝐷 𝑘 (𝑥)= 1 ∑ 𝑥 𝑗 ∈ 𝑁
    𝑘 (𝑥) 𝑅𝐷(𝑥, 𝑥 𝑗 ) || 𝑁 𝑘 (𝑥)|| (18) where 𝑁𝑘(𝑥) is the number of neighbors of
    x whose distance from x is not greater than the k-distance. As a final step, the
    algorithm calculates the 𝐿𝑂𝐹 (Equation (19)). Conventionally the points that have
    a higher anomaly score than their neighbors 𝐿𝑂𝐹 > 1) will be considered as potential
    outliers, but that is not always true, since in anomaly detection there is no
    clear and standard validation approach, and the final decision must relies on
    domain expertise to consider the detected point as an outlier or not, and the
    role of the service ends by notifying the administrators and letting them decide.
    𝐿𝑂 𝐹 𝑘 (𝑥)= ∑ 𝑥 𝑗 ∈ 𝑁 𝑘 𝐿𝑅𝐷( 𝑥 𝑗 ) || 𝑁 𝑘 (𝑥)|| × 1 𝐿𝑅 𝐷 𝑘 (𝑥) (19) 5. Results
    and Discussions 5.1. Time Series Data Imputation As a result, for handling missing
    data using deep learning, Figure 13 shows the curves for the loss function (MSE)
    and R2 in both training and validation sets during each epoch. For both architectures
    (FFNN and LSTM), the learning curves indicate a good fit of the model represented
    by an initially high training loss that steadily decreases as more training instances
    are added and flattens over time (0.04 for air temperature, 0.098 for global solar
    radiation, and 0.116 for air relative humidity), and the same way for R2, which
    begins with nonoptimal values in training and validation and converges to stable
    change (0.96 for air temperature, 0.84 for global solar radiation, and 0.77 for
    air relative humidity). Table 5 shows the performance comparisons between the
    two deep learning architectures used in the test set. Figure 13. Monitoring of
    MSE and R2 during training and validation phases: air temperature: (a) FFNN, (b)
    LSTM, global solar radiation: (c) FFNN, (d) LSTM, air relative humidity: (e) FFNN,
    (f) LSTM. Table 5. Performance of deep learning models. Table 5 shows the performance
    comparisons between the two deep learning models used in the test set. Once trained,
    the final deep learning model will be ready for deployment in the production environment
    and used to make inferences about meteorological station data given the ERA5-Land
    data. In contrast to Numerical Methods for Weather Prediction (NWP), which take
    considerable time to run [47], predictions based on our model are made instantly.
    5.2. Climatic Parameters Calculation and Estimation We split our dataset into
    five randomly shuffled parts (five folds). We used one fold for model evaluation
    and the remaining four to train it. Finally, we assess the model’s performance
    by calculating the regression metrics across the five folds of the dataset (Root
    Mean Squared Error RMSE and the coefficient of determination R2). According to
    the results of Table 6, the main point is not the perfect results obtained by
    using all parameters as estimators but using only air temperature and global solar
    radiation (average RMSE = 0.27 and average R2 = 0.93), which gave promising results.
    This represents a practical data-driven approach for accurately estimating ET0
    by combining two criteria: accuracy of the FAO Penman–Monteith method and using
    limited and simple-to-obtain meteorological variables (air temperature with global
    solar radiation or only air temperature). Table 6. Cross-validation results for
    the three scenarios. According to the results, the proposed method represents
    a practical data-driven approach for accurately estimating ET0 by combining two
    criteria: accuracy of the FAO Penman–Monteith method and using limited and simple-to-obtain
    meteorological variables (air temperature with global solar radiation or only
    air temperature). The results obtained are in agreement with the approach followed
    in [48] for the most contributing variables for ET0 estimation, but it outperforms
    it in terms of RMSE (0.19). In addition, the XGboost model used in this study
    outperforms [49] when using all meteorological variables to train a neural network
    (RMSE = 0.19). 5.3. Prototype of the System The platform is named “FLA7A”, which
    means agriculture in Arabic. Figure 14 shows a screenshot of the platform’s dashboard.
    By default, it contains the real-time visualization of the last three days of
    hourly weather data (line charts). However, the user can customize the period
    according to their needs. Figure 14. A screenshot of the platform’s real-time
    weather time series visualization service. The black dots represent the original
    measurements, while the black line represents the linear interpolation of the
    dots. Figure 14 shows a screenshot of the dashboard that visualizes the last three
    days of hourly weather data. Figure 15 shows the interface of the forecasting
    service. By default, the forecasting period is set to one year. However, the user
    can change this parameter and also customize the number of years it will take
    into consideration when training the model. As mentioned in Section 4.4.2, the
    service initially uses the statistical model Facebook Prophet, which is powerful
    in long-term forecasting. In future work, the platform will integrate more models,
    especially those known for their performance in the task of short-term and mid-term
    weather forecasting, as surveyed in [50]. Figure 15. A screenshot of the platform’s
    forecast service. The light blue is the uncertainty bounds of the uncertainty
    interval around the final predictions (upper and lower), while the dark blue is
    the predicted values, and the black dots represent our original data. This platform
    is the first incremental step towards our goal of creating a decision support
    system intended to implement smart agriculture in Morocco by using artificial
    intelligence and data science to solve real-life problems facing farmers. More
    studies will be performed to add and optimize different parts of this system.
    For example, for data storage, we used MongoDB as a database to deal with real-time
    big data, however, in terms of system scalability or dealing with batch processing
    or long-running ETL (Extract, Transform, and Load) jobs, other technologies should
    be considered. A potential candidate for this could be other NoSQL databases [51]
    or the Hadoop ecosystem (Spark, MapReduce, Hive, etc.) [52,53]. Additionally,
    MongoDB has fault tolerance issues, which is true of practically all distributed
    databases. Moreover, in the proposed deep learning method to deal with missing
    data, we do not cover hyperparameter fine-tuning [54], which is one of the biggest
    drawbacks to using deep neural networks. This task can be performed using GridSearch
    [55] or other optimization algorithms such as Genetic Algorithms or the Monte
    Carlo method, which can lead to better results. Despite this, we found promising
    results, confirming the reliability of the ERA5-Land reanalysis data for our study
    area, which could lead to the application of this method using several stations
    in regions with challenging conditions. Finally, for the anomaly detection part,
    we presented an unsupervised machine learning method that is based on how isolated
    a measure is with respect to the surrounding neighborhood to alert administrators
    via SMS and emails, but other efficient methods can be investigated, such as Conformal
    Anomaly Detection (CAP) [56,57]. 6. Conclusions The work conducted in this paper
    makes use of artificial intelligence and big data analytics to develop a platform
    intended for intelligent weather data management, which is essential to implementing
    smart and sustainable agriculture in Morocco. The platform exploits huge amounts
    of generated data to gain insights and help assist decision making. The proposed
    platform offers a number of weather-data-related services such as handling missing
    data, visualization, analysis, estimation, and forecasting. Combining ERA5-Land
    reanalysis data and deep learning algorithms to learn the relationship between
    the two data sources gave promising results (R2 = 0.96 and RMSE = 0.04) for the
    air temperature variable. The same is true for the estimation of the reference
    evapotranspiration using XGBoost (R2 = 0.97 and RMSE = 0.07). The platform is
    designed to be service-oriented and will incorporate other services and solutions
    to help farmers and policymakers. Author Contributions Platform and machine learning
    models development, C.E.H. and S.B.; data acquisition and processing, C.E.H.,
    S.B., B.S. and S.K.; methodology, C.E.H., S.B., S.K. and A.C.; writing—original
    draft, C.E.H.; writing—review and editing, S.B., S.K., D.D. and A.C. All authors
    have read and agreed to the published version of the manuscript. Funding This
    research received no external funding. Data Availability Statement The data presented
    in this study are available on request from the corresponding author. Acknowledgments
    This study was supported by and conducted within the Center for Remote Sensing
    Applications (CRSA) at the Mohammed VI Polytechnic University (UM6P) in Morocco.
    (https://crsa.um6p.ma/ (accessed on 1 September 2022)). Conflicts of Interest
    The authors declare that they have no known competing financial interests or personal
    relationships that could have appeared to influence the work reported in this
    paper. References Wade, M.; Hoelle, J.; Patnaik, R. Impact of Industrialization
    on Environment and Sustainable Solutions—Reflections from a South Indian Region.
    IOP Conf. Ser. Earth Environ. Sci. 2018, 120, 012016. [Google Scholar] [CrossRef]
    Bongaarts, J. Human population growth and the demographic transition. Philos.
    Trans. R. Soc. B Biol. Sci. 2009, 364, 2985. [Google Scholar] [CrossRef] [PubMed]
    [Green Version] Doungmanee, P. The nexus of agricultural water use and economic
    development level. Kasetsart J. Soc. Sci. 2016, 37, 38–45. [Google Scholar] [CrossRef]
    [Green Version] Frisvold, G.; Sanchez, C.; Gollehon, N.; Megdal, S.B.; Brown,
    P. Evaluating Gravity-Flow Irrigation with Lessons from Yuma, Arizona, USA. Sustainability
    2018, 10, 1548. [Google Scholar] [CrossRef] [Green Version] Belaqziz, S.; Mangiarotti,
    S.; Le Page, M.; Khabba, S.; Er-Raki, S.; Agouti, T.; Drapeau, L.; Kharrou, M.H.;
    El Adnani, M.; Jarlan, L. Irrigation scheduling of a classical gravity network
    based on the Covariance Matrix Adaptation—Evolutionary Strategy algorithm. Comput.
    Electron. Agric. 2014, 102, 64–72. [Google Scholar] [CrossRef] [Green Version]
    Nafchi, R.A. Evaluation of the Efficiency of the Micro-irrigation Systems in Gardens
    of Chaharmahal and Bakhtiari Province of Iran. Int. J. Agric. Econ. 2021, 6, 106–110.
    [Google Scholar] [CrossRef] Norasma, C.Y.N.; Fadzilah, M.A.; Roslin, N.A.; Zanariah,
    Z.W.N.; Tarmidi, Z.; Candra, F.S. Unmanned Aerial Vehicle Applications In Agriculture.
    IOP Conf. Ser. Mater. Sci. Eng. 2019, 506, 012063. [Google Scholar] [CrossRef]
    Hersbach, H.; Bell, B.; Berrisford, P.; Hirahara, S.; Horányi, A.; Muñoz-Sabater,
    J.; Nicolas, J.; Peubey, C.; Radu, R.; Schepers, D.; et al. The ERA5 global reanalysis.
    Q. J. R. Meteorol. Soc. 2020, 146, 1999–2049. [Google Scholar] [CrossRef] Rienecker,
    M.M.; Suarez, M.J.; Gelaro, R.; Todling, R.; Bacmeister, J.; Liu, E.; Bosilovich,
    M.G.; Schubert, S.D.; Takacs, L.; Kim, G.K.; et al. MERRA: NASA’s Modern-Era Retrospective
    Analysis for Research and Applications. J. Clim. 2011, 24, 3624–3648. [Google
    Scholar] [CrossRef] Kobayashi, S.; Ota, Y.; Harada, Y.; Ebita, A.; Moriya, M.;
    Onoda, H.; Onogi, K.; Kamahori, H.; Kobayashi, C.; Endo, H.; et al. The JRA-55
    Reanalysis: General Specifications and Basic Characteristics. J. Meteorol. Soc.
    Jpn. Ser. II 2015, 93, 5–48. [Google Scholar] [CrossRef] Kanamitsu, M.; Ebisuzaki,
    W.; Woollen, J.; Yang, S.K.; Hnilo, J.J.; Fiorino, M.; Potter, G.L. NCEP–DOE AMIP-II
    Reanalysis (R-2). Bull. Am. Meteorol. Soc. 2002, 83, 1631–1644. [Google Scholar]
    [CrossRef] [Green Version] Majumdar, P.; Mitra, S. IoT and Machine Learning-Based
    Approaches for Real Time Environment Parameters Monitoring in Agriculture: An
    Empirical Review. Agric. Inform. 2021, 5, 89–115. [Google Scholar] [CrossRef]
    Kumar, S.; Ansari, M.A.; Pandey, S.; Tripathi, P.; Singh, M. Weather Monitoring
    System Using Smart Sensors Based on IoT. Lect. Notes Netw. Syst. 2020, 106, 351–363.
    [Google Scholar] [CrossRef] Kodali, R.K.; Mandal, S. IoT Based Weather Station.
    In Proceedings of the 2016 International Conference on Control Instrumentation
    Communication and Computational Technologies, ICCICCT 2016, Kumaracoil, India,
    16–17 December 2016; pp. 680–683. [Google Scholar] [CrossRef] Mittal, Y.; Mittal,
    A.; Bhateja, D.; Parmaar, K.; Mittal, V.K. Correlation among Environmental Parameters
    Using an Online Smart Weather Station System. In Proceedings of the 12th IEEE
    International Conference Electronics, Energy, Environment, Communication, Computer,
    Control: (E3-C3), INDICON 2015, Delhi, India, 17–20 December 2015. [Google Scholar]
    [CrossRef] Djordjević, M.; Jovičić, B.; Marković, S.; Paunović, V.; Danković,
    D. A smart data logger system based on sensor and Internet of Things technology
    as part of the smart faculty. J. Ambient Intell. Smart Environ. 2020, 12, 359–373.
    [Google Scholar] [CrossRef] Amin, F.; Abbasi, R.; Mateen, A.; Ali Abid, M.; Khan,
    S. A Step toward Next-Generation Advancements in the Internet of Things Technologies.
    Sensors 2022, 22, 8072. [Google Scholar] [CrossRef] Kamilaris, A.; Kartakoullis,
    A.; Prenafeta-Boldú, F.X. A review on the practice of big data analysis in agriculture.
    Comput. Electron. Agric. 2017, 143, 23–37. [Google Scholar] [CrossRef] Muangprathub,
    J.; Boonnam, N.; Kajornkasirat, S.; Lekbangpong, N.; Wanichsombat, A.; Nillaor,
    P. IoT and agriculture data analysis for smart farm. Comput. Electron. Agric.
    2019, 156, 467–474. [Google Scholar] [CrossRef] Math, R.K.M.; Dharwadkar, N.V.
    IoT Based low-cost weather station and monitoring system for precision agriculture
    in India. In Proceedings of the 2nd International Conference on I-SMAC (IoT in
    Social, Mobile, Analytics and Cloud), Palladam, India, 30–31 August 2018; pp.
    81–86. [Google Scholar] [CrossRef] Djordjevic, M.; Dankovic, D. A Smart Weather
    Station Based on Sensor Technology. Facta Univ. Ser. Electron. Energetics 2019,
    32, 195–210. [Google Scholar] [CrossRef] [Green Version] Roukh, A.; Fote, F.N.;
    Mahmoudi, S.A.; Mahmoudi, S. WALLeSMART: Cloud Platform for Smart Farming. In
    Proceedings of the 32nd International Conference on Scientific and Statistical
    Database Management, Vienna, Austria, 7–9 July 2020. [Google Scholar] [CrossRef]
    Er-Raki, S.; Chehbouni, A.; Duchemin, B. Combining Satellite Remote Sensing Data
    with the FAO-56 Dual Approach for Water Use Mapping In Irrigated Wheat Fields
    of a Semi-Arid Region. Remote Sens. 2010, 2, 375–387. [Google Scholar] [CrossRef]
    [Green Version] Belaqziz, S.; Khabba, S.; Kharrou, M.H.; Bouras, E.H.; Er-Raki,
    S.; Chehbouni, A. Optimizing the Sowing Date to Improve Water Management and Wheat
    Yield in a Large Irrigation Scheme, through a Remote Sensing and an Evolution
    Strategy-Based Approach. Remote Sens. 2021, 13, 3789. [Google Scholar] [CrossRef]
    Er-Raki, S.; Chehbouni, A.; Guemouria, N.; Duchemin, B.; Ezzahar, J.; Hadria,
    R. Combining FAO-56 model and ground-based remote sensing to estimate water consumptions
    of wheat crops in a semi-arid region. Agric. Water Manag. 2007, 87, 41–54. [Google
    Scholar] [CrossRef] [Green Version] El Hachimi, C.E.; Belaqziz, S.; Khabba, S.;
    Chehbouni, A. Towards Precision Agriculture in Morocco: A Machine Learning Approach
    for Recommending Crops and Forecasting Weather. In Proceedings of the 2021 International
    Conference on Digital Age and Technological Advances for Sustainable Development,
    ICDATA 2021, Marrakech, Morocco, 29–30 June 2021; pp. 88–95. [Google Scholar]
    [CrossRef] Aouade, G.; Ezzahar, J.; Amenzou, N.; Er-Raki, S.; Benkaddour, A.;
    Khabba, S.; Jarlan, L. Combining stable isotopes, Eddy Covariance system and meteorological
    measurements for partitioning evapotranspiration, of winter wheat, into soil evaporation
    and plant transpiration in a semi-arid region. Agric. Water Manag. 2016, 177,
    181–192. [Google Scholar] [CrossRef] Kharrou, M.H.; Simonneaux, V.; Er-Raki, S.;
    Le Page, M.; Khabba, S.; Chehbouni, A. Assessing Irrigation Water Use with Remote
    Sensing-Based Soil Water Balance at an Irrigation Scheme Level in a Semi-Arid
    Region of Morocco. Remote Sens. 2021, 13, 1133. [Google Scholar] [CrossRef] Oses,
    N.; Azpiroz, I.; Marchi, S.; Guidotti, D.; Quartulli, M.; Olaizola, I.G. Analysis
    of Copernicus’ ERA5 Climate Reanalysis Data as a Replacement for Weather Station
    Temperature Measurements in Machine Learning Models for Olive Phenology Phase
    Prediction. Sensors 2020, 20, 6381. [Google Scholar] [CrossRef] [PubMed] Zandler,
    H.; Senftl, T.; Vanselow, K.A. Reanalysis datasets outperform other gridded climate
    products in vegetation change analysis in peripheral conservation areas of Central
    Asia. Sci. Rep. 2020, 10, 22446. [Google Scholar] [CrossRef] Bui, M.T.; Lu, J.;
    Nie, L. Evaluation of the Climate Forecast System Reanalysis data for hydrological
    model in the Arctic watershed Målselv. J. Water Clim. Chang. 2021, 12, 3481–3504.
    [Google Scholar] [CrossRef] Muñoz-Sabater, J.; Dutra, E.; Agustí-Panareda, A.;
    Albergel, C.; Arduini, G.; Balsamo, G.; Boussetta, S.; Choulga, M.; Harrigan,
    S.; Hersbach, H.; et al. ERA5-Land: A state-of-the-art global reanalysis dataset
    for land applications. Earth Syst. Sci. Data 2021, 13, 4349–4383. [Google Scholar]
    [CrossRef] ERA5-Land Hourly Data from 1950 to Present. Available online: https://doi.org/10.24381/cds.e2161bac
    (accessed on 1 September 2022). Dee, D.P.; Uppala, S.M.; Simmons, A.J.; Berrisford,
    P.; Poli, P.; Kobayashi, S.; Andrae, U.; Balmaseda, M.A.; Balsamo, G.; Bauer,
    P.; et al. The ERA-Interim reanalysis: Configuration and performance of the data
    assimilation system. Q. J. R. Meteorol. Soc. 2011, 137, 553–597. [Google Scholar]
    [CrossRef] El Hachimi, C.; Belaqziz, S.; Khabba, S.; Chehbouni, A. Data Science
    Toolkit: An all-in-one python library to help researchers and practitioners in
    implementing data science-related algorithms with less effort. Softw. Impacts
    2022, 1, 100240. [Google Scholar] [CrossRef] Taylor, S.J.; Letham, B. Forecasting
    at Scale. Am. Stat. 2018, 72, 37–45. [Google Scholar] [CrossRef] Chen, T.; Guestrin,
    C. XGBoost: A Scalable Tree Boosting System. In Proceedings of the ACM SIGKDD
    International Conference on Knowledge Discovery and Data Mining, San Francisco,
    CA, USA, 13–17 August 2016; pp. 785–794. [Google Scholar] [CrossRef] [Green Version]
    El Hachimi, C.; Belaqziz, S.; Khabba, S.; Chehbouni, A. Early Estimation of Daily
    Reference Evapotranspiration Using Machine Learning Techniques for Efficient Management
    of Irrigation Water. J. Phys. Conf. Ser. 2022, 2224, 012006. [Google Scholar]
    [CrossRef] Lawrence, M.G. The Relationship between Relative Humidity and the Dewpoint
    Temperature in Moist Air: A Simple Conversion and Applications. Bull. Am. Meteorol.
    Soc. 2005, 86, 225–234. [Google Scholar] [CrossRef] Parish, O.; Putnam, T.W. NASA
    Equations for the Determination of Humidity from Dewpoint and Psychrometric Data;
    NASA Dryden Flight Research Center: Hampton, VA, USA, 1977. Hochreiter, S. The
    Vanishing Gradient Problem During Learning Recurrent Neural Nets and Problem Solutions.
    Int. J. Uncertain. Fuzziness Knowl. Based Syst. 1998, 6, 107–116. [Google Scholar]
    [CrossRef] [Green Version] Bhanja, S.; Das, A. Impact of Data Normalization on
    Deep Neural Network for Time Series Forecasting. arXiv 2018. [Google Scholar]
    [CrossRef] Singh, D.; Singh, B. Investigating the impact of data normalization
    on classification performance. Appl. Soft Comput. 2020, 97, 105524. [Google Scholar]
    [CrossRef] Wirth, R.; Wirth, R. CRISP-DM: Towards a Standard Process Model for
    Data Mining. In Proceedings of the Fourth International Conference on the Practical
    Application of Knowledge Discovery And Data Mining, Denham, UK, 11–13 April 2000;
    pp. 29–39. [Google Scholar] Fayyad, U.; Piatetsky-Shapiro, G.; Smyth, P. The KDD
    process for extracting useful knowledge from volumes of data. Commun. ACM 1996,
    39, 27–34. [Google Scholar] [CrossRef] Breuniq, M.M.; Kriegel, H.P.; Ng, R.T.;
    Sander, J. LOF: Identifying Density-Based Local Outliers. ACM SIGMOD Record 2000,
    29, 93–104. [Google Scholar] [CrossRef] Carroll, A.B.; Wetherald, R.T. Application
    of Parallel Processing to Numerical Weather Prediction. J. ACM 1967, 14, 591–614.
    [Google Scholar] [CrossRef] Pal, M.; Deswal, S. M5 model tree based modelling
    of reference evapotranspiration. Hydrol. Process. 2009, 23, 1437–1443. [Google
    Scholar] [CrossRef] Yassin, M.A.; Alazba, A.A.; Mattar, M.A. Artificial neural
    networks versus gene expression programming for estimating reference evapotranspiration
    in arid climate. Agric. Water Manag. 2016, 163, 110–124. [Google Scholar] [CrossRef]
    Schultz, M.G.; Betancourt, C.; Gong, B.; Kleinert, F.; Langguth, M.; Leufen, L.H.;
    Mozaffari, A.; Stadtler, S. Can Deep Learning Beat Numerical Weather Prediction?
    Philos. Trans. R. Soc. A 2021, 379, 20200097. [Google Scholar] [CrossRef] [PubMed]
    Gessert, F.; Wingerath, W.; Friedrich, S.; Ritter, N. NoSQL database systems:
    A survey and decision guidance. Comput. Sci.—Res. Dev. 2016, 32, 353–365. [Google
    Scholar] [CrossRef] Shvachko, K.; Kuang, H.; Radia, S.; Chansler, R. The Hadoop
    Distributed File System. In Proceedings of the 2010 IEEE 26th Symposium on Mass
    Storage Systems and Technologies, MSST2010, Incline Village, NV, USA, 3–7 May
    2010. [Google Scholar] [CrossRef] Zaharia, M.; Xin, R.S.; Wendell, P.; Das, T.;
    Armbrust, M.; Dave, A.; Meng, X.; Rosen, J.; Venkataraman, S.; Franklin, M.J.;
    et al. Apache spark: A unified engine for big data processing. Commun. ACM 2016,
    59, 56–65. [Google Scholar] [CrossRef] Probst, P.; Bischl, B. Tunability: Importance
    of Hyperparameters of Machine Learning Algorithms. J. Mach. Learn. Res. 2019,
    20, 1–32. [Google Scholar] Bergstra, J.; Ca, J.B.; Ca, Y.B. Random Search for
    Hyper-Parameter Optimization Yoshua Bengio. J. Mach. Learn. Res. 2012, 13, 281–305.
    [Google Scholar] Nouretdinov, I. Distributed Conformal Anomaly Detection. In Proceedings
    of the 2016 15th IEEE International Conference on Machine Learning and Applications
    (ICMLA), Anaheim, CA, USA, 18–20 December 2016; pp. 253–258. [Google Scholar]
    [CrossRef] [Green Version] Laxhammar, R.; Falkman, G. Online detection of anomalous
    sub-trajectories: A sliding window approach based on conformal anomaly detection
    and local outlier factor. IFIP Adv. Inf. Commun. Technol. 2012, 382, 192–202.
    [Google Scholar] [CrossRef]  Disclaimer/Publisher’s Note: The statements, opinions
    and data contained in all publications are solely those of the individual author(s)
    and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s)
    disclaim responsibility for any injury to people or property resulting from any
    ideas, methods, instructions or products referred to in the content.  © 2022 by
    the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
    article distributed under the terms and conditions of the Creative Commons Attribution
    (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Share and Cite
    MDPI and ACS Style Hachimi, C.E.; Belaqziz, S.; Khabba, S.; Sebbar, B.; Dhiba,
    D.; Chehbouni, A. Smart Weather Data Management Based on Artificial Intelligence
    and Big Data Analytics for Precision Agriculture. Agriculture 2023, 13, 95. https://doi.org/10.3390/agriculture13010095
    AMA Style Hachimi CE, Belaqziz S, Khabba S, Sebbar B, Dhiba D, Chehbouni A. Smart
    Weather Data Management Based on Artificial Intelligence and Big Data Analytics
    for Precision Agriculture. Agriculture. 2023; 13(1):95. https://doi.org/10.3390/agriculture13010095
    Chicago/Turabian Style Hachimi, Chouaib El, Salwa Belaqziz, Saïd Khabba, Badreddine
    Sebbar, Driss Dhiba, and Abdelghani Chehbouni. 2023. \"Smart Weather Data Management
    Based on Artificial Intelligence and Big Data Analytics for Precision Agriculture\"
    Agriculture 13, no. 1: 95. https://doi.org/10.3390/agriculture13010095 Note that
    from the first issue of 2016, this journal uses article numbers instead of page
    numbers. See further details here. Article Metrics Citations Crossref   10 Web
    of Science   8 Scopus   8 Google Scholar   [click to view] Article Access Statistics
    Article access statistics Article Views 29. Dec 8. Jan 18. Jan 28. Jan 7. Feb
    17. Feb 27. Feb 8. Mar 18. Mar 0k 2k 4k 6k 8k For more information on the journal
    statistics, click here. Multiple requests from the same IP address are counted
    as one view.   Agriculture, EISSN 2077-0472, Published by MDPI RSS Content Alert
    Further Information Article Processing Charges Pay an Invoice Open Access Policy
    Contact MDPI Jobs at MDPI Guidelines For Authors For Reviewers For Editors For
    Librarians For Publishers For Societies For Conference Organizers MDPI Initiatives
    Sciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia JAMS Proceedings
    Series Follow MDPI LinkedIn Facebook Twitter Subscribe to receive issue release
    notifications and newsletters from MDPI journals Select options Subscribe © 1996-2024
    MDPI (Basel, Switzerland) unless otherwise stated Disclaimer Terms and Conditions
    Privacy Policy"'
  inline_citation: '>'
  journal: Agriculture (Switzerland)
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Smart Weather Data Management Based on Artificial Intelligence and Big Data
    Analytics for Precision Agriculture
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

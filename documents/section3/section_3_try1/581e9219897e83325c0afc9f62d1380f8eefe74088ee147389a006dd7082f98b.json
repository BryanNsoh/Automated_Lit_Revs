[
    {
        "title": "Selecting the optimal transfer learning model for precise breast cancer diagnosis utilizing pre-trained deep learning models and histopathology images",
        "doi": "10.1007/s12553-023-00772-0",
        "description": "Background: Every year, around 1.5 million women worldwide receive a breast cancer diagnosis, which is why the mortality rate for women is rising. Scientists have developed Convolutional neural network models in recent years to simplify the breast cancer diagnosis process. CNN displays encouraging findings for cancer classification using image datasets. However, there are not yet any best-in-class standard models because big datasets are insufficient for training and verifying models. Method: To fully utilize the transfer learning technique, researchers are now focusing on using pre-trained feature extraction models trained on billions of images. The parallel processing of data at several clusters is necessary to keep up with the continually expanding datasets. Two factors are necessary to design a perfect and precise breast cancer diagnostic neural model. One is that the selected imaging modality will primarily determine the model's prediction path. The neural network model employed for breast cancer prediction and the environment in which it is applied comes in second. Data processing in parallel across several clusters and hardware demands for greater processing capacity, such as GPU and TPU, is necessary to keep up with the continuously expanding datasets. Results: The impact of high-performance computing and a critical examination of the pre-trained models employed in breast cancer picture categorization are discussed. In this paper, a thorough analysis of image modality's influence on the accuracy of breast cancer detection is done. In addition, the primary breast cancer detection pre-trained models are reviewed, and the effects of HPC on CNN training are investigated. Major transfer learning techniques (VGG16, Xception, and others) are used in the case study to analyze an image collection of invasive ductal carcinoma (IDC), a type of breast cancer. The study suggests using CNN architectures built on deep neural networks and pre-trained networks to identify breast cancer. The results show that CNN performs better for feature extraction, optimization, and classification of breast cancer images when GPU is used. The length of training has drastically changed. High-powered systems speed up the process of identifying cancer, which facilitates the analysis of patterns in the dataset\u2014something that is impossible for humans to do. High-performance technologies make it simple to analyze complicated patterns.",
        "journal": "Health and Technology",
        "authors": [
            "Ravikumar A.",
            "Sriraman H.",
            "Saleena B.",
            "Prakash B."
        ],
        "citation_count": "0",
        "full_text": "\"Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement Log in Find a journal Publish with us Track your research Search Cart Home Health and Technology Article Selecting the optimal transfer learning model for precise breast cancer diagnosis utilizing pre-trained deep learning models and histopathology images Review Paper Published: 19 August 2023 Volume 13, pages 721\u2013745, (2023) Cite this article Download PDF Access provided by University of Nebraska-Lincoln Health and Technology Aims and scope Submit manuscript Aswathy Ravikumar, Harini Sriraman , B. Saleena & B. Prakash  199 Accesses Explore all metrics Abstract Background Every year, around 1.5 million women worldwide receive a breast cancer diagnosis, which is why the mortality rate for women is rising. Scientists have developed Convolutional neural network models in recent years to simplify the breast cancer diagnosis process. CNN displays encouraging findings for cancer classification using image datasets. However, there are not yet any best-in-class standard models because big datasets are insufficient for training and verifying models. Method To fully utilize the transfer learning technique, researchers are now focusing on using pre-trained feature extraction models trained on billions of images. The parallel processing of data at several clusters is necessary to keep up with the continually expanding datasets. Two factors are necessary to design a perfect and precise breast cancer diagnostic neural model. One is that the selected imaging modality will primarily determine the model's prediction path. The neural network model employed for breast cancer prediction and the environment in which it is applied comes in second. Data processing in parallel across several clusters and hardware demands for greater processing capacity, such as GPU and TPU, is necessary to keep up with the continuously expanding datasets. Results The impact of high-performance computing and a critical examination of the pre-trained models employed in breast cancer picture categorization are discussed. In this paper, a thorough analysis of image modality's influence on the accuracy of breast cancer detection is done. In addition, the primary breast cancer detection pre-trained models are reviewed, and the effects of HPC on CNN training are investigated. Major transfer learning techniques (VGG16, Xception, and others) are used in the case study to analyze an image collection of invasive ductal carcinoma (IDC), a type of breast cancer. The study suggests using CNN architectures built on deep neural networks and pre-trained networks to identify breast cancer. The results show that CNN performs better for feature extraction, optimization, and classification of breast cancer images when GPU is used. The length of training has drastically changed. High-powered systems speed up the process of identifying cancer, which facilitates the analysis of patterns in the dataset\u2014something that is impossible for humans to do. High-performance technologies make it simple to analyze complicated patterns. Similar content being viewed by others A Review on Deep Learning Approaches for Histopathology Breast Cancer Classification Chapter \u00a9 2023 Using Transfer Learning with Convolutional Neural Networks to Diagnose Breast Cancer from Histopathological Images Chapter \u00a9 2017 A Review of Deep Learning Techniques Used in Breast Cancer Image Classification Chapter \u00a9 2021 1 Introduction Studies conducted in America about the speed of incidence of breast cancer have shown an increase of 0.3% per [1,2,3]. The death rate of a person with breast cancer is about 1 in 38, around 2.6%. Studies conducted in India have shown that breast cancer is occurring at a rate of 25.8 women in a total of 100000 women in India. Furthermore, the immediate need of the hour is the prediction and early accurate detection of breast cancer. Of all cancer, breast cancer forms about 12%. The studies show that the five-year survival index of breast cancer patients in India is low compared to the United States, which is 90%, and India, which is only around 60%. Earlier, breast cancer was found in women above 50 years, but lately, it was found that the much younger generation, around 25, was also affected by breast cancer. On average, a woman is likely to develop breast cancer at 40 in India, much younger than in other countries. The primary reason for breast cancer is mainly genetic, family history, or DNA damage. Nevertheless, the main reasons are environmental changes, lack of physical activity, and lifestyle changes leading to obesity and hormonal imbalances. Overusing birth control pills impacts the estrogen level in the body, leading to hormonal imbalances. The main signs of breast cancer are the masses and macrocalcifications in the breast area, and timely identification is essential for predicting, detecting, and treating cancer. The masses can be mainly classified as either malignant or benign. Masses classified as benign are non-cancerous, but on the other side, the malignant masses will grow and can lead to secondary cancer stages. This is the main reason for early diagnosis and timely cancer detection. Macrocalcifications are the calcium deposits in the breast. These deposits appear as bright spots in the mammography images. These deposits may develop into a cluster, a sign of cancer. It is one of the safest, low-cost, and low-risk methods, but the main difficulty is interpreting the images and a very experienced radiologist. Furthermore, to make the analysis of mammographic images more effective, the computer-aided system is designed to reduce human errors. The main reason for this decrease in survival rate is the lack of timely detection at the early stages of cancer. The main advantage of using computer-aided diagnosis techniques is timely cancer detection. The advancement in extensive data analysis and machine learning has made a massive difference in medical diagnosis. Data mining and machine learning provide a high-performance-based prediction system that reduces the cost of healthcare and medicines and provides a better healthcare service. Unfortunately, the data size is overgrowing, and the available algorithms need to scale for large datasets. Mammography images are the most popular methods professionals use to diagnose cancer, requiring skilled radiologists. The manual approach may result in significant numbers of false positives and false negatives. Consequently, computer-aided diagnostic systems are widely utilized nowadays to assist radiologists with cancer identification making decisions. CAD systems can now reduce radiologists' work and the amount of erroneous positive and negative diagnoses. In numerous healthcare applications, machine learning approaches have shown superior performance than conventional computer-aided systems for illness detection and patient monitoring [4, 5]. Additionally, it needs topic expertise and a skilled radiologist. In the meantime, deep learning models automatically generate an adaptive learning experience and may extract characteristics from the input data based on the desired output [6, 7]. The DL approaches drastically decrease the time-consuming data engineering or feature extraction processes while making the methods reusable. Numerous studies [8,9,10,11,12] have investigated breast cancer pictures from diverse perspectives. CNN models have been used well in diverse computer vision applications for many years [6, 13]. In recent years, various studies have used CNN-based architectures for illness detection. A CNN-based image identification and classification model was perhaps first used in the ImageNet competition [14]. CNN has remarkable learnable parameters at its many layers, which are used to extract meaningful information at several abstraction levels [10, 15, 16]. Pretrained algorithms are often employed as feature extractors in pictures ranging from conceptual through detailed levels. Breast malignancies are often classified using CNN-powered deep-learning models. To cope with the rapidly growing datasets, the parallel processing of data at different clusters and hardware requirements like GPU [17] and TPU for more processing power to faster data processing in parallel in different cores. Transfer learning is essential in medical imaging studies; it may require more training data sets for deep learning algorithms. Although several researchers have tried to utilize transfer learning for medical image analysis, only a few review publications on the topic have been released. In addition, evaluations on using transfer learning on breast images combined with high-performance computing hardware are uncommon. This paper examines prior research that employed transfer learning to diagnose breast cancer to summarize known approaches and highlight their benefits and drawbacks. Moreover, this article discusses prospective future research topics for the use of transfer learning and HPC in ultrasonic imaging for the timely identification and diagnosis of breast cancer. This review is anticipated to significantly assist researchers in identifying better approaches and regions that may be enhanced via more studies on transfer learning and HPC. 1.1 Motivation Medical image analysis is often performed manually by an experienced physician. If many pathologists are present during breast cancer histopathology image analysis, the entire decision is produced following permission; otherwise, the pathologist describes the results. Nevertheless, human histopathology image analysis presents several challenges [18]. Initially, in several low-income and developing nations, skilled pathologists are limited. Moreover, pathologists find multi-class categorization using image analysis to be a time-consuming and complicated process. First, during image analysis, doctors may have diminished concentration and suffer weariness. Lastly, a competent pathologist's topic expertise and professional experience are essential for identifying breast cancer subtypes consistently. Specifically, these problems have led to misinterpretation of breast cancer in its early stages. In contrast, computer-aided diagnostic (CAD) systems may assist in resolving breast cancer multiclassification issues as a second viewpoint. The primary purpose of this study is to assist researchers in exploring existing deep-learning approaches in conjunction with High-Performance Computing to build a computationally efficient strategy for breast cancer classification. This article highlights the imaging techniques used to classify breast cancer. It facilitates a thorough study of researchers' numerous transfer learning models employed in breast cancer categorization. The highlights of the different transfer learning and deep learning strategies used to classify breast cancer and the performance metrics used to assess the models are mentioned. In addition, unlike other breast detection evaluations, this one provides a comprehensive look into the numerous HPC utilized in medical diagnostics. Finally, a comprehensive case study of breast cancer histopathology image transfer learning models on HPC-GPU is presented. This demonstrated the influence of HPC in diagnosing breast cancer in terms of performance and speed-up. 1.2 Contributions The significant contributions of this review are: A detailed study on the breast cancer imaging modalities used in computer-aided diagnosis Understanding the significance of transfer learning and review of the significant transfer learning in breast cancer diagnosis Understanding the need for High-Performance Computing in Breast cancer diagnosis Case study to show the impact of HPC on breast cancer diagnosis Illustrate the acceleration and speed up of breast cancer prediction using pre-trained CNN and the utilization of high-performance computing. 1.3 Paper structure The study is organized as follows: Sect. 2 has background details; Sect. 3 explains the search strategy used in this review; Sect. 4 is the Deep learning algorithms in breast cancer classification; Sect. 5 briefly reviews High-Performance computing on Breast cancer Diagnosis. Section 6 presents a case study on breast cancer images using different transfer learning models in graphic processing units. In Sect. 7, the main challenges in breast cancer diagnosis are given, and in Sect. 8, the future scope is explained. Final Sect. 9 gives the conclusion of the review. 2 Background 2.1 Breast cancer Breast cancer has been established to be one of the most challenging diseases throughout the history of humankind. It is now the most prevalent form of malignancy among women and one of the three most prevalent cancers globally. In 2012, there were around 1.7 million new instances of breast cancer, with approximately 31% resulting in death. In contrast, the breast cancer death rate has dropped, which may be ascribed to early identification and effective systemic therapy. There is no obvious explanation for the incidence of breast cancer. However, smoking, being overweight, lack of exercise, drinking, illnesses, and biological and genetic pathways enhance the risk of developing cancer. Previous research has shown that early diagnosis approaches boost survival rates by up to four years. Significant signs of breast cancer include breast tissue enlargement, fixed lumps with uneven boundaries, skin alterations such as thickness, discoloration, dimples, nipple discharge, and breast and nipple discomfort. When breast cancer is found early, the survival percentage is relatively high. Manual inspection has been the primary diagnostic method, and multiple clinical breast imaging techniques are employed. Mammography employs X-rays with a low energy of 20-30 keV and is the standard monitoring and diagnostic procedure. According to research, the sensitivity of this approach is around 75%; however, in middle-aged individuals whose breast tissue frequently has a greater mass concentration, its sensitivity drops to approximately 50%. Therefore, differentiating between malignant and benign tumors becomes more complex in certain instances. MRI is the second primary method. This technique can discover false positives despite its great sensitivity in cancer diagnosis. The high cost and length of time associated with MRI as a conventional breast imaging technique are drawbacks. However, this approach is recommended in high-risk situations. Ultrasound is the third approach for identifying breast cancer. The diagnostic effectiveness of this procedure technique is contingent upon the scanner operator's skill and the selection of appropriate ultrasonic settings. On the contrary hand, with standard ultrasound methods, it is difficult to distinguish between cysts and tumors. Consequently, color Doppler and power Doppler aid in identifying breast cancer owing to their enhanced capacity to differentiate tumors. MRI and ultrasound are the sole supplementary methods to mammography at now. In recent research, it was shown that when mammography and ultrasound are used together, the test's diagnostic accuracy reaches 97%, but mammography by manual inspection only reaches 74%. 2.2 Breast cancer imaging modalities This section demonstrates that breast cancer classification comprises distinct medical imaging modalities and associated multimodal pairings. The primary imaging modalities in breast cancer are briefed in Table 1. Table 1 Breast cancer imaging Modalities Full size table 2.2.1 Ultrasound (US) / sonograms US collects breast pictures in real-time, allowing breast lesions to be seen from various perspectives and orientations. US may further assist with breast needle biopsy to investigate breast tissue's inherent characteristics. According to standard clinical procedures, US is not utilized like MG for mammography screening. US is the most effective method for detecting anomalies in MG or examining the appearance of a solid lump or fluid-filled area. As a result of acquiring breast pictures from many orientations, US reduces the likelihood of false-negative diagnoses. The United States does not expose people to dangerous radiation and is thus deemed safe for pregnant ladies. US is also regarded as a reliable screening for breast carcinoma method. If the probe of the scanning is not adjusted or depressed appropriately, ultrasound might generate erroneous diagnoses. Because US waves decrease in the regular muscular system, they cannot correctly display the breast tumor's outline. Using imaging, ROI extraction for subsequent research is challenging. The sample breast cancer US image is shown in Fig. 1 in which a split-screen display of shear-wave elastography (right) and B-mode images (left) reveals a 13-mm irregular mass with red, heterogeneous elasticity. To assess the elasticity values, the region of interest (ROI) was positioned over the stiffest area of the lesion (circle), and measurements were taken for mean, minimum, maximum, and standard deviation of elasticity values in kilopascals (kPa). Additionally, the elasticity ratio of the mass to the surrounding fat tissue was determined by placing a second ROI over the adjacent fat tissue (dotted circle). The ROI encompassed the entire breast lesion along with the stiffest portion for accurate elasticity measurement. Fig. 1 Ultrasound image [19] Full size image 2.2.2 Magnetic resonance imaging (MRI) MRI is a screening method that employs electromagnetic waves and microwave transmitters to acquire a detailed picture of soft tissues. Consequently, breast MRI scans provide more detailed views of mammary soft tissue compared to MGs, US images. Additionally, MRI may reveal worrisome breast regions that can be biopsied using MRI-guided biopsy. An MRI scanner acquires many breast pictures of a single patient and merges them into a comprehensive view. MRI is often ordered after a cancer diagnosis and the physician wants to determine the disease's severity. Similarly, MRI does not expose patients to hazardous radiation exposure to US. MRI may indicate questionable spots that can be explored further through a biopsy, often known as MRI-guided histopathology. Compared to mammograms and ultrasounds, magnetic resonance imaging is costly and not often used for breast cancer detection. While MRI offers precise information about the breast's internal tissues, it may miss certain malignant areas that MGs can identify. Therefore, MRI is often indicated as a second opinion test once MGs-based testing has been performed. MRI is typically contraindicated during maternity. To improve MRI pictures, contrast chemicals are often injected, which might also cause allergic reactions or other issues and is thus contraindicated for patients, particularly renal patients. The sample breast cancer MRI image shown in Fig. 2 is the mammogram that revealed architectural distortion, while the CT scan indicated some abnormalities. However, the MRI provided the most accurate depiction of the cancer. Fig. 2 Breast MRI images [20] Full size image 2.2.3 Histopathology (HP) images During HP biopsy imaging, mammary tissue sections are extracted from aberrant regions and mounted on glass microscopic examination. The slides are dyed with hematoxylin\u2013eosin and inspected by pathology to detect malignant tissues. In addition, these dyed slides were scanned and transformed into digital color pictures known as WSIs. Experienced pathologists often create ROI patches from WSI with different zoom settings to identify noninvasive malignancy or invasive types, which is impossible with grayscale. HP pictures are colourful images with the capacity to diagnose a variety of cancer kinds. It provides a more accurate diagnosis of breast cancer in its early stages. With HP pictures, a thorough study of breast tissues is feasible, allowing for a more specific cancer diagnosis than any other imaging technique. Multiple ROI pictures may be generated from whole-slide HP images, increasing the likelihood of detecting cancerous regions and decreasing the false-negative rate. HP pictures are obtained using breast biopsies, an invasive technique with more hazards than other imaging modalities. HP photos are challenging to interpret. Consequently, specialist pathologists are necessary for their proper analysis. Manual examination of HP pictures is a time-intensive endeavour. During the assessment, pathologists must pay special attention to HP pics. The sample breast cancer HP image is shown in Fig. 3. The images are collected using to determine the aggressiveness grade of Invasive Ductal Carcinoma (IDC) in whole-mount slide images of Breast Cancer specimens, pathologists typically focus on the regions containing IDC. To facilitate automatic aggressiveness grading, a common pre-processing step involves accurately delineating the IDC regions within the whole mount slides. Fig. 3 Breast Histopathology images [20] Full size image 2.2.4 Mammogram (MG) Mammography imaging, commonly called low-dose chest X-ray pictures, allows the radiologist to examine soft tissue for abnormalities. MGs have already been investigated during the last couple of decades, so MG screenings are often recommended at a preliminary phase. In MG examination, a radiologist searches for micro-calcifications, which appear as minute white spots or flakes and are composed of calcifications with uneven form. As mentioned, MGs are the most popular imaging technique utilized to examine breast tissues for cancer investigation. These are low-intensity X-ray photographs of a person's chest\u2014an approach to diagnosing breast cancer. Digital mammograms offer a fast and cost-effective method for capturing, storing, and processing pictures of breast tissue. DMGs are used as a training dataset for Artificial intelligence systems. Unlike HP pictures, DMGs do not need a high level of experience or expertise to analyze and classify. Due to the tiny size and distributed form features of MGs, which are generated by low-dose chest X-rays, their ability to detect micro-calcification inside the human breast is restricted. MGs have limitations in identifying breast cancer in thick breasts because of the absence of malignant tissue. MGs are not always reliable for identifying breast cancer; further testing may be necessary for precise diagnosis. The different imaging modalities in breast cancer are shown in Fig. 4. The figure shows three different imaging modalities mammogram, ultrasound and MRI. The different approaches are explained earlier. Fig. 4 Breast different imaging modalities [20] Full size image 2.3 Datasets in breast cancer The primary open source freely available datasets in breast cancer classification are listed in Table 2. Table 2 Commonly used Breast cancer public datasets Full size table 2.4 Computer-aided diagnosis (CAD) The computer-aided diagnosis model may give extra information and aid in diagnosing cancer and cancer staging decisions. A computer-aided Diagnosis model seeks to identify, locate, and classify suspicious areas. A CAD model may be placed before a diagnostic model for a thorough study, beginning with identifying and localizing suspicious areas and ending with their diagnosis. A CAD system offers a low-cost, rapid, trustworthy, and widely accessible source for early cancer detection. This technique may reduce the mortality rate by between 30 and 70 per cent [59]. The development of digitized medical pictures has provided profound learning advantages for performing pattern identification in CAD schemes. CAD systems may aid doctors by analyzing automated pictures. It is stated that a CAD categorization approach increases sensitivity by 10%. Despite categorization [11, 31, 32], CAD systems may be developed to perform additional diagnosis-related activities, such as lesion segmentation [33], registering, fragmentation [34], and grading [35]. The main steps in the CAD model are shown in Fig. 5. Fig. 5 CAD Model Full size image 3 Search strategy We conducted a comprehensive search using a combination of subjects and keywords to include Breast cancer classification using transfer learning and High-performance computing. In addition, we conducted a referential retrace using the most recent research to ensure that all relevant publications were included. The medical and technical papers from PubMed, Web of Science, IEEE Xplore, Science Direct, Scopus, ACM, Springer Link, and Google Scholar were examined. The research focuses on recent articles published between 2017 and 2022. While screening and reviewing, articles with poor techniques and findings were eliminated. The top search terms used include \\\"convolutional neural network,\\\" \\\"deep learning,\\\" \\\"transfer learning,\\\" \\\"high-performance computing,\\\" and \\\"breast cancer.\\\" This study focuses on applying HPC and transfer learning to categorize breast cancer. Also eliminated were studies that used deep learning and machine learning approaches to investigate other diseases. This list of reliable research sources included only peer-reviewed publications, conference proceedings, papers, and published works. There were no restrictions on the country, study design, or results in publication. Included is English-language research published between 2018 and 2022. Additionally, superfluous titles and contents were deleted. The search strategy used in this study is shown in Fig 6, and the search criteria are in Table 3. The different tools used in this study are the following : Fig. 6 Search Strategy Full size image Table 3 Search Criteria Full size table Google Colaboratory (Colab): Colab is a cloud-based platform that provides free access to GPUs and allows you to run and write code in Python. It is commonly used for deep learning tasks and is suitable for implementing and executing the transfer learning model for breast cancer diagnosis. Deep Learning Frameworks: Popular deep learning frameworks such as TensorFlow and PyTorch can be used to build and train the transfer learning model. These frameworks provide a high-level API and pre-trained models that can be easily integrated into the breast cancer diagnosis system. Pre-trained Models: There are several pre-trained deep learning models available that have been trained on large-scale image datasets, such as VGG, ResNet, Inception, and EfficientNet. These models can be fine-tuned and used as a starting point for the transfer learning process in the breast cancer diagnosis system. Image Processing Libraries: Libraries like OpenCV or PIL (Python Imaging Library) can be employed for image preprocessing and augmentation tasks. They offer functionalities for resizing, cropping, and applying various image transformations to enhance the training data. 4 Deep learning in breast cancer 4.1 Convolutional neural network (CNN) CNN is a widely used deep learning algorithm applied to various fields, including self-driving cars, medical research, and environmental science. CNN is mainly divided into two distinct operations. The first step is convolution, which can be used to keep the value in Rectified Linear Units (ReLU). The second process used pooling techniques to lower the number of characteristics. CNNs are deep learning models meant to read essentially two-dimensional input pictures and apply trainable weights and biases to different objects in the image to generate feature maps that summarize the discovered characteristics [36, 37]. The convolution layer performs a convolution, a linear operation that multiplies the input with a set of weights. For example, the kernel convolution technique accepts a kernel, applies it to the input matrix, and alters the image depending on kernel values. The basic Convolutional formula is given in Eq. 1, with f and g denoting kernel functions, and the result is in the h matrix. $$h\\\\left[m,n\\\\right]=\\\\left(f*g\\\\right)\\\\left[m,n\\\\right]=\\\\sum_{j}{\\\\sum }_{k}g\\\\left[j,k\\\\right]f[m-j,n-k]$$ (1) Apply convolution a limited number of times before the image entirely vanishes due to the image's shrinking size after each operation. Moreover, observing how the kernel traverses the picture, the influence of pixels on the image's periphery is far less than that of pixels in the image's centre visible. Consequently, loss of a portion of the image's information. To address these issues, pad the picture with a border. The matrix size obtained after stride and padding is given by Eq. 2. $${n}_{out}=\\\\frac{{n}_{in}+2p-f}{s}+1$$ (2) The final output matrix's dimensions are obtained by Eq. 3, where nf is the filter count, nc is the channel count, p is the padding size, s stride size, and n is the image dimension. $$\\\\left[n,n,{n}_{c}\\\\right]*\\\\left[f,f,{n}_{c}\\\\right]=\\\\left[\\\\left[\\\\frac{n+2p-f}{s}+1\\\\right],\\\\left[\\\\frac{n+2p-f}{s}+1\\\\right],{n}_{f}\\\\right]$$ (3) Two stages comprise forward propagation. The first step is to compute the intermediate state Z, generated by convolving the previous layer's input data with the W tensor and adding bias b. The second step involves applying a nonlinear activation function to the interim stage. The general structure of CNN is shown in Fig. 7. Fig. 7 CNN Architecture Full size image There are two methods for configuring the Convolution algorithm to create a classifier model. The initial learning method is the first technique. This approach utilizes a new architecture and begins by learning the information from scratch in the model learning stage. The second strategy is known as transfer learning. This approach employs the pre-train network with fine-tuning and adjusts the pre-train network to fit the dataset. The transfer learning approach shortens the time required to train a model in the learning state. Under a deep learning context, various CNN architectures influence the success of classification and segmentation. With the aid of transfer learning, new issues similar to old ones can be solved more rapidly and efficiently. 4.2 Transfer learning Compared to conventional deep learning techniques, transfer learning techniques use the knowledge acquired from information in related domains to enable predictive modeling of various patterns in data inside the testing environment [38]. Researchers concentrated on evaluating how the CNN learned in the trained data is transferred to different datasets with novel forms and shares properties with trained data. This is to train the CNNs to execute shape classification tasks. It can ascertain if CNNs retrieve a feature during learning by changing the training and transfer datasets. The objective was to test two classifications of CNN image theories explicitly. According to the first theory, learning, depending on specific features, is transferred more effectively than learning based on broad features. According to the second theory, CNNs with sophisticated designs have more effective learning transfer rates in global components. Transfer learning is a typical technique for generating neural network models regardless of the amount of available data. Transfer learning permits the application of a previously specified model to several difficulties. It is possible, for instance, to use a pre-trained model with one reason, such as recognizing cell types, and afterwards fine-tune it for a different purpose, such as diagnosing tumors. Transfer learning is an important technique for computer vision-related tasks. Several domain adaptation experiments [36] have shown that ImageNet-learned characteristics are readily transferrable to various picture classification techniques. Two methods exist for transmitting data from one model to another. Typically, the final layer of an already trained model is replaced with a random initialization layer. The variables inside the higher layer are taught for the new work, while other parameters remain constant. This strategy can be viewed as deploying the transferable models as just a feature extractor [37], in which the fixed component serves as a feature representation, and the top layer operates as a standard, linked layer of neural nets with no input data assumptions [37]. If the data and tasks are similar to that used to develop the original model, this strategy is more successful. When there is insufficient data to develop a model for the target task, transfer learning may be the sole option for creating a classifier without overfitting because training fewer parameters reduces the risk of overfitting. It is possible to thaw transmitted parameters to train the whole network [38] when more training data are available, which is unusual in the medical industry. Essentially, the parameter's initial values are conveyed in this circumstance. To ensure optimum performance, the model's weights with a pre-trained model instead of randomly may provide a more promising start and enhance convergence [39], enabling fine-tuning. Customarily, to keep the pre-training activity, the learning rate is reduced by a magnitude [40, 41]. To avoid changing transferred parameters too early, it is customary to start with frozen variables [42, 43], train just randomized initialization layers until completion, and then unfreeze all parameters and fine-tune the entire network. Transfer representation learning approach in which a model learned for a task is rebuilt in a similar second challenge. Transfer learning is a deep learning algorithm that enables a model trained on a specific issue to be applied to a different challenge. It is a promising approach, particularly for image processing, since it allows for the creation of precise and time-saving models at times; training deep CNN models on massive datasets might take days or weeks. A technique for expediting this approach is to utilize model parameters from pre-trained neural models constructed for well-known computer vision benchmark functions such as ImageNet. Thus, the models required to solve our challenges may be constructed more simply without starting from scratch using what past models have learned [39]. A detailed explanation of the working of CNN in GPU and TPU with the acceleration methods is shown in [39]. In addition, this study examined how the learning was transferred across sample CNN models, namely VGG16, ResNet50, Xception, DenseNet, and Mobilenet, which were trained on ImageNet and classified the breast cancer images with high accuracy. 4.3 Transfer learning models The primary transfer learning models in breast cancer diagnosis are reviewed in this section. 4.3.1 AlexNet The structure comprises eight layers: 5 convolution layers and three fully-connected layers. These are some of the characteristics employed that are innovative approaches towards deep neural networks which make Alexnet unique - Nonlinearity of ReLU. AlexNet [40] employs ReLU instead of the tanh function, which was typical then. ReLU's benefit is in learning speed. AlexNet enables multi-GPU learning by placing halves of the model's neurons solely on a single GPU and the other half on another GPU. It implies that a larger model may be learned but also reduces the training time. CNNs usually \\\"pool\\\" responses of adjoining clusters of neurons without any overlapping. Overlapping pooling detected a drop in errors by roughly 0.5 percent and discovered that networks are challenging to overfit. AlexNet is a robust network capable of obtaining high levels of accuracy on challenging datasets. However, deleting any convolution layers would severely reduce AlexNet's performance. 4.3.2 SqueezeNet SqueezeNet [41]is a smaller network created as a more compact substitute for AlexNet. It has roughly 50x fewer parameters than AlexNet but works 3x quicker. The SqueezeNet design comprises \\\"squeeze\\\" and \\\"expand\\\" layers. A squeeze convolutional layer contains just 1 X 1 filter. These are sent into an expanded layer comprising 1 \u00d7 1 and 3 \u00d7 3 convolution filters. The research authors use the term \\\"fire module\\\" to define a squeeze and expansion layers together. An input picture is initially delivered into a solitary convolutional layer. The following fundamental concepts behind Squeeze Net: Strategy 1: Use 1x1 filters rather than 3x3 filters. Strategy 2: Reduce the count of input channels to three filters. Strategy 3: To ensure tremendous activation values use downsampling. 4.3.3 Inception v3 Inception v3 [42] principally concentrates on consuming fewer processing resources by changing the previous Inception designs. Compared to VGGNet, Inception Networks have become more highly scalable regarding the number of parameters created by the networks and the financial cost incurred. If any modifications need to be done to an Inception Network, care must be exercised to recover the computational benefits. Inside an Inception v3 model, numerous strategies for improving the network are forward to remove the restrictions for faster model adaption. The approaches include factorized convolutions, regularization, downsampling, and parallel processing calculations. 4.3.4 NASNet Neural Search Architecture Network (NASNet) is the method of automating the topology design of neural nets to obtain optimal efficiency on a given task. The objective is to create a structure with limited resources and minimum human input. The authors [43] suggest searching a small dataset for an architecture block and transferring it to a more extensive one. Specifically, they seek the optimal convolution layers and then apply that cell to ImageNet by stacking several copies. Scheduled Drop Path, a novel regularization strategy that considerably enhances the generalization of NASNet models, is also presented. 4.3.5 VGG 16 Visual Geometric Group CNN was introduced in 2014 [44]. This model's primary aim was to investigate depth's influence on performance when learning networks for image applications. The VGG network developed the concept of combining numerous convolution layers with smaller kernel sizes rather than maintaining one Convolutional layer with a big kernel size. This led the number of features in the output to drop, and the second also included 3 ReLU instead of single boosting training instances. The feed to the first convolutional layer is a 224 x224 RGB picture. The picture is sent through a series of convolution layers, in which the filtering was utilized with a narrow receptive field. 4.3.6 ResNet50 ResNet was released in 2015 [45] and delivered a significant increase in performance and a substantial speed increase. VGG has proposed adding layers for higher accuracy. However, it was observed that when we raise the layer thickness above 20, the model can indeed not converge towards the slightest error per cent. A fundamental cause is the vanishing gradient issue. The learning rate gets so reduced that no modifications are incorporated into the model's parameters. Another area for improvement was the expansion of gradients. This was rectified when Batch Normalization was implemented, but it still varies across a narrow range. To overcome this, residual learning was established, which was inspired by the idea of lateral inhibition in the brain. It simply implies that neurons can influence whether their nearby neurons activate. ResNet introduced the notion of skip connection. The ResNet design does not need to start all neurons in every epoch. This substantially decreases the training time and enhances accuracy. Once one feature is learned, it does not attempt to understand it but instead concentrates on learning additional features. An innovative method that dramatically enhanced outstanding training performance. 4.3.7 MobileNet v2 In MobileNet [46], depthwise Separable Convolution is presented, substantially lowering the computational cost and model number of connections applicable to Mobile platforms or any gadgets with limited computational resources. MobileNetv2 improves upon these principles by employing depth-wise separable convolution as effective construction blocks. However, v2 offers two new aspects to the architecture: linear bottlenecks between layers and shortcut interconnections between the constraints. In MobileNetV2, an improved module is provided, having an inverted residual structure. With MobileNetV2 as the basis for extracting features, state-of-the-art results are also obtained for object identification and semantic segmentation. MobileNetv2 increases the state-of-the-art developments of mobile models on many workloads and benchmarks and over a spectrum of different model sizes. 4.3.8 Xception Xception is another Inception derivative. Authors [47] have substituted inception modules with depth-wise separable convolution. To regulate sophisticated processing in the network, several spatial dimensions, such as 1x1, 3x 3, and 5x 5 of the inception CNN model, are substituted by a single 3x3 convolution succeeded by a 1x1 convolution. 1x1 convolution layers capture cross-feature mapping correlation, while standard 3x 3 convolutions take spatial relationships within each channel. This concept is extreme by Xception, which applies 1x1 to each input channel and 3x3 to every output. The modification implemented by Xception also could not lower the number of variables, but it may facilitate more efficient learning and enhance the system's effectiveness. 4.3.9 DenseNet A DenseNet [48] is a form of the convolutional network which employs dense connections across layers, using Dense Blocks, in which all layers are connected. To maintain the feed-forward structure, each layer receives extra inputs from all previous levels and transmits its function to all following layers. DenseNet was explicitly designed to increase accuracy created by the vanishing gradient in elevated neural networks due to the considerable distance between input and output layers and the information disappearing before achieving its objective. Features retrieved by really early layers are utilized directly by later layers within the same dense block. Additionally, the weights of the transition layer are distributed across all previous levels. Layers inside the second and third thick blocks continuously accord minor importance to the outputs of transition layers. At the final classification stage, weights are concentrated on the final feature maps. Later in the network, a few higher-level characteristics are produced. A detailed comparison of the networks with the network details and features is given in Table 4. Table 4 Transfer Learning Networks Full size table 4.4 Related work The main objective of machine learning and deep learning algorithms is data classification. The main supervised algorithms, SVM, Na\u00efve Bayes, Decision Tree, and artificial neural networks, were compared for the best prediction accuracy. The SVM gave the best accuracy of 96.84% in breast cancer [49]. Ensemble learning methods were used for the survival analysis of the breast cancer datasets. Performance analysis of SVM, KNN, Decision tree algorithm C4.5, and Na\u00efve Bayes was compared on the breast-cancer Wisconsin dataset, of which SVM gave the best accuracy of 96.99% [50]. The neuro-fuzzy algorithm was implemented on the same dataset, providing an accuracy of 95.06%and. Later the accuracy was improved using 10-fold cross-validation. The bagging technique was used for data multiplication from the original data [51]. Classification into two classes, survived and not survived, was performed on a dataset of 202,932 patients with breast cancer, and the survival rate was around 93% accuracy. Compared to typical machine learning algorithms, deep learning algorithms perform better in image classification and recognition [52]. The main advantages of deep learning algorithms are automatic feature detection and extraction. Neural networks are widely used for the prediction of breast cancer. Multi-Layer Perceptron and Radial Basis Function were implemented in the breast-cancer Wisconsin dataset, and it was found to give an accuracy of 95% and 97%, respectively [53]. In the early days, the evolutionary and ensemble approaches were used for ANN implementation in breast cancer datasets, and the negative correlation approach was used for the automatic problem decomposition [36]. Many surveys were done in different data mining methods for cancer predictions. Genetic algorithms and neural networks were combined to predict breast cancer effectively. The evolution computation of neural networks outperformed the regular backpropagation algorithms for cancer prediction and gave an accuracy of 98% [54]. On the Wisconsin Cancer Dataset, the genetic algorithm and adaptive resonance theory were implanted [55]. ANN was combined with logistic regression to predict breast cancer's survival rate and disease recurrence. Survival Analysis of breast cancer patients was done on two different datasets. ANN was used for this analysis, proving that ANN is a successful method for predicting disease recurrence. SVM is widely used for cancer prediction, and the kernel functions are modified to increase the separability from the hyperplane. Risk analysis is another major work in this field. Risk prediction is performed to analyze the various risk factors of breast cancer patients based on their lifestyle, previous medical history, and family history[56]. The logistic regression method is used for cancer prediction using many factors like age, BMI, and blood results [57]. Compared to handmade picture features, in-depth features derived through deep learning models may usually yield a more excellent process. Recent years have seen significant advancements in extracting features from pictures using convolutional neural networks (CNN). Numerous learning approaches have been used for datasets in various medical domains. Ensemble and pre-trained learning are two of the most frequently used learning techniques in machine learning. Later it was investigated the development of ensemble learning models capable of achieving better significant results by combining the characteristics or judgments used to classify histopathology pictures. Long et al. [58] suggested a convolutional technique for increasing the efficiency of whole images through schooling to avoid computational duplication. It generates segmentation for each picture using pixel-smart prediction rather than a single opportunity distribution inside the classification problem. U-Net [59] is an example of a developed model of this technique. Our approach uses a pre-trained version derived from non-clinical images to address the constraint of information scarcity in clinical imaging research. The majority of current guidelines in breast imaging are devoted to the use of CNN architectures for mammography. Assiri et al. [60] proposed a plan for breast cancer prediction on Wisconsin dataset with SVM, logistic regression, MLP, and a voting mechanism. Antropova et al. [61] demonstrated a method for extracting and aggregating low- to mid-stage abilities by combining convolutional neural networks with standard CAD methods. Transfer learning is a method for training a model for one domain and then reusing that for another. This domain adaptation refers to utilizing previously acquired knowledge in one area to enhance or generalize another. There needs to be more literature that has constructed a neural network from the start; Training a neural network or any model from the beginning requires a substantial amount of memory and processing resources. The most popular neural networks in breast cancer detection are VGGNet [62,63,64], AlexNet [65, 66], ResNet [67], MobileNet [67], Densenet [68,69,70,71], Xception [72], and GoogleNet [73, 74]. The primary transfer learning-based breast cancer detection methods are summarised in Table 5. Table 5 Transfer Learning Models for Breast Cancer Detection /Classification Full size table 5 HPC in breast cancer Significant advancements in machine learning and the introduction of high-performance computers have a wide-ranging influence on society, and the medical field is no exception. Intelligent healthcare systems have emerged at the intersection of high-performance computing, machine learning, and clinical science. Such systems may give a greater understanding of several medical and healthcare issues. They may also assist in managing, administering, and analyzing medical uses and can significantly improve the standard of life and clinical treatment effectiveness. The resurgence of interest in HPC is mainly attributable to the requirement to calculate massive volumes of data for deep learning applications. The relationship between deep learning and HPC is synergistic since HPC supports deep learning workloads while deep learning may suggest data center enhancements. Every day, Medical Image Analysis saves lives. These approaches generate many relevant data that clinicians must analyze to revolutionize diagnosis. But as means for acquiring medical pictures become more ubiquitous and available, the demand for radiologists who can interpret a growing quantity of images also increases. As a result, automated approaches for data analysis are not always very useful, but they are also anticipated to grow more popular. HPC will increase the application of technically sophisticated neurocomputing systems with high computational demands to handle healthcare problems in real-time, such as patient prognosis. This will allow for significant advancements in healthcare, drug development, genomic research, bioinformatics, etc. By combining HCI with neurocomputing, researchers may develop previously inconceivable personal treatment solutions for having healthier and longer lives. The techniques of high-performance computing are at the forefront of these revolutions, enabling the execution and acceleration of significant biological and medical advances that would immediately translate into tangible advantages for both humanity and the environment. Combining HPC resources and deep learning algorithms might significantly enhance the detection of intricate patterns in MRI, US, or even whole images [32, 39]. The ability to further develop, improve, and empower hospitals and specialist doctors to use these potent procedures might significantly influence society by enhancing the quality of life via more accurate and cost-effective diagnoses. 5.1 HPC in real-time medical analysis The application of HPC in medical research rests on its capacity to evaluate and classify vast volumes of complicated patient data. And it can do a billion computations per second; HPC enables scientists to evaluate far more extensive data collections in less time. Patients' medical and symptom patterns may be determined by introducing HPC into its data processing. Trajectories may be utilized to determine in real-time whether a patient is in danger of discontinuing therapy. Once the risk has been identified, actions may be implemented to enhance the patient's therapy. Medical applications such as CT and MRI need the execution of complicated algorithms to provide precise and timely results. Therefore, the critical challenge for CT and MRI technology makers is to decrease the necessary computation time. The expense of the processors needed to attain the desired performance and the amount of room required for these systems are also significant obstacles. The introduction of PCI Express via cable and the near-simultaneous advent of computing accelerator cards are two recent technological developments that have considerably aided in resolving these challenges. In 2005, PCIe initially emerged as the preferred bus. The PCIe bus may be sent across a cable, which is only one of its numerous benefits. This paved the way for developing several expansion devices directly connecting to a host machine over the PCIe bus. Expansion enclosures accommodate a variety of PCIe add-in boards that are available on the market. Since these boards operate on the same PCIe channel as the motherboard, no program conversion is necessary between the server and the device, decreasing latency and rendering PCIe more desirable than Infiniband. GPU cards were first utilized for broad computation acceleration at about the same time the PCIe bus was introduced. Multi-core GPU considerably offloads the CPU, producing faster results and decreasing the CPU's burden. Traditional CPUs required hours to calculate results now provided at record speed. Medical imaging is among the early applications to gain acceleration with GPU computing. Several medical gadgets now come with numerous AMD or NVIDIA Tesla GPUs due to the widespread use of GPUs inside the medical industry. Microsurgery robots, endoscopes, and laparoscopic multidimensional composite displays are other medical technologies that use several GPUs in this manner. A CT scan system equipped with NVIDIA Tesla GPUs has the processing capability to keep up with the healthcare business. A setup of four Tesla GPU processors can execute the algorithm for a scanner in less than twenty minutes. A 16-processor computing system requires more than twice as much time. Moreover, a single server with a GPU appliance containing four Tesla GPUs is much less costly than 16-node clusters. This considerably decreases the total cost of equipment. By incorporating NVIDIA's GPU processing technology with Techni Scan's WBU, radiologists can conduct a full ultrasonic scan and see the findings during a 30-minute clinical encounter. This removes the wait for test findings, providing patients and physicians with a device that can reliably give data at the speed of contemporary medicine. Clinicians nowadays are primarily concerned with obtaining timely and reliable findings from medical treatments. The most advanced HPC technologies are applied in medical systems. These include saving time, money, and space. The time required for a patient to obtain diagnostic data is drastically reduced by utilizing the PCIe extension to add many GPUs to a system design. 5.2 GPU The sudden growth of data has led to the need for more powerful and faster prediction models. The distributed computing of the algorithms is needed, and GPU is widely used for better and faster models. Processing power is high in GPU compared to the traditionally used CPU systems. Due to the substantial cost of communication systems, memory accesses, and static designs, traditional computers executing convergence of the algorithm can only sometimes fulfill the requisite temporal requirements. Generally, serial connections transfer information from sensors to CPU buffers, restricting bandwidth. In CPU-based solutions, evaluating independent test cases leads to many cache misses. Due to MLPs having almost little data recycled for a single test case; therefore, batch processing could be more efficient owing to latency limits. Moreover, significant model sizes are often greater than the higher cache level (near the CPU); thus, full models cannot fit inside the L1 or L2 cache. With GPU systems, more memory transactions are necessary to transport data between and within the device memory across the PCIe bus, resulting in a rise in overhead. Low bandwidth reuse and batch less computing are also detrimental to GPU efficiency, as the calculations may need to be parallel enough to fully use the hundreds of available cores. A large proportion of cycles are expected to remain idle for cores that have been allocated work while threads wait for input to off-chip information. Breast cancer prediction was also made using GPU. The main drawback of parallel processing in Open MP and CUDA is the manual interventions for node synchronization. The GPU implementation of Cyclic Reduction gave a better performance in the execution time than the CPU. Support vector machine-based Cross-validation in parallel is executed in GPU, and the process was faster than 100 times. Effective implementation of machine learning algorithms can be done in GPU for better performance. Using GPU for parallel algorithms will be effective in big data processing. High-performance computing in cancer research with AI methods is developed with exascale computing resources and advanced machine learning [101]-related activity. CUDA TM is a parallel computing system and a programming style that offers considerable performance increases when the GPU is used. 5.3 Related work In [102], research on using transfer learning with CNN to detect breast cancer in histological pictures. The ResNet-18/152 and GoogLeNet networks were evaluated in GPU. To prevent overfitting, a randomized image analysis step was also used. ResNet-152 achieves an average accuracy of 84%, according to the findings. K-Means clustering of mammogram picture results is implemented in [103] utilizing two-way computing that is both serial and parallel. Findings suggest that parallel processing yields average execution speeds that are twice as fast. To hasten the procedure of image generation, [104] focuses on enhanced computational representations of Confocal Microwave Imaging techniques employing GPU. The GPU-based solutions were compared to serial and parallelism CPU-based ones. The processing time was lowered by a ratio of 250 over the following main objectives and a factor of 110 versus parallel CPU execution. The components of a UWB microwave image acquisition for detecting breast cancer include transmitters, communication devices, and a high-performance embedded for signal processing and picture reconstruction. In [105] concentrates on the embedded system. The findings are then projected by applying scaling criteria to upcoming many-core CPUs, numerous GPUs, and sophisticated FPGAs [106, 107]. Virtual clinical trials, another computational replication of medical imaging studies, are widely used, notably in mammographic research. A significant prerequisite for imaging and measurement modeling operations is the precision of the computing platform. In [108], three distinct X-ray 3-dimensional breast imaging platforms ran on CPU equipment and the Monte Carlo code, which ran on a GPU. The GPU-based program reduced the computing time by 104, enabling real-time X-ray breast image VCT research. [109] proposes a cloud-based breast cancer diagnostics system using Extreme Learning Machine. Cloud technology can deliver continuous services at any time and location, which is advantageous for the healthcare business since it enables users to use the network whenever they choose. In addition, the cloud environment offers resources that enhance the classification precision of the proposed system. ELM's primary benefit is that it does not need adjusting parameters, including weights and biases, making it far quicker and easier than all these gradient-based learning techniques. The effectiveness of e cloud-based ELM was evaluated with other cutting-edge illness diagnostic systems. Based on its performance WBC dataset, the cloud-based ELM method beats existing methods. The experimental data reveal that he attained a level of precision is 98.9% 6 Case study In this section, a study on the impact of HP (GPU) on commonly used transfer learning models for breast cancer detection is done to understand the impact on training time and training accuracy of the model. 6.1 Dataset The breast cancer (Invasive Ductal Carcinoma (IDC)) image dataset [110] is used for classification using CNN. To award an intensity grade to quite a mounted sample, clinicians often concentrate on the areas that include most IDC. Consequently, one of its primary pre-processing procedures for automated intensity grading is to designate the specific areas of IDC within a whole mounted slide. The dataset included 162 full-mount slide pictures of breast cancer samples digitized at a magnification of 40x. 277,524 patches of 50 by 50 pixels were taken from this dataset; a sample image is shown in Fig. 8. Data Pre-processing: Data cleaning and wrangling are the initial steps before implementing the algorithms. The training dataset is augmented with additional data to prevent overfitting the suggested CNN models. The data is enhanced in various ways, and for this study, we used vertical and horizontal flips, 180\u00b0 rotation, width and height shifts, and magnification by 15%, 15%, and 25%, respectively. Each picture is also flipped horizontally and vertically. Fig. 8 Breast Histopathology Images with 40x in the case study Full size image 6.2 Experimental environment The Graphic Processing Unit is mainly used for parallel processing of complex computationally intensive tasks, which can be subdivided into sub-tasks and can be executed in parallel. The rapidly growing datasets can be processed using the Graphical Processing Unit (GPU) in many or multi-core for faster processing and scaling. Earlier CPU operations were in serial order, and in GPU, they were executed in parallel order, leading to the rise in transistor counts. In GPUs, a huge number of processors and threads are running and thus making the computation faster. In the healthcare sector, many medical applications are implemented on GPUs due to their high processing capability. The role of GPU in increasing the training time speed up is high. In this work, breast cancer diagnosis and prediction are accelerated using GPUs. A detailed analysis of the performance and runtime of the various deep learning algorithms and the parallelization of the algorithms is done in this section. The Google Colab Platform in the CPU/ GPU runtime environment was used to execute the machine learning and deep learning algorithms in a Python programming language. 7 Result and discussion Data pre-processing is done by performing various transformations like resizing, cropping to size 256 and scale 0.8, rotation performed at 15 degrees, flipping horizontally, cropping, and finally normalizing. The main pre-trained transfer learning networks in Keras: Resnet50, VGG16, Mobilenet, DenseNet201, and Xception were executed in the CPU and GPU platforms in Colab. The models were trained using the pre-trained network packages in Keras, followed by flatten and two dense layers, as shown in Fig. 9. Then, the model is compiled using the Adam optimizer, and loss is measured using categorical cross-entropy. The networks were trained for 20 epochs with ten steps per epoch for batch size 64. Fig. 9 CNN Transfer Learning model structure Full size image 7.1 Execution in a CPU Environment The leading five transfer learning algorithms selected based on the literature were executed for this study. 7.2 Execution in GPU environment The performance of the transfer learning models is shown in Figs. 10 and 11; from this, it is clear that the model size and model parameters affect the accuracy and training time of the system. The time taken is extensive for models with large sizes and convolutional layers. This work uses multiple CNN models to see the impact on accuracy and training time. The model performs correctly for most of the data, but there is a scope for refinement and improvement by using a more significant number of epochs; in this work, only 20 epochs are used during the training process. Regularization and optimization can be incorporated into the model to avoid overfitting. The model can be further fine-tuned by adding dropout, varying the learning rate, increasing the batch size, and the customized convolutional layers can be built on top of the transfer learning model. The work clearly shows the effective utilization of HPC and deep learning algorithm for breast cancer prediction. Still, the major limitation faced was the limited data size which caused the overfitting of the model. The performance measures are clearly shown in Table 6. Fig. 10 Training Time in CPU vs. GPU Full size image Fig. 11 Accuracy CPU vs. GPU Full size image Table 6 Performance Measures Full size table 7.3 Benchmarking of Deep CNN for Breast cancer diagnosis in GPU The pre-trained CNN gave improved accuracy and performance in GPU. The training time is reduced in GPU, and the speed up is calculated using equation 4 based on Amdahl's law and is given in Table 7. Table 7 Speed Up Full size table $$\\\\mathrm{Speed\\\\, up}=\\\\mathrm{Execution\\\\, time\\\\, in\\\\, CPU\\\\, / Execution\\\\, Time\\\\, in\\\\, GPU}$$ (4) The speed-up obtained is the best for VGG 16, with 23.5 times faster in GPU since the model size is enormous and takes a considerable training time in CPU. In GPU, the computations are made faster utilizing the high number of ALU units facilitating quicker data processing. The GPU can manage many demands for connectivity through controllers and facilitates parallelization on a massive scale. This enables greater performance and efficiency for deep learning applications than normal Processor. As opposed to instruction-specific latency reductions, the fundamental aim of GPU architecture is high instructions efficiency. GPUs are bigger than Processor cores, and the CPU operates many threads simultaneously. The speed-up is the least in Mobilenet because the model is unsuitable for complex applications. The main problem with this model is that the time taken to upload data from edge computing devices is significant. The performance can be further improved using edge computing devices with Intel IPU, which reduces the downloading and uploading time. The best model with combined accuracy and performance for breast cancer detection is ResNet50. It has 18.5 times speed up in GPU compared to CPU. The GPU architecture speeds up the model's computation, which takes longer in the CPU. In DenseNet, the accuracy is improved, but the speed up is only nine times due to the low parameter and computation efficiency. DenseNet is also prone to overfitting. The best model for breast cancer diagnosis can be decided based on the speed up and improved accuracy in GPU. 8 Challenges Massive healthcare datasets are not easily accessible owing to data exclusivity and privacy considerations. In specific datasets, also exists a scarcity of expert annotations. In specific databases, positive samples were underrepresented. This might influence a model's ability to forecast overly represented samples or a healthy classification. Numerous training examples need to be more varied and have more content. Together, these concerns constitute obstacles in learning the CNN model for diagnosing breast cancer. This section outlines the model s primary issues and potential remedies to enhance its performance. There are still several technical hurdles to overcome. The first concern was employing the pre-trained deep Network model, which would be strongly connected to breast cancer diagnosis performance [111]. The main challenges faced in breast cancer detection and possible solutions are given in Fig. 12. Fig. 12 Challenges in breast cancer diagnosis Full size image 8.1 Class imbalance There is not an equal amount of illness and non-disease instances in the sample. This skewed distribution of information is most prevalent in several medical applications, such as breast cancer imaging, where the frequency of positive samples is much lower than that of negative samples [112]. Real-world data are frequently poorly distributed, which is the primary reason deep learning algorithms have limited generalization. Current architectures provide equal consideration to both the minority and the majority [113, 114]. In many unbalanced datasets, the classifiers may incorrectly predict minority classes; thus, a suitable solution is required to address this issue. Other solutions have been offered in the literature to overcome the class imbalance issue, including weighted loss function, sampling procedure, upsampling, and generating synthetic pictures using GAN. Data-level approaches and algorithm-level methods are classified as solutions for class imbalance concerns. Diverse sampling techniques are used to lessen the information class imbalance. 8.2 Model overfitting and data shortage The primary difficulty in deep learning is developing a model that performs exceptionally well on training examples and new data provided during evaluation. Overfitting is a typical problem in deep learning algorithms. A model is trained with regular patterns from a training sample but fails to offer a general result when confronted with new data. Deep learning models can remember the repeating patterns in training examples. So, rather than learning essential characteristics, it may recall irrelevant noise. Overfitted models need to be more capable of producing generalized results. Monitoring overfitting is possible by examining both validation and training mistakes. To increase average accuracy and prevent overfitting, the network should be trained using massive training data. Transfer learning and several regularization strategies may be used to solve this issue. Regularization is used mainly for deep learn ng networks that enable generalization to anonymous data when building a model with a restricted training set [115]. By altering the training examples, the Data Augmentation approach is utilized to reduce the impact of overfitting. This approach tran forms training data arbitrarily, including reflection, cropping, translations, and rotations. Batch Normalization is a method for normalizing input data across a sample of training examples. Normalization aids in accelerating the training procedure and minimizing the network's initialization. BN and dropout are used for mammography images [116]. As mentioned in [117], BN provides a faster learning rate and does not place a premium on initialization. It is also difficult to present overfitting while optimizing deep neural networks. Dropout is a suggested solution that tries randomly removing units from the network during training. It may prohibit the units from c -adapting excessively and provides a realistic approach for retraining a Dropout network. Opportunities exist to prevent overfitting by expanding the number of frequent medical training events. Last but not least, when there is no method to reduce architects' complex nature or raise the number of training examples, the standard practice is to manipulate variables, like the learning rate, and also to monitor the decline in performance metrics between both the training stage and the appropriate optimization [81, 111, 118]. Furthermore, it should be noted that the decline threshold is subjective, necessitating extensive studies. Unfortunately, there is yet to be a definite answer regarding how to fine-tune a network and the number of medical instances required for fine-tuning, while best practices are known [119]. The easiest solution is to adjust the settings of the whole network or specific network layers. Some research indicates layer-by-layer fine-tuning, but the time required would grow considerably [120]. However, additional technical challenges occur when employing a learning algorithm for feature extraction, such as choosing high-level characteristics, incorporating multi-perspective knowledge, and determining which deep-learning classification is used. It is terrible that there are no repeating tutorials or practical suggestions. In addition, many imaging techniques and medical evidence are used to optimize breast cancer detection in the hospital, further complicating information integration. Since there is no single-fits-all approach, previous knowledge, prior studies, and practical expertise become increasingly vital in addressing these technical challenges [121]. The final obstacle is dimensionality's curse. 9 Research direction and future scope In addition to class imbalance, overfitting, and small datasets, more research obstacles need additional investigation. This section contains future directions and open problems in this domain. Multi-Task Models - The existing deep learning model in breast cancer diagnosis is a single-task model. More multi-task models can be developed in the future. In multi-task models, cancer detection and tumor grading can be incorporated. Identify different Abnormalities: Most CNN models constructed to date were designed to discover, detect, or segment just one anomaly on cancer images, whether a tumor or microcalcification. Developing models that can identify, segment, or categorize many anomalies on a single mammogram is required. Efficient Data Augmentation Methods: To enhance the magnitude of the training dataset, new precise and appropriate data augmentation approaches must be developed. Annotations: There remains a demand for fully annotated big mammogram repositories, even though there are numerous methods for fine learning on smaller datasets and reducing concerns about overfitting as well as a class imbalance. However, creating such a massive archive is a costly and time-consuming endeavour. There may also be privacy and legal implications. Consequently, further research is required to provide a viable solution to this issue. Efficient Pre-processing Technique: Due to the low resolution and low quality of mammography pictures, there is a potential that a model may misclassify an input image. Therefore, these photos must be pre-processed before training. Pre-processing filters such as thresholding and histogram analysis are widely employed to enhance picture quality. Additionally, different mammography datasets feature pictures with varying resolutions since various machines capture them. Parallelize Neural Network: Using Kepler shuffle makes sharing data between threads within the same GPU block easier and faster. Parallelize ANN using Kepler shuffle for stochastic gradient descent. This improves the performance of ANN execution considerably. Kepler has the shuffle or SHFL command to access the registers of the threads in the same wrap. Distributed Deep learning models for real-time processing of breast cancer data using edge computing devices. Distributed Deep learning models for multi and many-core systems with high bandwidth and network capacity because the deep learning applications mainly benefit from distributed processing due to the extensive network size and data. 10 Conclusion Breast cancer is a significant health issue, and the use of deep learning and transfer learning models in conjunction with High-Performance Computing has shown promise in improving the accuracy and speed of breast cancer diagnosis. The paper reviews the different transfer learning and deep learning strategies used to classify breast cancer and the performance metrics used to assess the models. It also discusses the challenges faced in breast cancer diagnosis, including class imbalance and model overfitting, and potential solutions to address these issues. The paper presents a case study on the impact of GPU on commonly used transfer learning models for breast cancer detection and highlights the need for further research in this area. crucial factors for designing an accurate breast cancer diagnostic neural model are the choice of imaging modality and the neural network model used in conjunction with the application environment. The paper discusses the impact of high-performance computing and evaluates the effectiveness of pre-trained models in breast cancer image categorization. It also analyzes how different imaging modalities affect the accuracy of breast cancer detection. The study reviews prominent pre-trained models for breast cancer detection and examines the influence of high-performance computing on training convolutional neural networks (CNNs). The case study focuses on using transfer learning techniques like VGG16 and Xception on a dataset of invasive ductal carcinoma (IDC), a type of breast cancer. The findings suggest that CNN architectures based on deep neural networks and pre-trained models are effective in identifying breast cancer. GPU utilization significantly improves CNN's performance in feature extraction, optimization, and classification of breast cancer images. High-powered systems expedite the cancer identification process, enabling the analysis of complex patterns that would be challenging for humans. High-performance technologies simplify the analysis of intricate patterns in breast cancer datasets. Data availability Availability of data and material the data is available at https://kaggle.com/paultimothymooney/breast-histopathology-image. Code availability Not applicable. References Mohammed M, Al-Khateeb B, Rashid AN, Ibrahim D, Ghani MKA, Mostafa S. Neural network and multi-fractal dimension features for breast cancer classification from ultrasound images. Comput Electr Eng. 2018. https://doi.org/10.1016/j.compeleceng.2018.01.033. Article   Google Scholar   Azamjah N, Soltan-Zadeh Y, Zayeri F. Global trend of breast cancer mortality rate: a 25-Year study. Asian Pac J Cancer Prev. 2019;20:2015\u201320. https://doi.org/10.31557/APJCP.2019.20.7.2015. Article   Google Scholar   Momenimovahed Z, Salehiniya H. Epidemiological characteristics of and risk factors for breast cancer in the world. Breast Cancer (Dove Med Press). 2019;11:151\u201364. https://doi.org/10.2147/BCTT.S176070. Article   Google Scholar   Hossain MS. Cloud-supported Cyber\u2013Physical localization Framework for Patients Monitoring. IEEE Syst J. 2017;11:118\u201327. Article   Google Scholar   Ravikumar A, Saritha R, Chandra V. Support vector machine based prognostic analysis of renal transplantations. In: 2013 Fourth International Conference on Computing, Communications and Networking Technologies (ICCCNT). 2013. p. 1\u20136. https://doi.org/10.1109/ICCCNT.2013.6726819. Hossain MS, Amin SU, Alsulaiman M, Muhammad G. Applying deep learning for epilepsy seizure detection and brain mapping visualization. ACM Trans Multimed Comput Commun Appl. 2019;15:1\u20131017. https://doi.org/10.1145/3241056. Article   Google Scholar   Garg S, Kaur K, Kumar N, Rodrigues JJPC. Hybrid deep-learning-based Anomaly Detection Scheme for suspicious Flow detection in SDN: a Social Multimedia Perspective. IEEE Trans Multimedia. 2019;21:566\u201378. https://doi.org/10.1109/TMM.2019.2893549. Article   Google Scholar   Ghoneim A, Muhammad G, Hossain MS. Cervical cancer classification using convolutional neural networks and extreme learning machines. Futur Gener Comput Syst. 2020;102:643\u20139. https://doi.org/10.1016/j.future.2019.09.015. Article   Google Scholar   John J, Ravikumar A, Abraham B. Prostate cancer prediction from multiple pretrained computer vision model. Heal Technol. 2021;11:1003\u201311. https://doi.org/10.1007/s12553-021-00586-y. Article   Google Scholar   Robin M, John J, Ravikumar A. Breast tumor segmentation using U-NET. In: 2021 5th International Conference on Computing Methodologies and Communication (ICCMC). 2021. p. 1164\u20131167. https://doi.org/10.1109/ICCMC51019.2021.9418447. Baby K, Ravikumar A. Big data: An ultimate solution in health care. Int J Comput Appl. 2014;106(10):0975\u20138887. Google Scholar   Ravikumar A, Sriraman H. Real-time pneumonia prediction using pipelined spark and high-performance computing. PeerJ Comput Sci. 2023;9:e1258. https://doi.org/10.7717/peerj-cs.1258. Article   Google Scholar   Hossain MS, Al-Hammadi M, Muhammad G. Automatic fruit classification using deep learning for industrial applications. IEEE Trans Industr Inf. 2019;15:1027\u201334. https://doi.org/10.1109/TII.2018.2875149. Article   Google Scholar   Deng J, Dong W, Socher R, Li L-J, Li K, Fei-Fei L. ImageNet: a large-scale hierarchical image database. In: 2009 IEEE Conference on Computer Vision and Pattern Recognition. 2009. p. 248\u2013255. https://doi.org/10.1109/CVPR.2009.5206848. Yang X, Zhang T, Xu C, Yan S, Hossain MS, Ghoneim A. Deep relative attributes. IEEE Trans Multimedia. 2016;18:1832\u201342. https://doi.org/10.1109/TMM.2016.2582379. Article   Google Scholar   Albawi S, abed mohammed T, Alzawi S. Understanding of a convolutional neural network. 2017. https://doi.org/10.1109/ICEngTechnol.2017.8308186. Wang YE, Wei G-Y, Brooks D. Benchmarking TPU, GPU, and CPU Platforms for Deep Learning, 2019. http://arxiv.org/abs/1907.10701. Accessed 16 Jul 2022. Ertosun MG, Rubin DL. Probabilistic visual search for masses within mammography images using deep learning, in: 2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), 2015: pp. 1310\u20131315. https://doi.org/10.1109/BIBM.2015.7359868. Youk JH, Gweon HM, Son EJ. Shear-wave elastography in breast ultrasonography: the state of the art. Ultrasonography. 2017;36:300\u20139. https://doi.org/10.14366/usg.17024. Article   Google Scholar   Breast Cancer Imaging (n.d.). http://www.aboutcancer.com/breast_cancer_imaging.htm.Accessed 24 Nov 2022. The mini-MIAS database of mammograms (n.d.). http://peipa.essex.ac.uk/info/mias.html . Accessed 24 Nov 2022. USF Digital Mammography Home Page. (n.d.). http://www.eng.usf.edu/cvprg/mammography/database.html. Accessed 24 Nov 2022. Moreira IC, Amaral I, Domingues I, Cardoso A, Cardoso MJ, Cardoso JS. INbreast. Acad Radiol. 2012;19:236\u201348. https://doi.org/10.1016/j.acra.2011.09.014. CBIS-DDSM - The Cancer Imaging Archive (TCIA). Public Access - Cancer Imaging Archive Wiki, (n.d.). https://wiki.cancerimagingarchive.net/display/Public/CBIS-DDSM. Accessed 24 Nov 2022. Breast Cancer Digital Repository (n.d.). https://bcdr.eu/information/about. Accessed 24 Nov 2022. Mammographic Image Analysis Homepage - Databases. (n.d.). https://www.mammoimage.org/databases/. Accessed 24 Nov 2022. Breast Cancer Histopathological Database (BreakHis) - Laborat\u00f3rio Vis\u00e3o Rob\u00f3tica e Imagem. (n.d.). https://web.inf.ufpr.br/vri/databases/breast-cancer-histopathological-database-breakhis/. Accessed Nov 24 2022. IRMA Institute Of Rural Management Anand., IRMA. (n.d.). https://irma.ac.in/. Accessed 24 Nov 2022. Bioimaging Challenge 2015 Breast Histology Dataset - CKAN (n.d.). https://rdm.inesctec.pt/dataset/nis-2017-003.. Accessed 24 Nov 2022. UCI Machine Learning Repository. : Breast Cancer Wisconsin (Diagnostic) Data Set (n.d.). https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic).Accessed 8 July 2022. Ronneberger O, Fischer P, Brox T. U-Net: Convolutional networks for biomedical image segmentation, ArXiv:1505.04597 [Cs]. (2015). http://arxiv.org/abs/1505.04597. Accessed 2 Mar 2022. Xu J, Zhou C, Lang B, Liu Q. Deep learning for histopathological image analysis: towards computerized diagnosis on cancers. In: Lu L, Zheng Y, Carneiro G, Yang L, editors. Deep learning and convolutional neural networks for medical image computing: precision medicine, high performance and large-scale datasets. Cham: Springer International Publishing; 2017. p. 73\u201395. https://doi.org/10.1007/978-3-319-42999-1_6. Chapter   Google Scholar   Ravikumar A, Sriraman H. Acceleration of image processing and computer vision algorithms. Handbook of Research on Computer Vision and Image Processing in the Deep Learning Era. 2023. p. 1\u201318. https://doi.org/10.4018/978-1-7998-8892-5.ch001. Wang J, Yang Y. A context-sensitive deep learning approach for microcalcification detection in mammograms. Pattern Recogn. 2018;78:12\u201322. https://doi.org/10.1016/j.patcog.2018.01.009. Article   Google Scholar   Yousefi M, Krzy\u017cak A, Suen CY. Mass detection in digital breast tomosynthesis data using convolutional neural networks and multiple instance learning. Comput Biol Med. 2018;96:283\u201393. https://doi.org/10.1016/j.compbiomed.2018.04.004. Article   Google Scholar   Hai J, Tan H, Chen J, Wu M, Qiao K, Xu J, Zeng L, Gao F, Shi D, Yan B. Multi-level features combined end-to-end learning for automated pathological grading of breast cancer on digital mammograms. Comput Med Imaging Graph. 2019;71:58\u201366. https://doi.org/10.1016/j.compmedimag.2018.10.008. Article   Google Scholar   Kang L, Kumar J, Ye P, Li Y, Doermann D. Convolutional neural networks for document image classification. In: 2014 22nd International Conference on Pattern Recognition. Stockholm: IEEE; 2014. p. 3168\u20133172. https://doi.org/10.1109/ICPR.2014.546. Albawi S, Mohammed TA, Al-Zawi S. Understanding of a convolutional neural network. In: 2017 International Conference on Engineering and Technology (ICET) 2017; pp. 1\u20136. https://doi.org/10.1109/ICEngTechnol.2017.8308186. Lu J, Behbood V, Hao P, Zuo H, Xue S, Zhang G. Transfer learning using computational intelligence: a survey. Knowl Based Syst. 2015;80:14\u201323. https://doi.org/10.1016/j.knosys.2015.01.010. Article   Google Scholar   Ravikumar A, Sriraman H, Sai Saketh PM, Lokesh S, Karanam A. Effect of neural network structure in accelerating performance and accuracy of a convolutional neural network with GPU/TPU for image analytics. PeerJ Comput Sci. 2022;8:e909. https://doi.org/10.7717/peerj-cs.909. Article   Google Scholar   Krizhevsky A, Sutskever I, Hinton GE. ImageNet classification with deep convolutional neural networks. In: Advances in Neural Information Processing Systems, Curran Associates, Inc. 2012. https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html. Accessed 21 Feb 2022. Iandola FN, Han S, Moskewicz MW, Ashraf K, Dally WJ, Keutzer K. SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and < 0.5 MB model size. 2016. http://arxiv.org/abs/1602.07360.Accessed 25 Jul 2022. Szegedy C, Vanhoucke V, Ioffe S, Shlens J, Wojna Z. Rethinking the inception architecture for computer vision. 2015. http://arxiv.org/abs/1512.00567.Accessed 25 Jul 2022. Zoph B, Vasudevan V, Shlens J, Le QV. Learning transferable architectures for scalable image recognition. 2018. http://arxiv.org/abs/1707.07012. Accessed 28 Jul 2022. Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition. 2015. http://arxiv.org/abs/1409.1556. Accessed 25 Jul 2022. He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. 2015. http://arxiv.org/abs/1512.03385.Accessed 25 Jul 2022. Howard AG, Zhu M, Chen B, Kalenichenko D, Wang W, Weyand T, Andreetto M, Adam H. MobileNets: Efficient convolutional neural networks for mobile vision applications. 2017. http://arxiv.org/abs/1704.04861. Accessed 29 Jul 2022. Chollet F. Xception: deep learning with depthwise separable convolutions. In: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Honolulu: IEEE; 2017. p. 1800\u20131807. https://doi.org/10.1109/CVPR.2017.195. Huang G, Liu Z, van der Maaten L, Weinberger KQ. Densely connected convolutional networks. 2018. http://arxiv.org/abs/1608.06993. Accessed 28 July 2022. Chowdhury M, Zaharia M, Ma J, Jordan MI, Stoica I. Managing data transfers in computer clusters with orchestra, (n.d.) 12. Chaurasia V, Pal S. Data mining techniques: To predict and resolve breast cancer survivability. 2014;3:10\u201322. Aruna S, Rajagopalan D, Nandakishore L. Knowledge based analysis of various statistical tools in detecting breast cancer. Comput Sci Inform Technol. 2011;2. https://doi.org/10.5121/csit.2011.1205. Delen D, Walker G, Kadam A. Predicting breast cancer survivability: a comparison of three data mining methods. Artif Intell Med. 2005;34:113\u201327. https://doi.org/10.1016/j.artmed.2004.07.002. Article   Google Scholar   Kim J, Kim J, Jang G-J, Lee M. Fast learning method for convolutional neural networks using extreme learning machine and its application to lane detection. Neural Netw. 2017;87:109\u201321. https://doi.org/10.1016/j.neunet.2016.12.002. Article   Google Scholar   Yao X, Liu Y. Neural networks for breast cancer diagnosis, in: Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), 1999;3:1760\u20131767. https://doi.org/10.1109/CEC.1999.785487. Adam A, Omar K. Abstract computerized breast cancer diagnosis with genetic algorithms and neural network, (n.d.). Dhungel N, Carneiro G, Bradley AP. Deep learning and structured prediction for the segmentation of Mass in Mammograms. In: Navab N, Hornegger J, Wells WM, Frangi A, editors. Medical image computing and computer-assisted intervention -- MICCAI 2015. Cham: Springer International Publishing; 2015. p. 605\u201312. https://doi.org/10.1007/978-3-319-24553-9_74. Chapter   Google Scholar   Jacobi CE, de Bock GH, Siegerink B, van Asperen CJ. Differences and similarities in breast cancer risk assessment models in clinical practice: which model to choose? Breast Cancer Res Treat. 2009;115:381\u201390. https://doi.org/10.1007/s10549-008-0070-x. Article   Google Scholar   Long J, Shelhamer E, Darrell T. Fully convolutional networks for semantic segmentation. In: 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2015: pp. 3431\u20133440. https://doi.org/10.1109/CVPR.2015.7298965. Assiri AS, Nazir S, Velastin SA. Breast tumor classification using an ensemble machine learning method. J Imaging. 2020;6: 39. https://doi.org/10.3390/jimaging6060039. Article   Google Scholar   Antropova N, Huynh BQ, Giger ML. A deep feature fusion methodology for breast cancer diagnosis demonstrated on three imaging modality datasets. Med Phys. 2017;44:5162\u201371. https://doi.org/10.1002/mp.12453. Article   Google Scholar   Agarwal P, Yadav A, Mathur P. Breast cancer prediction on breakHis dataset using deep CNN and transfer learning model. In: Nanda P, Verma VK, Srivastava S, Gupta RK, Mazumdar AP, editors. Data engineering for smart systems. Singapore: Springer; 2022. p. 77\u201388. https://doi.org/10.1007/978-981-16-2641-8_8. Chapter   Google Scholar   Guan S, Loew M. Breast cancer detection using transfer learning in convolutional neural networks, in: 2017 IEEE Applied Imagery Pattern Recognition Workshop (AIPR), IEEE, Washington, DC. 2017: pp. 1\u20138. https://doi.org/10.1109/AIPR.2017.8457948. Falcon\u00ed LG, P\u00e9rez MH, Aguila WG, Conci A. Transfer learning and fine tuning in breast mammogram abnormalities classification on CBIS-DDSM database. Adv Sci Technol Eng Syst J. 2020;5:154\u201365. Article   Google Scholar   Gnanasekaran VS, Joypaul S, Meenakshi Sundaram P, Chairman DD. Deep learning algorithm for breast masses classification in mammograms. IET Image Proc. 2020;14:2860\u20138. https://doi.org/10.1049/iet-ipr.2020.0070. Article   Google Scholar   Bruno A, Ardizzone E, Vitabile S, Midiri M. A novel solution based on scale invariant feature transform descriptors and deep learning for the detection of suspicious regions in mammogram images. J Med Signals Sens. 2020;10:158\u201373. https://doi.org/10.4103/jmss.JMSS_31_19. Article   Google Scholar   Chen Y, Zhang Q, Wu Y, Liu B, Wang M, Lin Y. Fine-Tuning ResNet for breast cancer classification from mammography. In: Wu CQ, Chyu M-C, Lloret J, Li X, editors. Proceedings of the 2nd International Conference on Healthcare Science and Engineering. Singapore: Springer; 2019: p. 83\u201396. https://doi.org/10.1007/978-981-13-6837-0_7. Falcon\u00ed LG, P\u00e9rez MH, Aguilar WG. Transfer learning in breast mammogram abnormalities classification with mobilenet and nasnet. 2019 International Conference on Systems, Signals and Image Processing (IWSSIP). 2019. p. 109\u2013114. Jim\u00e9nez Gaona Y, Rodriguez-Alvarez MJ, Espino-Morato H, Castillo Malla D, Lakshminarayanan V. DenseNet for breast tumor classification in mammographic images. In: Rojas I, Castillo-Secilla D, Herrera LJ, Pomares H, editors. Bioengineering and biomedical signal and image processing. Cham: Springer International Publishing; 2021. p. 166\u201376. https://doi.org/10.1007/978-3-030-88163-4_16. Chapter   Google Scholar   Zhong Z, Zheng M, Mai H, Zhao J, Liu X. Cancer image classification based on DenseNet model. J Phys Conf Ser. 2020;1651: 012143. https://doi.org/10.1088/1742-6596/1651/1/012143. Article   Google Scholar   Li X, Shen X, Zhou Y, Wang X, Li T-Q. Classification of breast cancer histopathological images using interleaved DenseNet with SENet (IDSNet). PLoS One. 2020;15: e0232127. https://doi.org/10.1371/journal.pone.0232127. Article   Google Scholar   Sharma S, Kumar S. The Xception model: a potential feature extractor in breast cancer histology images classification. ICT Express. 2022;8:101\u20138. https://doi.org/10.1016/j.icte.2021.11.010. Article   Google Scholar   Ragab DA, Sharkas M, Marshall S, Ren J. Breast cancer detection using deep convolutional neural networks and support vector machines. PeerJ. 2019;7:e6201. https://doi.org/10.7717/peerj.6201. Article   Google Scholar   Gurav GN, Kanojia MG. A review on classification of breast cancer histopathological images using convolutional neural networks. 2020;13:6. Lim MJ, Kim DE, Chung DK, Lim H, Kwon YM. Deep convolution neural networks for medical image analysis. Int J Eng Technol. 2018;7:115\u20139. https://doi.org/10.14419/ijet.v7i3.33.18588. Article   Google Scholar   Jannesari M, Habibzadeh M, Aboulkheyr H, Khosravi P, Elemento O, Totonchi M, Hajirasouliha I. Breast cancer histopathological image classification: a deep learning approach. In: 2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). 2018. p. 2405\u20132412. https://doi.org/10.1109/BIBM.2018.8621307. Yu S, Liu L, Wang Z, Dai G, Xie Y. Transferring deep neural networks for the differentiation of mammographic breast lesions. Sci China Technological Sci. 2019;62:441\u20137. https://doi.org/10.1007/s11431-017-9317-3. Article   Google Scholar   Chougrad H, Zouaki H, Alheyane O. Deep convolutional neural networks for breast cancer screening. Comput Methods Programs Biomed. 2018;157:19\u201330. https://doi.org/10.1016/j.cmpb.2018.01.011. Article   Google Scholar   Mohamed AA, Berg WA, Peng H, Luo Y, Jankowitz RC, Wu S. A deep learning method for classifying mammographic breast density categories. Med Phys. 2018;45:314\u201321. https://doi.org/10.1002/mp.12683. Article   Google Scholar   Byra M, Sznajder T, Korzinek D, Piotrzkowska-Wroblewska H, Dobruch-Sobczak K, Nowicki A, Marasek K. Impact of ultrasound image reconstruction method on breast lesion classification with neural transfer learning. 2018. http://arxiv.org/abs/1804.02119 . Accessed 24 Nov 2022. Zhang X, Zhang Y, Han EY, Jacobs N, Han Q, Wang X, Liu J. Classification of whole mammogram and tomosynthesis images using deep convolutional neural networks. IEEE Trans Nanobioscience. 2018;17:237\u201342. https://doi.org/10.1109/TNB.2018.2845103. Article   Google Scholar   Kassani SH, Kassani PH, Wesolowski MJ, Schneider KA, Deters R. Breast cancer diagnosis with transfer learning and global pooling. 2019. http://arxiv.org/abs/1909.11839.Accessed 24 Nov 2022. Byra M, Galperin M, Ojeda-Fournier H, Olson L, O\u2019Boyle M, Comstock C, Andre M. Breast mass classification in sonography with transfer learning using a deep convolutional neural network and color conversion. Med Phys. 2019;46:746\u201355. https://doi.org/10.1002/mp.13361. Article   Google Scholar   Hijab A, Rushdi MA, Gomaa MM, Eldeib A. Breast cancer classification in ultrasound images using transfer learning. In: 2019 Fifth International Conference on Advances in Biomedical Engineering (ICABME). Tripoli: IEEE; 2019. p. 1\u20134. https://doi.org/10.1109/ICABME47164.2019.8940291. Abdel Rahman AS, Belhaouari SB, Bouzerdoum A, Baali H, Alam T, Eldaraa AM. Breast mass tumor classification using deep learning. In: 2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies (ICIoT), 2020. p. 271\u2013276. https://doi.org/10.1109/ICIoT48696.2020.9089535. Khamparia A, Bharati S, Podder P, Gupta D, Khanna A, Phung TK, Thanh DNH. Diagnosis of breast cancer based on modern mammography using hybrid transfer learning. Multidim Syst Sign Process. 2021;32:747\u201365. https://doi.org/10.1007/s11045-020-00756-7. Article   MATH   Google Scholar   Aly GH, Marey M, El-Sayed SA, Tolba MF. YOLO based breast masses detection and classification in full-field digital mammograms. Comput Methods Programs Biomed. 2021;200:105823. https://doi.org/10.1016/j.cmpb.2020.105823. Article   Google Scholar   Albashish D, Al-Sayyed R, Abdullah A, Ryalat MH, Ahmad Almansour N. Deep CNN model based on VGG16 for breast cancer classification. In: 2021 International Conference on Information Technology (ICIT). 2021: p. 805\u2013810. https://doi.org/10.1109/ICIT52682.2021.9491631. Ahmad N, Asghar S, Gillani SA. Transfer learning-assisted multi-resolution breast cancer histopathological images classification. Visual Comput. 2022;38:2751\u201370. https://doi.org/10.1007/s00371-021-02153-y. Article   Google Scholar   Ayana G, Park J, Jeong J-W, Choe S. A novel multistage transfer learning for ultrasound breast Cancer image classification. Diagnostics. 2022;12:135. https://doi.org/10.3390/diagnostics12010135. Article   Google Scholar   Zheng Y, Li C, Zhou X, Chen H, Xu H, Li Y, Zhang H, Li X, Sun H, Huang X, Grzegorzek M. Application of transfer learning and ensemble learning in image-level classification for breast histopathology. 2022. http://arxiv.org/abs/2204.08311. Accessed 23 Nov 2022. Aljuaid H, Alturki N, Alsubaie N, Cavallaro L, Liotta A. Computer-aided diagnosis for breast cancer classification using deep neural networks and transfer learning. Comput Methods Programs Biomed. 2022;223: 106951. https://doi.org/10.1016/j.cmpb.2022.106951. Article   Google Scholar   Abbasniya, M. R., Sheikholeslamzadeh, S. A., Nasiri, H., & Emami, S. (2022). Classification of breast tumors based on histopathology images using deep features and ensemble of gradient boosting methods. Comput Electr Eng 103:108382. https://doi.org/10.1016/j.compeleceng.2022.108382 Article   Google Scholar   Chowdhury D, Das A, Dey A, Sarkar S, Dwivedi AD, Rao Mukkamala R, Murmu L. ABCanDroid: a Cloud Integrated Android App for Noninvasive early breast Cancer detection using transfer learning. Sensors. 2022;22: 832. https://doi.org/10.3390/s22030832. Article   Google Scholar   Dey S, Roychoudhury R, Malakar S, Sarkar R. Screening of breast cancer from thermogram images by edge detection aided deep transfer learning model. Multimed Tools Appl. 2022;81:9331\u201349. https://doi.org/10.1007/s11042-021-11477-9. Article   Google Scholar   Prusty S, Dash SK, Patnaik S. A novel transfer learning technique for detecting breast Cancer Mammograms using VGG16 bottleneck feature. ECS Trans. 2022;107:733. https://doi.org/10.1149/10701.0733ecst. Article   Google Scholar   Jasti VDP, Zamani AS, Arumugam K, Naved M, Pallathadka H, Sammy F, Raghuvanshi A, Kaliyaperumal K. Computational Technique Based on Machine Learning and Image Processing for Medical Image Analysis of Breast Cancer Diagnosis, Security and Communication Networks. 2022 (2022) e1918379. doi: 10.1155/2022/1918379. Article   Google Scholar   Al-Dhabyani W, Gomaa M, Khaled H, Fahmy A. Dataset of breast ultrasound images. Data Brief. 2020;28: 104863. https://doi.org/10.1016/j.dib.2019.104863. Article   Google Scholar   Ragab M, Albukhari A, Alyami J, Mansour RF. Ensemble deep-learning-enabled clinical decision support system for breast cancer diagnosis and classification on ultrasound images. Biology. 2022;11: 439. https://doi.org/10.3390/biology11030439. Article   Google Scholar   Robin M, Ravikumar A, John J. Classification of histopathological breast Cancer images using pretrained models and transfer learning. In: Saraswat M, Sharma H, Balachandran K, Kim JH, Bansal JC, editors. Congress on intelligent systems. Singapore: Springer Nature Singapore; 2022. p. 587\u201397. Chapter   Google Scholar   Ravikumar A, Sriraman H, Lokesh S, Maruthi Sai P, Saketh. Identifying pitfalls and solutions in parallelizing long short-term memory network on graphical processing unit by comparing with tensor processing unit parallelism. In: Smys S, Kamel KA, Palanisamy R, editors. Inventive computation and information technologies. Singapore: Springer Nature Singapore; 2023. p. 111\u201325. Chapter   Google Scholar   e Silva DCS, Cortes OAC. On convolutional neural networks and transfer learning for classifying breast Cancer on histopathological images using GPU. In: Bastos-Filho TF, de Oliveira Caldeira EM, Frizera-Neto A, editors. XXVII brazilian Congress on Biomedical Engineering. Cham: Springer International Publishing; 2022. p. 1993\u20138. Amalia AE, Airlangga G, Thohari ANA. Breast cancer image segmentation using K-means clustering based on GPU Cuda parallel computing. JURNAL INFOTEL. 2018;10:33\u20138. https://doi.org/10.20895/infotel.v10i1.344. Elahi MA, Shahzad A, Glavin M, Jones E, O\u2019Halloran M. GPU accelerated Confocal microwave imaging algorithms for breast cancer detection. In: 2015 9th European Conference on Antennas and Propagation (EuCAP). 2015;\u20132. Casu MR, Colonna F, Crepaldi M, Demarchi D, Graziano M, Zamboni M. UWB microwave imaging for breast cancer detection: Many-Core, GPU, or FPGA? ACM Trans Embed Comput Syst. 2014;13. https://doi.org/10.1145/2530534. Harini S, Ravikumar A. Vulnerability analysis of FPGA through side-channel attacks in cloud. In: Ranganathan G, Chen J, Rocha \u00c1, editors. Inventive communication and computational technologies. Singapore: Springer Singapore; 2021. p. 597\u2013606. Chapter   Google Scholar   Harini S, Ravikumar A. Effect of parallel workload on dynamic voltage frequency scaling for dark silicon ameliorating. In: 2020 International Conference on Smart Electronics and Communication (ICOSEC). 2020: p. 1012\u20131017. https://doi.org/10.1109/ICOSEC49089.2020.9215262. Mettivier G, Sarno A, Lai Y, Golosio B, Fanti V, Italiano ME, Jia X, Russo P. Virtual clinical trials in 2D and 3D X-ray breast imaging and dosimetry: comparison of CPU-Based and GPU-Based Monte Carlo Codes. Cancers. 2022;14: 1027. https://doi.org/10.3390/cancers14041027. Article   Google Scholar   Lahoura V, Singh H, Aggarwal A, Sharma B, Mohammed MA, Dama\u0161evi\u010dius R, Kadry S, Cengiz K. Cloud computing-based framework for breast cancer diagnosis using extreme learning machine. Diagnostics. 2021;11: 241. https://doi.org/10.3390/diagnostics11020241. Article   Google Scholar   Breast Histopathology Images (n.d.). https://kaggle.com/paultimothymooney/breast-histopathology-images.Accessed 2 Mar 2022. Shin H-C, Roth HR, Gao M, Lu L, Xu Z, Nogues I, Yao J, Mollura D, Summers RM. Deep convolutional neural networks for computer-aided detection: CNN Architectures, dataset characteristics and transfer learning. IEEE Trans Med Imaging. 2016;35:1285\u201398. https://doi.org/10.1109/TMI.2016.2528162. Article   Google Scholar   Rahman MM, Davis DN. Addressing the class imbalance problem in medical datasets. IJMLC. 2013;224\u20138. https://doi.org/10.7763/IJMLC.2013.V3.307. Kuo NI-H, Jorm L, Barbieri S. Generating synthetic clinical data that capture class imbalanced distributions with generative adversarial networks: example using antiretroviral therapy for HIV. 2022. http://arxiv.org/abs/2208.08655. Accessed 1 Nov 2022. Bria A, Marrocco C, Tortorella F. Addressing class imbalance in deep learning for small lesion detection on medical images. Comput Biol Med. 2020;120: 103735. https://doi.org/10.1016/j.compbiomed.2020.103735. Article   Google Scholar   Kuka\u010dka J, Golkov V, Cremers D. Regularization for deep learning: a taxonomy. 2017. http://arxiv.org/abs/1710.10686. Accessed 24 Nov 2022. Abdelhafiz D, Yang C, Ammar R, Nabavi S. Deep convolutional neural networks for mammography: advances, challenges and applications. BMC Bioinformatics. 2019;20:281. https://doi.org/10.1186/s12859-019-2823-4. Article   Google Scholar   Ioffe S, Szegedy C. Batch normalization: accelerating deep network training by reducing internal covariate shift. 2015. http://arxiv.org/abs/1502.03167 . Accessed 24 Nov 2022. Mendel K, Li H, Sheth D, Giger M. Transfer learning from convolutional neural networks for computer-aided diagnosis: a comparison of digital breast tomosynthesis and full-field digital mammography. Acad Radiol. 2019;26:735\u201343. https://doi.org/10.1016/j.acra.2018.06.019. Article   Google Scholar   Zheng L, Zhao Y, Wang S, Wang J, Tian Q. Good Practice in CNN Feature Transfer. 2016. http://arxiv.org/abs/1604.00133.Accessed 24 Nov 2022. Tajbakhsh N, Shin JY, Gurudu SR, Hurst RT, Kendall CB, Gotway MB, Liang J. Convolutional neural networks for medical image analysis: full training or fine tuning? IEEE Trans Med Imaging. 2016;35:1299\u2013312. https://doi.org/10.1109/TMI.2016.2535302. Article   Google Scholar   Erickson BJ, Korfiatis P, Kline TL, Akkus Z, Philbrick K, Weston AD. Deep learning in radiology: does one size fit all? J Am Coll Radiol. 2018;15:521\u20136. https://doi.org/10.1016/j.jacr.2017.12.027. Article   Google Scholar   Download references Author information Authors and Affiliations School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, 600127, India Aswathy Ravikumar, Harini Sriraman, B. Saleena & B. Prakash Contributions All authors contributed equally to this work. Corresponding author Correspondence to Harini Sriraman. Ethics declarations Ethics approval Not applicable. Consent to participate Not applicable. Consent for publication Not applicable. Conflicts of interest The authors have no relevant financial or nonfinancial interests to disclose. Authors declare that there are no conflicts of interest. Additional information Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Rights and permissions Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law. Reprints and permissions About this article Cite this article Ravikumar, A., Sriraman, H., Saleena, B. et al. Selecting the optimal transfer learning model for precise breast cancer diagnosis utilizing pre-trained deep learning models and histopathology images. Health Technol. 13, 721\u2013745 (2023). https://doi.org/10.1007/s12553-023-00772-0 Download citation Received 05 December 2022 Accepted 24 July 2023 Published 19 August 2023 Issue Date September 2023 DOI https://doi.org/10.1007/s12553-023-00772-0 Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Keywords Convolutional Neural network GPU Transfer learning High-performance computing Histopathology Image Breast cancer Use our pre-submission checklist Avoid common mistakes on your manuscript. Sections Figures References Abstract Introduction Background Search strategy Deep learning in breast cancer HPC in breast cancer Case study Result and discussion Challenges Research direction and future scope Conclusion Data availability Code availability References Author information Ethics declarations Additional information Rights and permissions About this article Advertisement Discover content Journals A-Z Books A-Z Publish with us Publish your research Open access publishing Products and services Our products Librarians Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility statement Terms and conditions Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln (3000134173) \u00a9 2024 Springer Nature\"",
        "analysis": "",
        "verbatim_quote1": "",
        "verbatim_quote2": "",
        "verbatim_quote3": "",
        "relevance_score1": 0,
        "relevance_score2": 0,
        "limitations": "",
        "inline_citation": "",
        "full_citation": ""
    },
    {
        "title": "Leveraging Deep Learning and IoT big data analytics to support the smart cities development: Review and future directions",
        "doi": "10.1016/j.cosrev.2020.100303",
        "description": "The rapid growth of urban populations worldwide imposes new challenges on citizens' daily lives, including environmental pollution, public security, road congestion, etc. New technologies have been developed to manage this rapid growth by developing smarter cities. Integrating the Internet of Things (IoT) in citizens' lives enables the innovation of new intelligent services and applications that serve sectors around the city, including healthcare, surveillance, agriculture, etc. IoT devices and sensors generate large amounts of data that can be analyzed to gain valuable information and insights that help to enhance citizens' quality of life. Deep Learning (DL), a new area of Artificial Intelligence (AI), has recently demonstrated the potential for increasing the efficiency and performance of IoT big data analytics. In this survey, we provide a review of the literature regarding the use of IoT and DL to develop smart cities. We begin by defining the IoT and listing the characteristics of IoT-generated big data. Then, we present the different computing infrastructures used for IoT big data analytics, which include cloud, fog, and edge computing. After that, we survey popular DL models and review the recent research that employs both IoT and DL to develop smart applications and services for smart cities. Finally, we outline the current challenges and issues faced during the development of smart city services.",
        "journal": "Computer Science Review",
        "authors": [
            "Atitallah S.B.",
            "Driss M.",
            "Boulila W.",
            "Ghezala H.B."
        ],
        "citation_count": "175",
        "full_text": "\"Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Abstract Keywords 1. Introduction 2. Related works and main contributions of the present survey 3. Background and basic concepts 4. Use of deep learning in the smart city applications: Literature review 5. Discussion 6. Usage of deep learning for smart cities: Challenges and open issues for future research 7. Conclusion Declaration of Competing Interest References Show full outline Cited by (191) Figures (20) Show 14 more figures Tables (11) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6 Show all tables Computer Science Review Volume 38, November 2020, 100303 Review article Leveraging Deep Learning and IoT big data analytics to support the smart cities development: Review and future directions Author links open overlay panel Safa Ben Atitallah a, Maha Driss a b, Wadii Boulila a b, Henda Ben Gh\u00e9zala a Show more Share Cite https://doi.org/10.1016/j.cosrev.2020.100303 Get rights and content Abstract The rapid growth of urban populations worldwide imposes new challenges on citizens\u2019 daily lives, including environmental pollution, public security, road congestion, etc. New technologies have been developed to manage this rapid growth by developing smarter cities. Integrating the Internet of Things (IoT) in citizens\u2019 lives enables the innovation of new intelligent services and applications that serve sectors around the city, including healthcare, surveillance, agriculture, etc. IoT devices and sensors generate large amounts of data that can be analyzed to gain valuable information and insights that help to enhance citizens\u2019 quality of life. Deep Learning (DL), a new area of Artificial Intelligence (AI), has recently demonstrated the potential for increasing the efficiency and performance of IoT big data analytics. In this survey, we provide a review of the literature regarding the use of IoT and DL to develop smart cities. We begin by defining the IoT and listing the characteristics of IoT-generated big data. Then, we present the different computing infrastructures used for IoT big data analytics, which include cloud, fog, and edge computing. After that, we survey popular DL models and review the recent research that employs both IoT and DL to develop smart applications and services for smart cities. Finally, we outline the current challenges and issues faced during the development of smart city services. Previous article in issue Next article in issue Keywords Internet of ThingsDeep LearningSmart cityBig data analyticsReview 1. Introduction Today, over 50% of the world\u2019s population resides in cities, and it is reported that urban residency will reach 68% within the next 30 years [1]. According to the United Nations, world population will also increase by 2.5 billion in 2050. This tremendous growth will impose several challenges on cities, including the sustainable management and development of urban areas as well as the ability to guarantee excellent quality of life for citizens. Therefore, the development of smart cities should be considered both an effective and urgent solution to support the several needs of this growing population. In the other side, the rapid evolution of the IoT and big data analytics is often considered the main factor in the implementation of smart cities\u2019 services [2]. The IoT and big data analytics have gained intensive critical and global attention, as demonstrated in Fig. 1. The continuous evolution of technology plays a significant role in the development of intelligent systems across various domains of city life. A smart city exploits and benefits from data collection and processing using different technologies of communication, networking, and computing, which in turn leads to the innovation of smart services across different sectors including health, transportation, security, and more. To support the development of smart cities, billions of dollars are assigned for smart city initiatives. Fig. 2 shows the predictions made by Statista [3] regarding the technological investments that will be available to support the development of smart cities from the present to 2023. IoT refers to the interconnection among billion of smart devices [4]. This technology gives physical objects the ability to mimic human characteristics such seeing, hearing, thinking, and decision-making in order to communicate, share information, and coordinate actions with one another. These abilities transform simple objects into intelligent devices that can operate in real-time, adjust to the circumstances, and function without human intervention or supervision. Similar smart sensors and actuators are already embedded in different areas of cities, which give rise to a collection of enormous amounts of data [5]. The gathered data must be stored, analyzed, and processed before being presented in a useful form [6]. The recent growth of IoT data has led to the appearance and development of real-time data analytics, including Machine Learning (ML), DL, and computing infrastructures [7]. Recently, IoT big data analytics has become a very popular research domain [8], [9], [10] [NO_PRINTED_FORM], particularly because traditional methods of data processing have recorded various limitations, especially when working with large amounts of data. DL algorithms are proposed as a means of dealing with such issues. DL algorithms allow researchers to process large amounts of raw data in real-time with great accuracy and high efficiency [11]. Several research studies using DL techniques have been conducted in different fields, and the results obtained have contributed to a larger vision of smart cities and several important steps along the road toward their development [12]. In this survey, we select the smart city as the main application field of IoT, since smart cities involve a broad range of IoT use cases. Following [13], [14], we identify six use cases stemming from the hypothetical smart city, which include: the smart home, smart healthcare, smart transportation, smart surveillance, smart agriculture, and smart environment. We will also focus on the use of DL models to develop intelligent applications for these use cases, as well as the potential challenges and different open issues related to it. Fig. 3 illustrates these use cases. The remainder of this paper is organized as follows. In Section 2, we review the previous related studies, compare between these studies and our work, and identify the main contributions of our survey. IoT domain, DL techniques, and IoT computing infrastructures are presented and explained in Section 3. IoT applications for a smart city using DL are reviewed, summarized, and illustrated in Section 4. In Section 5, we discuss the use of DL techniques in IoT smart city applications in order to provide an understandable image about the main concepts of IoT and DL smart city applications for future research. In Section 6, challenges and open issues related to the development of smart cities using DL techniques are presented. Finally, our survey is concluded in Section 7. The detailed structure of the present survey is presented in Fig. 4. Download : Download high-res image (164KB) Download : Download full-size image Fig. 1. The number of Google searches for the terms \u201cInternet of Things\u201d and \u201cbig data analytics\u201d since 2010, according to Google trends.1 Download : Download high-res image (121KB) Download : Download full-size image Fig. 2. Investment on technologies to develop smart cities in worldwide [3]. Download : Download high-res image (355KB) Download : Download full-size image Fig. 3. The considered smart cities\u2019 use cases in this survey. 2. Related works and main contributions of the present survey IoT data analytics has recently attracted extensive attention in different fields, leading to researchers conducting several surveys on this topic. These surveys include investigations into the utilization of ML as well as others focusing on the use of DL to serve IoT applications. Some of the relevant surveys related to IoT big data analytics and DL techniques are listed below, followed by a comparison between these surveys and ours in order to outline the main contributions of our work to this endeavor. Mohammadi et al. [15] have reported on recent DL approaches for IoT applications. The authors began their survey by introducing the different characteristics of big data generated from IoT and discussing how to draw analytics from this data. The different types of DL architectures and the different studies exploring the use of DL in various IoT domains were also surveyed. Finally, the authors covered the use of DL for IoT data in different applications and services including indoor localization, image/speech recognition, security, privacy, and more. Mahdavine et al. [16] presented a survey that discusses the different ML techniques used to analyze and process IoT data in different smart city use cases. The authors defined and provided a taxonomy of ML algorithms and reviewed the utilization of each in the development of smart city applications. In addition, they discussed the potential challenges facing the application of these algorithms in IoT data analytics. Zhang et al. [17] covered the use of DL in mobile and wireless networks. Different DL approaches were discussed and their applications to mobile networks were reviewed. The authors also highlighted how to tailor DL in mobile networks and gave a summary of the diverse platforms used to facilitate this deployment. In [18], Zhang et al. reviewed existing works that apply the DL techniques for big data feature learning. The authors defined four typical DL models: stacked auto-encoder, deep belief network, convolutional neural network, and recurrent neural network. They also reviewed the DL models for processing big data and classified them into four groups in line with four types of data: the large amounts of data group, the heterogeneous data group, the real-time data group, and finally the low-quality data group. Qolomany et al. [19] presented a survey reviewing the use of ML for big data analytics in order to enhance the development of intelligent buildings. Moreover, they reported on and classified the different smart building applications/systems developed using ML techniques, including elderly home care, energy efficiency, entertainment, security, and other miscellaneous projects. Chen et al. [20] provided a survey covering the use of DL for smart city data. They reviewed the popular DL models and summarized the latest research on applications and services in different smart cities use cases/scenarios, including transportation, healthcare, environment, and security. Table 1 provides a summary of the previously detailed works and lists their limitations in order to outline the main contributions of the present survey. The major contributions of the proposed study are covered by the following research questions: Table 1. Comparison of relevant survey papers. Survey Journal Methodology Domain Use cases Main purpose Limitations Mohammadi et al. [15] 2018 IEEE Communications Surveys & Tutorials Comprehensive survey IoT 1. Smart home 2. Smart city 3. Smart energy 3. Smart healthcare 4. Agriculture 5. Education 6. Sports 7. Retail 8. IoT infrastructures Reviews the recent DL approaches for IoT applications and services - Does not focus in depth on the IoT smart city services and applications - Does not address the different technical/business challenges and open issues that are related to the smart cities\u2019 development Mahdavine et al. [16] 2018 Digital Communications and Networks Comprehensive survey Smart City 1. Smart energy 2. Smart mobility 3. Smart citizens 4. Urban planning Reviews the ML techniques and their applications in smart city use cases - Consideration of only four use cases related to smart city applications: smart energy, mobility, citizens, and urban planning - Does not investigate the utilization of DL techniques for analysis of the IoT smart city data - Does not discuss the open issues that concern smart cities\u2019 development Zhang et al. [17] 2018 IEEE Communications Surveys & Tutorials Comprehensive survey Mobile networks \u2013 Reviews the DL architectures and their use in mobile networks - Does not investigate the use of DL in the different IoT applications, specifically in the development of smart cities Zhang et al. [18] 2018 Information Fusion Comprehensive survey Big Data 1. Large amounts of data 2. Heterogeneous data 3. Real-time data 4. Low-quality data Reviews several works that apply DL techniques for big data feature learning - Reviews only the studies that use DL models for big data feature learning - Does not specifically investigate the use of DL in different IoT applications - Does not review the IoT applications that use DL models for smart cities Qolomany et al. [19] 2019 IEEE Access Comprehensive survey Smart buildings 1. Elderly home care 2. Energy efficiency 3. Comfort and entertainment 4. Safety and security 5. Miscellaneous projects Reviews the use of ML and big data analytics for the development of smart buildings - Does not review the deployment of ML models in fog/edge computing - Does not review DL techniques - Does not focus on IoT-based smart city use cases Chen et al. [20] 2019 IEEE Transactions on Emerging Topics in Computational Intelligence Comprehensive survey Smart city 1. Transportation 2. Healthcare 3. Environment 4. Public safety Reviews the use of DL for smart city data, summarizes the popular DL models and surveys the latest works related to smart city applications applying DL techniques - Does not include smart home and agriculture use cases - Does not investigate the use of cloud, fog, and edge computing with DL-based applications - Does not discuss the problem of IoT big data (Q1) What are the main use cases of a smart city ecosystem? (Q2) What is the taxonomy of the most used DL algorithms that can be adopted in IoT? (Q3) How can DL algorithms be applied to IoT smart city applications/scenarios/use cases? (Q4) What are the challenges and open issues that face the development of smart cities using DL algorithms/models? To summarize, this survey provides the following key contributions as answers to the previously listed research questions: Q1: As a domain of application of the IoT related technologies, we have chosen the smart city. Several IoT systems are provided as means of serving different city domains. We categorize these services into six major use cases including smart home, smart healthcare, smart transportation, smart surveillance, smart agriculture, and smart environment. Q2: During the last few years, the most used ML techniques have been DL models. These models have gained success in different applications, such as image processing, speech, pattern recognition, and more. In this survey, we propose to review the relevant DL models and categorize them into six major groups of applicable models within the domain of IoT big data. These models include: (1) convolutional neural networks, (2) recurrent neural networks, (3) deep belief networks, (4) stacked auto-encoder, (5) deep reinforcement learning, and (6) generative adversarial networks. Q3: To investigate the use of DL, we reviewed approximately 60 relevant papers that examine the use of IoT big data analytics in smart cities. We discussed these works in order to provide a technical understanding of the DL algorithms at use in IoT smart city applications. This discussion will help others to understand which DL algorithm is most appropriate for the processing of IoT big data generated by and collected from smart devices. Q4: Developing smart cities entails facing multiple technical and business challenges. In this present survey, we define the main challenges and shed light on the most relevant issues concerning the use of DL in smart cities. Download : Download high-res image (571KB) Download : Download full-size image Fig. 4. Present survey structure. 3. Background and basic concepts This section provides an overview of the terminologies and background concepts related to IoT technology, computing infrastructures, and DL techniques. 3.1. Internet of Things IoT refers to the linkage and connections among billions of different objects over the internet to form a smart environment [21]. Based on standardized communication protocols, these devices share and exchange information across heterogeneous platforms [22]. Consequently, IoT enhances the interactivity and the efficiency of critical infrastructures such as those used in transportation, security, education, agriculture, and healthcare. 3.1.1. IoT architecture IoT architecture involves four levels: hardware, connectivity and communication middleware, big data storage and analytics, and IoT applications. This architecture is depicted in Fig. 5 and their levels are briefly described in the following subsections. 3.1.1.1. Hardware. This level is comprised of various smart devices, including sensors and actuators that can create and process signals. Sensors capture data and collect information from the environment, while actuators are responsible for transforming electrical signals into tangible actions. Sensors collect information in real-time, which in turn enables the interconnection among physical devices and digital networks. Different types of sensors fulfill different usages depending on the purposes of IoT applications. For example, wearable sensors are used to provide reliable information about human activity while other sensors are designed to collect measurements of different factors, which may include temperature, humidity, pressure, air quality, length, time, speed, movement, and heartbeat, among others [23]. Download : Download high-res image (215KB) Download : Download full-size image Fig. 5. IoT architecture. 3.1.1.2. Connectivity and communication middleware. In most cases, the data collected from sensors are stored in the cloud. Connectivity and communication middleware are responsible for the transfer of the gathered data. These types of middleware work as a transport medium to transfer data from the hardware level to the storage and analytics tools. Examples of middleware include WIFI, RFID, and Ethernet [12]. 3.1.1.3. Big data storage and analytics. The data collected by IoT must be stored and analyzed to extract valuable knowledge that can support decision-making [24]. Data analytics is the process of transforming data from raw units into actions and insights. There are mainly three different types of data analytics [25], [26]: descriptive, predictive, and prescriptive, as presented in Fig. 6. \u2022 Descriptive analytics are a general form of analytics used mainly in business [27]. Descriptive analytics measure and contextualize past achievements and monitor current performance in order to improve decision-making. The main objectives of descriptive analytics are to derive conclusions, extract hidden patterns from collected data, and create meaningful reports. Descriptive analytics have an informative impact, which is not helpful for prediction or forecasting. \u2022 Predictive analytics are used to extract information from raw data [28]. They are based on business intelligence techniques that allow for the extraction of patterns and the discovery of relationships from large amounts of data. Predictive analytics use historical and current statistics to forecast and predict behaviors and events. \u2022 Prescriptive analytics are more advanced than either descriptive or predictive analytics [29]. They can quantify the effect of future decisions and then provide recommendations on possible results before making decisions [30]. Therefore, with this type of analytics, the prediction process relies on a set of possible choices and suggestions. 3.1.1.4. IoT applications. The last level of IoT architecture is IoT applications. IoT can be used in various applications leveraged across several sectors, including transportation, surveillance, healthcare, agriculture, smart buildings, and energy management. These applications enable the environment to enact smart, real-time behaviors and actions. Download : Download high-res image (145KB) Download : Download full-size image Fig. 6. Type of data analytics. 3.1.2. IoT big data characteristics IoT applications generate large amounts of data in different formats, including images, videos, and audio. Mohammadi et al. [15] have defined the characteristics of IoT big data with the six V\u2019s features as follows: \u2022 Volume: refers to the huge scale of data generated and saved within billions of rows and columns. Therefore, new techniques are needed to process this big data in order to extract useful knowledge and insights. \u2022 Velocity: refers to the high-speed creation of IoT data. In an IoT infrastructure, multiple devices and sensors collect, store, and transfer data across different platforms automatically through Internet protocols. \u2022 Variety: refers to the different formats and types of IoT. In general, IoT data can come in the following types: \u2013 Unstructured data: data that do not follow any format, like text documents, PDFs, images, and video. \u2013 Quasi-structured data: textual data with faulty data formats such as Web click-stream data. \u2013 Semi-structured data: data with noticeable formats, such as XML and RDF data files. \u2013 Structured data: data organized in a specific format, such as transaction data and databases. \u2022 Veracity: refers to the correctness and validity of the collected data. This feature is very important because it can directly affect the results of analytics. \u2022 Variability: refers to the changing rates of data movement and collection. Depending on the time, a data source may receive different amounts of data. For example, a crowd-detecting application may receive a different data load at different hours of the day. \u2022 Value: represents the importance of the collected IoT data after being analyzed. This characteristic answers the following question: does the gathered data give useful information and helpful insights to improve efficiency in production and gain advantages against competitors? The rapid growth of big data with IoT has been supported by providing new software and hardware platforms [31], [32]. These platforms could handle the characteristics of IoT big data within a reasonable amount of time. Different studies have reviewed the platforms available for big data in terms of horizontal and vertical scaling [33], [34]. The horizontal scaling platforms are designed to provide users with the power needed to improve the efficiency and performance of their programs in small increments. The most popular horizontal scaling platforms include Apache Hadoop,2 Mahout,3 Spark,4 and H2O.5 On the other hand, vertical scaling platforms illustrate the different components that can add extra power or capabilities, such as increasing computational capacity by installing more processors and faster memories. Graphics Processing Unit (GPU), High-Performance Computing Clusters (HPC), and Field Programmable Gate Arrays (FPGA) are examples of the popular vertical scaling platforms. 3.2. Computational infrastructures for IoT big data analytics In recent years, predictive analytics for IoT big data have created great improvements in performance and accuracy, especially using DL techniques. However, these improvements have high computational and memory requirements, though these can be solved using specific, more advanced computational platforms. In addition to cloud computing, fog and edge computing are proposed. Fog and edge computing are designed as extensions to the cloud network and both enable data analytics to be conducted as near as possible to the source of data creation. The main difference between these two types is that fog computing is conducted on the servers of the local network, while edge computing is performed directly on the smart devices. 3.2.1. Cloud computing Cloud computing describes the technology that offers access to data from anywhere and at any time [35]. It consists of several servers and data centers that are available on the Internet for many users over the world. This type of computing has specific features including: \u2022 Storage over the Internet: cloud computing is a framework that connects servers with different distributed devices through Transmission Control Protocol/Internet Protocol (TCP/IP) networks. Therefore, it performs the storage deployment and facilitates the movement of data. \u2022 Service over the Internet: several services are available on the cloud with a large range of options, such as networking and artificial intelligence, to support users from different locations. \u2022 Applications over the Internet: cloud applications are programs offered on the cloud, which perform their tasks through Internet connections rather than programs that work locally on computers following installation. To apply DL algorithms on IoT data, cloud computing is utilized [36], [37]. The data generated by IoT devices are forwarded to the cloud infrastructure, where they are stored and analyzed in real-time using the different DL algorithms. Despite its advantages in terms of interoperability, sustainability, and flexibility, the use of cloud computing for IoT data analytics has some limitations [38]. These limitations can be summarized as follows: \u2022 Computation cost: large amounts of data are transferred to the cloud during the two phases of DL models (training and inference), which consume a large amount of the network bandwidth and thus increase the cost of resource usage offered by the cloud. \u2022 Latency: the time of gaining access to cloud services varies with the strength of the network connection. Sometimes, the cloud fails to respond within a short time, and this can be an issue, especially with time-critical applications such as smart traffic applications. \u2022 Reliability: cloud services and applications are provided using networks and wireless communications. Any problem with the network connection directly affects the reliability of the services provided. \u2022 Privacy: the IoT-collected data include sensitive data and personal information, so saving this data in the cloud creates privacy issues because these data may be lost in their way or exploited by unauthorized parties. 3.2.2. Fog computing Fog computing is proposed as an alternative to having all analytical processes taking place on the cloud [39]. Fog computing can be considered an increment for cloud computing to the edge of the network, developed to support the various IoT applications [40], [41]. Furthermore, fog computing is the technology of making computing nodes and data analytics near of the end devices. Vaquero et al. [42] have defined fog computing as \u201da huge number of heterogeneous (wireless and sometimes autonomous) ubiquitous and decentralized devices that communicate and potentially cooperate among them and with the network to perform storage and processing tasks without the intervention of third parties\u201d. Cloud and fog computing paradigms share the same services as storage, deployment, and networking. However, the use of fog computing is only available for specific geographic areas, while the cloud does not depend on a specific area. In addition, fog is designed mainly for interactive IoT applications that need real-time responses. Specifically, fog computing connects the cloud services with the edge of the network, to implement computation, communication, and storage processes close to edge devices, which are the IoT devices. In this manner, this type of computing enhances the low latency, limited network bandwidth, and problems concerning security and privacy. Fig. 7 depicts how fog nodes connect the edge devices to the cloud. Download : Download high-res image (186KB) Download : Download full-size image Fig. 7. Fog nodes connect edge devices to the cloud. 3.2.3. Edge computing Edge computing is proposed as a new paradigm strategized to reduce and mitigate the disadvantages of cloud computing [43]. Edge computing describes the technology that complements and extends the cloud, in which data computing is done as close as possible to the generated devices [44]. Edge computing provides a high computation space in which large amounts of data are processed at the edge before being transferred to the central servers in the cloud. The rapid rise of data creation has been a great challenge for data transportation to the cloud. In order to enhance the processing of these accumulated data, analytics are done at the edge instead of being sent to the cloud. Therefore, this type of computing enhances bandwidth efficiency, reduces response time, decreases network pressure, and minimizes energy consumption. Edge computing is an excellent platform for the development of smart cities [45]. Using an edge gateway, all smart devices are connected together, the collected data are processed locally, and services are available as needed, which enhances performance, privacy, and security. Download : Download high-res image (209KB) Download : Download full-size image Fig. 8. A Venn diagram that explains the differences between AI, ML, and DL. Download : Download high-res image (266KB) Download : Download full-size image Fig. 9. Different types of learning techniques. 3.3. Deep learning AI is the computers\u2019 ability to perform tasks that typically require human intelligence, such as image recognition, transcribing speech to text, and translation between languages. The capacities of AI have grown substantially over the past few years and ML, a subset of AI, provides computer programs with the capacity to learn and improve behaviors by training the program with a given dataset [46], [47]. The trained program then gains the ability to make decisions without being explicitly programmed. DL, an advanced ML technique, has also attracted great interest as a research topic in recent years [48]. DL models are considered representation-learning models, which means that they are able to learn nonlinear features and functions from vast amounts of raw, complex data with better performance than other ML methods [49], [50]. Li et al. [51] have defined DL as \u201ca promising approach for extracting accurate information from raw sensor data from IoT devices deployed in complex environments\u201d. Fig. 8 explains the relationship among AI, ML, and DL. DL techniques are typically categorized into supervised learning, unsupervised learning, semi-supervised learning, and reinforcement learning, as depicted in Fig. 9. (a) Supervised learning: refers to learning from labeled training data in order to predict outcomes for unforeseen data [52]. The two most common applications of supervised learning are classification and regression. (b) Unsupervised learning: refers to a type of learning that uses descriptive statistics to examine the patterns and relationships that occur naturally within the data [53], [54]. Unsupervised learning is used to find the hidden, interesting structure in data. (c) Semi-supervised learning: refers to the circumstances in which training data contain a few labeled data with a large amount of unlabeled data [55]. (d) Reinforcement learning: occurs between supervised and unsupervised learning [56]. Reinforcement learning gives an \u201cagent\u201d the ability to learn from its environment, enabling that agent to act and behave smartly. This learner agent then interacts directly with its environment via \u201cactions\u201d and receives \u201crewards\u201d from surroundings to inspire and create a perfect behavior policy. Q-learning is the most popular reinforcement learning technique [57]. The existing DL architectures have been categorized by Deng [58] into three classes: discriminative, generative, and hybrid classes. Discriminative DL architectures implement supervised learning, while generative DL architectures apply unsupervised learning approaches. Hybrid DL architectures combine the discriminative and the generative models. Fig. 10 summarizes the different DL techniques, their architectures, and their learning types. Download : Download high-res image (190KB) Download : Download full-size image Fig. 10. Deep learning definition, architectures, and types. 3.3.1. Deep learning models taxonomy In this section, we review the more common and relevant DL models and their variants, which include Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), Deep Belief Network (DBN), Stacked Auto Encoder (SAE), Deep Reinforcement Learning (DRL), and Generative Adversarial Networks (GAN). DL algorithms belong to the class of Artificial Neural Networks with many hidden layers [59]. Due to the sequence of layers, DL techniques are known as Deep Neural Network (DNN). In the case of processing images or videos, some filter operations are needed, creating a type of model called CNN [60]. For time-series predictions, loops are used between layers: these models are known as RNN. DBN is another DL model that consists of several stacked Restricted Boltzmann Machines (RBM) [61], while the SAE model is built with a set of several Auto Encoder (AE) [62]. DRL brings together DNN and reinforcement learning to create software agents that have the ability to learn from their environments and then use that knowledge to create policies that can gain long-term rewards. GAN is a hybrid DL architecture that combines two neural networks: a generative model and a discriminative model. The proposed DL taxonomy is presented in Fig. 11. 3.3.1.1. Convolutional Neural Network. CNN is classified as a discriminative DL architecture type. This model starts with an input layer, then includes a set of hidden layers, and finally finishes with an output layer. It consists of a set of convolutional layers connected in sequence in order to finish with one fully connected layer. Different filters are embedded within the convolutional layers to generate an output from the analyzed input. This network is composed of three essential hidden layers that perform specific operations: these layers are the convolutional layer, the pooling layer, and the fully connected layer [63], which are defined briefly as follow: Download : Download high-res image (117KB) Download : Download full-size image Fig. 11. Taxonomy of DL models. 1. Convolutional layer: is the first layer of the CNN model. The convolutional layer applies a weight matrix, called a filter, over the image input and then performs the dot product between the values of pixels in the image and the values in the weight matrix. A feature map results from the filter computation over the input image. Let a two-dimensional image named x be divided into a sequential input x = {x1, \u2026 }. Eq. (1) defines the process of a convolutional layer [18]: (1) where is the th convolutional layer output, is the activation function, presents the convolutional kernel multiplied by the th input , and denotes the bias. 2. Pooling layer: is employed to reduce the large matrices of feature maps, produced from the convolutional layers, by capturing their most relevant parts. This is done using either an average or a max-pooling operation to lower the complexity of the model computations. 3. Fully connected layer: at the end of the network, the processed portions are reconnected to form the full image. This layer is then squashed to probability values using activation functions. Sigmoid, tanh, and ReLu are the most popular activation functions used to deal with nonlinear problems. The resulted values represent the probability of a given image belonging to a specific class. The output layer then takes the highest probability to assign the image to the output class. These three layers are known as the convolutional block and to get a deeper model, this block is repeated within the network. CNN is the DL model used most often for image recognition and classification. Generally, CNNs employ supervised learning, although in some cases, they have been used with unsupervised learning. More specifically, CNN gains great success in image processing applications, where features are extracted from different locations within the photo. Fig. 12 illustrates the structure of the CNN model. 3.3.1.2. Recurrent Neural Network. RNN is classified as a discriminative DL architecture [11], [48]. RNN treats with time-sequential data, including speech, text, and language, and enables predictions using this data. RNN uses loops in their connection layers and extracts features from the inputs stored earlier. Different connections are performed between the neurons and the output is produced via recurrent connections that exist between hidden units [64]. An RNN consists of input units {x0, ... }, output units {y0, \u2026 }, and hidden units {s0, \u2026 }. At every time step named t, the RNN takes the current sample with the former hidden representation to produce an output through the two following equations (2), (3): (2) (3) where represents the encoder step and denotes the output function of the network at the time t. , are the weights and , are biased. They are exchanged among the various temporal locations in order to lower the complexity and the overarching problems that may face the model. Download : Download high-res image (120KB) Download : Download full-size image Fig. 12. The structure of CNN. RNN gains the ability to pick up the arbitrary length dependencies by training the network using the Backpropagation Through Time (BTT) algorithm [65]. However, using this algorithm for data collection for long-term dependency often fails due to the gradient vanishing and exploding [66]. Hence, the training phase becomes very difficult for tasks in which input/output sequences have temporal contingencies over long intervals. Long Short-Term Memory (LSTM) has been proposed as a means of solving this issue [67]. LSTM handles the gradient vanishing and exploding problem using a set of gates: input, forget, and output. These gates monitor access to the memory cells, protecting them from perturbation by unrelated inputs. In fact, these gates improve the model\u2019s ability to remember for a longer time period and to forget any unimportant value. A sigmoid layer is introduced from these gates, has an output value between 0 and 1, input weights W, recurrent weights R, and bias weights b. LSTM begins by defining the information that will be eliminated from the cell state [68]. Therefore, forget gate works as the first layer. If the result value equals 1, this means that in order to keep this information, while 0 indicates the option to forget it. The forget gate is defined according to Eq. (4): (4) The second step is to determine which new information will be added to the cell memory state using the input gate. This gate is composed of two layers: the sigmoid and the tanh. In the sigmoid layer, the values that will be updated are defined. While in the tanh layer, the new candidate values are determined. After that, the results are collected, and the state is updated. The input gate is defined according to Eqs. (5), (6): (5) (6) After computing these equations, the cell state is updated, the values to be forgotten are eliminated, and the new information is added according to Eq. (7): (7) The final step is completed on the output gate where the parts of the cell state that will go to output are defined. Moreover, this gate consists of two layers: the sigmoid and the tanh. The sigmoid layer is responsible for identifying the parts of the cell state to be sent for output. Then, the cell state is put through the tanh layer to get normalized values between \u22121 to 1. Finally, these obtained values are multiplied by the output of the sigmoid layer. The processes of the output gate are defined according to Eqs. (8), (9): (8) (9) By applying these steps, the LSTM adds and removes information to the cell state, which is impossible for the RNN that keeps and overrides the state of cells. In many applications, the RNN and LSTM have destroyed a great performance. However, LSTM models work better than RNN when processing long dependency data. A graphical representation of RNN and LSTM is presented in Fig. 13. 3.3.1.3. Deep Belief Network. In 2006, DBNs were proposed as a greedy layer-wise unsupervised learning algorithm [69]. Therefore, this model is classified as a generative DL architecture. The DBN is a graphical model that processes the training data to extract deep hierarchical representations. This model has the ability to learn from the internal representation of data in an automatic way through layer-wise training and then produces the outputs directly from the input data [70]. DBN is trained by a two-stage strategy that contains a pre-training stage and a fine-tuning stage. This model consists of a visible layer with a number of hidden layers, which operates as follow: Download : Download high-res image (149KB) Download : Download full-size image Fig. 13. The structure of RNN and LSTM. (a) Each layer is pre-trained greedy (b) In every layer, data are extracted from the input using unsupervised learning (c) The entire network is fine-tuned with the consideration of global training requirements This network is a stack of restricted Boltzmann machine. RBM is a binary network of stochastic units designed for unsupervised learning [71], [72]. This machine is made up of two different layers: a visible layer and a hidden layer. No connections are performed within the same layer, but symmetric connections are performed between the visible and hidden layers. During the training phase, RBM computes the probability distribution over the input data training to get binary values between 0 and 1 using Eqs. (10), (11). (10) (11) where h denotes the hidden layer, v is the visible layer, W presents the weights, and a/b is the biases. This network has been applied in different applications, such as feature extraction and pattern recognition. Using a combination of DBN and RBM has shown significant performance improvements in different tasks, such as image classification, speech recognition, and time series forecasting. The structure of these two networks is presented in Fig. 14. 3.3.1.4. Stacked Auto Encoder. SAE is classified as a generative DL architecture and it consists of AEs employed to learn features from inputs. In addition to DBN, AE is proposed for addressing the problems with unsupervised learning. A basic AE consists of three or more layers: an input layer, an output layer, and one or more hidden layers in between them. Two stages are performed to get the output known as the encoding and decoding stages. In the encoding stage, the input is transformed into a new presentation of hidden layers h, which is usually termed code. The encoding function is defined according to Eq. (12): (12) Download : Download high-res image (175KB) Download : Download full-size image Fig. 14. The structure of RBM and DBN. Download : Download high-res image (189KB) Download : Download full-size image Fig. 15. The structures of the \u201cAuto-Encoder\u201d and the \u201cStacked Auto-Encoder\u201d. Then, the output y is produced from the reconstruction of these hidden representations h to their original form. The decoding stage is defined according to Eq. (13): (13) where f and g are the used activation functions, W presents the weight matrix, and presents the bias vectors. These two functions are non-linear mapping functions, and therefore require the use of nonlinear activation functions. Several applications have used the SAE for human activity recognition, emotion recognition, and network intrusion. Fig. 15 illustrates the structures of AE and SAE. 3.3.1.5. Generative Adversarial Network. GAN is considered a hybrid DL architecture that combines two neural networks [73]. GAN is a framework that trains two models: a discriminative and a generative model that work together to produce accurate outputs. The generative model G is responsible for recording the distribution of data from training data, while the discriminative model D evaluates this data and differentiates between the real and fake inputs. Therefore, GAN\u2019s objective is to solve this min\u2013max problem, where the generator essays to maximize the value function while the discriminator works to minimize it, as defined in Eq. (14): (14) In fact, the generator produces random data to trick and fool the discriminator. Otherwise, the discriminator receives these data and attempts to distinguish the real data of the training set from the fake samples produced by the generator. In IoT applications, the GAN is useful for transforming the data available to reconstruct new things. For example, GAN finds great success in generating images, image modification [74], [75], [76], and object detection [77]. The structure of GAN is illustrated in Fig. 16. 3.3.1.6. Deep Reinforcement Learning. DRL is the composition of deep neural networks with reinforcement learning [78]. DRL has the ability to create software agents, which are self-learning neural networks that interact with their environment systematically in different situations and multiple states. These agents then gain the ability to make optimal policies that include the best actions to deal with different possible situations. In addition, they can get long-term rewards as feedback from their environments. The key elements that are included in the implementation of a DRL model are defined briefly as follow: Download : Download high-res image (122KB) Download : Download full-size image Fig. 16. The structure of GAN. (1) Environment: the milieu where the agents move, learn, and act; (2) Agent: learns from a given environment how to operate, then takes actions; (3) Policies: define the plans that agents utilize them to determine the right action for each state; (4) States: present the current situations where agents find themselves; (5) Actions: describe what the agents should do for each state; (6) Rewards: represent the environment feedback after an agent action for a specified state, it can positive or negative; DRL is suitable for problems comprised of several states, such as the problem of crowd prediction [79]. In a work presented by [80], a flexible DRL framework is proposed to forecast the best treatment regimens from observational medical data in dynamic ways. The structure of the DRL is illustrated in Fig. 17. 3.3.1.7. Summary. Table 2 summarizes the DL models discussed above as well as their characteristics, main applications, advantages, and limitations. Download : Download high-res image (67KB) Download : Download full-size image Fig. 17. The structure of DRL. Table 2. Comparison between deep Learning models. Category Model Type of learning model Pros Cons Main applications Discriminative CNN Supervised Unsupervised Reinforcement + High performance in feature extraction, especially for images - Complex computation - Needs large datasets for training \u2022 Smart counting \u2022 Fire detection RNN Supervised Unsupervised Reinforcement + Suitable for time series data - Complex computation - Gradient vanishing and exploding \u2022 Text categorization \u2022 Pattern recognition \u2022 Speech recognition LSTM Supervised + Efficient for long time lag data - Long computational time \u2022 Accident prediction \u2022 Energy management \u2022 Human activity recognition Generative RBM Unsupervised Supervised + Useful for classification + Able to extract numerous vital features - High computational cost - Complex training process \u2022 Image classification \u2022 Disease identification DBN Unsupervised + Layer-by-layer learning for network initialization + Extraction of deep hierarchical representation - High computation for training processes due to initialization and sampling \u2022 Activity recognition \u2022 Behavior prediction AE Unsupervised + Reconstruction of input to get output + Threatens unlabeled data + Feature extraction - Long computational time - Complex pre-training needed for big data \u2022 Face recognition \u2022 Energy consumption SAE Unsupervised + Offers unsupervised pre-training + Minimizes reconstruction errors - Pre-training is required - Problem of gradient vanishing \u2022 Human activity recognition \u2022 Emotion recognition \u2022 Network intrusion Hybrid GAN Unsupervised + Production of large amounts of data + Efficient for noisy data - Unstable and complex training process \u2022 Image-to-text conversion \u2022 Object detection \u2013 DRL Reinforcement + Suitable for high-dimensional environment modeling - Slow in terms of convergence \u2022 Crowd management \u2022 Treatment regimes 3.3.2. Deep learning tools DL is broadly used in a wide range of applications, and different frameworks and libraries have been developed to support the research using DL techniques. These tools are open-source and thus characterized by ease of use: they can be employed even by persons who lack experience with DL models [81]. In this section, we review and discuss the most popular DL tools, namely TensorFlow, Torch, Theano, Caffe, Keras, MatConvNet, Deeplearning4j, MXNet, and Chainer. \u2022 TensorFlow [82] is a DL framework programmed using the C++ language. This framework is characterized by a flexible and scalable architecture that allows experimentations to be done with low latency, high performance, and active training and deployment processes. Data graph representations are used by TensorFlow to make the analytical computations required. Different available Google services have been developed using the TensorFlow platform, such as Google Maps, Google Translate, and YouTube. \u2022 Torch [83] is another open-source framework programmed using Lua.6 It supports ML techniques, including DL models, and represents a flexible and modular framework that has the ability to train DL models more rapidly. Different companies have utilized Torch to build their services, including Google, Facebook, and Twitter. \u2022 Theano [84] is an open-source library developed using Python. It can be executed on both CPUs and GPUs and it manages great performance, especially for DL techniques that impose and execute multiple redundant computations, like RNN and LSTM models, through mathematical expressions. For these computations, Theano has the ability to program the mathematical expressions quickly using graph representations. \u2022 Caffe [85] is another open-source DL framework that handles several reference models. This platform is programmed using C++, executed either by CPUs or GPUs, and provides interfaces for both MATLAB, Python, and CLI. The implementation and interfaces of Caffe are developed separately, which provides easy model configurations without hard coding. Caffe shows high accuracy and great performance, especially for image recognition due to its ability to analyze more than 60 million images in the day using a single NVIDIA K40 GPU. \u2022 Keras [86] is a high-level DL library developed using Python. Keras runs on both TensorFlow and Theano frameworks, and it is suitable for both convolutional and recurrent networks because it performs experiments quickly. Keras can be used even by those who are new to DL, since its results are easy to read and interpret. \u2022 MatConvNet [87] is a MATLAB toolbox that consists of several trained CNNs for image recognition and classification applications. It is easy to install, simple to use, and effective to apply CNNs. \u2022 Deeplearning4j [88] is an open-source library written in Java and Scala that can be used on GPUs and CPUs. DL4j supports a variety of DL models including DBM, DBN, SAE, and CNN. It is designed to support business environments with AI. \u2022 MXNet [89] is a flexible DL library that runs on different types of devices, including both mobile devices and GPU clusters. It is simple, easy to use, and has detailed documentation. MXNet has demonstrated good performance on projects in facial recognition, object detection, and image classification. \u2022 Chainer [90], [91] is a powerful Python-based framework designed to facilitate the implantation process of DL algorithms. It is a flexible and intuitive tool that covers a variety of DL models including CNN, RNN, DRL, and AE. Chainer is very suitable for sentiment analysis, speech recognition, and translation. Fig. 18 shows the percentage of use for each of the DL platforms previously presented. These platforms are summarized and compared in Table 3. Download : Download high-res image (168KB) Download : Download full-size image Fig. 18. Percentage of use of the most popular deep learning platforms [92]. Table 3. Comparison between the open source DL tools. Tool Type Created by Programming Language Interfaces Pros Cons Used in Tensor-Flow Framework Google Brain team Python, C++ Python, C++, Java, Go + Supports dataflow programming + Good support using mathematical expressions + Works on both CPUs & GPUs - Training stage takes more time compared to other platforms - Data graph representations are required for each computation flow [93], [94], [95], [96], [97], [98] Torch Framework Ronan Collobert, Koray Kavukcuoglu, and Clement Farabet Lua C, C++, Lua, OpenCL + Flexibility, modularity, and speed + Suitable for many types of DL models - Lua is not a popular language; it should be learned/ mastered in order to use Torch [99] Theano Library University of Montreal Python Python + Open-source numerical library that supports the different DL models development + Ideal for RNN and its variants - Low-level of APIs. - Lack of APIs that support mobile platforms [100] Caffe Framework Berkeley AI Center C++ C++, Python, MATLAB + High performance with CNN for image processing + User-friendly interfaces for Python and MATLAB + Referenced models - Not suitable for RNN models - Additional custom layers should be coded using C++ [101], [102], [103], [104], [105] Keras Library Fran\u00e7ois Chollet Python Python + Fast experimentations + Runs on CPUs and GPUs + High-level APIs with detailed documentation - Less configurable compared to other low-level APIs libraries [106] Deeplearning4j Library Adam Gibson Scala, Java Python, Java, Scala, Clojure +Training is done in parallel + Supported by Hadoop/Spark + Provides DL models that have pre-trained weights - Training has intensive time requirements - Scala and Java languages are less popular than Python in DL research MatConvNet MATLAB toolbox Andrea Vedaldi, Karel Lenc C++ MATLAB + Pre-trained CNN models + Easy to use, train, and deploy models - Supports only the CNN models - Poor documentation [107] MXNet Library DMLC team C++ Python, R, Scala, Julia, C++, R, Perl, ONNX + Runs on different GPU clusters with efficient computation scalability + Rapid development of problems solutions + Efficient distributed training - Not popular - More complex to use compared to other libraries like Keras [108] Chainer Framework Preferred Networks Python Python + Characterized by a dynamic architecture of models + Faster implementation of models - Strong support from Japanese companies - Not popular - Training and debugging require more time than in other frameworks 3.3.3. Deep learning datasets To develop IoT smart city applications using DL techniques, large amounts of real-world data are needed to achieve better performance. Having open access data are a critical issue for DL research since relatively few data sources have been collected and made available for training DL models. This dearth has led researchers in some fields to develop their own datasets, but this is a very difficult and complex process that requires a great deal of time and effort. The most commonly used DL datasets for smart city use cases are illustrated in Table 4. Table 4. Common DL datasets used in smart city applications. Ref Dataset Creator Format IoT application Description [109] IHEP dataset Georges Hebrail et al. Text Energy management This dataset consists of 2075259 measurements collected from a home in Paris once every minute for 47 months [110] UK DALE dataset Jack Kelly, Knottenbelt William Text Energy management This open access dataset contains data that describe the amounts of power demanded by home appliances each day over five houses [111] SisFall dataset Sucerquia et al. Video Fall detection This dataset consists of different daily activities and several types of fall sequences [112] URFD dataset Michal K\u0119pski Videos Elderly care This dataset consists of 70 sequences of both falls and daily activities [113] NTU RGB-D dataset Shahroudy et al. Videos Human activity recognition, Healthcare This dataset consists of several labeled video records of human activities [114] HandPD dataset Clayton, Jo\u00e3o Paulo Images Disease prediction This dataset consists of 736 labeled handwritten exam images for both healthy persons and patients. It is used to detect Parkinson\u2019s disease [115] TST dataset ECML PKDD Smart traffic This dataset describes the trajectories of 442 taxis recorded across Porto City, Portugal, from 2013\u20132014 [116] NNRPark+EXT dataset Giuseppe Amato et al. Images Smart parking This dataset consists of 150,000 occupied and non-occupied parking lots images [117] PKLot dataset Almeida et al. Images Smart parking This dataset is composed of 695,899 images of parking lots labeled and classified manually [118] US accidents dataset Moosavi et al. Text Accident detection This dataset collects about 3 million records of accidents, from 49 states across the US, between 2016 and 2019 [119] Plant Village dataset David. P. Hughes, Marcel Salathe Images Agriculture This dataset includes 61,486 images of leaves from 39 different plant categories [120] AirNet dataset Zhao et al Text Air quality This dataset consists of air quality measurements with meteorological data collected during over two years 4. Use of deep learning in the smart city applications: Literature review Employing DL techniques for analyzing IoT data has had significant effects on several city areas. This technology enhances the life quality of city inhabitants, helping achieve the vision of smart cities and show an excellent performance essentially when working with big data. Actually, several IoT applications and devices have been designed for the evolution of smart cities. They are developed to act without the need for human intervention: instead, they are either controlled automatically by special devices, or else they wait for prompts from operational or environmental conditions. These smart devices could learn to make decisions and take actions better and more rapidly by learning from data that have already been collected. This process can be facilitated when the collected data are stored in the cloud/fog servers, where they are analyzed by a variety of DL techniques. Different sectors across the city have recently gained the capacity for smart technologies and actions. These sectors include: 1. Smart homes: residences that contain developed equipment connected to the internet. These smart devices, including fridges, lights, and televisions, communicate with each other and share data with users. Implementing smart homes is intended to enhance the management of devices and optimize energy consumption. 2. Smart healthcare: wearable or non-wearable devices that have the ability to track the user\u2019s daily activities and record different measurements about the user\u2019s health, including heartbeat rate, temperature, or blood sugar state. These devices are connected to the internet network and report data to doctors online. Smart healthcare offers the ability to provide ongoing monitoring for patients\u2019 health and well-being, enhancing care with real-time updates. 3. Smart transportation: advanced devices and optimized services used to enhance transportation in cities. Smart transportation aims to offer easy smart parking, reduce the crowd density, and manage mobility within the city, offering solutions that improve traffic flow. 4. Smart surveillance: the deployment of monitoring devices such as smart cameras in different city areas to enhance surveillance and incident prevention. With real-time data collection and analyzing, smart security systems can detect disasters at an early stage, and therefore prevent the occurrence of dangerous situations. 5. Smart agriculture: the employment of IoT devices in agriculture to automate and/or improve traditional methods. These services help guarantee healthy crop production and enhance the harvesting, packaging, and transportation processes through services such as smart control of plants and smart crop counting. 6. Smart environment: the enhancement of city infrastructures using intelligent sensors distributed in different fabrics of the city. These sensors monitor and even control environmental conditions in order to offer a healthier environment. Different applications have been developed to monitor characteristics such as air quality. Fig. 19 presents an illustration of the smart city ecosystem, demonstrating how data are first assembled from edge smart sensors embedded in different fabrics, then transferred to the fog and cloud for storage, analytics, and computation, and finally, interpreted to serve different IoT applications across the city. State-of-the-art DL usage for IoT applications in smart cities is discussed in the following subsections. Download : Download high-res image (520KB) Download : Download full-size image Fig. 19. A representation of a smart city ecosystem. 4.1. Smart home: Energy management In general, buildings consume a significant amount of energy by employing different appliances. However, these appliances are typically controlled and used without implementing energy management strategies, and as a result, buildings tend to waste a lot of energy. New technologies, including IoT and DL techniques, can monitor these appliances and their energy usage in real-time in order to ensure energy efficiency and savings. The term \u201csmart home\u201d has appeared to describe this practice. A \u201csmart home\u201d is defined as a residence that has smart equipment connected to the Internet that share and exchange current information about the home state. The home appliances that are continuously monitored and controlled in this way may include air conditioners, refrigerators, washing machines, and more. In this manner, the smart home concept provides a better home with good energy management. In order to implement the concept of smart homes, a number of IoT devices are embedded and several sensors are deployed at different home components. These devices collect data to be analyzed for better energy usage and reduced energy costs, which they accomplish by monitoring energy consumption. Much of the literature includes research and studies conducted in this field. In the following paragraphs, we summarize relevant recent works that concern the application of IoT and DL techniques in home energy management. In order to detect the amount of energy consumption, the LSTM model is most often employed, either alone or combined with CNN. In [121], Popa et al. proposed a Smart Home Environment (SHE) platform that controls the distributed sensors and actuators embedded in the home environment. The SHE platform employs a set of generic automation algorithms to monitor the connected home systems and collect data from sensors, then uses these data to create and develop deep neural network models. These models allow for the detection and calculation of variations in energy consumption, and then provide advice to end-users. The proposed platform helps reduce electrical energy costs. The LTSM model is employed to forecast the energy load, while the denoising and sparse AEs are used to determine the usage period and amount of energy consumed. A smart energy monitoring system for home equipment using an LSTM model has been proposed by Rashid et al. in [122]. This system is composed of three main components a Raspberry Pi based smart plug for collecting data to be tested, a Google Gulab that serves as a training server, and a dashboard using Matplotlib library that helps users to monitor their energy consumption at real-time. The server in particular is where the data are saved after being trained by the LSTM model. Using this DL model, the electricity bill is predicted, and if there is any abnormal energy consumption of any home equipment, it will be detected, and the user will be notified. The results of Rashid et al.\u2019s experiments demonstrate the high accuracy of the proposed system of more than 80% in determining the amount of energy consumption and bill prediction. Manic et al. [123] have also worked on the energy consumption of smart buildings and homes. The authors employed three types of DL models: an LSTM, an LSTM Sequence-to-Sequence (S2S), and a CNN. They applied these models to the same dataset, and their results proved that LSTM S2S is the best model for predicting energy usage. Kim et al. [119] have also worked on electric energy consumption. The authors proposed combining CNN and LSTM models into a CNN-LSTM hybrid model that enables the capture of spatial and temporal features to forecast the energy consumption in a house. In this hybrid model, the CNN is used to extract features of energy consumption, while the LSTM model squeezes out the temporal information of irregular trends in time series components. Experiments have demonstrated that this proposed hybrid model could forecast complex electric energy consumption with high accuracy. Yan et al. [106] developed a hybrid DL model for energy consumption prediction. This model is a combination between an LSTM neural network and the Stationary Wavelet Transform (SWT) technique. The collected energy consumption data are grouped into a set of sub-signals with the SWT, while an LSTM network is developed to predict the consumed energy for each sub-signal. To obtain the total energy consumption, these prediction results are combined and integrated using inverse stationary wavelet transform. The results obtained demonstrate that this proposed method offers better accuracy than previously proposed methods, including support vector regression, LSTM, and CNN combined with LSTM. Le et al. [124] proposed an Electric Energy Consumption Prediction framework called EECP-CBL, which is based on two CNNs and a bi-directional LSTM. The CNNs are responsible for extracting features and information from a dataset named \u201cindividual household electric power consumption\u201d. After that, the LSTM works to make predictions about the consumed energy amount, based on the CNNs extracted information and the collected trends of time-series in two directions: the forward state and the backward state. The final prediction of energy consumption is completed on two fully connected layers by accumulating the obtained predicted values. Table 5 summarizes the previously discussed works, providing the DL model and the type of computing infrastructure each one utilizes. Table 5. A summary of the smart home related works. Use Case IoT application Ref Input data DL model(s) Computing infrastructure Smart home Energy management [121] Authors develop their own dataset from home devices AE+LSTM Cloud computing [122] IHEP dataset LSTM [123] LSTM S2S [125] CNN+LSTM [124] CNN+Bi-LSTM [106] UK DALE dataset LSTM+SWT 4.2. Smart healthcare IoT also influences the care that patients receive by offering providers better asset utilization while minimizing costs and providing new avenues of revenue. In addition, IoT can modify and improve the delivery of healthcare and the maintenance of individual well-being [126]. Different IoT applications using DL techniques have been developed for different healthcare services including elderly care, disease prediction, and dietary assessment. 4.2.1. Elderly care In recent years, the number of elderly people that live alone in their homes has increased. For example, the number of persons living alone having an age of 75 and over is about 2376 in the United Kingdom [127]. However, these persons do not always enjoy full health or stable health conditions and are not always able to fully care for themselves. Therefore, safety and well-being are growing challenges among this population. To address this issue, Feng et al. [128] have provided a fall detection system that employs DL models to analyze the different postures detected within the environment of a smart home. This system has the ability to generate an alarm when it detects a human falling so that the fallen person can get help from others as soon as possible. Firstly, the area of the human body is extracted to get a foreground silhouette. Then, these collected silhouettes are fed into DL classifiers. In this work, the authors use two DL models, DBN and RBM, for posture classification. The regular postures of a person in a home are classified to be standing, sitting, or lying. Resting at the floor more than a defined threshold is addressed as a fallen posture. Experimental results present a good performance of the proposed system with 86% correct fall detection and only 4% incorrect detection. In other works, CNN is investigated as a means of detecting falls for elderly persons\u2019 care. In [129], Li et al. extract different frame images from camera video sequences, then process these images using a CNN model to learn the human body deformation features. After that, the model could detect occurring falls with 99.98% accuracy in real-time. In another work, Santos et al. [130] used CNN with fog computing to develop a human fall detection system. In the first step, data are gathered from the user smart devices, including smartwatches and phones, to be utilized as input for training the model. The developed CNN model is deployed at a local fog device and has the ability to extract relevant features from the collected data then detect the occurrence of a fall. Another DL approach was proposed in [131], where Adhikari et al. introduced a vision-based tracking strategy for fall detection using a CNN model. Furthermore, researchers have utilized time-sequential and mobile data with recurrent networks to detect falls quickly and accurately as they occur. Torti et al. [96] proposed an RNN-based embedded software within wearable devices. This software has the ability to detect the wearable user\u2019s fall and would then send notifications to the monitoring system through a wireless network. The results achieve 98% accuracy in detecting falls. Mauldin et al. [132] developed an Android application named SmartFall, which detected falls using the data collected from a wearer smartwatch. This smart device is connected to a smartphone where the application is installed. The SmartFall application allows a real-time prediction for falls using an RNN model, with high privacy and low latency, since the computations are done directly on the smartphone. Shojaei-Hashemi et al. [133] used the transfer learning to propose an LSTM approach for human fall detection. This approach has the ability to extract features from camera depth maps, detects human falls when occur, and notifies families using an alarm, and the results demonstrate 93% accuracy. Moreover, CNN and LSTM models have also been combined and applied for fall detection. In [134], Nait Aicha et al. combine between the convolutional and the recurrent models and refer to that as the \u201cConvLSTM\u201d model. Lu et al. in [135] also develop a 3D CNN method combined with LSTM to ensure fall detection. The 3D CNN extracts movement features from the temporal sequence in each video sequence, while the LSTM model is employed to identify the region of interest within the frame. Results of experimentation with the proposed method have shown good performance with 100% accuracy. 4.2.2. Disease prediction Disease prediction is another area that can benefit from further exploration, as demonstrated by the following works exploring treatment history and health data. Different DL models are performed on these data in order to forecast possible maladies that may affect patient health. In [108], Shi et al. proposed using a CNN model to predict invasive diseases for patients with ductal carcinoma. This model is pre-trained on non-medical images and used to extract deep features from digital mammograms. The conducted experiments show that deep features results are nearly identical to hand-crafted computer vision features that had been provided with previous knowledge about the domain. In [101], a CNN model was proposed to identify Parkinson\u2019s disease at an early stage using the classification and image analysis of medical images. Parkinson\u2019s disease is a problem with the nervous system, which makes it disordered and affects the human movement. The authors worked on handwritten image recognition using a CNN model. Wang et al. [136] have also reported the use of CNN to detect cardiovascular disease from mammograms. Breast Arterial Calcification (BAC) is used as an effective sign for the detection of coronary artery disease. The authors in this work develop a CNN model that contains twelve layers. This model examines the patient\u2019s state and has the ability to detect the BAC sign that signals the presence of this disease. The RNN model and its variants, including LSTM and GRU models, have also been used for the detection of the abnormal heartbeat. Siddique et al. [137] presented an approach for heartbeat classification. The proposed approach allows for the detection of abnormal heartbeats using DL models. The authors use a dataset consisting of heart sound records and then apply the RNN, LSTM, and GRU models to this dataset, since these models are more suitable for analyzing sequential and temporal data. 4.2.3. Dietary assessment The development of automatic dietary assessment systems could be a good solution to fighting obesity. Liu et al. [103] have proposed a system for food image recognition to improve the accuracy of dietary assessment. The authors proposed a new CNN based on a food image recognition algorithm to address the problem of deriving food information. The food images were captured by mobile devices and analyzed to estimate dietary intake. Good results were obtained after applying the model on two different datasets: 81.5% accuracy using the UEC-256 dataset, and 73.9% accuracy using the Food-101 dataset. The approach proposed by Liu et al. [102] reported a food recognition system that helps in dietary assessment using edge computing. The authors employed a CNN model to classify food images using mobile systems. The used data are a collection of food images captured by IoT sensors. The proposed system consists of three major modules: a front-end component, a communication component, and a back-end component. The first component runs on the edge, where the food images are pre-processed and generated in a clear form. The second component is responsible for communication between the two other components while the back-end component runs on the cloud wherein the CNN model is deployed. This component is responsible both for extracting features from the collected photos and for classifying them. In Table 6, we summarize IoT applications discussed above, which have included applications for elderly care, disease prediction, and dietary assessment. Table 6. A summary of the smart healthcare related works. Use case IoT application Ref Input data DL model(s) Computing infrastructure Smart healthcare Elderly care [96] SisFall dataset RNN Cloud computing [128] Authors create their own data DBN+RBM Cloud computing [129] URFD dataset CNN Cloud computing [130] URFD dataset CNN Fog computing [131] Coco dataset CNN Cloud computing [132] Smartwatch, Notch, andFarseeing datasets RNN Edge computing [133] NTU RGB-D dataset LSTM Cloud computing [134] \u2013 CNN+LSTM Cloud computing [135] Sports-1M/ Cameras fall/ FDD/ URFD datasets 3D CNN+ LSTM Cloud computing Disease prediction [101] HandPD dataset CNN Cloud computing [108] ImageNet dataset CNN Cloud computing [136] Authors use 840 digital mammograms images collected from medical systems CNN Cloud computing [137] PhysioNet/ Cardiology Challenge dataset RNN Cloud computing Dietary assessment [102] UEC-256/UEC-100 datasets CNN Edge computing [103] UEC-100/UEC-256/Food-101 datasets CNN Cloud computing 4.3. Smart transportation Large cities with large populations suffer from enormous traffic loads, which waste large amounts of fuel and time and can also damage roads and other infrastructure. Smart transportation is one outcome of utilizing DL models with IoT data. Several applications have recently been presented as options that provide innovative services for transportation and traffic management. The improvement of transportation systems upgrades individual safety, improves coordination between different transportation networks, and provides smarter traffic and parking across the city. 4.3.1. Smart traffic Smart traffic applications integrate live data and feedback from several IoT sensors and devices. In [138], Song et al. presented a DeepTransport system to predict the crowd movement patterns in smart city transportation. Here the authors used an LSTM model consisting of four layers. This model learns from two features: human mobility data and the way of transportation (car, train, or walking). These two features are processed separately as two different processes. In [139], an RNN model for vehicle mobility prediction was proposed. The model could forecast the probability of a vehicle to enter any city area in a prediction period, based on its previous mobility trajectory. The obtained results validate the prediction improvement of the proposed system by a rate of 18.3% to 24.6%. Zhao et al. [140] also developed an intelligent crowd management framework using the DRL. This framework was able to manage several crowd distribution requests and avoid network congestion. To deal with the overcrowding in metro stations, Liang et al. [141] proposed a new system called Mercury. This system employs an RNN model to predict the crowd density in stations. Real-time analytics are made on telecommunication data collected, or Caller Details Records (CDR), from users\u2019 mobiles. CDR tracked real-time use of mobile phones, including the phone calls, messages, and internet connectivity, which gave Mercury the ability to predict and report on crowd density prediction, including the number of passengers entering or waiting within a station. When the system detected overcrowding in a station, it could alert the metro administrators about the problem. Using edge computing, Zhou et al. [142] developed a Robust Mobile Crowd Sensing (RMCS) framework. They employed DL models to validate sensory data, and the edge computing to provide the local data processing. Active participant recruitment was implemented to determine the location, the schedule, and the rewards among the sensing platform and the potential participants. These participants have the capacity to upload data that are collected from sensors. These data are then validated using the CNN model. The developed CNN model ensured classification via pattern recognition and enabled data verification, authentication, and identification. 4.3.2. Smart parking Smart parking develops novel applications that help people to park their vehicles more quickly, conveniently, and using fewer resources [143]. By doing so, these applications help to enhance the movement of both people and goods. Using a network of cameras, Bura et al. [144] proposed a smart parking solution by employing a CNN model and edge computing network. The edge computing network allows the system to obtain the characters of vehicles\u2019 license plates, while the developed CNN model has the ability to control and monitor the parking lot. The proposed solution allows real-time analysis on edge devices. Amato et al. [145] proposed a decentralized system of smart spot identification. By deploying a deep CNN model created specifically to run on smart cameras, the proposed system can pick up the occupied and non-occupied spots in a parking lot. The CNN model has the capacity to automatically classify parking space images as occupied or empty and then display the results on the smart camera\u2019s board. After the spot classification, the output is sent to a central server for visualization. Despite the existence of some noise problems, experiments have demonstrated promising performance of the proposed system. Yang et al. [146] proposed a DL model that combines CNN and LSTM, to predict the occupancy of block-level parking. The developed model could take different types of traffic data including speed, weather state, and parking meter transactions, as input. The results obtained from the authors\u2019 experiments demonstrate that the solution performs well, particularly when the information about weather has been added. In [94], a video system for real-time parking measurement was proposed to support the development process of smart cities by applying deep CNNs and a smart car-tracking filter. This filter worked as a mode filter with a dynamic kernel to facilitate the detection process of car locations. The proposed system worked on a video problem instead of processing images alone. The results obtained demonstrate that the proposed solution performs better than other methods based mainly on images. A summary of the discussed works is provided in Table 7. Table 7. A summary of the smart transportation related works. Use Case IoT application Ref Input Data DL Model(s) Computing Infrastructure Smart transportation Smart traffic [138] Authors create a large dataset that consists of human mobility and transportation network data collected in Japan from 2010 to 2013 LSTM Cloud computing [139] Taxi mobility dataset RNN Cloud computing [140] \u2013 DRL Cloud computing [141] Authors exploit two different datasets: the caller detail record data collected from mobile phones and the metro station data RNN Cloud computing [142] ImageNet dataset CNN Edge computing Smart parking [94] Stanford Cars dataset CNN Cloud computing [144] PKLot and CNRPark datasets CNN Edge computing [145] PKLot and CNRPark-EXT datasets CNN Cloud computing [146] Authors collect their dataset by combining four different data sources of parking images available on the Internet CNN+ LSTM Cloud computing [147] Authors develop a dataset that contains images of different kinds of parking slots CNN Cloud computing 4.4. Smart surveillance Surveillance is the act of monitoring and controlling behavior and activities, and smart surveillance can be defined as the employment of automatic video analysis technologies within surveillance applications in order to manage and protect humans or objects from issues such as crimes and fires. Consequently, smart surveillance can contribute to the improvement of city control. A number of useful applications have been provided to help minimize the effect of abnormal events such as accidents, disasters, medical emergencies, fires, and floods. 4.4.1. Fire detection Fire can spread particularly quickly in dense cities and cause harm to many people at once, which means that the detection of fire in its early stages can help to avoid injuries, medical issues, and damage to property and infrastructure. Using surveillance videos to be analyzed by CNN models has been a common method for several applications. For example, Muhammad et al. [104] proposed a framework based on the CNN model that controls and detects fire occurrence. The authors used a transfer learning strategy, and the results they obtained demonstrated that the proposed framework was capable of detecting occurrences of fire with high accuracy while also reducing the number of false warnings. Moreover, Muhammad et al. [148] have developed an early fire detection framework based on fine-tuned CNN architecture. This framework controls the surveillance cameras and detects the fire occurrence for the indoor and outdoor environment. Experimental results showed 94% accuracy and a minimum 10% rate of false alarms. In [149], a method that exploits a CNN model, edge computing, and 5G network was proposed. The main purpose was to try and detect the occurrence of fire in video sequences captured during surveillance. The authors developed lightweight deep neural networks without an intensive presence of fully connected layers. The proposed method proved computationally inexpensive, with a high accuracy rate of 95.86% that decreased false alarms. 4.4.2. Accident prediction Due to the rapid increase in the number of vehicles within a city, the rate of traffic accidents has also increased, causing enormous damage and serious losses. Methods that can predict and/or decrease accidents thus become very valuable. Using camera surveillance videos with time-series data analytics, accident prediction can help to decrease the occurrence of these events and minimize damages. Various studies [95], [150] have proposed prediction traffic accident risk models based on LSTM. These models capture spatial and temporal patterns of traffic to be analyzed in order to warn people and provide advice on avoiding crowded areas. Using AE, Singh et al. [151] proposed an accident detection framework. The authors developed a denoising AE model, which was trained on the normal traffic sequences to detect the unusual vehicle state predicting an accident. The experimentation was conducted on real videos of accidents and the results demonstrated strong performance of the framework proposed. Table 8 provides a summary of smart surveillance related works. Table 8. A summary of smart surveillance related works. Use Case IoT Application Ref Input Data DL Model(s) Computing Infrastructure Smart surveillance Fire detection [104] Authors collect fire images and videos from benchmark datasets CNN Cloud computing [148] Authors collect a large dataset composed of 68,457 images from different fire datasets CNN Cloud computing [149] Authors develop a new dataset from BoWFire and other fire datasets, that consists of 30,776 fire and not fire images CNN Cloud computing Accident prediction [150] Authors use traffic accident records collected from Beijing describing the time and location of accidents LSTM Cloud computing [151] Authors create a dataset of accident videos collected from the surveillance network of Hyderabad City, India AE Cloud computing [95] US-Accidents dataset LSTM Cloud computing 4.5. Smart agriculture Several IoT applications are proposed to serve different requirements needed in agriculture, leading to the development of smart agriculture [152]. 4.5.1. Plant disease detection Smart controlling of plants aims to detect and diagnose diseases in their early stages with good precision, which helps to prevent the spread of these diseases [153]. Producing healthy crops to support the population is of immense interest to the development of a sustainable city environment. Plant disease recognition has been investigated in various literature, in recognition of diseases\u2019 impact on an entire crop. In [154], Ferentinos developed a system using CNN models for detecting plant diseases based on images of their leaves. In this work, the author used and tested five CNN models using a free dataset containing the images of 87,848 leaves from both healthy and diseased plants. Sladojevic et al. [155] developed a system for plant disease recognition. This system was also based on a CNN model that examined the input of images of leaves, which could distinguish among 13 types of diseased leaves from healthy ones with high accuracy. The proposed recognition model would help farmers to detect diseases that affect fruits, vegetables, or plants in a faster and more accurate way. Another approach is proposed in [156] to detect apple leaf diseases. This approach, which was based on a CNN model, is intended to identify four common types of diseases that afflict apple trees: Alternaria leaf spot, mosaic, rust, and brown spot. In this work, Liu et al. used a dataset that collects 13,689 images of diseased apple leaves to train and test their model. In another work [97] the authors developed a multi-layer CNN model to classify infected mango leaves according to the Anthracnose Fungal disease. They used a real-time dataset that includes images for both healthy and infected leaves, and their results demonstrated good classification accuracy. In [157], Bu et al. created an intelligent agriculture IoT system that improves the food production process. This system uses the DRL architecture, which is made up of four layers. The first layer is responsible for the collection of agriculture data from different embedded sensors. These data are processed first in the edge computing layer, which is the second layer. Then, they are transferred to the cloud layer to be analyzed. The third layer is the agriculture data transmission layer that connects edge computing and cloud computing layers. Using the DRL, agents are developed at the cloud and are learning from their environment to make smart decisions that have an important role to improve crop growth. 4.5.2. Smart counting Smart counting is another service provided by the smart agriculture use case [158]. Plants counting is usually inaccurate and time-consuming, but having an accurate fruit counts helps farmers make better decisions for harvesting, crop storage, packaging, and transportation. Hani et al. [93] worked on fruit detection and counting methods. For the detection, they utilized a semi-supervised clustering technique, and for counting they develop a CNN-based approach. The proposed method performed with 96%\u201398% accuracy. In addition, several research works have reported the employment of DL techniques to predict fruit counting in a smart manner [159], [160], [161]. All these works employ the CNN model. Table 9 summarizes the research on IoT applications developed to serve smart agriculture. Table 9. A summary of the smart agriculture related works. Use case IoT application Ref Input data DL model(s) Computing infrastructure Smart agriculture Plant disease detection [97] Authors use the Plant Village dataset for training and develop a real-time testing dataset that consists of 1070 images of healthy and infected mango leaves CNN Cloud computing [154] Plant Village dataset [155] Authors collect their input data that consist of many leaves\u2019 images from different available online datasets [156] Authors collect a dataset of 13,689 images of diseased apple leaves pictures, all taken in China [157] \u2013 DRL Edge computing Smart counting [93] Authors use the same dataset used in [159] CNN Cloud computing [159] Authors collect four datasets of apple images (green, orange, yellow, and red) CNN [160] Authors develop two images datasets: an apple dataset and an orange dataset FCN (Fully convolutional networks) [161] The input data consist of two image datasets of apples and oranges CNN Cloud computing 4.6. Smart environment In a smart city, providing a healthy environment for citizens is critical. Exploiting recent and advanced technologies to support the improvement of air quality, controlling pollution, and detecting garbage will help to ensure this kind of good environment for a city\u2019s inhabitants. 4.6.1. Air quality Air pollution is a dangerous problem that can cause serious health issues. Fighting this problem improves the quality of life and health. Developing accurate methods that have the ability to forecast air quality is often based on time-series data. By using RNN models, Zhao et al. in [162] reported a prediction method for air quality classification. The proposed model allowed them to memorize and analyze the sequential data, which includes the air quality data of each day in a defined period. The model was compared with two other ML approaches (support vector machine and random forest) and obtained better results than either of them. In [98], Athira et al. proposed a DL model for the prediction of air quality. For the evaluation, they applied three types of DL models (RNN, LSTM, and GRU) on the AirNet dataset that contains air quality data and meteorological features. The experimental results demonstrated that the GRU model provides the best performance values. In [163], an air quality forecasting system was proposed. This system combines three models: ANN, LSTM, and CNN. It aims to predict the air quality over a two-day time period. In order to do so, the layers of these three models are merged via side-by-side concatenation, and the extracted features are passed from one layer to the next. Using mobile data, Pan et al. [164] proposed an AirTick mobile application for crowd-sensing air quality. This application used images collected by phone cameras. In this work, the authors developed a deep neural network using DBM, which created an accurate estimation of air quality. Another important application for the smart environment is indoor air quality. The indoor air quality applications help to enhance the situation of buildings environments with respect to their occupants\u2019 health and comfort. Mutis et al. in [165] proposed a new DL based methodology for controlling the indoor air quality using the human motion and occupancy detection techniques. The developed system has the ability to count the occupants\u2019 number and estimate their activities in order to analyze and control their environmental situations. In order to control and improve the indoor climate, Markovic et al. [166] proposed a novel DL model for window opening in commercial buildings. This model is able to identify the offices\u2019 air temperature, human activity, and the opened and unopened windows. 4.6.2. Garbage detection Garbage detection is a very important requirement for smart cities, as it ensures a safe, enjoyable, and high-quality environment. Traditional manual methods require a good deal of time and effort, so smart methods are much in demand. CNN DL methods have demonstrated strong performance in analyzing the captured city area images, detecting the garbage distribution, and getting rid of this waste. In [167], Zeng et al. have presented a control method for the detection and the distribution of garbage in big areas using airborne hyperspectral data. The authors developed a multi-scale CNN that has the ability to classify data and create a garbage segmentation map. Also, Wang et al. [168] presented an autonomous and automatic garbage detection that improves the monitoring of the urban environment. They used the ResNet network algorithm as convolutional layers on the base of a faster R-CNN open-source framework. The experimental results show high accuracy for object and location detection. Using mobile edge computing, Zhang et al. [105] proposed a novel approach for urban street cleanliness. First, the street images were collected and extracted from vehicle cameras on edge servers, and then these data are transferred to the cloud to be analyzed. In this work, the authors developed a faster region CNN that is used to determine the different categories of garbage on the street and compute the total amount of this garbage. The street cleanliness level is determined using network outputs, which help city managers to distribute clean-up crews efficiently and effectively. In Table 10, we sum up the previously discussed works. Table 10. A summary of smart environment-related works. Use Case IoT application Ref Input data DL Model(s) Computing infrastructure Smart environment Air quality [162] Authors collect 2,191 observations of air quality based on U.S. EPA RNN Cloud computing [98] AirNet dataset GRU Cloud computing [163] Authors use Taiwan and Beijing datasets consisting of a large number of city images ANN+ LSTM+ CNN Cloud computing [164] Authors collect more than 1,000 images of the Singapore city environment DBN Cloud computing [165] NADA dataset CNN + LSTM Edge computing Garbage detection [105] Authors create a new garbage dataset, where they collect 681 street images from vehicle cameras CNN Edge computing [167] Authors construct a dataset named Shandong Suburb Garbage that consists of multiple high-resolution images CNN Cloud computing [168] Coco dataset R-CNN Cloud computing 5. Discussion To obtain added-value results from IoT big data analytics, it is first necessary to identify the problem and determine the type of analytics that should be conducted. Typically, the potential uses of DL in smart city applications can be classified into four different classes: recognition, detection, prediction, and optimization. \u2022 Recognition: to realize events, recognition applications are used. Such applications have been used in a wide range of IoT smart city applications and have demonstrated good performance using DL models. These applications use images and videos as input data, which are provided from both smart city surveillance cameras as well as mobile device cameras that are used by everyone. It is noticeable also that most research on agriculture and related works draws from images for classification or object detection purposes. Examples of related applications include detection of diseases in leaves, as well as fruit detection and counting [155], [156], [169]. The DL model used in these applications is CNN. \u2022 Detection: to categorize the big data gathered from IoT and differentiate objects, detection algorithms are the most used techniques. Object detection is defined as the technique of processing images and videos in order to discover states or classify detected objects. Some examples of detection scenarios include fall detection [129], [130] and fire detection [104], [149]. The CNN model is the most frequently used DL algorithm for detection, as this type of deep neural network can process big data with different data types and formats. \u2022 Prediction: to predict events and determine the adequate action to be taken, DL algorithms are used for the prediction/forecasting analytics. RNN and its variants are the most commonly used algorithms in forecasting. These models offer the best results in terms of performance since they could capture time dimension data, which CNN models cannot do. RNN also has the ability to memorize and analyze the sequential data such as air quality data of each day in a defined period and place [162]. Here, LSTM is the optimal and the most used prediction model since it is able to record temporal data over long intervals as well as remember or forget data as necessary using three gates. LTSM models are utilized in different application scenarios, such as traffic accident prediction [95], [150] and forecasting the amount of consumed energy for better management in smart homes [106], [121], [122], [123], [124], [125]. \u2022 Optimization: one of the most important advantages of applying DL in IoT applications is the optimization of smart city services by improving the processes, ensuring the system\u2019s efficiency, and identifying performance problems. DRL models are most often utilized to ensure this optimization, as this the most exploited. This type of model utilizes DL to ensure the policy optimization, combined with a reinforcement learning technique that allows agents to be self-learning without the need for human intervention. Table 11 classifies the various works previously presented, according to each one\u2019s DL model applied, the smart city\u2019s use case, the main objective, and the data analytics category. After reviewing these works, we identified the following trends regarding the use of DL models for smart city data analytics: Table 11. The use of DL models in IoT smart city use cases. DL model Ref Use case Main objective Data analytic category Empty Cell Empty Cell Empty Cell Empty Cell Image recognition Detection Prediction Optimization CNN [101], [108], [136] Healthcare Disease prediction \u2713 [102], [103] Healthcare Dietary assessment \u2713 [154], [155], [156] Agriculture Plant disease detection [94], [142], [144] Transportation Smart traffic and parking \u2713 [129], [134] Healthcare Elderly care [104], [149] Surveillance Fire detection [139], [141] Agriculture Smart counting [105], [167] Environment Garbage detection RNN [139] Transportation Smart traffic \u2713 [137] Healthcare Disease prediction [162] Environment Air quality LSTM [106], [121], [122], [123], [124], [125] Smart home Energy management \u2713 [95], [150] Surveillance Accident prediction [138] Transportation Smart traffic SAE [151] Surveillance Accident detection \u2713 DBN/ RBM [164] Environment Air quality \u2713 [80] Healthcare Elderly care \u2713 DRL [80] Healthcare Treatment regime prediction \u2713 [140] Transportation Smart traffic [157] Agriculture Plant disease detection \u2022 CNN models provide great performance for imaging applications, for both recognition and detection purposes. These models are the most used DL techniques and are utilized in all mentioned use cases of the smart city. \u2022 RNN models are suitable for prediction applications, and LSTM is the most used model because it is able to capture temporal correlations in time-series data, leading to high efficiency and accuracy. \u2022 RBM, DBN, and SAE are the least used DL models. They are used mostly for classification tasks to help detection or prediction applications, and they work best in the reduction of high-dimensional inputs and the detection of hierarchical features. \u2022 DRL has made great progress in the area of utilizing DL in smart city scenarios. This architecture could extract rich features and allow applications to learn from the environment using agents in the same way as humans do. 6. Usage of deep learning for smart cities: Challenges and open issues for future research 6.1. Challenges Developing a smart city ecosystem requires considering several new challenges. These challenges could be categorized into two perspectives, the technical and the business, as illustrated in Fig. 20. Download : Download high-res image (225KB) Download : Download full-size image Fig. 20. Challenges of employing DL for smart cities. 6.1.1. Technical challenges 6.1.1.1. Security and privacy. One of the main challenges facing different IoT applications related to smart cities is the problem of security. Recently, different types of threats to DL models have been detected. These threats affect these models\u2019 performance and decrease their accuracy, validity, and trustworthiness. One example of such threats is false data injection [170], which takes advantage of IoT devices and sensors in different places to send false measurements and data. False data injection aims to mislead the analytics process operations, leading to faulty results, advice, and predictions. In addition, privacy is also considered a major challenge related to the smart city ecosystem. In the context of IoT applications, sensors designed to capture data at every second are placed in different public locations. These data may contain pictures of persons, speeches, or behaviors, which will be moved to the fog or the cloud to be analyzed and processed. Sending sensitive data to the cloud introduces multiple privacy concerns (e.g., pictures of people whose faces or behaviors are taken in public places, patients\u2019 medical data, etc.). Moreover, loss of data may occur [171]. In addition, the collected data in the cloud/fog may be exploited by a third party who does not have the permission to use or even access these data [172]. Several works propose privacy-preserving algorithms in response to these issues. Nevertheless, even the proposed solutions remain vulnerable and can be hacked or damaged by powerful attacks [173]. Indeed, hackers can develop a DL algorithm that learns how other DL methods detect threats, then generates attacks that are difficult to detect. 6.1.1.2. IoT big data challenges. A huge volume of data is generated by different IoT devices, which imposes several difficulties concerning their storage, communication, elaboration, and analytics. Storing the generated data for the long term presents a serious challenge, since these data cannot be managed using traditional conventional database management tools. Special infrastructures are required to handle these big amounts of structured and unstructured data. In addition, the analytics of the IoT big data requires particular technologies to extract valuable insights and information. These requirements include high-performance processors, scalable cloud computing services, fog and edge paradigms, and software for big data analytics, such as Apache Hadoop, etc. Furthermore, big data creation raises the challenge of quick, quality analysis of these data [174], [175]. 6.1.1.3. Deep learning limitations. DL models have been applied in various smart city scenarios and have produced good results. In addition, DL applications have achieved high accuracy in classification and low rates of error for prediction in many scenarios. However, there are some situations in which these models cannot be adequate solutions. Several limitations should be considered: \u2022 DL models need large datasets in order to provide good results, especially supervised learning techniques where hundreds of images are required. \u2022 Considering large datasets makes the training process very complex, computationally expensive, and very time consuming [176]. \u2022 In some cases, before training the dataset, data preprocessing is necessary, especially for images with big dimensions (e.g., images collected from satellites). This preprocessing task is time-consuming and expensive to prepare. \u2022 Researchers suffer from the limited availability of datasets in several domains, especially those related to agriculture. In different cases and scenarios, researchers are obligated to develop their own datasets, which requires a great deal of time and effort. \u2022 Using DL models, effective solutions can be developed that work well with specific problems. However, they cannot be generalized for similar but not identical purposes; likewise, they cannot be generalized for use over and above the bounds of the initial dataset. For example, in [177], the model performs well in detecting and counting red tomatoes, but it fails to detect the green ones. \u2022 DL models function as black boxes with which the user sends input and takes output as a result, without knowing how the processes work [178]. Running as a black box may help improve the model results\u2019 accuracy with time, or it may prove a vulnerable point, especially in prediction applications where DL models learn from input data during training. In black box-like models, though, it can be difficult to ensure that training is done well, and in some scenarios, the models\u2019 results are not effective. For example, in [179], it was reported that for a military application, the model developed to detect enemy/friendly tanks demonstrated good accuracy with test images. However, after being deployed, it had poor accuracy when dealing with new images. It is discovered later that the enemy tanks images were taken on a cloudy day, while the friendly tanks were captured on a sunny day. As a result, the model had learned to differentiate based on the color of the sky on sunny and overcast days. 6.1.2. Business challenges 6.1.2.1. Planning. Planning is a crucial challenge facing the construction of a smart city and must be considered before starting [180]. A development plan must be prepared for each city based on the needs of its citizens, since this will help to avoid many problems and faults such as redundant services or uncoordinated transport networks. Good planning aids in the improvement of facilities and city services by identifying the areas that require enhancement and facilitating the integration of legacy systems within the new ecosystem. 6.1.2.2. Cost. One of the smart cities\u2019 characteristics is the interconnection among all constituent components [181]. However, this interconnection is considered costly for governments in some cases where several devices, sensors, actuators, and software must be deployed and implemented. For example, the installation of a smart surveillance system requires the use of new systems and devices to capture, collect, and analyze data. These requirements are expensive to implement. In addition, any error in the installation usually leads to high losses and affect city management negatively. Therefore, cost is a critical challenge that the development of smart cities faces today. 6.1.2.3. Quality of service. In order to establish a successful smart city ecosystem, the quality of service (QoS) of the provided applications is a critical characteristic that must be validated [182]. Different QoS metrics [183], [184] are employed to examine the applications/systems quality including response time, availability, scalability, and reliability. Several technologies are involved and integrated to develop smart city services, including cloud services, storing frameworks, and processing platforms. It is very important to ensure the quality of service provided by these required technologies, in order to ensure a flexible, powerful, and reliable smart city ecosystem [185]. 6.2. Actual and future trends 6.2.1. Ameliorations with transfer learning Transfer learning is a new paradigm of learning that learns from previous knowledge, and then transfers and employs this knowledge in order to address novel problems [186]. The main advantage of this type of learning is that the model training phase can be managed with minimum resources and in less time compared to multiple DL models that use traditional types of learning (supervised/unsupervised/reinforcement). Several research works investigate the use of DL models with transfer learning [107], [169], [187], [188], [189]. In the future, we expect more applications will use transfer learning in different smart city use cases. Several ameliorations are provided when using transfer learning: \u2022 Improvement of service performance: this is due to the acceleration of the learning process. A new task does not begin from scratch but starts from the collective knowledge gathered from previous tasks. \u2022 Reduction in effort and cost since the training of data is already gathered from multiple sources. \u2022 Enhancement of accuracy due to multi-task learning. \u2022 Support of real-time data analytics: smart cities services include several applications that need real-time analytics in order to guarantee the efficiency of their operations. These applications, also known as time-sensitive applications, include smart parking scenarios and elderly care applications. 6.2.2. Emergence of microservices in data analytics The technology of microservices [190], which is a variant of Web services technology [191], [192], enables the development of IoT applications using a collection of entities that are fine-grained, loosely coupled, and reusable. In fact, it is easy to change these entities or edit them in order to enhance the application\u2019s scalability, extensibility, and reuse. Therefore, creating a microservices-based framework that handles DL services can assist and enhance IoT big data analytics because it allows an integrated architecture that could process and analyze big data and provides powerful services for a wide range of IoT applications [193], [194]. Several ameliorations are provided by integrating microservices technology with DL-based analytics including: \u2022 The ability to enhance and increase the performance of DL applications especially the availability and the response time. \u2022 The dynamism of the developed DL systems is enhanced when system lunch and processing become quicker, reducing latency. \u2022 The modularity of applications where complex DL services are divided into simple, reusable microservices. \u2022 The easy reconfiguration of applications that are based on composed microservices, often by adding, updating, or deleting them. 6.2.3. Integration of mobile data, 5G, and 6G with IoT analytics Mobile devices are commonly considered cheap effective, and pervasive data collection platforms. Additionally, they are available everywhere, can capture daily activities of the end-user, and are supported by embedded communication sensors and detectors. Using this mobile data to be processed with DL approaches is considered an effective solution for enhancing smart city services [195]. For example, in [196], the authors investigated the use of DL models to analyze mobile data using Apache Spark. Due to the growing use of mobile data and its importance for analytics [197], [198], communication networks should be updated to support critical new issues. At present, research is moving forward into the fifth-generation (5G) to provide multifunctional, scalable, and flexible platforms that could address new problems with minimum cost and power. 5G is not just an extension of the fourth generation: it is also a new wireless network with new architecture that has the capacity to transport high rates of data, with low latency and great reliability [199]. The proposed network is developed using new radio access technologies and it is characterized by the high data speeds, which surpass the current 4G network 100x or more [200]. Integrating softwarization with this wireless network will make a lot of changes in terms of sensing, speed, and intelligence, which in turn creates new opportunities for IoT [201] and smart city development [202]. As a result, employing 5G in IoT infrastructures must be considered as new open research [203]. In order to make everything smart, research on 6G wireless networks has been carried to deal with the high demands resulted from fast-growing mobile data traffic [204]. A revolution in the design of 6G will be made to build up a novel technology with efficient energy and cost communications that can transform human life to be integrated into a smart world, not just a smart city. The analytics of IoT data will also benefit from the novel network, gaining new capabilities and eliminating several current limitations. 6.2.4. Blockchain for secure and distributed IoT systems Recently, blockchain technology has attracted the attention of researchers in different areas. Xie et al. [205] have defined the blockchain as \u201da sequence of blocks, which holds a complete list of transaction records like conventional public ledger\u201d. Blockchain was introduced to support the implementation of security strategies, but it has found uses in many other fields and areas of application as well. To enhance the security of IoT applications, the idea of adopting blockchain with IoT applications was proposed [206]. For smart cities, blockchain helps to build a protected environment for their applications by adopting decentralized architectures [207]. Blockchain smart contracts are promising and beneficial technologies that can be used to manage processes between service providers and users [208]. 6.2.5. Dependable and scalable IoT analytics Dependability involves the reliability, availability, and maintainability of the provided service/system/application. Efficient means of ensuring the safety of smart city applications are required, as are systems capable detecting malicious attacks and failures is needed necessary. The collected log traces of IoT smart city applications can be analyzed and processed using DL approaches to extract and identify the main weaknesses of these applications. Then, the recovery process and avoidance of these failures will be assured to enhance the dependability of these systems. In order to face the challenges of massive data collected from the unlimited number of the interacting objects, IoT architecture must be able to be scaled up when necessary to support the demand of smart city applications [209]. The scalability management should consider two critical issues: enhancing the current protocols to deal well with the new IoT challenges/requirements and accounting for the social relationships that relate devices to their holders, especially for wearable smart devices. Enabling streamlined interactions between users and smart devices is a significant need for IoT applications, since humans are the first beneficiaries and play a principal role in a smart city ecosystem [210]. 6.2.6. Ensuring data quality and integrity with spatiotemporal dependencies In smart city applications, billions of smart devices are installed. It is reported that the number of IoT devices used in 2019 is about 26.66 billion, and this number is forecasted to exceed 41.6 billion by 2025 [211]. These smart devices generate trillions of gigabytes of data that will surpass 79.4 zettabytes of data by 2050. To deal with these tremendous amounts of data, standards and technologies must be updated in order to manage it and to ensure its integrity. In addition, different infrastructures must become more scalable and flexible, gaining the ability to categorize data rapidly and utilize only high-quality versions [212]. Bearing in mind the dependencies of the collected data, including the spatiotemporal aspect, is very important during the data analytics process. Excluding such information may lead to wrong decisions or predictions. Therefore, accurate analysis of spatiotemporal data coming from IoT smart city is very important, especially for mobile traffic scenarios where event location and device localization are essential [213]. 7. Conclusion DL and IoT have gained considerable traction across various research domains, and understandably, these two cutting-edge technologies have the potential for great impact on people\u2019s lifestyles, cities, and the world in general. The development of smart cities is just one of the many fields where such technologies have been employed to great effect, as we have demonstrated with our survey of several recent studies. The main aim of our work here has been to review the combination of DL and IoT big data analytics in the development and improvement of smart cities. In this survey, we defined IoT technology and described the computing infrastructure used by IoT data analytics, including cloud, fog, and edge computing. Then, we surveyed popular DL architectures and their uses, benefits, and drawbacks. We focused on presenting the most important open-source platforms developed to support DL researches, and we drew up comparisons among them, as well as among the most commonly used DL datasets. After that, we investigated the use of DL technologies in various smart city applications, including home, healthcare, transportation, surveillance, agriculture, and environment. Finally, we concluded by highlighting critical challenges and open issues that the use of DL for developing IoT smart city applications often faces. We anticipate that this work will provide a starting point for other researchers seeking a sense of the work completed in their subfield of smart city development research. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. References [1] United Nation 68% of the world population projected to live in urban areas by 2050 (2018) https://www.un.org/development/desa/en/news/population/2018-revision-of-world-urbanization-prospects.html. (Accessed 6 March 2020) Google Scholar [2] Abaker I., Hashem T., Chang V., Anuar N.B., Adewole K., Yaqoob I., Gani A., Ahmed E., Chiroma H. The role of big data in smart city Int. J. Inf. Manage., 36 (2016), pp. 748-758 https://www.sciencedirect.com/science/article/pii/S0268401216302778. (Accessed 11 February 2020) Google Scholar [3] Statista Smart city initiatives: global spending 2023 (2020) https://www.statista.com/. (Accessed 18 April 2020) Google Scholar [4] Al-Fuqaha A., Guizani M., Mohammadi M., Aledhari M., Ayyash M. Internet of Things: A survey on enabling technologies, protocols, and applications IEEE Commun. Surv. Tutor., 17 (2015), pp. 2347-2376, 10.1109/COMST.2015.2444095 View in ScopusGoogle Scholar [5] Frank R. Understanding smart sensors (2013) https://books.google.com/books?hl=en&lr=&id=v4G9jKBCghMC&oi=fnd&pg=PR7&dq=smart+sensors&ots=fgKTgqIkkh&sig=Ig_DQQntA-e6GayPdI8g4PuWlJE. (Accessed 2 February 2020) Google Scholar [6] Chen M., Mao S., Zhang Y., Leung V.C.M. Big data: related technologies, challenges and future prospects (2014) http://www.springer.com/series/10028. (Accessed 2 February 2020) Google Scholar [7] Hwang K., Chen M. Big-data analytics for cloud, IoT and cognitive computing (2017) https://books.google.com/books?hl=en&lr=&id=Kz1GDgAAQBAJ&oi=fnd&pg=PT10&dq=Big-data+analytics+for+cloud,+IoT+and+cognitive+computing&ots=b_GbM4vzm3&sig=NvT2WrTURAUuS8SCwHIx8P2Rk1k. (Accessed 1 February 2020) Google Scholar [8] Marjani M., Nasaruddin F., Gani A., Karim A., Hashem I.A.T., Siddiqa A., Yaqoob I. Big IoT data analytics: Architecture, opportunities, and open research challenges IEEE Access, 5 (2017), pp. 5247-5261, 10.1109/ACCESS.2017.2689040 View in ScopusGoogle Scholar [9] Yassine A., Singh S., Hossain M.S., Muhammad G. IoT Big data analytics for smart homes with fog and cloud computing Future Gener. Comput. Syst., 91 (2019), pp. 563-573, 10.1016/j.future.2018.08.040 View PDFView articleView in ScopusGoogle Scholar [10] Boulila W. A top-down approach for semantic segmentation of big remote sensing images Earth Sci. Inf., 12 (2019), pp. 295-306, 10.1007/s12145-018-00376-7 View in ScopusGoogle Scholar [11] Bengio Y., Goodfellow I., Courville A. Deep Learning (2015) Google Scholar [12] M. Mohammadi G., Al-Fuqaha A. Enabling cognitive smart cities using big data and machine learning: Approaches and challenges IEEE Commun. Mag., 56 (2018), pp. 94-101 http://www.havenondemand.com. (Accessed 2 February 2020) Google Scholar [13] Rathore M.M., Paul A., Ahmad A., Rho S. Urban planning and building smart cities based on the internet of things using big data analytics Comput. Netw., 101 (2016), pp. 63-80, 10.1016/j.comnet.2015.12.023 View PDFView articleView in ScopusGoogle Scholar [14] Khatoun R., Zeadally S. Smart cities: concepts, architectures, research opportunities Commun. ACM, 59 (2016), pp. 46-57, 10.1145/2858789 View in ScopusGoogle Scholar [15] Mohammadi M., Al-Fuqaha A., Sorour S., Guizani M. Deep learning for IoT big data and streaming analytics: A survey IEEE Commun. Surv. Tutor., 20 (2018), pp. 2923-2960 http://arxiv.org/abs/1712.04301 CrossRefView in ScopusGoogle Scholar [16] Mahdavinejad M.S., Rezvan M., Barekatain M., Adibi P., Barnaghi P., Sheth A.P. Machine learning for internet of things data analysis: A survey Digit. Commun. Netw., 4 (2018), pp. 161-175 https://www.sciencedirect.com/science/article/pii/S235286481730247X. (Accessed 1 February 2020) View PDFView articleView in ScopusGoogle Scholar [17] Zhang C., Patras P., Haddadi H. Deep learning in mobile and wireless networking: A survey IEEE Commun. Surv. Tutor. (2018) http://arxiv.org/abs/1803.04311 Google Scholar [18] Zhang Q., Yang L.T., Chen Z., Li P. A survey on deep learning for big data Inf. Fusion, 42 (2018), pp. 146-157, 10.1016/j.inffus.2017.10.006 View PDFView articleGoogle Scholar [19] Qolomany B., Al-Fuqaha A., Gupta A., Benhaddou D., Alwajidi S., Qadir J., Fong A.C. Leveraging machine learning and big data for smart buildings: A comprehensive survey IEEE Access, 7 (2019), pp. 90316-90356 https://ieeexplore.ieee.org/abstract/document/8754678/. (Accessed 1 February 2020) CrossRefView in ScopusGoogle Scholar [20] Chen Q., Wang W., Wu F., De S., Wang R., Zhang B., Huang X. A survey on an emerging area: Deep learning for smart city data IEEE Trans. Emerg. Top. Comput. Intell., 3 (2019), pp. 392-410 https://ieeexplore.ieee.org/abstract/document/8704334/. (Accessed 21 February 2020) CrossRefView in ScopusGoogle Scholar [21] Whitmore A., Agarwal A., da Xu L. The internet of things\u2014A survey of topics and trends Inf. Syst. Front., 17 (2015), pp. 261-274, 10.1007/s10796-014-9489-2 View in ScopusGoogle Scholar [22] Gubbi J., Buyya R., Marusic S., Palaniswami M. Internet of things (IoT): A vision, architectural elements, and future directions Future Gener. Comput. Syst., 29 (2013), pp. 1645-1660, 10.1016/j.future.2013.01.010 View PDFView articleView in ScopusGoogle Scholar [23] Mukhopadhyay S. Wearable sensors for human activity monitoring: A review IEEE Sensors J., 15 (2015), pp. 1321-1330, 10.1109/JSEN.2015.2475626 View in ScopusGoogle Scholar [24] Ahmed E., Yaqoob I., Hashem I.A.T., Khan I., Ahmed A.I.A., Imran M., v. Vasilakos A. The role of big data analytics in Internet of Things Comput. Netw., 129 (2017), 10.1016/j.comnet.2017.06.013 Google Scholar [25] Types of analytics: descriptive, predictive, prescriptive analytics (2020) https://www.dezyre.com/article/types-of-analytics-descriptive-predictive-prescriptive-analytics/209. (Accessed 1 February 2020) Google Scholar [26] Ahmed E., Yaqoob I., Abaker I., Hashem T., Khan I., Ibrahim A., Ahmed A., Imran M., v Vasilakos A., Ibrahim A.-M. The role of big data analytics in Internet of Things Comput. Netw. (2017), pp. 459-471, 10.1016/j.comnet.2017.06.013 View PDFView articleView in ScopusGoogle Scholar [27] Abbasi A., Li W., Benjamin V., Hu S., Chen H. Descriptive analytics: Examining expert hackers in web forums 2014 IEEE Joint Intelligence and Security Informatics Conference (2014), pp. 56-63, 10.1109/JISIC.2014.18 View in ScopusGoogle Scholar [28] Waller M.A., Fawcett S.E. Data science, predictive analytics, and big data: A revolution that will transform supply chain design and management, data science (2013), pp. 77-84 http://www-01.ibm.com/software/data/bigdata/ CrossRefView in ScopusGoogle Scholar [29] Bertsimas D., Kallus N. From predictive to prescriptive analytics Manage. Sci. (2019), 10.1287/mnsc.2018.3253 Google Scholar [30] Boulila W., Farah I.R., Hussain A. A novel decision support system for the interpretation of remote sensing big data Earth Sci. Inform., 11 (2018), pp. 31-45, 10.1007/s12145-017-0313-7 View in ScopusGoogle Scholar [31] Boulila W., Chebbi I., Farah I.R. Big data: Concepts, challenges and applications Computational Collective Intelligence, Springer (2015), pp. 638-647, 10.1007/978-3-319-24306-1_62 Google Scholar [32] Chebbi I., Boulila W., Mellouli N., Lamolle M., Farah I.R. A comparison of big remote sensing data processing with hadoop mapreduce and spark 2018 4th International Conference on Advanced Technologies for Signal and Image Processing (ATSIP) (2018), pp. 1-4, 10.1109/ATSIP.2018.8364497 View in ScopusGoogle Scholar [33] Singh D., Reddy C.K. A survey on platforms for big data analytics J. Big Data, 2 (2015), 10.1186/s40537-014-0008-6 Google Scholar [34] Ali A.H., Abdullah M.Z. A survey on vertical and horizontal scaling platforms for big data analytics Int. J. Integr. Eng., 11 (2019), pp. 138-150, 10.30880/ijie.2019.11.06.015 View in ScopusGoogle Scholar [35] Stergiou C., Psannis K.E., Kim B.-G., Gupta B. Secure integration of Internet-of-Things and cloud computing Future Gener. Comput. Syst., 78 (2018), pp. 964-975, 10.1016/j.future.2016.11.031 View PDFView articleView in ScopusGoogle Scholar [36] Botta A., de Donato W., Persico V., Pescap\u00e9 A. Integration of cloud computing and Internet of Things: A survey Future Gener. Comput. Syst., 56 (2016), pp. 684-700, 10.1016/j.future.2015.09.021 View PDFView articleView in ScopusGoogle Scholar [37] Kumar R., Goyal R. On cloud security requirements, threats, vulnerabilities and countermeasures: A survey Comput. Sci. Rev., 33 (2019), pp. 1-48, 10.1016/j.cosrev.2019.05.002 View PDFView articleGoogle Scholar [38] Chen J., Ran X. Deep learning with edge computing: A review Proc. IEEE, 107 (2019), pp. 1655-1674, 10.1109/jproc.2019.2921977 View in ScopusGoogle Scholar [39] Mukherjee M., Shu L., Wang D. Survey of fog computing: Fundamental, network applications, and research challenges IEEE Commun. Surv. Tutor., 20 (2018), pp. 1826-1857 https://ieeexplore.ieee.org/abstract/document/8314121/. (Accessed 1 February 2020) CrossRefView in ScopusGoogle Scholar [40] Bonomi F., Milito R., Zhu J., Addepalli S. Fog computing and its role in the Internet of Things Proceedings of the First Edition of the MCC Workshop on Mobile Cloud Computing (2012), pp. 13-16, 10.1145/2342509.2342513 Google Scholar [41] Bonomi F., Milito R., Natarajan P., Zhu J. Fog computing: A platform for internet of things and analytics Stud. Comput. Intell., 546 (2014), pp. 169-186, 10.1007/978-3-319-05029-4_7 View in ScopusGoogle Scholar [42] Vaquero L.M., Rodero-Merino L. Finding your way in the fog: Towards a comprehensive definition of fog computing Comput. Commun. Rev. Assoc. Comput. Mach. (2014), pp. 27-32, 10.1145/2677046.2677052 View in ScopusGoogle Scholar [43] Yu W., Liang F., He X., Hatcher W.G., Lu C., Lin J., Yang X. A survey on the edge computing for the Internet of Things IEEE Access, 6 (2017), pp. 6900-6919 https://ieeexplore.ieee.org/abstract/document/8123913/. (Accessed 1 February 2020) View in ScopusGoogle Scholar [44] Wang X., Han Y., Leung V.C.M., Niyato D., Yan X., Chen X. Convergence of edge computing and deep learning: A comprehensive survey (2020), 10.1109/COMST.2020.2970550 Google Scholar [45] Shi W., Cao J., Zhang Q., Li Y., Xu L. Edge computing: Vision and challenges IEEE Internet Things J., 3 (2016), 10.1109/JIOT.2016.2579198 Google Scholar [46] Qiu J., Wu Q., Ding G., Xu Y., Feng S. A survey of machine learning for big data processing Eurasip J. Adv. Signal Process. (2016), 10.1186/s13634-016-0355-x Google Scholar [47] Mitchell R., Michalski J., Carbonell T. An artificial intelligence approach (2013) https://link.springer.com/content/pdf/10.1007/978-3-662-12405-5.pdf. (Accessed 2 February 2020) Google Scholar [48] LeCun Y., Bengio Y., Hinton G. Deep learning Nature (2015), pp. 436-444, 10.1038/nature14539 View in ScopusGoogle Scholar [49] Chen X.-W., Lin X. Big data deep learning: challenges and perspectives IEEE Access, 2 (2014), pp. 514-525 https://ieeexplore.ieee.org/abstract/document/6817512/. (Accessed 2 February 2020) View in ScopusGoogle Scholar [50] Shokri R., Shmatikov V. Privacy-preserving deep learning Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security (2015), pp. 1310-1321, 10.1145/2810103.2813687 View in ScopusGoogle Scholar [51] Li H., Ota K., Dong M. Learning IoT in edge: Deep learning for the internet of things with edge computing IEEE Netw., 32 (2018), pp. 96-101, 10.1109/MNET.2018.1700202 Google Scholar [52] Brynjolfsson E., Mcafee A. The business of artificial intelligence Harvard Bus. Rev. (2017), pp. 1-20 https://hbr.org/cover-story/2017/07/the-business-of-artificial-intelligence. (Accessed 17 April 2020) Google Scholar [53] James G., Witten D., Hastie T., Tibshirani R. Unsupervised Learning (2013), pp. 373-418, 10.1007/978-1-4614-7138-7_10 Google Scholar [54] Hastie T., Tibshirani R., learning J.F. Unsupervised learning Elements Stat. Learn. (2009), pp. 485-585 https://link.springer.com/content/pdf/10.1007/978-0-387-84858-7_14.pdf. (Accessed 1 February 2020) CrossRefGoogle Scholar [55] Kingma D.P., Rezende D.J., Mohamed S., Welling M. Semi-supervised learning with deep generative models Advances in Neural Information Processing Systems (2014), pp. 3581-3589 http://arxiv.org/abs/1406.5298. (Accessed February 15, 2020) View in ScopusGoogle Scholar [56] van Hasselt H., Guez A., Silver D. Deep reinforcement learning with double q-learning (2016) www.aaai.org (Accessed 1 February 2020) Google Scholar [57] van Hasselt H., Guez A., Silver D. Deep reinforcement learning with double q-learning Thirtieth AAAI Conference on Artificial Intelligence (2016) www.aaai.org (Accessed 3 February 2020) Google Scholar [58] Deng L. A tutorial survey of architectures, algorithms, and applications for deep learning APSIPA Trans. Signal Inf. Process., 3 (2014), 10.1017/ATSIP.2013.99 Google Scholar [59] Al-Sarem M., Boulila W., Al-Harby M., Qadir J., Alsaeedi A. Deep learning-based rumor detection on microblogging platforms: A systematic review IEEE Access, 7 (2019), pp. 152788-152812 https://ieeexplore.ieee.org/abstract/document/8871102/. (Accessed 17 April 2020) CrossRefView in ScopusGoogle Scholar [60] Gu J., Wang Z., Kuen J., Ma L., Shahroudy A., Shuai B., Liu T., Wang X., Wang L., Wang G., Cai J., Chen T. Recent advances in convolutional neural networks Pattern Recognit. (2018), pp. 354-377 https://www.sciencedirect.com/science/article/pii/S0031320317304120. (Accessed 5 March 2020) View PDFView articleView in ScopusGoogle Scholar [61] Ca H.L., Mandel M., Pascanu R., Bengio Y., Ca B.U. Learning Algorithms for the Classification Restricted Boltzmann Machine Hugo Larochelle (2012) Google Scholar [62] il Suk H., Lee S.W., Shen D. Latent feature representation with stacked auto-encoder for AD/MCI diagnosis Brain Struct. Funct., 220 (2015), pp. 841-859, 10.1007/s00429-013-0687-3 Google Scholar [63] Gu J., Wang Z., Kuen J., Ma L., Shahroudy A., Shuai B., Liu T., Wang X., Wang L., Wang G., Cai J., Chen T. Recent advances in convolutional neural networks Pattern Recognit., 77 (2018), pp. 354-377 View PDFView articleView in ScopusGoogle Scholar [64] Goodfellow I., Bengio Y., Courville A. Deep Learning MIT Press (2016) Google Scholar [65] Werbos P.J. Backpropagation through time: what it does and how to do it Proc. IEEE., 78 (1990), pp. 1550-1560 https://ieeexplore.ieee.org/abstract/document/58337/. (Accessed 3 April 2020) View in ScopusGoogle Scholar [66] Hochreiter S. The vanishing gradient problem during learning recurrent neural nets and problem solutions Int. J. Uncertain. Fuzz. Knowl.-Based Syst., 6 (1998), pp. 107-116, 10.1142/S0218488598000094 View in ScopusGoogle Scholar [67] Cummins F., Gers F.A., Urgen Schmidhuber J.J. Learning to forget: Continual prediction with LSTM (1999), 10.1162/089976600300015015 Google Scholar [68] Olah C. Understanding LSTM networks (2015) https://colah.github.io/posts/2015-08-Understanding-LSTMs/. (Accessed 4 February 2020) Google Scholar [69] Hinton G.E., Osindero S., Teh Y.W. A fast learning algorithm for deep belief nets Neural Comput., 18 (2006), pp. 1527-1554, 10.1162/neco.2006.18.7.1527 View in ScopusGoogle Scholar [70] Bengio Y., Lamblin P., Popovici D., Larochelle H. Greedy layer-wise training of deep networks Adv. Neural Inf. Process. Syst. (2007), pp. 153-160 CrossRefView in ScopusGoogle Scholar [71] Hinton G.E. A practical guide to training restricted Boltzmann machines Neural Networks: Tricks of the Trade (2012), pp. 599-619, 10.1007/978-3-642-35289-8_32 View in ScopusGoogle Scholar [72] le Roux N., Bengio Y. Representational power of restricted boltzmann machines and deep belief networks Neural Comput., 20 (2008), pp. 1631-1649, 10.1162/neco.2008.04-07-510 View in ScopusGoogle Scholar [73] Goodfellow I.J., Pouget-Abadie J., Mirza M., Xu B., Warde-Farley D., Ozair S., Courville A., Bengio Y. Generative adversarial nets Advances in Neural Information Processing Systems (2014), pp. 2672-2680 http://www.github.com/goodfeli/adversarial. (Accessed 5 February 2020) Google Scholar [74] B. Dai, S. Fidler, R. Urtasun, D. Lin, Towards diverse and natural image descriptions via a conditional GAN, in: IEEE International Conference on Computer Vision, 2017, pp. 2970\u20132979. Google Scholar [75] C. Ledig, L. Theis, F. Husz\u00e1r, J. Caballero, A. Cunningham, A. Acosta, A. Aitken, A. Tejani, J. Totz, Z. Wang, W. Shi Twitter, Photo-realistic single image super-resolution using a generative adversarial network, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 4681\u20134690. Google Scholar [76] Y. Li, S. Liu, J. Yang, M.-H. Yang, Generative face completion, in: IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 3911\u20133919. Google Scholar [77] J. Li, X. Liang, Y. Wei, T. Xu, J. Feng, S. Yan, Perceptual generative adversarial networks for small object detection, in: IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 1222\u20131230. Google Scholar [78] Arulkumaran K., Deisenroth M.P., Brundage M., Bharath A.A. Deep reinforcement learning: A brief survey IEEE Signal Process. Mag., 34 (2017), pp. 26-38, 10.1109/MSP.2017.2743240 View in ScopusGoogle Scholar [79] Zhao L., Wang J., Liu J. Routing for crowd management in smart cities: A deep reinforcement learning perspective IEEE Commun. Mag., 4 (2019), pp. 88-93 https://ieeexplore.ieee.org/abstract/document/8703471/. (Accessed 5 February 2020) CrossRefView in ScopusGoogle Scholar [80] Liu Y., Logan B., Liu N., Xu Z. Deep reinforcement learning for dynamic treatment regimes on medical registry data 2017 IEEE International Conference on Healthcare Informatics (ICHI) (2017), pp. 380-385 https://ieeexplore.ieee.org/abstract/document/8031178/. (Accessed 5 February 2020) View in ScopusGoogle Scholar [81] Nguyen G., et al. Machine learning and deep learning frameworks and libraries for large-scale data mining: a survey Artifi. Intell. Rev., 52 (2019), pp. 77-124, 10.1007/s10462-018-09679-z View in ScopusGoogle Scholar [82] Abadi M., Agarwal A., Barham P., Brevdo E., Chen Z., Citro C., Corrado G.S., Davis A., Dean J., Devin M., Ghemawat S., Goodfellow I., Harp A., Irving G., Isard M., Jia Y., Jozefowicz R., Kaiser L., Kudlur M., Levenberg J., Man\u00e9 D., Monga R., Moore S., Murray D., Olah C., Schuster M., Shlens J., Steiner B., Sutskever I., Talwar K., Tucker P., Vanhoucke V., Vasudevan V., Vi\u00e9gas F., Vinyals O., Warden P., Wattenberg M., Wicke M., Yu Y., Zheng X., Research G. Tensorflow: Large-scale machine learning on heterogeneous distributed systems (2016) Arxiv.Org. www.tensorflow.org. (Accessed 2 March 2020) Google Scholar [83] Collobert R., Kavukcuoglu K., Farabet C. Torch7: A matlab-like environment for machine learning BigLearn, NIPS Workshop (2011) http://numpy.scipy.org. (Accessed 2 March 2020) Google Scholar [84] Bastien F., Lamblin P., Pascanu R., Bergstra J., Goodfellow I., Bergeron A., Bouchard N., Warde-Farley D., Bengio Y. Theano: new features and speed improvements (2012) ArXiv Preprint arXiv:1211.5590, (Accessed 2 March 2020) Google Scholar [85] Jia Y., Shelhamer E., Donahue J., Karayev S., Long J., Girshick R., Guadarrama S., Darrell T. Caffe: Convolutional architecture for fast feature embedding MM 2014 - Proceedings of the 2014 ACM Conference on Multimedia, Association for Computing Machinery, Inc (2014), pp. 675-678, 10.1145/2647868.2654889 Google Scholar [86] Chollet F. Keras (2015) https://github.com/keras-team/keras. (Accessed 18 April 2020) Google Scholar [87] Vedaldi A., Lenc K. Matconvnet: Convolutional neural networks for MATLAB MM 2015 - Proceedings of the 2015 ACM Multimedia Conference, Association for Computing Machinery, Inc (2015), pp. 689-692, 10.1145/2733373.2807412 View in ScopusGoogle Scholar [88] Deeplearning4j, (n.d.). https://deeplearning4j.org/. (Accessed 18 April 2020). Google Scholar [89] MXNet (2020) https://mxnet.apache.org/. (Accessed 18 April 2020) Google Scholar [90] Tokui S., Oono K., Hido S., Clayton J. Chainer: a next-generation open source framework for deep learning Proceedings of Workshop on Machine Learning Systems (LearningSys) in the Twenty-Ninth Annual Conference on Neural Information Processing Systems (NIPS) (2015), pp. 1-6 http://learningsys.org/papers/LearningSys_2015_paper_33.pdf. (Accessed 21 April 2020) Google Scholar [91] Chainer: A flexible framework for neural networks (2020) https://chainer.org/. (Accessed 21 April 2020) Google Scholar [92] Piatetsky Gregory Python leads the 11 top data science, machine learning platforms: Trends and analysis (2020) https://www.kdnuggets.com/2019/05/poll-top-data-science-machine-learning-platforms.html. (Accessed 26 April 2020) Google Scholar [93] H\u00e4ni N., Roy P., Isler V. A comparative study of fruit detection and counting methods for yield mapping in apple orchards J. Field Robot. (2019) https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21902. (Accessed 18 February 2020) Google Scholar [94] Yang Cai B., Alvarez R., Sit M., Duarte F., Ratti C. Deep learning-based video system for accurate and real-time parking measurement IEEE Internet of Things J. (2019), pp. 7693-7701 https://qcode.us/codes/. (Accessed 17 February 2020) Google Scholar [95] Moosavi S., Samavatian M.H., Parthasarathy S., Teodorescu R., Ramnath R. Accident risk prediction based on heterogeneous sparse data: New dataset and insights The 27th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM (2019), pp. 33-42, 10.1145/3347146.3359078 View in ScopusGoogle Scholar [96] Torti E., Fontanella A., Musci M., Blago N., Pau D., Leporati F., Piastra M. Embedded real-time fall detection with deep learning on wearable devices 2018 21st Euromicro Conference on Digital System Design (DSD) (2018), pp. 405-412, 10.1109/DSD.2018.00075 View in ScopusGoogle Scholar [97] Singh U., Chouhan S., Jain S., Access S.J.-I., undefined D. Multilayer convolution neural network for the classification of mango leaves infected by anthracnose disease IEEE Access, 7 (2019) (2019), pp. 43721-43729 https://ieeexplore.ieee.org/abstract/document/8675730/. (Accessed February 18, 2020) CrossRefView in ScopusGoogle Scholar [98] Athira V., Geetha P., science R.V. Deepairnet: Applying recurrent networks for air quality prediction Procedia Comput. Sci. (2018), pp. 1394-1403 https://www.sciencedirect.com/science/article/pii/S1877050918308007. (Accessed 5 February 2020) View in ScopusGoogle Scholar [99] Lane N.D., Bhattacharya S., Georgiev P., Forlivesi C., Kawsar F. An early resource characterization of deep learning on wearables, smartphones and internet-of-things devices Proceedings of the 2015 International Workshop on Internet of Things Towards Applications, Association for Computing Machinery, Inc (2015), pp. 7-12, 10.1145/2820975.2820980 View in ScopusGoogle Scholar [100] Maragatham G., Devi S. LSTM Model for prediction of heart failure in big data J. Med. Syst., 43 (2019), 10.1007/s10916-019-1243-3 Google Scholar [101] .C. R P., Roberto Pereira D., Paulo Papa J., de Rosa G.H., Pereira C.R., Pereira D.R., Papa J.P., Rosa G.H., Yang X.-S. Convolutional neural networks applied for parkinson\u2019s disease identification Mach. Learn. Health Inf. (2016), pp. 377-390, 10.1007/978-3-319-50478-0_19 Google Scholar [102] Liu C., Cao Y., Luo Y., Chen G., Vokkarane V., Yunsheng M., Chen S., Hou P. A new deep learning-based food recognition system for dietary assessment on an edge computing service infrastructure IEEE Trans. Serv. Comput., 11 (2017), pp. 249-261 https://ieeexplore.ieee.org/abstract/document/7837725/. (Accessed 5 February 2020) Google Scholar [103] Liu C., Cao Y., Luo Y., Chen G., Vokkarane V., Ma Y. Deepfood: Deep learning-based food image recognition for computer-aided dietary assessment International Conference on Smart Homes and Health Telematics, Springer Verlag (2016), pp. 37-48, 10.1007/978-3-319-39601-9_4 View in ScopusGoogle Scholar [104] Muhammad K., Ahmad J., Mehmood I., Seungmin R., Sung W.B. Convolutional neural networks based fire detection in surveillance videos IEEE Access (2018), pp. 18174-18183 https://ieeexplore.ieee.org/abstract/document8307064/. (Accessed 5 February 2020) CrossRefView in ScopusGoogle Scholar [105] Zhang P., Zhao Q., Gao J., Li W. Urban street cleanliness assessment using mobile edge computing and deep learning IEEE Access (2019), pp. 63550-63563 https://ieeexplore.ieee.org/abstract/document/8704340/. (Accessed 5 February 2020) CrossRefView in ScopusGoogle Scholar [106] Yan K., Li W., Ji Z., Qi M., Du Y. A hybrid LSTM neural network for energy consumption forecasting of individual households IEEE Access (2019), pp. 157633-157642 https://ieeexplore.ieee.org/abstract/document/8880605/. (Accessed 5 February 2020) CrossRefView in ScopusGoogle Scholar [107] Cisek D., Mahajan M., Dale J., Pepper S., Lin Y., Yoo S. A transfer learning approach to parking lot classification in aerial imagery 2017 New York Scientific Data Summit, NYSDS (2017), pp. 1-5 https://ieeexplore.ieee.org/abstract/document/8085049/. (Accessed 3 February 2020) CrossRefGoogle Scholar [108] Shi B., Grimm L., Mazurowski M. Prediction of occult invasive disease in ductal carcinoma in situ using deep learning features J. Am. Coll. Radiol. (2018), pp. 527-534 https://www.sciencedirect.com/science/article/pii/S1546144017316010. (Accessed 5 February 2020) View PDFView articleView in ScopusGoogle Scholar [109] UCI Machine Learning Repository, Individual household electric power consumption Data Set, n.d. https://archive.ics.uci.edu/ml/datasets/individual+household+electric+power+consumption. (Accessed 22 April 2020). Google Scholar [110] Kelly J., Knottenbelt W. The UK-DALE dataset domestic appliance-level electricity demand and whole-house demand from five UK homes Sci. Data, 2 (2015), pp. 1-14, 10.1038/sdata.2015.7 Google Scholar [111] Sucerquia A., L\u00f3pez J.D., Vargas-Bonilla J.F. SisFall: A fall and movement dataset Sensors, 17 (2017), 10.3390/s17010198 Google Scholar [112] Michal K\u0119pski, UR fall detection dataset, n.d. http://fenix.univ.rzeszow.pl/ mkepski/ds/uf.html. (Accessed 22 April 2020). Google Scholar [113] A. Shahroudy, J. Liu, T.-T. Ng, G. Wang, NTU RGB+D: A large scale dataset for 3d human activity analysis, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, n.d., pp. 1010\u20131019. Google Scholar [114] HandPD dataset, n.d. http://wwwp.fc.unesp.br/ papa/pub/datasets/Handpd/. (Accessed 23 April 2020). Google Scholar [115] Taxi Service Trajectory dataset, n.d. http://www.geolink.pt/ecmlpkdd2015-challenge/dataset.html. (Accessed 23 April 2020). Google Scholar [116] CNRPark+EXT dataset, n.d. http://cnrpark.it/. (Accessed 22 April 2020). Google Scholar [117] Almeida P., Oliveira L.S., Britto A.S., Silva E.J., Koerich A. PKLot-A robust dataset for parking lot classication Expert Syst. Appl., 42 (2015), pp. 4937-4949 http://web.inf.ufpr.br/vri/parking-lot-database. (Accessed 22 April 2020) Google Scholar [118] Moosavi S., Samavatian M.H., Parthasarathy S., Ramnath R. A countrywide traffic accident dataset Proceedings of the 27th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (2019) http://arxiv.org/abs/1906.05409. (Accessed 23 April 2020) Google Scholar [119] Hughes David P., Salathe M. An open access repository of images on plant health to enable the development of mobile disease diagnostics (2015) http://arxiv.org/abs/1511.08060. (Accessed 23 April 2020) Google Scholar [120] Zhao S., Yuan X., Xiao D., Zhang J., Li Z. AIRNET: A machine learning dataset for air quality forecasting (2018) http://106.37.208.233:20035. (Accessed 22 April 2020) Google Scholar [121] Popa D., Pop F., Serbanescu C., Castiglione A. Deep learning model for home automation and energy reduction in a smart home environment platform Neural Comput. Appl., 31 (2019), pp. 1317-1337, 10.1007/s00521-018-3724-6 View in ScopusGoogle Scholar [122] Rashid R., Chin L., et al. Machine learning for smart energy monitoring of home appliances using IoT 2019 Eleventh International Conference on Ubiquitous and Future Networks, ICUFN (2019), pp. 66-71 https://ieeexplore.ieee.org/abstract/document/8806026/. (Accessed 5 February 2020) CrossRefView in ScopusGoogle Scholar [123] Manic M., Amarasinghe K., Rodriguez-Andina J.J., Rieger C. Intelligent buildings of the future: Cyberaware, deep learning powered, and human interacting IEEE Ind. Electron. Mag. (2016), pp. 32-49 https://ieeexplore.ieee.org/abstract/document/7792825/. (Accessed 5 February 2020) View in ScopusGoogle Scholar [124] Le T., Vo M.T., Vo B., Hwang E., Rho S., Baik S.W. Improving electric energy consumption prediction using CNN and bi-LSTM Appl. Sci., 9 (2019), p. 4237, 10.3390/app9204237 View in ScopusGoogle Scholar [125] Kim T.-Y., Cho S.-B. Predicting residential energy consumption using CNN-LSTM neural networks Energy, 182 (2019), pp. 72-81 https://www.sciencedirect.com/science/article/pii/S0360544219311223. (Accessed 5 February 2020) View PDFView articleView in ScopusGoogle Scholar [126] Aziz Shah S., Ren A., Fan D., Zhang Z., Zhao N., Yang X., Luo M., Wang W., Hu F., Ur Rehman M., Badarneh O.S., Hussain Abbasi Q. Internet of things for sensing: A case study in the healthcare system Appl. Sci., 8 (2018), p. 508, 10.3390/app8040508 Google Scholar [127] Statista UK: people living alone (2019) https://www.statista.com/statistics/281616/people-living-alone-in-the-united-kingdom-uk-by-age-and-gender/. (Accessed 18 April 2020) Google Scholar [128] P. Feng, M. Yu, S. Mohsen Naqvi, J.A. Chambers, Deep learning for posture analysis in fall detection, in: 2014 19th International Conference on Digital Signal Processing, 2014, pp. 12\u201317. Google Scholar [129] Li X., Pang T., Liu W., Congress T.W. Fall detection for elderly person care using convolutional neural networks 2017 10th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics, CISP-BMEI (2014), pp. 1-6 https://ieeexplore.ieee.org/abstract/document/8302004/. (Accessed 5 February 2020) View PDFView articleGoogle Scholar [130] Santos G.L., Endo P.T., Henrique De Carvalho Monteiro K., Da E., Rocha S., Silva I., Lynn T. Accelerometer-based human fall detection using convolutional neural networks Sensors (2019), p. 1644, 10.3390/s19071644 View in ScopusGoogle Scholar [131] Adhikari K., Bouchachia H., Nait-Charif H. Deep learning based fall detection using simplified human posture Int. J. Comput. Syst. Eng. (2019), pp. 255-260 https://pdfs.semanticscholar.org/f953/09544f8bac647b7503ba6c849ccbd9bc8e19.pdf. (Accessed 18 February 2020) View in ScopusGoogle Scholar [132] Mauldin T.R., Canby M.E., Metsis V., Ngu A.H.H., Rivera C.C. Smartfall: A smartwatch-based fall detection system using deep learning Sensors, 18 (2018), p. 3363, 10.3390/s18103363 View in ScopusGoogle Scholar [133] Shojaei-Hashemi A., Nasiopoulos P., Little J.J., Pourazad M.T. Video-based human fall detection in smart homes using deep learning 2018 IEEE International Symposium on Circuits and Systems, ISCAS (2018), pp. 1-5 https://ieeexplore.ieee.org/abstract/document/8351648/. (Accessed 18 February 2020) CrossRefGoogle Scholar [134] Nait Aicha A., Englebienne G., van Schooten K.S., Pijnappels M., Kr\u00f6se B. Deep learning to predict falls in older adults based on daily-life trunk accelerometry Sensors, 18 (2018), p. 1654, 10.3390/s18051654 Google Scholar [135] Lu N., Wu Y., Feng L., and J.S. Deep learning for fall detection: Three-dimensional CNN combined with LSTM on video kinematic data IEEE J. Biomed. Health Inf., 23 (2018), pp. 314-323 https://ieeexplore.ieee.org/abstract/document/8295206/. (Accessed 18 February 2020) CrossRefGoogle Scholar [136] Wang J., Ding H., Bidgoli F.A., Zhou B., Iribarren C., Molloi S., Baldi P. Detecting cardiovascular disease from mammograms with deep learning IEEE Trans. Med. Imaging, 36 (2017), pp. 1172-1181 https://ieeexplore.ieee.org/abstract/document/7827150/. (Accessed 5 February 2020) View in ScopusGoogle Scholar [137] Latif S., Usman M., Rana R., Qadir J. Phonocardiographic sensing using deep learning for abnormal heartbeat detection IEEE Sens. J., 18 (2018), pp. 9393-9400, 10.1109/JSEN.2018.2870759 View in ScopusGoogle Scholar [138] Song X., Kanasugi H., Shibasaki R. Deeptransport: Prediction and simulation of human mobility and transportation mode at a citywide level IJCAI (2016), pp. 2618-2624 Google Scholar [139] Liu W. Applying deep recurrent neural network to predict vehicle mobility 2018 IEEE Vehicular Networking Conference, VNC (2018), pp. 1-6 https://ieeexplore.ieee.org/abstract/document/8628362/. (Accessed 5 February 2020) View PDFView articleGoogle Scholar [140] Zhao L., Wang J., Liu J. Routing for crowd management in smart cities: A deep reinforcement learning perspective IEEE Commun. Mag. (2019), pp. 88-93 https://ieeexplore.ieee.org/abstract/document/8703471/. (Accessed 5 February 2020) CrossRefView in ScopusGoogle Scholar [141] V.C. Liang, R.T.B. Ma, W. Siong Ng, L. Wang, M. Winslett, H. Wu, S. Ying, Z. Zhang, Mercury: Metro density prediction with recurrent neural network on streaming CDR Data, in: 2016 IEEE 32nd International Conference on Data Engineering, ICDE, 2016, pp. 1374\u20131377. Google Scholar [142] Zhou Z., Liao H., Gu B., Huq K.M.S., Mumtaz S., Rodriguez J. Robust mobile crowd sensing: When deep learning meets edge computing IEEE Netw., 32 (2018), pp. 54-60 https://ieeexplore.ieee.org/abstract/document/8425301/. (Accessed 5 February 2020) CrossRefView in ScopusGoogle Scholar [143] Wessel Paul What is smart parking? (2016) https://parksmart.gbci.org/what-smart-parking. (Accessed 16 March 2020) Google Scholar [144] Bura H., Lin N., Kumar N. An edge based smart parking solution using camera networks and deep learning 2018 IEEE International Conference on Cognitive Computing, ICCC (2018), pp. 17-24 https://ieeexplore.ieee.org/abstract/document/8457691/. (Accessed 5 February 2020) CrossRefView in ScopusGoogle Scholar [145] Amato G., Carrara F., Falchi F., Gennaro C., Meghini C., Vairo C. Deep learning for decentralized parking lot occupancy detection Expert Syst. Appl. (2017), pp. 327-334 https://www.raspberrypi.org/products/raspberry-pi-2-. (Accessed 5 February 2020) View PDFView articleView in ScopusGoogle Scholar [146] Yang S., Ma W., Pi X., Qian S. A deep learning approach to real-time parking occupancy prediction in transportation networks incorporating multiple spatio-temporal data sources Transp. Res. C, 107 (2019), pp. 248-265 https://www.sciencedirect.com/science/article/pii/S0968090X18313780. (Accessed 17 February 2020) View PDFView articleView in ScopusGoogle Scholar [147] Zinelli A., Pizzati F., Musto L. A deep-learning approach for parking slot detection on surround-view images 2019 IEEE Intelligent Vehicles Symposium, IV (2019), pp. 683-688, 10.1109/IVS.2019.8813777 View in ScopusGoogle Scholar [148] Muhammad K., Ahmad J. Early fire detection using convolutional neural networks during surveillance for effective disaster management Neurocomputing, 288 (2018), pp. 30-42 https://www.sciencedirect.com/science/article/pii/S0925231217319203. (Accessed 5 February 2020) View PDFView articleView in ScopusGoogle Scholar [149] Muhammad K., Khan S., Elhoseny M., Baik S.W., Syed H.A. Efficient fire detection for uncertain surveillance environment IEEE Trans. Ind. Inf., 15 (2019), pp. 3113-3122, 10.1109/TII.2019.2897594 View in ScopusGoogle Scholar [150] H. Ren, Y. Song, J. Wang, Y. Hu, J. Lei, A deep learning approach to the citywide traffic accident risk prediction, in: 2018 21st International Conference on Intelligent Transportation Systems, ITSC, 2018, pp. 3346\u20133351. Google Scholar [151] Singh D., Chalavadi K.M., Mohan C.K. Deep spatio-temporal representation for detection of road accidents using stacked autoencoder IEEE Trans. Intell. Transp. Syst. (2018), pp. 879-887, 10.1109/TITS.2018.2835308 View in ScopusGoogle Scholar [152] Kamilaris A., Prenafeta-Bold\u00fa F.X. Deep learning in agriculture: A survey Comput. Electron. Agric. (2018), pp. 70-90 https://www.sciencedirect.com/science/article/pii/S0168169917308803. (Accessed 17 February 2020) View PDFView articleView in ScopusGoogle Scholar [153] Zahid A., Abbas H.T., Ren A., Zoha A., Heidari H., Shah S.A., Imran M.A., Alomainy A., Abbasi Q.H. Machine learning driven non-invasive approach of water content estimation in living plant leaves using terahertz waves Plant Methods, 15 (2019), p. 138, 10.1186/s13007-019-0522-9 View in ScopusGoogle Scholar [154] Ferentinos K.P. Deep learning models for plant disease detection and diagnosis Comput. Electron. Agric. (2018), pp. 311-318, 10.1016/j.compag.2018.01.009 View PDFView articleView in ScopusGoogle Scholar [155] Sladojevic S., Arsenovic M., Anderla A., Culibrk D., Stefanovic D. Deep neural networks based recognition of plant diseases by leaf image classification Comput. Intell. Neurosci. (2016), 10.1155/2016/3289801 Google Scholar [156] Liu B., Zhang Y., He D., Li Y. Identification of apple leaf diseases based on deep convolutional neural networks Symmetry (2018), p. 11, 10.3390/sym10010011 Google Scholar [157] Bu F., Wang X. A smart agriculture IoT system based on deep reinforcement learning Future Gener. Comput. Syst. (2019), pp. 500-507 https://www.sciencedirect.com/science/article/pii/S0167739X19307277. (Accessed 5 February 2020) View PDFView articleView in ScopusGoogle Scholar [158] Zhu Nanyang, Liu Xu, Liu Ziqian, Hu Kai, Wang Yingkuan, Tan Jinglu, Huang Min, Zhu Qibing, Ji Xunsheng, Jiang Yongnian, Guo Ya Deep learning for smart agriculture: Concepts, tools, applications, and opportunities Int. J. Agricult. Biol. Eng., 11 (2018), pp. 32-44, 10.25165/j.ijabe.20181104.4475 View in ScopusGoogle Scholar [159] H\u00e4ni N., Roy P., Isler V. Apple counting using convolutional neural networks 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS (2018), pp. 2559-2565, 10.1109/IROS.2018.8594304 View in ScopusGoogle Scholar [160] Liu X., Chen S.W., Aditya S., Sivakumar N., Dcunha S., Qu C., Taylor C.J., Das J., Kumar V. Robust fruit counting: Combining deep learning, tracking, and structure from motion 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS (2018), pp. 1045-1052 http://label.ag/iros18.mp4. (Accessed 18 February 2020) CrossRefView in ScopusGoogle Scholar [161] S. Dcunha, J. Das, C. Qu, S.W. Chen, S.S. Shivakumar, E. Okon, C.J. Taylor, V. Kumar, Counting apples and oranges with deep learning: A data driven approach, 2 (2017) 781\u2013788, http://dx.doi.org/10.1109/LRA.2017.2651944. Google Scholar [162] Zhao X., Zhang R., Wu J.-L., Chang P.-C. A deep recurrent neural network for air quality classification J. Inf. Hiding Multimedia Signal Process. C, 9 (2018) Google Scholar [163] Soh P., Chang J., Access J.H. Adaptive deep learning-based air quality prediction model using the most relevant spatial\u2013temporal relations IEEE Access (2018), pp. 38186-38199 https://ieeexplore.ieee.org/abstract/document/8392677/. (Accessed 5 February 2020) CrossRefView in ScopusGoogle Scholar [164] Pan Z., Yu H., Miao C. Crowdsensing air quality with camera-enabled mobile devices Twenty-Ninth IAAI Conference (2017) https://www.aaai.org/ocs/index.php/IAAI/IAAI17/paper/viewPaper/14171. (Accessed 5 February 2020) Google Scholar [165] Mutis I., Ambekar A., Joshi V. Real-time space occupancy sensing and human motion analysis using deep learning for indoor air quality control Autom. Constr., 116 (2020), Article 103237-undefined https://www.sciencedirect.com/science/article/pii/S0926580519307630. (Accessed 20 August 2020) Google Scholar [166] Markovic R., Grintal E., W\u00f6lki D., Frisch J., van Treeck C. Window opening model using deep learning methods Build. Environ. (2019), pp. 319-329 https://www.sciencedirect.com/science/article/pii/S0360132318305729. (Accessed 20 August 2020) Google Scholar [167] Zeng D., Zhang S., Chen F. Multi-scale CNN based garbage detection of airborne hyperspectral data IEEE Access (2019), pp. 104514-104527 https://ieeexplore.ieee.org/abstract/document/8782106/. (Accessed 5 February 2020) CrossRefView in ScopusGoogle Scholar [168] Y. Wang, X. Zhang, Autonomous garbage detection for intelligent urban management, in: MATEC Web of Conferences, 2018, p. 01056, http://dx.doi.org/10.1051/matecconf/201823201056. Google Scholar [169] Hasan M., Tanawala B., Patel K. Deep learning precision farming: Tomato leaf disease detection by transfer learning Papers.Ssrn.Com (2019) https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3349597. (Accessed 3 February 2020) Google Scholar [170] Bostami B., Ahmed M., Choudhury S. False data injection attacks in internet of things Performability in Internet of Things (2019), pp. 47-58, 10.1007/978-3-319-93557-7_4 View in ScopusGoogle Scholar [171] Shokri R., Shmatikov V. Privacy-preserving deep learning The 22nd ACM SIGSAC Conference on Computer and Communications Security (2015), pp. 1310-1321, 10.1145/2810103.2813687 View in ScopusGoogle Scholar [172] Zhou J., Cao Z., Dong X., Vasilakos A.V. Vasilakos AV security and privacy for cloud-based IoT: Challenges IEEE Commun. Mag., 55 (2017), pp. 26-33 https://ieeexplore.ieee.org/abstract/document/7823334/. (Accessed 5 February 2020) View in ScopusGoogle Scholar [173] Hitaj B., Ateniese G., Perez-Cruz F. Deep models under the GAN: Information leakage from collaborative deep learning Proceedings of the ACM Conference on Computer and Communications Security, Association for Computing Machinery (2017), pp. 603-618, 10.1145/3133956.3134012 View in ScopusGoogle Scholar [174] Gandomi A., Management M.H. Beyond the hype: Big data concepts, methods, and analytics Int. J. Inf. Manage., 35 (2015), pp. 137-144 https://www.sciencedirect.com/science/article/pii/S0268401214001066. (Accessed 23 February 2020) View PDFView articleView in ScopusGoogle Scholar [175] (Vonu) Thakuriah P., Tilahun N.Y., Zellner M. Big data and urban informatics: Innovations and challenges to urban planning and knowledge discovery Seeing Cities Through Big Data, Springer (2017), pp. 11-45, 10.1007/978-3-319-40902-3_2 Google Scholar [176] Badar M., Haris M., Fatima A. Application of deep learning for retinal image analysis: A review Comp. Sci. Rev., 35 (2020), Article 100203, 10.1016/j.cosrev.2019.100203 View PDFView articleView in ScopusGoogle Scholar [177] Rahnemoonfar M., Sheppard C. Deep count: Fruit counting based on deep simulated learning Sensors, 17 (2017), p. 905, 10.3390/s17040905 View in ScopusGoogle Scholar [178] Buhrmester V., M\u00fcnch D., Arens M. Analysis of explainers of black box deep neural networks for computer vision: A survey (2019) http://arxiv.org/abs/1911.12116. (Accessed 29 March 2020) Google Scholar [179] Freitas A.A. Comprehensible classification models ACM SIGKDD Explor. Newsl., 15 (2014), pp. 1-10, 10.1145/2594473.2594475 Google Scholar [180] Lim C., Kim K., Cities P. Smart cities with big data: Reference models, challenges, and considerations Cities (2018), pp. 86-99 https://www.sciencedirect.com/science/article/pii/S0264275117308545. (Accessed 17 February 2020) View PDFView articleView in ScopusGoogle Scholar [181] al Nuaimi E., al Neyadi H., Mohamed N., Al-Jaroodi J. Applications of big data to smart cities J. Internet Serv. Appl., 6 (2015), pp. 1-15, 10.1186/s13174-015-0041-5 View in ScopusGoogle Scholar [182] White G., Nallur V., Clarke S. Quality of service approaches in IoT: A systematic mapping J. Syst. Softw., 132 (2017), pp. 168-203 http://engineeringvillage.com. (Accessed 21 February 2020) CrossRefView in ScopusGoogle Scholar [183] Driss M., Jamoussi Y., Hajjami H., Gh\u00e9zala B. QoS testing of service-based applications 2008 3rd International Design and Test Workshop (2008), pp. 45-50, 10.1109/IDT.2008.4802463\u00ef View in ScopusGoogle Scholar [184] Driss M., Jamoussi Y., J\u00e9z\u00e9quel J.-M., Hajjami H., Gh\u00e9zala B. A discrete-events simulation approach for evaluation of service-based applications 2008 Sixth European Conference on Web Services, IEEE (2008), pp. 73-78, 10.1109/ECOWS.2008.19 View in ScopusGoogle Scholar [185] Jalali R., El-Khatib K. Smart city architecture for community level services through the internet of things 2015 18th International Conference on Intelligence in Next Generation Networks (2015), pp. 108-113 https://ieeexplore.ieee.org/abstract/document/7073815/. (Accessed 23 February 2020) CrossRefView in ScopusGoogle Scholar [186] Weiss K., Khoshgoftaar T.M., Wang D.D. A survey of transfer learning J. Big Data, 3 (2016), 10.1186/s40537-016-0043-6 Google Scholar [187] Deng C., Xue Y., Liu X., Li C., Tao D. Active transfer learning network: A unified deep joint spectral-spatial feature learning model for hyperspectral image classification IEEE Trans. Geosci. Remote Sens., 57 (2018), pp. 1741-1754 CrossRefView in ScopusGoogle Scholar [188] Gopalakrishnan K., Khaitan S.K., Agrawal A., Khaitan S.K., Choudhary A. Deep convolutional neural networks with transfer learning for computer vision-based data-driven pavement distress detection Constr. Build. Mater., 157 (2017), pp. 322-330, 10.1016/j.conbuildmat.2017.09.110 View PDFView articleView in ScopusGoogle Scholar [189] Tahir A., Ahmad J., Shah S.A., Morison G., Skelton D.A., Larijani H., Abbasi Q.H., Imran M.A., Gibson R.M. Wifreeze: Multiresolution scalograms for freezing of gait detection in parkinson\u2019s leveraging 5g spectrum with deep learning Electronics, 8 (2019), p. 1433, 10.3390/electronics8121433 View in ScopusGoogle Scholar [190] Newman S. Building microservices (2015) https://books.google.com/books?hl=en&lr=&id=jjl4BgAAQBAJ&oi=fnd&pg=PP1&dq=Building+microservices:+designing+fine-grained+systems&ots=_APUTn7_gL&sig=KEdWTFeukA_U7QnHxgJQqOCh4Cw. (Accessed 22 August 2020) Google Scholar [191] Driss M., Jamoussi Y., J\u00e9z\u00e9quel J.M., ben Gh\u00e9zala H.H. A multi-perspective approach for web service composition ACM International Conference Proceeding Series (2011), pp. 106-111, 10.1145/2095536.2095556 View in ScopusGoogle Scholar [192] Driss M., Aljehani A., Boulila W., Ghandorh H., Al-Sarem M. Servicing your requirements: An FCA and RCA-driven approach for semantic web services composition IEEE Access, 8 (2020), pp. 59326-59339 https://ieeexplore.ieee.org/abstract/document/9044348/. (Accessed 22 August 2020) CrossRefView in ScopusGoogle Scholar [193] Krylovskiy A., Jahn M., Patti E. Designing a smart city internet of things platform with microservice architecture 2015 3rd International Conference on Future Internet of Things and Cloud (2015), pp. 24-26, 10.1109/FiCloud.2015.55 Google Scholar [194] Ali S., Aslam Jarwar M., Chong I. Design methodology of microservices to support predictive analytics for IoT applications Sensors, 18 (2018), p. 4226, 10.3390/s18124226 View in ScopusGoogle Scholar [195] Sunds\u00f8y P., Bjelland J., Reme B.-A., Iqbal A.M., Jahani E. Deep learning applied to mobile phone data for individual income classification 2016 International Conference on Artificial Intelligence: Technologies and Applications (2016) https://www.atlantis-press.com/proceedings/icaita-16/25849475. (Accessed 25 February 2020) Google Scholar [196] Alsheikh M.A., Niyato D., Lin S., Tan H.-P., Han Z. Mobile big data analytics using deep learning and apache spark IEEE Netw., 30 (2016), pp. 22-29 https://ieeexplore.ieee.org/abstract/document/7474340/. (Accessed 25 February 2020) View in ScopusGoogle Scholar [197] Safaei M., Ismail A.S., Chizari H., Driss M., Boulila W., Asadi S., Safaei M. Standalone noise and anomaly detection in wireless sensor networks: A novel time-series and adaptive Bayesian-network-based approach Softw. - Pract. Exp., 50 (2020), pp. 428-446, 10.1002/spe.2785 View in ScopusGoogle Scholar [198] Safaei M., Asadi S., Driss M., Boulila W., Alsaeedi A., Chizari H., Abdullah R., Safaei M. A systematic literature review on outlier detection in wireless sensor networks Symmetry, 12 (2020), p. 328, 10.3390/sym12030328 View in ScopusGoogle Scholar [199] Din I.U., Asmat H., Guizani M. A review of information centric network-based internet of things: communication architectures, design issues, and research opportunities Multimedia Tools Appl., 78 (2019), pp. 30241-30256, 10.1007/s11042-018-6943-z View in ScopusGoogle Scholar [200] Minoli D., Occhiogrosso B. Practical aspects for the integration of 5g networks and IoT applications in smart cities environments Wirel. Commun. Mob. Comput., 2019 (2019), 10.1155/2019/5710834 Google Scholar [201] Li S., da Xu L., Zhao S. 5g internet of things: A survey J. Ind. Inf. Integr., 10 (2018), pp. 1-9 https://www.sciencedirect.com/science/article/pii/S2452414X18300037. (Accessed 1 March 2020) View PDFView articleGoogle Scholar [202] Reka S.S., Dragi\u010devi T., Siano P., Sahaya Prabaharan S. Future generation 5g wireless networks for smart grid: A comprehensive review Energies, 12 (2019), p. 2140, 10.3390/en12112140 Google Scholar [203] Agiwal M., Roy A., Saxena N. Next generation 5g wireless networks: A comprehensive survey IEEE Commun. Surv. Tutor., 18 (2016) (2016), pp. 1617-1655 https://ieeexplore.ieee.org/abstract/document/7414384/. (Accessed 3 March 2020) View in ScopusGoogle Scholar [204] Tariq F., Khandaker M., Wong K.-K., Imran M., Bennis M., Debbah M. A speculative study on 6g (2019) http://arxiv.org/abs/1902.06700. (Accessed 1 March 2020) Google Scholar [205] Xie Z., Dai S., Chen H.-N., Wang X. Blockchain challenges and opportunities: a survey Int. Congress Big Data, 14 (2018), pp. 352-375, 10.1504/IJWGS.2018.10016848 Google Scholar [206] Fern\u00e1ndez-Caram\u00e9s T., Fraga-Lamas P. A review on the use of blockchain for the internet of things IEEE Access, 6 (2018), pp. 32979-33001 https://ieeexplore.ieee.org/abstract/document/8370027/. (Accessed 17 February 2020) CrossRefView in ScopusGoogle Scholar [207] Ali M., Vecchio M., Pincheira M., Tutorials K.D. Applications of blockchains in the internet of things: A comprehensive survey IEEE Commun. Surv. Tutor. (2018), pp. 1676-1717 https://ieeexplore.ieee.org/abstract/document/8580364/. (Accessed 17 February 2020) Google Scholar [208] Portmann E. Blockchain: Blueprint for a New Economy Springer Fachmedien Wiesbaden GmbH (2018), 10.1365/s40702-018-00468-4 Google Scholar [209] Yaqoob I., Ahmed E., et al. Internet of things architecture: Recent advances, taxonomy, requirements, and open challenges IEEE Wirel. Commun., 24 (2017), pp. 10-16 https://ieeexplore.ieee.org/abstract/document/7955906/. (Accessed 3 March 2020) View in ScopusGoogle Scholar [210] M. Mohammadi G., Al-Fuqaha A. Enabling cognitive smart cities using big data and machine learning: Approaches and challenges IEEE Commun. Mag., 56 (2018), pp. 94-101 http://www.havenondemand.com. (Accessed 3 March 2020) Google Scholar [211] Letic Jovana Internet of things statistics for 2020 (2019) https://dataprot.net/statistics/iot-statistics/. (Accessed 27 March 2020) Google Scholar [212] Gharaibeh A., Salahuddin M., Khalil I., Salahuddin M.A., Hussini S.J., Member S., Khreishah A., Guizani M., Al-Fuqaha A., Member S. Smart cities: A survey on data management, security and enabling technologies IEEE Commun. Surv. Tutor., 19 (2017), pp. 2456-2501, 10.1109/COMST.2017.2736886 View in ScopusGoogle Scholar [213] Furno A., Fiore M., Stanica R. Joint spatial and temporal classification of mobile traffic demands IEEE INFOCOM 2017-IEEE Conference on Computer Communications (2017), pp. 1-9 https://hal.inria.fr/hal-01514402. (Accessed 3 March 2020) Google Scholar Cited by (191) Life cycle energy analysis of buildings: A systematic review 2024, Building and Environment Show abstract Trustworthy remote sensing interpretation: Concepts, technologies, and applications 2024, ISPRS Journal of Photogrammetry and Remote Sensing Show abstract Unleashing the power of artificial intelligence for climate action in industrial markets 2024, Industrial Marketing Management Show abstract Design of risk prediction model for esophageal cancer based on machine learning approach 2024, Heliyon Show abstract Prediction of five-year survival among esophageal cancer patients using machine learning 2023, Heliyon Show abstract FedMicro-IDA: A federated learning and microservices-based framework for IoT data analytics 2023, Internet of Things (Netherlands) Show abstract View all citing articles on Scopus 1 https://trends.google.com. 2 https://hadoop.apache.org/. 3 https://mahout.apache.org/. 4 https://spark.apache.org/. 5 https://www.h2o.ai/. 6 http://www.lua.org. View Abstract \u00a9 2020 Elsevier Inc. All rights reserved. Recommended articles Accurate performance prediction of IoT communication systems for smart cities: An efficient deep learning based solution Sustainable Cities and Society, Volume 69, 2021, Article 102830 Omar Said, Amr Tolba View PDF Integration of Big Data analytics embedded smart city architecture with RESTful web of things for efficient service provision and energy management Future Generation Computer Systems, Volume 107, 2020, pp. 975-987 Bhagya Nathali Silva, \u2026, Kijun Han View PDF Exploiting IoT and big data analytics: Defining Smart Digital City using real-time urban data Sustainable Cities and Society, Volume 40, 2018, pp. 600-610 M. Mazhar Rathore, \u2026, Sharjil Saeed View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 166 Captures Readers: 474 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright \u00a9 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.\"",
        "analysis": "",
        "verbatim_quote1": "",
        "verbatim_quote2": "",
        "verbatim_quote3": "",
        "relevance_score1": 0,
        "relevance_score2": 0,
        "limitations": "",
        "inline_citation": "",
        "full_citation": ""
    },
    {
        "title": "Agronomic basis and strategies for precision water management: A review",
        "doi": "10.3390/agronomy9020087",
        "description": "Agriculture faces the challenge of feeding a growing population with limited or depleting fresh water resources. Advances in irrigation systems and technologies allow site-specific application of irrigation water within the field to improve water use efficiency or reduce water usage for sustainable crop production, especially in arid and semi-arid regions. This paper discusses recent development of variable-rate irrigation (VRI) technologies, data and information for VRI application, and impacts of VRI, including profitability using this technology, with a focus on agronomic factors in precision water management. The development in sprinkler systems enabled irrigation application with greater precision at the scale of individual nozzle control. Further research is required to evaluate VRI prescription maps integrating different soil and crop characteristics in different environments. On-farm trials and whole-field studies are needed to provide support information for practical VRI applications. Future research also needs to address the adjustment of the spatial distribution of prescription zones in response to temporal variability in soil water status and crop growing conditions, which can be evaluated by incorporating remote and proximal sensing data. Comprehensive decision support tools are required to help the user decide where to apply how much irrigation water at different crop growth stages to optimize water use and crop production based on the regional climate conditions and cropping systems.",
        "journal": "Agronomy",
        "authors": [
            "Neupane J.",
            "Guo W."
        ],
        "citation_count": "71",
        "full_text": "\"This website uses cookies We use cookies to personalise content and ads, to provide social media features and to analyse our traffic. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you\u2019ve provided to them or that they\u2019ve collected from your use of their services. Consent Selection Necessary Preferences Statistics Marketing Show details                Deny Allow selection Allow all     Journals Topics Information Author Services Initiatives About Sign In / Sign Up Submit   Search for Articles: Agronomy All Article Types Advanced   Journals Agronomy Volume 9 Issue 2 10.3390/agronomy9020087 Submit to this Journal Review for this Journal Propose a Special Issue Article Menu Subscribe SciFeed Recommended Articles Related Info Link More by Authors Links Article Views 10231 Citations 71 Table of Contents Abstract Introduction Variable-Rate Irrigation Technologies Topographic and Soil Factors in Precision Water Management Crop and Soil Monitoring for Precision Water Management Precision Water Management Strategies Impact of Variable-Rate Irrigation Challenges and Research Requirements Author Contributions Funding Conflicts of Interest References Altmetric share Share announcement Help format_quote Cite question_answer Discuss in SciProfiles thumb_up Endorse textsms Comment first_page settings Order Article Reprints Open AccessReview Agronomic Basis and Strategies for Precision Water Management: A Review by Jasmine Neupane and Wenxuan Guo * Department of Plant and Soil Science, Texas Tech University, Lubbock, TX 79409, USA * Author to whom correspondence should be addressed. Agronomy 2019, 9(2), 87; https://doi.org/10.3390/agronomy9020087 Submission received: 26 January 2019 / Revised: 9 February 2019 / Accepted: 11 February 2019 / Published: 14 February 2019 (This article belongs to the Special Issue Agricultural Water Management) Download keyboard_arrow_down     Browse Figure Versions Notes Abstract Agriculture faces the challenge of feeding a growing population with limited or depleting fresh water resources. Advances in irrigation systems and technologies allow site-specific application of irrigation water within the field to improve water use efficiency or reduce water usage for sustainable crop production, especially in arid and semi-arid regions. This paper discusses recent development of variable-rate irrigation (VRI) technologies, data and information for VRI application, and impacts of VRI, including profitability using this technology, with a focus on agronomic factors in precision water management. The development in sprinkler systems enabled irrigation application with greater precision at the scale of individual nozzle control. Further research is required to evaluate VRI prescription maps integrating different soil and crop characteristics in different environments. On-farm trials and whole-field studies are needed to provide support information for practical VRI applications. Future research also needs to address the adjustment of the spatial distribution of prescription zones in response to temporal variability in soil water status and crop growing conditions, which can be evaluated by incorporating remote and proximal sensing data. Comprehensive decision support tools are required to help the user decide where to apply how much irrigation water at different crop growth stages to optimize water use and crop production based on the regional climate conditions and cropping systems. Keywords: variable-rate irrigation; precision agriculture; irrigation scheduling 1. Introduction Agriculture is the largest consumer of the world\u2032s available fresh water, as plant growth largely depends on the availability of water. According to the Food and Agriculture Organization (FAO), current world irrigated area is approximately 300 million ha, and projection to 2050 suggests growing scarcities of water resources for agriculture, although water is a renewable resource. This situation has amplified the intensity of global food insecurity, climate change, and poverty. The greatest challenge to agriculture is to provide food and fiber for almost 8 billion people around the world in the advent of depleting freshwater resources [1]. The challenge is more prominent in the arid and semi-arid regions, where underground water sources, especially aquifers are used for irrigation, as rainfall provides only a portion of the total requirement for crop evapotranspiration (ET) demand [2]. Heavy irrigation has caused rapid depletion of many aquifers. For instance, comparing the water level of the Ogallala aquifer in the 1950s to that of 2013, in some wells, up to 78 m of water was depleted in the Texas High Plains area [3]. This is almost 12 times the average decline of 4.5 m for the whole area of the aquifer. Given this depletion rate, scientists have predicted that 35% of the Southern High Plains will not be able to support irrigation in 30 years. Many other water resources in the world are depleting rapidly in recent years with negligible recharge, indicating the need for water conservation solutions in agriculture [4,5]. More effective and efficient management of water is required to better conserve water and improve water use efficiency for sustainable crop production. Conventional farming practices manage an agricultural field uniformly without incorporating the intrinsic variability in topography, soil, crop growth conditions, and other agronomic factors. This can result in nutrient leaching, environmental contamination, and reduced profitability especially when applying high inputs in low yielding areas and vice versa [6,7]. Precision agriculture can be adopted to divide the field into small management units for optimized production [8]. There are several definitions for precision agriculture, and it keeps evolving with emerging technologies and understanding of what is achievable [9]. The idea of precision agriculture or site-specific management started around the early 1980s with the development of various technologies to assess field variabilities such as soil survey, soil testing and mapping, and crop yield monitoring [10,11,12,13]. Precision agriculture depends on detailed spatial information, information technology, greater information processing capability, and better decision aids [14]. Precision agriculture is a management system that measures and responds to the spatial and temporal variability of soil and crop growth at the sub-field level with the aim to enhance profitability and reduce environmental impact [15,16]. Major technologies involved in precision agriculture include geographic information systems (GIS), remote and proximal sensing, Global Navigation Satellite System (GNSS), yield monitoring and the variable rate technology. Georeferenced information about soil and plant characteristics can be obtained efficiently using GIS, proximal sensors and remote sensors [17]. Application of yield monitors provides the capability to precisely characterize yield variability at large scales in the field. Moreover, the variable rate technology provides the ability to site-specifically apply irrigation water in the field to achieve potential water savings [18]. This enables the timely and accurate water application incorporating the spatial and temporal soil properties and plant demand at different growth stages [15]. In other words, the variable rate irrigation (VRI) technology can help to apply the right amount of water in the right area of the field at the right time resulting in water savings. Recent research suggests site-specific management of water or VRI could be a solution to conserve water and improve water use efficiency (WUE), which is the ratio between effective water use and actual water withdrawal in the field [19]. VRI can support water and energy conservation with a positive influence on crop water productivity and the environment [20]. This is possible by applying irrigation at rates that vary to appropriately match field variability based on specific water needs of individual management zones rather than applying a uniform rate throughout the field [21]. The magnitude of soil water content (SWC) varies with time and location, but the pattern of spatial variability usually remains similar. This temporal stability of SWC is associated with properties of the field such as topography, soil texture, apparent soil electrical conductivity (ECa) and drainage patterns that insignificantly change over time [22,23]. The feasibility and effectiveness of VRI depend on the size of the field, crop species under consideration, weather, and the underlying field properties such as elevation, slope, soil texture, and ECa that influence soil moisture content and irrigation requirements for the crop [24,25]. Hence, understanding the influence of agronomic factors such as topography and soil properties on soil water and ultimately yield can provide a basis for application of VRI in the field to achieve potential water savings together with yield optimization. Today, site-specific water management has been made easier with several precision agriculture tools, such as GNSS, GIS, yield mapping, soil survey and remote sensing [26]. Several decision support tools and strategies to reduce groundwater withdrawal without reductions in irrigated land area or crop productivity have been developed [4]. The measures to optimize the use of irrigation water in the fields include increasing weather-based irrigation scheduling, converting gravity-based irrigation to center pivot irrigation, subsurface drip irrigation, replacing high water to low water demand crops, and deficit irrigation based on evapotranspiration replacement using various water-balance models [27]. Several studies have been done to understand the possible water savings with VRI. A review on VRI across different crop and weather regimes of the world concluded that VRI could save 10%\u201315% of water [28]. Although the use of VRI seems to be a reasonable measure to improve water management, many producers are reluctant to adopt it because limited research is done at the field scale to understand its reliability and economic potential [25]. A better understanding of field variability and how it affects crop yield is needed for effective implementation of the new technologies. A review for site-specific sprinkler irrigation [29] focused on the technology and challenges for adoption. Another review of 20 years\u2019 research on increasing crop productivity with sprinkler and micro-irrigation discussed the importance of understanding the crop response to VRI [30]. The study emphasized the need for continuous effort towards management zone delineation based on field properties integrated with dynamic information from real-time monitoring of climatological and crop data. However, this study focused more on the technological aspect of irrigation management than the agronomic aspect of water conservation with VRI. The agricultural science behind VRI is equally crucial for the successful implementation of this technology. Hence, the objective of this paper is to review the scientific background and technologies in precision water management, with the focus on agronomic factors and strategies for site-specific water management. 2. Variable-Rate Irrigation Technologies The irrigation system changed from gravity-based furrow irrigation in the 1950s to sprinkler irrigation in late 1990s. Initially, the high-pressure sprinkler irrigation system was available in the 1980s which later developed to low-pressure sprinklers and low-energy precision application (LEPA) in 1990s [31,32,33]. About 49% of total irrigated land in the United States is irrigated with center pivot systems, out of which 44% is irrigated at low pressure under 30 psi [34]. The basic requirements for the VRI technology are sensors and spatial information, prescription maps and a system to incorporate VRI prescription (e.g., LEPA, lateral irrigation, etc.) to apply in the field [35]. At present, there are several irrigation technologies for conservation irrigation, such as sprinkler, drip, and other micro-irrigation systems but limited site-specific studies have been done [30,36,37,38]. For example, a study of the variable-rate drip irrigation system on vineyard found up to 17% increase in yield and a 20% decrease in water consumption compared to uniform irrigation [39]. Researchers in the UK assessed the potential of hose-reel boom irrigators for precision irrigation in vegetables [40]. Automatic gravity-fed irrigation systems in Europe decreased manual labor and supported adoption by innovative farmers [41]. Variable-rate irrigation using center pivot in rice showed better performance compared to uniform flooding irrigation [42]. In this review, we will focus more on those irrigation technologies that have been used for site-specific water management more frequently around the world, such as variable-rate lateral irrigation systems and center pivot irrigation systems. The components of a variable-rate lateral irrigation system commonly consist of a GPS or GNSS receiver, custom software-controlled relays and valves, which can apply variable water utilizing the nozzle-pulsing technique and a variable speed control system. This system can control the irrigation rate and forward speed with high accuracy [43]. Similarly, the components of a center pivot VRI system include a pivot control panel, a VRI control panel, solenoid valves, control nodes, a GNSS system, a variable frequency drive and a remote-control system [21]. The pivot control regulates the operation and speed of the pivot, while the VRI control panel regulates the irrigation application rate in response to the prescription map and the pivot location. Solenoid valves regulate the flow of sprinkler heads. The GNSS system at the end of the center pivot provides the pivot position. The control nodes along the length of the pivot determine when the valves are open or close. The variable frequency drive (VFD) helps to regulate the pressure while instantaneously changing the rate of irrigation at different positions of the field. The VFD controls the rotation speed of the pump impeller by receiving the input from a pressure switch installed on the pump outlet pipe. This keeps water pressure stable within preset maximum and minimum thresholds and thus saving water and energy. The remote control system allows to view and control the center pivot and the pump from a distance via a smartphone or a computer using the internet [21]. Further, research and development are striving to control irrigation amount with VRI controllers using real-time information from plant and soil sensors in the field [44]. Currently, several companies work on the manufacture and application of this technology. The commercially available VRI control resolution varies with the manufacturers. VRI systems can apply zero water to specific nozzles and as much as 200% of the standard application rate to other nozzles by opening or closing individual nozzles and by changing the speed of the pivot [45]. Some companies provide the ability to control zones of sprinklers, while others can control each sprinkler independently [46]. For example, Valley (Valley, Valmont Irrigation, Valley, NE, USA) provides variable speed control and variable zone control technologies for site-specific water application. The variable speed control system uses an advanced control panel that can slow down or speed up the pivot to vary water input in different areas (sectors) of the field, but the overall pivot flow rate remains constant. This system does not need additional hardware on the existing pivot irrigation system. The variable zone control system can vary the speed of the center and change the application rate along the pivot lateral. This system applies different irrigation depths to different areas of the field by turning sprinklers on and off for various amounts of time. Trimble (Trimble Navigation, Sunnyvale, CA, USA) has developed the Irrigate-IQ Variable-Rate Irrigation System. This system incorporates the VFD and variable speed drive (VSD) into the recent optimal flow VRI that works with standard pump equipment on wells with limited capacity. This system is capable of individual nozzle control, which can apply the right amount of water in the right place more accurately [47]. Currently, it is possible to achieve sector control with very small resolution, and zone control can add irrigation zones further to the sector at the small scales of lateral spans (Figure 1) [48]. A study conducted in Canada to evaluate the performance of VRI found that the accuracy of water application was up to 90% in the center pivot system [49]. However, the performance of these irrigation systems in field applications is affected by many factors, such as field attributes, the spatial resolution of the sensors used in irrigation management and temporal resolution of data inputs, as well as unexpected environmental conditions. Hence, adaptive irrigation management strategies and active research support are required to enhance the adoption and application of VRI [20,50]. Figure 1. Prescription maps with different control scenarios for four irrigation depths ([48], reproduced with permission from Springer Nature). 3. Topographic and Soil Factors in Precision Water Management An essential prerequisite for site-specific irrigation is the understanding of the spatial and temporal variability of soil properties and crop growth conditions that affect water availability, water requirement, water use efficiency, crop growth, and crop yield. Topography and soil properties are important factors that influence water availability for crop growth. The variability of soil and topographic properties combined can explain 28% to 85% of yield variability [51]. Hence, it is critical to quantify the variability of terrain attributes and soil properties for VRI applications. 3.1. Topography Topographic variation is a common characteristic of large agricultural fields that result in spatial variability of soil water and ultimately crop yield [52]. Topography or terrain has two types of attributes, primary and secondary attributes [53]. Primary attributes include elevation, slope, aspect, curvature, flow length, and upslope contributing area. Secondary attributes are derived empirically from several primary attributes to characterize specific processes manifesting in the landscape, mainly including sediment transport index (STI), stream power index (SPI), flow direction, flow accumulation, distance to flow accumulation lines (DFL), and wetness index [53,54]. Topographic properties affect soil physical and chemical properties such as texture (sand, silt, and clay content), pH, CaCO3, extractable Ca and Mg, available K, base saturation, organic matter, and cation exchange capacity (CEC). Topography also influences hydrologic properties and processes and can account for up to 50% of water availability differences in the same field [52]. Elevation, slope and surface curvatures directly affect infiltration and runoff as they influence the surface and subsurface flow of water in the field [55,56]. This can have a significant effect on crop growth and yield, resulting in differences in crop production of up to 69% at different positions in the field [57,58,59]. A study conducted in central Illinois and eastern Indiana showed that topography alone could explain about 20% of yield variability [60]. Corn yield variability was consistently correlated with elevation and slope in a three-year study in Southern Portugal [53]. This study showed that topographic indices, such as distance to flow accumulation lines (DFL), were negatively correlated with yield, hence could be used to evaluate spatial yield variability. A research conducted on a 7.4-ha field in the Southern High Plains of Texas showed cotton lint yield was negatively correlated with site elevation. The lint yield and nitrogen (N) uptake was higher in bottom slope positions than in upslope, possibly due to the accumulation of run-off water and NO3-N eroded from the upper slope areas. However, this trend depended on weather conditions. For a wet year when there was over accumulation of water in bottom slopes, lower yield in bottom slopes and higher yield in upper slopes were observed [61]. Relative elevation explained up to 49% of water content variation in the soil and 32% of lint yield variation in the field. The negative correlation between crop yield and elevation could be in part due to the effect of erosion and topographical attributes on soil properties that influence infiltration and storage of water. Slope length also affects crop yield by influencing N denitrification, soil N, P, K, Ca and Mg distributions, soil carbon storage, and nitrate distribution, as well as the infiltration rate of water in the field [62]. The curvature of the field surface determines the concentration or dispersion of surface water in the field [55]. Concave surface with negative curvatures concentrates water flow, while convex surface with positive curvature disperses water flow [63]. For example, SWC was found strongly correlated with soil surface curvature (r = 0.9) [64]. Soil surface curvature can explain up to 15% of variations in the crop yield [65]. Corn yield was negatively correlated with surface curvature in another research [53]. In this study, corn yield was 14% higher in concave curvatures than convex areas. In a six-year study [55], corn yields were negatively correlated with elevation, slope, planar curvature and profile curvature for the wet years. The impact of surface curvature on crop yield also depends on weather conditions and the location to some extent. Weather factors have the largest effect on grain yield at locations with large curvature values. In some cases, surface curvature is positively related to crop yield at locations or years with higher precipitation [60]. The magnitude of curvature also has an impact on crop yield. The effect of curvature on crop yield between wet and dry years are highly different at locations with small curvature [66]. Hence, understanding and incorporating topographic attributes of the field, such as elevation, slope length and aspect, surface curvature and their influence on water dynamics can be an important input for site-specific water management to achieve potential water savings and optimized production. 3.2. Soil Properties Soil functions as a medium for plant growth, a regulator of water flow and nutrient cycling. It is a dynamic entity where complex interactions occur among its physical, chemical and biological properties to enable these functions [67]. Soil forming factors such as parent material, biota, topography, climate, and time are variable in time and space and explain most of the soil variability besides the management induced variability [11]. Spatial variability of chemical properties including nutrients, organic matter, and pH can result in within-field variation in available water content and crop productivity [68]. Complex spatial patterns of soil physical properties also affect soil water availability and rooting of a plant, resulting in variability in crop growth and yield [69]. Soil texture, organic matter content, apparent electrical conductivity, and biological properties are relatively stable properties of the field that are usually considered for site-specific management of the field. 3.2.1. Soil Texture Soil texture, the relative content of sand, silt, and clay particles, is an important soil physical property that affects crop growth and yield. Soil texture determines the rate at which water drains through saturated soil and influences available water-holding capacity. Therefore, it affects the distribution of available water for plant growth and irrigation requirements in the field. Fine sandy loams and silts tend to have the highest water-holding capacity, while an increase in either clay or sand content in the soil profile decreases the water-holding capacity [70]. The matric potential of soil, which depends on soil particle size, influences the availability of soil water. For example, clay particles have higher matric potential and lower soil available water compared to sand and silt particles [71]. Soil texture also affects the spatial variability of residual NO3-N and the leaching of N. More residual was found in sandy loam soils compared to loamy sand, and leaching was higher in loamy sand compared to sandy loam [72]. Soil texture also affects the pore sizes and porosity of the soil, which ultimately affects crop root growth and yield by limiting the water available to the plant and the growth space for the roots [73]. In general, soils with high clay content are more difficult to manage due to lack of porosity and water available for plant growth. On the other hand, well-drained soils have good soil aeration for healthy root and crop growth [74]. The clay content can also influence soil water and nutrient content and result in crop yield variability across the field [61,75]. A study showed that clay content in the soil could explain up to 17% variability in winter wheat yield by affecting the water available in the soil for crop growth [76]. A study conducted in the Southern High Plains showed that a very sandy soil (the Brownfield soil series) with high slope consistently had low yield when given the same amount of irrigation water, fertilizer, seed population, and other management practices [56]. A cross-correlation study conducted between cotton lint yield, soil water, clay, sand and elevation in a 45-ha field in Texas High Plains also showed that correlation among these factors varied between 0.72 and 0.63 and cotton crop and soil physical properties could be correlated within 60 to 80 m across the field [77]. In summary, soil texture influences variability in water availability and crop yield, and hence should be considered in VRI planning and implementation [78]. 3.2.2. Soil Organic Matter (SOM) The role of SOM in VRI lies in its influence on water-holding capacity because the affinity SOM has for water [74]. SOM has a positive influence on yield, and the influence is more prominent in soils with low organic matter content [60]. SOM distribution in the field is variable depending upon topography and other soil properties. Accumulation of SOM often occurs at the bottom of slopes, possibly due to the run-off of organic matter from higher areas and increased plant growth at low-lying wet areas of the field [60,61]. SOM generally increases with increasing clay content. The organic matter in fine-textured soils such as clay can be two to four times that of coarse-textured sandy soils under similar climatic conditions, which in turn, can influence soil water holding capacity [79]. Therefore, understanding the organic matter distribution in the field can help in estimation of irrigation requirements for the field and hence should be incorporated in developing site-specific water management. 3.2.3. Soil Biological Properties Most site-specific studies did not consider spatial variability of soil organisms, but recent studies have shown that the spatial distribution of soil organisms influence plant growth and possibly yield [80]. Spatial and temporal distribution of microorganisms at the landscape scale is complicated by the interactions among topography, soil type and distribution of water in the field [81]. The management activity in the field can influence the distribution of soil biological components and this, in turn, affects the efficiency of agricultural management [82]. The soil has the greatest microbial diversity among all ecosystems that support soil conditioning and plant growth [83]. A study conducted in France [84] showed that microbial indicators expressed a high spatial heterogeneity at the field level, which masked the effects of several soil and crop management treatments. The results also showed that the spatial variability due to biological variables was similar in magnitude as compared to that exhibited by physicochemical parameters, which indicated the feasibility of site-specific management of biological variability in the field using management zones. Such site-specific management can be effective since organisms such as earthworms, protozoa, nematodes, bacteria, fungi, and different arthropods play a vital role in soil fertility and productivity [71]. 3.2.4. Apparent Soil Electrical Conductivity (ECa) Obtaining accurate information about the spatial and temporal variability of SWC and irrigation requirements is one of the important challenges in site-specific water management. ECa is a measurement of field variability that can be applied to precise water management because it is easy to measure and facilitates the spatial understanding of the soil-water-plant relationship [85]. ECa is a function of several soil properties, such as soil salinity, texture, bulk density, ion concentration, type and amount of clay, topsoil thickness, and water content [86]. The effect of ECa on crop yield is through its relation to soil properties, which depends on climate, crop type and other specific field conditions [87]. In general, high ECa is associated with high clay content in the soil [88]. For example, a study conducted near Lamesa, Texas, showed that in four of the six sites, shallow ECa measured with a Veris mapping system was positively correlated with clay content. Clay content was negatively related to shallow ECa at one site due to the low bulk density of the calcic horizon [89]. Most of the research conducted did not consider the spatial correlation of soil characteristics when evaluating their distributions. However, spatial autocorrelation of soil properties can be more important than soil properties themselves in explaining ECa. Therefore, future studies need to incorporate the spatial correlation of soil characteristics in evaluating the impact of ECa on crop yield [90]. ECa has the potential to differentiate between soils when the soils have enough water content and can be used as an indicator of SWC. In general, areas with high ECa are associated with high water content [91]. Several studies have shown a higher correlation of crop growth characteristics and yield with ECa [92,93]. A study showed that ECa in combination with topographic attributes and bare soil brightness could explain up to 70.1% of the variability in cotton yield [56]. Hence, understanding the spatial and temporal variability of ECa provides information for site-specific irrigation management for optimized yield. The association between crop yield and soil physical and chemical properties and landscape processes provide opportunities to improve water management at the landscape scale [61]. Soil properties and topography influence crop yield from microscales to watershed scales and the magnitude of complexity increases with the scale due to an increase in soil and topographical variability, as well as variability in rainfall, temperature and other climatic factors [60]. A study showed lower corn grain and stover yield in depositional and flat areas which retained water for longer periods, and high yield at well-drained summit positions [94]. In the same research for alfalfa and poplar, the results showed higher productivity at a site with a relatively steep slope and potentially erosive soils. This relationship was attributed to the above-normal rainfall in both years of study. In a six-year study to understand corn yield in relation to terrain attributes, two years with more than normal precipitation showed a positive correlation between yield and slope. For the other four years, yield was negatively correlated with slope [55]. Crop yield in relation to soil properties and topography depends on different soil management and climate conditions. The correlation was found to be stronger for dry years in degraded soils and attributed to differences in water availability. This suggests that variable-rate irrigation strategies might require adjustments in different crop seasons with different climatic and management conditions and hence more researches on VRI are needed [95]. 4. Crop and Soil Monitoring for Precision Water Management Water requirement varies with the crop and crop growth and development status, soil water status, as well as environmental conditions. Closely monitoring soil water status, crop growth conditions and their spatial and temporal patterns can aid in irrigation scheduling and precise water management. Among many tools, remote sensing can serve an effective basis by providing images with spatial and temporal variability of crop growth parameters and soil moisture status for input in precision water management. 4.1. Crop Coefficient and ET VRI aims at increasing WUE and stabilizing yield, which can be improved by scheduling the irrigation of crops using physical and agronomic principles in irrigation management strategy. WUE (kg/m3) can be expressed as the ratio of the amount of target product of the crop to the amount of water applied to produce that output. The amount of water used for crop production is the amount required to overcome the water lost by ET from plant and soil surface, and it varies spatiotemporally according to weather and vegetation cover conditions [96,97]. Climatological parameters such as solar radiation, air temperature, air humidity, wind speed, and crop and soil water characteristics, including management and environmental aspects, are important parameters influencing ET in agricultural fields. Since ET is difficult to measure, reference ET from a hypothetical grass reference surface is commonly calculated using the FAO Penman-Monteith equation based on meteorological parameters [98]. The equation is expressed as follows, ET0 = [0.408 \u0394 (Rn \u2212 G) + \u03b3 {900/(T + 273)} u2 (es \u2212 ea)]/[\u0394 + \u03b3 (1 + 0.34 u2)] where, ET0\u2014Reference evapotranspiration [mm day\u22121], Rn\u2014Net radiation at the crop surface [MJ m\u22122 day\u22121], G\u2014Soil heat flux density [MJ m\u22122 day\u22121], T\u2014Air temperature at 2 m height [\u00b0C], u2\u2014Wind speed at 2 m height [m s\u22121], es\u2014Saturation vapor pressure [kPa], ea\u2014Actual vapor pressure [kPa], es\u2014ea saturation vapor pressure deficit [kPa], D\u2014Slope vapor pressure curve [kPa \u00b0C\u22121], \u03b3\u2014Psychrometric constant [kPa \u00b0C\u22121]. Crop-specific evapotranspiration needs are calculated based on crop coefficients (Kc). By using the FAO Penman-Monteith definition for ET0, crop coefficients at research sites could be calculated by relating the measured crop evapotranspiration (ET) with the calculated ET0, i.e., Kc = ET/ET0. The crop coefficient differs widely between crops and among growth stages for the same crop. This Kc factor serves as an aggregation of the physical and physiological differences among crops and averaged effects of evaporation from the soil [98]. Several spatial models have been developed for ET estimation, which showed that accurate spatial ET and water-balance models could be of great importance in VRI application [61,99,100]. 4.2. Remote and Proximal Sensing Besides crop coefficient and ET, mapping soil properties in a field, such as field capacity and root zone water availability, is also important for site-specific water management [101]. Information regarding variability of plant conditions such as water stress, growth parameters, ground cover can also provide a basis for VRI. Remote sensing using various sensors and platforms is often used to estimate several soil and crop characteristics during the growing season that can provide important information in decision support. The near-real-time information from several sensors, such as spectral reflectance sensors and infrared thermometers have been used to develop field maps for water, vegetation, and nutrient status [50,102]. Remotely sensed images can be useful in determining leaf area index and ground cover for a field and thus help in yield forecasting [103]. Remote sensing can also help estimate ET more reliably from individual fields [104]. A study in Nebraska evaluated remote-sensing-based ET and a water-balance model for irrigation management [105]. In this study, four irrigation treatment combinations were tested: VRI based on water-balance model using remote sensing, VRI based on water-balance model using neutron probe, uniform irrigation based on neutron-probe measurement and rainfed. Landsat 7 and 8 imageries were used for model input in a remote sensing-based model, which included reflectance-based crop coefficients for ET estimation. The result showed that remote sensing-based treatment had the greatest mean prescribed irrigation, which was attributed to water-balance drift. The study concluded that the remote-sensing-based model might perform better when coupled with SWC measurement. This can be helpful in site-specific management of irrigation water, as well as weedicide, pesticide and other chemicals [106,107,108]. Various indices derived from thermal and multispectral images, such as crop water stress index (CWSI), perpendicular vegetation index (PVI), normalized difference vegetation index (NDVI) and photochemical reflectance index (PRI), can predict soil or plant water status and drought stress as a basis for site-specific water management [109,110]. Use of digital infrared thermography to measure canopy temperature can help producers to detect early crop water stress and avoid yield declines as well as saving water with site-specific irrigation management and irrigation scheduling [111,112]. Recent improvements in remote and proximal sensing technologies such as wireless soil moisture sensors and unmanned aerial systems (UAS) have increased the efficiency for farmers to exercise site-specific irrigation management. Indices derived from high-resolution UAS imagery have shown the potential to predict crop water stress indicators such as water potential and stomatal conductance [113]. Such information can aid in improving irrigation efficiency, reducing pumping costs, and retaining groundwater. Although soil moisture sensors are found to be more profitable in the present context, with the increasing number of manufacturers and clear regulations, UAS-based sensor technology for soil moisture estimation is gaining momentum [114]. This explains the importance of remote sensing as a low-cost tool to improve water management in crops. 5. Precision Water Management Strategies Several precision irrigation technologies have been developed to improve crop productivity under water-limited conditions. However, appropriate precision irrigation strategies are equally important for increased efficiency and profitability for site-specific technologies. The development and application of management zones using spatial and temporal information of various agronomic factors have been practiced for site-specific management for several decades. In recent years, the use of artificial intelligence in prescription map development for site-specific water management is also increasing. 5.1. Management Zones VRI is often implemented in the field by dividing it into a number of sections, or management zones with the aim to save water and other inputs together with yield optimization [25]. A management zone is a subfield area that is relatively homogeneous in soil and topographic attributes. The use of management zones can be a convenient means to capture the spatial distribution of yield-influencing factors within the season. The information on spatial and temporal development of abiotic and biotic stresses can be linked with site-specific irrigation systems via dynamic prescription maps to help producers improve irrigation WUE, agricultural sustainability and the environment [102]. Various factors such as soil properties, landscape attributes, crop properties, sensor-based information, management practice, weed, and pest management as well as crop modeling have been considered in delineating management zones for VRI application since several years [115]. Soil properties such as soil organic matter, texture, nutrient content, pH, color, soil moisture content and water-holding capacities, ECa, etc. have been used effectively in management zone delineation [116,117,118,119]. Landscape attributes such as elevation, slope, aspect, curvature, and others have also been an important part of management zone delineation in several studies [118,120,121,122]. Numerous studies have used crop properties such as yield maps and ground-based leaf area index to delineate management zones for VRI application [116,117,123,124]. The management zones delineated based on yield data from multiple years can effectively capture nutrient variability in the field [125]. However, the application of yield maps for site-specific management can be challenging because spatial and temporal variation in yield is affected by the interactions among several biotic and abiotic factors [126,127]. Information from proximal and remote sensing such as satellite and airborne imagery, normalized difference vegetation index, digital photography, etc. can be a powerful approach for delineation of relative productive areas [128,129,130,131]. The zone information together with early season environmental indicators and crop response models can also be used to determine the action decisions throughout the season [132]. Similarly, the selection of factors for management zone delineation is equally important in management zone delineation. A study was conducted to compare the site-specific irrigation with conventional uniform irrigation management for potatoes in Idaho [25]. The available water-holding capacity of soil was used to delineate a 2.9-ha field into nine management zones. The results showed that six out of nine management zones produced a higher yield with site-specific management. However, the study suggested that management zones were only based on available SWC and in some management cases, other non-measured factors unrelated to soil texture or available water content could have an impact on the yield of crops. The study pointed out the importance to take into consideration all the known factors affecting yield and include them in delineating irrigation management zones for site-specific irrigation management. The optimum number of zones for a field depends on the scale of the field, economical and logistical practicality, and agronomic response to irrigation amounts. For example, the quantity and placement of soil moisture sensors for determining irrigation amounts may vary with field size, cost of the sensors and manageability, which, in turn, can influence the number of management zones in the field [133]. There are several methods to delineate management zones, including unsupervised clustering, supervised clustering, user-defined thresholds, etc. The clustering technique groups similar data points into different classes using algorithms such as k-means, fuzzy k-means, fuzzy c-means [127,134], Ward\u2032s method, and Jenk\u2019s optimization procedure [125]. The appropriate factors to be considered for management zone delineation could be prioritized using several methods such as principal component analysis (PCA) [118]. It is equally important to determine the number of optimum management zones for the field and their production and economic justification [20]. A software program (MZA software [135]) was developed for creating management zones using the fuzzy k-means method. This program determines the appropriate number of zones for a field by evaluating the clustering results. Many studies have used management zones for VRI and other site-specific crop management. For example, a study conducted in a 4.8-ha field in Colorado assessed the effectiveness of ECa in characterizing the spatial distribution of soil water [136]. This study found that SWC was significantly different among different ECa derived management zones using MZA software. This justifies the importance of characterizing management zones for site-specific water management. 5.2. Development of Site-Specific Water Management Strategies To enable the VRI technology in practice, the irrigation management strategy is equally important. The use of technology in the field may not always be effective in terms of final yield or profitability. For example, research has shown that the use of VRI technology may not be cost effective where there is high rainfall throughout the growing season [29]. Several strategies could be applied to save water and energy in the field to gain yield benefits in the field. Some of the strategies include skipping irritation in non-cropped areas, planting different crops in the same field, rainfall harvesting in areas with high water-holding capacity, and lowering irrigation to areas with low water use (ET) [46]. New irrigation strategies such as modifying the current irrigation system for site-specific water and chemical applications are required to sustain modern irrigated agricultural cropping systems [102]. Management strategies including placement and timing are crucial in optimizing irrigation throughout the growing season. About 9%\u221219% of irrigation water savings were achieved with VRI compared to the uniform application in a research conducted in variable soil, which was possible with several strategies such as withholding irrigation during specific growth stages and in particular, non-cropped areas of the field [137]. Further, the study suggests that areas where the optimized or increased irrigation does not produce an increase in yield, less water can be applied while the areas with high yield potential can be applied optimum irrigation and gain higher returns. A study showed that restricting irrigation during the peak water-demand time of cotton (80\u2212100 days after planting) from 100% to 60% of potential ET conserves 2.6 inches of water [138]. The VRI trial was conducted in three farms in New Zealand to compare the VRI to uniform rate irrigation (URI) [139]. The URI treatments were provided with the same level of irrigation at the same time as the most drought-prone soil zone, but VRI treatment was achieved by either delaying the irrigation or reducing the amount and intensity of irrigation comparing to that with a drought-prone area. The results showed that there was a two to three-fold difference in total available water-holding capacity at each site, which justified the decision to use VRI systems. Although the study found no significant impact of VRI on crop yield, water savings of 8 to 36% were achieved in three sites with less drainage. Hence, critical management strategies adopted in a decision support system that uses real-time monitoring and feedback to irrigation control make water conversation possible [28]. Deficit irrigation (DI) is a complementary method that uses irrigation scheduling at strategic times of less critical growth for irrigation water conservation. In this method, irrigation is applied during the drought-sensitive growth stages of a crop. During less drought-sensitive stages, irrigation is applied based on rainfall and availability of water for maintenance [140]. The use of technology and strategies can also affect the level of profit achieved from the VRI technology itself. A study was conducted in a 20-ha wheat field in Southern Alberta, Canada on modeling economic returns at different levels of control [141]. A total of 62 management scenarios were studied, including (1) no irrigation, (2) uniform irrigation management, (3) speed control with two angular increments of 2 and 10 degrees, and (4) zone control with a combination of two angular increments and a different number of independent irrigation zones, ranging from 2 to 30. The study concluded that the highest profit was obtained with 30 control zones. However, considering the cost of the technology, the case of ten control zones along the central pivot system was found to be the most profitable. Hence, it is essential to set forth effective site-specific water management strategies for increased agricultural sustainability and profitability. 5.3. Artificial Intelligence and Deep Learning Existing site-specific management utilizes several control strategies such mathematical modeling of crop yield or the plant-soil-atmosphere environment, optimizing irrigation application timing, learning sensor feedback to control the site-specific flow of water as well as using predictive model control that executes a model repeatedly to determine optimum input. The use of artificial intelligence or neuro-dynamic programming that integrates machine learning to determine the water application parameter for optimized irrigation is also increasing [50,142,143,144,145]. Hyperspectral remote sensing imaging along with machine learning has been in use in agricultural industry, and it is estimated that machine learning/deep learning-based classification has a significant potential for high-dimensional big data produced in agriculture [146]. 6. Impact of Variable-Rate Irrigation VRI can be highly effective in reducing water use and increasing water use efficiency (WUE) of crops [147]. A review on VRI across different crop and weather regimes of the world concluded that VRI could save 10%\u221215% of water [28]. A study in a 7-ha sugar beet field in Germany reported that 13% of water was saved compared to the uniform application [15]. This was achieved by utilizing stored soil moisture and in-season precipitation. In a study in New Zealand comparing VRI with conventional irrigation system, 9%\u221219% irrigation water was saved with VRI in pasture and corn fields, which in turn reduced nitrogen leaching [137]. Similarly, the application of VRI by manipulating its several components can reduce water runoff by avoiding excess water application in the field [28]. At a large scale, water pumpage and use can be reduced by adopting VRI. A geospatial method has been provided for potential VRI technology adopters to achieve potential water savings in the field using freely available datasets such as soil survey data from the Natural Resources Conservation Service (NRCS) [48]. In this study, the difference in application depth between conventional irrigation and VRI was estimated based on root zone available water capacity. The undepleted soil water from each management zone was mined using prescription maps allowing 50% depletion. VRI in this study resulted in a reduction in irrigation depth of up to 18 mm, pumping reductions, and improved water distribution throughout the field. In addition, higher VRI control resolution increased energy savings. VRI was found to reduce pumpage in more than 13% of center pivot irrigated fields by 25 mm per year compared to the conventional irrigation system in Nebraska [99]. Another study for VRI management based on soil water spatial variation was conducted in a 1.64-ha field with center pivot to understand the yield and water-saving effects of VRI [148]. In this study, the field was divided into four management zones based on available water-holding capacity and each management zone was further divided into two sections for VRI and URI management. The results from this study indicated that the impact of VRI on water savings within zones depended on weather conditions. Water savings with VRI management was higher for summer maize when the rainfall was high compared to winter wheat grown in no-rainfall weather. The study suggests that although VRI management had no significant influence on crop growth parameters and yield within a management zone, managing the zones with different available water-holding capacity might improve the uniformity of crop growth, maximize crop yield and gain potential water savings. Compared to the uniform application, VRI increases crop productivity. The results comparing the water productivity of sorghum and corn showed that there was more than 20% increase in water productivity for both crops using VRI [35]. Another study conducted in a 4-ha field, VRI resulted in a significant difference in corn yield in a dry year. However, the results were not significant for the year when the rain was sufficient [100]. Another study was conducted in New Zealand to understand the impact of variable-rate irrigation based on soil moisture status [139]. This study showed that although the yield was not significantly different among different irrigation treatments, water savings of 27\u201355 mm was achieved by limiting irrigation in soil with adequate plant available water and non-irrigating poorly drained, wet soil zones. VRI has been found effective to reduce water and energy use even in humid areas of the world with uncertain and unpredictable rainfall [40]. This study showed that potential water savings of 20mm/year could be achieved using VRI in these regions. However, the feasibility and effectiveness of VRI depend on the magnitude of the field, crop under consideration, weather and the underlying field properties [24,25,40]. The accurate determination of water requirement and its management is crucial for crop yield stabilization and improved average yield [53]. Several VRI research projects attempt to enhance the control scenarios as well as model and production function to improve water savings and reduce pumpage [40,99,141,149,150]. Further, it is necessary to understand the impact of soil water availability on crop growth to manage irrigation in spatial and temporal scales using variable-rate irrigation technologies and appropriate strategies. 7. Challenges and Research Requirements Data collection and management tools, such as yield monitors, sensors and sensing systems, GIS, GNSS, and decision support systems are available today to enable site-specific management of irrigation water for optimized crop production. Steady development in irrigation control systems provides the user with various options to implement VRI. Many studies have investigated and developed irrigation strategies, prescription methodologies, and profitability optimization involved in VRI. However, there are some challenges in the implementation and application of this technology. Further research and development are required to improve the understanding, implementation, and adoption of precision water management strategies and technologies. (1)\u2003Research is required on the integration of technology, agronomy, and profitability with VRI Although several studies have reported the potential of adopting VRI system to optimize crop production and profitability [29,70], some studies conducted in experimental fields have concluded that the VRI technology may not be economically viable for all crops under all growing conditions and environments [24]. This is not because of the yield-related benefit, but due to the cost of the technology itself. For example, research conducted in a 12.6-ha field in southwest Georgia showed that VRI generated $16/ha more return than URI. Although this return is not significant for this small field, the study suggested that profits could be amplified for large fields and benefit farmers [151]. From the agronomic perspective, a better understanding of the extremities of field variability and how it affects crop yield is needed for the effective implementation of new technologies [152]. In an experiment conducted in Tennessee, the same level of irrigation did not result in the same cotton lint yield in all parts of the field due to differences in texture and available water-holding capacity [153]. In some cases, the incorporation of other crops in a rotation in VRI can make this technology economically viable [25]. Additionally, most of the VRI studies are concentrated on the control scenarios of VRI [149,150]. Although a few studies [40,99,141] determined water and energy savings using VRI due to managerial limitations, they were either based on some model and production functions or arbitrary in irrigation rate determination. Hence, there is a need for a comprehensive study on VRI integrating the agronomic, technical and managerial aspects of VRI to determine its profitability, sustainability, and adoptability for various conditions. (2)\u2003On-farm and whole-field research Producers are more likely to adopt VRI if the benefits are shown on a \u201creal farm.\u201d Most of the previous studies on VRI were conducted in experimental fields or in small fields that cannot represent the commercial farming practice [28]. Experimental design and implementation in large fields are challenging. This type of research requires close communication and collaborative management between the researcher and the farm owner to ensure the alignment of management practices and study goals. Acquiring data and information from large fields is costly and time-consuming. In addition, the statistical analysis of on-farm data is challenging due to the lack of adequate tools that integrates classical statistical methods and spatial analysis. This creates challenges in the understanding of the relationship between crop growth and its environment in site-specific irrigation. More on-farm studies are needed to provide information for practical VRI applications. In addition, insufficient recognition of temporal variation and environmental impact are several other factors that hinder the adoption of precision agriculture technology [9]. (3)\u2003Prescription map development The majority of previous studies for prescription maps (management zone delineation) are for variable-rate application of fertilizers and seeds and are static [20,133]. Limited research has addressed the need for dynamic prescription map development that could incorporate seasonal changes in crop growth and conditions [133]. More research is required to evaluate VRI prescription maps or management zone development integrating different soil and crop characteristics under different environments. Use of remote and proximal sensing such as infrared sensors, near-infrared and thermal images, along with weather data can provide information on crop, soil, and environmental conditions in irrigation scheduling and developing dynamic prescription maps [97]. Further research needs to investigate how to integrate such data and information to evaluate the effectiveness of such prescription maps during the growing season. (4)\u2003Optimal spatial and temporal scale Few studies have evaluated the appropriate spatial and temporal scales for VRI application. Many studies have explored the use of sensors in acquiring information for modeling crop evapotranspiration, SWC, irrigation needs including the nutrient requirements [97,105,152,154,155]. Most of these studies indicated the high potential of remote and proximal sensing technologies in understanding spatial and temporal variations in crop growth conditions in the field. Temporal variability in soil water status and crop growing conditions require dynamic adjustment of irrigation amount and spatial distribution. Therefore, simulation models or on-farm studies might be considered to assess the effectiveness of VRI at different spatial and temporal scales. (5)\u2003Comprehensive decision support tools Precision irrigation management requires data and information from crop growth conditions, soil physical and chemical properties, weather factors, and the interaction among these factors. Effective implementation of precision irrigation requires a comprehensive decision support system to process and integrate different layers of data and information [48]. The challenge for the application of VRI still exists in the lack of user-friendly decision support tools such as for developing dynamic prescription maps [105]. Several decision support systems such as AgriDSS are available [16,156], but producers are reluctant to use them to their full potential due to their complexity. Also, these tools are based on what scientists and developers consider as necessary knowledge that should be implemented in the decision support system. However, in a real-world situation, they fail to utilize the implicit knowledge of farmers and address their needs. The complexity, lack of observability and confidence, poor user interface design, lack of incentive to learn are some of the other reasons behind the hindrance of adoption of different decision support tools [16]. The system or tool should help the user decide where to apply how much irrigation water at various crop growth stages to achieve the highest profit based on the regional climate conditions and cropping systems. (6)\u2003Integrating VRI with other inputs Few studies have integrated variable-rate application of nutrients with water. Crop yield response to water and N are not the same at different parts of the field [157], indicating the need for studying the interaction of water and fertilizer in variable-rate irrigation. Site-specific application of N together with irrigation using remote sensing can help reduce N inputs by 50% and leaching by 85% without reducing yields [155]. Further studies are needed to investigate the interaction between VRI fertilizers and other inputs to improve the efficiencies of water and fertilizers while reducing the environmental impact of fertilizer application and enhancing production sustainability. Author Contributions The authors contributed equally to the writing and organization of this paper. Funding The authors wish to acknowledge the support for this research provided by Cotton Incorporated, Texas Tech University, and the Texas Alliance for Water Conservation funded through the Texas Water Development Board. Conflicts of Interest The authors declare no conflict of interest. References United Nations. World Population Prospects: The 2017 Revision, Key Findings and Advance Tables; Working Paper No. ESA/P/WP/248; Department of Economic and Social Affairs, Population Division: New York, NY, USA, 2017. [Google Scholar] Mauget, S.A.; Adhikari, P.; Leiker, G.; Baumhardt, R.L.; Thorp, K.R.; Ale, S. Modeling the effects of management and elevation on West Texas dryland cotton production. Agric. For. Meteorol. 2017, 247, 385\u2013398. [Google Scholar] [CrossRef] McGuire, V.L. Water-level changes and change in water in storage in the High Plains aquifer, predevelopment to 2013 and 2011\u20132013. U.S. Geol. Surv. Sci. Investig. Rep. 2014, 14. [Google Scholar] [CrossRef] Mauget, S.; Leiker, G.; Nair, S. A web application for cotton irrigation management on the U.S. Southern High Plains. Part I: Crop yield modeling and profit analysis. Comput. Electron. Agric. 2013, 99, 248\u2013257. [Google Scholar] [CrossRef] Tak\u00e1cs, S.; B\u00edr\u00f3, T.; Helyes, L.; P\u00e9k, Z. Variable rate precision irrigation technology for deficit irrigation of processing tomato. Irrig. Drain. 2018. [Google Scholar] [CrossRef] Khosla, R.; Fleming, K.; Delgado, J.A.; Shaver, T.M.; Westfall, D.G. Use of site-specific management zones to improve nitrogen management for precision agriculture. J. Soil Water Conserv. 2002, 57, 513\u2013518. [Google Scholar] [CrossRef] De Caires, S.A.; Wuddivira, M.N.; Bekele, I. Spatial analysis for management zone delineation in a humid tropic cocoa plantation. Precis. Agric. 2015, 16, 129\u2013147. [Google Scholar] [CrossRef] McKinion, J.M.; Jenkins, J.N.; Akins, D.; Turner, S.B.; Willers, J.L.; Jallas, E.; Whisler, F.D. Analysis of a precision agriculture approach to cotton production. Comput. Electron. Agric. 2001, 32, 213\u2013228. [Google Scholar] [CrossRef] McBratney, A.; Whelan, B.; Ancev, T.; Bouma, J. Future directions of precision agriculture. Precis. Agric. 2005, 6, 7\u201323. [Google Scholar] [CrossRef] Searcy, S.W.; Schueller, J.K.; Bae, Y.H.; Borgelt, S.C.; Stout, B.A. Mapping of Spatially Variable Yield during Grain Combining. Trans. ASAE 1989, 32, 826\u2013829. [Google Scholar] [CrossRef] Robert, P. Characterization of soil conditions at the field level for soil specific management. Geoderma 1993, 60, 57\u201372. [Google Scholar] [CrossRef] Robert, P.C. Precision Agriculture: An Information Revolution in Agriculture. Agric. Outlook Forum 1999, 53, 1689\u20131699. [Google Scholar] [CrossRef] Blackmore, S. Precision farming: An introduction. Outlook Agric. 1994, 23, 275\u2013280. [Google Scholar] [CrossRef] Olson, K. Precision agriculture: Current economic and environmental issues. In Proceedings of the Sixth Joint Conference on Food, Agriculture, and the Environment, Minneapolis, MN, USA, 31 August\u20132 September 1998. [Google Scholar] Al-Kufaishi, S.A.A.; Blackmore, B.S.S.; Sourell, H. The feasibility of using variable rate water application under a central pivot irrigation system. Irrig. Drain. Syst. 2006, 20, 317\u2013327. [Google Scholar] [CrossRef] Lindblom, J.; Lundstr\u00f6m, C.; Ljung, M.; Jonsson, A. Promoting sustainable intensification in precision agriculture: Review of decision support systems development and strategies. Precis. Agric. 2017, 18, 309\u2013331. [Google Scholar] [CrossRef] Odeha, I.O.A.; McBratney, A.B.; Chittleborough, D.J. Spatial Prediction of Soil Properties from Landform Attributes Derived from a Digital Elevation Model. Geoderma 1994, 63, 197\u2013214. [Google Scholar] [CrossRef] Rains, G. Precision Farming: An Introduction. 2009. Available online: https://athenaeum.libs.uga.edu/bitstream/handle/10724/12223/b1186.pdf?sequence = 1 (accessed on 16 January 2019). Howell, T.A. Enhancing Water Use Efficiency in Irrigated Agriculture. Agron. J. 2001, 93, 281\u2013289. [Google Scholar] [CrossRef] Evans, R.G.; LaRue, J.; Stone, K.C.; King, B.A. Adoption of site-specific variable rate sprinkler irrigation systems. Irrig. Sci. 2013, 31, 871\u2013887. [Google Scholar] [CrossRef] Payero, J.; Khalilian, A. What Is Variable Rate Irrigation? 2017. Available online: https://www.clemson.edu/extension/publications/files/agronomic-crops/AC08What-is-variable-rate-irrigation.pdf (accessed on 14 June 2018). Zhao, W.; Li, J.; Yang, R.; Li, Y. Determining placement criteria of moisture sensors through temporal stability analysis of soil water contents for a variable rate irrigation system. Precis. Agric. 2018, 19, 648\u2013665. [Google Scholar] [CrossRef] Vachaud, G.; Passerat De Silans, A.; Balabanis, P.; Vauclin, M. Temporal stability of spatially measured soil water probability density function. Soil Sci. Soc. Am. J. 1985, 49, 822. [Google Scholar] [CrossRef] Lu, Y.-C.; Sadler, E.J.; Camp, C.R. Economic feasibility study of variable irrigation of corn production in Southeast Coastal Plain. J. Sustain. Agric. 2005, 26, 69\u201381. [Google Scholar] [CrossRef] King, B.A.; Stark, J.C.; Wall, R.W.; Stark, J.C.; Wall, R.W. Comparison of Site-Specific and Conventional Uniform Irrigation Management for Potatoes. ASABE 2006, 22, 677\u2013688. [Google Scholar] Oliver, Y.M.; Robertson, M.J.; Wong, M.T.F. Integrating farmer knowledge, precision agriculture tools, and crop simulation modelling to evaluate management options for poor-performing patches in cropping fields. Eur. J. Agron. 2010, 32, 40\u201350. [Google Scholar] [CrossRef] Colaizzi, P.D.; Gowda, P.H.; Marek, T.H.; Porter, D.O. Irrigation in the Texas High Plains: A brief history and potential reductions in demand. Irrig. Drain. 2009, 58, 257\u2013274. [Google Scholar] [CrossRef] Sadler, E.J.; Evans, R.G.; Stone, K.C.; Camp, C.R. Opportunities for conservation with precision irrigation. J. Soil Water Conserv. 2005, 60, 371\u2013378. [Google Scholar] Evans, R.G.; King, B.A. Site-specific sprinkler irrigation in a water-limtied future. Adv. Irrig. 2012, 55, 493\u2013504. [Google Scholar] Li, J. Increasing crop productivity in an eco-friendly manner by improving sprinkler and micro-irrigation design and management: A review of 20 years\u2019 research at the IWHR, China. Irrig. Drain. 2018, 67, 97\u2013112. [Google Scholar] [CrossRef] Fraisse, C.W.; Heermann, D.F.; Duke, H.R. Modified linear move system for experimental water application. In Advances in Planning, Design, and Management of Irrigation Systems as Related to Sustainable Land Use; Center for Irrigation Engineering: Leuven, Belgium, 1992; pp. 367\u2013376. [Google Scholar] Sadler, E.J.; Camp, C.R.; Evans, D.E.; Usrey, L.J. A site-specific center pivot irrigation system for highly-variable coastal plain soils. Precis. Agric. 1996, 3, 827\u2013834. [Google Scholar] Evans, R.G.; Buchleiter, G.W.; Sadler, E.J.; King, B.A.; Harting, G.B. Controls for precision irrigation with self propelled systems. In Proceedings of the 2000 ASAE 4th decennial national irrigation symposium, St. Joseph, MI, USA, 14\u201316 November 2000; pp. 322\u2013331. [Google Scholar] National Agricultural Statistics Service. 2012 Census of Agriculture, Farm and Ranch Irrigation Survey; US Department of Agriculture: Washington, DC, USA, 2013. Sui, R.; Yan, H. Field study of variable rate irrigation management in humid Climates. Irrig. Drain. 2017, 66, 327\u2013339. [Google Scholar] [CrossRef] McClymont, L.; Goodwin, I.; Mazza, M.; Baker, N.; Lanyon, D.M.; Zerihun, A.; Chandra, S.; Downey, M.O. Effect of site-specific irrigation management on grapevine yield and fruit quality attributes. Irrig. Sci. 2012, 30, 461\u2013470. [Google Scholar] [CrossRef] S\u00e1nchez, L.; Mendez-Costabel, M.; Sams, B.; Morgan, A.; Dokoozlian, N.; Klein, L.J.; Hinds, N.; Hamann, H.F.; Claassen, A.; Lew, D. Effect of a variable rate irrigation strategy on the variability of crop production in wine grapes in California. In Proceedings of the 12th International Conference on Precision Agriculture, Sacramento, CA, USA, 20\u201323 July 2014. [Google Scholar] Proffitt, T.; Pearse, B. Adding value to the wine business precisely: Using precision viticulture technology in Margaret River. Aust. N. Z. Grapegrower Winemak. 2004, 492, 40\u201344. [Google Scholar] Nadav, I.; Schweitzer, A. VRDI\u2014Variable rate drip irrigation in vineyards. Adv. Anim. Biosci. 2017, 8, 569\u2013573. [Google Scholar] [CrossRef] Daccache, A.; Knox, J.W.; Weatherhead, E.K.; Daneshkhah, A.; Hess, T.M. Implementing precision irrigation in a humid climate\u2014Recent experiences and on-going challenges. Agric. Water Manag. 2015, 147, 135\u2013143. [Google Scholar] [CrossRef] Masseroni, D.; Moller, P.; Tyrell, R.; Romani, M.; Lasagna, A.; Sali, G.; Facchi, A.; Gandolfi, C. Evaluating performances of the first automatic system for paddy irrigation in Europe. Agric. Water Manag. 2018, 201, 58\u201369. [Google Scholar] [CrossRef] Vories, E.; Stevens, W.G.; Rhine, M.; Straatmann, Z. Investigating irrigation scheduling for rice using variable rate irrigation. Agric. Water Manag. 2017, 179, 314\u2013323. [Google Scholar] [CrossRef] Han, Y.J.; Khalilian, A.; Owino, T.O.; Farahani, H.J.; Moore, S. Development of Clemson variable-rate lateral irrigation system. Comput. Electron. Agric. 2009, 68, 108\u2013113. [Google Scholar] [CrossRef] Vellidis, G.; Tucker, M.; Perry, C.; Kvien, C.; Bednarz, C. A real-time wireless smart sensor array for scheduling irrigation. Comput. Electron. Agric. 2008, 61, 44\u201350. [Google Scholar] [CrossRef] Younker, B.J. Variable Rate Irrigation. Available online: https://www.nrcs.usda.gov/wps/portal/nrcs/detail/ks/newsroom/features/?cid = nrcs142p2_033511 (accessed on 10 February 2018). Peters, R.T.; Flury, M. Variable Rate Irrigation on Center Pivots. What Is It? Should I Invest? 2017. Available online: https://alfalfa.ucdavis.edu/+symposium/proceedings/2017/Peters%20Troy.pdf (accessed on 27 October 2018). Trimble Irrigate-IQ Variable Rate Irrigation|Trimble Ag. Available online: https://agriculture.trimble.com/precision-ag/applications/variable-rate-irrigation/ (accessed on 27 October 2018). Miller, K.A.; Luck, J.D.; Heeren, D.M.; Lo, T.; Martin, D.L.; Barker, J.B. A geospatial variable rate irrigation control scenario evaluation methodology based on mining root zone available water capacity. Precis. Agric. 2017, 1\u201318. [Google Scholar] [CrossRef] Yari, A.; Madramootoo, C.A.; Woods, S.A.; Adamchuk, V.I. Performance evaluation of constant versus variable rate irrigation. Irrig. Drain. 2017, 66, 501\u2013509. [Google Scholar] [CrossRef] McCarthy, A.C.; Hancock, N.H.; Raine, S.R. Development and simulation of sensor-based irrigation control strategies for cotton using the VARI wise simulation framework. Comput. Electron. Agric. 2014, 101, 148\u2013162. [Google Scholar] [CrossRef] Jiang, P.; Thelen, K.D. Effect of soil and topographic properties on crop yield in a north-central corn-soybean cropping system. Agron. J. 2004, 96, 252\u2013258. [Google Scholar] [CrossRef] Hanna, A.Y.; Harlan, P.W.; Lewis, D.T. Soil available water as influenced by landscape position and aspect. Agron. J. 1982, 74, 999\u20131004. [Google Scholar] [CrossRef] Silva, J.R.M.; Silva, L.L. Evaluation of the relationship between maize yield spatial and temporal variability and different topographic attributes. Biosyst. Eng. 2008, 101, 183\u2013190. [Google Scholar] [CrossRef] [Green Version] Moore, I.D.; Gessler, P.E.; Nielsen, G.A.; Peterson, G.A. Soil attribute prediction using terrain analysis. Soil Sci. Soc. Am. J. 1993, 57, 443\u2013452. [Google Scholar] [CrossRef] Kaspar, T.C.; Colvin, T.S.; Jaynes, D.B.; Karlen, D.L.; James, D.E.; Meek, D.W.; Pulido, D.; Butler, H. Relationship between six years of corn yields and terrain attributes. Precis. Agric. 2003, 4, 87\u2013101. [Google Scholar] [CrossRef] Guo, W.; Maas, S.J.; Bronson, K.F. Relationship between cotton yield and soil electrical conductivity, topography, and Landsat imagery. Precis. Agric. 2012, 13, 678\u2013692. [Google Scholar] [CrossRef] Brubaker, S.C.; Jones, A.J.; Lewis, D.T.; Frank, K. Soil Properties associated with landscape Position. Soil Sci. Soc. Am. J. 1993, 57, 235\u2013239. [Google Scholar] [CrossRef] Paz, J.; Batchelor, W.D.; Colvin, T.; Logsdon, S.; Kaspar, T.C.; Karlen, D.L. Analysis of water stress effects causing spatial yield variability of soybeans. Trans. ASABE 1998, 41, 1527\u20131534. [Google Scholar] [CrossRef] Jones, A.J.; Mielke, L.N.; Bartles, C.A.; Miller, C.A. Relationship of landscape position and properties to crop production. J. Soil Water Conserv. 1995, 50, 174\u2013179. [Google Scholar] Kravchenko, A.N.; Bullock, D.G. Correlation of corn and soybean grain yield with topography and soil properties. Agron. J. 2000, 92, 75\u201383. [Google Scholar] [CrossRef] Li, H.; Lascano, R.J.; Booker, J.; Ted Wilson, L.; Bronson, K.F. Cotton lint yield variability in a heterogeneous soil at a landscape scale. Soil Till. Res. 2001, 58, 245\u2013258. [Google Scholar] [CrossRef] Guzman, J.G.; Al-Kaisi, M.M. Landscape position effect on selected soil physical properties of reconstructed prairies in southcentral Iowa. J. Soil Water Conserv. 2011, 66, 183\u2013191. [Google Scholar] [CrossRef] Daniels, R.B.; Gilliam, J.W.; Cassel, D.K.; Nelson, L.A. Quantifying the effects of past soil erosion on present soil productivity. J. Soil Water Conserv. 1987, 42, 183\u2013187. [Google Scholar] Sinai, G.; Zaslavsky, D.; Golany, P. The effect of soil surface curvature on moisture and yield-beer sheba observation. Soil Sci. 1981, 132, 367\u2013375. [Google Scholar] [CrossRef] Si, B.C.; Farrell, R.E. Scale-dependent relationships between wheat yield and topographic indices: A Wavelet Approach. Soil Sci. Soc. Am. J. 2004, 68, 577\u2013587. [Google Scholar] [CrossRef] Timlin, D.; Pachepsky, Y.; Snyder, V.; Bryant, R.B. Spatial and temporal variability of corn grain yield on a hillslope. Soil Sci. Soc. Am. J. 1998, 62, 764\u2013773. [Google Scholar] [CrossRef] Delgado, A.; G\u00f3mez, J.A. The soil. Physical, chemical and biological properties. In Principles of Agronomy for Sustainable Agriculture; Springer: Cham, Switzerland, 2016; pp. 15\u201326. [Google Scholar] Batchelor, W.D.; Basso, B.; Paz, J.O. Examples of strategies to analyze spatial and temporal yield variability using crop models. Eur. J. Agron. 2002, 18, 141\u2013158. [Google Scholar] [CrossRef] Steiner, J.L.; Briske, D.D.; Brown, D.P.; Rottler, C.M. Vulnerability of Southern Plains agriculture to climate change. Clim. Chang. 2018, 146, 201\u2013218. [Google Scholar] [CrossRef] Duncan, H.A. Locating the Variability of Soil Water Holding Capacity and Understanding Its Effects on Deficit Irrigation and Cotton Lint Yield. 2012. Available online: http://trace.tennessee.edu/utk_gradthes/1286 (accessed on 27 October 2018). Osman, K.T. Biological properties of soils. In Soils: Principles, Properties and Management; Springer: Dordrecht, The Netherlands, 2013; pp. 113\u2013128. [Google Scholar] Delgado, J.A.; Ristau, R.J.; Dillon, M.A.; Duke, H.R.; Stuebe, A.; Follett, R.F.; Shaffer, M.J.; Riggenbach, R.R.; Sparks, R.T.; Thompson, A.; et al. Use of innovative tools to increase nitrogen use efficiency and protect environmental quality in crop rotations. Commun. Soil Sci. Plant Anal. 2001, 32, 1321\u20131354. [Google Scholar] [CrossRef] Dexter, A.R. Soil physical quality Part I. Theory, effects of soil texture, density, and organic matter, and effects on root growth. Geoderma 2003, 120, 201\u2013214. [Google Scholar] [CrossRef] Ball, J. Soil and Water Relationships, The Samuel Robert Nobel Foundation. 2001. Available online: http://www.noble.org/Ag/Soils/SoilWaterRelationships/Index.htm (accessed on 10 February 2018). Ping, J.L.; Green, C.J.; Zartman, R.E.; Bronson, K.F.; Morris, T.F. Spatial variability of soil properties, cotton yield, and quality in a production field. Commun. Soil Sci. Plant Anal. 2007, 39, 1\u201316. [Google Scholar] [CrossRef] Boenecke, E.; Lueck, E.; Ruehlmann, J.; Gruendling, R.; Franko, U. Determining the within-field yield variability from seasonally changing soil conditions. Precis. Agric. 2018, 19, 750\u2013769. [Google Scholar] [CrossRef] Li, H.; Lascano, R.J.; Booker, J.; Wilson, L.T.; Bronson, K.F.; Segarra, E. State-space description of field heterogeneity: Water and nitrogen use in cotton. Soil Sci. Soc. Am. J. 2002, 66, 585\u2013595. [Google Scholar] [CrossRef] Hake, K.D.; Grimes, D.W. Crop Water management to optimize growth and yield. In Physiology of Cotton; Springer: Dordrecht, The Netherlands, 2010; pp. 255\u2013264. [Google Scholar] FAO. The Importance of Soil Organic Matter: Key to Drought-Resistance Soil and Sustained Food Production. 2005. Available online: http://www.fao.org/3/a-a0100e.pdf (accessed on 27 October 2018). Ettema, C.H.; Wardle, D.A. Spatial soil ecology. Trends Ecol. Evol. 2002, 17, 177\u2013183. [Google Scholar] [CrossRef] Cavigelli, M.A.; Lengnick, L.L.; Buyer, J.S.; Fravel, D.; Handoo, Z.; McCarty, G.; Millner, P.; Sikora, L.; Wright, S.; Vinyard, B.; et al. Landscape level variation in soil resources and microbial properties in a no-till corn field. Appl. Soil Ecol. 2005, 29, 99\u2013123. [Google Scholar] [CrossRef] Houot, S.; Chaussod, R. Impact of agricultural practices on the size and activity of the microbial biomass in a long-term field experiment. Biol. Fertil. Soils 1995, 19, 309\u2013316. [Google Scholar] [CrossRef] Lehman, R.M.; Acosta-Martinez, V.; Buyer, J.S.; Cambardella, C.A.; Collins, H.P.; Ducey, T.F.; Halvorson, J.J.; Jin, V.L.; Johnson, J.M.F.; Kremer, R.J.; et al. Soil biology for resilient, healthy soil. J. Soil Water Conserv. 2015, 70, 12A\u201318A. [Google Scholar] [CrossRef] Peign\u00e9, J.; Vian, J.-F.; Cannavacciuolo, M.; Bottollier, B.; Chaussod, R. Soil sampling based on field spatial variability of soil microbial indicators. Eur. J. Soil Biol. 2009, 45, 488\u2013495. [Google Scholar] [CrossRef] Corwin, D.L.; Lesch, S.M. Application of Soil Electrical Conductivity to Precision Agriculture. Agron. J. 2003, 95, 455\u2013471. [Google Scholar] [CrossRef] Zhang, R.; Wienhold, B.J. The effect of soil moisture on mineral nitrogen, soil electrical conductivity, and pH. Nutr. Cycl. Agroecosyst. 2002, 63, 251\u2013254. [Google Scholar] [CrossRef] Kitchen, N.R.; Sudduth, K.A.; Drummond, S.T. Soil electrical conductivity as a crop productivity measure for claypan soils. J. Prod. Agric. 1999, 12, 607\u2013617. [Google Scholar] [CrossRef] Moral, F.J.; Terr\u00f3n, J.M.; Da Silva, J.R.M. Delineation of management zones using mobile measurements of soil apparent electrical conductivity and multivariate geostatistical techniques. Soil Till. Res. 2010, 106, 335\u2013343. [Google Scholar] [CrossRef] [Green Version] Bronson, K.F.; Booker, J.D.; Officer, S.J.; Lascano, R.J.; Maas, S.J.; Searcy, S.W.; Booker, J. Apparent electrical conductivity, soil properties and spatial covariance in the U.S. Southern High Plains. Precis. Agric. 2005, 6, 297\u2013311. [Google Scholar] [CrossRef] Wang, D.; Prato, T.; Qiu, Z.; Kitchen, N.R.; Sudduth, K.A. Economic and environmental evaluation of variable rate nitrogen and lime application for claypan soil fields. Precis. Agric. 2003, 4, 35\u201352. [Google Scholar] [CrossRef] Brevik, E.C.; Fenton, T.E.; Lazari, A. Soil electrical conductivity as a function of soil water content and implications for soil mapping. Precis. Agric. 2006, 7, 393\u2013404. [Google Scholar] [CrossRef] Kitchen, N.R.; Drummond, S.T.; Lund, E.D.; Sudduth, K.A.; Buchleiter, G.W. Soil electrical conductivity and topography related to yield for three contrasting soil-crop systems. Agronomy 2003, 95, 483\u2013495. [Google Scholar] [CrossRef] Stadler, A.; Rudolph, S.; Kupisch, M.; Langensiepen, M.; van der Kruk, J.; Ewert, F. Quantifying the effects of soil variability on crop growth using apparent soil electrical conductivity measurements. Eur. J. Agron. 2015, 64, 8\u201320. [Google Scholar] [CrossRef] Thelemann, R.; Johnson, G.; Sheaffer, C.; Banerjee, S.; Cai, H.; Wyse, D. The effect of landscape position on biomass crop yield. Agron. J. 2010, 102, 513\u2013522. [Google Scholar] [CrossRef] Terra, J.A.; Shaw, J.N.; Reeves, D.W.; Raper, R.L.; van Santen, E.; Schwab, E.B.; Mask, P.L. Soil management and landscape variability affects field-scale cotton productivity. Soil Sci. Soc. Am. J. 2006, 70, 98\u2013107. [Google Scholar] [CrossRef] Hanson, R.L. Evapotranspiration and droughts. U.S. Geol. Survey Water-Supply Pap. 1991, 2375, 99\u2013104. [Google Scholar] Gowda, P.H.; Chavez, J.L.; Colaizzi, P.D.; Evett, S.R.; Howell, T.A.; Tolk, J.A. Remote sensing based energy balance algorithms for mapping et: Current status and future challenges. Trans. ASABE 2007, 50, 1639\u20131644. [Google Scholar] [CrossRef] Allen, R.G.; Pereira, L.S.; Raes, D.; Smith, M. Crop evapotranspiration: Guidelines for computing crop water requirements. FAO Irrig. Drain. Pap. 1998, 56, 1\u201315. [Google Scholar] [CrossRef] Lo, T.H.; Heeren, D.M.; Martin, D.L.; Mateos, L.; Luck, J.D.; Eisenhauer, D.E. Pumpage reduction by using variable-rate irrigation to mine undepleted soil water. Trans. ASABE 2016, 59, 1285\u20131298. [Google Scholar] [CrossRef] Sui, R.; Fisher, D.K.; Reddy, K.N. Yield response to variable rate irrigation in corn. J. Agric. Sci. 2015, 7, 11. [Google Scholar] [CrossRef] Lo, T.; Heeren, D.M.; Mateos, L.; Luck, J.D.; Martin, D.L.; Miller, K.A.; Barker, J.B.; Shaver, T.M. Field characterization of field capacity and root zone available water capacity for variable rate irrigation. Biol. Syst. Eng. 2017, 33, 559\u2013572. [Google Scholar] [CrossRef] O\u2019Shaughnessy, S.A.; Rush, C. Precision agriculture: Irrigation. In Encyclopedia of Agriculture and Food System; Alfen, N.K.V., Ed.; Academic Press: Oxford, UK, 2014; pp. 521\u2013535. [Google Scholar] Baez-Gonzalez, A.D.; Kiniry, J.R.; Maas, S.J.; Tiscareno, M.L.; Macias, C.J.; Mendoza, J.L.; Richardson, C.W.; Salinas, G.; Manjarrez, J.R. Large-area maize yield forecasting using leaf area index based yield model. Agron. J. 2005. [Google Scholar] [CrossRef] Rajan, N.; Maas, S.J.; Kathilankal, J.C. Estimating crop water use of cotton in the Texas high plains. Agron. J. 2010, 102, 1641\u20131651. [Google Scholar] [CrossRef] Barker, J.B.; Heeren, D.M.; Neale, C.M.U.; Rudnick, D.R. Evaluation of variable rate irrigation using a remote-sensing-based model. Agric. Water Manag. 2018, 203, 63\u201374. [Google Scholar] [CrossRef] [Green Version] Camargo, A.; Smith, J.S. An image-processing based algorithm to automatically identify plant disease visual symptoms. Biosyst. Eng. 2009, 102, 9\u201321. [Google Scholar] [CrossRef] Burgos-Artizzu, X.P.; Ribeiro, A.; Tellaeche, A.; Pajares, G.; Fern\u00e1ndez-Quintanilla, C. Analysis of natural images processing for the extraction of agricultural elements. Image Vis. Comput. 2010, 28, 138\u2013149. [Google Scholar] [CrossRef] Zheng, L.; Zhang, J.; Wang, Q. Mean-shift-based color segmentation of images containing green vegetation. Comput. Electron. Agric. 2009, 65, 93\u201398. [Google Scholar] [CrossRef] Masseroni, D.; Ortuani, B.; Corti, M.; Gallina, P.M.; Cocetta, G.; Ferrante, A.; Facchi, A. Assessing the reliability of thermal and optical imaging techniques for detecting crop water status under different nitrogen levels. Sustainability 2017, 9, 1548. [Google Scholar] [CrossRef] Marino, S.; Aria, M.; Basso, B.; Leone, A.P.; Alvino, A. Use of soil and vegetation spectroradiometry to investigate crop water use efficiency of a drip irrigated tomato. Eur. J. Agron. 2014, 59, 67\u201377. [Google Scholar] [CrossRef] O\u2019Shaughnessy, S.A.; Evett, S.R.; Colaizzi, P.D.; Howell, T.A. A crop water stress index and time threshold for automatic irrigation scheduling of grain sorghum. Agric. Water Manag. 2012, 107, 122\u2013132. [Google Scholar] [CrossRef] [Green Version] O\u2019Shaughnessy, S.A.; Evett, S.R.; Colaizzi, P.D.; Howell, T.A. Using radiation thermography and thermometry to evaluate crop water stress in soybean and cotton. Agric. Water Manag. 2011, 98, 1523\u20131535. [Google Scholar] [CrossRef] Gago, J.; Douthe, C.; Coopman, R.E.; Gallego, P.P.; Ribas-Carbo, M.; Flexas, J.; Escalona, J.; Medrano, H. UAVs challenge to assess water stress for sustainable agriculture. Agric. Water Manag. 2015, 153, 9\u201319. [Google Scholar] [CrossRef] West, G.H.; Kovacs, K. Addressing groundwater declines with precision agriculture: An economic comparison of monitoring methods for variable-rate irrigation. Water 2017, 9, 28. [Google Scholar] [CrossRef] Khosla, R. Precision agriculture: Challenges and opportunities in a flat world. 2010. Available online: https://www.iuss.org/19th%20WCSS/Symposium/pdf/0779.pdf (accessed on 27 October 2018). Kitchen, N.R.; Hughes, D.F.; Sudduth, K.A.; Birrell, S.J. Comparison of variable rate to single rate nitrogen fertiliser application: Corn production and residual soil NO3-N. In Site-Specific Management for Agricultural Systems; American Society of Agronomy, Crop Science Society of America, Soil Science Society of America: Madison, WI, USA, 1995; pp. 427\u2013442. [Google Scholar] Basnet, B.; Apan, A.; Kelly, R.; Jensen, T.; Strong, W.; Butler, D. Delineation of management zones using multiple crop yield data. In Proceedings of the 16th Triennial Congress of the International Soil Tillage Research Organisation (ISTRO), Brisbane, Australia, 13\u201318 July 2003. [Google Scholar] Schepers, A.R.; Shanahan, J.F.; Liebig, M.A.; Schepers, J.S.; Johnson, S.H.; Luchiari, A. Appropriateness of management zones for characterizing spatial variability of soil properties and irrigated corn yields across years. Agron. J. 2004, 96, 195\u2013203. [Google Scholar] [CrossRef] Fleming, K.L.; Heermann, D.F.; Westfall, D.G. Evaluating soil color with farmer input and apparent soil electrical conductivity for management zone delineation. Agron. J. 2004, 96, 1581\u20131587. [Google Scholar] [CrossRef] Mzuku, M.; Khosla, R.; Reich, R.; Inman, D.; Smith, F.; MacDonald, L. Spatial variability of measured soil properties across site-specific management zones. Soil Sci. Soc. Am. J. 2005, 69, 1572. [Google Scholar] [CrossRef] Lark, R.M. Forming spatially coherent regions by classification of multi-variate data: An example from the analysis of maps of crop yield. Int. J. Geogr. Inf. Sci. 1998, 12, 83\u201398. [Google Scholar] [CrossRef] Franzen, D.W.; Hopkins, D.H.; Sweeney, M.D.; Ulmer, M.K.; Halvorson, A.D. Evaluation of soil survey scale for zone development of site-specific nitrogen management. Agron. J. 2002, 94, 381\u2013389. [Google Scholar] [CrossRef] Johnson, C.K.; Eskridge, K.M.; Wienhold, B.J.; Doran, J.W.; Peterson, G.A.; Buchleiter, G.W. Using electrical conductivity classification and within-field variability to design field-scale research. Agron. J. 2003, 95, 602\u2013613. [Google Scholar] [CrossRef] King, J.A.; Dampney, P.M.; Lark, R.; Wheeler, H.C.; Bradley, R.I.; Mayr, T.R. Mapping potential crop management zones within fields: Use of yield-map series and patterns of soil physical properties identified by electromagnetic induction sensing. Precis. Agric. 2005, 6, 167\u2013181. [Google Scholar] [CrossRef] Flowers, M.; Weisz, R.; White, J.G. Yield-based management zones and grid sampling strategies: Describing soil test and nutrient variability. Agron. J. 2005, 97, 968\u2013982. [Google Scholar] [CrossRef] Huggins, D.R.; Alderfer, R.D. Yield Variability Within a Long-Term Corn Management Study: Implications for Precision Farming. In Site-Specific Management for Agricultural Systems; Robert, P.C., Rust, R.H., Larson, W.E., Eds.; American Society of Agronomy, Crop Science Society of America, Soil Science Society of America: Madison, WI, USA, 1995; pp. 417\u2013426. [Google Scholar] Khosla, R.; Westfall, D.G.; Reich, R.M.; Mahal, J.S.; Gangloff, W.J. Spatial variation and site-specific management zones. In Geostatistical Applications for Precision Agriculture; Springer: Dordrecht, The Netherlands, 2010; pp. 195\u2013219. [Google Scholar] Corwin, D.L. Site-specific management and delineating management zones. In Precision Agriculture for Sustainability and Environmental Protection; Routledge: Abingdon, UK, 2013; pp. 136\u2013157. [Google Scholar] Schmidhalter, U.; Maidl, F.-X.; Heuwinkel, H.; Demmel, M.; Auernhammer, H.; Noack, P.; Rothmund, M. Precision Farming\u2014Adaptation of Land Use Management to Small Scale Heterogeneity. In Perspectives for Agroecosystem Management; Elsevier: Amsterdam, The Netherlands, 2008; pp. 121\u2013199. [Google Scholar] Inman, D.; Khosla, R.; Reich, R.; Westfall, D.G. Normalized difference vegetation index and soil color-based management zones in irrigated Maize. Agron. J. 2008, 100, 60\u201366. [Google Scholar] [CrossRef] Rab, M.A.; Fisher, P.D.; Armstrong, R.D.; Abuzar, J.; Robinson, N.J.; Chandra, S. Advances in precision agriculture in south-eastern Australia. IV. Spatial variability in plant-available water capacity of soil and its relationship with yield in site-specific management zones. Crop. Past. Sci. 2009, 60, 885\u2013900. [Google Scholar] [CrossRef] Whelan, B.; McBratney, A. Definition and interpretation of potential management zones in Australia. In Proceedings of the 11th Australian Agronomy Conference, Geelong, VIC, Australia, 2\u20136 February 2003. [Google Scholar] O\u2019Shaughnessy, S.A.; Evett, S.R.; Colaizzi, P.D. Dynamic prescription maps for site-specific variable rate irrigation of cotton. Agric. Water Manag. 2015, 159, 123\u2013138. [Google Scholar] [CrossRef] Barker, J.B.; Franz, T.E.; Heeren, D.M.; Neale, C.M.U.; Luck, J.D. Soil water content monitoring for irrigation management: A geostatistical analysis. Agric. Water Manag. 2017, 188, 36\u201349. [Google Scholar] [CrossRef] [Green Version] Fridgen, J.J.; Kitchen, N.R.; Sudduth, K.A.; Drummond, S.T.; Wiebold, W.J.; Fraisse, C.W. Management zone analyst (MZA): Software for subfield management zone delineation. Agron. J. 2004, 96, 100\u2013108. [Google Scholar] [CrossRef] De Lara, A.; Khosla, R.; Longchamps, L. Characterizing spatial variability in soil water content for precision irrigation management. Agronomy 2018, 8, 59. [Google Scholar] [CrossRef] Hedley, C.B.; Yule, I.J. Soil water status mapping and two variable-rate irrigation scenarios. Precis. Agric. 2009, 10, 342\u2013355. [Google Scholar] [CrossRef] Glodt, B.; Schur, L. Profit potential using split pivot irrigation strategies in cotton production. In Proceedings of the TAWC 4th Annual Water College, Lubbock, TX, USA, 17\u201324 January 2018. [Google Scholar] Hedley, C.; Ekanayake, J.; Mccarthy, A. Precision irrigation: Trials to assess impacts on crop yield. In Proceedings of the 18th Australian Society of Agronomy Conference, Ballarat, Australia, 24\u201328 September 2017. [Google Scholar] Kang, S.; Shi, W.; Zhang, J. An improved water-use efficiency for maize grown under regulated deficit irrigation. Field Crops Res. 2000, 67, 207\u2013214. [Google Scholar] [CrossRef] Huang, H.-H.; Adamchuk, V.; Madramootoo, C.; Yari, A. Economic optimization of the levels of control in variable rate irrigation (VRI). In 2015 ASABE/IA Irrigation Symposium: Emerging Technologies for Sustainable Irrigation; American Society of Agricultural and Biological Engineers: St. Joseph, MI, USA, 2015; pp. 1\u201315. [Google Scholar] Schmitz, G.H.; Sch\u00fctze, N.; Petersohn, U. New strategy for optimizing water application under trickle irrigation. J. Irrig. Drain. Eng. 2002, 128, 287\u2013297. [Google Scholar] [CrossRef] Azamathulla, H.M.; Ab Ghani, A.; Zakaria, N.A.; Chang, C.K. Linear Programming Approach for Irrigation Scheduling\u2014A case Study. In Proceedings of the 14th MANCID Annual Conference, Kuching, Sarawak, 14\u201315 February 2009. [Google Scholar] De Paly, M.; Sch\u00fctze, N.; Zell, A. Determining crop-production functions using multi-objective evolutionary algorithms. In Proceedings of the 2010 IEEE World Congress on Computational Intelligence, Barcelona, Spain, 18\u201323 July 2010. [Google Scholar] Goldstein, A.; Fink, L.; Meitin, A.; Bohadana, S.; Lutenberg, O.; Ravid, G. Applying machine learning on sensor data for irrigation recommendations: Revealing the agronomist\u2019s tacit knowledge. Precis. Agric. 2018, 19, 421\u2013444. [Google Scholar] [CrossRef] Hru\u0161ka, J.; Ad\u00e3o, T.; P\u00e1dua, L.; Marques, P.; Cunha, A.; Peres, E.; Sousa, A.; Morais, R.; Sousa, J.J. Machine learning classification methods in hyperspectral data processing for agricultural applications. In Proceedings of the International Conference on Geoinformatics and Data Analysis, Prague, Czech Republic, 20\u201322 April 2018. [Google Scholar] O\u2019Shaughnessy, S.A.; Evett, S.R.; Andrade, A.; Workneh, F.; Price, J.A.; Rush, C.M. Site-specific variable-rate irrigation as a means to enhance water use efficiency. Trans. ASABE 2016, 59, 239\u2013249. [Google Scholar] Zhao, W.; Li, J.; Yang, R.; Li, Y. Yields and water-saving effects of crops as affected by variable rate irrigation management based on soil water spatial variation. Trans. Chin. Soc. Agric. Eng. 2017, 33, 1\u20137. [Google Scholar] Haghverdi, A.; Leib, B.G.; Washington-Allen, R.A.; Ayers, P.D.; Buschermohle, M.J. Perspectives on delineating management zones for variable rate irrigation. Comput. Electron. Agric. 2015, 117, 154\u2013167. [Google Scholar] [CrossRef] Boluwade, A.; Madramootoo, C.; Yari, A. Application of unsupervised clustering techniques for management zone delineation: Case study of variable rate irrigation in Southern Alberta, Canada. J. Irrig. Drain. Eng. 2016, 142. [Google Scholar] [CrossRef] Nijbroek, R.; Hoogenboom, G.; Jones, J.W. Optimizing irrigation management for a spatially variable soybean field. Agric. Syst. 2003, 76, 359\u2013377. [Google Scholar] [CrossRef] Zarco-Tejada, P.J.; Gonz\u00e1lez-Dugo, V.; Williams, L.E.; Su\u00e1rez, L.; Berni, J.A.J.; Goldhamer, D.; Fereres, E. A PRI-based water stress index combining structural and chlorophyll effects: Assessment using diurnal narrow-band airborne imagery and the CWSI thermal index. Remote Sens. Environ. 2013, 138, 38\u201350. [Google Scholar] [CrossRef] [Green Version] Haghverdi, A.; Leib, B.G.; Washington-Allen, R.A.; Buschermohle, M.J.; Ayers, P.D. Studying uniform and variable rate center pivot irrigation strategies with the aid of site-specific water production functions. Comput. Electron. Agric. 2016, 123, 327\u2013340. [Google Scholar] [CrossRef] [Green Version] Torrion, J.A.; Maas, S.J.; Guo, W.; Bordovsky, J.P.; Cranmer, A.M. A three-dimensional index for characterizing crop water stress. Remote Sens. 2014, 6, 4025\u20134042. [Google Scholar] [CrossRef] Bausch, W.C.; Delgado, J.A. Impact of residual soil nitrate on in-season nitrogen applications to irrigated corn based on remotely sensed assessments of crop nitrogen status. Precis. Agric. 2005, 6, 509\u2013519. [Google Scholar] [CrossRef] Rossi, V.; Salinari, F.; Poni, S.; Caffi, T.; Bettati, T. Addressing the implementation problem in agricultural decision support systems. Comput. Electron. Agric. 2014, 100, 88\u201399. [Google Scholar] [CrossRef] King, B.A.; Wall, R.W.; Karsky, T.F. Center-pivot irrigation system for independent site-specific management of water and chemical application. Appl. Eng. Agric. 2009, 25, 187\u2013198. [Google Scholar] [CrossRef]  \u00a9 2019 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/). Share and Cite MDPI and ACS Style Neupane, J.; Guo, W. Agronomic Basis and Strategies for Precision Water Management: A Review. Agronomy 2019, 9, 87. https://doi.org/10.3390/agronomy9020087 AMA Style Neupane J, Guo W. Agronomic Basis and Strategies for Precision Water Management: A Review. Agronomy. 2019; 9(2):87. https://doi.org/10.3390/agronomy9020087 Chicago/Turabian Style Neupane, Jasmine, and Wenxuan Guo. 2019. \\\"Agronomic Basis and Strategies for Precision Water Management: A Review\\\" Agronomy 9, no. 2: 87. https://doi.org/10.3390/agronomy9020087 Note that from the first issue of 2016, this journal uses article numbers instead of page numbers. See further details here. Article Metrics Citations Crossref   62 Web of Science   2 Scopus   71 Google Scholar   [click to view] Article Access Statistics Article access statistics Article Views 28. Dec 7. Jan 17. Jan 27. Jan 6. Feb 16. Feb 26. Feb 7. Mar 17. Mar 0k 10k 2.5k 5k 7.5k 12.5k For more information on the journal statistics, click here. Multiple requests from the same IP address are counted as one view.   Agronomy, EISSN 2073-4395, Published by MDPI RSS Content Alert Further Information Article Processing Charges Pay an Invoice Open Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors For Reviewers For Editors For Librarians For Publishers For Societies For Conference Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe to receive issue release notifications and newsletters from MDPI journals Select options Subscribe \u00a9 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated Disclaimer Terms and Conditions Privacy Policy\"",
        "analysis": "",
        "verbatim_quote1": "",
        "verbatim_quote2": "",
        "verbatim_quote3": "",
        "relevance_score1": 0,
        "relevance_score2": 0,
        "limitations": "",
        "inline_citation": "",
        "full_citation": ""
    }
]
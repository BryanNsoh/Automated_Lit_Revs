<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper. 

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: stated in: <subsection_title>
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>

<documents>
<review_intention>
  
the purpose and intention of this systematic review on automated systems for real-time irrigation management can be interpreted as follows:
Addressing the global food challenge: The review aims to explore how automated, real-time irrigation management systems can contribute to the efficient use of water resources and enhance agricultural productivity to meet the growing demand for food.
Evaluating the current state and future potential: The primary objective is to critically assess the current state of end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. The review also seeks to identify gaps and propose solutions for seamless integration across the automated irrigation management system to achieve fully autonomous, scalable irrigation management.
Examining automation across the entire pipeline: The review intends to systematically analyze the automation of each component of the irrigation management pipeline, from data collection and transmission to processing, analysis, decision-making, and automated action. It aims to investigate the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
Highlighting the role of interoperability and standardization: The review seeks to emphasize the importance of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline. It aims to identify existing and emerging standards and their applicability to real-time irrigation management systems.
Identifying challenges and proposing solutions: The review intends to uncover the challenges associated with implementing real-time, automated irrigation systems, such as data quality, scalability, reliability, and security. It aims to propose solutions and best practices based on the analysis of case studies and real-world implementations.
Guiding future research and innovation: By identifying research gaps and proposing new research questions and hypotheses, the review aims to provide a roadmap for advancing the field of real-time, automated irrigation management. It seeks to encourage collaborative research efforts across disciplines to address the complex challenges of automated irrigation systems.
In summary, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.
</review_intention>

<section_intention>
INTEGRATION, INTEROPERABILITY, AND STANDARDIZATION: Explores the challenges and strategies for integrating automated systems with existing irrigation infrastructure and other precision agriculture technologies, highlighting the importance of interoperability and standardization in enabling seamless communication and compatibility.
</section_intention>

<subsection_title>
7.1. Resilience and Fault Tolerance in Automated Irrigation Systems
</subsection_title>

<subsection_point_Point 1>
Point: Strategies for ensuring robustness and reliability in the face of failures, disruptions, or unexpected events

Papers to support point:

Paper 1:
- APA Citation: Sherafatpour, Z., Roozbahani, A., & Hasani, Y. (2019). Agricultural Water Allocation by Integration of Hydro-Economic Modeling with Bayesian Networks and Random Forest Approaches. Water Resources Management, 33(7), 2277-2299.
  Main Objective: To develop an integrated hydro-economic model for allocating agricultural water based on its economic value and to explore the potential of Bayesian Networks and Random Forest algorithms for automating the allocation process.
  Study Location: Zayandeh Rood River Basin, Iran
  Data Sources: Historical water use data, crop production costs, crop prices, irrigation network characteristics
  Technologies Used: Positive Mathematical Programming (PMP), Bayesian Networks, Random Forest
  Key Findings: The Nekoabad Network had the highest priority for water allocation based on economic value, followed by Barkhar, Mahyar, Sonati, Abshar, and Rodasht Networks. The Bayesian Network and Random Forest models demonstrated high accuracy in automating water allocation and predicting economic, social, and water resources indicators.
  Extract 1: This framework has been extensively used; for example, to analyze water and agricultural policies, preserve groundwater resources and subsistence of farmers in a region in Spain (Varela-Ortega et al., 2011), study the various economic, social, and environmental effects of different policy-making and of climate change in the Guadiana river on the Portuguese/Spanish border (Blanco-Gutiérrez et al., 2013), and to evaluate the economic costs of pumping groundwater in the Central Valley of California (Medellín-Azuara et al., 2015).
  Extract 2: The modeling framework in this study can be classified as a hydro-economic simulation model. Simulation models are extensively used to simulate behaviors of complex water resources systems. Most water allocation models are founded on mass balance principles and use a network linear program defined by the priorities of the user to allocate resources in a river system (Bekchanov et al., 2015).
  Limitations: This study relies on data from a specific region (Zayandeh Rood River Basin in Iran) and a limited time period (44 water years). The transferability and generalizability of the findings to other regions or longer timeframes may require further investigation.
  Relevance Evaluation: The paper is highly relevant to the point being made, as it directly addresses the need for robust and reliable strategies to ensure resilience and reliability in the face of failures, disruptions, or unexpected events within automated irrigation systems. The authors propose a hydro-economic model that integrates optimization, water availability constraints, and economic factors to allocate water resources in a way that maximizes economic value and minimizes negative impacts on employment, productivity, and reliability. This approach is particularly valuable in semi-arid and arid regions like Iran, where water scarcity and competition for resources are significant challenges.
  Relevance Score: 1.0
  Inline Citation: (Sherafatpour, Roozbahani, & Hasani, 2019)
  Explanation: The research in question employs a well-established and flexible modeling framework to examine the real-time allocation of irrigation water across various irrigation networks. This hydro-economic model considers water use optimization, water availability, and economic factors to make informed allocation decisions. By quantifying the economic value of water for different crops in each network, the model assigns allocation priorities based on crop profitability. The study's originality lies in the incorporation of Bayesian Networks and Random Forest algorithms to automate the allocation process, effectively replacing the complex hydro-economic model while maintaining accuracy.

 Full Text: >
"Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement Log in Find a journal Publish with us Track your research Search Cart Home Water Resources Management Article Agricultural Water Allocation by Integration of Hydro-Economic Modeling with Bayesian Networks and Random Forest Approaches Published: 09 May 2019 Volume 33, pages 2277–2299, (2019) Cite this article Download PDF Access provided by University of Nebraska-Lincoln Water Resources Management Aims and scope Submit manuscript Zohreh Sherafatpour, Abbas Roozbahani & Yousef Hasani  781 Accesses 27 Citations Explore all metrics Abstract Sustainable utilization of water resources requires preventive measures that must be taken to promote optimal use of water resources together with consideration of stakeholder interests and the economic value of water. The main objective of this study is to present an integrated hydro-economic model for allocating agricultural water based on its economic value. The study region covered six irrigation networks downstream of the Zayandeh Rood Dam in Iran. In fact, this study addresses questions of how to allocate scarce water to different consumers, in order to achieve the highest efficiency and economic benefits. To gain this goal, the existing agricultural activities in each irrigation network were simulated by applying the Positive Mathematical Programming (PMP) economic model and then by coupling the economic model with a water allocation planning model of the basin (MODSIM), the hydro-economic framework was generated. These tools helped to allocate water based on its economic value, maximize net profit by determining the optimal cultivating area and analyze the effects of various allocation scenarios on employment, economic productivity, and reliability indicators. Moreover, Bayesian Networks and Random Forest algorithms were developed as an automated substitute to simplify the process and reduce computational complexity. The results showed that the Nekoabad Network enjoys top priority followed by the Barkhar, Mahyar, Sonati, Abshar, and Rodasht Networks. After implementing the Bayesian Network, the four criteria of MAE, MAPE, R2, and the Nash-Sutcliffe index for the irrigation networks were 9 MCM, 24%, 0.738, and 0.644 respectively, which indicated the model has good accuracy. Random Forest method was also employed as a novel technique in automated allocation, and the values obtained for the four mentioned criteria were 7 MCM, 15%, 0.861, and 0.80, which showed it is more accurate. The results indicated the capability of the presented hydro-economic model as well as the intelligent models substituting it in allocating agricultural water. Similar content being viewed by others Development of random forest model as decision support tool in water resources management of Ogun headwater catchments Article Open access 30 June 2021 Comparing data driven models versus numerical models in simulation of waterfront advance in furrow irrigation Article 06 May 2019 Application of rotation forest with decision trees as base classifier and a novel ensemble model in spatial modeling of groundwater potential Article 27 March 2019 1 Introduction The water crisis is an important challenge especially in the Middle East including Iran. As in most countries, the agriculture sector in Iran is the biggest water user. With the expansion of agriculture in many regions and occurrences of droughts in recent years, the economy of the agriculture sector is facing serious limitations. In the past, the strategy for overcoming these limitations was mainly concentrating on increasing water supply, which depleted aquifers and groundwater (Saravi et al. 2015). Currently, most arid and semi-arid regions in the world, as most parts of Iran, face insufficient water supply on the one hand and large water demand for agricultural water on the other hand, which is mainly caused by the substantial difference between the price paid for water and the value of the products produced by using it (Esmaeili and Vazirzadeh 2009). A large number of recent studies have concluded that water price should cover the total costs of supplying it (Brooks 2006; Bithas 2008). Limited water resources, increased water demand, and uncontrolled and unsystematic utilization of these resources have caused increasing problems and conflicts. Consequently, it is very important and necessary to consider the economic situation in allocating water to its users. He et al. (2006) in their studies tried to find out how to allocate scare water to agricultural production in Egypt and Morocco. They used positive mathematical programing (PMP) and examined the various policy including water pricing policy, water complementary input factor tax policy, and output tax policy. The results for both countries indicate that some of these policies can be used to make decisions about crops with less water requirements. These policies can also be used when the government does not set the price for water. During recent decades, Positive Mathematical Programming (PMP) models have had numerous applications for analyzing policies in the agricultural sector (Gómez-Limón and Riesgo 2004; Buysse et al. 2007). This method has been successfully employed in many areas and fields such as estimating the economic value of agricultural water in the Rio river in northern Mexico under different conditions (Medellín-Azuara et al. 2010), analysis of policy substitutes for improving irrigation water allocation in Egypt and Morocco (He et al. 2006), study and analysis of political tools for controlling nitrate pollution in irrigation of agricultural lands in Costilla in Spain (Gallego-Ayala and Gómez-Limón 2009), and determination of economic value of water in the Qazvin Plain in Iran (Hashemy Shahdany et al. 2017). Furthermore, Ouazar et al. (2017) introduced a new application for the framework of mathematical modeling that evaluates the social and economic impacts of climate change on agricultural activities in Morocco. Hydrology engineers during the 20th and 21st centuries have increasingly employed hydro-economic models and economic principles for systems analysis. Bear et al. (1964) created a conceptual framework for models of the integrated management of regional water resources, where the purpose in water management and allocation is the maximization of net profit. This framework has been extensively used; for example, to analyze water and agricultural policies, preserve groundwater resources and subsistence of farmers in a region in Spain (Varela-Ortega et al. 2011), study the various economic, social, and environmental effects of different policy-making and of climate change in the Guadiana river on the Portuguese/Spanish border (Blanco-Gutiérrez et al. 2013), and to evaluate the economic costs of pumping groundwater in the Central Valley of California (Medellín-Azuara et al. 2015). The modeling framework in this study can be classified as a hydro-economic simulation model. Simulation models are extensively used to simulate behaviors of complex water resources systems. Most water allocation models are founded on mass balance principles and use a network linear program defined by the priorities of the user to allocate resources in a river system (Bekchanov et al. 2015). Many tools including the MODSIM 1 model has been employed to allocate water in watersheds. This model has been successfully used in a number of complicated river systems such as the Rio Grande river basin in Colorado (Graham et al. 1986), the South Platte river basin (Fredericks et al. 1998), the Piracicaba river basin in Brazil (Azevedo et al. 2000), water resources upstream of the Sirvan river basin (Shourian et al. 2008), the northern part of the Kashafrud basin in Mashhad, Iran (Raafatisokhango 2010), the Karkheh river basin in Iran (Vaghefi et al. 2015) and the Prek Te river basin in Cambodia (Chhuon et al. 2016). Furthermore, numerous methods can be used in predicting and planning volumes of water required from the water resources including Bayesian Networks and Random Forest algorithm. Bayesian Networks have been employed in various fields such as the environment (Aalders and Aitkenhead 2006; Ticehurst et al. 2007; Steventon and Daust 2009; Voie et al. 2010; Madadgar and Moradkhani 2014), research in water resources management (Reggiani and Weerts 2008; Wang et al. 2009; Martínez-Santos et al. 2010; Zorrilla et al. 2010; Biondi and De Luca 2012), and urban water management (Berardi et al. 2008; Roozbahani et al. 2013; Anbari et al. 2017; Tabesh et al. 2018). Also, the Random Forest method has been rarely used in water resources management; however, it has been employed to predict drought in the Hai river basin in China (Chen et al. 2012), simulate monthly streamflow in five highly seasonal rivers in the highlands of Ethiopia (Shortridge et al. 2016) and evaluate the quantitative potential of groundwater in regions having springs (Naghibi et al. 2017). In order to correctly allocate water to agricultural lands, this study attempted to determine the economic value of agricultural water and allocate it by employing a hydro-economic model. This model is developed by combination of MODSIM water resources and PMP economic models. It also studied the economic and social effects of this allocation and also its effects on water resources. Finally, for the first time, two automated allocation models (Bayesian Network and Random Forest) that have been trained based on information obtained from a hydro-economic model can replace the complex hydro-economic model in order to offer an accurate estimation of allocations by using its strong mathematical foundation. The proposed framework has been evaluated in allocating agricultural water to six irrigation networks in Zayandehrud River Basin as an important river basin in Iran. 2 Methodology 2.1 Research Flowchart The stages of the research, which are introduced below, are presented in the research flowchart in Fig. 1. Fig. 1 Flowchart of the proposed framework Full size image Using the data collected from the information on production costs and information on prices of products and resources, the elements of the PMP model including the technical coefficients, the variables of the objective function, and the limitations are formed for the base year. After calculating the mentioned parameters, the PMP model is built and calibrated based on the production function. After the economic model is constructed, the value of water for the products and the irrigation networks followed by the priority of each network is calculated based on the information on the base year. The MODSIM water resources model is then developed and the available water is allocated considering the priority of each network. The acreages under cultivation in the networks are then optimized by the PMP model by taking into consideration the water allocated to each network. The MODSIM model is implemented again and water is allocated to the new acreages. The final obtained results are used to calculate the economic, social, and water resources indicators. This process is implemented in the hydro-economic model for other years. The obtained results are utilized for training and validating the Bayesian Network and Random Forest models. Finally, the results for the Bayesian Networks and the Random Forest algorithm are compared and evaluated to investigate the capabilities of these models to substitute the hydro-economic model and serve as automated water allocation models. 2.2 Positive Mathematical Programing Positive mathematical programming (PMP) is followed in three stages (Paris and Howitt 1998): 2.2.1 Specifying the Linear Programming Model in Order to Obtain Shadow Price of Production Resources Model Objective Function It is assumed that all the farmers intend to increase their gross profit in each crop year. Therefore, the basis of the analytic model in this research is the objective function is as follows. $$ \\mathit{\\operatorname{Max}}\\kern0.5em GM=\\sum \\limits_{i=1}^I{X}_i\\left({P}_i\\times {Y}_i-{CW}_i-{C}_i\\right) $$ (1) In the above equation, gross margin (GM) represents the annual gross income resulting from the total irrigation farming activities, Xi is the area under cultivation of crop i in hectares, Pi is the price of crop i, Yi is the yield of crop i in kg/ha, CWi is the cost of water used per hectare under cultivation of crop i, and Ci is total production cost (such as labor, fertilizers and machinery) Constraint on labor force: This limitation indicates the labor force required for the agricultural activities in the region, and is expressed in the following equation: $$ \\sum \\limits_{i=1}^n{L}_i{X}_i\\le Tlabour $$ (2) In this equation, Li is the required labor force per hectare for producing crop i, Xi is the area under crop i cultivation, and Tlabour is the total number of the workers. Constraint on chemical fertilizers: this limitation, specified in eq. 3, states that the fertilizer source required in producing crop i should not exceed its present and available amount (TFertilizer). It is repeated for phosphate and urea fertilizers and for pesticides used in the region. $$ \\sum \\limits_{i=1}^n{F}_i{X}_i\\le TFertilizer $$ (3) In the above equation, Fi signifies the amount of fertilizer per hectare in producing crop i. Constraint on machinery: The various crops compete for machinery since agricultural activities require machinery to produce crops during planting, maintenance, and harvesting, and because these activities are concentrated over a specific period of time. Therefore, in the present research, limited access to machinery is considered in the model in the form of the following limitation: $$ \\sum \\limits_{i=1}^n{M}_i{X}_i\\le Tmachine $$ (4) In this equation, Mi is the required machine hours in producing crop i in each hectare and TMachine is the total machinery capacity in the region in hours. Constraint on Water Resources The present study assumes that the water required for agricultural activities is supplied from the reservoir outlet of the Zayandeh Rood Dam. Based on this, the limitations on water resources are presented in a general form in eq. 5: $$ \\sum \\limits_{i=1}^n\\sum \\limits_{\\mathrm{j}=1}^{12}{\\mathrm{WC}}_{\\mathrm{i}\\mathrm{j}}{\\mathrm{X}}_{\\mathrm{i}}\\le \\mathrm{SW} $$ (5) Where, WCij is the volume of water utilized to produce crop i in month j, Xi is the area under cultivation of crop i, and SW is the volume of surface water needed for agricultural activities in the study region during the year. This limitation shows that the total volume of water required for growing crop plants in the region is less than or equal to the volume of available surface water. Constraint on Calibration With the addition of calibration limitations to the set of the linear programming model, and by solving it, the shadow values related to the mentioned limitations will be determined. $$ \\sum \\limits_{\\mathrm{i}=1}^{\\mathrm{n}}{\\mathrm{X}}_{\\mathrm{i}}\\le {\\mathrm{X}}_{\\mathrm{i}}^0+\\upvarepsilon $$ (6) Where, \\( {\\mathrm{X}}_1^0 \\) are the values for the base year and ε is the (n×1) matrix of small positive numbers for preventing linear dependence among structural limitations and calibration limitations. 2.2.2 Estimation of the Production Function Parameters In this step, the parameters of the production function will be estimated by using shadow prices of the resources and the calibration constraints which are derived from the previous phase. (Golan et al. 1997; Paris and Howitt 1998; Mittelhammer et al. 2002) In this study, the analytical approach with optimal economic conditions assumption is used to determine the parameters of production function (Eq. 7). Therefore, the optimal economic conditions are obtained by putting the final value of production at the expense of each resource unit. $$ {y}_i={A}_i{\\left(\\sum {C}_i{X}_i+{C}_w\\right)}^{\\raisebox{1ex}{${\\varepsilon}_i$}\\!\\left/ \\!\\raisebox{-1ex}{$\\lambda $}\\right.} $$ (7) Ai represents the regional parameters share and Ci is the parameters of production function for all production resources except surface water, Cw is the volume of water utilized, λ is the shadow price variable associated with resource constraints and εi represents the returns to scale parameter. 2.2.3 Economic Model Simulation In order to simulate the existing agricultural conditions of the study region and achieve the optimum set of resources which maximizes gross income of the farmers, the nonlinear CES production function obtained in the previous step (Eq. 7) is placed instead of Yi in the initial linear objective function (Eq. 1). The nonlinear objective function is used in a nonlinear programming problem (without calibration limitations, but with other model constraints) as follows: $$ \\mathit{\\operatorname{Max}}\\ GM=\\sum \\limits_{i=1}^I{X}_i\\left({P}_i\\times \\left({A}_i{\\left(\\sum {C}_i{X}_i+{C}_w\\right)}^{\\raisebox{1ex}{${\\varepsilon}_i$}\\!\\left/ \\!\\raisebox{-1ex}{$\\lambda $}\\right.}\\right)-{CW}_i-{C}_i\\right) $$ (8) To use the Eq. 5 at monthly step, the national water data document of the country has been used. By using of evapotranspiration values and effective rainfall in this document for each product (in NETWAT software), the amount of pure water allocated to product i in month m is \\( {X}_{isw_m}={Met}_{im}{X}_{isw} \\) and Also, the total amount of water used to produce the product i from surface water sources is equal to: $$ \\sum \\limits_i{X}_{isw_m}=\\sum \\limits_i{Met}_{im}\\times {a}_{isw}\\times {X}_{iland} $$ (9) In this equation Metim is percentage of water requirement of product i in month m and aisw is the annual amount of surface water used per hectare\\( \\left(\\raisebox{1ex}{${X}_{isw}$}\\!\\left/ \\!\\raisebox{-1ex}{${X}_{iland}$}\\right.\\right) \\). Equation 10, along with other economic model constraints, has been used to achieve the objectives of the research. It must be mentioned that information on the cultivars, prices of products and resources was provided by Organization of Agriculture of Esfahan Province. Also, the amount of water allocated to the regional farmers, the cost of water allocation and the status of irrigation networks, discharge network’s channels and etc. is collected through the Esfahan Regional Water Authority and related organizations. Information on crop production costs was obtained through questionnaire information (farmers’ and experts’ opinions) during the 2014–2015 crop year. Economic modelling has been done using GAMS (General Algebraic Modeling System) software. 2.3 MODSIM Simulation Model MODSIM has been designed as a decision support system for basin management and is employed as a computerized tool to develop and improve short-term water management strategies, long-term utilization planning and analyses related to water rights and inter-sectoral water conflicts (for drinking, industrial, agricultural, and environmental purposes) within river basins. MODSIM is able to model large-scale systems in basins by using a network flow optimization algorithm that minimizes costs. The MODSIM model simulates water allocation mechanisms in river basins by sequential solving the network flow optimization problem (Labadie 2006). 2.4 Bayesian Networks Graphical models are among the most common techniques for modeling uncertainty. With the help of probability theory, these models provide a method for coping with uncertainty and use graph theory to address complexity. Bayesian Networks are based on directed graphs, and hence, they are also called directed graphical models. In fact, a Bayesian Networks is a directed acyclic graph (DAG) that can be defined as a number of nodes that represent a group of interacting random variables. Bayesian Networks, which have been developed based on conditional probabilities and on the Bayes’ theorem, are graphical models for expressing probable relationship between variables (Eq. 10): $$ P\\left(A|B\\right)=\\frac{P\\left(B|A\\right)P(A)}{P(B)} $$ (10) Where P(A) is the probability of event A, P(B) is the probability of event B, P(B|A) the conditional probability of B given A, p (A|B) the conditional probability of A given B. A graphical Bayesian Networks is used to represent the simultaneous probability distribution of a set of variables. The knowledge gained for a problem is modeled as qualitative and quantitative information in this graph. This is performed by specifying a set of linearly independent vectors by graph arcs. If a node has one or more parents, it will have a CPT. 2 In the case of continuous variables, the CPTs display information on the mean and variance related to each node (variable). In the case of discontinuous (clustered) variables, the CPT table indicates the P value of each node (variable) belonging to various clusters. Various software and toolboxes are available to work with Bayesian Networks. In the present research, model training was performed by the Hugin 8.5 software together with the Necessary Path Condition (NPC) training structure at the 5 % confidence level. The parameters were also trained using the expectation-maximization (EM) algorithm. 2.5 Random Forest Algorithm Breiman (2001) introduced the Random Forest concept based on the theory of bagging. A decision making forest is a group of various trees that act in parallel. This algorithm uses decision trees for classification or regression. A decision tree is a recursive algorithm with a tree structure that, based on training data, starts to work in each stage by selecting one key characteristic. In this process, multiple decision trees are produced. Random operation in a Random Forest takes place in two ways. Random sampling, the same method that is used in bagging, is employed in one, and in the other, the eigenvector for training the tree is selected implicitly by using methods such as information coefficient or entropy (Quinlan 1986). The training for each tree in the Random Forest is modeled by h(x, Θk),  k = 1, 2, …  (Breiman 2001): Θk represents the vector for training parameters specifically used for tree k. In this method, each decision tree is created from a random vector. To investigate the output of a sample, it is given to each tree in the forest and each tree produces a vote for the incoming variable (sample) x. K stands for the number of trees. Prediction for a new sample is made by collecting the votes of all trees, and majority voting then takes place. If the desired output is Y, the Random Forest calculates \\( \\overline{Y} \\) by averaging the decision trees. Therefore, \\( \\overline{Y} \\) is equal to: $$ \\overline{Y}={avg}_kh\\left(x,{\\varTheta}_k\\right) $$ (11) This process can be explained in the following way: The Bi sample is created from the original one. This is done randomly and by inserting from the original data. The samples are randomly obtained from D that indicates the original data. The samples now form the training set, and the ti tree is created by applying a decision tree algorithm. For each tree node, the set of features or characteristics is limited to the set of k features. $$ \\left({X}_1,{X}_2,\\dots ..,{X}_k\\right) $$ The first step is repeated for i = 1, 2... n so that n number of ti trees are created. The votes (decisions) given by ti trees are collected and the new sample is classified using majority voting. In other words, the main process in a Random Forest is to first select Bi samples of the original training dataset D. This is carried out by using the bagging technique randomly. This Bi sample is then employed as input for the growth of each ti tree. Finally, the outputs of all of the trees are averaged considering their accuracies. T represents the final output (Han et al. 2013). The general structure of this classification in the Random Forest is presented in Fig. 2. The Python programming language was employed to use the Random Forest algorithm. Fig. 2 The general classification structure in the Random Forest algorithm Full size image 2.6 Evaluation Indicators for Hydro-Economic Modeling Each new allocation causes changes in the economic, social, and water resources situations. These changes are studied and evaluated using the economic productivity, employment, and reliability indicators. Economic productivity indicator: This indicator shows the annual economic productivity of each crop for every cubic meter of water. In other words, it expresses the annual profit made for every cubic meter of water: $$ {EI}_i=\\frac{1}{N}\\sum \\limits_{j=1}^N\\left(\\frac{NB_j}{W_j}\\right) $$ (12) $$ {EI}_T=\\frac{1}{M}\\sum \\limits_{i=1}^M\\left({EI}_i\\right) $$ (13) In this equation, n is the number of crops in each network, NB is the net profit (in IRR 10000) received from crop j, W is the volume of water (m3) used for crop j per hectare, and m represents the number of networks. Employment indicator: This indicator demonstrates the annual reduction in the number of workers caused by the reduction in the acreage under cultivation of each crop: $$ {SI}_i=\\frac{1}{N}\\sum \\limits_{j=1}^N\\left({CA}_j\\times {L}_j\\right) $$ (14) $$ {SI}_T=\\frac{1}{M}\\sum \\limits_{i=1}^M\\left({SI}_i\\right) $$ (15) In this equation, n is the number of crops in each network, CA is the reduction in the area under cultivation of crop j, L is the day-person of workers required for crop j per hectare, and m is the number of networks. Reliability indicator: Reliability is defined as the probability that the allocated water will meet the user’s demand (Hashimoto et al. 1982): $$ \\mathit{\\operatorname{Re}}=\\frac{1}{M}\\sum \\limits_{i=1}^M\\left(\\frac{N_s}{T}\\right)\\times 100\\kern7.25em 0\\le \\mathit{\\operatorname{Re}}\\le 100\\% $$ (16) In this equation, m is the number of networks, Ns is the number of time steps during which the user’s water need is completely satisfied, and T is the total number of time steps in the simulation period (Mcmahon et al. 2006). In the present research, monthly time steps were employed and reliability indicator was calculated for each year. 2.7 Evaluation Criteria for BNs and RF Models The criteria used to evaluate and validate the models proposed for automated water allocation applied the predicted values and the observed values to show the accuracies of the models. Observed values refer to values calculated by the hydro-economic model and predicted values are the outputs of the Bayesian Networks and Random Forest models. These criteria include Coefficient of determination (R2), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE) and Nash-Sutcliffe (NS). 3 Results and Discussion 3.1 The Study Region The case study consists of the water resources downstream of the Zayandeh Rood Dam. The Zayandeh Rood river basin is one of the most important basins in Iran due to the various activities and water uses, and also because of inter basin water transfer projects. It covers an area of about 26,000 ha, constituting a major part of the Gavkhouni Wetland. The Zayandeh Rood river has a vital role in supplying the drinking, industrial, and agricultural water of the central region in Iran. About five million residents in this region and also large industries depend on this river for water. Most importantly, this river provides the agricultural water for the irrigation plains. Water scarcity has become more severe in recent years with the population growth, industrial concentration, and increase in water uses on the one hand and water transfer to rural and urban population centers outside of the basin. Moreover, droughts in the region in general, and in recent years in particular, have influenced the water system with greater intensity. To achieve the objectives of the research, the agricultural areas in the study region receiving irrigation water from the Zayandeh Rood Dam were divided into six sub-areas: 1: the Sonati Network; 2: The Modern Mahyar and Jarghouyeh Network; 3: The Modern Left and Right Nekoabad Network; 4: The Modern Barkhar Network; 5: The Modern Left and Right Abshar Network; 6: The Northern and Southern Modern Rodasht Network (Fig. 3). This basin suffers from lack of a systematic mechanism for agricultural water allocation within the irrigation districts, since no economic orientation (e.g. water market) exists in the current water resources management in the basin. Fig. 3 Area under cultivation in the Irrigation Networks of the Zayandeh Rood river basin Full size image 3.2 Results of PMP After implementing the PMP model, the value of water for each crop (from the total volume of required water during the base water year 2014–2015) in each network is calculated. Results of the calculations regarding the values of water for the crops are presented in Table 1. Table 1 Priorities of the crops grown in the networks downstream of the Zayandeh Rood Dam considering the value of water in the base year 2014–2015 Full size table Table 1 lists the crops grown in the networks in the order of their priorities with respect to the value of water for them. In the Nekoabad, Abshar, Mahyar, and Rodasht Networks, onion has the top priority, in these networks, barley, bean, wheat and bean products are the last priority. In the Barkhar Network, forage corn is the first priority and cantaloupe and honeydew the last. Rice enjoys the highest priority and watermelon (considering its value of water) the lowest in the Sonati network. Among all crops, onion is the most valuable with its value of water of 3710 (IRR/m3) in the Abshar Network, whereas the least valuable crop is watermelon with its value of water of 2487 (IRR/m3) in the Sonati Network. After the priority for each crop is determined for all the Networks, the priorities of the Networks are calculated by averaging the values of water for the crops in each one. Figure 4 presents the priority for each network based on its value of water and on the current allocation of water in the region. Fig. 4 The order of priorities in water allocation and economic value for the networks (2014–2015) Full size image As shown in Fig. 4, the Nekoabad Network enjoys the first priority (based on the current allocation) followed by Abshar, Barkhar, Mahyar, Rodasht, and Sonati Networks. In priorities based on the value of water in the Networks, the Nekoabad Network has the top priority because it has a higher value of water than the others. The other Networks, in the order of their priorities, are Barkhar, Mahyar, Sonati, Abshar, and Rodasht. The Abshar and Rodasht Networks have higher acreages under cultivation than the other Networks but, since crops grown in them have low values of water, they have lower values of water than the other Networks that have smaller acreages under cultivation. Moreover, the largest difference between the current water tariff 3 and the economic value of water (3229 IRR/m3) is that of the Barkhar Network followed by the Nekoabad, Mahyar, Sonati, Abshar, and Rodasht with 3224, 3187, 3036, 2877, and 2689 IRR/m3, respectively. Results obtained from the analysis of the data indicate that the economic value of water per cubic meter in all the networks is higher than the tariff paid by the farmers. Obviously, determination of the economic value of water can substantially affect water use management because the low price paid for this scarce source leads to its uncontrolled and wasteful use. 3.3 Results of MODSIM Model In addition to the irrigation Networks, priorities are given to drinking, industrial, and environmental water. After water is allocated for these uses, the remainder is utilized for the irrigation networks. Table 2 lists water needed for these purposes in the base year (2014–2015) and Table 3 the priorities in water allocation. The schematic diagram of the MODSIM model for the study region is also shown in Fig. 5. Table 2 Water needed for other purposes in the base year (2014–2015) Full size table Table 3 The priorities given to water use downstream of the Zayandeh Rood Dam (2014–2015) Full size table Fig. 5 The schematic diagram of MODSIM model showing simulation of basin downstream of the Zayandeh Rood Dam Full size image Furthermore, Table 4 lists changes in areas under cultivation downstream of the Zayandeh Rood Dam based on the priorities shown in Table 3: Table 4 Changes in areas under cultivation in irrigation networks downstream of the Zayandeh Rood Dam (2014–2015) Full size table The largest change in areas under cultivation (5.66%) happened in the Rodasht Network. It has the last priority based on the economic value of water and receives less water than the other Networks. That is why greater changes in acreages under cultivation happen in it. The Abshar, Sonati, Mahyar, Nekoabad, and Barkhar Networks experience 4.57, 0.89, 0.63, 0.5, and 0.28% reductions, respectively, in areas under cultivation. Considering water outflow from the Dam and the monthly water requirement of the crops in the Networks, the Barkhar Network experiences less reduction in areas under cultivation compared to the Nekoabad Network although it enjoys the second priority. This is because in some months when the crops in the Networks need water, the Dam may not have enough water to satisfy their needs, and the Networks with higher priorities may not receive the water they require. Taking the water allocated to the Networks into consideration, the total reduction in areas under crop cultivation is 2.7% (1665 ha). The scenario tested in this paper by the hydro-economic structure was the scenario of drought period. According to the Table 5, the gross profit from agricultural activity on the studied area in drought conditions and without using hydro-economic model, was obtained to be equal to 4,128,660,521,010 IRR. Whereas, in drought conditions, using the hydro economic model, the profit from agricultural activity in the study area was 4,500,726,845,580 IRR. In other words, water allocation based on economic value of the water caused the profit of the agricultural activity to increase to 372,066,324,570 IRR. Table 5 The results of using hydro-economic model Full size table Also, according to the table below, by consuming 1,384,882,000 m3 of water in the base year (2014–2015), a gross profit of 4,280,646,041,830 IRR is acquired. Whereas, by using hydro-economic model in drought conditions, despite using less water and cultivating a smaller land (634,643,332 m3 and 1850 ha, respectively), a higher gross profit compared to the base year is obtained which is equal to 220,080,803,750 IRR. 3.4 Result of Bayesian Network Various structures must be employed for training the allocation model in order to make the best use of the Bayesian method and obtain more accurate results. Different structures for training the allocation model were used and after many trials and errors, the best training model was selected based on the accuracies of the models and by using previous knowledge and utilizing the relationships between the data (Fig. 6). Fig. 6 The final structure of the Bayesian Network for water allocation model in Hugin 8.5 software Full size image Of the data related to 44 water years (from 1971 to 1972 to 2014–2015), 80% (the data for 35 years) was used for training the model and 20% (the data for 9 years) for validating it. Table 6 lists results concerning the accuracy of the predictions made by the final structure for the Bayesian model. Table 6 The evaluation criteria of the Bayesian Network automated water allocation model Full size table As stated in Section 2.6, the economic productivity index determines how much profit a product can obtain per year by using each cubic meters of water. Also, the employment index shows the level of workforce reduction per year by decreasing the cultivation area. Finally, the water resources index states the probability of meeting the needs of the consumer with the allocated water. Between the networks the largest amount of error (12 MCM) is that of the Abshar and the smallest that of the Mahyar Jarghouyeh Network. R2 indicates the accuracy in estimating water allocation for the irrigation networks and in estimating the economic, social, and water resources indicators. The highest correlation coefficient belongs to the Rodasht Network (0.962) and the lowest R2 to the Nekoabad Network (0.672). The average correlation coefficients for the economic, social and reliability indicators are 0.724, 0,624, and 0.739, respectively. Moreover, according to the values listed in Table 5, the Bayesian Networks model has yielded acceptable results in predicting water allocation, which suggests its high capacity for automated and intelligent annual water allocation. The diagrams derived from the results of estimation by the Bayesian Network model for each irrigation Network and each indicator is presented in Fig. 7. These diagrams indicate that the closer the data is to the 45° line the higher the accuracy of the model in prediction is. It must be mentioned that reference allocation in the Figures below refers to allocation by the hydro-economic model. As results of the Bayesian Network in Fig. 7 show, this model has had good accuracy in automated water. Fig. 7 Comparison between the results obtained from the Bayesian Networks model and from the reference data Full size image 3.5 Results of the Random Forest The new Random Forest method was used to compare results and investigate the accuracy of the Bayesian Networks. The same data employed for training and validation of the Bayesian model was utilized for this model. The relevant results are presented in Table 7. Table 7 Evaluation indicators for automated water allocation using the Random Forest Full size table The correlation coefficients are the largest for the Rodasht Network (0.925) and the smallest for the Abshar Network (0.797). This coefficient is larger than 0.80 for all the Networks, which suggests that the model is highly accurate. The largest MAE in this method belongs to the Abshar Network with 14 million cubic meters per year and smallest to the Mahyar Jarghouyeh with 2 million cubic meters per year. As for the NS index, it can be realized that the model has performed well and yielded acceptable results. Figure 8 presents the diagram derived from the results of the prediction made by the Random Forest model for each network and for each indicator, which indicates the good accuracy of the model for automated water allocation. Fig. 8 Comparison between the results obtained from the Random Forest and from the reference data Full size image Comparison between the results of the Bayesian Networks and Random Forest models indicated that the MAPE averages for the networks were 15% for the Random Forest model and 24% for the Bayesian model, and the mean correlation coefficients between the models were 0.861 for the Random Forest model and 0.738 for the Bayesian model. This coefficient was higher than 0.8 for the economic, social, and reliability indicators in the Random Forest model, but the correlation coefficients of these indicators were 0.724, 0.624, and 0.739, respectively, in the Bayesian model. All these results suggest that the Random Forest model is more accurate than the Bayesian model, since its learning is based on ensemble learning; such that the Random Forest itself includes several decision tree learning models and each of these sub-models learn different distributions depending on the sampling and placement of data. However, both models can substitute the complicated hydro-economic model for automated water allocation. 4 Conclusion Water is the most important limiting factor in agricultural economy development. Therefore, this study attempted to use a hydro-economic model to analyze agricultural water allocation based on the economic value of water and to use the output of this model for training two intelligent models (Bayesian Networks and Random Forest) that could replace the hydro-economic model as automated water allocation models for six irrigation networks in Zayandeh Rood basin in Iran. The available data was firstly used to develop the PMP economic model and obtain the value of water for each crop. The priority of each network was determined by weighted averaging of the values of water for the crops. Based on the economic values of the irrigation networks, the Nekoabad Network had the top priority followed by the Barkhar, Mahyar Jarghouyeh, Sonati, Abshar, and Rodasht Networks. Water allocation based on the hydro-economic model causes the allocation to each irrigation network and the products found in their cultivation pattern to be performed according the product’s price, product’s performance, final water productivity, the farmer’s experience in producing a product, etc. The result of using the mentioned structure is the optimum water allocation and increase of the farmers’ profit in the considered study domain. After water allocation using the MODSIM model, the economic, social, and water resources indicators were calculated for each crop by taking into consideration the water allocated to each one. Results obtained from optimal allocation of water for 44 years were used as training data for the Bayesian networks. Finally, the new Random Forest method was employed for comparison with the Bayesian Network and for its further investigation. The results of the Random Forest algorithm also indicated its high accuracy for allocating water to the networks and in evaluating the indicators, in comparison with Bayesian Network. Also in researches done by Chen et al. (2012), Shortridge et al. (2016) and Li et al. (2017), random forest algorithm performed consistently better than the other models. Furthermore, in this research due to the economic value of water, water has been allocated considering the priority of each network thus these networks had a better water provision, farmers’ profits, and economic productivity than current allocation, although the employment declines due to the reduction in areas under cultivation. These results are consistent with researches carried out by He et al. (2006), Varela-Ortega et al. (2011) and Hashemy Shahdany et al. (2017). The obtained results of this study provides a reliable, systematic and realistic agricultural water allocation in Zayandeh Rood river basin considering economic perspectives. The proposed framework in this paper with slight changes, can be used in other regions to study the policies and management of basins. Notes Modular Simulator Conditional Probability Table 1The price set by the government based on the law fixing the price of agricultural water (passed by the Parliament in 1990) References Aalders IH, Aitkenhead MJ (2006) Agricultural census data and land use modelling. Comput Environ Urban Syst 30(6):799–814 Article   Google Scholar   Anbari MJ, Tabesh M, Roozbahani A (2017) Risk assessment model to prioritize sewer pipes inspection in wastewater collection networks. J Environ Manag 190:91–101 Article   Google Scholar   Azevedo LG, Gates TD, Fontane DG, Labadie JW, Porto RL (2000) Integration of water quantity and quality in strategic river basin planning. J Water Resour Plan Manag 126(2):85–97 Article   Google Scholar   Bear J, Levin O, Buras N, (1964) optimal utilization of aquifers as elements of water-resource systems. Hydraulic laboratory pn. TECHNION Bekchanov M, Sood A, Jeuland M (2015) Review of hydro-economic models to address river basin management problems: Structure, applications and research gaps, IWMI Berardi L, Giustolisi O, Kapelan Z, Savic D (2008) Development of pipe deterioration models for water distribution systems using epr. J Hydroinf 10(2):113–126 Article   Google Scholar   Biondi D, De Luca D (2012) A bayesian approach for real-time flood forecasting. Phys Chem Earth, Parts A/B/C 42-44:91–97 Article   Google Scholar   Bithas K (2008) The sustainable residential water use: sustainability, efficiency and social equity. The european experience. Ecol Econ 68(1–2):221–229 Article   Google Scholar   Blanco-Gutiérrez I, Varela-Ortega C, Purkey DR (2013) Integrated assessment of policy interventions for promoting sustainable irrigation in semi-arid environments: a hydro-economic modeling approach. J Environ Manag 128:144–160 Article   Google Scholar   Breiman L (2001) Random forests. Mach Learn 45(1):5–32 Article   Google Scholar   Brooks DB (2006) An operational definition of water demand management. Int J Water Resou Dev 22(4):521–528 Article   Google Scholar   Buysse J, Van Huylenbroeck G, Lauwers L (2007) Normative, positive and econometric mathematical programming as tools for incorporation of multifunctionality in agricultural policy modelling. Agric Ecosyst Environ 120(1):70–81 Article   Google Scholar   Chen J, Li M, Wang W (2012) Statistical uncertainty estimation using Random Forests and its application to drought forecast. Mathematical Problems in Engineering 2012, Article ID 915053: 12 pages Chhuon K, Herrera E, Nadaoka K (2016) Application of integrated hydrologic and river basin management modeling for the optimal development of a multi-purpose reservoir project. Water Resour Manag 30(9):3143–3157 Article   Google Scholar   Esmaeili A, Vazirzadeh S (2009) Water pricing for agricultural production in the south of Iran. Water Resour Manag 23(5):957–964 Article   Google Scholar   Fredericks JW, Labadie JW, Altenhofen JM (1998) Decision support system for conjunctive stream-aquifer management. J Water Resour Plan Manag 124(2):69–78 Article   Google Scholar   Gallego-Ayala J, Gómez-Limón J (2009) Analysis of policy instruments for control of nitrate pollution in irrigated agriculture in castilla y león, Spain. Span J Agric Res 7(1):24–40 Article   Google Scholar   Golan A, Judge G, Miller D (1997) Maximum entropy econometrics: Robust estimation with limited data. WILEY Press Gómez-Limón JA, Riesgo L (2004) Irrigation water pricing: differential impacts on irrigated farms. Agric Econ 31(1):47–66 Article   Google Scholar   Graham L, Labadie J, Hutchison I, Ferguson K (1986) Allocation of augmented water supply under a priority water rights system. Water Resour Res 22(7):1083–1094 Article   Google Scholar   Han J, Liu Y, Sun X (2013) A scalable Random Forest algorithm based on mapreduce. Software Engineering and Service Science (ICSESS), 4th IEEE International Conference on. pp. 849–852. IEEE Hashemy Shahdany SM, Hasani Y, Majidi Y, Maestre JM (2017) Modern operation of main irrigation canals suffering from water scarcity based on an economic perspective. J Irrig Drain Eng 143(3):B4016001-1-11 Article   Google Scholar   Hashimoto T, Stedinger JR, Loucks DP (1982) Reliability, resiliency, and vulnerability criteria for water resource system performance evaluation. Water Resour Res 18(1):14–20 Article   Google Scholar   He L, Tyner WE, Doukkali R, Siam G (2006) Policy options to improve water allocation efficiency: analysis on Egypt and Morocco. Water Int 31(3):320–337 Article   Google Scholar   Labadie JW (2006) Modsim: decision support system for integrated river basin management Google Scholar   Li J, Alvarez B, Siwabessy J, Tran M, Huang Z, Przeslawski R, Radke L, Howard F, Nichol S (2017) Application of random forest, generalised linear model and their hybrid methods with geostatistical techniques to count data: Predicting sponge species richness. Environ Model Softw 97:112–129. Madadgar S, Moradkhani H (2014) Spatio-temporal drought forecasting within bayesian networks. J Hydrol 512:134–146 Article   Google Scholar   Martínez-Santos P, Henriksen HJ, Zorrilla P, Martínez-Alfaro PE (2010) Comparative reflections on the use of modelling tools in conflictive water management settings: the mancha occidental aquifer, Spain. Environ Model Softw 25(11):1439–1449 Article   Google Scholar   Mcmahon TA, Adeloye AJ, Zhou SL (2006) Understanding performance measures of reservoirs. J Hydrol 324(1–4):359–382 Article   Google Scholar   Medellín-Azuara J, Harou JJ, Howitt RE (2010) Estimating economic value of agricultural water under changing conditions and the effects of spatial aggregation. Sci Total Environ 408(23):5639–5648 Article   Google Scholar   Medellín-Azuara J, Macewan D, Howitt RE, Koruakos G, Dogrul EC, Brush CF, Kadir TN, Harter T, Melton F, Lund JR (2015) Hydro-economic analysis of groundwater pumping for irrigated agriculture in california’s central valley, USA. Hydrogeol J 23(6):1205–1216 Article   Google Scholar   Mittelhammer R, Judge G, Miller D (2002) Econometric foundation. Cambridge Univ. Press, New York Google Scholar   Naghibi SA, Ahmadi K, Daneshi A (2017) Application of support vector machine, random Forest, and genetic algorithm optimized random Forest models in groundwater potential mapping. Water Resour Manag 31(9):2761–2775 Article   Google Scholar   Ouazar D, Doukkali M, Elyoussfi L (2017) A mathematical model for assessment of socio-economic impact of climate change on agriculture activities: cases of the east of Morocco (africa). Indian J Sci Technol 10(17) Paris Q, Howitt RE (1998) An analysis of ill-posed production problems using maximum entropy. Am J Agric Econ 80(1):124–138 Article   Google Scholar   Quinlan JR (1986) Induction of decision trees. Mach Learn 1(1):81–106 Google Scholar   Raafatisokhango AM 2010 Application of modsim systems analysis in decision support system (DSS). University of Mashhad Ferdowsi Reggiani P, Weerts A (2008) A bayesian approach to decision-making under uncertainty: an application to real-time forecasting in the river Rhine. J Hydrol 356(1–2):56–69 Article   Google Scholar   Roozbahani A, Zahraie B, Tabesh M (2013) Integrated risk assessment of urban water supply systems from source to tap. Stoch Env Res Risk A 27(4):923–944 Article   Google Scholar   Saravi MM, Shahbazi R, Malekian A (2015) Drought and water scarcity in iran: How to cope with and prepare for it? Research and Science-Policy Interfacing – Andreu et al. (Eds) © 2015 Taylor & Francis Group, London, ISBN 978–1–138-02779-4 Shortridge JE, Guikema SD, Zaitchik BF (2016) Machine learning methods for empirical streamflow simulation: a comparison of model accuracy, interpretability, and uncertainty in seasonal watersheds. Hydrol Earth Syst Sci 20:2611–2628 Article   Google Scholar   Shourian M, Mousavi SJ, Tahershamsi A (2008) Basin-wide water resources planning by integrating pso algorithm and modsim. Water Resour Manag 22(10):1347–1366 Article   Google Scholar   Steventon JD, Daust DK (2009) Management strategies for a large-scale mountain pine beetle outbreak: modelling impacts on american martens. For Ecol Manag 257(9):1976–1985 Article   Google Scholar   Tabesh M, Roozbahani A, Roghani B, Rasi Faghihi N, Heydarzadeh R (2018) Risk assessment of factors influencing non-revenue water using Bayesian networks and fuzzy logic. Water Resour Manag 32(11):3647–3670 Article   Google Scholar   Ticehurst JL, Newham LTH, Rissik D, Letcher RA, Jakeman AJ (2007) A bayesian network approach for assessing the sustainability of coastal lakes in new south wales, Australia. Environ Model Softw 22(8):1129–1139 Article   Google Scholar   Vaghefi SA, Mousavi S, Abbaspour K, Srinivasan R, Arnold J (2015) Integration of hydrologic and water allocation models in basin-scale water resources management considering crop pattern and climate change: Karkheh river basin in Iran. Reg Environ Chang 15(3):475–484 Article   Google Scholar   Varela-Ortega C, Blanco-Gutiérrez I, Swartz CH, Downing TE (2011) Balancing groundwater conservation and rural livelihoods under water and climate uncertainties: an integrated hydro-economic modeling framework. Glob Environ Chang 21(2):604–619 Article   Google Scholar   Voie ØA, Johnsen A, Strømseng A, Longva KS (2010) Environmental risk assessment of white phosphorus from the use of munitions — a probabilistic approach. Sci Total Environ 408(8):1833–1841 Article   Google Scholar   Wang QJ, Robertson DE, Haines CL (2009) A bayesian network approach to knowledge integration and representation of farm irrigation: 1. Model development. Water Resour Res 45(2):1–18 Article   Google Scholar   Zorrilla P, Carmona García G, Hera ADL, Varela Ortega C, Martinez Santos P, Bromley J, Henriksen HJ (2010) Evaluation of bayesian networks in participatory water resources management, upper guadiana basin, Spain. Ecol Soc 15(3):12 Article   Google Scholar   Download references Acknowledgements The authors would like to acknowledge the financial support of Esfahan Water Authority for this research under grant number 94/147. Author information Authors and Affiliations Department of Irrigation and Drainage Engineering, Aburaihan Campus, University of Tehran, Tehran, Iran Zohreh Sherafatpour & Abbas Roozbahani Water Productivity Office, Ministry of Energy, Tehran, Iran Yousef Hasani Corresponding author Correspondence to Abbas Roozbahani. Ethics declarations Conflict of Interest None. Additional information Publisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Rights and permissions Reprints and permissions About this article Cite this article Sherafatpour, Z., Roozbahani, A. & Hasani, Y. Agricultural Water Allocation by Integration of Hydro-Economic Modeling with Bayesian Networks and Random Forest Approaches. Water Resour Manage 33, 2277–2299 (2019). https://doi.org/10.1007/s11269-019-02240-9 Download citation Received 21 June 2018 Accepted 19 March 2019 Published 09 May 2019 Issue Date 15 May 2019 DOI https://doi.org/10.1007/s11269-019-02240-9 Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Keywords Water allocation Positive mathematical programming (PMP) Bayesian networks Random Forest Economic value of water Hydro-economic model Use our pre-submission checklist Avoid common mistakes on your manuscript. Sections Figures References Abstract Introduction Methodology Results and Discussion Conclusion Notes References Acknowledgements Author information Ethics declarations Additional information Rights and permissions About this article Advertisement Discover content Journals A-Z Books A-Z Publish with us Publish your research Open access publishing Products and services Our products Librarians Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility statement Terms and conditions Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"

Paper 2:
- APA Citation: Poni, S., Galbignani, M., Bernizzoni, F., Talaverano, M. I., & Magnanini, E. (2015). A Device Enabling Fully Automated Water-Deficit Experiments with Potted Grapevines. American Journal of Enology and Viticulture, 66(2), 251-255.
  Main Objective: To present a newly designed, automated water-supply system for conducting controlled water-deficit experiments on potted grapevines.
  Study Location: Unspecified
  Data Sources: Vine transpiration measurements, vine physiological parameters
  Technologies Used: Multichamber gas-exchange system, water-supply apparatus
  Key Findings: The automated water-supply apparatus effectively adjusted water delivery based on real-time measurements of vine transpiration, ensuring reliable water replenishment under varying water availability. The system maintained vine water status and enabled customizable water supply adjustments according to vine size and transpiration potential.
  Extract 1: "In addition to relieving operators of laborious and time-consuming manual irrigation, the system provides the ability to adjust water supply to actual water use as measured concurrently in a grapevine-enclosure system and enables customization of the water supply according to the size and transpiration potential of each vine."
  Extract 2: "The proposed system is a “closed-loop” process in which the operator defines a general control strategy, after which the control system determines when and how much water to apply based on feedback from one or more sensors (Zazueta et al. 1993)."
  Limitations: The study did not explicitly evaluate the system's performance in response to specific failures, disruptions, or unexpected events.
  Relevance Evaluation: The paper is highly relevant to the point of interest because it focuses on strategies for ensuring robustness and reliability in automated irrigation systems in the face of failures, disruptions, or unexpected events. The proposed automated water-supply apparatus provides an effective way to maintain soil and vine water status under controlled conditions, addressing the need for resilience and fault tolerance in automated irrigation systems.
  Relevance Score: 0.9
  Inline Citation: (Poni et al., 2015)
  Explanation: The study described the development of an automated water-supply device to conduct long-term water-deficit experiments on potted grapevines. This system precisely controls water replenishment based on real-time measurements of vine transpiration, gravimetrically or through whole-canopy gas exchange, making it well-suited for studying plant responses to varying water availability.

 Full Text: >
"Skip to main content Institution: University of Nebraska Lincoln Library Log in Log out Follow ajev on Twitter Follow ajev on Linkedin Search for this keyword Advanced Search Home Content Information For About Us Feedback Alerts Help Login ASEV MEMBER LOGIN Technical Brief A Device Enabling Fully Automated Water-Deficit Experiments with Potted Grapevines Stefano Poni, Marco Galbignani, Fabio Bernizzoni, Maria Inmaculada Talaverano, Eugenio Magnanini Am J Enol Vitic.  2015  66: 251-255  ; DOI: 10.5344/ajev.2014.14109 ArticleFigures & DataInfo & Metrics PDF Abstract Here, we describe a novel device for programming and replenishing water transpired by potted plants. To test the robustness of the system, vines were subjected to progressive water stress (WS), the severity of which was maintained in relation to transpiration (Tc) of well-watered (WW) plants. Throughout the 40-day experiment, water supply in the WS treatment was progressively lowered to 70, 50, and 30% of WW Tc prior to rewatering. During the same stages, mean Tc of WS plants was 74, 48, 28, and 93% that of WW plants. Linear relationships between vine transpiration and water supply during the 40-day experiment (R2 = 0.95 for WW and 0.94 for WS) confirmed the reliability of the system in providing a water supply that closely tracked measured transpiration. The emptying volume of the cylinder tank was set at 265 mL and proved to be adequate for daily water losses, which ranged from ~300 to 2300 mL. In addition to relieving operators of laborious and time-consuming manual irrigation, the system provides the ability to adjust water supply to actual water use as measured concurrently in a grapevine-enclosure system and enables customization of the water supply according to the size and transpiration potential of each vine. chamber systemwater supplytranspirationpotted vines As traditionally rainfed viticultural regions experience more frequent, temporary summer drought, in-depth knowledge about the adaptation of grape genotypes to varying severity of water deficit is needed. In Italy, comprehensive surveys of the response of certain genotypes to water stress have been performed for a few varieties, especially Sangiovese and Montepulciano (Merli et al. 2014, Palliotti et al. 2014), but little is known about this subject for most varieties. This knowledge gap has adverse consequences for several reasons: (i) typically, when supplemental irrigation must be introduced in areas that have no previous experience with irrigation management, overuse is common, leading to obvious overirrigation and vine imbalances; (ii) gaps in knowledge about genotype-related vine water requirements and responses to water stress make it difficult to gauge the level of water deficit the plant can withstand without compromising grape yield and quality but while restricting excessive vegetative growth; and (iii) if direct measurements of soil or plant water status (i.e., predawn or midday leaf water potential) cannot be made, decisions about if, when, and how to irrigate are made according to empirical methods such as visual observation of vines. A second issue is the choice of field versus pot studies, each of which has advantages and drawbacks. An advantage of field studies is that they are unbiased toward mature and fully productive experimental vines with no apparent root restrictions. However, in environments marked by variable summer rainfall, it is likely that severe stress will not occur in any given year unless a labor-intensive treatment, such as covering the berm early in the season to limit rainfall infiltration, is applied (Poni et al. 1994). Another major concern is that due to erratic root distribution in vineyards, targeting a given fraction of evapotranspiration replacement as the ratio of absorbed-to-delivered water is difficult. Site-specific assessment of vine water use is feasible using methods such as field lysimeters (Williams et al. 2003), sap-flow techniques (Ginestar et al. 1998), and trunk-diameter variation (Intrigliolo and Castel 2007), although these methods are time-consuming and allow only a limited number of vine replicates. We chose a pot study because: (i) stress can be induced and relieved easily without interference from the surrounding climate; (ii) actual vine water use can be determined gravimetrically prior to water stress, thus allowing precise control of stress severity; and (iii) the use of pots assures that all water supplied is available for root uptake. The proposed system is a “closed-loop” process in which the operator defines a general control strategy, after which the control system determines when and how much water to apply based on feedback from one or more sensors (Zazueta et al. 1993). In this type of system, feedback and control occur continuously. The majority of commercial microirrigation closed-loop control systems base irrigation decisions on sensors that measure soil moisture status (water potential or volumetric water content), use climatic data to estimate plant water use, or use a combination of these approaches. Systems that base decision making on plant water status are less common than those that use soil water status; a broadly marketed example is the Dynagage Flow32-1K Sap Flow system (Dynamax Inc., Houston, TX) in which the closed loop is established through a pump controller programmed to continuously deliver actual transpiration volumes as scanned through sap-flow readings (Van Bavel 1992). Our aims in the present study were to (a) describe a new, custom-built system for running fully automated long-term water-deficit trials on potted plants by embedding a whole-canopy gas-exchange apparatus and a device for programmed water replenishment; (b) provide examples of the kinds of datasets the system can deliver; and (c) assess whether the automated water supply maintains soil and vine water status under the expected conditions. Materials and Methods Water-supply apparatus The new water-supply device is embedded in the whole-canopy gas-exchange system described in detail by Poni et al. (2014). The system can concurrently monitor up to 12 chambers, and the switching interval is set at 90 sec. Figure 1 shows schematic and actual views of the automated water-supply apparatus, and Figure 2 shows the electrical wiring of the solenoid valve control system to the AM64 multiplexer. Items and relative costs needed to configure the system to measure vine transpiration gravimetrically or by whole-canopy gas exchange are shown in Table 1. Download figureOpen in new tab Figure 1 Actual view (A) and diagram (B) of the mechanical and hydraulic components of the water-supply system. 1: connection to the water pipeline; 2: valve for manual regulation of tank-filling speed; 3: solenoid valve for automated tank filling; 4: cylinder tank; 5: cylinder tank shaft; 6: adjustable volume of water supply; 7: stirrup connected to the cylinder shaft; 8: adjustable shaft dead end (adjustment is made through the stirrup); 9: spring for cylinder discharge; 10: valve for manual regulation of cylinder discharge speed; 11: solenoid valve for irrigation supply; 12: vine pots. Download figureOpen in new tab Figure 2 Layout for electrical wiring of the solenoid valves. CR10X: Campbell data logger; AM416: Campbell multiplexer; C: channel; GND: ground; RES: reset; CLK: clock; Com: common; H: high excitation voltage; BD649: Darlington transistor equipped with a protection diode; A: solenoid valve for filling cylinder tank; B: solenoid valve for vine water supply. View inlineView popup Table 1 List of components and relative current costs (USD) for assessing vine transpiration by gravimetric or whole-canopy gas-exchange methods. Material and equipment quantities are calculated for a system that accommodates 12 potted vines and an ambient reference. The core of the system is the cylinder tank (Figure 1, component 4), which is programmed to deliver water to the vine based on real-time measurements of vine transpiration. In brief, the system set-up, functioning, and operations are as follows: (i) the volume of water contained in the tank is determined by the length of shaft run (5) × the cylinder cross-section. Acting on the adjustable shaft dead end (8), the tank volume (6) to be loaded and delivered at any watering event can be set from 10 to 460 mL; (ii) when solenoid valve 3 is commanded to open, valve 2 is manually regulated so that water pulled under pressure from the urban pipeline fills the tank in ~15 sec; (iii) when valve 3 is shut off and one of the solenoid valves is concurrently opened (11), valve 10 is manually regulated so that the cylinder tank is pushed by the spring and shaft (9) to empty in ~40 sec; (iv) valve 3, the function of which is to fill the tank, is controlled by a Darlington transistor (item A in Figure 2) connected to the data logger through control line C4; (v) each of the 12 solenoid valves on the bench (11) is controlled by another Darlington transistor (item B in Figure 2) that functions to deliver water to each pot; cycling activation of the solenoid valves (11) is accomplished by the multiplexer AM416 via the control line Com H2 connected to the C3 clamp on the data logger (Figure 2). In summary, each watering event is activated by the following three steps: (1) the data logger activates the opening of valve 3 for 20 sec to allow filling of the cylinder from the urban pipeline; (2) the data logger deactivates valve 3 and waits for 0.5 sec; (3) the data logger activates the opening of one of the solenoid valves on the bench (11) and waits for up to 50 sec until the cylinder tank driven by the springs (9) returns to its initial, normally closed condition. The first decision required is the working volume of the cylinder tank, which must initially be set by the operator at a value between 10 and 470 mL and adjusted against the expected total diurnal vine transpiration. Volumes that are too small must be avoided because a significant proportion of the supplied water would evaporate from the soil surface and thus be unavailable for root absorption. Moreover, depending on the soil texture and infiltration rate, a low-volume supply may wet only the upper part of the root system. Conversely, when used under low vine-water demand, volumes that are too high may result in only one application per day, thus increasing diurnal soil-moisture fluctuations. Here, daily vine transpiration varied between ~300 and 2300 mL depending on the severity of the water deficit, and the volume of the cylinder tank was set at 265 mL. The system operates on the principle that the daily water supply to the vines can be replaced based on concurrent measurements of canopy transpiration. This makes water replenishment sensitive to large fluctuations in water use, which can occur depending on evaporative demand (e.g., cloudy days with low air vapor pressure deficit [VPD] versus clear days with high VPD) or as a result of new leaf development. For a water stress (WS) experiment, the system can be programmed to supply a group of plants with a specified fraction of the water delivered to a well-watered (WW) treatment. The replenishment coefficient that sets the fraction of water to be metered to WS can be adjusted according to prestress transpiration rates of each vine so that, for example, a more vigorous WS plant will receive more water than one with lower vigor. Plant material and treatment layout Data for system testing were derived from a water-stress experiment conducted in 2014 on twelve 2-year-old nonfruiting Vitis vinifera L. cv. Sangiovese grafted on SO4 rootstock and grown outdoors in 40-L pots. The pots were filled with a loam soil with 41% sand, 39% loam, 20% clay, pH 8.02, and organic matter content of 1.22%. Water content by volume, calculated after Saxton and Willey (2005) based on soil texture and organic matter, was 26.3% for maximum pot capacity and 12.9% for wilting point. Pots were painted white before the trial to limit radiation-induced overheating, and each vine was fertilized twice (one week before and two weeks after budbreak) with 5 g of Greenplant (15% N, 2.2% P, 20.7% K + 1.2% Mg + micronutrients) (Green Has Italia, Cuneo, Italy). Four shoots per vine were allowed to grow from the two 2-node spurs retained at winter pruning. Shoot growth was directed upward along the catch wires to fill all available space while providing optimal light exposure and minimizing mutual shading. Twelve vines of vertically positioned shoots were arranged along a single, 35° NE–SW-oriented row and randomly assigned to a WW or WS treatment. All vines were kept well watered until day of year (DOY) 174 (23 June) by supplying 1950 mL/vine daily, which corresponded to the actual mean canopy transpiration (Tc) measured by the whole-canopy system over the four days before beginning restricted irrigation. Starting on DOY 175, a progressive water deficit was imposed on half of the vines by programming the water-supply system to deliver 70% of WW Tc to each vine until DOY 183. From DOY 184 to DOY 196, the supply was reduced to 50% of WW Tc. Maximum stress (30% of WW Tc) was applied from DOY 197 to DOY 199; rewatering with 100% of Tc was performed on DOY 200 (19 July). During water stress, the pot surface in both treatments was covered with a plastic sheet to prevent infiltration of rainfall and to minimize losses due to soil evaporation. Gas-exchange and vine measurements Whole-canopy transpiration measurements were taken using the multichamber system described above. The chambers were set up on each vine and operated continuously (24 hr) from DOY 171 (20 June, 4 days before beginning the stress treatment) until DOY 209 (28 July, 9 days after rewatering). The flow rate fed to the polyethylene chambers (0.602 m3 ± 0.060) was set at 10 L/s and was kept constant throughout the measuring season; a complete volume air change occurred at intervals of ~60 sec. Tc (mmol H2O/sec) was calculated from flow rates and water vapor differentials after Long and Hallgren (1985). Upon dismantling the system on DOY 208, the vines were entirely defoliated and the surface of each blade was measured in the laboratory with a leaf-area meter (LI-3000A; LI-COR, Lincoln, NE). Progression of water stress was monitored by measuring predawn leaf water potential (Ψpd) on DOY 169, 184, 188, 197, 200, and 209. Measurements were taken before sunrise on three leaves per vine using a Scholander pressure chamber (Model 3500; Soilmoisture Equipment Corp., Santa Barbara, CA). On DOY 184, 188, 197, and 200, the chambers were snipped for quick access to the foliage and then were immediately resealed with transparent tape. Statistical analysis The degree of variation around means was given as standard error (SE). Linear regression analysis was used when appropriate. The SyStat Software (San Jose, CA) was used. Results and Discussion There was a close linear relationship between vine transpiration and water supply for the 40 days of measurement data (Figure 3). Deviation from the 1:1 relationship was between 3 and 6%, and root mean square error was 72 mL for WW and 127 mL for WS. Such a close relationship confirms the reliability of the system for supplying vines with a volume of water that closely tracks measured transpiration. As the severity of the water stress increased from 100% to 70%, 50%, and 30% of WW, the actual fraction of water supplied to WS vines was 102% (average of prestress and rewatering), 67%, 46%, and 26%, respectively; these rates indicated that under water deficit, the system tended to deliver slightly less water than the defined threshold. This suggests that at the low daily transpiration rates recorded for WS plants (~300 to 1000 mL/vine), a slight reduction of the cylinder tank operating volume would be advisable. However, as shown in Figure 3, the defined threshold of 265 mL per watering event was well suited to the 400 to 2300-mL range of vine transpiration values. These metering rates are low compared to those measured in the field (Williams et al. 2003) because of the small canopy size of our vines, which had a final leaf area of 1.55 ± 0.107 m2 (WW) and 1.48 ± 0.077 m2 (WS). Specific transpiration rates calculated over the rewatering period when all vine canopies had reached full size were ~0.8 L/m2·day, a value close to those measured by Poni et al. (2014) and Palliotti et al. (2014) under comparable conditions. Download figureOpen in new tab Figure 3 Relationship between daily canopy transpiration measured by the chambers and daily vine water supply for the well-watered (•) or water stressed (○) treatments. Data are single daily values averaged from dawn to dusk during the chamber operating period (DOY 171–209). Linear equations: WW, y = 1.068x, R2 = 0.95; WS, y = 0.974, R2 = 0.94. Slopes of single regressions of WW and WS data did not differ according to the test of equality of slopes (p = 0.05). The dashed line indicates the 1:1 relationship. Clearly, reliability of the system also depends upon accurate assessment of canopy transpiration, its driving factor. Close correlations have also been found between gravimetric daily vine water loss and canopy transpiration calculated by gas exchange on vines with final leaf area ranging from 3 to 14 m2 (Poni et al. 1999, 2014). Given that whole-canopy gas-exchange systems are sophisticated and specialized, the automated water-supply device easily fits with other methods, including gravimetric, heat-balance sap flow, and trunk diameter measurements. Predawn leaf water potential (Ψpd) progressively decreased with the gradual reduction of the Tc fraction supplied and reached its lowest value (≅ −0.8 MPa) toward the end of the 30% Tc replenishment (data not shown). A steep decrease in Ψpd occurred when the water supply in WS was lowered from 50 to 30% of WW. One week after rewatering on DOY 200, Ψpd of previously stressed vines promptly recovered to the same level as that of the WW vines (−0.1 MPa). The experimental period (DOY 171–209) had notably variable weather, with large fluctuations in average daily PAR and VPD (Figure 4A). Overall, stable weather with conditions conducive to high evaporative demand occurred only at the end of the 50% Tc deficit period and for 3 days during 30% Tc. The seasonal trends of canopy transpiration measured in WW and WS reflected these fluctuations, and average Tc during the prestress, 70, 50, 30%, and rewatering supply levels was 103, 74, 48, 28, and 93% of the Tc rates recorded in WW, respectively. Thus, despite day-to-day variability, the restriction in water use was fairly proportional to the severity of the imposed shortage, indicating that the system worked properly. The Ψpd value (−0.8 MPa) reached at the end of the stress cycle confirms that the system is suitable for short-term water deficit experiments in which progressive water stress is applied to vines. Download figureOpen in new tab Figure 4 (A) Seasonal trends of daily mean air vapor pressure deficit (VPD) and incoming photosynthetically active radiation (PAR); (B) whole-canopy transpiration (Tc) measured on Sangiovese grapevines that were well-watered (•) or water stressed (○). In panel B, the duration of each water deficit level is shown by the horizontal bar (left to right: 70, 50, and 30% of vine transpiration). Vertical bars indicate SE (n = 6). Arrow indicates rewatering. To examine the accuracy of the system over a wider range of instantaneous Tc, diurnal trends in Tc are shown for DOY 184, the first day of 50% water deficit, during which there were clear-sky conditions and high evaporative demand (Figure 5A, B). Well-watered vines showed a bell-shaped Tc trend that closely tracked incoming PAR. There were 7.5 watering events that yielded a total of 1987 mL water supply versus the cumulative daily Tc value of 1897 mL. In WS, the Tc trend was slightly more variable throughout the day, during which 3.5 watering events provided 927 mL of total supplied water versus a cumulative Tc value of 975 mL. Download figureOpen in new tab Figure 5 (A) Diurnal trends (dawn to dusk) of air vapor pressure deficit (VPD) (⋄) and incoming photosynthetically active radiation (PAR) (•); (B) whole-canopy transpiration (Tc) measured on DOY 184 (first day of 50% water deficit in WS) in well-watered (•) or water stressed (○) Sangiovese grapevines. Vertical bars indicate SE (n = 6). Conclusions A new system designed to perform automated, unattended water-deficit experiments on potted plants was successfully tested. In addition to exempting operators from laborious and time-consuming manual irrigation, the system has the ability to calibrate water supply according to actual water use measured concurrently using a vine-enclosure system, and it can customize the water supply according to plant size and transpiration potential. If a whole-canopy gas-exchange apparatus cannot be put in place, the system is preconfigured to log signals from a set of scales that can measure gravimetric vine water loss. This equipment would be valuable for automating trials examining genotype response to drought, a subject for which data are needed given the effects of global warming on grapevine water relations. Footnotes Received September 2014. Revision received November 2014. Accepted November 2014. Published online May 2015 ©2015 by the American Society for Enology and Viticulture Literature Cited ↵Ginestar C., Eastham J., Gray S. and Iland P.. 1998. Use of sap-flow sensors to schedule vineyard irrigation. I. Effects of post-veraison water deficits on water relations, vine growth, and yield of Shiraz grapevines. Am. J. Enol. Vitic. 49:413–420.Abstract/FREE Full TextGoogle Scholar ↵Intrigliolo D.S. and Castel J.R.. 2007. Evaluation of grapevine water status from trunk diameter variations. Irrig. Sci. 26:49–59.Google Scholar ↵Long S.P. and Hallgren J.E.. 1985. Measurement of CO2 assimilation by plants in the field and the laboratory. In Techniques in Bioproductivity and Photosynthesis. Coombs J., et al. (eds.), pp. 62–93. Pergamon Press, Oxford, UK.Google Scholar ↵Merli M.C., Gatti M., Galbignani M., Bernizzoni F., Magnanini E. and Poni S.. 2014. Water use efficiency in Sangiovese grapes (Vitis vinifera L.) subjected to water stress before veraison: Different levels of assessment lead to different conclusions. Funct. Plant Biol. 42:198–208.Google Scholar ↵Palliotti A., Tombesi S., Frioni T., Famiani F., Silvestroni O., Zamboni M. and Poni S.. 2014. Morpho-structural and physiological response of container-grown Sangiovese and Montepulciano cvv. (Vitis vinifera) to re-watering after a pre-veraison limiting water deficit. Funct. Plant Biol. 41:634–647.Google Scholar ↵Poni S., Lakso A.N., Turner J.R. and Melious R.E.. 1994. Interactions of crop level and late season water stress on growth and physiology of field-grown Concord grapevines. Am. J. Enol. Vitic. 45:252–258.Abstract/FREE Full TextGoogle Scholar ↵Poni S., Intrieri C. and Magnanini E.. 1999. Set-up, calibration and testing of a custom-built system for measuring whole-canopy transpiration in grapevine. Acta Hort. 493:149–160.Google Scholar ↵Poni S., Merli M.C., Magnanini E., Galbignani M., Bernizzoni F., Vercesi A. and Gatti M.. 2014. An improved multichamber gas exchange system for determining whole-canopy water-use efficiency in grapevine. Am. J. Enol. Vitic. 65:268–276.Abstract/FREE Full TextGoogle Scholar ↵Saxton K.E. and Willey P.H.. 2005. The SPAW model for agricultural field and pond hydrologic simulation. In Watershed Models. Frevert D.K. and Singh V.P. (eds.), pp. 400–435. Taylor & Francis, Boca Raton, FL.Google Scholar ↵Bavel Van M.G. 1992. Stem flow gauges for measurement of crop water use. Nat. Irr. Convention. Proc. First Austr. Irr. Expo, May 1992, pp. 59–72.Google Scholar ↵Williams L.E., Phene C.J., Grimes D.W. and Trout T.J.. 2003. Water use of mature Thompson Seedless grapevines in California. Irrig. Sci. 22:11–18.Google Scholar ↵Zazueta F.S., Smajstrla A.G. and Clark G.A.. 1993. Irrigation system controllers. Univ. of Florida, IFAS, Coop. Exten. Pub. AGE-32. http://edis.ifas.ufl.edu/ae077.Google Scholar Previous Next Back to top Vol 66 Issue 2 Table of Contents Table of Contents (PDF) Index by author Print View full PDF Email Article Citation Tools Request Permissions Share Save to my folders Jump to section Article Abstract Materials and Methods Results and Discussion Conclusions Footnotes Literature Cited Figures & Data Info & Metrics PDF Related Articles No related articles found. Google Scholar Cited By... More from this TOC section Similar Articles AJEV Content Current Volume Archive Best Papers ASEV National Conference Technical Abstracts Print on Demand Information For Authors AJEV Preprint and AI Software Policy Open Access/Subscription Publishing Submission Subscribers Permissions and Reproductions Advertisers Other Home About Us Feedback Help Alerts Catalyst ASEV © 2024 American Society for Enology and Viticulture.  ISSN 0002-9254."

Paper 3:
- APA Citation: Desai, A. A., Metri, R. A., Patil, S. R., Nagargoje, A. A., & Desai, D. S. (2023). Automated Irrigation System for Efficient and Portable Farming. 2023 International Conference on Power, Instrumentation, Control and Computing, 1-6. https://doi.org/10.1109/PICC57976.2023.10142376
  Main Objective: To develop a fully automated irrigation system that integrates moisture-based and timer-based control for optimal water and electricity usage.
  Study Location: Unspecified
  Data Sources: Field survey, Literature review
  Technologies Used: Real-time control (RTC) module, Moisture sensors, Solenoid valve, Embedded C programming
  Key Findings: The proposed system combines moisture sensors with a real-time clock to optimize irrigation schedules, resulting in significant savings in electricity and water consumption. The integrated approach enhances the system's resilience and fault tolerance, reducing the need for manual intervention.
  Extract 1: The proposed system consists of RTC module, so the date and time is set in the controller and accordingly the water is given to the crops. Furthermore, to make the system robust, sensors are employed in the soil.
  Extract 2: The proposed hardware is shown in Fig. 8. It has one rack which contains 3 layers; each layer has different placement in it and independent irrigation control.
  Limitations: The study was conducted in a controlled environment using a rack structure and may need adaptation for different farming conditions and crop types.
  Relevance Evaluation: This paper is highly relevant to the point of focus regarding strategies for ensuring robustness and reliability in automated irrigation systems. It specifically addresses the challenge of optimizing water and electricity usage while enhancing the system's resilience and fault tolerance. The paper's findings on integrating moisture and timer-based control contribute to the development of more efficient and reliable automated irrigation systems.
  Relevance Score: 0.9
  Inline Citation: (Desai et al., 2023)
  Explanation: The study titled "Automated Irrigation System for Efficient and Portable Farming" aims to develop an automated irrigation system for optimal water and electricity usage in agricultural settings. The system integrates both moisture-based and timer-based control mechanisms to overcome the limitations of existing approaches. By integrating moisture sensors with a real-time clock, the system automatically adjusts irrigation schedules based on soil conditions while adhering to predefined timetables.

 Full Text: >
"IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Conferences >2023 International Conference... Automated Irrigation System for Efficient and Portable Farming Publisher: IEEE Cite This PDF Aditya A. Desai; Rajanikant A. Metri; Shreyas R. Patil; Aishwarya A. Nagargoje; Devika S. Desai All Authors 44 Full Text Views Abstract Document Sections I. Introduction II. Related Work III. Proposed System IV. Hardware Implementation V. Results and Discussions Show Full Outline Authors Figures References Keywords Metrics Abstract: The practise of farming has endured significant transformation as technology advances every day. The constraints of area and nonlinear nature of climatic conditions, polyhouse kind of concepts are increasing, which is helpful in production of flowers, vegetables and fruits. The proposed work discusses such an automated irrigation system that highlights the optimum solution for the efficient use of water and electricity for agricultural purposes. Field survey and literature shows that the existing systems are available with two solutions, one is timer-based and another one is moisture-based automization. Moreover, the timer-based system has demerits like being semi-automated i.e., timer needs to be changed manually according to climate. Similarly, in moisture-based systems, reliability is the issue. Therefore, the main objectives of the proposed work are to overcome the demerits of the present systems by integrating both the systems, to develop a fully automated irrigation system, to manage the use of water, electricity, and to add a remote controlling system. The report includes algorithm for the integration of moisture and timer-based system which provides the optimum efficiency on the water use and the use of solenoidal valve. Published in: 2023 International Conference on Power, Instrumentation, Control and Computing (PICC) Date of Conference: 19-21 April 2023 Date Added to IEEE Xplore: 08 June 2023 ISBN Information: DOI: 10.1109/PICC57976.2023.10142376 Publisher: IEEE Conference Location: Thrissur, India SECTION I. Introduction The process of farming has witnessed dramatic change as technology advances every day. The demands for off-season yields has dramatically increased, and when traditional methods were formerly deemed to be sufficient for crop production, they now have little application and appeal to consumers. India's ground water levels are critically low and present irrigation systems are poor in efficient water and energy management. Moreover, the situation is similar all over the World. So there is definite need of developing the efficient system for irrigation of water. Traditional farming practises in India have changed because of concepts like polyhouse [1], which also offers new chances to increase productivity while using fewer resources. The motivation behind this work is as follows: It takes time for the farmers to visit their fields to check the moisture content. They turn on the motor and wait till there is enough water in the tank before watering the land. It takes a lot of time and is unpleasant. Any unconsciousness could result in excessive watering. Over-irrigating refers to providing too much water to the soil. The productivity of crops is harmed by this. Additionally, it is a waste of water. Power usage in-creases. Thus, the price of irrigation rises. Smart irrigation systems [2]–[5] automatically adjust watering schedules and run times to suit unique landscape requirements. Farmers will find it easy to steer the motor away from them. This will make their lives and work easier. This article proposes an automated irrigation system that highlights the optimum solution for the efficient use of water and electricity for agricultural purposes. There are some existing systems who came up with two solutions, one is timer-based [6] and another one is moisture-based [7], [8] automation. The timer-based approach includes drawbacks such being semi-automated, or the necessity to manually modify the timing in accordance with the weather. Similar problems with reliability exist in moisture-based systems. Therefore, the major contributions of the article are to construct a completely automated irrigation system, monitor the usage of water and electricity, and add a remote controlling system in order to eliminate the drawbacks of the existing systems by merging both systems. The employment of solenoidal valve and siphoned technology reduces the consumption of less water and power therefore increasing the overall system efficiency, while the integration of moisture and timer-based system produces better quality crops. The rest of paper is arranged as follows. Section II briefs about the existing technologies used in automated irrigation system. In Section III, the overall block diagram and algorithm of the proposed system is discussed. The hardware and implementation part is discussed in Section IV. In Section V the analysis of results is carried out. Section VI lists the conclusions. SECTION II. Related Work A. Literature Survey Despite being a more sustainable agricultural method than monoculture, polyculture involves more manual labour and is more difficult to automate. In this article, we suggest a quick, first-order simulator that models plant growth in a polyculture environment. However, it has not yet been tried in a real garden. Simulation trials imply that the simulator can be used to learn a planting, watering, and pruning strategy a robot can follow to produce the most yield from a variety of plants with minimal irrigation. In the future, we'll do research to create a completely automated controller that will run planting, irrigation, and trimming equipment in a real garden during various plant growth cycles [1]. Automation is practised in various fields by different technologies [9]–[11]. An embedded controller PIC 16F877A, moisture sensor, and an induction valve have all been used in an attempt to create an automatic irrigation system. The sensors are utilised to gauge the soil's moisture content and adjust the valve accordingly. [12]. Data pertaining the microcontroller-based automated irrigation system has been attempted to give (ATMEGA 328). With an automated irrigation control system based on an ATMEGA 328 and GSM module, an effort is made to give continuous readings of soil humidity and ambient temperature [13]. To control the temperature and relative humidity inside polyhouse using microcontroller is discussed in [14]. The tracking and record-keeping of seedlings and other agricultural products during the germination and growth stages is illustrated using an internet of things (IoT)-based greenhouse traceability model [15]. A model for polyhouse using various sensors and IoT have been proposed by the researchers [16]–[20]. A closed loop irrigation system that completely automates the distribution of irrigation water and determines in real time the amount of water needed using satellite photos is exhibited in [21]. MATLAB/Simulink is used to build and model a structure for an automated control system of the soil's moisture within the modular field using subterranean irrigation. [8]. B. Field Survey For further understanding we have visited one automated irrigation system i.e. Suman Agro Industries, Itkare. The system is provided by Jain solutions; and it costs a huge amount. The firm have implemented the timer based irrigation system for open fields. The actual field on which dripper lines are laid is shown in Fig. 1. Fig. 1. Automated irrigation system at itkare Show All SECTION III. Proposed System The proposed system is elaborated in the following two subsections. A. Block Diagram The block diagram of the proposed system is shown in Fig. 2. The flow of water from water tank to field is controlled by a solenoid valve and motor. The control signal is given to motor from controller. The controller is connected with real-time control (RTC) module which provides actual time and date. Also, the controller receives signals from moisture sensor. Hence, RTC and moisture sensors are two major inputs for controlling. The overall controlling of water is done by following way. The water is stored in upper tank and supplied to each rack independently. Then each rack has its own 12 V motor for individual flow control. Motor is actuated by relay while signal for each really is given by a microcontroller. Fig. 2. Block diagram of proposed system Show All B. Flowchart The working of overall proposed work is illustrated through flowchart which is as given below. The proposed system consists of RTC module, so the date and time is set in the controller and accordingly the water is given to the crops. Furthermore, to make the system robus, sensors are employed in the soil. The Fig. 3 shows the 1st week operation logic where every alternate day watering to the crops is done or if moisture level goes down then based on the moisture sensor water is supplied, taking care of crops with desired water. Similarly for Fig. 4 and Fig. 5 demonstrate the operations of 2nd and 3rd week respectively. Here, if input date and input time are matched with the set date and set time then the motor is turned ON. Then proper delay is applicable to keep motor turned on for certain pre-defined time, which is calulated based on the crop study, after that signal is provided so that motor turns OFF. The overall system is programmed using embedded C code and downloaded to microcontroller. Fig. 3. Flowchart for 1stweek Show All Fig. 4. Flowchart for 2ndweek Show All Fig. 5. Flowchart for 3rdweek Show All SECTION IV. Hardware Implementation A. Plan of Installation The test bench of the proposed work planned in rack structure and is prepared as depicted in Fig. 6. The same is built at Tulip Farms Project location, as shown in Fig. 7. The test bench consists of four racks and each rack have dimensions as: height of approximately 7 feet, length of 11 feet and width of 2 feet. The rack is made of metal (iron) for robust structure. These structures are generally named as ‘Model - D’ which are used for balcony or terrace of the house. These movable racks can help to move the polyhouse structures from one place to other place very easily and conveniently. There are two tanks available in polyhouse as per the proposed plan. One tank contains water and other tank contains nutrition. Every rack has different pipeline of water and nutrition and whose flow will be controlled either by solenoidal valve or small 12V DC pumps according to requirement. B. Actual Hardware The proposed hardware is shown in Fig. 8. It has one rack which contains 3 layers; each layer has different placement in it and independent irrigation control. Fig. 6. Actual plan of installation Show All Fig. 7. Making of test bench Show All Fig. 8. Model D structure of test bench Show All Fig. 9. Control unit for the test bench Show All Each layer is provided with the different moisture sensors and different motors for controlling flow of water. Fig 9 is of the controlling unit which has controller LCD relay and RTC placed on it Each relay is connected to different motors of different layers while connections of moisture sensor is connected to different pins of controller. SECTION V. Results and Discussions The results acquired by proposed hardware model are compared with the conventional timer-based farm model. The performance criteria are decided by considering most significant factors while implementing the automation for any system. Therefore, energy, cost and effort are taken as comparison parameters. The first comparison is based on the power usage and second is on the water usage and the third comparison is based on the human efforts required for conventional system and proposed system. A. Power Usage Calculations are made considering the maximum running time of motor is 30 minutes. Comparison of power usage by proposed system and conventional system is given in Table I. Table I Quantitative analysis of electricity by proposed and conventional systems The calculations shows that there is almost 50% saving on a particular crop by the use of proposed method. B. Water Usage Comparison of water usage by proposed system and con-ventional system is given in Table II. From the comparison, it is evident that there is saving of water in the proposed system. Table II Quantitative analysis of water usage by proposed and conventional systems C. Human Efforts In conventional system no matter what you have to put one person for monitoring and control of motor in our case these human are eliminated by incorporating automation for sake of convenience we have considered half hour of human efforts in entire month. Fig. 10. Comparison of proposed system with conventional Show All The Fig. 10 shows graphical view of comparison of both systems in terms of electricity usage, water usage and human efforts. In all of these aspects the proposed system comes looks better choice. In case of electricity usage proposed system save around 50 percent of money spend on electricity. The graph also shows the total water usage of the system which is comparatively lot lower than conventional one. It can easily save 40 percent of water by implementing the automated system. Looking towards human efforts column we can easily say proposed system eliminates conventional one, in this case with saving around 90 percent of human efforts. SECTION VI. Conclusion The automated system is built independently for moisture sensor-based control and RTC-based control. Both systems are integrated together after satisfactory operation. A schedule programme is prepared for a few crops. System has been changed to provide maximum effectiveness. A microcontroller is used in the design and development of the automated irrigation system, which is constructed on a rack structure. Results from the devised system are contrasted with those from the standard system. After comparing our system to the old one, we found that it offers superior efficiency in terms of water and electricity use, making it the optimal replacement for the existing system. Also, in comparison to a typical system, human efforts are insignificant. This proposed automated irrigation system can be further incorporated with artificial intelligence (AI) and machine learning technologies for remote monitoring and control. Authors Figures References Keywords Metrics More Like This Report on Reliability Survey of Industrial Plants, Part V: Plant Climate, Atmosphere, and Operating Schedule, the Average Age of Electrical Equipment, Percent Production Lost, and ... IEEE Transactions on Industry Applications Published: 1974 The Effect of Water Saving and Production Increment by Drip Irrigation Schedules 2013 Third International Conference on Intelligent System Design and Engineering Applications Published: 2013 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."

Paper 4:
- APA Citation: Kim, Y., Abdel-Haleem, H., Luo, Z., & Szczepanek, A. (2022). Open-source electronics for plant phenotyping and irrigation in controlled environment. Smart Agricultural Technology, 3, 100093.
  Main Objective: To develop a portable, low-cost, and open-source electronic system for plant phenotyping and irrigation control.
  Study Location: Unspecified
  Data Sources: Plant phenotyping metrics: vegetation index, canopy coverage, plant height, and temperature
  Technologies Used: Microcontroller, Raspberry Pi, multispectral camera, soil moisture sensors, water pumps, temperature\humidity sensor, LCD screen
  Key Findings: The developed system successfully produced two different water treatments and effectively created drought environment that was used in plant phenotyping for drought resistance.  Camelina genotype 1 showed tolerance responses under H, D, and HD conditions.
  Extract 1: Automation of each component of the irrigation management pipeline, from data collection and transmission to processing, analysis, decision-making, and automated action, is systematically analyzed.
It investigates the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
  Extract 2: Highlighting the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline, the review seeks to identify existing and emerging standards and their applicability to real-time irrigation management systems.
  Limitations: None
  Relevance Evaluation: The study is relevant to the point in the literature review that discusses the importance of integrating automated systems with existing irrigation infrastructure for effective resource management. The study provides a detailed description of how to develop a low-cost and open-source system that can be used for plant phenotyping and irrigation control. It also demonstrates the effectiveness of the system in characterizing phenotypic responses of camelina plants to heat and drought stress.
  Relevance Score: 0.9
  Inline Citation: (Kim et al., 2022)
  Explanation: The goal of this study was to develop a portable, low-cost, and open-source electronic system for plant phenotyping and irrigation control. The system was developed using Arduino-Raspberry Pi protocol and image analytics for remote monitoring of plant phenotypes, integration of an irrigation controller for water management, and identifying phenotypic responses of camelina plants to heat and drought stress.

 Full Text: >
"Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue View Open Manuscript Outline Highlights Abstract BetaPowered by GenAIQuestions answered in this article Keywords Introduction Materials and methods Results Discussion Conclusions Declaration of Competing Interest Acknowledgments References Show full outline Cited by (5) Figures (12) Show 6 more figures Tables (3) Table 1 Table 2 Table 3 Smart Agricultural Technology Volume 3, February 2023, 100093 Open-source electronics for plant phenotyping and irrigation in controlled environment Author links open overlay panel James Y. Kim a, Hussein Abdel-Haleem b, Zinan Luo b, Aaron Szczepanek b Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.atech.2022.100093 Get rights and content Under a Creative Commons license open access Highlights • Cost-effective portable high-throughput phenotyping system developed for plant breeding in controlled environment. • Seamless integration of multi-modal sensor system to implement irrigation control and plant phenotyping. • Characterized phenotypic differences of camelia genotypes with plant-level metrics. Abstract Integration of plant phenotyping and irrigation is particularly advantageous for identifying genetic variation associated with crop productivity. Collecting phenotypic data and water management under controlled or open environment can be expensive and laborious. This study aims to design a cost-effective solution for high-throughput phenotyping (HTP) and automated irrigation using open-source electronics. A portable HTP system was developed using a microcontroller and a single-board computer Raspberry Pi and was extended to include soil water monitoring and water pump control. An Arduino board was integrated with a multispectral camera, mini LiDAR sensors, infrared thermometers, soil moisture sensors, water pumps, and a temperature/humidity sensor. Sensor calibration and power management enhanced the accuracy and reliability of the system. Two genotypes (CAM212 and Giessen#4) of camelina were used to evaluate the system to measure phenotypic responses to abiotic stress in growth chambers under two temperatures (25 °C and 35 °C) and two water treatments (40% and 90% water holding capacity). The HTP system monitored 24 plants periodically, and data were wirelessly accessed by a smartphone and transferred to a computer for further analyses. The system revealed that camelina genotype 1 (CAM212) showed superior resistance to heat and drought stress. The results showed that the developed HTP system offers a cost-effective and portable solution for phenotyping and water management in controlled environment and can be modified for field applications. Previous article in issue Next article in issue Questions answered in this article BetaPowered by GenAI This is generative AI content and the quality may vary. Learn more. How does Arduino support both plant phenotyping and irrigation? How does the system perform plant phenotyping? How does the use of Arduinos and Raspberry Pi benefit plant phenotyping? How does the system achieve remote monitoring of plant phenotypes? What was considered when designing the cost-effective solution for plant phenotyping and automated irrigation? Keywords PhenotypingIrrigationSensorImage processingArduinoRaspberry Pi Introduction Plant breeding promotes the development of new cultivars for sustainable agriculture and requires measurement of phenotypic responses developed from the interaction of genotypes with the environment. High-throughput phenotyping (HTP) equipped with novel sensing and analytical capabilities is essential to improve genetic modeling and thus expedites the identification of germplasm that increases the crop productivity. HTP systems have been used in plant phenotyping to identify crop responses to abiotic stress and to discover novel traits related to tolerance [1,2]. Image-based phenotyping became a promising HTP tool because of the improvement in handling large numbers of images. Multispectral cameras have been widely used for plant phenotyping [[3], [4], [5]]. Various image processing pipelines were developed to assess plant vigor by NDVI [6], growth rate by measuring leaf area [7], and shoot phenotypes by image classification [8]. HTPheno software [9] was reported to automate image analysis of a single barley plant at a time. An ideal image analytic toolbox is to process multiple plants through the automated image processing. Canopy temperature was used for plant stress detection [[10], [11], [12]] and phenotyping [[13], [14], [15]] using infrared (IR) thermometers. Plant height has been measured for plant phenotyping by Light Detection and Ranging (LiDAR) [[16], [17], [18], [19]] or ultrasonic sensors [13,15]. Microcontroller-based systems are low-cost, highly configurable computing devices that have transformed the field of agricultural research. Arduino is an open-source electronics consisting of microcontroller hardware and Arduino software for programming and has been identified as a viable alternative for commercial instrumentation in scientific research [20]. The wide variety of inexpensive hardware and availability of open-source code libraries make Arduino the best choice for data loggers [21]. The plug-and-play nature of Arduino devices has attracted researchers for power-efficient systems [22] such as plant growers [23], environmental monitoring [24], and harvest management [25]. Prior applications of Arduino on water management include water conservation [26], water quality [27], irrigation [[28], [29], [30]], and water intake [31]. Most applications focus on irrigation control from soil water feedback [[32], [33], [34]] or plant sensing [[35], [36], [37]]. Breeding research increased the need to support both plant phenotyping and percipient irrigation for effective plant monitoring under the water stress maintained by an irrigation controller. Raspberry Pi (RPi) is a compact single-board computer created for the development of a small and affordable computing platform for education [38]. Open-source software such as Python provides a flexible design of open-source systems and allows users to address specific needs in agronomic and environmental monitoring. A growing population of researchers use RPi computers for a wide range of applications: autonomous farming machines [39], pest detection in livestock feed storage [40], and plant phenotyping [41,42]. Arduinos along with the Raspberry Pi (RPi) pack considerable power on their diminutive boards, making them ideal for integration into scientific sensors and providing tremendous opportunities for automation, networking, and data collection and analysis [22]. This inexpensive open-source protocol increased the possibilities of design and resources available for troubleshooting. Although many applications of this protocol were reported, there are only a few applied on plant phenotyping [1,2]. Details of sensor integration, power management, and sensor calibration are not sufficiently provided. This research aims to develop a cost-effective HTP system to measure plant responses under abiotic stress using open-source electronics associated with sensor integration, calibration, and power management. Specific objectives are to (1) build a portable HTP system using Arduino-RPi protocol and image analytics for remote monitoring of plant phenotypes, (2) add an irrigation controller to the system to support water management for drought study, and (3) apply the system on camelina plants in growth chambers to identify phenotypic responses to heat and drought stress. Materials and methods In order to support plant phenotyping and automated irrigation, a cost-effective reliable solution was considered for end-users to enable them to afford sensing systems and expand their applications. A portable wireless HTP system was designed to offer quick installation and easy modification and was developed using Arduino Uno (DFR0216, DFRobot, China) and RPi (3B+, Raspberry Pi Foundation, UK). An irrigation controller was needed to automate water management for drought study and was integrated with the HTP system. The system was applied on camelina plants in growth chambers to characterize agronomic traits conditioning abiotic stress tolerance. Sensing system Plant phenotyping Metrics for plant phenotyping included canopy temperature, plant height, and vegetation indexes measured by infrared (IR) thermometers (SEN0206, DFRobot, China), mini LiDAR sensors (SEN0259, DFRobot, China), and multispectral cameras (Survey3W, MAPIR, San Diego, CA, USA), respectively. The IR thermometer measures the surface temperature by detecting IR radiation energy and wavelength distribution through an amplifier with 17-bit ADC. The sensor has a 35° field of view (FOV) with 0.01 °C precision and ±0.5 °C accuracy and is connected through inter-integrated circuit (I2C) to the microcontroller. An I2C multiplexer (DFR0576, DFRobot, China) was used to solve the address conflict of multiple IR thermometers on a single I2C port by providing addresses from 0x70 to 0x77. The LiDAR sensor is an unidirectional laser range finder based on time-of-flight (ToF) technology and measures the distance in the range of 0.3–12 m at 2° FOV in 100 Hz with 1-mm resolution and ±6 cm accuracy. The sensor is interfaced through a universal asynchronous receiver\\transmitter (UART). In order to connect multiple LiDAR sensors on one UART port in the microcontroller, software serial was used through digital ports such that Rx (receiver) and Tx (transmitter) wires were defined in SoftwareSerial function in the Arduino program. The LiDAR sensor ran at higher amperage than the maximum current provided from the microcontroller, and thus an external power source was required to achieve stable operation of the LiDAR sensor. A temperature\\relative humidity (T\\RH) sensor (DHT22, DFRobot, China) was used to monitor the temperature and humidity in the chamber. The sensor delivers digital output of the temperature with 0.1 °C precision and ±0.5 °C accuracy and humidity with 0.1% resolution and ±2% accuracy. It is connected through a standard single-bus digital interface. An LCD screen (DFR0063, DFRobot, China) was added to the microcontroller through the I2C multiplexer to display T\\RH with a time stamp. A multispectral (Red, Green, and Near-infrared) camera was attached in nadir view to monitor the plant vegetation index (VI) and leaf area index (LAI) and triggered by a pulse-width modulation (PWM) signal from the microcontroller. Image analytics The images captured by the multispectral camera were processed through a series of steps as shown in Fig. 1. The raw image is acquired in 3-band (3b) false color in the order of red (R), green (G), and near-infrared (N) with 4000 × 3000 resolution and 16-bit depth. They were preprocessed for conversion from raw to tif format and radiometric calibration to deliver canopy reflectance with a reflectance target board provided by the camera manufacturer. An image processing pipeline was developed for HTP through thresholding, filtering, masking, segmentation, and gridding (Fig. 1). A normalized difference vegetation index (NDVI) image was converted from the 16-bit RGN image using a band math of (N - R) / (N + R) and automatically segmented by using Otsu [43] algorithm and filtered through the opening operation. Once the NDVI is masked to exclude non-vegetation background pixels, A 2 × 7 grid was applied on the masked NDVI to create 14 regions of interest (ROI), where seven columns were evenly spaced to fit three pots on each side and a dummy column in the middle to isolate non-vegetation pixels (Fig. 1). Three ROIs on each side were grouped to extract individual metrics of four experimental groups in each chamber. Canopy coverage was calculated from the masked NDVI image as a percentage of vegetation pixels to the combined area of three ROIs. A Python script was coded for a batch process to implement a series of image processing algorithm and export into a comma delimited file phenotypic metrics, i.e., vegetation index and canopy coverage. Download : Download high-res image (810KB) Download : Download full-size image Fig. 1. Flowchart of image processing pipeline for the analysis of HTP data, where the raw image is processed and extracted for phenotypic metrics through calibration, thresholding, filtering, masking, segmentation, and gridding. The lower part illustrates a sequence of the images processed. Microcontroller The Arduino is a standardized rapid prototyping platform using the ATmega328 microcontroller [44] and was selected based on its inexpensive and customizable advantages with a wide range of sensors and actuators which are easily setup with sample codes and wire diagrams provided by manufacturer. The microcontroller has four main types of sensor interface: Analog\\Digital inputs, I2C, serial peripheral interface (SPI), and UART. I2C is the most common interface that uses 2-wire bus from a master to many slaves in 400 kHz: ‘SDA’ (serial data) for bidirectional data transmission and ‘SCL’ (serial clock) for synchronizing the data transfer. SPI is used for fast, full-duplex sync serial data link. UART is a serial data transfer and has two ways to implement: software serial and hardware serial. The software serial reads only a single data entry at a time, whereas hardware serial can read data simultaneously using ‘Rx’ (receiver) and ‘Tx’ (transmitter) pins. Arduino Uno provides six multiplexed analog input pins, 14 digital input\\output (DIO) of which six provide pulse-width modulation (PWM) output, one I2C, one SPI, and one UART. The analog input pins support 10-bit analog-to-digital conversion (ADC) using analogRead function. Most of the analog inputs can also be used as digital pins: analog input 0 as digital pin 14 through analog input 5 as digital pin 19 [45]. All sensors and actuators were connected to the microcontroller that was placed in a waterproof enclosure box (1020, Pelican, Torrance, CA, USA) including a relay shield mounted on the microcontroller. Arduino Shields were added as pin layout that makes wire connection efficient without soldering and thus saves time and cost for projects. The enclosure box was modified to feed cables through three holes: a USB cable from the RPi, wires from the four water pumps, and wires from all other sensors. The box allowed all wires to remain intact and undamaged inside the box during the experiment and the flexibility to rewire in hardware update and troubleshooting wire connectivity. Single-board computer The RPi is low cost and low power consumption with light weight but still offers a powerful computing and a full peripheral interface of a computer. The RPi 3B+ contains 1.4 GHz quad-core ARM processor with Wi-Fi, Bluetooth, HDMI, and four USB ports. The RPi was enclosed in a protective box. Table 1 shows a complete list of all electronic components of the sensing system with total cost of USD 874 and total weight of 1.7 kg. A flowchart of Python code operating RPi is illustrated in Fig. 2. For the convenience of debugging, a serial port is opened for either an RPi or a personal computer (PC). After first 10 dummy iterations to avoid broken characters that were observed at the beginning of serial connection, input strings from Arduino were validated by the length of characters before saving them into a file Table 1. Electronic components of the sensing system used in each growth chamber (prices as of August 2020). Sensors & Parts Interface Metrics Vendor Part # (Qt) Weight Price Camera PWM MAPIR Survey3W 76g $400 miniLiDAR UART Height DFRobot SEN0259 (2) 10g $80 IR thermometer I2C T DFRobot SEN0206 (4) 60g $64 T\\RH sensor DIO T\\RH DFRobot DHT22 10g $6 Soil water sensor AIO Soil DFRobot SEN0193 (4) 60g $24 Water pump DIO DFRobot FIT0200 (4) 500g $36 LCD screen I2C DFRobot DFR0063 50g $10 Microcontroller USB DFRobot DFR0216 45g $20 Relay Shield DFRobot DFR0144 100g $14 I2C Multiplexer I2C DFRobot DFR0576 10g $7 Enclosure box Pelican 1020 250g $15 RPi USB Raspberry Pi 3 B+ 50g $35 Solar battery USB Kenruipu Q90–5 420g $19 Support frames Home Depot 564,195 (3) 100g $50 Miscellaneous Amazon SD (64GB,32GB), case, mount, cable 20g $65+$10+$10+$9 Total 1.7kg $874 Download : Download high-res image (184KB) Download : Download full-size image Fig. 2. Flowchart of Python code in RPi in a sequence of opening a serial port for either RPi or PC, reading strings from Arduino after first 10 dummy iterations, validating the input strings by a string length, and saving them to an output file. Wireless communication The RPi was programmed by a Python script to read a serial data from the Arduino through a USB connection at 115,200 baud rate and store data strings to a file with time stamps. Real-time status of all sensory data was also displayed by the script on the RPi terminal and accessed wirelessly from a remote computer or a smartphone through Wi-Fi connection. Wi-Fi was selected for wireless data communication, because it is a built-in feature in RPi and can easily connect to the internet cloud that allows the user to remotely access to data stored in the RPi. The RPi was configured for Wi-Fi by enabling Secure Shell (SSH) and Virtual Network Computing (VNC) interfaces. When the RPi is connected to Wi-Fi through an access point (AP), network IP address is assigned to the RPi and used to remotely connect to the RPi using PuTTY via SSH for terminal access or VNC Viewer for remote desktop access. When the RPi is connected to a hidden network, wpa_supplicant.conf must be created in the RPi directory of etc/wpa_supplicant to assign network ID and user account credential. RPi 3B+ with Debian Stretch operation system (OS) was used for a stable Wi-Fi connection, as RPi 4 with Debian Buster OS was found unstable in connecting to a hidden network. The RPi configuration was updated to automatically run a Python script (e.g., autowater.py) that starts reading data from the Arduino when the RPi is powered on by adding codes (Fig. 3) at the end of the file ‘∼/.config/lxsession/LXDE-pi/autostart’ for automatically opening a terminal at reboot and adding ‘python autowater.py’ at the end of the file ’.bashrc’. Download : Download high-res image (38KB) Download : Download full-size image Fig. 3. Codes added at the end of the file ‘∼/.config/lxsession/LXDE-pi/autostart’ for automatically opening a terminal when the RPi is powered on. In order to automatically run a Python script (e.g., autowater.py) and start reading data from the Arduino at reboot, ‘python autowater.py’ was added at the end of the file ’.bashrc’. Water management The characterization of agronomic traits resistant to drought stress requires a system to support both plant phenotyping and water management. The HTP system was extended to include soil water monitoring and irrigation control for effective monitoring of plant responses to water stress in a controlled environment. Growth chambers were used for the experiment to provide arid (heat and drought) conditions for the plant. Fig. 4 illustrates a schematic diagram of the automated irrigation and phenotyping system in a chamber. Download : Download high-res image (645KB) Download : Download full-size image Fig. 4. Schematic diagram of the automated irrigation and phenotyping system in a growth chamber for interacting effects of plant traits to temperature and water management. Six pots on the left and right were the drought and control group, respectively. Lines of information flow and interface types are drawn and described in the right top inset. Drought condition was generated by separating water treatments from water pumps (FIT0200, DFRobot, China) to plants based on soil status readings from soil moisture sensors (SEN0193, DFRobot, China). The water pump was equipped with a capacity of 280–500 L/h and powered by 6–18 DCV rated at 64–500 mA. A relay (DFR0144, DFRobot, China) was added to operate four water pumps. Each water pump supplied water to three replicated pots through an irrigation dripper (Fig. 4). A vinyl-flex PVC tube was used for irrigation from the water pumps to pots. A 13-L water bucket was placed in the chamber as a water reservoir for 12 pots and was refilled weekly. To automate water management, soil moisture sensors were deployed to control amount of irrigation based on soil water status. Four soil moisture sensors were used in each chamber by installing a sensor on each pot in four observation groups and inserted vertically at 7.2-cm soil depth. Four water pumps were paired with four soil sensors to control each pump individually based on corresponding soil moisture reading. The closed-loop irrigation was scheduled every 6 h to maintain two soil conditions (drought and control) by checking soil sensors and triggering the water pumps. Sensor installation Two adjustable rods were mounted 131 cm above the floor in parallel between side walls of the growth chamber to hold four IR thermometers and two LiDAR sensors (Fig. 5). Two LiDAR sensors aimed two pots next to the water bucket: one in the control group and the other in the drought group, whereas four IR thermometers aimed at four pots located around the bucket. Another rod was mounted 140 cm above the floor to hold the multispectral camera. All sensors and the camera were angled perpendicular to the ground. Two horizontal metal plates were mounted to a vertical rack on the rear wall and used to hold the microcontroller, RPi, and T\\RH sensor at the lower plate and the LCD screen at the upper plate. Download : Download high-res image (668KB) Download : Download full-size image Fig. 5. Sensor installation in the growth chamber with three rods 131 cm above the floor to hold the camera, IR thermometers, and LiDAR on the rods and two plates attached on a vertical rack on the rear wall to hold the LCD screen, RPi, Arduino, and T\\RH sensor. The soil moisture sensors were installed in the soil of four pots next to the water bucket where the water pumps were immersed in the water. Power management Power management is important to ensure stable operations of all sensors and actuators, the microcontroller (Arduino), and the RPi and must be determined by understanding the power consumption of each module and optimizing the wiring configurations. The RPi is powered by 5 DCV rated at 2.5 A and typically requires 500–700 mA [38]. The USB peripheral of RPi 3B+ model draws maximum current of 1.2 A and typical active current of 500 mA [46]. The Arduino is powered by 5 DCV via USB connection or 7–12 DCV power adapter. Maximum DC current provided by the Arduino is 40 mA per DIO pin [45], which suffices for most sensors, whereas some sensors or actuators use higher current and voltage and thus require power management rewired from an external power source. For seamless power management, each sensor was troubleshooted and calculated for power consumptions (Table 2). In the sensing system, the LiDAR sensor and the water pump draw 120 mA and 500 mA current, respectively, that reaches above the maximum current of 40 mA supplied from the microcontroller and can cause unstable power supply with the multiple connections. An external power source was supplied to LiDAR sensors from a 5 DCV 1A power adapter through an external power terminal of the microcontroller. Another external power source was provided to the water pump from a 7.5 DCV 2A power adapter through the relay sockets. The use of the relay sockets and external power supply allows multiple water pumps and LiDAR sensors to work flawlessly without power demand from the microcontroller. Though the sensing system was powered by two DC adapters, it can be easily converted to a standalone system for outdoor use by using a solar rechargeable battery pack (Q90–5, Kenruipu, China) that provides 25 Ah with three ports (two 5 V 2A ports and one 5 V 1A port) shown in Table 2. Table 2. Power management of each module and external power. Experimental design An experiment was conducted in a controlled environment to identify plant responses to abiotic stress (heat and drought) using the HTP system while automating irrigation for drought environment. Two camelina genotypes (CAM212 and Giessen#4) were grown in two growth chambers located in U.S. Arid-Land Agricultural Research Center in Maricopa, AZ, USA, where the average daily temperature measures up to 37 °C in the range of 31 °C to 43 °C during the growing season. The chambers were equipped with temperature, humidity, and light control. The chamber temperature was set at 25 °C in chamber 1 for control and 35 °C in chamber 2 for heat-stressed environment. Drought environment was generated by controlling water treatments with 40% and 90% water holding capacity for drought and control plants, respectively. Thus, combined interactions to be observed are four treatment groups: control, heat (H), drought (D), and heat-drought (HD) (Fig. 6(a)). With three replications of two genotypic varieties of camelina at each group, total 24 plants were cultivated in pots and split to 12 pots to each chamber as shown in Fig. 6(b). All sensors and controllers were installed identically in both growth chambers. Data were collected for 34 days from December 12, 2019 to January 14, 2020 and recorded every four seconds generating 21,600 strings per day that were downsized in post processing to the averaged data per 10 min for further analysis. Multispectral images were captured every 10 min for 10 h (7am - 5pm) during the lights on in the chambers. Download : Download high-res image (569KB) Download : Download full-size image Fig. 6. Experimental setup: (a) Four observation groups of heat (H), drought (D), and heat-drought (HD) stress groups compared with the control group; (b) Two growth chambers (control at 25 °C and heat stress at 35 °C) with two water treatments (drought stress and control with 40% and 90% water holding capacity, respectively) for two genotypic varieties (var. 1 and var. 2) of camelina with three replications at each group to identify plant phenotypic responses to abiotic stress. Sensor calibration Sensor calibrations were performed to obtain the unbiased data from the measurements of the soil moisture sensors, water pump, IR thermometers, and LiDAR sensors. Each sensor is pre-calibrated by the manufacturer, but sensitivity errors between sensors remain. Sensor calibration minimizes differences among sensors and ensures sensors for consistent accuracy. Soil moisture sensor and water pump The output value of the soil moisture sensor (SEN0193, DFRobot, China) is from 0 to 1023 through a 10-bit ADC and affected by probe insertion depth and how tightly the soil is packed around the sensor. Calibration was conducted for each soil sensor by reading digital values from dry to soaked soil in a pot with plants, and the maximum and minimum values were reversely mapped to 0–100% water holding capacity. Table 3 shows the calibration values obtained for eight soil sensors in two chambers, where digital numbers in ‘Min’ and ‘Max’ of each sensor were obtained from soaked and dry soil, respectively. For instance of sensor 1 in chamber 1, 244 is the minimum value obtained when the soil in the pot is soaked indicating 100% soil moisture, whereas 430 is the maximum value obtained when the soil is dry indicating 0% soil moisture. The percentage soil moisture values were used to calculate the amount of water treatment, i.e., time to turn the water pump on to supply plant-specific irrigation. Table 3. Calibration values of four soil moisture sensors in each growth chamber measured in digital readings of Min (soaked soil) and Max (dry soil) that are reversely mapped to 0–100% soil moisture. Chamber Digital readings Sensor 1 Sensor 2 Sensor 3 Sensor 4 1 (25 °C) Min–Max 244–430 244–462 253–462 258–417 2 (35 °C) Min–Max 253–470 243–515 250–515 255–515 The water pump is rated with a capacity of 280–500 L/h, i.e., 78–138 mL/sec but practically underrated by the resistance due to the elevation and length of the water tubes. The flow rate of the water pump was calibrated by recording water amount from the pump. Under the circumstance of the 3-way split water piping to distribute water from each pump to three pots, the calibrated flow rate (f) of 8 mL/sec was obtained. Total amount of irrigation water (Wt) per pot was measured to bring dry (0% watered) soil to soaked (100% watered) soil, where no more water drained, e.g., 1500 mL pouring on the dry soil subtracted by 65 mL of the drained water, resulting in 1435 mL as 100% water holding capacity. The water shortage (Ws) per pot was calculated from the deviation from water moisture set points (40% for drought and 90% for control) multiplied by Wt using the following equation: (1) The operation time for the water pump was calculated by the water shortage divided by the pump flow rate, f using the following equation: (2) Thermometer and range finder The IR thermometers and LiDAR sensors were calibrated and corrected for the consistency among the multiple sensors. The IR thermometer was calibrated at multiple temperatures by attaching four sensors to a horizontal arm of a copy stand (402,183, Smith-Victor, Bartiett, IL, USA) and aiming down to the water in a glass beaker that was heated by an electric heater. Data were collected at six temperatures settings from 21.5 °C to 43.9 °C with approximately 5 °C increment with reference temperatures measured by a total emersion thermometer. The IR thermometers were run to record 500 readings at each temperature setting. Fig. 7(a) illustrates calibration of the four IR thermometers. Linear regression models were extracted and applied to obtain the calibrated temperatures of the IR thermometers. The LiDAR sensor calibration was performed at multiple distances by attaching two LiDAR sensors to a horizontal arm of the copy stand that is vertically adjustable up to 107 cm. Data were collected at 16 heights from 30 cm to 105 cm with 5 cm increment. 500 readings from the LiDAR sensor were recorded at each height with reference distances measured by a tape ruler. Fig. 7(b) illustrates calibration of two LiDAR sensors used for dry and wet plants. Calibration coefficients were derived from a linear regression model and applied for the correction of sensitivity and variation of the LiDAR sensors. Download : Download high-res image (354KB) Download : Download full-size image Fig. 7. Sensor calibration: (a) IR thermometers for temperature correction. An inset photo shows a copy stand to hold four sensors aiming down to the water in a glass beaker heated by an electric heater with true temperatures measured by a total emersion thermometer; (b) LiDAR sensors used for dry and wet plants in the growth chamber for distance correction. An inset photo shows a copy stand used to adjust the sensor height at 16 heights from 30 cm to 105 cm with 5 cm increment with true distances measured by a tape rule. The corrections of the calibrated values of the IR thermometers and LiDAR sensors were compared to the uncalibrated values in Fig. 8. The corrected values of the IR thermometers remained within ±0.35 °C for all eight sensors except one used for camelina genotype 1 of the wet plants in chamber 2 which showed −1.55 °C offset (Fig. 8(a)) for which an erroneous sensitivity of the sensor is suspected. The performance of the other seven IR thermometers stayed consistent within the manufacture accuracy of ±0.5 °C. The corrected values of the LiDAR sensor persisted within 3.2 cm for all four sensors (Fig. 8(b)) which is within the range of manufacture accuracy of ±6 cm. The calibrated values of the temperature and distance sensors were applied to further data analysis. Download : Download high-res image (139KB) Download : Download full-size image Fig. 8. Corrections of the calibrated values compared to the uncalibrated values of: (a) IR thermometers showing the consistency within ±0.35 °C in all eight sensors except one (−1.55 °C) labeled ‘Wet1_Ch2’ used for camelina genotype 1 of the wet plants in chamber 2; (b) LiDAR sensors showing the consistent accuracy within 3.2 cm for all four sensors. Results Soil moisture and irrigation Fig. 9(a) shows the amount of water provided by the water pumps based on the soil moisture sensors. Two pots in the dry group had daily average water treatments of 4 mL and 15 mL, whereas those in the wet group had 319 mL and 249 mL in camelina genotype 1 and 2, respectively. There were data missing on January 5–7, 2020 in chamber 1 and on December 17–19, 2019 and December 26, 2019 to January 1, 2020 in chamber 2 due to the accidental disconnection of power cables. Fig. 9(b) illustrates soil moisture data from two water treatments in chamber 1. The initial large fluctuations in the dry group in Fig. 9(b) were caused by the sensor location relative to the irrigation dripper and remedied by repositioning the sensor closer to the dripper. Zero soil moisture on Dry1 during December 23–27 was recorded due to a damaged sensor. Soil moisture was expressed in percentage water holding capacity that was converted from a full range of calibrated digital readings of the sensor (Table 3). Two pots in the dry treatment showed soil moisture in daily average of 63% and 51%, whereas those in the wet treatment showed 70% and 72% in camelina genotype 1 and 2, respectively. Daily average of soil moisture in chamber 2 under the heat (35 °C) stress reached 47% and 40% in the dry treatment and 71% and 68% in the wet treatment in genotype 1 and 2, respectively. These ranges were not exactly matching to the predefined set points of 40% and 90% but represented separation of the drought (dry treatment) from the control (wet treatment) with an analysis of variance (ANOVA) of the average daily soil moisture indicating that soil water status was significantly different between the irrigated and dry plants in both genotype 1 (F1,62 = 15.97, p < .0005) and genotype 2 (F1,66 = 3.99, p < .0005). The result indicated that automated irrigation successfully produced two different water treatments and effectively created drought environment that was used in plant phenotyping for drought resistance. Download : Download high-res image (421KB) Download : Download full-size image Fig. 9. Water management on two water treatments (40% for wet and 90% for dry) of two camelina genotypes in chamber 1: (a) Water irrigated from the water pumps showing daily average of 319 mL and 249 mL for the wet plants and of 4 mL and 15 mL for the dry plants; (b) Soil moisture showing daily average of 63% and 51% for the dry plants and of 70% and 72% for the wet plants in genotype 1 and 2, respectively. Plant temperature and height Fig. 10(a) illustrates canopy temperature responses of the irrigated and dry plants in chamber 2. All measurements show the same trend of higher canopy temperatures up to 1.49 °C in the dry plants than those in the wet plants (Fig. 10(a)). When plants undergo water stress, their stomata begin to close and cease to transpire, causing the canopy temperature to rise. Camelina genotype 1 showed 1.32 °C lower than genotype 2 under high temperature stress. ANOVA test of the average daily plant temperature showed that the canopy temperature was significantly different between camelina genotypes under combination of heat and drought (HD) stress (F1,36 = 30.36, p < .0005). Similar results were obtained under the individual stress of heat (H) and drought (D). The results of lower canopy temperature indicated that camelina genotype 1 has tolerance responses under H, D, and HD conditions (Fig. 10(b)). Download : Download high-res image (223KB) Download : Download full-size image Fig. 10. Plant temperature responses of: (a) Dry and irrigated wet plants in the chamber 2 under heat stress; (b) Two camelina genotypes showing lower canopy temperature in genotype 1 under heat (H), drought (D), and heat-drought (HD) stresses. The result in chamber 1 showed that the height of the wet plant was gradually increased up to 79 cm until December 23 and became decreasing to 40 cm and fluctuating from 48 to 67 cm, whereas the dry plant remained relatively constant at 40–50 cm (Fig. 11(a)). The plant height in chamber 2 showed 51 ± 2.4 cm and 38 ± 1.9 cm for the dry and irrigated plants, respectively. This adverse response of the plant height was caused by tall thin camelina plants leaning out of the sensor's FOV. The plant height differences between camelina genotypes were measured manually for four treatment groups showing that genotype 1 is taller under all three stress conditions than genotype 2 (Fig. 11(b)). The result indicated that camelina genotype 1 grows in lower canopy temperature (i.e., more leaf transpiration) and taller and has superior resistance to heat and drought stress. Download : Download high-res image (284KB) Download : Download full-size image Fig. 11. Plant height comparison of: (a) Dry and irrigated wet plants in chamber 1; (b) Two camelina genotypes showing genotype 1 is taller than genotype 2 under heat (H), drought (D), and heat-drought (HD) stresses. Plant vegetation and leaf area Fig. 12 illustrates the phenotypic responses of plant vegetation and leaf area measured by the multispectral camera. Plant vegetation of all four groups remained greenish at NDVI = 0.7 during the first three weeks and decreased to 0.5 except Dry2 group that stayed below 0.6 (Fig. 12(a)). The result indicated camelina genotype 1 grew healthier than genotype 2 in the drought condition, whereas NDVI in chamber 2 under the heat (35 °C) stress remained close (e.g., NDVI = 0.01 or less) between two genotypes. Canopy coverage gradually decreased from approximately 40% to 10% (Fig. 12(b)). The irregular increase and decrease in Wet1 and Wet2 groups during December 16–20 were caused by manual adjustment to keep the plants upright as they became tall and leaning out of the camera's FOV. With the consideration of data from December 20, the result showed more leaf areas in camelina genotype 1 than those in genotype 2 in both chambers, indicating that camelina genotype 1 has superior performance than genotype 2 in H, D, and HD resistance. Download : Download high-res image (329KB) Download : Download full-size image Fig. 12. Plant phenotypic metrics: (a) Plant vegetation for the dry and irrigated wet plants in chamber 1; (b) Leaf area showing camelina genotype 1 grows more canopy coverage than genotype 2 and has superior resistant to drought stress. Discussion The soil moisture sensors responded continuously to moisture conditions and should be carefully calibrated with target plants to correctly map readings from dry to soaked soil to 0% to 100% soil moisture. As the sensitivity of the sensor varies on density of soil contact, a consistent method of sensor installation is highly recommended to avoid measurement errors caused by loose soil contact. The IR thermometers performed well with stable readings and corrected values from the calibration stayed within the manufacture accuracy. The mini LiDAR sensor had consistent accuracy within 3.2 cm from the sensor calibration but showed measurement errors caused by tall thin camelina plants leaning out of the sensor's narrow FOV of 2°. Thus, it is recommended to use the sensor on the plant with broad leaves for accurate height measurement. The performance of the HTP system developed in this study is compared with prior studies which were either irrigation [[28], [29], [47]], or phenotyping [[35], [36], [37], [48]] not integrating both nor fully deploying open-source hardware and software packages. Prior studies of RPi-based phenotyping [41,2,42] were limited to an imaging tool using a color camera only, whereas the system developed in this study is featured with tri-metric phenotyping metrics: canopy temperature, plant height, vegetation/leaf area indexes from a multispectral camera. Granier et al. [1] discussed image-based phenotyping of plant responses to soil water deficit in a growth chamber but using a color camera only without open-source packages. The HTP system performs characterizing phenotypes of plant traits but needs to be coupled with a variable rate irrigation system in a growth chamber to simulate the drought stress by controlling the amount of water to plants. The great value of the system lies in the use of open-source hardware and software packages as well as multispectral image (MSI)-based plant phenotyping that can maximize the difference of spectral signature of the plants in visible and near-infrared bands through image analytics software [49]. Using PWM signals from the Arduino allowed the simplicity of the MSI camera trigger. Conclusions Current application provided a cost-effective HTP system for plant phenotyping and irrigation control using open-source hardware and software packages. The proposed system achieved the aim of remote monitoring of plant phenotypes using Arduino-RPi and image analytics, integration of irrigation controller for water management, and identifying phenotypic responses to abiotic stress. The system design was detailed for the seamless integration of sensors and actuators with sensor calibration and power management for the accuracy and reliability of the system. The system was able to phenotypically differentiate two camelina genotypes based on their canopy temperature and height as well as vegetation and leaf area. The open-source sensor integration offers a real potential for the applied plant scientists to achieve on plant breeding and physiological assessment at cost-effective design of an automated control and monitoring system. The total cost of the system for each growth chamber was USD 874, and its weight was only 1.7 kg. With cost-effective, portable, and energy-efficient features, this system can be easily adopted for other sensing and control applications such as in greenhouses, vertical farms, or outdoor fields. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Mention of trade names or commercial products in this article is solely for the purpose of providing specific information and does not imply recommendation or endorsement by the U.S. Department of Agriculture. USDA is an equal opportunity provider and employer. Acknowledgments The authors would like to acknowledge Nancy Parks, Mario Aguilera, and Beichen Lyu for their cooperation and support in facilitating sensor installations and calibrations in the growth chambers. This research was funded by the U.S. Department of Agriculture under project numbers 2020–21410–007–00D, 2020–21000–013–00D, and 2020–11000–013–00D and National Institute of Food and Agriculture (NIFA) under grant number 2016–67009–25639. The authors would like to thank the anonymous reviewers for their comments and suggestions to improve the manuscript. References [1] C. Granier, L. Aguirrezabal, K. Chenu, S.J. Cookson, M. Dauzat, P. Hamard, J.J. Thioux, G. Rolland, S. Bouchier-Combaud, A. Lebaudy, B. Muller, T. Simonneau, F. Tardieu PHENOPSIS, an automated platform for reproducible phenotyping of plant responses to soil water deficit in Arabidopsis thaliana permitted the identification of an accession with low sensitivity to soil water deficit New Phytol., 169 (3) (2006), pp. 623-635, 10.1111/j.1469-8137.2005.01609.x View in ScopusGoogle Scholar [2] M. Minervini, M.V. Giuffrida, P. Perata, S.A. Tsaftaris Phenotiki: an open software and hardware platform for affordable and easy image-based phenotyping of rosette-shaped plants Plant J., 90 (1) (2017), pp. 204-216, 10.1111/tpj.13472 View in ScopusGoogle Scholar [3] J. Blancon, D. Dutartre, M.-.H. Tixier, M. Weiss, A. Comar, S. Praud, F. Baret A high-throughput model-assisted method for phenotyping maize green leaf area index dynamics using unmanned aerial vehicle imagery Front. Plant Sci., 10 (685) (2019), pp. 1-16, 10.3389/fpls.2019.00685 Google Scholar [4] M. Burnette, G.S. Rohde, N. Fahlgren, V. Sagan, P. Sidike, R. Kooper, J.A. Terstriep, T. Mockler, P. Andrade-Sanchez, R. Ward, J.D. Maloney, C. Willis, M. Newcomb, N. Shakoor, D. LeBauer TERRA-REF data processing infrastructure ACM International Conference Proceeding Series, Association for Computing Machinery, New York, NY, USA (2018), pp. 1-7, 10.1145/3219104.3219152 Google Scholar [5] J. Svensgaard, T. Roitsch, S. Christensen Development of a mobile multispectral imaging platform for precise field phenotyping Agron. J., 4 (2014), pp. 322-336, 10.3390/agronomy4030322 View in ScopusGoogle Scholar [6] A. Walter, F. Liebisch, A. Hund Plant phenotyping: from bean weighing to image analysis Plant Methods, 11 (1) (2015), p. 14, 10.1186/s13007-015-0056-8 View in ScopusGoogle Scholar [7] D. Leister, C. Varotto, P. Pesaresi, A. Niwergall, F. Salamini Large-scale evaluation of plant growth in Arabidopsis thaliana by non-invasive image analysis Plant Physiol. Biochem., 37 (9) (1999), pp. 671-678, 10.1016/S0981-9428(00)80097-2 View PDFView articleView in ScopusGoogle Scholar [8] J. de Vylder, F. Vandenbussche, Y. Hu, W. Philips, D. van der Straeten Rosette Tracker: an open source image analysis tool for automatic quantification of genotype effects Plant Physiol., 160 (3) (2012), pp. 1149-1159, 10.1104/pp.112.202762 View in ScopusGoogle Scholar [9] A. Hartmann, T. Czauderna, R. Hoffmann, N. Stein, F. Schreiber HTPheno: an image analysis pipeline for high-throughput plant phenotyping BMC Bioinform., 12 (1) (2011), p. 148, 10.1186/1471-2105-12-148 View in ScopusGoogle Scholar [10] D.E. Evans, E.J. Sadler, C.R. Camp, J.A. Millen Spatial canopy temperature measurements using center pivot mounted IRTS Proceedings of the 5th International Conference of Precision Agriculture, American Society of Agronomy (2001) Google Scholar [11] D.M. Glenn, J.W. Worthington, W.V. Welker, M.J. McFarland Estimation of peach tree water use using infrared thermometry J. Am. Soc. Hortic. Sci., 114 (1989), pp. 737-741 CrossRefGoogle Scholar [12] Z. Ni, Z. Liu, H. Huo, Z.-.L. Li, F. Nerry, Q. Wang, X. Li Early water stress detection using leaf-level measurements of chlorophyll fluorescence and temperature data Remote Sens. (Basel), 7 (3) (2015), pp. 3232-3249, 10.3390/rs70303232 View in ScopusGoogle Scholar [13] J. Barker, N. Zhang, J. Sharon, R. Steeves, X. Wang, Y. Wei, J. Poland Development of a field-based high-throughput mobile phenotyping platform Comput. Electron. Agric., 122 (2016), pp. 74-85, 10.1016/j.compag.2016.01.017 View PDFView articleView in ScopusGoogle Scholar [14] J.L. Crain, Y. Wei, J. Barker, S.M. Thompson, P.D. Alderman, M. Reynolds, N. Zhang, J. Poland Development and deployment of a portable field phenotyping platform Crop Sci., 56 (3) (2016), pp. 965-975, 10.2135/cropsci2015.05.0290 View in ScopusGoogle Scholar [15] X. Wang, K.R. Thorp, J.W. White, A.N. French, J.A. Poland Approaches for geospatial processing of field-based high-throughput plant phenomics data from ground vehicle platforms Trans. ASABE, 59 (5) (2016), pp. 1053-1067, 10.13031/trans.59.11502 View in ScopusGoogle Scholar [16] G. Bai, Y. Ge, D. Scoby, B. Leavitt, V. Stoerger, N. Kirchgessner, S. Irmak, G. Graef, J. Schnable, T. Awada NU-Spidercam: a large-scale, cable-driven, integrated sensing and robotic system for advanced phenotyping, remote sensing, and agronomic research Comput. Electron. Agric., 160 (3) (2019), pp. 71-81, 10.1016/j.compag.2019.03.009 View PDFView articleView in ScopusGoogle Scholar [17] K. Beauchêne, F. Leroy, A. Fournier, C. Huet, M. Bonnefoy, J. Lorgeou, B. de Solan, B. Piquemal, S. Thomas, J.P. Cohan Management and characterization of abiotic stress via phénofield® a high-throughput field phenotyping platform Front. Plant Sci., 10 (2019), pp. 1-17, 10.3389/fpls.2019.00904 Google Scholar [18] L. Busemeyer, D. Mentrup, K. Möller, E. Wunder, K. Alheit, V. Hahn, H.P. Maurer, J.C. Reif, T. Würschum, J. Müller, F. Rahe, A. Ruckelshausen Breedvision - a multi-sensor platform for non-destructive field-based phenotyping in plant breeding Sensors, 13 (3) (2013), pp. 2830-2847, 10.3390/s130302830 View in ScopusGoogle Scholar [19] N. Virlet, K. Sabermanesh, P. Sadeghi-Tehran, M.J. Hawkesford Field Scanalyzer: an automated robotic field phenotyping platform for detailed crop monitoring Funct. Plant Biol., 44 (1) (2017), pp. 143-153, 10.1071/FP16163 View in ScopusGoogle Scholar [20] D.K. Fisher, P.J. Gould Open-source hardware is a low-cost alternative for scientific instrumentation and research Mod. Instrum., 01 (02) (2012), pp. 8-20, 10.4236/mi.2012.12002 Google Scholar [21] P.A. Beddows, E.K. Mallon Cave pearl data logger: a flexible Arduino-based logging platform for long-term monitoring in harsh environments Sensors, 18 (2) (2018), p. 530, 10.3390/s18020530 View in ScopusGoogle Scholar [22] D. Cressey The DIY electronics transforming research Nature, 544 (7648) (2017), pp. 125-126, 10.1038/544125a View in ScopusGoogle Scholar [23] O.K. Paul, H. Mao, L. Li New type arduino plant grower (GCKJ) In 2018 ASABE Annual International Meeting, St. Joseph, MI: ASABE, Detroit, Michigan (2018), 10.13031/aim.201800016 July 29-August 1, 2018, Paper No. 1800016 Google Scholar [24] M. Li, J. Ma, W. Jia, H. Zhang Design and implementation of facilities agriculture environment monitoring system based on single-chip Proceedings of the ASABE Annual International Meeting, St. Joseph, MI: ASABE, Spokane, Washington (2017) July 16-19, 2017, Paper No. 1700938 Google Scholar [25] Y. Ampatzidis, L. Tan, R. Haley, R. Wortman, M. Whiting Harvest management information system for specialty crops 2013 ASABE Annual International Meeting, St. Joseph, MI: ASABE, Kansas City, Missouri (2013), 10.13031/aim.20131596473 July 21-24, 2013, Paper No. 131596473 Google Scholar [26] S. Kuznetsov, E. Paulos UpStream: motivating water conservation with low-cost water flow sensing and persuasive displays Proceedings of the Conference on Human Factors in Computing Systems, ACM Press (2010), pp. 1851-1860 CrossRefView in ScopusGoogle Scholar [27] A.S. Rao, S. Marshall, J. Gubbi, M. Palaniswami, R. Sinnott, V. Pettigrovet Design of low-cost autonomous water quality monitoring system Proceedings of the International Conference on Advances in Computing, Communications and Informatics, ICACCI (2013), pp. 14-19 CrossRefView in ScopusGoogle Scholar [28] N. Agrawal, S. Singhal Smart drip irrigation system using raspberry pi and arduino International Conference on Computing, Communication and Automation, Institute of Electrical and Electronics Engineers Inc (2015), pp. 928-932, 10.1109/CCAA.2015.7148526 View in ScopusGoogle Scholar [29] J. Gutierrez, J. Villa-Medina, A. Francisco, Nieto-Garibay, M.A. Porta-Gandara Automated irrigation system using a wireless sensor network and GPRS module IEEE Trans. Instrum. Meas., 63 (1) (2014), pp. 166-176, 10.1109/TIM.2013.2276487 View in ScopusGoogle Scholar [30] G. Vellidis, M. Tucker, C. Perry, C. Kvien, C. Bednarz A real-time wireless smart sensor array for scheduling irrigation Comput. Electron. Agric., 61 (1) (2008), pp. 44-50, 10.1016/j.compag.2007.05.009 View PDFView articleView in ScopusGoogle Scholar [31] B. Dai, R.C. Chen, W.B. Yang Using arduino to develop a bluetooth electronic scale for water intake Proceedings of the IEEE International Symposium on Computer, Consumer and Control, Institute of Electrical and Electronics Engineers Inc (2016), pp. 751-754 IS3C 2016. CrossRefView in ScopusGoogle Scholar [32] C.M. Devika, K. Bose, S. Vijayalekshmy Automatic plant irrigation system using Arduino Proceedings of the IEEE International Conference on Circuits and Systems (ICCS), IEEE (2017), pp. 384-387 View in ScopusGoogle Scholar [33] A. Imteaj, T. Rahman, M.K. Hossain, S. Zaman IoT based autonomous percipient irrigation system using raspberry Pi Proceedings of the 19th International Conference on Computer and Information Technology (ICCIT), IEEE (2016), pp. 563-568 CrossRefView in ScopusGoogle Scholar [34] K. Taneja, S. Bhatia Automatic irrigation system using Arduino UNO Proceedings of the International Conference on Intelligent Computing and Control Systems (ICICCS), IEEE (2017), pp. 132-135 CrossRefView in ScopusGoogle Scholar [35] Da Silva, Starliper RL, Bhosale N, Taggart DK, Ranganath M, Sarje R, Daniele T, Bozkurt M, Rufty A, Lobaton T, E Feasibility study of water stress detection in plants using a high-throughput low-cost system Proceedings of the IEEE Sensors, Institute of Electrical and Electronics Engineers Inc (2020) Google Scholar [36] M. Minervini, H. Scharr, S.A. Tsaftaris Image analysis: the new bottleneck in plant phenotyping [applications corner] IEEE Signal Process. Mag., 32 (4) (2015), pp. 126-131, 10.1109/MSP.2015.2405111 View in ScopusGoogle Scholar [37] A.J. Moshayedi, A.S. Roy, L. Liao, S. Li Raspberry Pi SCADA zonal based system for agricultural plant monitoring Proceedings of the 6th International Conference on Information Science and Control Engineering (ICISCE), IEEE (2019), pp. 427-433 CrossRefView in ScopusGoogle Scholar [38] D. Molloy Introduction Exploring Raspberry Pi: Interfacing to the Real World With Embedded Linux, Wiley, Indianapolis, IN, USA (2016) https://www.wiley.com/en-us/Exploring+Raspberry+Pi%3A+Interfacing+to+the+Real+World+with+Embedded+Linux-p-9781119188681 Google Scholar [39] J.R. Pandya, D.A. Nagchaudhuri, D.C. Nindo, D.M. Mitra FarmBot- a platform for backyard precision farming: installation and initial experimental layout Proceedings of the ASABE Annual International Meeting, St. Joseph, MI: ASABE, Boston (2019) Massachusetts, July 7- July 10, 2019, Paper No. 1900194 Google Scholar [40] H. Inoue Development of a Raspberry Pi based pest detection device for use in livestock feed storage systems Proceedings of the ASABE Annual International Meeting, St. Joseph, MI: ASABE, Boston, Massachusetts (2019) July 7- July 10, 2019, Paper No. 1900337 Google Scholar [41] J. Mei, Z. Liu, L. Han, Z. Yang RPi macro camera: an inexpensive and handheld camera based on the Raspberry Pi computer for plant phenotype studies Proceedings of the ASABE 2018 Annual International Meeting, St. Joseph, MI: ASABE (2018) Detroit, Michigan, July 29-August 1, 2018, Paper No. 1801117 Google Scholar [42] J.C. Tovar, J.S. Hoyer, A. Lin, A. Tielking, S.T. Callen, S. Elizabeth Castillo, M. Miller, M. Tessman, N. Fahlgren, J.C. Carrington, D.A. Nusinow, M.A. Gehan Raspberry Pi–powered imaging for plant phenotyping Appl. Plant Sci., 6 (3) (2018), pp. 1-12, 10.1002/aps3.1031 Google Scholar [43] N. Otsu A threshold selection method from gray level histograms IEEE Trans. Syst. Man Cybern., 9 (1) (1979), pp. 62-66, 10.1109/TSMC.1979.4310076 Google Scholar [44] Arduino. 2020a. Arduino Uno Rev3 [WWW Document]. URL https://store.arduino.cc/usa/arduino-uno-rev3 (Accessed 7.17.20). Google Scholar [45] Arduino. 2020b. Introduction to the Arduino Board [WWW Document]. URL https://www.arduino.cc/en/reference/board (Accessed 7.18.20). Google Scholar [46] Raspberry. 2020. Raspberry Pi power supply [WWW Document]. URL https://www.raspberrypi.org/documentation/hardware/raspberrypi/power (Accessed 9.14.20). Google Scholar [47] Y. Kim, R.G. Evans, W.M. Iversen Remote sensing and control of an irrigation system using a distributed wireless sensor network IEEE Trans. Instrum. Meas., 57 (7) (2008), pp. 1379-1387, 10.1109/TIM.2008.917198 View in ScopusGoogle Scholar [48] C. Zet, M. Branzila, C. Fosalau Sensor network for indoor home plants Proceedings of the International Conference on Sensing and Instrumentation in IoT Era (ISSI), IEEE (2019), pp. 1-6 CrossRefGoogle Scholar [49] J.Y. Kim Software design for image mapping and analytics for high throughput phenotyping Comput. Electron. Agric., 191 (2021), p. 106550, 10.1016/j.compag.2021.106550 View PDFView articleView in ScopusGoogle Scholar Cited by (5) Compound minirhizotron device for root phenotype and water content near root zone 2023, Computers and Electronics in Agriculture Citation Excerpt : Plant phenotype is very important to understand causal effects of genotype and environment on trait expression, and it is a critical factor in expediting plant cultivation (An et al., 2016). With the rapid development of phenotypic technology, researchers have made new progress in plant phenotypic research (Bai et al., 2019; Du et al., 2021; Kim et al., 2022). Root phenotype plays an increasingly significant role in plant growth. Show abstract Development of a Low-Cost Plant Growth Chamber for Improved Phenotyping Research 2023, Journal of Biosystems Engineering Enhancing Smart Agriculture by Implementing Digital Twins: A Comprehensive Review 2023, Sensors Enhancing resilience in agricultural production systems with AI-based technologies 2023, Environment, Development and Sustainability Compound Minirhizotron Device for Root Phenotype and Water Content Near Root Zone 2022, SSRN Published by Elsevier B.V. Recommended articles Assessment of the Priestley-Taylor coefficient and a modified potential evapotranspiration model Smart Agricultural Technology, Volume 3, 2023, Article 100075 Georgios Nikolaou, …, Nikolaos Katsoulas View PDF Spatial modeling via geostatistics and infrared thermography of the skin temperature of dairy cows in a compost barn system in the Brazilian semiarid region Smart Agricultural Technology, Volume 3, 2023, Article 100078 Marcos Vinícius da Silva, …, José Francisco de Oliveira Júnior View PDF HOB-CNN: Hallucination of occluded branches with a convolutional neural network for 2D fruit trees Smart Agricultural Technology, Volume 3, 2023, Article 100096 Zijue Chen, …, Chao Chen View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 4 Captures Readers: 34 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply."

Paper 5:
- APA Citation: Laha, S. R., Pattnayak, B. K., Pattnaik, S., Mishra, D., & Kumar Nayak, D. S. (2023). IOT-Based Soil Moisture Management System for Precision Agriculture: Real-Time Monitoring and Automated Irrigation Control. In 2023 4th International Conference on Smart Electronics and Communication (ICOSEC) (pp. 1-5). IEEE.
  Main Objective: To develop and implement an IoT-based soil moisture management system for precision agriculture at Siksha ‘O’ Anusandhan (SOA) University.
  Study Location: Siksha ‘O’ Anusandhan (SOA) University, Bhubaneswar, Odisha, India
  Data Sources: Sensor data from soil moisture sensors, temperature and humidity sensors
  Technologies Used: IoT, sensor nodes, wireless communication, cloud computing
  Key Findings: The IoT-based soil moisture management system significantly improves water use efficiency compared to traditional methods. The system is reliable and adaptable to different crop types and field conditions, enhancing crop productivity and promoting sustainable water resource utilization.
  Extract 1: Through extensive testing and validation, the study demonstrates the system's reliability and ability to improve water use efficiency compared to traditional methods.
  Extract 2: The IoT -based architecture of the system offers scalability and flexibility, making it adaptable to different crop types and field conditions within the university.
  Limitations: The study does not explicitly address resilience and fault tolerance in the context of automated irrigation systems.
  Relevance Evaluation: The paper is moderately relevant to the point of strategies for ensuring robustness and reliability in the face of failures, disruptions, or unexpected events in the context of automated irrigation systems. While the paper does not explicitly address resilience and fault tolerance, it highlights the system's reliability and ability to improve water use efficiency, which are important aspects of robustness in irrigation systems.
  Relevance Score: 0.7
  Inline Citation: (Laha et al., 2023)
  Explanation: The study presented in this paper introduces an IoT-based soil moisture management system for precision agriculture. This system utilizes sensors, wireless communication, and cloud computing to enable real-time monitoring and automated irrigation control. Through extensive testing and validation, the study demonstrates the system's reliability and ability to improve water use efficiency compared to traditional methods. The IoT -based architecture of the system offers scalability and flexibility, making it adaptable to different crop types and field conditions within the university.

 Full Text: >
"IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Conferences >2023 4th International Confer... An IOT-Based Soil Moisture Management System for Precision Agriculture: Real-Time Monitoring and Automated Irrigation Control Publisher: IEEE Cite This PDF Suprava Ranjan Laha; Binod Kumar Pattanayak; Saumendra Pattnaik; Debashree Mishra; Debasish Swapnesh Kumar Nayak; Bibhuti Bhusan Dash All Authors 135 Full Text Views Abstract Document Sections I. Introduction II. Proposed Work III. Methedologies Used IV. Experimentation & Model Evaluation V. Result Analysis & Validation Show Full Outline Authors Figures References Keywords Metrics Abstract: Managing soil moisture is crucial for optimizing crop growth and yield in agriculture. With the advancements in Internet of Things (IoT) technology, innovative soil moisture monitoring and control solutions have emerged. This paper presents a pioneering IoT -based soil moisture management system tailored for precision agriculture within Siksha ‘O’ Anusandhan (SOA) University. The system utilizes sensor nodes, wireless communication, and cloud computing to enable real-time monitoring and automated irrigation control, addressing the limitations of conventional manual approaches. Providing continuous, remote, and precise measurements of soil moisture levels revolutionizes how soil moisture is managed within the university's agricultural practices. Low-cost sensor nodes are strategically placed throughout the fields to collect data, which is wirelessly transmitted to a central hub for analysis and decision-making. A cloud-based platform processes the data, generating actionable insights and triggering automated irrigation when necessary. Extensive testing and validation demonstrate the system's reliability and ability to improve water use efficiency, surpassing traditional methods. Furthermore, the IoT architecture of the system offers scalability and flexibility, making it adaptable to different crop types and field conditions present within SOA University. This innovative research contributes to the field of precision agriculture by providing an efficient and tailored solution for soil moisture management within the university's agricultural practices. This IoT -based system enhances crop productivity by enabling real-time monitoring and automated irrigation control, promoting sustainable water resource utilization. Its implementation within SOA University fosters the integration of cutting-edge technology into agricultural practices, facilitating optimized crop growth and contributing to the university's commitment to environmental sustainability and resource managem... (Show More) Published in: 2023 4th International Conference on Smart Electronics and Communication (ICOSEC) Date of Conference: 20-22 September 2023 Date Added to IEEE Xplore: 16 October 2023 ISBN Information: DOI: 10.1109/ICOSEC58147.2023.10276266 Publisher: IEEE Conference Location: Trichy, India SECTION I. Introduction Water is a basic necessity for all the life forms on Earth [1], [2]. It is well known that water is the main reason behind Earth being the only living planet. It is impossible for any living being to live without water [3], [4]. Without water, a plant cannot perform its essential photosynthesis. It is understandable that if the problem of water scarcity continues to increase, it will remove the greenery in the future. As a result of which, there will be less rainfall. Water is also essential for agricultural production and food security [5]–[7]. Technology has always served to overcome such problems and to make lives easy with its innovations. Here through this study one such solution is introduced, named ‘lOT based Soil Management System,’ a model for controlling irrigation that uses IoTto sense soil moisture with temperature and humidity of the surroundings with a microcontroller to make an intelligent irrigation system to help millions of farmers and University gardeners [8], [9]. Soil moisture is critical to plant growth, and maintaining the right amount of moisture can help plants grow faster and produce better yields. An efficient soil moisture management system can help conserve water by reducing the water needed for irrigation [10], [11]. A soil moisture management system can help reduce water usage and lead to cost savings of water bills and other expenses. By managing soil moisture levels, it helps to maintain soil health and reduce erosion, which is essential for sustainable agriculture [12]–[14]. Farmers and growers can proactively avoid drought conditions and other weather-related risks that can harm crops by monitoring soil moisture levels [15]–[17]. To evaluate the link between soil moisture readings acquired from soil moisture sensors and the gravimetric approach, a study was conducted at the Water Technology Centre farm (WTC) at Hyderabad based college [18]. In 2021, Fengfei et al.'s Portable PHS Method for Moisture in the Soil Monitoring Based on Thermal Effect is implemented. The results were compared to those obtained using the drying procedure, confirming the practicality of the suggested method [19]. In 2019, G. S. Swileam et al. assessed soil heterogeneity utilising electrical resistance for typical alluvial soils in Egypt [20]. In 2018 smith et aI., proposed a system for efficiently maintaining optimal soil moisture levels for crops using various traditional soil management systems [21]. Gupta et al. (2020) analyze whether rooftop harvesting of rainwater and outline bunding enhances the moisture in the soil. Their effects on yields of crops, availability of water, and soil moisture management are examined [22]. Contour plowing, terracing, and checking dams in arid environments are the main focus of this study by Patel et al. It assesses their ability to reduce soil moisture evaporation and increase water retention [23]. To measure the soil moisture content, humidity, and temperature using Raspberry Pi Pico and other sensors to minimize the over-watering and under-watering of plants. This paper deals with multiple sensors/modules and Raspberry Pi Pico to measure the current readings of the soil & surrounding of the University plants, analyze them, display the measurements on the webpage, and automatically water the plants when required by connecting them to a water pump. IoT-based soil management systems can collect real-time data on soil moisture levels, weather conditions, and other relevant factors. This enables farmers and growers of the university to make data-driven decisions and respond quickly to changes in soil moisture levels. Farmers and growers can remotely monitor soil moisture levels and other factors with this system. This can save time and reduce the need for manual labor in the field. The curated system can automate the irrigation process based on soil moisture levels and other data. Intelligent systems can help reduce water waste and improve crop yields. IoT -based soil management systems can be easily scaled to accommodate more significant areas of farmland or garden spaces in universities. These innovative systems are also suitable for large-scale agricultural operations and smaller-scale applications. SECTION II. Proposed Work This IoT -based system deals with multiple sensors/modules and Raspberry Pi Pico to measure the current readings of the soil & surroundings, analyze them, display the measurements on the website, and automatically water the plants when required by connecting to a water pump. The system uses micro python to interface the sensors and modules with the microcontroller Raspberry Pi Pico. This project deals with the automatic watering of plants whenever the moisture, humidity, and temperature level decreases to a specific standard limit. The working of proposed model consists of a soil moisture sensor and a temperature humidity sensor, which tracks the soil moisture along with the humidity and temperature of the surroundings. When the measurements exceed the required standard readings, the relay directs the motor to pump water to plants. This model will benefit people with large patches of gardens, Universities, or those farther from their places. The proposed system has advantages in reducing costs, restricting water waste, and minimizing physical interference. It also promotes irrigation that requires little maintenance and is environmentally friendly. In order to regulate the water flow, a relay module has been installed. The model shows expected impacts at various levels of humidity and temperature. Figure 1 shows the proposed model of our IoT -based system. Fig. 1: Proposed IoT-based system for Soil Moisture management system Show All SECTION III. Methedologies Used The Soil Moisture Sensor yields real-time data in the form of an analog. Analog to Digital (A/D) and data conditions are converted using Raspberry Pi Pico Microcontroller. The Microcontroller is used to acquire real-time soil moisture using a soil moisture sensor. The Thonny Integrated Development Environment (IDE) is a cross-platform application that supports high-level programming languages like Python. The IDE makes writing code and uploading the source program to the board easy. It contains libraries and cores. The samples are measured from low to High moisture contents of the soil. The gardener can get the processed data through the webpage with the help of Wireless Fidelity (Wi-Fi) Technology. This system can give real-time data on soil moisture. The Soil moisture system is connected to the web page. We have interfaced the soil moisture sensor, DHTII Module, and relay with a Raspberry Pi Pico to measure the volumetric concentration of water inside the soil and the humidity and temperature of the surroundings. This system uses Raspberry Pi Pico as a microcontroller, which is then connected to the Moisture Sensor, which measures the soil's moisture content. Raspberry Pi Pico acts as the central brain of the IoT-based soil moisture management system, responsible for data collection, processing, analysis, communication, and automated control. It is also linked to DHT -11, the Temperature and Humidity sensor, which measures the ambient temperature and humidity. The Pico is also connected to the Wi-Fi module ESP-Ol, bridging the divide between the hardware and software components of the system shown in fig. 2. The measurements of the above sensors and modules and the standard measurements will subsequently be displayed for users on our self-designed website using the ESP-Ol. Fig. 2. Schematic Layout of our Proposed System Show All SECTION IV. Experimentation & Model Evaluation The proposed intelligent system captures data in real-time using a range of sensors and modules shown in fig. 5. University gardeners use these sensors to assess soil and environmental conditions. The soil management system we built is responsible for several duties. It begins by measuring the soil moisture content using a capacitive soil moisture sensor and then monitors the humidity and temperature of the surrounding environment with a DHTII Module. All plants have a threshold value set to standard soil moisture content for home/university gardeners. When the moisture level falls below the set standard/threshold level, the relay module turns the Motor On and begins pumping water to the plants from the tank until the moisture level returns to the desired level. The measurements mentioned above’ readings will be shown on a website built with the ESP-OI, which we designed with HTML and CSS and coded in Python. Fig. 3 shows the hardware connection of sensors/modules to Raspberry Pico and figure 4 depicts the Circuit diagram of the connection of all the sensors, modules, and motors. Fig. 3. Hardware connection of sensors/modules to Pico Show All Fig. 4. Circuit diagram of our proposed System Show All Fig. 5. Experimental model of our proposed System Show All SECTION V. Result Analysis & Validation The analysis of the results demonstrates the efficacy of IoT-based watering systems in sustaining optimal soil moisture levels for plant growth in the university. These systems provide optimal irrigation, water conservation, improved plant health and growth, resource efficiency, data-driven insights, remote monitoring and control, and flexibility. Using IoT technology, plant owners, farmers, and gardeners can achieve precise and effective watering techniques, resulting in healthier and more robust plants. The moisture reading experiments conducted at our University on different plants and shrubs can provide valuable insights into plant water requirements and watering patterns shown in fig. 6. Fig. 6. Soil moisture reading experimentation done at our University's Plants & Shrubs Show All The collected data on moisture readings from the different plants and shrubs helps in understanding their specific water requirements and watering patterns. This IoT-based system enables informed decision-making regarding irrigation scheduling, optimization of water management practices, and adjustment of watering parameters based on the specific needs of each plant species. The model then starts measuring and taking the readings displayed on the Thonny Shell shown in fig. 7. Table I shows the soil moisture readings from the capacitive soil moisture sensor & level of accuracy of the sensor when compared to the recommended moisture level. Fig. 8 depicts the soil moisture level and the recommended moisture needed for the plants. The relationship between soil moisture levels and the recommended moisture level for plants is graphically represented in Figure 8. Individuals can make informed decisions to promote healthy plant growth, conserve water, and preserve natural and agricultural ecosystems by comprehending this relationship. Gardeners can decide when and how much to water their plants by monitoring soil moisture and using the specified range. Avoiding under watering and overwatering optimizes plant growth and conserves water. Water management influences the ecological balance and is essential for plant and animal survival. Fig. 9, the online snapshot showing the moisture reading, promotes transparency, engagement, and accessibility, enhancing your research's effect. It supports the study's findings and contributes to broader educational and practical applications, promoting sustainable water management and nurturing collaboration within the scientific community. Fig. 7:. Thonny Shell displaying sensors readings Show All Fig. 8. Levels of soil moisture of different Plants Show All Fig. 9. Self-designed Web showing sensor and module readings Show All Table I. Readings from the capacitive soil moisture sensor along with the accuracy of the sensor SECTION VI. Conclusion & Futurescope In this study, we an intelligent soil moisture management system at Siksha ‘O’ Anusandhan (S ‘O’A) University using IoT technology is developed and implemented. The system utilizes sensor nodes, wireless communication, and cloud computing to enable real-time monitoring and automated irrigation control. Through extensive testing and validation, the study demonstrates the system's reliability and ability to improve water use efficiency compared to traditional methods. The IoT -based architecture of the system offers scalability and flexibility, making it adaptable to different crop types and field conditions within the university. The system revolutionizes soil moisture management practices by providing continuous, remote, and precise measurements of soil moisture levels. This contributes to the field of precision agriculture by offering an efficient and tailored solution for optimizing crop growth and yield. The implementation of this IoT -based system within SOA University promotes the integration of cutting-edge technology into agricultural practices. It enhances crop productivity by enabling real-time monitoring and automated irrigation control, leading to sustainable water resource utilization. Moreover, it aligns with the university's environmental sustainability and resource management commitment. The smart soil moisture management system developed in this research has the potential to significantly benefit gardeners and farmers of the university by reducing labor, saving time, and increasing crop yields while minimizing damage. Furthermore, the system's capability to conserve water and resources contributes to a more sustainable and environmentally friendly approach to agriculture. However, this research highlights the importance and effectiveness of IoT -based soil moisture management systems in precision agriculture. It showcases the potential for using advanced technologies to optimize crop growth, improve water management practices, and create a more sustainable future. Authors Figures References Keywords Metrics More Like This Greenhouse smart irrigation based on soil moisture and vegetation index measurements 2023 IEEE Conference on Technologies for Sustainability (SusTech) Published: 2023 Irrigation pivot-center connected at low cost for the reduction of crop water requirements 2018 International Conference on Advanced Communication Technologies and Networking (CommNet) Published: 2018 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."

</subsection_point_Point 1>

<previous_sections>

A systematic review of automated systems for real-time irrigation management

1. INTRODUCTION
The challenge of feeding a growing population with finite resources is becoming increasingly pressing. By 2050, the world population is expected to reach 9.7 billion, necessitating a 70% increase in food production (Falkenmark and Rockstrom, 2009). Irrigation plays a crucial role in enhancing crop yields and agricultural productivity to meet this growing demand. Studies have shown that irrigation can significantly increase crop water productivity, contributing to increased food production (Ali and Talukder, 2008; Playan and Mateos, 2005). However, water scarcity poses a significant challenge, with many regions facing water deficits and the need for improved water management practices (Falkenmark and Rockstrom, 2009). Optimizing irrigation schedules and doses based on crop requirements and environmental conditions is essential for maximizing yield and quality while minimizing water use (Zhang et al., 2024). The necessity of scalable water-efficient practices for increasing food demand cannot be overstated. Techniques such as regulated deficit irrigation, magnetically treated water, and the use of drought-tolerant crops like sorghum have shown promise in improving water productivity and ensuring food security (Mehmood et al., 2023; Putti et al., 2023; Hadebe et al., 2016). As the global food challenge intensifies, it is imperative to critically evaluate the current state and future potential of irrigation management systems to guide research, innovation, and implementation efforts towards fully autonomous, scalable solutions.

Despite the importance of irrigation in addressing the global food challenge, traditional irrigation management techniques, such as manual scheduling and timer-based systems, have significant limitations. These methods are often labor-intensive, inefficient, and less adaptable to changing conditions (Savin et al., 2023). Manual and timer-based scheduling can lead to high operational costs and inefficient water use (Raghavendra, Han, and Shin, 2023). The reliance on manual intervention and predetermined schedules limits their adaptability to changing environmental conditions, crop water requirements, and soil moisture levels (Kaptein et al., 2019). Sensor-based irrigation systems offer an alternative, enabling real-time adjustments based on soil water status measurements (Kaptein et al., 2019). However, the adoption of these systems in commercial settings has been limited, often requiring extensive input from researchers (Kim et al., 2014; Lea-Cox et al., 2018; Ristvey et al., 2018). The limitations of traditional irrigation management techniques highlight the need for scalable, automated solutions for greater efficiency in irrigation management. Automated systems that collect real-time data, analyze it, and make autonomous irrigation decisions can lead to improved water use efficiency and increased crop productivity (Champness et al., 2023; Wu et al., 2022). To fully understand the potential of automated systems, it is necessary to examine the automation of each part of the irrigation management pipeline and analyze the effectiveness and efficiency of integrated end-to-end solutions.

The emergence of smart irrigation management and IoT marks a significant shift from historical irrigation practices. Modern approaches rely on vast data and analysis algorithms, leveraging technologies such as remote sensing, sensor networks, weather data, and computational algorithms (Atanasov, 2023; Bellvert et al., 2023; Kumar et al., 2023). IoT plays a vital role in collecting vast amounts of data through sensors, data transmission, and tailored networks, enabling real-time monitoring and control of irrigation systems (Liakos, 2023; Zuckerman et al., 2024). These advancements in data collection and analysis have the potential to revolutionize irrigation management, allowing for more precise and efficient water use. However, challenges such as processing diverse data sources, data integration, and lack of integrated data analysis hamper the full benefit of IoT in irrigation management (Dave et al., 2023). The current fragmented approach in smart irrigation, focusing on individual components rather than the entire system, limits the potential for fully autonomous, real-time end-to-end irrigation management (Togneri et al., 2021). To address these challenges and fully realize the potential of smart irrigation management, there is a need for automating and integrating each section of the irrigation management pipeline, from sensor/weather data collection and transmission to processing, analysis, decision-making, and automated action (McKinion and Lemmon, 1985). This integration requires a thorough investigation of the role of interoperability and standardization in enabling seamless communication and compatibility between components within the automated irrigation management pipeline.

Machine learning (ML) plays a significant role in processing vast data, predicting plant stress, modeling climate effects, and optimizing irrigation in smart irrigation management systems. ML algorithms can analyze data collected from sensors and weather stations to determine optimal irrigation schedules (Vianny et al., 2022). However, the potential of ML is often constrained by manual steps, such as data interpretation, decision-making on irrigation timing and volume, and system adjustments. Automating ML integration to allow direct action from insights to irrigation execution, removing bottlenecks and achieving real-time adaptability, is crucial for fully autonomous irrigation management (Barzallo-Bertot et al., 2022). By integrating ML into automated systems, the irrigation management pipeline can become more seamless and efficient, enabling real-time decision-making and action based on data-driven insights. To achieve this level of automation and integration, it is essential to identify gaps and propose solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.

To achieve seamless integration across the automated irrigation management system, interoperability and standardization are critical. Interoperability allows different system components, such as sensors, actuators, and software, to communicate and exchange data effectively, while standardization ensures that data is represented in a consistent format (Santos et al., 2020). Standardized protocols and data formats are essential for achieving seamless integration and ensuring compatibility between components in real-time irrigation management systems (Robles et al., 2022; Hatzivasilis et al., 2018). Existing and emerging standards, such as OGC SensorThings API and ISO 11783, have applicability to real-time irrigation management systems (Hazra et al., 2021). However, challenges such as data quality, scalability, reliability, and security need to be addressed to fully realize the potential of interoperability and standardization in automated irrigation management systems (Hazra et al., 2021). Addressing these challenges is crucial for enabling the seamless integration of components within the automated irrigation management pipeline, which is essential for achieving fully autonomous, scalable irrigation management. A comprehensive evaluation of the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline is necessary to guide future research and implementation efforts.
The primary objective of this systematic review is to critically evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies for enhancing agricultural water use efficiency and crop productivity.
Specific objectives include:
•	Examining the automation of each part of the irrigation management pipeline and the seamless integration of each section in the context of irrigation scheduling and management.
•	Analyzing the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
•	Investigating the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.
•	Identifying gaps and proposing solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.
By addressing these objectives, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.

2. REVIEW METHODOLOGY
•	Question-driven framework to guide the literature review of real-time, autonomous irrigation management systems
•	Key research questions posed, each with the motivation behind investigating them and a starting hypothesis to evaluate against the examined literature
•	Table presenting the major objectives, specific objectives, questions, motivations, and hypotheses
3. DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING
3.1. Irrigation management data
The success of automated irrigation management systems relies heavily on the collection, transmission, and analysis of various types of data. The most applicable data types for irrigation management include soil moisture, canopy temperature, weather data, and plant physiological parameters (Farooq et al., 2019; Li et al., 2019; Olivier et al., 2021; Evett et al., 2020). These data are typically collected from a range of sources, including in-field sensors, remote sensing platforms, weather stations, and manual measurements (Li et al., 2019; Karimi et al., 2018).
Soil moisture data is arguably the most critical type of data for irrigation management, as it directly reflects the water available to plants and can be used to determine the optimal timing and amount of irrigation (Olivier et al., 2021; Intrigliolo & Castel, 2006). Soil moisture sensors, such as tensiometers, capacitance probes, and time-domain reflectometry (TDR) sensors, can provide real-time measurements of soil water content at various depths (Farooq et al., 2019). These sensors can be deployed in a network configuration to capture spatial variability in soil moisture across a field (Karimi et al., 2018).
Canopy temperature data is another valuable type of data for irrigation management, as it can be used to assess plant water stress and adjust irrigation accordingly (Evett et al., 2020). Infrared thermometers and thermal cameras can be used to measure canopy temperature, which is influenced by factors such as air temperature, humidity, wind speed, and plant water status (Li et al., 2019). When plants experience water stress, they tend to close their stomata to reduce water loss, leading to an increase in canopy temperature (Evett et al., 2020). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
Weather data, including temperature, humidity, precipitation, wind speed, and solar radiation, are essential for predicting crop water requirements and scheduling irrigation events (Akilan & Baalamurugan, 2024). Weather stations equipped with various sensors can provide real-time measurements of these parameters, which can be used as inputs for crop water requirement models, such as the FAO-56 Penman-Monteith equation (Li et al., 2019). These models estimate crop evapotranspiration (ET) based on weather data and crop-specific coefficients, allowing for the calculation of irrigation requirements (Intrigliolo & Castel, 2006). By integrating weather data into automated irrigation systems, irrigation schedules can be dynamically adjusted based on changing environmental conditions, ensuring that crops receive the optimal amount of water at the right time (Akilan & Baalamurugan, 2024).
When collecting and utilizing these data types, several considerations must be taken into account, including the volume, frequency, format, and source of the data (Farooq et al., 2019). The volume of data generated by automated irrigation systems can be substantial, especially when high-resolution sensors are deployed at a large scale (Bastidas Pacheco et al., 2022). This necessitates the use of efficient data storage, processing, and transmission technologies to handle the data load (Farooq et al., 2019). The frequency of data collection is another important consideration, as it directly impacts the temporal resolution of the data and the ability to detect rapid changes in plant water status or environmental conditions (Bastidas Pacheco et al., 2022). Bastidas Pacheco et al. (2022) demonstrated that collecting full pulse resolution data from water meters provides more accurate estimates of event occurrence, timing, and features compared to aggregated temporal resolutions, highlighting the importance of selecting appropriate data collection frequencies to ensure the quality and usefulness of the data for irrigation management.
The format of the data is also crucial, as it determines the compatibility and interoperability of the data with various analysis tools and platforms (Farooq et al., 2019). Standardized data formats, such as JSON, XML, or CSV, can facilitate data exchange and integration between different components of the automated irrigation system (Zhang et al., 2023). The source of the data is another important consideration, as it can impact the reliability, accuracy, and spatial coverage of the data (Farooq et al., 2019). For example, in-field sensors provide highly localized measurements, while remote sensing platforms, such as satellites or drones, can provide data at larger spatial scales (Li et al., 2019). By combining data from multiple sources, automated irrigation systems can achieve a more comprehensive understanding of crop water requirements and optimize irrigation management accordingly (Farooq et al., 2019).
Data quality, accuracy, and reliability are paramount in irrigation management, as they directly impact the effectiveness of decision-making processes and the efficiency of water use (Gupta et al., 2020). Inaccurate or unreliable data can lead to suboptimal irrigation decisions, resulting in crop stress, yield losses, or wasted water resources (Ramli & Jabbar, 2022). Gupta et al. (2020) emphasized the critical importance of data security and privacy in smart farming systems, as the leakage of sensitive agricultural data can cause severe economic losses to farmers and compromise the integrity of the automated irrigation system. The authors also highlighted the need for robust authentication and secure communication protocols to prevent unauthorized access to smart farming systems and protect data in transit (Gupta et al., 2020).
Ramli and Jabbar (2022) addressed the challenges associated with implementing real-time, automated irrigation systems, including data quality, scalability, reliability, and security. They proposed solutions and best practices based on the analysis of case studies and real-world implementations, such as the use of redundant sensors, data validation techniques, and secure communication protocols (Ramli & Jabbar, 2022). The authors also emphasized the importance of regular maintenance and calibration of sensors to ensure the accuracy and reliability of the collected data (Ramli & Jabbar, 2022).
Researchers have investigated the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in automated irrigation systems (Karim et al., 2023; Rady et al., 2020; Cui, 2023). Karim et al. (2023) explored the effectiveness of various data compression techniques, such as lossless and lossy compression algorithms, in reducing the size of data packets transmitted over wireless networks. The authors found that lossless compression techniques, such as Huffman coding and Lempel-Ziv-Welch (LZW), can significantly reduce data size without compromising data quality, while lossy compression techniques, such as JPEG and MP3, can further reduce data size by introducing acceptable levels of distortion (Karim et al., 2023).
Rady et al. (2020) developed a novel data compression algorithm specifically designed for irrigation data, which achieved significant compression ratios without compromising data quality. The authors demonstrated that their algorithm could reduce the amount of data transmitted over wireless networks, thereby improving the efficiency of the irrigation system and reducing costs (Rady et al., 2020). Cui (2023) investigated the use of data aggregation and filtering techniques to reduce the number of transmissions and save bandwidth in automated irrigation systems. The author proposed a data aggregation scheme that combines multiple sensor readings into a single value, such as the average soil moisture over a specified time interval, to reduce the frequency of data transmissions (Cui, 2023). Additionally, the author explored the use of data filtering techniques, such as Kalman filters and particle filters, to remove noise and outliers from sensor data, improving the accuracy and reliability of the transmitted information (Cui, 2023).
Data standardization and harmonization are crucial for facilitating seamless integration and interoperability between the various components of automated irrigation management systems (Zhang et al., 2023; Ermoliev et al., 2022). Zhang et al. (2023) developed a novel cyberinformatics technology called iCrop, which enables the in-season monitoring of crop-specific land cover across the contiguous United States. The authors highlighted the importance of data standardization and harmonization in the context of iCrop, as it allows for the efficient distribution of crop-specific land cover information based on the findable, accessible, interoperable, and reusable (FAIR) data principle (Zhang et al., 2023). By adopting standardized data formats and protocols, such as the Open Geospatial Consortium (OGC) standards, iCrop enables the seamless integration of various data sources and facilitates the interoperability of the system with other agricultural decision support tools (Zhang et al., 2023).
Ermoliev et al. (2022) proposed a linkage methodology for linking distributed sectoral/regional optimization models in a situation where private information is not available or cannot be shared by modeling teams. The authors emphasized the need for data standardization to enable decentralized cross-sectoral coordination and analysis, as it allows for the consistent representation and exchange of data between different models and stakeholders (Ermoliev et al., 2022). By adopting standardized data formats and interfaces, the proposed linkage methodology can facilitate the integration of various optimization models and support the development of comprehensive decision support systems for sustainable resource management (Ermoliev et al., 2022).
Metadata plays a vital role in providing context and enabling better data interpretation and decision-making in automated irrigation management systems (Jahanddideh-Tehrani et al., 2021). Metadata refers to the additional information that describes the characteristics, quality, and context of the primary data, such as the sensor type, calibration parameters, measurement units, and timestamp (Jahanddideh-Tehrani et al., 2021). Jahanddideh-Tehrani et al. (2021) highlighted the importance of metadata in water resources management, as it enables decision-makers to use the data to the best of its capabilities by understanding factors such as when water data was collected and what factors might have contributed to the measurements. The authors emphasized the need for standardized metadata formats and guidelines, such as the Dublin Core Metadata Initiative (DCMI) and the ISO 19115 standard, to ensure the consistency and interoperability of metadata across different water information systems (Jahanddideh-Tehrani et al., 2021).
In the context of automated irrigation management systems, metadata can provide valuable information about the data collection process, sensor performance, and environmental conditions that can aid in data interpretation and decision-making (Cota & Mamede, 2023). For example, metadata about the sensor type and calibration parameters can help assess the accuracy and reliability of the collected data, while metadata about the weather conditions and soil properties can provide context for interpreting the data and adjusting irrigation strategies accordingly (Cota & Mamede, 2023). By incorporating metadata into the data management and analysis pipeline of automated irrigation systems, decision-makers can make more informed and context-aware decisions, leading to improved water use efficiency and crop productivity (Jahanddideh-Tehrani et al., 2021).

3.2. Edge Computing and Fog Computing
Edge computing and fog computing have emerged as transformative technologies in the realm of real-time irrigation management systems, offering significant potential for improving efficiency, scalability, and reliability (Abdel Nasser et al., 2020; Tran et al., 2019). Edge computing refers to the practice of processing data near the edge of the network, close to the source of the data, while fog computing is a decentralized computing infrastructure that extends cloud computing capabilities to the network edge (Hassija et al., 2019). These technologies bring computation and analytics closer to the data source, reducing the need for data to travel to the cloud and enabling faster processing and decision-making (Hassija et al., 2019; Zhang et al., 2020).
The potential of edge computing and fog computing in real-time irrigation management is immense. Abdel Nasser et al. (2020) proposed a two-layer system for water demand prediction using automated meters and machine learning techniques, demonstrating the potential of edge computing in improving the efficiency and scalability of irrigation management. The system collects and aggregates data from distributed smart meters in the first layer, while the second layer uses LSTM neural networks to predict water demand for different regions of households. By leveraging edge computing, the system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management (Abdel Nasser et al., 2020).
Tran et al. (2019) conducted a comprehensive review of real-time, end-to-end automated irrigation management systems, highlighting the role of fog computing in addressing data transmission challenges and enabling seamless integration across the irrigation management pipeline. The authors emphasize that real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs. However, they also identify several challenges that need to be addressed, such as data quality, scalability, reliability, and security, which can be effectively tackled by implementing fog computing architectures (Tran et al., 2019).
Edge computing offers several benefits in real-time irrigation management systems, including reduced latency, real-time decision-making, and reduced reliance on cloud connectivity (Mishra, 2020; Zhang et al., 2020). By processing data closer to the source, edge computing enables faster response times and more efficient data handling (Mishra, 2020). Mishra (2020) highlights that edge computing reduces latency by processing data closer to the source, enabling real-time decision-making and lessening reliance on cloud connectivity by shifting processing to local or edge devices.
Zhang et al. (2020) explore the application of edge computing in agricultural settings, demonstrating its potential to improve the efficiency and accuracy of irrigation systems. The authors discuss how edge computing has prospects in various agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. They also emphasize that the emergence of edge computing models, such as fog computing, cloudlet, and mobile edge computing, has transformed the management and operation of farms (Zhang et al., 2020).
Fog computing plays a crucial role in distributing processing and storage across the network, enhancing the scalability and reliability of automated irrigation systems (Premkumar & Sigappi, 2022; Singh et al., 2022). Premkumar and Sigappi (2022) evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation. Their study emphasizes the potential of fog computing in distributing processing and storage across the network, improving the efficiency and scalability of irrigation systems. The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture, demonstrating the effectiveness of fog computing in enhancing the performance of automated irrigation systems (Premkumar & Sigappi, 2022).
Singh et al. (2022) discuss the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability in agricultural management systems. The authors argue that by implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness. They also highlight that fog computing can address the challenges faced by real-time data transmission in agricultural management systems, such as latency, bandwidth limitations, and data security (Singh et al., 2022).
The integration of edge and fog computing in real-time irrigation management systems is crucial for achieving fully automated, scalable, and reliable solutions. As the demand for autonomous irrigation management grows, these technologies will play a pivotal role in enabling faster decision-making, reduced latency, improved resource utilization, and seamless integration across the irrigation management pipeline (Tran et al., 2019; Zhang et al., 2020). By bringing computation and analytics closer to the data source and distributing processing and storage across the network, edge and fog computing can significantly enhance the efficiency and effectiveness of automated irrigation systems, contributing to the overall goal of addressing the global food challenge through optimized water resource management and increased agricultural productivity (Abdel Nasser et al., 2020; Premkumar & Sigappi, 2022; Singh et al., 2022).

3.3. Automation of Data Collection
The automation of data collection is a critical component in the development of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. It enables the efficient gathering of vital information about crop health, environmental conditions, and water requirements, which is essential for enhancing agricultural water use efficiency and crop productivity. Two key aspects of automated data collection are the use of advanced sensing technologies for non-invasive plant stress detection and the implementation of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.
Advanced sensing technologies, such as hyperspectral imaging and thermal sensing, have emerged as powerful tools for non-invasive plant stress detection in automated irrigation management systems. These technologies provide valuable information about crop traits, enabling early and accurate detection of plant health issues (Triantafyllou et al., 2019). Triantafyllou et al. (2019) propose a comprehensive reference architecture model that incorporates advanced sensing technologies in the sensor layer for real-time plant stress detection, highlighting their importance in providing non-invasive plant stress detection. Similarly, Hossain et al. (2023) present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that leverages advanced sensing technologies to optimize water use and improve crop yield, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
Hyperspectral imaging can capture subtle changes in plant physiology that are indicative of stress, while machine learning algorithms can be employed to extract meaningful patterns from the spectral data and classify different stress types (Araus et al., 2014). Thermal sensing can detect changes in canopy temperature, which is influenced by factors such as plant water status (Li et al., 2019). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
The integration of advanced sensing technologies in automated irrigation management systems has the potential to revolutionize precision agriculture. Jiang et al. (2019) demonstrate the effectiveness of a deep learning-based model in accurately detecting leaf spot diseases, highlighting the importance of image augmentation and deep learning algorithms in enhancing the model's performance.
Wireless sensor networks (WSNs) and energy-efficient communication protocols have the potential to significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. WSNs offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems, providing remote monitoring and automated control capabilities (Mehdizadeh et al., 2020). Nishiura and Yamamoto (2021) propose a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields, reducing operational costs and enhancing the efficiency of data collection. Similarly, Higashiura and Yamamoto (2021) introduce a network system that employs UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands, optimizing data collection and reducing travel distance and time.
Energy-efficient communication protocols are crucial for ensuring reliable data transmission in challenging environmental conditions and extending the lifespan of sensor nodes (Mehdizadeh et al., 2020). Al-Ali et al. (2023) investigate the potential of WSNs and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems, discussing the challenges and opportunities of using these technologies to improve the efficiency and reliability of real-time data collection in irrigation management. Mehdizadeh et al. (2020) emphasize the need for careful consideration of factors such as data accuracy, energy consumption, and network reliability when designing effective WSNs for irrigation management, enabling timely irrigation decisions and improved crop yields.
The automation of data collection through the use of advanced sensing technologies and wireless sensor networks is essential for achieving fully autonomous, scalable irrigation management. By enabling non-invasive plant stress detection and large-scale, long-term data collection, these technologies contribute to the overall goal of optimizing water resource management and increasing agricultural productivity. The integration of these technologies in real-time, end-to-end automated irrigation management systems has the potential to enhance agricultural water use efficiency and crop productivity, ultimately contributing to the development of fully autonomous, scalable irrigation management solutions.

3.4: Real-Time Data Transmission Protocols and Technologies
Real-time data transmission is a critical component of automated irrigation management systems, as it enables the timely delivery of sensor data to the cloud for processing and decision-making. The exploration of suitable protocols and network architectures is essential for ensuring efficient and reliable data transmission in these systems, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
The Message Queuing Telemetry Transport (MQTT) protocol has emerged as a popular choice for real-time data transmission in IoT networks, including those used for automated irrigation management. MQTT is a lightweight, publish-subscribe protocol designed for constrained devices and low-bandwidth networks (Author, 2019). Its simplicity and low overhead make it well-suited for IoT applications where data transmission speed and energy efficiency are critical (Saranyadevi et al., 2022). MQTT provides three Quality of Service (QoS) levels, ensuring data reliability in real-time scenarios (Author, 2019). Chen et al. (2020) proposed novel algorithms to improve data exchange efficiency and handle rerouting in MQTT-based IoT networks for automated irrigation management systems. Their TBRouting algorithm efficiently finds the shortest paths for data transmission, while the Rerouting algorithm effectively handles the rerouting of topic-based session flows when a broker crashes. The combination of these algorithms can significantly improve the performance and reliability of automated irrigation management systems (Chen et al., 2020).
Client-server IoT networks, such as those based on MQTT, play a crucial role in real-time data transmission for automated irrigation management systems. In these networks, sensors and devices (clients) publish data to a central broker (server), which then distributes the data to subscribed clients (Verma et al., 2021). This architecture enables efficient data collection, processing, and dissemination, facilitating the integration of various components within the automated irrigation management pipeline. Verma et al. (2021) proposed an architecture for healthcare monitoring systems using IoT and communication protocols, which provides a comprehensive overview of existing approaches and highlights challenges and opportunities in the field. Although focused on healthcare, the insights from this study can be applied to automated irrigation management systems, emphasizing the importance of interoperability and standardization for seamless integration (Verma et al., 2021).
In addition to MQTT, other application layer protocols such as XMPP, CoAP, SOAP, and HTTP have been explored for real-time data transmission in IoT networks. Each protocol has its strengths and weaknesses, making them suitable for different applications and scenarios. XMPP (Extensible Messaging and Presence Protocol) is an open-standard protocol that supports real-time messaging, presence, and request-response services (Saint-Andre, 2011). CoAP (Constrained Application Protocol) is a specialized web transfer protocol designed for use with constrained nodes and networks in the Internet of Things (Shelby et al., 2014). SOAP (Simple Object Access Protocol) is a protocol for exchanging structured information in the implementation of web services, while HTTP (Hypertext Transfer Protocol) is the foundation of data communication for the World Wide Web (Fielding et al., 1999).
Motamedi and Villányi (2022) compared and evaluated wireless communication protocols for the implementation of smart irrigation systems in greenhouses, considering factors such as power consumption, range, reliability, and scalability. They found that ZigBee is the most suitable local communication protocol for greenhouse irrigation due to its large number of nodes and long range, while MQTT is the recommended messaging protocol for smart irrigation systems due to its TCP transport protocol and quality of service (QoS) options. GSM is a reliable and cost-effective global communication protocol for greenhouse irrigation, providing wide coverage and low cost (Motamedi & Villányi, 2022).
Syafarinda et al. (2018) investigated the use of the MQTT protocol in a precision agriculture system using a Wireless Sensor Network (WSN). They found that MQTT is suitable for use in IoT applications due to its lightweight, simple, and low bandwidth requirements. The average data transmission speed using the MQTT protocol was approximately 1 second, demonstrating its effectiveness for real-time data transmission in precision agriculture systems (Syafarinda et al., 2018).
The choice of application layer protocol for real-time irrigation management depends on factors such as data transmission speed, reliability, and energy efficiency. MQTT and RTPS (Real-Time Publish-Subscribe) are both suitable for real-time data transmission in IoT systems, but they have different strengths and weaknesses. MQTT is a better choice for applications that require low latency and high throughput, while RTPS is a better choice for applications that require high reliability and low latency (Sanchez-Iborra & Skarmeta, 2021). The exploration of MQTT and client-server IoT networks, along with the comparison of various application layer protocols, provides valuable insights into the suitability of these technologies for real-time data transmission in automated irrigation management systems.
In summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.

3.5. Challenges and Solutions in Real-Time Data Transmission
Following the exploration of data collection, processing at the edge and fog, and automation in previous sections, we now turn to the critical aspect of real-time data transmission. While essential for automated irrigation management, this stage presents unique challenges that must be addressed to ensure system efficiency and reliability.
Obstacles in Real-Time Data Transmission
Agricultural environments present unique challenges for real-time data transmission, directly impacting the effectiveness of automated irrigation systems. Environmental factors can significantly disrupt wireless communication. Adverse weather conditions such as heavy rain, fog, and high winds can weaken or even block radio signals, leading to data loss and compromised system performance. Physical obstacles like trees, buildings, and uneven terrain further complicate signal propagation, creating reliability issues (Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). These environmental challenges necessitate robust communication protocols and network architectures that can ensure consistent and reliable data flow.
In addition to environmental factors, technical limitations also present significant obstacles. Large-scale agricultural operations often demand long-distance data transmission, which can be hindered by the limited range of certain wireless communication protocols. Network congestion, occurring when multiple sensors transmit data concurrently, can lead to delays and potential data loss, further complicating real-time decision-making (Hameed et al., 2020). To mitigate these issues, researchers have investigated the potential of cognitive radio networks (CRNs) and dynamic spectrum access (DSA) for optimizing spectrum utilization and reducing interference (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). CRNs enable devices to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency. DSA, on the other hand, facilitates the dynamic allocation of unused spectrum, enhancing spectrum utilization and reducing congestion.
Furthermore, data security and privacy are paramount concerns in real-time irrigation systems. The sensitive nature of agricultural data, such as crop yields and farm management practices, necessitates robust security measures to prevent unauthorized access and data breaches (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential to protect data integrity and ensure the trustworthiness of the system.
Investigating Data Optimization Techniques
To enhance the efficiency and reliability of real-time data transmission in automated irrigation systems, researchers have explored a range of data optimization techniques. Data compression techniques aim to reduce the size of data packets transmitted over the network, minimizing bandwidth requirements and improving transmission speed (Rady et al., 2020; Karim et al., 2023). Lossless compression algorithms, such as Huffman coding and LZW, preserve data integrity while effectively reducing data size, ensuring that no information is lost during transmission (Cui, 2023). Lossy compression algorithms, such as JPEG and MP3, offer higher compression ratios but introduce a controlled level of data loss, which may be acceptable for certain applications where some loss of precision is tolerable (Karim et al., 2023). The choice between lossless and lossy compression depends on the specific application and the trade-off between data size and accuracy.
Data aggregation techniques provide another effective approach to optimize data transmission. By aggregating multiple sensor readings into a single representative value, such as average soil moisture or temperature, the number of transmissions can be significantly reduced, conserving bandwidth and energy resources (Cui, 2023). This is particularly beneficial in large-scale irrigation systems where numerous sensors are deployed across vast areas, generating substantial amounts of data. Additionally, data filtering techniques play a crucial role in improving data quality and reliability. Kalman filters and particle filters can effectively remove noise and outliers from sensor data, ensuring that only accurate and relevant information is transmitted and used for decision-making (Cui, 2023). This is essential for preventing erroneous data from influencing irrigation decisions and potentially leading to suboptimal water management.
Sensor calibration, drift correction, and fault detection are essential for maintaining data accuracy and reliability (Dos Santos et al., 2023). Regular calibration ensures that sensors provide accurate measurements over time, while drift correction techniques account for gradual changes in sensor readings due to environmental factors or aging. Fault detection mechanisms can identify and address sensor malfunctions or anomalies, preventing erroneous data from influencing irrigation decisions and potentially harming crops or wasting water.
Addressing the Challenges
Effectively addressing the challenges in real-time data transmission requires a multifaceted approach that encompasses environmental, technical, and data-related considerations. Implementing robust and adaptive communication protocols is crucial for overcoming interference and signal degradation caused by weather conditions and physical obstacles. Selecting appropriate protocols, such as LoRa or ZigBee, with suitable range and penetration capabilities can ensure reliable data transmission in challenging agricultural environments (Motamedi & Villányi, 2022). Additionally, employing techniques like frequency hopping and error correction codes can further improve communication resilience and mitigate data loss.
Optimizing network architecture is another key consideration. Deploying a distributed network architecture with edge and fog computing capabilities can significantly enhance data processing and transmission efficiency (Abdel Nasser et al., 2020; Tran et al., 2019). Edge devices can perform initial data processing and aggregation tasks, reducing the amount of data transmitted to the cloud and minimizing latency, while fog nodes can provide additional processing power and storage closer to the data source, enhancing scalability and reliability. This distributed approach alleviates the burden on the central cloud server and allows for more responsive and efficient irrigation management.
Data optimization techniques play a vital role in reducing bandwidth requirements and improving transmission efficiency. The choice of data compression, aggregation, and filtering techniques should be tailored to the specific requirements of the irrigation system, considering factors such as data type, accuracy needs, and available bandwidth. By carefully selecting and implementing these techniques, the overall performance and effectiveness of real-time irrigation systems can be significantly enhanced, leading to more sustainable water management practices and improved agricultural productivity.
By addressing these challenges and implementing appropriate solutions, real-time data transmission can become a reliable and efficient component of automated irrigation systems, contributing to the overall goal of achieving sustainable and productive agriculture in the face of growing food demands and water scarcity.

3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
Real-time irrigation management systems heavily rely on the efficient and reliable transmission of data from sensors and weather stations to the cloud for processing and decision-making. However, agricultural environments present unique challenges to wireless communication, including adverse weather conditions, physical obstacles, and the limitations of wireless technologies. These challenges necessitate robust and adaptive solutions to ensure the consistent and timely flow of data, enabling truly autonomous irrigation scheduling.
Environmental factors, such as heavy rain, fog, and strong winds, can significantly disrupt wireless communication by attenuating or even blocking radio signals, leading to data loss and compromised system performance (Ed-daoudi et al., 2023; Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). Dense vegetation, buildings, and uneven terrain create further complications by causing multipath propagation and shadowing effects (Yim et al., 2018; Gautam and Pagay, 2020). The study by Yim et al. (2018) on LoRa networks in a tree farm environment exemplifies these challenges, revealing reduced communication range and data reliability compared to theoretical expectations. This underscores the need for carefully selecting and optimizing communication protocols and network parameters to ensure reliable data transmission in such environments.
The study by Guzinski et al. (2014a) using a modified TSEB model further highlights the importance of high-resolution data in accurately capturing the spatial and temporal dynamics of energy fluxes influenced by environmental factors. This emphasizes the need for advanced data acquisition and processing techniques that can effectively represent the complexities of agricultural settings.
The limitations of traditional wireless communication technologies, such as limited range and network congestion, pose additional challenges for large-scale agricultural operations. Long-distance data transmission can be hindered by range limitations, while network congestion arising from numerous sensors transmitting concurrently can lead to delays and data loss, hindering real-time decision-making (Hameed et al., 2020). Addressing these challenges requires the exploration of advanced networking technologies that can optimize spectrum utilization, mitigate interference, and improve reliability and efficiency.
Cognitive Radio Networks (CRNs) and Dynamic Spectrum Access (DSA) offer promising solutions for optimizing wireless communication in agricultural settings. CRNs empower devices with the ability to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). Research has explored the potential of CRNs in predicting Radio Frequency (RF) power to avoid noisy channels and optimize spectrum utilization (Iliya et al., 2014; Iliya et al., 2014). These studies demonstrate the effectiveness of combining optimization algorithms with artificial neural networks (ANNs) to enhance the accuracy and generalization of RF power prediction, enabling CRNs to make informed decisions about channel selection and avoid interference.
DSA complements CRN technology by dynamically allocating unused spectrum, further enhancing spectrum utilization and reducing congestion (Shi et al., 2023). The numerical model developed by Shi et al. (2023) showcases the potential of CRNs and DSA for optimizing wireless communication in challenging environments.
The integration of CRNs and DSA into the IoT network architecture requires careful consideration of spectrum sensing techniques, network topology, and data security. Research on cooperative spectrum sensing suggests that distributed approaches, where sensor nodes collaborate and share information, can significantly improve the accuracy and efficiency of spectrum sensing, particularly in dynamic environments (Trigka and Dritsas, 2022; Khalid & Yu, 2019). This collaborative approach enables a more comprehensive understanding of the radio environment and facilitates the identification of available frequency bands for data transmission.
The choice of network topology also impacts the performance and scalability of CRN-based irrigation systems. Mesh networks, where sensor nodes are interconnected and relay data for each other, offer enhanced resilience and coverage compared to star topologies where nodes communicate directly with a central gateway (Akyildiz & Vuran, 2010). However, mesh networks can be more complex to manage and may introduce additional routing overhead. The trade-off between network resilience and complexity needs to be carefully evaluated to select the most appropriate topology for a specific agricultural setting.
Data security and privacy are paramount concerns in IoT-based irrigation systems due to the sensitive nature of agricultural data (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential for protecting data integrity and ensuring system trustworthiness. Research on secure spectrum leasing and resource allocation algorithms for CR-WSN-based irrigation systems has demonstrated the potential of these technologies for enhancing security and efficiency (Hassan, 2023; Afghah et al., 2018).
In conclusion, the development of effective and reliable real-time irrigation management systems requires a comprehensive approach that addresses the challenges of data transmission in agricultural environments. The integration of robust and adaptive communication protocols, optimized network architectures, and advanced networking technologies like CRNs and DSA, along with a focus on data security and privacy, can contribute significantly to achieving the goal of autonomous and efficient irrigation scheduling.
4. AUTOMATED DATA PROCESSING IN THE CLOUD
4.1. Data Quality and Preprocessing
Data quality is paramount in automated irrigation systems as it directly influences the effectiveness of decision-making and water use efficiency. Issues like missing values, inconsistencies, and outliers arising from sensor malfunctions, environmental interference, or network problems (Lv et al., 2023) can significantly impact the performance of machine learning models used for irrigation scheduling and management.
Real-time data cleaning techniques are essential for addressing these challenges. Kalman filtering proves particularly effective in handling missing values and correcting erroneous readings by recursively estimating the system's state based on previous measurements and current sensor data, taking into account noise and uncertainty (Kim et al., 2020). Moving average techniques, by averaging consecutive data points, provide a more stable representation of the underlying trend, filtering out short-term fluctuations (Chhetri, 2023). For outlier detection, adaptive thresholding methods offer a dynamic approach, adjusting thresholds based on the statistical properties of the data to effectively identify anomalies and minimize false positives (Bah et al., 2021). These techniques are crucial in maintaining the integrity of real-time data streams and ensuring the accuracy of subsequent analyses.
Adaptive data preprocessing is essential for managing the diversity of data sources and formats commonly found in irrigation systems. Data normalization techniques, such as min-max scaling or z-score normalization, ensure that all features contribute equally to the analysis by transforming data values to a common scale (Pradal et al., 2016). This is crucial for preventing features with larger values from dominating the analysis and ensuring that all features are given equal consideration. Similarly, feature scaling methods, like standardization or normalization, optimize the range of feature values to improve the performance and convergence of machine learning models (Tortorici et al., 2024). By scaling features to a similar range, the influence of outliers is reduced, and the model's ability to learn from the data is enhanced.
Data fusion techniques play a critical role in integrating information from diverse sources, creating a more comprehensive and reliable dataset for irrigation management. Dempster-Shafer theory, a generalization of probability theory, allows for the expression of both uncertainty and the degree of conflict in evidence, making it suitable for fusing uncertain and conflicting data from heterogeneous sources (Sadiq and Rodriguez, 2004). This is particularly relevant in irrigation systems where data from different sensors may provide slightly different or even contradictory information due to sensor variations or environmental factors. Bayesian inference offers another powerful framework for combining information from multiple sources, updating the probability of a hypothesis as new evidence becomes available. By applying these techniques, data from soil moisture sensors, canopy temperature sensors, weather stations, and other sources can be integrated to provide a holistic understanding of crop water requirements and environmental conditions, leading to more informed and accurate irrigation decisions.
The impact of data quality extends beyond model accuracy to the robustness of machine learning models under varying conditions. Robust models should maintain consistent performance even when faced with data inconsistencies or unexpected situations. Techniques like data augmentation and domain adaptation can enhance model robustness by exposing the model to a wider range of data variations during training. Data augmentation involves generating additional training data by applying transformations or introducing noise to existing data, making the model more resilient to noise and variations in the real-world data. Domain adaptation techniques aim to adapt a model trained on one domain (e.g., a specific crop or geographic location) to perform well on another domain with different data characteristics. This is particularly relevant in irrigation management, where models may need to be applied to different crops, soil types, or climatic conditions.
The choice of data cleaning, preprocessing, and fusion techniques should be carefully considered based on the specific characteristics of the irrigation system and the available data. By selecting and implementing appropriate techniques, the accuracy, reliability, and robustness of machine learning models can be significantly improved, leading to more efficient and sustainable irrigation management practices.
4.2. Scalable and Autonomous Deployment using Containerization Strategies
The transition from data collection and transmission to efficient data processing requires a robust infrastructure capable of handling diverse workloads and data volumes. Containerization technologies, specifically Docker and Kubernetes, offer a promising solution for deploying and scaling data processing and machine learning modules within cloud environments like AWS, Azure, and GCP (Vargas-Rojas et al., 2024; Rosendo et al., 2022; Solayman & Qasha, 2023). Docker provides a standardized way to package applications and their dependencies into self-contained units known as containers, ensuring consistent and reproducible execution across different platforms (Rosendo et al., 2022). Kubernetes, acting as a container orchestrator, manages their deployment, scaling, and networking across a cluster of machines (Rosendo et al., 2022). This combination presents several advantages for automated irrigation management systems.
Firstly, containerization facilitates efficient resource utilization and scalability. By encapsulating applications and their dependencies, containers enable the isolation of resources and prevent conflicts between different modules (Vargas-Rojas et al., 2024; Solayman & Qasha, 2023). This isolation allows for the efficient allocation of resources, such as CPU, memory, and storage, to each container based on its specific needs. Kubernetes further enhances scalability by allowing for the automatic scaling of containers based on real-time demand, ensuring the system can adapt to varying workloads and data volumes, preventing bottlenecks, and ensuring responsiveness to changing conditions (Karamolegkos et al., 2023).
Secondly, containerization promotes portability and reproducibility. By packaging applications and their dependencies into a single unit, containers make it easy to move and deploy them across different cloud environments without the need for environment-specific configurations (Rosendo et al., 2022; Solayman & Qasha, 2023). This portability simplifies the development and deployment process, reducing the time and effort required to set up and manage the system. Additionally, containers ensure reproducibility by providing a consistent execution environment, regardless of the underlying infrastructure. This eliminates variability and ensures that the system will behave consistently across different deployments (Zhou et al., 2023).
Optimizing container orchestration and resource allocation is crucial to minimizing latency and maximizing throughput in real-time data processing pipelines. Techniques like auto-scaling and dynamic resource allocation play a critical role in this context (Hethcoat et al., 2024; Werner and Tai, 2023; Kumar et al., 2024). Auto-scaling automatically adjusts the number of container instances based on real-time demand, ensuring that sufficient resources are available to handle peak workloads while avoiding over-provisioning during periods of low demand (Hethcoat et al., 2024; Kumar et al., 2024). Dynamic resource allocation enables the fine-grained adjustment of resources allocated to each container based on its specific needs and the current workload (Werner and Tai, 2023). This ensures efficient resource allocation and provides each container with the necessary resources to perform its tasks effectively.
Performance monitoring tools, such as Kubernetes Metrics Server and Prometheus, are essential for gaining insights into the performance of containers and the overall system (Hethcoat et al., 2024; Kuity & Peddoju, 2023). These tools provide valuable data on key performance indicators, such as CPU and memory usage, network traffic, and application-specific metrics. By monitoring this data, administrators can identify bottlenecks, optimize resource allocation strategies, and continuously improve system performance (Hethcoat et al., 2024). This data-driven approach ensures that automated irrigation management systems can operate efficiently and reliably.
By integrating containerization technologies with optimization techniques and performance monitoring, automated irrigation management systems achieve the scalability, autonomy, and efficiency required for effective real-time data processing and decision-making. This approach facilitates a seamless and responsive system that can adapt to changing conditions and contribute to the overall goal of optimizing water resource management and increasing agricultural productivity.

4.3. Deploying ML Models for Data Processing
Transitioning from data collection, preprocessing, and transmission, the deployment of machine learning (ML) models marks a pivotal stage in the automated irrigation management pipeline. This stage entails utilizing cloud platforms to facilitate real-time data processing and inference, enabling data-driven decision-making for optimal irrigation management and ultimately contributing to fully autonomous, scalable irrigation management.
Several architectures and frameworks exist for deploying ML models on cloud platforms, each offering unique advantages and catering to different requirements. TensorFlow Serving, for instance, provides a high-performance system specifically designed for serving TensorFlow models (Abadi et al., 2016). This framework enables efficient and scalable inference, making it suitable for real-time applications where low latency and high throughput are crucial. For instance, in a large-scale irrigation system with numerous sensors generating data continuously, TensorFlow Serving can efficiently handle the high volume of inference requests and provide timely predictions for irrigation scheduling. Similarly, Apache MXNet Model Server offers a flexible and efficient solution for deploying models trained with MXNet, supporting a wide range of deep learning models and inference backends (MXNet Developers, 2015). This versatility makes it suitable for complex irrigation systems that may utilize different types of ML models for various tasks, such as predicting crop water requirements, detecting plant stress, or forecasting weather conditions. ONNX Runtime, on the other hand, provides a cross-platform inference engine compatible with various ML frameworks, including PyTorch, TensorFlow, and MXNet (Microsoft, 2017). This versatility enables the deployment of models in diverse environments, facilitating interoperability and reducing the need for model conversion. For example, an irrigation system that uses models trained in different frameworks can utilize ONNX Runtime to deploy them on a single platform without the need for time-consuming and error-prone model conversion processes.
Choosing the appropriate architecture or framework depends on several factors, including the specific ML framework used for model training, the desired level of performance and scalability, and the need for cross-platform compatibility. For instance, if the primary concern is low latency and high throughput for real-time inference, TensorFlow Serving might be the optimal choice for TensorFlow models. However, if flexibility and support for various deep learning models are required, Apache MXNet Model Server could be more suitable. In cases where cross-platform compatibility is essential, ONNX Runtime offers a versatile solution.
Once the ML model is deployed, optimizing its performance and resource utilization becomes crucial for ensuring the efficiency of integrated end-to-end automated irrigation systems. Model compression techniques, such as pruning and quantization, offer effective methods for reducing the size and computational requirements of ML models without compromising accuracy (Premkumar & Sigappi, 2022). Pruning involves eliminating unnecessary connections or neurons from the model, effectively streamlining its structure and reducing computational complexity. This can be particularly beneficial for deep learning models, which often have a large number of parameters and can be prone to overfitting. By removing redundant or less important connections, pruning can improve modelgeneralizability and reduce inference time. Quantization, on the other hand, involves reducing the precision of model parameters, typically from 32-bit floating-point numbers to lower-precision formats such as 8-bit integers. This reduction in precision leads to smaller model sizes and faster inference speeds, making it particularly beneficial for resource-constrained environments or real-time applications. For instance, in edge computing scenarios where ML models are deployed on devices with limited computational resources, quantization can enable efficient inference without sacrificing accuracy.
Furthermore, hardware acceleration through the utilization of GPUs or TPUs can significantly enhance model performance by leveraging specialized hardware designed for parallel processing (Premkumar & Sigappi, 2022). GPUs, with their massive parallelism and high memory bandwidth, excel at accelerating matrix operations and convolutions, which are fundamental computations in many deep learning models. This acceleration can significantly reduce inference time and enable real-time processing of sensor data for timely irrigation decisions. TPUs, specifically designed for deep learning workloads, offer even greater performance and energy efficiency for specific model architectures. These hardware accelerators can drastically reduce inference time, enabling near real-time decision-making and enhancing the responsiveness of automated irrigation systems. For example, in a scenario where immediate response to changing weather conditions or soil moisture levels is critical, hardware acceleration can ensure that irrigation decisions are made and executed promptly.
In addition to model compression and hardware acceleration, distributed training techniques play a crucial role in optimizing the training process for large-scale ML models. Techniques such as Horovod and BytePS enable the distribution of training across multiple machines, effectively parallelizing the process and reducing training time (Premkumar & Sigappi, 2022). This is particularly beneficial for complex models with a large number of parameters or when dealing with large datasets. By leveraging distributed training, irrigation management systems can train more sophisticated models and improve their predictive capabilities, leading to more accurate and efficient irrigation decisions. For instance, a system that utilizes a deep learning model with millions of parameters can benefit from distributed training to reduce training time from days to hours, enabling faster model iteration and improvement.
Integrating the deployed ML models with other components of the automated irrigation management pipeline is essential for achieving a fully autonomous and cohesive system and addressing the need for seamless integration across the automated irrigation management system. Standardized protocols, such as MQTT and CoAP, provide lightweight and efficient communication channels for exchanging data between these components (Poojara et al., 2023; Jimenez et al., 2020a; Gour et al., 2023). MQTT, with its publish-subscribe architecture, enables real-time data streaming and event-driven communication, making it suitable for transmitting sensor data, control signals, and inference results (Raikar & M, 2023). This enables the ML model to receive real-time updates on soil moisture, weather conditions, and plant health, allowing for dynamic adjustments to irrigation schedules based on the latest data. CoAP, designed for constrained devices and low-power networks, offers a web-transfer protocol for resource-constrained environments, enabling efficient communication between sensors, actuators, and the ML models (Raikar & M, 2023). This is particularly relevant in situations where sensors or actuators have limited processing power or battery life, as CoAP minimizes communication overhead and energy consumption. Additionally, RESTful APIs provide a standardized interface for accessing and controlling the ML models, enabling seamless integration with other software components and facilitating system management and monitoring (Wang et al., 2022). This allows for easy integration with existing farm management systems or third-party applications, creating a unified platform for comprehensive irrigation management.4.4. Online Learning in the Cloud
The complexities of real-time data processing in irrigation management necessitate the exploration of advanced techniques to continuously learn and adapt to the dynamic nature of agricultural environments. Online learning algorithms offer a promising solution, enabling the continuous update and improvement of machine learning models based on incoming real-time data. This adaptability is crucial for addressing the challenges of changing environmental conditions, such as weather patterns and crop growth stages, and optimizing irrigation decision-making to enhance water usage efficiency and crop productivity.
Several online learning algorithms have demonstrated potential for real-time data processing and model adaptation in the context of irrigation management. Stochastic Gradient Descent (SGD) facilitates the incremental update of model parameters with each new data point, allowing for efficient adaptation to changing data distributions (Bottou, 2010). This incremental learning process ensures that the model remains responsive to the latest conditions, minimizing the risk of outdated predictions and improving the accuracy of irrigation decisions. Passive-Aggressive algorithms, on the other hand, adjust model parameters only when a misclassification occurs, providing a computationally efficient approach for handling large data streams (Crammer et al., 2006). These algorithms offer a robust approach to handling noisy data, a common challenge in real-world sensor readings, by making small adjustments only when the model's prediction deviates significantly from the actual value (Fei et al., 2019). Online Random Forests extend the concept of random forests to the online setting, enabling the incremental construction and update of decision trees as new data arrives (Saffari et al., 2009). The continuous evolution of the ensemble ensures that the model remains relevant to the changing environment, capturing intricate relationships between variables and leading to more informed irrigation decisions.
Research in various domains highlights the importance of online learning for real-time data stream analytics. Snyder et al. (2020) explored the application of online learning techniques for identifying relevant tweets in real-time, improving situational awareness for first responders. The proposed interactive learning framework allows users to continuously label the relevance of incoming tweets, enabling the real-time refinement of the underlying machine learning model. This user-guided approach aligns well with the dynamic nature of irrigation management, where models need to continuously adjust to varying environmental conditions and crop water requirements. Similarly, research in the field of cyber-physical systems (CPS) underscores the need for online learning algorithms to effectively extract insights and knowledge from continuously generated data streams (Fei et al., 2019). These capabilities are crucial for enabling feedback loops between physical processes and cyber elements, facilitating the integration and optimization of CPS in irrigation management systems.
To implement online learning in cloud-based irrigation management systems, various architectures and frameworks can be considered. Apache Spark Streaming, Apache Flink, and AWS Kinesis provide scalable and fault-tolerant platforms for processing real-time data streams, allowing for the development of online learning pipelines that continuously ingest and analyze data to update machine learning models (Zaharia et al., 2012; Carbone et al., 2015; Amazon Web Services, 2023). These frameworks leverage serverless computing paradigms, automatically scaling resources based on the volume and velocity of incoming data, ensuring efficient resource utilization and responsiveness to fluctuations in demand (Fei et al., 2019).
Effectively managing the exploration-exploitation trade-off is crucial for optimizing online learning in irrigation management. Techniques such as Multi-armed bandits (Sutton & Barto, 2018), Bayesian optimization (Shahriari et al., 2016), and Reinforcement Learning (RL) (Sutton & Barto, 2018) can be employed to balance the allocation of resources between exploring new irrigation strategies and exploiting the current best-performing approaches. These techniques enable the identification of optimal irrigation policies, adapting to changing environmental conditions and maximizing long-term rewards.
In conclusion, online learning techniques, coupled with scalable cloud-based architectures, offer a powerful solution for real-time data processing and continuous adaptation in irrigation management systems. By leveraging algorithms like SGD, Passive-Aggressive, and Online Random Forests, along with stream processing frameworks like Apache Spark Streaming, Apache Flink, and AWS Kinesis, irrigation management systems can effectively handle the complexities of real-time data, optimize water usage, and enhance crop productivity in the face of dynamic environmental conditions.

5. GENERATING AND APPLYING IRRIGATION INSIGHTS 
5.1. Real-Time Generation of Actionable Irrigation Insights
•	Advanced predictive models, such as deep learning (e.g., LSTM, CNN) and ensemble methods (e.g., Random Forests), for precise, site-specific irrigation recommendations
•	Integration of IoT sensor data (e.g., soil moisture probes, weather stations) and cloud-based data sources (e.g., weather forecasts, satellite imagery) using data fusion techniques (e.g., Kalman filtering) to enhance insight accuracy and resolution
•	Strategies for handling data heterogeneity, uncertainty, and quality issues in real-time insight generation, such as data preprocessing and outlier detection
•	Techniques for reducing computational complexity and latency, such as edge computing (e.g., fog computing), model compression (e.g., quantization), and hardware accelerators (e.g., GPUs)
5.2. Automated Application of Irrigation Insights
•	Architectures and protocols for seamless integration of ML-generated insights with IoT-enabled irrigation control systems, such as MQTT and CoAP for lightweight, real-time communication
•	Analysis of industry-leading products and services, such as smart irrigation controllers (e.g., Rachio) and cloud-based irrigation management platforms (e.g., CropX)
•	Strategies for ensuring reliability, security, and scalability of automated insight application, such as redundant communication channels and secure edge-to-cloud architectures
•	Case studies of successful implementations of closed-loop, autonomous irrigation systems in research and commercial settings, highlighting technologies used and benefits achieved

6. INTEGRATION, INTEROPERABILITY, AND STANDARDIZATION 
6.1. Interoperability and Standardization
•	Importance of interoperability and standardization in enabling seamless integration of automated irrigation components
•	Overview of existing and emerging standards for IoT devices, communication protocols, and data formats in precision agriculture (e.g., ISOBUS, agroXML, SensorML)
•	Role of standardization bodies and industry consortia in promoting interoperability (e.g., AgGateway, Open Ag Data Alliance, Agricultural Industry Electronics Foundation)
•	Challenges in adopting and implementing standards across diverse hardware and software platforms
•	Strategies for encouraging widespread adoption of standards and best practices for interoperability in automated irrigation systems
6.2. Integration with Existing Irrigation Infrastructure
•	Challenges and strategies for retrofitting legacy irrigation systems with IoT sensors, actuators, and communication devices
•	Hardware compatibility issues and solutions (e.g., adapters, modular designs)
•	Software and firmware updates to enable integration with automated decision-making systems
•	Data integration and normalization techniques for merging legacy and new data sources
•	Economic and practical considerations for transitioning from manual to automated irrigation management
•	Cost-benefit analysis of upgrading existing infrastructure vs. implementing new systems
•	Phased implementation approaches to minimize disruption and optimize resource allocation
•	Training and support requirements for farmers and irrigation managers adopting automated systems
•	Case studies and real-world examples of successful integration of automated irrigation with existing infrastructure
6.3. Integration with Other Precision Agriculture Technologies
•	Synergies between automated irrigation and complementary technologies
•	Remote sensing (satellite, UAV, and ground-based) for crop monitoring and evapotranspiration estimation
•	Soil moisture sensors and weather stations for real-time, localized data collection
•	Variable rate application systems for precise irrigation delivery based on crop requirements
•	Yield mapping and analytics for assessing the impact of automated irrigation on crop productivity
•	Architectures and frameworks for integrating diverse data sources and technologies into a unified precision agriculture ecosystem
•	Edge computing and fog computing paradigms for real-time data processing and decision-making
•	Cloud-based platforms for data storage, analysis, and visualization
•	API-driven approaches for modular integration of third-party services and applications
•	Challenges and solutions for ensuring data quality, consistency, and security across integrated precision agriculture systems
•	Data cleaning, preprocessing, and harmonization techniques
•	Blockchain and distributed ledger technologies for secure, tamper-proof data sharing and traceability
•	Access control and authentication mechanisms for protecting sensitive data and resources
•	Future trends and research directions in the integration of automated irrigation with advanced precision agriculture technologies (e.g., AI-driven crop modeling, robotics, and autonomous vehicles)
6.4. Cybersecurity Considerations for Integrated Automated Irrigation Systems
•	Unique security risks and vulnerabilities associated with IoT-based automated irrigation systems
•	Potential for unauthorized access, data tampering, and system manipulation
•	Implications of security breaches for crop health, water resource management, and farm productivity
•	Best practices and strategies for securing automated irrigation systems
•	Secure device provisioning and authentication (e.g., hardware security modules, certificates)
•	Encryption and secure communication protocols (e.g., TLS, DTLS)
•	Firmware and software updates to address emerging security threats
•	Network segmentation and access control to limit the impact of breaches
•	Role of cybersecurity standards and frameworks in guiding the development and deployment of secure automated irrigation systems (e.g., NIST CSF, IEC 62443)
•	Importance of user awareness, training, and incident response planning in maintaining the security of integrated automated irrigation systems

7. MONITORING AND ENSURING SYSTEM RELIABILITY
7.1. Resilience and Fault Tolerance in Automated Irrigation Systems
•	Strategies for ensuring robustness and reliability in the face of failures, disruptions, or unexpected events
•	Redundancy: Implementing redundant components, such as duplicate sensors (e.g., soil moisture sensors, weather stations), controllers (e.g., PLCs, microcontrollers), and communication channels (e.g., cellular, satellite, LoRaWAN) to maintain system functionality during component failures
•	Failover mechanisms: Designing seamless failover mechanisms that automatically switch to backup components or systems in case of primary system failure, such as hot-standby controllers or multi-path communication protocols (e.g., mesh networks, software-defined networking)
•	Self-healing capabilities: Incorporating AI-driven self-healing mechanisms that can detect, diagnose, and recover from faults without human intervention, using techniques like reinforcement learning, Bayesian networks, or self-organizing maps
•	The role of distributed architectures and edge computing in enhancing system resilience
•	Decentralizing critical functions and data processing to minimize the impact of single points of failure, using fog computing or multi-agent systems
•	Leveraging edge computing to enable localized decision-making and control, reducing dependence on cloud connectivity and improving response times, using technologies like Raspberry Pi, NVIDIA Jetson, or Intel NUC
•	Anomaly detection and predictive maintenance using AI techniques
•	Employing unsupervised learning algorithms (e.g., autoencoders, clustering) to detect anomalies in sensor data, system performance, and water usage patterns
•	Developing predictive maintenance models using techniques like long short-term memory (LSTM) networks, convolutional neural networks (CNNs), or gradient boosting machines (GBMs) to anticipate and prevent potential system failures based on historical data and real-time monitoring
7.2. Advanced Monitoring Techniques for Automated Irrigation Systems
•	Remote monitoring using IoT-enabled sensors and computer vision
•	Deploying a heterogeneous network of IoT sensors to collect real-time data on soil moisture (e.g., capacitive, tensiometric), temperature (e.g., thermocouples, thermistors), humidity (e.g., capacitive, resistive), and plant health (e.g., sap flow, leaf wetness)
•	Integrating high-resolution cameras (e.g., multispectral, hyperspectral) and computer vision algorithms for visual monitoring of crop growth, disease detection (e.g., using deep learning-based object detection and segmentation), and irrigation system performance (e.g., leak detection, sprinkler uniformity)
•	Transmitting sensor and camera data to cloud-based platforms (e.g., AWS IoT, Google Cloud IoT, Microsoft Azure IoT) for remote access and analysis using protocols like MQTT, CoAP, or AMQP
•	Innovative approaches for real-time system health assessment
•	Developing novel algorithms and metrics for evaluating the health and performance of automated irrigation systems, such as entropy-based measures, network resilience indices, or multi-criteria decision analysis (MCDA) frameworks
•	Combining data from multiple sources (e.g., sensors, weather forecasts, satellite imagery) using data fusion techniques (e.g., Kalman filters, Dempster-Shafer theory) to create a comprehensive view of system health
•	Employing advanced data visualization techniques (e.g., interactive dashboards, augmented reality) to present system health information in an intuitive and actionable format
7.3. Closed-Loop Control and Feedback Mechanisms
•	Exploring the concept of closed-loop control in autonomous irrigation systems
•	Implementing feedback loops that continuously monitor system performance and adjust irrigation schedules based on real-time data, using control techniques like proportional-integral-derivative (PID), model predictive control (MPC), or fuzzy logic control (FLC)
•	Integrating machine learning algorithms (e.g., reinforcement learning, genetic algorithms) to optimize closed-loop control strategies over time, adapting to changing environmental conditions and crop requirements
•	Designing effective feedback mechanisms for user interaction and system optimization
•	Providing user-friendly interfaces (e.g., mobile apps, web dashboards) for farmers to input preferences, constraints, and expert knowledge into the automated irrigation system, using techniques like participatory design or user-centered design
•	Incorporating user feedback and domain expertise to refine irrigation strategies and improve system performance
8. CASE STUDIES AND REAL-WORLD IMPLEMENTATIONS OF FULLY AUTONOMOUS IRRIGATION SYSTEMS
8.1. Fully Autonomous Irrigation Systems in Diverse Agricultural Settings
•	Row Crops: maize, wheat, soybean with real-time soil moisture monitoring and weather-based irrigation scheduling for fully automated precision irrigation
•	Orchards: citrus, apple, almond with plant health monitoring and precision water application for fully autonomous orchard management
•	Greenhouses: tomato, lettuce, herbs with automated drip irrigation and climate control integration for fully automated greenhouse operations
•	Urban Farming: rooftop gardens, vertical farms with IoT-enabled hydroponic systems and remote management for fully autonomous urban crop production
8.2. Integration of Advanced System Components for End-to-End Automation
•	Wireless sensor networks: soil moisture probes, weather stations, plant health monitoring cameras with low-power, long-range communication for fully automated data acquisition
•	Secure data transmission: LoRaWAN, NB-IoT, 5G, satellite communication for reliable, real-time data transfer from field to cloud in fully autonomous irrigation systems
•	Intelligent data processing: edge computing for local data filtering, cloud platforms for scalable storage and analysis, machine learning algorithms for predictive insights in fully automated irrigation management
•	Autonomous decision-making: advanced irrigation scheduling algorithms, precise valve control, closed-loop feedback systems for optimal water management in fully autonomous irrigation systems
8.3. Quantitative Performance Evaluation of Fully Automated Irrigation Systems
•	Water use efficiency: percent reduction in water consumption compared to conventional methods, improved water productivity (yield per unit of water) achieved through fully autonomous irrigation
•	Crop yield and quality improvements: percent increase in yield, enhanced crop uniformity, improved nutritional content attributed to fully automated precision irrigation
•	Labor and energy savings: quantified reduction in labor hours for irrigation management, decreased energy consumption for pumping due to optimized scheduling in fully autonomous systems
•	Economic viability: detailed return on investment analysis, payback period calculations, comprehensive cost-benefit analysis for fully autonomous irrigation management systems
8.4. Lessons Learned and Challenges Encountered in Deploying Autonomous Irrigation Systems
•	Technical challenges and solutions: ensuring reliable data transmission in remote locations, addressing interoperability issues between diverse system components, optimizing power consumption for extended battery life, adapting algorithms to local soil and weather conditions in fully autonomous irrigation systems
•	Operational and logistical hurdles: streamlining installation and maintenance procedures, providing effective user training, seamlessly integrating with existing farm management practices and legacy systems for fully automated irrigation management
•	Regulatory and socio-economic considerations: navigating complex water use regulations, addressing data privacy and security concerns, ensuring equitable access and affordability for smallholder farmers adopting fully autonomous irrigation technologies
8.5. Best Practices and Recommendations for Successful Implementation
•	Designing scalable, modular, and adaptable autonomous irrigation systems to accommodate future growth and changing requirements for fully automated water management
•	Prioritizing user-centered design principles and actively engaging stakeholders throughout the development and deployment process of fully autonomous irrigation solutions
•	Adopting open standards and communication protocols to enable seamless integration of system components and interoperability with third-party platforms in fully automated irrigation setups
•	Implementing robust data validation, filtering, and quality control mechanisms to ensure data integrity and reliability for decision-making in fully autonomous irrigation systems
•	Establishing clear data governance policies and security frameworks to protect sensitive information and maintain user trust in fully automated irrigation management
•	Developing intuitive user interfaces and decision support tools to facilitate easy adoption and effective use of fully autonomous irrigation systems
•	Collaborating with local extension services, agribusinesses, and technology providers for knowledge transfer, technical support, and continuous improvement of fully automated irrigation solutions
8.6. Synthesis of Case Studies and Implications for Autonomous Irrigation Adoption
•	Cross-case analysis of key performance indicators and critical success factors for fully autonomous irrigation scheduling systems in various contexts
•	Identification of common themes, challenges, and innovative solutions across diverse implementations of end-to-end fully automated irrigation management
•	Assessment of the potential for replicability and scaling of successful fully autonomous irrigation projects in different regions and farming systems
•	Implications for future research priorities, technology development roadmaps, and policy interventions to support widespread adoption of fully autonomous irrigation technologies

CONCLUSION/FUTURE DIRECTIONS AND UNANSWERED QUESTIONS
•	Summarize the key insights gained from the question-driven review, emphasizing how each section contributes to the overarching goal of achieving real-time, end-to-end automation in irrigation management
•	Based on the questions addressed, propose new research directions and unanswered questions
•	Identify key research gaps and propose concrete research questions and hypotheses for advancing the field of real-time, automated irrigation management
•	Highlight the need for collaborative research efforts across disciplines, such as computer science, agricultural engineering, and environmental science, to address the complex challenges of automated irrigation systems
•	Emphasize the need for further innovation and exploration in real-time, automated irrigation systems




</previous_sections>

</documents>
<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper. 

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: stated in: <subsection_title>
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>

<subsection_point_Point 2>
Point: Redundancy: Implementing redundant components, such as duplicate sensors (e.g., soil moisture sensors, weather stations), controllers (e.g., PLCs, microcontrollers), and communication channels (e.g., cellular, satellite, LoRaWAN) to maintain system functionality during component failures

Papers to support point:

Paper 1:
- APA Citation: Emami, S., & Dehghanisanij, H. (2024). Fault Tree Analysis of Trade-Offs between Environmental Flows and Agricultural Water Productivity in the Lake Urmia Sub-Basin Using Agent-Based Modeling.  _Water_ 16(6), 844. https://doi.org/10.3390/w16060844
  Main Objective: To evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems.
  Study Location: Unspecified
  Data Sources: Unspecified
  Technologies Used: Internet of Things (IoT), Machine Learning (ML)
  Key Findings: Integration of IoT and ML technologies has enhanced automated irrigation management systems, providing real-time field data for effective decision-making.
  Extract 1: The need for automated systems has driven research and development efforts towards the utilization of the Internet of Things (IoT) and machine learning (ML) within the field of irrigation.
  Extract 2: IoT-enabled wireless sensor networks have been utilized to gather real-time field data, which is used to train ML algorithms for effective decision making.
  Limitations: The paper does not provide specific examples or case studies of automated irrigation systems that address redundancy in system components.
  Relevance Evaluation: The paper is relevant to the specific point in my literature review because it provides a comprehensive analysis of the current state and future potential of real-time, end-to-end automated irrigation management systems. The paper's focus on integration, interoperability, and standardization aligns well with the section and subsection titles in my review.
  Relevance Score: 1.0
  Inline Citation: (Emami and Dehghanisanij, 2024)
  Explanation: The proposed study employs a systematic review methodology to critically evaluate the current state and future prospects of end-to-end automated irrigation management systems by integrating Internet of Things (IoT) and machine learning (ML) technologies. The review aims to identify gaps and propose solutions for seamless integration across the automated irrigation management system to achieve fully autonomous, scalable irrigation management.

 Full Text: >
"This website uses cookies We use cookies to personalise content and ads, to provide social media features and to analyse our traffic. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you’ve provided to them or that they’ve collected from your use of their services. Consent Selection Necessary Preferences Statistics Marketing Show details                 Deny Allow selection Allow all    Journals Topics Information Author Services Initiatives About Sign In / Sign Up Submit   Search for Articles: Water All Article Types Advanced   Journals Water Volume 16 Issue 6 10.3390/w16060844 Submit to this Journal Review for this Journal Propose a Special Issue Article Menu Academic Editor Maria Mimikou Subscribe SciFeed Recommended Articles Related Info Link More by Authors Links Article Views 556 Table of Contents Abstract Introduction Materials and Methods Methodology Results and Discussion Conclusions Author Contributions Funding Data Availability Statement Conflicts of Interest References Altmetric share Share announcement Help format_quote Cite question_answer Discuss in SciProfiles thumb_up Endorse textsms Comment first_page settings Order Article Reprints Open AccessArticle Fault Tree Analysis of Trade-Offs between Environmental Flows and Agricultural Water Productivity in the Lake Urmia Sub-Basin Using Agent-Based Modeling by Somayeh Emami * and Hossein Dehghanisanij Agricultural Research, Education and Extension Organization, Agricultural Engineering Research Institute, Karaj P.O. Box 31585-845, Alborz, Iran * Author to whom correspondence should be addressed. Water 2024, 16(6), 844; https://doi.org/10.3390/w16060844 Submission received: 2 February 2024 / Revised: 10 March 2024 / Accepted: 12 March 2024 / Published: 15 March 2024 (This article belongs to the Special Issue Adaptive Water Resources Management in an Era of Changing Climatic, Environmental and Social Conditions) Download keyboard_arrow_down     Browse Figures Versions Notes Abstract The recent problems of Lake Urmia (LU) are caused by extensive and complex socio-ecological factors that require a comprehensive approach to consider the relationships between users and identify failure factors at the basin level. For this purpose, an agent-based simulation model of farmers’ social interactions and economic interests (ABM) with various support scenarios and random supervision and training by the government agent is developed to evaluate its impact on independent farmers’ decision-making in the form of a complex adaptive system. Finally, a fault tree analysis (FTA) is created in the Cara-FaultTree 4.1. software to identify scenarios that lead to the non-development technology in irrigation management (non-DTIM) in the LU sub-basin. The assessment of the impact of government supervision and training revealed that the main causes of non-DTIM in the LU basin are a lack of demands from farmers and low awareness among residents of the basin, with failure probabilities of 0.90 and 0.86, respectively. Ultimately, the failure probability of the main event (non-DTIM) was 0.50. The paths of proper training and farmers’ requirements for sustainable agricultural water supply should become more stringent. The results confirm that appropriate measures to strengthen government supervision and training, as well as raise farmers’ awareness of the importance of long-term sustainability of water resources, can lead to greater resilience in the DTIM. Keywords: water resources; demand; risk; resilience; LU 1. Introduction The water crisis poses a serious threat to human life. The short-term perspective in managing risks, as well as the lack of transparency and unscientific planning, raise the possibility that the crisis will worsen and expand once it occurs [1,2]. It is, therefore, necessary to assess the catchment areas with a tool so that the right quality of required water can be provided. If financial resources are not made available within the schedule, there will be delays in the implementation of projects in the individual basin areas. The lack of community perspective in regional planning and the lack of codified laws in the watershed as well as the absence of a land-use plan are among the main reasons for the emergence of a critical situation in the basin [3]. With population increase, climate variability, and its numerous problems, watersheds have become less important and are facing various threats. Therefore, the possibility of the occurrence of an undesirable phenomenon (risk) and systematic efforts to determine and manage the threats and hazards through risk identification and analysis are proposed [4]. This objective requires accurate identification of catchment problems and risks. A comprehensive and accurate identification of risks and the determination of the effectiveness of system failure concerning each of these risks may require the provision of accurate and effective solutions to improve the status of the water resources of the basins [5]. In recent years, the LU basin has faced many problems in terms of a lack of water resources and economic and social damage. A comprehensive approach to assessing the performance of catchments can reduce their vulnerability in critical situations and focus on the most vulnerable points [6,7,8]. The purpose of the risk analysis of the total failure of a watershed is to assess and identify all threat factors regarding the amount of available water; the environmental, economic, and social water quality of the basin; and the impossibility of its provision [9]. On the other hand, the cross-sectional approach to dealing with risks and the lack of transparency in planning increases the risks caused by risks and harbors the possibility of aggravation and expansion of the crisis after it occurs [10]. Accurate knowledge of the basin, the elimination of human and natural destructive factors, and the need to apply novel approaches to risk analysis are the keys to success in improving and preventing possible risks in basins. Compared to water resource use studies with high costs and difficulties, simulation-based modeling offers an alternative method [11]. Many water resource models were proposed to describe population dynamics, which are mainly divided into two types, namely, microscopic and macroscopic models [12]. Microscopic models, including the social force model (SF model) [13], the cellular automata model (CA model) [14,15], and the agent-based model (ABM) [16], can describe individual behavior more accurately and come closer to reality. Among these models, agent-based models have made significant progress in recent years. ABMs have improved the processing speed of computers. ABM can simulate a variety of “agents” that may have rudimentary artificial intelligence to make decisions. Each agent can have a unique set of behavioral rules that allow modeling heterogeneity in the population [17,18]. In recent years, ABM models have been developed for water resources management [19,20]. ABMs have the potential to significantly improve the design of stringent regulations and incentives for water resources management [21]. Nhim et al. [22] concluded that ABM models are a powerful tool for studying how socioeconomic and environmental changes affect the human use of water resources. Pouladi et al. [23] reported that farmers’ performance and willingness to engage in LU restoration could be simulated by integrating ABM into the socio-hydrological framework. Ohab-Yazdi and Ahmadi [24] showed that the regional water organization’s relevant interactions with other stakeholders led to the control of illegal water extraction and the rise of water levels in aquifers. Anbari et al. [25] concluded that through government-sponsored programs it is possible to offset about 23% of the negative balance of the aquifer within 13 years. Lang and Ertsen [26] investigated the interaction between human and non-human agents in an irrigation system. The results showed that the Irrigation-Related Agent-Based Model (IRABM) offers a new perspective in modeling the human–water system. Okura et al. [27] studied irrigation management using the ABM model and game theory. The results showed that social changes can accelerate farmers’ non-cooperative behavior. Shoushtarian et al. [28] developed an ABM model to simulate agricultural water use and socio-hydrological dynamics of California. The results showed that ABM helps to evaluate current water reuse management practices in terms of sustainability of water resources. Streefkerk et al. [29] presented a dynamic adaptive drought modeling model in Kenya that combines socio-hydrological modeling and ABM approaches. The results showed that the absorption of drought adaptation affects soil moisture, groundwater, and drought propagation. Mirzaei et al. [30] concluded that for the implementation of the water–energy–food nexus model in the water-stressed region, the policy of using advanced irrigation technologies under the government’s support scenarios is necessary. Previous studies on water resource utilization mainly focused on farmer behavior and water resource modeling and optimization. There is a knowledge gap regarding the use of information from ABM modeling in decision-making that improves safety. To fill this gap, this study aims to adopt ABM modeling and further develop a fault tree analysis (FTA) method to identify scenarios that lead to non-DTIM in the LU sub-basin. FTA is a decision tree structure based on a graphical method to represent the logical cause of failure [31]. The purpose of the FTA is generally to control risk, the worst-case event is considered the top event, and then the various failures that can lead to the top event are determined through top-down layer-wise logical analysis. These disturbance events are distributed layer by layer in the form of a tree structure. To this end, a case study in the LU sub-basin in the Miandoab Plain was used as an example to demonstrate the methodology. The increase in the area under water cultivation, the decrease in rainfall, the low efficiency of agricultural irrigation, and the lack of an allocation of sufficient water to meet the biological needs of the leading rivers are considered to be the most important factors aggravating the crisis and dryness of LU. In addition, traditional agriculture is one of the reasons for the drying up of LU after the decrease in rainfall. The change from traditional to advanced agriculture is of particular importance due to the drying up of LU. Therefore, risk indicators need to be provided for risk management and improvement of this catchment area. This paradigm can be used for any watershed to identify critical paths and prevent the inappropriate use of water resources. The developed free trade agreement provides water resource managers with a basis for formulating water resource use plans to avoid the catastrophic consequences of water scarcity in catchment areas. According to the mentioned main goals, in the present study, an ABM simulation model of social interactions and economic interests of farmer agents, along with different scenarios of support policies as well as random supervision and training by the government agent to evaluate its impact on the decision-making of independent farmers in the form of a complex adaptive system, is presented. Next, by using FTA, the scenarios that led to the non-development technology in irrigation management (non-DTIM) in the Lake Urmia basin were identified. In this regard, there are fundamental questions and hypotheses, such as what are the main reasons and factors for solving the non-DTIM in the Lake Urmia basin? The use of ABM and FTA models based on the identification of various factors and their interactions is effective in identifying the reasons for the non-DTIM. The answers to the questions mentioned as the main goals are necessary for the purposeful design of the road map for the DTIM in the LU sub-basin and the achievement of its goals. Regardless of the mentioned cases, the implementation of water consumption management programs is not only accompanied by many uncertainties from the point of view of their effectiveness but will also entail huge costs. 2. Materials and Methods 2.1. LU The LU basin in northwestern Iran is one of the main basins of Iran, with an area of 51,876 km2. LU is the largest inland lake in Iran and one of the most valuable aquatic ecosystems in Iran and the world [32]. The downward trend of the water level of LU began in 1995, and in 20 years, the lake level has dropped by more than 8 m. As a result, the remainder of more than 30 billion cubic meters of LU’s water volume has been lost due to evaporation and lack of annual rainfall. Due to LU’s location in a closed basin, precipitation and runoff are considered sources of water input into the lake, and evaporation is considered water discharge [32]. The two main causes of LU drying are (1) excessive extraction of renewable water resources and unbalanced development in the LU basin (human factors, 69%) and (2) climate change (18%) and persistent drought (natural factors) [33]. Improved living conditions and higher incomes of farmers were the main reasons for the expansion of cultivated area and increase in water consumption in the LU basin due to human factors. The expansion of the cultivated area and increased water consumption created a crisis in LU that is making life more and more difficult for the population living there [33]. 2.2. Miandoab Plain The Miandoab Plain lies in the southern part of LU (Figure 1). The geographical coordinates of Miandoab are 45°43′ N, 36°46′ E, and its altitude is 1292 m above sea level [34]. The average annual rainfall is 296 mm, and the average humidity is 53%. The average annual and minimum temperatures are 11.8 °C and −3 °C, respectively [34]. In the Miandoab Plain, half of the surface flows flow into LU and 20% of the total groundwater. Zarineh Roud and Simineh Roud are the main sources of Miandoab Plain surface water discharged into LU [35]. The Zarineh Roud and Simineh Roud basins comprise the largest sub-basin of the LU basin (34% of the total LU basin area). In recent years, the function of securing the rights of LU has been lost due to the development of exploitation of surface water resources of these rivers. Figure 1. Geographical location of Miandoab Plain (https://www.esri.com/en-us/arcgis/about-arcgis/overview, 8 March 2022). 2.3. Agent-Based Modeling (ABM) Agent-based models (ABMs) are a popular tool in today’s computing environment for simulating the collective outcomes of individual behavior in complex systems. These models are based on the idea that interactions between autonomous and independent agents shape the behavior of a system rather than just focusing on the system’s internal variables [36]. ABMs allow for variation and interactions between individual factors to be taken into account by returning the focus to the agents themselves, resulting in a more accurate and realistic representation of the system’s behavior. ABMs are particularly useful in modeling complex systems whose behavior is difficult to predict due to the relationships, competition, and interdependencies between their components or between the system and its environment. Using these models, researchers can capture the patterns and structures that emerge from, rather than those that are dictated by, the interactions of individual actors or the emergent properties of the system (Figure 2). Additionally, ABMs enable agents to make decisions by considering the concepts of adaptive learning and intelligence [37]. Figure 2. Design of the ABM model. 2.4. Fault Tree Analysis (FTA) The FTA includes building a fault tree, entering the fault probabilities of the base events, distributing the fault probabilities to determine the probability of the main event, and determining the intersections [38]. When a shear set occurs simultaneously as a group of initiators, the main event occurs. The first step in FTA analysis is to gain a complete and accurate understanding of the system. Accurate and detailed information, including system components, physical and functional interactions between components, and normal and abnormal conditions, can be obtained from various sources, such as reviewing maps, diagrams, instruction manuals, maintenance methods, and interviews with experts. Gates defines the logic in the fault tree and links base events to intermediate and main events (Figure 3). If the main event results from the simultaneous failure of two events or at least one of the events results in the failure of a higher event, AND or OR gates are used [39]. Figure 3. Schematic of FTA. 3. Methodology 3.1. Designed ABM Model The ABM model aims to replicate farmers’ ability to adapt to new DTIM (development technologies in irrigation management). In this model, there are two groups of farmers and government officials. Farmers with low DTIM-WP, regardless of their experience, seek financial benefits and cheaper production and irrigation costs. Looking for long-term strategic goals to maintain the sustainability of water resources on behalf of the government. To encourage farmers to use DTIM, the government offers incentives, in this case, subsidies. It also serves as a tool for tracking farmer productivity and training. Currently, water resources are used by farmers to achieve short-term benefits through irrigation systems and different levels of technology. Farmers adjust the current plan based on a cost–benefit analysis, their desire to increase WP, and their understanding of the importance of DTIM. DTIM charges costs for the initial setup. Government subsidies can be used by any farmer to increase WP. If no farmer makes optimal use of available water resources, long-term access to these resources is at risk. If this is the case, farmers consider this an ad hoc expense. By increasing the allocation of government subsidies, it is possible to motivate farmers to increase their profits. To achieve this, the government can rely on assessment teams equipped with DTIM training to offer help and support to farmers. As part of the government’s assessment process, monitoring farmers’ behavior is crucial. However, it is important to note that farmers who benefit from the sale of an improved irrigation system may no longer be eligible for certain government programs and future subsidies. The government has the power to strengthen the integrity of farmers through these assessments. Furthermore, to create an effective framework for DTIM in the Moandoab region, government policies are evaluated using the ABM model. For this purpose, NetLogo 6.2.2. is used, a software that simulates various phenomena and has a user-friendly interface. The use of NetLogo 6.2.2., programmed in Java, offers further advantages to the decision model used in this study [40,41]. 3.2. Model Description 3.2.1. Farmer Agent The decision-making power of the government and the changing characteristics and behaviors of a group of farmers are presented in the ABM model as the two most important and powerful players in the use of technology to maximize irrigation management in the LU Basin. ABM helps clarify the complex adaptive system of individual farmers’ decisions in response to government policies as well as interactions with other farmers and the environment. The farmer agent receives subsidies from the government (acting as an agent of the Ministry of Water and Agriculture) to increase WP through DTIM. The agent-based adaptability model of farmers in DTIM is schematically shown in Figure 4. Figure 4. Agents’ interactions with the environment and one another at different levels. The inputs that the proposed framework gathers include job preference, academic education level, age, size of agricultural farm, coordinates, and distances. These data are used to calculate the entrepreneurship index (entrepre), which indicates each farmer’s potential for developing an irrigation system. The various degrees of the efficacy of the aforementioned elements in determining the entrepre index are displayed in Table 1. As model inputs, the amount of farmers’ expenses and profits, as well as DTIM costs, have been estimated. Farmers are dispersed throughout the modeling industry. Every farmer has social ties to neighbors with whom they can exchange experiences. They are impacted by government policies in the model environment, which includes education and monitoring programs, government subsidies for irrigation system improvements, and weather- or decision-making-related uncertainties. Table 1. The effectiveness of the components in calculating the entrepre index. It is assumed that farmers who do not have the proper level of WP can make decisions for DTIM. One of the considered triggers is the propensity of farmers to DTIM (prop). The minimum value of the prop trigger (prop.min) is defined as follows: 𝑝𝑟𝑜𝑝.min= (𝛼 𝑠𝑐𝑎𝑙𝑒)+(𝛽 𝑒𝑛𝑡𝑟𝑒𝑝𝑟𝑒) (𝛼+𝛽) (1) where α and β express the effect of farm scale and the farmer’s entrepreneurship on the initial propensity to DTIM, respectively. To make decisions, farmers can weigh the costs and benefits of their options, consider past performance, and consider the costs of sustainable water supply (SWS). In this study, it is assumed that the challenge of SWS in the long term is such that if farmers do not take action to correct the existing process of using water resources, this possibility is seriously threatened. Considering this issue, the non-participation of farmers in upgrading the irrigation system is regarded as a cost. This cost will decrease with the participation of more farmers in improving irrigation productivity (SWR). SWR is calculated as follows: 𝑆𝑊𝑅= 6×𝑐𝑜𝑢𝑛𝑡 𝑓𝑎𝑟𝑚𝑒𝑟 𝑠 6 ∑ 𝑖=1 6 𝑖𝑟 𝑟 𝑠𝑡𝑎𝑡𝑢𝑠 ×𝑐𝑜𝑢𝑛𝑡 𝑓𝑎𝑟𝑚𝑒 𝑟 𝑖𝑟 𝑟 𝑠𝑡𝑎𝑡𝑢𝑠 (2) Farmers typically leverage their desire for DTIM and honesty when using government subsidies as a trigger for decision-making. Farmers’ decisions are influenced by the amount of these stimuli and vice versa. The ABM model then undergoes a sufficient number of iterations in different scenarios and the resulting results of the model are then statistically analyzed. The mean ratio of DTIM, the mean speed of DTIM, the field application efficiency (FAE), and government expenditure (which are taken into account in the number of cases of granting subsidies) are among the results that are considered consistent with the main objectives of the study. 3.2.2. Government Agent The main goal of the government agent is to improve WP. Assuming that crop yields rise or stay at the same level, the government agent is attempting to persuade the farmer agent to DTIM. The main defenders of the WP in the agriculture sector, incentive policies, have been taken into consideration by the government. One of the policies taken into consideration in this area is providing DTIM with subsidies. Through subsidies, the government hopes to persuade farmers to raise WP. Additionally, the government can lessen DTIM issues and contribute to an increase in WP and crop yield by considering monitoring and training teams. Farmers become more honest and there is less misuse of the facilities provided by the government when it is monitored. Increasing WP in the study area is one of the government’s top priorities in this investigation. Consequently, irrigation efficiency is assessed using the FAE index in the manner described as follows: 𝐹𝐴𝐸= ∑ 𝑖=1 6 𝑖𝑟 𝑟 𝑠𝑡𝑎𝑡𝑢𝑠=1  𝑐𝑜𝑢𝑛𝑡 𝑓𝑎𝑟𝑚𝑒 𝑟 𝑖𝑟 𝑟 𝑠𝑡𝑎𝑡𝑢𝑠 (𝑟×𝑒𝑓 𝑓 𝑖𝑟 𝑟 𝑠𝑡𝑎𝑡𝑢𝑠 ×(1−𝑟) 𝜌) ∑ 𝑖=1 6 𝑖𝑟 𝑟 𝑠𝑡𝑎𝑡𝑢𝑠=1  𝑐𝑜𝑢𝑛𝑡 𝑓𝑎𝑟𝑚𝑒 𝑟 𝑖𝑟 𝑟 𝑠𝑡𝑎𝑡𝑢𝑠 (3) where 𝑒𝑓 𝑓 𝑖𝑟 𝑟 𝑠𝑡𝑎𝑡𝑢𝑠 is the amount of expected WP in different irrigation systems, which is estimated as follows (Table 2) [42]. Table 2. Expected WP in different irrigation systems. The government’s achievement in raising the FAE index’s value can be attributed to one of the most important factors. Thus, in the complex socio-environmental system under study, the government’s best policies have the potential to either improve this index or accelerate its advancement. The effects of these incentive policies are assessed in the ABM model using various scenarios. To this end, the influence of governmental policies on the outcomes is assessed. Farmers may be encouraged to make money if government subsidies are increased in proportion. Thus, by taking the assessment teams at various levels with DTIM education into consideration, the government can aid in raising farmers’ profits. One aspect of government assessments is keeping an eye on farmers’ conduct. Farmers risk losing access to certain government services and the chance to reapply for subsidies if they profit from the sale of their upgraded irrigation system. Evaluations: The government can make farmers more truthful. The government policies are then assessed using the ABM model to provide a framework that works for the management of water resources in the Miandoab region. The parameters of the ABM model are calibrated using the investigated data and field studies and are presented in Table 3. Table 3. Range of ABM model parameters. 3.2.3. Questionnaire Investigation To define scenarios and identify stakeholders, questionnaires and specialized interviews were employed. The sample size of the interview was 72. Interviews with a range of relevant parties were undertaken in the Miandoab Plain, including farmers, the Ministry of Agriculture (15 agents), managers and specialists of local water organizations (15 agents). The validity of the interview findings was confirmed when the researcher’s self-review method and member control were applied to the gathered interviews. ABMs have apparent validity if an expert (group of experts) related to the subject confirms the quality of the simulation results by real-world phenomena. This is performed by taking into account outputs such as the trend of area change under different irrigation methods and the trend of economic profit at micro and macro levels, and it is compared with the actual situation of the studied area according to the opinions of experienced experts. To guarantee the reliability of the interviews, convergent interviews were employed. To achieve this, model attributes and input factors—a variety of social and environmental factors—that influence farmers’ adjustment to DTIM were first arranged. Next, every environmental and social component is understood to form the ABM model. Finally, a statistical analysis is used to assess the components and policies that have an impact on the outcomes. The developed ABM model is applied for 100 years at the time step of a half-crop season. The model considers 42 farmer agents. Drip and sprinkler irrigation are two common examples of both traditional and advanced irrigation techniques that are taken into consideration. The sub-model for figuring out the farmers’ economic spending was taken into consideration because of how crucial the economic factor is to the farmer’s agent decision-making. The price of planting and harvesting crops, the cost of installing irrigation systems, and the cost of fertilizers and seeds, labor costs for manual labor, water pumps, etc., were computed. 3.3. Compilation of the FTA of LU Sub-Basin The FTA model was created to quantify and evaluate different scenarios of non-DTIM of LU sub-basin. The probability of failure of basic events is estimated quantitatively and qualitatively based on recorded records. After estimating the failure probability of basic events, AND and OR gates are calculated as follows: 𝑃= ∏ 𝑖=1 𝑛 𝑃 𝑖 (4) 𝑃=1− ∏ 𝑖=1 𝑛 (1− 𝑃 𝑖 ) (5) where P is the probability of each basic event, Pi is the value of the failure probability of the ith basic event, i is the counter, and n is the number of input events connected to the gate. The impact (contribution) of basic events on the main event is calculated as follows: 𝐼 𝑥 = ∑ 𝑈 𝑥 𝑈 𝑠 (6) where Ix is the importance of the basic event x in creating the main event, ∑ 𝑈 𝑥 is the sum of the error percentages of the cuts in which the event x is present, and 𝑈 𝑠 shows the probability of the main event. If the failure probability of the main event is satisfactory, the FTA analysis ends. If the FTA analysis is not satisfactory, it is necessary to reduce the failure probability of the main event and take corrective actions. A total of 18 parameters were identified as the basic event for non-DTIM risk assessment in the LU sub-basin. Table 4 shows the basic events according to their performance type. Table 4. Basic events of the FTA of LU basin. The flowchart of the study process is presented in Figure 5. Figure 5. Flowchart of the study process. 4. Results and Discussion The suggested scenarios, which include 64,800 states, have been combined and run 100 times apiece in the model with 100 time periods to implement the suggested model. By using balanced variance analysis, each of these scenarios was examined. The factors influencing farmers’ adaptation to DTIM were examined using balanced variance analysis and Minitab 16.2 software. Table 5, Table 6, Table 7 and Table 8 and Figure 6, Figure 7, Figure 8 and Figure 9 show average WP indicators (SWR, FAE), average propensity threshold (mean.prop), and honesty threshold (mean.honesty). Figure 6. The effect of input indicators on the mean.prop. Figure 7. The effect of input indicators on the amount of mean.honesty. Figure 8. The effect of input parameters on SWR. Figure 9. The effect of input indicators on the amount of FAE. Table 5. Balanced variance analysis for mean.prop. Table 6. Balanced variance analysis for mean.honesty. Table 7. Balanced variance analysis for SWR. Table 8. Balanced variance analysis for FAE. Thus, uncertainty (random change of the system due to climate and agent behavior patterns), SWS, subsidy policy, government supervision, and training are the most effective indicators of the farmer agent’s propensity to DTIM (p-value = 0.0 at the confidence level of 95%). The most significant predictors of the farmer agent’s inclination to DTIM are SWS, government supervision, and training, with F-values of 4375.59 and 1055.10, respectively. The farmer agent’s propensity to DTIM is least affected by the seed-owner and seed-ratio indices. The mean.prop index barely changes as a result of the initial population. As a result, different inputs influence the agents’ subjective propensity in the DTIM. The appointment, potential for ideal local management, and involvement of the farmer agent are all facilitated by their involvement in the management of water resources [43,44,45,46]. Participation and awareness foster the desire for DTIM. Government subsidies and cost reductions have a significant impact on farmers’ adoption of DTIM [47,48]. The most significant parameters on the SWR index are random change (r), SWS, government supervision, and training, with p-value = 0.0 at a 95% confidence level. The SWR index is independent of the initial population’s seed-ratio, seed-owner, and network-density. The crop yield and WP are greatly influenced by the indicators of SWS, government supervision, and training. The F-values for SWS and government supervision are 1729.93 and 1441.14, respectively. The presence of government supervision and training is crucial for improving WP and taking advantage of government subsidies. This also affects the integrity threshold and the propensity of farmer agents. The effective supervision and management of irrigation systems play a significant role in increasing both the physical and economic WP as well as crop yield, which aligns with the findings of previous studies [49]. Uncertainty, SWS, government supervision, and training are the most effective indicators at the 95% confidence level on FAE (p-value = 0.0). Consistent with the findings of the present study, optimal irrigation systems coupled with sufficient government supervision and training will raise FAE and crop yield [50]. The water resource conditions in the LU basin state that the WP can be improved through training and monitoring of the irrigation system [34,51,52]. All inputs and production must be provided continuously, and farmers’ representatives must be continuously supersized and trained by the government in the management, maintenance, and operation of field irrigation systems [53]. 4.1. Risk of Failure of LU Sub-Basin In Table 9, the failure probability of the basic events was calculated based on the specific statistics of the LU sub-basin and entered as input into the Cara-FaultTree 4.1. software. In this study, Cara-FaultTree software was used for the complete graphical representation of the overall risk of the basin due to the unique features and simplicity of the environment. Table 9. Ranking of basic events effective in non-DTIM in LU sub-basin. 4.2. Measure the Importance of Basic Events 4.2.1. Lack of Accurate Planning in Water Supply and Demand The average amount of water consumed in the short-term period of the LU basin, in excess of the virtual upper limit of surface water in the agricultural sector, and the amount of surface water consumed in the long-term normal in the agricultural sector are 3600 MCM and 2370 MCM, respectively. The average amount of water consumed in agriculture in the short-term period of the LU basin in excess of the virtual limit of groundwater and the amount of groundwater consumed in agriculture in the long-term in the normal state is 1756 MCM and 1580 MCM, respectively. The event failure probability value is calculated as follows: P (A24) = 0.51 Surface water (7) P (A24) = 0.11 Ground water (8) 4.2.2. Unreasonable Economic Value of Water The low economic value of water in the LU basin is caused by the low price of water. The low price of water causes an excessive increase in water in the agricultural sector and leads to economic failure. The probability of an inappropriate water price failure is calculated as follows: 4.2.3. Destructive Water Transfer Systems Protecting and conserving water in irrigation and drainage networks should be considered one of the cost-effective solutions in water projects. Therefore, the destructive water transfer system may lead to economic failure in the LU basin. The failure caused by this event is similar to the water loss event along the transmission path and is calculated as follows: P (A11) = 0.30 (9) In Figure 10a,b and Figure 11a–d, the probability of the main event is determined based on the probability assigned to the basic events. Indiscriminate water abstraction, dam construction, land-use changes, non-compliance with environmental rights for water, increased CO2 emissions, low WP, and social and economic conditions are among the important intermediate factors for the failure of the Urmia Lake basin due to human factors. Climate changes (floods, droughts) are important natural factors for reducing water resources in the LU sub-basin. Figure 10. (a,b) FTA under LU basin failure—caused by natural factors. Figure 11. (a–e) FTA under LU basin—failure caused by human factors. In Table 9, the ranking of basic events effective in the non-DTIM of LU sub-basin was calculated. According to Table 9, the basic events are sorted in descending order by the greatest impact on the vertex event. The higher the value of the Ix index, the more important the basic event is in the vertex event. The results show that the low awareness of the basin residents and the lack of demands of farmers are the most important failure factors in the LU basin, with a failure probability of 0.86 and 0.90, respectively. Finally, the probability of failure of the main event (non-DTIM in the LU sub-basin) was 0.50. The quantity and quality of water resources in the LU can be considered the most important factors affecting the sustainability of its ecological function. However, both factors are influenced by human activities, particularly the increase in cultivated area and the development of irrigation in the upstream sections of this basin. Increasing water use along with the implementation of agricultural development plans will reduce the quantity and quality of water entering the LU basin. In recent years, the lack of environmental protection measures in the LU basin has led to the disappearance of rare species. In addition, the events of a lack of sufficient training, insufficient knowledge, and management of irrigation systems have a significant impact on the lack of non-DTIM in the LU sub-basin. The participation of users in decision-making and the development of coordination between different organizations in water resources management are the most important parameters in the sustainable management of agricultural water resources. Participatory and centralization events were identified as key components in water resources management, which is consistent with the results of the present study [54,55,56,57], Farmers’ communities are the first trustees of water resources in the LU sub-basin, which is highly dependent on water resources. The lack of water resources in the LU sub-basin causes the loss of economic activities and disrupts the biological balance. These results are consistent with the studies of [23,58]. These studies also emphasize the participation and role of farmers in the management and exploitation of water resources. Governance and its effectiveness, which correspond to the development and management of surface and underground water resources, were introduced as intermediate events dependent on other events. The results of this study are consistent with the findings of [59,60]. The farming community is the primary manager of water resources in the LU sub-basin, which is highly dependent on water resources. The lack of water resources in the LU sub-basin leads to the loss of economic activities and disrupts the biological balance. These results are consistent with the studies by [58] that emphasize the participation and role of farmers in the management and use of water resources. Governance and its effectiveness corresponding to the development and management of surface and groundwater resources were introduced as intermediate events dependent on other events. The results of this study are consistent with the findings of [59,60]. The government is an influential player in decision-making on LU restoration programs. In addition to government supervision and training, stakeholders must be empowered to implement the prescribed programs (e.g., reducing water consumption) and revitalize LU. However, this local-level approach has not yielded success in structuring the requirements for the implementation of LU restoration programs. In other words, restoring LU is not the concern of stakeholders, and the government is failing to build consensus, achieve user satisfaction and participation, create alternative value for water, and awareness and knowledge of upgrading society and getting to know the real problems and creating solutions for the restoration of LU. Furthermore, farmers, as key beneficiaries, view the restoration of LU as a form of governance and show a desire to achieve this goal. The government’s performance in sensitizing the farming community has been weak, and the politically motivated messages tended to play a destructive role. A key factor in the failure was the avoidance of government and stakeholder involvement, as well as inadequate internal and cross-border management in the LU basin caused by centralized legislation, multiple decision-making centers, and inaccurate planning of water supply and demand. The creation of integrated management based on a comprehensive law and plan is the most effective strategy in this area to achieve the sustainable development of the LU basin. Managing the LU basin in an integrated manner that balances regional function and farmers’ empowerment can achieve the government’s policy objectives. Due to the lack of “implementation-feedback-learning” mechanisms, the government has not taken advantage of the impending obstacles to learn from and achieve success. In this way, when faced with many problems, instead of finding solutions, it erased them instead of solving them. For example, the strategy to reduce water consumption from dams for use in this sector by 40% was gradually replaced by a 40% reduction in water consumption in the agricultural sector, which has a significantly smaller impact on water supplies than initially expected. Therefore, it is necessary to strengthen and develop educational and promotional activities in the Urmia Lake basin to improve farmers’ attitudes and self-efficacy and expand their knowledge and skills in using irrigation systems. Studies show that there is a positive relationship between extension calls, use of communication channels, social participation, and technical knowledge of farmers and their attitude towards the use of irrigation systems [61,62]. Studies show that there are problems in the LU basin, such as that the government is at the center of the problem, has a technical view, and is satisfied with the cross-sectional results, and that there is no real goal that can be achieved with the government’s results consistent with the present study [58,59]. Training farmers in the LU basin about the consequences of lake drying and involving local communities in the restoration process can be successful. To achieve the goals and implement the plans to restore LU, farmers’ trust in the government is crucial. Traditional agriculture in the LU basin is not profitable despite the region’s high water consumption. Plans to restore LU demonstrate the importance of farmers in the restoration and provide an opportunity for development and sustainable agriculture in the LU basin. By using training tools to improve LU’s water resources and revitalize the lake, farmers can contribute to the engagement of surrounding communities. By allocating funds and implementing construction projects and policies, the government has taken measures to revitalize LU. However, to reduce water consumption in LU, experts and advocates must work together to promote local culture, awareness, and engagement. The management and control of the LU basin depend heavily on the residents’ awareness of the values of the basin and the threats to its further development [7,59,62]. To prevent the collapse of the LU basin, one of the main objectives is to raise awareness among farmers. To achieve this, the government needs to strengthen its capacity [63]. A similar study concluded that the lack of community perspective in regional planning, the development and lack of codified laws in the basins, the absence of land-use plans, and the lack of sufficient information for the residents of the basin are the most important reasons for social failure. This is consistent with the results of the present study [9]. 4.3. Analysis of the Proposed Methods In socio-ecological systems, there are a variety of complexities, including dynamics, feedback and heterogeneity, and a lack of proper understanding of the complexities in these systems leads to failure in good water governance. However, technical models are needed to understand the behavior of water resources and provide useful information about the current situation. In order to have a correct approach to the process of water governance, a correct understanding of the attitudes, beliefs, and behaviors of the stakeholders is required. One of the approaches that has been widely noticed in recent years for the study of complex systems is the ABM and FTA approaches. These approaches were introduced as effective tools for cooperative management, designing effective strategies, and water resources management policies. By using this approach while modeling the behavior of different stakeholders and the relationships and interactions between them and with the environment and with the dynamic participation of individual, group, and institutional stakeholders in the modeling process, it is possible to make correct decisions with appropriate implementation support. The framework developed in this study is used to understand the characteristics, behaviors, and interactions of effective factors in the process of system changes. In addition, system analysis in such a framework provides a better understanding of the structures of complex systems to support decision-making under conditions of uncertainty in a collaborative process. In the aforementioned cooperative approach, while gaining a more accurate understanding of the components, patterns, and connections of the studied system by attracting the cooperation and willingness of the stakeholders, better solutions can be achieved in the decision-making process. Implementing the developed framework in more case studies with different conditions can lead to the production of more comprehensive guidelines for issues such as cooperative management at the country level while processing the process of stakeholder analysis. This issue will be fruitful in defining the procedures of water governance according to different social, economic, and environmental conditions in the wide area of Iran. Although the majority of water consumption in the catchment area of Lake Urmia is related to the agricultural sector, to complete the developed framework, especially in the areas where the drinking and industrial sectors are influential consumers, their goals, characteristics, and behavioral patterns were evaluated. The relevant factors and interactions should be added to the model. One of the problems and complexities in modeling social systems is the existence of human agents who potentially have irrational behaviors and complex psychological characteristics—in other words, factors that make quantification, calibration, and validation difficult. Although this issue is a main source of problems in providing simulation outputs, in most cases, the only model that can challenge these conditions is the ABM and FTA models. To develop the presented framework, the integrated exploitation model of surface and underground water can be considered as the environment of the ABM model. The use of more accurate agricultural economic models can have a significant effect in matching the results with the existing reality. In this study, the effects of climate change in the future have been ignored and only sensitivity analysis on climate change has been considered. In future research, the effect of different scenarios of climate change in the process of changing the behavior of the agents and policy-making according to these changes can be considered. 5. Conclusions The problems of the LU basin are related to extensive and complex factors, which require a comprehensive approach to identify failure factors at the basin level. The search for a general index that covers the general risks of the LU basin to various aspects of water resource scarcity and environmental, economic, and social situations will lead to sufficient knowledge and mastery. Using the ABM model as a basis, farmers’ social interactions and financial gains from government subsidies could be simulated. The purpose of the FTA was to set out the sequence of events that could lead to the depletion of water resources in the LU basin. The findings demonstrated that, at a 95% confidence level, random change, SWS, subsidy policy, and government supervision and training are the most reliable measures of farmers’ willingness and participation in adapting to the DTIM. A key factor in raising WP is government supervision and training. According to the basic event ranking, the main reasons for failures in the LU basin are low awareness among residents of the basin and lack of demands from farmers, with failure probabilities of 0.86 and 0.90, respectively. In the end, the main event had a probability of failure of 0.50. The inadequate social structure at LU is the main cause of the existing catastrophic situation. The key to maximizing the use of the LU basin’s water resources is to demand awareness and participation of the basin residents. Other sub-basins can benefit from an improved situation by mimicking the fault tree structure of the LU basin. As a suggestion for future direction, the methodology used in this study should be extended to other sub-basins of LU over different periods, considering how productivity and development plans may alter the demonstrated risk index. Author Contributions Conceptualization, S.E.; methodology, H.D.; software, S.E.; validation, S.E.; formal analysis, S.E.; investigation, H.D.; resources, H.D.; data curation, S.E.; writing—original draft preparation, H.D. and S.E.; writing—review and editing, H.D. and S.E.; visualization, S.E.; supervision, H.D.; project administration, H.D.; funding acquisition, H.D. All authors have read and agreed to the published version of the manuscript. Funding The present study was carried out with the financial support of the Iran National Science Foundation (INSF) (project No. 4015227). Data Availability Statement The data presented in this study are available on request from the corresponding author. Conflicts of Interest The authors declare no conflicts of interest. References Dehghanisanij, H.; Emami, S.; Khasheisiuki, A. Functional Properties of Irrigated Cotton under Urban Treated Wastewater Using an Intelligent Method. Appl. Water Sci. 2022, 12, 66. [Google Scholar] [CrossRef] Zhao, Z.; Zuo, J.; Zillante, G. Transformation of Water Resource Management: A Case Study of the South-to-North Water Diversion Project. J. Clean. Prod. 2015, 163, 136–145. [Google Scholar] [CrossRef] Pramova, E.; Locatelli, B.; Djoudi, H.; Olufunso, A. Forests and Trees for Social Adaptation to Climate Variability and Change. WIREs Clim. Change 2012, 3, 581–596. [Google Scholar] [CrossRef] Misra, A.K. Climate Change and Challenges of Water and Food Security. Int. J. Sustain. Environ. 2014, 3, 153–165. [Google Scholar] [CrossRef] Anghileri, D.; Pianosi, F. Sciences A Framework for the Quantitative Assessment of Climate Change Impacts on Water-Related Activities at the Basin Scale. Hydrol. Earth Syst. Sci. 2011, 15, 2025–2038. [Google Scholar] [CrossRef] Zarrineh, N.; Abad, M.A.N. Integrated Water Resources Management in Iran: Environmental, Socio-Economic and Political Review of Drought in Lake Urmia. Int. J. Water Resour. Environ. Eng. 2014, 6, 40–48. [Google Scholar] [CrossRef] Schmidt, M.; Gonda, R.; Transiskus, S. Environmental Degradation at Lake Urmia (Iran): Exploring the Causes and Their Impacts on Rural Livelihoods. GeoJournal 2021, 86, 2149–2163. [Google Scholar] [CrossRef] Ženko, M.; Menga, F. Linking Water Scarcity to Mental Health: Hydro–Social Interruptions in the Lake Urmia Basin, Iran. Water 2019, 11, 1092. [Google Scholar] [CrossRef] Gachlou, M.; Roozbahani, A. Comprehensive Risk Assessment of River Basins Using Fault Tree Analysis. J. Hydrol. 2019, 577, 123974. [Google Scholar] [CrossRef] Ojiemhende, F.; Oluseye, O.; Sidiq, A. Fault Tree Analysis and Its Modifications as Tools for Reliability and Risk Analysis of Engineering Systems—An Overview. Int. J. Res. Publ. Rev. 2022, 2582, 7421. [Google Scholar] Singh, A. Simulation—Optimization Modeling for Conjunctive Water Use Management. Agric. Water Manag. 2014, 141, 23–29. [Google Scholar] [CrossRef] Sun, Y.; Liu, N.; Shang, J.; Zhang, J. Sustainable Utilization of Water Resources in China: A System Dynamics Model. J. Clean. Prod. 2016, 142, 613–625. [Google Scholar] [CrossRef] Ma, L.; Chen, B.; Wang, X.; Zhu, Z.; Wang, R. The Analysis on the Desired Speed in Social Force Model Using a Data Driven Approach. Physica A 2019, 525, 894–911. [Google Scholar] [CrossRef] Kocabas, V.; Dragicevic, S. Assessing Cellular Automata Model Behaviour Using a Sensitivity Analysis Approach. Comput. Environ. Urban Syst. 2006, 30, 921–953. [Google Scholar] [CrossRef] Santé, I.; García, A.M.; Miranda, D.; Crecente, R. Landscape and Urban Planning Cellular Automata Models for the Simulation of Real-World Urban Processes: A Review and Analysis. Landsc. Urban Plan. 2010, 96, 108–122. [Google Scholar] [CrossRef] Macal, C.M.; North, M.J. Agent-Based Modeling and Simulation. In Proceedings of the 2009 Winter Simulation Conference (WSC), Austin, TX, USA, 13–16 December 2009; pp. 86–98. [Google Scholar] Grimm, V.; Berger, U.; Bastiansen, F.; Eliassen, S.; Ginot, V.; Giske, J.; Goss-custard, J.; Grand, T.; Heinz, S.K.; Huse, G.; et al. A Standard Protocol for Describing Individual-Based and Agent-Based Models. Ecol. Model. 2006, 8, 115–126. [Google Scholar] [CrossRef] Hommes, C.H. Heterogeneous agent models in economics and finance. In Handbook of Computational Economics; Elsevier: Amsterdam, The Netherlands, 2006; Volume 2. [Google Scholar] [CrossRef] Berglund, E.Z.; Asce, M. Using Agent-Based Modeling for Water Resources Planning and Management. J. Water Resour. Plan. Manag. 2015, 141, 04015025. [Google Scholar] [CrossRef] Lin, Z.; Lim, S.H.; Lin, T.; Borders, M. Using Agent-Based Modeling for Water Resources Management in the Bakken Region. J. Water Resour. Plan. Manag. 2020, 146, 05019020. [Google Scholar] [CrossRef] Castilla-rho, J.C.; Mariethoz, G.; Rojas, R.; Andersen, M.S.; Kelly, B.F.J. Environmental Modelling & Software An Agent-Based Platform for Simulating Complex Human E Aquifer Interactions in Managed Groundwater Systems. Environ. Model. Softw. 2015, 73, 305–323. [Google Scholar] [CrossRef] Nhim, T.; Richter, A.; Zhu, X. The Resilience of Social Norms of Cooperation under Resource Scarcity and Inequality—An Agent-Based Model on Sharing Water over Two Harvesting Seasons. Ecol. Complex. 2018, 40, 100709. [Google Scholar] [CrossRef] Pouladi, P.; Afshar, A.; Hadi, M.; Molajou, A.; Farahmand, H. Agent-Based Socio-Hydrological Modeling for Restoration of Urmia Lake: Application of Theory of Planned Behavior. J. Hydrol. 2019, 576, 736–748. [Google Scholar] [CrossRef] Ohab-yazdi, S.A.; Ahmadi, A. Using the Agent-Based Model to Simulate and Evaluate the Interaction Effects of Agent Behaviors on Groundwater Resources, A Case Study of a Sub-Basin in the Zayandehroud River Basin. Simul. Model. Pract. Theory 2018, 87, 274–292. [Google Scholar] [CrossRef] Javad, M.; Zarghami, M.; Nadiri, A. An Uncertain Agent-Based Model for Socio-Ecological Simulation of Groundwater Use in Irrigation: A Case Study of Lake Urmia Basin, Iran. Agric. Water Manag. 2021, 249, 106796. [Google Scholar] [CrossRef] Lang, D.; Ertsen, M.W. Conceptualising and Implementing an Agent-Based Model of an Irrigation System. Water 2022, 14, 2565. [Google Scholar] [CrossRef] Okura, F.; Budiasa, I.W.; Kato, T. Exploring a Balinese Irrigation Water Management System Using Agent-Based Modeling and Game Theory. Agric. Water Manag. 2022, 274, 107951. [Google Scholar] [CrossRef] Shoushtarian, F.; Negahban-azar, M.; Crooks, A. Investigating the Micro-Level Dynamics of Water Reuse Adoption by Farmers and the Impacts on Local Water Resources Using an Agent-Based Model. Socio-Environ. Syst. Model. 2022, 4, 18148. [Google Scholar] [CrossRef] Streefkerk, I.N.; De Bruijn, J.; Haer, T.; Van Loon, A.F.; Quichimbo, E.A.; Wens, M.; Hassaballah, K.; Aerts, J.C.J.H. A Coupled Agent-Based Model to Analyse Human-Drought Feedbacks for Agropastoralists in Dryland Regions. Front. Water 2023, 4, 1037971. [Google Scholar] [CrossRef] Mirzaei, A.; Ashktorab, N.; Noshad, M. Evaluation of the Policy Options to Adopt a Water-Energy-Food Nexus Pattern by Farmers: Application of Optimization and Agent-Based Models. Front. Environ. Sci. 2023, 11, 1139565. [Google Scholar] [CrossRef] Kabir, S. An Overview of Fault Tree Analysis and Its Application in Model Based Dependability Analysis. Expert Syst. Appl. 2017, 77, 114–135. [Google Scholar] [CrossRef] Danesh-yazdi, M. Lake Urmia Crisis and Restoration Plan: Planning without Appropriate Data and Model Is Gambling. J. Hydrol. 2019, 576, 639–651. [Google Scholar] [CrossRef] Cover, S. Changing Causes of Drought in the Urmia Lake Basin—Increasing Influence of Evaporation and Disappearing. Water 2021, 13, 3273. [Google Scholar] Dehghanisanij, H.; Emami, S.; Emami, H.; Elbeltagi, A. Evaluating Performance Indicators of Irrigation Systems Using Swarm Intelligence Methods in Lake Urmia Basin, Iran. Environ. Dev. Sustain. 2023, 26, 4175–4195. [Google Scholar] [CrossRef] Rahimi, A.; Breuste, J. Why Is Lake Urmia Drying up? Prognostic Modeling With Land-Use Data and Arti Fi Cial Neural Network. Front. Environ. Sci. 2021, 9, 603916. [Google Scholar] [CrossRef] Heppenstall, A.; Malleson, N.; Crooks, A. “Space, the Final Frontier”: How Good Are Agent-Based Models at Simulating Individuals and Space in Cities? Systems 2016, 4, 9. [Google Scholar] [CrossRef] Deangelis, D.L.; Diaz, S.G. Decision-Making in Agent-Based Modeling: A Current Review and Future Prospectus. Front. Ecol. Evol. 2019, 6, 237. [Google Scholar] [CrossRef] Ferdous, R.; Khan, F.; Sadiq, R.; Amyotte, P.; Veitch, B. Fault and Event Tree Analyses for Process Systems Risk Analysis: Uncertainty Handling Formulations. Risk Anal. 2011, 31, 86–107. [Google Scholar] [CrossRef] [PubMed] Austin, P.C. Fine-Gray Subdistribution Hazard Models to Simultaneously Estimate the Absolute Risk of Different Event Types: Cumulative Total Failure Probability May Exceed 1. Stat. Med. 2021, 40, 4200–4212. [Google Scholar] [CrossRef] [PubMed] Wilensky, U.; Tisue, S. Center for connected learning and computer-based modeling northwestern university, evanston, illinois. In Proceedings of the Agent 2004 Conference on Social Dynamics: Interaction, Reflexivity and Emergence, Argonne, IL, USA, 7–9 October 2004. [Google Scholar] Chiacchio, F.; Pennisi, M.; Russo, G.; Motta, S.; Pappalardo, F. Agent-Based Modeling of the Immune System: NetLogo, a Promising Framework. BioMed Res. Int. 2014, 2014, 907171. [Google Scholar] [CrossRef] Amosson, S.H.; New, L.; Almas, L.; Bretz, F.; Marek, T. Economics of Irrigation Systems; Texas FARMER Collection; Texas A&M University: College Station, TX, USA, 2002; 20p. [Google Scholar] Taher, M.; Connor, J.D.; Albiac, J. Ef Fi Cient Water Management Policies for Irrigation Adaptation to Climate Change in Southern Europe. Ecol. Econ. 2015, 120, 226–233. [Google Scholar] [CrossRef] Liu, T. Factors Influencing Farmers’ Adoption of Best Management Practices: A Review and Synthesis. Sustainability 2018, 10, 432. [Google Scholar] [CrossRef] Horbach, J.; Rammer, C.; Rennings, K. Determinants of Eco-Innovations by Type of Environmental Impact—The Role of Regulatory Push/Pull, Technology Push and Market Pull. Ecol. Econ. 2012, 78, 112–122. [Google Scholar] [CrossRef] Diaz, C.J.; Donoso, G.; Speelman, S. The Irrigation Subsidy Policy in Chile: Lessons from the Allocation, Uneven Distribution, and Water Resources Implications. Int. J. Water Resour. Dev. 2021, 39, 133–154. [Google Scholar] [CrossRef] Chuchird, R.; Sasaki, N. Influencing Factors of the Adoption of Agricultural Irrigation Technologies and the Economic Returns: A Case Study in Chaiyaphum Province, Thailand. Sustainability 2017, 9, 1524. [Google Scholar] [CrossRef] Zhang, W.; Member, S.; Valencia, A.; Chang, N.; Agent-based, A. Learning and Agent-Based Modeling: A Multidisciplinary Review. IEEE Trans. Neural Networks Learn. Syst. 2023, 34, 2170–2190. [Google Scholar] [CrossRef] [PubMed] Palanisami, K.; Mohan, K.; Giordano, M.; Charles, C. Measuring Irrigation Subsidies in Andhra Pradesh and Southern India: An Application of the GSI Method for Quantifying Subsidies; Global Subsidies Initiative; International Institute for Sustainable Development (IISD): Winnipeg, MB, Canada, 2011; 56p. [Google Scholar] Adeyemi, O.; Grove, I.; Peets, S.; Norton, T. Advanced Monitoring and Management Systems for Improving Sustainability in Precision Irrigation. Sustainability 2017, 9, 353. [Google Scholar] [CrossRef] Aliabadi, B.T.; Hassandokht, M.R.; Etesami, H.; Alikhani, H.A. Effect of Mulching on Some Characteristics of Tomato (Lycopersicon Esculentum Mill.) under Deficit Irrigation. J. Agric. Sci. Technol. 2019, 21, 927–941. [Google Scholar] Zhou, Q.; Deng, X.; Wu, F.; Li, Z.; Song, W. Participatory Irrigation Management and Irrigation Water Use Efficiency in Maize Production: Evidence from Zhangye City, Northwestern China. Water 2017, 9, 822. [Google Scholar] [CrossRef] Abiodun, E.; Shukri, M.; Abidin, Z.; Saiful, M.; Mahmud, A.; Buyamin, S.; Hafis, M.; Ishak, I.; Khairie, M.; Abd, I.; et al. A Review on Monitoring and Advanced Control Strategies for Precision Irrigation. Comput. Electron. Agric. 2020, 173, 105441. [Google Scholar] [CrossRef] Nabiafjadi, S.; Sharifzadeh, M.; Ahmadvand, M. Social Network Analysis for Identifying Actors Engaged in Water Governance: An Endorheic Basin Case in the Middle East. J. Environ. Manag. 2021, 288, 112376. [Google Scholar] [CrossRef] Galvez, V.; Rojas, R.; Bennison, G.; Prats, C. Collaborate or Perish: Water Resources Management under Contentious Water Use in a Semiarid Basin. Intl. J. River Basin Manag. 2019, 18, 421–437. [Google Scholar] [CrossRef] Pahl-wostl, A.C.; Craps, M.; Dewulf, A.; Mostert, E.; Tabara, D. Social Learning and Water Resources Management. Ecol. Soc. 2007, 12, 5. [Google Scholar] [CrossRef] Alborzi, A.; Mirchi, A.; Moftakhari, H.; Mallakpour, I.; Alian, S.; Nazemi, A. Climate-Informed Environmental Inflows to Revive a Drying Lake Facing Meteorological and Anthropogenic Droughts. Environ. Res. Lett. 2018, 13, 084010. [Google Scholar] [CrossRef] Enqvist, J.P.; Ziervogel, G. Water Governance and Justice in Cape Town: An Overview. WIREs Water 2019, 6, e1354. [Google Scholar] [CrossRef] Cosgrove, W.J.; Loucks, D.P. Water management: Current and future challenges and research directions. Water Resour. Res. 2015, 51, 4823–4839. [Google Scholar] [CrossRef] Hunecke, C.; Engler, A.; Jara-rojas, R.; Poortvliet, P.M. Understanding the Role of Social Capital in Adoption Decisions: An Application to Irrigation Technology. Agric. Syst. 2021, 153, 221–231. [Google Scholar] [CrossRef] Sani, L.I. Influence of Socio-Economic Characteristics of Irrigation Farmers to Access and Utilization of Agricultural Knowledge and Information. Libr. Philos. Pract. 2017, 1571, 1–17. [Google Scholar] Bozorgzadeh, E.; Mousavi, S.J. A Quantitative Approach to Resource Effectiveness Assessment: Application in the Urmia Lake Basin. J. Environ. Manag. 2021, 289, 112559. [Google Scholar] [CrossRef] [PubMed] Abadi, B. How Agriculture Contributes to Reviving the Endangered Ecosystem of Lake Urmia? The Case of Agricultural Systems in Northwestern Iran. J. Environ. Manag. 2019, 236, 54–67. [Google Scholar] [CrossRef]   Disclaimer/Publisher’s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.  © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Share and Cite MDPI and ACS Style Emami, S.; Dehghanisanij, H. Fault Tree Analysis of Trade-Offs between Environmental Flows and Agricultural Water Productivity in the Lake Urmia Sub-Basin Using Agent-Based Modeling. Water 2024, 16, 844. https://doi.org/10.3390/w16060844 AMA Style Emami S, Dehghanisanij H. Fault Tree Analysis of Trade-Offs between Environmental Flows and Agricultural Water Productivity in the Lake Urmia Sub-Basin Using Agent-Based Modeling. Water. 2024; 16(6):844. https://doi.org/10.3390/w16060844 Chicago/Turabian Style Emami, Somayeh, and Hossein Dehghanisanij. 2024. \"Fault Tree Analysis of Trade-Offs between Environmental Flows and Agricultural Water Productivity in the Lake Urmia Sub-Basin Using Agent-Based Modeling\" Water 16, no. 6: 844. https://doi.org/10.3390/w16060844 Note that from the first issue of 2016, this journal uses article numbers instead of page numbers. See further details here. Article Metrics Citations No citations were found for this article, but you may check on Google Scholar Article Access Statistics Article access statistics Article Views 15. Mar 17. Mar 19. Mar 21. Mar 23. Mar 25. Mar 27. Mar 29. Mar 31. Mar 2. Apr 4. Apr 6. Apr 0 200 400 600 800 For more information on the journal statistics, click here. Multiple requests from the same IP address are counted as one view.   Water, EISSN 2073-4441, Published by MDPI RSS Content Alert Further Information Article Processing Charges Pay an Invoice Open Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors For Reviewers For Editors For Librarians For Publishers For Societies For Conference Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe to receive issue release notifications and newsletters from MDPI journals Select options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated Disclaimer Terms and Conditions Privacy Policy"

Paper 2:
- APA Citation: None
  Main Objective: The primary objective of this study is to critically evaluate the current state and future prospects of end-to-end automated irrigation management systems that integrate IoT and machine learning technologies.
  Study Location: None
  Data Sources: None
  Technologies Used: None
  Key Findings: None
  Extract 1: "Addressing the global food challenge: The review aims to explore how automated, real-time irrigation management systems can contribute to the efficient use of water resources and enhance agricultural productivity to meet the growing demand for food."
  Extract 2: "Evaluating the current state and future potential: The primary objective is to critically assess the current state of end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. The review also seeks to identify gaps and propose solutions for seamless integration across the automated irrigation management system to achieve fully autonomous, scalable irrigation management."
  Limitations: The drawbacks of the study, as stated by the authors, include its restricted scope, methodological issues, and the possible bias and dependability of the data sources used in the analysis. Future research recommendations are made to address these limitations and expand the study's breadth and depth.
  Relevance Evaluation: This study's relevance to the overall review has been assessed as exceptionally relevant, earning it a score of 1.0 on a scale of 0 to 1. The article's focus aligns perfectly with the review's intention to explore automated systems for real-time irrigation management in order to increase agricultural productivity and close the global food gap. The paper offers substantial information on the study's aims, context, and methodology, making it a valuable resource for the review's discussion and analysis.
  Relevance Score: 1.0
  Inline Citation: (Author, Year)
  Explanation: The study's primary goal, according to this article, is to determine how automated systems for real-time irrigation management can help close the global food gap and promote agricultural productivity. The research team provides an overview of the study's context by outlining existing issues with inefficient water use in agriculture and the growing demand for food. They also highlight the urgent need for innovative solutions to address these challenges. The paper's objectives then address specific challenges and strategies for integrating automated systems with irrigation infrastructure, interoperability, and standardization, as well as examining potential automation across the irrigation management pipeline and assessing key technologies, methods, and approaches used in the study.

 Full Text: >
"Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Graphical abstract Keywords 1. Introduction 2. Methodology 3. Case study 4. Results and discussion 5. Concluding remarks CRediT authorship contribution statement Declaration of competing interest Appendix A. Supplementary data Data availability References Show full outline Cited by (13) Figures (9) Show 3 more figures Tables (6) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6 Extras (1) Multimedia component 1 Journal of Cleaner Production Volume 397, 15 April 2023, 136437 Enhancing the resilience of ecosystem services under extreme events in socio-hydrological systems: A spatio-temporal analysis Author links open overlay panel Massoud Behboudian a c, Sara Anamaghi b, Najmeh Mahjouri b, Reza Kerachian c Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.jclepro.2023.136437 Get rights and content Highlights • A new methodology is proposed to assess basin-wide spatio-temporal resilience. • 128 scenarios are evaluated using a novel two-point evidential reasoning approach. • The best management scenario enhances the resilience value from 0.53 up to 0.85. • The selected scenario suggests improving irrigation networks and drainage facilities. • The seven resilience principles decrease the width of uncertainty band by 0.44%. Abstract Due to the adverse impacts of severe droughts on various aspects of human life and ecosystem services (ESs), the spatio-temporal assessment of the resilience of ESs under droughts is essential. In this paper, we propose a new methodology for assessing ESs-based resilience, taking into account the seven resilience principles: a) redundancy and diversity, b) managing connectivity, c) managing slow variables and their feedback, d) complex adaptive system (CAS) thinking, e) experimentation and learning, f) broadening participation, and g) polycentric governance. These principles enable us to consider the main social, political, hydrological, economic, and environmental aspects concerning resilience which have been overlooked in previous studies. The methodology is evaluated by applying it to Zarrinehroud River Basin (ZRB) in north-western Iran. A set of qualitative and quantitative criteria and their sub-criteria are proposed for quantifying the ES-based resilience and generating time series of resilience against severe droughts in several sub-basins in the study area. To evaluate the criteria and sub-criteria, the required data are derived from calibrated SWAT and MODSIM models as well as experts’ judjments. The time series of ES-based resilience under 128 Water and Environmental Resources Management (WERM) scenarios (for enhancing agricultural practices, altering and modernizing irrigation methods, improving irrigation network and drainage facilities) and Climate Change (CC) scenarios (RCP 4.5, RCP6.0, and RCP 8.5) are derived for each sub-basin based on short-term (2020–2049) and long-term (2020–2098) periods. The low resilience values (0.53–0.6) of all sub-basins under the base management scenario (the status quo scenario (SC0)) illustrate the need for implementing some projects to enhance the ESs in the study area. The results show that the WERM scenario SC12346 can improve the values of the resilience criterion in sub-basins up to 0.85 and reduce the vulnerability of the study area to droughts. By evaluating all management scenarios, scenario SC12346 is reported as the best scenario, since it can significantly increase the resilience of all sub-basins against extreme droughts with an acceptable cost of 636 million US dollars compared to other scenarios. Under this WERM scenario, the resilience values of sub-basins increase up to 40%. This scenario suggests implementing a set of projects such as improving irrigation networks and drainage facilities. Graphical abstract Download : Download high-res image (390KB) Download : Download full-size image Previous article in issue Next article in issue Keywords Spatio-temporal resilienceDroughtsEcosystem servicesZarrinehroud riverClimate changeLake Urmia 1. Introduction The ecosystem contributions to human well-being are referred to as ecosystem services (ESs) (Pan et al., 2021). ESs can be categorized into four groups of provisioning (water, food, and energy supply), regulating (climate regulations and air quality), supporting (soil formation and retention), and cultural (recreation and aesthetic considerations) ecosystem services (Ashrafi et al., 2022a). Most environmental challenges arise from neglecting the importance of ESs and over-exploiting them by the communities. Furthermore, human interventions to reduce losses and damages caused by nature can also affect the Social-Hydrological Systems (SHSs). SHSs refer to the dynamics and evolution of human-water systems (Blair and Buytaert, 2016). The climate change and changes in the water demand pattern due to population growth, urbanization, and expansion of cultivated areas have caused perturbations in SHSs and Hydrological ESs (HESs). Due to the underscored value of the ESs in human life, the impacts of natural processes alteration on ESs must be investigated. Several studies have been dedicated to the assessment of ESs under different perturbations (Goldenberg et al., 2017; Mörtberg et al., 2017; Keesstra et al., 2018). Ashrafi et al. (2022a) highlighted the importance of evaluating a set of ESs to address social and hydrological issues involved in an SHS. They identified water yield, sediment yield, air quality, climate regulation, biodiversity, education, tourism and recreation, and aesthetic inspiration for culture and art as important ESs. Resilience is usually viewed as the ability of an SHS to prepare for threats, absorb adverse impacts, and adapt to or recover from a disruptive event. When resilience is built into a system, conservation occurs naturally. In fact, the concept of resilience is embedded in the broader concept of sustainability. Therefore, monitoring and enhancing the resilience of a system, especially in a spatio-temporal manner, can help to detect vulnerable spots and employ better management strategies toward resilience and sustainability enhancement. Gómez-baggethun et al. (2019) scrutinized changes in ESs in the Danube Delta over twenty years. Despite implementing restoration policies, they detected a 67% decline in ESs over the studied period. Caro et al. (2020) introduced a new approach to assess the vulnerability of coastal ecosystems. The results showed that considering the resilience of ESs is more in accordance with the social-environmental realm. Behboudian et al. (2021a) proposed a new method for analyzing alternative Water and Environmental Resource Management (WERM) scenarios utilizing ES-based criteria and a hierarchical decision-making structure based on game theory. They applied their methodology to determine the best WERM scenario in the Lake Urmia (LU) basin in Iran. They did not study the spatial variations of ESs. Using the InVEST1 model, Luo et al. (2021) examined the effects of changing land use on the spatial pattern of four ESs (water production, soil retention, carbon storage, and nitrogen export). They scrutinized the varying spatial traits of each ES (service level and trade-off) in the Chishui river basin in China. Ashrafi et al. (2022a) proposed a framework to evaluate the sustainability of a broad range of services such as water yield, biodiversity, air quality, climate regulation, and education considering various climate change and WERM scenarios. Ashrafi et al. (2022b) introduced the concept of bankrupt ecosystems and used some bankruptcy methods to manage water-related ecosystem services in such ecosystems. The concept of resilience criterion was firstly defined in the field of ecology. It was described as “the capacity of the system to absorb disturbances and maintain the same relationships between populations and state variables” (Holling, 1973). The resilience of ESs is the capacity of SHSs to absorb and adapt to disturbances and sustain a set of ESs in the face of perturbations (Biggs et al., 2012). Several frameworks and methodologies have been proposed to assess resilience (Bruneau et al., 2003; Behboodian and Kerachian, 2020; Behboudian and Kerachian, 2021; Ferreira et al., 2021; Kalantari, 2021 ; Pourmoghim et al., 2022; Behboudian et al., 2022). The framework proposed by Bruneau et al. (2003), also known as “4R″, originally evaluated the seismic resilience of communities based on their robustness, redundancy, rapidity, and resourcefulness and has been widely applied in many fields. Biggs et al. (2012) pointed out that enhancing the resilience of ESs is a key factor in developing humans' social and economic well-being. Seven resilience principles (7P) include 1) maintaining redundancy and diversity, 2) managing connectivity, 3) managing slow variables and their feedback, 4) understanding the Social-Ecological System (SES) as a Complex Adaptive System (CAS), 5) encouraging experimentation and learning, 6) participation and 7) promoting polycentric governance, were introduced to enhance the resilience of ESs. Mugume et al. (2015) investigated the resilience of urban drainage systems under pressures of extreme rainfalls or increase in demand which lead to failure and overloading of the system, and defined resilience as minimizing levels of service failure duration and magnitude over its design life. Karamouz et al. (2016) developed a framework to assess vulnerability and used the 4R framework to quantify resilience of a river basin located in northwest Iran in the face of drought. In another research, Karamouz and Zahmatkesh (2017) proposed a set of 4R-based criteria considering socioeconomic, anthropogenic, and natural conditions and evaluated flood resilience in coastal cities. Kotzee and Reyers (2016) presented an index regarding some social-ecological criteria for quantifying resilience under flood events. They used Principal Components Analysis (PCA) to integrate all the criteria into one criterion. To design urban wastewater systems. Sweetapple et al. (2018) employed a resilience criterion to take into account both known and undiscovered threats. They confirmed that the reliability, resilience, and risk are complementing criteria and should be taken into consideration for evaluating a system under threats. Behboudian and Kerachian (2021) suggested a new ER-based technique for assessing the resilience of water resources management scenarios in the face of extreme events. To quantify the total resilience, they proposed several resilience-based criteria including reliability, vulnerability, 4R, and an ecological index. Behboudian et al. (2021b) proposed a methodology for evaluating water resource system resilience using RRV (Reliability-Traditional Resilience-Vulnerability) criteria, 4R-D criteria, and a social resilience criterion. They used a Two Parameter Evidential Reasoning (TPER) technique to integrate the criteria under uncertain extreme events. Moghaddasi et al. (2022) introduced a framework for groundwater resources' resilience assessment based on stakeholder analysis and system dynamic modeling. They applied the proposed framework to the Rafsanjan plain in Iran to investigate the performance of some groundwater management scenarios. Several social, political, hydrological, economic, and environmental aspects affect the resilience of SHSs. Reviewing previous studies indicates that those researches almost fail to consider all mentioned aspects in a comprehensive framework. For instance, the 4R framework mainly considers hydrological, economic, and social facets and lets the other aspects pale into significance. Some approaches, such as using traditional RRV criteria, mainly focus on the hydrological aspects (Fowler et al., 2003). The literature review also reveals that the seven resilience principles, namely 7RP, have not been quantified to assess and enhance the resilience of ESs in river basins. In addition, previous works have not investigated the spatio-temporal variations of the ESs resilience. Investigating the spatio-temporal variation of SHSs resilience provides essential information (regarding more vulnerable areas or how to detect these areas) for their protection in the face of severe droughts and enhancing their resilience. Lack of a comprehensive framework for resilience assessment and insufficiency of former frameworks in addressing all the aspects required in resilience assessment, and the need to scrutinize the status of any area in terms of resilience in a spatio-temporal manner, which has been overlooked in the antecedent studies, have been the main incentives in conducting this research. Taking thereof literature gaps into consideration, how can all key facets be incorporated into the resilience evaluation process, and how can the accuracy of recognizing the most susceptible spots and enhancing their resilience be improved? The main contribution of this paper is to answer the mentioned question by defining a comprehensive set of criteria to quantify the spatio-temporal variations of ESs resilience in river basins and proposing some projects to enhance this resilience in the face of extreme droughts. This holistic approach considers all crucial social, political, hydrological, environmental, and economic facets impacting the SHSs resilience. For this purpose, time series of daily precipitation and temperature are estimated using several Climate Change (CC) scenarios and imported into a calibrated SWAT2 model. We consider the impacts of these CC scenarios as extreme events with unknown occurrence probabilities. Then, the study area is divided into several sub-basins, and a coupled SWAT-MODSIM model is used to extract the required hydrologic data for assessing ES-based resilience. In the next step, several criteria and their corresponding sub-criteria are proposed based on the 7P to comprehensively evaluate the ESs resilience. After quantifying all criteria for each sub-basin, the TPER technique (Du and Zhong, 2021) is used to integrate all criteria and determine the time series of the resilience criterion for each sub-basin. The TPER is a two-parametric evidential reasoning technique that considers the weight and reliability of both quantitative and qualitative criteria. The reason behind the selection of the TPER technique is that it considers a broader range of infeasibilities and takes the uncertainties arising from biased measurements into consideration. Finally, several WERM scenarios are proposed and evaluated regarding the resilience and operational cost criteria to find the best scenario for improving the ES-based resilience of the study area with an acceptable cost. The proposed methodology is fully explained in Section 2 and described in detail through six sub-sections. The case study is presented in Section 3, and the results of adopting the proposed methodology are expounded in Section 4. In Section 5, concluding remarks and some recommendations for future works are provided. 2. Methodology Fig. 1 depicts a flowchart of the proposed methodology. The following sections present details of the main steps of the methodology. Download : Download high-res image (3MB) Download : Download full-size image Fig. 1. A flowchart of the proposed methodology for enhancing the spatio-temporal . 2.1. Data gathering The essential data such as climatic and hydrologic data (precipitation and temperature), surface and groundwater resources, water demands of different sectors (municipal, environmental, industrial, and agricultural demand nodes), and social data (population, employment rate, and level of education) are gathered to quantify the criteria and sub-criteria of the resilience of SHSs. Land use, land soil, and digital elevation maps (DEM) are also needed as some essential maps to simulate the hydrologic characteristics of basin-wide areas. The gathered data are inputs of the simulation models. The outputs of the models and the collected data, such as population and employment rate, are then used to assign values to each principle's defined criteria and sub-criteria. Each sub-criterion is either qualitative (the value of these criteria is assigned according to experts' judjments) or quantitative (these criteria are time-series-based) sub-criteria. For each WERM scenario, the values of all sub-criteria related to the first principle (diversity and redundancy), excluding reservoir operation policies (RD5), are assigned based on the experts' judgment. From the models, the monthly time series of dam release-based criterion for P2 (managing connectivity) is derived. Under each WERM scenario, the values for all sub-criteria of principle P3 (managing slow variables and feedback) are determined using model outputs, except for the value of the miscellaneous ecosystem services sub-criterion, which is determined based on the responses of experts to questionnaires. Fostering understanding of an SHS as a CAS (P4) involves four sub-criteria: robustness, resourcefulness, rapidity, and durability. Quantitative sub-criteria of robustness include the system's economic vulnerability (RO2), annual rainfall (RO4), and annual temperature (RO6). RO2 and RO4 are assigned based on the model's output, and the RO6 time series is derived using the downscaled data of projection models for each CC scenario. The population of the system (RA1-sub-criterion of rapidity) for year t ( ) is estimated based on the obtained historical data using equation (1) (Pourmoghim et al., 2022): (1) is the current population, r is the average growth rate, and n represents the number of years. Drought severity (RA4-sub-criteria of rapidity) is quantified using the dam monthly inflow from the model outputs. The sub-criteria of durability are also measured using the model outputs. The remaining sub-criteria of P4 are qualitative, and their values are the resilience of ecosystem services in socio-hydrological systems under uncertainty Social network analysis is also used to determine the values of P5 (encouraging experimentation and learning), P6 (participation), and P7 (promoting polycentric governance) principles. The details of using this data are described in the following sections. 2.2. Identifying extreme events Evaluating ESs-based resilience is usually done under severe events with unknown probability of occurrences (Sweetapple et al., 2018; Behboudian and Kerachian, 2021; Pourmoghim et al., 2022). We use several Representative Concentration Pathway (RCP)-based climate change scenarios to generate extreme hydrologic events (Bakhtar et al., 2022). With this in mind, daily precipitation and maximum and minimum daily air temperatures time series are generated for the future and imported to a coupled SWAT-MODSIM model to evaluate the basin-wide resilience of ESs. It should be noted that two time horizons of 2020–2049 (short-term) and 2020–2098 (long-term) are considered future time horizons. The outputs of the SWAT-MODFLOW model (inflow to reservoirs and lakes) are regarded as the impacts of severe droughts with an unknown probability of occurrence. 2.3. Developing a simulation-optimization model Regarding the selected climate change (CC) scenarios, a calibrated SWAT model is considered to simulate different variables, such as time series of evapotranspiration, runoff, and crop yield. The SWAT model, which is used in this study, has been calibrated and verified by Emami and Koch (2018). For the projection of daily maximum and minimum air temperature and daily precipitation, which are used as inputs of the SWAT model, CESM-CAM5 and MRI-CGCM3 models were utilized. A MODSIM model is then developed to investigate the effects of implementing WERM scenarios on surface and groundwater resources in the study area and to determine the allocated water to each municipal, industrial, agricultural, and environmental demand nodes under each WERM scenario regarding some imported temporal time series from the calibrated SWAT model to the MODSIM model, such as inflow to reservoirs and interactions between sub-basins. It should be mentioned that the MODSIM model uses the SWAT outputs for estimating available water resources. The MODSIM model, which is used in this paper, has been developed and verified by Pourmoghim et al. (2022). 2.4. Analyzing the spatio-temporal resilience of ESs regarding the seven resilience principles (7RP) In this paper, seven resilience principles introduced by Biggs et al. (2012) are taken into account to quantify resilience. These principles are: redundancy and diversity (P1), managing connectivity (P2), managing slow variables and their feedback (P3), CAS thinking (P4), encouraging experimentation and learning (P5), broadening participation (P6), and promoting polycentric governance (P7) (Fig. 2). Download : Download high-res image (2MB) Download : Download full-size image Fig. 2. A hierarchal framework of the proposed resilience-based criteria and their corresponding sub-criteria. The first principle (P1) states that having redundant and diverse elements can ensure the provision of ESs in the case of a disturbance. The redundancy of an SHS refers to the existence of different components with the same function in a way that they can be replaced to prevent loss of system performance in the face of a perturbation. In addition to redundancy, diversity denotes the different responses of the system's elements and components to disturbances. The P1 criterion is quantified considering both the diversity and redundancy as the sub-criteria. For example, suppose a particular ES is produced by a specific and limited number of species or elements (key species or key stakeholders) in a system. In that case, a high diversity factor may not ensure high redundancy. In addition, too much diversity and redundancy weaken the resilience of ESs in the long run. Therefore, maintaining ESs resilience requires a level of diversity and redundancy that balances the two factors (Biggs et al., 2012). To evaluate this criterion (P1), we propose several sub-criteria for the redundancy and diversity criteria (Fig. 2). More details about criteria and sub-criteria and their definitions can be found in the supplementary material. The second principle (P2) defines the extent of dispersion, transmission, and interaction of the available resources, species, and social actors across SHS (Biggs et al., 2012). To evaluate this principle as a second main criterion of ES-based resilience, we consider the number of months during the planning horizon in which proper dam release and upstream-downstream connectivity have occurred. The stability of an SHS and its related ESs rests on the slow variables and their feedback to changes (P3). Variations of slow variables (soil composition and sediment concentration, as well as legal systems, values, and traditions of society) can result in nonlinear changes and shifts in the existing regimes. Slow variables have been often overlooked in the monitoring and management of ESs, mainly due to the attention to fast variables, which show considerable changes over time. Therefore, identifying and managing key slow variables is essential to enhance the resilience of ESs. For this purpose, several ESs such as evapotranspiration, water yield, biodiversity, sediment yield, changes in groundwater level, climate regulation, air quality, educational value, tourism and recreation, and aesthetic inspiration for art and culture are selected as slow representative variables and assessed in this paper for evaluatin the third principle. The fourth principle affirms that enhancing the resilience of ESs depends upon integrated and comprehensive management under uncertainty at multiple temporal and spatial scales (P4). We propose the robustness, resourcefulness, rapidity, and durability sub-criteria for evaluating this principle. The intrinsic ability of the SHS to remain unaffected in the face of a specific level of stress and perturbation without loss of function is called robustness (Behboudian and Kerachian, 2021; Pourmoghim et al., 2022). Resourcefulness is also defined as the capacity of an SHS for mobilizing available resources and providing emergency responses under severe events of drought and flood, and prioritizing necessary tasks (Karamouz et al., 2016). Rapidity depends on the recovery time after facing a disturbance or an extreme event with an undetermined probability of occurrence. Durability is assumed as the average time period in which agricultural and environmental demands are satisfactorily supplied. As mentioned earlier, encouraging learning and experimentation is considered the fifth principle (P5). Various levels of learning are possible through observing existing processes and participatory activities. The proposed criterion to evaluate the learning level (the fifth main criterion of ES-based resilience) is the exchange of information determined by analyzing the existing social network. Four sub-criteria, including beta centrality, betweenness centrality, in-degree, and out-degree centrality are taken into account to assess the information exchange between stakeholders. Centrality refers to the number of nodes (stakeholders) adjacent to a specific node. It should be noted that adjacent nodes are connected to the specific node without intermediaries (Ahmadi et al., 2019). To calculate the beta centrality of each stakeholder, the centrality of the adjacent nodes is also taken into account as equation (2) (Ahmadi et al., 2020): (2) and are the beta centralities of the nth and mth node. Also, represents the element of the nth row and the mth column of the adjacency matrix, and is the normalization parameter. is the independence factor of each node to the adjacent nodes. Betweenness centrality determines the mediating role of each stakeholder. The greater the betweenness centrality score, the stronger the mediating role. To calculate this sub-criterion for node n, the ratio of the number of geodesic paths between nodes m and k which pass through node n, (Pm,k (n)) to the total of all geodesic paths between nodes m and k (Pm,k) is taken into account (equation (3)) (Ahmadi et al., 2019): (3) In-degree centrality of mth stakeholder ( denotes the number of stakeholders who have chosen the stakeholder m to have an institutional or formal relationship with them and the intensity of their relationship (equation (4)). The higher the value of of mth stakeholder, the more central the role of this stakeholder. As a fourth sub-criterion, out-degree centrality ( ) is the number of stakeholders that the nth stakeholder chooses to have institutional or formal relationships with. This sub-criterion is calculated using equation (5) as follows (Ahmadi et al., 2020): (4) (5) N represents the number of stakeholders (nodes), and is the element of the nth row and the mth column of the adjacency matrix, which is an N × N matrix. For more detailed information on the social network analysis and the mentioned sub-criteria, readers are referred to Ahmadi et al. (2019) The value of information (VOI) exchange criterion of the nth stakeholder ( ) is then calculated by weighted averaging the normalized values of the four above-mentioned sub-criteria using equation (6): (6) A pairwise comparison method is used to compute the relative weights and . The 6th principle concerns stakeholders' role in the management and governance of ESs (P6). This involvement can range from information exchange to authority delegation. Participation can help to strengthen the link between obtained information and decision-making, which is critical for effective decision-making and learning. This principle is assessed through the evaluation of stakeholders' interest in cooperation. We assess this main criterion based on four sub-criteria, 1) the rate of affectability of stakeholders from implementing different WERM scenarios, 2) stakeholders' responsibility in implementing a scenario, 3) the compatibility of a scenario with the stakeholders' mission, and 4) the type of the institution of each stakeholder. The value of each sub-criterion for each stakeholder is estimated using experts’ judjments. We then integrate the normalized values of these sub-criteria using the Ordered Weighted Averaging (OWA) approach (Behboudian et al., 2021c) to calculate the values of the sixth main of ES-based resilience criteria. Polycentric governance, which involves multiple stakeholders at multiple scales (Morrison et al., 2017), is the last resilience principle (P7). Each governance entity has a predetermined authority domain, can be in touch with other organizations with the same level of governing power and is nested within a higher-ranking governance unit. This paper proposes a centrality measure as a criterion to quantify this principle. To assess this criterion, some sub-criteria namely, “beta” centrality, “betweenness” centrality, “in-degree” centrality, and “out-degree” centrality are estimated based on the social network of stakeholders and the averaged value is calculated using equation (6). They are then integrated using the OWA method. After calculating the integrated centrality (comprehensive centrality) value for each stakeholder, to evaluate the level of polycentric governance, the number of stakeholders with the value of comprehensive centrality equal to or higher than 0.85 is considered, and the ratio of the number of selected stakeholders to the total number of stakeholders is calculated. A higher value for this ratio shows a more appropriate status for polycentric governance in the study area. The redundancy and the sub-criteria of criterion P4 are considered based on Behboudian and Kerachian (2021) and Pourmoghim et al. (2022). The proposed criterion for P2 has been adopted from Bouska et al. (2019). The values of P3's sub-criteria are quantified using the findings of Ashrafi et al. (2022a). Also, the criteria and sub-criteria of P5, P6, and P7 have been adopted from Ahmadi et al. (2019). Readers can refer to the online supplementary material for more detailed information on the proposed criteria. 2.5. Calculating the resilience of ESs Before conducting any assessment, the values of quantitative sub-criteria (precipitation and drought severity) should be normalized using benefit and cost normalization equations (Wang et al., 2006): (7) (8) is the normalized value of the ith criterion (cr), and are maximum and minimum values of the criterion , respectively. Equations (7), (8)) are used for benefit (positive) and cost (negative) criteria, respectively. We define a set of assessment grades which is denoted by H = {H1, H2, …, HN} to estimate the total resilience using the TPER technique, comprising a number of mutually exclusive grades. Each assessment grade is given a number between zero and 1, which shows the degree of belief of that grade. In this paper, we define five assessment grades which are represented in Table 1. The TPER technique is an extension of the ER technique that addresses a broader range of infeasibilities due to completely reliable, completely unreliable evidences and inconsistency in the integration (Du and Zhong, 2021). For more detailed information on the TPER technique, readers can refer to Du and Zhong (2021). In the proposed framework, when the grade-based values of rainfall or river flow fall in Class H1 (Table 1), an extreme drought has occurred. Table 1. Assessment grades and their description. Grade Definition Grade-based Value (0–1) H1 Poor 0.0–0.2 H2 Average 0.2–0.4 H3 Good 0.4–0.6 H4 Very good 0.6–0.8 H5 Excellent 0.8–1.0 In the next step, the belief degree of each criterion based on whether it has a temporal variation (Equation (9)) or average value (Equation (10)) is calculated as follows (Behboudian et al., 2021b): (9) (10) is belief degree of nth assessment grade for criterion , denotes the number of values in temporal time series for the criterion . represents the total number of time steps in the time horizon. and are respectively the values of assessment grades for criterion in assessment classes and , and is the average value of the criterion (Behboudian et al., 2021b). In the next step, the reliability of evidence is used to obtain discounted belief degree as follows (Behboudian et al., 2021b): (11) is the discounted belief degree of nth assessment grade for criterion and is the reliability of the criterion . Suppose M alternatives (al, l = 1, …, M) are assessed using N assessment grades of Hn, I criterion which each has a weight of wi ( and reliability of reli ( . If option al is selected based on the criterion with the assessment grade of and discounted belief degree of , the problem can be represented by equation (12) (Behboudian et al., 2021b): (12) Once belief degrees for all criteria and their sub-criteria are calculated, resilience under uncertainty is calculated using the maximum, minimum, and average value of the resilience (Behboudian et al., 2021b): (13) (14) (15) when , the incomplete assessment grade may be assigned to any other assessment grade. and denote the cases is assigned to the most desired grade assessment (HN) and least preferred assessment grade (H1). Resilience in each time step is the average value of the upper and lower limits (Resavg). 2.6. Calculating spatio-temporal resilience of ESs After calculating the temporal time series of ES-based resilience with regard to the seven core resilience principles, the spatial variations of the total resilience should be studied. To do so, the first step is defining WERM scenarios. In the following sub-sections, these two steps are elucidated. 2.6.1. Defining WERM scenarios The WERM scenarios are based on the projects defined by the involved stakeholders and organizations to investigate the impacts of implementing the projects on the study area. These WERM projects are initially defined considering three different classes of direct projects, indirect projects, and supporting projects. Direct projects directly address water and environmental problems and improve ESs. The effectiveness of indirect projects is mainly through boosting the performance of direct projects. Supporting projects contribute to improving the effectiveness of both direct and indirect projects. The projects are also classified as compulsory and non-compulsory. Compulsory projects provide high effectiveness with low cost. These projects have been previously classified into eight packages (P0, …, P7) by Pourmoghim et al. (2022) to define numerous WERM scenarios. Each WERM scenario consists of a group of projects (e.g., water transfer projects and projects concerning agricultural water demand reduction and enhancement of water distribution facilities) with similar purposes, progress rates, and cost-effectiveness. The zero package (P0) contains compulsory projects that have already been completed or have relatively high effectiveness or low implementation cost. The remaining projects are then classified into one of the following packages based on their objectives: Package 1 (water allocation to Lake Urmia from new resources), Package 2 (modern irrigation techniques), Package 3 (facilitating and increasing inflow of water to the lake), Package 4 (improving drainage and irrigation networks and related facilities), Package 5 (low-cost agricultural improvement projects), Package 6 (medium-cost agricultural improvement projects), and Package 7 (high-cost agricultural improvement projects). Combining these packages with different orders (1st, 2nd, …, nth), 128 WERM scenarios are generated. It should be noted that package P0 has been included in all WERM scenarios. For further information on the WERM scenarios, readers can refer to Pourmoghim et al. (2022). 2.6.2. Quantifying the defined resilience-based criteria and sub-criteria Different approaches are taken into account to quantify the defined criteria and sub-criteria. The time series of quantitative sub-criteria are estimated using the calibrated simulation models. The values of the qualitative sub-criteria are assigned using experts' judjments. Also, the values of some sub-criteria are calculated using social network analysis. Readers can refer to the online supplementary material for more detailed information on the quantifying methods for each criterion and sub-criterion. 3. Case study Lake Urmia, with an average area of about 5200 km2 at its normal level (1275.65 m), is the second hypersaline lake of the world after the Dead Sea in Palestine (Hassanzadeh et al., 2012; Stevens et al., 2012). This lake and its basin are located in north-western Iran, surrounded by the provinces of East Azerbaijan, Kurdistan, and West Azerbaijan at the latitude of 37° 00ˊ to 38° 12ˊ N and longitude of 44° 40ˊ to 45° 50ˊ E (Schulz et al., 2020; Pourmoghim et al., 2022). The lake's basin is among the six main basins of Iran, and most parts of the watershed are in the mountainous areas with a maximum height of 3720 masl,3 and the lake is surrounded by plains with a minimum elevation of 1256 masl. This area has a semi-arid climate with annual precipitation ranging from 300 to 400 mm, and an annual mean temperature of approximately 11.2 °C. Also, the annual evaporation is about 1200 mm (Emami and Koch, 2018; Rezaei and Gurdak, 2020). According to the topography, the Lake Urmia basin is a close inland basin located in a natural depression in the catchment, and all rivers of the basin flow towards this lake. The annual inflow of the lake is approximated at about 5300 million cubic meters (MCM). It is supplied through 16 permanent and a number of seasonal rivers, groundwater discharge, and direct precipitation over its surface (ULRNC, 2015). It should be mentioned that Lake Urmia's annual water level fluctuation has always been high in the past decades, but the dramatic decline of the water level in the 90s is a unique event. This lake lost almost 60% of its surface and more than 90% of its water volume from 1995 to 2013. The lake depletion adversely impacted its ecosystem by significantly reducing aquatic habitats resulted from increasing salinity to more than 300 gr/L (Schulz et al., 2020). Many studies have proved that the impacts of climate change, along with mismanagement of water resources and over-development of cultivated areas, which have led to increased water demand in agricultural section and decreased inflow to the lake, has exacerbated the lake's conditions (Fathian et al., 2015; Khazaei et al., 2019; Schulz et al., 2020; Pourmoghim et al., 2022). Nearly 41% of the lake's annual inflow is provided by the Zarrinehroud river, which is located in the southern part of this lake. The annual temperature of Zarrinehroud River Basin (ZRB) ranges from 8 °C to 12 °C, while precipitation ranges from 200 to 530 mm/yr (Behboudian and Kerachian, 2021). The length of the main river (i.e. the Zarrinehroud river), which originates from the Chehel-Cheshmeh mountains in Kurdistan province, is approximately 300 km (ULRNC, 2015). The study area is divided into 11 sub-basins to assess the spatio-temporal resilience against extreme drought events with undetermined probabilities, as shown in Fig. 3. Then, the temporal variations of resilience are calculated for each sub-basin. The most significant hydraulic structures of the ZRB are the Boukan dam located in sub-basin eight and the Novrouzloo diversion dam embedded in sub-basin two. The main cities of West Azerbaijan province, Miandoab, Shahindej, and Tekab are located in sub-basins two, seven, and nine, and one of Kurdistan province's cities, Saghez, is situated in sub-basin eight. Furthermore, sub-basins one and two contain parts of the Miandoab plain, which has an aquifer with an area of 1250 km2 (ULRNC, 2015). Download : Download high-res image (1MB) Download : Download full-size image Fig. 3. The ZRB and its sub-basins with its different land uses. 4. Results and discussion 4.1. Defining the WERM scenarios By investigating the current status of the study area, it can be concluded that the ZRB is not in a palatable condition in terms of ESs. Therefore, different WERM scenarios should be implemented to enhance the resilience of ESs. This study uses 128 different WERM scenarios for improving ecosystem services in the basin, based on the proposed projects of ULRNC (2015) and defined by Pourmoghim et al. (2022). 4.2. Calculating the resilience of ESs with regard to seven resilience principles The steps toward calculating the spatio-temporal resilience regarding the seven resilience are briefly mentioned in four steps and expounded in the following paragraphs. 1. Defining the criteria and sub-criteria of the seven resilience principles 2. Assigning values to the criteria and sub-criteria for each sub-basin 3. Assigning the weights of the sub-criteria, criteria, and the resilience principles 4. Integrating the values of the sub-criteria, criteria, and principles using the TPER approach to generate the resilience time series of each sub-basin Several criteria and sub-criteria are proposed to evaluate ES-based resilience based on the seven resilience principles (7RP). The time series of hydrologic quantitative sub-criteria were obtained using the SWAT and MODSIM models. The values of qualitative sub-criteria were assigned based on the experts' judjments. After determining the value of each criterion, the weights of criteria and sub-criteria are estimated using experts' judjments and the pairwise comparison method. For instance, the relative weights of the sub-criteria for the 4th criterion (P4) have been estimated as 0.395, 0.233, 0.175, and 0.197. Then the grade-based values of all sub-criteria are obtained. The TPER technique is applied to integrate the sub-criteria's grade-based values of each criterion and the criteria of each resilience principle (RP). In the TPER technique, the reliability of the qualitative criteria and their sub-criteria is assumed to be 90%, and for quantitative criteria, the reliability is considered 100%. The grade-based values of the resilience of ESs criterion are calculated for each time step and sub-basin. The upper and lower uncertainty bounds for the resilience time series also, are calculated. In this paper, the spatial variations of the drought resilience criterion are also calculated to assess the impacts of the WERM scenarios on different sub-basins under the RCP 4.5, 6.0, and 8.5 CC scenarios. The study area is divided into 11 sub-basins for the means of spatial assessment. The value of each sub-criterion is then calculated for each sub-basin. The spatial values of some sub-criteria (precipitation, changes in groundwater level, evapotranspiration, and population density) are available through the outputs of SWAT and MODSIM models. Data for the remaining sub-criteria are available for the entire basin. These data can be broken down for each sub-basin using some coefficients. If the criterion is related to the agricultural sector (modern agricultural irrigation method -RD3), the ratios of cultivated area in Table 2are used to separate these values for 11 sub-basins. If the criterion is related to the river channel and main reach (sediment yield), the ratios of channel length in Table 2 are used to separate these values for 11 sub-basins. Other types of criteria, such as the existence of systems for drought warning and forecasting and organizations' cooperation for drought management, are related to policies implemented in the entire basin and the values of these criteria are identical in sub-basins. Table 2. The ratio of the cultivated area in different sub-basin. No of sub-basin. Length of the channel (%) Cultivated area (ha) Cultivated area (%) Length of the channel (km) 1 17% 89.98 9% 46.1 2 27% 202.96 9% 42.87 3 7% 91.51 13% 62.68 4 6% 46.26 6% 27.91 5 4% 28.5 3% 13 6 5% 37.55 2% 11.05 7 20% 152.8 17% 83.61 8 9% 63.89 17% 79.87 9 6% 42.35 7% 33.8 10 2% 12.29 9% 42.96 11 2% 13.99 7% 36.1 Total 100% 742.68 100% 479.95 Table 3 presents the grade-based values for sub-basin two under WERM scenarios SC0 and SCT (a scenario that comprises all packages from P1 to P7). Almost the values of all the sub-criteria under scenario SC0 fall into the H1 (poor), H2 (average), or H3 (good) assessment classes. This condition results in an average value for the total resilience of the sub-basins under scenario SC0. Under scenario SCT, the criteria values fall into the assessment classes H4 (very good) and H5 (excellent). The grade-based values of total resilience of each sub-basin under RCP 4.5 and SC0 in January 2020 are listed in Table 4. Readers can refer to the online supplementary material for more detailed information on the value of each sub-criterion and grade values of the resilience of all sub-basins under the mentioned scenarios. Table 3. Grade values of sub-criteria for sub-basin two under WERM scenario SCT. Resilience based criteria Sub criteria Scenario H1 H2 H3 H4 H5 Hn Diversity and Redundancy Diversity SCT 0 0 0 0 0.9 0.1 SC0 0.67 0.23 0 0 0 0.1 Redundancy SCT 0.22 0.01 0.14 0.46 0.1 0.07 SC0 0.3 0.23 0.36 0.04 0 0.07 Connectivity Open river SCT 0 0 0 0 1 0 SC0 0 0 0 0 1 0 Managing slow variables and feedback Changes in hydrological ecosystem services SCT 0.21 0.07 0.13 0.22 0.28 0.09 SC0 0.48 0.1 0.16 0.02 0.15 0.09 Understanding SHS as a CAS Robustness SCT 0.24 0.17 0.02 0.33 0.23 0.03 SC0 0.24 0.29 0.24 0.05 0.15 0.03 Resourcefulness SCT 0.06 0.08 0.17 0.48 0.12 0.09 SC0 0.09 0.42 0.26 0.09 0.05 0.09 Rapidity SCT 0 0.08 0.28 0.16 0.42 0.06 SC0 0 0.27 0.16 0.1 0.41 0.06 Durability SCT 0.2 0.03 0.15 0.35 0.19 0.08 SC0 0.42 0.32 0.15 0.02 0.01 0.08 Learning and experimentation Information exchange SCT 0 0 0 0 0.9 0.1 SC0 0 0.01 0.89 0 0 0.1 Participation Interest in cooperation SCT 0 0 0 0 0.9 0.1 SC0 0 0 0.87 0.04 0 0.09 Polycentric governance Comprehensive centrality SCT 0 0 0 0 0.9 0.1 SC0 0.22 0.68 0 0 0 0.1 Table 4. The grade values of each sub-basin under RCP 4.5 and scenario SC0 in January 2020. Sub-basin H1 H2 H3 H4 H5 Hn 1 0.15 0.17 0.47 0.03 0.12 0.06 2 0.1 0.17 0.5 0.03 0.14 0.06 3 0.15 0.16 0.49 0.03 0.1 0.07 4 0.14 0.18 0.48 0.02 0.12 0.06 5 0.17 0.15 0.47 0.03 0.12 0.06 6 0.14 0.18 0.47 0.03 0.12 0.06 7 0.18 0.16 0.51 0.03 0.06 0.06 8 0.19 0.15 0.51 0.03 0.06 0.06 9 0.13 0.16 0.5 0.02 0.13 0.06 10 0.16 0.16 0.48 0.02 0.11 0.07 11 0.15 0.18 0.47 0.02 0.12 0.06 To examine the monthly variation of resilience, for instance, in Fig. 4, Fig. 5, the time series of the resilience criteria for sub-basins two and five are presented for SC0 (containing only package P0, which is similar to the current situation of the study area), SC134 (comprising packages 1, 2, and 3, which mainly focus on the allocation of alternative water resources and repair, maintenance and improvement of embedded facilities), SC2567 (comprising packages 2, 5, 6, and 7, which are related to the improvement of the agricultural sector of the study area) and SCT (containing all packages) under RCP 4.5 (2020–2049). The dotted lines in Fig. 4, Fig. 5 represent the uncertainty bounds. Download : Download high-res image (714KB) Download : Download full-size image Fig. 4. Time series of the estimated resilience for sub-basin two under WERM scenarios SC0, SC134, SC2567, and SC1234567 and climate change scenario RCP 4.5. Download : Download high-res image (526KB) Download : Download full-size image Fig. 5. Time series of the estimated resilience for sub-basin five under WERM scenarios SC0, SC134, SC2567, and SC1234567 and climate change scenario RCP 4.5. Sub-basin two has the highest, and sub-basin five has the lowest resilience values among all sub-basins. According to the resilience time series presented in the supplementary material, the resilience of all sub-basins under scenario SC0 varies between 0.53 and 0.6, indicating the necessity of implementing further WERM projects. In sub-basins three and four, the implementation of scenario SC134 has a better impact on the resilience against extreme droughts. In addition, this scenario has no significant impact on the sub-basins located upstream of the dam (sub-basins 10 and 11). Scenario SC134 has the most significant impact on the resilience of sub-basin two by increasing its resilience value up to 0.74. This occurs because of the existence of the Novrouzloo diversion dam and the irrigation and drainage network of the Rahim Khan plain in the sub-basin two. The implementation of the agricultural scenarios (SC2567) increases the resilience of sub-basin two to an average value of 0.84. This scenario improves the resilience of other sub-basins in proportion to the area of their cultivated lands. 4.3. Selecting the best WERM scenario for each sub-basin To determine an appropriate WERM scenario for each sub-basin, the average value of the total resilience criterion under all WERM scenarios is calculated. Then, a cost-effective scenario with an appropriate total resilience value is selected as the best scenario. The value of resilience is depicted in Fig. 6 for the top six WREM scenarios. The most resilient scenario across all sub-basins is scenario SCT, which comprises all packages. The total cost of scenario SCT is 855 million US dollars, which is a sizable sum. Scenario SC12346 provides an appropriate level of resilience for all sub-basins at a significantly reduced cost of 636 million US dollars. In scenario SC12346, two agricultural packages are eliminated, P5 with low-cost projects and P7, which comprises high-cost projects. P5 includes projects such as early corn cultivar substitution. Due to the study area's minimal corn farming (just in sub-basins seven and nine), implementing this package has a negligible effect on resilience. Additionally, it may be determined that projects included in package seven (P7) are more expensive and contribute little to the study area's resilience enhancement. Considering the implementation cost, scenario SC12346 is selected as the best WERM scenario for all sub-basins. Download : Download high-res image (333KB) Download : Download full-size image Fig. 6. The average resilience of the sub-basins under WERM scenarios SC1234567, SC123467, SC123457, SC134567, and SC12346. Table 5, Table 6 illustrate grade-based values for two environmental sub-criteria under WERM scenarios SC0 and SC12346 for sub-basin two. The state of enjoyable scenes and landscapes is examined in each scenario to assess aesthetic inspiration for art and culture. Tourism and recreation are evaluated using several criteria, including the availability and quality of water for recreational activities, such as fishing and boating, and the existence and condition of tourism infrastructures, such as hotels, hustles, restaurants, and roads. The captured carbon is the difference between the amount of CO2 plants take during photosynthesis and the amount of CO2 released during respiration. With this in mind, net primary productivity (NPP) can be used to quantify the amount of collected carbon. Air quality is evaluated based on the extent to which dust-prone zones are covered under each WERM scenario. For example, under WERM scenario SC0, values of the sub-criteria are classified as poor or average, but under the best scenario, they are classified as average or good. Table 5. Grade values of environmental sub-criteria for sub-basin two under WERM scenario SC0. Sub-criteria H1 H2 H3 H4 H5 Hn Aesthetic Considerations 0.8 0.1 0 0 0 0.1 Tourism 0.83 0.07 0 0 0 0.1 Captured Carbon 0.9 0 0 0 0 0.1 Air Quality 0 0 0.66 0.24 0 0.1 Table 6. Grade values of environmental sub-criteria for sub-basin two under WERM scenario SC12346. Sub-criteria H1 H2 H3 H4 H5 Hn Aesthetic Considerations 0 0.57 0.33 0 0 0.1 Tourism 0 0.49 0.41 0 0 0.1 Captured Carbon 0.71 0.19 0 0 0 0.1 Air Quality 0 0.68 0.22 0 0 0.1 Fig. 7, Fig. 8 elucidate the state of each sub-basin in terms of resilience for WREM scenarios SC0 and SC12346 under climate change scenario RCP 4.5. Download : Download high-res image (427KB) Download : Download full-size image Fig. 7. Drought resilience map of the study area under the best WERM scenario and climate change scenario RCP 4.5. Download : Download high-res image (421KB) Download : Download full-size image Fig. 8. Drought resilience map of the study area under WERM scenario SC0 and climate change scenario RCP 4.5. 4.4. Discussion According to the resilience time series of all sub-basins, it can be concluded that the implementation of all WERM scenarios will increase resilience in all sub-basins. The time series of resilience in scenario SC0, which varies between 0.53 and 0.6 in all sub-basins, illustrates the unacceptable condition of the current system. More drought events are observed in sub-basins seven and eight due to these regions' high density of agricultural lands. Management scenarios related to agricultural activities significantly increase the resilience of sub-basins -with a higher proportion of agricultural lands. The implementation of SCT in sub-basin two has a significant impact on the enhancement of resilience up to an average value of 0.86, since the farming land, Novrouzloo Diversion Dam, Miandoab town, and the Miandoab plain aquifer are located in this sub-basin, and this management scenario can improve a different aspect of the system's resilience. The better response of sub-basin two to the SCT scenario is related to the projects which modernize the irrigation methods. Modern irrigation techniques reduce the aquifer's recharge and can adversly impact groundwater level in the region. This side effect has been accounted for in simulating the groundwater balance. In sub-basin two, the Miandoab aquifer has a shallow groundwater depth. This aquifer experiences significant water loss due to evaporation (Motamedinejad, 2021). Therefore, scenarios that comprise modern irrigation techniques can positively impact groundwater level in the Miandoab plain in sub-basin two. Due to the uncertainty associated with qualitative sub-criteria and the use of both qualitative and quantitative sub-criteria in the assessment process, the TPER approach was implemented to assess and integrate the values of sub-criteria, criteria, and principles. In the study of Behboudian and Kerachian (2021), the bandwidth of the resilience uncertainty after the year 2050 increased from an average of 0.035–0.09; however, the implementation of the seven principles of resilience enables us to lower the increase in the bandwidth of the uncertainty after the year 2050 from 0.61% to 0.17%. The grade-based values of the resilience under the RCP 4.5 CC scenario and the base WERM scenario (SC0) for all the sub-basins fall into the average (0.2–0.4) and good (0.4–0.6) assessment ranges. This indicates the unfavorable condition of the study area. These results are similar to those of the previous works in the study area. Pourmoghim et al. (2022) stated that the Zarriehroud river basin was plagued by inadequate resilience under the same scenario (scenario SC0), and the water resources in the study area would not be able to fully address the future demands (Behboudian and Kerachian, 2021). Implementing the SCT WERM scenario, which comprises all the projects, can enhance the resilience status of all sub-basins by up to approximately 41% for both short-term and long-term horizons. Ashrafi et al. (2022a) evaluated several ESs under similar CC and WERM scenarios in the ZRB using a decision-making-based approach and recommended the SCT scenario to improve ESs status. The implementation cost of this scenario, however, is high. By investigating different WERM scenarios, scenario SC12346, which implements different projects concerning water allocation to Lake Urmia from new resources and facilitates and increases inflow of water to the lake, is selected as the best scenario with a lower implementation cost. This scenario can enhance the average resilience of sub-basins up to 0.85, and the grade-based values of resilience under this scenario fall into the very good and excellent assessment class. Similarly, Balkanlou et al. (2020) pointed out that to mitigate the profound impact of human interventions on ES provision in the Lake Urmia basin, projects which increase the supply of water to the lake, decrease the expansion of cultivation, and increase the overseeing of existing agricultural practices must be implemented. In addition, using a hierarchical multi-agent decision-making framework, Motlaghzadeh et al. (2023) stated that implementing a WERM scenario, which focuses on using new water resources, the modernization of irrigation methods and enhancement of irrigation and drainage networks can lead to improvement of the status of the Lake Urmia. 5. Concluding remarks In this paper, we introduced a methodology for assessing the spatio-temporal resilience of ecosystem services based on the seven core resilience principles. To this end, several criteria and sub-criteria were defined to quantify the resilience principles. According to the results, the following conclusions can be drawn: 1) Evaluating the ES-based resilience under the base management scenario (the status quo scenario-SC0) provided low resilience values (0.53–0.6) for all sub-basins of the study area and the grade-based values of ES-based and environmental sub-criteria (e.g., tourism, air quality, water yield, and captured carbon) fell into the poor to average assessment classes. 2) The WERM scenario SC134 (comprising packages one, two, and three) which considers new water resources and improves the efficiency of existing facilities, enhances the resilience in sub-basin eight and all the sub basins located downstream of the Boukan dam. 3) The WERM scenario SC2567 (comprising packages two, five, six, and seven) which mainly focuses on the modernization of irrigation methods and enhancement of agricultural practices, improves the resilience more significantly in the sub-basins with greater agricultural lands. The average value of resilience under this scenario in the sub-basin two (i.e. the sub-basin with the highest ratio of agricultural lands) increases up to 0.84. 4) The WERM scenario SC12346 was selected as the ideal scenario based on the total resilience and implementation cost criteria. Implementing this scenario improves the resilience of the ESs from 0.53 up to 0.85 with a 27.7 percent increase in the annual inflow to Lake Urmia. 5) The proposed criteria for assessing spatio-temporal resilience regarding the seven resilience principles is general and can be easily applied to other case studies. The following suggestions are put forward for future studies: 1) In this paper, the social network analysis has been done at the basin scale. In future studies, this analysis could be performed at the provincial or sub-basin levels. 2) In this study, the results obtained from the calibrated SWAT model have been used to examine groundwater table variations. It is suggested to use the SWAT-MODFLOW model to better quantify the impacts of WERM scenarios on groundwater resources in the study area. 3) This paper has not considered the uncertainties of CC scenarios. For a more accurate assessment, it is suggested to incorporate the CC scenarios' uncertainties in future studies. 4) For future research, the proposed WERM scenarios and the results of resilience analysis can be used in a multi-criteria-multi-agent decision-making model (i.e. a group decision-making model) to select the best scenario for enhancing the resilience of river basins in the face of droughts. CRediT authorship contribution statement Massoud Behboudian: Conceptualization, Methodology, Writing – original draft, Software. Sara Anamaghi: Conceptualization, Methodology, Writing – original draft, preparation, Software. Najmeh Mahjouri: Supervision, Methodology, Writing – review & editing, Validation. Reza Kerachian: Supervision, Methodology, Writing – review & editing, Validation. Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Appendix A. Supplementary data The following is the Supplementary data to this article: Download : Download Word document (571KB) Multimedia component 1. Data availability Data will be made available on request. References Ahmadi et al., 2019 A. Ahmadi, R. Kerachian, R. Rahimi, M.J.E. Skardi Comparing and combining social network analysis and stakeholder analysis for natural resource governance Environmental Development, 32 (2019), Article 100451, 10.1016/j.envdev.2019.07.001 View PDFView articleView in ScopusGoogle Scholar Ahmadi et al., 2020 A. Ahmadi, R. Kerachian, M.J.E. Skardi, A. Abdolhay A stakeholder-based decision support system to manage water resources J. Hydrol., 589 (2020), Article 125138, 10.1016/j.jhydrol.2020.125138 View PDFView articleView in ScopusGoogle Scholar Ashrafi et al., 2022a S. Ashrafi, R. Kerachian, P. Pourmoghim, M. Behboudian, K. Motlaghzadeh Evaluating and improving the sustainability of ecosystem services in river basins under climate change Sci. Total Environ., 806 (2022), Article 150702, 10.1016/j.scitotenv.2021.150702 View PDFView articleView in ScopusGoogle Scholar Ashrafi et al., 2022b S. Ashrafi, M.M.M. Khoie, R. Kerachian, M. Shafiee-Jood Managing basin-wide ecosystem services using the Bankruptcy theory Sci. Total Environ., 842 (2022), Article 156845, 10.1016/j.scitotenv.2022.156845 View PDFView articleView in ScopusGoogle Scholar Balkanlou et al., 2020 K.R. Balkanlou, B. Müller, A.F. Cord, F. Panahi, A. Malekian, M. Jafari, L. Egli Spatiotemporal Dynamics of Ecosystem Services Provision in a Degraded Ecosystem: A Systematic Assessment in the Lake Urmia Basin, Iran, vol. 716, Science of the Total Environment (2020), Article 137100, 10.1016/j.scitotenv.2020.137100 View PDFView articleView in ScopusGoogle Scholar Bakhtar et al., 2022 A. Bakhtar, A. Rahmati, A. Shayeghi, J. Teymoori, N. Ghajarnia, P. Saemian Spatio-temporal evaluation of GPM-IMERGV6. 0 final run precipitation product in capturing extreme precipitation events across Iran Water, 14 (10) (2022), p. 1650 CrossRefView in ScopusGoogle Scholar Behboodian and Kerachian, 2020 M. Behboodian, R. Kerachian Sustainability assessment of basin-wide water supply and demand scenarios using intelligent decision system (IDS) model Iran-Water Resources Research, 15 (4) (2020), pp. 316-329 (In Persian) https://dorl.net/dor/20.1001.1.17352347.1398.15.4.21.4 Google Scholar Behboudian and Kerachian, 2021 M. Behboudian, R. Kerachian Evaluating the resilience of water resources management scenarios using the evidential reasoning approach : the Zarrinehrud river basin experience J. Environ. Manag., 284 (2021), Article 112025, 10.1016/j.jenvman.2021.112025 View PDFView articleView in ScopusGoogle Scholar Behboudian et al., 2021a M. Behboudian, R. Kerachian, K. Motlaghzadeh, S. Ashrafi Evaluating water resources management scenarios considering the hierarchical structure of decision-makers and ecosystem services-based criteria Sci. Total Environ., 751 (2021), 10.1016/j.scitotenv.2020.141759 Google Scholar Behboudian et al., 2021b M. Behboudian, R. Kerachian, P. Pourmoghim Evaluating the long-term resilience of water resources systems : application of a generalized grade-based combination approach Sci. Total Environ., 786 (2021), Article 147447, 10.1016/j.scitotenv.2021.147447 View PDFView articleView in ScopusGoogle Scholar Behboudian et al., 2021c M. Behboudian, R. Kerachian, M. Hosseini Application of information fusion techniques and satellite products in the optimal redesign of rain gauge networks Stoch. Environ. Res. Risk Assess., 35 (8) (2021), pp. 1665-1680 CrossRefView in ScopusGoogle Scholar Behboudian et al., 2022 M. Behboudian, R. Kerachian, N. Mahjourimajd Evaluating the resilience of water resources management projects in river basins considering stakeholder's characteristics Iran-Water Resources Research, 18 (1) (2022), pp. 180-207 (In Persian) https://dorl.net/dor/20.1001.1.17352347.1401.18.1.12.0 Google Scholar Biggs et al., 2012 R. Biggs, M. Schlüter, D. Biggs, E.L. Bohensky, S. Burnsilver, G. Cundill, V. Dakos, T.M. Daw, L.S. Evans, K. Kotschy, A.M. Leitch, C. Meek, A. Quinlan, C. Raudsepp-Hearne, M.D. Robards, M.L. Schoon, L. Schultz, P.C. West Toward principles for enhancing the resilience of ecosystem services Annu. Rev. Environ. Resour., 37 (2012), pp. 421-448, 10.1146/annurev-environ-051211-123836 View in ScopusGoogle Scholar Blair and Buytaert, 2016 P. Blair, W. Buytaert Socio-hydrological modelling : a review asking “ why , what, and how Hydrol. Earth Syst. Sci., 20 (1) (2016), pp. 443-478, 10.5194/hess-20-443-2016 View in ScopusGoogle Scholar Bouska et al., 2019 K.L. Bouska, N. Houser, N. R. De Jager, M. Van Appledorn, J.T. Rogala Applying concepts of general resilience to large river ecosystems : a case study from the Upper Mississippi and Illinois rivers Ecol. Indicat., 101 (2019), pp. 1094-1110, 10.1016/j.ecolind.2019.02.002 View PDFView articleView in ScopusGoogle Scholar Bruneau et al., 2003 M. Bruneau, M. Eeri, S.E. Chang, M. Eeri, T. Ronald, M. Eeri, G.C. Lee, M. Eeri, T.D.O. Rourke, M. Eeri, A.M. Reinhorn, M. Eeri, M. Shinozuka, M. Eeri, W.A. Wallace, D. Von Winterfeldt A framework to quantitatively assess and enhance the seismic resilience of communities Earthq. Spectra, 19 (4) (2003), pp. 733-752, 10.1193/1.1623497 View in ScopusGoogle Scholar Caro et al., 2020 C. Caro, J.C. Marques, P.P. Cunha, Z. Teixeira Ecosystem services as a resilience descriptor in habitat risk assessment using the InVEST model Ecol. Indicat., 115 (2020), Article 106426, 10.1016/j.ecolind.2020.106426 View PDFView articleView in ScopusGoogle Scholar Du and Zhong, 2021 Y.W. Du, J.J. Zhong Generalized combination rule for evidential reasoning approach and Dempster–Shafer theory of evidence Infor. Sci., 547 (2021), pp. 1201-1232 https://doi.org/10.1016/j.ins.2020.07.072 View PDFView articleView in ScopusGoogle Scholar Emami and Koch, 2018 F. Emami, M. Koch Evaluation of statistical-downscaling/bias-correction methods to predict hydrologic responses to climate change in the Zarrine river basin, Iran Climate, 6 (2) (2018), p. 30, 10.3390/cli6020030 View in ScopusGoogle Scholar Fathian et al., 2015 F. Fathian, S. Morid, E. Kahya Identification of trends in hydrological and climatic variables in Urmia Lake basin, Iran Theor. Appl. Climatol., 119 (3) (2015), 10.1007/s00704-014-1120-4 Google Scholar Ferreira et al., 2021 C.S.S. Ferreira, K. Potočki, M. Kapović-Solomun, Z. Kalantari Nature-based solutions for flood mitigation and resilience in urban areas Nature-Based Solutions for Flood Mitigation: Environmental and Socio-Economic Aspects, Springer International Publishing, Cham (2021), pp. 59-78 CrossRefGoogle Scholar Fowler et al., 2003 H.J. Fowler, C.G. Kilsby, P.E.O. Connell Modeling the impacts of climatic change and variability on the reliability, resilience, and vulnerability of a water resource system Water Resour. Res., 39 (8) (2003), 10.1029/2002WR001778 Google Scholar Goldenberg et al., 2017 R. Goldenberg, Z. Kalantari, V. Cvetkovic, U. Mörtberg, B. Deal, G. Destouni Distinction, quantification and mapping of potential and realized supply-demand of flow-dependent ecosystem services Sci. Total Environ., 593 (2017), pp. 599-609 View PDFView articleView in ScopusGoogle Scholar Gómez-baggethun et al., 2019 E. Gómez-baggethun, M. Tudor, M. Doroftei, S. Covaliov, A. Năstase, D. Onără, M. Mierlă, M. Marinov, A. Doroșencu, G. Lupu, L. Teodorof, I. Tudor, B. Köhler, J. Museth, E. Aronsen, S. Ivar, O. Ibram, E. Marin, A. Crăciun, E. Cioacă Changes in ecosystem services from wetland loss and restoration : an ecosystem assessment of the Danube Delta (1960 – 2010) Ecosyst. Serv., 39 (1432) (2019), Article 100965, 10.1016/j.ecoser.2019.100965 View PDFView articleView in ScopusGoogle Scholar Hassanzadeh et al., 2012 E. Hassanzadeh, M. Zarghami, Y. Hassanzadeh Determining the main factors in declining the Urmia Lake Level by using system dynamics modeling Water Resour. Manag., 26 (1) (2012), pp. 129-145, 10.1007/s11269-011-9909-8 View in ScopusGoogle Scholar Karamouz et al., 2016 M. Karamouz, A. Zeynolabedin, M.A. Olyaei Regional drought resiliency and vulnerability Hydrologic Engineering, 21 (11) (2016), pp. 1-12, 10.1061/(ASCE)HE.1943-5584.0001423 Google Scholar Kalantari, 2021 Z. Kalantari Enlivening our cities: Towards urban sustainability and resilience: This article belongs to Ambio’s 50th Anniversary Collection. Theme: Urbanization Ambio, 50 (9) (2021), pp. 1629-1633 CrossRefView in ScopusGoogle Scholar Karamouz and Zahmatkesh, 2017 M. Karamouz, Z. Zahmatkesh Quantifying resilience and uncertainty in coastal flooding events: framework for assessing urban vulnerability J. Water Resour. Plann. Manag., 143 (1) (2017), Article 04016071, 10.1061/(ASCE)WR.1943-5452.0000724 Google Scholar Keesstra et al., 2018 S. Keesstra, J. Nunes, A. Novara, D. Finger, D. Avelar, Z. Kalantari, A. Cerdà The superior effect of nature based solutions in land management for enhancing ecosystem services Sci. Total Environ., 610 (2018), pp. 997-1009 View PDFView articleView in ScopusGoogle Scholar Khazaei et al., 2019 B. Khazaei, S. Khatami, S.H. Alemohamad, L. Rashidi, C. Wu, K. Madani, Z. Kalantari, G. Destouni, A. Aghakouchak Climatic or regionally induced by humans ? Tracing hydro-climatic and land-use changes to better understand the Lake Urmia tragedy J. Hydrol., 569 (2019), pp. 203-217, 10.1016/j.jhydrol.2018.12.004 View PDFView articleView in ScopusGoogle Scholar Kotzee and Reyers, 2016 I. Kotzee, B. Reyers Piloting a social-ecological index for measuring flood resilience : a composite index approach Ecol. Indicat., 60 (2016), pp. 45-53, 10.1016/j.ecolind.2015.06.018 View PDFView articleView in ScopusGoogle Scholar Luo et al., 2021 R. Luo, S. Yang, Z. Wang, T. Zhang, P. Gao Impact and trade-off analysis of land use change on spatial pattern of ecosystem services in Chishui River Basin Environ. Sci. Pollut. Control Ser. (2021), Article 0123456789, 10.1007/s11356-021-17188-w Google Scholar Motamedinejad, 2021 M. Motamedinejad Simulating the impacts of different measures on the inflow to the south of Lake Urmia using the MIKE-SHE model M.Sc. Thesis Faculty of Civil Engineering, Sharif University of Technology, Iran (2021) (In Persian) Google Scholar Moghaddasi et al., 2022 P. Moghaddasi, R. Kerachian, S. Sharghi A stakeholder-based framework for improving the resilience of groundwater resources in arid regions J. Hydrol., 609 (2022), p. 127737 https://doi.org/10.1016/j.jhydrol.2022.127737 View PDFView articleView in ScopusGoogle Scholar Morrison et al., 2017 T.H. Morrison, W.N. Adger, K. Brown, M.C. Lemos, D. Huitema, T.P. Hughes Mitigation and adaptation in polycentric systems: sources of power in the pursuit of collective goals Wiley Interdisciplinary Reviews: Clim. Change, 8 (5) (2017), pp. 1-16, 10.1002/wcc.479 Google Scholar Mörtberg et al., 2017 U. Mörtberg, R. Goldenberg, Z. Kalantari, O. Kordas, B. Deal, B. Balfors, V. Cvetkovic Integrating ecosystem services in the assessment of urban energy trajectories–A study of the Stockholm Region Energy Pol., 100 (2017), pp. 338-349 View PDFView articleView in ScopusGoogle Scholar Motlaghzadeh et al., 2023 K. Motlaghzadeh, A. Eyni, M. Behboudian, P. Pourmoghim, S. Ashrafi, R. Kerachian, K. Hipel A multi-agent decision-making framework for evaluating the water and environmental resources management scenarios under climate change Sci. Total Environ., 864 (2023), Article 161060, 10.1016/j.scitotenv.2022.161060 View PDFView articleView in ScopusGoogle Scholar Mugume et al., 2015 S.N. Mugume, D.E. Gomez, G. Fu, R. Farmani, D. Butler A global analysis approach for investigating structural resilience in urban drainage systems Water Res., 81 (2015), pp. 15-26, 10.1016/j.watres.2015.05.030 View PDFView articleView in ScopusGoogle Scholar Pan et al., 2021 H. Pan, J. Page, C. Cong, S. Barthel, Z. Kalantari How ecosystems services drive urban growth: Integrating nature-based solutions Anthropocene, 35 (2021), p. 100297 View PDFView articleView in ScopusGoogle Scholar Pourmoghim et al., 2022 P. Pourmoghim, M. Behboudian, R. Kerachian An uncertainty-based framework for evaluating and improving the long-term resilience of lakes under anthropogenic droughts J. Environ. Manag., 301 (2022), Article 113900, 10.1016/j.jenvman.2021.113900 View PDFView articleView in ScopusGoogle Scholar Rezaei and Gurdak, 2020 A. Rezaei, J.J. Gurdak Large-scale climate variability controls on climate, vegetation coverage, lake and groundwater storage in the Lake Urmia watershed using SSA and wavelet analysis Sci. Total Environ., 724 (2020), Article 138273, 10.1016/j.scitotenv.2020.138273 View PDFView articleView in ScopusGoogle Scholar Schulz et al., 2020 S. Schulz, S. Darehshouri, E. Hassanzadeh, M. Tajrishy, C. Schüth Climate change or irrigated agriculture–what drives the water level decline of Lake Urmia Sci. Rep., 10 (1) (2020), pp. 1-10, 10.1038/s41598-019-57150-y View in ScopusGoogle Scholar Stevens et al., 2012 L.R. Stevens, M. Djamali, V. Andrieu-Ponel, J.L. de Beaulieu Hydroclimatic variations over the last two glacial/interglacial cycles at Lake Urmia, Iran J. Paleolimnol., 47 (4) (2012), pp. 645-660, 10.1007/s10933-012-9588-3 View in ScopusGoogle Scholar Sweetapple et al., 2018 C. Sweetapple, M. Astaraie-Imani, D. Butler Design and operation of urban wastewater systems considering reliability, risk and resilience Water Res., 147 (2018), pp. 1-12 https://doi.org/10.1016/j.watres.2018.09.032 View PDFView articleView in ScopusGoogle Scholar Urmia Lake Restoration National Committee, 2015 Urmia Lake Restoration National Committee (ULNRC) Investigating and Analyzing Proposed Executional and Perusal Approaches toward Urmia Lake Restoration (2015), Article OC07RN9306002 Google Scholar Wang et al., 2006 Y.M. Wang, J.B. Yang, D.L. Xu, K.S. Chin The evidential reasoning approach for multiple attribute decision analysis using interval belief degrees Eur. J. Oper. Res., 175 (1) (2006), pp. 35-66, 10.1016/j.ejor.2005.03.034 View PDFView articleView in ScopusGoogle Scholar Cited by (13) Analyzing hydrological alteration and environmental flows in a highly anthropized agricultural river basin system using SWAT+, WEAP and IAHRIS 2024, Journal of Hydrology: Regional Studies Show abstract Biodiversity conservation indicators and conflict management: Application of environmental expert-based approach in Romania 2024, Journal of Cleaner Production Show abstract Quantifying multi-dimensional services of water ecosystems and breakpoint-based spatial radiation of typical regulating services considering the hierarchical clustering-based classification 2024, Journal of Environmental Management Show abstract Assessment and optimization of urban ecological network resilience based on disturbance scenario simulations: A case study of Nanjing city 2024, Journal of Cleaner Production Show abstract Thriving arid oasis urban agglomerations: Optimizing ecosystem services pattern under future climate change scenarios using dynamic Bayesian network 2024, Journal of Environmental Management Show abstract Using desirable urban states to understand key linkages between resilience subsystems 2024, Journal of Cleaner Production Show abstract View all citing articles on Scopus 1 Integrated Valuation of Ecosystem Services and Tradeoffs. 2 Soil and Water Assessment Tool. 3 Meter Above Sea Level (masl). View Abstract © 2023 Elsevier Ltd. All rights reserved. Recommended articles Settlement of a swelling plastic particle in the hydrothermal environment Journal of Cleaner Production, Volume 395, 2023, Article 136430 Bin Bai, …, Hui Jin View PDF The effect mechanism of HCl on chromium removal by CaO sorbent Journal of Cleaner Production, Volume 397, 2023, Article 136559 Aijia Zhang, …, Yingju Yang View PDF Application of meteorological drought for assessing watershed health using fuzzy-based reliability, resilience, and vulnerability International Journal of Disaster Risk Reduction, Volume 66, 2021, Article 102616 Mahmood Fooladi, …, Vijay P. Singh View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 11 Captures Readers: 32 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply."

Paper 3:
- APA Citation: Zhu, Z., Guan, G., Wang, K., & Chen, G. (2023). Distributed model predictive control based on the alternating direction method of multipliers for branching open canal irrigation systems. Agricultural Water Management, 285, 108372.
  Main Objective: Develop a reliable and flexible distributed control operating system for branching open canal irrigation systems (BOCISs) using an ADMM-based DMPC scheme.
  Study Location: Unspecified
  Data Sources: Simulation data from the Saint Venant equations
  Technologies Used: Distributed model predictive control, Alternating direction method of multipliers
  Key Findings: The proposed DMPC scheme demonstrates improved robustness, interference immunity, and fault tolerance compared to centralized control methods. It effectively handles sudden accidents, quickly and conveniently isolating affected subsystems to maintain the normal operation of others.
  Extract 1: The designed distributed controller in this paper is based on the ADMM. After system decomposition, the dynamics of subsystem i are described by:
  Extract 2: This work makes it possible to convey the water automatically from the water source to the users or farms at the last level canal, whereby higher efficiency and equity of water delivery can be guaranteed.
  Limitations: The study does not consider the impact of environmental factors such as rainfall or evapotranspiration on the irrigation scheduling.
  Relevance Evaluation: The paper is highly relevant to my literature review on automated systems for real-time irrigation management and the outline point regarding redundancy for maintaining system functionality during component failures. The paper's focus on developing a distributed control architecture for real-time irrigation management aligns well with the overall scope of my review.
  Relevance Score: 0.95
  Inline Citation: (Zhu et al., 2023)
  Explanation: Based on the paper provided, the primary goal was to develop a resilient, reliable, and cost-effective automated irrigation system for real-time water management. The authors propose a distributed model predictive control (DMPC) algorithm based on the alternating direction method of multipliers (ADMM) to achieve optimal water distribution and efficient utilization of resources.

 Full Text: >
"Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Keywords 1. Introduction 2. Materials and methods 3. Results 4. Discussion 5. Conclusions Acknowledgments Declaration of Competing Interest Appendix Control architectures Data availability References Show full outline Cited by (2) Figures (8) Show 2 more figures Tables (3) Table 1 Table 2 Table 3 Agricultural Water Management Volume 285, 1 July 2023, 108372 Distributed model predictive control based on the alternating direction method of multipliers for branching open canal irrigation systems Author links open overlay panel Zheli Zhu, Guanghua Guan, Kang Wang Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.agwat.2023.108372 Get rights and content Under a Creative Commons license open access Highlights • A distributed control algorithm is developed for large-scale branching open canal irrigation systems. • The alternating direction method of multipliers is used for the communication and coordination process. • The distributed control results converge to the global optimal solutions of centralized control. • More powerful robustness and outstanding performance of fault isolation are obtained. Abstract Most studies of open canal automation concentrated on the control of single canal pool or cascaded multiple canal pools, neglecting the hydraulic coupling effects between the main canal and lateral canals. Low transmission efficiency and poor equity of agriculture water delivery may be caused in the practical application of large-scale irrigation networks. Considering the high computation and communication requirements for large-scale operating systems, a distributed model predictive control (DMPC) algorithm based on the alternating direction method of multipliers (ADMM) is developed for the branching open canal irrigation systems (BOCISs). A simplified BOCIS example, originating from Test case 2 proposed by the American Society of Civil Engineers, is used for control tests. Moreover, for control performance comparisons and evaluations, centralized model predictive control (CMPC) is employed by modifying the state space of the integrator delay (ID) model. The results show that the control performance of the proposed DMPC converges to the global optimal solution of the CMPC under the normal scenario, and the degradation is less than 0.35 %. The communication and coordination process of DMPC contributes to more powerful robustness and interference immunity than CMPC. Furthermore, in case of sudden accidents occurring in some subsystems, the proposed DMPC is more convenient and timely to execute fault isolation. The improvements on water level oscillations and overshoots can reach 20.3 % and 52.1 % in the other subsystems which need normal water delivery, respectively. Equipped with outstanding control characteristics, the proposed ADMM-based DMPC framework enables the water authorities of large-scale BOCISs to promote surface water distribution in a practicable, flexible, and secure way, showing great potential in developing intelligent irrigation districts. Previous article in issue Next article in issue Keywords Distributed controlCentralized controlModel predictive controlIrrigation canal networkAlternating direction method of multipliers 1. Introduction Compared with backward manual operation methods, canal automation technologies represent a more water-saving and efficient alternative for the management of open canal systems (OCSs) (Avargani et al., 2022, Lozano et al., 2010, Sadowska et al., 2015, Schuurmans et al., 1995, Wahlin and Clemmens, 2006). Therefore, the last decades have witnessed a continuous generation of contributions in this field, but most concentrated on the control of single canal pool or cascaded multiple canal pools with no branches (Conde et al., 2021). From a practical point of view, the OCSs are always based on a network of multilevel canals with a tree topology, like the main, secondary, tertiary, or even more branching canals in the hierarchy. Just as individual pools interact with each other in an in-line cascaded canal system, individual branches can interact with each other (Wahlin and Clemmens, 2006). An improper automatic control system may cause severe oscillations of water level or gate movements. Ultimately, the surface water failed to be conveyed with high efficiency and equity from the water sources to the customers or farms along the multilevel canals. With the development of canal automation, the control of branching open canal networks gets more and more attention in the areas of inland waterways (Segovia et al., 2019), hydro-power valleys (Maestre et al., 2015), polder systems (Aydin et al., 2022), natural river network (Breckpot et al., 2013), and others. Notwithstanding, few studies consider the automatic control of branching open canal irrigation systems (BOCISs). Elfawal-Mansour et al. (2000) used a nonlinear black box model NARX for the control of the Canal de la Bourne, a real branching canal system in France that served for irrigation and electricity generation. By modifying the Integrator Delay (ID) model, Wahlin and Clemmens (2006) developed two centralized controllers of the linear quadratic regulator (LQR) and model predictive control (MPC), respectively. Results showed that both were able to bring the water level back to the setpoints in a branching canal network. Tariq et al. (2012) implemented a cyber-physical system towards the decentralized control of real irrigation canal networks in Pakistan, by which a slow response speed and risky water level fluctuation resulted. Alvarez et al. (2013) combined local controllers with distributed generalized predictive controllers for a Y-shaped irrigate canal, but only the head gate of the branch, not all check gates along the branch canal, is controlled. Sutrisno et al. (2012) and Zhang et al. (2015) proposed distributed model predictive controllers based on Game Theory and Nash Optimality, respectively. The former neglected the large delay of the flow and only tested a simple water level tracking scenario, while the latter restricted the direction of information transferring only from downstream to upstream. Xu and Schwanenberg (2017) applied nonlinear MPC with a diffusive wave model to a virtual drainage canal network, and achieved a satisfactory outcome with a reasonable computation time, though the global optimum was not guaranteed. Nowadays, with population growth and the modernization of irrigation districts, the size and complexity of the BOCISs have grown enormously. For the control of large-scale BOCISs, MPC with distributed control architecture is regarded as a promising control scheme (Kordestani et al., 2021). MPC is a control strategy that gets the highest attention for agriculture water management (Conde et al., 2021). It is given the credit to the versatile abilities to consider constraints in optimization, and the possibility of taking into account measurable disturbances (Overloop, 2006). The most classical control architecture of MPC is the centralized architecture, where systemwide measurements are gathered and a globally optimal solution is calculated. However, the huge size and wide geographic distribution of the large-scale BOCISs would lead to expensive communication costs and unbearable computing burdens (Maestre and Negenborn, 2013, Shi et al., 2021, Tang and Daoutidis, 2019). Simultaneously, the communication network-induced issues and the potential concerns of privacy and security problems are also unavoidable obstructions to the practical applications of centralized MPC (CMPC) (Tang and Daoutidis, 2019). The decentralized control architecture is a good choice for its low communication and computational requirements. But the neglect of the strong hydraulic interactions among individual pools and individual branches would lead to the phenomenon of disturbance amplification and poor control performance (Alvarez et al., 2013, Wahlin and Clemmens, 2006). In this case, distributed MPC (DMPC) works toward combing the advantages of the above two control architectures, though compared with the CMPC, there is some performance loss due to the partial knowledge of the entire system (Kordestani et al., 2021, Tang and Daoutidis, 2019, Tian, 2015). Specifically, in the DMPC, the large-scale system is decomposed into several interconnected subsystems. Then, a computing agent (or local controller) is associated with each subsystem and makes control decisions, like the decentralized MPC. The distinction between decentralized and distributed MPC lies in whether or not the information is exchanged actively between the adjacent agents to coordinate their decisions for a consensus, even in the case of conflicting goals. The modularization nature of DMPC contributes to its high scalability, which is one of the critical characteristics for the flexible control of large-scale BOCISs. Furthermore, different subsystems can consider diverse control objects and constraints, which distinguishes the DMPC from CMPC. In this way, in arid regions or water-deficit scenarios, the limited water can be delivered with various attitudes to different subsystems according to their water supply objects or crop species, so that better social, irrigation, energy, and economic benefits could be achieved. More detailed comparisons between different control architectures can be found in the Appendix. Over the last years, there has been a growing interest in DMPC for the control of many large-scale systems, like smart grids (Shi et al., 2021), waterborne vessels (Zheng et al., 2018), water systems (Maestre et al., 2021), traffic control (Li et al., 2020), and others. Nevertheless, no single generally accepted distributed algorithm has been proposed due to the complexities of various control objects (Maestre and Negenborn, 2013). It has been argued that the alternating direction method of multipliers (ADMM) is a particularly powerful distributed algorithm blending the strong decomposability of the dual ascent method with the excellent convergence property of the augmented Lagrange multiplier method (Ghadimi et al., 2015, Li et al., 2020, Teixeira et al., 2016). The most attractive feature of ADMM is that it is surprisingly guaranteed to converge for all positive values of the step-size parameter (Bai et al., 2021). This contrasts many popular distributed algorithms, such as dual decomposition methods (Teixeira et al., 2016) and gradient methods (Ghadimi et al., 2015), where mistuning of the step size can render the iterations unstable. Compared with the distributed techniques based on game theory, whose results correspond to a Nash equilibrium, the ADMM yields tighter approximations to the overall optimization (Lemos and Pinto, 2012). Moreover, it is recently investigated that the powerful ADMM performs outstandingly in dealing with the issues of reconfiguration control (Bai et al., 2021), whereby the scalability and the plug-and-play functionality are demonstrated. To the best of the authors’ knowledge, the ADMM algorithm is rarely reported for canal automation studies to date. So there are obvious difficulties in coding the complicated communication and coordination process of ADMM compared with the relatively mature centralized or decentralized control technologies. The main contribution of this paper is innovatively providing a reliable and flexible control operating system for the BOCISs by ADMM-based DMPC scheme. This work makes it possible to convey the water automatically from the water source to the users or farms at the last level canal, whereby higher efficiency and equity of water delivery can be guaranteed. Meanwhile, the proposed control framework is also vital for the future of intelligent irrigation systems, where the stored water in the water source and canal network can be delivered timely to the farmlands according to the real-time prediction of irrigation water requirements (Avargani et al., 2022). Accordingly, the present study is meaningful for precise irrigation and the sustainable development of agricultural water. The rest of the paper is organized as follows. Section 2 presents the design principles of the ADMM-based DMPC controller. The study case and test scenarios are also introduced. Section 3 analyses the simulation results, followed by the discussion in Section 4. Finally, some concluding remarks are drawn in Section 5. 2. Materials and methods 2.1. Model predictive control Model predictive control (MPC) refers to a family of control methods that explicitly use a process model of the real system to obtain the control actions by minimizing an objective function (Overloop, 2006). The process model is used to predict the evolution of the system, for which the ID model, proposed by Schuurmans et al. (1995) for open canals, is one of the most reported. The canal is assumed to be divided into two parts: i) a normal depth section with a uniform flow, and ii) a backwater section with an inflow delay. Delay time of inflow (τ in min) and average storage area (As in m2) are two main model properties, as shown in Eq.(1). (1) where e(t) is the water level deviation at the downstream end of the canal pool, m; q1(t-τ) is the inflow deviation to the backwater with delay time τ, m3/s; q2(t) is the downstream outflow deviation, m3/s; d(t) is the offtake flow deviation according to the irrigation schedule, m3/s. The deviation means the difference between the instantaneous value and the initial steady-state value. Based on the process model in discrete time, a state space is constructed to forecast the system dynamics over the prediction horizon, see Eq.(2). x(k+1) = A x(k)+Bu u(k)+Bd d(k) (2) y(k) = C x(k) where x(k) represents the system states at control step k; A is the system matrix; Bu is the control input matrix; Bd is the known disturbance input matrix; C is the output matrix; u(k) is the input vector calculated by the controller, i.e. the control commands for gates flow regulation; d(k) is the disturbance vector, i.e. the schedule of offtake flow changes; y(k) is the output vector, i.e. the water level deviation from setpoint at the downstream end of each canal pool. Then, the objective function J, see Eq. (3), can be minimized to obtain optimal control actions. This optimization problem is subject to the constraints of water level limitations and flow capacities. Once the sequence of future control actions is determined, only the first step is implemented. Then the system is updated and the prediction and optimization processes are repeated at the next control step. (3) where p and m represent the prediction horizon and control horizon, respectively; Q and R are the weight matrixes for a trade-off between minimizing the water level deviations and minimizing flow changes. The BOCISs are complex systems with large time delays, high hydraulic interactions, intermittent demands, disturbances, and multiple inputs and outputs. MPC is an outstanding control alternative for its versatility, but only under suitable control architecture can achieve high regulation accuracy with implementability (Kordestani et al., 2021). More details are shown in Fig. 1 and Appendix. In this paper, CMPC and DMPC are compared for the control of the BOCISs. Download : Download high-res image (713KB) Download : Download full-size image Fig. 1. Comparison among three common control architectures of model predictive control (MPC). 2.2. Alternating direction method of multipliers ADMM was first proposed by Gabay and Mercier (1976) for solving elliptic and parabolic partial difference equations. But it did not receive much attention until Stephen et al. (2011) made a review and proved that ADMM is well-suited for solving large-scale convex optimization problems in a distributed manner. The designed distributed controller in this paper is based on the ADMM. After system decomposition, the dynamics of subsystem i are described by: xi(k+1) = Ai xi(k)+Bu,i ui(k)+Bd,i di(k) (4) yi(k) = Ci xi (k) where i is the index of subsystems, , is the set of all subsystems; xi, yi, ui, di are the system state, output vector, input vector, and disturbance vector of the subsystem i; Ai, Bu,i, Bd,i, Ci are the system matrix, control input matrix, known disturbance input matrix, and output matrix of subsystem i. The subsystem i is coupled to the neighboring subsystem with the constraint: (5) where is the neighbors set connected to subsystem i; Eij and Eji are coupled weight matrices, indicating that the impacts of subsystem i on subsystem j are supposed to be equal to the impacts of subsystem j on subsystem i. Each agent only knows its own dynamics and cost function, and the local quadratic programming problem is given: (6) Where consists of all the coupling information passed to subsystem i from all neighboring agents; nij is the number of subsystems coupled to subsystem i; . Then the augmented Lagrangian function based on Eq.(6) is presented: (7) Where λi is the dual variable, ρ is the step size of the ADMM. It is convenient to use scaled dual variable , which yields the iterations: (8) (9) (10) Each agent is responsible for minimizing Eq.(7) to obtain its own control signal under current coupled information by solving Eq. (8), in which k is the index of iteration times. Then and the scaled dual variable in the next iteration are updated by Eq.(9) and Eq.(10), respectively. Afterward, the updated is communicated to its neighbors and new coupled information is received from its neighbors. This iterative process repeats until the following stopping criterion is reached: (11) where σ is the tolerance for consensus judgment, set as 10−3. For a clearer introduction, the decision-making process of the distributed control algorithm is generalized as follows: Step 1: When the distributed controller module is called, the measurements in each subsystem are transported to the corresponding computing agent. Step 2: Based on the state space model of subsystem (Eq. (4)), the local quadratic programming problem (Eq. (6)) is solved with coupling information from neighboring agents. Step 3: Neighboring agents communicate to judge the convergence criterion (Eq. (11)). Step 4: Coupling information is transferred between neighboring agents. Step 5: Return to Step 2 until the convergence and consensus. Above steps are done in parallel by each agent. Step 2 to Step 4 are carried out by the ADMM, see Fig. 2. Download : Download high-res image (170KB) Download : Download full-size image Fig. 2. Flow diagram of distributed algorithm based on the Alternating Direction Method of Multipliers. One advantage of the basic ADMM algorithm is that there is only one algorithm parameter ρ, and the method can be shown to converge for all positive values of ρ. However, ρ has a direct impact on the convergence speed of the algorithm. The calculation method proposed by Ghadimi et al. (2015) for the optimal ρ is employed. Ultimately, according to the categorization criteria (Maestre and Negenborn, 2013), a non-cooperative and iterative distributed model predictive controller is designed with parallel computation and synchronous communication. The non-cooperative attitude means that each agent only considers its local interests, rather than a global performance. Although some systemwide welfare may be sacrificed in this control attitude, less algorithm complexity and better scalability are guaranteed (Bai et al., 2021). 2.3. Study area In general, the gentler the bed slope of the canal, the stronger the coupling effects among individual pools and individual branches may be. Hence, controllers are performed on the branched version of Test canal 2, a typical test canal with a very gentle bed slope, proposed by the American Society of Civil Engineers (ASCE) (Clemmens et al., 1998), see Fig. 3. Because there are offtake changes both at the Pool 5 and Pool 6 in this test case, it is assumed that there are two branches that occur at the downstream end of Pool 5 and Pool 6, respectively. Each branch contains two canal pools, which have the same physical sizes as Pool 7 and Pool 8. More details about the branching canal network are presented in Table 1, in which the properties of the ID model for each canal pool are estimated by the parameter identification method (Zhong, 2016). Download : Download high-res image (1007KB) Download : Download full-size image Fig. 3. The sketch of the studied branching canal system and the communication diagram in the distributed controller. Table 1. Basic modeling parameters for the studied branching canal system and control parameters of model predictive controllers. Canal system Pool Design flow (m3/s) Bed slope Manning coefficient Length (m) Bottom width (m) Slide slope Target depth (m) Delay time (min) Storage area (m2) Q R The main canal 1 14 0.0001 0.02 7000 7 1.5 2.1 22 5.80 × 104 1 2.25 × 10−3 2 14 0.0001 0.02 3000 7 1.5 2.1 8 2.99 × 104 1 2.25 × 10−3 3 14 0.0001 0.02 3000 7 1.5 2.1 8 3.04 × 104 1 2.25 × 10−3 4 10 0.0001 0.02 4000 6 1.5 1.9 12 3.13 × 104 1 3.61 × 10−3 5 10 0.0001 0.02 4000 6 1.5 1.9 12 3.23 × 104 1 3.61 × 10−3 6 7 0.0001 0.02 3000 5 1.5 1.7 9 2.11 × 104 1 5.90 × 10−3 7 7 0.0001 0.02 2000 5 1.5 1.7 6 1.62 × 104 1 5.90 × 10−3 8 7 0.0001 0.02 2000 5 1.5 1.7 6 1.66 × 104 1 5.90 × 10−3 The first lateral canal 5–1 7 0.0001 0.02 2000 5 1.5 1.7 7 1.74 × 104 1 5.90 × 10−3 5–2 7 0.0001 0.02 2000 5 1.5 1.7 7 1.74 × 104 1 5.90 × 10−3 The second lateral canal 6–1 7 0.0001 0.02 2000 5 1.5 1.7 7 1.74 × 104 1 5.90 × 10−3 6–2 7 0.0001 0.02 2000 5 1.5 1.7 7 1.74 × 104 1 5.90 × 10−3 According to the engineering experience, the farmers or ditch riders always manipulated the gravity-based offtake gate according to the predefined gate opening-flow curve and water schedule. This operation implies the assumption that the water level at the downstream end of each canal pool is stable. And this is why keeping the distant downstream water level at setpoint as much as possible is always the control objective (Wahlin and Clemmens, 2006). The availability of a real system for control tests is often unusual. In order to perform more rigorous control tests, one alternative could be modelling the system with the Saint Venant equations (SVEs), which are widely accepted as a fairly accurate representation of physical reality. In the paper, the canal control simulation platform SCCS (Wang and Guan, 2011) installed on a 2.80 GHz Intel Xeon machine with 16 GB of ram running Windows 10 is used, on which the SVEs are resolved with the Preissmann four-point implicit difference scheme. The SCCS can simulate the hydraulic behavior of most irrigation canals, under steady or unsteady flow conditions, and has been applied and verified by previous studies (Liu et al., 2013, Zhong et al., 2020, Zhu et al., 2020). Including the heading gates of the two lateral canals, all check gates are formulated by Eq.(12) (Yeh et al., 1980) to calculate the flow rate of radial gates. Meanwhile, all gravity offtakes are governed by the sluice free flow formula during the unsteady flow process, see Eq.(13) (Li, 2006). In addition, the unsteady flow simulation is carried out with the computation time step Dt= 1 min. (12) (13) Where Q is the gate discharge, m3/s; Cd and μ are discharge coefficients; g is the acceleration of gravity, m/s2; E is the gate opening, m; B is the gate width, m; Hu and Hd are the upstream and downstream water depth of the gate, m; Au is the cross-sectional area of water upstream the gate, m2. 2.4. Controllers design On-demand operating method is used in this study, which provides high flexibility for the irrigation requirements and is suitable for the concept of online canal automation control. To design appropriate controllers for the BOCISs, centralized and distributed control architectures are adopted, respectively. Referring to (Wahlin and Clemmens, 2006), the CMPC controller is designed by modifying the state-space model, meaning that the offtake term is added or removed from the ID model of individual canal pool according to the network system structure. Care must be taken to assure that the hydraulics of every subsystem is properly described. Once the system structure is changed, the whole tedious modeling process needs to be redone. In contrast, the DMPC controller is much more flexible. The entire system is decomposed into three subsystems: the main canal, the first lateral canal, and the second lateral canal, see Fig. 3. Each subsystem is associated with a computing agent for local optimization. Agent 1 and Agent 2 are coupled by the discharge of the head gate of the first lateral canal while Agent 1 and Agent 3 are coupled by the discharge of the head gate of the second lateral canal. In other words, the head gate discharge of the lateral canal is supposed to be the offtake flow of the corresponding main canal pool. The basic controller configurations for the CMPC and DMPC controllers are the same. The sampling period Ts, which is also the control time interval, is set to 15 min. In the objective function, Eq.(3) or Eq.(6), the engineering tuning method of Q and R proposed by Zhong et al. (2020) is adopted since the objection functions of MPC and LQR are similar. Moreover, p and m are both set as 96 by trial-and-error, meaning that the prediction horizon and control horizon both are 24 h long. For removing the complex gate hydraulics for the control system, a master-slave control scheme is implemented. The master control refers to the DMPC or CMPC, in which every check gate is commanded to reach a new target flow every 15 min. The slave control refers to the local flow controller, manipulating the gate per 5 min to deliver the desired flow according to real-time hydraulic state. 2.5. Test scenarios Three test scenarios are set to compare the response capacities and control performance of CMPC and DMPC for the comprehensive evaluation of the designed controllers. Permanent flow exists in the main canal and the two lateral canals, except for the accident scenario, where the first lateral canal is closed for fault isolation. 2.5.1. Normal scenario Referring to the Test 2–1 proposed by ASCE, the offtakes in Pool 5–2 and Pool 6–2 begin to draw more water from T = 5 h to T = 6 h linearly, while each offtake in the main canal keeps the initial offtake flow, i.e. 1 m3/s, and the offtakes in Pool 5–1 and Pool 6–1 keep close overall process. More details are displayed in Table 2. This test scenario is used to compare the control effect and computational efficiency of both controllers. Table 2. Scheduled offtake flow changes and the offtake gate operations in the normal scenario. Canal system Pool Upstream initial flow (m3/s) Initial offtake flow (m3/s) Scheduled offtake flow changes from T = 5 h to T = 6 h (m3/s) Opening change of offtake gate from T = 5 h to T = 6 h (m) The main canal 1 11 1 \\ \\ 2 10 1 \\ \\ 3 9 1 \\ \\ 4 8 1 \\ \\ 5 7 1 \\ \\ 6 6 1 \\ \\ 7 5 1 \\ \\ 8 4 1 \\ \\ The first lateral canal 5–1 1 0 \\ \\ 5–2 1 1 +1.5 +0.54 The second lateral canal 6–1 1 0 \\ \\ 6–2 1 1 +1 +0.35 2.5.2. Water-deficient scenario With the same initial states of the normal scenario, there is an offtake flow oscillation in Pool 5–2 from T = 5 h to T = 9 h, see Fig. 4, and other offtakes remain unchanged. Noteworthy is there is a constant limitation on the water source. In other words, the inflow of the main canal keeps 11 m3/s, representing a water shortage scenario facing downstream water demand changes. This test scenario is designed to analyze the impacts of the disturbance of one subsystem on the other subsystems. The water scarcity may aggravate the water supply contradiction and highlight the superiority of the proposed DMPC controller. Download : Download high-res image (134KB) Download : Download full-size image Fig. 4. Scheduled offtake flow changes and the offtake gate operations in the water-deficient scenario. 2.5.3. Accident scenario With the same initial states of the normal scenario, there is a sudden accident in the first lateral canal at T = 5 h. Then all gates and offtakes in this branch canal need to be urgently closed for fault isolation, including the heading gate, i.e. the offtake gate of Pool 5. However, the main canal and the second lateral canal need to maintain normal operations and water delivery in this scenario. For the DMPC, due to its modularity, it is quick and convenient to disconnect the communication link between the first lateral canal and the main canal, highlighting the response capacities to deal with unconventional conditions. But it is much more complicated for the CMPC to handle the accident. For simplicity, once the sudden accident occurs, the fixed constraints are set for all the check gates in the first lateral canal to make them compulsory to close during the optimization, rather than redesigning the state space model of the CMPC. It is also necessary to revise the offtake schedules of the first lateral canal to consider the offtake closure. 2.6. Operational performance indicators Several control performance indicators are employed in the study. Firstly, a posteriori control cost Jcost (Sadowska et al., 2015) is used to generally appraise the off-farm management, see Eq.(14). The smaller Jcost is, the better the comprehensive control performance is. (14) where N is the number of total simulation steps; ek is the downstream water level deviation from setpoint, m; uk is the upstream flow change, representing the gate movement, m3/s. Then, PA states the adequacy of water delivery (Molden and Gates, 1990), see Eq.(15). The bigger PA is, the more adequately the water is supplied to irrigate crops. (15) where Nofftake is the number of offtakes in the canal pool; Qd,i is the actual discharge delivered to the i-th offtake, m3/s; Qr,i is water demand by the i-th offtake, m3/s. In the results analysis of the water-deficient and accident test scenarios, CVT and Hovershoot are used to describe the degree of water level oscillations and overshoots during the control simulation process, see (16), (17). CVT is the temporal coefficient of variation of the water level deviation. As the value of CVT approaches zero, the water level control is becoming more smooth and more stable over time. (16) (17) where and are the standard deviation and mean value of the water level deviation , . 3. Results 3.1. Normal scenario The control simulation results with two control architectures are shown in Fig. 5. Comparing the control results of the same main canal by the CMPC with that by MPC-B, a centralized model predictive controller proposed by Horváth et al. (2015), it can be seen that the water level fluctuations are similar. Both controllers began to work before the demand changes, and the water was stored in pool 5 and pool 6 in advance for future water demands, showing the superiority of the MPC algorithm. Download : Download high-res image (1MB) Download : Download full-size image Fig. 5. Water depth response process with both controllers in the normal scenario: (a) subsystem 1, the main canal; (b) subsystem 2, the first lateral canal; (3) subsystem 3, the second lateral canal. It is satisfying to see that both controllers can effectively control the branching canal system. More specifically, it is plotted in Fig. 5(a) that DMPC is superior to CMPC in controlling the main canal, except for Pool 1. The CMPC shows more aggressive features, resulting in greater water level deviation and oscillation. In contrast, the control results on the two lateral canals are the opposite, and CMPC shows better control effects. But on the whole, the control performances of the entire system are similar, see Table 3. Although the CMPC has better control results than the DMPC on Jcost and PA because of the full knowledge of the BOCIS, the degradation is less than 0.35 % and can be negligible. It means that the designed DMPC controller is comparable to the CMPC controller proposed by Wahlin and Clemmens (2006) in control performance. Table 3. The calculated performance indicators in the normal scenario. Operational performance indicators Controllers Degradation by DMPC CMPC DMPC Jcost 146.26 146.73 0.32 % PA 0.9986 0.9981 0.05 % 3.2. Water-deficient scenario The global communication and centralized optimization of CMPC contributes to better global control performance than DMPC. In this control architecture, the system states in all subsystems are closely linked. Any disturbance at any position is able to immediately affect all control structures to take actions. But that is also why the influence of local disturbance or failure is hard to be limited in just one subsystem. The control results of the main canal and the second lateral canal are presented in Fig. 6. It can be seen that the offtake disturbance in the first lateral canal has impacts on the other parts whether the controller is designed with centralized or distributed architecture. However, CMPC is much more aggressive, meaning that the disturbance of one subsystem has greater impacts on the neighboring subsystems under this control scheme. Obvious water level oscillations occurred in Pool 2 ∼ Pool 6, and bigger water level deviations than the DMPC are observed. Nonetheless, such influence could be weakened by the communication and coordination process of the distributed algorithms. In this way, the proposed DMPC controller shows powerful robustness, interference immunity, and fault tolerance. The results of Fig. 7(a) display that, compared with CMPC, the highest improvements on water level oscillations and overshoots by the DMPC can reach 36.4 % and 28.1 % for the adjacent subsystems, respectively. Download : Download high-res image (970KB) Download : Download full-size image Fig. 6. Water depth response process with both controllers in the water-deficient scenario: (a) subsystem 1, the main canal; (b) subsystem 3, the second lateral canal. Download : Download high-res image (232KB) Download : Download full-size image Fig. 7. The improvement of DMPC on water level oscillations and overshoots compared to CMPC: (a) the water-deficient scenario; (b) the accident scenario. 3.3. Accident scenario The accident responses of the controllers are provided in Fig. 8. The CMPC behaved more aggressively than the DMPC again. Obvious water level oscillations are observed in Pool 2 ∼ Pool 6, and bigger water level deviations resulted in Pool 6 ∼Pool 8, as well as the second lateral canal. Fig. 7(b) displays that the DMPC helps the improvements in water level oscillations and overshoots up to 20.3 % and 52.1 %, respectively. It means that the designed DMPC controller is more outstanding in the face of sudden accidents, not only being able to deal with the accidents more quickly and easily but also controlling the hydraulic response in adjacent subsystems more smoothly. Download : Download high-res image (1MB) Download : Download full-size image Fig. 8. Water depth response process with both controllers in the accident scenario: (a) subsystem 1, the main canal; (b) subsystem 3, the second lateral canal. Furthermore, the computing efficiency of the CMPC may be relatively low, though the automatic control under sudden accident scenarios is completed. The first lateral canal has not been removed from the state space, meaning that some computing resources still have to be allocated for this part during optimization. If the scale of the isolated subsystem is large, the unnecessary waste of computing resources would be considerable. Moreover, the prediction results of this subsystem also have some impact on the other subsystems that need proper functioning. 4. Discussion The results of the normal scenario show that the designed ADMM-based DMPC controller is comparable to the centralized controller in control performance. Nonetheless, there is an unexpected result that the computational efficiency of the CMPC is much higher than the DMPC. In this test scenario, the CMPC solves the optimization problem at an average rate of 1.3 s per control cycle, while the DMPC is 4.6 s. It is interesting and worth pondering. Similar results were observed by Tian (2015) and Burk et al. (2019). There are some possible explanations. Firstly, the scale of the current test case and the number of agents are small. Although a systemwide optimization problem has been divided into three smaller problems which were solved with parallel computing technology, the time cost required for the communication and coordination by the DMPC is relatively higher. By contrast, the global optimization of CMPC is more efficient. As the system scale increases and more subsystems (or agents) are taken into account, the computational requirements of the centralized solution would increase heavily but the computing efficiency of the DMPC stays approximately constant (Burk et al., 2019). Afterward, during the numerical experiments, the communication and coordination process is fully demonstrated in the distributed algorithm, but the communication network-induced issues that prevent the CMPC from functioning properly are hard to be considered, such as the communication delay and packet loss in a large-scale communication network. Then, the ADMM algorithm is often slower than other distributed algorithms, but an acceptable result can be obtained in fewer iterations (23–26 iterations in this study) with medium convergence precision. Lastly, the inconsistency of subsystem scale may lead to a decrease in computation efficiency, but it is common in practice. In every iteration, the small optimization problems associated with the lateral canals have to wait for the results of the big one of the main canal. The asynchronous ADMM algorithm may be a solution (Dunham et al., 2020). Fortunately, benefiting from the big delay nature of open canals, it is acceptable to implement more complex control algorithms even with moderate computing capabilities (Alvarez et al., 2013, Conde et al., 2021). Though DMPC takes 4.6 s to solve the optimization problem each control cycle, nearly 3.5 times slower than CMPC, it is still much less than the control interval of 15 min. In other words, the losses of control performance and computational speed caused by the designed DMPC controller could be ignored for BOCISs, and the practical applications are promisingly feasible. The DMPC still has greater potential advantages than the CMPC, see the Introduction and Appendix. The response-ability in a sudden accident is also a compelling factor for the comprehensive controller evaluation and a fundamental guarantee of system security. In this paper, a simplified method is adopted for the CMPC to implement fault isolation. A more common way is redesigning the controller for better control results. The centralized state space and the ID model structure of Pool 5 are modified to remove the first lateral canal. However, this method is cumbersome, requiring the presence of professional operators. The fault isolation may not be completed timely so that the accident risk of the first lateral canal is further increased. Moreover, the state space model needs to be modified again when the accident subsystem is put back into service. In contrast, it is quick and convenient for the DMPC to disconnect or reconnect the subsystem, highlighting the motivation for distributed control study. The inherent modularity nature of the distributed control architecture determines the scalability of the proposed DMPC framework. If the system construction and scale need to be changed, it is flexible to add or delete subsystems and communication connections. Therefore, it is easily scalable to a large-scale irrigation canal network with a complex tree topology, though the proposed distributed controller is examined on a simplified example with only two lateral canals. On the other hand, the operation type of the canal network determines the required automation level. That means the number of branches irrigated simultaneously, the permanent flow in the main canal, and the circulation of irrigation in some canals affect the controller design. In fact, the operation type changes over the lifecycle of the canal operation system as the actual condition changes. It is a big challenge for canal automation design. Decentralized control (e.g. the PI control) is feasible for its high flexibility but may result in poor performance, especially for large-scale systems. Centralized control (e.g. the CMPC) gets the global optimal control performance, whereas, once the operation type changes, the whole controller needs to be redesigned. For these reasons, the distributed control of the canal network has a strong practical significance and research value. In this way, the level of automation technology required for the canal network could be minimized and good control performance is guaranteed, meaning that control costs may be significantly reduced in the future. 5. Conclusions The automatic control of branching open canal irrigation systems (BOCISs) is of great significance for precision irrigation and sustainable development of agricultural water. For the first time in the study, a distributed model predictive control (DMPC) algorithm based on the alternating direction method of multipliers (ADMM) is innovatively proposed for the BOCISs. It is compared with the centralized model predictive control (CMPC) developed by Wahlin and Clemmens (2006) on a simplified example. Both the CMPC and proposed DMPC were able to take actions before offtake changes and successfully bring the water level back. On the one hand, due to the full knowledge of the system, the CMPC performs better than the DMPC. But the degradation of the latter is less than 0.35 % under the normal scenario, showing that the proposed DMPC is comparable to the CMPC. On the other hand, the influence of the violent disturbance in one subsystem on the neighboring subsystem by CMPC is more aggressive than that by the proposed DMPC. With the help of the communication and coordination process of DMPC, the improvements in water level oscillations and overshoots in the adjacent system pools can reach 36.4 % and 28.1 % under the water-deficient scenario, respectively. In the face of a sudden accident, the proposed DMPC shows promising superiority in executing fault isolation over the CMPC. Benefiting from the outstanding modularization nature of distributed control architecture and the powerful scalability of the ADMM, it is more convenient and timely for the DMPC to disconnect the accident subsystem. The improvements on water level oscillations and overshoots can reach 20.3 % and 52.1 % in the other subsystems which need normal water delivery. For mitigating crop yield reduction and increasing the irrigation benefits during times of water scarcity, future research is required to consider the diversity of water supply objects and control objectives among different canal subsystems by the proposed distributed control framework. Acknowledgments This work was financially supported by the National Natural Science Foundation of China (Nos. 51979202 and Nos. 51009108). We are grateful to the editors and the anonymous reviewers. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Appendix Control architectures Automatic controls can be organized in a variety of ways. Centralized control, decentralized control, and distributed control are common control architectures, and the former two are applied more in the literatures. Centralized control architecture In theory, CMPC can reach the globally optimal solution, better than the other control architectures. However, MPC is a technique with strong computational and communication requirements that hinder its successful application to large-scale OCIS in a centralized way. As the size and complexity of the system grow, more system states are taken into account inevitably. Accordingly, the size of the state space grows exponentially. Even though computational power has increased dramatically with the development of computer technologies, the optimization problem may still not be solved fast enough for online control. Considering systems that spread over large geographical areas, the communication network-induced issues are also points of attention, like time delay or packet loss of transmitted information, competition of multiple communication nodes, errors resulting from signal quantization, available bandwidth, and information security. Moreover, sometimes different sections of the canal network are managed by different control entities, who may not be timely to or willing to share information. The above issues lead to expensive communication costs and maintenance difficulties. Decentralized control architecture In a decentralized control architecture, only local information of the subsystem is used with no required communication among each local controller. Compared with CMPC, the decentralized MPC has the lowest computational and communication requirements with strong interference immunity and scalability. However, there is always a significant loss in control performance for the ignorance of coupling effects among interconnected subsystems. Every local controller takes into account the influence of neighboring subsystems only by responding to the dynamic changes of the local subsystem with a time delay. In fact, the individual local controllers are always fighting each other, even though they have no intention to do so. As a consequence, more hydraulic oscillations are generated and more energy than necessary is expended. Distributed control architecture The distributed control architecture is a combination of the above two control architecture. Compared with the CMPC, DMPC has important advantages that justify its application. Firstly, the computational requirements are much lower than CMPC because a complex problem is substituted by several smaller problems. The need for communication shifts from global communication to information exchange between locally adjacent controllers. In this way, the communication network-induced issues are much easier to solve and the coupling effects among different subsystems can also be given consideration. Benefiting from the inherent modularity of the DMPC, the system maintenance and the possible expansions of the control system are simplified. Moreover, the effect of a possible disturbance or failure on the overall system is weakened because of the coordination or negotiation process. Nevertheless, because each agent does not have a global vision of the entire system, the loss of control performance in comparison with the CMPC becomes the main drawback of the DMPC. This loss depends on the degree of interaction between the neighboring subsystems and the coordination mechanisms between the agents. Consequently, a reasonable trade-off between control performance and the cost of communication and coordination is pursued to reach a cooperative solution. Data availability Data will be made available on request. References Alvarez et al., 2013 A. Alvarez, M.A. Ridao, D.R. Ramirez, L. Sanchez Constrained predictive control of an irrigation canal J. Irrig. Drain. Eng., 139 (10) (2013), pp. 841-854, 10.1061/(ASCE)IR.1943-4774.0000619 View in ScopusGoogle Scholar Avargani et al., 2022 H.K. Avargani, S.M.H. Shahdany, K. Kamrani, J.M. Maestre, S.E.H. Garmdareh, A. Liaghat Prioritization of surface water distribution in irrigation districts to mitigate crop yield reduction during water scarcity Agric. Water Manag., 269 (2022), Article 107653, 10.1016/j.agwat.2022.107653 View PDFView articleView in ScopusGoogle Scholar Aydin et al., 2022 B.E. Aydin, G.H.P. Oude Essink, J.R. Delsman, N. van de Giesen, E. Abraham Nonlinear model predictive control of salinity and water level in polder networks: case study of Lissertocht catchment Agric. Water Manag., 264 (2022), Article 107502, 10.1016/j.agwat.2022.107502 View PDFView articleView in ScopusGoogle Scholar Bai et al., 2021 T. Bai, S. Li, Y. Zou Distributed MPC for reconfigurable architecture systems via alternating direction method of multipliers IEEE-CAA J. Autom., 8 (7) (2021), pp. 1336-1344, 10.1109/JAS.2020.1003195 View in ScopusGoogle Scholar Breckpot et al., 2013 M. Breckpot, O.M. Agudelo, B. De Moor Flood control with model predictive control for river systems with water reservoirs J. Irrig. Drain. Eng., 139 (7) (2013), pp. 532-541, 10.1061/(ASCE)IR.1943-4774.0000577 View in ScopusGoogle Scholar Burk et al., 2019 D. Burk, A. Völz, K. Graichen Towards a modular framework for distributed model predictive control of nonlinear Neighbor-Affine systems IEEE 58th Conference on Decision and Control (CDC), Nice, France (2019), 10.1109/CDC40024.2019.9029800 Google Scholar Clemmens et al., 1998 A.J. Clemmens, T.F. Kacerek, B. Grawitz, W. Schuurmans Test cases for canal control algorithms J. Irrig. Drain. Eng., 124 (1) (1998), pp. 23-30, 10.1061/(asce)0733-9437(1998)124:1(23) View in ScopusGoogle Scholar Conde et al., 2021 G. Conde, N. Quijano, C. Ocampo-Martinez Modeling and control in open-channel irrigation systems: a review Annu. Rev. Control., 51 (5) (2021), pp. 153-171, 10.1016/j.arcontrol.2021.01.003 View PDFView articleView in ScopusGoogle Scholar Dunham et al., 2020 W. Dunham, B. Hencey, A.R. Girard, I. Kolmanovsky Distributed model predictive control for more electric aircraft subsystems operating at multiple time scales IEEE Trans. Control Syst. Technol., 28 (6) (2020), pp. 2177-2190, 10.1109/TCST.2019.2932654 View in ScopusGoogle Scholar Elfawal-Mansour et al., 2000 H. Elfawal-Mansour, D. Georges, N. Ohnishi Optimal control of an open channel irrigation system based on nonlinear models Tencon Proceedings., Kuala Lumpur, Malaysia (2000), 10.1109/TENCON.2000.892279 Google Scholar Gabay and Mercier, 1976 D. Gabay, B. Mercier A dual algorithm for the solution of nonlinear variational problems via finite element approximation Comput. Math. Appl., 2 (1) (1976), pp. 17-40, 10.1016/0898-1221(76)90003-1 View PDFView articleView in ScopusGoogle Scholar Ghadimi et al., 2015 E. Ghadimi, A. Teixeira, I. Shames, M. Johansson Optimal parameter selection for the alternating direction method of multipliers (ADMM): quadratic problems IEEE Trans. Autom. Control., 60 (3) (2015), pp. 644-658, 10.1109/TAC.2014.2354892 View in ScopusGoogle Scholar Horváth et al., 2015 K. Horváth, E. Galvis, M.G. Valentín, J. Rodellar New offset-free method for model predictive control of open channels Control Eng. Pract., 41 (2015), pp. 13-25, 10.1016/j.conengprac.2015.04.002 View PDFView articleView in ScopusGoogle Scholar Kordestani et al., 2021 M. Kordestani, A.A. Safavi, M. Saif Recent survey of large-scale systems: architectures, controller strategies, and industrial applications IEEE Syst. J., 15 (4) (2021), pp. 5440-5453, 10.1109/JSYST.2020.3048951 View in ScopusGoogle Scholar Lemos and Pinto, 2012 J.M. Lemos, L.F. Pinto Distributed linear-quadratic control of serially chained systems: application to a water delivery canal IEEE Control Syst. Mag., 32 (6) (2012), pp. 26-38, 10.1109/MCS.2012.2214126 View in ScopusGoogle Scholar Li et al., 2020 S.K. Li, L.X. Yang, Z.Y. Gao Distributed optimal control for multiple high-speed train movement: an alternating direction method of multipliers Automatica., 112 (2020), Article 108646, 10.1016/j.automatica.2019.108646 View PDFView articleView in ScopusGoogle Scholar Li, 2006 W. Li Hydraulic calculation manual (2nd ed.,), China Water & Power Press, Beijing China (2006) Google Scholar Liu et al., 2013 G.Q. Liu, G.H. Guan, C.D. Wang Transition mode of long distance water delivery project before freezing in winter J. Hydroinformatics., 15 (15) (2013), pp. 306-320, 10.2166/hydro.2012.167 View in ScopusGoogle Scholar Lozano et al., 2010 D. Lozano, C. Arranja, M. Rijo, L. Mateos Simulation of automatic control of an irrigation canal Agric. Water Manag., 97 (1) (2010), pp. 91-100, 10.1016/j.agwat.2009.08.016 View PDFView articleView in ScopusGoogle Scholar Maestre and Negenborn, 2013 J.M. Maestre, R.R. Negenborn Distributed model predictive control made easy (1st ed.,), Springer, London (2013) Google Scholar Maestre et al., 2015 J.M. Maestre, M.A. Ridao, A. Kozma, C. Savorgnan, M. Diehl, M.D. Doan, A. Sadowska, T. Keviczky, B. De Schutter, H. Scheu, W. Marquardt, F. Valencia, J. Espinosa A comparison of distributed MPC schemes on a hydro-power plant benchmark Optim. Contr. Appl. Met, 36 (3) (2015), pp. 306-332, 10.1002/oca.2154 View in ScopusGoogle Scholar Maestre et al., 2021 M. Maestre, L.R. Francisco, F.J. Muros, O.M. Carlos Modular feedback control of networked systems by clustering: a drinking water network case study Processes., 9 (2) (2021), pp. 1-18, 10.3390/pr9020389 View in ScopusGoogle Scholar Molden and Gates, 1990 D.J. Molden, T.K. Gates Performance measures for evaluation of irrigation-water-delivery systems J. Irrig. Drain. Eng., 116 (6) (1990), pp. 804-823, 10.1061/(ASCE)0733-9437(1990)116:6(804) View in ScopusGoogle Scholar Overloop, 2006 Overloop, P.J.V. 2006. Model predictive control on open water systems. Delft University of Technology, Netherlands. Google Scholar Sadowska et al., 2015 A. Sadowska, B.D. Schutter, P.J.V. Overloop Delivery-oriented hierarchical predictive control of an irrigation canal: event-driven versus time-driven approaches IEEE Trans. Control Syst. Technol., 23 (5) (2015), pp. 1701-1716, 10.1109/TCST.2014.2381600 View in ScopusGoogle Scholar Schuurmans et al., 1995 J. Schuurmans, O.H. Bosgra, R. Brouwer Open-channel flow model approximation for controller design Appl. Math. Model., 19 (9) (1995), pp. 525-530, 10.1016/0307-904X(95)00053-M View PDFView articleView in ScopusGoogle Scholar Segovia et al., 2019 P. Segovia, L. Rajaoarisoa, F. Nejjari, E. Duviella, V. Puig Model predictive control and moving horizon estimation for water level regulation in inland waterways J. Process Control., 76 (2019), pp. 1-14, 10.1016/j.jprocont.2018.12.017 View PDFView articleView in ScopusGoogle Scholar Shi et al., 2021 Y. Shi, H.D. Tuan, A.V. Savkin, C.T. Lin, J.G. Zhu, H.V. Poor Distributed model predictive control for joint coordination of demand response and optimal power flow with renewables in smart grid Appl. Energy., 290 (2021), Article 116701, 10.1016/j.apenergy.2021.116701 View PDFView articleView in ScopusGoogle Scholar Stephen et al., 2011 B. Stephen, P. Neal, C. Eric, P. Borja, E. Jonathan Distributed optimization and statistical learning via the alternating direction method of multipliers Found. Trends Mach. Learn., 3 (1) (2011), pp. 1-122, 10.1561/2200000016 Google Scholar Sutrisno and Wijayanti, 2012 Salmah Sutrisno, I.E. Wijayanti Distributed model predictive control and application to irrigation canal IEEE Conference on Control, Systems & Industrial Informatics, Bandung, Indonesia (2012), 10.1109/CCSII.2012.6470486 Google Scholar Tang and Daoutidis, 2019 W.T. Tang, P. Daoutidis Distributed control and optimization of process system networks: a review and perspective Chin. J. Chem. Eng., 27 (7) (2019), pp. 1461-1473, 10.1016/j.cjche.2018.08.027 View PDFView articleView in ScopusGoogle Scholar Tariq et al., 2012 M.U. Tariq, H.A. Nasir, A. Muhammad, M. Wolf Model-driven performance analysis of large scale irrigation networks IEEE/ACM Third International Conference on Cyber-physical Systems, Beijing, China (2012), 10.1109/ICCPS.2012.23 Google Scholar Teixeira et al., 2016 A. Teixeira, E. Ghadimi, I. Shames, H. Sandberg, M. Johansson The ADMM algorithm for distributed quadratic problems: parameter selection and constraint preconditioning IEEE Trans. Signal Process., 64 (2) (2016), pp. 290-305, 10.1109/TSP.2015.2480041 View in ScopusGoogle Scholar Tian, 2015 Tian, X. 2015. Model predictive control for operational water management a case study of the dutch water system. Delft University of Technology, Netherlands. Google Scholar Wahlin and Clemmens, 2006 B.T. Wahlin, A.J. Clemmens Automatic downstream water-level feedback control of branching canal networks: theory J. Irrig. Drain. Eng., 132 (3) (2006), pp. 198-207, 10.1061/(ASCE)0733-9437(2006)132:3(198) View in ScopusGoogle Scholar Wang and Guan, 2011 Wang, C.D., Guan, G.H. Simulation and control of canal system. China: 2011SR034392, 2011. Google Scholar Xu and Schwanenberg, 2017 M. Xu, D. Schwanenberg Sequential and simultaneous model predictive control of a drainage canal network using an implicit diffusive wave model J. Irrig. Drain. Eng., 143 (3) (2017), pp. 1-7, 10.1061/(asce)ir.1943-4774.0001082 Google Scholar Yeh et al., 1980 W.G. Yeh, L. Becker, D. Toy Central Arizona Project: operations model J. Water Res. Pl-ASCE, 106 (2) (1980), pp. 521-540 CrossRefView in ScopusGoogle Scholar Zhang et al., 2015 R.C. Zhang, A.D. Liu, L. Yu, W.A. Zhang Distributed model predictive control based on Nash Optimality for large scale irrigation systems IFAC-PapersOnLine (2015), 10.1016/j.ifacol.2015.09.025 Google Scholar Zheng et al., 2018 H. Zheng, R.R. Negenborn, G. Lodewijks Robust distributed predictive control of waterborne AGVs—a cooperative and cost-effective approach IEEE T. Cybern., 48 (8) (2018), pp. 2449-2461, 10.1109/TCYB.2017.2740558 View in ScopusGoogle Scholar Zhong et al., 2020 K. Zhong, G.H. Guan, X. Tian, J.M. Maestre, Z.H. Mao Evaluating optimization objectives in linear quadratic control applied to open canal automation J. Water Resour. Plann. Manag., 146 (11) (2020), p. 04020087, 10.1061/(ASCE)WR.1943-5452.0001286 View in ScopusGoogle Scholar Zhong, 2016 Zhong, L. 2016. Channel modeling of control based on parameter identification case from Zhanghe Irrigation District. Wuhan University, Wuhan. Google Scholar Zhu et al., 2020 Z.L. Zhu, G.H. Guan, Z.H. Mao, K. Wang, S.X. Gu, G. Chen Application of model predictive control for large-scale inverted siphon in water distribution system in the case of emergency operation Water., 12 (10) (2020), p. 2733, 10.3390/w12102733 View in ScopusGoogle Scholar Cited by (2) Observer-based event-triggered distributed model predictive control for a class of nonlinear interconnected systems 2024, International Journal of Robust and Nonlinear Control Application of Hydraulic Sensitivity Indicators in Improving Canal Control Capabilities for Irrigation Systems 2024, Water Resources Management © 2023 The Authors. Published by Elsevier B.V. Recommended articles High-low seedbed cultivation drives the efficient utilization of key production resources and the improvement of wheat productivity in the North China Plain Agricultural Water Management, Volume 285, 2023, Article 108357 Junming Liu, …, Aiwang Duan View PDF Improvement and validation of a decision support system to maintain optimal nutrient levels in crops grown in closed-loop soilless systems Agricultural Water Management, Volume 285, 2023, Article 108373 Dimitrios Savvas, …, Georgia Ntatsi View PDF Reducing nutrient imbalance in recirculating drainage solution of stone wool grown tomato Agricultural Water Management, Volume 285, 2023, Article 108360 Chris Blok, …, Tommaso Barbagli View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 2 Captures Readers: 9 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply."

Paper 4:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: 
  Extract 2: 
  Limitations: >
  Relevance Evaluation: 
  Relevance Score: 0.9069707158593081
  Inline Citation: >
  Explanation: The paper aims to evaluate the suitability of automated irrigation systems that integrate IoT and machine learning for real-time irrigation management. The specific point this response focuses on is the relevance of the paper to different components of the irrigation management pipeline. Specifically, the paper is relevant to the data collection and transmission component of the pipeline, as it contributes to addressing the global food challenge by developing new methods for data collection and transmission in automated irrigation systems.

The paper presents a novel approach that combines IoT sensors with machine learning algorithms to optimize water usage in precision agriculture. This approach involves collecting data from sensors deployed in the field, transmitting the data to a cloud platform, and using machine learning algorithms to analyze the data and make informed decisions about irrigation. By optimizing water usage, the approach can contribute to addressing the global food challenge by increasing crop yields and reducing water consumption.

The paper is particularly relevant to the data collection and transmission component of the irrigation management pipeline, as it focuses on developing new methods for collecting and transmitting data from sensors deployed in the field. The data collected by these sensors can be used to monitor soil moisture levels, crop health, and other factors that are critical for making informed decisions about irrigation. By providing new methods for collecting and transmitting data, the paper can help to improve the efficiency and effectiveness of automated irrigation systems.

In addition to the data collection and transmission component, the paper is also relevant to other components of the irrigation management pipeline, such as data analysis and decision-making. The data collected from sensors can be used to train machine learning algorithms that can make informed decisions about irrigation. These algorithms can be used to adjust irrigation schedules, identify leaks, and diagnose problems with irrigation systems. By providing new methods for data analysis and decision-making, the paper can help to improve the overall efficiency and effectiveness of automated irrigation systems.

Overall, the paper is a valuable contribution to the field of automated irrigation systems and has the potential to make a significant impact on the global food challenge. The paper's focus on developing new methods for data collection and transmission is particularly relevant to the data collection and transmission component of the irrigation management pipeline, and the paper's contributions can help to improve the efficiency and effectiveness of automated irrigation systems.

 Full Text: >
"Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Keywords 1. Introduction 2. Materials and methods 3. Results and discussion 4. Conclusions Authors' contributions Funding information Declaration of competing interest Acknowledgment Appendix A. Supplementary data Data availability References Show full outline Cited by (6) Figures (10) Show 4 more figures Tables (5) Table 1 Table 2 Table 3 Table 4 Table 5 Extras (1) Multimedia component 1 Environmental Research Volume 234, 1 October 2023, 116509 Fuzzy logic, geostatistics, and multiple linear models to evaluate irrigation metrics and their influencing factors in a drought-prone agricultural region Author links open overlay panel S.M. Rabbi Al Zihad a, Abu Reza Md Towfiqul Islam a b, Md Abu Bakar Siddique c, Md Yousuf Mia a, Md Saiful Islam d, Md Aminul Islam a, A.B.M. Mainul Bari e, Md Bodrud-Doza f, Sobhy M. Yakout g, Venkatramanan Senapathi h, Sumanta Chatterjee i j Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.envres.2023.116509 Get rights and content Highlights • Fuzzy logic-derived irrigation index was used to identify suitable agriculture regions. • Most of the irrigation metrics have moderate to low spatial dependence. • Na+, Ca2+, Cl−, K+, and HCO3− in water increase with decreasing temperature. • SAR (0.66), KR (0.74), and PI (0.84) were the primary key parameters influencing EC. Abstract The quality of water used for irrigation is one of the major threats to maintaining the long-term sustainability of agricultural practices. Although some studies have addressed the suitability of irrigation water in different parts of Bangladesh, the irrigation water quality in the drought-prone region has yet to be thoroughly studied using integrated novel approaches. This study aims to assess the suitability of irrigation water in the drought-prone agricultural region of Bangladesh using traditional irrigation metrics such as sodium percentage (NA%), magnesium adsorption ratio (MAR), Kelley's ratio (KR), sodium adsorption ratio (SAR), total hardness (TH), permeability index (PI), and soluble sodium percentage (SSP), along with novel irrigation indices such as irrigation water quality index (IWQI) and fuzzy irrigation water quality index (FIWQI). Thirty-eight water samples were taken from tube wells, river systems, streamlets, and canals in agricultural areas, then analyzed for cations and anions. The multiple linear regression model predicted that SAR (0.66), KR (0.74), and PI (0.84) were the primary important elements influencing electrical conductivity (EC). Based on the IWQI, all water samples fall into the “suitable” category for irrigation. The FIWQI suggests that 75% of the groundwater and 100% of the surface water samples are excellent for irrigation. The semivariogram model indicates that most irrigation metrics have moderate to low spatial dependence, suggesting strong agricultural and rural influence. Redundancy analysis shows that Na+, Ca2+, Cl−, K+, and HCO3− in water increase with decreasing temperature. Surface water and some groundwater in the southwestern and southeastern parts are suitable for irrigation. The northern and central parts are less suitable for agriculture because of elevated K+ and Mg2+ levels. This study determines irrigation metrics for regional water management and pinpoints suitable areas in the drought-prone region, which provides a comprehensive understanding of sustainable water management and actionable steps for stakeholders and decision-makers. Previous article in issue Next article in issue Keywords Sustainable water managementFuzzy logicChemometric toolGeostatisticalRDANorthern Bangladesh 1. Introduction Water scarcity is a growing problem for agriculture practices worldwide, especially in drought-prone areas. This threatens food security and agricultural crop yields (Islam et al., 2022). The quality of groundwater and surface water is important for growing crops and maintaining soil health (Rahman et al., 2017; Ahmed et al., 2020b). This is because both surface and groundwater are the primary water sources for agriculture production in many parts of the world, including Bangladesh. In recent times, numerous human-inducing factors such as unplanned urbanization, industrialization, increasing application of chemical fertilizers, herbicides, pesticides, and insecticides, and residential and commercial consumption of water have had a significant impact on both surface and groundwater quality in Bangladesh and the globe (Ahmed et al., 2020a; Elsayed et al., 2020; Masoud et al., 2022; Mia et al., 2023). Previous studies have identified several natural factors that have an impact on water quality deterioration, such as evaporation of water, especially surface water, weathering of rocks and minerals, exchange of various ions through the water system, and seawater intrusion (Li et al., 2019; Elsayed et al., 2020; Masoud et al., 2022; Eid et al., 2023). The irrigation water quality significantly influences soil salinization, soil fertility and productivity reduction, and health risks (Mikunthan et al., 2010; Prakash et al., 2020; Gaagai et al., 2023). On the one hand, excessive groundwater withdrawals meet the demand for water consumption for large populations. On the other hand, extreme salinity, flash flooding, and brackish water are the leading factors that are continuously deteriorating the quality of irrigation water (Gaagai et al., 2023; Rao et al., 2021; Ravindra et al., 2022; Shammi et al., 2023). In addition, persistent toxic chemicals can contaminate the groundwater and surface water, reducing water quality. Therefore, continuous surveillance of both surface and groundwater using credible water valuation techniques is essential to mitigate adverse effects on irrigation water resources and their sustainable management (Singh et al., 2020; Egbueri, 2022; Ibrahim et al., 2023; Al-Mashreki et al., 2023; Gad et al., 2023). Irrigation metrics measure how well an irrigation system works and show how much water plants need. They are critical for determining the optimal irrigation schedule and reducing water waste. Selecting an appropriate irrigation index depends on several factors, including climatic conditions, crop type, and soil type. Previous studies have used various indexes to evaluate the quality of groundwater and surface water for irrigation purposes (Elsayed et al., 2020; Mia et al., 2023; Eid et al., 2023; Gaagai et al., 2023; Siddique et al., 2022). Plenty of research has been done to understand the feasibility of water for irrigation using geographic information system (GIS) methods (Table S1). Regardless of location, lithology, landscape, or climate, the analysis of this research functioned as a foundation for developing the variables, understanding the importance of these generated variables, and selecting the quality of irrigation water. Existing mathematical techniques of hydrochemistry evaluations of water quality in actual time and on a large scale are limited; there is an essential need for precise, realistic, speedy, and low-cost measurement methods. These methodologies are helpful to the decision-makers to establish a simple indicator that can critically and methodically evaluate groundwater quality (Krishna Kumar et al., 2015; Masoud et al., 2022). Irrigation water quality (IWQ) is routinely analyzed using a variety of irrigation water quality indices (IWQIs) and parameters based on the criteria set by the Food and Agriculture Organization (FAO) (Ayers and Westcot, 1985). The literature review (Table S1) also found that numerous studies have used multiple IWQIs such as sodium percentage (NA%), sodium adsorption ratio (SAR), magnesium adsorption ratio (MAR), potential salinity (PS), residual sodium carbonate (RSC), Kelley's ratio (KR), total dissolved solids (TDS), total hardness (TH), and permeability index (PI) to evaluate water quality for agricultural purposes (Abbasnia et al., 2019; Aravinthasamy et al., 2020; Panneerselvam et al., 2021; Rao et al., 2021; Gharibi et al., 2019; Masoud et al., 2022). Horton (1965) first combines many water-related factors into a single value to assess water quality. Later, many scholars created combined water quality indices to determine the suitability of groundwater and surface water for irrigation purposes, industrial usage, and biodiversity conservation (Gad et al., 2021; Khadr et al., 2021). To obtain an actual outcome from this qualitative assessment approach, expert knowledge in allocating variable weights to calculate the water quality index score is required, which, in some cases, creates difficulties and faces a significant challenge now a day. Therefore, implementing a viable and cost-effective water quality assessment approach is critical to get the reliability of water quality data. Geostatistics is a statistical method to analyze and interpolate spatial data on soil and water properties for sustainable irrigation water management (Chatterjee et al., 2021). Khadr et al. (2021), used geostatistics to analyze the spatiotemporal variability of soil water content for irrigation management and water-saving practices in a drought-prone region in Pakistan. In addition, many geospatial techniques have been used to describe the spatial distribution and analysis of groundwater and surface water quality (Chidambaram et al., 2022; Cordier et al., 2021; Kumar et al., 2019). In addition, remote sensing and geospatial techniques have recently gained increasing attention in the assessment of irrigation indices and water use in agriculture (Chatterjee et al., 2021). Fuzzy logic is a mathematical tool for dealing with uncertainty and imprecision in data (Karmaker et al., 2023). It is widely used in agricultural research for decision-making processes, especially water management (Oladipo et al., 2020). Environmental problems are now solved using fuzzy set theory. Recently, fuzzy logic has been used for the water quality index (WQI) because it improves the accuracy and precision of criteria for decision-making (Dhaoui et al., 2022; Venkatramanan et al., 2015; Mckone and Deshpande, 2005). GIS uses categorization with fuzzy logic to evaluate water quality. Fuzzy logic and GIS technologies improve descriptions and assessments of natural variations (Venkatramanan et al., 2017; Anand and Karunanidhi, 2020; Ahmed et al., 2020a; Brahim et al., 2021) and their combined approach provides a robust technique to assess water quality even in limited field observations (Yanar and &Akyürek, 2006; Tsiko and Haile, 2011; Biwas and Nahar, 2019; Ahmed et al., 2020a). Prior studies have ignored multivariate statistical methods due to study constraints and technical challenges and preferred GIS, fuzzy logic, and different metrics for sustainable water quality estimation. Given the aforementioned considerations, the irrigation water quality index (IWQI) as well as fuzzy logic techniques, are profound performance appraisal methods for an effective and adaptable approach to assessing the quality of surface and groundwater (Egbueri, 2022; Hajji et al., 2021). Even though the IWQI and fuzzy logic were employed independently for assessing the appropriateness of irrigation water (Hue and Thanh, 2020) but their combined application has not yet been studied. Therefore, the fuzzy irrigation water quality index (FIWQI), and MLR model were used in this study to identify the most effective parameters of water-related factors and to solve the challenges of previously applied individual techniques for water quality assessment. On the one hand, water quality assessment is essential to provide good quality irrigation water; on the other hand, the northern and western parts of Bangladesh are threatened by drought, and farmers face significant challenges in securing an adequate water supply. As a result, using irrigation metrics and assessing the factors affecting them are critical for these regions to optimize water use efficiency for sustaining crop production (Elsayed et al., 2020; Sarker et al., 2021; Eid et al., 2023). Failure to do so can have undesirable consequences for agriculture, such as lower agricultural yields and increased dependence on imports, leading to higher food prices and inflation. Therefore, conducting a critical and regular evaluation to assess irrigation water quality in the drought-prone northern parts of Bangladesh is crucial to maximizing agricultural production and achieving food self-sufficiency. Although some studies have addressed the suitability of irrigation water in different parts of Bangladesh (Rahman et al., 2017; Islam et al., 2017b; Mia et al., 2023), the irrigation water quality in the drought-prone agricultural region has not been thoroughly studied. Evaluating the water's suitability for agriculture has proven to be a significant challenge. Therefore, a glaring issue that requires immediate attention is systematic and thorough research on the irrigation water condition and the variables that affect irrigation metrics in this critical region. To address this gap, this research developed a novel approach that encompasses key irrigation water quality metrics to help decision-makers in evaluating the few surface and groundwater samples. The hypothesis of the present study states that the integration of IWQI, FIWQI, and MLR models successfully assessed the suitability of water for irrigation in the drought-prone agricultural region in Bangladesh. The precise goals of this study are to evaluate the variations in irrigation water variables using traditional irrigation metrics; to assess the suitability of water for irrigation in a drought-prone agricultural region using an integrated IWQI and FWQI in a GIS environment; to identify what influences surface and groundwater variables on irrigation metrics utilizing multiple linear regression (MLR); to delineate suitable areas for agriculture using geostatistical modeling (Kriging) and inverse distance weighting (IDW); and to examine irrigation water variables and associations using redundancy and correlation analysis. It is indeed noteworthy to mention that this newly developed research on comprehensive IWQI and fuzzy irrigation water quality index (FIWQI) in appraising water quality in the drought-prone agricultural region of northern Bangladesh is such a novel concept for effective and consistent irrigation water assessment. This is the first time that a new irrigation index, fuzzy logic index, and MLR model have been used together in a GIS-based geostatistical model to assess irrigation metrics in a drought-prone agricultural region of Bangladesh. This study will explore new research opportunities for sustainably evaluating water quality. To ensure successful water management in the drought-prone agricultural region in Bangladesh, this research intends to give tools to water managers and agriculture managers to properly manage irrigation water. This study will also provide a clearer picture for redesigning sampling tactics and utilizing FIWQI and MLR models by concentrating on the most influential parameters of water-related factors. 2. Materials and methods 2.1. Description of the study area Drought-prone Rangpur and Nilphamari districts (a large administrative unit) in northern Bangladesh were selected for the study (Fig. 1). The study area was selected primarily because of its agricultural production focus and environmental importance. Physiographically, the study area belongs to the land of the Old Himalayan piedmont plain (Islam et al., 2014). The total irrigated area for paddy cultivation is 70.82 km2 for Taraganj and 119.43 km2 for Kishoreganj (BBS, 2013a, b). Most of the people in the study area depend on agriculture. Farmers in the selected area use various irrigation methods including diesel apartment pumps, electric irrigation pumps, siphon systems, and manual irrigation from tube wells to irrigate small agricultural areas. There is a mix of shallow and deep tube wells used for irrigation and drinking water. Irrigation canals, rivers, streams, and ponds are also used for irrigation. The Teesta Dam Project is the main canal used for irrigation. About 80% of the area is alluvium from the Tista floodplain and 20% is Barind Track. Groundwater quality is mainly controlled by the Jamuneswari, Dhaigan, and Chiklirivers. Physiographically, the study area belongs to the land of Old Himalayan piedmont plain (Islam et al., 2014). The altitude of the study area is 34 m above the mean sea level. Download : Download high-res image (981KB) Download : Download full-size image Fig. 1. Map of the study area with sample location points. Geologically, the study area belongs to the Rangpur Saddle under the Indian Platform. Rangpur saddle connects the Mikir hills and the Shillong massif with the Indian shield. This is an uplifted zone, which consists of a narrow deposit of sediments. The study area consists of alluvial deposits containing gravel, sand, silt, and clay of recent age. The aquifers of the Tista fan, active and inactive fans, located in Rangpur and Nilphamari districts, consist of coarser sediments and have the highest permeability in Bangladesh, ranging from 1000 to 7000 m2/day (Hussain and Abdullah, 2001). The study area is located within the active part of Tista fan. The aquifers are mainly composed of the deposits of the old Tista floodplain, which include fine, medium, and coarse sands with a higher proportion of silt and clay with an average thickness of 2 m. The thickness of the aquifer varies from 5 to 50 m with an average thickness of 20 m (Fig. S1) (Hussain and Abdullah, 2001). The aquifer of the study region is predominantly unconfined in the Rangpur district and locally semi-confined in the Nilphamari district. The flow of groundwater is from north to south direction. The most dominant aquifer is the lower shallow aquifer, which is 50 m thick in the subsurface. Other aquifer systems include an upper shallow aquifer located 30 to 20 m, a deep aquifer situated 30–35 m below the subsurface (Islam et al., 2017a). The summer rains are primarily responsible for recharging the groundwater. The environment in this region is characterized by irregular monsoons, high temperatures, high humidity, and significant rainfall. The months of May, June, July, and August have the highest average temperatures, ranging from 32 to 36 °C, while January has the lowest average temperatures, ranging from 7 to 16 °C (Islam et al., 2017b). The average annual rainfall in the study region is 2065 mm (Rahman and Islam, 2019). Most precipitation occurs in July (465 mm), and the lowest rainfall is observed during December (8 mm) (BMD, 2016). The average daily evaporation is 2.98 mm/day in Nilphamari and 3.26 mm/day in Rangpur (Salam et al., 2020). The lowest daily evaporation is observed in December (2.0 mm/day) and the highest in April (4.7 mm/day). 2.2. Sampling and analytical strategies For this research, a total of 38 water samples were collected from the selected location of two Upazilas (the smallest administrative unit, a subdistrict) of the two districts namely Taraganj (19 samples) and Kisorganj (19 samples) in April 2022. Sampling locations were selected based on a randomly to cover all parts of the selected sites in the study area. The month of April is considered to be in the dry season since the normal precipitation is low except for occasional nor'westers. Following standard methods (APHA, 2017; Siddique et al., 2022), the water samples were collected manually in prewashed (10% HNO3) high-density polyethylene (HDPE) bottles purchased from the local market as the white HDPE are resistant to chemical reactions compared to other plastics (ManjunathaNanjegowda et al., 2013). Before collection, the bottles were washed with the sampling water carefully to avoid contamination from the bottles. Samples of surface water, groundwater from the irrigation pump, and tube wells were randomly collected when the electrical conductivity (EC) and pH became stable. Both shallow and deep tube wells near rice fields were used for water collection. The depth of the tube wells and irrigation pumps varied from 9 to 60 m. The number of irrigation pumps was four as same as tube wells. The number of irrigation pumps was four and they were the same as tube wells. Six samples of surface water, which are also used for irrigation in the conjugated area, were collected. Of these, 1 is from the Jamuneswari River, 1 is from a Beel, and the others are from the Teesta Irrigation Canal. The surface water in these areas is highly prone to contamination, as people use these waters for bathing, washing jute buckles, washing clothes, and so on. People also use soap and detergent powders for bathing and washing, respectively. For these reasons, the surface water of this region may contain high pH in some areas. After completing the sample collections, the sampling bottles were labeled by location and sample number for easy recognition. A portable GPS (global positioning system) meter (Garmin Etrex 30x, Taiwan) was used for taking the reading of the geographic locations of each sample collection point (Fig. 1). GPS locations from Google Maps were also taken for cross-checking. The collected water samples were then brought to the laboratory for performing chemical analysis. The physicochemical properties of the water samples such as pH, total dissolved solids (TDS), and electrical conductivity (EC) were recorded at the point of sampling by a portable Multimeter (Lutron WA-2015, Taiwan) directly immersing the probe of the meter into the water body. Other parameters, such as Na+, K+, Ca2+, Mg2+, Cl−, and HCO3− were analyzed at the laboratory (INARS, BCSIR, Dhaka, Bangladesh) using several techniques. For instance, Na+, K+, Ca2+, and Mg2+ concentrations in the water samples were analyzed using an Atomic Absorption Spectrometer (AAS, Model: AA240FS, Varian, Australia) in air-acetylene flames, except for Ca which was determined in air-acetylene-nitrous oxide flames. Na+ and K+ were measured using the emission technique whereas Ca2+ and Mg2+ were analyzed by the absorption technique in AAS. For the analysis of Na+, K+, Ca2+, and Mg2+, the water samples were digested with concentrated HNO3 (68%) and measured directly by aspirating the samples through the nebulizer of the AAS instrument. The calibration curves were prepared using the certified reference materials (CRM, purchased from Fluka Analytical, Sigma-Aldrich, Germany) of the individual metal, and their concentrations were detected against the constructed calibration curves (linearity: 0.99–1.00). The trimetric method was used for the determination of Cl− and HCO3− concentrations in the water samples (APHA, 2017). During analysis, analytical grade chemicals and reagents such as AgNO3, acid-base indicator, and concentrated HNO3 were used. Good quality deionized water with EC less than 0.5 μS cm−1 was used throughout the experiment for the sample and standard preparation. Traceable CRM was used for checking the accuracy and precision in the analysis of all the considered parameters in this study. The quality control standard sample (CRM) and method blank sample (2% HNO3) were measured after 5 and 10 samples, respectively. All parameters were measured three times and the average results with a relative standard deviation of less than 10% were counted in this work. The limit of quantification (LOQ) for Na+, K+, Ca2+, and Mg2+ were 0.2, 0.2, 0.1, and 0.1 mg/L, respectively whereas the limit of detection (LOD) was 0.05, 0.06, 0.03, and 0.006 mg/L, respectively. The measurement uncertainty was 8.4, 9.6, 8.4, and 5.2%, respectively for Na+, K+, Ca2+, and Mg2+. The spike recovery for the analysis of Na+, K+, Ca2+, and Mg2+ using AAS was between 97 and 102%. This study adopted a flow chart to illustrate the analysis performed in the experiment (Fig. S2). 2.3. Irrigation metrics Irrigation water quality has a major role in a country's economic growth through agricultural productivity (Siddique et al., 2022; Islam et al., 2017b). To calculate the quality of irrigation water, some parameters are used, namely, NA% (Todd, 1980), SAR (Richards, 1954), TH (Raghunath, 1987; Brindha and &Elango, 2011), soluble sodium (SSP) (Wilcox, 1955), MAR (Raghunath, 1987), KR (Kelley, 1963), PI (Doneen, 1964) and residual sodium bicarbonate (RSBC) (Gupta, 1983). The formulas used to calculate the parameters can be found in Table S2. All concentration unit data were converted from milligrams per liter [mg/L] to milliequivalents per liter [meq/L] using conversion factors provided by Lesch and Suarez (2009). Total hardness was measured in ppm or mg/L National and international standards for chemical parameters were used to compare all calculation results. 2.4. Irrigation water quality index (IWQI) Irrigation water quality variables, including infiltration and permeability hazards, specific ion toxicity, salinity, trace element toxicity, and miscellaneous effects, were selected based on the guiding principles of Ayers &Westcot (1985) to create an irrigation water quality index for suitability assessment of the water of the studied area. Each parameter group is assigned a weighting coefficient, with (5) being the highest and (1) being the lowest (Islam et al., 2017b; Salem et al., 2018). The IWQI was calculated using the equations in Table S3 (Simsek and &Gunduz, 2007; Islam et al., 2017b), where G is the contributing factor of each hazard category that is most important for evaluating water resources used for irrigation, and I is an incremental index, w is the value of the weight of the group in question, N is the sum of the available parameters in the analysis, k is an incremental index, and r is the value of the score of each parameter. From Tables S4, S5, and S6, it can be seen that the hazard of salinization is considered the most significant and is given a weighting coefficient of (5). The hazard of infiltration and permeability, specific ion toxicity, trace element toxicity, and other effects are assigned a weighting coefficient of (2), (1), respectively. According to Table S3, G1 is the salinity hazard and is represented by EC and the TDS values of the sample water, G2 is the infiltration and permeability hazard and is represented by the combination EC-SAR, G3 is the specific ion toxicity represented by SAR, G4 is the trace element toxicity represented by the elements listed in Table S6, and G5 is the other effect on sensitive plants represented by the pH of the water. 2.5. Geostatistical modeling Geostatistics is a branch of statistics that deals with geographic or spatiotemporal data sets. It is based on the study of regionalized factors (Goovaerts, 2000). The variogram is considered as an important component used to evaluate the spatial relationship between the information components collected. More specifically, a variogram is an existing difference between data values in two main sections that are not connected by a common distance h (Islam et al., 2017a). In general, the purpose of considering variable mode is to evaluate variable changes considering temporal and spatial changes. To calculate this variation, which is the total squared difference between pairs, given a distance h from each other, and plotted in comparison to h in a semivariogram, we must follow a specific procedure, as given below in Eq. (1) (Theodossiou and Latinopoulos, 2006). (1) Where h is the distance (lag) between pairs of sample locations. Var is the variance. Z(x) is the observed value of a parameter at site xi. Z (x + h) is the value of the element at point xi + h. For the geostatistical analysis, the ordinary kriging method (OK) was used, using different semivariogram models with the Geostatistical Analyst tool (ESRI, 2020). Among the kriging methods, ordinary kriging (OK) is the most commonly used because this method uses data from the neighborhood to estimate the value using the known variogram at another point in a different region (Wackernagel, 2003). Several semivariogram models have been described in the literature, including stable, J-Bessel, K-Bessel, circular, hole-effect, exponential, spherical, pentaspherical, tetraspherical, rational quadratic, and Gaussian (Chatterjee et al., 2021; Gundogdu and &Guney, 2007). The semivariogram model that best fits the data was selected after reviewing the ’performances of all models separately (Islam et al., 2017b). The model that had the lowest root mean square error (RMSE) was selected as the best model for the data (Gundogdu and &Guney, 2007). The cribbed map of the spatial distribution was created using ArcGIS (version 10.8.2) during the analysis. In geostatistics, the nug/sill ratio calculated from the best-fitting semivariogram model can be considered as a classification criterion for determining spatial dependence. The result of less than 0.25 can be classified as strongly dependent, 0.25 to 0.75 is moderately dependent, and more than 0.75 is weakly dependent (Chang et al., 1998). More details on the geostatistical model can be found elsewhere (Islam et al., 2017a; Boufekane and Saighi, 2019). Irrigaiton metrics data were used for assessing spatial dependence, and spatial dependence maps were produced as previously used in the literature by Islam et al. (2017a, b). 2.6. Statistical analysis Origin Pro software was used to plot the data set of major anions and cations of ground and surface water in a trilinear plot called the Piper trilinear plot” (Piper, 1944). This plot is used for determining water type and visualizing water chemistry (Nwankwoala and &Udom, 2011). Inputting the calculated data into the Origin Pro software spreadsheet helped to create the Piper trilinear diagram. The various hydrogeochemical properties of the water samples were plotted using the Wilcox diagram (Wilcox, 1955) and USSL diagram (Richards, 1954) to determine the suitability of water for irrigation (Selvakumar et al., 2017). These diagrams were also generated using OriginLab, 2022 software (OriginLab, 2022). Redundancy analysis (RDA)was performed using RStudio 2022 “Spotted Wakerobin” for Windows. van den Wollenberg (1977) developed redundancy analysis to analyze the asymmetric data using eigenvalue analysis to examine the correlation between multiple dependent variables and multiple independent variables. The degree of association between a pair of variables can be described as correlation, and regression can be defined as the relationship between the specified value of one variable and the mean of the corresponding values of the second variable’ (Asuero et al., 2006). Multiple linear regression (MLR) can be defined as a technique in statistics for analyzing the relationship between a single dependent variable and multiple independent variables to use the known values of the independent variables to predict the single dependent value (Moore et al., 2006). Pearson's correlation coefficient analysis and stepwise MLR analysis were performed using IBM SPSS 26 software. 2.7. Fuzzy irrigation water quality index (FIWQI) Fuzzy logic can be termed as a reasoning method that aims to give approximate categorization instead of a precise category (Bari et al., 2022). Fuzzy logic gives any logical answer between 1 and 0 in mathematical terms and a degree of truth or false answer, like almost false, very small, or near true, instead of conventional Boolean “true or false” or “1 or 0″ logic (Dhaoui et al., 2022; Tushar et al., 2022). The entire process of transforming input functions into fuzzy output functions using fuzzy logic rules is called a fuzzy inference system (FIS) (Dhaoui et al., 2022). The Mamdani FIS (Mamdani and &Assilian, 1975) was preferred over the Sugeno FIS (Sugeno, 1985) for this study because it is highly intuitive, best suited for human input, and widely used and accepted due to its simple structure and the ease of interpretation of its rules, while there are drawbacks in the interpretability of the Sugeno FIS (Pandey et al., 2020; Salman and Seno, 2010). The Mamdani FIS contains three main components (Muhamad et al., 2020; Malik et al., 2021), such as fuzzification, fuzzy inference, and defuzzification, whose process is shown in Fig. 2. The trapezoidal membership function (MF) is used for irrigation water quality analysis in the step of fuzzification because itis simple and effective (Zadeh, 2008; Al Mamun et al., 2019; Hue and Thanh, 2020; Mia et al., 2023). The MF can be expressed as equation (2). (2) where x denotes the parameters and a, b, and c are the explanatory variables used to categorize the parameters. Download : Download high-res image (239KB) Download : Download full-size image Fig. 2. Process of a fuzzy inference system. In this study, the fuzzy toolbox in MATLAB software (MATLAB, 2022) was used to create the Mamdani fuzzy inference system. The structure of the fuzzy model is shown in Fig. S3. EC, SAR, SSP, MAR, KR, TH, PI, and the RSBC classification of water quality proposed by Ayers &Westcot (1985) was used as input membership functions. The Mamdani FIS is the most widely used inference system which uses a certain rule like the “if … Then” pattern (Agoubi et al., 2016; Al Mamun et al., 2019; Hajji et al., 2021). For example, Raman et al. (2009) used six parameters to generate 86 rules, while Semiromi et al. (2011) constructed 58 rules using 6 parameters and Mia et al. (2023) used six parameters to generate 31 rules. In this study, a total of 56 rules were constructed to generate the FIWQI as output by the defuzzification process, and finally, the “evalfis” function was used to analyze the data (Fig. S4). 3. Results and discussion 3.1. Physiochemical characterization of water The physiochemical properties of water depend on many factors, including the intensity of chemical weathering of different rock types, the general geology of the sampling area, the effects of surrounding pollution sources, and the quality of groundwater (Islam et al., 2017a). The results of geochemical, trace element, and physiochemical properties of the collected groundwater (GW) and surface water samples (SW) are presented in Table S7 and the descriptive statistics of physiochemical properties are presented in Table 1. Table 1. Descriptive statistics of the groundwater (GW) and surface water (SW) and comparison with different standards of irrigation water quality. Parameters Descriptive statistics Irrigation water standards Min. Max. Mean Median SD. CV. Skewness Kurtosis FAO (1985) UCCC (1974) DoE (1997) Groundwater pH 6.52 8.14 6.98 6.98 0.33 0.11 1.42 3.63 6.0–8.5 6.5–8.4 6.5–8.5 EC (μS/cm) 104 1008 286.9 203.5 193.3 38568.3 2.08 4.94 0–3000 700–3000 2250 TDS (mg/L) 69 672 191.8 135 129 17186.7 2.06 4.87 0–2000 450–2000 Na+ (mg/l) 4.98 55.9 17.0 12.2 12.3 156.2 1.58 2.21 0–900 68–204 K+ (mg/L) 1.07 80.6 13.9 6.13 17.8 328.3 2.53 6.67 0–2 Ca2+ (mg/L) 12.3 53.5 23.0 19.2 10.7 118.4 1.54 1.79 0–400 Mg2+ (mg/L) 1.77 15.7 5.68 5.025 2.70 7.54 1.90 4.85 0–60 Cl− (mg/L) 1.05 132.1 17.0 11.0 23.0 545.7 4.18 20.0 0–1100 0–133 0–600 HCO3− (mg/L) 43 260 106 89.5 57.2 3380.4 1.06 0.29 0–600 0–91 Surface Water pH 7.04 10.22 8.56 8.19 1.203 1.736 0.48 −1.74 6.0–8.5 6.5–8.4 6.5–8.5 EC (μS/cm) 70.4 226 125.3 109.3 50.4 3044.8 1.44 2.33 0–3000 700–3000 2250 TDS (mg/L) 46.9 151 83.6 72.8 33.8 1367.8 1.44 2.29 0–2000 450–2000 Na+ (mg/L) 6.30 16.1 9.54 8.12 3.27 12.85 1.55 2.20 0–900 68–204 0–260 K+ (mg/L) 2.28 8.33 5.02 4.8 1.81 3.94 0.59 1.74 0–2 Ca2+ (mg/L) 9.40 13.8 11.95 12.5 1.57 2.95 −0.67 −1.21 0–400 Mg2+ (mg/L) 1.89 4.22 2.94 2.86 0.77 0.71 0.41 −0.57 0–60 Cl− (mg/L) 3.06 10.12 8.03 9.50 2.64 8.38 −1.31 0.50 0–1100 0–133 0–600 HCO3− (mg/L) 30.0 48.0 38.8 39.0 6.79 55.4 −0.02 −1.78 0–600 0–91 The pH is one of the most important factors affecting water quality. pH in GW ranged from 6.52 to 8.14 with an average of 6.98 ± 0.33 and in SW ranged from 7.04 to 10.22 with an average of 8.56 ± 1.20, indicating that the groundwater in the study area is slightly acidic to slightly alkaline (Jannat et al., 2022). The higher pH values in SW could be due to human intervention or everyday purposes such as washing clothes, bathing, bathing livestock, and even washing jute buckles. The average EC and TDS values in GW were 286.94 ± 193.30 and 191.82 ± 129.03, while for SW the average values were 125.30 ± 50.37 and 83.58 ± 33.76, respectively. All EC and TDS samples are within the standard range according to the Food and Agriculture Organization (FAO, 1985) and the Department of Environment (DoE, 1997). However, according to the College of California Committee of Consultants (UCCC, 1974), most values are below the standards for irrigation and these results classify the water sources as freshwater (Carroll, 1962; DoE, 1997). The average concentration of Na+ in GW was 17.0 ± 12.3, whereas in SW it was 9.54 ± 3.27. The average concentration of Na+ in GW and SW was 13.9 ± 17.8 and 5.02 ± 1.81, respectively, which is the third major cation in terms of abundance. Ca2+ values in GW ranged from 12.3 to 53.5 with an average of 23.0 ± 10.7 and in SW from 9.14 to 13.8 with an average of 12.0 ± 1.57. Magnesium is another important cation in the water samples and the average concentration of Mg2+ in GW and SW was 5.68 ± 2.70 and 2.94 ± 0.77, respectively. The average concentration of Cl− in GW was 17.0 ± 23.0, while in SW it was 8.03 ± 2.64. Bicarbonate (HCO3−) levels in GW ranged from 43 to 260 with an average of 106 ± 57.2 and in SW ranged from 30 to 48 with an average of 38.8 ± 6.79. The major cation in GW and SW is Ca2+ and the major anion is HCO3−. The ion concentration of cations in the GW and SW samples follows the following chronological order Ca2+>Na+>K+>Mg2+ and HCO3− > Cl− for anions. The results for cations were slightly different, but the results for anions are consistent with those found by Saha et al. (2019) in a similar study in northern Bangladesh. The cations and anions except for K+ in the GW and SW samples were within the FAO (1985) standard limits but below the standard values reported by UCCC (1974), signifying that the water samples are excellent and adequate for irrigation purposes (Islam and Mostafa, 2022). The values of kurtosis and skewness between −2 and +2 can be considered acceptable to prove a univariate distribution in the normal range (George and Mallery, 2010). Only the kurtosis of Ca2+ and HCO3− falls within the normal range. All kurtosis values of major ions fall into the leptokurtic category. All values of major ions fall in the standard skew range, except for K+ and Cl−, which are positively skewed and can be considered extreme for the aquifer system (Islam et al., 2017b; Ruidas et al., 2022). The sodium in the GW and SW may have been introduced by weathering of silicate in the form of feldspar and halite minerals (Srivastava and &Parimal, 2020). Chemical weathering of shale and granite could be the source of high K+ content in the study area (Huang et al., 2020). The high use of potassium fertilizers in agriculture also increases the salinity of groundwater (Buvaneshwari et al., 2020). The exchange of cations and dolomite could be the cause of the high Ca2+ concentration in the aquifer system (Islam et al., 2017a). The presence of dolomite (CaMg (CO3)2) can be further demonstrated by the high concentration of Mg2+ and HCO3−. Other sources of calcium could be calcite (CaCO3) or the use of large amounts of gypsum fertilizer and lime in agriculture in this region (Saha et al., 2019). The sources of Mg2+ in groundwater are ferromagnesian minerals and dolomitic limestones (Mebarki et al., 2021; Ratri et al., 2021). Decomposition of organic matter leading to microbial production of carbonic acid, formic acid, and acetic acid, and the reaction of water with dolomite and calcite rocks could be the source of bicarbonate in groundwater of the study area (Rahman et al., 2017; Islam et al., 2018). The major sources of chloride in groundwater are precipitation and halite (Konwea et al., 2023). The other major source of Cl− in groundwater is fertilization with potassium (KCl) (Buvaneshwari et al., 2020). A Piper trilinear diagram is a visual representation of data that is a well-known and commonly used approach for evaluating the hydrochemical characterization of water (Piper, 1944; Qishlaqi et al., 2017). Fig. 3 illustrates the results of measuring the hydrochemical properties of the samples. According to Fig. 3, Ca2+, Mg2+, and HCO3−play a crucial role in identifying the water type, indicating the presence of dolomite and other Mg2+ minerals in the aquifer system of the study area. The interaction of flowing water with bedrock could have introduced these ions into the water through weathering (Zakir et al., 2020; Kabir et al., 2021; Sarkar et al., 2022). The results of this study are consistent with the result of a similar study by Islam et al. (2017a) and Howladar et al. (2014). Download : Download high-res image (355KB) Download : Download full-size image Fig. 3. Piper diagram showing irrigation water type of (a) groundwater and (b) surface water in the study area. 3.2. Geostatistical modeling and mapping for irrigation metrics The experimental semivariograms of groundwater and surface water are shown in Fig. 4. The sign around the omnidirectional semivariogram models shown with blue line and the average values of the semivariogram models with plus sign. The best-fit semivariogram model for groundwater and surface water samples and their characteristics are shown in Table 2. Download : Download high-res image (2MB) Download : Download full-size image Download : Download high-res image (1MB) Download : Download full-size image Fig. 4. Semivariogram models of irrigation water quality metrics in the study area (a. EC, b. TH, c. SAR, d. SSP, e. IWQI, f. FIWQI of groundwater and g. EC, h. TH, i. SSP, j. SAR, k. IWQI, l. FIWQI of surface water). Table 2. The suitable characteristics of water quality indices of semivariogram models for groundwater and surface water parameters and their changes. Empty Cell Indices Fitted Model Nugget Major range (m) Sill Nugget/Sill Lag size ME RMSE MSE RMSSE ASE Groundwater EC K-Bessel 37,527.73 1675.93 56361.72 0.67 179.41 2.17 219.27 0.01 1.00 220.45 TH Hole Effect 918.99 1905.45 1724.99 0.53 164.70 −0.37 39.51 0.001 1.07 36.72 SSP Tetraspherical 130.48 537.91 174.83 0.75 57.97 −0.14 13.64 −0.01 0.97 13.95 SAR Hole Effect 0.12 1858.15 0.205 0.56 169.46 −0.02 0.51 −0.03 1.19 0.41 IWQI J-Bessel 3.27 2770.39 4.17 0.78 246.95 −0.04 2.03 −0.02 1.01 2.00 FIWQI J-Bessel 0.0036 1942.8 0.0076 0.47 161.90 −0.001 0.09 0.005 1.20 0.07 Surface water EC J-Bessel 1058.98 5754.65 3084.13 0.34 709.46 −3.22 52.91 −0.03 0.99 52.58 TH Rational Quadratic 26.08 9538.82 44.61 0.58 794.90 −0.39 6.90 −0.03 1.04 6.50 SSP Rational Quadratic 0.08 7383.13 81.04 0.001 782.09 −0.34 8.87 −0.03 1.17 6.76 SAR Gaussian 0.03 5718.99 0.09 0.34 701.81 −0.01 0.29 −0.02 1.18 0.04 IWQI Gaussian 1.4 5718.99 2.54 0.55 701.81 −0.04 1.67 −0.02 1.11 1.48 FIWQI Rational Quadratic 0.000001 8421.77 0.001 0.001 701.81 0.0009 0.038 0.014 1.23 0.03 As with the groundwater samples, the best-fitting model for EC was the K-Bessel model, which had the lowest root mean square error (RMSE) among the models. The Hole Effect model for TH and SAR, the Tetrasphere model for SSP, and the J-Bessel model for IWQI and FIWQI were found to be the best fit. For surface water samples, the J-Bessel model for EC was the best fit and had the lowest RMSE. Rational Quadratic was the best-fitting model for TH, SSP, and FIWQI and the Gaussian model was found to be the best fit for SAR and IWQI. The large reaches of the groundwater samples ranged from 537.91 to 2770.39 m and 5718.99–9538.82 m for the surface water samples. The wide variation among the large reaches suggests the influence of fertilizer use, runoff and precipitation, and other geometric and topographic factors of groundwater (Islam et al., 2017a; Chakraborty et al., 2023). From the Ordinary Kriging results, EC, TH, SSP, and SAR of the groundwater samples show moderate spatial dependence. The IWQI shows a low spatial dependence. The FIWQI shows moderate spatial dependence. On the other hand, the surface water samples show moderate to strong spatial dependence. The differences in spatial dependence show the different land use patterns in this region, including residential, agricultural, cropland, and industrial. The spatial distribution of EC, TH, SSP, and SAR, of groundwater and surface water in the study area are shown in Figs. S5 and S6. These values could be attributed to the spatial distribution of these parameters in northern Bangladesh, indicating different land use patterns and human activities. A downward trend is observed in all water parameters from Taraganj (the southern part) to Kishoreganj (the northern part). This could be due to various rivers, canals, and other activities such as fertilizer use in this region. Zakir et al. (2020) found that 45.2% of the GW samples from the Jamalpur Sadar area, Bangladesh is good quality for irrigation. This difference in water condition could be impacted by the depth and type of water bodies and the nature of aquifers. 3.3. Multiple linear regression model MLR models were applied to irrigation water quality data to determine the contribution of these parameters to water quality variation. For the prediction of SAR, EC, KR, Na%, MAR, TH, RSBC, PI, and SSP from several known agglomerations of other indices of groundwater used for irrigation, the multivariate regression model with the highest significance was presented in Table 3. In the model, the significant effect of seven independent variables was tested and their significance on correlated dependent variables was observed. A ‘t-test was performed for part of the regression coefficients, using a probability of 5. Table 3. Water quality parameters influencing irrigation metrics using MLR model. Dependent variable (multiple R2 values) Constant of the model (standard error) Regression coefficients for independent variables (standard error of regression coefficients) Standard error of regression model (ANOVA, F-statistic)a 01 EC (.92) −247.05 (358.73) 3.95 TH (1.50) −9.16 Na% (5.76) 97.06 SAR (219.70) 8.99 SSP (2.72) 2.46 MAR (3.17) −141.83 KR (414.34) .68 PI (3.70) −39.60 RSBC (32.13) 66.35 (31.08) t values −0.69 2.63 −1.59 0.44 3.3 0.78 −.34 0.18 −1.23 p values 0.5 0.02 0.13 0.66 0 0.45 0.74 0.86 0.23 02 TH (.97) 166.37 (27.15) .06 EC (.02) 1.51 Na% (.67) 70.60 SAR (22.42) −.05 SSP (.40) −.40MAR (.38) −156.52 KR (38.53) −1.33 PI (.36) 7.39 RSBC (3.73) 8.07 (80.60) t values 6.13 2.63 2.26 3.15 −.13 −1.06 −4.06 −3.73 1.98 p values 0 0.02 0.03 0 0.9 0.3 0 0 0.06 03 Na% (.93) −14.83 (12.07) −.01 EC (.01) .12 TH (.05) 2.77 SAR (7.56) −.14 SSP (.11) −.10 MAR (.11) 30.21 KR (12.82) .31 PI (.11) −1.32 RSBC (1.11) 2.28 (36.56) t values −1.23 −1.59 2.26 0.37 −1.30 −.95 2.36 2.78 −1.19 p values 0.23 0.13 0.03 0.72 0.21 0.35 0.03 0.01 0.25 04 SAR (.99) −.46 (.33) .00 EC (.00) .00 TH (.00) .00 Na% (.00) .00 SSP (.00) .01 MAR (.00) 1.53 KR (.23) 0.00 PI (.00) .05 RSBC (.03) .06 (204.91) t values −1.39 0.44 3.15 0.37 0.17 1.77 6.62 −0.14 1.58 p values 0.18 0.66 0 0.72 0.87 0.09 0 0.89 0.13 05 SSP (.91) −15.97 (22.61) .04 EC (.01) −.01 TH (.11) −.48 Na% (.37) 2.36 SAR (13.90) −.27 MAR (.20) 45.11 KR (24.45) .47 PI (.21) −.49 RSBC (2.09) 4.18 (28.30) t values −0.71 3.3 −.13 −1.30 0.17 −1.37 1.85 2.21 −.23 p values 0.49 0 .90 0.21 0.87 0.18 0.08 0.04 0.82 06 MAR (.28) 27.84 (22.83) .01 EC (.01) −.12 TH (.11) −.37 Na% (.39) 23.84 SAR (13.45) −.28 SSP (.21) −14.33 KR (26.83) .17 PI (.24) −1.24 RSBC (2.14) 4.31 (1.12) t values 1.22 0.78 −1.06 −.95 1.77 −1.37 −.53 0.73 −.58 p values 0.24 0.45 0.3 0.35 0.09 0.18 0.6 0.47 0.57 07 KR (.99) .32 (.17) −.00 EC (.00) −.00 TH (.00) .01 Na% (.00) .43 SAR (.07) .00 SSP (.00) −.00 MAR (.00) −.00 PI (.00) −.01 RSBC (.02) .03 (192.78) t values 1.89 −.34 −4.06 2.36 6.62 1.85 −.53 −1.45 −.74 p values 0.07 0.74 0 0.03 0 0.08 0.6 0.16 0.47 08PI(.91) 85.15 (10.06) .00 EC (.01) −.29 TH (.08) .82 Na% (.30) −1.75 SAR (12.42) .37 SSP (.17) .13 MAR (.18) −32.39 KR (22.40) 6.21 RSBC (1.35) 3.74 (30.11) t values 8.46 0.18 −3.73 2.78 −.14 2.21 0.73 −1.45 4.61 p values 0 .86 0 0.01 0.89 0.04 0.47 0.16 0 09RSBC(.70) −6.62 (1.81) −.00 EC (.00) .02 TH (.01) −.04 Na% (.04) 2.08 SAR (1.32) −.01 SSP (.02) −.01MAR (.02) −1.91 KR (2.58) .08 PI (.02) .42 (6.59) t values −3.65 −1.23 1.98 −1.19 1.58 −.23 −0.58 −.74 4.61 p values 0 0.23 0.06 0.25 0.13 0.82 0.57 0.47 0 For the prediction of EC, other available independent variables were used, including SSP, Na%, SAR, KI, TH, RSBC, PI, and MAR, and the result is quite good. In predicting EC, other independent variables from the test, such as SAR (p = 0.66), KR (p = 0.74), and PI (p = 0.86), had the greatest effect. According to the regression model, the value of the coefficient of determination or multiple R2 of EC was 0.92, which means that 92% of the variability of EC can be explained by the combined effects of Na%, KI, SAR, MAR, RSBC, SSP, PI and TH. In the multivariate regression model, SAR and KR showed the highest observed variability of 99%, and the lowest value was observed by MAR (28%). Other observations such as TH (97%), Na% (93%), SSP (91%), PI (91%), and RSBC (70%) show that all irrigation water quality parameters are interdependent except MAR, which has very low dependence. Multiple regression models of similar nature have been used by others to predict groundwater quality for irrigation (Adhikary et al., 2012; Islam et al., 2017a). 3.4. Redundancy analysis (RDA) The relationship between irrigation water quality indices and physiochemical parameters was studied using redundancy analysis. Fig. 5 shows the RDA diagram of (a) groundwater and (b) surface water. Download : Download high-res image (341KB) Download : Download full-size image Fig. 5. RDA diagram showing a relationship between toxic metals with physiochemical parameters of (a) groundwater and (b) surface water. The eigenvalues of the controlled RDA axes were RDA1 = 52.72% and RDA2 = 4.78% for groundwater and RDA1 = 37.1% and RDA2 = 21.61% for surface water. The RDA results show that RDA1 of groundwater explains 52.72% and RDA2 explains 4.78% of the variance in groundwater parameters, RDA1 of surface water explains 37.1% and RDA2 explains 21.61% of the variance in surface water quality parameters. Both results can be considered as very good and can be used to efficiently explain the variance of water quality parameters. The RDA plot of groundwater shows that the physiochemical parameters were positively associated with Na+, Ca2+, Cl−, K+, HCO3−, and other ions of the groundwater sample as well as the water quality indices of groundwater. The temperature was negatively associated with major ions and water indices. Trace elements followed the same path as other major ions in groundwater. SSP, Ca2+, K+, and Cl−, are positively correlated with TDS and EC and negatively correlated with temperature. Na, Na%, HCO3− is positively correlated with pH and depth. The surface water sample shows that there is no correlation between pH, temperature, EC, TDS, and depth with Cl−, Na+, HCO3−, TH, PI, and Mg2+. EC, TDS, pH, temperature, and depth show a positive correlation with each other and a positive correlation with SSP, K+, IWQI, Na%, and some trace metals, but a negative correlation with Fe2+ and MAR. 3.5. Suitability of irrigation water quality The quality of irrigation water can vary drastically, depending primarily on the type and concentration of dissolved chemical and it occur in extremely small amounts in the water, but impact significantly (Mia et al., 2023; Raihan and &Alam, 2008; Islam et al., 2017b). The suitability of the studied samples for irrigation purposes can be seen in Table S8. About 100% of the water samples, both groundwater and surface water, are very suitable for irrigation as all the samples have IWQI values above 23. According to Table 4, when evaluating the EC values, 96.88% of the groundwater samples fall into the excellent for irrigation category, and 3.13% fall into the good category. 100% of the EC values for surface water quality fall into the excellent category for irrigation. Considering SAR, 100% of the groundwater and surface water samples can be classified as excellent for irrigation. In contrast, all samples on the U.S. salinity plot (Fig. 6a and b) fall into the low sodium (alkali) category, but one surface water sample falls into the medium salinity category, one groundwater sample falls into the high salinity category, and 15 groundwater samples fall into the medium salinity category. The other samples of groundwater and surface water fall into the low salinity category. There should be no risk of mobile Na+ (Islam et al., 2017b; Sarkar et al., 2022; Biswas et al., 2023). The high salinity could have been caused by rock weathering processes due to groundwater movement (Shah et al., 2022; Su et al., 2023). Groundwater and surface water quality in the study area is currently suitable for irrigation. However, since surface water is susceptible to human intervention, the increasing use of chemical fertilizers, pesticides, herbicides, and household wastes may also alter the quality of surface water and slowly change the quality of groundwater due to infiltration and percolation. Human activities such as the use of chemical fertilizers, pesticides, washing clothes, and bathing should be controlled. Natural and organic agriculture should be introduced. Household and industrial wastes should be disposed of properly. Constant monitoring of water quality is recommended for sustainable agriculture. Table 4. Classification of irrigation water quality matrices of the examined area. Indexing method Category Class of water Groundwater Surface water Total locations Percentage of samples Total of locations Percentage of samples EC <700 Excellent 31 96.875 6 100 700–3000 Good 1 3.125 0 0 >3000 Fair 0 0 0 0 SAR <10 Excellent 32 100 6 100 10–18 Good 0 0 0 0 18–26 Fair 0 0 0 0 >26 Poor 0 0 0 0 SSP <20 Excellent 1 3.125 0 0 20–40 Good 21 65.625 1 16.67 40–80 Fair 10 31.25 5 83.33 >80 Poor 0 0 0 0 TH <75 Soft 20 62.5 6 100 75–150 Moderately hard 9 28.125 0 0 150–300 Hard 3 9.375 0 0 >300 Very hard 0 0 0 0 KR <1 Excellent 31 96.875 6 100 >1 Excess level of Na+ 1 3.125 0 0 MAR <50 Excellent 32 100 6 100 >50 Harmful to soil 0 0 0 0 PI >75% Excellent 29 90.625 6 100 25–75% Suitable 3 9.375 0 0 <25% Unsuitable 0 0 0 0 RSBC <5 Safe 32 100 6 100 5–10 Marginal 0 0 0 0 >10 Unsatisfactory 0 0 0 0 IWQI <22 Low suitability 0 0 0 0 22–23 Medium suitability 0 0 0 0 >23 High suitability 32 100 6 100 Download : Download high-res image (364KB) Download : Download full-size image Fig. 6. Irrigation suitability using US salinity diagram (a) groundwater and (b) surface water. To understand irrigation water quality, the Wilcox diagram was used to plot Na% values against EC (Wilcox, 1955; Fallahati et al., 2020; Jaydhar et al., 2022) (Fig. 7a and b). All surface water samples fall into the excellent to good category, while only one groundwater sample falls into the good to acceptable category. The other groundwater samples fall into the excellent to good category, indicating that the water in the study area is very suitable for irrigation. This result is consistent with the work of Howladar et al. (2014) in northern Bangladesh, while it is inconsistent with the work of Tajwar et al. (2023) in Hatiya Island, Bangladesh. Download : Download high-res image (405KB) Download : Download full-size image Fig. 7. Irrigation suitability using Wilcox's diagram (a) groundwater and (b)surface water. The values for the soluble sodium percentage (SSP) show that 65.63 and 31.25% of the groundwater samples fall in the “good” and “moderate” categories for irrigation, respectively, while only one sample falls in the “excellent” category. On the other hand, 16.67% of the surface water samples fall into the good category and 83.33% of the samples fall into the moderate category for irrigation. Looking at the values of total hardness (TH), 100% of the surface water falls in the soft water category, which is of no benefit to plants. Groundwater samples also fall predominantly into the soft category (62.5%), while 28.13% of groundwater falls into the moderately hard category and 9.33% falls into the hard category (Table 4). KR shows the balance of Na+, Ca2+, and Mg2+ in the water samples. Table 4 shows that 96.88% of the groundwater samples and 100% of the surface water samples fall into the excellent category. One sample of groundwater falls into the category of excessive Na+ in water, which can be harmful to certain crops. The MAR is also able to categorize water quality based on the amount of magnesium in the water. Abundant magnesium increases soil pH and decreases its integrity (Alsubih et al., 2022; George and &Ngole-Jeme, 2022; Anonna et al., 2022; Mia et al., 2023). Based on MAR, 100% of groundwater and surface water samples fall into the “excellent” category, indicating that there are no adverse effects on soil. When considering residual sodium bicarbonate (RSBC) values, all groundwater and surface water samples have RSBC less than 5 meq/l. This falls into the “safe” category for irrigation and is not a problem for plants. The PI is an important indication of irrigation water efficiency because it reflects the impact of long-term irrigation on soil permeability. Regular irrigation with sufficient mineral groundwater can reduce soil permeability and thus affect agricultural productivity (Zafar et al., 2022; Anonna et al., 2022; Mokhtar et al., 2022). The results of the permeability index (PI) show that a total of 29 samples (90.63%) of groundwater are more than 75% permeable which is excellent for irrigation. The other 3 groundwater samples (9.38%) fall into the “suitable” category. However, the indices of PI were used to create a scatter plot, and the Doneen diagram (Doneen, 1964) was created, which shows very different results, as shown in Fig. S7. This diagram contains 3 classes where class 1 of this diagram is excellent for irrigation, class 2 is suitable, and class 3 is not suitable (Doneen, 1964). According to the diagram, only one sample falls into the class 1 or excellent category. 12 samples fall into the class 2 category which is suitable for irrigation with 75% permeability and the remaining 19 samples fall into class 3 with 25% maximum permeability. This means that most of the samples are not suitable for irrigation. The boxplot was made using the values of Na%, SSP, MAR, PI, RSBC, SAR, KR, Mg:Ca, Na:Ca, EC, and TH in Fig. 8 and shows that theNa% of groundwater and MAR have similar values and are suitable for irrigation. SSP is slightly higher but is in the acceptable range. The RSBC value is lower than the standard limit and the value of PI exceeds the acceptable limit and is not suitable for irrigation. The values of SAR and Na:Caare slightly higher than the values of KR and Mg:Ca, and the value of EC is higher than that of TH, indicating harmful effects on agriculture. On the other hand, Na%, SSP, RSBC, PI and MAR values of surface water show similar results to those of groundwater. SAR and Na:Ca values are higher than KR and Mg:Ca. EC values are very high than TH values, indicating similar results to groundwater samples. The boxplot of PI and EC values shows that there are risks to plants in both GW and SW. The results of this study are consistent with the results of a similar study conducted by Islam et al. (2017b) in Faridpur, Bangladesh. Download : Download high-res image (414KB) Download : Download full-size image Fig. 8. Box plots showing the irrigation indices of groundwater (a, b, c) and surface water (d, e, f) of the study area. Pearson correlation was used to study the correlations between physiochemical parameters of water with significance (Kadir et al., 2022; Acharjee et al., 2022; Islam et al., 2022). The Pearson correlation matrix in Table 5 shows that most of the parameters are positively correlated with each other and some have very strong relationships, although very few results have very low negative correlation for surface water and groundwater samples. Table 5. Pearson's correlation matrix of the groundwater (lower-left) and surface water (upper-right). Empty Cell EC TH Na% SAR SSP MAR KR PI RSBC Mg:Ca Na:Ca EC 1 0.268 0.787 .919a .887b −0.151 .860b −0.091 0.211 −0.173 .834b TH .874a 1 −0.157 0.006 −0.164 0.219 −0.165 −.872b .884b 0.207 −0.127 Na% 0.172 0.123 1 .965a .937a 0.015 .979a 0.159 −0.111 −0.022 .984a SAR .597a .512a .843a 1 .972a −0.084 .985a 0.078 −0.009 −0.115 .973a SSP .503a 0.251 .741a .847a 1 −0.162 0.986 0.233 −0.19 −0.181 0.962 MAR 0.059 −0.062 0.182 0.244 0.184 1 −0.120 −0.646 0.493 .997a 0.074 KR 0.280 0.127 .924a .906a .861a 0.264 1 0.227 −0.157 −0.149 .981a PI −.688a −.805a 0.125 −0.256 0.026 0.091 0.048 1 −.865b −0.643 0.102 RSBC 0.178 0.266 0.246 0.300 0.261 0.013 0.159 0.226 1 0.469 −0.074 Mg:Ca 0.073 −0.063 0.230 0.286 0.227 .996a 0.319 0.094 0.000 1 0.046 Na:Ca 0.272 0.113 .894a .894a .835a .374b 0.991 0.040 0.131 .428 1 a Correlation is significant at the 0.01 level (2-tailed). b Correlation is significant at the 0.05 level (2-tailed). Among groundwater parameters, Mg:Ca and MAR have shown the strongest positive correlation (r = 0.996). Other significant positive correlations are shown for EC with TH (r = 0.874), SAR (r = 0.597), SSP (r = 0.503), for Na% with SAR (r = 0.843), SSP (r = 0.741), KR (r = 0.924), Na:Ca (r = 0.894), and of SAR with SSP (r = 0.847), KR (r = 0.906), Na:Ca (r = 0.894). SSP and KR (r = 0.861), SSP and Na:Ca (r = 0.835), KR and Na:Ca (r = 0.991), at significance, p = <0.01. However, PI has a significant negative correlation with EC (r = −0.688) and TH (r = -0.805). In the case of surface water, a similar trend can be observed. MAR and Mg:Ca show the strongest significant correlation (r = 0.997, p = <0.01). Other strong positive correlations can be observed between EC and Na% (r = 0.787), EC and SAR (r = 0.919), Na% and SAR (r = 0.965), Na% and SSP (r = 0.937), SAR and SSP (r = 0.972), Na% and KR (r = 0.979), SAR and KR (r = 0.985), SSP and KR (r = 0.986),Na% and Na:Ca (r = 0.984), SAR and Na:Ca (r = 0.973), SSP and Na:Ca (r = 0.962), KR and Na:Ca (r = 0.981) at a significance level, p = <0.01 and EC and SSP (r = 0.887), EC and KR (r = 0.860), TH and RSBC (r = 0.884), EC and Na:Ca (r = 0.834), at a significance level, p = <0.05. Strong negative correlation exists between TH and PI (r = −0.872, p = <0.05), MAR and PI (r = −0.646, p = <0.05), RSBC and PI (r = −0.865, p = <0.05), Mg:Ca and PI (r = −0.643, p = <0.05). The strong correlation between GW and SW parameters may indicate that irrigation water quality parameters are derived from similar roots. 3.6. Fuzzy irrigation water quality index (FIWQI) A clear understanding of water quality is necessary for managing water for irrigation. Finally, IWQI classification made decisions based on fuzzy values. The fuzzy interface system also used linguistic expressions to classify water quality input values into two groups (Dernoncourt, 2013). The fuzzy logic allows more precise and uniform input of water quality for irrigation. As stated by Priya (2013), Agoubi et al. (2016), Mohammed et al. (2019), Chidambaram et al. (2022), and Dhaoui et al. (2022), fuzzy logic can evaluate the water condition better than other measurement methods. The use of fuzzy logic can raise the index of irrigation water quality to another level. It can automate some processes of irrigation system managers and create a simpler and clearer system to determine water quality. It could mimic water quality by providing an alternative response to vague or ambiguous thresholds. Different water quality indices interpret water quality for irrigation differently and produce different results. Fuzzy logic can eliminate some of these ambiguities by introducing a new category of water quality. The irrigation water quality indices (EC, TH, SAR, SSP, KR, MAR, PI, and RSBC) were used as fuzzy model input membership functions in the fuzzy inference system, as shown in Fig. S8. The result of defuzzification after adopting the created rules is the extracted FIWQI, which has a value within 0–1 (Fig. 9). The FIWQI had seven categories of water quality for all inputs, including excellent, excellent to good, good, good to fair, fair, fair to poor, and poor, while the IWQI had only three categories. This suggests that the FIWQI may be a better substitute for other water quality indices, providing an accurate categorization of water quality (Selvaraj et al., 2020; Dhaoui et al., 2022). The FIWQI was compared to the IWQI in Table S9. Download : Download high-res image (343KB) Download : Download full-size image Fig. 9. Classification of water samples using FIWQI from output membership function in the fuzzy toolbox. Most of the water bodies in the study area serve as the center for domestic activities in surrounding communities. Fig. 10 shows that Taraganjhas a relatively lower IWQI than Kishorganj. Most of the Kishorganj upazila had excellent quality water for irrigation, while a majority of the Taraganj upazila was dominated by good quality. The northeastern part of Kishorganj has water of excellent quality for irrigation, while the southwestern Taraganj upazila has less acceptable water quality for irrigation based on the FIWQI. The unsuitable irrigation water was identified mostly in the southwestern part of the Taraganj upazila. Download : Download high-res image (1MB) Download : Download full-size image Fig. 10. Spatial distribution map of (a) IWQI, (b) FIWQI of the groundwater and (c) IWQI, and (d) FIWQI of the surface water samples in the study area. In addition, land use in Taraganj differs slightly from that in Kishoreganj within the study area. Taraganj is more business-oriented, while Kishoreganj is more residential-oriented. The water in Kishorganj is more suitable for irrigation than that in Taraganj. Otherwise, there is a mixed spatial variation for all water parameters. The IWQI map shows that the water samples are suitable for irrigation, according to Simsek and &Gunduz (2007) and Batarseh et al. (2021). Agricultural practices, extensive abstraction of groundwater, sedimentation, rock-water interactions, and dynamic geochemical mechanisms could be the cause of poor water quality in the north-central region (Islam et al., 2017b). Sedimentation and decomposition of different minerals, predominantly agricultural exchange processes, could control the hydrogeochemistry of water (Nepolian, 2017). The result of the FIWQI assessment shows that 100% of the surface water samples were classified as excellent (Table S10). When considering groundwater, 75% of the samples were rated excellent, 12.5% of the samples were rated excellent to good, and 12.5% were rated good for irrigation. These FIWQI results are critical for water quality because it highlights and drive much more stable potential, especially for samples that are in the middle of two groups (Hue and Thanh, 2020; Wagh et al., 2022; Mia et al., 2023). This fuzzy logic method will provide more accurate and consistent irrigation water quality. In its ability to capture the condition of water, the fuzzy technique is useful and superior to other methods. It could be a suitable approach for water quality modeling as it provides an alternative response to situations where boundaries are unclear or ambiguous (de Oliveira et al., 2019; Jha et al., 2020; Trach et al., 2022; Kord and &Arshadi, 2022). 3.7. Sustainable agricultural practices and policy intervention Regarding the findings from this study, water can be used for agricultural production after diagnosing the water resources in the study area. Intensive application of chemical pesticides and fertilizers should be controlled because these chemicals increase the pH of the soil. Residents need to be aware that dumping waste in open waters harms domestic production because it degrades groundwater. The government as well as NGOs should launch an awareness activity among the farmers to promote organic methods instead of industrially produced ones. Western and southwestern areas such as Taraganj are ideal for the short-term production of agricultural crops with minimal water requirements. These recommendations are related to the research area and areas facing similar problems. This research will also help in assessing water purity, putting water quality standards into practice, and monitoring developments in the drought-prone agricultural region. MLR model results show that the most important factors affecting surface and groundwater quality are K+, Na+, and Ca2+. Also, they have an adverse effect on human well-being via the food chain. (Grzebisz, 2011; Paquette et al., 2022; Abdel-Rahman, 2022). A lack of Mg2+ in edible plant parts can lead to Ca2+ shortage in humans, whereas excessive Ca2+ levels in plant roots reduce the plant's resilience to disease (Sharma et al., 2022; Zhang et al., 2022). It is necessary to address the issue of plant roots receiving excess Ca2+ from the soil. As a result, agricultural succession is disrupted, temperatures rise, and water shortages occur on agricultural lands (Wang et al., 2020). Information about irrigation water quality is provided for end consumers as well as others and GIS effectively analyzed precise spatial data in this study. The study was limited to a drought-prone agricultural region in northern Bangladesh, but the findings and lessons are universal. Overconsumption, climate change fluctuations in precipitation, and increased blending of contaminants from various inputs are causing the deterioration of water quality in the study area and in other developing countries, including Bangladesh which creates a matter of discussion. Subtropical climate, geogenic conditions (subsurface lithology that produces contaminants), and human actions can trigger countless concerns regarding water quality and endanger the health of water-consuming organisms. The results of the study can help agencies create a workable plan for managing water resources in the study area. The current research aims to develop decision support tools and mobile apps that take into consideration sustainable agriculture, ongoing water utilize, supply, and demand. This study will help agricultural managers to plan the distribution of irrigation water in the study area and surrounding areas in northern Bangladesh. Regular monitoring should be ensured for sustainable agriculture in the study area. Further studies are needed to improve the purity of drinking water and to ensure water security in the study area. In the future, the quality of groundwater and surface water used for drinking, livestock, and other purposes needs to be checked. 3.8. Implications for future outlook Completing this research has important theoretical and practical implications for developing and adopting sustainable practices. These implications are outlined below: Advancing knowledge: This research has contributed to the existing body of knowledge by providing new insights into environmental challenges and potential solutions. By studying different irrigation matrices, the work has expanded our understanding of the field and uncovered vital factors that influence agricultural quality. This knowledge can be a foundation for future studies and enable further theoretical advances. Conceptual framework: Through the research, this study has developed and refined conceptual frameworks that help understand the complexity of sustainability challenges. This work has created a framework for analyzing and addressing drought-prone agricultural regions by integrating fuzzy logic, geostatistics, and multiple linear models. This framework can guide future research efforts and support the development of comprehensive strategies. Decision-making support: The research findings provide practical guidance to decision-makers in addressing sustainability challenges. Decision makers, such as policymakers and managers, can use our results to make informed decisions prioritizing sustainability and promoting positive environmental outcomes. Community engagement: This study highlights the importance of community engagement and participation in sustainability efforts. The results serve as a foundation for community-based initiatives and empower individuals to actively protect the environment and build resilience. Capacity building: The work helps build capacity by providing information and tools for professionals and practitioners in water resources. This capacity building can facilitate the implementation of sustainable practices and contribute to long-term environmental resilience. By combining theoretical advances with practical implications, this research provides a comprehensive understanding of sustainable water management and actionable steps to address it. These implications pave the way for developing and implementing our current findings, enabling stakeholders to make informed decisions, promote sustainability, and positively impact the community and society at large. 4. Conclusions Both surface and groundwater are the primary water sources for agriculture in northern Bangladesh's drought-prone agricultural region. This study established a robust approach to assess the applicability and select a suitable agricultural zone by coupling IWQI and FIWQI. The surface and groundwater variables affecting the irrigation metrics are investigated using the MLR and RDA models. Surface water was slightly to strongly alkaline, whereas the groundwater was slight acidic to slightly alkaline. The average values for most ions in the groundwater were greater than those in the surface water. According to semivariogram models, low to moderate spatial dependence was found for groundwater, and medium to high spatial dependence was found for surface water quality indices, suggesting agricultural and strong rural influences. The fuzzy-derived spatial map reveals that irrigation water quality in the areas southwest of Taraganj is significantly less suitable than in the remaining region. However, the water in the northern parts of the Kisorganj region was more appropriate for irrigation. Agricultural activities, excessive withdrawal from nearby areas, weathering or rock water interaction, and active geochemical processes may have all contributed to the poor water quality in the southwest region. As a result, it is recommended that short-term crops with lower water requirements may be grown utilizing the region's groundwater resources. To evaluate the general quality of groundwater and surface water, implementing parameter-based irrigation water quality in fuzzy GIS platforms has proven helpful. Determining water quality is an essential tool in irrigation management in many ways, and it is beneficial for the general public and policymakers to be aware of this. The resulting map will also help non-academic users and the general public understand the water quality for irrigation. As a result, the GIS platform could be crucial in decision-making procedures that target agricultural practices and stop regional crop output declines. Even though the research was only conducted in a part of Bangladesh's northern region, its conclusions, and lessons may still be used globally. Similar problems with water quality have been seen in the present research area and in other emerging countries, such as other regions of Bangladesh. Other areas of northern Bangladesh may experience water shortages and quality issues due to excessive water use, variations in rainfall pattern brought about by climate change, and heavy mixing of pollutants from numerous sources. Thus, a sub-humid climate, pre-existing geogenic concerns (e.g., aquifer lithology), and anthropogenic activities may cause several water quality problems and increase the risks to human health associated with drinking water in these areas. Administrators and decision-makers must consider this when creating water quality maps for a sustainable management plan to protect these water resources from further pollution and negative consequences. Additionally, depending on the irrigation water quality, the research aids crop selection. The targeted measures could lessen surface and groundwater pollution to support agricultural output in the future. This study will help agricultural managers plan irrigation water distribution in the study area and surrounding areas in northern Bangladesh. The study's analytical materials will aid regional planners in developing a successful, comprehensive strategy for managing and conserving surface and groundwater. Regular monitoring should be ensured for sustainable agriculture in the study area. In further studies, groundwater and surface water quality for drinking, livestock, and other purposes should be checked. Authors' contributions S M Rabbi Al Zihada: Methodology, Investigation, sample collections and preparation., Md. Yousuf Mia: Methodology, Validation, Abu Reza Md. Towfiqul Islam and S M Rabbi Al Zihad: Conceptualization, Writing - original draft preparation, Writing - reviewing and editing, Supervision. Md. Saiful Islam, Md. Aminul Islam and Md. Abu Bakar Siddique: Sample analysis, data curation and interpretation. Md. Bodrud-Doza, and Sobhy M. Ibrahim: Original draft preparation, reviewing and editing. Venkatramanan Senapathi, A. B. M. Mainul Bari and Sumanta Chatterjee: Reviewing, and editing. All authors read and approved the final manuscript. Funding information The authors extend their appreciation to the Deputyship for Research and Innovation, “Ministry of Education” in Saudi Arabia for funding this research (IFKSUOR3–146–3). Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgment The authors extend their appreciation to the Deputyship for Research and Innovation, “Ministry of Education” in Saudi Arabia for funding this research (IFKSUOR3–146–3). We truly acknowledge the Bangladesh Council of Scientific and Industrial Research (BCSIR), Dhaka, Bangladesh for proving support to analyze the water samples. Appendix A. Supplementary data The following is the Supplementary data to this article. Download : Download Word document (10MB) Multimedia component 1. Data availability Data will be made available on request. References Abbasnia et al., 2019 A. Abbasnia, N. Yousefi, A.H. Mahvi, R. Nabizadeh, M. Radfard, M. Yousef, M. Alimohammadi Evaluation of groundwater quality using water quality index and its suitability for assessing water for drinking and irrigation purposes: case study of Sistan and Baluchistan province (Iran) Hum. Ecol. Risk Assess., 25 (4) (2019), pp. 988-1005 CrossRefView in ScopusGoogle Scholar Abdel-Rahman, 2022 G.N.E. Abdel-Rahman Heavy metals, definition, sources of food contamination, incidence, impacts and remediation: a literature review with recent updates Egypt. J. Chem., 65 (1) (2022), pp. 419-437 View in ScopusGoogle Scholar Acharjee et al., 2022 A. Acharjee, Z. Ahmed, P. Kumar, R. Alam, M.S. Rahman, J. Simal-Gandara Assessment of the ecological risk from heavy metals in the surface sediment of River Surma, Bangladesh: coupled approach of Monte Carlo simulation and multi-component statistical analysis Water, 14 (2) (2022), p. 180 CrossRefView in ScopusGoogle Scholar Adhikary et al., 2012 P.P. Adhikary, C.J. Dash, H. Chandrasekharan, T.B.S. Rajput, S.K. Dubey Evaluation of groundwater quality for irrigation and drinking using GIS and geostatistics in a peri-urban area of Delhi, India Arabian J. Geosci., 5 (2012), pp. 1423-1434 CrossRefView in ScopusGoogle Scholar Agoubi et al., 2016 B. Agoubi, F. Souid, A. Kharroubi, A. Abdallaoui Assessment of hot groundwater in an arid area in Tunisia using geochemical and fuzzy logic approaches Environ. Earth Sci., 75 (2016), pp. 1-12 Google Scholar Ahmed et al., 2020a A. Ahmed, P.K. Ghosh, M. Hasan, A. Rahman Surface and groundwater quality assessment and identification of hydrochemical characteristics of a south-western coastal area of Bangladesh Environ. Monit. Assess., 192 (2020), pp. 1-15 Google Scholar Ahmed et al., 2020b S. Ahmed, S. Khurshid, R. Madan, B.A.A. Amarah, M. Naushad Water quality assessment of shallow aquifer based on Canadian Council of Ministers of the environment index and its impact on irrigation of Mathura District, Uttar Pradesh J. King Saud Univ. Sci., 32 (1) (2020), pp. 1218-1225 View PDFView articleView in ScopusGoogle Scholar Al Mamun et al., 2019 M.A. Al Mamun, M.F. Howladar, M.A. Sohail Assessment of surface water quality using Fuzzy Analytic Hierarchy Process (FAHP): a case study of Piyain River's sand and gravel quarry mining area in Jaflong Sylhet. Groundwater for Sustainable Development, 9 (2019), Article 100208 View PDFView articleView in ScopusGoogle Scholar Al-Mashreki et al., 2023 M.H. Al-Mashreki, M.H. Eid, O. Saeed, A. Székács, P. Szűcs, M. Gad, M.R. Abukhadra, A.A. AlHammadi, M.S. Alrakhami, M.A. Alshabibi, S. Elsayed, M. Khadr, M. Farouk, H.S. Ramadan Integration of geochemical modeling, multivariate analysis, and irrigation indices for assessing groundwater quality in the Al-jawf basin Yemen. Water., 15 (8) (2023), p. 1496, 10.3390/w15081496 View in ScopusGoogle Scholar Alsubih et al., 2022 M. Alsubih, J. Mallick, A.R.M.T. Islam, M.K. Almesfer, N.B. Kahla, S. Talukdar, M. Ahmed Assessing surface water quality for irrigation purposes in some dams of asir region, Saudi Arabia using multi-statistical modeling approaches Water, 14 (9) (2022), p. 1439 CrossRefView in ScopusGoogle Scholar Anonna et al., 2022 T.A. Anonna, Z. Ahmed, R. Alam, M.M. Karim, Z. Xie, P. Kumar, et al. Water quality assessment for drinking and irrigation purposes in Mahananda River Basin of Bangladesh Earth Systems and Environment (2022), pp. 1-12 Google Scholar APHA, 2017 APHA Standard Methods for the Examination of Water and Wastewater; Federation Water Environmental American Public Health Association (APHA), Washington, DC, USA (2017) Google Scholar Aravinthasamy et al., 2020 P. Aravinthasamy, D. Karunanidhi, N. Subba Rao, T. Subramani, K. Srinivasamoorthy Irrigation risk assessment of groundwater in a non-perennial river basin of South India: implication from irrigation water quality index (IWQI) and geographical information system (GIS) approaches Arabian J. Geosci., 13 (2020), pp. 1-14 Google Scholar Asuero et al., 2006 A.G. Asuero, A. Sayago, A.G. González The correlation coefficient: an overview Crit. Rev. Anal. Chem., 36 (1) (2006), pp. 41-59 CrossRefView in ScopusGoogle Scholar Ayers and Westcot, 1985 R.S. Ayers, D.W. Westcot Water Quality for Agriculture, vol. 29, Food and Agriculture Organization of the United Nations Rome (1985) Google Scholar Bari et al., 2022 A.M. Bari, M.T. Siraj, S.K. Paul, S.A. Khan A Hybrid Multi-Criteria Decision-Making approach for analysing operational hazards in heavy fuel oil-based power plants Decision Analytics Journal, 3 (2022), Article 100069 View PDFView articleView in ScopusGoogle Scholar Batarseh et al., 2021 M. Batarseh, E. Imreizeeq, S. Tilev, M. Al Alaween, W. Suleiman, A.M. Al Remeithi, et al. Assessment of groundwater quality for irrigation in the arid regions using irrigation water quality index (IWQI) and GIS-Zoning maps: case study from Abu Dhabi Emirate, UAE Groundwater for Sustainable Development, 14 (2021), Article 100611 View PDFView articleView in ScopusGoogle Scholar BBS, 2013a Bangladesh Bureau of Statistics, District Statistics 2011 Nilphamari, BBS (2013) Google Scholar BBS, 2013b Bangladesh Bureau of statistics,District Statistics 2011 Rangpur, BBS (2013) Google Scholar Biswas and &Naher, 2019 J.C. Biswas, U.A. Naher Soil nutrient stress and rice production in Bangladesh Advances in Rice Research for Abiotic Stress Tolerance, Woodhead Publishing (2019), pp. 431-445 View PDFView articleCrossRefView in ScopusGoogle Scholar Biswas et al., 2023 T. Biswas, S.C. Pal, A. Saha, D. Ruidas, A.R.M.T. Islam, M. Shit Hydro-chemical assessment of groundwater pollutant and corresponding health risk in the Ganges delta, Indo-Bangladesh region J. Clean. Prod., 382 (2023), Article 135229 View PDFView articleView in ScopusGoogle Scholar BMD, 2016 Normal Monthly Rainfall Bangladesh Meteorological Department, BMD (2016) https://live3.bmd.gov.bd/p/Normal-Monthly-Rainfall, Accessed 10th Jan 2023 Google Scholar Boufekane and Saighi, 2019 A. Boufekane, O. Saighi Assessing groundwater quality for irrigation using geostatistical method–Case of wadi Nil Plain (North-East Algeria) Groundwater for Sustainable Development, 8 (2019), pp. 179-186 View PDFView articleView in ScopusGoogle Scholar Brahim et al., 2021 F.B. Brahim, E. Boughariou, S. Bouri Multicriteria-analysis of deep groundwater quality using WQI and fuzzy logic tool in GIS: a case study of Kebilli region, SW Tunisia J. Afr. Earth Sci., 180 (2021), Article 104224 Google Scholar Brindha and &Elango, 2011 K. Brindha, L. Elango Hydrochemical characteristics of groundwater for domestic and irrigation purposes in Madhuranthakam, Tamil Nadu, India Earth Sci. Res. J., 15 (2011), pp. 101-108 (Scieloco) View in ScopusGoogle Scholar Buvaneshwari et al., 2020 S. Buvaneshwari, J. Riotte, M. Sekhar, A.K. Sharma, R. Helliwell, M.S.M. Kumar, J.J. Braun, L. Ruiz Potash fertilizer promotes incipient salinization in groundwater irrigated semi-arid agriculture Sci. Rep., 10 (1) (2020), p. 3691, 10.1038/s41598-020-60365-z View in ScopusGoogle Scholar Carroll, 1962 D. Carroll Rainwater as a chemical agent of geologic processes; a review Water Supply Paper (1962), 10.3133/wsp1535G Google Scholar Chakraborty et al., 2023 T.K. Chakraborty, M.S. Islam, G.C. Ghosh, P. Ghosh, S. Zaman, A. Habib, et al. Human health risk and hydro-geochemical appraisal of groundwater in the southwest part of Bangladesh using GIS, water quality indices, and multivariate statistical approaches Toxin Rev., 42 (1) (2023), pp. 285-299 CrossRefView in ScopusGoogle Scholar Chang et al., 1998 Y.H. Chang, M.D. Scrimshaw, R.H.C. Emmerson, J.N. Lester Geostatistical analysis of sampling uncertainty at the Tollesbury Managed Retreat site in Blackwater Estuary, Essex, UK: kriging and cokriging approach to minimise sampling density Sci. Total Environ., 221 (1) (1998), pp. 43-57, 10.1016/S0048-9697(98)00262-9 View PDFView articleView in ScopusGoogle Scholar Chatterjee et al., 2021 S. Chatterjee, A.E. Hartemink, J. Triantafilis, A.R. Desai, D. Soldat, J. Zhu, et al. Characterization of field-scale soil variation using a stepwise multi-sensor fusion approach and a cost-benefit analysis Catena, 201 (2021), Article 105190 View PDFView articleView in ScopusGoogle Scholar Chidambaram et al., 2022 S. Chidambaram, M.V. Prasanna, S. Venkatramanan, M. Nepolian, K. Pradeep, B. Panda, et al. Groundwater quality assessment for irrigation by adopting new suitability plot and spatial analysis based on fuzzy logic technique Environ. Res., 204 (2022), Article 111729 View in ScopusGoogle Scholar Cordier et al., 2021 T. Cordier, L. Alonso-Sáez, L. Apothéloz-Perret-Gentil, E. Aylagas, D.A. Bohan, A. Bouchez, et al. Ecosystems monitoring powered by environmental genomics: a review of current strategies with an implementation roadmap Mol. Ecol., 30 (13) (2021), pp. 2937-2958 CrossRefView in ScopusGoogle Scholar de Oliveira et al., 2019 M.D. de Oliveira, O.L.T. de Rezende, J.F.R. de Fonseca, M. Libanio Evaluating the surface Water quality index fuzzy and its influence on water treatment J. Water Proc. Eng., 32 (2019), Article 100890 Google Scholar Dernoncourt, 2013 F. Dernoncourt Introduction to Fuzzy Logic, vol. 21, Massachusetts Institute of Technology (2013), pp. 50-56 Google Scholar Dhaoui et al., 2022 O. Dhaoui, B. Agoubi, I.M. Antunes, L. Tlig, A. Kharroubi Groundwater quality for irrigation in an arid region—application of fuzzy logic techniques Environ. Sci. Pollut. Control Ser. (2022), 10.1007/s11356-022-24334-5 Google Scholar Doneen, 1964 L.D. Doneen Notes on Water Quality in Agriculture Department of Water Science and Engineering, University of California, Davis (1964) Google Scholar Egbueri, 2022 J.C. Egbueri Predicting and analysing the quality of water resources for industrial purposes using integrated data-intelligent algorithms Groundwater for Sustainable Development, 18 (2022), Article 100794 View PDFView articleView in ScopusGoogle Scholar Eid et al., 2023 M.H. Eid, M. Elbagory, A.A. Tamma, M. Gad, S. Elsayed, H. Hussein, F.S. Moghanm, A.E.-D. Omara, A. Kovács, S. Péter Evaluation of groundwater quality for irrigation in deep aquifers using multiple graphical and indexing approaches supported with machine learning models and GIS techniques, souf valley, Algeria Water, 15 (2023), p. 182, 10.3390/w15010182 View in ScopusGoogle Scholar Elsayed et al., 2020 S. Elsayed, H. Hussein, F.S. Moghanm, K.M. Khedher, E.M. Eid, M. Gad Application of irrigation water quality indices and multivariate statistical techniques for surface water quality assessments in the northern nile delta, Egypt Water, 12 (2020), p. 3300, 10.3390/w12123300 View in ScopusGoogle Scholar ESRI, 2020 ESRI ArcGIS Desktop (10.8.2) Environmental Systems Research Institute (ESRI) (2020) Google Scholar Fallahati et al., 2020 A. Fallahati, H. Soleimani, M. Alimohammadi, E. Dehghanifard, M. Askari, F. Eslami, L. Karami Impacts of drought phenomenon on the chemical quality of groundwater resources in the central part of Iran—application of GIS technique Environ. Monit. Assess., 192 (2020), pp. 1-19 Google Scholar FAO, 1985 Water Quality for Agriculture. Food and Agriculture Organization of the United Nations, FAO (1985) https://www.fao.org/3/t0234e/T0234E01.htm#ch1.4 Google Scholar Gaagai et al., 2023 A. Gaagai, H.A. Aouissi, S. Bencedira, G. Hinge, A. Athamena, S. Heddam, M. Gad, O. Elsherbiny, S. Elsayed, M.H. Eid, H. Ibrahim Application of water quality indices, machine learning approaches, and GIS to identify groundwater quality for irrigation purposes: a case study of sahara aquifer, doucen plain, Algeria Water, 15 (2) (2023), p. 289, 10.3390/w15020289 View in ScopusGoogle Scholar Gad et al., 2021 M. Gad, M.M. Abou El-Safa, M. Farouk, H. Hussein, A.M. Alnemari, S. Elsayed, M.M. Khalifa, F.S. Moghanm, E.M. Eid, A.H. Saleh Integration of water quality indices and multivariate modeling for assessing surface water quality in Qaroun lake Egypt Water, 13 (2021), p. 2258 CrossRefView in ScopusGoogle Scholar Gad et al., 2023 M. Gad, A. Gaagai, M.H. Eid, P. Szűcs, H. Hussein, O. Elsherbiny, S. Elsayed, M.M. Khalifa, F.S. Moghanm, M.E. Moustapha, D.A. Tolan, H. Ibrahim Groundwater quality and health risk assessment using indexing approaches, multivariate statistical analysis, artificial neural networks, and GIS techniques in el kharga oasis, Egypt Water, 15 (6) (2023), p. 1216, 10.3390/w15061216 View in ScopusGoogle Scholar George and &Ngole-Jeme, 2022 M. George, V.M. Ngole-Jeme An evaluation of the khubelu wetland and receiving stream water quality for community use Water, 14 (3) (2022), p. 442 CrossRefView in ScopusGoogle Scholar George and Mallery, 2010 D. George, P. Mallery SPSS for Windows Step by Step : a Simple Guide and Reference viaf)92115668 (tenth ed.), Allyn & Bacon, Boston (2010) 17.0 update http://lib.ugent.be/catalog/rug01:001424067 Google Scholar Gharibi et al., 2019 A. Gharibi, Z.I. Ali, M. Zairi Groundwater suitability for irrigation and agricultural purposes using irrigation water quality index and multivariate analysis: case of Sidi Bouzaid aquifer, central Tunisia Environ. Earth Sci., 78 (2019), p. 692 Google Scholar Goovaerts, 2000 P. Goovaerts Geostatistical approaches for incorporating elevation into the spatial interpolation of rainfall J. Hydrol., 228 (1–2) (2000), pp. 113-129 View PDFView articleView in ScopusGoogle Scholar Grzebisz, 2011 W. Grzebisz Magnesium–food and human health Journal of Elementology, 16 (2) (2011) Google Scholar Gundogdu and &Guney, 2007 K.S. Gundogdu, I. Guney Spatial analyses of groundwater levels using universal kriging J. Earth Syst. Sci., 116 (1) (2007), pp. 49-55, 10.1007/s12040-007-0006-6 View in ScopusGoogle Scholar Gupta, 1983 S.K. Gupta Variations of Water Table in Yamuna Drainage Basin of Haryana-implications and Management Strategies Seminar on Strategies for Irrigation Water Management, Patna (1983) Google Scholar Hajji et al., 2021 S. Hajji, N. Yahyaoui, S. Bousnina, F. Ben Brahim, N. Allouche, H. Faiedh, S. Bouri, W. Hachicha, A.M. Aljuaid Using a mamdani fuzzy inference system model (Mfism) for ranking groundwater quality in an agri-environmental context: case of the hammamet-nabeul shallow aquifer (Tunisia) Water, 13 (18) (2021), p. 2507 CrossRefView in ScopusGoogle Scholar Horton, 1965 R.K. Horton An index number system for rating water quality J. Water Pollut. Control Fed., 37 (1965), pp. 300-306 Google Scholar Howladar et al., 2014 M. Howladar, P. Deb, S. Mazumder, D. Ahmed Evaluation of Water Resources Around Barapukuria Coal Mine Industrial Area, Dinajpur, Bangladesh, vol. 4, Applied Water Science - Springer (2014), 10.1007/s13201-014-0207-5 Google Scholar Huang et al., 2020 T.Y. Huang, F.Z. Teng, R.L. Rudnick, X.Y. Chen, Y. Hu, Y.S. Liu, F.Y. Wu Heterogeneous potassium isotopic composition of the upper continental crust Geochem. Cosmochim. Acta, 278 (2020), pp. 122-136 View PDFView articleView in ScopusGoogle Scholar Hue and Thanh, 2020 N.H. Hue, N.H. Thanh Surface water quality analysis using fuzzy logic approach: a case of inter-provincial irrigation network in vietnam IOP Conf. Ser. Earth Environ. Sci., 527 (1) (2020), Article 012017 CrossRefView in ScopusGoogle Scholar Hussain and Abdullah, 2001 Hussain, M.M., Abdullah, S.K.M., 2001. Geological setting of the areas of arsenic aquifers, ground water task force (No. 1). interim report. Local Government Division, Minitry of Local Government, Rural Development & Cooperatives, Bangladesh, pp. A 1-A 45. Google Scholar Ibrahim et al., 2023 H. Ibrahim, Z.M. Yaseen, M. Scholz, M. Ali, M. Gad, S. Elsayed, M. Khadr, H. Hussein, H.H. Ibrahim, M.H. Eid, A. Kovács, S. Péter, M.M. Khalifa Evaluation and prediction of groundwater quality for irrigation using an integrated water quality indices, machine learning models and GIS approaches: a representative case study Water, 15 (4) (2023), p. 694, 10.3390/w15040694 View in ScopusGoogle Scholar Islam and Mostafa, 2022 M.S. Islam, M.G. Mostafa Development of an integrated irrigation water quality index (IIWQIndex) model Water Supply, 22 (2) (2022), pp. 2322-2337 CrossRefView in ScopusGoogle Scholar Islam et al., 2014 M.S. Islam, A.R.M.T. Islam, F. Rahman, F. Ahmed, M.N. Haque Geomorphology and land use mapping of northern part of Rangpur District, Bangladesh Journal of Geosciences and Geomatics, 2 (4) (2014), pp. 145-150 CrossRefGoogle Scholar Islam et al., 2017a A.R.M.T. Islam, S. Shen, M. Bodrud-Doza, M. Atiqur Rahman, S. Das Assessment of trace elements of groundwater and their spatial distribution in Rangpur district, Bangladesh Arabian J. Geosci., 10 (4) (2017), 10.1007/s12517-017-2886-3 Google Scholar Islam et al., 2017b A.R.M.T. Islam, S. Shen, M.D. Bodrud-Doza, M. Safiur Rahman Assessing irrigation water quality in Faridpur district of Bangladesh using several indices and statistical approaches Arabian J. Geosci., 10 (19) (2017), p. 418, 10.1007/s12517-017-3199-2 Google Scholar Islam et al., 2018 A.R.M.T. Islam, S. Shen, M.A. Haque, M. Bodrud-Doza, K.W. Maw, M.A. Habib Assessing groundwater quality and its sustainability in Joypurhat district of Bangladesh using GIS and multivariate statistical approaches Environ. Dev. Sustain., 20 (2018), pp. 1935-1959 CrossRefView in ScopusGoogle Scholar Islam et al., 2022 M.S. Islam, K. Nakagawa, M. Abdullah-Al-Mamun, A.S. Khan, M.A. Goni, R. Berndtsson Spatial distribution and source identification of water quality parameters of an industrial seaport riverbank area in Bangladesh Water, 14 (9) (2022), p. 1356 CrossRefView in ScopusGoogle Scholar Jannat et al., 2022 J.N. Jannat, M.S.I. Khan, H.T. Islam, M.S. Islam, R. Khan, M.A.B. Siddique, M. Varol, C. Tokatli, S.C. Pal, A. Islam, A.M. Idris, G. Malafia, A.R.M.T. Islam Hydro-chemical assessment of fluoride and nitrate in groundwater from east and west coasts of Bangladesh and India J. Clean. Prod., 372 (2022), Article 133675 View PDFView articleView in ScopusGoogle Scholar Jaydhar et al., 2022 A.K. Jaydhar, S.C. Pal, A. Saha, A.R.M.T. Islam, D. Ruidas Hydrogeochemical evaluation and corresponding health risk from elevated arsenic and fluoride contamination in recurrent coastal multi-aquifers of eastern India J. Clean. Prod., 369 (2022), Article 133150 View PDFView articleView in ScopusGoogle Scholar Jha et al., 2020 M.K. Jha, A. Shekhar, M.A. Jenifer Assessing groundwater quality for drinking water supply using hybrid fuzzy-GIS-based water quality index Water Res., 179 (2020), Article 115867 View PDFView articleView in ScopusGoogle Scholar Kabir et al., 2021 M.M. Kabir, N. Hossain, A.R.M.T. Islam, S. Akter, K.J. Fatema, L.N. Hilary, et al. Characterization of groundwater hydrogeochemistry, quality, and associated health hazards to the residents of southwestern Bangladesh Environ. Sci. Pollut. Control Ser., 28 (48) (2021), pp. 68745-68761 CrossRefView in ScopusGoogle Scholar Kadir et al., 2022 A. Kadir, Z. Ahmed, M. Uddin, Z. Xie, P. Kumar Integrated approach to quantify the impact of land use and land cover changes on water quality of surma river, sylhet, Bangladesh Water, 14 (1) (2022), p. 17 View in ScopusGoogle Scholar Karmaker et al., 2023 C.L. Karmaker, R. Al Aziz, T. Palit, A.M. Bari Analyzing supply chain risk factors in the small and medium enterprises under fuzzy environment: implications towards sustainability for emerging economies Sustainable Technology and Entrepreneurship, 2 (1) (2023), Article 100032 View PDFView articleView in ScopusGoogle Scholar Kelley, 1963 W.P. Kelley Use of saline irrigation water Soil Sci., 95 (6) (1963), pp. 385-391 CrossRefView in ScopusGoogle Scholar Khadr et al., 2021 M. Khadr, M. Gad, S. El-Hendawy, N. Al-Suhaibani, Y.H. Dewir, M.U. Tahir, M. Mubushar, S. Elsayed The integration of multivariate statistical approaches, hyperspectral reflectance, and data-driven modeling for assessing the quality and suitability of groundwater for irrigation Water, 13 (2021), p. 35 View in ScopusGoogle Scholar Konwea et al., 2023 C.I. Konwea, F.C. Eziagor, D.E. Evurani, O. Ajayi Characterization and assessment of groundwater from Obafemi Awolowo University campus, southwestern Nigeria Phys. Chem. Earth, Parts A/B/C, 129 (2023), Article 103354, 10.1016/j.pce.2022.103354 View PDFView articleView in ScopusGoogle Scholar Kord and &Arshadi, 2022 M. Kord, B. Arshadi Applying the water quality index with fuzzy logic as a way to analyze multiple long-term groundwater quality data: a case study of Dehgolān plain Arabian J. Geosci., 15 (3) (2022), p. 253 Google Scholar Krishna Kumar et al., 2015 S. Krishna Kumar, A. Logeshkumaran, N.S. Magesh, P.S. Godson Hydro-geochemistry and application of water quality index (DWQI) for groundwater quality assessment, Anna Nagar, part of Chennai city, Tamil Nadu, India Appl. Water Sci., 5 (2015), pp. 335-343 CrossRefView in ScopusGoogle Scholar Kumar et al., 2019 D. Kumar, A. Singh, R.K. Jha, B.B. Sahoo, S.K. Sahoo, V. Jha Source characterization and human health risk assessment of nitrate in groundwater of middle Gangetic Plain, India Arabian J. Geosci., 12 (2019), pp. 1-12 View in ScopusGoogle Scholar Lesch and Suarez, 2009 S.M. Lesch, D.L. Suarez Technical note: a short note on calculating the adjusted sar index Transactions of the ASABE, 52 (2) (2009), pp. 493-496 View in ScopusGoogle Scholar Li et al., 2019 P. Li, R. Tian, R. Liu Solute geochemistry and multivariate analysis of water quality in the Guohuaphosphorite Mine, Guizhou Province, China Expo Health, 11 (2019), pp. 81-94 CrossRefView in ScopusGoogle Scholar Malik et al., 2021 S. Malik, S.C. Pal, A. Arabameri, I. Chowdhuri, A. Saha, R. Chakrabortty, P. Roy, B. Das GIS-based statistical model for the prediction of flood hazard susceptibility Environ. Dev. Sustain., 23 (2021), pp. 16713-16743 CrossRefView in ScopusGoogle Scholar Mamdani and &Assilian, 1975 E.H. Mamdani, S. Assilian An experiment in linguistic synthesis with a fuzzy logic controller Int. J. Man Mach. Stud., 7 (1) (1975), pp. 1-13, 10.1016/S0020-7373(75)80002-2 View PDFView articleGoogle Scholar ManjunathaNanjegowda et al., 2013 L. ManjunathaNanjegowda, R. Bommulu, V. Juikar, S. Hatna Investigation on the influence of different compatibilizers on polycarbonate and high density polyethylene blends: mechanical properties, thermal properties, morphology, and chemical resistance Ind. Eng. Chem. Res., 52 (16) (2013), pp. 5672-5682, 10.1021/ie303382g View in ScopusGoogle Scholar Masoud et al., 2022 M. Masoud, M. El Osta, A. Alqarawy, S. Elsayed, M. Gad Evaluation of groundwater quality for agricultural under different conditions using water quality indices, partial least squares regression models, and GIS approaches Appl. Water Sci., 12 (2022), p. 244, 10.1007/s13201-022-01770-9 View in ScopusGoogle Scholar Mckone and Deshpande, 2005 T.E. Mckone, A.W. Deshpande Can fuzzy logic bring complex environmental problems into focus? Environ. Sci. Technol., 39 (2005) Google Scholar Mebarki et al., 2021 S. Mebarki, B. Kharroubi, M.A. Kendouci Physicochemical evolution and evaluation of groundwater quality in Mougheul area (Southwest of Algeria) Appl. Water Sci., 11 (2) (2021), p. 40, 10.1007/s13201-021-01368-7 View in ScopusGoogle Scholar Mia et al., 2023 M.Y. Mia, A.R.M.T. Islam, J.N. Jannat, M.M.M.F. Jion, A. Sarker, C. Tokatli, M.A.B. Siddique, S.M. Ibrahim, V. Senapathi Identifying factors affecting irrigation metrics in the Haor basin using integrated Shannon's entropy, fuzzy logic and automatic linear model Environ. Res., 115688 (2023), 10.1016/j.envres.2023.115688 Google Scholar Mikunthan et al., 2010 T. Mikunthan, S.C. Nishanthiny, M. Thushyanthy, T. Barathithasan, S. Saravanan Irrigation water quality based on hydro chemical analysis, jaffna, Sri Lanka electro coagulation view project identification of alage view project irrigation water quality based on hydro chemical analysis, jaffna, Sri Lanka J. Agric. & Environ. Sci, 7 (1) (2010), pp. 100-102 https://www.researchgate.net/publication/263118906 Google Scholar Mohammed et al., 2019 A. Mohammed, I. Harris, A. Soroka, R. Nujoom A hybrid MCDM-fuzzy multi-objective programming approach for a G-resilient supply chain network design Comput. Ind. Eng., 127 (2019), pp. 297-312 View PDFView articleView in ScopusGoogle Scholar Mokhtar et al., 2022 A. Mokhtar, A. Elbeltagi, Y. Gyasi-Agyei, N. Al-Ansari, M.K. Abdel-Fattah Prediction of irrigation water quality indices based on machine learning and regression models Appl. Water Sci., 12 (4) (2022), p. 76 View in ScopusGoogle Scholar Moore et al., 2006 A.W. Moore, B. Anderson, K. Das, W.K. Wong Combining multiple signals for biosurveillance Handbook of Biosurveillance, 235–242 (2006), 10.1016/B978-012369378-5/50017-X Google Scholar Muhamad et al., 2020 S.N.N. Muhamad, M.F.I.M. Idris, N.I.H. Wahab, W.N.W. Shahidan Fuzzy logic water quality index (FWQI) model in determining the water quality status of river in penang Island N.Z. Alias, R. Yusof (Eds.), Charting the Sustainable Future of ASEAN in Science and Technology, Springer Singapore (2020), pp. 399-410 CrossRefGoogle Scholar Nepolian, 2017 M. Nepolian Geochemical Variation of Groundwater in a Hard Rock Aquifer of Villupuram District Tamilnadu (2017) Google Scholar Nwankwoala and &Udom, 2011 H.O. Nwankwoala, G.J. Udom Hydrochemical facies and ionic ratios of groundwater in Port Harcourt, Southern Nigeria Res. J. Chem. Sci., 1 (3) (2011), pp. 87-101 Google Scholar Oladipo et al., 2020 J.O. Oladipo, O.S. Aboyeji, A.S. Akinwumiju, A.A. Adelodun Fuzzy logic interference for characterization of surface water potability in Ikare rural community, Nigeria Journal of Geovisualization and Spatial Analysis, 4 (2020), pp. 1-14 View in ScopusGoogle Scholar OriginLab, 2022 OriginLab Origin Pro (No. 2022 OriginLab Corporation (2022) https://www.originlab.com Google Scholar Pandey et al., 2020 D.C. Pandey, G.S. Kushwaha, S. Kumar Mamdani fuzzy rule-based models for psychological research SN Appl. Sci., 2 (5) (2020), p. 913, 10.1007/s42452-020-2726-z View in ScopusGoogle Scholar Panneerselvam et al., 2021 B. Panneerselvam, K. Muniraj, M. Thomas, N. Ravichandran GIS-based legitimatic evaluation of groundwater's health risk and irrigation susceptibility using water quality index, pollution index, and irrigation indexes in semiarid region Groundwater Resources Development and Planning in the Semi-arid Region, Springer International Publishing, Cham (2021), pp. 239-268 CrossRefView in ScopusGoogle Scholar Paquette et al., 2022 C. Paquette, I. Gregory-Eaves, B.E. Beisner Environmental drivers of taxonomic and functional variation in zooplankton diversity and composition in freshwater lakes across Canadian continental watersheds Limnol. Oceanogr., 67 (5) (2022), pp. 1081-1097 CrossRefView in ScopusGoogle Scholar Piper, 1944 A.M. Piper A graphic procedure in the geochemical interpretation of water-analyses Eos, Transactions American Geophysical Union, 25 (6) (1944), pp. 914-928, 10.1029/TR025I006P00914 View in ScopusGoogle Scholar Prakash et al., 2020 R. Prakash, K. Srinivasamoorthy, S. Gopinath, K. Saravanan, F. Vinnarasi Hydrogeochemical investigations to assess groundwater and saline water interaction in coastal aquifers of the southeast coast, Tamil Nadu, India Environ. Sci. Pollut. Res., 28 (2020), pp. 5495-5519 Google Scholar Priya, 2013 K.L. Priya A fuzzy logic approach for irrigation water quality assessment: a case study of Karunya Watershed, India J Hydrogeol Hydrol Eng, 2 (2013), p. 1 of, 8, 2 Google Scholar Qishlaqi et al., 2017 A. Qishlaqi, S. Kordian, A. Parsaie Hydrochemical evaluation of river water quality—a case study Appl. Water Sci., 7 (2017), pp. 2337-2342 CrossRefView in ScopusGoogle Scholar Raghunath, 1987 H.M. Raghunath Ground Water: Hydrogeology, Ground Water Survey and Pumping Tests, Rural Water Supply and Irrigation Systems (second ed.), New Age International (1987) Google Scholar Rahman and Islam, 2019 M.S. Rahman, A.R.M.T. Islam Are precipitation concentration and intensity changing in Bangladesh overtimes? Analysis of the possible causes of changes in precipitation systems Sci. Total Environ., 690 (2019), pp. 370-387, 10.1016/j.scitotenv.2019.06.529 View PDFView articleView in ScopusGoogle Scholar Rahman et al., 2017 M.S. Rahman, N. Saha, A.T. Islam, S. Shen, M. Bodrud-Doza Evaluation of water quality for sustainable agriculture in Bangladesh Water, Air, Soil Pollut., 228 (2017), pp. 1-16 View in ScopusGoogle Scholar Raihan and &Alam, 2008 F. Raihan, J.B. Alam Assessment of groundwater quality in Sunamganj of Bangladesh Iran. J. Environ. Health Sci. Eng., 5 (3) (2008), pp. 155-166 View in ScopusGoogle Scholar Raman et al., 2009 B.V. Raman, R. Bouwmeester, S. Mohan Fuzzy logic water quality index and importance of water quality parameters Air Soil. Water Res., 2 (2009) ASWR-S2156 Google Scholar Rao et al., 2021 N.S. Rao, A. Dinakar, M. Sravanthi, B.K. Kumari Geochemical characteristics and quality of groundwater evaluation for drinking, irrigation, and industrial purposes from a part of hard rock aquifer of South India Environ. Sci. Pollut. Control Ser., 28 (2021), pp. 31941-31961 CrossRefView in ScopusGoogle Scholar Ratri et al., 2021 D. Ratri, D.P.E. Putra, W. Wilopo Groundwater geochemistry and hydrogeochemical processes assessment in Bantul, Yogyakarta, Indonesia IOP Conf. Ser. Earth Environ. Sci., 958 (1) (2021), Article 012013, 10.1088/1755-1315/958/1/012013 Google Scholar Ravindra et al., 2022 B. Ravindra, N. Subba Rao, E.N. Dhanamjaya Rao Groundwater Quality Monitoring for Assessment of Pollution Levels and Potability Using WPI and WQI Methods from a Part of Guntur District, Andhra Pradesh Environment, Development and Sustainability, India (2022), pp. 1-31 Google Scholar Richards, 1954 L.A. Richards Diagnosis and improvement of saline and alkali soils LWW, 78 (No. 2) (1954), p. 154 CrossRefGoogle Scholar Ruidas et al., 2022 D. Ruidas, S.C. Pal, A.R.M. Towfiqul Islam, A. Saha Hydrogeochemical evaluation of groundwater aquifers and associated health hazard risk mapping using ensemble data driven model in a water scares plateau region of eastern India Exposure and Health (2022), pp. 1-19 Google Scholar Saha et al., 2019 S. Saha, A.H.M.S. Reza, M.K. Roy Hydrochemical evaluation of groundwater quality of the Tista floodplain, Rangpur, Bangladesh Appl. Water Sci., 9 (8) (2019), pp. 1-12, 10.1007/S13201-019-1085-7 2019 9:8 Google Scholar Salam et al., 2020 R. Salam, A.R.M.T. Islam, Q.B. Pham, M. Dehghani, N. Al Ansari, N.T.T. Linh The optimal alternative for quantifying reference evapotranspiration in climatic sub-regions of Bangladesh Sci. Rep., 10 (1) (2020), Article 20171, 10.1038/s41598-020-77183-y View in ScopusGoogle Scholar Salem et al., 2018 Z. Salem, A. Al Temamy, M. Salah, M. Kassab Evaluation of water resources qualities for agriculture irrigation in Abu madi area, northern middle nile delta Handbook of Environmental Chemistry (2018), 10.1007/698_2018_273 Google Scholar Salman and Seno, 2010 M.A. Salman, N.I. Seno A comparison of Mamdani and Sugeno inference systems for a satellite image classification Anbar Journal for Engineering Sciences (2010), pp. 296-306 Google Scholar Sarkar et al., 2022 M. Sarkar, S.C. Pal, A.R.M.T. Islam Groundwater quality assessment for safe drinking water and irrigation purposes in Malda district, Eastern India Environ. Earth Sci., 81 (2) (2022), p. 52 View in ScopusGoogle Scholar Sarker et al., 2021 M.R. Sarker, M.V. Galdos, A.J. Challinor, A. Hossain A farming system typology for the adoption of new technology in Bangladesh Food Energy Secur., 10 (3) (2021), p. e287, 10.1002/FES3.287 View in ScopusGoogle Scholar Selvakumar et al., 2017 S. Selvakumar, N. Chandrasekar, G. Kumar Hydrogeochemical characteristics and groundwater contamination in the rapid urban development areas of Coimbatore, India Water Resour. Ind., 17 (2017), pp. 26-33, 10.1016/j.wri.2017.02.002 View PDFView articleView in ScopusGoogle Scholar Selvaraj et al., 2020 A. Selvaraj, S. Saravanan, J.J. Jennifer Mamdani fuzzy based decision support system for prediction of groundwater quality: an application of soft computing in water resources Environ. Sci. Pollut. Control Ser., 27 (20) (2020), pp. 25535-25552, 10.1007/s11356-020-08803-3 View in ScopusGoogle Scholar Semiromi et al., 2011 F.B. Semiromi, A.H. Hassani, A. Torabian, A.R. Karbassi, F.H. Lotfi Water quality index development using fuzzy logic: a case study of the Karoon River of Iran Afr. J. Biotechnol., 10 (50) (2011), pp. 10125-10133 Google Scholar Shah et al., 2022 K.M. Shah, I.H. Billinge, X. Chen, H. Fan, Y. Huang, R.K. Winton, N.Y. Yip Drivers, challenges, and emerging technologies for desalination of high-salinity brines: a critical review Desalination, 538 (2022), Article 115827 View PDFView articleView in ScopusGoogle Scholar Shammi et al., 2023 R.S. Shammi, Md Saddam Hossain, M.H. Kabir, M.S. Islam, M.T.I. Taj, Md Shafiqul Islam, M.E. Sarker, Md Samrat Hossain, A.M. Idris Hydrochemical appraisal of surface water from a subtropical urban river in southwestern Bangladesh using indices, GIS, and multivariate statistical analysis Environ. Sci. Pollut. Res., 30 (2023), pp. 3467-3489 CrossRefView in ScopusGoogle Scholar Sharma et al., 2022 B. Sharma, M. Shrivastava, L.O. Afonso, U. Soni, D.M. Cahill Zinc-and magnesium-doped hydroxyapatite nanoparticles modified with urea as smart nitrogen fertilizers ACS Appl. Nano Mater., 5 (5) (2022), pp. 7288-7299 CrossRefView in ScopusGoogle Scholar Siddique et al., 2022 M.A.B. Siddique, A.R.M.T. Islam, M.S. Hossain, R. Khan, M.A. Akbor, M. Hasanuzzaman, M. Bodrud-Doza Multivariate statistics and entropy theory for irrigation water quality and entropy-weighted index development in a subtropical urban river, Bangladesh Environ. Sci. Pollut. Control Ser. (2022), pp. 1-20 View in ScopusGoogle Scholar Simsek and &Gunduz, 2007 C. Simsek, O. Gunduz IWQ index: a GIS-Integrated technique to assess irrigation water quality Environ. Monit. Assess., 128 (2007), pp. 277-300, 10.1007/s10661-006-9312-8 View in ScopusGoogle Scholar Singh et al., 2020 K.R. Singh, R. Dutta, A.S. Kalamdhad, B. Kumar Review of existing heavy metal contamination indices and development of an entropy-based improved indexing approach Environ. Dev. Sustain., 22 (2020), pp. 7847-7864 CrossRefView in ScopusGoogle Scholar Srivastava and &Parimal, 2020 A.K. Srivastava, P.S. Parimal Source rock weathering and groundwater suitability for irrigation in Purna alluvial basin, Maharashtra, central India J. Earth Syst. Sci., 129 (1) (2020), p. 52, 10.1007/s12040-019-1312-5 View in ScopusGoogle Scholar Su et al., 2023 X. Su, C. Lu, M. Li, Y. Wang, N. Wang Using 222Rn temporal and spatial distributions to estimate the groundwater discharge rate and associated nutrient fluxes into high salinity lakes in Badain Jaran Desert, Northwest China Sci. Total Environ., 857 (2023), Article 159359 View PDFView articleView in ScopusGoogle Scholar Sugeno, 1985 M. Sugeno Industrial Applications of Fuzzy Control (First) Elsevier Science Pub. Co., Japan (1985) Google Scholar Tajwar et al., 2023 M. Tajwar, A. Uddin, M.K. Lee, J. Nelson, A. Zahid, N. Sakib Hydrochemical characterization and quality assessment of groundwater in Hatiya Island, southeastern coastal region of Bangladesh Water, 15 (5) (2023), p. 905 CrossRefView in ScopusGoogle Scholar Theodossiou and Latinopoulos, 2006 N. Theodossiou, P. Latinopoulos Evaluation and optimisation of groundwater observation networks using the Kriging methodology Environ. Model. Software, 21 (7) (2006), pp. 991-1000 View PDFView articleView in ScopusGoogle Scholar Todd, 1980 D.K. Todd Groundwater Hydrology (second ed., Vol. 535) (1980) Google Scholar Trach et al., 2022 R. Trach, Y. Trach, A. Kiersnowska, A. Markiewicz, M. Lendo-Siwicka, K. Rusakov A study of assessment and prediction of water quality index using fuzzy logic and ANN models Sustainability, 14 (9) (2022), p. 5656 CrossRefView in ScopusGoogle Scholar Tsiko and Haile, 2011 R.G. Tsiko, T.S. Haile Integrating geographical information systems, fuzzy logic and analytical hierarchy process in modelling optimum sites for locating water reservoirs A case study of the Debub District in Eritrea. Water, 3 (1) (2011), pp. 254-290 CrossRefView in ScopusGoogle Scholar Tushar et al., 2022 Z.N. Tushar, A.M. Bari, M.A. Khan Circular supplier selection in the construction industry: a sustainability perspective for the emerging economies Sustainable Manufacturing and Service Economics, 1 (2022), Article 100005 View PDFView articleGoogle Scholar UCCC, 1974 UCCC Guidelines for Interpretations of Water Quality for Irrigation University of California Committee of Consultants, California, USA (1974) Google Scholar van den Wollenberg, 1977 A.L. van den Wollenberg Redundancy analysis an alternative for canonical correlation analysis Psychometrika, 42 (2) (1977), pp. 207-219, 10.1007/BF02294050 View in ScopusGoogle Scholar Venkatramanan et al., 2015 S. Venkatramanan, S.Y. Chung, R. Rajesh, S.Y. Lee, T. Ramkumar, M.V. Prasanna Comprehensive studies of hydrogeochemical processes and quality status of groundwater with tools of cluster, grouping analysis, and fuzzy set method using GIS platform: a case study of Dalcheon in Ulsan City, Korea Environ. Sci. Pollut. Control Ser., 22 (2015), pp. 11209-11223 CrossRefView in ScopusGoogle Scholar Venkatramanan et al., 2017 S. Venkatramanan, S.Y. Chung, S. Selvam, S.Y. Lee, H.E. Elzain Factors controlling groundwater quality in the Yeonjegu District of Busan City, Korea, using the hydrogeochemical processes and fuzzy GIS Environ. Sci. Pollut. Control Ser., 24 (2017), pp. 23679-23693 CrossRefView in ScopusGoogle Scholar Wackernagel, 2003 H. Wackernagel Ordinary kriging H. Wackernagel (Ed.), Multivariate Geostatistics: an Introduction with Applications, Springer Berlin Heidelberg (2003), pp. 79-88, 10.1007/978-3-662-05294-5_11 Google Scholar Wagh et al., 2022 S.J. Wagh, P.M. Paithane, S.N. Patil Applications of fuzzy logic in assessment of groundwater quality index from jafrabad taluka of marathawada region of Maharashtra state: a GIS based approach Hybrid Intelligent Systems: 21st International Conference on Hybrid Intelligent Systems (HIS 2021), Springer International Publishing, Cham (2022), pp. 354-364 December 14–16, 2021 CrossRefView in ScopusGoogle Scholar Wang et al., 2020 Z. Wang, M.U. Hassan, F. Nadeem, L. Wu, F. Zhang, X. Li Magnesium fertilization improves crop yield in most production systems: a meta-analysis Front. Plant Sci., 10 (2020), p. 1727 Google Scholar Wilcox, 1955 L. Wilcox Classification and Use of Irrigation Waters (Issue 969) United States Salinity Laboratory, US Department of Agriculture (1955) Google Scholar Yanar and &Akyürek, 2006 T.A. Yanar, Z. Akyürek The enhancement of the cell-based GIS analyses with fuzzy processing capabilities Inf. Sci., 176 (8) (2006), pp. 1067-1085 View PDFView articleView in ScopusGoogle Scholar Zadeh, 2008 L.A. Zadeh Is there a need for fuzzy logic? Inf. Sci., 178 (13) (2008), pp. 2751-2779 View PDFView articleView in ScopusGoogle Scholar Zafar et al., 2022 M.M. Zafar, M.A. Sulaiman, R. Prabhakar, A. Kumari Evaluation of the suitability of groundwater for irrigational purposes using irrigation water quality indices and geographical information systems (GIS) at Patna (Bihar), India International Journal of Energy and Water Resources (2022), pp. 1-14 Google Scholar Zakir et al., 2020 H.M. Zakir, S. Sharmin, A. Akter, M.S. Rahman Assessment of health risk of heavy metals and water quality indices for irrigation and drinking suitability of waters: a case study of Jamalpur Sadar area, Bangladesh Environmental advances, 2 (2020), Article 100005 View PDFView articleView in ScopusGoogle Scholar Zhang et al., 2022 Y. Zhang, X. Tan, G. Duan, J. Cui, M. Ren, J. Cao, et al. Magnesium slag for remediation of cadmium‐and arsenic‐contaminated paddy soil: a field study Soil Use Manag., 38 (3) (2022), pp. 1470-1480 Google Scholar DoE, 1997 DoE, 1997. In: The Environment Conservation Rules, vol. 1997. Ministry of Environment and Forest, Government of the People’s Republic of Bangladesh Vol. S.R.O.No https://www.elaw.org/system/files/Bangladesh+Environmental+Conservation+Rules,+1997.pdf. Google Scholar Cited by (6) Evaluation of groundwater quality indices using multi-criteria decision-making techniques and a fuzzy logic model in an irrigated area 2024, Groundwater for Sustainable Development Show abstract Ecological risk assessment, source identification and spatial distribution of organic contaminants in terms of mucilage threat in streams of Çanakkale Strait Basin (Türkiye) 2024, Chemosphere Show abstract Using unsupervised machine learning models to drive groundwater chemistry and associated health risks in Indo-Bangla Sundarban region 2024, Chemosphere Show abstract Gender-based vulnerability and adaptive capacity in the disaster-prone coastal areas from an intersectionality perspective 2024, Climate Risk Management Show abstract Analyzing the factors influencing the wind energy adoption in Bangladesh: A pathway to sustainability for emerging economies 2023, Energy Strategy Reviews Show abstract Appraisal of Water Metrics in a Drought-Prone Agricultural Basin By Adopting Fuzzy Logic Technique 2023, SSRN View Abstract © 2023 Elsevier Inc. All rights reserved. Recommended articles Analyzing the factors influencing the wind energy adoption in Bangladesh: A pathway to sustainability for emerging economies Energy Strategy Reviews, Volume 50, 2023, Article 101265 Binoy Debnath, …, Abu Reza Md Towfiqul Islam View PDF Fundamental alteration of cellular biochemicals from attached microalgae onto palm kernel expeller waste upon optimizing the growth environment in forming adhesion complex Environmental Research, Volume 233, 2023, Article 116533 Hemamalini Rawindran, …, Hui-Suan Ng View PDF Association of greenness surrounding school with aggression among adolescents: A multi-site study in China Environmental Research, Volume 234, 2023, Article 116529 Yi Zhang, …, Jie Tang View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 2 Captures Readers: 9 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply."

Paper 5:
- APA Citation: Zhang, Y., Wang, L., Shi, Y., Xiao, Z., & Zhang, S. (2022). Resilience and Fault Tolerance in Automated Irrigation Systems: A Review. Agronomy, 12(12), 2964.
  Main Objective: To investigate resilience and fault tolerance strategies in automated irrigation systems, with a focus on redundancy techniques.
  Study Location: Unspecified
  Data Sources: Literature review
  Technologies Used: Not specified in the abstract
  Key Findings: Redundant components, such as sensors, controllers, and communication channels, can significantly improve the reliability and resilience of automated irrigation systems. Implementing redundancy strategies minimizes system downtime and ensures continuous operation, even during component failures.
  Extract 1: "Redundancy is a critical strategy to ensure the continuous operation of automated irrigation systems. By duplicating key components and providing multiple pathways for data transmission, automated systems can minimize the impact of component failures and maintain system functionality."
  Extract 2: "Implementing redundant sensors and controllers allows for cross-checking and validation of data, enhancing the reliability of the system. Additionally, employing redundant communication channels ensures seamless data transmission and prevents system downtime due to communication failures."
  Limitations: The paper focuses solely on hardware redundancy and does not explore software or algorithmic redundancy techniques.
  Relevance Evaluation: This paper is highly relevant to the review as it directly addresses the point of redundancy in automated irrigation systems. The paper provides practical recommendations and insights into implementing redundant components to improve system reliability and resilience. It complements the review's intention of identifying challenges and solutions associated with real-time irrigation management systems.
  Relevance Score: 0.9
  Inline Citation: (Zhang et al., 2022)
  Explanation: This study exclusively focuses on real-time irrigation management systems and provides valuable insights into improving their reliability and fault tolerance using redundant components. The paper delves into different redundancy strategies, including duplicating sensors, controllers, and communication channels, emphasizing their effectiveness in minimizing system downtime and ensuring continuous operation even when individual components fail.

 Full Text: >

Paper 6:
- APA Citation: Ding, S., Zhang, S., Wang, Y., Chen, S., & Chen, Q. (2023). Restricted colloidal-bound phosphorus release controlled by alternating flooding and drying cycles in an alkaline calcareous soil. Environmental Pollution, 343, 123204.
  Main Objective: The main objective of the study was to investigate the dynamics of colloidal-bound phosphorus release as influenced by irrigation in alkaline calcareous soil and explore the role of Ca in determining the release of Pcoll.
  Study Location: Unspecified
  Data Sources: Water-dispersible colloids (0.6 nm–1 μm) were extracted by combining filtration and ultrafiltration methods.
  Technologies Used: Soil water-dispersible colloids were extracted using filtration followed by ultrafiltration methods, and the contents of P, cation and organic carbon in the water-dispersible colloids were determined.
  Key Findings: 1) Alternating flooding and drying treatment significantly reduced the Pcoll content by 11.6%–88.0% (mean 67.6%) compared to the control treatment.
2) The decrease of Pcoll was accompanied by an increase of truly dissolved P, suggesting the transformation of Pcoll to truly dissolved P under alternating flooding and drying cycles.
3) Redundancy analysis and random forest modeling showed that colloidal calcium (Ca) and ionic strength in soil solutions had negative correlations with the Pcoll content, indicating the importance of Ca and ionic strength in determining the release of Pcoll.
  Extract 1: The Pcoll content of the flooding event was always greater than the Pcoll content of the drying event during flooding and drying cycles. Redundancy analysis and random forest modeling showed that the colloidal calcium (Ca) and ionic strength in soil solutions had negative correlations with the Pcoll content, and pH, ionic strength and truly dissolved P were the critical factors affecting Pcoll
  Extract 2: In summary, controlled flooding and drainage when managed correctly have a role to play in mitigating Pcoll loss from P-enriched calcareous soils.
  Limitations: The study was conducted in a greenhouse setting and may not fully represent field conditions. The authors did not investigate the long-term effects of alternating flooding and drying cycles on Pcoll release.
  Relevance Evaluation: The paper is highly relevant to my literature review on automated systems for real-time irrigation management. The paper presents an in-depth analysis of the dynamics of colloidal P release and explores the role of Ca in determining the release of Pcoll. The findings have important implications for developing strategies to mitigate Pcoll loss from agricultural soils, which aligns well with the goal of my review to identify effective practices for sustainable water management.
  Relevance Score: 0.9
  Inline Citation: (Ding et al. 2023)
  Explanation: The study conducted by Ding et. al (2023) investigates the dynamics of colloidal-bound phosphorus release as influenced by irrigation in alkaline calcareous soil. The authors hypothesized that alternating flooding and drying cycles would reduce the content of Pcoll in the calcareous soil and emphasize the importance of Ca as a governing factor which determines the release of Pcoll. Findings suggest that controlled flooding and drainage, when managed correctly, can play a role in mitigating Pcoll loss from P-enriched calcareous soils.

 Full Text: >
"Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Graphical abstract Keywords 1. Introduction 2. Materials and methods 3. Results and discussion 4. Conclusion CRediT authorship contribution statement Declaration of competing interest Acknowledgments Appendix A. Supplementary data Data availability References Show full outline Figures (6) Tables (1) Table 1 Extras (1) Multimedia component 1 Environmental Pollution Volume 343, 15 February 2024, 123204 Restricted colloidal-bound phosphorus release controlled by alternating flooding and drying cycles in an alkaline calcareous soil☆ Author links open overlay panel Shuai Ding a, Shuai Zhang a b, Yang Wang c, Shuo Chen a, Qing Chen a Show more Share Cite https://doi.org/10.1016/j.envpol.2023.123204 Get rights and content Highlights • Colloidal P accounts for 53.2% of water-extracted P in the calcareous soil. • Alternating flooding and drying cycles decrease the colloidal P by 67.6%. • Enhanced colloidal aggregation explains the decrease of colloidal P content. • The positive charges on colloid surface increased when soil moisture dropped. Abstract Colloid-facilitated phosphorus (P) migration plays an important role in P loss from farmland to adjacent water bodies. However, the dynamics of colloidal P (Pcoll) release as influenced by irrigation in alkaline calcareous soil remains a knowledge gap. The present study, monitored the dynamic change of Pcoll under different water management strategies: 1) control, 2) flooding, and 3) alternating flooding and drying cycles. Soil water-dispersible colloids (0.6 nm-1 μm) were extracted by combining filtration and ultrafiltration methods. The contents of P, cation and organic carbon in the water-dispersible colloids were determined and the stability and mineral composition of colloidal fractions were characterized. The results showed that Pcoll ranged from 16.5 to 25.5 mg kg−1 and represented 42.8%–64.9% of the water-extracted P in the control. Flooding significantly decreased the Pcoll content by 16.0%–62.1% (mean 32.7%) and it may be attributed to the dissolution of colloidal iron (Fe) bound P. The alternating flooding and drying treatment significantly reduced the Pcoll content by 11.6%–88.0% (mean 67.6%). The Pcoll content of the flooding event was always greater than the Pcoll content of the drying event during flooding and drying cycles. Redundancy analysis and random forest modeling showed that the colloidal calcium (Ca) and ionic strength in soil solutions had negative correlations with the Pcoll content, and pH, ionic strength and truly dissolved P were the critical factors affecting Pcoll. Drying of the flooded soil led to the decrease of pH and the increase of ionic strength, colloidal Ca content and positive charges of colloid surfaces, which promoted colloid aggregation and enhanced soil P sorption capacity. This restricted the loss potential of Pcoll. In summary, controlled flooding and drainage when managed correctly have a role to play in mitigating Pcoll loss from P-enriched calcareous soils. Graphical abstract Download : Download high-res image (284KB) Download : Download full-size image Previous article in issue Next article in issue Keywords Moisture managementColloidal transportPhosphorus lossIonic strengthPhosphorus sorption 1. Introduction Globally, phosphorus (P) fertilizers applied to ensure the growth of crops also accumulate in the soil, as legacy P and can gradually be lost into adjacent water bodies by surface runoff or subsurface leaching pathways, causing eutrophication (Tian et al., 2022; Wu et al., 2020). It is known that elevated P loss potential of soil is related to soil colloid transport and that colloid-facilitated P migration has been one of the critical P loss pathways in agricultural ecosystems (Adediran et al., 2021; Eltohamy et al., 2023; Siebers et al., 2023). Soil colloid has high specific surface area and charge density thereby can be suspended in the soil solution and promote the vertical movement of various contaminants and nutrients to groundwater (Liang et al., 2016; Missong et al., 2018). Generally, the colloidal P (Pcoll) is the P that associated to soil colloids with a diameter of 1–1000 nm (Wang et al., 2021). Qin et al. (2020) have reported that over 40% of P in soil solutions were associated with colloids. A previous study has reported that rainstorms can promote the subsurface transport of P-enriched granules and that Pcoll (200–660 mg L−1) accounted for 64% of the total P in tile drainage water (Jiang et al., 2021). Based on field runoff plots, Sharma et al. (2017) examined P forms and fluxes via runoff, throughflow and leaching and it was found that 90% of P losses were in colloidal forms. As global warming continues, extreme precipitation and drought occur frequently in the North China Plain (Cui et al., 2021; Lorelei de Jesus et al., 2020). The heterogeneous distribution of precipitation in spatiotemporal patterns caused the alternation of flooding and drying. The flooding and subsequent drainage also is a common phenomenon induced by irrigation practices occurring in paddy fields (Mueller et al., 2012). In addition, flooding for several months after the crop harvest in protected vegetable field is recommended to eliminate soil diseases (Zhang et al., 2021). The alternating flooding and drying events inevitably affect the dispersion of soil colloid and the release of Pcoll by changing soil properties, such as pH, redox potential and ionic strength (Liang et al., 2010). For example, Gu et al. (2018) reported that flooding and drying cycles could decrease the redox potential and stimulate the release of P bound to soil colloids/nanoparticles in two riparian wetland soils. The mechanisms of Pcoll release due to alternating flooding and drying cycles is often attributed to the lysis of microbial cells (Blackwell et al., 2010), physical disruption of soil aggregates (Sun et al., 2017) and substrate release from soil aggregate surfaces. Furthermore, the fate of Pcoll due to alternating flooding and drying cycles may also be influenced by soil type (Buchanan et al., 2023; Chen et al., 2022). It was found that the elevated Calcium (Ca) content was accompanied by the decrease of the Pcoll content in semiarid calcareous soils under dry-wet alternation conditions (Lu et al., 2004). Vonk et al. (2017) also reported that rewetting carbonate sediment induced a strong release flux of Ca that contributed to limiting the fluxes of Pcoll to surface water. As an important agricultural soil, calcareous soils account for 47% of arable land globally and are widely distributed in the North China Plain and arid and semi-arid regions (Gandois et al., 2011; Guo et al., 2018). Long-term excessive P input leads to significant P accumulation in these calcareous soils and promotes P loss with water movement in the soil (Zhou et al., 2021). Previous studies have focused on the loss of dissolved P, while not paying enough attention to the loss of Pcoll from such calcareous soils. On the other hand, in calcareous soils, long-term organic fertilization during agricultural practice enhanced soil organic matter, which is beneficial to promoting soil organic colloid formation and may strengthen the association between soil colloids and phosphate through the Ca2+ ion bridge (Wang et al., 2020; Zhang et al., 2022). Alternating flooding and drying events also affect Pcoll release, which increases P migration along leaching pathways to adjacent waters. Therefore, it is important to determine the implication of alternating flooding and drying on Pcoll release of calcareous soils. However, to date, it remains unclear how alternating flooding and drying cycles affect the Pcoll release potentials in calcareous soils. The objectives of this study were to illustrate Pcoll release dynamics and explore the corresponding mechanism in a calcareous soil when experiencing alternating flooding and drying events. It was hypothesized that 1) alternating flooding and drying cycles would reduce the content of Pcoll in the calcareous soil and 2) Ca was a governing important factor which determined the release of Pcoll. 2. Materials and methods 2.1. Study site and soil samples collection Soil samples for this study were collected from a greenhouse in the Daxing District (39°73′ N, 116°33′ E), Beijing Province, China. The mean annual temperature and mean annual precipitation of the area were 11.6 °C and 556 mm, respectively. Soil in this area was classified as Cambisol according to the USDA soil taxonomy with 43.2% sand, 45.2% silt, and 11.6% clay. Before soil collection, vegetables were planted for 13 years from 2008 (annual double cropping, winter-spring and autumn-winter seasons, pepper or eggplant were planted in February for the winter-spring season, and cabbage or tomato were planted in August for the autumn-winter season). Composted chicken manure (220 kg ha−1 P per year) was incorporated into the soil before transplanting, correspondingly, 169 kg ha−1 P was in surplus and accumulated in the soil per year. After the tomato harvest in January 2022, the topsoil (0–20 cm) was sampled in triplicate. The soil cores were fully mixed to obtain one soil sample and then air-dried, sieved (<2 mm), and stored for further analysis. Soil pH was 7.81, electrical conductivity was 333 μs cm−1, soil organic carbon (SOC) was 19.1 g kg−1, total phosphorus (TP) was 1.71 g kg−1, Olsen-P was 239 mg kg−1. 2.2. Incubation experiment design Each 70 g air-dried soil sample was put into a 100 ml plastic bottle and the water content was adjusted to 50% of field capacity. The bottles were pre-incubated for 2 weeks at 25 °C to equilibrate soil moisture (n = 54). Next, the formal incubation experiment was carried out with irrigation imposed every 3 days. Three treatments were applied with 3 replicates: 1) control, soil moisture at 70% of field capacity; 2) flooding, the overlying water layer was held at 1 cm corresponding to 130% of field capacity and 3) alternating flooding and drying, the soil was submerged to 130% of field capacity for 2 days, then the water capacity was dropped to 70% of field capacity with silica desiccant (Fig. S1). The prospective moisture content was determined by regularly weighing the sample bottles and replacing the desiccants, according to the preliminary results, it took 6 days to go from 130% field capacity to 70% field capacity. The bottles were kept on 70% field capacity for 2 extra days to equilibrate moisture. Subsequently, these bottles were reflooded to 130% field capacity for the next cycle. The incubation experiment was conducted for 30 days including three flooding-drying cycles. Soils were sampled at the moisture variation point of three cycles (day 2 and 8 for cycle 1, day 12 and 18 for cycle 2 and day 22 and 30 for cycle 3). For samples in the flooding treatment and during the flooding period in the alternating flooding and drying treatment (day 2, day 12, day 22), since the exact moisture of the soil cannot be determined, it is impossible to add deionized water to adjust the soil/water ratio, thereby the water extracted P and colloidal P was directly extracted. The overlying water samples were collected before the soil samples and the volume of overlying water samples was less than 6 ml and not enough for the colloidal P separation in the present study. The concentration of P in the overlying water samples was also measured and it was found that the content of P in the overlying water accounted for <4% of the water extracted P of the residual soil in the bottom of tubes. Based on this consideration, it was decided to discard the overlying water and extract the legacy soil to obtain water extracted P and colloidal P. 2.3. Soil properties analysis and P sorption isotherms determination Soil pH and electrical conductivity were determined in deionized water with soil: water ratio of 1:2.5 and 1:5, respectively (Richards, 1954). The electrical conductivity was monitored to indicate the ionic strength in soil solutions, which has an impact on colloidal properties (Rousseau et al., 2004). Olsen-P was measured by the standard ammonium molybdate blue method after soil was extracted by 0.5 M NaHCO3 (soil:solution ratio of 1:20) (Olsen, 1954). P sorption isotherms were determined as described by Holford (1997). Briefly, 1 g soil in triplicate was added to 20 mL 0.01 M CaCl2 solutions containing 0, 1.0, 2.5, 5.0, 10, 20, 25 and 40 mg L−1 phosphate (KH2PO4), then the mixtures were shaken, centrifuged and filtered (<0.45 μm). The P concentration in the filtrates was analyzed by the standard ammonium molybdate blue method (Murphy and Riley, 1962). The P amount absorbed by soil was obtained based on the difference between the original P and equilibrium P concentration in the supernatants. The maximum P sorption capacity and binding energy constant for the Langmuir model and sorption equilibrium constant for the Freundlich model were calculated according to a previous study (Holford, 1997): Eq.(1) Eq.(2) where C is equilibrium P concentration, Q is P sorption capacity, Qmax is maximum P sorption capacity, K is binding energy constant, Kf and 1/n are Freundlich constants. 2.4. Soil water-dispersible colloid separation and colloidal elements determination Water-dispersible colloid of the soil were separated as described by Liang et al. (2010). Briefly, 10 g fresh soil and 80 ml deionized water were mixed and horizontally shaken at 180 rpm for 24 h (20 °C). The mixture was centrifuged at 3500 g for 8 min to settle large soil particles (∼8 μm) and the supernatant was stored for the next analysis (sample I). The P content in sample I was defined as water-extracted P. The water-extracted P includes the truly dissolved P, Pcoll and particulate P. Based on this, further separations were carried out to distinguish them. Then, a portion of the sample I was filtered through a 1 μm Millipore filter paper, and the filtrate was collected (sample II). Sample II was ultra-filtrated at 4500 g for 45 min with a 1 kDa (about 0.6 nm) pore size membrane, and the filtrate was collected (sample III). The centrifugation time was calculated according to the Stokes’ law (Wang et al., 2020). The P content in sample III was defined as the truly dissolved P (<0.6 nm), Pcoll (0.6–1000 nm) was obtained from the difference between sample II and III, and particulate P (1–8 μm) was obtained based on the difference between sample I and II. The total P concentration of the three fractions (sample I, sample II and sample III) was determined by standard ammonium molybdate blue method after alkaline persulphate oxidation. Molybdate-reactive P of water-extracted P fraction was directly measured (Baldwin, 1998). Molybdate-unreactive P was calculated as the concentration difference between the total P and molybdate-reactive P of water-extracted P. The concentrations of iron (Fe), aluminum (Al), Ca and magnesium (Mg) in each fraction were determined by inductively coupled plasma-mass spectrometry (ICP-MS, Agilent 7850, USA) after acidiﬁcation (pH < 2) with 1 M nitric acid. The total organic carbon (TOC) concentration in each fraction was measured by a total organic carbon analyzer (enviro-TOC, Elementar, Germany). 2.5. Colloidal stabilities and mineral compositions analysis Zeta potentials of the sample II were measured by a Zeta-sizer (Nano-ZS90, Malvern, UK) (Liang et al., 2010). Colloidal absorbances were determined after sonicated the <1 μm size fraction for 3 min using a UV–Vis spectrophotometer (TU-1901, China) with a wavelength of 300 nm, which was chosen because the dissolved organic matters did not show distinct absorption peaks in this spectrum. The absorbance was continuously measured every 2 min during 0–120 min. The ratio of absorbance at a particular point (A) to the initial absorbance (A0) can be used for estimating the stability of colloids and the A/A0 value approaching 1 representing higher stability (Xu et al., 2022). After freeze drying, the mineral composition of sample II was characterized by X-ray diffraction (XRD) using a Bruker D-5000 X-ray diffractometer (Billerica, MA, USA) with a Cu Kα radiation (λ = 0.154 18 nm), at 40 kV and 40 mA. Diffraction data were recorded from 5° to 90° and scanning rate was set at 2° min−1. The Jade software (Materials Data Inc., Livermore, CA) was used for the calibration and phases analysis of mineral compositions of the colloidal samples (Huang et al., 2016). 2.6. Statistical analysis The means and standard error of each treatment were calculated by Microsoft Excel (2019). A repeated measure analysis of variance (ANOVA) was performed by SPSS IBM 20.0 (SPSS, Chicago, IL, USA). The data passed the normal distribution and homogeneity test before ANOVA. The significant differences in soil properties and P fractions between the different water management strategies or the time series of incubation period within specific treatment were tested using the Least Significant Difference test (P < 0.05). The redundancy analysis (RDA) and random forest model were conducted by CANOCO 5 (Microcomputer Power, Ithaca, NY, USA) and R (R 4.0.3, R Development Core Team) to assess the correlations among truly dissolved P, Pcoll and particulate P and soil properties and explore the affecting factors on Pcoll contents, respectively. 3. Results and discussion 3.1. Dynamic changes of colloidal P in the control treatment Soil moisture in the control treatment was kept at 70% of field capacity. In this scenario, Pcoll (16.5–25.5 mg kg−1) was the dominating fraction of water-extracted P, and its proportion in water-extracted P ranging from 42.8% to 64.9% (Fig. 1a and b). This content of Pcoll was higher than in previous studies (2.33–7.92 mg kg−1 in rice-wheat rotation field and 6.51–12.7 mg kg−1 in double cropping rice field) (Li et al., 2021; Wang et al., 2021).This could be attributed to the long-term compost application not only enhanced the labile P content but also enhanced soil organic matter, which is beneficial to promoting soil organic colloid formation and may strengthen the association between soil colloids and phosphate. Moreover, the contents of Pcoll gradually increased in the early stage (day 2 to day 12) but decreased by 35.1% in the late stage (day 12 to day 30). The decrease of Pcoll was accompanied by an increase in truly dissolved P, the proportions of truly dissolved P had increased from 25.7% (day 2 to day 12) to 36.8% (day 18 to day 30). These results support the assumption that fluctuations in Pcoll content may be due to the change of soil colloid amounts and the change of interaction between free phosphate and soil colloid. The results of Ilg et al. (2008) also show that the combination of free phosphate with soil colloid in soil solutions resulted in the enhancement of Pcoll content. The contents (0.72–7.03 mg kg−1) and proportions (13.8%–18.5%) of particulate P stayed relatively stable during the entire incubation time. Download : Download high-res image (495KB) Download : Download full-size image Fig. 1. P content in water-extracted phosphorus pools under control (a), flooding (b) and alternating flooding and drying (c) treatments. Error bars represent standard error and lowercase letters and capital letters represent significant differences between water management treatments and incubation times at P < 0.05. Truly dissolved P: <0.6 nm, colloidal P: 0.6–1000 nm, particulate P: 1–8 μm.The red arrows represent the time point when flooding events occurred. (For interpretation of the references to colour in this figure legend, the reader is referred to the Web version of this article.) 3.2. Flooding or alternating flooding and drying decreased the release of colloidal P Compared with Pcoll in the control treatment, the flooding treatment significantly decreased Pcoll contents by 16.0%–62.1%. The truly dissolved P contents in the flooding treatment increased by 17.3%–167% (Fig. 1c). The transformation of the Pcoll and truly dissolved P was found in the present study. These results indicated that the risk of Pcoll loss was reduced under the flooded condition in this calcareous soil, however, the risk of truly dissolved P loss increased significantly. In addition, the proportion of truly dissolved P was enhanced from 33% on day 2–59% on day 18. A similar result was shown by Schroth et al. (2015) that the reductive dissolution of colloidal Fe (hydr)oxides during the flooding period in paddy soils may explain the decreased Pcoll and the enhanced truly dissolved P contents. Significantly decreased colloidal Fe contents were found from day 12 to day 30 in the flooding treatment in this study (Fig. 2b). This result also agrees with the assumption that the Fe reduction dissolves part of the soil colloid and thereby decreases the Pcoll. Particulate P content in the flooding treatment was significantly higher than that in the control treatment on day 2, day 12, and day 22, respectively. Previous studies have found that flooding irrigation promoted the release of dissolved P and Pcoll in an organic fertilizer-amended paddy soil (Eltohamy et al., 2021). The present results indicated that flooding decreased Pcoll but increased truly dissolved P release, which were not in accordance with Eltohamy et al. (2021). It could also be attributed to prolonged flooding of soil which accelerated the dissolution of Fe/Mn oxides and the disintegration of soil aggregates thereby released the intra-aggregate particulate P and Pcoll (Xia et al., 2018), however, Pcoll could further convert into truly dissolved P under the reducing condition (Fig. 1d). Positive correlations among truly dissolved P, Pcoll, particulate P and colloidal Fe also confirmed this inference. Download : Download high-res image (802KB) Download : Download full-size image Fig. 2. Diagram of alternating flooding and drying events (a) and contents of colloidal Fe (b), Al (c), Ca (d), Mg (e), organic carbon (f), soil pH (g) and conductivity (h) under three water management treatments. Arrows indicate the dates of sampling. Compared to the control treatment, the alternating flooding and drying treatment significantly decreased the Pcoll content by 11.6%–88.0%. The content of Pcoll decreased by 50.8% in cycle 1 and decreased by 63.9% in cycle 2 while it tended to be stable (2.87–3.38 mg kg−1) in cycle 3 (Fig. 1e). Moreover, the alternating flooding and drying treatment significantly increased the truly dissolved P content from day 2 to day 12 while decreased it from day 18 to day 30The truly dissolved P content in the alternating flooding and drying treatment decreased by 5.17% in cycle 1 and decreased by 84.0% in cycle 2 while it increased by 47.6% in cycle 3. The transformation of Pcoll and truly dissolved P coupled with the changed P retention capacity of soil may be interpreted as the fluctuation of truly dissolved P. Dantas Mendes (2020) also found that the increased P sorption in drainage ditch sediments from agricultural catchments lead to the reduction of truly dissolved P. For the particulate P fraction, alternating flooding and drying did not affect its content significantly but increased the particulate P proportion. Soil drainage increased the proportion of particulate P by 12.7% and 27.2% in cycle 1 and cycle 2, respectively. It suggested truly dissolved P and Pcoll may be involved in conversion to larger-size particulate P under the alternating flooding and drying cycles. It may be attributed to both effects of strong sorption by soil Ca minerals and colloidal aggregation induced by electrostatic attraction (Xu et al., 2022). Above results were also confirmed by a previous study which has shown that alternating flooding and drying cycles could not only decrease Pcoll but also decrease truly dissolved P release and therefore decrease P loss risk (Eltohamy et al., 2023). The formation of large particles is largely responsible for such results(Jin et al., 2023; Li et al., 2020). 3.3. Decreased colloidal P contents explained by the enhanced colloidal aggregation and soil sorption capacity In order to further interpret the significant decline in Pcoll content and proportion of the alternating flooding and drying treatment, the zeta potentials and stability behaviors of colloidal phases (sample II) were measured. Colloids were negatively charged under the three flooding and drying cycles (Fig. 3). Colloidal zeta potentials were less negative when the soil dried. Upon flooding again, the values of zeta potentials recovered to the initial level. This might be explained by the evaporation-driven aggregation of colloidal granules (Seiphoori et al., 2020). Colloidal stability behavior also supported the aggregation-prone trend during the alternating flooding and drying events (Fig. S2). The A/A0 values tended to be larger when soil got dried during cycle 1, which illustrated that the soil colloids started to be unstable. Zeta potentials and stability behaviors results both showed that alternating flooding and drying promoted the aggregation of soil colloids and reduced their stability (Xu et al., 2021). The enhanced aggregation role accelerated colloids flocculation and separated out of the water-extracted P and this may be one reason accounting for the decreased Pcoll contents. Download : Download high-res image (216KB) Download : Download full-size image Fig. 3. Zeta potential of colloidal fractions under the alternating flooding and drying treatment. Capital letters represent significant differences among incubation times at P < 0.05. For the alternating flooding and drying treatment, the P sorption isotherms were measured to evaluate the soil retention capacity for P. Both Langmuir and Freundlich models were used to fit the P sorption data in the present study (Fig. 4 and Table 1). It was shown that Langmuir seems unsuitable for sorption data fitting in the present study, as no plateau of P sorption has been reached yet at higher equilibrium P concentrations. Obvious deviations were found between the fitting line and the data points at higher equilibrium P concentrations. Higher correlation coefficients and smaller deviations between points and fitting lines support that the Freundlich model is more suitable for describing the P sorption process in the present study. Dried soil from day 2 to day 8 in the alternating flooding and drying treatment significantly increased Kf, which indicated that the P sorption of soil increased through multilayer/non-uniform sorption during this drying period. The dried soil from day 12 to day 18 and the dried soil from day 22 to day 30 both decreased Kf. This is inconsistent with the information from the first drying period. This information supports that the decreasing contribution of the multilayer/non-uniform sorption to soil P sorption capacity after the second drying period. The decreasing contribution of the multilayer/non-uniform sorption to soil P sorption capacity as the drying period is repeated. Upon the reflooding condition, the increased Kf (Table 1) supports that the slightly increasing contribution of the multilayer/non-uniform sorption process to soil P sorption capacity as the reflooding process is repeated. The Pcoll content decreased during the drying periods while it increased during the reflooding period. This supported that the variation of soil P sorption capacity contributed the change of Pcoll content. Khan et al. (2022) also attributed the decrease of Pcoll content to the increase of P sorption capacity in dried paddy soils, which is consistent with the result of the present study. Therefore, the combined effects of colloidal stability and the change of soil sorption capacity collectively caused the decrease of Pcoll contents. Download : Download high-res image (545KB) Download : Download full-size image Fig. 4. Phosphorus adsorption isotherms fitted by Langmuir (a) and Freundlich (b) models under the alternating flooding and drying treatment (n = 3). Table 1. Langmuir and Freundlich fitted adsorption parameters of the alternating flooding and drying treatment. Time (day) Langmuir Freundlich Qmax (mg kg−1) K (L mg−1) PBC (L kg−1) R12 Kf (mg kg−1) 1/n R22 2 364 0.187 68.1 ≥0.96 90.8 0.39 ≥0.96 8 390 0.198 77.2 ≥0.95 99.3 0.39 ≥0.96 12 380 0.224 85.1 ≥0.97 106 0.37 ≥0.96 18 604 0.132 79.7 ≥0.95 101 0.52 ≥0.98 22 526 0.161 84.7 ≥0.89 106 0.47 ≥0.97 30 433 0.190 82.3 ≥0.92 102 0.42 ≥0.97 Qmax: maximum P sorption capacity; K: binding energy; PBC: P buffer capacity; R12: determination coefficient of adsorption isotherm by Langmuir. Kf and 1/n: an empirical parameter related to sorption capacity and intensity; R22: determination coefficient of adsorption isotherm by Freundlich. The release of colloidal Ca and Mg and subsequent formation of Ca-containing minerals could partially explain the enhanced P sorption capacity (Fig. 2d and e and Fig. S3). Contents of colloidal Ca and Mg increased by 776%, 343%, 462% and 186%, 138%, 361% during cycle 1, cycle 2 and cycle 3 in the alternating flooding and drying treatment, respectively. In contrast, colloidal Ca and Mg stayed stable in the control treatment. It has been reported that P was prone to be combined with colloidal Ca instead of colloidal Fe or Al in calcareous soils (Fan et al., 2020), it mainly attributed to the higher colloidal Ca content and smaller hydrated ionic radius, lower positive charges of Ca2+ making it easier for phosphate to bind to colloidal Ca. (Mendez and Hiemstra, 2020). In addition, strong correlations between Pcoll and colloidal Ca were found across forests (Wang et al., 2020), reservoir sediments (Nguyen et al., 2020) and paddy soils (Liang et al., 2016). The present study also illustrated that Pcoll is negatively related to colloidal Ca (Fig. 5a). The presence of Ca can facilitate cation bridging and formulate larger colloidal granules and therefore contribute to the reduction of Pcoll (Fan et al., 2020). Through a column study and multi-surface complexation model, Warrinnier et al. (2019) revealed that low Ca concentration in solution enhanced leachate P amounts but with a high Ca concentration reduced P leaching. Missana et al. (2018) also suggested Ca2+ in soil solution is a crucial factor for the aggregation behavior of colloidal particles and that a Ca concentration exceeding 0.3 mM was enough to aggregate any colloids. The Ca concentration in this present study exceeded 0.3 mM, and surplus Ca2+ would precipitate to Ca-containing minerals (such as calcite) when soil got dried (Fig. S3). P sorption by these newly generated minerals further decreased Pcoll contents (Xu et al., 2014). In general, alternating flooding and drying promoted soil Ca dissolution and release to water, the abundant Ca2+ reduced colloidal stability, the new Ca-containing minerals increased P sorption capacity, ultimately resulting in a decrease of Pcoll loss potential. Download : Download high-res image (508KB) Download : Download full-size image Fig. 5. Redundancy analysis between truly dissolved P, Pcoll, particulate P and soil properties (a); random forest analysis for the determination of factors affecting Pcoll contents (b). Asterisks indicated significant differences between treatments: *P < 0.05; **P < 0.01. EC: electrical conductivity. 3.4. Variation of pH/ionic strength contributed to restrict the colloidal P release Compared with the flooding treatment, alternating flooding and drying caused the opposite effect on soil pH and electrical conductivity (Fig. 2g and h). Dried soil decreased soil pH by 0.22 units from day 2 to day 8 and decreased soil pH by 0.48 units from day 12 to day 18, respectively. Kong and Lu (2022) explained the increase of soil acidity may be due to protons generated in Fe2+ oxidation during soil drainage. However, the redox potential of the overlying water was not less than 100 mV in the present study (Fig. S4), which illustrated that Fe2+ oxidation may be not the major contributor for the decrease of pH value. Otherwise, the acidification may be attributed to nitrification. Since previous studies have shown a high total nitrogen content (1.52 g kg−1) in this calcareous soil (Yan et al., 2018), the role of nitrification in soil acidification was further confirmed. Another explanation for the decreased pH was that flooding inhibited mineralization of soil organic matter but promoted some low-molecular-weight organic acid accumulation (Shan et al., 2008). On the other hand, the reduction of pH was always accompanied by an increase of electrical conductivity, the latter increased by 14.5 times and 8.6 times from day 2 to day 8 and from day 12 to day 18, respectively. Negative correlations between soil pH and electrical conductivity were also reported in previous studies (Nie et al., 2018). The enhanced ionic strength was probably because soil drying promoted the disruption of soil aggregates and increased the extractability of exchangeable cations (Buenemann et al., 2013). Previous studies have confirmed that the content of Pcoll is closely related to soil pH, ionic strength, colloid minerals and soil organic carbon (Liang et al., 2016; Liang et al., 2010). A positive correlation between Pcoll and soil pH and a negative correlation between Pcoll and electrical conductivity were also found in this study (Fig. 5a). Also, pH and electrical conductivity were the most important factors affecting Pcoll (Fig. 5b). Huang et al. (2016) suggested the effect of pH on Pcoll was evident, as pH decreased, positive charges on colloid surface increased, which suppressed the electric double layer between colloidal particles and promoted Pcoll aggregation. The decreased mobility of Pcoll was reported in salinized soils compared to the non-salinized soils by means of soil column leaching experiments (Zhang, 2008). 3.5. Environmental implications of transformation of colloidal P and truly dissolved P The significant transformation from Pcoll to truly dissolved P was found not only among different treatments but also during different incubation periods in the present study. Specifically, Pcoll gradually decreased in the control treatment and 80% of the decreased Pcoll converted into truly dissolved P during the incubation period (Fig. 1a). Similar trends were found during the flooding treatment and 90% of the decreased Pcoll converted into truly dissolved P (Fig. 1c). The truly dissolved P had a high mobility with soil moisture migration and could cause potential eutrophication to downstream water bodies (Pratiwi et al., 2016). The increased truly dissolved P coupled with the intense water management, such as the flooding irrigation and rainstorm, would generate higher P loss potential (Jiang et al., 2021). Previous studies have reported that the migration of Pcoll is usually accompanied by soil preferential flow, which could form and accelerate the loss of Pcoll even on conventional irrigation regimes (Kianpoor Kalkhajeh et al., 2021). Decreased Pcoll contents and proportions were found in the control and in the flooding treatment, which meant the Pcoll loss potential was decreased in this present study. In contrast, the Pcoll and truly dissolved P contents were both decreased in the alternating flooding and drying treatment (Fig. 1e). This could be attributed to the enhanced soil P retention capacity (colloidal aggregation and soil sorption capacity) and the transformation of Pcoll and truly dissolved P, and the P loss potential decreased in the alternating flooding and drying treatment. Above results confirm the theory that the truly dissolved P was an important fate of the decreased Pcoll and that the reduction of Pcoll content and proportion did not always mean the decrease in P loss potential. Potential P loss risk existed in the moist soil and would be intensified in the flooding condition, therefore, to reduce the P loss potential of these soils, the amended irrigation management consisting of filtration irrigation and drip irrigation, is essential in agriculture. The alternating flooding and drying events contributed to decrease the P loss risk and should be recommended as an important regulation measure to control of agricultural non-point pollution. However, the flooding and drying alternation should be appropriate and be evaluated based on the actual requirement to avoid potential environmental risk. 4. Conclusion A different water management regime consisting of alternating flooding and drying cycles significantly reduced the contents and the proportions of Pcoll compared with the control treatment or flooding condition. Drainage of the waterlogged calcareous alkaline soils decreased the soil pH and increased ionic strength, promoted the release of colloidal Ca and colloidal Mg and enhanced positive charges on colloid surfaces. The aggregation of Pcoll and increased P sorption capacity by newly formed Ca-containing minerals together resulted in the decrease of Pcoll contents and proportions. This study developed the Pcoll release mechanism upon alternating flooding and drying events and proposed a novel viewpoint that flooding and drying alternation could also decrease the P loss potential in a calcareous soil. The results show that appropriate water management decisions could achieve double benefits for water conservation and environmental management in vegetable fields. Practical-based flooding and subsequent drainage could be an effective agricultural practice to minimizing P loss potential from the intensive vegetable fields to downstream water. However, more research based on multiple field sites and multiple-year studies should be conducted before using the findings to support management decisions in alkaline calcareous soils. CRediT authorship contribution statement Shuai Ding: Writing - original draft, Investigation, Data curation. Shuai Zhang: Writing - review & editing, Visualization, Supervision, Project administration, Funding acquisition. Yang Wang: Writing - review & editing, Methodology. Shuo Chen: Writing - review & editing. Qing Chen: Funding acquisition, Conceptualization. Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgments This work was financially supported by the National Natural Science Foundation of China (42307434 and 42077089). Appendix A. Supplementary data The following is the Supplementary data to this article: Download : Download Word document (647KB) Multimedia component 1. Data availability The authors do not have permission to share data. References Adediran et al., 2021 G.A. Adediran, D. Lundberg, G. Almkvist, A.E.P. del Real, W. Klysubun, S. Hillier, J.P. Gustafsson, M. Simonsson Micro and nano sized particles in leachates from agricultural soils: phosphorus and sulfur speciation by X-ray micro-spectroscopy Water Res., 189 (2021), Article 116585 View PDFView articleView in ScopusGoogle Scholar Baldwin, 1998 D.S. Baldwin Reactive \"organic\" phosphorus revisited Water Res., 32 (1998), pp. 2265-2270 View PDFView articleView in ScopusGoogle Scholar Blackwell et al., 2010 M.S.A. Blackwell, P.C. Brookes, N. de la Fuente-Martinez, H. Gordon, P.J. Murray, K.E. Snars, J.K. Williams, R. Bol, P.M. Haygarth Phosphorus solubilization and potential transfer to surface waters from the soil microbial biomass following drying–rewetting and freezing–thawing D.L. Sparks (Ed.), Advances in Agronomy, Academic Press (2010), pp. 1-35 View PDFView articleView in ScopusGoogle Scholar Buchanan et al., 2023 A.C. Buchanan, P.W. Inglett, J.D. Judy Ultrafine (<0.45 μm) particulate SRP fluxes entering and leaving Everglades Stormwater Treatment Areas as a function of STA management and performance Ecol. Eng., 194 (2023), Article 107043 View PDFView articleView in ScopusGoogle Scholar Buenemann et al., 2013 E.K. Buenemann, B. Keller, D. Hoop, K. Jud, P. Boivin, E. Frossard Increased availability of phosphorus after drying and rewetting of a grassland soil: processes and plant use Plant Soil, 370 (2013), pp. 511-526 Google Scholar Chen et al., 2022 X. Chen, W. Zhang, G. Gruau, E. Couic, P. Cotinet, Q. Li Conservation practices modify soil phosphorus sorption properties and the composition of dissolved phosphorus losses during runoff Soil Tillage Res., 220 (2022), Article 105353 View PDFView articleView in ScopusGoogle Scholar Cui et al., 2021 Y. Cui, B. Zhang, H. Huang, J. Zeng, X. Wang, W. Jiao Spatiotemporal characteristics of drought in the North China plain over the Past 58 Years Atmosphere, 12 (2021), Article 120708 Google Scholar Dantas Mendes, 2020 L.R. Dantas Mendes Edge-of-field technologies for phosphorus retention from agricultural drainage discharge Applied Sciences-Basel, 10 (2020), Article 100206 Google Scholar Eltohamy et al., 2023 K.M. Eltohamy, S. Khan, S. He, J. Li, C. Liu, X. Liang Prediction of nano, fine, and medium colloidal phosphorus in agricultural soils with machine learning Environ. Res., 220 (2023), Article 115222 View PDFView articleView in ScopusGoogle Scholar Eltohamy et al., 2021 K.M. Eltohamy, C. Liu, S. Khan, C. Niyungeko, Y. Jin, S.H. Hosseini, F. Li, X. Liang An internet-based smart irrigation approach for limiting phosphorus release from organic fertilizer-amended paddy soil J. Clean. Prod., 293 (2021), Article 126254 View PDFView articleView in ScopusGoogle Scholar Fan et al., 2020 B. Fan, J. Ding, O. Fenton, K. Daly, Q. Chen Understanding phosphate sorption characteristics of mineral amendments in relation to stabilising high legacy P calcareous soil Environ. Pollut., 261 (2020), Article 114175 View PDFView articleView in ScopusGoogle Scholar Gandois et al., 2011 L. Gandois, A.-S. Perrin, A. Probst Impact of nitrogenous fertiliser-induced proton release on cultivated soils with contrasting carbonate contents: a column experiment Geochem. Cosmochim. Acta, 75 (2011), pp. 1185-1198 View PDFView articleView in ScopusGoogle Scholar Gu et al., 2018 S. Gu, G. Gruau, F. Malique, R. Dupas, P. Petitjean, C. Gascuel-Odoux Drying/rewetting cycles stimulate release of colloidal-bound phosphorus in riparian soils Geoderma, 321 (2018), pp. 32-41 View PDFView articleView in ScopusGoogle Scholar Guo et al., 2018 L. Guo, X. Wang, T. Diao, X. Ju, N. Xiaoguang, L. Zheng, X. Zhang, X. Han N2O emission contributions by different pathways and associated microbial community dynamics in a typical calcareous vegetable soil Environ. Pollut., 242 (2018), pp. 2005-2013 View PDFView articleView in ScopusGoogle Scholar Holford, 1997 I.C.R. Holford Soil phosphorus: its measurement, and its uptake by plants Aust. J. Soil Res., 35 (1997), pp. 227-239 View in ScopusGoogle Scholar Huang et al., 2016 L.-M. Huang, X.-H. Zhang, M.-A. Shao, D. Rossiter, G.-L. Zhang Pedogenesis significantly decreases the stability of water-dispersible soil colloids in a humid tropical region Geoderma, 274 (2016), pp. 45-53 View PDFView articleGoogle Scholar Ilg et al., 2008 K. Ilg, P. Dominik, M. Kaupenjohann, J. Siemens Phosphorus-induced mobilization of colloids: model systems and soils Eur. J. Soil Sci., 59 (2008), pp. 233-246 CrossRefView in ScopusGoogle Scholar Jiang et al., 2021 X. Jiang, K.J.T. Livi, M.R. Arenberg, A. Chen, K.-y. Chen, L. Gentry, Z. Li, S. Xu, Y. Arai High flow event induced the subsurface transport of particulate phosphorus and its speciation in agricultural tile drainage system Chemosphere, 263 (2021), Article 128147 View PDFView articleView in ScopusGoogle Scholar Jin et al., 2023 J. Jin, S. Khan, K.M. Eltohamy, S. He, C. Liu, F. Li, X. Liang Biochar-coupled organic fertilizer reduced soil water-dispersible colloidal phosphorus contents in agricultural fields Chemosphere, 333 (2023), Article 138963 View PDFView articleView in ScopusGoogle Scholar Khan et al., 2022 S. Khan, P.J. Milham, K.M. Eltohamy, Y. Hamid, F. Li, J. Jin, M. He, X. Liang Pteris vittata plantation decrease colloidal phosphorus contents by reducing degree of phosphorus saturation in manure amended soils J. Environ. Manag., 304 (2022), Article 114214 View PDFView articleView in ScopusGoogle Scholar Kianpoor Kalkhajeh et al., 2021 Y. Kianpoor Kalkhajeh, B. Huang, W. Hu Impact of preferential flow pathways on phosphorus leaching from typical plastic shed vegetable production soils of China Agric. Ecosyst. Environ., 307 (2021), Article 107218 View PDFView articleView in ScopusGoogle Scholar Kong and Lu, 2022 F. Kong, S. Lu Effects of microbial organic fertilizer (MOF) application on cadmium uptake of rice in acidic paddy soil: regulation of the iron oxides driven by the soil microorganisms Environ. Pollut., 307 (2022), Article 119447 View PDFView articleView in ScopusGoogle Scholar Li et al., 2021 F. Li, Y. Jin, S. He, J. Jin, X. Liang Use of polyacrylamide modified biochar coupled with organic and chemical fertilizers for reducing phosphorus loss under different cropping systems Agric. Ecosyst. Environ., 310 (2021), Article 107306 View PDFView articleView in ScopusGoogle Scholar Li et al., 2020 F. Li, X. Liang, H. Li, Y. Jin, J. Jin, M. He, E. Klumpp, R. Bol Enhanced soil aggregate stability limits colloidal phosphorus loss potentials in agricultural systems Environ. Sci. Eur., 32 (2020), Article 123020 Google Scholar Liang et al., 2016 X. Liang, Y. Jin, Y. Zhao, Z. Wang, R. Yin, G. Tian Release and migration of colloidal phosphorus from a typical agricultural field under long-term phosphorus fertilization in southeastern China J. Soils Sediments, 16 (2016), pp. 842-853 CrossRefView in ScopusGoogle Scholar Liang et al., 2010 X. Liang, J. Liu, Y. Chen, H. Li, Y. Ye, Z. Nie, M. Su, Z. Xu Effect of pH on the release of soil colloidal phosphorus J. Soils Sediments, 10 (2010), pp. 1548-1556 CrossRefView in ScopusGoogle Scholar Lorelei de Jesus et al., 2020 A. Lorelei de Jesus, H. Thompson, L.D. Knibbs, M. Kowalski, J. Cyrys, J.V. Niemi, A. Kousa, H. Timonen, K. Luoma, T. Petäjä, D. Beddows, R.M. Harrison, P. Hopke, L. Morawska Long-term trends in PM2.5 mass and particle number concentrations in urban air: the impacts of mitigation measures and extreme events due to changing climates Environ. Pollut., 263 (2020), Article 114500 View PDFView articleView in ScopusGoogle Scholar Lu et al., 2004 S.G. Lu, C. Tang, Z. Rengel Combined effects of waterlogging and salinity on electrochemistry, water-soluble cations and water dispersible clay in soils with various salinity levels Plant Soil, 264 (2004), pp. 231-245 CrossRefView in ScopusGoogle Scholar Mendez and Hiemstra, 2020 J.C. Mendez, T. Hiemstra High and low affinity sites of ferrihydrite for metal ion adsorption: data and modeling of the alkaline-earth ions Be, Mg, Ca, Sr, Ba, and Ra Geochem. Cosmochim. Acta, 286 (2020), pp. 289-305 View PDFView articleView in ScopusGoogle Scholar Missana et al., 2018 T. Missana, U. Alonso, A. Maria Fernandez, M. Garcia-Gutierrez Analysis of the stability behaviour of colloids obtained from different smectite clays Appl. Geochem., 92 (2018), pp. 180-187 View PDFView articleView in ScopusGoogle Scholar Missong et al., 2018 A. Missong, S. Holzmann, R. Bol, V. Nischwitz, H. Puhlmann, K. v Wilpert, J. Siemens, E. Klumpp Leaching of natural colloids from forest topsoils and their relevance for phosphorus mobility Sci. Total Environ., 634 (2018), pp. 305-315 View PDFView articleView in ScopusGoogle Scholar Mueller et al., 2012 N.D. Mueller, J.S. Gerber, M. Johnston, D.K. Ray, N. Ramankutty, J.A. Foley Closing yield gaps through nutrient and water management Nature, 490 (2012), pp. 254-257 CrossRefView in ScopusGoogle Scholar Murphy and Riley, 1962 J. Murphy, J.P. Riley A modified single solution method for the determination of phosphate in natural waters Anal. Chim. Acta, 27 (1962), pp. 31-36 View PDFView articleView in ScopusGoogle Scholar Nguyen et al., 2020 D.N. Nguyen, M. Grybos, M. Rabiet, V. Deluchat How do colloid separation and sediment storage methods affect water-mobilizable colloids and phosphorus? An insight into dam reservoir sediment Colloids and Surfaces a-Physicochemical and Engineering Aspects, 606 (2020), Article 125505 View PDFView articleView in ScopusGoogle Scholar Nie et al., 2018 S.a. Nie, L. Zhao, X. Lei, R. Sarfraz, S. Xing Dissolved organic nitrogen distribution in differently fertilized paddy soil profiles: implications for its potential loss Agric. Ecosyst. Environ., 262 (2018), pp. 58-64 View PDFView articleView in ScopusGoogle Scholar Olsen, 1954 S.R. Olsen Estimation of Available Phosphorus in Soils by Extraction with Sodium Bicarbonate Miscellaneous Paper Institute for Agricultural Research Samaru (1954) Google Scholar Pratiwi et al., 2016 E.P.A. Pratiwi, A.K. Hillary, T. Fukuda, Y. Shinogi The effects of rice husk char on ammonium, nitrate and phosphate retention and leaching in loamy soil Geoderma, 277 (2016), pp. 61-68 View PDFView articleView in ScopusGoogle Scholar Qin et al., 2020 X. Qin, S. Guo, L. Zhai, J. Pan, B. Khoshnevisan, S. Wu, H. Wang, B. Yang, J. Ji, H. Liu How long-term excessive manure application affects soil phosphorous species and risk of phosphorous loss in fluvo-aquic soil Environ. Pollut., 266 (2020), Article 115304 View PDFView articleView in ScopusGoogle Scholar Richards, 1954 L.A. Richards Diagnosis and improvement of saline and Alkali soils Soil Sci., 64 (1954), p. 290 Google Scholar Rousseau et al., 2004 M. Rousseau, L. Di Pietro, R. Angulo-Jaramillo, D. Tessier, B. Cabibel Preferential transport of soil colloidal particles: Physicochemical effects on particle mobilization Vadose Zone J., 3 (2004), pp. 247-261 View in ScopusGoogle Scholar Schroth et al., 2015 A.W. Schroth, C.D. Giles, P.D.F. Isles, Y. Xu, Z. Perzan, G.K. Druschel Dynamic coupling of iron, manganese, and phosphorus behavior in water and sediment of shallow ice-covered eutrophic lakes Environ. Sci. Technol., 49 (2015), pp. 9758-9767 CrossRefView in ScopusGoogle Scholar Seiphoori et al., 2020 A. Seiphoori, X.G. Ma, P.E. Arratia, D.J. Jerolmack Formation of stable aggregates by fluid-assembled solid bridges Proc. Natl. Acad. Sci. U.S.A., 117 (2020), pp. 3375-3381 CrossRefView in ScopusGoogle Scholar Shan et al., 2008 Y. Shan, Z. Cai, Y. Han, S.E. Johnson, R.J. Buresh Organic acid accumulation under flooded soil conditions in relation to the incorporation of wheat and rice straws with different C : N ratios Soil Sci. Plant Nutr., 54 (2008), pp. 46-56 CrossRefView in ScopusGoogle Scholar Sharma et al., 2017 R. Sharma, R.W. Bella, M.T.F. Wong Dissolved reactive phosphorus played a limited role in phosphorus transport via runoff, throughflow and leaching on contrasting cropping soils from southwest Australia Sci. Total Environ., 577 (2017), pp. 33-44 View PDFView articleCrossRefView in ScopusGoogle Scholar Siebers et al., 2023 N. Siebers, J. Kruse, Y. Jia, B. Lennartz, S. Koch Loss of subsurface particulate and truly dissolved phosphorus during various flow conditions along a tile drain-ditch-brook continuum Sci. Total Environ., 866 (2023), Article 161439 View PDFView articleView in ScopusGoogle Scholar Sun et al., 2017 D. Sun, Q. Bi, H. Xu, K. Li, X. Liu, J. Zhu, Q. Zhang, C. Jin, L. Lu, X. Lin Degree of short-term drying before rewetting regulates the bicarbonate-extractable and enzymatically hydrolyzable soil phosphorus fractions Geoderma, 305 (2017), pp. 136-143 View PDFView articleView in ScopusGoogle Scholar Tian et al., 2022 K. Tian, Z. Xing, Y.K. Kalkhajeh, T. Zhao, W. Hu, B. Huang, Y. Zhao Excessive phosphorus inputs dominate soil legacy phosphorus accumulation and its potential loss under intensive greenhouse vegetable production system J. Environ. Manag., 303 (2022), Article 114149 View PDFView articleView in ScopusGoogle Scholar Vonk et al., 2017 J.A. Vonk, T. Rombouts, J.C. Schoorl, P. Serne, J.W. Westerveld, P. Cornelissen, H.G. van der Geest Impact of water drawdown and rewetting on sediment nutrient-dynamics in a constructed delta-lake system (Oostvaardersplassen, The Netherlands): a mesocosm study Ecol. Eng., 108 (2017), pp. 396-405 View PDFView articleView in ScopusGoogle Scholar Wang et al., 2020 L. Wang, A. Missong, W. Amelung, S. Willbold, J. Prietzel, E. Klumpp Dissolved and colloidal phosphorus affect P cycling in calcareous forest soils Geoderma, 375 (2020), Article 114507 View PDFView articleView in ScopusGoogle Scholar Wang et al., 2021 Z. Wang, L. Chen, C. Liu, Y. Jin, F. Li, S. Khan, X. Liang Reduced colloidal phosphorus loss potential and enhanced phosphorus availability by manure-derived biochar addition to paddy soils Geoderma, 402 (2021), Article 115348 View PDFView articleView in ScopusGoogle Scholar Warrinnier et al., 2019 R. Warrinnier, T. Goossens, F. Amery, T. Vanden Nest, M. Verbeeck, E. Smolders Investigation on the control of phosphate leaching by sorption and colloidal transport: column studies and multi-surface complexation modelling Appl. Geochem., 100 (2019), pp. 371-379 View PDFView articleView in ScopusGoogle Scholar Wu et al., 2020 Q. Wu, S. Zhang, G. Feng, P. Zhu, S. Huang, B. Wang, M. Xu Determining the optimum range of soil Olsen P for high P use efficiency, crop yield, and soil fertility in three typical cropland soils Pedosphere, 30 (2020), pp. 832-843 View PDFView articleCrossRefView in ScopusGoogle Scholar Xia et al., 2018 B. Xia, H. Qiu, K.-H. Knorr, C. Blodau, R. Qiu Occurrence and fate of colloids and colloid-associated metals in a mining-impacted agricultural soil upon prolonged flooding J. Hazard Mater., 348 (2018), pp. 56-66 View PDFView articleView in ScopusGoogle Scholar Xu et al., 2022 G. Xu, C. Chen, C. Shen, H. Zhou, X. Wang, T. Cheng, J. Shang Hydrogen peroxide and high-temperature heating differently alter the stability and aggregation of black soil colloids Chemosphere, 287 (2022), Article 132018 View PDFView articleView in ScopusGoogle Scholar Xu et al., 2021 H. Xu, B. Xia, E. He, R. Qiu, W.J.G.M. Peijnenburg, H. Qiu, L. Zhao, X. Xu, X. Cao Dynamic release and transformation of metallic copper colloids in fl ooded paddy soil: role of soil reducible sulfate and temperature J. Hazard Mater., 402 (2021), Article 123462 View PDFView articleView in ScopusGoogle Scholar Xu et al., 2014 N. Xu, M. Chen, K. Zhou, Y. Wang, H. Yin, Z. Chen Retention of phosphorus on calcite and dolomite: speciation and modeling RSC Adv., 4 (2014), pp. 35205-35214 CrossRefView in ScopusGoogle Scholar Yan et al., 2018 Z. Yan, S. Chen, B. Dari, D. Sihi, Q. Chen Phosphorus transformation response to soil properties changes induced by manure application in a calcareous soil Geoderma, 322 (2018), pp. 163-171 View PDFView articleGoogle Scholar Zhang, 2008 M.-K. Zhang Effects of soil properties on phosphorus subsurface migration in sandy soils Pedosphere, 18 (2008), pp. 599-610 View PDFView articleView in ScopusGoogle Scholar Zhang et al., 2022 S. Zhang, L. Wang, S. Chen, B. Fan, S. Huang, Q. Chen Enhanced phosphorus mobility in a calcareous soil with organic amendments additions: Insights from a long term study with equal phosphorus input J. Environ. Manag., 306 (2022), Article 114451 View PDFView articleView in ScopusGoogle Scholar Zhang et al., 2021 S. Zhang, X. Yang, L.-C. Hsu, Y.-T. Liu, S.-L. Wang, J. White, S. Shaheen, Q. Chen, J. Rinklebe Soil acidification enhances the mobilization of phosphorus under anoxic conditions in an agricultural soil: Investigating the potential for loss of phosphorus to water and the associated environmental risk Sci. Total Environ., 793 (2021), Article 148531 View PDFView articleView in ScopusGoogle Scholar Zhou et al., 2021 J. Zhou, X. Jiao, L. Ma, W. de Vries, F. Zhang, J. Shen Model-based analysis of phosphorus flows in the food chain at county level in China and options for reducing the losses towards green development Environ. Pollut., 288 (2021), Article 117768 View PDFView articleView in ScopusGoogle Scholar Cited by (0) ☆ This paper has been recommended for acceptance by Xiang-Yu Tang. View Abstract © 2023 Elsevier Ltd. All rights reserved. Part of special issue Land development and water pollution Edited by Xiaoyu Li, Xiangyu Tang, María Estrella Báez Contreras, Debin Mao View special issue Recommended articles Biochar supported nanoscale zerovalent iron-calcium alginate composite for simultaneous removal of Mn(II) and Cr(VI) from wastewater: Sorption performance and mechanisms Environmental Pollution, Volume 343, 2024, Article 123148 Bing Wang, …, Miao Chen View PDF Prenatal exposure to environmental heavy metals and newborn telomere length: A systematic review and meta-analysis Environmental Pollution, Volume 343, 2024, Article 123192 Kyi Mar Wai, …, Kazushige Ihara View PDF Extraction of eutrophic and green ponds from segmentation of high-resolution imagery based on the EAF-Unet algorithm Environmental Pollution, Volume 343, 2024, Article 123207 Yating Hu, …, Liqiao Tian View PDF Show 3 more articles Article Metrics Captures Readers: 1 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply."

Paper 7:
- APA Citation: Atoui, M., & Agoubi, B. (2022). Assessment of groundwater vulnerability and pollution risk using AVI, SPI, and RGPI indexes: Applied to southern Gabes aquifer system, Tunisia. Environmental Science and Pollution Research, 29(50881–50894). https://doi.org/10.1007/s11356-022-19309-5
  Main Objective: The primary goal of the study was to evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems. The study aimed to identify gaps and challenges in the integration, interoperability, and standardization of these systems and propose solutions to enable fully autonomous, scalable irrigation management.
  Study Location: Unspecified
  Data Sources: Literature review
  Technologies Used: IoT, machine learning
  Key Findings: 1. Automated irrigation systems have the potential to significantly contribute to addressing the global food challenge by increasing agricultural productivity and optimizing crop yields.
2. Real-time, end-to-end automated irrigation systems can improve the efficiency and effectiveness of irrigation management by automating data collection, analysis, decision-making, and actions.
3. Interoperability and standardization are crucial for enabling the seamless integration of components within automated irrigation management systems.
4. Challenges associated with implementing real-time, automated irrigation systems include data quality, scalability, reliability, and security, and need to be addressed to ensure the successful adoption of these systems.
  Extract 1: "Redundancy: Implementing redundant components, such as duplicate sensors (e.g., soil moisture sensors, weather stations), controllers (e.g., PLCs, microcontrollers), and communication channels (e.g., cellular, satellite, LoRaWAN) to maintain system functionality during component failures"
  Extract 2: "The values predicted by the SVM and CART approaches are in extremely good agreement with the measured IGWQI, with a mean coefficient of determination (R2) close to 1, about 0.91 and 0.99, respectively, thus ensuring practicality and confidence for the artificial intelligent model."
  Limitations: None
  Relevance Evaluation: The study on which this prompt is based is relevant to the outline point because it addresses the need for redundancy in automated irrigation systems, which is a specific aspect of the broader topic of integration, interoperability, and standardization in automated irrigation management systems. The study proposes the implementation of redundant components, such as sensors, controllers, and communication channels, to maintain system functionality during component failures, which aligns with the point's focus on resilience and fault tolerance. By exploring specific strategies to enhance the robustness of automated irrigation systems, the study contributes to the overall discussion on the integration, interoperability, and standardization of these systems.
  Relevance Score: 0.9
  Inline Citation: (Atoui & Agoubi, 2022)
  Explanation: The authors of this study sought to determine the relevance of an automated, real-time irrigation management system. A review of related literature was conducted, and the following key themes emerged from the literature:

1. **Addressing the global food challenge**: Automated irrigation systems can contribute significantly to meeting the growing demand for food by enabling more efficient and targeted use of water resources, increasing agricultural productivity, and optimizing crop yields.
2. **Evaluating the current state and future potential**: The study aims to critically assess the current state-of-the-art in end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. This includes identifying gaps and proposing solutions for seamless integration across the automated irrigation management system to achieve fully autonomous, scalable irrigation management.
3. **Examining automation across the entire pipeline**: The review intends to systematically analyze the automation of each component of the irrigation management pipeline, from data collection and transmission to processing, analysis, decision-making, and automated action. It aims to investigate the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
4. **Highlighting the role of interoperability and standardization**: The review seeks to emphasize the importance of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline. It aims to identify existing and emerging standards and their applicability to real-time irrigation management systems.
5. **Identifying challenges and proposing solutions**: The review intends to uncover the challenges associated with implementing real-time, automated irrigation systems, such as data quality, scalability, reliability, and security. It aims to propose solutions and best practices based on the analysis of case studies and real-world implementations.
6. **Guiding future research and innovation**: By identifying research gaps and proposing new research questions and hypotheses, the review aims to provide a roadmap for advancing the field of real-time, automated irrigation management. It seeks to encourage collaborative research efforts across disciplines to address the complex challenges of automated irrigation systems.

 Full Text: >
"Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Log in Find a journal Publish with us Track your research Search Cart Home Water, Air, & Soil Pollution Article Geothermal Water Quality Index Assessment for Irrigation Purpose with Multicomputing Modeling Coupled with GIS: Case of El Hamma, Southeastern Tunisia Published: 15 February 2024 Volume 235, article number 160, (2024) Cite this article Download PDF Access provided by University of Nebraska-Lincoln Water, Air, & Soil Pollution Aims and scope Submit manuscript Boulbaba Haddaji , Mounir Atoui, Khyria Wederni, Belgacem Agoubi & Adel Karroubi  91 Accesses Explore all metrics Abstract Aquifer quality monitoring and scoping are essential for both groundwater control and water provision in agricultural areas. The Irrigation Geothermal Water Quality Index (IGWQI) was investigated based on 6 variables (EC, SAR, Cl, Na, HCO3, and T) for 41 water samples using conventional method and predicted with support vector machine (SVM) and classification tree and regression (CART) computer models as an indicator to evaluate the suitability of geothermal water for irrigation. It was found that the use of such parameters allows for more accurate identification of unsuitable groundwater areas and reduces estimation bias, particularly if the dataset is limited (6 variables). In this study, the SVM and CART models were developed and validated to assess the groundwater quality of the EL Hamma aquifer. The values predicted by the SVM and CART approaches are in extremely good agreement with the measured IGWQI, with a mean coefficient of determination (R2) close to 1, about 0.91 and 0.99, respectively, thus ensuring practicality and confidence for the artificial intelligent model. Findings showed that three classes of groundwater quality were identified: 12% are good, 56% are satisfactory, and 32% are classified as unsuitable water. The poor water quality for irrigation is shown in the eastern parts of the study area, which is nearly similar to that of the water temperature, averaging between 35 and 57 °C. This rise in water temperature is controlled by the fault that connects the deep compartments of the system and the shallow aquifer. IGWQI delineation and mapping is an excellent tool for the protection and safeguarding of groundwater resources, notably in arid areas where groundwater is the sole source of life, as well as an important tool in decision-making for groundwater planning and use. Similar content being viewed by others Modeling of groundwater quality index by using artificial intelligence algorithms in northern Khartoum State, Sudan Article Open access 22 December 2022 Integrated machine learning–based model and WQI for groundwater quality assessment: ML, geospatial, and hydro-index approaches Article Open access 03 March 2023 Groundwater Quality Prediction in Upper and Middle Cheliff Plain, Algeria Using Artificial Intelligence Chapter © 2024 1 Introduction As an essential resource, groundwater is essential for meeting various human needs, particularly in the agricultural sector, where it accounts for around 43% of total groundwater use worldwide (Seibert et al., 2010). However, the integrity of this vital resource is increasingly compromised due to the significant impact of anthropogenic activities, including agriculture, industry, and tourism. These collective pressures have led to a quantitative depletion and qualitative degradation of groundwater, constituting a major threat to its sustainability (Zammouri et al., 2014; Agoubi, 2018; Hamed et al., 2018; Ncibi et al., 2020; Yahiaoui et al., 2021; Atoui & Agoubi, 2022; Wederni et al., 2023; Atoui & Agoubi, 2024). The impact of degraded groundwater quality is global, as evidenced by the alarming number of approximately 829,000 annual deaths attributed to unsafe water consumption, according to the WHO (2019). Furthermore, projections indicate that over the next decade, up to 5.5 billion people could face water scarcity, underlining the imperative for concerted efforts in water resource management (Amitrano et al., 2014). In response to this global concern, numerous studies in various geographical regions have sought to assess and monitor water quality. These efforts have focused primarily on assessing the suitability of groundwater for vital uses such as drinking and irrigation, using a variety of methodologies and indices (Bouksila et al., 2010; Agoubi et al., 2016; Besser et al., 2017; Madhav et al., 2018; Kawo & Karuppannan, 2018; Hasan & Rai, 2020; Gopinath et al., 2021; Ben Brahim et al., 2021; Khan et al., 2022; Nadiri et al., 2022). While the traditional Water Quality Index (WQI) methodology was introduced in 1965 (Horton, 1965), its limitations in providing a holistic assessment of water quality have motivated the development of new assessment methodologies. Recent advances in water quality assessment have relied on cutting-edge technologies, incorporating artificial intelligence (AI) techniques such as artificial neural networks (ANNs), machine learning (ML), and deep learning (DL) (Wagh et al., 2016; Lu & Ma, 2020; Hannan & Anmala, 2021). In addition, several global studies have adopted a combination of methodologies, integrating Geographic Information Systems (GIS)-based approaches, fuzzy logic, and multicriteria decision-making to comprehensively assess the suitability of groundwater for specific applications (Agoubi et al., 2016; Ben Brahim et al., 2021). However, despite the advances in the global assessment of groundwater quality, specific methodologies using algorithms such as classification and regression trees (CART) and Support Vector Machines (SVM) to assess the Geothermal Irrigation Water Quality Index (IGWQI) remain relatively unexplored. In particular, regions such as El Hamma, in the south of Tunisia, offer a favorable context for the application of these methodologies but have not yet been studied in depth. This research seeks to fill this gap by proposing an innovative approach to evaluating IGWQI, by incorporating the temperature parameter and using CART and SVM algorithms. The introduction of this innovative methodology offers promising prospects for informing and improving decision-making processes relating to groundwater management in the region. The cited studies collectively contribute valuable insights into the assessment and utilization of geothermal water resources in different regions. Pandey et al. (2022) provide a hydrochemical analysis of geothermal water in Gujarat, India, using the Irrigation Water Quality Index. Ben Brahim et al. (2022b) employ spatial analysis and decision-making tools to evaluate irrigation groundwater sustainability in South Tunisia. Hajji et al. (2021) introduce an adaptive Mamdani fuzzy inference system model to assess irrigation groundwater quality in Tunisia, incorporating fuzzy logic for Water Quality Index determination. Ben Brahim et al. (2020) offer a comprehensive exploration of the geothermal potential in Tunisia’s Djerid Basin, utilizing multicriteria decision analysis for mapping potential areas. Additionally, Ben Brahim et al. (2022a) assess groundwater quality in Southeastern Tunisia for agricultural use, employing a diverse methodology that integrates hydrogeological and geochemical data with GIS and simulations. Lastly, focus on the Unai geothermal field in Gujarat, India, evaluating geothermal water suitability for industrial and irrigation purposes and highlighting the necessity of water treatment for effective utilization. Together, these studies underscore the importance of employing diverse methodologies, incorporating advanced decision-making tools, and considering various factors for a comprehensive understanding of geothermal water resources and their potential applications. Moreover, the scarcity of studies adopting similar methodologies in the specific context of El Hamma underlines the novelty and crucial importance of this research project. Responding urgently to the need to preserve and manage groundwater quality in this region is essential to ensure the stability and sustainability of life, particularly in the face of worsening water scarcity and the degradation of essential water resources. 2 Study Area The region of El Hamma is in the southeastern part of Tunisia (33° 50′-33° 55′ N and 9° 42′-9° 49′ E). In the East, it is limited by the Jebal Ragouba, in the West by Jebal Aziza, the Jebal Bou Najma in the south, and by Sebket El Hamma in the North (Fig. 1). The total area of the study area is 95 km2. This area is characterized by an arid to semi-arid climate with a strong seasonal variation affected by the Mediterranean climate. The average annual rainfall is 150 mm, and the average annual temperature is around 21.5 °C, sometimes exceeding 40 °C in July and August (GDWR, 2021). Fig. 1 Geographical and geological map of the study area Full size image 3 Geological and Hydrogeological Settings The study area is characterized by vertical and rebounding discontinuities which lead to the appearance of complex geological features, thus the presence of sedimentation conditions (Agoubi, 2018; Agoubi et al., 2015). It consists of the Synclinal of Wadi Aied, which is stuck between Jebel Aziza to the west and Jebel Ragouba to the east, and by the anticline of Jebel Bou Nejma which has been cut by three accidents (fault of NW–SE direction is born at the southern end of Jebel Hallouga and two other faults of NW–SE directions limit the horst of the Intercalary Continental which appears on the flank of Jebel Bou Nejma) (Abidi, 2004). The lithostratigraphic series of this study area ranges from the Cretaceous to the Quaternary (Fig. 1). The lowest Cretaceous deposits are dominated by the Hauterivian–Barremian, Albian, and Turonian stages. Thus, the Barremian is constituted of clays, gypsums, and anhydrite (Agoubi, 2018). The Albian deposits are dominated by carbonate series (limestone, dolomite, and marl) (Agoubi, 2018). The Turonian deposits are formed mainly by dolomites. The Upper Cretaceous series is mainly formed of sands, clays, and gypsums. The Mio-Pliocene deposits lie unconformably in the Cretaceous, formed mainly of sandy clays (Abbes et al, 1994; Agoubi, 2018). An outcrop of quaternary exists throughout the study area. This outcrop is characterized by a variety of sediments (sandy clays, sands, conglomerates, and sandstones). The hydrogeological framework of the El Hamma region is characterized by the presence of three distinct aquifer systems: the intercalary continental aquifer (CI), the deep El Hamma-Chenchou aquifer composed mainly of Upper Cretaceous formations, and the shallow El Hamma aquifer. The CI aquifer, covering around 1,000,000 km2 of the Algerian-Tunisian-Libyan Sahara, is a major source of water for southern Tunisia, with sandstone formations from the Lower Cretaceous and notable temperatures of between 60 and 80 °C (OSS, 2003). In the El Hamma region, a network of faults facilitates the contribution of the CI aquifer to the Gabès Jeffara aquifer system (Abidi, 2004). The deep El Hamma-Chenchou aquifer, mainly composed of Lower Senonian dolomitic limestones and Turonian limestones and dolomites, is a crucial component of the larger Jeffara aquifer. Significantly influenced by dense fault networks in the Senonian limestones, extending from the Upper Senonian to the Plio-Quaternary, this aquifer has an impact on its hydrogeological dynamics (Abbès et al., 1994). With the roof of the aquifer at a depth of around 60 m and levels reaching up to 600 m at Mzirâa El Hamma due to tectonic events, its main source of water supply comes from the discharge of the continental intercalary into the limestone layers via faults oriented SSE-NNW. Contributions from current rainfall remain marginal, occurring mainly at specific outcrops of Cretaceous limestone, such as those in the Daher region and in wadi beds. The El Hamma shallow aquifer, made up of conglomeratic formations covering the marl-limestone of the Lower Senonian and the sandy sandstone series of the Continental Intercalary, is fed both by transfer from the CI aquifer through fault networks and by infiltration of rainwater, particularly from wadis such as El Hamma, El Khardeja, and El Tkouri to the east and Oued El Aïd and its tributaries to the south-west (Abbès et al., 1994). This in-depth analysis of the hydrogeological units of El Hamma highlights their interconnection and the complex dynamics that govern the region’s water resources. 4 Materials and Methods 4.1 Sample Collection and Database The comprehensive sampling of 41 groundwater samples covering almost the entirety of the study area, except for the northern part near the Sebkha where thermal drilling faced limitations, forms a robust foundation for this study. Conducted in March 2022 within the shallow geothermal aquifer at depths ranging from 25 to 100 m, these samples offer a thorough representation of the aquifer’s composition. The absence of thermal boreholes in the northern region, near the Sebkha, underscores a coverage gap attributable to specific constraints on borehole availability in that particular area (Fig. 2). Fig. 2 Location map of groundwater samples in the study area Full size image The decision to conduct a single sampling event in March 2022 is supported by the geological characteristics of the vadose zone and the considerable depth of the water table in the geothermal aquifer. This combination suggests that the water table is minimally influenced by external variations such as climatic conditions (rainfall, air temperature, etc.). Consequently, a one-time sampling approach is deemed appropriate, eliminating the necessity for collecting samples during both wet and dry periods and streamlining the study methodology. Additionally, prior to each sampling event, groundwater was diligently pumped for 15–20 min to release stored groundwater in the well, ensuring stability in the sampled conditions. Overall, these methodological choices contribute to the reliability and efficiency of the study’s groundwater analysis. All recovered water samples were collected in polyethylene bottles and stored in freezers from the well site to the geochemical laboratory of the Higher Institute of Water Science and Technology at Gabes University. Major ions (Na, K, Ca, Mg, Cl, SO4, and HCO3) have been assayed by ion chromatography (Methrohm 850 Professional IC). The hydro-chemical analyses were validated using the CBE % (Eq. (1)). $$CBE \\left(\\%\\right)= \\frac{\\sum cations-\\sum anions}{\\sum cations+\\sum anions}*100$$ (1) According to the data, all these samples showed a CBE of lower than ± 5%, and a very good correlation (R2 = 0.93) which is assumed to be reliable for groundwater studies (Fig. 3). Fig. 3 Cross-validation cations-anions Full size image The strategy used in this study was mainly devoted to the thermal groundwater adequacy for irrigation using the IGWQI. A database including hydro-chemical and physical groundwater data was established to identify the water resources appropriate for irrigation in the El Hamma region. In the current study, six parameters were included to estimate the quality of irrigation water as sodium (Na+), chloride (Cl−), HCO3−, electrical conductivity, sodium adsorption ratio (SAR), and water temperature. To reach the study goal, we used a machine learning tool to calculate the parameter weights of the IGWQI, then predicted the IGWQI using a classification and regression tree (CART), and the support vector machine (SVM). Incorporating GIS technology to yield a digital spatial allocation of analytical parameters results in the monitored study area. Observed IGWQI map was produced by superposing thematic maps (EC, SAR, Na+, Cl−, HCO3−, and T) using geo-statistical analysis, which involves the inverse distance weighted (IDW) interpolation approach (Fig. 4). Fig. 4 Flowchart of the method used in the study Full size image 4.2 Irrigation Geothermal Water Quality Index (IGWQI) The Water Quality Index (WQI) has played a pivotal role in water quality studies since its introduction by Horton in 1965. Horton’s model, founded on 10 key water quality parameters universally deemed significant, has evolved into a valuable tool for local authorities in provinces and territories. It aids in refining decisions pertaining to water usage in both agricultural and human contexts. Various scientific endeavors, such as the study conducted by Ben Brahim et al. (2021) have leveraged the WQI to categorize drinking and irrigation water quality. Additionally, Atoui and Agoubi (2022) have employed the index to evaluate groundwater sensitivity, introducing a Pollution Sensitivity Index (SPI) that encompasses the WQI. The Irrigation Water Quality Index (IWQI) model, initially proposed by Meireles et al., 2010, has been a focal point in previous studies. Notably, influential parameters affecting irrigation water quality, including EC, SAR, Na + , Cl-, and HCO3-, have been identified in works by Abbasnia et al. (2018). Furthermore, insights from Bordalo et al. (2007) and Hoseinzadeh et al. (2014), coupled with statistical analyses such as correlation matrices, have revealed that temperature in geothermal groundwater zones significantly influences the Water Quality Index. Consequently, these findings advocate for the inclusion of temperature as a sixth parameter, giving rise to the Geothermal Irrigation Water Quality Index (IGWQI) concept. The conversion of concentration units from (mg/L) to (meq/L) was done using the conversion factors given by Lesch and Suarez (2009), and the sodium absorption ratio (SAR) was then calculated using Eq. (2) (Richards, 1954). $$SAR= \\frac{\\left[{Na}^{+}\\right]}{\\sqrt{\\frac{\\left[{Ca}^{2+}\\right]+\\left[{Mg}^{2+}\\right]}{2}}}$$ (2) Then, the Qi values are derived because of each parameter Meireles et al. (2010), which denotes the status of variables from 0 to 100 and is a function of their value. Using Eq. (3), Qi values were calculated within the tolerance limits described in Table 1 proposed by Abbasnia et al. (2018) after Agoubi et al. (2016) for the water temperature classification interval. $${q}_{i}={q}_{max}-\\left(\\frac{\\left({X}_{ij}-{X}_{inf}\\right)*{q}_{iamp}}{{X}_{iamp}}\\right)$$ (3) where Qi max and Qi amp are respectively the maximum value and the class amplitude of Qi for each class, Xij is the value observed for the parameter, and Xinf and Xiamp correspond to the lower limit value of the class and class amplitude for each parameter, respectively. $${w}_{i}=\\frac{\\sum_{j=1}^{k}{F}_{j}{A}_{ij}}{\\sum_{j=1}^{k}\\sum_{i=1}^{n}{F}_{j}{A}_{ij}}$$ (4) where wi is the weight of the parameter, F is the eigenvalue of component 1, Aij is the explainability of parameter I by factor j, i is the number of parameters considered in the model ranging from 1 to n, and j is the number of factors selected in the model ranging from 1 to k. Table 1 Parameter limiting values for quality measurement (Qi) calculations (Agoubi et al., 2016; Meireles et al., 2010) Full size table The output of the described operation is the IGWQI value which is given by Eq. (5), and Table 2 represents the IGWQI characteristics for each class. Table 2 The range and type of irrigation water for IGWQI (Zahedi, 2017) Full size table $$IGWQI= \\sum_{i=1}^{n}{Q}_{i}{w}_{i}$$ (5) It is worth considering that the calculation of Qi indices and wi is only carried out for this step in order to compare and validate the SVM and CART models that automatically compute the Qi and the weights by artificial intelligence. 4.3 Machine Learning Model 4.3.1 Support Vector Machine Technique (SVM) Support Vector Machine (SVM) is a classification method rooted in statistical learning theory, as articulated by Vapnik, 1998 (Malek et al., 2022). This innovative clustering approach adopts the principle of structural risk minimization (SRM) to address overfitting challenges in machine learning, a concern highlighted by Mohammadpour et al., 2014. This transformative process involves converting SRM into quadratic programming, thereby bolstering the generalization capabilities of the SVM model, as elucidated by Behzad et al. (2009). In SVM classification, an adaptively split plane is employed, strategically dividing the plane into two distinct sections, with each class assigned to a separate side. The foundation of SVM estimates rests on a small subset of the training data denoted as {xi, yi}, commonly known as support vectors. The primary objective of SVM is to ascertain a function, denoted as f(x) and described by Eqs. (6) and (7), based on the target values (yi). This function should ideally be as flat as possible. If we define f(x) as a linear discriminant function, the SVM function can be expressed as follows: $$f\\left(x\\right)= \\sum_{i=1}^{m}\\left({\\alpha }_{i}-{{\\alpha }_{i}}^{*}\\right)\\left({x}_{i},{x}_{j}\\right)+b$$ (6) To solve the nonlinear problem in the support vector regression, the SVM works by taking an appropriate kernel function to map the initial data into a high-dimensional feature space where a maximum separation plane is built. To split the data, two parallel hyperplanes can be expanded on either side of the SP. Then the SVM can be written as follows: $$f\\left(x\\right)= \\sum_{i=1}^{m}\\left({\\alpha }_{i}-{{\\alpha }_{i}}^{*}\\right)K\\left({x}_{i},{x}_{j}\\right)+b$$ (7) where αi and αi* are Lagrangian parameters, and b is the bias. And K (xi; xj) = γ (1 + xi:xj)p or exp (− γ||xi yj||2), respectively, if it is a polynomial kernel function or Gaussian kernel function with p and γ are adjustable kernel parameters. 4.3.2 Classification and Regression Tree (CART) The classification and regression tree (CART) algorithm is designed to generate models that fulfill both explanatory and predictive objectives. This involves determining the number of observations required to estimate specific statistics reliably. The CART process hinges on strategically dividing observations into groups that exhibit homogeneity concerning the variable in question for prediction. First introduced by Quinlan (1990), CART orchestrates decisions based on various values of different parameters. To achieve short-term predictions with a swift computational speed, multiple iterations are employed. At each iteration, the observation dataset is iteratively split into K = 2 classes to elucidate the dependent variable. This iterative separation continues until no further division is feasible. Node separation ceases under certain stopping rules, including achieving a pure node, reaching a user-defined tree depth, or if the node size surpasses a user-defined threshold, as proposed by Breiman et al. (1984). The primary objective of each separation is to minimize the variance at each node, as defined by Eq. (8). This iterative process allows CART to iteratively refine its model, ensuring both explanatory and predictive goals are met while adapting to the unique characteristics of the dataset. $$\\sum_{{X}_{i}\\epsilon t}{\\left({Y}_{i}-\\overline{y }\\left(t\\right)\\right)}^{2}$$ (8) where Yi is the value of the dependent variable associated to the observation I and y(t) is the average of the outputs associated to the node. To select the root and depending on the variable, the Gini impurity index can be used to divide nodes following Eq. (9) $$GINI :i\\left(t\\right)=1-\\sum_{j}{p}^{2}\\left(j/t\\right)$$ (9) with p(j/t) the probability of having the modality j of Y knowing that we are in the node t. The weights of the observations are included in the ranking calculus. In case of a tie, the average rank is used. The rank and corresponding values are designated in ascending order as follows (Eq. (10)): $${\\left\\{{r}_{\\left(i\\right)},{x}_{(i)}\\right\\}}_{i=1}^{n}$$ (10) For each category, k = 0 \\(x\\) (K − 1), \\({I}_{k}=\\left\\{i : \\left[r\\left(i\\right)*\\frac{K}{N+1}\\right]=k\\right\\}\\) where [\\(x\\)] is the floor integer of\\(x\\). If the group \\({I}_{k}\\) is nonempty,\\({i}_{k}={\\text{max}}\\left\\{i : \\epsilon {I}_{k}\\right\\}\\). The breakpoints are set equal to the \\(x\\) values corresponding to the\\({i}_{k}\\), excluding the largest. The decision tree framework is parametric less and does not require any assumption on input data distribution, is simple to interpret, and necessitates a minimum of data preparation. 4.3.3 Validation of Model Performance The observed IGWQI data and the modeled values were compared to assess whether the results obtained by the models are reliable. Two proposed criteria were selected as follows: root mean square error and coefficient of determination. 4.3.4 Root Means Square Error The RMSE is a measure of the dispersion of the residuals (prediction errors). A smaller value of RMSE means a better model prediction. Given by the following (Eq. (11)): $$RMSE=\\sqrt{\\frac{1}{N}} {\\sum }_{i=1}^{N}{\\left({X}_{{0}_{i}}-{X}_{{p}_{i}}\\right)}^{2}$$ (11) 4.3.5 Determination Coefficient The coefficient of determination R2 is the Pearson squared correlation coefficient (Eq. (12)). This coefficient measures the strength of the linear relationship between the response variable and the predictor variable. $${R}^{2}=\\frac{SSR}{SST}$$ (12) where SSR is the sum of squared regression also known as variation explained by the model. And SST is the total variation in the data also known as the sum of squared total. 5 Results and Discussion 5.1 Irrigation Geothermal Water Quality Index (IGWQI) Assessment In this study, 41 sets of geothermal water observation data from 41 wells and boreholes were distributed in the study area. Table 3 shows the minimum, maximum, mean, and standard deviation of the variables selected to calculate the IGWQI which are as follows: electrical conductivity, sodium absorption ratio, temperature, and concentration of sodium, chloride, and hydrogen carbonate. The standard deviation values are lower than the mean for all parameters indicating heterogeneity of the water samples. The mineralization of the water is relatively high with an electrical conductivity varying between 1.73 and 4.96 (mS/cm). In comparison with the Food and Agriculture Organization (FAO) criterion for agricultural application, some wells and boreholes show inappropriate sodium and chloride values which show a maximum of 48.24 and 40.73 plus 40 and 30, respectively. Similarly, the electrical conductivity value gives a maximum of about 4.96 mS/cm outside the FAO electrical conductivity range [0–3]. Based on the descriptive statistics, some samples fall within the normal FAO range for Na, Cl, and EC values. The carbonate HCO3 ranges between 1.59 and 7.05 meq/L, with a mean and standard deviation of about 3.8 and 1.7, respectively. Table 3 Descriptive statistics of IGWQI parameters Full size table According to M’nassri et al. (2022), all irrigation water classified as “excellent” and “good” have a SAR value between 0 and 18. Following the descriptive statistics, most of the samples fall inside the normal FAO range for water potability with calculated SAR values ranging from 2.22 to 9.51, with a mean of about 6.2 and a standard deviation of around 2. The temperature varies from 20.8 to 56.4 °C, thus referring to thermal groundwater. For this case, the current study added water temperature as a sixth parameter to assess the quality of irrigation water which shows a good correlation with IGWQI (Table 4). Despite the low correlation between T and other parameters, according to El Bilali et al. (2020), these lower correlations are indicative of the fact that these parameters are not redundant and, hence, are useful for improving the predictive ability of machine learning. Table 4 Correlation matrix of water quality parameters Full size table Some wells can only be used for those plants with high salinity and temperature tolerance and with special control practice, such as many types of geothermal water coolers used to decrease water temperature and thus salt deposition (Karakuş & Yıldız, 2019). From the spatial development maps of EC, SAR, Na+, Cl−, HCO3−, and T (Fig. 5), it is shown that the study area has four classes of geothermal water quality parameters ranging from poor to extremely good quality, with the exception of Na+ and Cl− which reflect that more than 99% of the study area is in the inadequate class of more than 9 meq/L, and the thematic map of HCO3− shows two classes of excellent and good quality. Fig. 5 IGWQI’s parameter thematic maps Full size image In this main study, IGWQI’s value computing is carried out using Eq. (5), in which rates were calculated based on Eq. (3) and Table 1, and the weight values are computed using the first component’s variance linked to its ability to explain each parameter. The standardized weight values are presented in Table 5. Table 5 Calculated relative weight of each parameter Full size table The calculated IGWQI values varied from 23.494 to 57.089. About 12% of the samples fall into the “good” category, and the rest of the samples are satisfactory and unsuitable with about 56% and 32%, respectively (Table 6). Table 6 Irrigation Geothermal Water Quality Index frequency distribution Full size table 5.2 Implementation and Evaluation of Models In this research, we implemented a dataset of 41 observations for 6 water quality parameters to predict IGWQI in the El Hamma aquifer system, using CART and SVM models. The initial challenge is to identify the best training algorithms for the classification tree which may differ in the number of child nodes generated; for example, CART which systematically produces binary trees, and thus searches for the best-performing binary partition on the segmentation metric, or CHAID which tries to produce the most relevant groupings from statistical data, and the best kernel functions that fit the SVM model. The two predictive models adopted in this section are the power kernel function for the SVM and the CART algorithm for the classification tree, which obtained the lowest RMSE values with 2.56 and 0.23, respectively, and the highest R2 value with 0.91 and 0.99. The scatter plots in Fig. 5 illustrate the agreement between the predicted and observed IGWQI values in the CART and SVM models. This process output reveals that the CART model has significant R2 and RMSE values compared to the SVM models for the prediction of the WQI, but both are validated with a coefficient of determination close to 1 and a considerably low RMSE. Furthermore, it reveals that the predicted values are closely related to the observed values. Comparing the observed IGWQI values with those predicted by both CART and SVM for all samples is shown in Fig. 6 and Table 7. It is apparent that the CART-predicted values of the IGWQI are closer to the observed values than the SVM-predicted values, thereby indicating the coherence and suitability of the proposed CART model (Fig. 7). Fig. 6 Correlation between predicted and observed IGWQI values with SVM (a, b) and CART (c, d) model Full size image Table 7 Observed IGWQI values and those predicted by CART and SVM Full size table Fig. 7 Observed, CART, and SVM results of IGWQI for all samples Full size image According to the present results, groundwater consumption in the El Hamma aquifer, which is 31% classified as unsuitable for irrigation is highly dangerous for the soil and plants. In fact, the most considerable source of salinization in this region is agricultural activity and geothermal healing baths (Fig. 8). Fig. 8 Observed (a) and predicted Irrigation Water Quality Index thematic map with CART (b) and SVM (c) models Full size image In addition, the high temperature of the water strongly contributes to the dissolution of salts and pesticides in the irrigation water and thus to their leaching into the soil. Hot geothermal water also threatens plant roots and thus destroys plant tissue. Therefore, there might be measures to prevent the leaching of soluble salts that threaten water quality. It is worth mentioning a review of the predictive performance of the optimal model in our research with other works cited in the literature for the prediction of Water Quality Index in the world. Asadollah et al. (2021) reported that the tree regression model had an ideal predictive ability compared to other models considering a determination coefficient R2 = 0.97. Kamyab-Talesh et al. (2019) predicted the Water Quality Index by the support vector machine with a coefficient of determination (R2) and root mean square error (RMSE) values of 0.87 and 0.06, respectively. Wei Cong et al. (2021) and M’nassri et al. (2022) used different models with R2 values < 0.90. It is clearly apparent that the CART and SVM models exceed and validate several current models. Therefore, the SVM and CART models are popular learning models that deliver more precise predictive results compared to other developed forecasting models in this literature. The results were spatially distributed based on interpolation approaches. Using the color-coding system, the results were divided into five bands, in which red color corresponds to poor water quality and blue to excellent water quality. The IGWQI with a lower value corresponds to inadequate water quality and vice versa. Fig. 7 shows that the eastern areas of the plain exposed poor water quality area which was found almost similar to that of the water temperature (Fig. 5a), which shows an average between 35 and 57 °C. This height of water temperature is controlled by the fault which connects the deep compartments of the system and the shallow aquifer. IGWGI is used as a reference to illustrate the spatial distribution of the water quality indices of both models which are shown in Fig. 7. All models produced broadly similar spatial patterns; however, there were some but not large differences. The southern parts of the plain have poor water quality, while the rest parts of the plain have satisfactory water quality. According to Figs 6, 7 and 8, both models can integrate pysico-chemical parameter to develop new water quality indices, but the CART model proves its worth. Both the investigation conducted by Ben Brahim et al. in 2020 and our present study share a common theme of exploring the potential and applications of geothermal resources, although with different focuses. Ben Brahim et al.’s (2020) study centers on the identification of geothermal sites in the Tozeur region, Tunisia, using geographic information system-multicriteria decision analysis (GIS-MCDA). Their work emphasizes the diverse applications of harnessed geothermal resources, including thermal tourism, residential heating, greenhouse operations, and balneological treatment, showcasing the broad scope of geothermal utilization to meet local needs and contribute to renewable energy production in the Tunisian context. In contrast, our current study focuses on the hydrochemical analysis of geothermal water in El Hamma, Tunisia, utilizing the Irrigation Water Quality Index (IWQI) to assess its suitability specifically for irrigation purposes. Our work addresses the practical aspect of using geothermal water for sustainable irrigation practices, contributing insights into its viability for agricultural applications. While Ben Brahim et al.’s study in 2020 and Pandey et al.’s investigation in 2022 have broader scopes, encompassing the identification of geothermal sites and assessing geothermal water for various applications, respectively, our work provides valuable information on the specific application of geothermal water for irrigation, catering to the regional needs of Tunisia. Together, these studies contribute to a holistic understanding of geothermal resource utilization across different geographical contexts and applications. Ensuring the sustainable management of geothermal groundwater resources for long-term livelihood support involves a multifaceted strategy. It necessitates the enhancement of groundwater recharge through infrastructure like infiltration basins and injection wells, coupled with judicious extraction practices to maintain equilibrium between utilization and natural replenishment. Robust monitoring systems for geothermal gradients and subsurface temperatures are crucial, providing essential data for informed decision-making. Protective measures, such as regulating industrial discharges and enforcing land use practices, contribute to aquifer preservation. Engaging local communities through education and awareness initiatives fosters responsible water use. Integrated resource planning, research, and technological innovations, and a well-defined legal framework ensure comprehensive and sustainable management. Zoning for land use around geothermal areas, capacity building, economic diversification, and climate resilience planning further fortify the long-term viability of geothermal groundwater resources, safeguarding both livelihoods and environmental integrity. 6 Conclusion In conclusion, this in-depth study of groundwater quality in the study area, based on the Geothermal Irrigation Water Quality Index (IGWQI), has provided crucial information for the sustainable management of water resources. The use and development of innovative analysis methods, including the CART algorithm and SVM, enabled the IGWQI value to be accurately predicted for water samples from the shallow El Hamma aquifer. The results obtained revealed a significant distribution of samples in different categories of suitability for irrigation. Around 12% of samples were classified as unsuitable, highlighting the potential challenges associated with using these waters for irrigation. More encouragingly, over 56% of the samples were rated as satisfactory, offering positive prospects for the sustainable use of these resources. The CART model proved to be the most suitable for predicting the IGWQI value, performing exceptionally well with a coefficient of determination (R2) close to 1 (R2 = 0.99) and a root mean square error (RMSE) of 0.23. These results reinforce the reliability of the CART model in predicting the quality of geothermal irrigation water in this specific region. These findings are of particular importance to groundwater management for sustainable development in the study area. The information provided can guide decision-makers and water resource managers toward more effective strategies to ensure the judicious use of groundwater, thereby minimizing potential risks to agriculture and the environment. Ultimately, this study makes a significant contribution to the advancement of knowledge on groundwater quality and offers practical perspectives for the sustainability and preservation of these crucial resources. Data Availability The data used during this study will be made available upon request to the corresponding author, Boulbaba Haddaji (haddajiboulbaba2018@gmail.com). References Abbasnia, A., Radfarad, M., Mahvi, A., Nabizadeh, R., Yousefi, M., Soleimani, H., Alimohammadi, M. (2018). Groundwater quality assessment for irrigation purposes based on irrigation water quality index and its zoning with GIS in the villages of Chabahar, Sistan and Baluchistan, Iran. Data in Brief. 19. https://doi.org/10.1016/j.dib.2018.05.061. Abbes, C., Ben Ouezdou, H., Louhaichi, M. L., Mamou, A., & Lassoued, S. (1994). Notice explica-tive de la carte géologique d’El Hamma (feuille n° 74) (p. 60). De Tunisie: Serv. Géol. Google Scholar   Abidi,. (2004). Caractéristiques hydrodynamiques et géochimiques de la Jeffara de Gabès. DGRE, 2004, 198p. Google Scholar   Agoubi, B. (2018). Assessing hydrothermal groundwater flow path using Kohonen’s SOM, geochemical data, and groundwater temperature cooling trend. Environmental Science and Pollution Research, 25, 13597–13610. https://doi.org/10.1007/s11356-018-1525-1 Article   PubMed   CAS   Google Scholar   Agoubi, B., Souid, F., Telahigue, F., & Kharroubi, A. (2015). Temperature and Radon-222 as tracer of groundwater flow: Application to El Hamma’s geothermal aquifer system, southeastern Tunisia. Arabian Journal of Geosciences, 8, 11161–11174. https://doi.org/10.1007/s12517-015-1998-x Article   CAS   Google Scholar   Agoubi, B., Souid, F., Kharroubi, A., et al. (2016). Assessment of hot groundwater in an arid area in Tunisia using geochemical and fuzzy logic approaches. Environment and Earth Science, 75, 1497. https://doi.org/10.1007/s12665-016-6296-8 Article   ADS   CAS   Google Scholar   Amitrano, D., Martino, G. D., Iodice, A., Mitidieri, F., Papa, M. N., Riccio, D., & Ruello, G. (2014). Sentinel-1 for monitoring reservoirs: A performance analysis. Remote Sens., 6, 10676–10693. https://doi.org/10.3390/rs61110676 Article   ADS   Google Scholar   Asadollah, S. B. H. S., Sharafati, A., Motta, D., & Yaseen, Z. M. (2021). River water quality index prediction and uncertainty analysis: A comparative study of machine learning models. Journal of Environmental Chemical Engineering, 9(1), 104599. https://doi.org/10.1016/j.jece.2020.104599 Article   CAS   Google Scholar   Atoui, M., & Agoubi, B. (2022). Assessment of groundwater vulnerability and pollution risk using AVI, SPI, and RGPI indexes: Applied to southern Gabes aquifer system, Tunisia. Environmental Science and Pollution Research, 29, 50881–50894. https://doi.org/10.1007/s11356-022-19309-5 Article   PubMed   CAS   Google Scholar   Atoui, M., & Agoubi, B. (2024). Groundwater flow modeling and recharge estimation of heterogeneous aquifer: Applied to Matmata aquifer, southeastern, Tunisia. Physics and Chemistry of the Earth, Parts a/b/c, 133, 103513. https://doi.org/10.1016/j.pce.2023.103513 Article   Google Scholar   Behzad, M., Asghari, K., Eazi, M., & Palhang, M. (2009). Generalization performance of support vector machines and neural networks in runoff modeling. Expert Systems with Applications, 2009(36), 7624–7629. https://doi.org/10.1016/j.eswa.2008.09.053 Article   Google Scholar   Ben Brahim, F., Boughariou, E., Makni, J., & Bouri, S. (2020). Evaluation of groundwater hydrogeochemical characteristics and delineation of geothermal potentialities using multi-criteria-decision-analysis: Case of Tozeur region, Tunisia. Applied Geochemistry, 113(2020), 104504. https://doi.org/10.1016/j.apgeochem.2019.104504 Article   CAS   Google Scholar   Ben Brahim, F., Boughariou, E., & Bouri, S. (2021). Multicriteria-analysis of deep groundwater quality using WQI and Fuzzy Logic tool in GIS: A case study of Kebilli region, SW Tunisia. Journal of African Earth Sciences, 180, 104224. https://doi.org/10.1016/j.jafrearsci.2021.104224 Article   Google Scholar   Ben Brahim F., Msaddki H., Bouri S. (2022a). Groundwater quality index mapping for irrigation purposes in the “El Hezma-El Hmila” (Medenine, Tunisia). CLEAN-Soil, Air, Water Journa. https://doi.org/10.1002/clen.202100203. Ben Brahim F., Boughariou E., Hajji S., Bouri S. (2022b). Assessment of groundwater quality with analytic hierarchy process, Boolean logic and clustering analysis using GIS platform in the Kebilli’s Complex Terminal groundwater, SW Tunisia. Environmental Earth Sciences Journalhttps://doi.org/10.1007/s12665-022-10541-3 Besser, H., Mokadem, N., Redhouania, B., et al. (2017). GIS-based evaluation of groundwater quality and estimation of soil salinization and land degradation risks in an arid Mediterranean site (SW Tunisia). Arabian Journal of Geosciences, 10, 350. https://doi.org/10.1007/s12517-017-3148-0 Article   CAS   Google Scholar   El Bilali A., Taleb A., Brouziyne Y. (2020). Groundwater quality forecasting using machine learning algorithms for irrigation purposes. Agricultural Water Management, 106625. https://doi.org/10.1016/j.agwat.2020.106625 Bordalo, A., Teixeira, R., & Wiebe, W. (2007). A water quality index applied to an international shared river basin: The case of the Douro River. Environmental Management., 38, 910–920. https://doi.org/10.1007/s00267-004-0037-6 Article   ADS   Google Scholar   Bouksila, F., Persson, M., Berndtsson, R., Bahri, A., & Hamba, I. B. (2010). Estimating soil salinity over a shallow saline water table in semiarid Tunisia. Open Hydrology Journal, 4, 91–101. https://doi.org/10.2174/1874378101004010091 Article   ADS   CAS   Google Scholar   Breiman, L., Friedman, J., Stone, C. J., & Olshen, R. A. (1984). Classification and regression trees. CRC Press. Google Scholar   GDWR. (2021). Annual directories of groundwater exploitation. Tunis: General Directorate of Water Resources. Google Scholar   Gopinath R., Jessy R., Venkatesan G. (2021). Influence of groundwater quality on human health and its suitability for drinking and irrigation uses: A review. International Journal of Environmental Analytical Chemistry 0:0, 1–19. https://doi.org/10.1080/03067319.2021.1982922. Hajji, S., Yahyaoui, N., Bousnina, S., Ben Brahim, F., Allouche, A., Faiedh, H., Bouri, S., Hachicha, W., & Aljuaid, A. M. (2021). Using a Mamdani fuzzy inference system model (MFISM) for ranking groundwater quality in agri-environmental context: Case of the Hammamet-Nabeul shallow aquifer (Tunisia). Journal of Water, 2021(13), 2507. https://doi.org/10.3390/w13182507 Article   CAS   Google Scholar   Hamed, Y., Hadji, R., Redhaounia, B., et al. (2018). Climate impact on surface and groundwater in North Africa: A global synthesis of findings and recommendations. Euro-Mediterr J Environ Integr, 3, 25. https://doi.org/10.1007/s41207-018-0067-8 Article   Google Scholar   Hannan, A., & Anmala, J. (2021). Classification and prediction of fecal coliform in stream waters using decision trees (DTs) for Upper Green River Watershed, Kentucky, USA. Water, 2021(13), 2790. https://doi.org/10.3390/w13192790 Article   Google Scholar   Hasan, M. S. U., & Rai, A. K. (2020). Groundwater quality assessment in the Lower Ganga Basin using entropy information theory and GIS. Journal of Cleaner Production, 274, 123077. https://doi.org/10.1016/j.jclepro.2020.123077 Article   CAS   Google Scholar   Horton, R. K. (1965). An index number system for rating water quality. Journal of Water Pollution Control Federation, 37, 300–306. Google Scholar   Hoseinzadeh, E., Khorsandi, H., Wei, C., Alipour, M. (2014). Evaluation of Aydughmush River water quality using the National Sanitation Foundation Water Quality Index (NSFWQI), River Pollution Index (RPI), and Forestry Water Quality Index (FWQI). Desalination and water treatment. 54. https://doi.org/10.1080/19443994.2014.913206. Kamyab-Talesh, F., Mousavi, S.-F., Khaledian, M., Yousefi-Falakdehi, O., Norouzi, M., & Mojtaba. (2019). Prediction of Water Quality Index by support vector machine: A case study in the Sefidrud Basin. Northern Iran. Water Resources., 46, 112–116. https://doi.org/10.1134/S0097807819010056 Article   Google Scholar   Karakuş, C. B., & Yıldız, S. (2019). Evaluation for irrigation water purposes of groundwater quality in the vicinity of Sivas city centre (Turkey) by using GIS and an irrigation water quality index. Irrigation and Drainage, 69, 121–137. https://doi.org/10.1002/ird.2386 Article   Google Scholar   Kawo, N. S., & Karuppannan, S. (2018). Groundwater quality assessment using water quality index and GIS technique in Modjo River Basin, central Ethiopia. Journal of African Earth Sciences, 147, 300–311. https://doi.org/10.1016/j.jafrearsci.2018.06.034 Article   ADS   CAS   Google Scholar   Khan, I., Umar, R., & Izhar, S. (2022). Hydrogeochemical and health risk assessment in and around a Ramsar-designated wetland, the Ganges River Basin, India: Implications for natural and human interactions. Environmental Monitoring and Assessment, 194, 483. https://doi.org/10.1007/s10661-022-10154-0 Article   PubMed   CAS   Google Scholar   Lesch, S., Suarez, D. (2009). Technical note: A short note on calculating the adjusted SAR index. Transactions of the ASABE. 52. https://doi.org/10.13031/2013.26842. Lu H., Ma X. (2020). Hybrid decision tree-based machine learning models for short-term water quality prediction. Chemosphere 249, https://doi.org/10.1016/j.chemosphere.2020.126169 Madhav, S., Ahamad, A., Kumar, A., Kushawaha, J., Singh, P., & Mishra, P. K. (2018). Geochemical assessment of groundwater quality for its suitability for drinking and irrigation purpose in rural areas of Sant Ravidas Nagar (Bhadohi), Uttar Pradesh. Geology, Ecology, and Land-Scapes, 2, 127–136. https://doi.org/10.1080/24749508.2018.1452485 Article   Google Scholar   Malek, N. H. A., Wan Yaacob, W. F., Md Nasir, S. A., & Shaadan, N. (2022). Prediction of water quality classification of the Kelantan River Basin, Malaysia, using machine learning techniques. Water, 2022(14), 1067. https://doi.org/10.3390/w14071067 Article   CAS   Google Scholar   Meireles, A. C. M., Andrade, E. M. D., Chaves, L. C. G., Frischkorn, H., & Crisostomo, L. A. (2010). A new proposal of the classification of irrigation water. Revista Ciência Agronômica, 41(3), 349–357. https://doi.org/10.1590/S1806-66902010000300005 Article   Google Scholar   Mnassri, S., El Amri, A., Nasri, N., & Majdoub, R. (2022). Estimation of irrigation water quality index in a semi-arid environment using data-driven approach. Water Supply, 22(5), 5161–5175. https://doi.org/10.2166/ws.2022.157 Article   CAS   Google Scholar   Mohammadpour, R., Shaharuddin, S., Chang, C. K., Zakaria, N. A., Ghani, A. A., & Chan, N. W. (2014). Prediction of water quality index in constructed wetlands using support vector machine. Environmental Science and Pollution Research, 22(8), 6208–6219. https://doi.org/10.1007/s11356-014-3806-7 Article   PubMed   Google Scholar   Nadiri A, Moazamnia M, Sadeghfam S, Gnanachandrasamy G, Senapathi V (2022). Formulating convolutional neural network for mapping total aquifer vulnerability to pollution. Environmental Pollution. 304. https://doi.org/10.1016/j.envpol.2022.119208 Ncibi, K., Chaar, H., Hadji, R., Baccari, N., Abdelaziz, S., Khelifi, F., Abbes, M., & Hamed, Y. (2020). A GIS-based statistical model for assessing groundwater susceptibility index in shallow aquifer in Central Tunisia (Sidi Bouzid basin). Arabian Journal of Geosciences, 13, 98. https://doi.org/10.1007/s12517-020-5112-7 Article   CAS   Google Scholar   OSS. (2003). Système aquifère du Sahara septentrional. Volume 2 : Hydrogéologie. Projet SASS. Rapport interne. Coupes. Planches. Annexes. Tunis, Tunisie. 275p, Observatoire du Sahara et du Sahel. Pandey, V., Chotaliya, B., Bist, N., Yadav, K., & Sircar, A. (2022). Geochemical analysis and quality assessment of geothermal water in Gujarat. Energy Geoscience. https://doi.org/10.1016/j.engeos.2022.08.001 Book   Google Scholar   Quinlan, J. R. (1990). Decision trees and decision-making. IEEE Transactions on Systems, Man, and Cybernetics, 20(2), 339–346. https://doi.org/10.1109/21.52545 Article   Google Scholar   Richards LA. (1954). Diagnosis and improvement of saline and alkali soils. USDA Agric Handbook 60. US Department of Agriculture, Washington. https://doi.org/10.2136/sssaj1954.03615995001800030032x. Siebert, S., Burke, J., Faures, J. M., Frenken, K., Hoogeveen, J., Döll, P., & Portmann, F. T. (2010). Groundwater use for irrigation—A global inventory. Hydrology and Earth System Sciences, 14(10), 1863–1880. https://doi.org/10.5194/hess-14-1863-2010 Article   ADS   Google Scholar   Vapnik V. (1998). The support vector method of function estimation. In: Suykens, J.A.K., Vandewalle, J. (eds) Nonlinear Modeling. Springer, Boston, MA. https://doi.org/10.1007/978-1-4615-5703-6_3. Wagh, V., Panaskar, D., Muley, A., Mukate, S., Lolage, Y., & Aamalawar, M. (2016). Prediction of groundwater suitability for irrigation using artificial neural network model: A case study of Nanded tehsil, Maharashtra. India. Modeling Earth Systems and Environment., 2, 10. https://doi.org/10.1007/s40808-016-0250-3 Article   Google Scholar   Wederni, K., Alaya, M., Missaoui, R., & Hamed, Y. (2023). Assessment of groundwater hydrogeochemical characteristics and salinization intrusion in coastal arid area (South Gabes, South-East Tunisia). Journal of African Earth Sciences, 200, 104875. https://doi.org/10.1016/j.jafrearsci.2023.104875 WHO. (2019). World Health statistics overview 2019: Monitoring health for the SDGs, Sustainable Development Goals. World Health Organization (WHO/DAD/2019.1). Licence: CC BY-NC-SA 3.0 IGO. Yahiaoui B., Agoubi B., Kharroubi A. (2021). Groundwater potential recharge areas delineation using groundwater potential recharge index (GPRI) within arid areas: Ghomrassen, south Tunisia. Arabian Journal of Geosciences. 14. https://doi.org/10.1007/s12517-021-07173-5. Zahedi, S. (2017). Modification of expected conflicts between drinking water quality index and irrigation water quality index in water quality ranking of shared extraction wells using multi criteria decision making techniques. Ecological Indicators., 83, 368–379. https://doi.org/10.1016/j.ecolind.2017.08.017 Article   Google Scholar   Zammouri, M., Jarraya-Horriche, F., Odo, B. O., et al. (2014). Assessment of the effect of a planned marina on groundwater quality in Enfida plain (Tunisia). Arabian Journal of Geosciences, 7, 1187–1203. https://doi.org/10.1007/s12517-012-0814-0 Article   CAS   Google Scholar   Download references Author information Authors and Affiliations Higher Institute of Water Sciences and Techniques of Gabes, Department of Water Sciences, University of Gabes, Gabes, Tunisia Boulbaba Haddaji, Mounir Atoui, Khyria Wederni, Belgacem Agoubi & Adel Karroubi Research Unit of Applied Hydro Sciences, University of Gabes, Gabes, Tunisia Boulbaba Haddaji, Mounir Atoui, Belgacem Agoubi & Adel Karroubi Laboratory of Water, Energy and Environment, National School of Engineers of Sfax, University of Sfax, Sfax, Tunisia Khyria Wederni Contributions All authors contributed to the study’s conception and design. The first draft of the manuscript was written by BH, and all authors commented on previous versions of the manuscript. Material preparation, data collection, and analysis were performed by BH, MA, and KW. All authors read and approved the final manuscript. Corresponding author Correspondence to Boulbaba Haddaji. Ethics declarations Ethical Approval Not applicable. Consent to Participate Not applicable. Consent for Publication Not applicable. Conflict of Interest The authors declare no competing interests. Additional information Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Rights and permissions Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law. Reprints and permissions About this article Cite this article Haddaji, B., Atoui, M., Wederni, K. et al. Geothermal Water Quality Index Assessment for Irrigation Purpose with Multicomputing Modeling Coupled with GIS: Case of El Hamma, Southeastern Tunisia. Water Air Soil Pollut 235, 160 (2024). https://doi.org/10.1007/s11270-024-06961-5 Download citation Received 18 November 2022 Accepted 04 February 2024 Published 15 February 2024 DOI https://doi.org/10.1007/s11270-024-06961-5 Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Keywords Irrigation Geothermal Water Quality Index CART SVM Shallow aquifer El Hamma Use our pre-submission checklist Avoid common mistakes on your manuscript. Sections Figures References Abstract Introduction Study Area Geological and Hydrogeological Settings Materials and Methods Results and Discussion Conclusion Data Availability References Author information Ethics declarations Additional information Rights and permissions About this article Advertisement Discover content Journals A-Z Books A-Z Publish with us Publish your research Open access publishing Products and services Our products Librarians Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility statement Terms and conditions Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"

Paper 8:
- APA Citation: Abdulhamid, A., Rahman, M. M., Kabir, S., & Ghafir, I. (2024). Enhancing Safety in IoT Systems: A Model-Based Assessment of a Smart Irrigation System Using Fault Tree Analysis. Electronics, 13(6), 1156. https://doi.org/10.3390/electronics13061156
  Main Objective: The main objective of this study is to enhance the safety in IoT systems by proposing a model-based assessment of a smart irrigation system using fault tree analysis.
  Study Location: Unspecified
  Data Sources: None
  Technologies Used: None
  Key Findings: None
  Extract 1: Redundancy: Implementing redundant components, such as duplicate sensors (e.g., soil moisture sensors, weather stations), controllers (e.g., PLCs, microcontrollers), and communication channels (e.g., cellular, satellite, LoRaWAN), to maintain system functionality during component failures
  Extract 2: By implementing redundant components, the system can continue to operate even if one of the components fails.
  Limitations: None.
  Relevance Evaluation: Highly relevant - The information explicitly addresses the point about redundancy and provides specific examples of how it can be implemented in an automated irrigation system, including duplicate sensors, controllers, and communication channels.
  Relevance Score: 0.9
  Inline Citation: (Alhassan Abdulhamid, 2024)
  Explanation: Redundancy is a common strategy for improving system reliability, as it ensures that if one component fails, there is a backup component that can take over and maintain functionality. In an automated irrigation system, this could involve using multiple sensors to monitor soil moisture levels or multiple controllers to manage water flow. By implementing redundant components, the system can continue to operate even if one of the components fails.

Implementing redundant components, such as duplicate sensors (e.g., soil moisture sensors, weather stations), controllers (e.g., PLCs, microcontrollers), and communication channels (e.g., cellular, satellite, LoRaWAN), can increase the system's resilience to component failures and maintain operational continuity during component failures.

 Full Text: >
"This website uses cookies We use cookies to personalise content and ads, to provide social media features and to analyse our traffic. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you’ve provided to them or that they’ve collected from your use of their services. Consent Selection Necessary Preferences Statistics Marketing Show details                 Deny Allow selection Allow all    Journals Topics Information Author Services Initiatives About Sign In / Sign Up Submit   Search for Articles: Electronics All Article Types Advanced   Journals Electronics Volume 13 Issue 6 10.3390/electronics13061156 Submit to this Journal Review for this Journal Propose a Special Issue Article Menu Academic Editor Lei Shu Subscribe SciFeed Recommended Articles Related Info Link More by Authors Links Article Views 522 Table of Contents Abstract Introduction Applications of IoT in Smart Agriculture Overview of Manual Failure Analysis Methods Model-Based Approach in Safety Analysis of IoT Proposed Safety Analysis Approach Illustrative Example Conclusions Author Contributions Funding Data Availability Statement Conflicts of Interest Appendix A. Data Associated with the Fault Tree of Figure References share Share announcement Help format_quote Cite question_answer Discuss in SciProfiles thumb_up Endorse textsms Comment first_page settings Order Article Reprints Open AccessArticle Enhancing Safety in IoT Systems: A Model-Based Assessment of a Smart Irrigation System Using Fault Tree Analysis by Alhassan Abdulhamid 1, Md Mokhlesur Rahman 2, Sohag Kabir 1,* and Ibrahim Ghafir 1 1 School of Computer Science, AI, and Electronics, University of Bradford, Bradford BD7 1DP, UK 2 Department of Computer Science and Engineering, Military Institute of Science and Technology, Dhaka 1216, Bangladesh * Author to whom correspondence should be addressed. Electronics 2024, 13(6), 1156; https://doi.org/10.3390/electronics13061156 Submission received: 22 February 2024 / Revised: 16 March 2024 / Accepted: 19 March 2024 / Published: 21 March 2024 (This article belongs to the Collection Electronics for Agriculture) Download keyboard_arrow_down     Browse Figures Versions Notes Abstract The agricultural industry has the potential to undergo a revolutionary transformation with the use of Internet of Things (IoT) technology. Crop monitoring can be improved, waste reduced, and efficiency increased. However, there are risks associated with system failures that can lead to significant losses and food insecurity. Therefore, a proactive approach is necessary to ensure the effective safety assessment of new IoT systems before deployment. It is crucial to identify potential causes of failure and their severity from the conceptual design phase of the IoT system within smart agricultural ecosystems. This will help prevent such risks and ensure the safety of the system. This study examines the failure behaviour of IoT-based Smart Irrigation Systems (SIS) to identify potential causes of failure. This study proposes a comprehensive Model-Based Safety Analysis (MBSA) framework to model the failure behaviour of SIS and generate analysable safety artefacts of the system using System Modelling Language (SysML). The MBSA approach provides meticulousness to the analysis, supports model reuse, and makes the development of a Fault Tree Analysis (FTA) model easier, thereby reducing the inherent limitations of informal system analysis. The FTA model identifies component failures and their propagation, providing a detailed understanding of how individual component failures can lead to the overall failure of the SIS. This study offers valuable insights into the interconnectedness of various component failures by evaluating the SIS failure behaviour through the FTA model. This study generates multiple minimal cut sets, which provide actionable insights into designing dependable IoT-based SIS. This analysis identifies potential weak points in the design and provides a foundation for safety risk mitigation strategies. This study emphasises the significance of a systematic and model-driven approach to improving the dependability of IoT systems in agriculture, ensuring sustainable and safe implementation. Keywords: Internet of Things; smart agriculture; failure analysis; fault trees; model-based safety analysis; SysML 1. Introduction Agriculture plays a crucial role in providing sustenance and employment opportunities to millions of people around the world. As the global population continues to grow exponentially, there is an increasing demand for food production. Unfortunately, the amount of cultivable land is limited and is rapidly dwindling due to urbanisation and environmental degradation [1,2]. Therefore, there is a pressing need to improve crop yields to meet the growing demand for food. Modern farming techniques can optimise every aspect of the crop production process, from planting to harvesting. Precision agriculture, Solar Insecticidal Lamp Internet of Things (SIL-IoTs), and many other innovative ideas leverage technology to achieve this optimisation [3,4,5]. By prioritising sustainable and efficient farming practices, it is possible to ensure that agriculture remains a viable source of sustenance and employment for generations to come. Through efficient implementation of these smart techniques, farmers can increase their yield and improve the efficiency of their operations. The escalating worldwide water crisis is a significant worry, given the rising population and the need for fresh water. To tackle this problem, embracing sustainable water usage practices is imperative, particularly in agriculture, where water is a crucial resource. A viable solution is the adoption of Smart Irrigation Systems (SIS), which can track pertinent factors and regulate physical devices like water pumps to minimise water wastage by irrigating only when required [6,7]. Furthermore, sustainable farming practices can enhance soil health, reduce greenhouse gas emissions, and promote biodiversity [3]. Such approaches can also improve the overall quality of the produce and increase the economic sustainability of farming operations. The integration of IoT, edge computing, and AI has transformed the landscape of farming practices [8]. However, with these innovative approaches come new challenges, such as increased complexity, system safety, reliability, trustworthiness, and vulnerability [9,10]. To ensure the dependability of these systems, it is essential to understand their composition and inner workings and potential failures that may arise during operation. This proactive understanding of the system and its behaviour will help to mitigate risks from the design time and optimise the efficiency of such systems. In the case of large-scale smart farming, the failure of these systems can have devastating consequences on nature, people, agricultural production, and finances. Therefore, conducting a credible failure analysis of IoT-based technology during the conceptual design phase is crucial to ensure the development of safe and reliable IoT-based agricultural systems. While in this study we focus on the qualitative failure analysis of the IoT system, a recent overview of physical security and safety issues in IoT can be found in [11]. Failure analysis methods are indispensable in safety-critical domains, encompassing diverse sectors like aviation, automobiles, and industrial control systems [12]. Among these methods, Fault Tree Analysis (FTA) stands out as a widely acknowledged and highly effective technique for analysing failures in safety-critical systems [13]. By employing graphical models, FTA provides a systematic representation of the logical connections between failures and their root causes, offering valuable insights into potential vulnerabilities and areas for improvement in complex systems. The structured and methodical FTA method is an effective approach for identifying potential system failures, assessing risks, and developing strategies to prevent them during system design [13,14,15]. This approach is particularly useful in examining failures across a range of systems, including smart agriculture [13,14,15,16,17,18]. By utilising a visual and deductive approach, the FTA method identifies potential safety risks, predictive failure of the system, critical failure scenarios, and the shortest path to system failure [17,18]. The FTA process involves understanding system functions and components, identifying possible failure modes, determining the root cause of failures, and proposing corrective actions to address them [19]. The FTA method remains a well-established approach for assessing the safety and reliability of agricultural systems, contributing to improved performance and enhanced productivity. Therefore, incorporating the FTA method into the iterative design process of smart agricultural systems ensures that safety considerations evolve with the system design, promoting ongoing improvement and cultivating a proactive risk management culture within the agricultural industry. Despite the wide adoption of the FTA model as a safety analysis method, the reliance on FT has some inherent limitations, such as being a manual process, not supporting reusability, being prone to human errors, and becoming cumbersome when the failure behaviour becomes complicated [13,20]. Model-driven approaches are being adopted from the functional system design domain to the safety analysis environment to overcome these challenges and keep up with the latest advancements in the overall system design approach. In the model-driven environment, the Model-Based Systems Engineering (MBSE) approach is rich with various system models and diagrams, which can effectively model system architecture, and through their extension, model failure behaviour that can be viable for Model-Based Safety Analysis (MBSA) [21]. Recent studies in the safety analysis domain are now proposing the utilisation of MBSA approaches for the generation of the FTA process to simplify design trade-offs, increase IoT design flexibility, and reduce cost and time-to-market constraints [22,23,24,25,26,27,28,29,30,31]. This study utilises the use of the MBSA paradigm to create an FTA model of an IoT-based SIS in a SysML environment for a viable safety assessment. It is worth noting that although IoT-based agricultural systems are gaining more trust from the public, the MBSA approach of safety analysis is not being used as much in the intelligent agricultural domain as it is in other safety-critical domains. However, the failure of monitoring systems in agriculture can have a significant impact on food security and result in enormous financial loss. This article presents a novel MBSA approach for safety analysis of an IoT-based SIS. The framework leverages IoT-based SIS and focuses on the conceptual design phase to identify potential failure behaviours of the system. It generates detailed failure models for the system and its components, formalising them through MBSA-generated FTA diagrams. The method’s granular flexibility enables a better understanding of how individual component failures can cause system-wide safety problems, thereby improving system dependability and failure risk mitigation. The framework’s efficacy is demonstrated through a case study of IoT-based SIS. This approach represents a significant step towards proactive and comprehensive failure analysis in innovative agricultural ecosystems, aligning technological advancements with the goal of system analysis approaches. The article is divided into sections to provide a comprehensive overview of the IoT’s role in smart agriculture. It begins with an introduction and then moves on to Section 2, which provides a comprehensive overview of IoT’s role in smart agriculture. This is followed by a review of manual safety analysis methods in Section 3, and MBSA methods are covered in Section 4. Furthermore, Section 5 then describes the proposed framework in detail and demonstrates its application in a case study, which can be found in Section 6. This article concludes with Section 7, summarising the key points discussed and suggesting potential areas for future research. 2. Applications of IoT in Smart Agriculture This section provides a detailed overview of how IoT technology is leveraged to promote sustainable and intelligent farming practices. From monitoring soil moisture levels to tracking livestock, the IoT has revolutionised how agriculture is managed and optimised for greater productivity and efficiency. 2.1. Smart Irrigation System Freshwater scarcity is a critical global challenge that we must address, as only 2.5 % of Earth’s water supply is freshwater, with a mere 31.3 % available for human use, with the rest being in the form of glaciers or ice caps [32,33]. Agriculture consumes a vast amount of this resource, and as the demand for food increases, it is essential to manage water resources efficiently [34]. IoT technology offers a promising solution. By combining sensor networks, smart tech, and the Internet, we can measure critical parameters like soil moisture and temperature to enable real-time data analysis for accurate irrigation control [35]. With the integration of microcontrollers and wireless communication, IoT tech can facilitate the development of automated irrigation systems that conserve up to 90 % of water compared with traditional methods [36]. Several studies have proposed the use of an integrated sensor/actuator node network to measure various physical parameters such as soil moisture, air temperature, humidity, water level, water flow, and luminous intensity [37,38]. Leveraging smart Internet-based technology can help optimise water usage and improve crop yield, contributing to long-term resource sustainability. By incorporating IoT tech in agriculture, a comprehensive solution to freshwater scarcity can be provided, leading to better water conservation and benefiting farmers, consumers, and the environment. 2.2. Pest Control and Plant Disease Monitoring The agricultural industry has experienced significant changes due to the IoT, particularly in pest control and plant disease monitoring [39]. Farmers can now utilise advanced deep learning methods to identify pests, diseases, weeds, and yield and assess soil suitability for different crops. With the help of image processing, machine learning, and Logistic Decision Regression (LDR), researchers have achieved impressive accuracy rates in detecting pests and plant diseases, leading to better crop management practices and improved yields [39,40,41]. Smart agriculture has been introduced which utilises an IoT architecture that employs deep learning techniques to detect insects, diseases, weeds, and soil nutrients and predict crop yield with greater accuracy. This has revolutionised the industry, as sensor data have improved the accuracy and reliability of disease detection through innovative data analysis methods. Recently, there has been a surge of interest in using convolutional neural networks (CNNs) for image analysis, which have the potential to further enhance the accuracy and speed of disease detection. CNNs effectively identify plant diseases, pests, and nutrient deficiencies and predict crop yield [42,43]. Integrating IoT with advanced deep learning methods has transformed the agricultural industry, paving the way for innovative solutions to old problems. More farmers are expected to embrace this technology in the coming years, leading to increased productivity and better crop management practices. 2.3. Use of Drones and Harvesting Robots The agricultural industry has significantly transformed since the introduction of drones and IoT devices. These advanced technologies have revolutionised traditional cultivation methods by reducing physical strain and streamlining the process [44]. The introduction of intelligent agricultural systems has paved the way for implementing innovative methods to monitor soil conditions, spray pesticides and fertilisers, and transmit sensor data for analysis [45]. Drones have emerged as one of the most promising tools in agriculture. With high-resolution cameras, they can capture images of crops from an aerial view, providing farmers with an accurate measurement of crop damage caused by pests or weather, especially in challenging terrain [46]. They can also monitor crop growth and identify areas that require fertilisation or irrigation. In addition to drones, agricultural robots integrated with IoT devices and sensors are used for various tasks such as seedling, harvesting, weed detection, and pest control. These robots are designed to operate autonomously and can be programmed to perform specific tasks with precision and accuracy. Moreover, they can collect and transmit data in real time, enabling farmers to make informed decisions and take corrective actions quickly. Developed nations are adopting these technologies to enhance agricultural efficiency while minimising costs and time [47,48]. Implementing IoT devices and drones in agriculture can potentially increase crop yields, reduce labour costs, and minimise the use of harmful chemicals [49]. Therefore, integrating these advanced technologies in the agricultural industry is a significant step towards creating a sustainable future for the world. 2.4. Vertical Farming and Smart Greenhouse Vertical Farming (VF) has emerged as a modern agricultural technique wherein crops are grown on vertically inclined surfaces, predominantly in high-rise buildings. This innovative practice has gained immense popularity in recent years, owing to its ability to offer several advantages beyond food security. As per Kalantari et al. [50], VF has the potential to revamp urban design and architecture, augment food safety and security, and reduce environmental pollution. With the rapid advancement of digital technologies, IoT devices, artificial intelligence, and other cutting-edge technologies are increasingly being incorporated into VF. According to Siregar et al. [51], IoT devices and AI are being employed to monitor and control VF environments, and researchers such as those found in [52,53,54] have proposed methodologies that integrate sensors and IoT techniques for smart VF. Additionally, Kaur et al. [55,56] demonstrated how hydroponic VF could be carried out using IoT-based sensors with minimal water and soil usage. By harnessing these innovative ideas, VF has the potential to enhance crop yields while minimising resource usage, making it an attractive option for sustainable agriculture. Apart from IoT and machine learning, studies also explore using artificial intelligence to build smart greenhouses. For instance, Maraveas and Chrysanthos [57] conducted a detailed review of AI’s use in building smart greenhouses and explored methods to optimise their usability. Also, Gracia et al. [58] reviewed the usage of Artificial Neural Networks (ANNs) in greenhouse technology and proposed models to integrate IoT devices and ML for innovative agriculture development. Therefore, integrating cutting-edge technologies like IoT and AI in VF has immense potential to transform crop growth, enhance food security, and reduce environmental impact. 2.5. Tracking and Monitoring Livestock Precision Livestock Farming (PLF) is a modern approach that utilises IoT technologies to provide farmers with advanced tools for monitoring cattle behaviour, diagnosing diseases, managing their welfare, and improving overall management [59,60]. In recent years, significant progress has been made in developing web and mobile applications that use sensors and IoT devices to monitor livestock behaviour and environmental factors. Researchers have identified key technologies that have proven effective in PLF, including Radio Frequency Identification (RFID), Global Positioning Satellite (GPS), Digital Twin technology, and AI [60,61]. These technologies have improved data collection and analysis efficiency, enabling farmers to make informed decisions about their livestock. Furthermore, researchers have proposed efficient methods for monitoring cattle behaviour and environmental factors using indoor Ultra-WideBand (UWB) location data, accelerometer data, and automatic monitoring systems based on sensors. These methods allow farmers to monitor their cattle more accurately and in real time, improving the overall health and well-being of the animals. Additionally, smart geofencing methods that rely on IoT and General Packet Radio Service (GPRS) have been suggested for remote monitoring and controlling cattle, making it easier for farmers to monitor their livestock from a distance [61]. Other methods for herd location monitoring using Bluetooth and GPS have also been proposed, making it easier for farmers to track the location of their animals and ensure their safety and security. IoT technologies in PLF have transformed the livestock industry, allowing farmers to leverage advanced tools and technologies to manage their livestock more efficiently and effectively [62]. With continued advancements in this field, we can expect to see even more innovative solutions that will further improve the quality of life for livestock and enhance sustainability. 2.6. Effects of Sensor-Based IoT Device Failures in Smart Agriculture As the demand for sustainable and efficient agricultural production grows, farmers are increasingly adopting smart farming practices that rely on IoT technology. However, these practices come with risks. If the sensor-based IoT devices used in agriculture fail, it can have severe consequences for the entire system. The impact can range from environmental pollution to decreased crop yields or even famine. In the long run, these hazards can also damage soil health and fertility, crop disease control, supply chain management, and farmers’ trust in IoT technology. These risks can lead to economic collapse in rural areas, affecting farmers and related industries. Therefore, it is crucial to develop strategies to mitigate the risks associated with sensor-based IoT device failure in agriculture, particularly given that harsh weather conditions can make these devices prone to failure. 3. Overview of Manual Failure Analysis Methods Failure analysis is a systematic approach to investigate and comprehend the underlying causes of failures in various systems, products, or processes [26]. The primary objective of failure analysis is to prevent similar failures from happening in the future [12]. Failure analysis is extensively employed to analyse potential safety-related issues in domains where safety is critical. It is crucial to perform appropriate failure analysis on the conceptual design of IoT-based agricultural systems to ensure the design is safe and dependable [63]. Safety and reliability analysis are the two most significant dependability attributes, and they are used extensively in many safety-critical sectors. Below is a discussion of some of the well-known failure analysis methods. 3.1. Failure Mode and Effects Analysis Failure Mode and Effects Analysis (FMEA) is a proactive approach in safety-critical domains. It identifies and evaluates the potential failure modes of a system, assessing their impact on safety, reliability, and performance [14,64]. FMEAs are often attributed to the US military, who first utilised this technique in the late 1940s to mitigate potential failures and minimise sources of variation during munitions production [20,65]. Notably, FMEA is also used for failure analysis of smart agriculture [66]. Using FMEA, critical components and functions are identified, and failure modes are evaluated based on their severity, probability of occurrence, and detectability [67,68]. The Risk Priority Number (RPN) is calculated for each failure mode, and necessary mitigation strategies are adopted. High-RPN failure modes are prioritised through improved design, redundancy, maintenance, or additional safety measures [67]. 3.2. Bayesian Network A Bayesian Network (BN) is a sophisticated probabilistic model that is extensively utilised in various engineering domains, particularly in testing and verifying the safety properties of IoT systems. Employing a BN model aids in recognising and reducing risks by representing interdependencies and uncertainties [65]. The safety problem is defined, relevant components are identified, and probabilistic dependencies are established to achieve the utilisation of the BN model in the safety analysis. Numerical values are then assigned to calculate the probability of specific events occurring. Each variable is represented as a node, and the directed edges between nodes indicate the probabilistic dependencies between the variables [65,69,70]. The Conditional Probability Tables (CPTs) specify the probabilistic relationships for each node based on the values of its parent nodes. The Bayesian Network supports both qualitative and quantitative analysis. Qualitative analysis involves graphical representation, while quantitative analysis involves assigning numerical values to the parameters in the BN, such as conditional probabilities in CPTs, to calculate the probability of a specific event occurring or estimate the likelihood of different events [18,71]. 3.3. Markov Analysis Model The Markov model is a mathematical framework used to study systems that change over time through a sequence of discrete states. It is beneficial for analysing systems with memoryless properties [72]. These are systems where the future state depends only on the current state and not on the sequence of states that came before it. The model assumes that a system exists in one of several discrete states at any given time and can move to another state with specific probabilities [73]. A state transition matrix that captures these transition probabilities defines the system’s behaviour. Markov models are often used to analyse the behaviour of systems based on the exponential distribution of failure. The steady-state probabilities of the model can be calculated by solving the system of linear equations defined by the model [73]. 3.4. Petri Net A Petri Net is an essential graphical and mathematical modelling approach for analysing and describing intricate, concurrent, and distributed systems. It is a highly effective method for modelling and understanding systems in which multiple entities interact asynchronously and dynamically [65]. Typically, PNs are denoted as four-tuple N = (P, T, A, K), a bipartite graph that we discuss in detail below: 𝑃={ 𝑝 1 , 𝑝 2 , 𝑝 3 ,…, 𝑝 𝑛 } is a finite set of places: Places represent states or conditions within the system. They are typically depicted as circles or ovals in a PN diagram. 𝑇={ 𝑡 1 , 𝑡 2 , 𝑡 3 ,…, 𝑡 𝑛 } is a finite set of transitions: Transitions represent events or actions that can occur within the system. These are typically depicted as rectangles in the diagram. Transitions cause changes in the system’s state by consuming tokens from input places and producing tokens in output places. 𝐴⊆(𝑃×𝑇)∪(𝑇×𝑃) is a finite set of arcs: Arcs (also known as edges) connect from places to transitions or transitions to places, indicating the flow of tokens between them. There are two types of arcs: Input Arcs and Output Arcs. 𝐾={1,2,3,…} is a finite set of tokens: Tokens are small symbols or markers. Each place can hold a certain number of tokens, representing the presence or availability of resources, objects, or entities. They can move between places through transitions, following the defined flow of arcs. The PN model follows basic rules for activating transitions based on the availability of input tokens. The behaviour of PNs is determined by the movement of tokens and interaction between transitions. Coloured, timed, and stochastic PNs are variations of PNs that address specific aspects of system modelling and analysis [65,74,75]. An example of a simple PN is shown in Figure 1. Figure 1. Example of a Petri Net model. 3.5. Fault Tree Analysis The FTA method is a systematic graphical methodology widely used in engineering, safety, and risk assessment to thoroughly analyse the causes of failures within complex systems. It originated in 1962 at Bell Phone Laboratories and was initially crafted to evaluate the failure behaviours of the launch control system of the LGM-30 Minuteman intercontinental ballistic missile (ICBM) as part of the United States’ strategic deterrent forces [20,76]. Over the years, FTA has evolved into a pivotal tool for failure analysis, finding applications in diverse domains, including industrial safety-critical systems, and gaining momentum in IoT-based applications. FTA’s versatility is evident across various applications, spanning safety analysis in smart homes [77,78] to generic IoT systems [79,80], electric vehicles [81], industrial fire detection and prevention systems [82], industrial robots [17], self-healing industrial systems [83], and cyberphysical systems [15]. Additionally, FTA has successfully analysed the failure behaviour of smart agriculture systems [76,84], showcasing its adaptability across diverse domains. The FTA technique systematically identifies factors contributing to system failures and assesses the probability of such failures, solidifying its position as one of the most prominent techniques for dependability analysis. Recognising its significance, the International Electrotechnical Commission (IEC) has endorsed FTA as a leading method for failure analysis [13,85,86]. In Figure 2, the FTA model employs a logical and graphical diagram to pinpoint critical components for improvement, preventing future failures. The diagram outlines the hierarchy of events and utilises logic gates such as AND, OR, and Voting gates to model different systems’ behaviour. In an AND gate, all child events must occur for the parent event, whereas in an OR gate, any single child event can activate the parent event. The Voting gate requires a specific number of events (e.g., 2 out of 3), as the diagram indicates. The green triangle symbol facilitates the breakdown of the tree into smaller components for more accessible representation. Figure 2. Example of a fault tree. The fault tree is constructed using a top-down approach, starting with a top event causing the overall system failure. This top event is then decomposed into intermediate events using logic gates, representing the immediate causes of the top event. The recursive breakdown continues until the analysis reaches the component level failure or root causes that cannot be further decomposed. The ultimate goal is to assess how the top event will occur in the tree, representing the system failure. The analysis can be conducted qualitatively and quantitatively. Qualitative analysis involves obtaining Minimal Cut Sets (MCSs), the smallest combinations of root causes or basic events (BEs) leading to system failure. Identifying MCSs helps understand critical combinations of component failures or events. On the other hand, quantitative analysis uses failure rates of components or probabilities of root causes to predict system failure. Considering the type of logic gates used between events, the system failure probability can be calculated [12,20]. While FTA possesses strengths shown in Table 1, such as providing a structured approach for failure analysis, there are also acknowledged weaknesses [12,20]. These include the potential for human error in tree creation, a cumbersome process, lack of support for reusability, and inherent limitations of manual-based system analysis methods. Table 1. Strengths of Fault Tree Analysis Approach. 4. Model-Based Approach in Safety Analysis of IoT Several approaches in MBSA have been developed to model both functional and nonfunctional properties of modern and embedded systems, including those in the IoT environment. These modern and formal methods utilise modelling languages that draw from general engineering models or domain-specific models and profiles. In contrast to manual safety analysis techniques used with informal models discussed in Section 3, MBSA approaches have been developed to automate and semiautomate the process. These computer-based approaches facilitate safety analysis and support various aspects of system design. MBSA approaches can generate compositional analysable safety artefacts based on systematic modelling of systems’ static, dynamic, and failure behavioural patterns using existing modelling languages and their extensibility mechanisms. The MBSA approaches are model-driven and can manage system complexity while performing coherent, formalised, structured, and rigorous system safety analysis. Safety analysis approaches have been developed using various modelling languages, including Unified Modelling Language (UML), SysML, and Architecture Analysis and Design Language (AADL) as well as Hierarchically Performed Hazard Origin and Propagation Studies (HiP-HOPS) [20,31,87,88]. Additionally, these models are unambiguous, based on standardisation and various automation support tools, and possess a high level of abstraction to model the heterogeneity of IoT-based systems. The proposed approach used in this study is based on the UML/SysML modelling approach. 4.1. The Unified Modelling Language UML is a powerful modelling language that enables one to systematically visualise a system using modelling diagrams and conduct a formal analysis. It is widely used for systems and software specifications and can be customised to suit specific domains. With numerous diagrams and extensions, UML can effectively describe a system’s components, hierarchy, and states. UML diagrams are grouped into two categories: behaviour and structure [30]. Behaviour diagrams capture the system’s dynamic behaviour, while structure diagrams describe the system’s static structure. Some popular UML diagrams include activity, state machine, sequencing, timing, use case, class, and component diagrams. UML is a reliable tool for high-quality modelling of safety-critical systems and has been adopted as a standard by the Object Management Group [29]. 4.2. System Modelling Language The SysML is a general-purpose graphical modelling language that was developed in 2003 on top of the UML specifically for system development, such as software, hardware interactions, and dependencies, among others [22,28]. The SysML is similar to UML; however, some diagrams in UML were removed, and others more specific to system engineering design were added. Two groups of SysML diagrams can be used to describe a system: behaviour and structure. The behaviour diagram showcases how the system operates, while the structure diagram highlights the system’s static structure. Popular SysML diagrams that are widely used include the block definition diagram (BDD), internal block diagram (IBD), parametric, and state machine diagram (SMD) [27]. A Broad List of SysML diagrams that can be used for various modelling of system features is shown in Figure 3, and a high-level description of the diagrams is provided in Table 2. Figure 3. SysML Diagrams. Table 2. Overview of some of the Notable UML/SysML Diagrams. The uniqueness of both UML and SysML is their extension mechanisms, which are known as profiles. A UML/SysML profile defines an extension of the language in terms of stereotypes (concepts in the target domain) and tagged values (the attributes of the stereotypes). For instance, the UML profile for Modelling and Analysis of Real-Time and Embedded Systems (MARTE) provides an analysis framework called the Quantitative Analysis Model (GQAM), enabling performance specification in UML models. The Dependability Analysis Modelling (DAM) is a domain-specific profile of SysML designed to address safety concerns such as safety metrics, transitions from safe to failure states, and triggers leading to those transitions. In a safety analysis based on MBSA approaches, the static structure of the system and its components are annotated with failure behaviours, and the resulting models are transformed to develop system-level failure analysis models [26]. Studies have been conducted using SysML/UML to develop FT and FMEA [28,89,90,91,92]. Various methodologies have been used for FTA generation, such as transforming the MBSA design developed in SysML using IBD and SMD to FTA artefacts based on a failure mapping pattern [25]. Other approaches have used programming languages to parse the XML model file generated from the source model and automate a formal model. Notably, the XML file of the source model was parsed in the Python language to safety analysis artefacts [93], ATLAS Transformation Language (ATL) [24], and Eclipse Modelling Framework [23]. The MBSA offers several advantages, including a composition that enables an easy understanding of the effects of altering one or more components or subsystems on the entire system’s safety assurance. Additionally, it supports reusability, reduces human errors, and facilitates iterative system design. 5. Proposed Safety Analysis Approach The approach proposed in Figure 4 uses the MBSE method, which combines the benefits of MBSA and safety analysis models. This technique preserves the advantages of MBSA over other static FTA methods while establishing the link between the IoT system architecture and the analysis models. Figure 4. Proposed MBSA framework. The MBSA framework described in Figure 4 for modelling of an IoT-based SIS involves a systematic process, utilising SysML diagrams and software tools compatible with SysML for precise modelling of the IoT system. The open-source SysML-compatible tool Papyrus was employed to initiate the analysis, seamlessly integrating with other Eclipse-based tools. This tool creates models that accurately represent the system’s static, functional aspects, and failure behaviours. The first step in our proposed approach involves creating diagrams that capture the static architecture, functional behaviour, and potential failure scenarios of the system in the SysML environment using Papyrus–Eclipse-based open-source software (Website for Papyrus tool: https://eclipse.dev/papyrus/). This includes creating SysML diagrams such as BDD, IBD, and SMD to build a comprehensive model of the IoT system’s architecture, functional structure, and failure characteristics. The created diagrams are then combined using a specific methodology, which we define in the subsequent section, to create the FTA from the models. Notably, the failure behaviours of each component are annotated using a DAM profile, transforming the source model into a formal analysable model for safety analyses. The DAM profile defines stereotypes, tagged values, and constraints, which are applied to the SysML SMD model to accurately articulate the system’s failure behaviour. Once the DAM profile is imported, aligned with the SMD diagram, and configured with DAM stereotypes, the Papyrus software tool facilitates a seamless transition, bridging static and functional modelling for fault tree generation. The fault tree logic is specified to generate the fault tree automatically, providing the necessary input for the tool. To ensure a high level of consistency and accuracy in our methodology, we heavily depend on Papyrus’s robust support for SysML and the DAM profile throughout our process. Alongside Papyrus, we incorporate other software tools, such as Drawio (Drawio tool website: https://app.diagrams.net/), to streamline the transition from SysML modelling to fault tree generation. Our overarching approach adheres to the MBSA framework, supports iterative system development, provides a systematic and structured method for constructing an FTA and conducts a qualitative safety analysis of the IoT-based SIS. In the subsequent section, we delve into the intricacies of this process, providing a comprehensive understanding of our methodology. 5.1. Static System Modelling To create the system’s static architecture model, we utilised BDD to represent the system’s different compositions and hierarchical structures. We divided the system into components using predefined blocks that logically indicate the system’s hardware and software. Additionally, we defined relationships among the components and the overall system regarding dependencies, generalisations, associations, aggregation, and inheritance. 5.2. Functional Configuration Modelling To develop the failure behaviour of an IoT system, it is crucial to have a comprehensive understanding of its internal structure. One way to achieve this is by creating an IBD representing the system’s properties and interconnections. This visualises the system’s decomposition, facilitating an understanding of how information flows between its elements. The IBD depicts the system’s internal configuration using its components, ports, and data flows. The IBD illustrates how a malfunction can propagate throughout the system by combining connectivity and flow. A well-defined internal structure and an understanding of its behaviour are fundamental to ensuring system safety and reliability. By providing a visual representation of the system’s properties, interconnections, and internal configuration in an MBSA environment, these diagrams facilitate an understanding of the system’s behaviour, identifying potential malfunctions and designing measures to mitigate them. 5.3. Failure Annotation To effectively model the failure behaviour of a system, it is essential to understand its functional features and the nominal state of each component. This involves analysing the system’s overall function, any redundancy designed into the system, and the behavioural characteristics of individual components. It is necessary to depict how the system elements can fail, how they change from one state to another, and the conditions that cause these changes. SMDs display the different states of the components and how their state can change. Using the system’s decomposed BDD, various nominal and failure states of the system are developed, along with their corresponding transitions and triggers, as SMDs. However, more than SMDs are needed to provide all the necessary information to model the failure features of an IoT system. To address this, the SMD was extended through the use of the DAM Profile, a UML extension mechanism that models the metamodel of the system. The DAM Profile is particularly effective for failure modelling through its stereotypes, such as DaStep, which represents the failure and error states of the system. The tag value under DaStep represents the transitions and triggers of the components. Using the DAM Profile, unique stereotypes and tag values can be applied to annotate the failure of system components accurately. The Data-Intensive Computing Environment (DICE)-integrated simulation environment was employed to achieve this goal. 5.4. Component Fault Tree Generation In the paradigm of MBSA, it is possible to convert a source MBSA model into a target safety artefact by creating links between the two. The ultimate goal is to produce an executable model to analyse the system’s safety. To achieve this, it is essential to have a comprehensive understanding of both the source and target languages. Our approach involves transforming SysML SMDs into component-based models that can be analysed to determine the contribution of each component to the overall system failure. This approach simplifies the iterative design process by enabling the replacement of components with a higher failure rate and more resilience. The resulting component-based model is generated via failure modelling, identifying potential failures and enhancing overall system safety. To create a component-level fault tree (CFT), each system component failure represented as SMDs is mapped to obtain the corresponding component tree, generating several trees that can be studied to detect possible failures. 5.5. System Fault Tree Generation The system-level FT is a target model designed to conduct a comprehensive system failure analysis. It combines individual FTA models of system components to create a single, unified tree structure using the system’s IBD. The IBD instances are utilised to merge the various CFTs. This allows the model to represent the relationship between components based on their configuration in the IBD. Static gates are employed to illustrate the configuration of the components better. For instance, an OR gate indicates series configurations where the system fails if any components fail. On the other hand, an AND gate is utilised for parallel configurations where the system only fails if all components fail. This level of detail allows the model to predict potential failures and their causes more accurately. At the top of the tree, the undesired event represents the overall failure of the system. Prior to that, the previous top-level undesired events in each component FTs are intermediate events. This detailed approach allows for a more thorough understanding of the system’s potential points of failure and can help identify areas for improvement and optimisation. 6. Illustrative Example To demonstrate our proposed MBSA approach, we used the IoT-based Smart Irrigation System presented in Figure 5. Using this system, a farmer can remotely monitor the status of a field and control the water pump(s) to irrigate the field whenever needed without being physically present in the field. In normal operating conditions, this system will monitor different parameters of a field, and based on the monitoring knowledge, it will decide when and for how long to irrigate the field. It uses a temperature sensor (TS) and a moisture sensor (MS) for monitoring. TS monitors the temperature of the field, and MS monitors the soil moisture. TS and MS continuously sense the respective parameters and report them to the IoT gateway/controller for further processing. The communication between the sensors and the IoT gateway takes place via a wireless medium. An Arduino board or Raspberry Pi can be considered as an IoT gateway. A battery powers the board. The IoT gateway converts the analogue signals received from the sensors to digital values and sends these values to the edge cloud server. The communication between the edge cloud server and the gateway occurs through a wireless medium. Figure 5. Architecture of an IoT-based Smart Irrigation System. 6.1. Static System Modelling To create a formal system composition using the MBSA approach, it is crucial to have static configuration modelling. The system’s functional components and dependencies are depicted in the BDD shown in Figure 6, with SIS as the context. Direct composition relationships and SysML relationship link symbols were utilised to represent composite blocks in the system. Figure 6. Block definition diagram model of an IoT-based Smart Irrigation System. 6.2. Internal Configuration System Modelling The IBD Model of the system is crucial for effectively utilising MBSA modelling in system architecture. The SysML IBD depicts the system’s context and intricate, interdependent relationships among its components, accurately portraying data flow through ports and item flow symbols. The context blocks in SIS accurately represent interactions between different components as depicted in Figure 7. Figure 7. Internal block diagram model of an IoT-based Smart Irrigation System. 6.3. Failure Annotation Modelling of the System In the provided Figure 8a,b, the failure annotations of two system components, namely the temperature sensor and power source, are displayed based on the SysML SMD. The metamodel was extended using the DAM Profile. In the SysML extension mechanism, DAM Stereotypes DaStep extends the SysML parent model to represent the state of failure and error in the system. The tag value under DaStep describes the transitions and triggers of the components. The nominal and failure states of the components are shown, where the failure states are represented by no output from the temperature sensor and power source failure. DAM stereotypes represent the transitions and triggers of the components to illustrate the failure and error states. The extended SMDs include failure to capture sensor readings, false sensor readings, and loss of control. The transition link indicates the triggers responsible for the state change, and various triggers are defined for other system components. Figure 8. Example of failure annotation, (a) failure annotation of a temperature sensor and (b) failure annotation of a power source. 6.4. Model Transformation from MBSE Model to FT 6.4.1. Component Fault Tree Generation To create the corresponding CFT, each system component’s one-to-one SMDs are mapped. In the CFT, the component’s overall failure is TE, while the IEs represent various functional states’ failure or error deviation. BE represents their triggers. To illustrate, the SMDs created in Figure 8a,b are mapped to their respective CFTs, as shown in Figure 9. Figure 9. Mapping of component state machine diagram to component fault tree for (a) a temperature sensor and (b) a power source. 6.4.2. System Fault Tree Generation The different components’ fault trees generated are mapped based on the instances of the components in the system’s IBD. Accordingly, the overall system FT of SIS obtained is presented in Figure 10. The TE denotes the system failure condition, which is “the failure of the system to irrigate the field when needed”. The list of BEs and IEs and their description representing various basic device failures or communication failures between devices is provided in Table A1 in Appendix A. Figure 10. Fault tree generated for IoT-enabled SIS. 6.5. Qualitative Failure Analysis of the System Depending on the role(s) of a component in the system and its interactions with other components in the system, the failure of the component can have an enormous impact on the failure of the system. Therefore, this system’s qualitative failure behaviour analysis aims to identify its potential causes. For failure behaviour analysis, we identified “the failure of the system to irrigate the field when needed” as a system failure condition. Considering this event as the top event of the fault tree, we developed the fault tree shown in Figure 10. This FT contains 19 unique basic events and the root causes that can contribute to the system failure. These root causes are either an internal failure of the devices or the failure of the communication between devices. As seen in Figure 10, physical damage to the sensors or erroneous readings from the sensors is considered as the failure of the TS and MS, which are represented by the events TSF (temperature sensor failure) and MSF (moisture sensor failure). In the fault tree, five basic events—FCRG, FCGC, FCFC, FCTG, and FCMG—represent communication failures between system components. Note that, due to simplicity and brevity, we considered these communication failure-related events at an abstract level. This means we do not decompose these events further to show why a particular communication failure occurs. However, one can explore these events further by considering all the causes of a typical wireless communication failure. Similarly, the failure of the edge cloud is presented by the event ICS (internal failure of the edge cloud server) due to simplicity. Again, this event can be decomposed further by considering many potential causes of a cloud server failure, including hardware and software failures. We analysed the fault tree in Figure 10 to identify the MCSs and obtained 94 MCSs; each of these MCSs can cause the system to fail. Out of these 94 MCSs, 71 MCSs are of order 2 and 23 are of order 1. The order of an MCS represents the number of basic events contributing to that MCS. If all the basic events are equally probable to occur, then the higher the order of an MCS, the lower the criticality of that MCS is. Therefore, in this example, the first-order MCSs, such as “Water level is inadequate in the reservoir (WLIR)”, “Random Failure of Water Pump (RFWP)”, “Switch Failure (SWF)”, “Internal Failure of Relay (IFR)”, “Human Error (HE)”, “Random Failure of Gateway (RFG)”, and “Gateway Battery Failure (GBF)”, are the most critical ones. Therefore, actions should be taken to reduce the likelihood of these events. For instance, for the events related to communication failure, multiple communication media can be considered, so that if one medium fails, another can be used for successful communication. 7. Conclusions The integration of IoT technology into agriculture heralds a transformative era, albeit one fraught with challenges, particularly in areas of the dependability and trustworthiness of these systems to operate as expected over their mission time. Understanding the intricacies of individual component failures and their systemic impact is pivotal for ensuring the robust performance of agricultural IoT systems. As the agricultural landscape evolves, researchers are at the forefront of developing sophisticated analysis and verification frameworks essential for fostering intelligent systems contributing to long-term food sustainability. This study serves as a testament to the effectiveness of the MBSA approach in dissecting the failure behaviour of an abstract IoT-based Smart Irrigation System. Leveraging a model-driven methodology, the investigation not only illuminated the nuances of system failure but also showcased the MBSA approach’s merits—characterised by meticulousness, error reduction, model reuse, and adaptability to iterative processes. The fault tree generated through this approach systematically identified component failures as basic events, delineating their interconnected pathways leading to system failure. This granular analysis empowers stakeholders to pinpoint the root causes of system failure and implement remedial measures crucial for maintaining operational integrity. While the present study concentrated on qualitative analysis, future investigations hold promise in transitioning to quantitative assessments by incorporating components’ failure rates or probabilities and considering various failure distributions over time. Furthermore, the MBSA approach’s inherent flexibility opens avenues for including additional complex failure conditions, such as “unnecessary irrigation” or “insufficient irrigation duration”, demonstrating its ease of adaptation for diverse failure analyses. In the evolving landscape of agricultural technology, security considerations emerge as a paramount concern. Acknowledging the potential vulnerabilities to safety failures induced by malevolent attacks, future research endeavours should delve into fortifying the system against security threats and malicious operations. As we navigate the ever-expanding realm of IoT in agriculture, a continuous commitment to robust analysis, adaptability, and security considerations will undoubtedly shape the future of sustainable and resilient smart farming systems. Lastly, the proposed approach requires scalability, which can be achieved using a dynamic FTA. This tool is useful for modelling complex systems’ time- and function-dependent failure behaviour. By incorporating a dynamic FTA, we will be able to gain a more accurate understanding of how a system behaves over time and how different functions and components interact. This information can optimise framework performance, reduce risks, and improve the system’s overall dependability. Author Contributions Background, A.A. and M.M.R.; proposed methodology, S.K., I.G., A.A. and M.M.R.; writing—original draft preparation, A.A. and M.M.R.; writing—review and editing, S.K. and I.G.; problem space and formalisation, S.K. and I.G.; supervision, I.G. and S.K.; project administration, S.K. All authors have read and agreed to the published version of the manuscript. Funding This research received no external funding. Data Availability Statement Data are contained within the article. Conflicts of Interest The authors declare no conflicts of interest. Appendix A. Data Associated with the Fault Tree of Figure Table A1. Description of Events in the Fault Tree of Figure 10. References Bangladesh Bureau of Statistics (BBS). Agriculture Census 2019: Structure of Agricultural Holdings and Livestock & Fisheries, National Series Volume-1; BBS, Statistics and Informatics Division, Ministry of Planning, Government of the People’s Republic of Bangladesh: Dhaka, Bangladesh, 2022. Ayaz, M.; Ammad-Uddin, M.; Sharif, Z.; Mansour, A.; Aggoune, E.H.M. Internet-of-Things (IoT)-based smart agriculture: Toward making the fields talk. IEEE Access 2019, 7, 129551–129583. [Google Scholar] [CrossRef] Gondchawar, N.; Kawitkar, R. IoT based smart agriculture. Int. J. Adv. Res. Comput. Commun. Eng. 2016, 5, 838–842. [Google Scholar] Sushanth, G.; Sujatha, S. IOT based smart agriculture system. In Proceedings of the 2018 International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET), Chennai, India, 22–24 March 2018; IEEE: Toulouse, France, 2018; pp. 1–4. [Google Scholar] Yang, X.; Shu, L.; Li, K.; Nurellari, E.; Huo, Z.; Zhang, Y. A Lightweight Fault-Detection Scheme for Resource-Constrained Solar Insecticidal Lamp IoTs. Sensors 2023, 23, 6672. [Google Scholar] [CrossRef] [PubMed] Shahzadi, R.; Tausif, M.; Ferzund, J.; Suryani, M.A. Internet of things based expert system for smart agriculture. Int. J. Adv. Comput. Sci. Appl. 2016, 7, 341–350. [Google Scholar] [CrossRef] Saraf, S.B.; Gawali, D.H. IoT based smart irrigation monitoring and controlling system. In Proceedings of the 2017 2nd IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT), Bangalore, India, 19–20 May 2017; IEEE: Toulouse, France, 2017; pp. 815–819. [Google Scholar] Khanna, A.; Kaur, S. Evolution of Internet of Things (IoT) and its significant impact in the field of Precision Agriculture. Comput. Electron. Agric. 2019, 157, 218–231. [Google Scholar] [CrossRef] Huang, K.; Shu, L.; Li, K.; Chen, Y.; Zhu, Y.; Valluru, R. Sustainable and Intelligent Phytoprotection in Photovoltaic Agriculture: New Challenges and Opportunities. Electronics 2023, 12, 1221. [Google Scholar] [CrossRef] Ferrag, M.A.; Shu, L.; Yang, X.; Derhab, A.; Maglaras, L. Security and privacy for green IoT-based agriculture: Review, blockchain solutions, and challenges. IEEE Access 2020, 8, 32031–32053. [Google Scholar] [CrossRef] Yang, X.; Shu, L.; Liu, Y.; Hancke, G.P.; Ferrag, M.A.; Huang, K. Physical security and safety of IoT equipment: A survey of recent advances and opportunities. IEEE Trans. Ind. Inform. 2022, 18, 4319–4330. [Google Scholar] [CrossRef] Abdulhamid, A.; Kabir, S.; Ghafir, I.; Lei, C. Dependability of the Internet of Things: Current Status and Challenges. In Proceedings of the 2022 International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME), Maldives, Maldives, 16–18 November 2022; IEEE: Toulouse, France, 2022; pp. 1–6. [Google Scholar] Kabir, S. An overview of fault tree analysis and its application in model based dependability analysis. Expert Syst. Appl. 2017, 77, 114–135. [Google Scholar] [CrossRef] Relkar, A.S. Risk analysis of equipment failure through failure mode and effect analysis and fault tree analysis. J. Fail. Anal. Prev. 2021, 21, 793–805. [Google Scholar] [CrossRef] Niloofar, P.; Lazarova-Molnar, S. Fusion of data and expert knowledge for fault tree reliability analysis of cyber-physical systems. In Proceedings of the 2021 5th International Conference on System Reliability and Safety (ICSRS), Palermo, Italy, 24–26 November 2021; IEEE: Toulouse, France, 2021; pp. 92–97. [Google Scholar] Yang, X.; Shu, L.; Li, K.; Huo, Z.; Shu, S.; Nurellari, E. Silos: An intelligent fault detection scheme for solar insecticidal lamp iot with improved energy efficiency. IEEE Internet Things J. 2022, 10, 920–939. [Google Scholar] [CrossRef] Fazlollahtabar, H.; Niaki, S.T.A. Fault tree analysis for reliability evaluation of an advanced complex manufacturing system. J. Adv. Manuf. Syst. 2018, 17, 107–118. [Google Scholar] [CrossRef] Kabir, S.; Taleb-Berrouane, M.; Papadopoulos, Y. Dynamic reliability assessment of flare systems by combining fault tree analysis and Bayesian networks. Energy Sources Part A Recover. Util. Environ. Eff. 2023, 45, 4305–4322. [Google Scholar] [CrossRef] Abdulhamid, A.; Kabir, S.; Ghafir, I.; Lei, C. Developing Dependable IoT Systems: Safety Perspective. In Proceedings of the UNIfied Conference of DAMAS, IncoME and TEPEN Conferences, Huddersfield, UK, 29 August–1 September 2023; Springer: Cham, Switzerland, 2023; pp. 1–6. [Google Scholar] Abdulhamid, A.; Kabir, S.; Ghafir, I.; Lei, C. An Overview of Safety and Security Analysis Frameworks for the Internet of Things. Electronics 2023, 12, 3086. [Google Scholar] [CrossRef] Kabir, S.; Papadopoulos, Y.; Walker, M.; Parker, D.; Aizpurua, J.I.; Lampe, J.; Rüde, E. A model-based extension to HiP-HOPS for dynamic fault propagation studies. In Proceedings of the Model-Based Safety and Assessment, Trento, Italy, 11–13 September 2017; Bozzano, M., Papadopoulos, Y., Eds.; Springer: Cham, Switzerland, 2017; pp. 163–178. [Google Scholar] Alshboul, B.; Petriu, D.C. Automatic derivation of fault tree models from SysML models for safety analysis. J. Softw. Eng. Appl. 2018, 11, 204–222. [Google Scholar] [CrossRef] Feiler, P.; Delange, J. Automated fault tree analysis from aadl models. ACM SIGAda Ada Lett. 2017, 36, 39–46. [Google Scholar] [CrossRef] Sebastián, G.; Tesoriero, R.; Gallud, J.A. Automatic code generation for language-learning applications. IEEE Lat. Am. Trans. 2020, 18, 1433–1440. [Google Scholar] [CrossRef] Shboul, B.A.; Petriu, D.C. Pattern-based transformation of SysML models into fault tree models. In Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering, Toronto, ON, Canada, 4–6 November 2019; pp. 214–223. [Google Scholar] Sharvia, S.; Kabir, S.; Walker, M.; Papadopoulos, Y. Model-based dependability analysis: State-of-the-art, challenges, and future outlook. Softw. Qual. Assur. 2016, 2016, 251–278. [Google Scholar] Roudier, Y.; Apvrille, L. SysML-Sec: A model driven approach for designing safe and secure systems. In Proceedings of the 2015 3rd International Conference on Model-Driven Engineering and Software Development (MODELSWARD), Angers, France, 9–11 February 2015; IEEE: Toulouse, France, 2015; pp. 655–664. [Google Scholar] de Andrade Melani, A.H.; de Souza, G.F.M. Obtaining fault trees through SysML diagrams: A MBSE approach for reliability analysis. In Proceedings of the 2020 Annual Reliability and Maintainability Symposium (RAMS), Palm Springs, CA, USA, 27–30 January 2020; IEEE: Toulouse, France, 2020; pp. 1–5. [Google Scholar] Vyas, P.; Mittal, R. Hazard analysis of Unified Modelling Language sequence and state charts using software fault tree analysis. Int. J. Crit. Comput.-Based Syst. 2013, 4, 173–197. [Google Scholar] [CrossRef] Jürjens, J. Developing safety-critical systems with UML. In Proceedings of the «UML» 2003-The Unified Modeling Language. Modeling Languages and Applications: 6th International Conference, San Francisco, CA, USA, 20–24 October 2003; Proceedings 6. Springer: Berlin/Heidelberg, Germany, 2003; pp. 360–372. [Google Scholar] Papadopoulos, Y.; McDermid, J.A. Hierarchically performed hazard origin and propagation studies. In Proceedings of the International Conference on Computer Safety, Reliability, and Security, Toulouse, France, 27–29 September 1999; Springer: Berlin/Heidelberg, Germany, 1999; pp. 139–152. [Google Scholar] Cisco. What Percent of Earth Is Water? 2014. Available online: https://phys.org/news/2014-12-percent-earth.html (accessed on 25 October 2023). Water Science School. Ice, Snow, and Glaciers and the Water Cycle. 2019. Available online: https://www.usgs.gov/special-topics/water-science-school/science/ice-snow-and-glaciers-and-water-cycle (accessed on 25 October 2023). Wang, E.; Attard, S.; Linton, A.; McGlinchey, M.; Xiang, W.; Philippa, B.; Everingham, Y. Development of a closed-loop irrigation system for sugarcane farms using the Internet of Things. Comput. Electron. Agric. 2020, 172, 105376. [Google Scholar] [CrossRef] Dahane, A.; Kechar, B.; Benameur, R. Precision Agriculture: Automated Irrigation Management Platform Using Wireless Sensor Networks. In Precision Agriculture Technologies for Food Security and Sustainability; IGI Global: Hershey, PA, USA, 2021; pp. 150–165. [Google Scholar] Kumar Jayam, Y.; Tunuguntla, V.; Sreehari, J.; Harinarayanan, S. Smart Plant Managing System using IoT. In Proceedings of the 2020 4th International Conference on Trends in Electronics and Informatics (ICOEI) (48184), Tirunelveli, India, 15–17 June 2020; IEEE: Toulouse, France, 2020; pp. 271–277. [Google Scholar] Dahane, A.; Benameur, R.; Kechar, B.; Benyamina, A. An IoT based smart farming system using machine learning. In Proceedings of the 2020 International Symposium on Networks, Computers and Communications (ISNCC), Montreal, QC, Canada, 20–22 October 2020; IEEE: Toulouse, France, 2020; pp. 1–6. [Google Scholar] Gutiérrez, J.; Villa-Medina, J.F.; Nieto-Garibay, A.; Porta-Gándara, M.Á. Automated irrigation system using a wireless sensor network and GPRS module. IEEE Trans. Instrum. Meas. 2013, 63, 166–176. [Google Scholar] [CrossRef] Saranya, T.; Deisy, C.; Sridevi, S.; Anbananthen, K.S.M. A comparative study of deep learning and Internet of Things for precision agriculture. Eng. Appl. Artif. Intell. 2023, 122, 106034. [Google Scholar] [CrossRef] Ale, L.; Sheta, A.; Li, L.; Wang, Y.; Zhang, N. Deep learning based plant disease detection for smart agriculture. In Proceedings of the 2019 IEEE Globecom Workshops (GC Wkshps), Waikoloa, HI, USA, 9–13 December 2019; IEEE: Toulouse, France, 2019; pp. 1–6. [Google Scholar] Taneja, N.; Garg, N.; Gupta, S.; Kaushal, R. Comparative Analysis of Convolutional Neural Network Techniques for Plant Disease Detection. In Proceedings of the 2023 4th International Conference for Emerging Technology (INCET), Belgaum, India, 26–28 May 2023; IEEE: Toulouse, France, 2023; pp. 1–4. [Google Scholar] Mahlein, A.K. Plant disease detection by imaging sensors–parallels and specific demands for precision agriculture and plant phenotyping. Plant Dis. 2016, 100, 241–251. [Google Scholar] [CrossRef] Mishra, R.; Singh, D. Convolutional Neural Network Method for Effective Plant Disease Prediction. In Proceedings of the 2023 IEEE International Conference on Integrated Circuits and Communication Systems (ICICACS), Raichur, India, 24–25 February 2023; IEEE: Toulouse, France, 2023; pp. 1–5. [Google Scholar] Al-Shareeda, M.A.; Manickam, S.; Saare, M.A. Intelligent Drone-based IoT Technology for Smart Agriculture System. In Proceedings of the 2022 International Conference on Data Science and Intelligent Computing (ICDSIC), Karbala, Iraq, 1–2 November 2022; IEEE: Toulouse, France, 2022; pp. 41–45. [Google Scholar] Maslekar, N.; Kulkarni, K.P.; Chakravarthy, A.K. Application of unmanned aerial vehicles (UAVs) for pest surveillance, monitoring and management. In Innovative Pest Management Approaches for the 21st Century: Harnessing Automated Unmanned Technologies; Springer: Singapore, 2020; pp. 27–45. [Google Scholar] Dutta, J.; Dutta, J.; Gogoi, S. Smart farming: An opportunity for efficient monitoring and detection of pests and diseases. J. Entomol. Zool. Stud 2020, 8, 2352–2359. [Google Scholar] Cicioğlu, M.; Çalhan, A. Smart agriculture with internet of things in cornfields. Comput. Electr. Eng. 2021, 90, 106982. [Google Scholar] [CrossRef] Darwin, B.; Dharmaraj, P.; Prince, S.; Popescu, D.E.; Hemanth, D.J. Recognition of bloom/yield in crop images using deep learning models for smart agriculture: A review. Agronomy 2021, 11, 646. [Google Scholar] [CrossRef] Kootstra, G.; Wang, X.; Blok, P.M.; Hemming, J.; Van Henten, E. Selective harvesting robotics: Current research, trends, and future directions. Curr. Robot. Rep. 2021, 2, 95–104. [Google Scholar] [CrossRef] Kalantari, F.; Tahir, O.M.; Joni, R.A.; Fatemi, E. Opportunities and challenges in sustainability of vertical farming: A review. J. Landsc. Ecol. 2018, 11, 35–60. [Google Scholar] [CrossRef] Siregar, R.R.A.; Seminar, K.B.; Wahjuni, S.; Santosa, E. Vertical farming perspectives in support of precision agriculture using artificial intelligence: A review. Computers 2022, 11, 135. [Google Scholar] [CrossRef] Abhay, V.S.; Fahida, V.H.; Reshma, T.R.; Sajan, C.K.; Shelly, S. IoT-Based Home Vertical Farming. In Intelligent Systems, Technologies and Applications; Paprzycki, M., Thampi, S.M., Mitra, S., Trajkovic, L., El-Alfy, E.S.M., Eds.; Springer: Singapore, 2021; pp. 151–160. [Google Scholar] Kundu, K.; Sharma, S.; Bhardwaj, B.; Muddineni, R.; Rai, A. Design & Development of IoT based Vertical Farming Monitoring System. In Proceedings of the 2023 International Conference on Artificial Intelligence and Smart Communication (AISC), Greater Noida, India, 27–29 January 2023; IEEE: Toulouse, France, 2023; pp. 1018–1021. [Google Scholar] Putri, R.E.; Wibowo, M.; Ardli, J.; Andasuryani, A. Monitoring and controlling of vertical farming system using Internet of Things (IoT). In Proceedings of the AIP Conference Proceedings, Padang, Indonesia, 3–4 November 2021; AIP Publishing: New York, NY, USA, 2023. [Google Scholar] Kaur, G.; Upadhyaya, P.; Chawla, P. Comparative analysis of IoT-based controlled environment and uncontrolled environment plant growth monitoring system for hydroponic indoor vertical farm. Environ. Res. 2023, 222, 115313. [Google Scholar] [CrossRef] Kaur, G.; Upadhyaya, P.; Chawla, P. Iot based mobile application for monitoring of hydroponic vertical farming. In Proceedings of the 2022 10th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), Noida, India, 13–14 October 2022; IEEE: Toulouse, France, 2022; pp. 1–4. [Google Scholar] Maraveas, C. Incorporating artificial intelligence technology in smart greenhouses: Current State of the Art. Appl. Sci. 2022, 13, 14. [Google Scholar] [CrossRef] Escamilla-García, A.; Soto-Zarazúa, G.M.; Toledano-Ayala, M.; Rivas-Araiza, E.; Gastélum-Barrios, A. Applications of artificial neural networks in greenhouse technology and overview for smart agriculture development. Appl. Sci. 2020, 10, 3835. [Google Scholar] [CrossRef] Kagan, C.R.; Arnold, D.P.; Cappelleri, D.J.; Keske, C.M.; Turner, K.T. Special report: The Internet of Things for Precision Agriculture (IoT4Ag). Comput. Electron. Agric. 2022, 196, 106742. [Google Scholar] [CrossRef] Mishra, S.; Sharma, S.K. Advanced contribution of IoT in agricultural production for the development of smart livestock environments. Internet Things 2023, 22, 100724. [Google Scholar] [CrossRef] Benaissa, S.; Tuyttens, F.; Plets, D.; Martens, L.; Vandaele, L.; Joseph, W.; Sonck, B. Improved cattle behaviour monitoring by combining Ultra-Wideband location and accelerometer data. Animal 2023, 17, 100730. [Google Scholar] [CrossRef] Ilyas, Q.M.; Ahmad, M. Smart farming: An enhanced pursuit of sustainable remote livestock tracking and geofencing using IoT and GPRS. Wirel. Commun. Mob. Comput. 2020, 2020, 1–12. [Google Scholar] [CrossRef] Xu, X.; Du, Z.; Bai, Z.; Wang, S.; Wang, C.; Li, D. Fault diagnosis method of dissolved oxygen sensor electrolyte loss based on impedance measurement. Comput. Electron. Agric. 2023, 212, 108123. [Google Scholar] [CrossRef] Jenab, K.; Pineau, J. Failure mode and effect analysis on safety critical components of space travel. Manag. Sci. Lett. 2015, 5, 669–678. [Google Scholar] [CrossRef] Kabir, S.; Papadopoulos, Y. Applications of Bayesian networks and Petri nets in safety, reliability, and risk assessments: A review. Saf. Sci. 2019, 115, 154–175. [Google Scholar] [CrossRef] Patrizi, G.; Bartolini, A.; Ciani, L.; Catelani, M. Failure analysis of a smart sensor node for precision agriculture. In Proceedings of the 18th IMEKO TC10 Conference, Warsaw, Poland, 16–27 September 2022; pp. 26–31. [Google Scholar] Wang, Y.; Zhang, R.; Zhang, X.; Zhang, Y. Privacy Risk Assessment of Smart Home System Based on a STPA–FMEA Method. Sensors 2023, 23, 4664. [Google Scholar] [CrossRef] Korsunovs, A.; Doikin, A.; Campean, F.; Kabir, S.; Hernandez, E.; Taggart, D.; Parker, S.; Mills, G. Towards a Model-Based Systems Engineering Approach for Robotic Manufacturing Process Modelling with Automatic FMEA Generation. Proc. Des. Soc. 2022, 2, 1905–1914. [Google Scholar] [CrossRef] Abdulhamid, A.; Kabir, S.; Ghafir, I.; Lei, C. Reliability Assessment of IoT-enabled Systems using Fault Trees and Bayesian Networks. In Proceedings of the 5th International Conference on Advances in Distributed Computing and Machine Learning (ICADCML), Amaravati, India, 5–6 June 2024; pp. 1–10. [Google Scholar] Pearl, J. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference; Morgan Kaufmann: San Francisco, CA, USA, 1988. [Google Scholar] Xiao, Q.; Li, Y.; Luo, F.; Liu, H. Analysis and assessment of risks to public safety from unmanned aerial vehicles using fault tree analysis and Bayesian network. Technol. Soc. 2023, 73, 102229. [Google Scholar] [CrossRef] Kabir, S.; Aslansefat, K.; Sorokos, I.; Papadopoulos, Y.; Konur, S. A hybrid modular approach for dynamic fault tree analysis. IEEE Access 2020, 8, 97175–97188. [Google Scholar] [CrossRef] Kou, L.; Chu, B.; Chen, Y.; Qin, Y. An Automatic Partition Time-Varying Markov Model for Reliability Evaluation. Appl. Sci. 2022, 12, 5933. [Google Scholar] [CrossRef] Reisig, W. Petri Nets: An Introduction; Springer Science & Business Media: New York, NY, USA, 2012; Volume 4. [Google Scholar] Zurawski, R.; Zhou, M. Petri nets and industrial applications: A tutorial. IEEE Trans. Ind. Electron. 1994, 41, 567–583. [Google Scholar] [CrossRef] Kabir, S.; Azad, T.; Walker, M.; Gheraibia, Y. Reliability analysis of automated pond oxygen management system. In Proceedings of the 2015 18th International Conference on Computer and Information Technology (ICCIT), Dhaka, Bangladesh, 21–23 December 2015; IEEE: Toulouse, France, 2015; pp. 144–149. [Google Scholar] Wongvises, C.; Khurat, A.; Fall, D.; Kashihara, S. Fault tree analysis-based risk quantification of smart homes. In Proceedings of the 2nd International Conference on Information Technology (INCIT), Nakhonpathom, Thailand, 2–3 November 2017; IEEE: Toulouse, France, 2017; pp. 1–6. [Google Scholar] Wang, C.; Liu, Q.; Xing, L.; Guan, Q.; Yang, C.; Yu, M. Reliability analysis of smart home sensor systems subject to competing failures. Reliab. Eng. Syst. Saf. 2022, 221, 108327. [Google Scholar] [CrossRef] Silva, I.; Leandro, R.; Macedo, D.; Guedes, L.A. A dependability evaluation tool for the Internet of Things. Comput. Electr. Eng. 2013, 39, 2005–2018. [Google Scholar] [CrossRef] Silva, D.; Heideker, A.; Zyrianoff, I.D.; Kleinschmidt, J.H.; Roffia, L.; Soininen, J.P.; Kamienski, C.A. A management architecture for IoT smart solutions: Design and implementation. J. Netw. Syst. Manag. 2022, 30, 35. [Google Scholar] [CrossRef] Gao, D.X.; Hou, J.J.; Liang, K.; Yang, Q. Fault diagnosis system for electric vehicle charging devices based on fault tree analysis. In Proceedings of the 2018 37th Chinese Control Conference (CCC), Wuhan, China, 25–27 July 2018; IEEE: Toulouse, France, 2018; pp. 5055–5059. [Google Scholar] Rahman, M.M.; Abdulhamid, A.; Kabir, S. Qualitative Failure Analysis of IoT-enabled Industrial Fire Detection and Prevention System. In Proceedings of the 26th International Conference on Computer and Information Technology (ICCIT), Cox’s Bazar, Bangladesh, 13–15 December 2023; IEEE: Toulouse, France, 2023; pp. 1–6. [Google Scholar] Dai, W.; Riliskis, L.; Wang, P.; Vyatkin, V.; Guan, X. A cloud-based decision support system for self-healing in distributed automation systems using fault tree analysis. IEEE Trans. Ind. Informatics 2018, 14, 989–1000. [Google Scholar] [CrossRef] Chen, Y.; Zhen, Z.; Yu, H.; Xu, J. Application of fault tree analysis and fuzzy neural networks to fault diagnosis in the internet of things (IoT) for aquaculture. Sensors 2017, 17, 153. [Google Scholar] [CrossRef] Ruijters, E.; Stoelinga, M. Fault tree analysis: A survey of the state-of-the-art in modeling, analysis and tools. Comput. Sci. Rev. 2015, 15, 29–62. [Google Scholar] [CrossRef] Bell, R. Introduction and Revision of IEC 61508. In Proceedings of the Advances in Systems Safety: Proceedings of the Nineteenth Safety-Critical Systems Symposium, Southampton, UK, 8–10 February 2011; Springer: Berlin/Heidelberg, Germany, 2010; pp. 273–291. [Google Scholar] Kaiser, B.; Liggesmeyer, P.; Mäckel, O. A New Component Concept for Fault Trees. In Proceedings of the 8th Australian Workshop on Safety Critical Systems and Software (SCS’03), Canberra, ACT, Australia, 9–10 October 2003; Volume 33, pp. 37–46. [Google Scholar] Papadopoulos, Y.; Walker, M.; Parker, D.; Sharvia, S.; Bottaci, L.; Kabir, S.; Azevedo, L.; Sorokos, I. A synthesis of logic and bio-inspired techniques in the design of dependable systems. Annu. Rev. Control 2016, 41, 170–182. [Google Scholar] [CrossRef] Nordmann, A.; Munk, P. Lessons learned from model-based safety assessment with SysML and component fault trees. In Proceedings of the 21th ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, Copenhagen, Denmark, 14–19 October 2018; pp. 134–143. [Google Scholar] Kabir, S.; Walker, M.; Papadopoulos, Y. Dynamic system safety analysis in HiP-HOPS with Petri nets and Bayesian networks. Saf. Sci. 2018, 105, 55–70. [Google Scholar] [CrossRef] Mian, Z.; Bottaci, L.; Papadopoulos, Y.; Biehl, M. System dependability modelling and analysis using AADL and HiP-HOPS. IFAC Proc. Vol. 2012, 45, 1647–1652. [Google Scholar] [CrossRef] Wang, H.; Zhong, D.; Zhao, T.; Ren, F. Integrating model checking with SysML in complex system safety analysis. IEEE Access 2019, 7, 16561–16571. [Google Scholar] [CrossRef] Mhenni, F.; Nguyen, N.; Choley, J.Y. SafeSysE: A safety analysis integration in systems engineering approach. IEEE Syst. J. 2016, 12, 161–172. [Google Scholar] [CrossRef] Disclaimer/Publisher’s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.  © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Share and Cite MDPI and ACS Style Abdulhamid, A.; Rahman, M.M.; Kabir, S.; Ghafir, I. Enhancing Safety in IoT Systems: A Model-Based Assessment of a Smart Irrigation System Using Fault Tree Analysis. Electronics 2024, 13, 1156. https://doi.org/10.3390/electronics13061156 AMA Style Abdulhamid A, Rahman MM, Kabir S, Ghafir I. Enhancing Safety in IoT Systems: A Model-Based Assessment of a Smart Irrigation System Using Fault Tree Analysis. Electronics. 2024; 13(6):1156. https://doi.org/10.3390/electronics13061156 Chicago/Turabian Style Abdulhamid, Alhassan, Md Mokhlesur Rahman, Sohag Kabir, and Ibrahim Ghafir. 2024. \"Enhancing Safety in IoT Systems: A Model-Based Assessment of a Smart Irrigation System Using Fault Tree Analysis\" Electronics 13, no. 6: 1156. https://doi.org/10.3390/electronics13061156 Note that from the first issue of 2016, this journal uses article numbers instead of page numbers. See further details here. Article Metrics Citations No citations were found for this article, but you may check on Google Scholar Article Access Statistics Article access statistics Article Views 21. Mar 23. Mar 25. Mar 27. Mar 29. Mar 31. Mar 2. Apr 4. Apr 6. Apr 0 200 400 600 For more information on the journal statistics, click here. Multiple requests from the same IP address are counted as one view.   Electronics, EISSN 2079-9292, Published by MDPI RSS Content Alert Further Information Article Processing Charges Pay an Invoice Open Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors For Reviewers For Editors For Librarians For Publishers For Societies For Conference Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe to receive issue release notifications and newsletters from MDPI journals Select options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated Disclaimer Terms and Conditions Privacy Policy"

Paper 9:
- APA Citation: None
  Main Objective: To Enhance System Reliability and Fault Tolerance in Automated Irrigation Systems
  Study Location: Unspecified
  Data Sources: []
  Technologies Used: ['Redundancy']
  Key Findings: ['Redundancy involves implementing redundant components to maintain system functionality during component failures.', 'By detecting and isolating faults, the system can continue to operate reliably and effectively.', 'Redundancy helps to address the weaknesses of single-point-of-failure scenarios that could otherwise lead to system downtime or data loss.']
  Extract 1: 
  Extract 2: 
  Limitations: >
  Relevance Evaluation: {'extract_1': '"Implementing redundant components, such as multiple sensors, controllers, and communication channels, to maintain system functionality during component failures"', 'extract_2': '"By detecting and isolating faults, the system can continue to operate reliably and effectively." Redundancy helps to address the weaknesses of single-point-of-failure scenarios that could otherwise lead to system downtime or data loss.', 'relevance_score': '0.9'}
  Relevance Score: 0.9
  Inline Citation: See Section 4.1 Resilience and Fault Tolerance in Automated Irrigation Systems
  Explanation: Redundancy is a strategy used to increase system reliability and fault tolerance in automated irrigation systems. It involves implementing redundant components, such as multiple sensors, controllers, and communication channels, to maintain system functionality during component failures. By detecting and isolating faults, the system can continue to operate reliably and effectively. Implementing redundancy helps to address the weaknesses of single-point-of-failure scenarios that could otherwise lead to system downtime or data loss.

 Full Text: >
"This website uses cookies We use cookies to personalise content and ads, to provide social media features and to analyse our traffic. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you’ve provided to them or that they’ve collected from your use of their services. Consent Selection Necessary Preferences Statistics Marketing Show details                 Deny Allow selection Allow all     Journals Topics Information Author Services Initiatives About Sign In / Sign Up Submit   Search for Articles: Agronomy All Article Types Advanced   Journals Agronomy Volume 13 Issue 7 10.3390/agronomy13071679 Submit to this Journal Review for this Journal Propose a Special Issue Article Menu Academic Editors Shicheng Yan Yongzong Lu Shengcai Qiang Show more... Subscribe SciFeed Recommended Articles Related Info Link More by Authors Links Article Views 1673 Citations 2 Table of Contents Abstract Introduction Materials and Methods Results Discussion Conclusions Supplementary Materials Author Contributions Funding Data Availability Statement Conflicts of Interest References share Share announcement Help format_quote Cite question_answer Discuss in SciProfiles thumb_up Endorse textsms Comment first_page settings Order Article Reprints Open AccessArticle Effect of Irrigation Water Salinity on Soil Characteristics and Microbial Communities in Cotton Fields in Southern Xinjiang, China by Bangxin Ding 1,2, Yungang Bai 2,*, Shuchen Guo 1, Zijian He 1, Bei Wang 2, Hongbo Liu 2, Jiangrui Zhai 2 and Hongxia Cao 1,* 1 Key Laboratory of Agricultural Soil and Water Engineering in Arid and Semiarid Areas, Ministry of Education, Northwest A&F University, Yangling 712100, China 2 Xinjiang Institute of Water Resources and Hydropower Research, Urumqi 830049, China * Authors to whom correspondence should be addressed. Agronomy 2023, 13(7), 1679; https://doi.org/10.3390/agronomy13071679 Submission received: 29 May 2023 / Revised: 16 June 2023 / Accepted: 21 June 2023 / Published: 22 June 2023 (This article belongs to the Special Issue Agricultural Water Management in Arid, Semi-Arid and Drought Prone Areas) Download keyboard_arrow_down      Browse Figures Versions Notes Abstract Irrigation with saline water is a possible solution to alleviate freshwater shortages. The long-term use of saline water for irrigation requires consideration of the influence of salt on the environmental conditions of the soil. The objective of this field study was to determine the effects of three continuous years of saline water irrigation on physiochemical properties and microbial communities in drip-irrigated cotton fields. The three total dissolved solid (TDS) levels of irrigation water treatments were (i) 1 g L−1 (fresh water, FWI), (ii) 3 g L−1 (brackish water, BWI), and (iii) 7 g L−1 (salt water, SWI). After three years, the electrical conductivity (EC), sodium adsorption ratio (SAR), and contents of K+, Na+, Mg2+, Cl−, and SO42− in the SWI treatment were significantly higher than those in the FWI and BWI treatments, but there were no significant differences in EC and K+ between the FWI and BWI treatments. BWI treatment significantly increased microbial biomass carbon (MBC), microbial biomass nitrogen (MBN), urease, and sucrase contents. The diversity and abundance of bacteria and fungi were not affected by saline water irrigation, but the microbial community structure was altered. Saline water irrigation resulted in an elevation in the bacterial abundance of the phylum Chloroflexi and a decline in Proteobacteria and Actinobacteria. For fungi, the abundance of the phylum Ascomycota in the BWI treatment was greater than that in the FWI and SWI treatments. Linear discriminant analysis effect size (NMDS) results indicated clear variation in the microbiota profiles between the FWI, BWI, and SWI treatments for bacteria. Regarding the fungal microbiota profiles, the BWI and SWI treatments had similar microbiota profiles but were different from the FWI treatment. The number of bacterial biomarkers gradually increased with increasing total dissolved solids of irrigation water, while the number of fungal biomarkers gradually decreased. Additionally, cotton yield was significantly and positively correlated with the observed species of fungi, while it was significantly and negatively correlated with EC. Redundancy analysis (RDA) showed that bacterial community structure was regulated by SAR and fungal community structure was regulated by soil salinity and bulk density (BD). Future research will need to look into how the structure of the microbial community and the associated functional microorganisms are gradually changing with increased irrigation frequency under saline irrigation, as well as explore and screen for advantageous functional microorganisms. Keywords: saline mulched drip irrigation; bacterial and fungal communities; soil physicochemical properties; enzymatic activities; cotton field 1. Introduction Xinjiang in northwest China has a continental arid climate with excellent sunshine conditions and a large temperature change between day and night, resulting in a high quality of cotton, and it has the largest concentration of cotton cultivated in China [1,2,3]. Nevertheless, scant precipitation and intense evaporation have severely impeded this region’s cotton industry development [4]. Freshwater resources are scarce in the southern Xinjiang region, but saline groundwater resources are widely available. Utilizing regionally abundant saline water resources for irrigation can greatly reduce agricultural water constraints, and hence, irrigation with saline water has been widely applied [5]. However, there are several disadvantages to utilizing saline water for irrigation, including increases in soil salinity, decreases in enzyme activity, changes in soil physical properties, and plant stress resulting from the increased osmotic potential, which negatively impacts crop growth and production [6,7]. Additionally, compared to conventional watering with fresh water, the use of saline water for irrigation may drastically alter soil microbial communities. Microorganisms are important for soil nutrient conversion and crop growth [8,9]. The abundance and structure of the soil microbial community are highly responsive to alterations in soil environmental conditions and have been widely used to indicate soil quality changes [10,11,12]. Therefore, an understanding of soil microbiology has gained increasing recognition and importance. The effects of saltwater irrigation on crop yield, soil salt content, root density, soil physical qualities, soil nutrients, and groundwater quality have been reported in earlier research [7,13,14,15,16]. Most studies indicate that irrigation with saline water can result in secondary salinization, increase spatial variations in soil moisture, and reduce crop yield [5]. In a salt-affected environment, salinity can reduce microbial production and activity and alter the makeup of microbial communities [17]. Dong et al. [18] discovered that salinity had little impact on bacterial richness, but it was the main driver of a change in the makeup of the bacterial community and significantly reduced microbial activity. Hu et al. [19] found that long-term brackish irrigation led to an increase in electrical conductivity (EC) and sodium adsorption ratio (SAR) and a polarized distribution of microbial communities. However, less is known about the changes in biological community structure along a gradient of irrigation water salinity levels, and the key environmental factors influencing the distribution and abundance of soil microorganisms are still poorly understood. Several studies have shown that the soil microbial community structure can be influenced by the soil pH, organic matter content, soil salinity, soil disturbance level, and moisture status [20,21,22,23,24]. In many cases, the main factor driving changes in the makeup of the microorganisms has been identified as soil salinity [25]. The decrease in soil microbial biomass with increasing soil salinity is mostly due to the dehydration and lysis of cells under osmotic stress, which is exacerbated by higher soluble salt concentrations. Salt-tolerant microbes adjust to low osmotic potential by accumulating osmolytes [26]. Hence, changes in the structure of bacterial communities in saline soils compared to non-saline soils are caused by differences in bacterial salt tolerance. Zhalnina et al. [23] argued that pH is also a key factor in determining the composition of the soil microbial community, in addition to soil salinity. Many environmental factors, such as salinity type, nutrient availability, and ions in irrigation water (e.g., CO3−2, HCO3−1), are closely related to soil pH [27]. pH can indirectly affect microbial communities by altering some of the physicochemical properties of the soil, and changes in soil nutrient availability are the way in which pH is most likely to affect microorganisms. However, Wichern et al. [17] and Kabiri et al. [28] further noted that soil microorganisms can adapt to changes in the external environment, especially when regularly confronted with drought and salinity. Consequently, the effects of external factors on microbial diversity and community formation are not always the same. Due to the limited water resources and uneven seasonal distribution in the arid region of southern Xinjiang, saline groundwater with various total dissolved solids (1 g L−1–12 g L−1) is widely used for cotton cultivation. In order to achieve a deeper understanding of how saline irrigation affects microorganisms and to find the relationship between soil physicochemical properties and changes in the microbial community, this study conducted a three-year test of saline irrigation in drip-irrigated cotton fields. This study was conducted to fulfill the following objectives: (i) to investigate the influences of irrigation with different water salinity on soil physicochemical properties and enzyme activity; (ii) to evaluate how the soil bacterial and fungal community composition varies with the total dissolved solids gradient of irrigation water; and (iii) to explore the factors that influence alterations in soil microbial composition within cotton fields. We hypothesized that the microbial community is mainly influenced by the salinity content of the irrigation water and that soil enzyme activity, microbial diversity, and abundance decrease with increasing salinity. The findings of this study provide important insight into the consequences of drip irrigation systems utilizing saline water for microbial communities. 2. Materials and Methods 2.1. Study Site and Experimental Setup The field study was conducted at the Test Station of the Thirty-One Group located in Korla (40°53′ N, 86°56′ E), Xinjiang Province, Northwest China (Figure 1). The location of this site is in a continental desert climate with an altitude of 802 m. The annual precipitation is recorded to be 58 mm, whereas the annual evaporation is measured to be 2788 mm. The maximum temperatures in the cotton growing season (April–October) in 2019, 2020, and 2021 were 41.6 °C, 39.0 °C, and 41.5 °C, respectively, and the minimum temperatures were 2.7 °C, 2.6 °C, and 2.1 °C, respectively. The groundwater depth ranged from 1.4 to 1.8 m. Some physicochemical properties of soil are shown in Table 1. Figure 1. Schematic diagram of the study area. (a) Map of the study area; (b) irrigation water mixing device; (c) cotton planting pattern. Table 1. Experimental site soil physical and chemical qualities. In the study field, cotton has been continuously planted for 18 years. In 2019, 3 irrigation water salinities were set up for the experiment: 1 g L−1 (FWI: fresh water), 3 g L−1 (BWI: brackish water), and 7 g L−1 (SWI: salt water) were the total dissolved solids for the three water levels (Table 2). The salinity of fresh water was determined by the salinity of the local irrigation water source, which comes from the Tarim River. The salinity setting for saline water was based on the salinity of saline water used locally. The different total dissolved solids water used in the irrigation experiment was mixed with groundwater and fresh water. As the total dissolved solids of the groundwater constantly change, in order to ensure the salinity concentration of the irrigation water for each treatment, the total dissolved solids of the groundwater were measured on the day of each irrigation, and the mixing ratio of fresh and saline water was calculated based on the irrigation volume. The amounts of fresh and saline water were measured by means of a water meter. The mixing device is shown in Figure 1b, and the composition of groundwater is shown in Table 3. The experiment used a randomized block design. Each treatment was carried out in three experimental plots measuring 6 m wide and 7 m in length. The cotton planting method utilized winter irrigation plus drip irrigation under plastic mulch [29]. The cotton field’s drip lines were set up in the local design (Figure S1) [30]. Throughout the growth period, the experimental area was consistently irrigated with saline water on a weekly schedule until the crop was harvested. The total irrigation amount over the entire growing season was approximately 330 mm. The irrigation schedules for the growing seasons of 2019, 2020, and 2021 are shown in Table S1. Winter flood irrigation was conducted in the study area every year with a 400 mm irrigation amount to prevent soil salt accumulation. The Tarim River provides irrigation water for winter floods as well as fresh water. From 2019 to 2021, the salt content and pH value of the river water were between 0.81 g L−1 and 1.11 g L−1 and 7.52 and 8.32, respectively. Table 2. Total dissolved solids (TDS) (g L−1), electrical conductivity (EC) (mS cm−1), and main element contents (g L−1) of irrigation water in 2019, 2020, and 2021. Table 3. Total nitrogen (TN) (mg L−1), total dissolved solids (TDS) (g L−1), and the primary element contents (g L−1) of groundwater from 2019 to 2021. 2.2. Soil Sampling At the harvest (6 September) in 2021, soil samples were taken randomly from 0–20 cm of soil beneath the film-covered area using a 5 cm diameter auger. Fifteen subsamples were randomly collected from different locations within each plot to constitute the soil sample. After the collection of soil samples, they were promptly preserved in a portable storage container and expeditiously transported to the laboratory. Soil bulk density (BD) was measured at three randomly selected locations in the film-covered area of each plot, at depths of 0–10 cm, 10–20 cm, and 20–30 cm. 2.3. Soil Physicochemical Analysis The soil moisture (SM) was obtained using an indoor drying process. BD was calculated during the harvest stage in 2021 by placing steel cylinders [30]. Soil porosity (SP) was determined using the method of Carter et al. [31]. The electrical conductivity of the sample was determined utilizing a conductivity meter (model DDS-307, manufactured by INESA Scientific Instrument Co., Ltd., Shanghai, China) and using a dilution ratio of 1:5 [32]. The pH was measured using the methodology described by Gillman and Sumpter [33] with a dilution ratio of 1:5. Soil salt ions, groundwater ions, TDS, soil organic matter (SOM), total nitrogen (TN), available phosphorus (AP), and AK were measured using procedures described by Bao [32]. Briefly, SOM was determined through a wet oxidation–titration procedure using an acid dichromate system, TN concentration was determined through the micro-Kjeldahl method, AP contents were determined colorimetrically using a spectrophotometer, and an atomic adsorption spectrophotometer (TAS-990, Beijing, China) was used to determine AK concentrations [32]. The HCO3− and CO32− were determined through double indicator-neutralization titration, Cl− through silver nitrate titration, SO42− through EDTA indirect complex metric titration, Ca2+ and Mg2+ through EDTA titration, and Na+ and K+ through flame photometry [32]. The soil texture, field capacity, BD, and soil salinity in Table 1 were measured using procedures described by Liang et al. [30], and were measured in April 2019. SAR calculations are based on extracts with a soil to water ratio of 1:5. The soil SAR was then determined using Equation (1) [34]: SAR= [Na + ] (0.5[ Ca 2+ ]+0.5[ Mg 2+ ]) 0.5 (1) 2.4. Hydro-Chemical Ions The main anions (Cl− and SO42−) were determined using an ion chromatograph (ICS-900 Starter Line IC System, Waltham, MA, USA), and the main cations (Ca2+, Mg2+, Na+, and K+) were determined using an inductively coupled plasma emission spectrometer (ICP-OES, iCAP™ PRO, Waltham, MA, USA). The levels of HCO3− and CO32− were measured using double indicator-neutralization titration (methyl orange and phenolphthalein) [32]. 2.5. Microbial Biomass and Enzymatic Assay Invertase and urease were measured through the colorimetry method of 3,5-dinitro salicylic acid and sodium hypochlorite on a spectrophotometer, respectively [35]. Briefly, soil samples were incubated at 37 °C for 24 h, then invertase activity was assayed by measuring the amount of produced glucose. Urease activity was determined by measuring the released ammonium-N (NH3-N) in the filtrate. MBC and MBN in soil were determined through the chloroform fumigation method [35,36] and measured on a TOC/TN analyzer (GER, N/C 2100). 2.6. Cotton Seed Yield and Biomass At harvest time in 2021, three 1.0 m × 1.52 m (film width) areas were randomly selected in each plot to harvest by hand, and the seeds were then weighed to obtain seed cotton yield [37,38]. Plant samples were collected at the boll opening stage. From each plot, three cotton plants with comparable growth rates were selected, washed in deionized water, and dried at 105 °C for 30 min and then at 75 °C to achieve a constant weight [39]. 2.7. Measurement of Soil Microbial Communities Total genomic DNA samples were extracted using the OMEGA Soil DNA Kit (M5635-02) (Omega Bio-Tek, Norcross, GA, USA), following the manufacturer’s instructions, and stored at −20 °C prior to further analysis. The quantity and quality of extracted DNA samples were measured using a NanoDrop NC2000 spectrophotometer (Thermo Fisher Scientific, Waltham, MA, USA) and agarose gel electrophoresis, respectively. Afterwards, amplification was performed using the Illumina NovaSeq platform with a NovaSeq 6000 SP Reagent Kit (500 cycles) at Shanghai Personal Biotechnology Co., Ltd. (Shanghai, China). During amplification, the 16S rRNA gene’s V3V4 region was amplified for bacteria using the primer pair comprising 338F (5′-ACTCCTACGGGAGGCAGCA-3′) and 806R (5′-GGACTACHVGGGTWTCTAAT-3′) [36]. For fungi, the primer pair comprising ITS2 (5′-GCTGCGTTCTTCATCGATGC-3′) and ITS5 (5′-GGAAGTAAAAGTCGTAACAAGG-3′) was used to amplify the ITS1 region [40]. 2.8. Data Tools and Statistical Analyses The microbiome bioinformatics analysis was conducted using QIIME2 2019.4 [40,41]. The raw sequence data underwent demultiplexing using the Demux plugin and primer trimming using the cut adapt plugin [42]. To examine the significance of various treatments, Duncan’s multiple comparisons (p < 0.05) were used. The QIIME2 and R programs (v3.5.1) were primarily utilized for the analysis of sequence data. Using the amplifier sequence variation (ASV) table in QIIME2, the Shannon diversity index at the ASV level and the observed species were computed [43,44]. LEfSe analysis was utilized to determine species differences between groups. GeneCloud tools (https://www.genescloud.cn, accessed on 18 August 2022) were used to conduct the LEfSe analysis. Utilizing the “vegan” R package, redundancy analysis (RDA) was performed [45]. 3. Results 3.1. Soil Physicochemical Properties Compared to the FWI and SWI treatments, the soil bulk density in the 10–20 cm layer for the BWI treatment was significantly higher, while the corresponding soil porosity was significantly lower (Figure 2). There were no significant variations in AP, AK, SM, or pH between all treatments. The SWI treatment had significantly higher concentrations of EC, K+, Na+, Mg2+, Cl−, SO42−, and SAR compared to the FWI and BWI treatments, although there were no appreciable variations in EC and K+ between the FWI and BWI treatments. The SWI treatment had significantly higher TN, SOM, and SOC contents than the BWI treatment (Table 4). Figure 2. Comparison of bulk density (a) and porosity (b) in different layers (0–10 cm, 10–20 cm, and 20–30 cm) between the fresh (FWI), brackish (BWI), and salt (SWI) water irrigation treatments. Error bars represent standard errors. The different lower-case letters indicate significant differences between treatments (p < 0.05; Fisher’s LSD test). Table 4. Soil physicochemical characteristics (0–20 cm) of the cotton field under different irrigation water treatments. 3.2. Microbial Biomass and Enzymatic Activity The results indicate that the concentrations of MBC, MBN, urease, and sucrase were significantly higher in the BWI treatment compared to the FWI and SWI treatments (Figure 3). The order of concentrations was observed to be BWI > SWI > FWI. However, no significant differences were observed between the FWI and SWI treatments. The observed ratio of MBC/MBN in the FWI and SWI treatments was significantly higher than that in the BWI treatment (Figure 3c). Figure 3. Comparison of (a) soil microbial biomass carbon (MBC), (b) soil microbial biomass nitrogen (MBN), (c) MBC/MBN, (d) urease, and (e) sucrase between the fresh (FWI), brackish (BWI), and salt (SWI) water irrigation treatments. Error bars represent standard errors. The different lower-case letters indicate significant differences between treatments (p < 0.05; Fisher’s LSD test). 3.3. The Richness and Diversity of Bacterial and Fungal Communities A total of 25,315 bacterial ASVs were observed in the FWI, BWI, and SWI groups (Figure 4), with 2522 shared ASVs (9.96% of the total). The number of shared ASVs between FWI and BWI, FWI and SWI, and BWI and SWI was 1233, 1283, and 1378, respectively. In comparison, the proportion of ASVs in the BWI treatment (31.69%) was higher than that in the FWI and SWI treatments (31.54% and 26.81%, respectively). A total of 1505 fungal ASVs were obtained for the fungal community in the FWI, BWI, and SWI groups, and 203 of these ASVs (13.49% of the total) were shared. The number of shared ASVs between FWI and BWI, FWI and SWI, and BWI and SWI were 94, 60, and 90, respectively. In comparison to the FWI and SWI treatments, which had ASV proportions of 24.52% and 24.91%, respectively, the BWI had an ASV proportion of 37.08%. The Shannon indices and observed species of soil microorganisms were not significantly different between the FWI, BWI, and SWI treatments (Figure 5a,b). In comparison, the SWI treatment had the largest Shannon index for bacterial communities, and the BWI treatment had the largest Shannon index for fungal communities. The BWI treatment had the highest abundance of bacteria and fungi species (Figure 5a,b). The genus-level clustering of samples using nonmetric multidimensional scaling (NMDS) was analyzed (Figure 5c,d). The results indicated clear variation in the microbiota profiles between the FWI, BWI, and SWI treatments for bacteria (Figure 5c). For fungal microbiota profiles, the BWI and SWI treatments had similar microbiota profiles but were different from the FWI treatment (Figure 5d). Figure 4. Venn diagrams of bacterial ASV richness and fungal ASV richness. FWI, fresh water; BWI, brackish water; SWI, salt water. Figure 5. Comparison of the Shannon index and observed species of soil microbes between the fresh water, brackish water, and saline water treatment. (a) The Shannon index and observed species of bacteria; (b) the Shannon index and observed species of fungi; (c) NMDS of bacteria; (d) NMDS of fungi. The “p” indicates the K-W test at a significance level of 0.05. The “Stress” indicates the difference between the distance of a point in the 2-dimensional space and the distance of a point in the multi-dimensional space. 3.4. Microbial Community Composition The abundance of the main phyla in the FWI, BWI, and SWI treatments is illustrated in Figure 6a. All three of the FWI, BWI, and SWI treatments were predominated by the phyla Proteobacteria (44.31–50.11%), Actinobacteria (13.24–14.41%), Chloroflexi (10.03–12.84%), Acidobacteria (7.05–8.58%), Gemmatimonadetes (5.05–6.92%), and Firmicutes (2.60–3.22%), which accounted for more than 88.98% of the total reads in each library. The predominant fungal phyla of the FWI, BWI, and SWI treatments were Ascomycota (87.41–88.56%) and Basidiomycota (2.72–5.23%), which accounted for more than 91.29% of the total reads in each library (Figure 6c). Overall, changes in the dominant phylum (>10%) are more indicative of changes in the bacterial community in response to the environment [40]. In our study, the FWI treatment exhibited a higher abundance of the bacterial phyla Proteobacteria and Actinobacteria compared to the BWI and SWI treatments. Additionally, the Chloroflexi abundance was observed to be the lowest in the FWI treatment and the highest in the BWI treatment out of all the treatments (Figure 6b). In comparison to the FWI and SWI treatments, the BWI treatment had a higher abundance of the fungal phylum Ascomycota (Figure 6d). Figure 6. Distribution of the top 10 soil bacterial phyla (a,b) and fungal phyla (c,d) in different treatments. 3.5. Analysis of Biomarkers in Microbial Communities In order to find high-dimensional biomarker taxa with statistically differing abundances across all treatments, LEfSe analysis from the phylum to genus levels was carried out (Figure 7 and Figure 8). Regarding the bacterial communities, a total of 35 bacterial biomarker taxa presented significant differences, and 3, 9, and 23 biomarker taxa were enriched in FWI, BWI, and SWI, respectively (Figure 7b). Actinobacteria (class), Micrococcaceae (family), and Nitrosomonadaceae (family) were the three most abundant biomarkers in FWI soils. The relative abundances of Chloroflexi (phylum), Dehalococcoidia (class), and A4b (family) were especially enriched in BWI soils. In addition, the three most abundant biomarkers of SWI soils were Acidobacteria (phylum), Deltaproteobacteria (class), and Rhodovibrionales (order). Figure 7. The LEfSe method utilizing linear discriminant analysis was employed to detect statistically significant variations in the abundance of bacterial taxa across all treatments. (a) Taxonomic representation of important variations among groups shown in the cladogram. (b) LDA scores histogram. Figure 8. The LEfSe method utilizing linear discriminant analysis was employed to detect statistically significant variations in the abundance of fungal taxa across all treatments. (a) Taxonomic representation of important variations among groups shown in the cladogram. (b) LDA scores histogram. For the fungal communities, a total of 49 fungal biomarker taxa presented significant differences, and 27, 13, and 9 biomarker taxa were enriched in FWI, BWI, and SWI, respectively (Figure 8b). The three most abundant biomarkers in FWI soils were Dothideomycetes (class), Capnodiales (order), and Mycosphaerellaceae (family). The relative abundances of Microascales_fam_Incertae_sedis (family), Tricharina (genus), and Wardomyces (genus) were primarily changed in BWI soils. In addition, Basidiomycota (phylum), Tremellomycetes (class), and Cephalotrichum (genus) were the three most abundant biomarkers in SWI soils. In this study, LEfSe analysis indicated that the number of bacterial biomarkers gradually increased with increasing total dissolved solids in irrigation water, while the number of fungal biomarkers gradually decreased. 3.6. Correlation Analysis of Yield Index with Soil Physicochemical Properties and Microbial Community Redundancy analysis (RDA) identifies the relationship between community structure and environmental factors (Figure 9). Axis 1 and axis 2 explained 77.19% and 11.06% of the total variation in the bacterial community structure, respectively. The alteration in the structure of the bacterial communities exhibited a strong correlation with SAR (F = 4.6, p = 0.038, Explain% = 34.9%) (Figure 9a). For the structure of the fungal community, axis 1 and axis 2 explained 84.61% and 13.38% of the total variation, respectively. The alteration in the structure of the fungal communities exhibited a strong correlation with EC (F = 12.9, p = 0.028, Explain% = 11.9%) and BD (F = 6.0, p = 0.038, Explain% = 28.2%) (Figure 9b). Figure 9. RDA ordination diagram for soil indicators and bacterial community structure (a) and fungal community structure (b). Abbreviations are BD, bulk density; SOM, soil organic matter; SOC, soil organic carbon; TN, total nitrogen; SAR, sodium adsorption ratio; SM, soil moisture content; MBC/MBN, the ratio of microbial biomass carbon to microbial biomass nitrogen. FWI1, FWI2, FWI3 are the three samples for the FWI treatment, and the same three samples are included in the BWI and SWI treatments. The results of the correlation analysis of cotton yield, soil physicochemical properties, microbial abundance, and microbial diversity are shown in Figure 10. The statistical analysis revealed that there was no statistically significant correlation between the cotton yield and the observed bacterial species. In contrast, cotton yield was significantly and positively correlated with the observed species of fungi, while it was significantly and negatively correlated with EC (Figure 10 and Figure S2). The BWI treatment had the highest seed cotton yield and dry matter (Figure S3). The observed species of fungi were significantly and negatively correlated with EC. In addition, SAR was significantly and positively correlated with EC. Figure 10. Results of the correlation analysis between cotton yield, microbial community characteristics, and soil physicochemical properties. BOS, bacterial observed species; BSI, bacterial Shannon indices; FOS, fungal observed species; FSI, fungal Shannon index. The correlation values are mapped by the color of the heat map: the darker the shade of blue, the stronger the negative correlation, and the closer the color to white, the stronger the positive correlation. * means p < 0.05. The thickness of the line between the three nodes and each environmental factor indicates the magnitude of the correlation: the thicker the line, the stronger the correlation, and the weaker, the opposite. The color of the line between the node and the environmental factor indicates the p-value. 4. Discussion 4.1. Effect of Saline Water Irrigation on Physicochemical Characteristics and Biological Properties of Soil In this research, the data revealed a significant difference in soil Na+, Mg2+, HCO3−, Cl−, SO42−, and SAR between the different treatments (Table 4). The SWI treatment had higher salt and salt ion contents than the other treatments, which was mainly due to the high salt content of the irrigation water. These results are in line with the findings of Zhang et al. [46] Soil bulk and porosity can be altered by the accumulation of soil salts due to saline irrigation [47]. Therefore, BD was highest in the BWI treatment in the 10–20 cm soil layer (p < 0.05) (Figure 2). The significantly higher concentrations of MBC, MBN, urease, and sucrase in the BWI treatment (Figure 3) indicate that brackish water (3 g L−1) application may also have positive effects on microbial biomass and enzymatic activity. However, there were no significant differences in MBC, MBN, urease, and sucrase between the FWI and SWI treatments. Our findings are inconsistent with the results of Singh [48], who found that the values of microbial biomass and potential soil enzyme activity generally decreased as soil salinity and alkalinity increased. This may be attributed to alterations in the makeup of the microbial community in the long-term saline stress environment, and the salt-tolerant microorganisms had a better living environment under the BWI treatment conditions, resulting in higher MBC, MBN, urease, and sucrase contents in the BWI treatment. Microorganisms are the main providers of soil enzymes under stress from saline irrigation, with a consequent decrease in soil enzyme synthesis [48,49]; however, the BWI treatment in this study had the highest bacterial and fungal richness and, therefore, the BWI had higher enzyme activity. Zahran [50] also noted that the activity of soil enzymes produced by salt-tolerant bacteria is higher than the corresponding activity of soil enzymes produced by non-salt-tolerant bacteria, so higher soil enzyme activity may still be present in the soil even under high-salinity water irrigation conditions. On the other hand, plant roots can also secrete soil enzymes, and root secretions and organic carbon input from above-ground plants also provide nutrients for soil enzymes [51]. The BWI treatment in our study had the highest yield and biomass and, therefore, may have produced more root secretions (Figure S3). The enzyme activity of various soils and enzymes can vary significantly [52]. Rath and Rousk [53] also noted that the carbon content of microbial biomass stored in soil organic matter does not exhibit a consistent relationship with salinity levels. 4.2. Effect of Irrigation with Saline Water on Bacterial and Fungal Communities The activity of microorganisms is the primary factor driving the cycling of soil nutrients [54]. The results of our study showed that the Shannon indices and observed species were not significantly different between the FWI, BWI, and SWI treatments (Figure 5a,b). This demonstrates that the increased salinity of irrigation water has no significant effect on the diversity and abundance of microbial communities under long-term irrigation conditions. Our findings are in accordance with those of Hu et al. [19], who discovered no appreciable variations in the microbial Shannon indices between cotton fields watered with freshwater drip for 10 years and those irrigated with brackish water. Yan and Marschner [55] found that microbial growth in various soils exhibited varying responses to increasing salinity in the field. The impact of brackish water usage on microbial community abundance and diversity may be attributed to the final salinity level, rather than the salinity at the beginning. As a result of continuous saline water sub-membrane drip irrigation [56], soil salinity was at a higher level (1.03 ms cm−1–3.18 ms cm−1) under the BWI and SWI treatment conditions (Table 4). In addition, the amount of irrigation for film-covered drip irrigation is relatively low, and strong evaporation causes salt to accumulate on the surface. Flood irrigation in the winter is carried out every year in November-December to eliminate salt from the cotton plants’ roots. Approximately 4000 m3/ha of winter irrigation water is used annually. Flood irrigation is also an important factor affecting microbial community diversity and abundance. The Venn diagrams of microbial community ASV richness (Figure 4a,b) and the observed species of soil bacteria and fungi (Figure 5a,b) further show that the microbial communities’ abundance in the BWI treatment exhibited a higher level compared to the FWI and SWI treatments. One possible reason is that brackish water contains some trace elements that can stimulate crop growth [57]. If the initial soil salinity is relatively low, generally, the first 1–3 years of brackish water irrigation may be more beneficial to crop growth than freshwater irrigation, and crops will have more developed root systems compared with FWI and SWI treatments [7,58,59]. Root exudates are the key factors that regulate the vitality and function of rhizosphere micro-ecosystems. Under stress, many plants can actively or passively release various chemical substances from their roots into the environment, and the number and type of root exudates will increase. Different types of root secretions are key factors in determining the type and number of rhizosphere microorganisms, ultimately influencing their growth, reproduction, and metabolic activities [60,61]. The results of our investigation showed that the microorganisms exhibited varying responses to irrigation with freshwater, brackish water, and saltwater (Figure 6). The results indicated clear variation in the microbiota profiles between the FWI, BWI, and SWI treatments for bacteria (Figure 5c). Regarding the fungal microbiota profiles, the BWI and SWI treatments had similar microbiota profiles but were different from the FWI treatment (Figure 5d). This is mostly due to the fact that different irrigation treatments altered the soil conditions (Table 4), which, in turn, impacted the distribution of the microorganism community. Members of the microbial phylum have various adaptations to different soil conditions [62,63,64,65]. High-salt environments can adversely affect microbes, such as by reducing their respiration and growth [66]. However, organisms can change their physiology by producing osmolytes and altering the structure of cell membranes [47]. Microbes can adapt physiologically to minimize some of the harmful consequences of salinity [67]. The most dominant bacterial phylum in our study is consistent with the dominant phylum in the studies of Ma and Gong [68] and Guo et al. [45]. Saline water irrigation resulted in an elevation in the bacterial abundance of the phylum Chloroflexi and a decline in that of Proteobacteria and Actinobacteria (Figure 6b). This was mainly because the phylum Chloroflexi is generally found in hypersaline environments, while Proteobacteria and Actinobacteria were found only in moderate and low-salinity environments [69]. Proteobacteria, Actinobacteria, and Chloroflexi are the most prevalent halophilic bacteria in saline soils [68]. Regarding the fungal communities, the most prevalent fungal phyla are consistent with prior research on agricultural soils, as reported by Pan et al. [70] and Muneer et al. [71]. Ascomycota represent the most prevalent and varied phylum of eukaryotic organisms, exhibiting abilities in the process of organic substrate decomposition [72]. In comparison to the FWI and SWI treatments, the BWI treatment soil samples had a higher abundance of the fungal phylum Ascomycota (Figure 6d). One possible reason for this is that Ascomycota decrease with increasing organic matter content [73], and the content of soil SOM and SOC under the BWI treatment conditions was the lowest compared to the FWI and SWI treatments (Table 4). In our study, the LEfSe analysis revealed that the microorganisms exhibited significant variation in response to changes in the total dissolved solids content of the irrigation water. The number of bacterial biomarkers gradually increased with increasing total dissolved solids in water, while the number of fungal biomarkers gradually decreased. The primary reason for this phenomenon is the adaptive capacity of soil microbes to external environmental changes, with fungi being more tolerant of salinity than bacteria [74]. Zheng et al. [75] noted that high salinity can enhance microbial interactions. The community’s composition change, resulting in the replacement of less-adapted species by better-adapted ones, is a significant factor that influences the changing distribution of tolerant features within communities [76,77]. The specific bacterial taxa whose relative abundance increased with community salt tolerance might be employed as indicators for high community salt tolerance [45,78]. 4.3. Relationship between Microorganisms and Soil Physicochemical Properties The results of our experiment showed that SAR significantly alters the makeup of bacterial community structure (Figure 9a). This is inconsistent with the results of Tong et al. [79], who observed that soil salt concentration is the primary factor regulating soil microbial diversity and soil microbiome formation and that soil microbial diversity varied with soil salt contents. Dong et al. [18] also revealed that bacterial abundance was not significantly impacted by salinity; however, it was identified as the primary factor responsible for the alteration in bacterial community composition, leading to a notable decline in microbial activity. However, the correlation between the microbial species and salt ions exhibited complexity and ion specificity [80], and the potential effects of soil salinity on soil microbial communities are not detailed enough to be represented by EC gradients or total dissolved solids. The study conducted by Hu et al. [19] involved an analysis of correlations between pivotal species, EC, and salinity ions in brackish and freshwater-irrigated cotton fields. The findings revealed that, apart from the overall impact of EC, distinct major ions exhibited varying correlations with soil microbial pivotal species. This indicates the importance of identifying ion-specific soil microbial species, which supports our finding that SAR is the primary factor accounting for alterations in bacterial community structure. Additionally, the RDA analysis indicated that soil EC and BD significantly impacted the composition of the fungal community (Figure 9b). This finding is in accordance with earlier research that suggested salinity, moisture, and porosity may play a crucial role in regulating the makeup of microbial communities. Fungi may benefit from exchangeable ions provided to the soil by high salinity, and some fungal species under high salinity conditions can increase the absorption of various ions while reducing the transport of certain toxic ions [81,82,83]. We also found that EC had a strong relationship with the observed species of fungi (Figure 10). The observed species of fungi were significantly and positively connected with cotton production, indicating that they are important for improving cotton yield. This is most likely related to the fact that fungi have a decomposing effect on plant material. In the study area, cotton straw residues were shredded and returned to the field each year. In general, fungi are thought to be the primary organisms that break down plant matter [84]. This is attributed to their capacity to decompose both organic materials that are readily degradable (e.g., cellulose) and those that are resistant to degradation (e.g., polyphenols) by making a range of external depolymerizing enzymes [85]. Zhang et al. [86] noted that there was a significant correlation between the number of fungi and the dry weight of plants, indicating that plant productivity had an impact on fungal abundance. Chen et al. [87] also found that soil fungi utilize straw more efficiently than soil bacteria, which gives them a significant competitive advantage. Cotton production was significantly and negatively correlated with EC. This is consistent with previous studies [88]. 5. Conclusions In conclusion, irrigation with saline water of different salinity levels increased soil salinity and SAR but had no significant effect on the diversity and abundance of bacteria and fungi. SAR regulated the structure of the bacterial community, whereas salinity and porosity regulated the structure of the fungal community. The microbial community structure was altered. The number of bacterial biomarkers gradually increased with increasing total dissolved solids in irrigation water, while the number of fungal biomarkers gradually decreased. Soil microorganisms can adapt to changes in a high-salt environment after a prolonged period of irrigation with saline water. Future research should explore the process of changes in the functional groups of microorganisms under saline water irrigation and screen for functional genes for salt tolerance, which are important for the improved use of saline alkali soils and the growth of salt-tolerant plants. Supplementary Materials The following supporting information can be downloaded at: https://www.mdpi.com/article/10.3390/agronomy13071679/s1, Table S1: The irrigation schedule in the growing seasons of 2019, 2020, and 2021; Figure S1: Schematic diagram of cotton planting; Figure S2: Results of the correlation analysis between seed cotton yield and fungal observed species and EC; Figure S3: Comparison of seed cotton yield and dry matter between the fresh (FWI), brackish (BWI), and salt (SWI) irrigation water treatments. Author Contributions Conceptualization, Y.B. and H.C.; methodology, Y.B., S.G. and H.C.; formal analysis, B.D.; investigation, B.D., S.G., Z.H., H.L. and J.Z.; writing—original draft, B.D.; project administration, B.W.; funding acquisition, Y.B. and H.C. All authors have read and agreed to the published version of the manuscript. Funding This study was supported by the Natural Science Foundation of China (52269017, 52179047). The National Key Research and Development Program of China (2022YFD190010404). Tianshan Talent Project, Xinjiang Uygur Autonomous Region, China (2022TSYCLJ0069). Data Availability Statement The datasets used in the current study are available from the corresponding author on reasonable request. DNA sequencing data were deposited in the NCBI Sequence Read Archive and can be accessed using the accession number SRP353419. Conflicts of Interest The authors declare no conflict of interest. References Lambers, H. Introduction, dryland salinity: A key environmental issue in southern Australia. Plant Soil 2003, 257, 5–7. [Google Scholar] [CrossRef] Chen, W.; Jin, M.; Ferré, T.P.A.; Liu, Y.; Xian, Y.; Shan, T.; Ping, X. Spatial distribution of soil moisture, soil salinity, and root density beneath a cotton field under mulched drip irrigation with brackish and fresh water. Field Crop. Res. 2018, 215, 207–221. [Google Scholar] [CrossRef] Li, X.; Jin, M.; Zhou, N.; Huang, J.; Jiang, S.; Telesphore, H. Evaluation of evapotranspiration and deep percolation under mulched drip irrigation in an oasis of Tarim basin, China. J. Hydrol. 2016, 538, 677–688. [Google Scholar] [CrossRef] [Green Version] Wang, R.; Kang, Y.; Wan, S.; Hu, W.; Liu, S.; Liu, S. Salt distribution and the growth of cotton under different drip irrigation regimes in a saline area. Agric. Water Manag. 2011, 100, 58–69. [Google Scholar] [CrossRef] Cheng, M.; Wang, H.; Fan, J.; Wang, X.; Sun, X.; Yang, L.; Zhang, S.; Xiang, Y.; Zhang, F. Crop yield and water productivity under salty water irrigation: A global meta-analysis. Agric. Water Manag. 2021, 256, 107105. [Google Scholar] [CrossRef] Chunxia, W.; Guang, Y.; Junfeng, L.; Xinlin, H.; Lianqing, X.; Aihua, L. Effects of timing and duration under brackish water mulch drip irrigation on cotton yield in northern Xinjiang, China. Int. J. Agric. Biol. Eng. 2017, 10, 115–122. [Google Scholar] [CrossRef] Yang, G.; Li, F.; Tian, L.; He, X.; Gao, Y.; Wang, Z.; Ren, F. Soil physicochemical properties and cotton (Gossypium hirsutum L.) yield under brackish water mulched drip irrigation. Soil Tillage Res. 2020, 199, 104592. [Google Scholar] [CrossRef] Gong, X.; Liu, C.; Li, J.; Luo, Y.; Yang, Q.; Zhang, W.; Yang, P.; Feng, B. Responses of rhizosphere soil properties, enzyme activities and microbial diversity to intercropping patterns on the Loess Plateau of China. Soil Tillage Res. 2019, 195, 104355. [Google Scholar] [CrossRef] Zhang, H.; Luo, G.; Wang, Y.; Fei, J.; Xiangmin, R.; Peng, J.; Tian, C.; Zhang, Y. Crop rotation-driven change in physicochemical properties regulates microbial diversity, dominant components, and community complexity in paddy soils. Agric. Ecosyst. Environ. 2023, 343, 108278. [Google Scholar] [CrossRef] Chen, J.; Liu, X.; Zheng, J.; Zhang, B.; Lu, H.; Chi, Z.; Pan, G.; Li, L.; Zheng, J.; Zhang, X.; et al. Biochar soil amendment increased bacterial but decreased fungal gene abundance with shifts in community structure in a slightly acid rice paddy from Southwest China. Appl. Soil Ecol. 2013, 71, 33–44. [Google Scholar] [CrossRef] Hall, R.M.; Penke, N.; Kriechbaum, M.; Kratschmer, S.; Jung, V.; Chollet, S.; Guernion, M.; Nicolai, A.; Burel, F.; Fertil, A.; et al. Vegetation management intensity and landscape diversity alter plant species richness, functional traits and community composition across European vineyards. Agr. Syst. 2020, 177, 102706. [Google Scholar] [CrossRef] Liu, H.; Xu, W.; Li, J.; Yu, Z.; Zeng, Q.; Tan, W.; Mi, W. Short-term effect of manure and straw application on bacterial and fungal community compositions and abundances in an acidic paddy soil. J. Soils Sediments 2021, 21, 3057–3071. [Google Scholar] [CrossRef] Selim, T.; Berndtsson, R.; Persson, M.; Somaida, M.; El-Kiki, M.; Hamed, Y.; Mirdan, A.; Zhou, Q. Influence of geometric design of alternate partial root-zone subsurface drip irrigation (APRSDI) with brackish water on soil moisture and salinity distribution. Agric. Water Manag. 2012, 103, 182–190. [Google Scholar] [CrossRef] Li, X.; Jin, M.; Huang, J.; Yuan, J. The soil–water flow system beneath a cotton field in arid north-west China, serviced by mulched drip irrigation using brackish water. Hydrogeol. J. 2015, 23, 35–46. [Google Scholar] [CrossRef] Qi, Z.; Feng, H.; Zhao, Y.; Zhang, T.; Yang, A.; Zhang, Z. Spatial distribution and simulation of soil moisture and salinity under mulched drip irrigation combined with tillage in an arid saline irrigation district, northwest China. Agric. Water Manag. 2018, 201, 219–231. [Google Scholar] [CrossRef] Wang, R.; Wan, S.; Sun, J.; Xiao, H. Soil salinity, sodicity and cotton yield parameters under different drip irrigation regimes during saline wasteland reclamation. Agric. Water Manag. 2018, 209, 20–31. [Google Scholar] [CrossRef] Wichern, J.; Wichern, F.; Joergensen, R.G. Impact of salinity on soil microbial communities and the decomposition of maize in acidic soils. Geoderma 2006, 137, 100–108. [Google Scholar] [CrossRef] Dong, Y.; Zhang, J.; Chen, R.; Zhong, L.; Lin, X.; Feng, Y. Microbial community composition and activity in saline soils of coastal agro-ecosystems. Microorganisms 2022, 10, 835–846. [Google Scholar] [CrossRef] [PubMed] Hu, Y.; Li, X.; Jin, M.; Wang, R.; Chen, J.; Guo, S. Reduced co-occurrence and ion-specific preferences of soil microbial hub species after ten years of irrigation with brackish water. Soil Tillage Res. 2020, 199, 104599. [Google Scholar] [CrossRef] Chowdhury, N.; Nakatani, A.S.; Setia, R.; Marschner, P. Microbial activity and community composition in saline and non-saline soils exposed to multiple drying and rewetting events. Plant Soil 2011, 348, 103–113. [Google Scholar] [CrossRef] Chaudhry, V.; Rehman, A.; Mishra, A.; Chauhan, P.S.; Nautiyal, C.S. Changes in bacterial community structure of agricultural land due to long-term organic and chemical amendments. Microb. Ecol. 2012, 64, 450–460. [Google Scholar] [CrossRef] Yan, N.; Marschner, P. Response of soil respiration and microbial biomass to changing EC in saline soils. Soil Biol. Biochem. 2013, 65, 322–328. [Google Scholar] [CrossRef] Zhalnina, K.; Dias, R.; de Quadros, P.D.; Davis-Richardson, A.; Camargo, F.A.O.; Clark, I.M.; McGrath, S.P.; Hirsch, P.R.; Triplett, E.W. Soil pH Determines Microbial Diversity and Composition in the Park Grass Experiment. Microb. Ecol. 2015, 69, 395–406. [Google Scholar] [CrossRef] [PubMed] Soman, C.; Li, D.; Wander, M.M.; Kent, A.D. Long-term fertilizer and crop-rotation treatments differentially affect soil bacterial community structure. Plant Soil 2017, 413, 145–159. [Google Scholar] [CrossRef] Zhang, K.; Shi, Y.; Cui, X.; Yue, P.; Li, K.; Liu, X.; Tripathi, B.M.; Chu, H.; Lozupone, C. Salinity is a key determinant for soil microbial communities in a desert ecosystem. mSystems 2019, 4, e218–e225. [Google Scholar] [CrossRef] [PubMed] [Green Version] Oren, A. The bioenergetic basis for the decrease in metabolic diversity at increasing salt concentrations: Implications for the functioning of salt lake ecosystems. Hydrobiologia 2001, 466, 61–72. [Google Scholar] [CrossRef] Rousk, J.; Bååth, E.; Brookes, P.C.; Lauber, C.L.; Lozupone, C.; Caporaso, J.G.; Knight, R.; Fierer, N. Soil bacterial and fungal communities across a pH gradient in arable soil. ISME J. 2010, 4, 1340–1351. [Google Scholar] [CrossRef] Kabiri, V.; Raiesi, F.; Ghazavi, M.A. Tillage effects on soil microbial biomass, SOM mineralization and enzyme activity in semi-arid Calcixerepts. Agric. Ecosyst. Environ. 2016, 232, 73–84. [Google Scholar] [CrossRef] Yang, P.; Zia-Khan, S.; Wei, G.; Zhong, R.; Aguila, M. Winter Irrigation Effects in Cotton Fields in Arid Inland Irrigated Areas in the North of the Tarim Basin, China. Water 2016, 8, 47. [Google Scholar] [CrossRef] [Green Version] Liang, J.; Li, Y.; Si, B.; Wang, Y.; Chen, X.; Wang, X.; Chen, H.; Wang, H.; Zhang, F.; Bai, Y.; et al. Optimizing biochar application to improve soil physical and hydraulic properties in saline-alkali soils. Sci. Total Environ. 2021, 771, 144802. [Google Scholar] [CrossRef] Carter, D.L.; Mortland, M.M.; Kemper, W.D. Methods of Soil Analysis Part I: Physical and Mineralogical Methods; Amer Society of Agronomy: Madison, WI, USA, 1986. [Google Scholar] Bao, S.D. Soil Agricultural Chemistry Analysis; Agriculture Press: Beijing, China, 1999. [Google Scholar] Gillman, G.P.; Sumpter, E.A. Modification to the compulsive exchange method for measuring exchange characteristics of soils. Aust. J. Soil. Res. 1986, 24, 61–66. [Google Scholar] [CrossRef] Brady, N.C.; Weil, R.R.; Brady, N.C. Elements of Nature and Properties of Soils; Prentice Hall: Hoboken, NJ, USA, 2000. [Google Scholar] Yan, M.; Li, T.; Li, X.; Liu, Y.; Zhang, J. Microbial biomass and activity restrict soil function recovery of a post-mining land in eastern Loess Plateau. Catena 2021, 199, 105107. [Google Scholar] [CrossRef] Caporaso, J.G.; Lauber, C.L.; Walters, W.A.; Berg-Lyons, D.; Lozupone, C.A.; Turnbaugh, P.J.; Fierer, N.; Gordon, K. Supplement 1: Microbes and Health || Global patterns of 16S rRNA diversity at a depth of millions of sequences per sample. Proc. Natl. Acad. Sci. USA 2011, 108, 4516–4522. [Google Scholar] [CrossRef] [Green Version] Liang, J.; He, Z.; Shi, W. Cotton/mung bean intercropping improves crop productivity, water use efficiency, nitrogen uptake, and economic benefits in the arid area of Northwest China. Agric. Water Manag. 2020, 240, 106277. [Google Scholar] [CrossRef] Li, Y.; Yao, N.; Liang, J.; Wang, X.; Niu, B.; Jia, Y.; Jiang, F.; Yu, Q.; Liu, D.L.; Feng, H.; et al. Rational biochar application rate for cotton nutrient content, growth, yields, productivity, and economic benefits under film-mulched trickle irrigation. Agric. Water Manag. 2023, 276, 108079. [Google Scholar] [CrossRef] Liang, J.; Shi, W. Cotton/halophytes intercropping decreases salt accumulation and improves soil physicochemical properties and crop productivity in saline-alkali soils under mulched drip irrigation: A three-year field experiment. Field Crop. Res. 2021, 262, 108027. [Google Scholar] [CrossRef] Bellemain, E.; Carlsen, T.; Brochmann, C.; Coissac, E.; Kauserud, H. Its as an environmental DNA barcode for fungi: An in silico approach reveals potential PCR biases. BMC Microbiol. 2010, 10, 189–198. [Google Scholar] [CrossRef] [PubMed] [Green Version] Bolyen, E.; Rideout, J.R.; Dillon, M.R.; Bokulich, N.A.; Caporaso, J.G. QIIME 2: Reproducible, interactive, scalable, and extensible microbiome data science. PeerJ 2018, 25, 16–70. [Google Scholar] [CrossRef] [PubMed] Martin, M. Cutadapt removes adapter sequences from high-throughput sequencing reads. EMBnet. J. 2011, 17, 11–12. [Google Scholar] [CrossRef] Callahan, B.J.; Mcmurdie, P.J.; Rosen, M.J.; Han, A.W.; Johnson, A.; Holmes, S.P. DADA2: High-resolution sample inference from Illumina amplicon data. Nat. Methods 2016, 13, 581–583. [Google Scholar] [CrossRef] [Green Version] Bokulich, N.A.; Kaehler, B.D.; Ram, R.J.; Matthew, D.; Evan, B.; Rob, K.; Huttley, G.A.; Gregory, C.J. Optimizing taxonomic classification of marker-gene amplicon sequences with QIIME 2′s q2-feature-classifier plugin. Microbiome 2018, 6, 90. [Google Scholar] [CrossRef] Guo, H.; Shi, X.; Ma, L.; Yang, T.; Min, W. Long-term irrigation with saline water decreases soil nutrients, diversity of bacterial communities, and cotton yields in a gray desert soil in China. Pol. J. Environ. Stud. 2020, 29, 4077–4088. [Google Scholar] [CrossRef] Zhang, A.; Zheng, C.; Li, K.; Dang, H.; Cao, C.; Rahma, A.E.; Zhang, J.; Feng, D. Responses of soil water-salt variation and cotton growth to drip irrigation with saline water in the low plain near the Bohai Sea. Irrig. Drain. 2020, 69, 448–459. [Google Scholar] [CrossRef] Li, X.; Jin, M.; Zhou, N.; Jiang, S.; Hu, Y. Inter-dripper variation of soil water and salt in a mulched drip irrigated cotton field: Advantages of 3-D modelling. Soil Tillage Res. 2018, 184, 186–194. [Google Scholar] [CrossRef] Singh, K. Microbial and enzyme activities of saline and sodic soils. Land Degrad. Dev. 2015, 27, 706–718. [Google Scholar] [CrossRef] Doongar, R.; Chaudhary, A.P.; Rathore, B.J. Effects of seawater irrigation on soil microbial community structure and physiological function. Int. J. Environ. Sci. Technol. 2016, 13, 2199–2208. [Google Scholar] [CrossRef] [Green Version] Zahran, H.H. Diversity, adaptation and activity of the bacterial flora in saline environments. Biol. Fertil. Soils 1997, 25, 211–223. [Google Scholar] [CrossRef] Zhai, H.; Cao, C.; Liu, M. Effects of long-term brackish water irrigation on soil enzyme activity and reaction kinetics. Agric. Water Manag. 2018, 36, 95–101, (In Chinese with English Abstract). [Google Scholar] [CrossRef] Bowles, T.M.; Acosta-Martínez, V.; Calderón, F.; Jackson, L.E. Soil enzyme activities, microbial communities, and carbon and nitrogen availability in organic agroecosystems across an intensively-managed agricultural landscape. Soil Biol. Biochem. 2014, 68, 252–262. [Google Scholar] [CrossRef] Rath, K.M.; Rousk, J. Salt effects on the soil microbial decomposer community and their role in organic carbon cycling: A review. Soil Biol. Biochem. 2015, 81, 108–123. [Google Scholar] [CrossRef] Wang, Y.; Liu, L.; Yang, J.; Duan, Y.; Luo, Y.; Taherzadeh, M.J.; Li, Y.; Li, H.; Awasthi, M.K.; Zhao, Z. The diversity of microbial community and function varied in response to different agricultural residues composting. Sci. Total Environ. 2020, 715, 136983. [Google Scholar] [CrossRef] Yan, N.; Marschner, P. Response of microbial activity and biomass to increasing salinity depends on the final salinity, not the original salinity. Soil Biol. Biochem. 2012, 53, 50–55. [Google Scholar] [CrossRef] He, H.; Wang, Z.; Guo, L.; Zheng, X.; Zhang, J.; Li, W.; Fan, B. Distribution characteristics of residual film over a cotton field under long-term film mulching and drip irrigation in an oasis agroecosystem. Soil Tillage Res. 2018, 180, 194–203. [Google Scholar] [CrossRef] Wang, Q.; Shan, Y. Review of research development on water and soil regulation with brackish water irrigation. J. Agric. Mach. 2015, 46, 117–126. [Google Scholar] [CrossRef] Chen, W.; Jin, M.; Ferré, T.P.A.; Liu, Y.; Huang, J.; Xian, Y. Soil conditions affect cotton root distribution and cotton yield under mulched drip irrigation. Field Crop. Res. 2020, 249, 107743. [Google Scholar] [CrossRef] Singh, G.; Mukerji, K. Root Exudates as Determinant of Rhizospheric Microbial Biodiversity. In Microbial Activity in the Rhizoshere; Mukerji, K.G., Manoharachary, C., Eds.; Springer: Berlin/Heidelberg, Germany, 2006. [Google Scholar] Gao, Y.; Cui, J.; Ren, G.; Wei, S.; Yang, P.; Yin, C.; Liang, H.; Chang, J. Changes in the root-associated bacteria of sorghum are driven by the combined effects of salt and sorghum development. Environ. Microbiome 2021, 16, 14. [Google Scholar] [CrossRef] [PubMed] Eisenhauer, N.; Scheu, S.; Jousset, A. Bacterial diversity stabilizes community productivity. PLoS ONE 2012, 7, e34517. [Google Scholar] [CrossRef] [PubMed] [Green Version] Naether, A.; Foesel, B.U.; Naegele, V.; Wust, P.K.; Weinert, J.; Bonkowski, M.; Alt, F.; Oelmann, Y.; Polle, A.; Lohaus, G. Environmental factors affect Acidobacterial communities below the subgroup level in grassland and forest soils. Appl. Environ. Microb. 2012, 78, 7398. [Google Scholar] [CrossRef] [Green Version] Yin, C.; Hulbert, S.H.; Schroeder, K.L.; Mavrodi, O.; Mavrodi, D.; Dhingra, A.; Schillinger, W.F.; Paulitz, T.C. Role of Bacterial Communities in the Natural Suppression of Rhizoctonia solani Bare Patch Disease of Wheat (Triticum aestivum L.). Appl. Environ. Microb. 2013, 79, 7428–7438. [Google Scholar] [CrossRef] [Green Version] Paungfoo-Lonhienne, C.; Yeoh, Y.K.; Kasinadhuni, N.; Lonhienne, T.; Robinson, N.; Hugenholtz, P.; Ragan, M.A.; Schmidt, S. Nitrogen fertilizer dose alters fungal communities in sugarcane soil and rhizosphere. Sci. Rep. 2015, 5, 8678. [Google Scholar] [CrossRef] [Green Version] Couturier, M.; Tangthirasunun, N.; Xie, N.; Brun, S.; Berrin, J.G. Plant biomass degrading ability of the coprophilic ascomycete fungus Podospora anserina. Biotechnol. Adv. 2016, 34, 976–983. [Google Scholar] [CrossRef] Setia, R.; Marschner, P.; Baldock, J.; Chittleborough, D.; Smith, P.; Smith, J. Salinity effects on carbon mineralization in soils of varying texture. Soil Biol. Biochem. 2011, 43, 1908–1916. [Google Scholar] [CrossRef] Kakumanu, M.L.; Williams, M.A. Osmolyte dynamics and microbial communities vary in response to osmotic more than matric water deficit gradients in two soils. Soil Biol. Biochem. 2014, 79, 14–24. [Google Scholar] [CrossRef] Ma, B.; Gong, J. A meta-analysis of the publicly available bacterial and archaeal sequence diversity in saline soils. World J. Microb. Biotechnol. 2013, 29, 2325–2334. [Google Scholar] [CrossRef] [PubMed] Valenzuela-Encinas, C.; Neria-Gonzalez, I.; Alcantara-Hernandez, R.J.; Estrada-Alvarado, I.; Zavala-Diaz, D.L.S.F.; Dendooven, L.; Marsch, R. Changes in the bacterial populations of the highly alkaline saline soil of the former lake Texcoco (Mexico) following flooding. Extremophiles 2009, 13, 609–621. [Google Scholar] [CrossRef] [PubMed] Pan, H.; Chen, M.; Feng, H.; Wei, M.; Song, F.; Lou, Y.; Cui, X.; Wang, H.; Zhuge, Y. Organic and inorganic fertilizers respectively drive bacterial and fungal community compositions in a fluvo-aquic soil in northern China. Soil Tillage Res. 2020, 198, 104540. [Google Scholar] [CrossRef] Muneer, M.A.; Huang, X.; Hou, W.; Zhang, Y.; Cai, Y.; Munir, M.Z.; Wu, L.; Zheng, C. Response of fungal diversity, community composition, and functions to nutrients management in red soil. J. Fungi 2021, 7, 554–572. [Google Scholar] [CrossRef] Huang, X.; Muneer, M.A.; Li, J.; Hou, W.; Ma, C.; Jiao, J.; Cai, Y.; Chen, X.; Wu, L.; Zheng, C. Integrated nutrient management significantly improves pomelo (citrus grandis) root growth and nutrients uptake under acidic soil of southern China. Agronomy 2021, 11, 1231. [Google Scholar] [CrossRef] Ding, J.; Jiang, X.; Guan, D.; Zhao, B.; Ma, M.; Zhou, B.; Cao, F.; Yang, X.; Li, L.; Li, J. Influence of inorganic fertilizer and organic manure application on fungal communities in a long-term field experiment of Chinese Mollisols. Appl. Soil Ecol. 2017, 111, 114–122. [Google Scholar] [CrossRef] Rath, K.M.; Maheshwari, A.; Bengtson, P.; Rousk, J. Comparative Toxicities of Salts on Microbial Processes in Soil. Appl. Environ. Microb. 2016, 82, 2012–2020. [Google Scholar] [CrossRef] [Green Version] Zheng, W.; Xue, D.; Li, X.; Deng, Y.; Rui, J.; Feng, K.; Wang, Z. The responses and adaptations of microbial communities to salinity in farmland soils: A molecular ecological network analysis. Appl. Soil Ecol. 2017, 120, 239–246. [Google Scholar] [CrossRef] Lau, J.A.; Lennon, J.T. Rapid responses of soil microorganisms improve plant fitness in novel environments. Proc. Natl. Acad. Sci. USA 2012, 109, 14058–14062. [Google Scholar] [CrossRef] [PubMed] [Green Version] Shade, A.; Peter, H.; Allison, S.D.; Baho, D.L.; Berga, M.; Bürgmann, H.; Huber, D.H.; Langenheder, S.; Lennon, J.T.; Martiny, J.B.H.; et al. Fundamentals of microbial community resistance and resilience. Front. Microbiol. 2012, 3, 417. [Google Scholar] [CrossRef] [PubMed] [Green Version] Rath, K.M.; Maheshwari, A.; Rousk, J. Linking Microbial Community Structure to Trait Distributions and Functions Using Salinity as an Environmental Filter. mBio 2019, 10, e1607–e1619. [Google Scholar] [CrossRef] [PubMed] [Green Version] Tong, H.; Lili, Y.; Cecilie, H.; Baojian, W.; Ji, C.; Li, Z.; Jiawen, Y.; Xinlin, H. Linking microbial community compositions to cotton nitrogen utilization along soil salinity gradients. Field Crop. Res. 2022, 288, 108697. [Google Scholar] [CrossRef] Zhou, Z.; Hua, J.; Xue, J. Salinity drives shifts in soil microbial community composition and network complexity along vegetation community succession in coastal tidal flats. Estuar. Coast. Shelf Sci. 2022, 276, 108005. [Google Scholar] [CrossRef] Navarro, A.; Elia, A.; Conversa, G.; Campi, P.; Mastrorilli, M. Potted mycorrhizal carnation plants and saline stress: Growth, quality and nutritional plant responses. Sci. Hortic. 2012, 140, 139–148. [Google Scholar] [CrossRef] Gómez-Bellot, M.J.; Ortuño, M.F.; Nortes, P.A.; Vicente-Sánchez, J.; Bañón, S.; Sánchez-Blanco, M.J. Mycorrhizal euonymus plants and reclaimed water: Biomass, water status and nutritional responses. Sci. Hortic. 2015, 186, 61–69. [Google Scholar] [CrossRef] Nie, S.; Lei, X.; Zhao, L.; Brookes, P.C.; Wang, F.; Chen, C.; Yang, W.; Xing, S. Fungal communities and functions response to long-term fertilization in paddy soils. Appl. Soil Ecol. 2018, 130, 251–258. [Google Scholar] [CrossRef] Fontaine, S.; Henault, C.; Aamor, A.; Bdioui, N.; Bloor, J.M.G.; Maire, V.; Mary, B.; Revaillot, S.; Maron, P.A. Fungi mediate long term sequestration of carbon and nitrogen in soil through their priming effect. Soil Biol. Biochem. 2011, 43, 86–96. [Google Scholar] [CrossRef] Swift, M.J.; Heal, O.W.; Anderson, J.M. Decomposition in terrestrial ecosystems. Stud. Ecol. 1979, 5, 2772–2774. [Google Scholar] [CrossRef] Zhang, X.; Fu, G.; Xing, S.; Fu, W.; Liu, X.; Wu, H.; Zhou, X.; Ma, Y.; Zhang, X.; Chen, B. Structure and diversity of fungal communities in long-term copper-contaminated agricultural soil. Sci. Total Environ. 2022, 806, 151302. [Google Scholar] [CrossRef] [PubMed] Chen, L.; Zhang, J.; Zhao, B.; Yan, P.; Zhou, G.; Xin, X. Effects of straw amendment and moisture on microbial communities in Chinese fluvo-aquic soil. J. Soils Sediments 2014, 14, 1829–1840. [Google Scholar] [CrossRef] Wei, K.; Zhang, J.; Wang, Q.; Guo, Y.; Mu, W. Irrigation with ionized brackish water affects cotton yield and water use efficiency. Ind. Crop. Prod. 2022, 175, 114244. [Google Scholar] [CrossRef]      Disclaimer/Publisher’s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.  © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Share and Cite MDPI and ACS Style Ding, B.; Bai, Y.; Guo, S.; He, Z.; Wang, B.; Liu, H.; Zhai, J.; Cao, H. Effect of Irrigation Water Salinity on Soil Characteristics and Microbial Communities in Cotton Fields in Southern Xinjiang, China. Agronomy 2023, 13, 1679. https://doi.org/10.3390/agronomy13071679 AMA Style Ding B, Bai Y, Guo S, He Z, Wang B, Liu H, Zhai J, Cao H. Effect of Irrigation Water Salinity on Soil Characteristics and Microbial Communities in Cotton Fields in Southern Xinjiang, China. Agronomy. 2023; 13(7):1679. https://doi.org/10.3390/agronomy13071679 Chicago/Turabian Style Ding, Bangxin, Yungang Bai, Shuchen Guo, Zijian He, Bei Wang, Hongbo Liu, Jiangrui Zhai, and Hongxia Cao. 2023. \"Effect of Irrigation Water Salinity on Soil Characteristics and Microbial Communities in Cotton Fields in Southern Xinjiang, China\" Agronomy 13, no. 7: 1679. https://doi.org/10.3390/agronomy13071679 Note that from the first issue of 2016, this journal uses article numbers instead of page numbers. See further details here. Article Metrics Citations Scopus   2 Crossref   2 Web of Science   1 Google Scholar   [click to view] Article Access Statistics Article access statistics Article Views 8. Jan 18. Jan 28. Jan 7. Feb 17. Feb 27. Feb 8. Mar 18. Mar 28. Mar 0 500 1000 1500 2000 For more information on the journal statistics, click here. Multiple requests from the same IP address are counted as one view.   Agronomy, EISSN 2073-4395, Published by MDPI RSS Content Alert Further Information Article Processing Charges Pay an Invoice Open Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors For Reviewers For Editors For Librarians For Publishers For Societies For Conference Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe to receive issue release notifications and newsletters from MDPI journals Select options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated Disclaimer Terms and Conditions Privacy Policy"

Paper 10:
- APA Citation: Salhi, M. S., Salhi, M., Touti, E., Zitouni, N., & Benzarti, F. (2024). On the Use of Wireless Sensor Nodes for Agricultural Smart Fault Detection. Wireless Personal Communications, 134(1), 95–117. https://doi.org/10.1007/s11277-024-10889-8
  Main Objective: The primary goal of this study was to develop a smart fault detection system for agricultural equipment and irrigation systems using wireless sensor nodes, blockchain technology, and deep learning.
  Study Location: Unspecified
  Data Sources: A database of agricultural system fault signals
  Technologies Used: Wireless sensor nodes, Blockchain technology, Deep learning, Evolutionary recurrent self-organizing map (ERSOM)
  Key Findings: The proposed fault detection system is effective in detecting and diagnosing faults in agricultural equipment and irrigation systems in real-time. The system's performance is evaluated using various metrics, demonstrating its effectiveness in detecting and diagnosing faults in agricultural equipment and irrigation systems. The paper highlights the advantages of using wireless sensor nodes, blockchain technology, and deep learning in developing resilient and efficient fault detection systems for agriculture.
  Extract 1: "The proposed terminal wireless sensor node RTU comprises capture, processing, communication, and energy units. The Sensing unit includes a physical capture device for local environment data and an Analog to Digital Converter (ADC) transforming analog signals into digital ones interpreted by the microcontroller."
  Extract 2: "The processing result will be carried out based on a comparison between the primitives and singularities of the signal received from the system to be controlled and the data characterizing all types of faults from an archived database and updated at each event at the level of the Block-chain to which it is linked."
  Limitations: None
  Relevance Evaluation: This paper is relevant to the point being made in the literature review, which is the importance of redundancy in automated irrigation systems. The paper provides a detailed explanation of a fault detection system that uses wireless sensor nodes, blockchain technology, and deep learning. This system is designed to detect faults in agricultural equipment and irrigation systems in real-time, which can help to prevent crop loss and improve overall system efficiency. The paper's relevance to the point is high because it provides a concrete example of how redundancy can be implemented in an automated irrigation system to improve its reliability and performance.
  Relevance Score: 0.9
  Inline Citation: (Salhi et al., 2024)
  Explanation: This paper proposes a smart fault detection system for agriculture based on a hybrid model combining wireless sensor nodes, blockchain technology, and an evolutionary recurrent self-organizing map (ERSOM) deep learning classifier. The proposed system aims to overcome limitations and challenges faced by traditional techniques in detecting faults in agricultural systems. The ERSOM model is trained using a database of agricultural system fault signals, and a bi-spectrum analysis is used to extract signal features for fault identification. The system's performance is evaluated using various metrics, demonstrating its effectiveness in detecting and diagnosing faults in agricultural equipment and irrigation systems. The paper highlights the advantages of using wireless sensor nodes, blockchain technology, and deep learning in developing resilient and efficient fault detection systems for agriculture.

 Full Text: >
"Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Log in Find a journal Publish with us Track your research Search Cart Home Wireless Personal Communications Article On the Use of Wireless Sensor Nodes for Agricultural Smart Fault Detection Published: 04 March 2024 Volume 134, pages 95–117, (2024) Cite this article Download PDF Access provided by University of Nebraska-Lincoln Wireless Personal Communications Aims and scope Submit manuscript Mohamed Salah Salhi, Manel Salhi, Ezzeddine Touti, Naoufel Zitouni & Faouzi Benzarti  81 Accesses Explore all metrics Abstract Modern agriculture increasingly relies on technology to enhance productivity and sustainability. This paper explores the integration of wireless sensor nodes as a pioneering approach for smart fault detection in agricultural systems. This research delves into the design, implementation, and validation of a network of wireless sensors strategically placed across agricultural fields. These sensors are equipped with advanced data collection capabilities to monitor various environmental parameters such as soil moisture, temperature, humidity, and plant health indicators. Using machine learning algorithms and data analytics, these sensor nodes autonomously detect anomalies, diseases, irrigation issues, and other faults in real-time. The paper discusses the technological framework, the challenges encountered, and the potential benefits of employing wireless sensor nodes for proactive fault detection in agriculture. The results demonstrate the efficiency of this approach in optimizing irrigation, fertilizer use, predictive harvesting, mitigating crop losses, and fostering sustainable farming practices. Ultimately, this research contributes to the advancement of precision agriculture by offering a scalable and efficient solution for early fault detection and intervention, thereby revolutionizing farming practices towards increased efficiency and sustainability. Similar content being viewed by others Sensing with Wireless Sensor Networks Chapter © 2021 Wireless Sensor Network Technology for Precision Agriculture Chapter © 2014 A Survey on Wireless Sensor Networks and Instrumentation Techniques for Smart Agriculture Chapter © 2022 1 Introduction In the face of escalating global food demand and the imperative need for sustainable agricultural practices, the fusion of technology with farming methodologies has emerged as a pivotal solution. With the advent of wireless sensor networks (WSNs) and their seamless integration into various industries, agriculture has witnessed a paradigm shift towards precision farming. In this context, the deployment of wireless sensor nodes presents a promising avenue for proactive fault detection and real-time monitoring within agricultural landscapes. The conventional agricultural practices, while effective, often lack the precision and responsiveness demanded by the dynamic environmental conditions and evolving crop health challenges. Addressing this gap, the use of wireless sensor nodes offers an innovative approach by facilitating continuous and granular data collection across vast agricultural expanses. These sensor nodes, strategically placed throughout fields, enable the monitoring of crucial parameters such as soil moisture levels, temperature fluctuations, humidity variations, and vital plant health indicators. Harnessing the capabilities of these sensors coupled with advanced data analytics and machine learning algorithms, agricultural practitioners gain unprecedented insights into the intricacies of their farming ecosystems [1, 2]. This research endeavors to explore, analyze, and validate the efficiency of employing wireless sensor nodes as a cornerstone for smart fault detection in agricultural systems. By elucidating the technological framework, data acquisition methods, and the application of intelligent algorithms, this study aims to demonstrate the potential transformative impact of this technology on modern farming practices. Moreover, it seeks to address the challenges encountered in implementing wireless sensor networks in agriculture while highlighting their role in bolstering irrigation and fertilizer efficiency, predictive harvesting, minimizing crop losses, and fostering sustainable farming methods [3]. As the global population burgeons and the pressure on agricultural productivity intensifies, the need for innovative and proactive measures in farming becomes increasingly paramount. The integration of wireless sensor nodes stands poised to revolutionize the agricultural landscape, heralding a new era of precision, sustainability, and resilience in crop production. This paper endeavors to contribute to this unfolding narrative by providing empirical insights into the promising frontier of wireless sensor networks use for smart fault detection in agriculture, thereby reshaping the future of farming practices worldwide. In this research endeavor, the subsequent sections delve into various aspects of fault detection in the agricultural domain. Following the introduction, the second section meticulously examines the mechanisms and techniques employed for detecting defects, establishing a comparative analysis of their reliability and effectiveness. Emphasis is placed on the significance of using the WSN (wireless sensor nodes) technique while addressing the challenges it entails and offering potential solutions. Section three is dedicated to elucidating the motivation behind the robustness of WSN in contrast to contemporary and existing techniques for defect analysis and determination. The proposed methodology is thoroughly outlined in the fourth section. The fifth section is designated for an empirical investigation into the adopted strategy, underscoring the attained results. Subsequently, in the sixth section, a detailed interpretation of these findings is presented, demonstrating the efficiency of the proposed method in comparison to alternative models. Notably, limitations inherent in the approach are explicitly addressed, encompassing potential challenges, drawbacks, and constraints specifically related to the use of WSNs within this context. Additionally, the discussion encompasses prospective avenues for future research and enhancements, unveiling opportunities for further advancement. Finally, the conclusion section encapsulates the research outcomes and insights gained. 2 Literal Review 2.1 Position of WSN Over Models Agriculture is undergoing a significant transformation owing to technological advancements, with wireless sensor networks (WSNs) emerging as a critical tool for precision farming. This review aims to comprehensively analyze the role, challenges, and potential of WSNs in smart fault detection within agricultural systems. WSNs have revolutionized agriculture by enabling real-time monitoring of crucial environmental parameters. These sensor nodes, strategically positioned across fields, collect data on soil moisture, temperature, humidity, and plant health indicators. Their integration with IoT technologies facilitates seamless data transmission and analysis, empowering farmers with actionable insights for informed decision-making [4, 5]. Despite their potential, the deployment of WSNs in agriculture presents several challenges. Power management, data accuracy, network scalability, and interoperability among heterogeneous sensor nodes remain primary concerns. Moreover, environmental factors such as signal interference, harsh weather conditions, and geographical obstacles pose hurdles in maintaining reliable connectivity. As technological framework, advancements in sensor technology, data analytics, and machine learning algorithms have propelled the capabilities of WSNs in fault detection. Innovations in sensor miniaturization, energy-efficient designs, and data processing techniques have enhanced their reliability and accuracy in identifying anomalies, diseases, and irrigation issues in crops. Further more, as application and benefits, WSNs offer multifaceted benefits in agriculture. They optimize resource use by providing precise and localized information, thereby reducing water and fertilizer wastage. Early fault detection facilitates timely intervention, mitigating crop losses and improving overall yield. Additionally, these systems promote sustainable farming practices by minimizing environmental impact through targeted and optimized agricultural interventions. Thus, WSN play a pivotal role in agricultural fault detection and can be positioned in relation to various strategies commonly used in this domain. In Rule-Based Systems, WSN takes a complementary position. It can gather real-time data from agricultural fields or equipment, providing continuous input for rule-based systems. The WSN feeds data to these systems, enabling the application of predefined rules for fault detection based on the collected sensor information [6, 7]. In Statistical Analysis, WSN takes an integral component position. It provides the necessary data for statistical analysis by continuously collecting and transmitting sensor data. The sensor nodes contribute real-time data streams that form the basis for establishing statistical models to identify anomalies or deviations from normal patterns [8]. In Machine Learning Algorithms, WSN takes a fundamental component position. It serves as the primary data collection infrastructure for machine learning algorithms. The continuous data streams from sensor nodes are used to train and update machine learning models for fault detection, providing the necessary input for adaptive learning and pattern recognition. In Fusion of Multiple Techniques, WSN has an enabling component position. It acts as the backbone for collecting multi-source data necessary for integrating multiple fault detection techniques. It provides diverse sensor data, facilitating the fusion and integration of rule-based, statistical, and machine learning strategies for comprehensive fault detection. In IoT-Enabled Smart Sensors, WSN has an integral component position. It consists of smart sensors equipped with communication capabilities, forming the basis for real-time monitoring and data transmission essential for fault detection in agriculture [9, 10]. In Blockchain-Enabled Systems, WSN has a data source position. It contributes to blockchain-enabled systems by providing the data that needs to be securely stored and authenticated. It generates the sensor data, which can be securely stored on the blockchain to ensure data integrity and traceability. In Long-Range Wireless Technologies (LoRa), WSN takes an infrastructure position. It leverages long-range wireless technologies for communication between sensor nodes and gateways. These technologies serve as the communication infrastructure within WSNs, facilitating long-range data transmission from remote agricultural areas [11, 12]. Comparing the WSN approach with existing fault detection techniques in agriculture involves highlighting the advantages of WSNs over traditional methods or other contemporary technologies. Below, an analysis showcasing how WSN approach excels in comparison to existing techniques: For Real-Time Monitoring and Timely Detection: WSNs enable continuous, real-time monitoring of agricultural parameters. They offer immediate fault detection upon deviation from predefined thresholds or abnormal patterns, reducing response time and potential losses. Whereas, traditional methods, such as manual inspections, periodic checks, or testing equipment, often lack real-time monitoring capabilities. They might result in delayed fault detection, leading to increased downtime and losses [13]. For Data-Driven Precision and Accuracy: WSNs collect and analyze a vast amount of data from multiple sensors, facilitating precise fault detection through machine learning algorithms and data fusion techniques. This leads to accurate fault identification and reduces false positives or negatives. However, some existing techniques rely on simple rules or manual inspections, which might lack the depth of analysis or the ability to adapt to complex fault patterns, potentially resulting in less accurate detections. Concerning Cost Efficiency and Resource Optimization: while initial setup costs for WSNs might be higher, they offer long-term cost efficiency by minimizing losses through early fault detection, optimizing resource utilization (water, fertilizers, predictive harvesting), and reducing manual labor requirements over time. While, traditional methods might incur higher labor costs due to manual inspections or require periodic testing equipment maintenance, potentially leading to higher operational expenses in the long run. About the Scalability and Flexibility: WSNs are scalable and adaptable. Additional sensors can be integrated easily into the network, offering flexibility in expanding coverage or integrating new sensors for evolving fault detection needs. Unlike, some traditional methods might face limitations in scalability, especially when relying on manual labor or fixed testing equipment, making it challenging to adapt to changing agricultural requirements or expanding operations. For Comprehensive Fault Detection and Decision Support: the integration of diverse fault detection techniques within WSNs, such as machine learning, statistical analysis, and real-time data fusion, offers a comprehensive approach. This enables informed decision-making and actionable insights for farmers or stakeholders. But, other methods from existing techniques might lack the comprehensive nature of WSNs, focusing on specific fault types or lacking the ability to provide holistic insights based on real-time, multi-parameter data [14, 15]. Some stations highlighting the development and application of WSN in remote fault detection are mentioned below. From early 2000s: the concept of WSNs begins to emerge with the development of early sensor nodes like Telos, Mica, and Tmote Sky. The Support Vector Machines (SVM) as Machine Learning Models gain traction for classification tasks due to their effectiveness in handling high-dimensional data. From mid-2000s: creation of IEEE 802.15.4 Standard. The standardization of low-rate wireless personal area networks (LR-WPANs) lays the foundation for the development of WSNs for various applications, including agriculture. Decision tree-based models and ensemble methods like Random Forests gain popularity for their ability to handle classification tasks and interpretability [16]. From late 2000s to early 2010s: WSNs start being adopted in precision agriculture, focusing on soil monitoring, weather forecasting, and crop health assessment. Deep learning approaches, particularly neural networks, see a resurgence due to advancements in computational power and data availability. From mid-2010s: the integration of WSNs with the Internet of Things (IoT) ecosystem becomes prevalent, enabling seamless data collection, processing, and analysis from agricultural sensors. Gradient Boosting Machines (GBM) and its variants (e.g. XGBoost, LightGBM) gain attention for their superior performance in classification and regression tasks [16, 17]. From late 2010s to early 2020s: increased adoption of cloud-based platforms for data storage, processing, and scalability in handling large volumes of sensor data. Recurrent neural networks (RNNs), especially long short-term memory (LSTM) networks, gain prominence for time-series analysis and prediction in agriculture, considering temporal dependencies in sensor data. Actually, recent developments focus on developing machine learning models that offer interpretability and explainability, such as Explainable AI (XAI), in detecting faults to aid decision-making in farming practices. Federated Learning explores federated learning techniques to train models collaboratively across different agricultural sites while preserving data privacy and security [18]. From another horizon, integrating blockchain technology into the realm of agricultural equipment and irrigation systems, especially concerning fault detection and data management, offers several potential benefits. Blockchain provides a tamper-proof and immutable ledger, ensuring the integrity of data collected by sensors in agricultural equipment. This feature prevents unauthorized alterations or manipulations, ensuring the authenticity of fault detection records.Through blockchain, every change or transaction recorded within the system can be traced back to its origin. This traceability can be valuable for tracking the history of faults detected in equipment or changes in irrigation systems over time. Blockchain's decentralized nature enables secure data storage across multiple nodes, reducing the risk of a single point of failure and enhancing data security. Blockchain can facilitate controlled and permissioned access to sensor data. Authorized stakeholders, including farmers, agronomists, and maintenance personnel, can securely access specific data relevant to their roles. Smart contracts, self-executing contracts with predefined conditions, can automate tasks triggered by fault detections. For instance, when a fault is identified in an irrigation system, a smart contract could automatically trigger a maintenance request or adjust irrigation settings based on predefined parameters. Blockchain's transparency can aid in tracking agricultural equipment and components throughout their lifecycle. This transparency ensures authenticity and reliability in the supply chain, allowing farmers to verify the origin and authenticity of equipment [19]. Implementing tokenization through blockchain could incentivize stakeholders for efficient equipment maintenance or early fault reporting. This system can reward participants with tokens or digital assets for contributing valuable data or maintaining equipment in optimal conditions. Blockchain can facilitate interoperability between different agricultural systems and platforms, allowing seamless integration of data from various sources. Standardization of data formats can enhance compatibility and collaboration among different stakeholders and systems. Blockchain-enabled systems can track environmental impact data associated with agricultural practices, including water usage, energy consumption, and carbon emissions. This transparency can help in adopting more sustainable and environmentally friendly practices [20]. Integrating blockchain technology into fault detection in agricultural equipment and irrigation systems requires careful consideration of implementation challenges such as scalability, interoperability, and regulatory compliance. However, leveraging blockchain's inherent features can significantly enhance the security, transparency, and efficiency of fault detection processes in agriculture. According to the above descriptions, we have chosen to design an agricultural fault detection system based on a Delta-hybridization between WSN wireless sensor nodes, Block-chain and a Deep learning classifier ERSOM model that stands for Evolutionary Recurrent Self Organizing Map. 2.2 Node Principle A Node represents an autonomous real time computational system. It receives the signals through its integrated sensors and processes them using a Digital Signal Processor DSP. A sensor is a fundamental part of Smart technologies that functions as a transducer using various effects like capacitive or inductive (magnetic). A set of sensors, forming a Wireless Sensor Network (WSN), collaborate autonomously to monitor and communicate information regarding potential issues. These autonomous microsystems communicate wirelessly in a designated space, known as a collector field. Nodes, equipped with high-end sensors, organize themselves into a self-structured topology, transmitting collected data to an information system or processing center, potentially via specialized nodes called “sinks.” Energy constraints, typically from small batteries, underscore the importance of managing energy as a critical resource in sensor nodes, making WSN technology pervasive and adaptable across diverse domains. In general, wireless sensors typically consist of various components including capture, processing, communication, and energy units. Depending on the application, additional elements like Global Positioning System GPS for environmental tracking or solar-powered mobility systems can be integrated. The resilience of WSN heavily relies on sensor material quality and precision. Despite their small size, nodes feature an efficient architecture incorporating multiple circuits on a single board, comprising detection units, microcontrollers, RF-antennas, and power units [21]. Further details on the internal structure of a node are depicted in Fig. 1. Fig. 1 Architecture of wireless sensor node Full size image The detection unit comprises a set of sensors to assess information reliability from the environment; in case of sensor failure, it ensures data integrity. Sensor outputs link to the processing unit via anti-aliasing filters and an ADC for compatibility. This unit functions as the node's core, managing internal operations, fault detection, energy, and coordination among WSN nodes' processors. ROM and RAM storage support processing instructions, communication programs, and collected data. An RF antenna circuit enables communication between nodes, while the power unit's lifespan relies on limited resources. External flash memory expands applications limited by chip memory, and internal I/O buses ease component communication within the node. An RF antenna is integrated at the node's extremity. 3 Adopted Approach Our idea is to design a remote agricultural fault detection model offering better reliability and efficiency than those established by existing methods. This approach is based on the Delta-Hybridization between WSN wireless sensor nodes, Block-chain and a Deep learning classifier ERSOM model that stands for Evolutionary Recurrent Self Organizing Map. This last model represents the pivot of the analysis of the signals received by sensors. It revolves around a recurrent evolutionary algorithm of a self-organizing neural map with unsupervised learning, giving the possibility of processing a large volume of data. Recurrence is applied to this neural map in order to integrate the dynamic temporal aspect by adapting it to the ability to process and evaluate dynamic and not static data information. The fault detection and recognition algorithm carried out by this recurrent neural map will subsequently be considered a nucleus or an individual of population of iterations supported by an evolutionary genetic algorithm ensuring the extension of the search space. This insight allows to optimize results and avoid being trapped in an optimal static state. This algorithm will be managed by the DSP Mounted on the Sensor Node card. This algorithm will be managed by the DSP Mounted on the Sensor Node card. The processing result will be carried out based on a comparison between the primitives and singularities of the signal received from the system to be controlled and the data characterizing all types of faults from an archived database and updated at each event at the level of the Block-chain to which it is linked. This result will be broadcast in real time through the WSN to a master node linked by an HMI interface. The Blockchain and WSN models are detailed previously. The following Fig. 2 offers a view on the adopted strategy. Fig. 2 Typical used wireless sensor network Full size image RTU stands for remote terminal unit; terminal Node mounted on the system to be controlled. MTU stands for master terminal unit; terminal Node linked to human–machine interface HMI. The proposed terminal wireless sensor node RTU comprises capture, processing, communication, and energy units. The Sensing unit includes a physical capture device for local environment data and an Analog to Digital Converter (ADC) transforming analog signals into digital ones interpreted by the microcontroller. Memories store information from the capture unit. The communication unit, known as the Transceiver unit, handles wireless data transmission and reception. It can be optical, as in Smart Dust Nodes, or radiofrequency-based, with optical communication being robust against electrical interference but requiring a direct line of sight. Radio frequency units include modulation, demodulation, filtering, and multiplexing circuits. Sensor nodes equipped with various sensors, e.g., temperature, humidity, soil moisture, pH sensors, relevant to agricultural monitoring. These sensor nodes are distributed across the agricultural area, collecting real-time data continuously from the environment such as soil moisture levels, temperature variations, humidity, and other relevant parameters related to crop health and equipment status. Sensor nodes communicate wirelessly with each other and with a central base station or gateway, called sink, using communication protocols such as Long Range transmission LoRa. Wireless communication allows the collected data to be transmitted over extended distances to a centralized location for further processing and analysis. Data collected from various sensor nodes is aggregated and transmitted to a centralized system or cloud-based platform. In this centralized system, the received data undergoes processing, analysis, and storage for fault detection and decision-making. Advanced data analytics and machine learning algorithms are applied to the collected data to identify patterns, anomalies, or deviations from normal conditions. These algorithms analyze sensor data to detect potential faults in agricultural equipment, irrigation systems, or anomalies in environmental parameters that could affect crop health. Once anomalies or faults are detected through data analysis, the system generates alerts or notifications to relevant stakeholders, farmers, agronomists, maintenance personnel, for timely intervention. Early warning systems or automated alerts enable proactive maintenance, minimizing the impact of faults on agricultural operations. It is important to highlight that the ERSOM neural model's learning phase on an agricultural systems fault database might take several hours and can reach one day. The duration depends on factors such as the database size, model topology, neuron count, learning iterations, and stopping criteria. Once the model has learned and becomes proficient in identifying these faults, its real-time testing phase will be instantaneous during system control. The signal processing steps for the controlled part proceed as follows: Firstly, filtering, windowing, and segmenting the signal to extract primitives defining the contained information. Various methods define these primitives, such as the Mel Frequency Cepstral Coefficient (MFCC) matrix. However, our approach opts for determining the primitives as Bi-spectrum matrices, as they are well-suited for characterizing highly transient stochastic signals. Thus, the Bi-spectrum designates an autocorrelation of order 2, called moment of order 2. Namely that the cross correlation is the measure of the analogy between two signals according to a time shift applied to one of them. One of the signals will be the signal measured by the sensors and the other signal is that of the database as a reference. The autocorrelation goes deeper to determine the coefficients of similarities between the measured signal and the reference one which resembles it better among the samples of signals in the database as a reference. The Bi-spectrum, as an autocorrelation of order 2, goes even deeper to be like a more selective filter in the determination of the similarity coefficients to a very precise default sample. Each matrix of bispectrum coefficients will be concatinated vertically in order to reduce it into a line vector, without loss of characteristics, which represents the input to our ERSOM model. It will be processed quickly to visualize the type of defects on one of the neurons, if any. The computation of the bi-spectral coefficients will be performed in the following manner: We examine a discrete signal x(n) obtained from the motor-pump machine, with a mean of zero and considered a locally stationary random process. The signal's length, denoted as N, ranges from 0 to. N − 1. The expression for its autocorrelation function is as follows: $$ R_{xx} (m) = E\\left\\{ {x(n)x(n + m)} \\right\\} $$ (1) The calculated \\({\\text{E}}\\left\\{ \\cdot \\right\\}\\), known as the mathematical expectation, represents the average within a set, serving as a statistical function with a discrete time-delay denoted as m. It is also referred to as the second-order moment. If the two signals are not correlated, we have the autocorrelation R = 0. In case of resemblance we obtain simularity coefficients. The Power Spectrum PS is determined by applying the Fourier transform (FT) to the preceding formula [22]. $$ P_{xx} (f) = \\sum\\limits_{m = - \\infty }^{ + \\infty } {R_{xx} (m)} \\,e^{ - j2\\pi fm} $$ (2) An alternalive formula can be used. $$ P_{xx} (f) = E\\left\\{ {X(f)X^{ * } (f)} \\right\\} = E\\left\\{ {\\left| {X(f)^{2} } \\right|} \\right\\} $$ (3) X* represents the conjugate of X(f), which computes the discrete Fourier transform (DFT) of our primary current signal to be controlled, x(n). $$ X(f) = \\sum\\limits_{n = 0}^{N - 1} {x(n)} \\,e^{{ - j\\frac{2\\pi fn}{N}}} $$ (4) Additionally, we derive the bispectrum, referred to as bispectral density B(f1, f2), by applying a transform function (TF) to the third-order moment depicted in the equation below. $$ M_{3}^{x} (k,l) = E\\left\\{ {x^{ * } (n)x(n + k)x(n + l)} \\right\\}. $$ (5) The parameters k and l represent time delay points. Essentially, we need to estimate the expected bispectrum values from limited data using the following formula. $$ \\begin{aligned} \\hat{B}(f_{1} ,f_{2} ) & = \\frac{1}{M}\\sum\\limits_{k = 1}^{M} {X_{k} (f_{1} )X_{k} (f_{2} )X_{k}^{ * } (f_{1} + f_{2} )} \\\\ & \\approx E\\left\\{ {X(f_{1} )X(f_{2} )X^{ * } (f_{1} + f_{2} )} \\right\\} \\\\ \\end{aligned} $$ (6) The sensor detects the fault signal x(n), which is subsequently processed by the processor within the suitable WSN node. This calculation involves setting f1 and f2 to an identical value, denoted as f, and is expressed as: $$ \\hat{B}(f_{1} ,f_{2} )\\left| {_{{f_{1} = f_{2} = f}} } \\right. = \\hat{D}(f) \\approx E\\left\\{ {X^{2} (f)X^{ * } (2f)} \\right\\}. $$ (7) As exemple, considering a fracture defect in the bars of a motor-pump rotor estimated from research to constitute 10% of potential defects. The features of BRB related to this specific failure type include frequency components defined by the following Eq. (8) [22, 23]. $$ f_{BRB} = \\left[ {\\left( \\frac{k}{p} \\right)\\left( {1 - s} \\right) \\pm s} \\right]f_{s} $$ (8) Observing that the supply frequency is denoted by fs, the number of pole pairs by p, k represents a constant proportionality, and s signifies the rotor magnetic slip. Given the effects of speed ripple, it's plausible that supplementary frequency components might appear in the stator current spectrum. Hence, an additional Eq. (9) could identify these components. $$ f_{BRBs} = (1 \\pm 2ks)f_{s} $$ (9) To identify rotor faults through its connected WSN node, analysis of the side-band frequency components at (1 ± 2 s)fs has been conducted. We establish that the lower sideband represents the primary fault frequency, while the upper sideband signifies the harmonic frequency of certain resultant velocity fluctuations. Consequently, we can use these two distinct values as effective control factors. To create a singular factor, we calculate their average, as shown below. $$ I_{dB} = \\left[ {20\\log_{10} \\left( {\\frac{{I_{l} }}{I}} \\right) + 20\\log_{10} \\left( {\\frac{{I_{r} }}{I}} \\right)} \\right]/2 $$ (10) Namely, I1 represents the fault module, Ir signifies the rotor current module, which is depicted by the upper sideband, and I represents the stator current module as the fundamental. Additionally, the stator current related to a mechanical BRB fault can be mathematically depicted. This model characterizes the stator current concerning electrical asymmetries in the rotor, generating what are known as sideband frequencies, expressed by the equation. $$ \\begin{aligned} i_{a} (t) & = i_{f} \\cos (\\omega t - \\varphi ) + \\sum\\limits_{k} {i_{l,k} } \\cos ((\\omega - \\omega_{f,k} )t - \\varphi_{l,k} ) \\\\ & \\quad + \\sum\\limits_{k} {i_{r,k} } \\cos ((\\omega + \\omega_{f,k} )t - \\varphi_{r,k} ) \\\\ \\end{aligned} $$ (11) where fs is the fundamental frequency of the electrical power. As \\(\\omega_{f,k} = 2ks\\omega\\) and \\(\\omega = 2\\pi f_{s}\\), the above expression will be: $$ \\begin{aligned} i_{a} (t) & = i_{f} \\cos (2\\pi f_{s} t - \\varphi ) + \\sum\\limits_{k} {i_{l,k} } \\cos (2\\pi f_{l,k} t - \\varphi_{l,k} ) \\\\ & \\quad + \\sum\\limits_{k} {i_{r,k} } \\cos (2\\pi f_{r,k} t - \\varphi_{r,k} ) \\\\ \\end{aligned} $$ (12) The separated formula of the controlled current signal will undergo processing by the node's microcontroller. It will then be compared to a healthy signal used as a reference to detect faults in machines.This procedure involves applying a transform function to the aforementioned equation to obtain the subsequent spectral relationship. $$ \\begin{aligned} I_{a} (f) & = \\frac{{i_{f} }}{2}\\delta (f - f_{s} )e^{j\\varphi } + \\frac{1}{2}\\sum\\limits_{k}^{{}} {i_{l,k} \\delta (f - f_{l,k} )e^{{j\\varphi_{l,k} }} } \\\\ & \\quad + \\frac{1}{2}\\sum\\limits_{k}^{{}} {i_{r,k} \\delta (f - f_{r,k} )e^{{j\\varphi_{r,k} }} } . \\\\ \\end{aligned} $$ (13) This mathematical model allows for further breakdown into basic elements, which are easily comprehensible for the WSN Node's processor to handle [24]. $$ \\begin{aligned} B(f_{1} ,f_{2} ) & = I_{a} (f_{1} )I_{a} (f_{2} )I_{a}^{ * } (f_{1} + f_{2} ) \\\\ & = \\frac{1}{8}\\left( \\begin{gathered} i_{f} \\delta (f_{1} - f_{s} )e^{j\\varphi } + \\sum\\limits_{{k_{1} }} {i_{{l,k_{1} }} \\delta (f_{1} - f_{{l,k_{1} }} )e^{{j\\varphi_{{l,k_{1} }} }} } \\hfill \\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\, + \\,\\sum\\limits_{{k_{1} }} {i_{{r,k_{1} }} \\delta (f_{1} - f_{{r,k_{1} }} )e^{{j\\varphi_{{r,k_{1} }} }} } \\hfill \\\\ \\end{gathered} \\right) \\\\ & \\quad \\times \\left( \\begin{gathered} i_{f} \\delta (f_{2} - f_{s} )e^{j\\varphi } + \\sum\\limits_{{k_{2} }} {i_{{l,k_{2} }} \\delta (f_{2} - f_{{l,k_{2} }} )e^{{j\\varphi_{l,k2} }} } \\hfill \\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\, + \\,\\sum\\limits_{{k_{2} }} {i_{{r,k_{2} }} \\delta (f_{2} - f_{{r,k_{2} }} )e^{{j\\varphi_{{r,k_{2} }} }} } \\hfill \\\\ \\end{gathered} \\right) \\\\ & \\quad \\times \\left( \\begin{gathered} i_{f} \\delta (f_{3} - f_{s} )e^{ - j\\varphi } + \\sum\\limits_{{k_{3} }} {i_{{l,k_{3} }} \\delta (f_{3} - f_{{l,k_{3} }} )e^{{ - j\\varphi_{{l,k_{3} }} }} } \\hfill \\\\ \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\, + \\,\\sum\\limits_{{k_{3} }} {i_{{r,k_{3} }} \\delta (f_{3} - f_{{r,k_{3} }} )e^{{ - j\\varphi_{{r,k_{3} }} }} } \\hfill \\\\ \\end{gathered} \\right) \\\\ \\end{aligned} $$ (14) Next, a numerical example simulation will be conducted to generate the bi-spectrum. The description of the experimental stator current is outlined as follows: $$ i_{a} (t) = i_{f} \\cos (2\\pi f_{s} t - \\varphi ) + i_{l,1} \\cos (2\\pi f_{l,1} t - \\varphi_{l,1} ) + i_{r,1} \\cos (2\\pi f_{r,1} t - \\varphi_{r,1} ) $$ (15) Upon carefully selecting various parameter values from the preceding equation, the processor within the WSN Node of the respective machine, following the requested information routing at the collection node level, enables us to visualize curves labeled accordingly for power spectrum and bispectrum, depicted in Fig. 3. Fig. 3 Power spectrum PS and bi-spectrum of a node received signal [24] Full size image While this proposed approach offers significant advantages in agricultural fault detection, it is not without limitations. Overcoming these limitations and planning for future enhancements are pivotal to optimize WSN efficacy in agriculture. The constraints include issues such as limited battery life and energy consumption, data security and privacy concerns, scalability challenges, data management complexities, sensor accuracy reliability, implementation costs, and the need for interdisciplinary knowledge integration. To address these, advancements in low-power sensor technologies, robust encryption, improved scalability, efficient data processing, enhanced sensor reliability, cost-effective solutions, and interdisciplinary collaborations are essential. By focusing on technological advancements, refined protocols, and collaborative endeavors, WSNs can become more efficient, reliable, cost-effective, and user-friendly, ensuring widespread adoption and seamless integration into agricultural practices. A techno-economic study shows that implementing Wireless Sensor Networks (WSNs) in agriculture offers multifaceted advantages, but a comprehensive cost–benefit analysis compared to traditional fault detection methods is essential to ascertain their overall value. Examining the cost–benefit analysis reveals numerous benefits of WSNs in agriculture, such as enhanced precision and efficiency in monitoring parameters, real-time data collection enabling timely interventions, reduced labor and operational costs, optimized resource utilization, and early fault detection capabilities. However, implementing WSNs involves costs related to hardware, installation, maintenance, and data management. When compared to traditional methods, WSNs showcase superior accuracy, cost efficiency in the long run, scalability, comprehensive coverage, and adaptability to changing agricultural needs. Despite the higher initial investment, WSNs prove to be more efficient, minimizing losses, optimizing resources, and offering real-time, accurate data for improved productivity and sustainability in agriculture. In a simplified qualitative perspective, WSNs exhibit higher accuracy, real-time capabilities, scalability, and potential for cost reduction over time, leading to a moderately high to high techno-economic score, whereas traditional methods may offer lower initial costs but could result in increased long-term operational expenses and potential losses, resulting in a moderate to low techno-economic score. 4 Experiment Results The experimental setup consists of the following components: A three-phase induction machine under the control of an ‘OMRON’ inverter. The rotor shaft is linked to a DC generator, connected to a rheostat for load control. Characteristics of the induction machine include: Nominal power: 4 kW Nominal speed: 1480 rpm Moment of inertia: J = 0.013 kg m2 Number of stove pairs: P = 2 SKF 6208 ball bearing with mechanical rotational frequencies: outer ring (fbext = 89.4 Hz), inner ring (fbint = 136 Hz), ball cage (fc = 9.94 Hz), and ball frequency (fbille = 58.4 Hz). Using a Micro-log portable terminal for acquiring and storing sensor measurements. The sensor used is a piezoelectric accelerometer. The entire test bench is defined by Fig. 4 below. Fig. 4 Experimental bench Full size image Our ERSOM fault classification model was trained using an energetically balanced, locally developed database. This database comprises 100 signal samples obtained from the test bench, representing diverse failures such as mechanical, electrical, vibration, thermal, and physical issues, accompanying the normal signal. The neuron map consists of 100 neurons, and the ERSOM model was trained with a stopping criterion after 1000 iterations. Subsequently, during the control and testing phase, the ERSOM model analyzed the stator signal received from the machine, specifically depicting a mechanical fault in the ball bearing. The resulting output of the ERSOM model visualized the topology showcased in Fig. 5. Fig. 5 Visualization of the inner ring failure over ERSOM model Full size image The topology depicted by ERSOM revealed the presence of a ball bearing fault indicated by the frequency Fbi. This fault is accurately defined within the inner ring and is constrained by the cutoff harmonics Fn1 and Fn2, situated close to the Best Matching Unit (BMU) neuron linked to the fault. Additionally, further examination reveals the presence of the reasoning frequency Fre generated by the primary fault. Tthe character ‘h’ indicates a healthy signal. We plot the spectral amplitude of the processed signal and observe the curve in Fig. 6. Fig. 6 Spectrum of the inner ring failure Full size image The main fault occupies a frequency of 680 Hz and the two harmonics are present with a difference on either side of 25 Hz. This implies that Fn1 has a frequency of 655 Hz and Fn2 is at a frequency of 705 Hz. In the same way we can see the curve which defines the bi-spectrum of the same machine when it is requested by the same frequencies of a failure, as shown in Fig. 7. Fig. 7 The bi-spectrum of the inner ring failure Full size image Furthermore, using Bi-Spectrum analysis will aid in discerning the severity of faults. Referring to Fig. 7, it becomes apparent that the encountered peaks are extremely abrupt and lack any frequency breadth. In the same way, the rules determining the performance criteria of the fault classifier models which qualify the operation of the WSN Nodes are established as follows: a. Accuracy: measures the overall correctness of the model's predictions. Its formula is expressed as follows [25, 26]: $$ {\\mathbf{Ac}} = \\left( {{\\text{TP}} + {\\text{TN}}} \\right)/\\left( {{\\text{TP}} + {\\text{TN}} + {\\text{FP}} + {\\text{FN}}} \\right) $$ (16) where TP = True Positives, TN = True Negatives, FP = False Positives, FN = False Negatives. Accuracy gives the ratio of correctly predicted instances to the total instances in the dataset. b. Precision: indicates the ratio of correctly predicted positive observations to the total predicted positive observations. It has the following formula: $$ \\Pr = {\\text{TP}}/\\left( {{\\text{TP}} + {\\text{FP}}} \\right) $$ (17) Precision focuses on the accuracy of positive predictions and indicates the model's ability to avoid false positives. c. Recall (Sensitivity or True Positive Rate): Recall is the ratio of correctly predicted positive observations to all actual positives. It is defined by the following formula: $$ {\\mathbf{Recall}} = {\\text{TP}}/\\left( {{\\text{TP}} + {\\text{FN}}} \\right) $$ (18) Recall measures the model's ability to identify all relevant instances, showing its sensitivity to true positives. d. F1-score: F1-score is the harmonic mean of precision and recall. It provides a balance between precision and recall. It is calculated using the following formula: $$ {\\text{F1-score}} = 2*\\left( {{\\text{Precision}}*{\\text{Recall}}} \\right)/\\left( {{\\text{Precision}} + {\\text{Recall}}} \\right) $$ (19) F1-score considers both false positives and false negatives and is useful when the class distribution is imbalanced. The obtained indicators are presented in Table 1. Table 1 Evaluation of classifier models Full size table These findings are highlighted by the Fig. 8 represented in below. Wherein, It is remarkable that the proposed ERSOM model is clearly advantageous compared to other models. Fig. 8 Performance of different classifier models Full size image Based on the Fig. 8 curve, it's evident that neural models, particularly the dynamic model RSOM and the evolutionary model ERSOM, hold superior positions in performance compared to others. Nonetheless, it's worth noting that SVM has the potential to surpass both the Kmeans moving center algorithm and the static SOM model in terms of performance. 5 Results Discussion The ERSOM deep learning model’s topology, Fig. 5, reveals that among the 100 neurons, merely 2 neurons remain unoccupied. This signifies an impressive defect identification rate of 98% using this model. Thus, it offers a precise objective evaluation with a well-defined visualization. The ERSOM map identifies the anomaly on the inner ring, delineated by the frequency fbi signified by the winning neuron. Adjacent neurons signal frequencies fn1 and fn2, representing fbi + fc and fbi–fc, respectively. The indicator fre denotes the resonance frequency of the induction machine's structure. The curve depicted in Fig. 6 represents the spectral amplitude of the signal under examination, which help us in mechanical inner ring defect identification. However, this assessment remains subjective and lacks defined scores for evaluation. The spectrum illustrated in the same Fig. 6, depicting the vibration signal from the sensor, discloses the following insights: The amplitude evolution of harmonic components follows a pattern such as (555 + k25) Hz, where k = 0, 1, 2, 3, …, representing frequencies resulting from the ball's passage on the indentation. A substantial increase in amplitudes, approximately 100 dB around 780 Hz, signifies the resonance of the structure, possibly attributed to the 31st harmonic resonance of rotation (780.2/25 = 31.2). The identification of the 5th order harmonic (680.2/136 = 5) reveals the presence of a mechanical anomaly in the inner ring when observed in the spectrum's zoomed mode. The Bi-spectrum plotted in Fig. 7 distinctly illustrates a resemblance to the outcomes presented in the ERSOM topology depicted in Fig. 5. This similarity indicates that the ERSOM model, trained and tested using Bi-spectrum coefficients, aligns closely with the observed results. Consequently, this correlation strongly substantiates the accuracy and validity of the ERSOM deep learning model employed to steer the WSN Node. As depicted in Fig. 8, it's evident that the ERSOM deep learning evolutionary model stands out significantly due to its efficiency compared to other models. This superiority is attributed to its integration of three essential criteria: evolutionaryism for broadening the search space, dynamism facilitated by a loop of recurrence that incorporates temporal aspects, and a neuronal aspect that mimics human thought processes. However, it's important to note that this proposed model demands considerably more time during its unsupervised learning phase. Moreover, diverse outcomes arise from various fault detection strategies in agriculture: Rule-Based Systems: Swift fault identification using predefined rules, as seen in detecting irrigation system faults. Statistical Analysis: Identification of anomalies or outliers in soil moisture data, suggesting potential system issues. Machine Learning Algorithms: Improved accuracy in spotting subtle changes in crop health, aiding in early disease detection. Fusion of Multiple Techniques: Enhanced precision by combining strategies like rule-based systems and machine learning for fault detection. IoT-Enabled Smart Sensors: Real-time monitoring and rapid identification of temperature fluctuations, indicating potential crop damage. Blockchain-Enabled Systems: Ensuring secure and traceable records of fault detection through blockchain technology. Note that, Zigbee finds common usage in home automation, industrial control systems, and healthcare due to its cost-effectiveness and low power consumption. Meanwhile, Bluetooth enjoys widespread adoption in consumer electronics such as smartphones, audio devices, and wearables owing to its user-friendly nature and compatibility. The Internet serves various sectors, encompassing communication, commerce, cloud services, and IoT applications. Wireless Sensor Networks (WSN) excel in environmental monitoring, agriculture, and healthcare, offering real-time data collection from distant areas. Notably, WSN tends to have lower data rates but can cover extensive distances, while the Internet exhibits high return on investment ROI potential, particularly in business, communication, and data services. Comparably, Wireless Sensor Networks WSN technology can have a strong ROI in industries like environmental monitoring, healthcare, and agriculture due to their ability to gather data from remote or hazardous locations. However, using WSN for fault detection in agriculture encounters key challenges such as: Limited access to power sources in remote areas affects device lifespan and functionality. Varied landscapes impede signal transmission, affecting accuracy. Environmental factors impact sensor accuracy, requiring regular calibration. Efficiently handling large data volumes poses computational challenges. High deployment costs in vast agricultural areas need a balance for effectiveness. Security and protecting sensitive data during transmission is critical. Adapting WSN with existing systems is complex, requiring compatibility measures. As avenues for future research and improvements to reveal opportunities for further progress, we point out that advancements in sensor technology, energy efficiency, and tailored algorithms are crucial to overcome these challenges, realizing WSN's full potential in precise agriculture fault detection. 6 Conclusion The WSNs are actually widely applicable in major emerging technology. We expressed, in this topic, the ability of the proposed Wireless Sensor Node strategy, which becomes a smart powerful tool in remote monitoring condition. Our approach is enriched by using the higher order spectrum called Bi-spectrum in primitive extraction and analysis of controled signal over an evolutionary recurrent self organizing deep learning model ERSOM. This model is implemented on the DSP of a Wireless Node Card. Our adopted approach is based on the Delta-Hybridization between WSN wireless sensor nodes, Block-chain and a Deep learning classifier ERSOM model to overcome some limitations and challenges experienced by traditional techniques. The practical application of this method for detecting agricultural defects demonstrates its resilience in analyzing these issues and making real-time decisions, showcasing promising results in comparison to current techniques. However, there are additional paths for further advancement in the future. Data Availability The data used to support the findings of this research are available from the corresponding author upon request. References Doe, J., & Smith, J. (2021). A review of fault detection and diagnosis methods for precision agriculture. Journal IEEE Access. https://doi.org/10.1109/ACCESS.2021.123456 Article   Google Scholar   Bacha, K., Henao, H., Gossa, M., & Capolino, G.-A. (2007). Induction machine fault detection using stray flux EMF measurement and neural network-based decision. Electric Power Systems Research, 78(7), 1247–1255. Article   Google Scholar   Singh, P., & Gupta, A. K. (2019). Automated detection of plant diseases: A review. Journal of Intelligent Systems. Pandey, G., Karpatne, S., & Kumar, V. (2017). Agricultural field monitoring and analysis using unmanned aerial vehicles. Computers and Electronics in Agriculture. Jain, R., & Sood, S. K. (2015). Agricultural monitoring and early warning system for crop disease using wireless sensor networks. Procedia Computer Science. Beck, H. J., & Lee, S. H. (2017). Fault detection and diagnosis in agricultural machinery: A review. Biosystems Engineering. Chlingaryan, A., Sukkarieh, S., & Whelan, D. (2018). Machine learning for agricultural field monitoring and stress detection in plants. Trends in Plant Science. Johnson, A., & Brown, D. (2020). Machine learning techniques for fault detection in agricultural systems: A comprehensive review. Journal Computers and Electronics in Agriculture. https://doi.org/10.1016/j.compag.2020.105137 Article   Google Scholar   Green, E., & Clark, M. (2022). Blockchain-enabled fault detection in smart agriculture systems. In Conference proceedings of the 25th ACM symposium on virtual reality software and technology (VRST'22). https://doi.org/10.1145/1234567.1234567 Garcia, D., & Lopez, M. (2019). Enhancing fault detection in precision agriculture using LoRaWAN-based wireless sensor networks. Journal Sensors. https://doi.org/10.3390/s19143197 Article   Google Scholar   Adams, S., & Wilson, R. (2020). Intelligent fault detection in agricultural machinery using IoT-enabled smart sensors. In Conference: Proceedings of the international conference on internet of things design and implementation (IoTDI'20). https://doi.org/10.1109/IoTDI49375.2020.00039 Chen, Z., Wang, S., Li, Q., & Wang, Y. (2019). Development of a fault detection and diagnosis system for greenhouse environmental control. Journal of Agricultural Science and Technology. https://doi.org/10.17265/2161-6256/2019.06.001 Article   Google Scholar   Hou, J., Zhang, W., Li, X., & Wu, D. (2018). Application of wireless sensor network technology in agricultural environmental monitoring. Journal IOP Conference Series: Earth and Environmental Science. https://doi.org/10.1088/1755-1315/194/2/022047 Article   Google Scholar   Wu, L., Jin, X., Gong, Y., Liu, Y., & Du, S. (2020). Design of agricultural machinery fault detection system based on internet of things. Journal of Physics. https://doi.org/10.1088/1742-6596/1519/1/012083 Article   Google Scholar   Das, G., Kumar, D., & Kumar, V. (2019). Smart agriculture: IoT based autonomous irrigation and pest detection system. International Journal of Recent Technology and Engineering. https://doi.org/10.35940/ijrte.d6616.098219 Article   Google Scholar   Martinez, L., & Rodriguez, C. (2018). Fault detection and diagnosis in agricultural machinery: A review. Journal Biosystems Engineering. https://doi.org/10.1016/j.biosystemseng.2018.01.018 Article   Google Scholar   Anderson, M., & White, E. (2021). Wireless sensor networks for smart agriculture: A review. Journal Agronomy. https://doi.org/10.3390/agronomy11061215 Article   Google Scholar   Johnson, S., & Brown, W. (2019). Machine learning applications in agriculture: A review. Journal Sensors. https://doi.org/10.3390/s19092032 Article   Google Scholar   Garcia, L., & Martinez, S. (2021). Fault detection in agricultural irrigation systems using IoT and machine learning. In Conference proceedings of the IEEE international conference on industrial internet (ICII'21). https://doi.org/10.1109/ICII52689.2021.00024 Wilson, E., & Davis, A. (2020). Application of blockchain technology in agriculture and food supply chain: A systematic review of the literature. Journal Foods. https://doi.org/10.3390/foods9121736 Kia, S. H., Henao, H., & Capolino, G.-A. (2009). Diagnosis of broken-bar fault in induction machines using discrete wavelet transform without slip estimation. IEEE Transactions on Industry Applications, 45(4), 1395–1404. Article   Google Scholar   Büsching, G. F., Kulau, U., Wolf, L. (2011). Demo: INGA—an inexpensive node for general applications. In Proceedings of the 9th ACM conference on embedded networked sensor systems, SenSys’11, Seattle, WA, USA. ACM. Aydin, I., Karakose, M., & Akin, E. (2011). A new method for early fault detection and diagnosis of broken rotor bars. Energy Conversion and Management, 52(4), 1790–1799. Article   Google Scholar   Jin, Y., Liu, J., Xu, Z., Yuan, S., Li, P., Wang, J. (2021). Development status and trend of agricultural robot technology. International Journal of Agricultural and Biological Engineering, 14(4) Ibrahim, A., El Badaoui, M., Guillet, F., & Bonnardot, F. (2008). A new bearing fault detection method in induction machines based on instantaneous power factor. IEEE Transactions on Industrial Electronics, 55(12), 4252–4259. Article   Google Scholar   Salhi, M. S., Kashoob, S., & Lachiri, Z. (2022). Progress in smart industrial control applied to renewable energy system. Journal of Energy Harvesting and Systems. https://doi.org/10.1515/ehs-2021-0004 Article   Google Scholar   Download references Acknowledgements The authors extend their appreciation to the Deanship of Scientific Research at Northern Border University, Arar, KSA for funding this research work through the project number “NBU-FFR-2023-0176”. Funding This research work is funded by the Deanship of Scientific Research at Northern Border University, Arar, King Saudi Arabia through the project number: NBU-FFR-2023-0176. Author information Authors and Affiliations Department of Electrical Engineering, National Engineering School of Tunis: Ecole Nationale d’Ingenieurs de Tunis, 1002, Tunis, Tunisia Mohamed Salah Salhi, Manel Salhi & Faouzi Benzarti Department of Electrical Engineering, College of Engineering, Northern Border University, 73222, Arar, Saudi Arabia Ezzeddine Touti Department of Electrical Engineering, National Higher Engineering School of Tunis, University of Tunis, 1008, Tunis, Tunisia Ezzeddine Touti Department of Electronics, Faculty of Sciences, University of Tunis El Manar, 1002, Tunis, Tunisia Naoufel Zitouni Contributions All authors contributed to the study conception and design. Material preparation, data collection and analysis were performed by Mohamed Salah Salhi, Manel Salhi and Ezzeddine Touti. Naoufel Zitouni and Professor Faouzi Benzarti participated in the planning of the paper and ideas. The first draft of the manuscript was written by Mohamed Salah Salhi and all authors commented on previous versions of the manuscript. Mohamed Salah Salhi, Manel Salhi and Ezzeddine Touti ensured the revision of the paper following the Reviewer comments. All authors read and approved the final manuscript. Corresponding author Correspondence to Ezzeddine Touti. Ethics declarations Conflict of interest The authors have no relevant financial or non-financial interests to disclose. They declare no conflicts of interest in relation to this article. Additional information Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Rights and permissions Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law. Reprints and permissions About this article Cite this article Salhi, M.S., Salhi, M., Touti, E. et al. On the Use of Wireless Sensor Nodes for Agricultural Smart Fault Detection. Wireless Pers Commun 134, 95–117 (2024). https://doi.org/10.1007/s11277-024-10889-8 Download citation Accepted 29 January 2024 Published 04 March 2024 Issue Date January 2024 DOI https://doi.org/10.1007/s11277-024-10889-8 Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Keywords Wireless sensor nodes WSN Smart farming Machine learning Anomaly detection Sustainability optimization Use our pre-submission checklist Avoid common mistakes on your manuscript. Sections Figures References Abstract Introduction Literal Review Adopted Approach Experiment Results Results Discussion Conclusion Data Availability References Acknowledgements Funding Author information Ethics declarations Additional information Rights and permissions About this article Advertisement Discover content Journals A-Z Books A-Z Publish with us Publish your research Open access publishing Products and services Our products Librarians Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility statement Terms and conditions Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"

</subsection_point_Point 2>

<previous_sections>

A systematic review of automated systems for real-time irrigation management

1. INTRODUCTION
The challenge of feeding a growing population with finite resources is becoming increasingly pressing. By 2050, the world population is expected to reach 9.7 billion, necessitating a 70% increase in food production (Falkenmark and Rockstrom, 2009). Irrigation plays a crucial role in enhancing crop yields and agricultural productivity to meet this growing demand. Studies have shown that irrigation can significantly increase crop water productivity, contributing to increased food production (Ali and Talukder, 2008; Playan and Mateos, 2005). However, water scarcity poses a significant challenge, with many regions facing water deficits and the need for improved water management practices (Falkenmark and Rockstrom, 2009). Optimizing irrigation schedules and doses based on crop requirements and environmental conditions is essential for maximizing yield and quality while minimizing water use (Zhang et al., 2024). The necessity of scalable water-efficient practices for increasing food demand cannot be overstated. Techniques such as regulated deficit irrigation, magnetically treated water, and the use of drought-tolerant crops like sorghum have shown promise in improving water productivity and ensuring food security (Mehmood et al., 2023; Putti et al., 2023; Hadebe et al., 2016). As the global food challenge intensifies, it is imperative to critically evaluate the current state and future potential of irrigation management systems to guide research, innovation, and implementation efforts towards fully autonomous, scalable solutions.

Despite the importance of irrigation in addressing the global food challenge, traditional irrigation management techniques, such as manual scheduling and timer-based systems, have significant limitations. These methods are often labor-intensive, inefficient, and less adaptable to changing conditions (Savin et al., 2023). Manual and timer-based scheduling can lead to high operational costs and inefficient water use (Raghavendra, Han, and Shin, 2023). The reliance on manual intervention and predetermined schedules limits their adaptability to changing environmental conditions, crop water requirements, and soil moisture levels (Kaptein et al., 2019). Sensor-based irrigation systems offer an alternative, enabling real-time adjustments based on soil water status measurements (Kaptein et al., 2019). However, the adoption of these systems in commercial settings has been limited, often requiring extensive input from researchers (Kim et al., 2014; Lea-Cox et al., 2018; Ristvey et al., 2018). The limitations of traditional irrigation management techniques highlight the need for scalable, automated solutions for greater efficiency in irrigation management. Automated systems that collect real-time data, analyze it, and make autonomous irrigation decisions can lead to improved water use efficiency and increased crop productivity (Champness et al., 2023; Wu et al., 2022). To fully understand the potential of automated systems, it is necessary to examine the automation of each part of the irrigation management pipeline and analyze the effectiveness and efficiency of integrated end-to-end solutions.

The emergence of smart irrigation management and IoT marks a significant shift from historical irrigation practices. Modern approaches rely on vast data and analysis algorithms, leveraging technologies such as remote sensing, sensor networks, weather data, and computational algorithms (Atanasov, 2023; Bellvert et al., 2023; Kumar et al., 2023). IoT plays a vital role in collecting vast amounts of data through sensors, data transmission, and tailored networks, enabling real-time monitoring and control of irrigation systems (Liakos, 2023; Zuckerman et al., 2024). These advancements in data collection and analysis have the potential to revolutionize irrigation management, allowing for more precise and efficient water use. However, challenges such as processing diverse data sources, data integration, and lack of integrated data analysis hamper the full benefit of IoT in irrigation management (Dave et al., 2023). The current fragmented approach in smart irrigation, focusing on individual components rather than the entire system, limits the potential for fully autonomous, real-time end-to-end irrigation management (Togneri et al., 2021). To address these challenges and fully realize the potential of smart irrigation management, there is a need for automating and integrating each section of the irrigation management pipeline, from sensor/weather data collection and transmission to processing, analysis, decision-making, and automated action (McKinion and Lemmon, 1985). This integration requires a thorough investigation of the role of interoperability and standardization in enabling seamless communication and compatibility between components within the automated irrigation management pipeline.

Machine learning (ML) plays a significant role in processing vast data, predicting plant stress, modeling climate effects, and optimizing irrigation in smart irrigation management systems. ML algorithms can analyze data collected from sensors and weather stations to determine optimal irrigation schedules (Vianny et al., 2022). However, the potential of ML is often constrained by manual steps, such as data interpretation, decision-making on irrigation timing and volume, and system adjustments. Automating ML integration to allow direct action from insights to irrigation execution, removing bottlenecks and achieving real-time adaptability, is crucial for fully autonomous irrigation management (Barzallo-Bertot et al., 2022). By integrating ML into automated systems, the irrigation management pipeline can become more seamless and efficient, enabling real-time decision-making and action based on data-driven insights. To achieve this level of automation and integration, it is essential to identify gaps and propose solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.

To achieve seamless integration across the automated irrigation management system, interoperability and standardization are critical. Interoperability allows different system components, such as sensors, actuators, and software, to communicate and exchange data effectively, while standardization ensures that data is represented in a consistent format (Santos et al., 2020). Standardized protocols and data formats are essential for achieving seamless integration and ensuring compatibility between components in real-time irrigation management systems (Robles et al., 2022; Hatzivasilis et al., 2018). Existing and emerging standards, such as OGC SensorThings API and ISO 11783, have applicability to real-time irrigation management systems (Hazra et al., 2021). However, challenges such as data quality, scalability, reliability, and security need to be addressed to fully realize the potential of interoperability and standardization in automated irrigation management systems (Hazra et al., 2021). Addressing these challenges is crucial for enabling the seamless integration of components within the automated irrigation management pipeline, which is essential for achieving fully autonomous, scalable irrigation management. A comprehensive evaluation of the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline is necessary to guide future research and implementation efforts.
The primary objective of this systematic review is to critically evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies for enhancing agricultural water use efficiency and crop productivity.
Specific objectives include:
•	Examining the automation of each part of the irrigation management pipeline and the seamless integration of each section in the context of irrigation scheduling and management.
•	Analyzing the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
•	Investigating the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.
•	Identifying gaps and proposing solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.
By addressing these objectives, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.

2. REVIEW METHODOLOGY
•	Question-driven framework to guide the literature review of real-time, autonomous irrigation management systems
•	Key research questions posed, each with the motivation behind investigating them and a starting hypothesis to evaluate against the examined literature
•	Table presenting the major objectives, specific objectives, questions, motivations, and hypotheses
3. DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING
3.1. Irrigation management data
The success of automated irrigation management systems relies heavily on the collection, transmission, and analysis of various types of data. The most applicable data types for irrigation management include soil moisture, canopy temperature, weather data, and plant physiological parameters (Farooq et al., 2019; Li et al., 2019; Olivier et al., 2021; Evett et al., 2020). These data are typically collected from a range of sources, including in-field sensors, remote sensing platforms, weather stations, and manual measurements (Li et al., 2019; Karimi et al., 2018).
Soil moisture data is arguably the most critical type of data for irrigation management, as it directly reflects the water available to plants and can be used to determine the optimal timing and amount of irrigation (Olivier et al., 2021; Intrigliolo & Castel, 2006). Soil moisture sensors, such as tensiometers, capacitance probes, and time-domain reflectometry (TDR) sensors, can provide real-time measurements of soil water content at various depths (Farooq et al., 2019). These sensors can be deployed in a network configuration to capture spatial variability in soil moisture across a field (Karimi et al., 2018).
Canopy temperature data is another valuable type of data for irrigation management, as it can be used to assess plant water stress and adjust irrigation accordingly (Evett et al., 2020). Infrared thermometers and thermal cameras can be used to measure canopy temperature, which is influenced by factors such as air temperature, humidity, wind speed, and plant water status (Li et al., 2019). When plants experience water stress, they tend to close their stomata to reduce water loss, leading to an increase in canopy temperature (Evett et al., 2020). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
Weather data, including temperature, humidity, precipitation, wind speed, and solar radiation, are essential for predicting crop water requirements and scheduling irrigation events (Akilan & Baalamurugan, 2024). Weather stations equipped with various sensors can provide real-time measurements of these parameters, which can be used as inputs for crop water requirement models, such as the FAO-56 Penman-Monteith equation (Li et al., 2019). These models estimate crop evapotranspiration (ET) based on weather data and crop-specific coefficients, allowing for the calculation of irrigation requirements (Intrigliolo & Castel, 2006). By integrating weather data into automated irrigation systems, irrigation schedules can be dynamically adjusted based on changing environmental conditions, ensuring that crops receive the optimal amount of water at the right time (Akilan & Baalamurugan, 2024).
When collecting and utilizing these data types, several considerations must be taken into account, including the volume, frequency, format, and source of the data (Farooq et al., 2019). The volume of data generated by automated irrigation systems can be substantial, especially when high-resolution sensors are deployed at a large scale (Bastidas Pacheco et al., 2022). This necessitates the use of efficient data storage, processing, and transmission technologies to handle the data load (Farooq et al., 2019). The frequency of data collection is another important consideration, as it directly impacts the temporal resolution of the data and the ability to detect rapid changes in plant water status or environmental conditions (Bastidas Pacheco et al., 2022). Bastidas Pacheco et al. (2022) demonstrated that collecting full pulse resolution data from water meters provides more accurate estimates of event occurrence, timing, and features compared to aggregated temporal resolutions, highlighting the importance of selecting appropriate data collection frequencies to ensure the quality and usefulness of the data for irrigation management.
The format of the data is also crucial, as it determines the compatibility and interoperability of the data with various analysis tools and platforms (Farooq et al., 2019). Standardized data formats, such as JSON, XML, or CSV, can facilitate data exchange and integration between different components of the automated irrigation system (Zhang et al., 2023). The source of the data is another important consideration, as it can impact the reliability, accuracy, and spatial coverage of the data (Farooq et al., 2019). For example, in-field sensors provide highly localized measurements, while remote sensing platforms, such as satellites or drones, can provide data at larger spatial scales (Li et al., 2019). By combining data from multiple sources, automated irrigation systems can achieve a more comprehensive understanding of crop water requirements and optimize irrigation management accordingly (Farooq et al., 2019).
Data quality, accuracy, and reliability are paramount in irrigation management, as they directly impact the effectiveness of decision-making processes and the efficiency of water use (Gupta et al., 2020). Inaccurate or unreliable data can lead to suboptimal irrigation decisions, resulting in crop stress, yield losses, or wasted water resources (Ramli & Jabbar, 2022). Gupta et al. (2020) emphasized the critical importance of data security and privacy in smart farming systems, as the leakage of sensitive agricultural data can cause severe economic losses to farmers and compromise the integrity of the automated irrigation system. The authors also highlighted the need for robust authentication and secure communication protocols to prevent unauthorized access to smart farming systems and protect data in transit (Gupta et al., 2020).
Ramli and Jabbar (2022) addressed the challenges associated with implementing real-time, automated irrigation systems, including data quality, scalability, reliability, and security. They proposed solutions and best practices based on the analysis of case studies and real-world implementations, such as the use of redundant sensors, data validation techniques, and secure communication protocols (Ramli & Jabbar, 2022). The authors also emphasized the importance of regular maintenance and calibration of sensors to ensure the accuracy and reliability of the collected data (Ramli & Jabbar, 2022).
Researchers have investigated the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in automated irrigation systems (Karim et al., 2023; Rady et al., 2020; Cui, 2023). Karim et al. (2023) explored the effectiveness of various data compression techniques, such as lossless and lossy compression algorithms, in reducing the size of data packets transmitted over wireless networks. The authors found that lossless compression techniques, such as Huffman coding and Lempel-Ziv-Welch (LZW), can significantly reduce data size without compromising data quality, while lossy compression techniques, such as JPEG and MP3, can further reduce data size by introducing acceptable levels of distortion (Karim et al., 2023).
Rady et al. (2020) developed a novel data compression algorithm specifically designed for irrigation data, which achieved significant compression ratios without compromising data quality. The authors demonstrated that their algorithm could reduce the amount of data transmitted over wireless networks, thereby improving the efficiency of the irrigation system and reducing costs (Rady et al., 2020). Cui (2023) investigated the use of data aggregation and filtering techniques to reduce the number of transmissions and save bandwidth in automated irrigation systems. The author proposed a data aggregation scheme that combines multiple sensor readings into a single value, such as the average soil moisture over a specified time interval, to reduce the frequency of data transmissions (Cui, 2023). Additionally, the author explored the use of data filtering techniques, such as Kalman filters and particle filters, to remove noise and outliers from sensor data, improving the accuracy and reliability of the transmitted information (Cui, 2023).
Data standardization and harmonization are crucial for facilitating seamless integration and interoperability between the various components of automated irrigation management systems (Zhang et al., 2023; Ermoliev et al., 2022). Zhang et al. (2023) developed a novel cyberinformatics technology called iCrop, which enables the in-season monitoring of crop-specific land cover across the contiguous United States. The authors highlighted the importance of data standardization and harmonization in the context of iCrop, as it allows for the efficient distribution of crop-specific land cover information based on the findable, accessible, interoperable, and reusable (FAIR) data principle (Zhang et al., 2023). By adopting standardized data formats and protocols, such as the Open Geospatial Consortium (OGC) standards, iCrop enables the seamless integration of various data sources and facilitates the interoperability of the system with other agricultural decision support tools (Zhang et al., 2023).
Ermoliev et al. (2022) proposed a linkage methodology for linking distributed sectoral/regional optimization models in a situation where private information is not available or cannot be shared by modeling teams. The authors emphasized the need for data standardization to enable decentralized cross-sectoral coordination and analysis, as it allows for the consistent representation and exchange of data between different models and stakeholders (Ermoliev et al., 2022). By adopting standardized data formats and interfaces, the proposed linkage methodology can facilitate the integration of various optimization models and support the development of comprehensive decision support systems for sustainable resource management (Ermoliev et al., 2022).
Metadata plays a vital role in providing context and enabling better data interpretation and decision-making in automated irrigation management systems (Jahanddideh-Tehrani et al., 2021). Metadata refers to the additional information that describes the characteristics, quality, and context of the primary data, such as the sensor type, calibration parameters, measurement units, and timestamp (Jahanddideh-Tehrani et al., 2021). Jahanddideh-Tehrani et al. (2021) highlighted the importance of metadata in water resources management, as it enables decision-makers to use the data to the best of its capabilities by understanding factors such as when water data was collected and what factors might have contributed to the measurements. The authors emphasized the need for standardized metadata formats and guidelines, such as the Dublin Core Metadata Initiative (DCMI) and the ISO 19115 standard, to ensure the consistency and interoperability of metadata across different water information systems (Jahanddideh-Tehrani et al., 2021).
In the context of automated irrigation management systems, metadata can provide valuable information about the data collection process, sensor performance, and environmental conditions that can aid in data interpretation and decision-making (Cota & Mamede, 2023). For example, metadata about the sensor type and calibration parameters can help assess the accuracy and reliability of the collected data, while metadata about the weather conditions and soil properties can provide context for interpreting the data and adjusting irrigation strategies accordingly (Cota & Mamede, 2023). By incorporating metadata into the data management and analysis pipeline of automated irrigation systems, decision-makers can make more informed and context-aware decisions, leading to improved water use efficiency and crop productivity (Jahanddideh-Tehrani et al., 2021).

3.2. Edge Computing and Fog Computing
Edge computing and fog computing have emerged as transformative technologies in the realm of real-time irrigation management systems, offering significant potential for improving efficiency, scalability, and reliability (Abdel Nasser et al., 2020; Tran et al., 2019). Edge computing refers to the practice of processing data near the edge of the network, close to the source of the data, while fog computing is a decentralized computing infrastructure that extends cloud computing capabilities to the network edge (Hassija et al., 2019). These technologies bring computation and analytics closer to the data source, reducing the need for data to travel to the cloud and enabling faster processing and decision-making (Hassija et al., 2019; Zhang et al., 2020).
The potential of edge computing and fog computing in real-time irrigation management is immense. Abdel Nasser et al. (2020) proposed a two-layer system for water demand prediction using automated meters and machine learning techniques, demonstrating the potential of edge computing in improving the efficiency and scalability of irrigation management. The system collects and aggregates data from distributed smart meters in the first layer, while the second layer uses LSTM neural networks to predict water demand for different regions of households. By leveraging edge computing, the system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management (Abdel Nasser et al., 2020).
Tran et al. (2019) conducted a comprehensive review of real-time, end-to-end automated irrigation management systems, highlighting the role of fog computing in addressing data transmission challenges and enabling seamless integration across the irrigation management pipeline. The authors emphasize that real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs. However, they also identify several challenges that need to be addressed, such as data quality, scalability, reliability, and security, which can be effectively tackled by implementing fog computing architectures (Tran et al., 2019).
Edge computing offers several benefits in real-time irrigation management systems, including reduced latency, real-time decision-making, and reduced reliance on cloud connectivity (Mishra, 2020; Zhang et al., 2020). By processing data closer to the source, edge computing enables faster response times and more efficient data handling (Mishra, 2020). Mishra (2020) highlights that edge computing reduces latency by processing data closer to the source, enabling real-time decision-making and lessening reliance on cloud connectivity by shifting processing to local or edge devices.
Zhang et al. (2020) explore the application of edge computing in agricultural settings, demonstrating its potential to improve the efficiency and accuracy of irrigation systems. The authors discuss how edge computing has prospects in various agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. They also emphasize that the emergence of edge computing models, such as fog computing, cloudlet, and mobile edge computing, has transformed the management and operation of farms (Zhang et al., 2020).
Fog computing plays a crucial role in distributing processing and storage across the network, enhancing the scalability and reliability of automated irrigation systems (Premkumar & Sigappi, 2022; Singh et al., 2022). Premkumar and Sigappi (2022) evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation. Their study emphasizes the potential of fog computing in distributing processing and storage across the network, improving the efficiency and scalability of irrigation systems. The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture, demonstrating the effectiveness of fog computing in enhancing the performance of automated irrigation systems (Premkumar & Sigappi, 2022).
Singh et al. (2022) discuss the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability in agricultural management systems. The authors argue that by implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness. They also highlight that fog computing can address the challenges faced by real-time data transmission in agricultural management systems, such as latency, bandwidth limitations, and data security (Singh et al., 2022).
The integration of edge and fog computing in real-time irrigation management systems is crucial for achieving fully automated, scalable, and reliable solutions. As the demand for autonomous irrigation management grows, these technologies will play a pivotal role in enabling faster decision-making, reduced latency, improved resource utilization, and seamless integration across the irrigation management pipeline (Tran et al., 2019; Zhang et al., 2020). By bringing computation and analytics closer to the data source and distributing processing and storage across the network, edge and fog computing can significantly enhance the efficiency and effectiveness of automated irrigation systems, contributing to the overall goal of addressing the global food challenge through optimized water resource management and increased agricultural productivity (Abdel Nasser et al., 2020; Premkumar & Sigappi, 2022; Singh et al., 2022).

3.3. Automation of Data Collection
The automation of data collection is a critical component in the development of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. It enables the efficient gathering of vital information about crop health, environmental conditions, and water requirements, which is essential for enhancing agricultural water use efficiency and crop productivity. Two key aspects of automated data collection are the use of advanced sensing technologies for non-invasive plant stress detection and the implementation of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.
Advanced sensing technologies, such as hyperspectral imaging and thermal sensing, have emerged as powerful tools for non-invasive plant stress detection in automated irrigation management systems. These technologies provide valuable information about crop traits, enabling early and accurate detection of plant health issues (Triantafyllou et al., 2019). Triantafyllou et al. (2019) propose a comprehensive reference architecture model that incorporates advanced sensing technologies in the sensor layer for real-time plant stress detection, highlighting their importance in providing non-invasive plant stress detection. Similarly, Hossain et al. (2023) present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that leverages advanced sensing technologies to optimize water use and improve crop yield, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
Hyperspectral imaging can capture subtle changes in plant physiology that are indicative of stress, while machine learning algorithms can be employed to extract meaningful patterns from the spectral data and classify different stress types (Araus et al., 2014). Thermal sensing can detect changes in canopy temperature, which is influenced by factors such as plant water status (Li et al., 2019). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
The integration of advanced sensing technologies in automated irrigation management systems has the potential to revolutionize precision agriculture. Jiang et al. (2019) demonstrate the effectiveness of a deep learning-based model in accurately detecting leaf spot diseases, highlighting the importance of image augmentation and deep learning algorithms in enhancing the model's performance.
Wireless sensor networks (WSNs) and energy-efficient communication protocols have the potential to significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. WSNs offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems, providing remote monitoring and automated control capabilities (Mehdizadeh et al., 2020). Nishiura and Yamamoto (2021) propose a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields, reducing operational costs and enhancing the efficiency of data collection. Similarly, Higashiura and Yamamoto (2021) introduce a network system that employs UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands, optimizing data collection and reducing travel distance and time.
Energy-efficient communication protocols are crucial for ensuring reliable data transmission in challenging environmental conditions and extending the lifespan of sensor nodes (Mehdizadeh et al., 2020). Al-Ali et al. (2023) investigate the potential of WSNs and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems, discussing the challenges and opportunities of using these technologies to improve the efficiency and reliability of real-time data collection in irrigation management. Mehdizadeh et al. (2020) emphasize the need for careful consideration of factors such as data accuracy, energy consumption, and network reliability when designing effective WSNs for irrigation management, enabling timely irrigation decisions and improved crop yields.
The automation of data collection through the use of advanced sensing technologies and wireless sensor networks is essential for achieving fully autonomous, scalable irrigation management. By enabling non-invasive plant stress detection and large-scale, long-term data collection, these technologies contribute to the overall goal of optimizing water resource management and increasing agricultural productivity. The integration of these technologies in real-time, end-to-end automated irrigation management systems has the potential to enhance agricultural water use efficiency and crop productivity, ultimately contributing to the development of fully autonomous, scalable irrigation management solutions.

3.4: Real-Time Data Transmission Protocols and Technologies
Real-time data transmission is a critical component of automated irrigation management systems, as it enables the timely delivery of sensor data to the cloud for processing and decision-making. The exploration of suitable protocols and network architectures is essential for ensuring efficient and reliable data transmission in these systems, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
The Message Queuing Telemetry Transport (MQTT) protocol has emerged as a popular choice for real-time data transmission in IoT networks, including those used for automated irrigation management. MQTT is a lightweight, publish-subscribe protocol designed for constrained devices and low-bandwidth networks (Author, 2019). Its simplicity and low overhead make it well-suited for IoT applications where data transmission speed and energy efficiency are critical (Saranyadevi et al., 2022). MQTT provides three Quality of Service (QoS) levels, ensuring data reliability in real-time scenarios (Author, 2019). Chen et al. (2020) proposed novel algorithms to improve data exchange efficiency and handle rerouting in MQTT-based IoT networks for automated irrigation management systems. Their TBRouting algorithm efficiently finds the shortest paths for data transmission, while the Rerouting algorithm effectively handles the rerouting of topic-based session flows when a broker crashes. The combination of these algorithms can significantly improve the performance and reliability of automated irrigation management systems (Chen et al., 2020).
Client-server IoT networks, such as those based on MQTT, play a crucial role in real-time data transmission for automated irrigation management systems. In these networks, sensors and devices (clients) publish data to a central broker (server), which then distributes the data to subscribed clients (Verma et al., 2021). This architecture enables efficient data collection, processing, and dissemination, facilitating the integration of various components within the automated irrigation management pipeline. Verma et al. (2021) proposed an architecture for healthcare monitoring systems using IoT and communication protocols, which provides a comprehensive overview of existing approaches and highlights challenges and opportunities in the field. Although focused on healthcare, the insights from this study can be applied to automated irrigation management systems, emphasizing the importance of interoperability and standardization for seamless integration (Verma et al., 2021).
In addition to MQTT, other application layer protocols such as XMPP, CoAP, SOAP, and HTTP have been explored for real-time data transmission in IoT networks. Each protocol has its strengths and weaknesses, making them suitable for different applications and scenarios. XMPP (Extensible Messaging and Presence Protocol) is an open-standard protocol that supports real-time messaging, presence, and request-response services (Saint-Andre, 2011). CoAP (Constrained Application Protocol) is a specialized web transfer protocol designed for use with constrained nodes and networks in the Internet of Things (Shelby et al., 2014). SOAP (Simple Object Access Protocol) is a protocol for exchanging structured information in the implementation of web services, while HTTP (Hypertext Transfer Protocol) is the foundation of data communication for the World Wide Web (Fielding et al., 1999).
Motamedi and Villányi (2022) compared and evaluated wireless communication protocols for the implementation of smart irrigation systems in greenhouses, considering factors such as power consumption, range, reliability, and scalability. They found that ZigBee is the most suitable local communication protocol for greenhouse irrigation due to its large number of nodes and long range, while MQTT is the recommended messaging protocol for smart irrigation systems due to its TCP transport protocol and quality of service (QoS) options. GSM is a reliable and cost-effective global communication protocol for greenhouse irrigation, providing wide coverage and low cost (Motamedi & Villányi, 2022).
Syafarinda et al. (2018) investigated the use of the MQTT protocol in a precision agriculture system using a Wireless Sensor Network (WSN). They found that MQTT is suitable for use in IoT applications due to its lightweight, simple, and low bandwidth requirements. The average data transmission speed using the MQTT protocol was approximately 1 second, demonstrating its effectiveness for real-time data transmission in precision agriculture systems (Syafarinda et al., 2018).
The choice of application layer protocol for real-time irrigation management depends on factors such as data transmission speed, reliability, and energy efficiency. MQTT and RTPS (Real-Time Publish-Subscribe) are both suitable for real-time data transmission in IoT systems, but they have different strengths and weaknesses. MQTT is a better choice for applications that require low latency and high throughput, while RTPS is a better choice for applications that require high reliability and low latency (Sanchez-Iborra & Skarmeta, 2021). The exploration of MQTT and client-server IoT networks, along with the comparison of various application layer protocols, provides valuable insights into the suitability of these technologies for real-time data transmission in automated irrigation management systems.
In summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.

3.5. Challenges and Solutions in Real-Time Data Transmission
Following the exploration of data collection, processing at the edge and fog, and automation in previous sections, we now turn to the critical aspect of real-time data transmission. While essential for automated irrigation management, this stage presents unique challenges that must be addressed to ensure system efficiency and reliability.
Obstacles in Real-Time Data Transmission
Agricultural environments present unique challenges for real-time data transmission, directly impacting the effectiveness of automated irrigation systems. Environmental factors can significantly disrupt wireless communication. Adverse weather conditions such as heavy rain, fog, and high winds can weaken or even block radio signals, leading to data loss and compromised system performance. Physical obstacles like trees, buildings, and uneven terrain further complicate signal propagation, creating reliability issues (Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). These environmental challenges necessitate robust communication protocols and network architectures that can ensure consistent and reliable data flow.
In addition to environmental factors, technical limitations also present significant obstacles. Large-scale agricultural operations often demand long-distance data transmission, which can be hindered by the limited range of certain wireless communication protocols. Network congestion, occurring when multiple sensors transmit data concurrently, can lead to delays and potential data loss, further complicating real-time decision-making (Hameed et al., 2020). To mitigate these issues, researchers have investigated the potential of cognitive radio networks (CRNs) and dynamic spectrum access (DSA) for optimizing spectrum utilization and reducing interference (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). CRNs enable devices to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency. DSA, on the other hand, facilitates the dynamic allocation of unused spectrum, enhancing spectrum utilization and reducing congestion.
Furthermore, data security and privacy are paramount concerns in real-time irrigation systems. The sensitive nature of agricultural data, such as crop yields and farm management practices, necessitates robust security measures to prevent unauthorized access and data breaches (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential to protect data integrity and ensure the trustworthiness of the system.
Investigating Data Optimization Techniques
To enhance the efficiency and reliability of real-time data transmission in automated irrigation systems, researchers have explored a range of data optimization techniques. Data compression techniques aim to reduce the size of data packets transmitted over the network, minimizing bandwidth requirements and improving transmission speed (Rady et al., 2020; Karim et al., 2023). Lossless compression algorithms, such as Huffman coding and LZW, preserve data integrity while effectively reducing data size, ensuring that no information is lost during transmission (Cui, 2023). Lossy compression algorithms, such as JPEG and MP3, offer higher compression ratios but introduce a controlled level of data loss, which may be acceptable for certain applications where some loss of precision is tolerable (Karim et al., 2023). The choice between lossless and lossy compression depends on the specific application and the trade-off between data size and accuracy.
Data aggregation techniques provide another effective approach to optimize data transmission. By aggregating multiple sensor readings into a single representative value, such as average soil moisture or temperature, the number of transmissions can be significantly reduced, conserving bandwidth and energy resources (Cui, 2023). This is particularly beneficial in large-scale irrigation systems where numerous sensors are deployed across vast areas, generating substantial amounts of data. Additionally, data filtering techniques play a crucial role in improving data quality and reliability. Kalman filters and particle filters can effectively remove noise and outliers from sensor data, ensuring that only accurate and relevant information is transmitted and used for decision-making (Cui, 2023). This is essential for preventing erroneous data from influencing irrigation decisions and potentially leading to suboptimal water management.
Sensor calibration, drift correction, and fault detection are essential for maintaining data accuracy and reliability (Dos Santos et al., 2023). Regular calibration ensures that sensors provide accurate measurements over time, while drift correction techniques account for gradual changes in sensor readings due to environmental factors or aging. Fault detection mechanisms can identify and address sensor malfunctions or anomalies, preventing erroneous data from influencing irrigation decisions and potentially harming crops or wasting water.
Addressing the Challenges
Effectively addressing the challenges in real-time data transmission requires a multifaceted approach that encompasses environmental, technical, and data-related considerations. Implementing robust and adaptive communication protocols is crucial for overcoming interference and signal degradation caused by weather conditions and physical obstacles. Selecting appropriate protocols, such as LoRa or ZigBee, with suitable range and penetration capabilities can ensure reliable data transmission in challenging agricultural environments (Motamedi & Villányi, 2022). Additionally, employing techniques like frequency hopping and error correction codes can further improve communication resilience and mitigate data loss.
Optimizing network architecture is another key consideration. Deploying a distributed network architecture with edge and fog computing capabilities can significantly enhance data processing and transmission efficiency (Abdel Nasser et al., 2020; Tran et al., 2019). Edge devices can perform initial data processing and aggregation tasks, reducing the amount of data transmitted to the cloud and minimizing latency, while fog nodes can provide additional processing power and storage closer to the data source, enhancing scalability and reliability. This distributed approach alleviates the burden on the central cloud server and allows for more responsive and efficient irrigation management.
Data optimization techniques play a vital role in reducing bandwidth requirements and improving transmission efficiency. The choice of data compression, aggregation, and filtering techniques should be tailored to the specific requirements of the irrigation system, considering factors such as data type, accuracy needs, and available bandwidth. By carefully selecting and implementing these techniques, the overall performance and effectiveness of real-time irrigation systems can be significantly enhanced, leading to more sustainable water management practices and improved agricultural productivity.
By addressing these challenges and implementing appropriate solutions, real-time data transmission can become a reliable and efficient component of automated irrigation systems, contributing to the overall goal of achieving sustainable and productive agriculture in the face of growing food demands and water scarcity.

3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
Real-time irrigation management systems heavily rely on the efficient and reliable transmission of data from sensors and weather stations to the cloud for processing and decision-making. However, agricultural environments present unique challenges to wireless communication, including adverse weather conditions, physical obstacles, and the limitations of wireless technologies. These challenges necessitate robust and adaptive solutions to ensure the consistent and timely flow of data, enabling truly autonomous irrigation scheduling.
Environmental factors, such as heavy rain, fog, and strong winds, can significantly disrupt wireless communication by attenuating or even blocking radio signals, leading to data loss and compromised system performance (Ed-daoudi et al., 2023; Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). Dense vegetation, buildings, and uneven terrain create further complications by causing multipath propagation and shadowing effects (Yim et al., 2018; Gautam and Pagay, 2020). The study by Yim et al. (2018) on LoRa networks in a tree farm environment exemplifies these challenges, revealing reduced communication range and data reliability compared to theoretical expectations. This underscores the need for carefully selecting and optimizing communication protocols and network parameters to ensure reliable data transmission in such environments.
The study by Guzinski et al. (2014a) using a modified TSEB model further highlights the importance of high-resolution data in accurately capturing the spatial and temporal dynamics of energy fluxes influenced by environmental factors. This emphasizes the need for advanced data acquisition and processing techniques that can effectively represent the complexities of agricultural settings.
The limitations of traditional wireless communication technologies, such as limited range and network congestion, pose additional challenges for large-scale agricultural operations. Long-distance data transmission can be hindered by range limitations, while network congestion arising from numerous sensors transmitting concurrently can lead to delays and data loss, hindering real-time decision-making (Hameed et al., 2020). Addressing these challenges requires the exploration of advanced networking technologies that can optimize spectrum utilization, mitigate interference, and improve reliability and efficiency.
Cognitive Radio Networks (CRNs) and Dynamic Spectrum Access (DSA) offer promising solutions for optimizing wireless communication in agricultural settings. CRNs empower devices with the ability to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). Research has explored the potential of CRNs in predicting Radio Frequency (RF) power to avoid noisy channels and optimize spectrum utilization (Iliya et al., 2014; Iliya et al., 2014). These studies demonstrate the effectiveness of combining optimization algorithms with artificial neural networks (ANNs) to enhance the accuracy and generalization of RF power prediction, enabling CRNs to make informed decisions about channel selection and avoid interference.
DSA complements CRN technology by dynamically allocating unused spectrum, further enhancing spectrum utilization and reducing congestion (Shi et al., 2023). The numerical model developed by Shi et al. (2023) showcases the potential of CRNs and DSA for optimizing wireless communication in challenging environments.
The integration of CRNs and DSA into the IoT network architecture requires careful consideration of spectrum sensing techniques, network topology, and data security. Research on cooperative spectrum sensing suggests that distributed approaches, where sensor nodes collaborate and share information, can significantly improve the accuracy and efficiency of spectrum sensing, particularly in dynamic environments (Trigka and Dritsas, 2022; Khalid & Yu, 2019). This collaborative approach enables a more comprehensive understanding of the radio environment and facilitates the identification of available frequency bands for data transmission.
The choice of network topology also impacts the performance and scalability of CRN-based irrigation systems. Mesh networks, where sensor nodes are interconnected and relay data for each other, offer enhanced resilience and coverage compared to star topologies where nodes communicate directly with a central gateway (Akyildiz & Vuran, 2010). However, mesh networks can be more complex to manage and may introduce additional routing overhead. The trade-off between network resilience and complexity needs to be carefully evaluated to select the most appropriate topology for a specific agricultural setting.
Data security and privacy are paramount concerns in IoT-based irrigation systems due to the sensitive nature of agricultural data (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential for protecting data integrity and ensuring system trustworthiness. Research on secure spectrum leasing and resource allocation algorithms for CR-WSN-based irrigation systems has demonstrated the potential of these technologies for enhancing security and efficiency (Hassan, 2023; Afghah et al., 2018).
In conclusion, the development of effective and reliable real-time irrigation management systems requires a comprehensive approach that addresses the challenges of data transmission in agricultural environments. The integration of robust and adaptive communication protocols, optimized network architectures, and advanced networking technologies like CRNs and DSA, along with a focus on data security and privacy, can contribute significantly to achieving the goal of autonomous and efficient irrigation scheduling.
4. AUTOMATED DATA PROCESSING IN THE CLOUD
4.1. Data Quality and Preprocessing
Data quality is paramount in automated irrigation systems as it directly influences the effectiveness of decision-making and water use efficiency. Issues like missing values, inconsistencies, and outliers arising from sensor malfunctions, environmental interference, or network problems (Lv et al., 2023) can significantly impact the performance of machine learning models used for irrigation scheduling and management.
Real-time data cleaning techniques are essential for addressing these challenges. Kalman filtering proves particularly effective in handling missing values and correcting erroneous readings by recursively estimating the system's state based on previous measurements and current sensor data, taking into account noise and uncertainty (Kim et al., 2020). Moving average techniques, by averaging consecutive data points, provide a more stable representation of the underlying trend, filtering out short-term fluctuations (Chhetri, 2023). For outlier detection, adaptive thresholding methods offer a dynamic approach, adjusting thresholds based on the statistical properties of the data to effectively identify anomalies and minimize false positives (Bah et al., 2021). These techniques are crucial in maintaining the integrity of real-time data streams and ensuring the accuracy of subsequent analyses.
Adaptive data preprocessing is essential for managing the diversity of data sources and formats commonly found in irrigation systems. Data normalization techniques, such as min-max scaling or z-score normalization, ensure that all features contribute equally to the analysis by transforming data values to a common scale (Pradal et al., 2016). This is crucial for preventing features with larger values from dominating the analysis and ensuring that all features are given equal consideration. Similarly, feature scaling methods, like standardization or normalization, optimize the range of feature values to improve the performance and convergence of machine learning models (Tortorici et al., 2024). By scaling features to a similar range, the influence of outliers is reduced, and the model's ability to learn from the data is enhanced.
Data fusion techniques play a critical role in integrating information from diverse sources, creating a more comprehensive and reliable dataset for irrigation management. Dempster-Shafer theory, a generalization of probability theory, allows for the expression of both uncertainty and the degree of conflict in evidence, making it suitable for fusing uncertain and conflicting data from heterogeneous sources (Sadiq and Rodriguez, 2004). This is particularly relevant in irrigation systems where data from different sensors may provide slightly different or even contradictory information due to sensor variations or environmental factors. Bayesian inference offers another powerful framework for combining information from multiple sources, updating the probability of a hypothesis as new evidence becomes available. By applying these techniques, data from soil moisture sensors, canopy temperature sensors, weather stations, and other sources can be integrated to provide a holistic understanding of crop water requirements and environmental conditions, leading to more informed and accurate irrigation decisions.
The impact of data quality extends beyond model accuracy to the robustness of machine learning models under varying conditions. Robust models should maintain consistent performance even when faced with data inconsistencies or unexpected situations. Techniques like data augmentation and domain adaptation can enhance model robustness by exposing the model to a wider range of data variations during training. Data augmentation involves generating additional training data by applying transformations or introducing noise to existing data, making the model more resilient to noise and variations in the real-world data. Domain adaptation techniques aim to adapt a model trained on one domain (e.g., a specific crop or geographic location) to perform well on another domain with different data characteristics. This is particularly relevant in irrigation management, where models may need to be applied to different crops, soil types, or climatic conditions.
The choice of data cleaning, preprocessing, and fusion techniques should be carefully considered based on the specific characteristics of the irrigation system and the available data. By selecting and implementing appropriate techniques, the accuracy, reliability, and robustness of machine learning models can be significantly improved, leading to more efficient and sustainable irrigation management practices.
4.2. Scalable and Autonomous Deployment using Containerization Strategies
The transition from data collection and transmission to efficient data processing requires a robust infrastructure capable of handling diverse workloads and data volumes. Containerization technologies, specifically Docker and Kubernetes, offer a promising solution for deploying and scaling data processing and machine learning modules within cloud environments like AWS, Azure, and GCP (Vargas-Rojas et al., 2024; Rosendo et al., 2022; Solayman & Qasha, 2023). Docker provides a standardized way to package applications and their dependencies into self-contained units known as containers, ensuring consistent and reproducible execution across different platforms (Rosendo et al., 2022). Kubernetes, acting as a container orchestrator, manages their deployment, scaling, and networking across a cluster of machines (Rosendo et al., 2022). This combination presents several advantages for automated irrigation management systems.
Firstly, containerization facilitates efficient resource utilization and scalability. By encapsulating applications and their dependencies, containers enable the isolation of resources and prevent conflicts between different modules (Vargas-Rojas et al., 2024; Solayman & Qasha, 2023). This isolation allows for the efficient allocation of resources, such as CPU, memory, and storage, to each container based on its specific needs. Kubernetes further enhances scalability by allowing for the automatic scaling of containers based on real-time demand, ensuring the system can adapt to varying workloads and data volumes, preventing bottlenecks, and ensuring responsiveness to changing conditions (Karamolegkos et al., 2023).
Secondly, containerization promotes portability and reproducibility. By packaging applications and their dependencies into a single unit, containers make it easy to move and deploy them across different cloud environments without the need for environment-specific configurations (Rosendo et al., 2022; Solayman & Qasha, 2023). This portability simplifies the development and deployment process, reducing the time and effort required to set up and manage the system. Additionally, containers ensure reproducibility by providing a consistent execution environment, regardless of the underlying infrastructure. This eliminates variability and ensures that the system will behave consistently across different deployments (Zhou et al., 2023).
Optimizing container orchestration and resource allocation is crucial to minimizing latency and maximizing throughput in real-time data processing pipelines. Techniques like auto-scaling and dynamic resource allocation play a critical role in this context (Hethcoat et al., 2024; Werner and Tai, 2023; Kumar et al., 2024). Auto-scaling automatically adjusts the number of container instances based on real-time demand, ensuring that sufficient resources are available to handle peak workloads while avoiding over-provisioning during periods of low demand (Hethcoat et al., 2024; Kumar et al., 2024). Dynamic resource allocation enables the fine-grained adjustment of resources allocated to each container based on its specific needs and the current workload (Werner and Tai, 2023). This ensures efficient resource allocation and provides each container with the necessary resources to perform its tasks effectively.
Performance monitoring tools, such as Kubernetes Metrics Server and Prometheus, are essential for gaining insights into the performance of containers and the overall system (Hethcoat et al., 2024; Kuity & Peddoju, 2023). These tools provide valuable data on key performance indicators, such as CPU and memory usage, network traffic, and application-specific metrics. By monitoring this data, administrators can identify bottlenecks, optimize resource allocation strategies, and continuously improve system performance (Hethcoat et al., 2024). This data-driven approach ensures that automated irrigation management systems can operate efficiently and reliably.
By integrating containerization technologies with optimization techniques and performance monitoring, automated irrigation management systems achieve the scalability, autonomy, and efficiency required for effective real-time data processing and decision-making. This approach facilitates a seamless and responsive system that can adapt to changing conditions and contribute to the overall goal of optimizing water resource management and increasing agricultural productivity.

4.3. Deploying ML Models for Data Processing
Transitioning from data collection, preprocessing, and transmission, the deployment of machine learning (ML) models marks a pivotal stage in the automated irrigation management pipeline. This stage entails utilizing cloud platforms to facilitate real-time data processing and inference, enabling data-driven decision-making for optimal irrigation management and ultimately contributing to fully autonomous, scalable irrigation management.
Several architectures and frameworks exist for deploying ML models on cloud platforms, each offering unique advantages and catering to different requirements. TensorFlow Serving, for instance, provides a high-performance system specifically designed for serving TensorFlow models (Abadi et al., 2016). This framework enables efficient and scalable inference, making it suitable for real-time applications where low latency and high throughput are crucial. For instance, in a large-scale irrigation system with numerous sensors generating data continuously, TensorFlow Serving can efficiently handle the high volume of inference requests and provide timely predictions for irrigation scheduling. Similarly, Apache MXNet Model Server offers a flexible and efficient solution for deploying models trained with MXNet, supporting a wide range of deep learning models and inference backends (MXNet Developers, 2015). This versatility makes it suitable for complex irrigation systems that may utilize different types of ML models for various tasks, such as predicting crop water requirements, detecting plant stress, or forecasting weather conditions. ONNX Runtime, on the other hand, provides a cross-platform inference engine compatible with various ML frameworks, including PyTorch, TensorFlow, and MXNet (Microsoft, 2017). This versatility enables the deployment of models in diverse environments, facilitating interoperability and reducing the need for model conversion. For example, an irrigation system that uses models trained in different frameworks can utilize ONNX Runtime to deploy them on a single platform without the need for time-consuming and error-prone model conversion processes.
Choosing the appropriate architecture or framework depends on several factors, including the specific ML framework used for model training, the desired level of performance and scalability, and the need for cross-platform compatibility. For instance, if the primary concern is low latency and high throughput for real-time inference, TensorFlow Serving might be the optimal choice for TensorFlow models. However, if flexibility and support for various deep learning models are required, Apache MXNet Model Server could be more suitable. In cases where cross-platform compatibility is essential, ONNX Runtime offers a versatile solution.
Once the ML model is deployed, optimizing its performance and resource utilization becomes crucial for ensuring the efficiency of integrated end-to-end automated irrigation systems. Model compression techniques, such as pruning and quantization, offer effective methods for reducing the size and computational requirements of ML models without compromising accuracy (Premkumar & Sigappi, 2022). Pruning involves eliminating unnecessary connections or neurons from the model, effectively streamlining its structure and reducing computational complexity. This can be particularly beneficial for deep learning models, which often have a large number of parameters and can be prone to overfitting. By removing redundant or less important connections, pruning can improve modelgeneralizability and reduce inference time. Quantization, on the other hand, involves reducing the precision of model parameters, typically from 32-bit floating-point numbers to lower-precision formats such as 8-bit integers. This reduction in precision leads to smaller model sizes and faster inference speeds, making it particularly beneficial for resource-constrained environments or real-time applications. For instance, in edge computing scenarios where ML models are deployed on devices with limited computational resources, quantization can enable efficient inference without sacrificing accuracy.
Furthermore, hardware acceleration through the utilization of GPUs or TPUs can significantly enhance model performance by leveraging specialized hardware designed for parallel processing (Premkumar & Sigappi, 2022). GPUs, with their massive parallelism and high memory bandwidth, excel at accelerating matrix operations and convolutions, which are fundamental computations in many deep learning models. This acceleration can significantly reduce inference time and enable real-time processing of sensor data for timely irrigation decisions. TPUs, specifically designed for deep learning workloads, offer even greater performance and energy efficiency for specific model architectures. These hardware accelerators can drastically reduce inference time, enabling near real-time decision-making and enhancing the responsiveness of automated irrigation systems. For example, in a scenario where immediate response to changing weather conditions or soil moisture levels is critical, hardware acceleration can ensure that irrigation decisions are made and executed promptly.
In addition to model compression and hardware acceleration, distributed training techniques play a crucial role in optimizing the training process for large-scale ML models. Techniques such as Horovod and BytePS enable the distribution of training across multiple machines, effectively parallelizing the process and reducing training time (Premkumar & Sigappi, 2022). This is particularly beneficial for complex models with a large number of parameters or when dealing with large datasets. By leveraging distributed training, irrigation management systems can train more sophisticated models and improve their predictive capabilities, leading to more accurate and efficient irrigation decisions. For instance, a system that utilizes a deep learning model with millions of parameters can benefit from distributed training to reduce training time from days to hours, enabling faster model iteration and improvement.
Integrating the deployed ML models with other components of the automated irrigation management pipeline is essential for achieving a fully autonomous and cohesive system and addressing the need for seamless integration across the automated irrigation management system. Standardized protocols, such as MQTT and CoAP, provide lightweight and efficient communication channels for exchanging data between these components (Poojara et al., 2023; Jimenez et al., 2020a; Gour et al., 2023). MQTT, with its publish-subscribe architecture, enables real-time data streaming and event-driven communication, making it suitable for transmitting sensor data, control signals, and inference results (Raikar & M, 2023). This enables the ML model to receive real-time updates on soil moisture, weather conditions, and plant health, allowing for dynamic adjustments to irrigation schedules based on the latest data. CoAP, designed for constrained devices and low-power networks, offers a web-transfer protocol for resource-constrained environments, enabling efficient communication between sensors, actuators, and the ML models (Raikar & M, 2023). This is particularly relevant in situations where sensors or actuators have limited processing power or battery life, as CoAP minimizes communication overhead and energy consumption. Additionally, RESTful APIs provide a standardized interface for accessing and controlling the ML models, enabling seamless integration with other software components and facilitating system management and monitoring (Wang et al., 2022). This allows for easy integration with existing farm management systems or third-party applications, creating a unified platform for comprehensive irrigation management.4.4. Online Learning in the Cloud
The complexities of real-time data processing in irrigation management necessitate the exploration of advanced techniques to continuously learn and adapt to the dynamic nature of agricultural environments. Online learning algorithms offer a promising solution, enabling the continuous update and improvement of machine learning models based on incoming real-time data. This adaptability is crucial for addressing the challenges of changing environmental conditions, such as weather patterns and crop growth stages, and optimizing irrigation decision-making to enhance water usage efficiency and crop productivity.
Several online learning algorithms have demonstrated potential for real-time data processing and model adaptation in the context of irrigation management. Stochastic Gradient Descent (SGD) facilitates the incremental update of model parameters with each new data point, allowing for efficient adaptation to changing data distributions (Bottou, 2010). This incremental learning process ensures that the model remains responsive to the latest conditions, minimizing the risk of outdated predictions and improving the accuracy of irrigation decisions. Passive-Aggressive algorithms, on the other hand, adjust model parameters only when a misclassification occurs, providing a computationally efficient approach for handling large data streams (Crammer et al., 2006). These algorithms offer a robust approach to handling noisy data, a common challenge in real-world sensor readings, by making small adjustments only when the model's prediction deviates significantly from the actual value (Fei et al., 2019). Online Random Forests extend the concept of random forests to the online setting, enabling the incremental construction and update of decision trees as new data arrives (Saffari et al., 2009). The continuous evolution of the ensemble ensures that the model remains relevant to the changing environment, capturing intricate relationships between variables and leading to more informed irrigation decisions.
Research in various domains highlights the importance of online learning for real-time data stream analytics. Snyder et al. (2020) explored the application of online learning techniques for identifying relevant tweets in real-time, improving situational awareness for first responders. The proposed interactive learning framework allows users to continuously label the relevance of incoming tweets, enabling the real-time refinement of the underlying machine learning model. This user-guided approach aligns well with the dynamic nature of irrigation management, where models need to continuously adjust to varying environmental conditions and crop water requirements. Similarly, research in the field of cyber-physical systems (CPS) underscores the need for online learning algorithms to effectively extract insights and knowledge from continuously generated data streams (Fei et al., 2019). These capabilities are crucial for enabling feedback loops between physical processes and cyber elements, facilitating the integration and optimization of CPS in irrigation management systems.
To implement online learning in cloud-based irrigation management systems, various architectures and frameworks can be considered. Apache Spark Streaming, Apache Flink, and AWS Kinesis provide scalable and fault-tolerant platforms for processing real-time data streams, allowing for the development of online learning pipelines that continuously ingest and analyze data to update machine learning models (Zaharia et al., 2012; Carbone et al., 2015; Amazon Web Services, 2023). These frameworks leverage serverless computing paradigms, automatically scaling resources based on the volume and velocity of incoming data, ensuring efficient resource utilization and responsiveness to fluctuations in demand (Fei et al., 2019).
Effectively managing the exploration-exploitation trade-off is crucial for optimizing online learning in irrigation management. Techniques such as Multi-armed bandits (Sutton & Barto, 2018), Bayesian optimization (Shahriari et al., 2016), and Reinforcement Learning (RL) (Sutton & Barto, 2018) can be employed to balance the allocation of resources between exploring new irrigation strategies and exploiting the current best-performing approaches. These techniques enable the identification of optimal irrigation policies, adapting to changing environmental conditions and maximizing long-term rewards.
In conclusion, online learning techniques, coupled with scalable cloud-based architectures, offer a powerful solution for real-time data processing and continuous adaptation in irrigation management systems. By leveraging algorithms like SGD, Passive-Aggressive, and Online Random Forests, along with stream processing frameworks like Apache Spark Streaming, Apache Flink, and AWS Kinesis, irrigation management systems can effectively handle the complexities of real-time data, optimize water usage, and enhance crop productivity in the face of dynamic environmental conditions.

5. GENERATING AND APPLYING IRRIGATION INSIGHTS 
5.1. Real-Time Generation of Actionable Irrigation Insights
•	Advanced predictive models, such as deep learning (e.g., LSTM, CNN) and ensemble methods (e.g., Random Forests), for precise, site-specific irrigation recommendations
•	Integration of IoT sensor data (e.g., soil moisture probes, weather stations) and cloud-based data sources (e.g., weather forecasts, satellite imagery) using data fusion techniques (e.g., Kalman filtering) to enhance insight accuracy and resolution
•	Strategies for handling data heterogeneity, uncertainty, and quality issues in real-time insight generation, such as data preprocessing and outlier detection
•	Techniques for reducing computational complexity and latency, such as edge computing (e.g., fog computing), model compression (e.g., quantization), and hardware accelerators (e.g., GPUs)
5.2. Automated Application of Irrigation Insights
•	Architectures and protocols for seamless integration of ML-generated insights with IoT-enabled irrigation control systems, such as MQTT and CoAP for lightweight, real-time communication
•	Analysis of industry-leading products and services, such as smart irrigation controllers (e.g., Rachio) and cloud-based irrigation management platforms (e.g., CropX)
•	Strategies for ensuring reliability, security, and scalability of automated insight application, such as redundant communication channels and secure edge-to-cloud architectures
•	Case studies of successful implementations of closed-loop, autonomous irrigation systems in research and commercial settings, highlighting technologies used and benefits achieved

6. INTEGRATION, INTEROPERABILITY, AND STANDARDIZATION 
6.1. Interoperability and Standardization
•	Importance of interoperability and standardization in enabling seamless integration of automated irrigation components
•	Overview of existing and emerging standards for IoT devices, communication protocols, and data formats in precision agriculture (e.g., ISOBUS, agroXML, SensorML)
•	Role of standardization bodies and industry consortia in promoting interoperability (e.g., AgGateway, Open Ag Data Alliance, Agricultural Industry Electronics Foundation)
•	Challenges in adopting and implementing standards across diverse hardware and software platforms
•	Strategies for encouraging widespread adoption of standards and best practices for interoperability in automated irrigation systems
6.2. Integration with Existing Irrigation Infrastructure
•	Challenges and strategies for retrofitting legacy irrigation systems with IoT sensors, actuators, and communication devices
•	Hardware compatibility issues and solutions (e.g., adapters, modular designs)
•	Software and firmware updates to enable integration with automated decision-making systems
•	Data integration and normalization techniques for merging legacy and new data sources
•	Economic and practical considerations for transitioning from manual to automated irrigation management
•	Cost-benefit analysis of upgrading existing infrastructure vs. implementing new systems
•	Phased implementation approaches to minimize disruption and optimize resource allocation
•	Training and support requirements for farmers and irrigation managers adopting automated systems
•	Case studies and real-world examples of successful integration of automated irrigation with existing infrastructure
6.3. Integration with Other Precision Agriculture Technologies
•	Synergies between automated irrigation and complementary technologies
•	Remote sensing (satellite, UAV, and ground-based) for crop monitoring and evapotranspiration estimation
•	Soil moisture sensors and weather stations for real-time, localized data collection
•	Variable rate application systems for precise irrigation delivery based on crop requirements
•	Yield mapping and analytics for assessing the impact of automated irrigation on crop productivity
•	Architectures and frameworks for integrating diverse data sources and technologies into a unified precision agriculture ecosystem
•	Edge computing and fog computing paradigms for real-time data processing and decision-making
•	Cloud-based platforms for data storage, analysis, and visualization
•	API-driven approaches for modular integration of third-party services and applications
•	Challenges and solutions for ensuring data quality, consistency, and security across integrated precision agriculture systems
•	Data cleaning, preprocessing, and harmonization techniques
•	Blockchain and distributed ledger technologies for secure, tamper-proof data sharing and traceability
•	Access control and authentication mechanisms for protecting sensitive data and resources
•	Future trends and research directions in the integration of automated irrigation with advanced precision agriculture technologies (e.g., AI-driven crop modeling, robotics, and autonomous vehicles)
6.4. Cybersecurity Considerations for Integrated Automated Irrigation Systems
•	Unique security risks and vulnerabilities associated with IoT-based automated irrigation systems
•	Potential for unauthorized access, data tampering, and system manipulation
•	Implications of security breaches for crop health, water resource management, and farm productivity
•	Best practices and strategies for securing automated irrigation systems
•	Secure device provisioning and authentication (e.g., hardware security modules, certificates)
•	Encryption and secure communication protocols (e.g., TLS, DTLS)
•	Firmware and software updates to address emerging security threats
•	Network segmentation and access control to limit the impact of breaches
•	Role of cybersecurity standards and frameworks in guiding the development and deployment of secure automated irrigation systems (e.g., NIST CSF, IEC 62443)
•	Importance of user awareness, training, and incident response planning in maintaining the security of integrated automated irrigation systems

7. MONITORING AND ENSURING SYSTEM RELIABILITY
7.1. Resilience and Fault Tolerance in Automated Irrigation Systems
•	Strategies for ensuring robustness and reliability in the face of failures, disruptions, or unexpected events
•	Redundancy: Implementing redundant components, such as duplicate sensors (e.g., soil moisture sensors, weather stations), controllers (e.g., PLCs, microcontrollers), and communication channels (e.g., cellular, satellite, LoRaWAN) to maintain system functionality during component failures
•	Failover mechanisms: Designing seamless failover mechanisms that automatically switch to backup components or systems in case of primary system failure, such as hot-standby controllers or multi-path communication protocols (e.g., mesh networks, software-defined networking)
•	Self-healing capabilities: Incorporating AI-driven self-healing mechanisms that can detect, diagnose, and recover from faults without human intervention, using techniques like reinforcement learning, Bayesian networks, or self-organizing maps
•	The role of distributed architectures and edge computing in enhancing system resilience
•	Decentralizing critical functions and data processing to minimize the impact of single points of failure, using fog computing or multi-agent systems
•	Leveraging edge computing to enable localized decision-making and control, reducing dependence on cloud connectivity and improving response times, using technologies like Raspberry Pi, NVIDIA Jetson, or Intel NUC
•	Anomaly detection and predictive maintenance using AI techniques
•	Employing unsupervised learning algorithms (e.g., autoencoders, clustering) to detect anomalies in sensor data, system performance, and water usage patterns
•	Developing predictive maintenance models using techniques like long short-term memory (LSTM) networks, convolutional neural networks (CNNs), or gradient boosting machines (GBMs) to anticipate and prevent potential system failures based on historical data and real-time monitoring
7.2. Advanced Monitoring Techniques for Automated Irrigation Systems
•	Remote monitoring using IoT-enabled sensors and computer vision
•	Deploying a heterogeneous network of IoT sensors to collect real-time data on soil moisture (e.g., capacitive, tensiometric), temperature (e.g., thermocouples, thermistors), humidity (e.g., capacitive, resistive), and plant health (e.g., sap flow, leaf wetness)
•	Integrating high-resolution cameras (e.g., multispectral, hyperspectral) and computer vision algorithms for visual monitoring of crop growth, disease detection (e.g., using deep learning-based object detection and segmentation), and irrigation system performance (e.g., leak detection, sprinkler uniformity)
•	Transmitting sensor and camera data to cloud-based platforms (e.g., AWS IoT, Google Cloud IoT, Microsoft Azure IoT) for remote access and analysis using protocols like MQTT, CoAP, or AMQP
•	Innovative approaches for real-time system health assessment
•	Developing novel algorithms and metrics for evaluating the health and performance of automated irrigation systems, such as entropy-based measures, network resilience indices, or multi-criteria decision analysis (MCDA) frameworks
•	Combining data from multiple sources (e.g., sensors, weather forecasts, satellite imagery) using data fusion techniques (e.g., Kalman filters, Dempster-Shafer theory) to create a comprehensive view of system health
•	Employing advanced data visualization techniques (e.g., interactive dashboards, augmented reality) to present system health information in an intuitive and actionable format
7.3. Closed-Loop Control and Feedback Mechanisms
•	Exploring the concept of closed-loop control in autonomous irrigation systems
•	Implementing feedback loops that continuously monitor system performance and adjust irrigation schedules based on real-time data, using control techniques like proportional-integral-derivative (PID), model predictive control (MPC), or fuzzy logic control (FLC)
•	Integrating machine learning algorithms (e.g., reinforcement learning, genetic algorithms) to optimize closed-loop control strategies over time, adapting to changing environmental conditions and crop requirements
•	Designing effective feedback mechanisms for user interaction and system optimization
•	Providing user-friendly interfaces (e.g., mobile apps, web dashboards) for farmers to input preferences, constraints, and expert knowledge into the automated irrigation system, using techniques like participatory design or user-centered design
•	Incorporating user feedback and domain expertise to refine irrigation strategies and improve system performance
8. CASE STUDIES AND REAL-WORLD IMPLEMENTATIONS OF FULLY AUTONOMOUS IRRIGATION SYSTEMS
8.1. Fully Autonomous Irrigation Systems in Diverse Agricultural Settings
•	Row Crops: maize, wheat, soybean with real-time soil moisture monitoring and weather-based irrigation scheduling for fully automated precision irrigation
•	Orchards: citrus, apple, almond with plant health monitoring and precision water application for fully autonomous orchard management
•	Greenhouses: tomato, lettuce, herbs with automated drip irrigation and climate control integration for fully automated greenhouse operations
•	Urban Farming: rooftop gardens, vertical farms with IoT-enabled hydroponic systems and remote management for fully autonomous urban crop production
8.2. Integration of Advanced System Components for End-to-End Automation
•	Wireless sensor networks: soil moisture probes, weather stations, plant health monitoring cameras with low-power, long-range communication for fully automated data acquisition
•	Secure data transmission: LoRaWAN, NB-IoT, 5G, satellite communication for reliable, real-time data transfer from field to cloud in fully autonomous irrigation systems
•	Intelligent data processing: edge computing for local data filtering, cloud platforms for scalable storage and analysis, machine learning algorithms for predictive insights in fully automated irrigation management
•	Autonomous decision-making: advanced irrigation scheduling algorithms, precise valve control, closed-loop feedback systems for optimal water management in fully autonomous irrigation systems
8.3. Quantitative Performance Evaluation of Fully Automated Irrigation Systems
•	Water use efficiency: percent reduction in water consumption compared to conventional methods, improved water productivity (yield per unit of water) achieved through fully autonomous irrigation
•	Crop yield and quality improvements: percent increase in yield, enhanced crop uniformity, improved nutritional content attributed to fully automated precision irrigation
•	Labor and energy savings: quantified reduction in labor hours for irrigation management, decreased energy consumption for pumping due to optimized scheduling in fully autonomous systems
•	Economic viability: detailed return on investment analysis, payback period calculations, comprehensive cost-benefit analysis for fully autonomous irrigation management systems
8.4. Lessons Learned and Challenges Encountered in Deploying Autonomous Irrigation Systems
•	Technical challenges and solutions: ensuring reliable data transmission in remote locations, addressing interoperability issues between diverse system components, optimizing power consumption for extended battery life, adapting algorithms to local soil and weather conditions in fully autonomous irrigation systems
•	Operational and logistical hurdles: streamlining installation and maintenance procedures, providing effective user training, seamlessly integrating with existing farm management practices and legacy systems for fully automated irrigation management
•	Regulatory and socio-economic considerations: navigating complex water use regulations, addressing data privacy and security concerns, ensuring equitable access and affordability for smallholder farmers adopting fully autonomous irrigation technologies
8.5. Best Practices and Recommendations for Successful Implementation
•	Designing scalable, modular, and adaptable autonomous irrigation systems to accommodate future growth and changing requirements for fully automated water management
•	Prioritizing user-centered design principles and actively engaging stakeholders throughout the development and deployment process of fully autonomous irrigation solutions
•	Adopting open standards and communication protocols to enable seamless integration of system components and interoperability with third-party platforms in fully automated irrigation setups
•	Implementing robust data validation, filtering, and quality control mechanisms to ensure data integrity and reliability for decision-making in fully autonomous irrigation systems
•	Establishing clear data governance policies and security frameworks to protect sensitive information and maintain user trust in fully automated irrigation management
•	Developing intuitive user interfaces and decision support tools to facilitate easy adoption and effective use of fully autonomous irrigation systems
•	Collaborating with local extension services, agribusinesses, and technology providers for knowledge transfer, technical support, and continuous improvement of fully automated irrigation solutions
8.6. Synthesis of Case Studies and Implications for Autonomous Irrigation Adoption
•	Cross-case analysis of key performance indicators and critical success factors for fully autonomous irrigation scheduling systems in various contexts
•	Identification of common themes, challenges, and innovative solutions across diverse implementations of end-to-end fully automated irrigation management
•	Assessment of the potential for replicability and scaling of successful fully autonomous irrigation projects in different regions and farming systems
•	Implications for future research priorities, technology development roadmaps, and policy interventions to support widespread adoption of fully autonomous irrigation technologies

CONCLUSION/FUTURE DIRECTIONS AND UNANSWERED QUESTIONS
•	Summarize the key insights gained from the question-driven review, emphasizing how each section contributes to the overarching goal of achieving real-time, end-to-end automation in irrigation management
•	Based on the questions addressed, propose new research directions and unanswered questions
•	Identify key research gaps and propose concrete research questions and hypotheses for advancing the field of real-time, automated irrigation management
•	Highlight the need for collaborative research efforts across disciplines, such as computer science, agricultural engineering, and environmental science, to address the complex challenges of automated irrigation systems
•	Emphasize the need for further innovation and exploration in real-time, automated irrigation systems




</previous_sections>

</documents>
<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper. 

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: stated in: <subsection_title>
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>

<subsection_point_Point 8>
Point: Anomaly detection and predictive maintenance using AI techniques

Papers to support point:

Paper 1:
- APA Citation: Nguyen, T. T., Yokoya, N., Pham, T. D., Le, N. N., Ha, N. T., Xia, J., Takeuchi, W., & Pham, T. D. (2022). Improvement of mangrove soil carbon stocks estimation in North Vietnam using Sentinel-2 data and machine learning approach. GIScience & Remote Sensing, 58(1), 68-87.
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: This systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.
  Extract 2: In this research, a new approach involving the use of advance machine learning (ML) models, and multi-sensor data fusion including Sentinel-1(S1) C-band dual polarimetric synthetic aperture radar (SAR), Sentinel-2 (S2) multispectral data, and ALOS Global Digital Surface Model (ALOS DSM) to predict precisely soil moisture at 10 m spatial resolution across research areas in Australia.
  Limitations: Limited scope - The study does not explore the specific implementation and deployment challenges of real-time automated irrigation systems.
  Relevance Evaluation: Exceptionally relevant - Comprehensively addresses all key aspects of the point with highly insightful, reliable, and up-to-date information. A must-include for the review.
  Relevance Score: 1.0
  Inline Citation: (Nguyen et al., 2022)
  Explanation: The paper investigates the relevance of using automated, real-time irrigation management systems, which integrate IoT and machine learning technologies, for enhancing agricultural productivity and efficient water resource utilization. The study also focuses on the importance of interoperability and standardization in enabling seamless communication and compatibility within the automated irrigation management pipeline.

 Full Text: >
"Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Graphical abstract Keywords 1. Introduction 2. Materials and methods 3. Results and discussion 4. Conclusion CRediT authorship contribution statement Declaration of competing interest Acknowledgements References Show full outline Cited by (28) Figures (9) Show 3 more figures Tables (6) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6 Science of The Total Environment Volume 833, 10 August 2022, 155066 Research Paper A low-cost approach for soil moisture prediction using multi-sensor data and machine learning algorithm Author links open overlay panel Thu Thuy Nguyen a, Huu Hao Ngo a, Wenshan Guo a, Soon Woong Chang b, Dinh Duc Nguyen b, Chi Trung Nguyen c, Jian Zhang d, Shuang Liang d, Xuan Thanh Bui e, Ngoc Bich Hoang f Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.scitotenv.2022.155066 Get rights and content Highlights • Data fusion and machine learning are of importance for SM retrieval. • The predictor variables derived from S-1, S-2, and ALOS DSM data were generated. • 21 optimal features were identified using genetic algorithm. • The extreme gradient boosting regression performed best in SM estimation. • Inverted Red-Edge Chlorophyll Index was the most influential feature. Abstract A high-resolution soil moisture prediction method has recently gained its importance in various fields such as forestry, agricultural and land management. However, accurate, robust and non- cost prohibitive spatially monitoring of soil moisture is challenging. In this research, a new approach involving the use of advance machine learning (ML) models, and multi-sensor data fusion including Sentinel-1(S1) C-band dual polarimetric synthetic aperture radar (SAR), Sentinel-2 (S2) multispectral data, and ALOS Global Digital Surface Model (ALOS DSM) to predict precisely soil moisture at 10 m spatial resolution across research areas in Australia. The total of 52 predictor variables generated from S1, S2 and ALOS DSM data fusion, including vegetation indices, soil indices, water index, SAR transformation indices, ALOS DSM derived indices like digital model elevation (DEM), slope, and topographic wetness index (TWI). The field soil data from Western Australia was employed. The performance capability of extreme gradient boosting regression (XGBR) together with the genetic algorithm (GA) optimizer for features selection and optimization for soil moisture prediction in bare lands was examined and compared with various scenarios and ML models. The proposed model (the XGBR-GA model) with 21 optimal features obtained from GA was yielded the highest performance (R2 = 0. 891; RMSE = 0.875%) compared to random forest regression (RFR), support vector machine (SVM), and CatBoost gradient boosting regression (CBR). Conclusively, the new approach using the XGBR-GA with features from combination of reliable free-of-charge remotely sensed data from Sentinel and ALOS imagery can effectively estimate the spatial variability of soil moisture. The described framework can further support precision agriculture and drought resilience programs via water use efficiency and smart irrigation management for crop production. Graphical abstract Download : Download high-res image (192KB) Download : Download full-size image Previous article in issue Next article in issue Keywords Soil moistureMachine learningData fusionSentinelALOS 1. Introduction Soil moisture (SM) has played vital roles in hydrological state and ecological processes which affects energy, water, and carbon cycles such as evaporation, transpiration, diversity and rainfall-runoff of various ecosystems (Ågren et al., 2021; efBabaeian et al., 2021; Robinson et al., 2008). Soil moisture is also a crucial predictor indicator for identify crop water stress, which helps agricultural drought monitoring. Thorough knowledge about the spatiotemporal patterns of SM is of essential importance for understanding water budgets in hydrological systems which helps prevent agricultural drought problems, water vulnerability, the issues of water shortage, and improve properly crop production across the world (Chaudhary et al., 2021; Tuller et al., 2019). Traditional ground techniques of soil moisture based on field experiments, in-situ soil sensing instrumentation, and geophysical and mobile sensing (Cheng et al., 2022; Robinson et al., 2008). The disadvantages of this method are high cost with small-scale monitoring. Remotely sensed measurements including active remote sensing and passive remote sensing recently have employed effectively for SM monitoring globally (Chaudhary et al., 2021; Cheng et al., 2022; Dubois et al., 2021; Prasad et al., 2018; Warner et al., 2021). At present, various satellite systems via microwave remote sensing like Soil Moisture Active Passive (SMAP) (Entekhabi et al., 2010), Advanced Scatter meter (ASCAT) (Wagner et al., 2013), and Soil Moisture and Ocean Salinity (SMOS) (Kerr et al., 2001) have been explored for global SM monitoring with spatial resolutions of 10 km, 50 km, and 35 km, respectively. With the low spatial resolution, SM data obtained from these aforementioned missions have not been used widely in farm scales for agricultural management. Recent advances in earth observation technology such as using active and passive remote sensing (RS) imagery have been dedicated to solving the problems of SM dynamics retrieval on farming lands. Active remote sensing like Unmanned Aerial System (UAS) with highly flexible flight schedules and high spatial resolutions of images offer a great opportunity to estimate the SM for farm-scales (efBabaeian et al., 2021). The application of high-resolution about 2 m images from airborne LIDAR can accurately estimate the SM dynamics to support precision agriculture production (Ågren et al., 2021). However, the deployment of UAS and LIDAR have struggled with some obstacles such as limited fight time, high operation cost, and challenges with hyperspectral images processing which limits the application of active RS for SM monitoring (Gago et al., 2015). Multispectral remote sensing sensors such as Sentinel 1 and Sentinel 2 datasets from European earth observation program Copernicus have employed recently to capture effectively the SM content in several agricultural areas across the world with the spatial resolution of 10-100 m (El Hajj et al., 2017; Georganos et al., 2018). The free-of-charge imagery from Sentinel date at high spatial and temporal resolutions are a proper solution to address the challenges of hyperspectral images in agricultural SM prediction. The C-band of the Sentinel-1A and-1B Synthetic Aperture Radar (SAR), and vegetation and soil indices from Sentinel -2A and -2B have been generated to estimate SM properties at high spatial resolution in the pilot scale (Aksoy et al., 2021; El Hajj et al., 2017; Karthikeyan and Mishra, 2021; Ma et al., 2021; Prasad et al., 2018; Schönauer et al., 2021; Senanayake et al., 2021). In addition, terrain indices from digital elevation (DEM) models such as slope, topographic wetness index (TWI), and death-to-water (DTW) index have also been used to predict the agricultural SM (Ågren et al., 2021; Murphy et al., 2008). Topo-hydrological indicators generated from high-resolution DEM data illustrated high correlations with soil properties and soil moistures by capturing the hydrological processes' characteristics of specific sites (Zhao et al., 2021; Zhou et al., 2020a, Zhou et al., 2020b). According to Florinsky et al. (2002), soil properties including soil moisture have a significant relationship with topographic attributes, especially in agricultural landscapes. Machine learning techniques are already commonly applied to handle diverse and large volumes of remote-sensing datasets, with very high performances (Carranza et al., 2021; Gómez et al., 2020; Gómez et al., 2021; Hosoda et al., 2020; Karthikeyan and Mishra, 2021; Ma et al., 2021; Prasad et al., 2018; Schmidt et al., 2020). Artificial intelligence techniques such as random forest regression (RFR), support vector machine (SVM), extreme gradient boosting regression (XGBR), CatBoost gradient boosting regression (CBR) have been employed widely to estimate soil moisture products with high prediction accuracy (Ågren et al., 2021; Carranza et al., 2021; Senanayake et al., 2021). The RFR algorithm performed well to predict the field-scale of soil moisture in China using unmanned aerial vehicle (UAV) imagery with coefficient determination (R2) of 0.91 (Ge et al., 2019). The XGBR technique was used to estimate the SM dynamics in Swedish forest landscape using multiple LIDAR derived digital terrain indices with high performance values compared to RFR and SVM (Ågren et al., 2021). In general, ML algorithms provide a substantial potential for the SM estimation accurately. In this study, a new approach for soil moisture monitoring using the combination of three free-of-charge and high-resolution remote sensing datasets including Sentinel 1, Sentinel 2, and ALOS DSM was presented to estimate the soil moisture in field-scale. Four well-known ML algorithms including RFR, SVM, XGBR, and CBR were employed to test the performance of predictor variables from these datasets. The optimisation of hyper-parameters tuning and the selection of predictor variables during the construction phase of the ML techniques was applied to improve the performance of ML models. This study aims to: (1) assess the correlation of prediction indicators derived from multi-spectral images, SAR datasets, and ALOS DSM in the SM retrieval; (2) select and optimize features from these indicators using genetic algorithm (GA) and XGBR; (3) evaluate the prediction performance of the selected ML model (XGBR) with various scenarios of data-fusion level in the SM prediction while exploring the effectiveness of GA feature optimization on the ML model in mapping the SM content at 10 m spatial resolution; and (4) compare the estimation accuracy of XGBR model with other three well-known ML models using optimal features. The novel framework will be expanded to other field-scales or regional scales to build the SM map, which provides valuable data for different stakeholders like water managers, local authorities, and landholders to practice precision agriculture. 2. Materials and methods 2.1. Study area and soil sample collection The study sites are located in the Wests, Goomalling shire (latitude coordinate: −31° 18′ S and longitude coordinate: 116° 49′ E), and Cookies area - Northam shire (latitude: −31° 39′ S, and longitude: 116° 39′ E) in the agricultural region of Western Australia (WA). The WA has a diverse type of agricultural production including vegetable industries which contributes a majority of total value of agricultural production in the region. Pastoral and cropping are two key agricultural practices in the WA (Kingwell et al., 2020). According to Australian Bureau of Agricultural and Resource Economics, high-rainfall, wheat-sheep, and pastoral zones are the main agricultural climatic zones in Australian (Salim and Islam, 2010). The type of climate in the WA is a Mediterranean climate where is hot and dry in summer, and cool and wet in winter seasons. The rainfall season is from April and October which ranges between 300 and 600 mm (Kingwell et al., 2020). Soil sampling points were selected from a binary land-use classification map which was produced by extreme gradient boosting classification from high spatial resolution Google Earth imagery and Sentinel 2 imagery. Nguyen et al. (2022) illustrated the detail of soil samples selection using the binary map. The active learning technique in remote sensing classification was used to assist in the selection of soil samples, which helps reduce the influence of vegetation on SM contents (Fu et al., 2010). Forty bare-soil sampling areas with a pixel (size of 10 m × 10 m) across the study locations (20 points for each plot) were identified from the binary map (Fig. 1). A Differential Global Positioning System (DGPS) was applied for accurately the samples' location identification with an accuracy of 1–3 cm (Michalski and Czajewski, 2004). The soil samples were taken in April 2021. There are four soil cores being taken in each sampling area to a depth of 7 cm from each experimental block by a standard tube of 7.3 cm in diameter. The soil samples were sent to the laboratory for soil moisture analysis by oven drying method from Standards Association of Australia. Download : Download high-res image (484KB) Download : Download full-size image Fig. 1. Location of the study sites and sampling points in Wests and Cookies area. 2.2. Research framework The research framework consists of five main steps (Fig. 2): (1) collecting surface soil dataset (0–10 cm) from the binary land-use classification map; (2) generating predictor indicators from optical (Sentinel 2), synthetic aperture radar (Sentinel 1), and terrain indices derived from ALOS DSM; (3) computing Pearson's correlation analysis and feature selection using genetic algorithm; (4) evaluating the performance of the XGBR model with five different scenarios developed from features derived from S1, S2, and ALOS DSM with 70% of SM measured dataset used for models' training and 30% for models' validation; and (5) comparing the performance of the XGBR model with other ML techniques using optimal features and building the SM dynamics map for the study areas. Download : Download high-res image (468KB) Download : Download full-size image Fig. 2. A novel generated framework of SM estimation using multi-sensor data fusion and ML approach. 2.3. Remote sensing data acquisition and image processing 2.3.1. Data acquisition In this research, soil moisture predictor variables were computed from S-2 multispectral satellite data, S-1 C-band dual polarimetric SAR imagery, and ALOS DSM (Table 1). While Sentinel 1 and Sentinel 2 images were downloaded from the Copernicus Open Access Hub from European Space Agency (ESA), the ALOS DSM 30 m imagery was acquired from JAXA Earth Observation Research Centre. The SNAP Sentinel Application Platform toolbox were used for both Sentinel datasets processing, whereas ArcGIS 10.4 was employed to process ALOS imagery and compute the ALOS-DSM derived features. All images were resampled to a ground sampling distance (GSD) of 10 m and geocoded in the same projection of World Geodetic System (WGS84) - Universal Transverse Mercator (UTM) zone 50 South (50S). Table 1. Remote sensing data acquisition for the study areas. Sensor Scene / tile ID Acquisition date (month/day/year) Processing level Spatial resolution (m) Spectral band/polarization S-2 50JML 04/17/2021 1C 10–20 13 multispectral bands S-1 S1B_IW_GRDH1SDV 04/27/2021 GRD 10 Dual-polarization (VV and VH) ALOS-DSM AW3D30 04/01/2021 30 m Source: European Space Agency ESA and JAXA Earth Observation Research Centre. 2.3.2. Sentinel images processing The S-2 image was processed via four main steps which presented in the Fig. 3. Ten multispectral bands were extracted for the study including B2, B3, B4, B5, B6, B7, B8, B8A, B11, and B12. Vegetation indices, soil indices, and water index were computed by thematic land processing function in the SNAP toolbox (Pasqualotto et al., 2019). Vegetation, soil and water indicators are presented as being sensitive to soil moisture content which recently was used for soil moisture properties estimation (Jin et al., 2017). Predictor variables derived from S-2 were illustrated in Table 2 below. A total of 22 indicators were computed from S-2 for the SM prediction. Download : Download high-res image (111KB) Download : Download full-size image Fig. 3. The steps of Sentinel images processing using SNAP Toolbox. Table 2. Vegetation, soil, and water predictor variables derived from Sentinel 2. Vegetation and soil index Acronyms S-2 band wavelengths References Ratio Vegetation Index RVI (Tucker, 1979) Normalized Difference Vegetation Index NDVI (Rouse et al., 1973) Green Normalized Difference Vegetation Index GNDVI (Gitelson et al., 1996) Normalized Difference Index using Bands 4 & 5 of S-2 NDI45 (Delegido et al., 2011) Soil Adjusted Vegetation Index SAVI  L = 0.5 in most conditions (Huete, 1988) Inverted Red-Edge Chlorophyll Index IRECl (Frampton et al., 2013) Modified Chlorophyll Absorption in Reflectance Index MCARI [(RE1 − Red) − 0.2 × (RE1 − Green)] × (RE1 − NIR) (Daughtry et al., 2000) Brightness Index BI (Escadafal, 1989) Brightness Index 2 BI2 (Escadafal, 1989) Redness Index RI (Mathieu et al., 1998) Color Index CI (Mathieu et al., 1998) Normalized Difference Water Index NDWI (NIR − SWIR)/(NIR + SWIR) (Gao, 1996) Note: Band wavelengths of S-2: B2: Blue (492 nm), B3: Green (560 nm), B4: Red (665 nm), B5: Red-edge 1 (RE1) (704 nm), B6: Red-edge 2 (RE2) (740 nm), B7: Red-edge 3 (RE3) (783 nm), B8: near-infrared (NIR) (833 nm), B8A: Narrow-NIR (865 nm), B11: short-wavelength infrared (SWIR1) (1614 nm), and B12: SWIR2 (2202 nm). (Modified from (Pham et al., 2020)). A radar module in the SNAP toolbox was used to process the S-1 imagery. There are seven main stages involving the extraction of the SAR dataset for the SM monitoring. The first one is to convert the S-1 raw data to scale backscatter coefficient (σ0) in decibel (dB) and correct the orbit file. The next steps are: (1) the removal of thermal and border noise; (2) radiometric calibration; (3) speckle filtering; (4) the correction of range Doppler terrain; (5) normalized radar backscattering coefficient; and (6) the computation of SAR prediction variables including two original bands from dual polarization (VH and VV); the five transformed bands (VV/VH; VH/VV; VV-VH; VH-VV; (VV + VH)/2); and the 20 new indicators generated from VV and VH using the GLMC algorithm. 2.3.3. ALOS image processing The Advanced Land Observing Satellite (ALOS) was launched by the Japan Aerospace Exploration Agency (JAXA) in 2006. JAXA recently provided the product of ALOS-DSM which is one of the newest remote sensing-based DEM. The ALOS-DSM has two kinds of resolution. ALOS-DSM with the resolution of 30 m is a free-of-charge dataset and higher prediction performance compared to Reflection Radiometer (ASTER) Global Digital Elevation Model (GDEM) ASTER GDEM and Shuttle Radar Topography Mission Digital Elevation Model (SRTM-DEM) (Nikolakopoulos, 2020). DEM and SLOPE derived indicators were generated by raster processing and calculation in ArcGIS 10.4. Fig. 4 shows the elevation of the study sites which ranges from 139 m to 480 m and slope is between 0 and 87 degree. Download : Download high-res image (2MB) Download : Download full-size image Fig. 4. Indices generated from ALOS DSM: (a) DEM and (b) SLOPE. Topographic Wetness Index (TWI) generated from digital elevation model (DEM) has been used for soil moisture estimation because TWI is helpful to identify the place where water is accumulated in the specific area with the differences of elevation. TWI highlights the terrain-driven balance of the catchment water supply and the water drainage of specific local areas. However, there are various algorithms such as a flow accumulation, a flow width, or a slope algorithm can be employed to compute TWI. It should be selecting the best one that the TWI obtains the high correlation with soil moisture content. The best TWI for soil moisture prediction is Freeman flow algorithm, local slope, and the equal cell size of flow width which was generated by the following equation (Kopecký et al., 2021) (Fig. 5). (1) Download : Download high-res image (683KB) Download : Download full-size image Fig. 5. TWI mapping in the study site. 2.3.4. Prediction scenarios The prediction accuracy of ML techniques was tested with different scenarios which were developed based on the level of S-1, S-2, and ALOS DSM data fusion and the results from feature selection and optimization using GA. The five scenarios were presented in Table 3. While SC1 comprises of 22 indicators derived from S-2 and 3 indicators from ALOS-DSM, SC2 includes 27 S1 features, and three features derived from ALOS-DSM. SC3 consists of 22 S-2 predictor variables and 27 S1 variables. SC4 contains the total 52 features generated from both S-1, S-2, and ALOS DSM. The potential of 21 optimal features from GA selection for SM prediction was evaluated in SC5.The scenarios were presented in Table 3 below. The aim of scenarios development was to evaluate the impact of the level of different features combinations and the application of feature selection algorithm on how well the SM dynamic prediction went. Table 3. Lists of developed scenarios for soil moisture estimation. Scenario Data fusion Number of features SC1 S-2 + DEM 25 SC2 S-1 + DEM 30 SC3 S-1 + S-2 49 SC4 S-1 + S-2 + DEM 52 SC5 S-1 + S-2 + DEM with feature selection 21 2.4. Machine learning algorithm 2.4.1. Extreme gradient boosting regression (XGBR) Extreme gradient boosting technique is one of gradient tree boosting algorithms which developed by Chen and Guestrin (2016). It has a high performance for supervised learning to handle both regression and classification problems (Ha et al., 2021). The extreme gradient boosting regression (XGBR) algorithm is presented as a scalable end-to-end tree boosting which has widely used to address data mining issues (Chen and Guestrin, 2016). The XGBR is applied commonly because of its high execution speed with parallelization, out-of-core computation, and cache optimization. Data scientists prefer using the ML model due to its scalability in various scenarios, and its high performance for limited data studies. The XGBR model has a large of number of hyperparameters such as learning rate, max_depth, n_estimators, and gamma, which affects its performance. In this study, Optimal XGBR hyperparameters was explored by a Grid Search method with five-fold CV by testing the integration of hyperparameters. 2.4.2. Random forest regression (RFR) The RFR algorithm is a well-known machine learning algorithm and easily applied effectively for various applications due to its simplicity to tune, train, and validate (Breiman, 2001). This ML model consists of a wide range of regression trees. Each regression tree is developed by bootstrapped training samples from the input dataset which can helps reduce the risk of overfitting issues of ML algorithms. In generally, the samples will be separated with about two-thirds of the dataset (in-bag data) for the training samples and the others for the validation samples (Out-Of-Bag (OBB data) (Pham et al., 2020). Three crucial parameters of RFR includes the number of regression trees generated from the bootstrap sample of the observation, the number of prediction features at each node, and the minimal size of the terminal nodes. The selection of these parameters can affect the performance of RFR. 2.4.3. Support vector machine (SVM) The SVM algorithm was developed by Cortes and Vapnik (1995). It is one of the most popular supervised learning techniques using the kernel approach and statistical theory, which can handle for classification, regression, and outlier's detection problems (Cortes and Vapnik, 1995; Cristianini and Ricci, 2008). While the SVM can be applied effectively to death with non-linear problems, this technique does not obtain high performances with a noisy and overlapped dataset. Regularization parameter, the kernel function, and gamma controlling the overfitting are three main hyper-parameters of the SVM model which influences the prediction accuracy of this technique. Four types of kernel function for the SVM are polynomial, sigmoid, linear and radial basis function. The grid search with a five-fold CV was employed to identify the optimal hyper-parameters of each ML algorithm in Jupyter Notebook environment. 2.4.4. CatBoost gradient boosting regression (CBR) CBR is known as a family member of gradient boosted decision trees (GBDT's). It is an interdisciplinary approach for classification and regression tasks in time-series and big data (Hancock and Khoshgoftaar, 2020). It can also solve and minimize the issue of over-fitting by identifying the best tree structure for the calculation of the leaf values (Dorogush et al., 2018). CBR have recently been employed for soil parameters and soil carbon estimation (Xu et al.). Max depth, learning rate, and the number of iterations is the key hyper-parameters of the CBR model. It is similar to XGBR, important hyper-parameters were tuned by hyperparameter tuning using grid search with five-fold CV to select optimal ones which helps improve the CBR model performance. 2.5. Genetic algorithm (GA) for feature selection Features selection is vital for the ML model's performance. It also helps simplify the models, reduce the time for training and testing model, and address overfitting issues. A genetic algorithm with the XGBR method was employed to determine automatically optimal indicators for the SM content retrieval in the study from the total of 52 variables derived from selected RS missions. GA implementation includes the following stages: (1) population formation from soil samples; (2) generation of a mating pool based on the highest fitness individual values; (3) the selection of parents from the mating pool by random selection methods; and (4) the generation of parents' offspring using crossover and mutation operators. The selected generation with optimal features illustrates the lowest root mean squared error, RMSE. In this research, firstly, the prediction accuracy of the four ML algorithms including XGBR, CBR, RFR, and SVM were tested with all 52 generated features. The best predictive model was used with GA to select the optimal features. The prediction performance of selected ML models using the optimal features were then tested and compared. The prediction accuracy of ML models for soil properties can be improved with the use of the GA for the selection of predictor variables (Xie et al., 2015). 2.6. Model performance evaluation To assess the model performance of the soil moisture estimation, two standard testing criteria were used to evaluate the performance of ML techniques with various scenarios including: the root mean square error (RMSE), and the coefficient of determination (R2). Superior model performance illustrates the higher R2 and lower RMSE. These criteria are assessed using the equations below: (2) (3) where: n indicates the number of soil samples; Pi and Oi illustrate the predicted SM value and measured SM value of the i sample, respectively. Akaike's Information Criterion (AIC) and the Bayesian Information Criterion (BIC) indicator were employed to compare the performance of difference ML models for soil moisture estimation. Lower AIC and BIC values illustrated the better prediction accuracy of regression models (Claeskens and Hjort, 2008). These indicators were evaluated using Eqs. (4), (5) below: (4) (5) where: SSE illustrates the sum of squares errors; n indicates the number ò soil samples, and K presents the parameter's number. 3. Results and discussion 3.1. Correlation analysis of predictor indicators and measured SM The relationship between the input features derived from S-1, S-2, ALOS-DSM and measured SM content was computed by Pearson's correlation coefficient method. According to Table 4, indicators derived from ALOS imagery have a higher correlation with the SM content compared to other indicators. While DEM and Slope obtained negative correlations, TWI illustrated a positive correlation with the SM. All vegetation indices generated from S-2 demonstrated negative correlation with the SM content. Some these indices revealed higher correlations with the SM content including NDVI, SAVI, and IRECI. Color index from soil indices had a higher correlation to the SM compared to another SIs. NDWI confirmed a negative and high relationship with the estimation of SM. Regarding to the S-1 derived indicators, most transformation bands obtained weak correlations with the SM content, however; VV, VH, and most GLCM textures from VV confirmed strong relationships with the measured SM. Table 4. Pearson's correlation analysis of input variables and measured SM. Input variables Correlation coefficient (r) Input variables Correlation coefficient (r) B2 0.005 VV-VH 0.076 B3 −0.046 VV/VH −0.045 B4 0.087 VH/VV 0.045 B5 0.064 VH_Contrast −0.073 B6 −0.155 VH_Dissimilarity −0.045 B7 −0.247 VH_Homogeneity 0.022 B8 −0.279 VH_Angular Second Moment −0.037 B8A −0.355 VH_Energy −0.002 B11 0.049 VH_Maximum Probability −0.009 NDWI −0.366 VH_Entropy −0.014 B12 0.125 VH_GLCM Mean −0.437 RVI −0.389 VH_GLCM Variance −0.440 NDVI −0.402 VH_GLCM Correlation 0.042 GNDVI −0.249 VV_Contrast −0.328 NDI45 −0.055 VV_Dissimilarity −0.382 SAVI −0.499 VV_Homo-geneity 0.401 MCARI −0.070 VV_Angular Second Moment 0.332 IRECI −0.568 VV_Energy 0.352 BI 0.031 VV_Maximum Probability 0.311 BI2 −0.111 VV_Entropy −0.377 CI −0.329 VV_GLCM Mean −0.415 RI 0.142 VV_GLCM Variance −0.414 VH −0.414 VV_GLCM Correlation 0.311 VV −0.347 DEM −0.616 (VH + VV)/2 −0.403 Slope −0.495 VH-VV −0.083 TWI 0.368 3.2. Evaluation and comparison of scenarios and different ML models The proposed XGBR model was trained and tested with different scenarios which were developed by various features extracted from S-1, S-2 and ALOS DSM (Table 5). The genetic algorithm procedure with extreme gradient boosting regression was implemented to select the best subset comprising of 21 optimal predictors out of 52 variables with the best accuracy of 0.75. The SC5 with optimal number of features including seven vegetation indices (NDWI, RVI, NDVI, GNDVI, SAVI, MCARI, IREC1), 11 S-1 derived indicators (VH, VV, MeanVHVV, VV_Contrast, VV_Dissimilarity, VV_Homogeneity, VV_Angular Second Moment, VV_Energy, VV_Maximum Probability, VV_Entropy, VV_GLMC Correlation), and both three variables from ALOS DSM yielded the highest SM estimation accuracy with the highest R2 of 0.891 in the validation phase and the lowest RMSE of 0.875%, followed by SC4 with the maximum number of features extracted from selected sensors. A combination of S-2 and ALOS DSM derived predictor features illustrated a higher performance than the combination of S1 and DEM and S-1 and S-2 generated indicators. Table 5. Model performance of the XGBR technique in five scenarios. Scenario (SC) Number of features R2 testing (30%) RMSE (%) SC1 25 0.757 1.307 SC2 30 0.627 1.621 SC3 49 0.469 1.934 SC4 52 0.783 1.236 SC5 21 0.891 0.875 Three well-known ML techniques including CBR, RFR, and SVM were employed to compare the accurate estimation of the SM content with the proposed XGBR-GA model using multi-source EO data fusion. The comparison of ML techniques was conducted with optimal features derived from S-1, S-2, and ALOS DSM. According to Table 6, gradient boosting regression algorithms (XGBR) outperformed RFR and SVM. While XGBR-GA achieved a highest prediction accuracy with R2 = 0.891 and RMSE = 0.875, followed by CBR with R2 = 0.789 and RMSE = 1.217 and SVM with R2 = 0.493 and RMSE = 1.850. The RFR produced a lowest prediction performance with R2 = 0.368 and RMSE = 2.491. Moreover, the XGBR-GA also presented lowest value of AIC and BIC compared to CBR, RFR and SVM. Table 6. Performance comparison of ML algorithms on agricultural SM estimation. No Machine learning model R2 testing (30%) RMSE (%) AIC BIC 1 Extreme gradient boosting regression with GA (XGBR-GA) 0.891 0.875 155.36 194.21 2 CatBoost gradient boosting regression (CBR) 0.789 1.217 157.72 198.46 3 Random Forest regression (RFR) 0.368 2.491 186.49 226.54 4 Support Vector Machine regression SVM) 0.493 1.850 179.58 218.50 Fig. 6 presents the scatter plots of the estimated versus measured the SM content from four well-known ML techniques in testing phase using optimal features. The XGBR with higher R2 value and lower RMSE, AIC, and BIC yielded a better prediction with optimal variables extracted from these multiple sensors using the genetic algorithm compared to CBR, RFR, and SVM. The proposed model using XGBR and GA indicates an R2 value of 0.891, showing a higher prediction result compared to recent SM monitoring studies with R2 reached 0.83 in SM prediction study using S1 and Landsat-7 data in Egypt (Mohamed et al., 2020) and R2 of 0.72 in surface soil moisture estimation using S1 and S2 in India (Tripathi and Tiwari, 2020). Download : Download high-res image (209KB) Download : Download full-size image Fig. 6. Scatter plots of the measured SM and estimated SM using (a) XGBR, (b) CBR, (c) RFR, (d) and SVM. 3.3. Spatial distribution patterns of SM maps Based on scenario 5, the spatial dynamics of SM maps built for the Wests and Cookies areas using S-1, S-2, and ALOS DSM data fusion by the XGBR-GA model are revealed in Fig. 7. The XGBR model for the SM prediction in bare-soil pixels obtained the low level of uncertainty and stable prediction capabilities with the low standard deviation value. The proposed moisture prediction model using the XGBR-GA should be calibrated and tested with large-scale earth observation data, over several of land-use types, and various soil-depths. Download : Download high-res image (580KB) Download : Download full-size image Fig. 7. Maps of SM content in study areas: (a) Wests and (b) Cookies using XGBR-GA combined data fusion. 3.4. Relative importance of SM prediction indicators The estimation accuracy of the SM content has been greatly affected by predictor indicators selection and machine learning algorithm. The higher level of data fusion with optimal feature selection using the GA illustrated better prediction performance for retrieving the SM content. The XGBR had a higher capability to predict the SM pattern. The study also indicated that the GA could help improve the prediction accuracy of the SM estimation which is similar with the results from recent studies using ML models and GA for soil properties estimation (Xie et al., 2015). The successful application of ML models and big data from RS imagery in the SM prediction has been presented in much research at the regional, national and global scale (Carranza et al., 2021; Chaudhary et al., 2021; Cheng et al., 2022; Fang et al., 2021; Ma et al., 2021; Senanayake et al., 2021). The relative importance of optimal features using the GA is presented in Fig. 8. ALOS DSM-derived terrain indices played important roles in the SM prediction. Terrain variables were also mentioned as important indices for the SM prediction in previous studies (Ågren et al., 2021; Leempoel et al., 2015; Zhao et al., 2021). In addition, dual polarization VV, VH, and GLCM textures derived from S-1 are also crucial indices for the SM prediction. The SAR-based prediction indices can improve the estimation of soil moisture (El Hajj et al., 2017; Ma et al., 2020; Zhao et al., 2021). VH was illustrated as the most sensitive index for the SM retrieval in this study. Vegetation indices were selected as optimal features for the SM prediction such as the normalizer difference vegetation index (NDVI), and soil adjusted vegetation index (SAVI) which have been applied for not only vegetation classification, but also further indirectly the SM estimation (Kogan, 1995; Reza et al., 2020). Normalized difference water index (NDWI) from Sentinel 2 also highly correlated with the SM content (Ma et al., 2020). The soil moisture prediction model using the XGBR-GA should be calibrated and tested with large-scale earth observation data, over several of land-use types, and various soil-depths. Download : Download high-res image (76KB) Download : Download full-size image Fig. 8. Variable importance of optimal features derived from multi-source EO data. 4. Conclusion The present work presented a novel framework using the predictor variables from Sentinel datasets at 10 m and ALOS DSM at 30 m spatial resolution with a state-of-art machine learning technique (XGBR) and GA for the SM prediction. It is used for estimating the SM content in study sites of Western Australia. It can be seen that the combination of the selected remote sensing dataset illustrated to be very effective for the SM prediction. High level of data fusion and the GA method for optimal features selection showed remarkably better prediction accuracy than single sensor derived features or scenarios without feature optimization. The XGBR model with 21 optimal prediction variables using genetic algorithm approach illustrated the highest prediction performance (R2 = 0.891, RMSE = 0.875%). In addition, the proposed XGBR model combined with GA algorithm for variables selected can produce SM maps at 10 m spatial resolution using freely remote sensing datasets with a precise accuracy at different scales from field plots to region areas. VH and DEM had the highest relative importance in predicting the SM dynamics. The proposed model should be tested in large-scale areas with various land-use characteristics in further studies. In conclusion, this SM pattern monitoring approach can assist agricultural drought monitoring, the development of appropriate water management strategies, and precision agriculture in terms of climate change. CRediT authorship contribution statement Thu Thuy Nguyen: investigation, writing - original draft, methodology, formal analysis, data curation. Huu Hao Ngo: supervision, investigation, project administration, conceptualization, review & editing. Wenshan Guo: supervision, investigation, review & editing. Soon Wang Chang: investigation, project administration, review & editing. Dinh Duc Nguyen: methodology, formal analysis, resources, review. Chi Trung Nguyen: methodology, data curation, resources. Jian Zhang: methodology, data curation, resources. Shuang Liang: methodology, resources, review. Xuan Thanh Bui: methodology, data curation, review. Ngoc Bich Hoang: methodology, resources, review. Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgements This research was supported by the University of Technology, Sydney, Australia (UTS, RIA NGO; UTS SRS 2021), and the Australian Postgraduate Research Intern (APR. Intern), Astron Environmental Services Company. References Ågren et al., 2021 A.M. Ågren, J. Larson, S.S. Paul, H. Laudon, W. Lidberg Use of multiple LIDAR-derived digital terrain indices and machine learning for high-resolution national-scale soil moisture mapping of the Swedish forest landscape Geoderma, 404 (2021) Google Scholar Aksoy et al., 2021 S. Aksoy, A. Yildirim, T. Gorji, N. Hamzehpour, A. Tanik, E. Sertel Assessing the performance of machine learning algorithms for soil salinity mapping in Google earth engine platform using sentinel-2A and Landsat-8 OLI data Adv. Space Res., 69 (2021), pp. 1072-1086 Google Scholar Breiman, 2001 L. Breiman Random forests Mach. Learn., 45 (1) (2001), pp. 5-32 Google Scholar Carranza et al., 2021 C. Carranza, C. Nolet, M. Pezij, M. van der Ploeg Root zone soil moisture estimation with Random Forest J. Hydrol., 593 (2021) Google Scholar Chaudhary et al., 2021 S.K. Chaudhary, P.K. Srivastava, D.K. Gupta, P. Kumar, R. Prasad, D.K. Pandey, A.K. Das, M. Gupta Machine learning algorithms for soil moisture estimation using Sentinel-1: model development and implementation Adv. Space Res., 69 (2021), pp. 1799-1812 Google Scholar Chen and Guestrin, 2016 T. Chen, C. Guestrin XGBoost Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (2016), pp. 785-794 CrossRefGoogle Scholar Cheng et al., 2022 M. Cheng, B. Li, X. Jiao, X. Huang, H. Fan, R. Lin, K. Liu Using multimodal remote sensing data to estimate regional-scale soil moisture content: a case study of Beijing, China Agric. Water Manag., 260 (2022) Google Scholar Claeskens and Hjort, 2008 G. Claeskens, N.L. Hjort Model Selection and Model Averaging, 330, United Kingdom University Press Cambridge, Cambridge (2008) Google Scholar Cortes and Vapnik, 1995 C. Cortes, V. Vapnik Support-vector networks Mach. Learn., 20 (3) (1995), pp. 273-297 View in ScopusGoogle Scholar Cristianini and Ricci, 2008 N. Cristianini, E. Ricci Support vector machines M.-Y. Kao (Ed.), Encyclopedia of Algorithms, Springer US, Boston, MA (2008), pp. 928-932 CrossRefGoogle Scholar Daughtry et al., 2000 C.S.T. Daughtry, C.L. Walthall, M.S. Kim, E.B. de Colstoun, J.E. McMurtrey Estimating corn leaf chlorophyll concentration from leaf and canopy reflectance Remote Sens. Environ., 74 (2) (2000), pp. 229-239 View PDFView articleView in ScopusGoogle Scholar Delegido et al., 2011 J. Delegido, J. Verrelst, L. Alonso, J. Moreno Evaluation of Sentinel-2 red-edge bands for empirical estimation of green LAI and chlorophyll content Sensors (Basel, Switzerland), 11 (7) (2011), pp. 7063-7081 CrossRefView in ScopusGoogle Scholar Dorogush et al., 2018 A.V. Dorogush, V. Ershov, A. Gulin CatBoost: gradient boosting with categorical features support arXiv preprint arXiv:1810.11363 (2018), 10.48550/arXiv.1810.11363 Google Scholar Dubois et al., 2021 A. Dubois, F. Teytaud, S. Verel Short term soil moisture forecasts for potato crop farming: a machine learning approach Comput. Electron. Agric., 180 (2021) Google Scholar efBabaeian et al., 2021 E. efBabaeian, S. Paheding, N. Siddique, V.K. Devabhaktuni, M. Tuller Estimation of root zone soil moisture from ground and remotely sensed soil information with multisensor data fusion and automated machine learning 260 (2021) Google Scholar El Hajj et al., 2017 M. El Hajj, N. Baghdadi, M. Zribi, H. Bazzi Synergic use of Sentinel-1 and Sentinel-2 images for operational soil moisture mapping at high spatial resolution over agricultural areas Remote Sens., 9 (12) (2017), p. 1292 CrossRefGoogle Scholar Entekhabi et al., 2010 D. Entekhabi, E.G. Njoku, P.E.O. Neill, K.H. Kellogg, W.T. Crow, W.N. Edelstein, J.K. Entin, S.D. Goodman, T.J. Jackson, J. Johnson, J. Kimball, J.R. Piepmeier, R.D. Koster, N. Martin, K.C. McDonald, M. Moghaddam, S. Moran, R. Reichle, J.C. Shi, M.W. Spencer, S.W. Thurman, L. Tsang, J.V. Zyl The soil moisture active passive (SMAP) Mission Proc. IEEE, 98 (5) (2010), pp. 704-716 View in ScopusGoogle Scholar Escadafal, 1989 R. Escadafal Remote sensing of arid soil surface color with Landsat thematic mapper Adv. Space Res., 9 (1) (1989), pp. 159-163 View PDFView articleView in ScopusGoogle Scholar Fang et al., 2021 B. Fang, P. Kansara, C. Dandridge, V. Lakshmi Drought monitoring using high spatial resolution soil moisture data over Australia in 2015–2019 J. Hydrol., 594 (2021) Google Scholar Florinsky et al., 2002 I.V. Florinsky, R.G. Eilers, G.R. Manning, L.G. Fuller Prediction of soil properties by digital terrain modelling Environ. Model Softw., 17 (3) (2002), pp. 295-311 View PDFView articleView in ScopusGoogle Scholar Frampton et al., 2013 W.J. Frampton, J. Dash, G. Watmough, E.J. Milton Evaluating the capabilities of Sentinel-2 for quantitative estimation of biophysical variables in vegetation ISPRS J. Photogramm. Remote Sens., 82 (2013), pp. 83-92 View PDFView articleView in ScopusGoogle Scholar Fu et al., 2010 X. Fu, M. Shao, X. Wei, R. Horton Soil organic carbon and total nitrogen as affected by vegetation types in northern Loess Plateau of China Geoderma, 155 (1) (2010), pp. 31-35 View PDFView articleView in ScopusGoogle Scholar Gago et al., 2015 J. Gago, C. Douthe, R.E. Coopman, P.P. Gallego, M. Ribas-Carbo, J. Flexas, J. Escalona, H. Medrano UAVs challenge to assess water stress for sustainable agriculture Agric. Water Manag., 153 (2015), pp. 9-19 View PDFView articleView in ScopusGoogle Scholar Gao, 1996 B.-C. Gao NDWI—A normalized difference water index for remote sensing of vegetation liquid water from space Remote Sens. Environ., 58 (3) (1996), pp. 257-266 View PDFView articleView in ScopusGoogle Scholar Ge et al., 2019 X. Ge, J. Wang, J. Ding, X. Cao, Z. Zhang, J. Liu, X. Li Combining UAV-based hyperspectral imagery and machine learning algorithms for soil moisture content monitoring PeerJ, 7 (2019), Article e6926 CrossRefGoogle Scholar Georganos et al., 2018 S. Georganos, T. Grippa, S. Vanhuysse, M. Lennert, M. Shimoni, E. Wolff Very high resolution object-based land use-land cover urban classification using extreme gradient boosting IEEE Geosci. Remote Sens. Lett., 15 (4) (2018), pp. 607-611 CrossRefView in ScopusGoogle Scholar Gitelson et al., 1996 A.A. Gitelson, Y.J. Kaufman, M.N. Merzlyak Use of a green channel in remote sensing of global vegetation from EOS-MODIS Remote Sens. Environ., 58 (3) (1996), pp. 289-298 View PDFView articleView in ScopusGoogle Scholar Gómez et al., 2020 D. Gómez, P. Salvador, J. Sanz, J.L. Casanova Modelling desert locust presences using 32-year soil moisture data on a large-scale Ecol. Indic., 117 (2020) Google Scholar Gómez et al., 2021 D. Gómez, P. Salvador, J. Sanz, J.F. Rodrigo, J. Gil, J.L. Casanova Prediction of desert locust breeding areas using machine learning methods and SMOS (MIR_SMNRT2) near real time product J. Arid Environ., 194 (2021) Google Scholar Ha et al., 2021 N.T. Ha, M. Manley-Harris, T.D. Pham, I. Hawes The use of radar and optical satellite imagery combined with advanced machine learning and metaheuristic optimization techniques to detect and quantify above ground biomass of intertidal seagrass in a New Zealand estuary Int. J. Remote Sens., 42 (12) (2021), pp. 4712-4738 CrossRefGoogle Scholar Hancock and Khoshgoftaar, 2020 J.T. Hancock, T.M. Khoshgoftaar CatBoost for big data: an interdisciplinary review J. Big Data, 7 (1) (2020), p. 94 View in ScopusGoogle Scholar Hosoda et al., 2020 M. Hosoda, S. Tokonami, T. Suzuki, M. Janik Machine learning as a tool for analysing the impact of environmental parameters on the radon exhalation rate from soil Radiat. Meas., 138 (2020) Google Scholar Huete, 1988 A.R. Huete A soil-adjusted vegetation index (SAVI) Remote Sens. Environ., 25 (3) (1988), pp. 295-309 View PDFView articleView in ScopusGoogle Scholar Jin et al., 2017 X. Jin, K. Song, J. Du, H. Liu, Z. Wen Comparison of different satellite bands and vegetation indices for estimation of soil organic matter based on simulated spectral configuration Agric. For. Meteorol., 244–245 (2017), pp. 57-71 View PDFView articleView in ScopusGoogle Scholar Karthikeyan and Mishra, 2021 L. Karthikeyan, A.K. Mishra Multi-layer high-resolution soil moisture estimation using machine learning over the United States Remote Sens. Environ., 266 (2021) Google Scholar Kerr et al., 2001 Y.H. Kerr, P. Waldteufel, J. Wigneron, J. Martinuzzi, J. Font, M. Berger Soil moisture retrieval from space: the soil moisture and ocean salinity (SMOS) mission IEEE Trans. Geosci. Remote Sens., 39 (8) (2001), pp. 1729-1735 View in ScopusGoogle Scholar Kingwell et al., 2020 R. Kingwell, N. Islam, V. Xayavong Farming systems and their business strategies in South-Western Australia: a decadal assessment of their profitability Agric. Syst., 181 (2020), Article 102827 View PDFView articleView in ScopusGoogle Scholar Kogan, 1995 F.N. Kogan Application of vegetation index and brightness temperature for drought detection Adv. Space Res., 15 (11) (1995), pp. 91-100 View PDFView articleView in ScopusGoogle Scholar Kopecký et al., 2021 M. Kopecký, M. Macek, J. Wild Topographic wetness index calculation guidelines based on measured soil moisture and plant species composition Sci. Total Environ., 757 (2021), Article 143785 View PDFView articleView in ScopusGoogle Scholar Leempoel et al., 2015 K. Leempoel, C. Parisod, C. Geiser, L. Daprà, P. Vittoz, S. Joost Very high-resolution digital elevation models: are multi-scale derived variables ecologically relevant? Methods Ecol. Evol., 6 (12) (2015), pp. 1373-1383 View in ScopusGoogle Scholar Ma et al., 2020 C. Ma, X. Li, M.F. McCabe Retrieval of high-resolution soil moisture through combination of Sentinel-1 and Sentinel-2 data Remote Sens., 12 (14) (2020), p. 2303 CrossRefView in ScopusGoogle Scholar Ma et al., 2021 G. Ma, J. Ding, L. Han, Z. Zhang, S. Ran Digital mapping of soil salinization based on Sentinel-1 and Sentinel-2 data combined with machine learning algorithms Region. Sustain., 2 (2) (2021), pp. 177-188 View PDFView articleView in ScopusGoogle Scholar Mathieu et al., 1998 R. Mathieu, M. Pouget, B. Cervelle, R. Escadafal Relationships between satellite-based radiometric indices simulated using laboratory reflectance data and typic soil color of an arid environment Remote Sens. Environ., 66 (1) (1998), pp. 17-28 View PDFView articleView in ScopusGoogle Scholar Michalski and Czajewski, 2004 A. Michalski, J. Czajewski The accuracy of the global positioning systems IEEE Inst. Meas. Mag., 7 (1) (2004), pp. 56-60 Google Scholar Mohamed et al., 2020 E.S. Mohamed, A. Ali, M. El-Shirbeny, K. Abutaleb, S.M. Shaddad Mapping soil moisture and their correlation with crop pattern using remotely sensed data in arid region Egypt. J. Remote Sens. Space Sci., 23 (3) (2020), pp. 347-353 View PDFView articleView in ScopusGoogle Scholar Murphy et al., 2008 P.N.C. Murphy, J. Ogilvie, M. Castonguay, C.-F. Zhang, F.-R. Meng, P.A. Arp Improving forest operations planning through high-resolution flow-channel and wet-areas mapping For. Chron., 84 (4) (2008), pp. 568-574 CrossRefView in ScopusGoogle Scholar Nguyen et al., 2022 T.T. Nguyen, T.D. Pham, C.T. Nguyen, J. Delfos, R. Archibald, K.B. Dang, N.B. Hoang, W. Guo, H.H. Ngo A novel intelligence approach based active and ensemble learning for agricultural soil organic carbon prediction using multispectral and SAR data fusion Sci. Total Environ., 804 (2022), Article 150187 View PDFView articleView in ScopusGoogle Scholar Nikolakopoulos, 2020 K.G. Nikolakopoulos Accuracy assessment of ALOS AW3D30 DSM and comparison to ALOS PRISM DSM created with classical photogrammetric techniques Eur. J. Remote Sens., 53 (sup2) (2020), pp. 39-52 CrossRefView in ScopusGoogle Scholar Pasqualotto et al., 2019 N. Pasqualotto, G. D’Urso, S.F. Bolognesi, O.R. Belfiore, S. Van Wittenberghe, J. Delegido, A. Pezzola, C. Winschel, J. Moreno Retrieval of evapotranspiration from Sentinel-2: comparison of vegetation indices, semi-empirical models and SNAP biophysical processor approach Agronomy, 9 (10) (2019), p. 663 CrossRefView in ScopusGoogle Scholar Pham et al., 2020 T.D. Pham, N. Yokoya, T.T.T. Nguyen, N.N. Le, N.T. Ha, J. Xia, W. Takeuchi, T.D. Pham Improvement of mangrove soil carbon stocks estimation in North Vietnam using Sentinel-2 data and machine learning approach GISci. Remote Sens., 58 (1) (2020), pp. 68-87 View in ScopusGoogle Scholar Prasad et al., 2018 R. Prasad, R.C. Deo, Y. Li, T. Maraseni Soil moisture forecasting by a hybrid machine learning technique: ELM integrated with ensemble empirical mode decomposition Geoderma, 330 (2018), pp. 136-161 View PDFView articleView in ScopusGoogle Scholar Reza et al., 2020 H. Reza, Z. Davoud, N. Mohammad Reza, F. Bakhtiar, R. Mehdi Modification on optical trapezoid model for accurate estimation of soil moisture content in a maize growing field J. Appl. Remote. Sens., 14 (3) (2020), pp. 1-19 CrossRefGoogle Scholar Robinson et al., 2008 D.A. Robinson, C.S. Campbell, J.W. Hopmans, B.K. Hornbuckle, S.B. Jones, R. Knight, F. Ogden, J. Selker, O. Wendroth Soil moisture measurement for ecological and hydrological watershed-scale observatories: a review Vadose Zone J., 7 (1) (2008), pp. 358-389 CrossRefView in ScopusGoogle Scholar Rouse et al., 1973 J. Rouse, R.H. Haas, J.A. Schell, D. Deering Monitoring Vegetation Systems in the Great Plains With ERTS (1973) Google Scholar Salim and Islam, 2010 R.A. Salim, N. Islam Exploring the impact of R&D and climate change on agricultural productivity growth: the case of Western Australia* Aust. J. Agric. Resour. Econ., 54 (4) (2010), pp. 561-582 CrossRefView in ScopusGoogle Scholar Schmidt et al., 2020 A. Schmidt, D.B. Mainwaring, D.A. Maguire Development of a tailored combination of machine learning approaches to model volumetric soil water content within a Mesic forest in the Pacific northwest J. Hydrol., 588 (2020) Google Scholar Schönauer et al., 2021 M. Schönauer, K. Väätäinen, R. Prinz, H. Lindeman, D. Pszenny, M. Jansen, J. Maack, B. Talbot, R. Astrup, D. Jaeger Spatio-temporal prediction of soil moisture and soil strength by depth-to-water maps Int. J. Appl. Earth Obs. Geoinf., 105 (2021) Google Scholar Senanayake et al., 2021 I.P. Senanayake, I.Y. Yeo, J.P. Walker, G.R. Willgoose Estimating catchment scale soil moisture at a high spatial resolution: integrating remote sensing and machine learning Sci. Total Environ., 776 (2021) Google Scholar Tucker, 1979 C.J. Tucker Red and photographic infrared linear combinations for monitoring vegetation Remote Sens. Environ., 8 (2) (1979), pp. 127-150 View PDFView articleGoogle Scholar Tuller et al., 2019 M. Tuller, E. Babaeian, S. Jones, C. Montzka, H. Vereecken, M. Sadeghi The paramount societal impact of soil moisture Eos, 100 (2019) Google Scholar Wagner et al., 2013 W. Wagner, S. Hahn, R. Kidd, T. Melzer, Z. Bartalis, S. Hasenauer, J. Figa-Saldaña, P. de Rosnay, A. Jann, S. Schneider, J. Komma, G. Kubu, K. Brugger, C. Aubrecht, J. Züger, U. Gangkofner, S. Kienberger, L. Brocca, Y. Wang, G. Blöschl, J. Eitzinger, K. Steinnocher The ASCAT soil moisture product: a review of its specifications, validation results, and emerging applications Meteorol. Z., 22 (1) (2013), pp. 5-33 CrossRefView in ScopusGoogle Scholar Warner et al., 2021 D.L. Warner, M. Guevara, J. Callahan, R. Vargas Downscaling satellite soil moisture for landscape applications: a case study in Delaware, USA J. Hydrol. Region. Stud., 38 (2021) Google Scholar Xie et al., 2015 H. Xie, J. Zhao, Q. Wang, Y. Sui, J. Wang, X. Yang, X. Zhang, C. Liang Soil type recognition as improved by genetic algorithm-based variable selection using near infrared spectroscopy and partial least squares discriminant analysis Sci. Rep., 5 (1) (2015), p. 10930 View in ScopusGoogle Scholar Tripathi and Tiwari, 2020 A. Tripathi, R.K. Tiwari Synergetic utilization of sentinel-1 SAR and sentinel-2 optical remote sensing data for surface soil moisture estimation for Rupnagar, Punjab, India Geocarto Int. (2020), pp. 1-22 View in ScopusGoogle Scholar Zhao et al., 2021 Z. Zhao, Q. Yang, X. Ding, Z. Xing Model prediction of the soil moisture regime and soil nutrient regime based on DEM-derived topo-hydrologic variables for mapping ecosites Land, 10 (5) (2021) Google Scholar Zhou et al., 2020a T. Zhou, Y. Geng, J. Chen, M. Liu, D. Haase, A. Lausch Mapping soil organic carbon content using multi-source remote sensing variables in the Heihe River basin in China Ecol. Indic., 114 (2020) Google Scholar Zhou et al., 2020b T. Zhou, Y. Geng, J. Chen, J. Pan, D. Haase, A. Lausch High-resolution digital mapping of soil organic carbon and soil total nitrogen using DEM derivatives, Sentinel-1 and Sentinel-2 data based on machine learning algorithms Sci. Total Environ., 729 (2020), Article 138244 View PDFView articleView in ScopusGoogle Scholar Cited by (28) Unleashing the power of machine learning and remote sensing for robust seasonal drought monitoring: A stacking ensemble approach 2024, Journal of Hydrology Show abstract The application of machine learning techniques for smart irrigation systems: A systematic literature review 2024, Smart Agricultural Technology Show abstract Application of machine learning algorithms to model soil thermal diffusivity 2023, International Communications in Heat and Mass Transfer Show abstract Multiscale extrapolative learning algorithm for predictive soil moisture modeling &amp; applications 2023, Expert Systems with Applications Citation Excerpt : Extended historical data enabled us to considerably increase the size of the reliable training data and inform the AI models about the effects of climate extremes – that would likely be captured by longer records – on crop yields. Notably, different from other AI modeling efforts in soil science research used to estimate spatiotemporal variations in soil moisture near ground surface or in the root zone (Dursun & Özden, 2014; Elshorbagy & Parasuraman, 2008; Filipović et al., 2022; Gu et al., 2021; Im et al., 2016; Jamei et al., 2022; Kisekka et al., 2022; Nguyen et al., 2022; Srivastava et al., 2013; Wang, Fang et al., 2022; Wen et al., 2021), the MELA-XAI framework allowed us to extend temporally-limited pointwise (local) soil moisture data back in time at multiple soil depths and locations across a cropland to generate additional reliable data to train and test AI models. Thus, MELA-XAI emerged as a versatile predictive tool to overcome long-standing difficulties associated with short-term availability of local-scale soil moisture data in practice. Show abstract Timely monitoring of soil water-salt dynamics within cropland by hybrid spectral unmixing and machine learning models 2023, International Soil and Water Conservation Research Show abstract Digital Mapping and Scenario Prediction of Soil Salinity in Coastal Lands Based on Multi-Source Data Combined with Machine Learning Algorithms 2024, SSRN View all citing articles on Scopus View Abstract © 2022 Elsevier B.V. All rights reserved. Recommended articles TPE-CatBoost: An adaptive model for soil moisture spatial estimation in the main maize-producing areas of China with multiple environment covariates Journal of Hydrology, Volume 613, Part B, 2022, Article 128465 Jingxin Yu, …, Lili Zhangzhong View PDF Evaluation of machine learning methods to predict soil moisture constants with different combinations of soil input data for calcareous soils in a semi arid area Agricultural Water Management, Volume 234, 2020, Article 106121 Sevim Seda Yamaç, …, Hamza Negiş View PDF Developing pedotransfer functions using Sentinel-2 satellite spectral indices and Machine learning for estimating the surface soil moisture Journal of Hydrology, Volume 606, 2022, Article 127423 Azadeh Sedaghat, …, Hossein Bayat View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 23 Captures Readers: 78 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply."

Paper 2:
- APA Citation: Shafi, U., Mumtaz, R., Anwar, Z., Ajmal, M. M., Khan, M. A., Mahmood, Z., & Qamar, M. (2023). Tackling Food Insecurity Using Remote Sensing and Machine Learning-Based Crop Yield Prediction. IEEE Access, 11, 108640-108657. https://doi.org/10.1109/ACCESS.2023.3321020
  Main Objective: To develop a framework for wheat grain yield prediction using multispectral data, agronomic traits, and machine learning algorithms, and to investigate the optimal sowing time for wheat yield maximization.
  Study Location: Islamabad, Pakistan
  Data Sources: Multispectral data, agronomic traits, field surveys
  Technologies Used: Random Forest, XGB regression, LASSO regression
  Key Findings: 1. LASSO regression achieved the best prediction performance, with an R2 of 0.93 and MAE of 21.72 g/m2.
2. The optimal time for wheat yield prediction was identified as the month of April.
3. The highest average grain yield was obtained from the wheat field sown in November, and the yield decreased with delayed sowing dates.
  Extract 1: "Due to genetic potential of different genotypes, a significant variation is observed in the wheat yield response under different sowing dates.
  Extract 2: "LASSO achieved the best prediction performance with R2 of 0.93, and MAE of 21.72 g/m2."
  Limitations: None
  Relevance Evaluation: The paper is highly relevant to the point of using AI techniques such as anomaly detection and predictive maintenance for improving resilience and fault tolerance in automated irrigation systems. The authors investigate the use of machine learning algorithms, including Random Forest, XGBoost, and LASSO, to predict wheat yield using multispectral data and agronomic traits collected from three experimental fields with different sowing dates. The findings demonstrate the effectiveness of LASSO in predicting wheat grain yield with high accuracy (R2 = 0.93, MAE = 21.72 g/m2). This study contributes to the optimization of crop yield prediction and resource management in automated irrigation systems.
  Relevance Score: 1
  Inline Citation: (Shafi et al., 2023)
  Explanation: The study collected multispectral data in different crop growth stages, agronomic traits, and field surveys to predict wheat grain yield in three plots of various sowing dates. Three regression techniques were applied to estimate yield: Random Forest, XGB regression, and LASSO regression. LASSO achieved the best prediction performance with the highest R2 and lowest MAE, and the optimal prediction window was identified as the month of April.

 Full Text: >
"IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 11 Tackling Food Insecurity Using Remote Sensing and Machine Learning-Based Crop Yield Prediction Publisher: IEEE Cite This PDF Uferah Shafi; Rafia Mumtaz; Zahid Anwar; Muhammad Muzyyab Ajmal; Muhammad Ajmal Khan; Zahid Mahmood; Maqsood Qamar All Authors 2 Cites in Papers 1129 Full Text Views Open Access Comment(s) Under a Creative Commons License Abstract Document Sections I. Introduction II. Materials and Methods III. Results IV. Discussion V. Conclusion and Future Work Authors Figures References Citations Keywords Metrics Abstract: Precise estimation of crop yield is crucial for ensuring food security, managing the supply chain, optimally utilizing resources, promoting economic growth, enhancing climate resilience, controlling losses, and mitigating risks in the agricultural industry. Accurate yield prediction depends upon several interactive factors, including crop genotype, climate conditions, soil fertility, sowing & irrigation plan, and crop management practices. For this purpose, remote sensing data and machine learning (ML) algorithms are emerging as indispensable tools that can significantly increase farm productivity while using minimal resources and reducing environmental impact. In this context, the study presents a framework for wheat grain yield prediction using three regression techniques including Random Forest, Xtreme Gradient Boosting (XGB) regression, and Least Absolute Shrinkage & Selection Operator (LASSO) regression. Various aspects of the three models are investigated and results are compared to explore the optimal technique. Drone-based multispectral sensors are employed to acquire data from three wheat experimental fields with three different sowing dates (SD1, SD2, SD3), and the effect of the seeding plan on crop yield is examined. The prediction performance of models is assessed at different growth stages of the crop using several evaluation metrics. The results show that LASSO achieved the highest performance in April with the coefficient of determination (R2) of 0.93 and mean absolute error (MAE) of 21.72. The average annual predicted yield is 260.54 g/m2, 201.64 g/m2, and 47.29 g/m2 in the wheat field with SD1, SD2, and SD3 respectively. This study can help farmers and agronomists to make informed decisions about crop management activities such as planting & harvest plans, and resource handling. Step-wise workflow of the proposed framework for wheat yield prediction that involves multi-source data collection including drone data along with different agronomic tra...View more Published in: IEEE Access ( Volume: 11) Page(s): 108640 - 108657 Date of Publication: 29 September 2023 Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2023.3321020 Publisher: IEEE Funding Agency: SECTION I. Introduction According to the World Food Programme (WFP) the number of people facing high levels of food insecurity in 2023 more than doubled the number in 2020. The war in Ukraine, supply chain disruptions, the continued economic fallout of the COVID-19 pandemic, heat waves, heavy rainfall, and droughts due to global warming are all factors pushing food prices to all-time highs. Without appropriate solutions, falling crop yields will push many people into poverty. As an example, approximately 43 million people in Africa alone may fall below the poverty line by 2030. Accurate and timely prediction of crop yields of large farmlands using innovative technologies such as UAV monitoring, multi-spectral sensors, satellite imagery analysis, and use of machine learning tools is a promising area of research to tackle world food insecurity. Recognizing the importance of this, the upcoming USA farm bill - a massive piece of legislation that funds agricultural programs budgeted at more than USD $ 1 trillion is expected to direct billions of dollars to such solutions that help farmers conserve resources, fight climate change or cope with disasters. Wheat is the most widely grown crop in the world, owing to its vital role in global food security and contribution to the national economy of a country. For 35% of the world’s population, wheat-based foods serve as their primary source of nutrition crop [1] and contribute more calories & protein to the global diet than any other grain crop. There are various factors that significantly affect the global food supply chain, such as climate change, population growth, urbanization, market trends, pandemics, regional conflicts, plant diseases, availability & management of agricultural resources, etc [2]. In this perspective, timely yield prediction of wheat yield prior to harvesting can help farmers and other stakeholders to plan and implement necessary interventions for mitigating any adverse impact and ensuring food security. For this purpose, several techniques have been developed, including process-based simulation models and data analysis-based statistical algorithms employing multi-source data [3]. Among these techniques, Machine Learning (ML) is a powerful statistical technique that delivers promising results due to its ability to autonomously learn complex relationships and solve complicated real-world problems. Random Forests (RF), Linear Regression, Least Absolute Shrinkage and Selection Operator (LASSO), K-Nearest Neighbor (KNN), Ridge Regression, Support Vector Machine (SVM), Gradient Boosting algorithms, Light Gradient Boosting (LightGBoost), Convolutional Neural Network (CNN), and Deep Neural Network (DNN) are well-known ML techniques for yield prediction [4], [5]. For the prediction of crop yield using ML techniques, data acquisition is a critical preliminary phase that substantially impacts the quality and accuracy of the prediction. In this context, remote sensing platforms are commonly employed to acquire optical, multispectral, and hyperspectral data. Analysis of this data provides useful insights about crop phonology and forms the basis for estimating crop yield [6], [7]. Commonly used remote sensing platforms include satellites, specially equipped planes, and unmanned aerial vehicles (UAVs). Each platform collects data with its own specific spatial & temporal resolution and acquisition rate [8]. Typically, the satellites provide low spatial resolution data with a fixed temporal resolution, which limits their use for certain agricultural applications. Recently, UAVs and drones have become promising substitutes for remote sensing satellites as these can collect high-resolution data with flexible timings, making these more appropriate for crop yield prediction [9] Following data collection, data pre-processing is the next critical process where the collected data is reviewed, formatted, and prepared for further analysis. It includes noise removal, dealing with the inconsistent & missing values, data augmentation & aggregation, feature selection & creation, and discretization etc [10]. The remote sensing data, containing hyperspectral and multispectral information, is used to compute different vegetation indices (VIs) which help to capture several parameters related to crop phenology and growth. These VIs are derived from the measurement of reflected solar radiations across the electromagnetic spectrum that represent specific vegetation characteristics. The most common VIs are the Normalized Difference Vegetation Index (NDVI), Enhanced Vegetation Index (EVI), Soil Adjusted Vegetation Index (SAVI), Leaf Area Index (LAI), Infrared Percentage Vegetation Index (IPVI), Normalized Difference Red Edge Vegetation Index (NDRE), Normalized Difference Water Index (NDWI), Atmospherically Resistant Vegetation Index (ARVI), Wide Dynamic Range Vegetation Index (WDRVI), Green Ratio Vegetation Index (GRVI), and Green Chlorophyll Vegetation Index (GCI) [8], [11], [12]. Subsequently, the computed VIs are utilized as input for the ML algorithm to perform a particular task of interest including yield prediction. Duan et al. [13] used UAV drone imagery to compute several VIs including NDRE, NDVI, GNDVI, EVI, etc, and then employed linear regression for the estimation of rice yield. The results show that NDVI and GNDVI are the most appropriate VIs for rice yield prediction with an estimation error of less than 10%. In another study [14], UAV multispectral data is used to compute WDRVI, NDVI, and GRVI for maize yield prediction. The results indicate that WDRVI is the most relevant VI to predict maize yield with the nitrogen application of 250–300 kg/ha. In addition to the ML techniques, the usage of deep learning (DL) techniques is also becoming increasingly popular in the agriculture sector where deep CNN and long short-term memory networks (LSTM) are commonly employed architectures. Nevaruori et al. [15] used a deep CNN model with six layers to predict the wheat yield using UAV multispectral and optical data. The model was able to accurately predict yield with a mean absolute error of 484.3 kg/ha and a mean absolute percentage error of 8.8%. Similarly, Wang et al. [16], used LSTM to predict the wheat yield using LAI where the MSE was found to be 522.3 kg/ha with a coefficient of determination ( R 2 ) as 0.87. Cao et al. [17] explored the usage of random forest, deep neural network, LSTM, and 1D CNN for wheat yield prediction and compared results obtained from the application of ML and DL techniques. The results reveal that all aforementioned models have the predictive capability to estimate the winter wheat yield with the R 2 ≥0.85 and RMSE≤768 kg/ha. Recent studies highlight the increasing trend of utilizing data from multiple sources to enhance predictive performance. For this purpose, data from heterogeneous sources such as meteorological data, soil-related data, and remote sensing data are exploited. In [18], wheat yield is predicted using multi-source data including remote sensing data, climate data, and soil data. For this purpose, eight different ML techniques are applied to the collected data, where Gaussian process regression (GPR), SVM, and Random Forest (RF) achieved the highest performance with prediction error < 10%. Moreover, the predictive performance is evaluated in the four wheat growth stages to find the best time for predicting the crop yield. Similarly, in [19], a novel approach for crop yield prediction is presented that integrates data from several sensors (RGB, multi-spectral, and thermal infrared) installed on UAV platform which collects extensive data sets related to plant health, growth patterns, and environmental variables. Subsequently, different ML models are applied to combined data including Random Forests, NN, SVM, Cubist, and Ridge Regression for grain yield estimation. The key finding of the study is that multi-sensor data fusion-based yield prediction performed better than individual-sensor data. In [20], crop yield is predicted using MODIS data along with the twelve different climate variables using ML techniques including LASSO, SVM, NN, and FR regression. The results indicate that SVM outperformed with the R2 of 0.79. Another study [21] presents a framework to predict crop yield using data collected from different sources including environmental data, Sentinel-2 data, and yield data. The results show that RF achieved the highest accuracy with the R2 of 0.91. It is observed from the literature that the utilization of data from diverse sources has become common. Moreover, the significant parameters related to crop yield are recorded during the entire growth cycle to perform yield prediction. However, a few studies have investigated the different growth stages to find the most appropriate stage for precise yield estimation. Furthermore, a notable gap exists in the literature pertaining to the influence of sowing dates on crop production and its implications for crop productivity enhancement. While various studies have examined predictive models based on comprehensive datasets, there is a limited focus on the temporal aspect of crop growth, specifically the effect of different sowing dates on subsequent yield production. This gap is particularly significant because the timing of crop sowing has a direct impact on crop development, phenology, and yield. In this context, the proposed study aims to bridge this gap by introducing a framework that incorporates heterogeneous data and predictive models, and also explicitly investigates the impact of different sowing dates on crop yield. For this purpose, multispectral images of the crop field are captured throughout the growth cycle and various VIs are computed to assess crop phenology. Additionally, field surveys are performed to record several agronomic parameters to analyze the behavior of crop growth. Subsequently, different prediction models are applied to the collected datasets and further evaluated for different growth stages to discover the time window that optimally captures the crop progression. The step-wise workflow of the proposed framework for wheat grain yield prediction is shown in Figure 1. FIGURE 1. Wheat grain yield prediction workflow. Show All The objectives of this research are listed below: Feature Selection for Prediction: To select the best set of predictors for enhancing the prediction performance Optimal Time for Prediction: To identify the suitable time window for accurate wheat yield prediction Best Regression Model Selection: To identify the most appropriate prediction model for wheat yield estimation. Optimal Sowing Timing: To explore the effects of different sowing dates on crop yield and find the best time for crop sowing. In light of these objectives, the research endeavors to provide valuable insights into the optimization of wheat yield prediction by leveraging different data sources, temporal considerations, and robust predictive modeling techniques. SECTION II. Materials and Methods A. Study Area and Experimental Design This research is based on data collected from the wheat experimental field of the National Agricultural Research Centre (NARC), located in Islamabad, Pakistan (33.6692481° N, 73.1076928° E). The experimental field consists of three main plots where wheat is grown with three different sowing dates (SD) including (i) SD1: Nov 15, 2021, (ii) SD2: Dec 15, 2021, (iii) SD3: Jan 15, 2022. Each of these plots is further divided into three replications and each replicate contains plots of 15 different wheat varieties of area (1.5m X 6m). Wheat seeds of fifteen different varieties (V1, V2,...V15) are planted at the rate of 112.5 g/plot in every replicate. Hence, there are 45 plots for each SD organized in three replicates and each replicate contains 15 plots corresponding to 15 varieties of wheat seed to minimize statistical error for the study. The experimental setup utilized a randomized complete block design (RCBD) as illustrated in Figure 2. FIGURE 2. Experimental design (a) Study area, (b) Experimental field layout. Show All B. Data Preparation 1) Data Collection For the purpose of wheat yield estimation, data pertaining to multispectral bands and various agronomic traits are collected during the whole growth cycle of the crop. The multispectral data is captured by DJI Phantom 4 drone mounted with the Sentera multispectral imager that acquires red and near-infrared (NIR) bands. The drone is employed to collect aerial imagery of the field using a flight pattern that is fully automated and designed using customized Sentera ‘FlightAgent’ software. For data acquisition, multiple flights are carried out at the height of 80ft with more than 80% overlapping of ground coverage during days of clear skies and minimal wind speeds, between 10:00 am to 11:00 am local time. Drone data collection was initiated in February 2022, coinciding with the ‘single shot stage’ of the crop sown under SD3, and concluded during the ‘ripening stage’ of the crop sown under SD1. Subsequently, data was acquired via eight drone sessions on the following dates: (i) February 10, 2022, (ii) February 21, 2022, (iii) March 2, 2022, (iv) March 11, 2022, (v) March 17, 2022, (vi) March 31, 2022, (vii) April 8, 2022, (viii) April 15, 2022. After capturing multiple individual images covering the entire experimental field, the raw images are processed to generate a mosaic using WebODM which is an open-source software developed by OpenDroneMap [22]. This powerful tool is capable of generating point clouds, georeferenced models, elevation models, and 3D maps. It provides support for multiple processing engines, enhancing the efficiency of UAV and satellite image processing using Structure from Motion (SfM) and Multi-View Stereo (MVS) techniques. The software employs a web-based interface, simplifying the utilization of complex image processing algorithms. Its primary objective is to analyze extensive datasets and transform photographs into accurate georeferenced outputs. These outputs find applications in diverse fields like agriculture, urban planning, and environmental monitoring, among others. After generating the ortho mosaic images by WebODM, the resultant images are further segmented into 135 polygonal shapes in order to extract valuable insights for the crop sown in each plot. Additionally, several ground surveys were performed during the month of March 2022 and April 2022; where the wheat crop undergoes different development stages with respect to their sowing dates. Subsequently, the parameters related to wheat yield are recorded including the number of tillers/m2, bundle weight/m2, and grains weight/m2, where all collected data is used to predict the wheat yield. 2) Data Preprocessing It is an essential phase that involves transforming the raw data into an appropriate format prior to the application of advanced data analysis techniques. It mainly focuses on data cleaning, feature engineering, data scaling, dealing with categorical features, data integration, and feature selection [23], [24]. In order to enhance the quality of the data for regression analysis, we performed the following preprocessing steps considering our dataset: Data Cleaning: It is a mandatory phase prior to applying the regression technique and leads to the high performance of the ML model. For this purpose, the collected data is deeply analyzed to check for outliers, missing values, noise, and inconsistencies in the data points. Observed anomalies in the dataset are removed prior to the application of ML. Feature Engineering: It involves the manipulation of data to extract underlying significant patterns using domain knowledge that substantially impacts the performance of ML algorithms. For this study, nine features are generated from the collected data including six VIs, crop growth stage, no. of tillers/m2, and bundle weight/m2. Subsequently, these features are fed into regression models to predict the grain yield. Data Scaling: It refers to transforming the data to fit inside a certain range to improve the effectiveness of the ML model. Later, data scaling is applied to the computed features to fit them into a specific scale of [0-1]. One hot Encoding: It is a technique used to deal with the categorical features in the dataset as discussed in [25], [26]. In the collected feature set for wheat grain yield prediction, the growth stage is a categorical feature that has been transformed into a numerical feature using one-hot encoding. Feature selection: It is an important preprocessing phase that boosts the performance of the ML regression model and prevents overfitting. In this step, a subset of the most relevant features is selected from the large feature set to perform regression analysis. The feature set created for the wheat grain yield prediction contains nine features. The top ‘k’ most important features, out of the complete feature set, are selected by computing the correlation of each feature with the target variable [27]. C. Vegetation Indices (VIs) Vegetation Indices (VIs) are derived from the measured values of surface reflectance at two or more wavelengths to emphasize a specific characteristic of vegetation. The multispectral data collected by the drone is used to compute several VIs including NDVI, SR, IPVI, SAVI, OSAVI, and TSAVI by using relationships and hyperparameters as given in Table 1. TABLE 1 Vegetation Indices Figure 3 shows various VIs, computed in the month of February, for the crop sown on different dates i.e., SD1, SD2, and SD3. It is evident from Figure 3 that all computed VIs have higher values in the wheat field with SD1 where the crop is in the ‘stem elongation’ stage. On the other hand, the crop with SD2 is in the ‘tillering stage’ and all VIs have slightly smaller values as compared to the early planted wheat crop with SD1. However, all VIs have very small values in the wheat field with SD3 which is still in the ‘single shot’ stage. It is also evident from these plots that the wheat crop with SD1 is in the ‘50% heading’ stage, the wheat crop with SD2 is in the ‘booting’ stage, and the wheat crop with SD3 is in the ‘stem elongation’ stage. Subsequently, the variation in all computed VIs with respect to the crop growth can be visualized in Figure 4 which lists observed parameters in the month of March. Likewise, Figure 5 depicts the values of VIs in the month of April where the wheat crop with SD1 is in the ‘50% ripening’ stage, the wheat crop with SD2 is in the ‘milk development’ stage, and wheat crop with SD3 is in the ‘100% heading’ stage. FIGURE 3. Statistical data distribution of all computed VIs corresponding to different sowing dates SD1, SD2, and SD3 in the month of February 2022. Show All FIGURE 4. Statistical data distribution of all computed VIs corresponding to different sowing dates SD1, SD2, and SD3 in the month of March 2022. Show All FIGURE 5. Statistical data distribution of all computed VIs corresponding to different sowing dates SD1, SD2, and SD3 in the month of April 2022. Show All D. Regression Techniques After preprocessing the collected data, different regression techniques are employed to predict the grain yield of the wheat crop. These techniques are discussed in the following subsections: Least Absolute Shrinkage and Selection Operator (LASSO): It is a popular regression technique that uses a statistical approach to determine the linear relationship between features and the target variable [34]. To prevent overfitting and optimize feature selection, a penalty term is incorporated into the cost function that incentivizes the model to choose a subset of the most significant features. The goal of LASSO regression is to find the set of predictor variables that strongly influence the output while penalizing the magnitude of the regression coefficients to avoid overfitting. This is accomplished by employing a penalty term that represents the total of the absolute values of the regression coefficients. In this way, regression coefficients having the least relevance to output are effectively set to zero, removing the corresponding predictors from the model [35]. LASSO is particularly useful for high dimensional data having a large number of predictor variables and some of these may not be relevant for predicting the outcome variable. In this research study, the LASSO regression is applied with the regulation parameter ‘alpha’ set to 0.1. Random Forest: It is a well-known decision tree-based ensemble technique used for ML classification and regression problems [36]. The basic idea is to develop several decision trees, where each decision tree is developed utilizing a subset of features and a random sample of data. In order to predict the target value, each decision tree generates an output and the final value is evaluated by aggregating all generated outputs [37]. Random forest is considered a robust ML model that can deal with noisy data and multiple features without overfitting. To predict wheat grain yield, the random forest is applied with the number of the estimator set to 100 while the ‘squared_error’ function is employed for assessing the quality of the split. Xtreme Gradient Boosting (XGB) Regression: It is another powerful ensemble learning-based ML model employed for both regression and classification [38], [39]. This technique combines different weak models (commonly decision trees) to generate a stronger model. It iteratively builds and combines decision trees to reduce the loss function during each iteration in such a way that the new model attempts to rectify the errors of previous decision trees. In order to find the best hyperparameters of XGB, ‘GridSearchCV’ is used where the model is tested against several values and combinations of hyperparameters. Subsequently, the XGB regression model with ‘n_estimator’ value of 100, and a ‘max_depth’ value of 3 is used to predict grain yield. In order to evaluate the performance of the regression models, the following commonly employed evaluation metrics have been used [40]: Coefficient of determination (R2): It is a dimensionless metric in the range from 0 to 1 that is used to assess the ability of the regression model to predict the outcome. It represents the percentage of the variance in the dependent variable (target variable) that can be predicted from the independent variables (feature variables). A higher value of the coefficient implies better prediction performance. It is computed by using Eq 1. R 2 =1− ∑ n i=1 ( y i − y i ^ ) 2 ∑ n i=1 ( y i − y ¯ ) 2 (1) View Source where n is the number of data points, y i ^ is the predicted value of the dependent variable for the i th data point, y i is the actual value of the outcome for the i th data point, and y ¯ is the mean value of the dependent variable. Mean Absolute Error (MEA): This metric assesses the performance of the regression model by measuring the average absolute deviation between the predicted values and the actual value. It is evaluated using the Eq 2. MEA= 1 n ∑ i=1 n | y i − y i ^ | (2) View Source where y i is the actual value of the output variable for the i th data point, y i ^ is the predicted value of the output variable for the i th data point, and n is the number of observations in the dataset. Root Mean Square Error (RMSE): It is a commonly used statistical parameter to evaluate the prediction performance of the regression model. It is based on the square root of the average squared difference between the predicted values and the actual values of the output variable. It is calculated by using Eq 3. RMSE= 1 N ∑ i=1 N ( y i ^ − y i ) 2 − − − − − − − − − − − − −  ⎷   (3) View Source where y i is the actual value of the output variable for the i th data point, y i ^ is the predicted value of the output variable for the i th data point, and n is the number of observations in the dataset. SECTION III. Results In order to predict the wheat grain yield, three regression techniques are selected including random forest, LASSO, and XGB. All three techniques are commonly employed in situations having multiple features while avoiding overfitting. The collected dataset comprised nine features including the number of tillers, bundle weight, SR, SAVI, OSAVI, IPVI, NDVI, TSAVI, and growth stages. The target feature for prediction was grain weight. To analyze the relationship between the selected feature variables with the target variable, the correlation matrices are created for the three different growth stages of the wheat crop as shown in Figure 6, 7, and 8. However, the values of correlation matrices vary according to the growth stage of the crop. In the month of February, all computed VIs are highly correlated with the target variable; whereas the values of correlation coefficients start to decrease in March and April. These variations in the values of VIs are attributed to the chlorophyll content in the vegetation which keeps on increasing until the wheat crop reaches the grain-filling stage and then starts declining for the rest of the growth cycle. It is noteworthy that the dataset collected in February does not include the parameters ‘Bundle weight’ and ‘Number of tillers’, as these particular parameters were not recorded until March 2022. FIGURE 6. Correlation of input features with the target variable in February 2022. Show All FIGURE 7. Correlation of input features with the target variable in March 2022. Show All FIGURE 8. Correlation of input features with the target variable in April 2022. Show All It is evident from Figure 6, 7, 8 that the feature variables have correlations with each other leading to multicollinearity which makes it difficult to determine the individual effect of the features on the target variable. To address this problem, correlation statistics are used to compute ‘k’ most important and relevant features. For this purpose, the correlation of each feature variable with the target variable is computed and converted to an F-value representing the feature importance score. Figure 9 shows the F-value of all numerical features in different growth stages of the wheat crop. FIGURE 9. Feature selection using correlation statistics (a) February 2022 (b) March 2022 (c) April 2022. Show All The features with the highest F-value are selected for regression, whereas the rest of the features are eliminated from the model to avoid overfitting. In the month of February, the selected features were ‘NDVI’, ‘IPVI’, ‘SAVI’, ‘TSAVI’, and ‘OSAVI’; where the remaining features have been not considered. However, in the month of March, ‘bundle weight’ has the largest F-value followed by ‘SR’ and ‘TSAVI’. The remaining VI features have an equal F-value; where ‘NDVI’ is selected after assessing its effect on regression. Likewise, ‘Bundle weight’, ‘No of tillers’, ‘Growth stage heading complete’, and ‘NDVI’ are the selected features for the month of April. The feature selection phase addressed the first objective of the research i.e., to select the best set of predictors for enhancing the prediction performance. After feature selection, the regression models are applied in different growth stages of wheat crops and their performance is evaluated using three metrics: R2, MAE, and RMSE. For this purpose, the dataset comprising all sowing dates is divided into training and testing splits with a ratio of 7:3 respectively. Table 2 shows the performance comparison of the regression models on the data collected in February 2022; whereas Figure 10 illustrates the deviation between the predicted and actual wheat grain yield on a testing split containing 37 data points. It is apparent from Table 2 that LASSO generates the best prediction results with R2 of 0.92, MAE of 27.95 g/m2 and RMSE 33.32 g/m2. However, Random Forest performed better than XGB with R2 of 0.90, MAE of 28.49 g/m2. TABLE 2 Performance Comparison of Regression Techniques Applied to the Data Collected in February 2022 FIGURE 10. Deviation between the actual and the predicted grain yield in February 2022. Show All Similarly, Table 3 presents the performance comparison of regression techniques applied to the dataset collected in March 2022. Best results are again generated by LASSO giving the highest R2 of 0.93 with the MAE of 22.91 g/m2 and RMSE of 31.06 g/m2. Figure 11 shows the predicted grain yield versus actual grain yield against three regression techniques based on observations made in the month of March. TABLE 3 Performance Comparison of Regression Techniques Applied to the Data Collected in March 2022 FIGURE 11. Deviation between the actual and the predicted grain yield in March 2022. Show All Table 4 compares the results of three regression models on the basis of data collected in April 2022. The predicted grain yield for the various regression techniques versus actual yield is shown in Figure 12. These results clearly demonstrate that LASSO once again performed better than Random Forest and XGB for the dataset from the month of April. TABLE 4 Performance Comparison of Regression Techniques Applied to the Data Collected in April 2022 FIGURE 12. Deviation between the actual and the predicted grain yield in April 2022. Show All In order to evaluate the influence of individual features on regression performance, the widely used SHAP (Shapley Additive explanations) method is employed [41]. The SHAP feature importance graphs provide a comprehensive insight into the model’s interpretability and sensitivity to individual features and their contributions to predictions. To quantify the performance of each feature on the prediction model, all possible combinations of features are considered, and computing the difference in predictions when a particular feature is included versus when it is excluded. This difference served as SHAP value which signifies the degree of influence a feature wields on a prediction in comparison to its absence. Figure 13, 14, and 15 illustrate SHAP feature importance graphs that are computed on the datasets collected in February 2022, March 2022, and April 2022. FIGURE 13. Contribution of each feature using SHAP value on data collected in February 2022. Show All FIGURE 14. Contribution of each feature using SHAP value on data collected in March 2022. Show All FIGURE 15. Contribution of each feature using SHAP value on data collected in April 2022. Show All It is evident from the SHAP feature importance graphs that all selected features demonstrate roughly equal contributions in the case of Random forest on the dataset collected in February 2022. However, ‘NDVI’, and ‘SAVI’ have a significant contribution in the case of LASSO regression; whereas ‘NDVI’ has a dominant contribution in the case of XGB regression. Conversely, a distinct pattern emerges with the data collected in March 2022 and April 2022. where ‘Bundle weight’ has more contribution than any other feature. Similarly, the comprehensive visual representation of each feature’s contribution across all regression techniques can be observed in Figures 13, 14, and 15. In conclusion, the analysis of these graphs offers valuable insights into the influential dynamics of specific features in shaping the model’s outcome. Notably, changes in features with high positive SHAP values (indicated by red color code) can lead to proportionate shifts in predictions, while those with negative values(indicated by blue color code) might cause counteractive shifts. This profound understanding of feature importance not only enhances interpretability but also sheds light on the intricate relationships between input variables and outcomes. Furthermore, to conduct an in-depth analysis of the performance exhibited by various regression techniques, different graphs have been generated including a violin graph, Taylor diagram, and scatter plot as shown in Figure 16, 17, and 18. The violin graphs provide a statistical summary of actual versus predicted wheat grain yield by different regression techniques. Whereas, the scatter plots illustrate the difference in actual versus predicted wheat grain yield by plotting test data. However, Taylor diagrams provide deeper insights into the model performance in terms of standard deviation ratio, correlation, and centered root-mean-square error from the reference dataset [42]. These graphs offer a holistic view of how well each regression technique matches up against the true data, allowing for a deeper understanding of their relative performance. It is evident from these graphs that the regression results are pretty good on the dataset collected in April 2022 as compared to February 2022 and March 2022. Furthermore, it is notable that the LASSO regression technique produces prediction results that more closely approximate the actual dataset. FIGURE 16. Performance comparison of regression techniques in February 2022 using (a) Violin graph showing the statistical summary of predicted and actual wheat grain yield, (b) Taylor diagram exhibiting the model performance in terms of standard deviation ratio, correlation, and centered root-mean-square error from the reference dataset and (c) scatter plot illustrating the difference in actual and predicted values of wheat grain yield on test dataset. Show All FIGURE 17. Performance comparison of regression techniques in March 2022 using (a) Violin graph showing the statistical summary of predicted and actual wheat grain yield, (b) Taylor diagram exhibiting the model performance in terms of standard deviation ratio, correlation, and centered root-mean-square error from the reference dataset and (c) scatter plot illustrating the difference in actual and predicted values of wheat grain yield on test dataset. Show All FIGURE 18. Performance comparison of regression techniques in April 2022 using (a) Violin graph showing the statistical summary of predicted and actual wheat grain yield, (b) Taylor diagram exhibiting the model performance in terms of standard deviation ratio, correlation, and centered root-mean-square error from the reference dataset and (c) scatter plot illustrating the difference in actual and predicted values of wheat grain yield on test dataset. Show All It can be observed from the regression results that minimum MAE and RMSE are achieved by LASSO in the month of April 2022. This addresses the second research objective of this study i.e., to identify the suitable time window for accurate wheat yield prediction. The results from Tables 2, 3 and 4 show that LASSO achieved the best performance due to its ability to deal with high dimensional data and avoid overfitting. This addressed the third objective of the research i.e., to identify the most appropriate prediction model for wheat yield estimation. A comparison of an average wheat grain yield versus predicted yield for wheat fields with different sowing dates SD1, SD2, and SD3 is given in Table 5. It can be clearly seen that the highest average grain yield is achieved from the wheat field where the crop was sown on 15 November 2021 (SD1). This finding addressed the fourth objective of this research study i.e., to explore the effects of different sowing dates on the crop yield for identifying the best crop sowing time. TABLE 5 Comparison of Average Predicted and Actual Wheat Grain Yield in the Wheat Field With Different Sowing Dates (SD1, SD2, and SD3) In order to further analyze the growth behavior of the crop with different sowing dates, NDVI maps of the wheat field are developed as shown in Figure 19. The maximum greenness is observed in the month of March 2022 in the wheat field with SD1 which depicts the ideal growth behavior for the wheat crop. On the other hand, less vegetation is observed in the wheat field with SD2, and minimal vegetation is seen in the field having SD3. This is due to the fact that wheat, like any other crop, requires a specific temperature profile for its optimal growth. The wheat fields with SD2 and SD3 are sown in the months of December and January respectively. For wheat sown during these months, the temperature profiles do not match the optimal values required for crop growth, resulting in reduced grain yield. The correspondingly highest yield is obtained for SD1 and wheat production reduces as sowing is delayed beyond the optimal sowing date. FIGURE 19. NDVI profiles of wheat crop in SD1, SD2, and SD3. Show All It is worth mentioning that fifteen different wheat varieties were sown on three different dates in the experimental fields. It has been concluded that the highest average yield was obtained for SD1 and production dropped as sowing was delayed. However, the yield was found to vary for different varieties even for the same sowing date. Figures 20–22 show the wheat grain yield obtained by fifteen different wheat varieties on three different sowing dates (SD1, SD2, and SD3). FIGURE 20. Grain yield of different varieties in a wheat field with sowing date SD1. Show All FIGURE 21. Grain yield of different varieties in a wheat field with sowing date SD2. Show All FIGURE 22. Grain yield of different varieties in a wheat field with sowing date SD3. Show All A. Effect of Different Sowing Dates, Climate Variations and Genotypes on Crop Growth and Yield Varying sowing dates have a great impact on wheat yield. For this purpose, an investigation is carried out to check the response of wheat crop growth and yield of different advanced lines under three diverse sowing dates. The maximum average annual yield is recorded with the sowing date SD1 (292.25 g/m2), followed by sowing date SD2 (180.0 g/m2), and the minimum is recorded with the sowing date SD3 (58.25 g/m2) respectively (Table 5). Among different genotypes (varieties), the maximum yield is recorded with V8 (351 g/m2), followed by V3 (347 g/m2) in the wheat crop with sowing date SD1. Whereas, the minimum yield is recorded with V12 (225 g/m2) respectively as shown in Figure 20. In the wheat field with sowing date SD2, the highest yield is recorded with V13 (218 g/m2) followed by V6 (210 g/m2), and the lowest response is recorded with V9 (153 g/m2) as depicted in Figure 21. Similarly, the response of genotypes sown on sowing date SD3 is different in comparison to SD1 and SD2, where the highest yield is recorded with V14 (119 g/m2), followed by V3 (85 g/m2), and the minimum yield is recorded with V10 (17 g/m2) as illustrated in Figure 22. It is concluded that the maximum yield is obtained with SD1 as compared with the wheat crops sown in succeeding sowing dates. However, due to the genetic potential of different genotypes, a significant variation is observed in the wheat yield response under different sowing dates. SECTION IV. Discussion The crop yield prediction holds significant importance in optimizing agricultural resources and boosting overall productivity. To this end, a field experiment is presented to predict wheat grain yield; where different regression techniques have been investigated including LASSO, Random Forest, and XGB regression. For this purpose, the multispectral data is collected by drone in different crop growth stages along with different agronomic traits. Moreover, the effect of different genotypes and the sowing plan on wheat growth and its yield is analyzed by sowing the crop on three different sowing dates. Subsequently, three regression techniques are applied to three different datasets collected in February 2022, March 2022, and April 2022 to determine the best time window to accurately estimate the wheat crop yield. The results revealed that the best results for wheat grain prediction were observed in the month of April, where LASSO outperformed XGB and Random Forest with the minimum difference between the actual and predicted yield (31.69 g/m2, 21.64 g/m2, and 10.96 g/m2 for SD1, SD2 and SD3 respectively). Figure 16, 17, and 18 illustrate the performance comparison among regression techniques using a violin graph, scatter plot, and Taylor diagram. It is clearly evident that LASSO provides a more accurate estimation of wheat grain yield as compared to XGB and Random Forest. The effectiveness of LASSO in controlling overfitting with limited data, its ability to provide sparse solutions, and its interpretability make it particularly well-suited for addressing this specific problem. In contrast, the Random Forest and XGBoost algorithms, while powerful and capable of handling complex relationships within data, might struggle with limited data. These ensemble methods inherently rely on aggregating multiple decision trees, and their performance typically improves with larger datasets. With a small amount of data, there’s a higher risk of overfitting due to the complexity of these models. Additionally, tuning the hyperparameters of these algorithms becomes crucial, and without sufficient data, finding optimal hyperparameters can be challenging, leading to suboptimal performance. It is observed from the results that the optimal time for sowing the wheat crop is November (SD1); where the maximum grain yield of 351 g/m2 has been recorded. Whereas, the minimum yield of 17 g/m2 has been observed for the crop that was sown lately in January (SD3) due to a reduction in the length of the growing season. The suitable time of sowing is imperative to achieve the maximum yield on a sustainable basis because wheat production is highly sensitive to elevated temperatures. Erratic climate has influenced the optimum time of wheat sowing and grain production by variations in temperature during the growth period of the crop. The process of plant development accelerates due to elevation in temperature; however growth parameters reduced such as leaf area, tillers, and length of the spikes which results in a significant reduction of yield [43], [44]. Late sowing seriously affects germination, growth rate, grain development, and reduced tillering in low temperatures and ultimately concealed yield [45]. Similarly, elevation in temperature during vegetative and reproductive growth stages badly affects the emergence of plants and succeeding crop growth stages [46]. For this purpose, an optimum and appropriate environment results in a higher economic yield which aids genotypes to express their full growth potential. Wheat, as a cereal, requires specific environmental conditions for improved growth and production [43] and is vulnerable if exposed to high temperatures through the reproductive phase at grain formation [47]. The favorable temperature that is essential for the anthesis & grain filling phase of wheat ranges from (12 °C - to 22 °C). High temperature accelerates the process of development of grain filling [48], thus resulting in a reduction of assimilation of carbohydrates, deposition of starch in grains, and yield of grains [49]. With the management of the sowing date, potential variety and environmental factors production of wheat can be increased by 10-80% [50]. Whereas, late planting affects germination, growth, and development of grains and produces poor tillers due to winter injury in low-temperature [45], [51]. Therefore, it is very necessary to find the relationship between varying environments and newly developed genotypes. An appropriate sowing time for wheat plays a significant role in growth and development. However, in varying climatic conditions of Pakistan, it is estimated that yield may be decreased by 58.2 % in delayed sowing practice [52]. The precise and exact information of sowing time of specific variety at a particular location is crucial for meeting the potential yield of grains as discussed in [53]. Optimum environmental conditions are prerequisites for attaining the maximum yield. It has been found from research that each variety has its specific requirements of temperature and light for flowering and development of grains [54], [55]. However, the emergence and number of days to earing for the crop with sowing date SD1 decreased with delayed planting to sowing date SD2. Cultivation of wheat under late sowing results in a reduction of air and soil temperature causing a decrease in the emergence and crop stand establishment [56]. It has been reported in various studies that elevated temperature affects the emergence of crops [57]. Late planted crops decreased no. of tillers due to high temperature during the growth stage of tillering [58] and also decreased the duration of grain filling at the reproductive stage leading to a reduction in enzyme activity and yield of crop [45], [59]. Maximum yield can be obtained when the crop is sown earlier as it received extensive duration of grain filling in comparison with late sowing caused warmer environment. The results obtained from our analysis provide a foundation for practical implementations in the agricultural domain. The benefits of this research lie in its potential to equip farmers and agronomists with valuable insights that can drive more efficient and productive agricultural practices. The farmers could make decisions related to crop management, resource allocation, and harvest planning. Moreover, optimizing crop yield predictions can lead to more efficient resource utilization and improved crop planning, contributing to increased profitability. By addressing crucial gaps and leveraging data-driven insights, this study has the capacity to catalyze positive transformations within the agricultural landscape. that can drive more efficient and productive agricultural practices. SECTION V. Conclusion and Future Work Accurate and timely yield prediction of wheat crops is essential for global food security. Towards this end, a framework for wheat grain yield prediction is presented in this research study. Multispectral data spanning the crop growth cycle from three experimental fields, each planted with the wheat crop at different sowing dates, is collected using drone-based sensors. Following the preprocessing of datasets, the most relevant predictors are identified and three well-known ML regression models including Random Forest, XGB regression, and LASSO regression are employed to estimate crop yield. The results show that LASSO achieved the best prediction performance with R2 of 0.93, and MAE of 21.72 g/m2. The annual predicted yield is found to be 260.54 g/m2, 201.64 g/m2 and 47.29 g/m2 for the crop sown in November (SD1), December (SD2) and January (SD3) respectively. Additionally, the best prediction results are obtained from the observations made in the month of April. This research will help farmers and agronomists to timely and accurately estimate crop yields and manage crop resources prior to harvesting. At present, the estimation of wheat grain yield is accomplished through the use of multispectral data and machine learning techniques. However, in the future, we plan to explore deep learning techniques like CNN, LSTM, etc., to analyze drone optical data for crop yield forecasting. In addition, we plan to integrate more predictors like soil and climate data for enhancing the accuracy of yield estimation. Authors Figures References Citations Keywords Metrics More Like This An Enhanced Approach for Crop Yield Prediction System Using Linear Support Vector Machine Model 2022 International Conference on Communication, Computing and Internet of Things (IC3IoT) Published: 2022 Research and prediction of Shanghai-Shenzhen 20 Index Based on the Support Vector Machine Model and Gradient Boosting Regression Tree 2020 International Conference on Intelligent Computing, Automation and Systems (ICICAS) Published: 2020 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."

Paper 3:
- APA Citation: Hendrawan, V. S. A., Kim, W., Touge, Y., Ke, S., & Komori, D. (2023). A global-scale relationship between crop yield anomaly and multiscalar drought index based on multiple precipitation data. Environmental Research Letters, 17(1), 014037. https://doi.org/10.1088/1748-9326/ac45b4
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: Soybean and wheat yield loss is more associated with longer drought time scales (6–12 months); in contrast, rice and maize yield loss responds to short-medium drought time scales (1–8 months).
  Extract 2: Results indicate that temperature, GDP per capita, and water balance are critical parameters controlling the response of crop yield to drought time scales.
  Limitations: ['The study does not consider the potential impact of extreme weather events, such as heat waves and cold spells, on crop yield.', 'The study relies on global datasets and may not capture the local-scale variability in crop response to drought.', 'The study does not consider the role of agricultural management practices in mitigating the effects of drought on crop yield.', 'The study does not analyze the long-term trends in crop yields and the potential impact of climate change on these trends.']
  Relevance Evaluation: ['The study is directly relevant to the specific point mentioned in the outline as it investigates the impact of drought characterized by multiple meteorological time scales on major crop yields (maize, rice, soybean, and wheat) from 1981–2016 globally.', 'The study provides insights into the influence of key determinants on crop yield response and considers various factors such as temperature, GDP per capita, and water balance, which are related to the point in the outline about examining automation across the entire pipeline.']
  Relevance Score: 1.0
  Inline Citation: (Hendrawan et al., 2023)
  Explanation: The study analyzes the impact of drought characterized by multiple meteorological time scales (drought indices with various accumulation periods) on major crop yields (maize, rice, soybean, and wheat) from 1981–2016 globally. The study reveals significant differences in crop response across different drought time scales. Soybean and wheat yield loss is more associated with longer drought time scales (6–12 months); in contrast, rice and maize yield loss responds to short-medium drought time scales (1–8 months). The study also investigates the influence of key determinants on crop response. Results indicate that temperature, GDP per capita, and water balance are critical parameters controlling the response of crop yield to drought time scales. Warmer temperatures make crops more susceptible to short-term drought, while higher GDP per capita in a region may determine better coping capacities with drought impacts. The study contributes to understanding the multifaceted effects of drought and climate change on crop yields.

 Full Text: >
"Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Abstract Keywords 1. Introduction 2. Materials 3. Methods 4. Results 5. Discussion 6. Conclusion Declaration of Competing Interest Appendix A. Supplementary material Data Availability References Show full outline Cited by (1) Figures (5) Tables (2) Table 1 Table 2 Extras (1) Supplementary material Anthropocene Volume 43, September 2023, 100389 Crop response pattern to several drought timescales and its possible determinants: A global-scale analysis during the last decades Author links open overlay panel Vempi Satriya Adi Hendrawan a, Wonsik Kim b, Daisuke Komori c d Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.ancene.2023.100389 Get rights and content Under a Creative Commons license open access Abstract Crop response characteristics to different timescales of precipitation deficit may represent crop system resilience to drought characteristics. In this study, we assess the crop yield response of major crops to meteorological drought estimated by a standardized precipitation index with multiple timescales (1–12 months) during 1981–2016 all over the globe. We estimate that about one- to two-thirds of global harvested areas of maize, rice, soybean, and wheat, were significantly affected by various drought timescales. Soybean and wheat might respond to more prolonged droughts, while rice and maize responded to short-medium drought time scales. Using multiple machine learning models, we reveal that set of determinants could explain most variations of crop response to drought timescale with average accuracies between 45.7% and 56.0% (across models and crop types). Moreover, this study suggests that crops in warmer and higher water availability (precipitation minus potential evapotranspiration) might respond significantly to more short-term drought. The other factors (i.e., socioeconomic, fertilizer, soil, topography, production, irrigation) shows a complex and weaker effect on defining crop vulnerability to the various drought characteristics. This study attempts to fill the gaps in understanding global crop resistance to different drought characteristics. The future challenge in understanding the multifaceted effect of physical and socioeconomic factors on global crop vulnerability to drought may remain and should be addressed in further studies. Previous article in issue Next article in issue Keywords Meteorological droughtCrop yieldCrop-drought determinantsDrought timescales 1. Introduction Drought risk is a serious problem affecting losses and damages in many sectors, such as agriculture (e.g., crop losses), environment (e.g., wildfire), and socioeconomic sectors (e.g., famine, human loss, poverty) (Heim, 2002, Mishra and Singh, 2010, Wilhite and Glantz, 1985). Agriculture, particularly crops, is one of the most affected sectors by drought. As one of the extreme climate phenomena, drought can control crop yield variation by causing a lack of water availability, low plant development, and accordingly causing crop yield reduction or failure (Daryanto et al., 2016, Lu et al., 2017). Drought can be identified as four different types: meteorological, agricultural, hydrological, and socioeconomic drought, which is represented by precipitation deficit, soil moisture triggering lack of water supply to crops, streamflow deficit (i.e., low water level reservoir and groundwater deficit), and water supply deficit affecting the society as a subsequent impact of the drought (Spinoni et al., 2014, Wilhite and Glantz, 1985). Meteorological drought is the first adverse consequence of the natural water deficit triggered by a lack of precipitation (Guo et al., 2020, Zargar et al., 2011). Different accumulated precipitation deficits over time can induce different impacts on each terrestrial system. For example, an accumulated precipitation deficit over 1-month may induce soil moisture and crop stress during the growing season, while a 12-month precipitation deficit may trigger reservoir and groundwater level depletion (Spinoni et al., 2014, Zargar et al., 2011). The drought timescale may be used to understand crop vulnerability to drought, as different crop systems may respond to drought in a unique process (Barker et al., 2016, Zargar et al., 2011). The drought timescale may be used to understand crop vulnerability to drought, as different crop systems may respond to drought in a unique process (Barker et al., 2016). The drought impact on crops depends on how drought is defined and is related to the drought timescale, duration, and severity (McKee et al., 1993), as well as the character of each crop’s resistance (Chaves et al., 2003, Daryanto et al., 2016). Previous studies have assessed crop drought impact using multiple drought timescales (Peña-Gallardo et al., 2019a, Swain et al., 2022a, Vicente-Serrano et al., 2012, Zhang et al., 2019). A drought timescale can be referred to as the time (e.g., months) during which the event develops (Hayes, 2001). Drought indices with multiple timescales have been used to define a specific drought event for various terrestrial systems (Mishra and Singh, 2010, Zargar et al., 2011). Among them are the Standardized Precipitation Index (SPI) (McKee et al., 1993) and Standardized Precipitation Evapotranspiration Index (SPEI) (Vicente-Serrano et al., 2010) have been more extensively used in local or global scale studies. SPI is defined as a meteorological drought with precipitation as the input and is recommended by the World Meteorological Organization (WMO) for drought monitoring (Hayes et al., 2011). SPEI was developed by Vicente-Serrano et al. (2010), using precipitation and evapotranspiration as inputs, considering the important meteorological component other than precipitation. Previous studies have compared their skill to identify drought periods for various applications (Guttman, 1998, Hoffmann et al., 2020, Mishra and Singh, 2010). Some studies indicated the advantage of SPI due to a simple drought representation as the other drought index may require additional variables (i.e., evapotranspiration), which are not widely available and can introduce more complex drought parameterization (Hoffmann et al., 2020, Trenberth et al., 2014). Nonetheless, particularly for agricultural applications, SPEI can also be used as it considers temperature to indicate evaporative demand as one of the important parameters for crop development (Lobell and Field, 2007, Matiu et al., 2017, Peña-Gallardo et al., 2019b). Most studies have linked different drought timescales to vegetation response using several vegetation activity indicators to obtain which drought timescale and period are impactful to vegetation (Vicente-Serrano et al., 2013, Xu et al., 2018). However, the application of a multiscalar drought index for detecting crop anomalies using yield data on a global scale was sparse. Most of the studies were conducted in a local or regional study using aggregated crop yield statistics on a sub-country scale (e.g., city, county, province) (Bachmair et al., 2018, Peña-Gallardo et al., 2019b, Zipper et al., 2016). The spatially explicit global-scale analysis was still limited due to global crop yield data availability in a finer resolution (i.e., grid-scale) (Kim et al., 2019). The most widely used dataset for global-scale analysis was either country-level yield statistics from The Food and Agriculture Organization of the United Nations (FAO) (Lobell and Field, 2007, Vicente-Serrano et al., 2012) or yield data from crop growth modeling (Wang et al., 2017). Currently, a gridded global dataset of historical yields for major crops has been developed for the major crops (maize, rice, soybean, and wheat) (Iizumi et al., 2014, Iizumi and Sakai, 2020). This dataset allows us to extract valuable crop yield anomalies due to various impacts (i.e., drought) in a more spatially explicit way rather than on an aggregated scale. Furthermore, while there have been many field-based and local studies on determining factors influencing crop yield response to drought, there are limited global-scale studies providing pieces of evidence on potential determinants by which drought stress accumulates in crops and reduces crop productivity (Peña-Gallardo et al., 2019b, Yang et al., 2020). Previous studies have shown that the impact of drought on crops can be influenced by various factors, including crop type, climate, soil, and irrigation practices (Daryanto et al., 2016, Fahad et al., 2017). Understanding how drought propagates to affect crop yield at different timescales, and identifying the potential determinants that underlie this process, could help to develop more effective strategies for mitigating the impact of drought on crop productivity. This study is aimed to assess how crops respond to various drought characterization (i.e., timescales) as a measure of crop system resilience (and adaptive capacity). We utilized various determinants, e.g., climate, soil, environment, agricultural input, and socioeconomic factors, which may determine crop system’s vulnerability under climatic stress (i.e., drought). Specifically, we set the objectives of this study: (1) assessing which timescale crops primarily respond to drought, (2) mapping their spatial patterns, and (3) finding key determinants that control the pattern of crop response to different drought timescales. Here, drought is represented by a multiscalar meteorological drought index SPI with 1 – 12-month timescales based on the global gridded precipitation datasets. All analysis was done for each major crop (maize, rice, soybean, and wheat) in 0.5° grid resolution from 1981 to 2016 (36 years). This study elucidates the extent to which multifaceted physical and socioeconomic factors play an important role in building up the resilience of crop systems to droughts. Furthermore, this has implications for future adaptation and mitigation measures toward sustainable futures under pressured agricultural systems with an important commitment to achieve zero poverty and hunger of the Sustainable Development Goals (SDGs) by 2030 (United Nations, 2015). 2. Materials 2.1. Yield anomaly We used the global dataset of historical yields for major crops (GDHY) developed by (Iizumi and Sakai, 2020) for maize, rice, wheat, and soybean. GDHY provides gridded crop yield data (tons per hectare, t ha-1) with 0.5° spatial resolution over 1981–2016, calculated based on crop yield statistics (FAOSTAT), remote sensing data, and other crop-related datasets (i.e., crop calendar, crop harvested area). To obtain year-to-year growing season drought, we used a global crop calendar model developed based on the year 2000 (Sacks et al., 2010). 2.2. Precipitation We used several available precipitation datasets to estimate the ensemble mean of global drought events based on SPI on a monthly scale with a spatial and temporal scale similar to the global yield dataset. Nine publicly available datasets suiting the spatial and temporal resolution criteria were employed. The selected datasets consist of five-gauge observation-based data (GPCC, CRU, PRECL, UDEL, CPC), one merging-based data (MSWEP), and three reanalysis data (MERRA-2, ERA-5, JRA-55). Further details of the datasets used in the drought indicator development are provided (Hendrawan et al., 2022). 2.3. Key determinant datasets We obtained global datasets of various variables that are widely known to control agricultural production (i.e., crop yield) and its response pattern to climatic-related stress (i.e., drought). These variables were used to identify the spatial variation of crop response as a proxy for assessing agroecosystem vulnerability patterns over regions. We defined the possible determinants as climate (Lobell and Field, 2007), topography (Lychuk et al., 2017), soil (Iizumi et al., 2021), irrigation (Carrão et al., 2016, Meza et al., 2020), crop production (Williams et al., 2016), fertilizer (Simelton et al., 2012, Yamoah et al., 2000), and socioeconomic factors (Simelton et al., 2009, Swain et al., 2022b) (Table 1). The datasets were re-gridded to the common grid resolution of 0.5° following crop yield and the drought dataset. The temporal coverage of datasets is within the study period (1981–2016), depending on each data availability. Table 1. The determinant variables used to define crop response to different drought timescales for each crop based on the machine learning models. Category Variable Unit Period Resolution Source Climate Mean annual water balance (P-PET) mm year⁻¹ 1981 – 2016 0.5° (Harris et al., 2020) Mean daily temperature °C Topography Elevation m 2000 5′ (IIASA/FAO, 2010) Soil Topsoil saturated hydraulic conductivity cm day⁻¹ 2013 0.25° (Montzka et al., 2017) Plant extractable water capacity cm water per cm soil 2000 0.5° (Dunne and Willmott, 1996) Irrigation Irrigation fraction (irrigated harvested area) % of land area 2005 5′ (Siebert et al., 2005) Production Harvested area km² year⁻¹ 1998–2002 5′ (Portmann et al., 2010) Fertilizer Potassium rate application kg ha⁻¹ 2000 5′ (Mueller et al., 2012) Socioeconomic GPP per capita USD 2015 5′ (Kummu et al., 2018) 2.3.1. Climate factors This study used the CRU TS v. 4.05 dataset (Harris et al., 2020) of total precipitation, daily Potential Evapotranspiration (PET), and daily mean temperature on a monthly scale. We calculated the inter-annual total value for precipitation and daily mean PET and temperature from 1981 to 2016, corresponding to the yield and drought period analyzed in this study. Then, we used the water balance indicator by subtracting the mean annual total precipitation (P) with PET (P-PET) to indicate the simple net water availability within the land. 2.3.2. Topography factors Terrain attributes were used to indicate the general pattern of soil, fertility, and moisture availability (wetness) (Lychuk et al., 2017, Zeleke and Bing, 2004). This study used a global elevation dataset from IIASA and FAO (IIASA/FAO, 2010), generated by digital elevation data (DEM) from The NASA Shuttle Radar Topographic Mission (SRTM) and GTOPO30 (USGS, 2002). 2.3.3. Soil factors We employed the outermost layer of the soil indicators: hydraulic conductivity and available water capacity. We used the 30 cm saturated hydraulic conductivity (Ks) data from Montzka et al. (2017), based on the Schaap algorithm (Schaap, 2002) and SoilGrids1km dataset (Hengl et al., 2014). Furthermore, we used plant-extractable soil water capacity for the available water capacity indicator, developed by global soil profile (texture and depth), organic matter, and plant rooting depth (Dunne and Willmott, 1996). 2.3.4. Irrigation factors The irrigation rate indicator was represented by the global data set of crop-specific monthly irrigated and rainfed crop areas around the year 2000 (MIRCA2000). We obtained annual irrigated harvested areas to indicate to what extent harvested areas are irrigated (km2) for each crop (maize, rice, soybean, and wheat) among the 26 crop types MIRCA2000 provided. 2.3.5. Production factors The total harvested area to represent the crop system’s characteristics (i.e., farm size) (Williams et al., 2016) was used. The harvested area was obtained based on the MIRCA2000 as the total of annual irrigated and rainfed areas for each crop (Portmann et al., 2010). 2.3.6. Fertilizer factors The fertilizer application rate dataset from the crop-specific global fertilizer application rates (Mueller et al., 2012) was employed. This dataset estimated the fertilizer application rate for each crop based on the national-level statistics of fertilizer application rates, crop yield map (Monfreda et al., 2008), and livestock and manure nutrient content distribution. This study used the potassium input rate, which was reported to have a role in mitigating crop drought stress (Studer et al., 2017). 2.3.7. Socioeconomic factors We used gross domestic product (GDP) per capita as a proxy indicating the level of capital investment in agriculture associated with crop yield vulnerability to a stressor (Kim et al., 2019, Simelton et al., 2009). GDP data (PPP, i.e., purchasing power parity) was obtained from Kummu et al. (2018) based on sub-national and national data. We selected the data layer of the year 2015 as a representative period coinciding with this study period. 3. Methods 3.1. SPI calculation SPI was calculated solely based on monthly precipitation time series. First monthly precipitation data were fitted to gamma distribution and then transformed to a standardized value based on the standard normal distribution (mean 0 standard deviations 1) (Guttman, 1998, McKee et al., 1993). The complete procedures can be referred to (Lloyd-Hughes and Saunders, 2002). The positive SPI values represent a wet condition or rainfall surplus; the negative values indicate a dry condition or rainfall deficit relative to the long-term average associated with the total calculation period. This calculation was done independently for each grid cell; thus, SPI can be spatially comparable as standardization was done based on the climatology in each location. In this study, drought timescale ( ) refers to different SPI timescale, which was calculated from various moving average of monthly precipitation. Here we used a timescale from 1 to 12 months ( = 1, …, 12) considering the various response of crops from meteorological (shorter term) to hydrological drought (longer term) (Lloyd-Hughes and Saunders, 2002, Wilhite and Glantz, 1985). The SPI calculation was done according to Hendrawan et al. (2022) by employing an ensemble precipitation dataset. First, SPI was generated using each precipitation dataset (GPCC, CRU, PRECL, UDEL, CPC, MSWEP, MERRA-2, ERA-5, JRA-55), and subsequently, the average was calculated across SPIs. This average SPI is then referred to as the ensemble SPI, which represents the drought index in this study. We employed SPI because of several reasons. First, we limit uncertainties caused by larger input parameters that might be used to develop the drought indicator (i.e., evapotranspiration calculation needed for SPEI). In addition, the use of more variables would complicate drought index development since we used ensemble SPI from multiple global precipitation data (see Hendrawan et al., 2022). Second, it is a simple and flexible indicator while giving robust drought representation comparable with other complex drought indicators. Finally, SPI has been used widely for drought monitoring and suggested by World Meteorological Organization (WMO) (Hayes et al., 2011). 3.2. Drought intensity Drought intensity ) was calculated based on the calculated SPI with various timescales. Then the monthly SPI along 1981–2016 (432 months) were used to represent annual drought conditions based on harvesting months obtained from the crop calendar dataset (Sacks et al., 2010). We adopted the drought magnitude definition by McKee et al. (1993)) as a function of SPI and drought duration ( ). Following the previous study (Kim et al., 2019), here we set the fixed drought duration as three months ( =3) during and before harvesting (i.e., the harvest month and the two months earlier) (see Eq. 1 and Supplementary Fig. S1 in Appendix). We then considered using a measure of drought intensity ( ) as an average of SPI with during the above period to keep the standardized value range (i.e., mean 0 and standard deviation 1). was calculated in each grid cell as (1) where is the SPI of -month precipitation accumulation in month in year and H is the harvesting month (Sacks et al., 2010). For instance, with = 8 (August) is calculated based on three months average of -month SPI within June, July, and August in 2015 (see Supplementary Fig. S1). As we multiplied SPI with minus one, the higher positive drought intensity indicates a higher drought magnitude that might adversely affect crop yield loss. Moreover, as suggested in Kim et al. (2019), we only used indicating drought conditions. 3.3. Crop yield anomaly The exclusion of long-term trend of crop yield time series data as a technological yield increase is necessary to obtain crop yield anomaly due to short-term climate disruptions. Crop yield anomaly (ΔY) was calculated by a detrended time series based on a locally weighted regression method (Eq. 2) (Cleveland and Devlin, 1988). This method was selected to detrend yield data as it can account for possible trend non-linearity and is considered appropriate for a limited time series period (Hendrawan et al., 2022, Lu et al., 2017). (2) ̅ ̅ where is crop yield (t /ha) and ̅ is the long-term trend obtained by locally weighted regression (t /ha). For the window size or span ( parameter) used in the local regression, we used one-fourth of all data series for all grids (Hendrawan et al., 2022). 3.4. Assessing the crop response pattern to drought timescale We first assessed the relationship between multiple timescales ( =1, …,12) and crop yield anomaly for the four crop types using the Pearson correlation. Thus, we obtained 12 (timescales) × 4 (crops) correlations in each grid cell and obtained timescale, which reveals the maximum squared Pearson correlation coefficient ( ), indicating the most crop yield sensitivity to drought (Hendrawan et al., 2022, Peña-Gallardo et al., 2019b). Then, we obtained the global map of the most correlated drought timescale and its associated Pearson correlation value in each grid ( < 0.05). We further classified the most correlated drought timescale into three categories: short (1 – 4 months), medium (5 – 8 months), and long (9 – 12 months). This classification allows us to extract the spatial pattern of crop response to different drought lag times, indicating crop resistance and resilience to different drought characteristics (Vicente-Serrano et al., 2013). 3.5. Climate characteristics We obtained the climatic region’s characteristics which might be associated with the pattern of crop response to different drought time scales. Here we used the classification of the climatic region based on precipitation pattern: tropical, temperate, continental, and arid, according to the Köppen-Geiger climate classification (Kottek et al., 2006). 3.6. Machine learning models We employed several machine learning algorithms for classification: Random Forest (RF), Extreme Gradient Boosting (XGBoost), and Support Vector Machine (SVM) to assess the dependence between key factors and the responses of crops to different timescales. These particular machine-learning algorithms have been growingly utilized in previous studies to understand the relationship between multiple variables (e.g., climate hazard) and dependent indicators (e.g., environmental risk) (Beillouin et al., 2020, Vogel et al., 2019). We trained models using several input determinants as classifiers and the three categories of crop response to drought timescales (short, medium, and long) as response variables for each crop separately. In this study, RF, SVM, and XGBoost were applied using the “caret” library in R (Kuhn, 2008) with “ranger”, “svmRadial”, and “xgbTree” methods, respectively. We optimized the model based on the training accuracy metric from the 10-fold cross-validation with validation (leave-group out) of 25% of the data. Then we ranked the importance of variables calculated within the model using the variable importance method using the same library. Finally, we obtained the relationship between key variables and the crop response to drought timescale by constructing the “Partial Dependence Plot” using the “pdp” R library (Greenwell, 2017). The partial dependence for this purpose (classification) reveals the relationship between the probability of valid votes (0−1) for each class (short, medium, long) and the associated value for each variable predictor. This study utilized the average value of the results from RF, SVM, and XGBoost of the model accuracies, variable importance, and partial dependence plots to get the central tendency across the different machine learning models. 3.6.1. Random Forest Random Forest (RF) uses a decision trees ensemble formerly developed by Breiman (2001). The accuracy indicator of the model was calculated based on “out-of-bag” data or test (validation) data when the model was fitted using the training data. To reveal the variable importance of each factor in determining crop response to drought timescales, we used the “Mean Decrease Gini” metric representing the reduction of the model accuracy when each variable is removed; the higher the mean decrease accuracy value, the higher the variable importance in the model. In this study, we applied the model using the default hyperparameter inputs: e.g., the number of trees of 500 and maximum tree depth of 5 (Kuhn, 2008). 3.6.2. Extreme Gradient Boosting The Extreme Gradient Boosting (XGBoost) algorithm (Chen and Guestrin, 2016) is a further development of the Gradient Boosting Algorithms Machine, which is based on regression tree proposed by Friedman (2001). The idea of gradient boosting methods is to improve the model's accuracy by employing the negative gradient direction of the function of model loss (Friedman, 2001). Here, we implemented XGBoost with the number of gradients boosted trees by 500 with the maximum tree depth of 5 and learning rate of 0.3. 3.6.3. Support Vector Machine The Support Vector Machine (SVM) uses kernels by minimizing the distance to training data and limiting the model complexity (Boser et al., 1992). Here, the SVM algorithm was based on the radial basis function, which generally had two input parameters: 1) the penalty factor (C) aiming to find a trade-off between the fitting error and the model complexity and the kernel width (gamma). In this study, we applied SVM with the input set C= 1 and gamma= 0.1. We use default hyperparameter inputs for each machine learning model as it is adequate to reveal general linkages between determinants and crop response, as reported by previous studies (Hendrawan et al., 2023, Iizumi et al., 2021). However, it is also important to note that machine learning models can also be sensitive to the choice of kernel function and susceptible to overfitting when the training data is too complex or noisy. 4. Results 4.1. Crop response to drought timescales The yield loss is associated significantly with the drought in various timescales over the major global crop areas by 55%, 27%, 65%, and 65% of global cropland for maize, rice, soybean, and wheat, respectively. Fig. 1 shows the spatial distribution of the most correlated timescale categories. Overall, aggregated across crops, the result shows that shorter drought timescale was slightly more profound to crops (37% of total global cropland for maize, rice, soybean, and wheat) than long (34%) and medium (29%) timescale. For each crop, maize may respond to medium drought timescales more (20% of global cropland), while soybean and wheat tend to respond to longer timescales (24% and 27%, respectively). On the other hand, rice tends to respond to shorter timescales (13%) despite less cropland significantly affected by drought. This implies that the main driver of crop yield loss for rice might be complex and not necessarily correlated to meteorological drought events. Download : Download high-res image (495KB) Download : Download full-size image Fig. 1. Timescales at which Drought Index ( ) is most correlated with crop yield anomaly for maize, rice, soybean, and wheat. Drought timescales (1–12 months) are aggregated into short (1 – 4 months), medium (5 – 8 months), and long (9 – 12 months). Grids with no significant correlations ( ≥ 0.05) are represented by grey masks, while grids with no cropland or yield data are shown in white. Pie charts show the global crop area aggregate weighted by MIRCA2000. Furthermore, the linkage between drought with different timescales and crop yield anomaly was strong in some regions. Generally, the Great Plains and the Pampas had a prominent crop yield sensitivity to longer drought timescale. In particular, maize was sensitive to longer drought timescales in the Iberian Peninsula, Morocco, and south-eastern Europe, while the response to short and medium timescales are found in Southern Africa, Mideastern US, and Indonesia. On the other hand, the soybean and wheat response to a long drought timescale was also profound and sparse in Northeast China, part of Northern Kazakhstan, and a small part of Eastern Africa. Particular soybean responses to short-term drought are in India, the Great Plains, and Pampas. For wheat, the crop yield, which was sensitive to medium and shorter drought timescales, can be found in Eastern Europe and Australia. On the other hand, rice shows sparse regions sensitive to drought timescale with a tendency of shorter response in Africa. Based on the climate classification, the result in Fig. 2 shows that crop response to drought varies moderately depending on the crop types among different climatic regions. Results show Maize in the temperate climate sensitivity to medium drought timescales becomes more dominant, but a slightly different response in the other climate regions. Rice tends to show a short-term response to drought for all climate regions, especially tropical and temperate climates where rice is mostly grown. Soybean generally exhibits a more diverse response, where a short and medium response was dominant in temperate climates, while continental climates tend to be more sensitive to longer drought timescales. Wheat tends to respond to longer drought timescales for all climate regions except the tropics. Arid and continental regions generally respond to longer drought timescales, while temperate and tropical regions were influenced by short to medium drought timescales (except in wheat). As the major environments for global crops, temperate climates were mostly exposed to drought, given more dominant global harvested area shares. Download : Download high-res image (146KB) Download : Download full-size image Fig. 2. Percentage of the global harvested area corresponding to each dominant response timescale to drought (short, medium, and long) in different climatic regions based on Köppen-Geiger climate classification. The crop area assigned to crop grids is based on the MIRCA2000 dataset. 4.2. Comparison with local drought cases Here, we compare drought events estimated in this study with the previous local studies in the selected region of interest. For instance, Fig. 3a shows the relationship between maize yield anomaly and drought, with the most-correlated timescales in Southeast Africa. The drought events analyzed in this study capture several most extreme droughts in the recent decades, associated with El Nino events, especially during 1991/1992 and 1994/1995 in several countries: Malawi, Zimbabwe, Zambia, Mozambique, and Swaziland (Belbase and Morgan, 1994, Tschirley, 1998). This drought episode corresponds to a significant crop yield loss of maize in the region, as confirmed in reported data (Devereux and Næraa, 1996, Eldridge, 2002). Download : Download high-res image (800KB) Download : Download full-size image Fig. 3. The relationship between the regional average of the Drought Intensity ( ) and maize yield anomaly (%) for several selected regions shown in the red box in the right panel. The right y-axis showing is inverted to give a clear association between crop yield anomaly and drought severity. Yield anomaly and values are weighted based on MIRCA2000. Rice shows no clear spatial pattern of the crop response to each drought timescale. However, the dominant pattern, the short response, can be observed in southern African countries such as Mali and Chad (see Fig. 1). Moreover, Fig. 3b shows the sample region in Indonesia in the case of rice crop, showing a generally longer response to drought, even though globally rice mostly responds to shorter drought timescale. The drought events in this region analyzed in this study were associated with El Nino occurrences, such as in 1997/1998, 2002/2003, and 2013/2014. These drought events also trigger crop yield drops over the years, as widely reported in previous studies (D’Arrigo et al., 2006). The long response of drought affecting crop yield anomaly for soybean was shown in the arid region of The Great Plain, the Pampas, northern Italy, and South Africa. On the other hand, the short to medium soybean response was sparsely shown in the soybean croplands, such as in the US, South America, and China. Fig. 3c shows drought events and their associated crop yield loss in The Pampas area, demonstrating a strong linkage between medium and long drought timescale and crop yield anomaly (right panel). The left panel figure shows several major drought events, such as in 1988/1989, 1996/1997, and 2008/2009, corresponding to significant crop yield loss in the region. The drought and its implication on crop yield during the periods were also reported in previous studies (Lovino et al., 2014, Sgroi et al., 2021). A longer response dominates most wheat cropland in south-eastern Australia, northern Kazakhstan, the Iberian Peninsula, Morocco, and Ethiopia. On the other hand, the medium to short response can be found marginally in the rest of the significant crop-drought areas (e.g., France, Germany, UK). Fig. 3d shows the example region of Southeast Australia, which poses a long response to drought. Based on the report and previous studies, drought episodes and crop yield losses in this study correspond to the actual extreme drought conditions, such as in 1982, 1994, 2002, and 2006 in the region (Nicholls, 2004, van Dijk et al., 2013). 4.3. Key factors of crop response to drought timescales Machine learning models could explain around half of the spatial variability of crop response to drought timescales shown in Fig. 1, with average accuracies ranging between 45.7% and 56.0% (Table 2). This result suggests no substantial difference in the model‘s performance across the combinations (i.e., algorithms and crop types). The models generally show a moderate to higher predictive capacity of the key variables in determining the crop response. Among the algorithm, Random Forest reveals better predictability, followed by XGBoost and SVM. Among the models, the performance for all four crops is quite similar, although rice tends to have lower accuracy. It is noteworthy that the performance of the machine learning models might not align with the results of the relationship between various drought timescales and crop yield anomaly. The similar performance of the machine learning models for all four crops may reflect the capability of the algorithm to capture any relationships between input features and crop response to various drought timescales. Nevertheless, it is important to exercise caution when interpreting results for rice, considering its lower correlation with drought. Table 2. Machine learning model accuracy for each crop based on Random Forest, Support Vector Machine, and Extreme Gradient Boosting. Algorithm Accuracy Maize Rice Soybean Wheat RF 54.4% 50.6% 56.0% 53.2% SVM 47.0% 46.8% 49.1% 45.7% XGBoost 50.8% 48.0% 53.3% 49.5% Mean 49.3% 48.7% 50.5% 48.8% Furthermore, from the relative importance of variables to the model (Fig. 4), overall, we reveal that temperature, GDP per capita, and water balance are among the most influential parameters determining crop response to different drought timescales. The result indicates the importance of climate and socioeconomic factors in determining crop response. The result among these three important variables is relatively robust across the algorithm and crop type (see Supplementary Fig. S2). Meanwhile, the remaining factors (i.e., hydraulic conductivity, harvested area, topography, fertilizer, water-holding capacity, and irrigation) relatively play a lesser significant role in determining crop response to drought, despite more variations depending on the machine learning algorithm used and the type of crop. Download : Download high-res image (287KB) Download : Download full-size image Fig. 4. Relative importance of variables to define crop response to drought categories (short, medium, and long timescales) based on Machine learning models: Random Forest (RF), Support Vector Machine (SVM), and Extreme Gradient Boosting (XGBoost). The parameter order (top to bottom) indicates the importance order (most to least important). Colored bars denote the crop-wise average importance scaled from 0 to 1 (colors indicate different classes), while the black points indicate the individual machine learning output (RF, SVM, XGBoost). We further examine the functional relationship between determinants and the response categories (short, medium, and long) based on the partial dependence plots. Fig. 5 shows the model dependence from the average value resulting from RF, SVM, and XGBoost models on each variable; the positive value of the y-axis indicates higher accurate vote proportions given a change of variable values, that is, higher predictability. Here, we only show variable dependence based on their predictability to the short drought timescale to demonstrate the effect of each variable in the models (see Supplementary Fig. S3 and S4 for the medium and long drought timescale, respectively). Download : Download high-res image (648KB) Download : Download full-size image Fig. 5. Partial dependence plot for each variable in defining different crop responses to short drought timescales based on the model's average (RF, SVM, XGBoost). The y-axis indicates the probability of accurate votes given a change in the variable values. A higher positive y-axis denotes stronger evidence of which variable's value ranges are likely to define the crop response to the drought timescale. The line curves are smoothed based on the local polynomial regression to obtain the general tendency of the partial dependence (span=0.5). As shown in Fig. 5, for the most influential factor, temperature, the higher value (y-axis) tends to control crop response to a short drought timescale, while rice shows the opposite response. This may imply that crops in a warmer climate respond relatively as soon as a short-term drought develops. On the other hand, crops in a colder climate may be more sensitive to longer-term accumulated precipitation shortage (Supplementary Fig. S4). This also signifies a stronger drought impact and immediate crop response to drought across equatorial and tropical croplands (mostly humid) that typically have a higher temperature over the years, consistent with those in Fig. 2, showing that tropical crops likely respond more to shorter drought. The other climate parameter dependence, the water balance, similarly suggests that cropland with higher water availability (i.e., net positive precipitation over potential evapotranspiration) seems more susceptible to the shorter timescale. Nevertheless, this may imply that crops in semi-arid and arid regions respond to longer drought events than in humid-tropical regions, given their better adaptation to immediate drought shocks in the dry environment. These results are similar to those in Fig. 2; wheat mostly cultivated in drier environments exhibits a longer response to drought. The other most important factor, GDP per capita, tends to be associated with a short drought timescale within its lower value, especially for maize. This suggests that maize yield tends to respond to short-term drought quickly in a lower-capita income region. However, these variations of the GDP per capita dependence across crops show a complex effect of GDP per capita in determining crop vulnerability to different drought characteristics. Therefore, this study’s result is apart from a conclusion about whether GDP per capita can significantly influence crop drought vulnerability. Meanwhile, the remaining factors are less relevant, even though some variables show a stronger relationship for a specific model and crop. These variables with moderate effect on the models (i.e., hydraulic conductivity, harvested area, topography, fertilizer rate, water holding capacity) show a wider variation depending on the algorithm used and crop type, while the irrigation factor shows relatively weak importance among models. 5. Discussion This present study investigates crop yield anomaly response to different drought timescales based on SPI with multiple timescales (1–12 months). We found that temperate, continental, and arid regions might face significant yield loss due to drought than tropical regions, in agreement with the previous studies’ findings (Kim et al., 2019, Lesk et al., 2021, Ray et al., 2015). Therefore, crops are strongly exposed to such drought episodes, giving more crop susceptibility to damage (Schwabe et al., 2013). In temperate regions, an intermittent drought might also threaten crops that are not well adapted to drought than those in an arid region. Previous studies have reported that drought in a temperate region can be intensified under climate warming (Schlaepfer et al., 2017). In the continental region, the drought significance to crops might be related to prolonged winter drought hampering soil moisture supply by reducing snowmelt before the spring and summer growing seasons (Gevaert et al., 2018, Hamal et al., 2020). Furthermore, we compared our results with the local studies, indicating that the drought estimation in this study generally corresponds with the actual drought impact on crop production reported. Based on the highest correlation between crop yield anomaly and various drought timescales, we suggest maize, soybean, and wheat might be more sensitive to medium to long-term drought; rice responds to short-term drought, despite a lower correlation. These results may be related to the impact of prolonged drought in most dryland environments, triggering a lack of soil moisture and water storage and limiting water supply in an irrigated system (Wilhite and Glantz, 1985, Zargar et al., 2011). Previous studies also emphasize the relevance of medium to longer timescales on a local or global scale. For example, (Peña-Gallardo et al., 2019a) found that wheat was more sensitive to medium to longer timescale drought based on SPEI during spring and winter in Spain and the US (4–18 months) (Peña-Gallardo et al., 2019b), despite high variability across crops and drought seasonality. On a global scale, previous studies found a high correlation between medium drought timescales (∼6 months) using SPI or SPEI and crop production using sub-county level data (Kim et al., 2019, Vogel et al., 2019, Zampieri et al., 2017). In addition, it is notable that rice exhibits a lower correlated harvested area with drought. One possible explanation for this could be the sensitivity of rice to other factors, such as temperature, soil moisture, and irrigation (Hendrawan et al., 2022, Kim et al., 2019, Lobell and Field, 2007). These factors could also be affecting the rice yield and masking the direct impact of drought on the crop. Additionally, there could be regional variations in the relationship as rice in some regions may be more susceptible to drought (e.g., rainfed rice), while others may be less affected due to differences in environment and water management practices. Therefore, results for rice should be treated with care, especially in understanding the key drivers for this particular crop, given the previous study indicating a complex effect of drought on this typical wet farming crop (Irawan et al., 2023). Previous studies, mostly on a local scale using finer resolution data (i.e., county, sub-county level), suggest the importance of short-term drought for several crops (Peña-Gallardo et al., 2019b, Sgroi et al., 2021, Zipper et al., 2016). For instance, Sgroi et al. (2021) indicate that overall wheat, maize, and soybean yields were sensitive to drought periods shorter than three months during summer (maize and soybean) and spring (wheat). However, the previous studies mainly detect the most correlated timescales by varying seasonality (i.e., different months or seasons); thus, the most correlated timescale depends on the timing at which drought is calculated. This study used the fixed season to calculate drought to reflect only the growing season drought accumulated in harvest month. Moreover, the scale discrepancy between global and local studies may result in different representations of extreme drought severity and yield anomaly since hazard and crop response on finer spatial scales tend to be averaged out at lower resolution (Eggert et al., 2015). The difference in each crop’s response to a drought timescale may reflect different crop resistance with corresponding climate characteristics. For instance, in the wheat case, the dominant response may be related to the relatively long growing season and the importance of soil moisture recharge, especially during the critical season, as indicated by previous studies (Peña-Gallardo et al., 2019b, Sgroi et al., 2021). The significance of medium to longer drought may be because crops in arid and semi-arid regions generally can adapt to shorter water shortages due to internal strategies increasing crop efficiency to such abiotic stress (Chaves et al., 2003, Daryanto et al., 2016). Moreover, this present study indicates a similar response pattern between maize and soybean, typically having a shorter growing season than wheat. We suggest these crops respond to generally medium-term drought, agreeing that previous studies reporting short to medium-term drought during important timing (i.e., late spring to summer) might harm crop yield (Peña-Gallardo et al., 2019b, Sgroi et al., 2021, Zipper et al., 2016). In contrast, rice tends to respond to shorter droughts in most climate regions. This may be related to the common characteristics of the wet crops with poorer adaptability to abrupt water shortage, given their common favor from water availability (Jongdee et al., 2006, Vicente-Serrano et al., 2013). Further, it may be because propagation of meteorological drought (i.e., SPI) to the land occurs at shorter timescales in tropical climates than in continental or arid climates (Gevaert et al., 2018). Based on soil moisture data, (Sheffield and Wood, 2007) also indicate that short-timescale droughts (≤ 6 months) were more predominant in tropical regions and mid-latitudes due to high inter-annual climate variability. However, crops' response to tropical regions with abundant water resources may depend on the extent to which irrigation can buffer during meteorological drought stress (Zipper et al., 2016). We linked the variability of crop responses to different drought timescales with several possible determinants. We found that temperature, GDP per capita, and water balance are among the most important global parameters defining the crop response pattern. These parameters are considered key parameters to drive agricultural productivity and the vulnerability of the crop system to disruptions (Fraser et al., 2013, Kim et al., 2019, Lesk et al., 2021). Particularly, we suggest that crop tends to be damaged in warmer to hot regions by short-term drought. Warmer temperatures generally prompt higher evaporation with drier conditions in low precipitation periods than cooler conditions. Previous studies also indicated that the impact of extreme drought could be more exaggerated by extreme heat (i.e., joint hot and dry conditions), contributing to severe moisture stress, especially under global warming (Coffel et al., 2019, Lesk et al., 2021, Matiu et al., 2017, Vogel et al., 2019). Crops, particularly maize, in regions with higher GDP per capita are more sensitive to short-term drought, while the other crops suggest the opposite response. Previous studies suggested that resilient crop systems were strongly related to a high GDP per capita in agriculture (Simelton et al., 2009); that is, lower resilience, in this case, may determine the lower capability of crop systems to cope with the abrupt climate disruption (i.e., short term drought). On the other hand, a study by Lesk et al. (2016) suggests that crop production in more developed countries (i.e., higher income) might be more vulnerable to drought events, confirming part of our study findings. One of the possible reasons is the tendency of developing farmers to maintain low-risk production. In addition, small-scale farmers may have traditional farming practices that make them adapt to climatic variability. Nonetheless, GDP per capita can be a proxy of agricultural investment related to infrastructure, machinery used, fertilizer input, farm scale, etc. (Simelton et al., 2012, Stringer et al., 2020). Therefore, for the sensitive regions, promoting capital investments into agricultural inputs may partly buffer short or longer-term drought losses or damages (Kim et al., 2019). Moreover, in this present study, we could not detect the importance of the irrigation parameter, even though this factor is widely known as a factor playing a big role in reducing the impact of drought and extreme heat (Lesk et al., 2021, Troy et al., 2015, Vogel et al., 2019). One possible reason is that crop yield data used in this study is not separated between irrigated and rainfed systems (i.e., annual mean), which introduces a mixed response given that each irrigated and rainfed share the annual mean yield of a grid cell. Here, we might argue that the irrigation fraction variability under a predominantly rainfed system is insufficient to buffer drought impact, especially due to more intensive droughts during which irrigation supply is highly constrained (Leng, 2021). Further studies on a global scale may address this study’s limitation by, for example, providing separated crop yield data under irrigated and rainfed growing seasons and comparing each drought impact under different conditions, as suggested by previous work (Hendrawan et al., 2023). Finally, our study provides important insights into the relationship between crop response to drought and its possible determinants, with implications for several SDGs, including Zero Hunger, Climate Action, and Life on Land. The findings highlight the importance of understanding the complex interactions between climate, crops, and the environment to improve food security, build resilience to climate change, and promote sustainable land use achieving the SDGs. 6. Conclusion Targeting global sustainable and resilient crop systems is critical to achieving food security. This study addresses the gaps in understanding the significant drought time scales which influence crop yield sensitivity on a global scale. This study revealed several key results associated with the study's objectives. (1) We found that soybean and wheat might respond to more prolonged droughts spanning from medium to longer timescales (5–12 months), while rice and maize responded to short-medium drought time scales (1–8 months). Crop yield response to drought timescales might differ across crops and regions. (2) This study revealed that arid and continental regions generally respond to a longer drought timescale. In contrast, temperate and tropical regions were mostly influenced by short to medium drought timescales (except the dry farming crop, i.e., wheat which is mostly influenced by longer drought timescales). (3) Related to the key determinants, we suggest that climate (i.e., temperature, water balance) and socioeconomic factors (GDP per capita) may be key factors controlling the pattern of crop response to different drought timescales. Finally, we provide the first attempt to assess key factors determining crop response to different drought timescales globally, which might help mitigate crop systems' vulnerability to climate-related stressors. Therefore, this study may bring an additional framework for adaptation and mitigation against future climate risks to ensure future global food security under climate warming and more severe and frequent extreme climates. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Appendix A. Supplementary material Download : Download Acrobat PDF file (775KB) Supplementary material. Supplementary material . Data Availability Data will be made available on request. References Bachmair et al., 2018 S. Bachmair, M. Tanguy, J. Hannaford, K. Stahl How well do meteorological indicators represent agricultural and forest drought across Europe? Environ. Res. Lett., 13 (2018), 10.1088/1748-9326/aaafda Google Scholar Barker et al., 2016 L.J. Barker, J. Hannaford, A. Chiverton, C. Svensson From meteorological to hydrological drought using standardised indicators Hydrol. Earth Syst. Sci., 20 (2016), pp. 2483-2505, 10.5194/hess-20-2483-2016 View in ScopusGoogle Scholar Beillouin et al., 2020 D. Beillouin, B. Schauberger, A. Bastos, P. Ciais, D. Makowski Impact of extreme weather conditions on European crop production in 2018: Random forest - Yield anomalies Philos. Trans. R. Soc. B: Biol. Sci. (2020), p. 375, 10.1098/rstb.2019.0510 Google Scholar Belbase and Morgan, 1994 K. Belbase, R. Morgan Food security and nutrition monitoring for drought relief management. The case of Botswana Food Policy, 19 (1994), pp. 285-300, 10.1016/0306-9192(94)90076-0 View PDFView articleView in ScopusGoogle Scholar Boser et al., 1992 B.E. Boser, V.N. Vapnik, I.M. Guyon Training algorithm margin for optimal classifiers Perception (1992), pp. 144-152 Google Scholar Breiman, 2001 L. Breiman Random forests Mach. Learn, 45 (2001), pp. 5-32, 10.1023/A:1010933404324 Google Scholar Carrão et al., 2016 H. Carrão, G. Naumann, P. Barbosa Mapping global patterns of drought risk: an empirical framework based on sub-national estimates of hazard, exposure and vulnerability Glob. Environ. Change, 39 (2016), pp. 108-124, 10.1016/j.gloenvcha.2016.04.012 View PDFView articleView in ScopusGoogle Scholar Chaves et al., 2003 M.M. Chaves, J.P. Maroco, J.S. Pereira Understanding plant responses to drought - from genes to the whole plant Funct. Plant Biol., 30 (2003), pp. 239-264, 10.1071/FP02076 View in ScopusGoogle Scholar Chen and Guestrin, 2016 Chen, T., Guestrin, C., 2016. XGBoost: A scalable tree boosting system. Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 13–17-Augu, 785–794. 〈https://doi.org/10.1145/2939672.2939785〉. Google Scholar Cleveland and Devlin, 1988 W.S. Cleveland, S.J. Devlin Locally weighted regression: an approach to regression analysis by local fitting J. Am. Stat. Assoc., 83 (1988), pp. 596-610, 10.1080/01621459.1988.10478639 View in ScopusGoogle Scholar Coffel et al., 2019 E.D. Coffel, B. Keith, C. Lesk, R.M. Horton, E. Bower, J. Lee, J.S. Mankin Future hot and dry years worsen nile basin water scarcity despite projected precipitation increases Earths Future, 7 (2019), pp. 967-977, 10.1029/2019EF001247 View in ScopusGoogle Scholar D’Arrigo et al., 2006 R. D’Arrigo, R. Wilson, J. Palmer, P. Krusic, A. Curtis, J. Sakulich, S. Bijaksana, S. Zulaikah, L.O. Ngkoimani Monsoon drought over Java, Indonesia, during the past two centuries Geophys Res Lett. (2006), p. 33, 10.1029/2005GL025465 Google Scholar Daryanto et al., 2016 S. Daryanto, L. Wang, P.A. Jacinthe Global synthesis of drought effects on maize and wheat production PLoS One, 11 (2016), pp. 1-15, 10.1371/journal.pone.0156362 Google Scholar Devereux and Næraa, 1996 S. Devereux, T. Næraa Drought and survival in rural Namibia J. South Afr. Stud., 22 (1996), pp. 421-440 CrossRefView in ScopusGoogle Scholar van Dijk et al., 2013 A.I.J.M. van Dijk, H.E. Beck, R.S. Crosbie, R.A.M. de Jeu, Y.Y. Liu, G.M. Podger, B. Timbal, N.R. Viney The millennium drought in Southeast Australia (2001-2009): Natural and human causes and implications for water resources, ecosystems, economy, and society Water Resour. Res., 49 (2013), pp. 1040-1057, 10.1002/wrcr.20123 View in ScopusGoogle Scholar Dunne and Willmott, 1996 K.A. Dunne, C.J. Willmott Global distribution of plant-extractable water capacity of soil Int. J. Climatol., 16 (1996), pp. 841-859, 10.1002/(SICI)1097-0088(199608)16:8<841::AID-JOC60>3.0.CO;2-8 View in ScopusGoogle Scholar Eggert et al., 2015 B. Eggert, P. Berg, J.O. Haerter, D. Jacob, C. Moseley Temporal and spatial scaling impacts on extreme precipitation Atmos. Chem. Phys., 15 (2015), pp. 5957-5971, 10.5194/acp-15-5957-2015 View in ScopusGoogle Scholar Eldridge, 2002 C. Eldridge Why was there no famine following the 1992 southern African drought?: The contributions and consequences of household responses IDS Bull., 33 (2002), pp. 79-87, 10.1111/j.1759-5436.2002.tb00047.x View in ScopusGoogle Scholar Fahad et al., 2017 S. Fahad, A.A. Bajwa, U. Nazir, S.A. Anjum, A. Farooq, A. Zohaib, S. Sadia, W. Nasim, S. Adkins, S. Saud, M.Z. Ihsan, H. Alharby, C. Wu, D. Wang, J. Huang Crop production under drought and heat stress: plant responses and management options Front Plant Sci., 8 (2017), pp. 1-16, 10.3389/fpls.2017.01147 Google Scholar Fraser et al., 2013 E.D.G. Fraser, E. Simelton, M. Termansen, S.N. Gosling, A. South Vulnerability hotspots”: integrating socio-economic and hydrological models to identify where cereal production may decline in the future due to climate change induced drought Agric. Meteor., 170 (2013), pp. 195-205, 10.1016/j.agrformet.2012.04.008 View PDFView articleView in ScopusGoogle Scholar Friedman, 2001 J.H. Friedman Greedy function approximation: a gradient boosting machine Ann. Stat., 29 (2001), pp. 1189-1232, 10.1214/aos/1013203451 View in ScopusGoogle Scholar Gevaert et al., 2018 A.I. Gevaert, T.I.E. Veldkamp, P.J. Ward The effect of climate type on timescales of drought propagation in an ensemble of global hydrological models Hydrol. Earth Syst. Sci., 22 (2018), pp. 4649-4665, 10.5194/hess-22-4649-2018 View in ScopusGoogle Scholar Greenwell, 2017 B.M. Greenwell pdp: An R package for constructing partial dependence plots R. J., 9 (2017), pp. 421-436, 10.32614/rj-2017-016 View in ScopusGoogle Scholar Guo et al., 2020 Y. Guo, S. Huang, Q. Huang, G. Leng, W. Fang, L. Wang, H. Wang Propagation thresholds of meteorological drought for triggering hydrological drought at various levels Sci. Total Environ., 712 (2020), Article 136502, 10.1016/j.scitotenv.2020.136502 View PDFView articleView in ScopusGoogle Scholar Guttman, 1998 N.B. Guttman Comparing the palmer drought index and the standardized precipitation index J. Am. Water Resour. Assoc., 34 (1998), pp. 113-121, 10.1111/j.1752-1688.1998.tb05964.x View in ScopusGoogle Scholar Hamal et al., 2020 K. Hamal, S. Sharma, N. Khadka, G.G. Haile, B.B. Joshi, T. Xu, B. Dawadi Assessment of drought impacts on crop yields across Nepal during 1987–2017 Meteorol. Appl., 27 (2020), pp. 1-18, 10.1002/met.1950 View in ScopusGoogle Scholar Harris et al., 2020 I. Harris, T.J. Osborn, P. Jones, D. Lister Version 4 of the CRU TS monthly high-resolution gridded multivariate climate dataset Sci. Data, 7 (2020), pp. 1-18, 10.1038/s41597-020-0453-3 Google Scholar Hayes, 2001 M. Hayes Revisiting the SPI: clarifying the process revisiting the spi: clarifying the process Drought Netw. N., 1994–2001 (2001), pp. 18-20 View in ScopusGoogle Scholar Hayes et al., 2011 M. Hayes, M. Svoboda, N. Wall, M. Widhalm The lincoln declaration on drought indices: Universal meteorological drought index recommended Bull. Am. Meteor. Soc., 92 (2011), pp. 485-488, 10.1175/2010BAMS3103.1 View in ScopusGoogle Scholar Heim, 2002 R.R. Heim A review of twentieth-century drought indices used in the United States Bull. Am. Meteor. Soc., 83 (2002), pp. 1149-1166, 10.1175/1520-0477-83.8.1149 Google Scholar Hendrawan et al., 2022 V.S.A. Hendrawan, W. Kim, Y. Touge, S. Ke, D. Komori A global-scale relationship between crop yield anomaly and multiscalar drought index based on multiple precipitation data Environ. Res. Lett., 17 (2022), Article 014037, 10.1088/1748-9326/ac45b4 View in ScopusGoogle Scholar Hendrawan et al., 2023 V.S.A. Hendrawan, D. Komori, W. Kim Possible factors determining global-scale patterns of crop yield sensitivity to drought PLoS One, 18 (2023), pp. 1-20, 10.1371/journal.pone.0281287 Google Scholar Hengl et al., 2014 T. Hengl, J.M. de Jesus, R.A. MacMillan, N.H. Batjes, G.B.M. Heuvelink, E. Ribeiro, A. Samuel-Rosa, B. Kempen, J.G.B. Leenaars, M.G. Walsh, M.R. Gonzalez SoilGrids1km - Global soil information based on automated mapping PLoS One (2014), p. 9, 10.1371/journal.pone.0105992 Google Scholar Hoffmann et al., 2020 D. Hoffmann, A.J.E. Gallant, J.M. Arblaster Uncertainties in drought from index and data selection J. Geophys. Res.: Atmos., 125 (2020), pp. 1-21, 10.1029/2019JD031946 Google Scholar IIASA/FAO, 2010 IIASA/FAO, 2010. Global Agro-ecological Zones (GAEZ v3.0). Google Scholar Iizumi and Sakai, 2020 T. Iizumi, T. Sakai The global dataset of historical yields for major crops 1981–2016 Sci. Data, 7 (2020), pp. 1-7, 10.1038/s41597-020-0433-7 Google Scholar Iizumi et al., 2014 T. Iizumi, M. Yokozawa, G. Sakurai, M.I. Travasso, V. Romanernkov, P. Oettli, T. Newby, Y. Ishigooka, J. Furuya Historical changes in global yields: Major cereal and legume crops from 1982 to 2006 Glob. Ecol. Biogeogr., 23 (2014), pp. 346-357, 10.1111/geb.12120 View in ScopusGoogle Scholar Iizumi et al., 2021 T. Iizumi, N. Hosokawa, R. Wagai Soil carbon-food synergy: sizable contributions of small-scale farmers CABI Agric. Biosci., 2 (2021), pp. 1-15, 10.1186/s43170-021-00063-6 Google Scholar Irawan et al., 2023 A.N.R. Irawan, D. Komori, V.S.A. Hendrawan Correlation analysis of agricultural drought risk on wet farming crop and meteorological drought index in the tropical-humid region Theor. Appl. Clim. (2023), 10.1007/s00704-023-04461-w Google Scholar Jongdee et al., 2006 B. Jongdee, G. Pantuwan, S. Fukai, K. Fischer Improving drought tolerance in rainfed lowland rice: an example from Thailand Agric. Water Manag, 80 (2006), pp. 225-240, 10.1016/j.agwat.2005.07.015 View PDFView articleView in ScopusGoogle Scholar Kim et al., 2019 W. Kim, T. Iizumi, M. Nishimori Global patterns of crop production losses associated with droughts from 1983 to 2009 J. Appl. Meteor. Clim., 58 (2019), pp. 1233-1244, 10.1175/JAMC-D-18-0174.1 View in ScopusGoogle Scholar Kottek et al., 2006 Kottek, M., Grieser, J., Beck, C., Rudolf, B., Rubel, F., 2006. World map of the Köppen-Geiger climate classification updated. Google Scholar Kuhn, 2008 M. Kuhn Building predictive models in R using the caret package J. Stat. Softw., 28 (2008), pp. 1-26, 10.18637/jss.v028.i05 View in ScopusGoogle Scholar Kummu et al., 2018 M. Kummu, M. Taka, J.H.A. Guillaume Gridded global datasets for gross domestic product and human development index over 1990-2015 Sci. Data, 5 (2018), pp. 1-15, 10.1038/sdata.2018.4 Google Scholar Leng, 2021 G. Leng Maize yield loss risk under droughts in observations and crop models in the United States Environ. Res. Lett. (2021), p. 16, 10.1088/1748-9326/abd500 Google Scholar Lesk et al., 2021 C. Lesk, E. Coffel, J. Winter, D. Ray, J. Zscheischler, S.I. Seneviratne, R. Horton Stronger temperature–moisture couplings exacerbate the impact of climate warming on global crop yields Nat. Food, 2 (2021), pp. 683-691, 10.1038/s43016-021-00341-6 View in ScopusGoogle Scholar Lloyd-Hughes and Saunders, 2002 B. Lloyd-Hughes, M.A. Saunders A drought climatology for Europe Int. J. Climatol., 22 (2002), pp. 1571-1592, 10.1002/joc.846 View in ScopusGoogle Scholar Lobell and Field, 2007 D.B. Lobell, C.B. Field Global scale climate-crop yield relationships and the impacts of recent warming Environ. Res. Lett. (2007), p. 2, 10.1088/1748-9326/2/1/014002 Google Scholar Lovino et al., 2014 M. Lovino, N.O. García, W. Baethgen Spatiotemporal analysis of extreme precipitation events in the Northeast region of Argentina (NEA) J. Hydrol. Reg. Stud., 2 (2014), pp. 140-158, 10.1016/j.ejrh.2014.09.001 View PDFView articleView in ScopusGoogle Scholar Lu et al., 2017 J. Lu, G.J. Carbone, P. Gao Detrending crop yield data for spatial visualization of drought impacts in the United States, 1895–2014 Agric. Meteor., 237–238 (2017), pp. 196-208, 10.1016/j.agrformet.2017.02.001 View PDFView articleView in ScopusGoogle Scholar Lychuk et al., 2017 T.E. Lychuk, A.P. Moulin, R.L. Lemke, B.D. Gossen, J.Y. Leeson, A. Kirk, E.N. Johnson, O.O. Olfert, S.A. Brandt, A.G. Thomas Effects of crop inputs, diversity, environment, and terrain on yield in an 18-yr study in the semi-arid Canadian prairies Can. J. Plant Sci., 97 (2017), pp. 715-730, 10.1139/cjps-2016-0228 View in ScopusGoogle Scholar Matiu et al., 2017 M. Matiu, D.P. Ankerst, A. Menzel Interactions between temperature and drought in global and regional crop yield variability during 1961-2014 PLoS One, 12 (2017), pp. 1-23, 10.1371/journal.pone.0178339 Google Scholar McKee et al., 1993 T. McKee, N. Doesken, J. Kleist The relationship of drought frequency and duration to time scales Proc. 8th Conf. Appl. Climatol. (1993), pp. 179-183 View in ScopusGoogle Scholar Meza et al., 2020 I. Meza, S. Siebert, P. Döll, J. Kusche, C. Herbert, E.E. Rezaei, H. Nouri, H. Gerdener, E. Popat, J. Frischen, G. Naumann, J.V. Vogt, Y. Walz, Z. Sebesvari, M. Hagenlocher Global-scale drought risk assessment for agricultural systems Nat. Hazards Earth Syst. Sci., 20 (2020), pp. 695-712, 10.5194/nhess-20-695-2020 View in ScopusGoogle Scholar Mishra and Singh, 2010 A.K. Mishra, V.P. Singh A review of drought concepts J. Hydrol. (Amst.), 391 (2010), pp. 202-216, 10.1016/j.jhydrol.2010.07.012 View PDFView articleView in ScopusGoogle Scholar Monfreda et al., 2008 C. Monfreda, N. Ramankutty, J.A. Foley Farming the planet: 2. Geographic distribution of crop areas, yields, physiological types, and net primary production in the year 2000 Glob. Biogeochem. Cycles, 22 (2008), pp. 1-19, 10.1029/2007GB002947 Google Scholar Montzka et al., 2017 C. Montzka, M. Herbst, L. Weihermüller, A. Verhoef, H. Vereecken A global data set of soil hydraulic properties and sub-grid variability of soil water retention and hydraulic conductivity curves Earth Syst. Sci. Data, 9 (2017), pp. 529-543, 10.5194/essd-9-529-2017 View in ScopusGoogle Scholar Mueller et al., 2012 N.D. Mueller, J.S. Gerber, M. Johnston, D.K. Ray, N. Ramankutty, J.A. Foley Closing yield gaps through nutrient and water management Nature, 490 (2012), pp. 254-257, 10.1038/nature11420 View in ScopusGoogle Scholar Nicholls, 2004 N. Nicholls The changing nature of Australian droughts Clim. Change, 63 (2004), pp. 323-336, 10.1023/B:CLIM.0000018515.46344.6d View in ScopusGoogle Scholar Peña-Gallardo et al., 2019a M. Peña-Gallardo, S. Martín Vicente-Serrano, F. Domínguez-Castro, S. Beguería The impact of drought on the productivity of two rainfed crops in Spain Nat. Hazards Earth Syst. Sci., 19 (2019), pp. 1215-1234, 10.5194/nhess-19-1215-2019 View in ScopusGoogle Scholar Peña-Gallardo et al., 2019b M. Peña-Gallardo, S.M. Vicente-Serrano, S. Quiring, M. Svoboda, J. Hannaford, M. Tomas-Burguera, N. Martín-Hernández, F. Domínguez-Castro, A. el Kenawy Response of crop yield to different time-scales of drought in the United States: spatio-temporal patterns and climatic and environmental drivers Agric. Meteor., 264 (2019), pp. 40-55, 10.1016/j.agrformet.2018.09.019 View PDFView articleView in ScopusGoogle Scholar Portmann et al., 2010 F.T. Portmann, S. Siebert, P. Döll MIRCA2000-Global monthly irrigated and rainfed crop areas around the year 2000: a new high-resolution data set for agricultural and hydrological modeling Glob. Biogeochem. Cycles, 24 (2010), 10.1029/2008gb003435 Google Scholar Ray et al., 2015 D.K. Ray, J.S. Gerber, G.K. Macdonald, P.C. West Climate variation explains a third of global crop yield variability Nat. Commun., 6 (2015), pp. 1-9, 10.1038/ncomms6989 Google Scholar Sacks et al., 2010 W.J. Sacks, D. Deryng, J.A. Foley, N. Ramankutty Crop planting dates: an analysis of global patterns Glob. Ecol. Biogeogr., 19 (2010), pp. 607-620, 10.1111/j.1466-8238.2010.00551.x View in ScopusGoogle Scholar Schaap, 2002 M.G. Schaap Rosetta v1.2: A computer program for estimating soil hydraulic parameters with hierarchical pedotransfer functions 251 2002 163 176. Google Scholar Schlaepfer et al., 2017 D.R. Schlaepfer, J.B. Bradford, W.K. Lauenroth, S.M. Munson, B. Tietjen, S.A. Hall, S.D. Wilson, M.C. Duniway, G. Jia, D.A. Pyke, A. Lkhagva, K. Jamiyansharav Climate change reduces extent of temperate drylands and intensifies drought in deep soils Nat. Commun. (2017), p. 8, 10.1038/ncomms14196 Google Scholar Schwabe et al., 2013 K. Schwabe, J. Albiac, J.D. Connor, R.M. Hassan, L.M. González Drought in arid and semi-arid regions: a multi-disciplinary and cross-country perspective Springer, (2013) Google Scholar Sgroi et al., 2021 L.C. Sgroi, M.A. Lovino, E.H. Berbery, G.V. Müller Characteristics of droughts in Argentina’s core crop region Hydrol. Earth Syst. Sci., 25 (2021), pp. 2475-2490, 10.5194/hess-25-2475-2021 View in ScopusGoogle Scholar Sheffield and Wood, 2007 J. Sheffield, E.F. Wood Characteristics of global and regional drought, 1950-2000: Analysis of soil moisture data from off-line simulation of the terrestrial hydrologic cycle J. Geophys. Res. Atmosp., 112 (2007), pp. 1-21, 10.1029/2006JD008288 Google Scholar Siebert et al., 2005 S. Siebert, P. Döll, J. Hoogeveen, J.-M. Faures, K. Frenken, S. Feick Development and validation of the global map of irrigation areas Hydrol. Earth Syst. Sci., 9 (2005), pp. 535-547, 10.5194/hess-9-535-2005 View in ScopusGoogle Scholar Simelton et al., 2009 E. Simelton, E.D.G. Fraser, M. Termansen, P.M. Forster, A.J. Dougill Typologies of crop-drought vulnerability: an empirical analysis of the socio-economic factors that influence the sensitivity and resilience to drought of three major food crops in China (1961-2001) Environ. Sci. Policy, 12 (2009), pp. 438-452, 10.1016/j.envsci.2008.11.005 View PDFView articleView in ScopusGoogle Scholar Simelton et al., 2012 E. Simelton, E.D.G. Fraser, M. Termansen, T.G. Benton, S.N. Gosling, A. South, N.W. Arnell, A.J. Challinor, A.J. Dougill, P.M. Forster The socioeconomics of food crop production and climate change vulnerability: a global scale quantitative analysis of how grain crops are sensitive to drought Food Secur, 4 (2012), pp. 163-179, 10.1007/s12571-012-0173-4 Google Scholar Spinoni et al., 2014 J. Spinoni, G. Naumann, H. Carrao, P. Barbosa, J. Vogt World drought frequency, duration, and severity for 1951-2010 Int. J. Climatol., 34 (2014), pp. 2792-2804, 10.1002/joc.3875 View in ScopusGoogle Scholar Stringer et al., 2020 L.C. Stringer, E.D.G. Fraser, D. Harris, C. Lyon, L. Pereira, C.F.M. Ward, E. Simelton Adaptation and development pathways for different types of farmers Environ. Sci. Policy, 104 (2020), pp. 174-189, 10.1016/j.envsci.2019.10.007 View PDFView articleView in ScopusGoogle Scholar Studer et al., 2017 C. Studer, Y. Hu, U. Schmidhalter Interactive effects of N-, P- and K-nutrition and drought stress on the development of maize seedlings Agric. (Switz.) (2017), p. 7, 10.3390/agriculture7110090 Google Scholar Swain et al., 2022a S. Swain, S.K. Mishra, A. Pandey Assessing spatiotemporal variation in drought characteristics and their dependence on timescales over Vidarbha Region, India Geocarto Int., 37 (2022), pp. 17971-17993, 10.1080/10106049.2022.2136260 View in ScopusGoogle Scholar Swain et al., 2022b S. Swain, S.K. Mishra, A. Pandey, P. Kalura Inclusion of groundwater and socio-economic factors for assessing comprehensive drought vulnerability over Narmada River Basin, India: a geospatial approach Appl. Water Sci., 12 (2022), pp. 1-16, 10.1007/s13201-021-01529-8 View in ScopusGoogle Scholar Trenberth et al., 2014 K.E. Trenberth, A. Dai, G. van der Schrier, P.D. Jones, J. Barichivich, K.R. Briffa, J. Sheffield Global warming and changes in drought Nat. Clim. Chang, 4 (2014), pp. 17-22, 10.1038/nclimate2067 View in ScopusGoogle Scholar Troy et al., 2015 T.J. Troy, C. Kipgen, I. Pal The impact of climate extremes and irrigation on US crop yields Environ. Res. Lett. (2015), p. 10, 10.1088/1748-9326/10/5/054013 Google Scholar Tschirley, 1998 Tschirley, D.L., 1998. Planning for drought in Mozambique: Balancing the roles of food aid and food markets. Google Scholar United Nations, 2015 United Nations, 2015. Transforming our world: the 2030 Agenda for Sustainable Development [WWW Document]. URL 〈https://www.refworld.org/docid/57b6e3e44.html〉 (accessed 4.7.22). Google Scholar USGS, 2002 USGS, 2002. GTOPO30 – Global 30 arc second elevation data [WWW Document]. URL 〈https://lta.cr.usgs.gov/GTOPO30〉. Google Scholar Vicente-Serrano et al., 2010 S.M. Vicente-Serrano, S. Beguería, J.I. López-Moreno A multiscalar drought index sensitive to global warming: the standardized precipitation evapotranspiration index J. Clim., 23 (2010), pp. 1696-1718, 10.1175/2009JCLI2909.1 View in ScopusGoogle Scholar Vicente-Serrano et al., 2012 S.M. Vicente-Serrano, S. Beguería, J. Lorenzo-Lacruz, J.J. Camarero, J.I. López-Moreno, C. Azorin-Molina, J. Revuelto, E. Morán-Tejeda, A. Sanchez-Lorenzo Performance of drought indices for ecological, agricultural, and hydrological applications Earth Inter. (2012), p. 16, 10.1175/2012EI000434.1 Google Scholar Vicente-Serrano et al., 2013 S.M. Vicente-Serrano, C. Gouveia, J.J. Camarero, S. Beguería, R. Trigo, J.I. López-Moreno, C. Azorín-Molina, E. Pasho, J. Lorenzo-Lacruz, J. Revuelto, E. Morán-Tejeda, A. Sanchez-Lorenzo Response of vegetation to drought time-scales across global land biomes Proc. Natl. Acad. Sci. USA, 110 (2013), pp. 52-57, 10.1073/pnas.1207068110 View in ScopusGoogle Scholar Vogel et al., 2019 E. Vogel, M.G. Donat, L.V. Alexander, M. Meinshausen, D.K. Ray, D. Karoly, N. Meinshausen, K. Frieler The effects of climate extremes on global agricultural yields Environ. Res. Lett. (2019), p. 14, 10.1088/1748-9326/ab154b Google Scholar Wang et al., 2017 Q. Wang, J. Wu, X. Li, H. Zhou, J. Yang, G. Geng, X. An, L. Liu, Z. Tang A comprehensively quantitative method of evaluating the impact of drought on crop yield using daily multi-scale SPEI and crop growth process model Int J. Biometeorol., 61 (2017), pp. 685-699, 10.1007/s00484-016-1246-4 View in ScopusGoogle Scholar Wilhite and Glantz, 1985 D.A. Wilhite, M.H. Glantz Understanding: the drought phenomenon: the role of definitions Water Int, 10 (1985), pp. 111-120, 10.1080/02508068508686328 View in ScopusGoogle Scholar Williams et al., 2016 A. Williams, M.C. Hunter, M. Kammerer, D.A. Kane, N.R. Jordan, D.A. Mortensen, R.G. Smith, S. Snapp, A.S. Davis Soil water holding capacity mitigates downside risk and volatility in US rainfed maize: time to invest in soil organic matter PLoS One, 11 (2016), pp. 1-11, 10.1371/journal.pone.0160974 Google Scholar Xu et al., 2018 H. Jie Xu, X.Ping Wang, C.Yan Zhao, X.Mei Yang Diverse responses of vegetation growth to meteorological drought across climate zones and land biomes in northern China from 1981 to 2014 Agric. Meteor., 262 (2018), pp. 1-13, 10.1016/j.agrformet.2018.06.027 View PDFView articleGoogle Scholar Yamoah et al., 2000 C.F. Yamoah, D.T. Walters, C.A. Shapiro, C.A. Francis, M.J. Hayes Standardized precipitation index and nitrogen rate effects on crop yields and risk distribution in maize Agric. Ecosyst. Environ., 80 (2000), pp. 113-120, 10.1016/S0167-8809(00)00140-7 View PDFView articleView in ScopusGoogle Scholar Yang et al., 2020 J. Yang, J. Wu, L. Liu, H. Zhou, A. Gong, X. Han, W. Zhao Responses of winter wheat yield to drought in the North China Plain: spatial–temporal patterns and climatic drivers Water (Basel) (2020), p. 12, 10.3390/w12113094 View PDFView articleGoogle Scholar Zampieri et al., 2017 M. Zampieri, A. Ceglar, F. Dentener, A. Toreti Wheat yield loss attributable to heat waves, drought and water excess at the global, national and subnational scales Environ. Res. Lett. (2017), p. 12, 10.1088/1748-9326/aa723b Google Scholar Zargar et al., 2011 A. Zargar, R. Sadiq, B. Naser, F.I. Khan A review of drought indices Environ. Rev., 19 (2011), pp. 333-349, 10.1139/a11-013 View in ScopusGoogle Scholar Zeleke and Bing, 2004 T.B. Zeleke, C.S. Bing Scaling properties of topographic indices and crop yield: multifractal and joint multifractal approaches Agron. J., 96 (2004), pp. 1082-1090, 10.2134/agronj2004.1082 View in ScopusGoogle Scholar Zhang et al., 2019 F. Zhang, Y. Chen, J. Zhang, E. Guo, R. Wang, D. Li Dynamic drought risk assessment for maize based on crop simulation model and multi-source drought indices J. Clean. Prod., 233 (2019), pp. 100-114, 10.1016/j.jclepro.2019.06.051 View PDFView articleView in ScopusGoogle Scholar Zipper et al., 2016 S.C. Zipper, J. Qiu, C.J. Kucharik Drought effects on US maize and soybean production: spatiotemporal patterns and historical changes Environ. Res. Lett. (2016), p. 11, 10.1088/1748-9326/11/9/094021 Google Scholar Cited by (1) What drives the spatial heterogeneity of cropping patterns in the Northeast China: The natural environment, the agricultural economy, or policy? 2023, Science of the Total Environment Show abstract © 2023 The Authors. Published by Elsevier Ltd. Recommended articles Spatio-temporal dynamics of forest ecosystems revealed by the LiDAR-based characterization of medieval field systems (Vosges Mountains, France) Anthropocene, Volume 42, 2023, Article 100374 Benjamin Keller, …, Damien Ertlen View PDF The meanings of the Critical Zone Anthropocene, Volume 42, 2023, Article 100377 Raymond M. Lee, …, Benjamin W. Abbott View PDF 1100-years history of transformation of the East European forest-steppe into arable land: Case study from Kursk region (Russia) Anthropocene, Volume 42, 2023, Article 100385 Alisa Kasianova, …, Lyudmila Shumilovskikh View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 1 Captures Readers: 15 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply."

Paper 4:
- APA Citation: Wang, Y., Shi, F., Zhao, C., & Zhou, X. (2022). Identifying groundwater resilience zones in an arid inland basin using GIS-based Dempster-Shafer theory. Journal of Hydrology: Regional Studies, 44, 101232.
  Main Objective: To predict the spatial distribution of groundwater resilience and assess the resilience of groundwater systems in an arid inland river basin.
  Study Location: Hotan River Basin, Xinjiang, China
  Data Sources: Groundwater performance indicator, Resilience indicator, Spatial datasets of groundwater conditioning factors
  Technologies Used: Geographic Information Systems (GIS), Dempster-Shafer Theory Model
  Key Findings: 
  Extract 1: "Dempster-Shafer theory model, which supports the integration of information from multiple heterogeneous sources and enables the flexible construction of basic probability assignment (BPA) between single-factor resilience indicators and spatial data layers of groundwater conditioning factors and provides prediction results, systematic errors and random errors (Mogaji et al., 2015, Naghibi et al., 2015, Rahmati and Melesse, 2016)."
  Extract 2: Groundwater resilience zonation mapping consists of four primary steps. (1) Creating spatial datasets of groundwater conditioning factors as evidential layers for the Dempster-Shafer theory model. (2) Establishing mathematical relationships between resilience and groundwater conditioning factors and integrating evidence based on the Dempster-Shafer theory model. (3) Creating and validating the groundwater resilience zonation map. (4) Interpretation and comparison of results.
  Limitations: A possible limitation of the study is that the selection of groundwater conditioning factors could influence the prediction accuracy of the Dempster-Shafer theory model. The study considers nine groundwater conditioning factors, but there may be other relevant factors that could be included to improve the model's performance.
  Relevance Evaluation: This paper is relevant to my work because it presents a systematic methodology to quantify and map groundwater resilience in an arid inland river basin using the Dempster-Shafer theory model. The study area, the Hotan River Basin, shares similar arid climate, hydrological, and geological conditions with the region I am working on, making the findings and methods in this research highly relevant and applicable to my own study.
  Relevance Score: 1.0
  Inline Citation: (Wang et al., 2022)
  Explanation: Groundwater resilience is a crucial concept in arid inland river basins, where water resources are scarce and vulnerable to climate change. This study aims to construct a Dempster-Shafer theory model based on the groundwater performance indicator and the resilience indicator to spatially predict groundwater resilience in the Hotan River Basin, China and evaluate the validity of these two indicators. The article's main contributions are the following:

1. Development of a method for spatial prediction of groundwater resilience based on the Dempster-Shafer theory model. 
2. Establishment of the relationship between groundwater resilience and various conditioning factors through GIS technology combined with the Dempster-Shafer theory model. 
3. Evaluation of the validity of the groundwater resilience prediction map with groundwater resilience data from observation wells.

 Full Text: >
"Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Graphical Abstract Keywords 1. Introduction 2. Study area 3. Materials and methods 4. Results and discussion 5. Conclusions CRediT authorship contribution statement Declaration of Competing Interest Acknowledgements Appendix A. Supplementary material Data Availability References Show full outline Cited by (2) Figures (11) Show 5 more figures Tables (3) Table 1 Table 2 Table 3 Extras (1) Supplementary material Journal of Hydrology: Regional Studies Volume 44, December 2022, 101232 Identifying groundwater resilience zones in an arid inland basin using GIS-based Dempster-Shafer theory Author links open overlay panel Yuehui Wang a b c, Fengzhi Shi a b c, Chengyi Zhao d, Xu Zhou a b c Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.ejrh.2022.101232 Get rights and content Under a Creative Commons license open access Highlights • Evaluating the validity of and in predicting groundwater resilience. • Establishing relationships between groundwater resilience and conditioning factors. • The spatial distribution of groundwater resilience was quantified. • The method can predict the regional groundwater resilience effectively and reliably. Abstract Study region Hotan River Basin, an arid inland river basin, Northwest China. Study focus A method for assessing the spatial distribution of groundwater resilience is constructed by combining the Dempster-Shafer theory model and spatial analysis techniques. The groundwater performance indicator CRS and resilience indicator pi are calculated to present groundwater resilience. Using the Dempster-Shafer theory model to mine the data, nine groundwater conditioning factors are selected as evidential layers of the model, and the mathematical relationships between the resilience indicators and groundwater conditioning factors are established through evidence integration; Ultimately, a groundwater resilience spatial distribution map is generated, and the performance of the map is explored based on the CRS and pi values. New hydrological insights for the region The constructed assessment method based on this study reliably and effectively predicts the regional groundwater resilience. Validation of the groundwater resilience prediction map with pi indicates that this indicator outperforms the CRS. The areas with high groundwater resilience are mainly concentrated in the upstream oasis irrigation area and the downstream river channel. The groundwater resilience (pi) zonation map is divided into five categories: very low (Bel of 0–0.072), low (0.072–0.171), moderate (0.171–0.458), moderate high (0.458–0.786), and high (>0.786). The results can provide a scientific basis for groundwater safety and management in the Hotan River Basin. Graphical Abstract Download : Download high-res image (219KB) Download : Download full-size image Previous article in issue Next article in issue Keywords Groundwater resilienceSpatial distributionDempster-Shafer modelHotan River Basin 1. Introduction Groundwater is an indispensable water resource in arid inland regions (Elmqvist et al., 2003, Shamsudduha, 2013, Nampak et al., 2014, Chinnasamy et al., 2018). Not only is groundwater essential for all life, but it also performs valuable ecosystem services. The combination of climate change and human activities has already overburdened groundwater resources in arid inland river basins (Chen et al., 2019, Yang et al., 2019, Ozano et al., 2022). However, this essential resource remains at serious risk from declining groundwater levels, soil salinization, land desertification, and vegetation degradation, all of which degrade vulnerable ecosystems (Zhang et al., 2012). Groundwater security is experiencing significant challenges in arid regions where groundwater exploitation and utilization are approaching or surpassing its threshold, and concerns about the resilience of groundwater systems in arid regions are a primary focus (Hugman et al., 2012, Fuchs et al., 2018, Pourmoghim et al., 2022). Since Holling adopted resilience into ecosystem stability studies in 1973, resilience has been a research focus in the fields of hydrology, ecology and meteorology (Fuchs et al., 2018, Gönnert and Gerkensmeier, 2015, Holling, 1973, Thomas and Waring, 2015). Resiliency indicates how quickly a water resource system returns to a satisfactory condition after an unsatisfactory condition (Hashimoto et al., 1982). Katic and Grafton (2011) introduced groundwater resilience as the ability of a groundwater system to recover to its original state after an external disturbance and deviation from its equilibrium state, following natural and human intervention. The resilience and vulnerability of a groundwater system under external disturbance are constantly changing with the changes in external stresses and system functions. Many scholars have studied water resilience from various perspectives. Hashimoto et al. (1982) first proposed the indices of reliability, resiliency and vulnerability (RRV) for classifying and evaluating the performance of water resource systems. This approach (RRV) has been widely used by researchers because it is rational, efficient, and accessible (Fowler et al., 2003, Peters et al., 2005; Mondal and Wasimi, 2007; Rodak et al., 2014; Lu et al., 2019; Nair and Indu, 2021). Qi et al. (2016) proposed an indicator reflecting the autocorrelation of variables at a given time based on a convex model and critical slowing down theory, initially used to identify changes in watershed resilience for annual runoff. Liu et al. (2021) studied the resilience of the Yangtze River Basin under climatic factors and anthropogenic disturbance using this indicator. Herrera-Franco et al. (2020) developed a matrix for evaluating the resilience of coastal aquifers based on indicators from sustainable development goals (SDGs) within a sociohydrological framework, combining four axes of development (political, social, environmental and cultural). Behboudian et al. (2021) proposed two criteria based on robustness, redundancy, resourcefulness, rapidity, and durability (4R-D) and a social resilience-based criterion (SR) to assess the total resilience of water resource systems. According to previous studies, different methods have evaluated the resilience of water resource systems. Nevertheless, the quantification of groundwater resilience remains a challenge. Previous works have mostly focused on selecting single indicators (Hashimoto et al., 1982, Moy et al., 1986, Hugman et al., 2012, Qi et al., 2016) or constructing indicator frameworks (Herrera-Franco et al., 2020, Behboudian et al., 2021) to assess the resilience of water resource systems in changing environments. However, single-factor evaluation methods often lead to inconsistent resilience results due to differences in the selection of indicators and calculation methods. Although the indicator systematic evaluation method accounts for multiple factors, it can obtain only an average level of resilience at the local scale, which makes obtaining the spatial distribution characteristic of resilience and verifying the reliability of the selection of weights for each indicator difficult. Currently, few studies have been conducted to spatially predict groundwater resilience. For the effective management and long-term use of groundwater resources, an urgency exists to find a spatially scalable calculation method to assess groundwater resilience, which requires mapping to the spatial distribution of groundwater resilience. The factors influencing the spatial distribution of groundwater resilience can be divided into natural and anthropogenic factors. Natural factors include the geological and hydrogeological conditions of the aquifer (Singh et al., 2011, Garg and Wani, 2013, Mogaji et al., 2015, Rahmati and Melesse, 2016, Alraggad et al., 2017, Mogaji, 2017). Anthropogenic factors mainly refer to various behavioural factors that may cause groundwater decline and pollution (Singh et al., 2011, Nampak et al., 2014, Rahmati and Melesse, 2016). The available methods widely used for studying the spatial distribution of groundwater include the overlay and index method (Ertürk et al., 2017, Kumar et al., 2019), fuzzy logic (Naghibi et al., 2015, Rahmati et al., 2015), frequency ratio (FR) (Nampak et al., 2014, Razandi et al., 2015), analytic hierarchy process (AHP) (Chowdhury et al., 2009, Razandi et al., 2015), and Dempster-Shafer (DS) theory model (Nampak et al., 2014, Mogaji et al., 2015, Rahmati and Melesse, 2016). The Dempster-Shafer theory model, which supports the integration of information from multiple heterogeneous sources and enables the flexible construction of basic probability assignment (BPA) between single-factor resilience indicators and spatial data layers of groundwater conditioning factors and provides prediction results, systematic errors and random errors (Mogaji et al., 2015, Naghibi et al., 2015, Rahmati and Melesse, 2016), is a potentially reliable method for predicting the spatial distribution of groundwater resilience. The Hotan River Basin is a typical arid inland river basin, with mountains as the runoff generation regions and plains as the oasis water-consuming area (Guo et al., 2016). The Hotan River runoff is primarily recharged by glacial/snow meltwater, and the river is a seasonal river with runoff concentrated in the summer, accounting for 75% of annual runoff (Li et al., 2018). With scarce precipitation and uneven spatial and temporal distributions of surface water, groundwater plays an important role in meeting the growing demand for water for agricultural production and domestic use (Shi et al., 2021, Huang et al., 2022). With economic development and population growth, the human demand for groundwater resources has further intensified (Fu et al., 2018, Shi et al., 2021), and the water levels in groundwater wells in the Hotan River Basin have almost universally declined. Therefore, taking the Hotan River Basin as a case study, research on groundwater resilience especially after extraction, in arid inland river basins is significant for the safety and effective management of regional groundwater resources (Grönwall and Oduro-Kwarteng, 2018; Fuchs et al., 2018). The main purpose of this study is to construct a verifiable evaluation method for the spatial distribution of groundwater resilience in the Hotan River Basin. (1) The most widely used groundwater performance indicator (Nair and Indu, 2021) of the RRV criterion and the resilience indicator (Qi et al., 2016) are adopted to calculate groundwater resilience. (2) Quantitative analysis of the relationship between groundwater resilience and various conditioning factors is performed based on GIS technology combined with the Dempster-Shafer theory model. (3) Groundwater resilience zoning maps are generated and validated with groundwater resilience data from observation wells to assess the validity of the Dempster-Shafer theory model as a criterion for determining spatial groundwater resilience zones. The study will provide information on groundwater resilience in arid inland river basins and serve as a scientific reference for the integrated management of water resources in inland river basins. 2. Study area The study area (79°23′–80°38′E, 36°53′–38°7′N; Fig. 1) is part of the Hotan River Basin in the Xinjiang Uygur Autonomous Region in China, located at the southern edge of the Taklamakan Desert and the northern slope of the Kunlun Mountains, with a total area of 9349.63 km2. The study area has a warm continental arid desert climate, with an average annual precipitation of 48. 7 mm, and the average annual temperature is 11.9 °C (Fu et al., 2018). The Hotan River comprises two tributaries, the eastern branch of the Yurunkash River and the western branch of the Karakash River, which originate from the northern slope of the Kunlun Mountains and the Karakoram Mountains, respectively. The Yurunkash River has a total length of 504 km and a catchment area of 14813 km2 (Shi et al., 2021, Wang et al., 2021). The Karakash River has a total length of 808 km and a catchment area of 21532 km2 (Wang et al., 2021). The average annual runoff of the Yurunkash River and Karakash River is 22. 85 × 108 m3 and 21. 67 × 108 m3 respectively (Shi et al., 2021), which converts into runoff depths of 154.3 mm and 100.6 mm. Download : Download high-res image (342KB) Download : Download full-size image Fig. 1. Generalized location map of the study area with groundwater wells. (Drawing review No. GS(2020)4619 and GS(2019)3266). The groundwater recharge, runoff, and discharge in the study area are obviously horizontally zoned due to the constraints of climatic and hydrological conditions, geological formations, and geomorphology (Shi et al., 2021). The mountainous area is the groundwater recharge source area, the premontane diluvial gravel plain is the groundwater recharge runoff area, and the alluvial-diluvial fine soil plain and the northern desert alluvial layer are groundwater discharge areas (Shi et al., 2021). From south to north, the groundwater hydraulic gradient gradually declines and the groundwater level rises. The groundwater recharge sources and recharge modes in this area are mainly river seepage, channels and field irrigation infiltration (Huang et al., 2022). The discharge modes are mainly phreatic water evaporation and spring overflow (Huang et al., 2022). The Hotan oasis is an area of significant irrigated agriculture and urban and rural residents, whose survival and development are dependent on the water of the Hotan River (Fu et al., 2018). Agricultural water use is the mainstay of water resource use in the basin, with agriculture accounting for 55%− 75% and domestic water use accounting for 0.5%− 3% of the total consumption in the basin from 2003 to 2020 (the data are provided by the Xinjiang Tarim River Basin Authority). In addition, groundwater is an essential source of water supply, with production, domestic use and ecological use accounting for 90.6%, 8.6% and 0.8%, respectively, of the total groundwater extraction in 2010 in Hotan, and agriculture accounted for 62% of the total groundwater extraction (Wang et al., 2013). Ensuring the sustainable use of groundwater resources in the Hotan River Basin is therefore vital to the sustainable socioeconomic development of the Hotan oasis. 3. Materials and methods 3.1. Groundwater resilience index Single-factor evaluation methods are applied here to evaluate long-term groundwater resilience. The resilience indicates how quickly a system returns to a satisfactory state after an unsatisfactory state (Hashimoto et al., 1982). The resilience indicator , proposed by Qi et al. (2016), based on the convex model and critical slowing down theory, reflects the autocorrelation of variables at a given time and quantifies the temporal variation in water resource system resilience (Kumar et al., 2020, Liu et al., 2021). We thus use the two indicators above to calculate groundwater resilience. 3.1.1. Groundwater performance indicator ( ) The groundwater performance indicator from the traditional RRV criteria is used to assess groundwater resilience in the study area (Hashimoto et al., 1982, Nair and Indu, 2021). First, a criterion (i.e., multiyear average groundwater level) is defined for each groundwater well, and represents a time series of groundwater levels. A satisfactory state ) indicates that the groundwater level of the well exceeds the annual average, and an unsatisfactory state indicates that the groundwater level is lower than the annual average. The groundwater performance indicator can be defined in Eq. (1). (1) is used to assess the resilience of the wells in the study area, ranging from 0 to 1. This indicator reflects the rate of recovery to a satisfactory state after a system failure. The larger the value of is, the higher the groundwater resilience. 3.1.2. Resilience indicator ( We use groundwater level as a state variable and the resilience indicator to quantify the temporal variation in the resilience of the groundwater system. Groundwater resilience can be reflected by the deviance between a state variable and its adjacent values ( , with the number of neighbouring points being 2 n). The larger the deviation is, the higher the groundwater system resilience, indicating that the time series corresponding to state variables have a lower autocorrelation. The resilience indicator can be computed as shown in (2), (3), (4), (5). (2) (3) (4) (5) where γ is the threshold of the deviation of from its adjacent points. and denote the maximum and minimum of the monthly groundwater level data series, respectively. According to Qi et al. (2016), is used as an empirical value of 0.75, and the threshold γ is 0.375 (Eq. (4)). The temporal variation of is consistent for different . Here, is considered to be 4 (the number of neighbouring points is 8). The range of is 0–8. Based on the groundwater level data, we use (2), (3), (4), (5) to calculate the groundwater system resilience in the study area at moment . 3.1.3. Data source Data for the calculation of the groundwater resilience index can be directly retrieved from the monthly groundwater level data of 27 groundwater wells monitored by the Hotan Water Resources Bureau from 1989 to 2020. 3.2. Groundwater resilience zones Groundwater resilience zonation mapping consists of four primary steps. (1) Creating spatial datasets of groundwater conditioning factors as evidential layers for the Dempster-Shafer theory model. (2) Establishing mathematical relationships between resilience and groundwater conditioning factors and integrating evidence based on the Dempster-Shafer theory model. (3) Creating and validating the groundwater resilience zonation map. (4) Interpretation and comparison of results. The overall methodology is illustrated in Fig. 2. Download : Download high-res image (428KB) Download : Download full-size image Fig. 2. Methodological flowchart of groundwater resilience zonation mapping. 3.2.1. Groundwater resilience conditioning factors In addition, a spatial database of different spatial datasets is essential to establishing a reliable and accurate groundwater resilience prediction model in the study area. The spatial distribution of groundwater is governed by natural factors, including meteorology, hydrology, geomorphology and geological formations (Singh et al., 2011, Garg and Wani, 2013, Mogaji et al., 2015, Alraggad et al., 2017, Mogaji, 2017), and anthropogenic factors such as land use (Singh et al., 2011, Nampak et al., 2014, Rahmati and Melesse, 2016, Liu et al., 2021). Through the information obtained from the literature, nine groundwater conditioning factors, including lithology, geomorphology, slope, soil type, distance to river, canal density, hydraulic conductivity, groundwater depth, and land use, are considered in this study. These factors affect the groundwater resilience of the area by influencing groundwater storage, recharge, transport, and discharge. Raster datasets of the nine groundwater conditioning factors are generated in GIS to evaluate groundwater resilience in the study area. A brief description of these nine factors is provided below. 3.2.1.1. Lithology Lithological differences directly affect infiltration, and lithology is one of the indispensable factors for the evaluation and prediction of groundwater prospects in the region (Mogaji et al., 2015, Ait El Mekki and Laftouhi, 2016). The aquifer in the study area mainly consists of alluvial-diluvial aquifers in the gravel plain and alluvial-diluvial aquifers in the fine soil plain. The gravel plain alluvial-diluvial aquifer mainly comprises sand gravel and fine sand intercalated by sand gravel and gravel-cobble. As the slope of the terrain becomes flatter, the sediment grains of the alluvial-diluvial aquifer in the fine soil plain become finer, and the lithology of the aquifer is finer, with medium to coarse sand and fine sand generally found in the area (Shi et al., 2021). The lithology of the study area is divided into four categories, from south to north as follows: gravel, sand gravel, fine sand, and meal sand (Fig. 3a). Download : Download high-res image (556KB) Download : Download full-size image Fig. 3. Evidential datasets of groundwater spatial distribution conditioning factors: (a) lithology, (b) geomorphology, (c) slope, (d) soil type, (e) distance to river, (f) canal density, (g) hydraulic conductivity, (h) groundwater depth, and (i) land use. Fig. 3 (continued). 3.2.1.2. Geomorphology The topographic map of the study area is derived from the dataset of the remote sensing survey of resources and the environmental project of the Chinese Academy of Sciences, with a resolution of 100 m. The dataset has four geomorphology classes, including beach land, plain, mountains and desert (Fig. 3b). 3.2.1.3. Slope The slope determines the recharge process of groundwater and is negatively related to the infiltration rate of surface water with which groundwater interacts (Nampak et al., 2014, Ait El Mekki and Laftouhi, 2016). The slope is calculated from a digital elevation model (DEM) in GIS. The slope is classified into five classes using quantile classification, 0–0.313, 0.313–0.625, 0.625–0.938, 0.938–1.355, and 1.355–26.577, for evaluating groundwater resilience in the study area (Fig. 3c). 3.2.1.4. Soil type Soil properties are a critical factor controlling groundwater recharge, and soil types and their various permeabilities largely control the infiltration or transport rate of surface water into aquifer systems (Rahmati and Melesse, 2016). The soil map of the study area is extracted from the second national soil census data (a 1:1,000,000 scale digital soil map of China). Amorphic soils, semi-aquatic soils, anthrosols, desert soils, and alkali-saline soils are distributed throughout the study area (Fig. 3d). 3.2.1.5. Distance to river and canal density Euclidean distance and line density tools are applied to generate river distance and canal density maps in the study area, respectively, from the current river and canal data. The distance from the river is categorized into five groups: < 2.18, 2.18–5.89, 5.89–12.87, 12.87–24.20, and > 24.20 km (Fig. 3e). Fig. 3f indicates that the canal density is divided into five categories, including 0, 0–0.103, 0.103–0.175, 0.175–0.315, and > 0.315 km/km2. A shorter distance to the river and a higher canal density imply a higher surface runoff, which favours groundwater storage. 3.2.1.6. Hydraulic conductivity Hydraulic conductivity depends on the groundwater flow in the aquifer (Mogaji, 2017), and regions with a higher hydraulic conductivity favour groundwater enrichment. As shown in Fig. 3g, the spatial distribution of the hydraulic conductivity of shallow groundwater in the study area generally decreases from south to north. The zoning of hydraulic conductivity in the study area is divided into five classes. 3.2.1.7. Groundwater depth The groundwater depth dictates the depth of groundwater transport and the time of contact with the surrounding medium (Oikonomidis et al., 2015). The groundwater depth is separated into six categories: < 1, 1–3, 3–6, 6–10, 10–20, and > 20 m (Fig. 3h). The groundwater depth map of the study area is obtained from 2010 groundwater depth data from the Hotan River Basin. 3.2.1.8. Land use Land use is a vital factor in controlling groundwater recharge, and different land types have different impacts on the groundwater recharge process (Kaliraj et al., 2014). The land use data of the study area in 2015 are obtained from the results dataset of the remote sensing survey of resources and the environmental project of the Chinese Academy of Sciences with a resolution of 30 m. According to the land use characteristics of the study area and national land type classification standards, land types are reclassified into six categories: farmland, woodland, grassland, water body, residential area and unused land (Fig. 3i). 3.2.2. Dempster-Shafer evidence theory model In 1967, Dempster first suggested the Dempster-Shafer evidence theory as a rule of information combination in his study of statistical questions (Dempster, 1967). In further developing this evidence theory, Shafer proposed a mathematical approach to uncertainty inference based on \"evidence\" and \"combination\" by adopting the concept of a belief function (Shafer, 1976). In the present study, the Dempster-Shafer evidence theory model is applied to predict groundwater resilience, and it is constructed by establishing a framework of discernment, defining the basic probability assignment, calculating the mass function, and implementing the evidence combination. A framework of discernment is the set of all probable targets for a certain object to be judged and is a mutually exclusive nonempty finite set (Eq. (6)). in Eq. 6 is the probability that each pixel is high for the target groundwater resilience, and ̅ is the negation of , i.e., the probability that each pixel is lower for the groundwater resilience. The basic probability assignment is performed for the target in the framework of discernment, and the basic probability function (Eq. (7)) needs to fulfil the conditions and . (6) ̅ (7) According to the existing groundwater resilience calculation results, we consider ≥ 0.094 and ≥ 2 as the criteria for target . The belief function , disbelief function , plausibility function and uncertainty function ) are calculated using (8), (9), (10), (11) (Park, 2011, Rahmati and Melesse, 2016). indicates the degree of belief in any one target, the calculation of contains the degree of belief in this target and the degree of belief in the unknown field, and the difference between and is denoted as . and indicate the lower and upper probabilities in target , respectively. The [ , ] interval refers to the belief interval, which characterizes the range of the degree of uncertainty (Fig. 4). The size of the belief interval determines the extent of credibility of the evidence. The wider the interval is, the lower the credibility of the evidence and vice versa. (8) (9) ̅ ̅ (10) (11) where is the class attribute of the spatial information layer , is the likelihood ratio for supporting target , and ̅ is the likelihood ratio for supporting target ̅ . The likelihood ratio for supporting the target can be defined as ((12), (13)): (12) (13) ̅ where is the number of groundwater well pixels in that support target , is the total number of groundwater wells in the study area that support target , is the total number of pixels for class attributes in layer , and is the total number of pixels in the whole region. Download : Download high-res image (25KB) Download : Download full-size image Fig. 4. The relationships among the evidence belief functions. The basic probability assignment of each information layer is decided according to the spatial relationship between the spatial location of observation wells and the groundwater conditioning factor layers. The attributes of the groundwater conditioning factor layers are superimposed to obtain raster layers corresponding to the belief, disbelief, plausibility, and uncertainty of each groundwater conditioning factor. The basic probability assignment of different information layers is combined to obtain the ultimate results according to the combination rules of the Dempster-Shafer evidence theory. The evidence combination rules used in this study are as follows (Mogaji et al., 2015). (14) (15) (16) (17) (18) The degree of belief generated by evidence is expressed by , the degree of plausibility is expressed by , the degree of uncertainty is expressed by and calculated as , and the degree of disbelief is expressed by and calculated as . In (14), (15), (16), (17), (18): denotes the lower degree of belief for each layer of factor type or range, denotes the degree of disbelief for each layer of factor type or range, denotes the degree of uncertainty for each layer of factor type or range, denotes each factor type (1, 2, ..., 9), and is called the normalization factor. The mass functions in the Dempster-Shafer evidence theory model, including belief, disbelief, uncertainty, and plausibility, are the belief function components that evaluate the predictive ability of the evidence model. Using (14), (15), (16), (17), (18) to iterate evidential layers, eight operational iterations are performed on the nine evidential layers. The final results are used to construct a groundwater resilience zonation map for the study area. 4. Results and discussion 4.1. Groundwater resilience based on the groundwater performance indicator ( ) and resilience indicator ( ) The paper quantitatively estimates groundwater resilience based on groundwater level data in the study area using two methods: the groundwater performance indicator and the resilience indicator . The statistical characteristics are shown in Table 1. Table 1. Summary statistics of the groundwater resilience index. indicator time series (year) max min average stdev cv 1989–2020 0.25 0 0.094 0.073 0.775 1989–2020 4.18 1.25 2.82 0.83 0.30 The theoretical value of the groundwater performance indicator is 0–1, and ranges from 0 to 0.25 in the study area, with an average value of 0.094 and 44% of the wells being greater than the average. According to the value, resilience is classified into five classes with values ranging from 0 to 0.01, 0.01–0.02, 0.02–0.03, 0.03–0.094, and > 0.094. Nineteen percent of the wells have low resilience (compared with moderate resilience), and 44% of the wells have high resilience. The average of 27 wells is used to assess the interannual variation in groundwater resilience in the study area. The observation wells are located in areas with a relatively high resilience, while the wells with a relatively low resilience are mainly located in areas with a high groundwater depth and are far from the river. Wells with a relatively high resilience are mainly found in the upstream oasis irrigation area and near the downstream river channel, where the lithology is coarse (sand gravel and fine sand), the terrain is flat and canal systems are densely distributed, and the soil types are mainly semi-aquatic soils and anthrosols (Fig. 5). Download : Download high-res image (334KB) Download : Download full-size image Fig. 5. Spatial distribution of observation wells with various classes of resilience. Fig. 6 presents the proportion of different classes of resilience based on and . The is concentrated in the high and moderate high classes, accounts for the largest proportion (74%) in the high classes, and is higher than in the very low and moderate high classes. Which more representative in assessing regional groundwater resilience: the groundwater performance indicator or the resilience indicator ? The advantage of the water resource systems resilience metric proposed by Hashimoto et al. (1982) is that it can describe the rate at which the system recovers to a satisfactory state after a failure, but the satisfactory or unsatisfactory state depends on a set threshold. Here, we set the multiyear average groundwater level of each well as the threshold. The resilience indicator , based on a convex model and critical slowing down theory, can not only reveal the temporal variability of groundwater system resilience but also effectively identify critical shifts in groundwater system resilience (Qi et al., 2016, Kumar et al., 2020). Both approaches to assessing resilience can address long-term changes in system resilience, but the resilience metric better meets the five criteria (baseline functionality, threshold functionality, whole system damage, elapsed time to satisfactory recovery, and uncertainty scenarios of disruptions) included in the resilience assessment of water resource systems than does the resilience indicator (Shin et al., 2018). Notably, for four wells has a value of 0 but is not 0. The reason for this is that the calculation of is constrained by the threshold limit. If the observation wells are subject to external disturbance and the groundwater level is below the multiyear average groundwater level for a long time and cannot return to its original state, the water level is still stable within a fixed range. In this case, a calculated of 0 does not mean that the groundwater resilience at that location is low, and quantifying the groundwater resilience based on the is not reliable at this point. In contrast, the resilience indicator better reflects variations in long-term groundwater system resilience, as it is not limited by other conditions. Using the resilience indicator to assess groundwater resilience and exploring the effects of various resolutions (daily/monthly/annual) or different types of hydrological series as state variables on groundwater resilience under climate change and anthropogenic disturbance scenarios remains a challenge in quantifying groundwater resilience and requires further research in the future. Download : Download high-res image (79KB) Download : Download full-size image Fig. 6. Percentage of wells in each class based on and . 4.2. Application of the Dempster-Shafer theory model in groundwater resilience mapping Based on wells with a groundwater performance indicator value ≥ 0.094 and a resilience indicator value ≥ 2, the components of the belief function (including , , , and ) for each category of the groundwater resilience conditioning factor calculated using (8), (9), (10), (11), (12), (13) adequately represent the relationship between the groundwater resilience and nine conditioning factors (Table 2). Table 2. The belief functions of each conditioning factor based on and . Conditioning factors Class Belief functions components Lithology Meal sand 0.162 0.383 0.456 0.617 0.065 0.467 0.468 0.533 Empty Cell Fine sand 0.545 0.141 0.314 0.859 0.623 0.081 0.296 0.919 Empty Cell Gravel 0.000 0.241 0.759 0.759 0.000 0.231 0.769 0.769 Empty Cell Sand gravel 0.293 0.235 0.472 0.765 0.313 0.221 0.466 0.779 Geomorphology Beach land 0.575 0.221 0.204 0.779 0.000 0.242 0.758 0.758 Empty Cell Plain 0.297 0.174 0.530 0.826 0.742 0.140 0.118 0.860 Empty Cell Mountains 0.000 0.238 0.762 0.762 0.000 0.239 0.761 0.761 Empty Cell Desert 0.129 0.367 0.504 0.633 0.258 0.379 0.363 0.621 Slope 0–0.313 0.367 0.173 0.459 0.827 0.286 0.184 0.530 0.816 Empty Cell 0.313–0.625 0.269 0.167 0.564 0.833 0.189 0.200 0.611 0.800 Empty Cell 0.625–0.938 0.072 0.237 0.691 0.763 0.084 0.232 0.684 0.768 Empty Cell 0.938–1.355 0.093 0.223 0.685 0.777 0.325 0.169 0.506 0.831 Empty Cell ＞1.355 0.199 0.199 0.601 0.801 0.116 0.215 0.669 0.785 Soil type Desert soils 0.000 0.203 0.797 0.797 0.000 0.199 0.801 0.801 Empty Cell Amorphic soils 0.072 0.336 0.592 0.664 0.074 0.336 0.590 0.664 Empty Cell Semi-Aquatic soils 0.266 0.172 0.562 0.828 0.249 0.176 0.575 0.824 Empty Cell Alkali-saline soils 0.000 0.188 0.812 0.812 0.000 0.188 0.812 0.812 Empty Cell Anthrosols 0.662 0.101 0.237 0.899 0.677 0.101 0.222 0.899 Distance to river ＜2.18 0.191 0.203 0.605 0.797 0.058 0.232 0.710 0.768 (km) 2.18–5.89 0.547 0.107 0.346 0.893 0.476 0.128 0.396 0.872 Empty Cell 5.89–12.87 0.000 0.252 0.748 0.748 0.101 0.227 0.672 0.773 Empty Cell 12.87–24.20 0.000 0.251 0.749 0.749 0.154 0.213 0.633 0.787 Empty Cell ＞24.20 0.262 0.187 0.551 0.813 0.211 0.199 0.589 0.801 Canal density 0 0.027 0.334 0.639 0.666 0.017 0.330 0.653 0.670 (km/km2) 0–0.103 0.606 0.108 0.286 0.892 0.163 0.163 0.674 0.837 Empty Cell 0.103–0.315 0.149 0.191 0.660 0.809 0.113 0.166 0.721 0.834 Empty Cell 0.315–0.709 0.218 0.178 0.604 0.822 0.176 0.161 0.663 0.839 Empty Cell ＞0.709 0.000 0.189 0.811 0.811 0.530 0.181 0.289 0.819 Hydraulic conductivity 2 0.054 0.298 0.648 0.702 0.035 0.321 0.645 0.679 (m/d) 10 0.147 0.193 0.660 0.807 0.190 0.173 0.637 0.827 Empty Cell 20 0.505 0.127 0.367 0.873 0.586 0.120 0.294 0.880 Empty Cell 80 0.294 0.183 0.523 0.817 0.189 0.189 0.621 0.811 Empty Cell ＞80 0.000 0.198 0.802 0.802 0.000 0.197 0.803 0.803 Groundwater depth ＜1 0.000 0.157 0.843 0.843 0.000 0.147 0.853 0.853 (m) 1–3 0.183 0.154 0.663 0.846 0.248 0.134 0.619 0.866 Empty Cell 3–6 0.118 0.256 0.626 0.744 0.053 0.335 0.612 0.665 Empty Cell 6–10 0.234 0.147 0.619 0.853 0.211 0.132 0.657 0.868 Empty Cell 10–20 0.465 0.128 0.407 0.872 0.489 0.104 0.408 0.896 Empty Cell ＞20 0.000 0.158 0.842 0.842 0.000 0.148 0.852 0.852 Land use Woodland 0.242 0.150 0.608 0.850 0.470 0.139 0.391 0.861 Empty Cell Grassland 0.016 0.205 0.779 0.795 0.016 0.210 0.775 0.790 Empty Cell Water body 0.000 0.168 0.832 0.832 0.000 0.168 0.832 0.832 Empty Cell Residential area 0.673 0.123 0.204 0.877 0.435 0.139 0.426 0.861 Empty Cell Unused land 0.008 0.232 0.760 0.768 0.010 0.228 0.762 0.772 Empty Cell Farmland 0.060 0.123 0.817 0.877 0.070 0.116 0.814 0.884 The value directly reflects the groundwater resilience, with relatively high values implying a high groundwater resilience. values of 0 in a category indicate that no groundwater wells of the category are present. Lithology is a critical factor controlling groundwater occurrence (Rahmati and Melesse, 2016), and different lithological units affect the groundwater storage capacity. The results of the belief calculations show that the value of fine sand and sand gravel in the study area is higher than that of other lithological units, indicating a positive correlation between this category and groundwater resilience. In terms of geomorphology, the highest values are found on the plain, with showing low and high values and showing high and low values. is relatively high at the lower slope and closer to the river (2.18–5.89 km). Previous studies have illustrated that areas with flatter slopes have slower surface runoff, comparatively higher infiltration and higher groundwater potential (Nampak et al., 2014, Mogaji et al., 2015, Rahmati and Melesse, 2016). For soil types, the highest values occur in anthrosols and semi-aquatic soils, indicating the highest groundwater resilience, while the relationship between desert soils, amorphic soils and alkali-saline soils and groundwater resilience is weak. For canal density, the results for and are the reverse, with the former showing high groundwater resilience in low density zones (0–0.103 km/km2) and the latter showing an overall increasing trend in Bel as the canal density increases, with the highest at canal densities > 0.709 km/km2. According to the findings of Nampak et al. (2014), Rahmati and Melesse (2016), and Shi et al. (2021), a positive correlation exists between dense river/drainage systems and groundwater occurrence; therefore, we believe that estimating the belief function for each category of canal density based on is more reliable. The hydraulic conductivity is defined as the rate of water flow per unit cross-sectional area of an aquifer (Mogaji, 2017). Reducing hydraulic conductivity is important for improving resilience (Alraggad et al., 2017). The highest value in the study area is at k = 20 m/d; when k < 20 m/d, groundwater resilience tends to increase with increasing k values, and the value is 0 when k > 80 m/d due to the absence of groundwater well distribution in the area. Regarding the groundwater depth, the of shows an overall increasing trend with increasing groundwater depth, and the Bel of is highest at 10–20 m, illustrating the high probability of groundwater resilience occurring. In the case of land use, the calculation indicates that the Bel of residential areas is significantly higher than that of other land use types, probably because groundwater wells are mostly located in residential areas. shows that the Bel value of woodlands is the highest, followed by residential areas, indicating that the groundwater resilience is highest in woodlands. The reason for this is that the presence of woodlands decreases groundwater runoff and soil evaporation, while the presence of impermeable layers in residential areas is not conducive to groundwater recharge. The combined belief function components ( , , , and ) are integrated, and the integration results of the nine evidential layers are presented in Fig. 7, Fig. 8. The spatial distribution of values explain the combination of groundwater resilience with nine conditioning factor evidential layers (Fig. 7a, Fig. 8a). Mogaji et al. (2015) concluded that a correlation exists between areas with a high degree of , a low degree of , a high degree of , and a low degree of . In contrast to the spatial distribution of values, values are always low in areas with high , and the belief that areas with low values indicate a high groundwater resilience is reliable. Areas with high values are also characterized by relatively high and values. The belief function maps of the two indicators (Fig. 7a, Fig. 8a) reveal that the areas with the highest groundwater resilience in the study area are located mainly in the river channel and the oasis irrigation area in the southern part of the study area where the canal system is denser, the terrain is flatter and the lithological units are mostly fine sand and gravelly sand; meanwhile, the areas with relatively low groundwater resilience are concentrated around the oasis irrigation area and in the middle area from the river channel to the desert. The values in the study area range from < 10% (Fig. 7c) to < 11.8% (Fig. 8c). The value in the -based Dempster-Shafer theory model fusion is generally higher than , with Fig. 7c demonstrating that the areas of low values are mostly located in the oasis irrigation area. Fig. 8c illustrates that the areas with the highest values are mainly situated in mountains, with higher values outside the oasis irrigation area and around the downstream river due to insufficient observation well data in these areas available for validation. Download : Download high-res image (750KB) Download : Download full-size image Fig. 7. Results of Dempster-Shafer theory model integration based on the groundwater performance indicator ( ); (a) belief, (b) disbelief, (c) uncertainty, and (d) plausibility. Download : Download high-res image (706KB) Download : Download full-size image Fig. 8. Results of Dempster-Shafer theory model integration based on the groundwater resilience indicator ( ); (a) belief, (b) disbelief, (c) uncertainty, and (d) plausibility. 4.3. Validation of the groundwater resilience map The belief maps (Figs. 7a, 8a) are overlaid with the locations of 27 wells in GIS, and the predicted values for each point are obtained. (0–0.25) and (1.25–4.18) for the 27 wells are then classified as very low, low, moderate, moderate high and high and compared with the predicted values for that point. The Dempster-Shafer theory model results for and using nine groundwater conditioning factor evidential layers are 40.7% and 59.3% accurate, respectively, and the model is subsequently rerun by removing nonsignificant factors from the model. For this purpose, we consider excluding lithology (Fig. 3a) or hydraulic conductivity (Fig. 3g) from evidential layers because they are relatively coarse and unvalidated data with low reliability. The results from the final model after removing those factors from the evidential layer (Table 3) show that the values are consistent with the predicted values for 14 wells, with a prediction accuracy of 51.9%, and the values are consistent with those predicted for 18 wells, with a prediction accuracy of 66.7%. The selection of the groundwater conditioning factor (the evidential layer transformed in the Dempster-Shafer theory model) has a significant impact on the performance of the Dempster-Shafer theory model, a conclusion that is consistent with previous studies (Nampak et al., 2014, Mogaji et al., 2015). The prediction accuracy of the -based Dempster-Shafer model increases by 7.4% after removing the lithology factor and by 11.2% after the removal of lithology and hydraulic conductivity factors. In general, the Dempster-Shafer theory model constructed using as an indicator for evaluating groundwater resilience is superior to that using . Table 3. Validation results of groundwater resilience maps based on and . ID Expected description from the prediction map Actual description Remarks Expected description from the prediction map Actual description Remarks 1 0.050 High Moderate high Not coinciding 3.52 High Moderate Not coinciding 2 0.024 High Moderate Not coinciding 3.43 High High Coinciding 3 0.000 High Very low Not coinciding 4.18 High High Coinciding 4 0.068 High Moderate high Not coinciding 1.5 High High Coinciding 5 0.079 Moderate high Moderate high Coinciding 3.07 Moderate high High Not coinciding 6 0.211 High High Coinciding 2.73 High High Coinciding 7 0.000 Moderate high Very low Not coinciding 3 High High Coinciding 8 0.100 High High Coinciding 3.71 High High Coinciding 9 0.074 Moderate high Moderate high Coinciding 2.88 Moderate Moderate Coinciding 10 0.172 Median High Not coinciding 2.95 Moderate high Moderate high Coinciding 11 0.048 Moderate high Moderate high Coinciding 3.69 High High Coinciding 12 0.057 High Moderate high Not coinciding 1.38 High High Coinciding 13 0.043 High Moderate high Not coinciding 1.67 Moderate high Moderate high Coinciding 14 0.036 Moderate high Moderate high Coinciding 2.57 Moderate high Moderate high Coinciding 15 0.160 High High Coinciding 3.54 Moderate High Not coinciding 16 0.158 Median High Not coinciding 1.92 Moderate High Not coinciding 17 0.138 High High Coinciding 1.94 High High Coinciding 18 0.222 High High Coinciding 3.75 Moderate Moderate Coinciding 19 0.075 Moderate high Moderate high Coinciding 3.42 Moderate high Moderate Not coinciding 20 0.000 High Very low Not coinciding 2.83 High High Coinciding 21 0.018 Very low Low Not coinciding 1.25 Low High Not coinciding 22 0.250 Moderate high High Not coinciding 1.38 Moderate High Not coinciding 23 0.173 Median High Not coinciding 3.35 Moderate High Not coinciding 24 0.000 Very low Very low Coinciding 2.85 Moderate High Not coinciding 25 0.101 High High Coinciding 3.65 High High Coinciding 26 0.184 High High Coinciding 2.71 High High Coinciding 27 0.111 High High Coinciding 3.39 High High Coinciding 4.4. Creation of groundwater resilience map The groundwater resilience zonation map (Fig. 9) of the final output of the values show different levels of groundwater resilience within the study area, representing the degree to which the evidential layers support groundwater resilience, and is considered the most likely map for predicting groundwater resilience (Mogaji et al., 2015). The percentage of each category in the study area is shown in Fig. 10. Fig. 9a shows the spatial relationship between seven evidential layers (excluding lithology and hydraulic conductivity) and . The values are classified as very low (0–0.168), low (0.168–0.260), moderate (0.260–0.405), moderate high (0.405–0.632), and high (>0.632), accounting for 25%, 15%, 21%, 22% and 17% of the total area, respectively. Fig. 9b explains the spatial relationship between eight evidential layers (with lithology removed) and , with Bel values divided into five categories: very low (Bel value of 0–0.072, 3% of the total area), low (0.072–0.171, 30%), medium (0.171–0.458, 30%), high (0.458–0.786, 22%), and high (>0.786, 15%). Prediction maps based on the two resilience indicators show that the regions with moderate high and high resilience have a good coherence and are mostly distributed in the upstream oasis irrigation area and around the downstream river channel, but differences exist in the prediction results. The -based prediction map (Fig. 9a) indicates high resilience in the southern mountains of the study area and overall low resilience around the downstream channel, with large continuous zones of very low resilience. In contrast, the prediction map based on (Fig. 9b) displays a discontinuous strip of resilience around the downstream channel that transitions from higher areas to moderate, then alternating from very low to low, due to the different classification of the two indicators and the difference in the resilience categories corresponding to the observation wells (see 4.1., Fig. 5). Download : Download high-res image (432KB) Download : Download full-size image Fig. 9. Groundwater resilience potential zone map of the study area based on the Dempster-Shafer theory model; (a) based on , (b) based on . Download : Download high-res image (95KB) Download : Download full-size image Fig. 10. Groundwater resilience percentages for five classes (external- , internal- ). 5. Conclusions The purpose of this study is to construct a Dempster-Shafer theory model based on the groundwater performance indicator and the resilience indicator to spatially predict groundwater resilience in the study area and evaluate the validity of these two indicators in predicting groundwater resilience. Nine groundwater conditioning factors are selected and spatial datasets are created as evidential layers in the Dempster-Shafer theory model. The integration results are combined to spatially predict the groundwater resilience in the study area, ultimately outputting groundwater resilience zoning map. As quantitative criteria for groundwater resilience, both and can address long-term changes in the resilience of groundwater systems. Wells with relatively high resilience are mainly located in the upstream oasis irrigation area and near the downstream river, while wells with relatively low resilience are distributed in areas with higher groundwater depths and greater distances from the river. The Dempster-Shafer theory model is constructed based on resilience indicators and evidential layers consisting of groundwater conditioning factors to produce zonal maps of very low, low, moderate, moderate high and high groundwater resilience. The accuracy of the prediction maps produced by the final model is 51.9% ( ) and 66.7% ( ). Validation of the predicted results with yields better results than validation with . According to the spatial relationship between eight groundwater conditioning factors (geomorphology, slope, distance to river, soil type, canal density, hydraulic conductivity, groundwater depth, and land use) and , groundwater resilience is classified as very low (Bel value of 0–0.072), low (0.072–0.171), moderate (0.171–0.458), moderate high (0.458–0.786), and high (>0.786), accounting for 3%, 30%, 30%, 22%, and 15% of the total area of the region, respectively. In conclusion, regional groundwater resilience predictions based on the Dempster-Shafer theory model are reasonably reliable, and the model has the advantage of not only outputting the degree of support for the prediction results from the evidential layers through belief functions but also quantifying the uncertainty to reflect systematic and random errors. In addition, the selection of groundwater conditioning factors has a significant impact on the performance of the Dempster-Shafer theory model, which may produce more accurate and reliable spatial prediction results when the evidential layers are sufficiently detailed. This study may provide a scientific basis for groundwater resource planning and management in the Hotan River Basin, and the findings will assist in understanding groundwater resilience in arid inland river basins. CRediT authorship contribution statement Yuehui Wang: Writing – original draft, Writing – review & editing, Conceptualization, Methodology, Software. Fengzhi Shi: Supervision, Conceptualization, Methodology, Writing – review & editing, Data curation, Funding acquisition. Chengyi Zhao: Writing – review & editing, Data curation, Validation. Xu Zhou: Writing – review & editing, Data curation, Validation. All authors have read and agreed to the published version of the manuscript. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgements This research is supported by the West Light Foundation of Chinese Academy of Sciences (2021-XBQNXZ-007) and NSFC Project (U1903116, 42171041). Appendix A. Supplementary material Download : Download zip file (8KB) Supplementary material . Data Availability The data that has been used is confidential. References Ait El Mekki and Laftouhi, 2016 O. Ait El Mekki, N.E. Laftouhi Combination of a geographical information system and remote sensing data to map groundwater recharge potential in arid to semi-arid areas: the Haouz Plain, Morocco Earth Sci. Inform., 9 (4) (2016), pp. 465-479, 10.1007/s12145-016-0268-0 View in ScopusGoogle Scholar Alraggad et al., 2017 M. Alraggad, B. Johnsen-Haris, A. Shdaifat, A. Abugazleh, A. Hamaideh Groundwater resilience to climate change in the eastern Dead Sea basin Jordan Sci. Res. Essays., 12 (3) (2017), pp. 24-41, 10.5897/SRE2016.6459 Google Scholar Behboudian et al., 2021 M. Behboudian, R. Kerachian, P. Pourmoghim Evaluating the long-term resilience of water resources systems: Application of a generalized grade-based combination approach Sci. Total Environ., 786 (2021), Article 147447, 10.1016/j.scitotenv.2021.147447 View PDFView articleView in ScopusGoogle Scholar Chen et al., 2019 Y.N. Chen, B.F. Li, Y.T. Fan, C.J. Sun, G.H. Fang Hydrological and water cycle processes of inland river basins in the arid region of Northwest China J. Arid Land., 11 (2) (2019), pp. 161-179, 10.1007/s40333-019-0050-5 View in ScopusGoogle Scholar Chinnasamy et al., 2018 P. Chinnasamy, B. Maheshwari, S.A. Prathapar Adaptation of Standardised Precipitation Index for understanding watertable fluctuations and groundwater resilience in hard-rock areas of India Environ. Earth Sci., 77 (15) (2018), pp. 1-16, 10.1007/s12665-018-7734-6 Google Scholar Chowdhury et al., 2009 A. Chowdhury, M.K. Jha, V.M. Chowdary, B.C. Mal Integrated remote sensing and GIS‐based approach for assessing groundwater potential in West Medinipur district, West Bengal, India Int. J. Remote Sens., 30 (1) (2009), pp. 231-250, 10.1080/01431160802270131 View in ScopusGoogle Scholar Dempster, 1967 A.P. Dempster Upper and lower probability inferences based on a sample from a finite univariate population Biometrika, 54 (3–4) (1967), pp. 515-528, 10.1093/biomet/54.3-4.515 View in ScopusGoogle Scholar Elmqvist et al., 2003 T. Elmqvist, C. Folke, M. Nyström, G. Peterson, J. Bengtsson, B. Walker, J. Norberg Response diversity, ecosystem change, and resilience Front. Ecol. Environ., 1 (9) (2003), pp. 488-494, 10.1890/1540-9295(2003)001[0488:RDECAR]2.0.CO;2 View in ScopusGoogle Scholar Ertürk et al., 2017 A. Ertürk, A. Ekdal, M. Gurel, N. Karakaya, G. Cuceloglu, E. Gönenç Model-based assessment of groundwater vulnerability for the Dalyan Region of southwestern Mediterranean Turkey Reg. Environ. Change., 17 (4) (2017), pp. 1193-1203, 10.1007/s10113-017-1106-8 View in ScopusGoogle Scholar Fowler et al., 2003 H.J. Fowler, C.G. Kilsby, P.E. O'Connell Modeling the impacts of climatic change and variability on the reliability, resilience, and vulnerability of a water resource system Water Resour. Res., 39 (8) (2003), 10.1029/2002WR001778 Google Scholar Fu et al., 2018 X.H. Fu, B. Shen, Z.C. Dong, X. Zhang Assessing the impacts of changing climate and human activities on streamflow in the Hotan River, China J. Water Clim. Chang., 11 (1) (2018), pp. 166-177, 10.2166/wcc.2018.281 Google Scholar Fuchs et al., 2018 E.H. Fuchs, K.C. Carroll, J.P. King Quantifying groundwater resilience through conjunctive use for irrigated agriculture in a constrained aquifer system J. Hydrol., 565 (2018), pp. 747-759, 10.1016/j.jhydrol.2018.08.003 View PDFView articleView in ScopusGoogle Scholar Garg and Wani, 2013 K.K. Garg, S.P. Wani Opportunities to build groundwater resilience in the semi-arid tropics Groundwater, 51 (5) (2013), pp. 679-691, 10.1111/gwat.1007 View in ScopusGoogle Scholar Gönnert and Gerkensmeier, 2015 G. Gönnert, B. Gerkensmeier A multi-method approach to develop extreme storm surge events to strengthen the resilience of highly vulnerable coastal areas Coast Eng. J., 57 (1) (2015), Article 1540002, 10.1142/S0578563415400021 View in ScopusGoogle Scholar Grönwall and Oduro-Kwarteng, 2018 J. Grönwall, S. Oduro-Kwarteng Groundwater as a strategic resource for improved resilience: a case study from peri-urban Accra Environ. Earth Sci., 77 (1) (2018), p. 6, 10.1007/s12665-017-7181-9 View in ScopusGoogle Scholar Guo et al., 2016 H.W. Guo, H.B. Ling, H.L. Xu, B. Guo Study of suitable oasis scales based on water resource availability in an arid region of China: a case study of Hotan River Basin Environ. Earth Sci., 75 (11) (2016), p. 984, 10.1007/s12665-016-5772-5 View in ScopusGoogle Scholar Hashimoto et al., 1982 T. Hashimoto, J.R. Stedinger, D.P. Loucks Reliability, resiliency, and vulnerability criteria for water resource system performance evaluation Water Resour. Res., 18 (1) (1982), pp. 14-20, 10.1029/WR018i001p00014 View in ScopusGoogle Scholar Herrera-Franco et al., 2020 G. Herrera-Franco, P. Carrión-Mero, M. Aguilar-Aguilar, F. Morante-Carballo, M. Jaya-Montalvo, M.C. Morillo-Balsera Groundwater resilience assessment in a communal coastal aquifer system. the case of manglaralto in Santa Elena, ecuador Sustainability, 12 (19) (2020), p. 8290, 10.3390/su12198290 View in ScopusGoogle Scholar Holling, 1973 C.S. Holling Resilience and stability of ecological systems Annu. Rev. Ecol. Syst., 4 (1) (1973), pp. 1-23, 10.1146/annurev.es.04.110173.000245 Google Scholar Huang et al., 2022 L.W. Huang, Z.Y. Sun, A.G. Zhou, J. Bi, Y.D. Liu Source and enrichment mechanism of fluoride in groundwater of the Hotan Oasis within the Tarim Basin, Northwestern China Environ. Pollut., 300 (2022), Article 118962, 10.1016/j.envpol.2022.118962 View PDFView articleView in ScopusGoogle Scholar Hugman et al., 2012 R. Hugman, T.Y. Stigter, J.P. Monteiro, L. Nunes Influence of aquifer properties and the spatial and temporal distribution of recharge and abstraction on sustainable yields in semi-arid regions Hydrol. Process., 26 (18) (2012), pp. 2791-2801, 10.1002/hyp.8353 View in ScopusGoogle Scholar Kaliraj et al., 2014 S. Kaliraj, N. Chandrasekar, N.S. Magesh Identification of potential groundwater recharge zones in Vaigai upper basin, Tamil Nadu, using GIS-based analytical hierarchical process (AHP) technique Arab. J. Geosci., 7 (4) (2014), pp. 1385-1401, 10.1007/s12517-013-0849-x View in ScopusGoogle Scholar Katic and Grafton, 2011 P. Katic, R.Q. Grafton Optimal groundwater extraction under uncertainty: resilience versus economic payoffs J. Hydrol., 406 (3–4) (2011), pp. 215-224, 10.1016/j.jhydrol.2011.06.016 View PDFView articleView in ScopusGoogle Scholar Kumar et al., 2020 N. Kumar, J. Sinha, C.A. Madramootoo, M.K. Goyal Quantifying groundwater sensitivity and resilience over peninsular India Hydrol. Process., 34 (26) (2020), pp. 5327-5339, 10.1002/hyp.13945 View in ScopusGoogle Scholar Kumar et al., 2019 P. Kumar, P.K. Thakur, S.K. Debnath Groundwater Vulnerability Assessment and Mapping Using DRASTIC Model (first ed.), CRC Press (2019), 10.1201/9780429287862 Google Scholar Li et al., 2018 B.F. Li, Y.N. Chen, J.W. Chipman, X. Shi, Z.S. Chen Why does the runoff in Hotan River show a slight decreased trend in northwestern China Atmos. Sci. Lett., 19 (1) (2018), Article e800, 10.1002/asl.800 View in ScopusGoogle Scholar Liu et al., 2021 C.C. Liu, Y.F. Chai, B.Y. Zhu, Y.P. Yang, J.Y. Deng, Y. Hu River regulation and resilience: an approach for the Yangtze watershed Water Supply, 21 (4) (2021), pp. 1817-1833, 10.2166/ws.2021.035 View in ScopusGoogle Scholar Lu et al., 2019 H.W. Lu, Y. Kang, L. Liu, J. Li Comprehensive groundwater safety assessment under potential shale gas contamination based on integrated analysis of reliability-resilience-vulnerability and gas migration index J. Hydrol., 578 (2019), Article 124072, 10.1016/j.jhydrol.2019.124072 View PDFView articleView in ScopusGoogle Scholar Mogaji, 2017 K.A. Mogaji Development of AHPDST vulnerability indexing model for groundwater vulnerability assessment using hydrogeophysical derived parameters and GIS application Pure Appl. Geophys., 174 (4) (2017), pp. 1787-1813, 10.1007/s00024-017-1499-9 View in ScopusGoogle Scholar Mogaji et al., 2015 K.A. Mogaji, H.S. Lim, K. Abdullah Regional prediction of groundwater potential mapping in a multifaceted geology terrain using GIS-based Dempster-Shafer model Arab. J. Geosci., 8 (5) (2015), pp. 3235-3258, 10.1007/s12517-014-1391-1 View in ScopusGoogle Scholar Mondal and Wasimi Saleh, 2007 M.S. Mondal, A. Wasimi Saleh Evaluation of Risk-Related Performance in Water Management for the Ganges Delta of Bangladesh J. Water Resour. Plan. Manag. ASCE, 133 (2) (2007), pp. 179-187, 10.1061/(ASCE)0733-9496(2007)133:2(179) View in ScopusGoogle Scholar Moy et al., 1986 W.S. Moy, J.L. Cohon, C.S. ReVelle A programming model for analysis of the reliability, resilience, and vulnerability of a water supply reservoir Water Resour. Res., 22 (4) (1986), pp. 489-498, 10.1029/WR022i004p00489 Google Scholar Naghibi et al., 2015 S.A. Naghibi, H.R. Pourghasemi, B. Dixon GIS-based groundwater potential mapping using boosted regression tree, classification and regression tree, and random forest machine learning models in Iran Environ. Monit. Assess., 188 (1) (2015), p. 44, 10.1007/s10661-015-5049-6 Google Scholar Nair and Indu, 2021 A.S. Nair, J. Indu Assessment of Groundwater Sustainability and Identifying Factors Inducing Groundwater Depletion in India Geophys. Res. Lett., 48 (3) (2021), 10.1029/2020GL087255 Google Scholar Nampak et al., 2014 H. Nampak, B. Pradhan, M.A. Manap Application of GIS based data driven evidential belief function model to predict groundwater potential zonation J. Hydrol., 513 (2014), pp. 283-300, 10.1016/j.jhydrol.2014.02.053 View PDFView articleView in ScopusGoogle Scholar Oikonomidis et al., 2015 D. Oikonomidis, S. Dimogianni, N. Kazakis, K. Voudouris A GIS/Remote Sensing-based methodology for groundwater potentiality assessment in Tirnavos area, Greece J. Hydrol., 525 (2015), pp. 197-208, 10.1016/j.jhydrol.2015.03.056 View PDFView articleView in ScopusGoogle Scholar Ozano et al., 2022 K. Ozano, A. Roby, A. MacDonald, K. Upton, N. Hepworth, C. Gorman, A. Nicol Groundwater: making the invisible visible: FCDO briefing pack on water governance Financ. Clim. Change Inst. Dev. Stud. (2022), p. 36 https://doi.org/10.19088K4D.2022.027 Google Scholar Park, 2011 N.W. Park Application of Dempster-Shafer theory of evidence to GIS-based landslide susceptibility analysis Environ. Earth Sci., 62 (2) (2011), pp. 367-376, 10.1007/s12665-010-0531-5 View in ScopusGoogle Scholar Peters et al., 2005 E. Peters, H.A.J. van Lanen, P.J.J.F. Torfs, G. Bier Drought in groundwater-drought distribution and performance indicators J. Hydrol., 306 (1–4) (2005), pp. 302-317, 10.1016/j.jhydrol.2004.09.014 View PDFView articleView in ScopusGoogle Scholar Pourmoghim et al., 2022 P. Pourmoghim, M. Behboudian, R. Kerachian An uncertainty-based framework for evaluating and improving the long-term resilience of lakes under anthropogenic droughts J. Environ. Manag., 301 (2022), Article 113900, 10.1016/j.jenvman.2021.113900 View PDFView articleView in ScopusGoogle Scholar Qi et al., 2016 M. Qi, M.L. Feng, T. Sun, W. Yang Resilience changes in watershed systems: a new perspective to quantify long-term hydrological shifts under perturbations J. Hydrol., 539 (2016), pp. 281-289, 10.1016/j.jhydrol.2016.05.039 View PDFView articleView in ScopusGoogle Scholar Rahmati and Melesse, 2016 O. Rahmati, A.M. Melesse Application of Dempster-Shafer theory, spatial analysis and remote sensing for groundwater potentiality and nitrate pollution analysis in the semi-arid region of Khuzestan, Iran Sci. Total Environ., 568 (2016), pp. 1110-1123, 10.1016/j.scitotenv.2016.06.176 View PDFView articleView in ScopusGoogle Scholar Rahmati et al., 2015 O. Rahmati, S.A. Nazari, M. Mahdavi, P.H. Reza, H. Zeinivand Groundwater potential mapping at Kurdistan region of Iran using analytic hierarchy process and GIS Arab. J. Geosci., 8 (2015), pp. 7059-7071, 10.1007/s12517-014-1668-4 View in ScopusGoogle Scholar Razandi et al., 2015 Y. Razandi, H.R. Pourghasemi, N.S. Neisani, O. Rahmati Application of analytical hierarchy process, frequency ratio, and certainty factor models for groundwater potential mapping using GIS Earth Sci. Inf., 8 (2015) (2015), pp. 867-883, 10.1007/s12145-015-0220-8 View in ScopusGoogle Scholar Rodak et al., 2014 C. Rodak, S.E. Silliman, D. Bolster Time-dependent health risk from contaminated groundwater including use of reliability, resilience, and vulnerability as measures J. Am. Water Resour. Assoc., 50 (1) (2014), pp. 14-28, 10.1111/jawr.12103 View in ScopusGoogle Scholar Shafer, 1976 G. Shafer A Mathematical Theory of Evidence Princeton University Press, Princeton (1976) Google Scholar Shamsudduha, 2013 M. Shamsudduha Groundwater resilience to human development and climate change in South Asia GWF Discuss. Pap. (2013), p. 1332 Google Scholar Shi et al., 2021 F.Z. Shi, C.Y. Zhao, X.N. Zhao, X. Zhou, X.H. Li, J.T. Zhu Spatial variability of the groundwater exploitation potential in an arid alluvial-diluvial plain using GIS-based Dempster-Shafer theory Quat. Int., 571 (2021), pp. 127-135, 10.1016/j.quaint.2020.10.055 View PDFView articleView in ScopusGoogle Scholar Shin et al., 2018 S. Shin, S. Lee, D.R. Judi, M. Parvania, E. Goharian, T. McPherson, S.J. Burian A Systematic Review of Quantitative Resilience Measures for Water Infrastructure Systems Water, 10 (2) (2018), p. 164, 10.3390/w10020164 View in ScopusGoogle Scholar Singh et al., 2011 C.K. Singh, S. Shashtri, A. Singh, S. Mukherjee Quantitative modeling of groundwater in Satluj River basin of Rupnagar district of Punjab using remote sensing and geographic information system Environ. Earth Sci., 62 (4) (2011), pp. 871-881, 10.1007/s12665-010-0574-7 View in ScopusGoogle Scholar Thomas and Waring, 2015 Z. Thomas, K.M. Waring Enhancing resiliency and restoring ecological attributes in second-growth ponderosa pine stands in northern New Mexico, USA For. Sci., 61 (1) (2015), pp. 93-104 CrossRefView in ScopusGoogle Scholar Wang et al., 2013 M.X. Wang, B. Li, F. Wang The Report of Groundwater Resource Assessment in Hotan, Xinjiang Shihezi Branch of Xinjiang Hydropower Planning and Design Institute, Shihezi (2013), pp. 82-93 View in ScopusGoogle Scholar Wang et al., 2021 X.L. Wang, Y. Luo, L. Sun, M. Shafeeque Different climate factors contributing for runoff increases in the high glacierized tributaries of Tarim River Basin, China J. Hydrol. Reg. Stud., 36 (2021), Article 100845, 10.1016/j.ejrh.2021.100845 View PDFView articleView in ScopusGoogle Scholar Yang et al., 2019 G. Yang, F.D. Li, D. Chen, X.L. He, L.Q. Xue, A.H. Long Assessment of changes in oasis scale and water management in the arid Manas River Basin, north western China Sci. Total Environ., 691 (2019), pp. 506-515, 10.1016/j.scitotenv.2019.07.143 View PDFView articleView in ScopusGoogle Scholar Zhang et al., 2012 Y.L. Zhang, J.H. Ma, X.L. Chang, J. Van Wonderen, L.L. Yan, J.H. Han Water resources assessment in the Minqin Basin: an arid inland river basin under intensive irrigation in northwest China Environ. Earth Sci., 65 (6) (2012), pp. 1831-1839, 10.1007/s12665-011-1165-y View in ScopusGoogle Scholar Cited by (2) Assessing the evolution and attribution of watershed resilience in arid inland river basins, Northwest China 2024, Science of the Total Environment Show abstract An overview of the methods for evaluating the resilience of groundwater systems 2023, MethodsX Show abstract © 2022 The Authors. Published by Elsevier B.V. Recommended articles Challenges to estimate surface- and groundwater flow in arid regions: The Dead Sea catchment Science of The Total Environment, Volumes 485–486, 2014, pp. 828-841 Christian Siebert, …, Stefan Geyer View PDF Characterization of groundwater types and residence times in the Verlorenvlei catchment, South Africa to constrain recharge dynamics and hydrological resilience Journal of Hydrology, Volume 613, Part A, 2022, Article 128280 J.A. Miller, …, L. Palcsu View PDF Shallow Quaternary groundwater in the Lake Chad basin is resilient to climate change but requires sustainable management strategy: Results of isotopic investigation Science of The Total Environment, Volume 851, Part 2, 2022, Article 158152 A. Mahamat Nour, …, Y. Vystavna View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 2 Captures Readers: 10 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply."

Paper 5:
- APA Citation: Kaur, G., Rajni & Sivia, J.S. (2024). Integrating Data Envelopment Analysis and Machine Learning Approaches for Energy Optimization, Decreased Carbon Footprints, and Wheat Yield Prediction Across North-Western India. Journal of Soil Science and Plant Nutrition, 24, 1424–1447.
  Main Objective: To investigate the integration of Data Envelopment Analysis (DEA) and machine learning approaches to optimize energy use, reduce carbon footprints, and predict wheat yield across north-western India.
  Study Location: North-West India
  Data Sources: Data from 120 intensive wheat production systems in north-western India
  Technologies Used: Data Envelopment Analysis (DEA), machine learning, decision tree regression (DT), random forest regression (RF), support vector regression (SVR)
  Key Findings: - DEA-based energy optimization has significant potential for energy saving, with the potential to reduce technical inefficiency in 65% of the farms studied.
- Machine learning models, specifically decision tree regression (DT), random forest regression (RF), and support vector regression (SVR), outperformed in yield prediction with the lowest root mean square error and normalized mean square error but obtained the highest Nash-Sutcliffe efficiency and index of agreement.
  Extract 1: None
  Extract 2: None
  Limitations: None
  Relevance Evaluation: The study is highly relevant to the outline point as it specifically addresses the use of AI techniques for anomaly detection and predictive maintenance in automated irrigation systems. The paper demonstrates the effectiveness of using machine learning models to identify anomalies and predict irrigation needs, which is a key aspect of achieving resilience and fault tolerance in automated irrigation systems.
  Relevance Score: 1.0
  Inline Citation: Kaur, Rajni & Sivia (2024)
  Explanation: The study was conducted to investigate the integration of Data Envelopment Analysis (DEA) and machine learning approaches to optimize energy use, reduce carbon footprints, and predict wheat yield across north-western India. A total of 120 intensive wheat production systems were analyzed, and the results indicated that there is a high total input energy of 24.7 GJ ha-1, approximately 46.5% direct and 53.5% indirect energy sources. The study found that DEA-based energy optimization has significant potential for energy saving, with the potential to reduce technical inefficiency in 65% of the farms studied. Additionally, machine learning models, specifically decision tree regression (DT), random forest regression (RF), and support vector regression (SVR), outperformed in yield prediction with the lowest root mean square error and normalized mean square error but obtained the highest Nash-Sutcliffe efficiency and index of agreement. Hence, the study suggests that the integration of DEA and machine learning approaches can effectively optimize energy use, reduce carbon footprints, and predict wheat yield, contributing to sustainable and resilient wheat production systems.

 Full Text: >
"Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement Log in Find a journal Publish with us Track your research Search Cart Home Journal of Soil Science and Plant Nutrition Article Integrating Data Envelopment Analysis and Machine Learning Approaches for Energy Optimization, Decreased Carbon Footprints, and Wheat Yield Prediction Across North-Western India Original Paper Published: 02 February 2024 Volume 24, pages 1424–1447, (2024) Cite this article Journal of Soil Science and Plant Nutrition Aims and scope Submit manuscript Gagandeep Kaur , Rajni & Jagtar Singh Sivia  76 Accesses 2 Citations Explore all metrics Abstract An accurate, timely and large-scale yield prediction is considered critically important to frame policies to mitigate climate change risks and for ensured food security. Wheat (Triticum aestivum L.), being a major cereal grain crop of north-western India, has been highly energy intensive with large emissions of greenhouse gases, affecting ecosystems’ sustainability. We therefore, performed energy optimization in wheat for enhanced ecosystems’ resilience and carbon (C) sustainability, while predicting yields of 120 intensive wheat production systems across north-western India. An integrated approach of data envelopment analysis (DEA) and machine learning (ML) models was applied for energy optimization and accurate yield prediction. After optimization of energy input in wheat production, 8 different ML models of variable complexity viz. linear regression (LR), ridge regression (RR), lasso regression (LAR), elastic net regression (ENR), decision tree regression (DT), random forest regression (RF), gradient boosting regression (GB) and support vector regression (SVR) were applied and evaluated statistically for accurate prediction of wheat yields of studied decision making units (DMUs). These results revealed that wheat ecosystems have a high total input energy (EI) of 24.7 GJ ha−1, which comprises ~46.5% share of direct and 53.5% of indirect energy sources. The non-renewable energy input was ~3.9 times higher than the renewable energy. The total C equivalent emissions of 1815.7 kg CO2e ha−1 comprised the highest share of chemical fertilizers (~49.8%), and exhibited a linear significant relationship with EI (R2 = 0.8117**; p < 0.01). Nitrogenous fertilizers application contributes ~90.1% towards total fertilizer related energy input in wheat production. The net global warming potential of 2.30 Mg CO2e ha−1 yr−1 was estimated which resulted in yield scaled emissions (i.e., greenhouse gases intensity) of 0.34 kg CO2e kg−1 wheat grain yield. The DEA-based benchmarking showed that the technical efficiency (TE) score of 79 DMUs was < 1.00, elucidated ~65% DMUs as energy inefficient. The average (n = 120) TE score of 0.92 illustrates energy saving possibility of 2464.6 MJ ha−1 (~8% of EI), mostly via efficient fertilizer (54.4%) and irrigation water management (11.6%). The 1:1 (x = y) correspondence analysis implies that DT, GB, and RF models can accurately predict wheat productivity with significantly higher R2 values of 0.998** (p < 0.01), 0.950** (p < 0.01), and 0.832* (p < 0.05), respectively. These results underpin overwhelming significance of DEA-based energy optimization for wheat ecosystems, which helps reduce the energy and C footprints for sustainable and cleaner production. Nonetheless, DT, GB, and RF models outperformed in yield prediction with the lowest root mean square error and normalized mean square error, but the highest Nash–Sutcliffe efficiency and index of agreement. Therefore, DEA-based benchmarking has significant energy saving potential, while DT, GB, and RF models have highly accurate wheat yield prediction abilities for north-western India. This is a preview of subscription content, log in via an institution to check access.  Similar content being viewed by others Optimization of energy consumption and its effect on the energy use efficiency and greenhouse gas emissions of wheat production in Turkey Article Open access 02 June 2021 Comparison of energy consumption of wheat production in conservation and conventional agriculture using DEA Article 18 October 2018 An ensemble approach for assessment of energy efficiency of agriculture system in Pakistan| Article 11 February 2020 References Acaroglu M, Aksoy AS (2005) The cultivation and energy balance of Miscanthus giganteus production in Turkey. Biomass Bioenergy 29:42–48. https://doi.org/10.1016/j.biombioe.2005.01.002 Article   Google Scholar   Agarwal A, Tarar S (2021) A hybrid approach for crop yield prediction using machine learning and deep learning algorithms. J Phys Conf Series 1714:012012. https://doi.org/10.1088/1742-6596/1714/1/012012 Article   Google Scholar   Allesina G, Pedrazzi S, Sgarbi F, Pompeo E, Roberti C, Cristiano V, Tartarini P (2015) Approaching sustainable development through energy management, the case of Fongo Tongo, Cameroon. Intl J Energy Environ Engg 6:121–127. https://doi.org/10.1007/s40095-014-0156-7 Article   Google Scholar   Alpaydin E (2010) Introduction to machine learning, 2nd edn https://kkpatel7.files.wordpress.com/2015/04/alppaydin_machinelearning_2010.pdf (Assessed on 24-03-2023 at 3.52 m) Google Scholar   Alvarez R (2009) Predicting average regional yield and production of wheat in the Argentine Pampas by an artificial neural network approach. Eur J Agron 30:70–77. https://doi.org/10.1009/j.euragr.2009.10.030 Article   Google Scholar   Anakha V, Aparna S, Mani J, Mathew R, Williams V (2021) Crop yield prediction using machine learning algorithms. Intl J Engg Res Techn IJERTCONV9IS13019. https://doi.org/10.17577/IJERTCONV9IS13019 (Assessed on 24-03-2023 at 3.52 m) ASABE Standard D497.5 (2006) Agricultural machinery management data. St Joseph, Mich Google Scholar   Balezentiene L, Streimikiene D, Balezentis T (2013) Fuzzy decision support methodology for sustainable energy crop selection. Renew Sust Enenrgy 17:83–93. https://doi.org/10.1016/j.rser.2012.09.016 Article   Google Scholar   Banker R, Charnes A, Cooper W (1984) Some models for estimating technical and scale inefficiencies in data envelopment analysis. Management Sci 30:1078–1092 Article   Google Scholar   Binning AS, Pathak BS, Panesar V (1983) The energy audit of crop production system research report. School of Energy Studies for Agriculture, Punjab Agricultural University, Ludhiana, Punjab, India, Ludhiana, Punjab (India) Google Scholar   Breiman L (2001) Random forests. Machine Learning 45:5–32. https://doi.org/10.1023/A:1010933404324 Article   Google Scholar   Bruce P, Bruce A (2017) Practical Statistics for Data Scientists. O’Reilly Media Google Scholar   Cai Y, Guan K, Lobell D, Potgieter AB, Wang S, Peng J, Xu T, Asseng S, Zhang Y, You L, Peng B (2019) Integrating satellite and climate data to predict wheat yield in Australia using machine learning approaches. Agric Forest Meteor 274:144–159. https://doi.org/10.1016/j.agrformet.2019.03.010 Article   Google Scholar   Cai Y, Guan K, Peng J, Wang S, Seifert C, Wardlow B, Li Z (2018) A high-performance and in-season classification system of field-level crop types using time-series Landsat data and a machine learning approach. Remote Sens Environ 210:35–47. https://doi.org/10.1016/j.rse.2018.02.045 Article   Google Scholar   Canakci M, Topakci M, Akinci I, Ozmerzi A (2005) Energy use pattern of some field crops and vegetable production: case study for Antalya region, Turkey. Energy Converse Manage 46:655–666. https://doi.org/10.1016/j.enconman.2004.04.008 Article   Google Scholar   Cessie S, Le H, Van JC (1992) Ridge estimators in logistic regression. Appl Stat 41:191–194 https://www.jstor.org/stable/10.2307/2347628?origin=crossref Article   Google Scholar   CGWB (2013) Ground water information booklet Bathinda district, Punjab. Ministry of Water Resources Government of India North Western Region Chandigarh http://cgwb.gov.in/District_Profile/Punjab/Bathinda.pdf (Assessed on 10-03-2022 at 11.57 a.m.) Google Scholar   Charnes A, Cooper WW, Rhodes E (1978) Measuring the efficiency of decision making units. Eur J Operational Res 2:429–444 Article   Google Scholar   Charoen-Ung P, Mittrapiyanuruk P (2019) Sugarcane yield grade prediction using random forest with forward feature selection and hyper-parameter tuning. In: Book: Recent Advances in Information and Communication Technology, vol 2018, pp 33–42. https://doi.org/10.1007/978-3-319-93692-5_4 Chapter   Google Scholar   Chauhan NS, Mohapatra PKJ, Pandey KP (2006) Improving energy productivity in paddy production through benchmarking – an application of data envelopment analysis. Energy Convers Manage 47:1063–1085. https://doi.org/10.1016/j.enconman.2005.07.004 Article   Google Scholar   Chlingaryan A, Sukkarieh S, Whelan B (2018) Machine learning approaches for crop yield prediction and nitrogen status estimation in precision agriculture: a review. Computer Electron Agric 151:61–69. https://doi.org/10.1016/j.compag.2018.05.012 Article   Google Scholar   Cortes C, Vapnik V (1995) Support vector networks. Machine Learning 20:273–297 Article   Google Scholar   Crane-Droesch A (2018) Machine learning methods for crop yield prediction and climate change impact assessment in agriculture. Environ Res Lett 13:114003. https://doi.org/10.1088/1748-9326/aae159 Article   Google Scholar   Dash Y, Mishra SK, Panigrahi BK (2018) Rainfall prediction for the Kerala state of India using artificial intelligence approaches. Comput Electr Engg 70:66–73. https://doi.org/10.1016/j.compeleceng.2018.06.004 Article   Google Scholar   Deike S, Pallutt B, Christen O (2008) Investigations on the energy efficiency of organic and integrated farming with specific emphasis on pesticide use intensity. Europ J Agron 28:461–470. https://doi.org/10.1016/j.eja.2007.11.009 Article   Google Scholar   Devasenapathy P, Senthilkumar G, Shanmugam PM (2009) Energy management in crop production. Indian J Agron 54:80–90 Article   Google Scholar   Ebrahimi MA, Khoshtaghaza MH, Minaei S, Jamshidi B (2017) Vision-based pest detection based on SVM classification method. Comput Electron Agric 137:52–58. https://doi.org/10.1016/j.compag.2017.03.016 Article   Google Scholar   Esengun K, Erdal G, Gunduz O, Erdal H (2007) An economic analysis and energy use in stake-tomato production in Tokat province of Turkey. Renew Energy 32:1873–1881. https://doi.org/10.1016/j.renene.2006.07.005 Article   Google Scholar   Everingham Y, Sexton J, Skocaj D, Inman-Bamber G (2016) Accurate prediction of sugarcane yield using a random forest algorithm. Agron Sustainable Dev 36:27. https://doi.org/10.1007/s13593-016-0364-z Article   Google Scholar   FAO (2023) Global cereal trade seen down in 2022/23; world wheat production forecast to decline in 2023. https://www.fao.org/worldfoodsituation/csdb/en/ (Assessed on 13-05-2023 at 8.47 a.m.) Filippi P, Jones EJ, Wimalathunge NS, Somarathna PDSN, Pozza LE, Ugbaje SU, Bishop TFA (2019) An approach to forecast grain crop yield using multilayered, multi-farm data sets and machine learning. Precis Agric:1–15. https://doi.org/10.1007/s11119-018-09628-4 Fitzgerald A, Giollabhui NM, Dolphin L, Whelan R, Dooley B (2018) Dissociable psychosocial profiles of adolescent substance users. PLoS One 13:1–17. https://doi.org/10.1371/journal.pone.0202498 Article   CAS   Google Scholar   Folberth C, Baklanov Balkovič AJ, Skalský R, Khabarov N, Obersteiner M (2019) Spatio-temporal downscaling of gridded crop model yield estimates based on machine learning. Agric Forest Meteor 264:1–15. https://doi.org/10.1016/j.agrformet.2018.09.021 Article   Google Scholar   Friedman J, Hastie T, Tibshirani R (2010) Regularization paths for generalized linear models via coordinate descent. J Stat Softw 33:1–20 Article   PubMed   PubMed Central   Google Scholar   Gandhi N, Petkar O, Armstrong LJ, Tripathy AK (2016) Rice crop yield prediction in India using support vector machines. In: 13th Intl Joint Conference on Computer Sci and Software Engineering, JCSSE 2016. https://doi.org/10.1109/JCSSE.2016.7748856 Chapter   Google Scholar   Ginaldi F, Bajocco S, Bregaglio S, Cappelli G (2019) Specializing crop models for sustainable agriculture, innovations in sustainable agriculture. Springer, pp 599–619. https://doi.org/10.1007/978-3-030-23169-9_20 Book   Google Scholar   Greenwood CJ, Youssef GJ, Letcher P, Macdonald JA, Hagg LJ, Sanson A, Mcintosh J, Hutchinson DM, Toumbourou JW, Fuller-Tyszkiewicz M, Olsson CA (2020) A comparison of penalized regression methods for informing the selection of predictive markers. PLoS ONE 15(11):e0242730. https://doi.org/10.1371/journal.pone.0242730 Article   CAS   PubMed   PubMed Central   Google Scholar   Gupta S (2020) Pros and cons of various machine learning algorithms. In: Towards Data Science https://towardsdatascience.com/pros-and-cons-of-various-classification-ml-algorithms-3b5bfb3c87d6 (Assessed on 16-05-2023 at 7.00 pm) Google Scholar   Heidari MD, Omid M, Mohammadi A (2012) Measuring productive efficiency of horticultural green houses in Iran: a data envelopment analysis approach. Expert Syst Appli 39:1040–1045. https://doi.org/10.1016/j.eswa.2011.07.104 Article   Google Scholar   Herold N, Ekström M, Kala J, Goldie J, Evans JP (2018) Australian climate extremes in the 21st century according to a regional climate model ensemble: implications for health and agriculture. Weather Clim Extremes 20:54–68. https://doi.org/10.1016/j.wace.2018.01.001 Article   Google Scholar   Hillier J, Hawes C, Squire G, Hilton A, Wale S, Smith P (2009) The carbon footprints of food crop production. Int J Agric Sustain 7:107–118. https://doi.org/10.3763/ijas.2009.0419 Article   Google Scholar   Holloway J, Mengersen K (2018) Statistical machine learning methods and remote sensing for sustainable development goals: A review. Remote Sensing 10:1365. https://doi.org/10.3390/rs10091365 Article   Google Scholar   Hosmer DW (2000) Lemeshow S (2000) Applied logistic regression, 2nd edn. John Wiley & Sons, Inc., Hoboken, NJ, USA. https://doi.org/10.1002/0471722146 Book   Google Scholar   Htwe T, Sinutoka S, Chotikarna P, Amine N, Akhtaruzzamanf M, Techatoa K, Hossaing T (2021) Energy use efficiency and cost-benefits analysis of rice cultivation: a study on conventional and alternative methods in Myanmar. Energy 214:119104. https://doi.org/10.1016/j.energy.2020.119104 Article   Google Scholar   Huang J, Tian L, Liang S, Ma H, Becker-Reshef I, Huang Y, Su W, Zhang X, Zhu D, Wu W (2015) Improving winter wheat yield estimation by assimilation of the leaf area index from Landsat TM and MODIS data into the WOFOST model. Agric Forest Meteor 204:106–121. https://doi.org/10.1016/j.agrformet.2015.02.001 Article   Google Scholar   IPCC (2014) Climate Change: Mitigation of climate change. In: Edenhofer OR, Pichs-Madruga Y, Sokona E, Farahani S, Kadner K, Seyboth A, Adler I, Baum S, Brunner P, Eickemeier B, Kriemann J, Savolainen S, Schlömer C, von Stechow T, Zwickeland JC, Min X (eds) Contribution of Working Group III to the Fifth assessment report of the intergovernmental panel on climate change. Cambridge University Press, Cambridge, United Kingdom and New York, NY, USA https://www.ipcc.ch/site/assets/uploads/2018/02/ipcc_wg3_ar5_frontmatter.pdf Google Scholar   James G, Witten D, Hastie T, Tibshirani R (2014) An Introduction to Statistical Learning: With Applications. Springer Publishing Company Incorporated. https://static1.squarespace.com/static/5ff2adbe3fe4fe33db902812/t/6009dd9fa7bc363aa822d2c7/1611259312432/ISLR+Seventh+Printing.pdf (Assessed on 24-06-2023 at 4.49 pm) Google Scholar   Johnson DM (2014) An assessment of pre- and within-season remotely sensed variables for forecasting corn and soybean yields in the United States. Remote Sensing Environ 141:116–128. https://doi.org/10.1016/j.rse.2013.10.027 Article   Google Scholar   Johnson MD, Hsieh WW, Cannon AJ, Davidson A, Bédard F (2016) Crop yield forecasting on the Canadian Prairies by remotely sensed vegetation indices and machine learning methods. Agric For Meteorol 218–219:74–84. https://doi.org/10.1016/j.agrformet.2015.11.003 Article   Google Scholar   Kamir E, Waldner F, Hochman Z (2020) Estimating wheat yields in Australia using climate records, satellite image time series and machine learning methods. ISPRS J Photogram Remote Sensing 160:124–135. https://doi.org/10.1016/j.isprsjprs.2019.11.008 Article   Google Scholar   Kelm M, Loges R, Traube F (2001) Ressourceneffizienz ökologischer Fruchtfolgesysteme. Mitteilungen der Gesellschaft für Pflanzenbauwissenschaften 15:56–58 Google Scholar   Khoshnevisan B, Rafiee S, Omid M, Mousazadeh H (2013) Applying data envelopment analysis approach to improve energy efficiency and reduce GHG (greenhouse gas) emission of wheat production. Energy 58:588–593. https://doi.org/10.1016/j.energy.2013.06.030 Article   Google Scholar   Khoshnevisan B, Rafiee S, Omid M, Mousazadeh H (2014) Prediction of potato yield based on energy inputs using multi-layer adaptive neuro-fuzzy inference system. Measurement 47:521–530. https://doi.org/10.1016/j.measurement.2013.09.020 Article   Google Scholar   Kim K, Yoo K, Ki D, Son S, Oh KJ, Park J (2011) Decision-Tree-based data mining and rule induction for predicting and mapping soil bacterial diversity. Environ Monit Assess 178:595–610. https://doi.org/10.1007/s10661-010-1763-2 Article   PubMed   Google Scholar   Kovačević M, Bajat B, Gajić B (2010) Soil type classification and estimation of soil properties using support vector machines. Geoderma 154(3–4):340–347. https://doi.org/10.1016/j.geoderma.2009.11.005 Article   CAS   Google Scholar   Lal R (2004) Carbon emission from farm operations. Environ Intl 30:981–990. https://doi.org/10.1016/j.envint.2004.03.005 Article   CAS   Google Scholar   Lares-Orozco MF, Robles-Morúa A, Yepez EA, Handler RM (2016) Global warming potential of intensive wheat production in the Yaqui Valley, Mexico: a resource for the design of localized mitigation strategies. J Clean Prod 127:522–532. https://doi.org/10.1016/j.jclepro.2016.03.128 Article   Google Scholar   Li N, Jiang Y, Mu H, Yu Z (2018) Efficiency evaluation and improvement potential for the Chinese agricultural sector at the provincial level based on data envelopment analysis (DEA). Energy 164:1145–1160. https://doi.org/10.1016/j.energy.2018.08.150 Article   Google Scholar   Li Y, Chih-yu C, Kaye AM, Wasserman WW (2015) The identification of cis-regulatory elements: A review from a machine learning perspective. Biosystems 138:6–17. https://doi.org/10.1016/j.biosystems.2015.10.002 Article   CAS   PubMed   Google Scholar   Lobell DB (2013) The use of satellite data for crop yield gap analysis. Field Crops Res 143:56–64. https://doi.org/10.1016/j.fcr.2012.08.008 Article   Google Scholar   Lobell DB, Thau D, Seifert C, Engle E, Little B (2015) A scalable satellite-based crop yield mapper. Remote Sensing Environ 164:324–333. https://doi.org/10.1016/j.rse.2015.04.021 Article   Google Scholar   Madiwalar AF, Dhillon GPS, Singh A, Singh P, Singh B (2023) Eucalyptus clones respond differentially for heavy-metals phytoextraction and carbon sequestration in tree biomass and soil with distillery effluents irrigation in north-western India. Procs Indian Natl Sci Acad. https://doi.org/10.1007/s43538-022-00141-x Malana NM (2006) Malano HM (2006) Benchmarking productive efficiency of selected wheat areas in Pakistan and India-data envelopment analysis. Irrig Drain 55:383–394. https://doi.org/10.1002/ird.264 Article   Google Scholar   Manoj G, Prajwal G, Ashoka U, Krishna P, Anitha P (2020) Prediction and analysis of crop yield using machine learning techniques. Intl J Engg Res Tech 8. https://doi.org/10.17577/IJERTCONV8IS15005https://www.ijert.org/prediction-and-analysis-of-crop-yield-using-machine-learning-techniques (Assessed on 24-06-2023 at 5.07 pm) Mittal VK, Mittal JP, Dhawan KC (1985) Research digest on energy requirements in agricultural sector. In: Coordinating Cell, AICRP on energy requirements in agricultural sector. Punjab Agricultural University, Ludhiana Google Scholar   Mobtaker HG, Akram A, Keyhani A, Mohammadi A (2012) Optimization of energy required for alfalfa production using data envelopment analysis approach. Energy Sustain Develop 16:242–248. https://doi.org/10.1016/j.esd.2012.02.001 Article   Google Scholar   Mobtaker HG, Keyhani A, Mohammadi A, Rafiee S, Akram A (2010) Sensitivity analysis of energy inputs for barley production in Hamedan Province of Iran. Agric Ecosyst Environ 137:367–372. https://doi.org/10.1016/j.agee.2010.03.011 Article   Google Scholar   Mohammadi A, Rafiee S, Jafari A, Keyhani A, Mousavi-Avval SH, Nonhebel S (2014) Energy use efficiency and greenhouse gas emissions of farming systems in north Iran. Renew Sustain Energy Rev 30:724–733. https://doi.org/10.1016/j.rser.2013.11.012 Article   CAS   Google Scholar   Mohammadi A, Rafiee S, Mohtasebi SS, Mousavi-Avval SH, Rafiee H (2011) Energy efficiency improvement and input cost saving in kiwifruit production using data envelopment analysis approach. Renew Energy 36:2573–2579. https://doi.org/10.1016/j.renene.2010.10.036 Article   Google Scholar   Mohseni P, Borghei AM, Khanali M (2018) Coupled life cycle assessment and data envelopment analysis for mitigation of environmental impacts and enhancement of energy efficiency in grape production. J Clean Prod 197:937–947. https://doi.org/10.1016/j.jclepro.2018.06.243 Article   CAS   Google Scholar   Mousavi-Avval SH, Mohammadi A, Rafiee S, Tabatabaeefar A (2012) Assessing the technical efficiency of energy use in different barberry production systems. J Cleaner Prod 27:126–132. https://doi.org/10.1016/j.jclepro.2012.01.014 Article   Google Scholar   Mousavi-Avval SH, Rafiee S, Jafari A, Mohammadi A (2014) Optimization of energy consumption for soybean production using Data Envelopment Analysis (DEA) approach. Applied Energy 113:1548–1555. https://doi.org/10.1016/j.apenergy.2011.04.021 Article   Google Scholar   Muazu A, Yahya A, Ishak WIW, Khairunniza-Bejo S (2014) Yield prediction modeling using data envelopment analysis methodology for direct seeding, wetland paddy cultivation. Agric Sci Proced 2:181–190. https://doi.org/10.1016/j.aaspro.2014.11.026 Article   Google Scholar   Mulla S, Singh SK, Singh K, Praveen B (2020) Climate change and agriculture: A review of crop models, global climate change and environmental policy. Springer, pp 423–435. https://doi.org/10.1007/978-981-13-9570-3_15 Book   Google Scholar   Nabavi-Pelesaraei A, Abdi R, Rafiee S, Montaker HG (2014) Optimization of energy required and greenhouse gas emissions analysis for orange producers using data envelopment analysis approach. J Clean Prod 65:311–317. https://doi.org/10.1016/j.jclepro.2013.08.019 Article   CAS   Google Scholar   Nabavi-Pelesaraei A, Hosseinzadeh-Bandbafha H, Qasemi-Kordkheili P, Kouchaki-Penchah H, Riahi-Dorcheh F (2016) Applying optimization techniques to improve of energy efficiency and GHG (greenhouse gas) emissions of wheat production. Energy 103:672–678. https://doi.org/10.1016/j.energy.2016.03.003 Article   Google Scholar   Nabavi-Pelesaraei A, Rafiee S, Mohtasebi SS, Hosseinzadeh-Bandbafha H, Chau KW (2018) Integration of artificial intelligence methods and life cycle assessment to predict energy output and environmental impacts of paddy production. Sci Total Environ 631–632:1279–1294. https://doi.org/10.1016/j.scitotenv.2018.03.088 Article   CAS   PubMed   Google Scholar   Naderloo L, Alimardani R, Omid M, Sarmadian F, Javadikia P, Torabi MY, Alimardani F (2012) Application of ANFIS to predict crop yield based on different energy inputs. Measurement 45:1406–1413. https://doi.org/10.1016/j.measurement.2012.03.025 Article   Google Scholar   Narisetty NN (2020) Chapter 4 - Bayesian model selection for high-dimensional data. Handbook of Statistics 43:207–248. https://doi.org/10.1016/bs.host.2019.08.001 Article   Google Scholar   Nassi O, Di Nasso N, Bosco N, Di Bene C, Coli A, Mazzoncini M, Bonaria E (2010) Energy efficiency in long-term Mediterranean cropping systems with different management intensities. Energy 36:1924–1930. https://doi.org/10.1016/j.energy.2010.06.026 Article   Google Scholar   Nitze I, Schulthess U, Asche H (2012) Comparison of machine learning algorithms random forest, artificial neural network and support vector machine to maximum likelihood for supervised crop type classification. In: Proceedings of the 4th GEOBIA, May 7-9, 2012 - Rio de Janeiro - Brazil http://mtc-m16c.sid.inpe.br/col/sid.inpe.br/mtc-m18/2012/05.15.13.21/doc/015.pdf (Assessed on 24-06-2023 at 5.20 pm) Google Scholar   Omid M, Ghojabeige F, Delshad M, Ahmadi H (2011) Energy use pattern and benchmarking of selected greenhouses in Iran using data envelopment analysis. Energy Convers Manage 52:153–162. https://doi.org/10.1016/j.enconman.2010.06.054 Article   Google Scholar   Pantazi XE, Dimitrios M, Cedric B (2016b) Active learning system for weed species recognition based on hyperspectral sensing. Biosyst Engg 146:193–202. https://doi.org/10.1016/j.biosystemseng.2016.01.014 Article   Google Scholar   Pantazi XE, Moshou D, Alexandridis T, Whetton RL, Mouazen AM (2016a) Wheat yield prediction using machine learning and advanced sensing techniques. Comput Electron Agric 121:57–65. https://doi.org/10.1016/j.compag.2015.11.018 Article   Google Scholar   Pantazi XE, Tamouridou AA, Alexandridis TK, Lagopodi AL, Kashefi J, Moshou D (2017b) Evaluation of hierarchical self-organizing maps for weed mapping using UAS multispectral imagery. Comput Electron Agric 139:224–230. https://doi.org/10.1016/j.compag.2017.05.026 Article   Google Scholar   Pantazi XE, Tamouridou AA, Alexandridis TK, Lagopodi AL, Kontouris G, Moshou D (2017a) Detection of Silybummarianum infection with Microbotryumsilybum using VNIR field spectroscopy. Comput Electron Agric 137:130–137. https://doi.org/10.1016/j.compag.2017.03.017 Article   Google Scholar   Pathak BS, Bining AS (1985) Energy use pattern and potential for energy saving in rice-wheat cultivation. Energy Agric 4:271–278. https://doi.org/10.1016/0167-5826(85)90022-1 Article   Google Scholar   Paul M, Vishwakarma SK, Verma A (2015) Analysis of soil behaviour and prediction of crop yield using data mining approach. In: 2015 International Conference on Computational Intelligence and Communication Networks (CICN). IEEE, pp 766–771. https://doi.org/10.1109/CICN.2015.156 Chapter   Google Scholar   Pavlou M, Ambler G, Seaman S, De iorio M, Omar RZ (2016) Review and evaluation of penalised regression methods for risk prediction in low-dimensional data with few events. Stat Med 35:1159–1177. https://doi.org/10.1002/sim.6782 PMID: 26514699 Article   PubMed   Google Scholar   Pedro A, Fernández A, Ropero RF, Molina L (2013) Groundwater quality assessment using data clustering based on hybrid Bayesian networks. Stoch Environ Res Risk Assess 27:435–447. https://doi.org/10.1007/s00477-013-0719-9 Article   Google Scholar   Qader SH, Dash J, Atkinson PM (2018) Forecasting wheat and barley crop production in arid and semi-arid regions using remotely sensed primary productivity and crop phenology: A case study in Iraq. Sci Total Environ 613-614:250–262. https://doi.org/10.1016/j.scitotenv.2017.09.057 Article   CAS   PubMed   Google Scholar   Rahman S, Barmon BK (2015) Exploring the potential to improve energy saving and energy efficiency using fertilizer deep placement strategy in modern rice production in Bangladesh. Energy Effic. 8:1241–1250. https://doi.org/10.1007/s12053-015-9391-x Article   Google Scholar   Ramadas S, Kiran-Kumar TM, Singh GP (2019) Wheat production in India: Trends and Prospects. In: Shah F, Khan Z, Iqbal A, Turan M, Olgun M (eds) Recent Advances in Grain Crops Research. https://doi.org/10.5772/intechopen.86341https://www.intechopen.com/chapters/67311 (Assessed on 13-05-2023 at 12.04 pm) Chapter   Google Scholar   Ramos PJ, Prieto FA, Montoya EC, Oliveros CE (2017) Automatic fruit count on coffee branches using computer vision. Comput Electron Agric 137:9–22. https://doi.org/10.1016/j.compag.2017.03.010 Article   Google Scholar   Rathke GW, Wienhold BJ, Wilhelm WW, Diepenbrock W (2007) Tillage and rotation effect on corn–soybean energy balances in eastern Nebraska. Soil Till Research 97:60–70. https://doi.org/10.1016/j.still.2007.08.008 Article   Google Scholar   Rossner H (2009) Energy Efficiency of Field Crops Based on Long term fertilization experiment. (M.Sc. Thesis) Estonian University of Life Sciences, Institute of Agricultural and Environmental Sciences, Tartu, Estonia, p 75 Google Scholar   Safa M, Samarasinghe S, Mohssen M (2011) Afield study of energy consumption in wheat production in Canterbury New Zealand. Energy Convers Manage 52:2526–2532. https://doi.org/10.1016/j.enconman.2011.01.004 Article   Google Scholar   Sedighkia M, Abdoli A (2022) Balancing environmental impacts and economic benefits of agriculture under the climate change through an integrated optimization system. Intl J Energy Environ Engg 13:1053–1066. https://doi.org/10.1007/s40095-022-00482-9 Article   Google Scholar   Shiferaw B, Smale M, Braun H, Duveiller E, Reynolds M, Muricho G (2013) Crops that feed the world 10. Past successes and future challenges to the role played by wheat in global food security. Food Secur 5:291–317. https://doi.org/10.1007/s12571-013-0263-y.33 Article   Google Scholar   Singh P, Sandhu AS (2023) Energy budgeting and economics of potato (Solanum tuberosum L.) cultivation under different sowing methods in north-western India. Energy 269:126755. https://doi.org/10.1016/j.energy.2023.126755 Article   Google Scholar   Singh P, Singh G, Gupta A, Sodhi GPS (2023) Data envelopment analysis based energy optimization for improving energy efficiency in wheat established following rice residue management in rice-wheat cropping system. Energy 284:128615. https://doi.org/10.1016/j.energy.2023.128615 Article   CAS   Google Scholar   Singh G, Singh P, Sodhi GPS, Tiwari D (2021c) Energy auditing and data envelopment analysis (DEA) based optimization for increased energy use efficiency in wheat (Triticul aestivum L.) in north-western India. Sustain Energy Technol Assess 47:101453. https://doi.org/10.1016/j.seta.2021.101453 Article   Google Scholar   Singh P, Benbi DK (2020) Nutrient management impacts on net ecosystem carbon budget and energy flow nexus in intensively cultivated cropland ecosystems of north-western India. Paddy Water Environ 18:697–715. https://doi.org/10.1007/s10333-020-00812-9 Article   Google Scholar   Singh P, Singh G, Sodhi GPS (2019a) Energy auditing and optimization approach for improving energy efficiency of rice cultivation in south-western Punjab. Energy 174:269–279. https://doi.org/10.1016/j.energy.2019.02.169 Article   Google Scholar   Singh P, Singh G, Sodhi GPS (2019b) Applying DEA optimization approach for energy auditing in wheat cultivation under rice-wheat and cotton-wheat cropping systems in north-western India. Energy 181:18–28. https://doi.org/10.1016/j.energy.2019.05.147 Article   Google Scholar   Singh P, Singh G, Sodhi GPS, Benbi DK (2021a) Accounting carbon footprints and applying data envelopment analysis to optimize input induced greenhouse gases emissions under rice-wheat cropping system in north-western India. J Soil Sci Plant Nutr 21:3030–3050. https://doi.org/10.1007/s42729-021-00587-w Article   CAS   Google Scholar   Singh P, Singh G, Sodhi GPS, Sharma S (2021b) Energy optimization in wheat establishment following rice residue management with Happy Seeder technology for reduced carbon footprints in north-western India. Energy 230:120680. https://doi.org/10.1016/j.energy.2021.120680 Article   CAS   Google Scholar   Soltani A, Rajabi MH, Zeinali E, Soltani E (2013) Energy inputs and greenhouse gases emissions in wheat production in Gorgan, Iran. Energy 50:54–61. https://doi.org/10.1016/j.energy.2012.12.022 Article   CAS   Google Scholar   Swamy V (2018) Lasso versus ridge versus elastic net. https://medium.com/@vijay.swamy1/lasso-versus-ridge-versus-elastic-net-1d57cfc64b58 (Assessed on 16-05-2023 at 7.25 pm) Terra J (2023) Regression vs. classification in machine learning for beginners. https://www.simplilearn.com/regression-vs-classification-in-machine-learning-article (Assessed on 16-05-2023 at 7.14 pm) Tibshirani R (1996) Regression shrinkage and selection via the Lasso. J Royal Stat Soc Ser-B (Methodological) 58:267–288 Google Scholar   van Klompenburg T, Kassahuna A, Catal C (2020) Crop yield prediction using machine learning: A systematic literature review. Comput Electr Agric 177:105709. https://doi.org/10.1016/j.compag.2020.105709 Article   Google Scholar   Vinutha HP, Poornima B, Sagar BM (2018) Detection of outliers using interquartile range technique from intrusion dataset. In: Satapathy S, Tavares J, Bhateja V, Mohanty J (eds) Information and Decision Sciences. Advances in Intelligent Systems and Computing, vol 701. Springer, Singapore. https://doi.org/10.1007/978-981-10-7563-6_53 Chapter   Google Scholar   West TO, Marland WG (2002) A synthesis of carbon sequestration, carbon emissions, and net carbon flux in agriculture: comparing tillage practices in the United States. Agric Ecosyst Environ 91:217–232. https://doi.org/10.1016/S0167-8809(01)00233-X Article   Google Scholar   Whetton R, Zhao Y, Shaddad S, Mouazen AM (2017) Nonlinear parametric modelling to study how soil properties affect crop yields and NDVI. Comput Electron Agric 138:127–136. https://doi.org/10.1016/j.compag.2017.04.016 Article   Google Scholar   Wieder W, Shoop S, Barna L, Franz T, Finkenbiner C (2018) Comparison of soil strength measurements of agricultural soils in Nebraska. J Terramech 77:31–48. https://doi.org/10.1016/j.jterra.2018.02.003 Article   Google Scholar   Xu X, Gao P, Zhu X, Guo W, Ding J, Li C, Wu X (2019) Design of an integrated climatic assessment indicator (ICAI) for wheat production: a case study in Jiangsu Province, China. Ecol Ind 101:943–953. https://doi.org/10.1016/j.ecolind.2019.01.059 Article   Google Scholar   Ying-xue S, Huan X, Li-jiao Y (2017) Support vector machine-based open crop model (SBOCM): Case of rice production in China. Saudi J Biol Sci 24:537–547. https://doi.org/10.1016/j.sjbs.2017.01.024 Article   Google Scholar   Yuan S, Peng S (2017) Input-output energy analysis of rice production in different crop management practices in central China. Energy 141:1124–1132. https://doi.org/10.1016/j.energy.2017.10.007 Article   Google Scholar   Download references Author information Authors and Affiliations Shaheed Bhagat Singh State University, Ferozepur, Punjab, India Gagandeep Kaur &  Rajni Yadavindra Department of Engineering, Talwandi Sabo, Bathinda, Punjab, India Jagtar Singh Sivia Corresponding author Correspondence to Gagandeep Kaur. Ethics declarations Conflict of Interest The authors declare no competing interests. Additional information Publisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Supplementary information ESM 1 (DOCX 21 kb) ESM 2 (DOCX 22 kb) Rights and permissions Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law. Reprints and permissions About this article Cite this article Kaur, G., Rajni & Sivia, J.S. Integrating Data Envelopment Analysis and Machine Learning Approaches for Energy Optimization, Decreased Carbon Footprints, and Wheat Yield Prediction Across North-Western India. J Soil Sci Plant Nutr 24, 1424–1447 (2024). https://doi.org/10.1007/s42729-024-01647-7 Download citation Received 29 June 2023 Accepted 22 January 2024 Published 02 February 2024 Issue Date March 2024 DOI https://doi.org/10.1007/s42729-024-01647-7 Keywords Chemical fertilizers Energy use efficiency Carbon footprints Greenhouse gas intensity Decision tree regression Random forest regression Support vector machine Access this article Log in via an institution Buy article PDF USD 39.95 Price excludes VAT (USA) Tax calculation will be finalised during checkout. Instant access to the full article PDF. Rent this article via DeepDyve Institutional subscriptions Sections Figures References Abstract References Author information Ethics declarations Additional information Supplementary information Rights and permissions About this article Advertisement Discover content Journals A-Z Books A-Z Publish with us Publish your research Open access publishing Products and services Our products Librarians Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility statement Terms and conditions Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"

Paper 6:
- APA Citation: Zheng, W., Zheng, K., Gao, L., Zhangzhong, L., Lan, R., Xu, L., & Yu, J. (2024). GRU–Transformer: A novel hybrid model for predicting soil moisture content in root zones. Agronomy, 14(3), 432. https://doi.org/10.3390/agronomy14030432
  Main Objective: To develop a more precise and reliable system for managing automated irrigation in real-time.
  Study Location: Hebei Province, China
  Data Sources: Data on soil moisture content, temperature, and weather conditions
  Technologies Used: GRU neural networks, Transformer neural networks
  Key Findings: The GRU–Transformer model was highly accurate in predicting soil moisture content at different depths and under different weather conditions. The model’s mean square error (MSE) for a 1-day forecast was notably low at 5.22%, reducing further to a significant 2.71%, while the mean coefficient of determination (R2) reaches a high of 89.92%.
  Extract 1: The accurate measurement of soil moisture content emerges as a critical parameter within the ambit of agricultural irrigation management, wherein the precise prediction of this variable plays an instrumental role in enhancing the efficiency and conservation of agricultural water resources. This study introduces an innovative, cutting-edge hybrid model that ingeniously integrates Gated Recurrent Unit (GRU) and Transformer technologies, meticulously crafted to amplify the precision and reliability of soil moisture content forecasts.
  Extract 2: The results demonstrate that (1) the GRU–Transformer model exhibits remarkable superiority across various aspects, particularly in short-term projections (1- to 2-day latency). The model’s mean square error (MSE) for a 1-day forecast is notably low at 5.22%, reducing further to a significant 2.71%, while the mean coefficient of determination (R2) reaches a high of 89.92%. Despite a gradual increase in predictive error over extended forecast periods, the model consistently maintains robust performance.
  Limitations: The relatively small dataset size, encompassing merely eight consecutive years of data from eight locations, is a primary limitation of this study. This constraint poses a potential risk of overfitting, potentially impairing the model’s generalization capabilities. Additionally, this study did not incorporate factors such as the growth stages of maize or other agricultural management practices, including irrigation and fertilization, all of which can significantly influence soil moisture dynamics.
  Relevance Evaluation: The paper is highly relevant to the point in the literature review that discusses the need for more precise and reliable automated irrigation systems to ensure crops receive the optimal amount of water they need to grow. The paper proposes a novel hybrid model that uses a combination of GRU and Transformer neural networks to predict soil moisture content in root zones. The model was evaluated using data from eight monitoring stations in Hebei Province, China, and was shown to be highly accurate in predicting soil moisture content at different depths and under different weather conditions. The paper also discusses the limitations of the model and suggests areas for future research.
  Relevance Score: 1.0
  Inline Citation: (Zheng et al., 2024)
  Explanation: The study's primary goal is to develop a more precise and reliable system for managing automated irrigation in real-time. This system will use sensors to collect data on soil moisture content, temperature, and weather conditions. This data will then be used to train machine learning models that can predict future soil moisture levels. The system will use these predictions to automatically adjust irrigation schedules, ensuring that crops receive the optimal amount of water they need to grow and thrive.

 Full Text: >
"This website uses cookies We use cookies to personalise content and ads, to provide social media features and to analyse our traffic. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you’ve provided to them or that they’ve collected from your use of their services. Consent Selection Necessary Preferences Statistics Marketing Show details                 Deny Allow selection Allow all   Journals Topics Information Author Services Initiatives About Sign In / Sign Up Submit   Search for Articles: Agronomy All Article Types Advanced   Journals Agronomy Volume 14 Issue 3 10.3390/agronomy14030432 Submit to this Journal Review for this Journal Propose a Special Issue Article Menu Subscribe SciFeed Recommended Articles Related Info Link More by Authors Links Article Views 691 Table of Contents Abstract Introduction Material and Method Results and Discussion Conclusions Author Contributions Funding Institutional Review Board Statement Informed Consent Statement Data Availability Statement Conflicts of Interest References share Share announcement Help format_quote Cite question_answer Discuss in SciProfiles thumb_up Endorse textsms Comment first_page settings Order Article Reprints Open AccessArticle GRU–Transformer: A Novel Hybrid Model for Predicting Soil Moisture Content in Root Zones by Wengang Zheng 1,2, Kai Zheng 1, Lutao Gao 3, Lili Zhangzhong 2,4,*, Renping Lan 2, Linlin Xu 5 and Jingxin Yu 2,4,* 1 College of Agricultural Engineering, Shanxi Agricultural University, Jinzhong 030801, China 2 Intelligent Equipment Research Center, Beijing Academy of Agriculture and Forestry Sciences, Beijing 100097, China 3 School of Big Data, Yunnan Agricultural University, Kunming 650201, China 4 Information Technology Research Center, Beijing Academy of Agriculture and Forestry Sciences, Beijing 100097, China 5 Department of Systems Design Engineering, University of Waterloo, Waterloo, ON N2L 3G1, Canada * Authors to whom correspondence should be addressed. Agronomy 2024, 14(3), 432; https://doi.org/10.3390/agronomy14030432 Submission received: 13 January 2024 / Revised: 18 February 2024 / Accepted: 20 February 2024 / Published: 23 February 2024 (This article belongs to the Section Precision and Digital Agriculture) Download keyboard_arrow_down     Browse Figures Versions Notes Abstract The accurate measurement of soil moisture content emerges as a critical parameter within the ambit of agricultural irrigation management, wherein the precise prediction of this variable plays an instrumental role in enhancing the efficiency and conservation of agricultural water resources. This study introduces an innovative, cutting-edge hybrid model that ingeniously integrates Gated Recirculation Unit (GRU) and Transformer technologies, meticulously crafted to amplify the precision and reliability of soil moisture content forecasts. Leveraging meteorological and soil moisture datasets amassed from eight monitoring stations in Hebei Province, China, over the period from 2011 to 2018, this investigation thoroughly assesses the model’s efficacy against a diverse array of input variables and forecast durations. This assessment is concurrently contrasted with a range of conventional machine learning and deep learning frameworks. The results demonstrate that (1) the GRU–Transformer model exhibits remarkable superiority across various aspects, particularly in short-term projections (1- to 2-day latency). The model’s mean square error (MSE) for a 1-day forecast is notably low at 5.22%, reducing further to a significant 2.71%, while the mean coefficient of determination (R2) reaches a high of 89.92%. Despite a gradual increase in predictive error over extended forecast periods, the model consistently maintains robust performance. Moreover, the model shows exceptional versatility in managing different soil depths, notably excelling in predicting moisture levels at greater depths, thereby surpassing its performance in shallower soils. (2) The model’s predictive error inversely correlates with the reduction in parameters. Remarkably, with a streamlined set of just six soil moisture content parameters, the model predicts an average MSE of 0.59% and an R2 of 98.86% for a three-day forecast, highlighting its resilience to varied parameter configurations. (3) In juxtaposition with prevalent models such as Support Vector Regression (SVR), K-Nearest Neighbors (KNN), Gradient Boosting Decision Tree (GBDT), XGBoost, Random Forest, and deep learning models like Deep Neural Network (DNN), Convolutional Neural Network (CNN), and standalone GRU-branch and Transformer-branch models, the GRU–Transformer framework demonstrates a significant advantage in predicting soil moisture content with enhanced precision for a five-day forecast. This underscores its exceptional capacity to navigate the intricacies of soil moisture data. This research not only provides a potent decision-support tool for agricultural irrigation planning but also makes a substantial contribution to the field of water resource conservation and optimization in agriculture, while concurrently imparting novel insights into the application of deep learning techniques in the spheres of agricultural and environmental sciences. Keywords: GRU; transformer; soil moisture content; deep learning 1. Introduction Maize, ubiquitously recognized as a cornerstone in global food agriculture and a prominent cash crop within the Chinese agrarian economy [1], holds a paramount position in the agricultural sector. In 2019, as per the Food and Agriculture Organization of the United Nations (FAO), China’s maize yield escalated to an extraordinary 260 million tons, constituting a substantial 21.3% of the worldwide production [2]. However, the growth and fecundity of maize are contingent upon an array of determinants, with soil moisture content emerging as a critical environmental factor [3]. The hydration state of soil is pivotal, directly influencing the physiological and biochemical processes in maize, along with its root development [4]. Consequently, the precise prognostication of soil water content within the maize root zone is imperative for orchestrating efficient irrigation strategies and augmenting both the water-use efficiency and the crop’s yield. Yet, forecasting the moisture content in maize’s root zone presents a labyrinthine nonlinear challenge. It is intricately influenced by an amalgamation of factors such as meteorological conditions, soil characteristics, and various stages of crop growth, defying simplification into elementary mathematical models [5]. Thus, the exigent scientific quandary lies in harnessing the available meteorological and soil data to formulate a potent and efficacious predictive model. Conventional methodologies for forecasting the soil moisture content in maize’s root zone can be broadly categorized into three distinct classifications: physics-based approaches, statistics-based strategies, and machine learning-driven techniques [6]. Physics-based methods employ a combination of soil moisture movement and crop water demand equations, integrated with meteorological, soil, and crop parameters, to simulate the dynamic fluctuations of soil moisture. Exemplified by sophisticated models such as HYDRUS [7], SWAT (Soil and Water Assessment Tool) [8], DSSAT (Decision-support System for Agrotechnology Transfer) [9], and EPIC (Erosion Productivity Impact Calculator) [10], these methods adeptly mirror the physical underpinnings of soil moisture dynamics. However, they are hampered by their requirement for extensive parameter inputs, computational intricacy, and the need for highly precise parameter values, rendering them less viable for broad-scale and long-duration predictive applications [11]. Statistics-based methods, on the other hand, rely on the application of statistical principles and techniques to construct mathematical regression models. These models project future soil moisture levels based on historical meteorological and soil data [12] and are often represented through methodologies like linear regression [13], multiple regression [12], and exponential smoothing [14]. Despite their simplicity and ease of use, these methods fall short in acknowledging the nonlinear nature of soil moisture, failing to accurately track its dynamic variations and generally suffering from lower predictive accuracy [15]. Machine learning-based methods, meanwhile, harness the power of artificial intelligence to autonomously discern the intrinsic patterns of soil moisture from extensive meteorological and soil data, thereby predicting future soil moisture levels [13]. This category includes a diverse array of techniques such as the radial basis function neural network (RBF) [16], BP neural network [17], support vector machine (SVM) [18,19], extreme learning machine (ELM) [20], Random Forest [21], and Gradient Boosting Tree [22]. These methods are particularly proficient at processing nonlinear and high-dimensional data, yielding high prediction accuracy. However, they necessitate substantial volumes of training data, and their predictive performance is often limited by the models’ inadequate feature extraction capabilities [23]. Deep learning, a sophisticated subset of machine learning, is founded on multi-layered neural networks capable of autonomously extracting features and discerning patterns from voluminous datasets, thereby boasting potent expressive and generalization proficiencies. The primary modalities within deep learning encompass the convolutional neural network (CNN) [24], the recurrent neural network (RNN) [25], and the self-attention mechanism [26]. As deep learning has evolved, methods such as DNN [27] and RNN [26] have been increasingly applied to the prediction of soil moisture content in agricultural contexts, achieving notable advancements. Nonetheless, traditional deep learning methodologies are not without their limitations. The CNN, utilizing convolutional kernels for feature extraction, is adept at processing structured data like images and speech but falters with time-series data [28]. Conversely, the RNN, designed to handle time-series data, leverages historical information for future predictions but is plagued by gradient vanishing and explosion issues, impeding its ability to capture long-term dependencies [29]. Similarly, while the self-attention mechanism can effectively manage unstructured data such as natural language, it is less effective with structured data [30]. To address these challenges, the Gated Recurrent Unit (GRU) improves upon the RNN by incorporating a gating mechanism to mitigate gradient vanishing and explosion, thereby enhancing the model’s memory capabilities [4]. Meanwhile, the Transformer, based on the self-attention mechanism, can discern global dependencies within an input sequence through multi-head attention and position encoding, significantly bolstering the model’s expressive capacity [31]. Both GRU and Transformer, originating from the realm of natural language processing, excel in handling time-series prediction tasks and offer complementary advantages to redress the shortcomings of RNNs and self-attention mechanisms, respectively [32]. There have been successful applications of GRU and Transformer models in various fields, such as traffic flow analysis [33], speech recognition [34], and environmental sequence modeling [35], yet their application in predicting soil moisture content in maize’s root zone remains relatively unexplored. Given the proven efficacy of hybrid models in enhancing prediction accuracy by amalgamating different deep learning approaches [4,36], this study proposes a novel technical solution: the creation of a hybrid model that fuses GRU and Transformer technologies. This GRU–Transformer hybrid model will be applied to the prediction of soil water content in the root zone of maize, with an aim to evaluate its feasibility and effectiveness in this specific domain. The principal aim of this study is to introduce and assess the efficacy of a novel soil water content prediction model, christened the GRU–Transformer. This model’s validation involves a rigorous evaluation using meteorological and soil moisture data collected from maize cultivation areas across eight distinct locations in Hebei Province, China, spanning the years 2011 to 2018. The assessment strategy encompasses an analysis of the model’s predictive capabilities across various input configurations and forecast durations. Additionally, the performance of the GRU–Transformer model is benchmarked against a range of conventional machine learning and advanced deep learning models, providing a comprehensive understanding of its relative effectiveness in predicting soil moisture content in agricultural settings. 2. Material and Method The hybrid modeling methodology delineated in this manuscript leverages the synergistic capabilities of GRU and Transformer algorithms to prognosticate future soil moisture levels across varying depths, as depicted in Figure 1. This innovative model is bifurcated into two distinct branches: the GRU branch and the Transformer branch. Each branch meticulously processes the 3D tensor, characterized by the dimensions (batch_size, input_length, num_features), amalgamating input variables derived from both meteorological and soil datasets. Subsequently, the extracted features from each branch are intricately spliced and amalgamated through a meta-learner, culminating in the synthesis of the final predictive output. This output is represented as a two-dimensional tensor (batch_size, output_length), encapsulating the forecasted soil moisture content at a future juncture, thereby showcasing the model’s robust predictive acumen. Figure 1. Architectural blueprint of the GRU–Transformer model. 2.1. GRU Branch The purpose of the GRU branch in this study is to utilize the recurrent structure and gating mechanism of GRU to capture the long-term dependence and temporal dynamics features in the input sequences (Figure 2). GRU, using an improved RNN, can solve the problem of vanishing or exploding gradients that RNNs are prone to when dealing with long sequences [35]. The basic units of GRU are as follows: 𝑟 𝑡 =𝜎( 𝑊 𝑟 𝑥 𝑡 + 𝑈 𝑟 ℎ 𝑡−1 + 𝑏 𝑟 ) (1) 𝑍 𝑡 =𝜎( 𝑊 𝑍 𝑥 𝑡 + 𝑈 𝑍 ℎ 𝑡−1 + 𝑏 𝑍 ) (2) ℎ ̃  𝑡 =tanh( 𝑊 ℎ 𝑥 𝑡 + 𝑈 ℎ ( 𝑟 𝑡 ⨀ ℎ 𝑡−1 )+ 𝑏 ℎ ) (3) ℎ 𝑡 =(1− 𝑍 𝑡 )⨀ ℎ 𝑡−1 + 𝑍 𝑡 ⨀ ℎ ̃  𝑡 (4) where 𝑥 𝑡 is an input vector, ℎ 𝑡 is an output vector, 𝑟 𝑡 is a reset gate, 𝑍 𝑡 is an update gate, 𝜎 is a sigmoid function, ⨀ is an element-by-element multiplication, 𝑊 𝑟 , 𝑊 𝑍 , 𝑊 ℎ , 𝑈 𝑟 , 𝑈 𝑍 , 𝑈 ℎ is a learnable weight matrix, and 𝑏 𝑟 , 𝑏 𝑍 , 𝑏 ℎ is a learnable bias vector. Reset gates and update gates can control the flow of information, selectively forgetting or remembering historical states. The reset gate can decide whether to reset the historical state or not, and the update gate can decide whether to update the current state or not. Figure 2. Conceptual illustration of the GRU branch. The structural design and hyperparameter configuration of the GRU branch in the model proposed in this paper are shown in Table 1. Table 1. Configuration of hyperparameters in the GRU branch. Firstly, a two-layer GRU network is constructed with 512 neurons in each layer. ReLU is used for the activation function to increase the depth and nonlinearity of the model and to improve the expressive power of the model. The formula for the ReLU function is 𝑟𝑒𝑙𝑢(𝑥)=max(0,𝑥) (5) The output of the GRU is then mapped onto a low-dimensional space using a fully connected layer (Dense) of 256 neurons, reducing the number of parameters and decreasing the complexity of the model. The formula for the fully connected layer is 𝑦=𝑊𝑥+𝑏 (6) where 𝑥 is the input vector, 𝑦 is the output vector, 𝑊 is the learnable weight matrix, and 𝑏 is the learnable bias vector. Finally, a spreading layer (Flatten) is connected to obtain a 2D tensor (batch_size, 256), which converts the output of the fully connected layer into a 1D vector for easy splicing with the output of the Transformer branch. The formula for the Flatten layer is 𝑦=𝑥.𝑟𝑒𝑠ℎ𝑎𝑝𝑒(𝑏𝑎𝑡𝑐ℎ𝑠𝑖𝑧𝑒,−1) (7) where 𝑥 is the input tensor, 𝑦 is the output vector, 𝑏𝑎𝑡𝑐ℎ𝑠𝑖𝑧𝑒 is the batch size, and −1 indicates that the remaining dimensions are computed automatically. The output of the GRU branch can be expressed as 𝑦=𝐹𝑙𝑎𝑡𝑡𝑒𝑛(𝐷𝑒𝑛𝑠𝑒(𝐺𝑅𝑈(𝐺𝑅𝑈(𝑥)))) (8) where 𝑥 is the input tensor, 𝑦 is the output vector, 𝐺𝑅𝑈 is the GRU layer, 𝐷𝑒𝑛𝑠𝑒 is the fully connected layer, and 𝐹𝑙𝑎𝑡𝑡𝑒𝑛 is the spreading layer. 2.2. Transformer Branch In the proposed GRU–Transformer model, the Transformer branch plays a pivotal role in capturing global dependencies and multidimensional features within the input sequence. This is achieved through the employment of the Transformer’s self-attention and multi-head attention mechanisms, as depicted in Figure 3. The Transformer is adept at handling sequence-to-sequence tasks, utilizing its attention-based encoder–decoder structure [33]. This structure is integral to the model’s ability to process and analyze complex sequences of data effectively. The core unit of the Transformer can be conceptualized as follows: 𝑄=𝑋 𝑊 𝑄 (9) 𝐾=𝑋 𝑊 𝐾 (10) 𝑉=𝑋 𝑊 𝑉 (11) 𝐴=𝑠𝑜𝑓𝑡𝑚𝑎𝑥( 𝑄 𝐾 𝑇 𝑑 𝐾 − − √ ) (12) 𝑌=𝐴𝑉 (13) where X is the input matrix, 𝑄 , 𝐾 , 𝑉 is the query matrix, 𝑊 𝑄 , 𝑊 𝐾 , 𝑊 𝑉 key matrix, value matrix, 𝐴 is the learnable weight matrix, 𝑌 is the attention matrix, 𝑑 𝐾 is the output matrix, 𝑑 𝐾 − − √ is the dimension of the attention header, 𝑠𝑜𝑓𝑡𝑚𝑎𝑥 is a scaling factor used to prevent the attention weights from being too large or too small, and softmax is the normalization function used to compute the weight of the value corresponding to each key. The attention mechanism calculates the correlation of each element in the input sequence with the other elements, thus enabling global dependency capture. Figure 3. Conceptual diagram of the Transformer branch. The structure of the Transformer branch in the model proposed in this paper is designed as follows: firstly, position information is added to each element in the input sequence by adding position embeddings to the inputs, so that the model can distinguish between elements at different positions. The detailed hyperparameter configuration is shown in Table 2. Table 2. Hyperparameter configuration for the Transformer branch. The formula for position encoding is as follows: 𝑃𝐸 (𝑝𝑜𝑠,2𝑖) =sin ⎛ ⎝ ⎜ ⎜ ⎜ 𝑝𝑜𝑠 10000 2𝑖 𝑑 ⎞ ⎠ ⎟ ⎟ ⎟ (14) 𝑃𝐸 (𝑝𝑜𝑠,2𝑖+1) =cos ⎛ ⎝ ⎜ ⎜ ⎜ 𝑝𝑜𝑠 10000 2𝑖 𝑑 ⎞ ⎠ ⎟ ⎟ ⎟ (15) where 𝑃𝐸 is the position encoding matrix, 𝑝𝑜𝑠 is the position index, 𝑖 is the dimension index, 𝑑 is the dimension of the input. The dimensions of the position encoding are the same as the dimensions of the input and can be added directly to the input. Then, four Transformer encoder layers (Transformer_encoder) are constructed with four attention heads per layer (num_heads = 4), each with a dimension of 64 (head_size = 64), a feedforward network with a dimension of 128 (ff_dim = 128), and a Dropout layer with a rate of 0.1 (dropout_rate = 0.1). The above configuration increases the depth and diversity of the model and improves its expressive power. Among them, the Dropout layer can randomly discard a small number of neurons to prevent model overfitting. The structure of the Transformer encoder layer is as follows: 𝑋 ′ =𝑋+𝑀𝑢𝑙𝑡𝑖𝐻𝑒𝑎𝑑𝐴𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛(𝑋,𝑋,𝑋) (16) 𝑋 ″ = 𝑋 ′ +𝐹𝑒𝑒𝑑𝐹𝑜𝑟𝑤𝑎𝑟𝑑( 𝑋 ′ ) (17) 𝑌=𝐿𝑎𝑦𝑒𝑟𝑁𝑜𝑟𝑚( 𝑋 ″ ) (18) where 𝑋 is the input matrix, 𝑋 ′ is the output of the first residual connection, 𝑋 ″ is the output of the second residual connection, 𝑌 is the final output, 𝑀𝑢𝑙𝑡𝑖𝐻𝑒𝑎𝑑𝐴𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛 is the multi-head attention layer, 𝐹𝑒𝑒𝑑𝐹𝑜𝑟𝑤𝑎𝑟𝑑 is the feedforward network layer, and 𝐿𝑎𝑦𝑒𝑟𝑁𝑜𝑟𝑚 is the layer normalization layer. The multi-head attention layer can divide the input matrix into multiple sub-matrices, which are stitched together after separate attention computations to capture the multi-dimensional features in the input sequence. The feedforward network layer can increase the complexity of the model by performing a nonlinear transformation of the input matrix. The layer normalization layer normalizes each layer of the input matrix to make the model more stable. Residual connections make the model easier to optimize avoiding gradient vanishing or exploding. Then, a 256 neuron fully connected layer (Dense) is constructed to map the output of the Transformer to a low dimensional space reducing the number of parameters and decreasing the complexity of the model. Finally, a two-dimensional tensor (batch_size, 256) is obtained through a Flatten layer, which converts the output of the fully connected layer into a one-dimensional vector, which can be easily spliced with the output of the GRU branch. The output of the Transformer branch can be represented as follows: 𝑦=𝐹𝑙𝑎𝑡𝑡𝑒𝑛(𝐷𝑒𝑛𝑠𝑒( 𝑇𝑟𝑎𝑛𝑠𝑓𝑜𝑟𝑚𝑒𝑟𝐸𝑛𝑐𝑜𝑑𝑒𝑟 4 (𝑃𝑜𝑠𝑖𝑡𝑖𝑜𝑛𝐸𝑚𝑏𝑒𝑑𝑑𝑖𝑛𝑔𝑠(𝑥)))) (19) where 𝑥 is the input tensor, 𝑦 is the output vector, 𝑃𝑜𝑠𝑖𝑡𝑖𝑜𝑛𝐸𝑚𝑏𝑒𝑑𝑑𝑖𝑛𝑔𝑠 is the position encoding layer, 𝑇𝑟𝑎𝑛𝑠𝑓𝑜𝑟𝑚𝑒𝑟𝐸𝑛𝑐𝑜𝑑𝑒𝑟 is the Transformer encoder layer, 𝐷𝑒𝑛𝑠𝑒 is the fully-connected layer, 𝐹𝑙𝑎𝑡𝑡𝑒𝑛 is the spreading layer, and 4 means repeat four times. 2.3. Meta-Learner The purpose of the meta-learner in the model proposed in this paper is to splice and fuse the outputs of the two branches to obtain the final prediction results. The structure of the meta-learner is designed as follows: firstly, the outputs of the two branches are concatenated to obtain a two-dimensional tensor (batch_size, 512), and then the features of the two branches are combined to increase the information content of the model. The detailed hyper-parameter configuration is shown in Table 3. Table 3. Meta-learner hyperparameter configuration. The equation for the splicing layer can be expressed as follows: 𝑦=[ 𝑥 1 , 𝑥 2 ] (20) where 𝑥 1 is the output of the GRU branch, 𝑥 2 is the output of the Transformer branch, 𝑦 is the spliced output, and [] denotes the splicing operation. Then, a 5-layer neuron fully connected layer (Dense) is constructed and the activation function is ReLU. The formula for the fully connected layer is as follows: 𝑦=𝑟𝑒𝑙𝑢(𝑊𝑥+𝑏) (21) where 𝑥 is the input vector, 𝑦 is the output vector, 𝑊 is the learnable weight matrix, 𝑏 is the learnable bias vector, and 𝑟𝑒𝑙𝑢 is the activation function. Finally, the connection is made to the output layer, which is Dense, and the activation function used is linear to obtain the final output, which is a two-dimensional tensor (batch_size, output_length). The above process maps the output of the fully connected layer to a one-dimensional space to obtain the predicted values. 2.4. Model Evaluation and Training To evaluate the performance of different models, the following five evaluation metrics were chosen in this paper. Mean Squared Error (MSE): 𝑀𝑆𝐸= 1 𝑚 ∑ 𝑚 𝑖=1 ( 𝑦 𝑖 − 𝑦 ̂  𝑖 ) 2 (22) Mean Absolute Error (MAE): 𝑀𝐴𝐸= 1 𝑚 ∑ 𝑚 𝑖=1 |( 𝑦 𝑖 − 𝑦 ̂  𝑖 )| (23) Root Mean Squared Error (RMSE): 𝑅𝑀𝑆𝐸= 1 𝑚 ∑ 𝑚 𝑖=1 ( 𝑦 𝑖 − 𝑦 ̂  𝑖 ) 2 − − − − − − − − − − − − − − − √ (24) Coefficient of Determination (R2): 𝑅 2 =1− ∑ 𝑖 ( 𝑦 ̂  𝑖 − 𝑦 𝑖 ) 2 ∑ 𝑖 ( 𝑦 ̲ 𝑖 − 𝑦 𝑖 ) 2 (25) where 𝑦 ̂  𝑖 is the predicted value, 𝑦 𝑖 is the true value, 𝑦 ̲ 𝑖 is the average of the true values. 𝑀𝐴𝐸 can reflect the actual situation of the error of the predicted value: the smaller its value, the higher the accuracy of the prediction. 𝑀𝑆𝐸 is the expected value of the square of the difference between the predicted value and the true value, which can evaluate the degree of change of the data, the smaller its value, the higher the stability of the prediction. 𝑅𝑀𝑆𝐸 is the arithmetic square root of 𝑀𝑆𝐸 , which, like the 𝑀𝐴𝐸 , is used to measure the accuracy of the prediction, but it has a greater penalty for larger errors, so it is more suitable for evaluating models that are sensitive to errors. 𝑅 2 can eliminate the influence of dimensionality on the evaluation index, it indicates the degree of correlation between the predicted value and the real value, and the closer its value is to 1, the higher the fit of the prediction. Regarding the experimental setup for this research, the hardware configuration encompasses an Intel® Xeon® CPU E5-1620 v4 @ 3.50 GHz, an NVIDIA Quadro K2200 GPU, and 32 GB of RAM. The software infrastructure leverages Anaconda as the foundational platform for deep learning endeavors, with Keras serving as the framework for constructing deep learning models, and TensorFlow-gpu 1.13 functioning as the backend engine. CUDA technology, developed by NVIDIA Corporation based in Santa Clara, CA, USA, is employed to facilitate parallel computing on the GPU, thereby augmenting the training speed of the model. Python 3.7 is utilized as the primary programming language. The training methodology incorporates the Adam optimization algorithm for model refinement, complemented by an early stopping criterion as a termination condition for training. This criterion is set with a threshold of 50 iterations—training ceases if there is no improvement in the model’s loss on the validation set within these iterations. The optimal model weights are preserved, and the model is saved in the .h5 format. This comprehensive setup ensures a robust and efficient training environment, which is crucial for the development and validation of the deep learning model. 2.5. Study Area and Data Acquisition The focal area of this study is Hebei Province, China, encompassing geographical coordinates ranging from 36°05′ to 42°40′ N latitude and 113°27′ to 119°50′ E longitude. This region is characterized by a temperate continental monsoon climate, distinguished by four well-defined seasons, ample sunshine, moderate rainfall, and significant temperature variations, among other climatic attributes. The dataset employed in this study was procured from the China Meteorological Data Network, encompassing both meteorological and soil moisture content data spanning the years 2011 to 2018. In alignment with the prevalent conditions of maize cultivation in the region and subsequent consultations with local agricultural authorities, a comprehensive dataset comprising 450,120 records was assembled from eight agrometeorological monitoring stations within Hebei Province (namely Fuping, Weixian, Gaoyi, Fengning, Langfang, Xinglong, Weichang, and Qinglong stations), as illustrated in Figure 4. Soil water content measurements were conducted at an hourly frequency. The volumetric water content of the soil (denoted as 10SVWC, 20SVWC, 30SVWC, 40SVWC, 50SVWC, and 60SVWC, represented in percentage) was recorded at varying depths of 10 cm, 20 cm, 30 cm, 40 cm, 50 cm, and 60 cm, with daily average values being computed. The meteorological data encompassed a range of parameters, including the daily mean air temperature (TEM_Avg, in degrees Celsius), minimum air temperature (TEM_Min, in degrees Celsius), maximum air temperature (TEM_Max, in degrees Celsius), mean surface temperature (GST_Avg, in degrees Celsius), minimum surface temperature (GST_Min, in degrees Celsius), maximum surface temperature (GST_Max, in degrees Celsius), duration of sunshine (SSH, in hours), mean relative humidity (RHU_Avg, in percentages), precipitation during the period from 20:00 to 08:00 h (PRE_Time_2008, in millimeters), precipitation during the period from 08:00 to 20:00 h (PRE_Time_0820, in millimeters), 24 h precipitation (PRE_Time_2020, in millimeters), average wind speed (WIN_S_Avg, in kilometers per hour), maximum wind speed (WIN_S_Max, in kilometers per hour), dominant wind direction (WIN_D_S_Max, in degrees), instantaneous maximum wind speed (WIN_S_Inst_Max, in kilometers per hour), and the direction of the instantaneous maximum wind speed (WIN_D_INST_Max, in degrees). Figure 4. Geographical overview of the study area and distribution of sites. 2.6. Data Analysis Table 4 elegantly presents the synthesized statistical analysis of 22 distinct soil and meteorological indicators, encompassing an array of parameters such as mean, standard deviation, minimum, maximum, and median values across the eight meticulously chosen monitoring stations. The temporal scope of this study encompasses an entire annual cycle of data from maize cultivation locales, thereby encapsulating the complete spectrum of seasonal fluctuations and chronological diversities. This comprehensive temporal coverage, while providing a holistic view of the data, simultaneously introduces a formidable challenge in the precise prediction of soil water content at varying depths within the maize root zone. Such an encompassing approach ensures a thorough understanding of the intricate interplay between temporal variables and the dynamic nature of soil moisture content, critical for advancing predictive accuracy in agricultural environmental studies. Table 4. Comprehensive statistical analysis outcomes of soil and meteorological data. Figure 5 elegantly delineates the outcomes of the Pearson correlation analysis conducted among the various variables. This analysis reveals that the correlation coefficients pertaining to soil water content at diverse depths surpass the threshold of 0.7, indicating a robust and strongly positive correlation. The interplay between each meteorological parameter and soil water content exhibits varying degrees of correlation. Specifically, TEM_Avg, TEM_Max, TEM_Min, RHU_Avg, PRE_Time_2008, PRE_Time_0820, PRE_Time_2020, GST_Avg, GST_Max, and GST_Min all demonstrate a positive correlation with the soil water content at different depths. Conversely, WIN_S_Avg, WIN_S_Max, WIN_D_S_Max, WIN_S_Inst_Max, WIN_D_INST_Max, and SSH exhibit a negative correlation with soil water content across various depths. This intricate mosaic of correlations underscores the multifaceted nature of the interactions between meteorological factors and soil water content, providing invaluable insights into the complex dynamics governing soil moisture across different strata. Figure 5. Analytical depiction of correlation between soil water content and other variables at varied depths. Asterisks (*) indicate correlations statistically significant at p < 0.05. 3. Results and Discussion 3.1. Comparison of Model Prediction Accuracy for Different Days of Delay Figure 6 and Figure 7 elucidate the predictive accuracy outcomes of the GRU–Transformer model across various delay intervals. The model’s overall performance is noteworthy for its consistently high accuracy and stability under diverse conditions. Specifically, the MSE for soil moisture prediction at different depths fluctuated between 2.71% and 17.53%, while the R2 spanned from 60.47% to 96.08%. These figures emphatically underscore the model’s adaptability and resilience in varied scenarios. A more granular analysis reveals that the model’s predictive precision is notably superior for shorter delay periods, such as 1 to 2 days. For instance, the average MSE for a 1-day delay stands at 5.22%, with the lowest recorded value being 2.71%, and the average R2 is remarkably high at 89.92%. Nonetheless, it is observed that the predictive error incrementally ascends with an increase in the delay duration, suggesting a heightened proficiency of the model in forecasting near-term data. When delving into the comparison across different soil depths, it is discernible that the model’s predictive error for shallow soils, like at 10 cm depth, is relatively elevated, with a mean MSE of 15.00% and an average R2 of merely 66.17%. In stark contrast, the model’s error rate for deeper soils, such as at 50 cm, is markedly lower, boasting an average MSE of 7.71% and an average R2 of 85.66%. This disparity highlights the model’s significant advantage in predicting the water content of deeper soils. In summation, the soil water content prediction model introduced in this study exhibits exemplary efficacy across various prediction delays and soil depths. It is particularly commendable for its high accuracy and reliability in short-term predictions and in assessing the water content of deeper soil layers. Figure 6. Analysis of prediction error in GRU–Transformer model across different time delays. Figure 7. Error distribution in test set for GRU–Transformer model over various time delays. The marked disparities in the performance of the soil moisture content prediction model at varying delay intervals and soil depths, as highlighted in this study, underscore the intricate complexity of soil moisture dynamics and its susceptibility to environmental influences. These variances not only attest to the model’s adaptability but also furnish novel insights into the understanding of soil moisture behavior. The observed decrease in prediction accuracy with prolonged delay days is potentially attributable to escalating uncertainties on the temporal scale. In the immediate term, the soil moisture content is relatively less impacted by meteorological conditions, thereby enabling the model to forecast near-future soil moisture status with greater precision. However, the predictability diminishes as the timeframe extends, largely due to the increasing unpredictability of meteorological factors such as rainfall and evaporation, which exert a direct influence on the model’s accuracy [37]. Figure 8 delineates the outcomes of an autocorrelation analysis on soil water content over a 1–10-day delay period, using the data from this study. The analysis reveals a decline in the mean autocorrelation coefficient of soil water content from a peak of 0.91 to a mere 0.19 as the delay interval increases, thereby highlighting the amplified challenges in forecasting over longer future durations. This phenomenon aligns with the findings of Cai et al. (2019) [29], who examined the 1–16-day autocorrelation of soil water content. Figure 8. Autocorrelation analysis of soil water content under 1–10-day delay. Furthermore, the dynamics of soil moisture encompass a spectrum of intricate nonlinear processes such as evaporation, infiltration, and plant water uptake. Consequently, the model’s prediction error tends to escalate with the extension of the forecast period, a concept corroborated by theoretical studies in time-series prediction. From the standpoint of soil depth, the model exhibits heightened accuracy in predicting moisture content in deeper soils. This heightened accuracy could stem from the reduced impact of daily climatic fluctuations on deeper soils, which exhibit relatively less variability in moisture content. In contrast, surface soils are directly exposed to atmospheric elements, rendering their moisture status more immediately susceptible to variables like rainfall and evapotranspiration, thus posing greater challenges for accurate prediction [38]. The moisture dynamics in deeper soil strata are comparatively stable and are more effectively and accurately captured by existing hydrological and soil science models [39]. This observation underscores the significant role of soil physical characteristics in influencing the performance of prediction models and suggests the necessity of comprehensive consideration of the properties of different soil layers in the construction and parameter optimization of these models. 3.2. Assessing the Predictive Efficacy of Varied Input Parameter Combinations The efficacy of the proposed soil water content prediction model was exhaustively evaluated across a spectrum of input parameter combinations. Six distinct sets of input terms, comprising 6, 9, 12, 15, 18, and 22 parameters, respectively, were meticulously formulated based on the inter-correlation of the indicators (as outlined in Table 5). This approach was employed to juxtapose the model’s predictive accuracies under diverse parameter amalgamations. The experimental outcomes elucidate key characteristics and trends in the model’s performance. Table 5. Framework of diverse input term combinations. Figure 9 and Figure 10 depict the predictive accuracy of the GRU–Transformer model under these varied input scenarios. Regarding its overall performance, the model consistently exhibited high accuracy and stability across the range of parameter combinations. The MSE of the GRU–Transformer model oscillated between 0.43% and 1.11%, while the R2 ranged from 0.8482 to 0.8578. This variance indicates that the proposed model adeptly predicts soil water content, effectively handling different sets of input parameters. Figure 9. Assessment of prediction accuracy in GRU–Transformer model with varied input term combinations. Figure 10. Distribution of test set errors in GRU–Transformer model under different input term combinations. Focusing on the comparative performance across parameter combinations, the model attained its zenith under the 22-parameter ensemble (Group 1), registering an average MSE of 0.62% and an average R2 of 0.8578. This implies that the model harnesses a broader array of data features to enhance predictive accuracy when endowed with a higher count of parameters. Conversely, in the 6-parameter combination (Group 6)—the minimal parameter set—the average MSE modestly declined to 0.59%, and the average R2 marginally ascended to 0.8482. This demonstrates the model’s capacity to sustain high accuracy even with a reduced parameter set, underlining its robustness and adaptability. An in-depth analysis of the influence of the parameter count on the model’s efficacy reveals that, while both the maximal and minimal MSE values diminish as the number of parameters decreases, the overall performance remains relatively unaffected. This observation suggests that the model proficiently captures the salient features of soil water content, even under conditions of simplified input, highlighting its capability to efficiently distill and utilize essential data characteristics. This research discerned that diminishing the number of parameters led to a slight escalation in the error indices, while the R2 values continued to hover at elevated levels. This phenomenon suggests that the model retains the primary factors influencing soil water content, even under a regime of parameter simplification, thereby facilitating effective prediction. Such a capability could be attributed to the fact that the chosen parameters exhibit a strong correlation with soil water content, coupled with a degree of redundancy among them. That is, certain parameters can be inferred or approximated using others. Consequently, when the parameter count is reduced, the model compensates for the absence of certain parameters by adjusting the weights of the remaining ones, thus sustaining its high predictive accuracy. This characteristic also underscores the model’s robust self-adaptive nature, enabling automatic adjustments in its structure and parameters in response to varying parameter combinations, to achieve optimal prediction outcomes. Moreover, the progressive increase in MSE, RMSE, and MAE from Group 1 (22 parameters) to Group 6 (6 parameters), juxtaposed with the relatively minor fluctuation in the R2 value (0.8482–0.8578), indicates the model’s tolerance to changes in parameter quantity. This implies that alterations in the number of parameters do not significantly impact the predictive capability of the model. This resilience may stem from the model’s GRU–Transformer hybrid neural network architecture, which adeptly extracts higher-order features of the parameters through multilayer nonlinear transformations, thereby enhancing its expressive and generalization abilities. Hence, even with a limited number of parameters, the model is capable of discerning potential interrelationships through neural network learning, facilitating accurate soil water content prediction. The high consistency in error metrics between Groups 1 and 2 may be attributed to the inclusion of comprehensive soil volumetric water content parameters and other critical parameters such as temperature, relative humidity, precipitation, and wind speed in these combinations. These parameters collectively encapsulate the soil’s physical, chemical, and biological attributes, as well as the soil–atmosphere interactions, thereby influencing the dynamic shifts in soil water content. Hence, they provide a wealth of information that enhances the predictive accuracy and stability of the model. Interestingly, even with Group 6, which comprises the least number of parameters focused solely on volumetric soil water content, the decline in predictive accuracy is not significantly pronounced. This implies that these parameters are direct indicators of soil water content and the primary factors influencing its variability. Additionally, as depicted in Figure 11, the correlation between different soil depths ranges from 0.65 to 0.95, offering synergistic features that bolster the stability of the model’s predictions. Consequently, the model achieves satisfactory predictive accuracies even when solely reliant on soil water content data. Figure 11. Characterization and interrelation of soil water content at diverse depths. 3.3. Comparative Analysis of Prediction Accuracy against Benchmark Models In assessing the performance for five-day-ahead predictions, this study scrutinizes the distinctions in the predictive accuracy of the newly devised GRU–Transformer model relative to other established models. This comparative evaluation encompasses typical machine learning models such as Support Vector Regression (SVR [18]), K-Nearest Neighbors (KNN [40]), Gradient Boosted Decision Trees (GBDT [41]), XGBoost [42], Random Forest [21]), and deep learning models like Deep Neural Networks (DNN [27]), Convolutional Neural Networks (CNN [4]), as well as independent GRU and Transformer branches. Table 6 delineates the soil water content prediction accuracies of these various models, showcasing a spectrum of performances with MSE values ranging from 10.31% to 31.40% and R2 values spanning 42.32% to 80.27%. These results highlight the diverse capabilities and adaptability of the different models in predicting soil water content. Table 6. Comparative analysis of prediction accuracy across various models for soil water content. Upon comparing the performances of these models, the GRU–Transformer model, as proposed in this study, emerged as the most proficient, recording an MSE of 10.31% and an R2 of 80.27%. This exemplifies its superior predictive capabilities in handling complex soil moisture data. In stark contrast, the traditional KNN model fared the poorest, with an MSE of 31.40% and an R2 of merely 42.32%. The XGBoost model, known for its efficacy and popularity, yielded an MSE of 12.69% and an R2 of 75.79%, outperforming most models but still falling short of the GRU–Transformer model’s proficiency. When comparing deep learning models against traditional machine learning models, it is observed that deep learning-based models (such as CNN, LSTM, independent GRU, and Transformer branches) generally surpass their traditional counterparts. Their MSE and R2 values lie in the range of 11% to 13% and 76% to 79%, respectively, underscoring the formidable capability of deep learning in processing complex datasets. Conversely, traditional machine learning models, including SVR and GBDT, exhibit comparatively lower predictive accuracy, with significantly higher MSE and MAE values than those of deep learning models. This dichotomy accentuates the burgeoning potential of deep learning approaches in the realm of complex data analysis and prediction. In the realm of soil water content prediction, the exemplary performance of the GRU-Transformer model underscores the formidable potential of deep learning technologies in processing environmental data. The model’s capacity to surpass both traditional machine learning and other deep learning models can be primarily attributed to its unique structural composition and its enhanced capability in handling complex datasets. The GRU–Transformer model ingeniously amalgamates two cutting-edge neural network architectures: the GRU and the Transformer. This combination allows for an effective capture of long-term dependencies and intricate spatial features within time-series data. The GRU component of the model is particularly adept at processing time-series data [4], proving especially potent in comprehending and predicting the dynamically evolving nature of soil water content. Meanwhile, the Transformer branch, through its self-attention mechanism [35], excels in deciphering complex interrelationships between different data points, thereby substantially elevating the model’s prediction accuracy. In contrast to conventional machine learning models like SVR and GBDT, deep learning models demonstrate a heightened ability to manage highly nonlinear and multi-dimensional data. This study reveals that deep learning models, such as CNNs and LSTM networks, generally outperform traditional machine learning approaches, highlighting deep learning’s prowess in capturing intricate data patterns and relationships [27]. However, the GRU–Transformer model elevates this capability to a higher echelon by synergizing the strengths of both GRU and Transformer architectures. By integrating these two powerful neural network structures, their individual advantages are mutually amplified [33]. This synergistic fusion not only allows the GRU–Transformer model to surpass the accuracy of individual deep learning models but also to outshine traditional machine learning methods. This enhancement is pivotal in the context of environmental data processing, where the complexity and variability of data demand sophisticated analytical approaches. The GRU–Transformer model, with its dual-architecture advantage, thus stands as a significant advancement in the field, pushing the boundaries of what can be achieved in soil water content prediction and environmental data analysis. 3.4. Limitations and Further Study We advocate the utilization of deep learning methodologies for the intricate processing of meteorological and soil data, with the aim of achieving precise predictions of soil moisture at various depths. This approach effectively harnesses the strengths of the two models to enhance predictive outcomes. Nevertheless, this study is not devoid of limitations, which present opportunities for refinement in future endeavors. A primary shortcoming is the relatively limited dataset size, encompassing merely eight consecutive years of data from eight locations. This constraint poses a potential risk of overfitting, potentially impairing the model’s generalization capabilities. Additionally, this study did not incorporate factors such as the growth stages of maize or other agricultural management practices, including irrigation and fertilization, all of which can significantly influence soil moisture dynamics. In light of these limitations, future research directions will focus on expansion and optimization in several key areas. (1) Enlarging the dataset: Future studies will aim to broaden the dataset’s scope, encompassing data from diverse regions, encompassing different years and maize varieties. This expansion will provide a more comprehensive and varied dataset, enhancing the robustness and applicability of the model. (2) Incorporating additional variables: The inclusion of variables such as the maize’s growth stage, various agricultural management practices, and soil types will be a focal point. These additions will offer a more holistic view of the factors impacting soil moisture, thus enriching the model’s predictive accuracy. (3) Model optimization: We plan to refine the structure and parameters of the model further. This will involve exploring various combination methods and fusion strategies, with an emphasis on enhancing the model’s efficiency and stability. Through these enhancements, we aim to not only address the current study’s limitations but also significantly advance the field of soil moisture prediction using deep learning techniques, ultimately contributing to more effective and informed agricultural management. Given its demonstrated accuracy and versatility, the GRU–Transformer model holds potential for application in a range of environmental contexts, including the prediction of flash droughts, thereby contributing valuable insights for proactive disaster management and environmental preservation. 4. Conclusions This research introduces a novel hybrid modeling approach that synergizes GRU and Transformer architectures, aiming to predict soil moisture content at varying depths, specifically within the maize root zone. Utilizing meteorological and soil moisture data from eight maize cultivation sites in Hebei Province, China, spanning from 2011 to 2018, the study meticulously evaluates the model’s predictive performance across diverse input combinations and varying forecast durations. This evaluation also includes comparative analysis with conventional machine learning and other deep learning models. The findings of this study reveal distinct prediction efficacies under varying conditions. The results showed that (1) the GRU–Transformer model exhibited significant advantages under different prediction delay days and soil depth conditions. The model demonstrated the highest accuracy in the short-term prediction of 1 to 2 days, in which the mean MSE was 5.22% and the lowest reached 2.71% in the prediction with a 1-day delay, while the mean R2 was as high as 89.92%. The prediction accuracy decreased as the number of days of delay in prediction increased, but the overall performance remained stable. In addition, in the comparison of different soil depths, the model showed higher accuracy in predicting the water content of deeper soil layers, which was much better than the performance of shallow soil prediction. The methodology and experimental design adopted in the study fully considered the adaptability and robustness of the model under different environmental conditions. (2) By comparing the model performance under different combinations of input parameters, we found that the prediction error of the model rises with the decrease in parameters; however, even under the combination of only soil water content parameters, the model predicts the third day in the future with an average MSE of 0.59% and an average R2 of 98.86%, which reflects the high tolerance of the model to different combinations of parameters. (3) In comparative analysis, the GRU–Transformer model substantially outperformed a range of typical machine learning models (such as SVR, KNN, GBDT, XGBoost, and Random Forest) and deep learning models (including DNN, CNN, independent GRU, and Transformer branches). This superiority affirms the model’s exceptional capability in handling complex soil moisture data. Conclusively, this study presents a potent decision-support tool for agricultural irrigation management, contributing significantly to enhancing the efficiency and conservation of agricultural water resources. The GRU–Transformer model, with its robust predictive accuracy and adaptability, offers valuable insights for the sustainable development of agriculture, addressing critical needs in environmental data processing and agricultural resource management. Author Contributions Methodology, W.Z., J.Y. and K.Z.; investigation, K.Z. and L.G.; validation, K.Z. and J.Y.; formal analysis, J.Y.; resources, L.X.; data curation, K.Z. and L.G.; writing—original draft preparation, K.Z.; writing—review and editing, J.Y.; visualization, K.Z.; supervision, L.X., R.L. and L.Z.; project administration, J.Y.; funding acquisition, L.Z. All authors have read and agreed to the published version of the manuscript. Funding This project was supported by the National Key Research and Development Program (2022YFD1900803), the Yunnan Provincial Basic Research Plan Project (202101AT070248), the Beijing Academy of Agriculture and Forestry Sciences Youth Research Fund (QNJJ202410), and the Earmarked Fund for CARS-02 and CARS-54. Institutional Review Board Statement Not applicable. Informed Consent Statement Not applicable. Data Availability Statement Data are contained within the article. Conflicts of Interest The authors declare no conflicts of interest. References Rigden, A.; Mueller, N.; Holbrook, N.; Pillai, N.; Huybers, P. Combined Influence of Soil Moisture and Atmospheric Evaporative Demand Is Important for Accurately Predicting US Maize Yields. Nat. Food 2020, 1, 127–133. [Google Scholar] [CrossRef] [PubMed] China’s Corn Production Increases in 2021|World Grain. Available online: https://www.world-grain.com/articles/16188-chinas-corn-production-increases-in-2021 (accessed on 13 January 2024). Li, L.; Li, X.; Zheng, X.; Li, X.; Jiang, T.; Ju, H.; Wan, X. The Effects of Declining Soil Moisture Levels on Suitable Maize Cultivation Areas in Northeast China. J. Hydrol. 2022, 608, 127636. [Google Scholar] [CrossRef] Yu, J.; Xin, Z.; Xu, L.; Dong, J.; Zhangzhong, L. A Hybrid CNN-GRU Model for Predicting Soil Moisture in Maize Root Zone. Agric. Water Manag. 2020, 245, 106649. [Google Scholar] [CrossRef] Babaeian, E.; Sadeghi, M.; Jones, S.; Montzka, C.; Vereecken, H.; Tuller, M. Ground, Proximal and Satellite Remote Sensing of Soil Moisture. Rev. Geophys. 2019, 57, 530–616. [Google Scholar] [CrossRef] Simunek, J.; Van Genuchten, M.T.; Šejna, M. HYDRUS: Model Use, Calibration, and Validation. Trans. ASAE Am. Soc. Agric. Eng. 2012, 55, 1261–1274. [Google Scholar] [CrossRef] Er-Raki, S.; Ezzahar, J.; Merlin, O.; Amazirh, A.; Ait Hssaine, B.; Kharrou, H.; Khabba, S.; Chehbouni, A. Performance of the HYDRUS-1D Model for Water Balance Components Assessment of Irrigated Winter Wheat under Different Water Managements in Semi-Arid Region of Morocco. Agric. Water Manag. 2020, 244, 106546. [Google Scholar] [CrossRef] Belmans, C.; Wesseling, J.; Feddes, R. Simulation Model of the Water Balance of a Cropped Soil Providing Different Types of Boundary Conditions (SWATRE); ICW: Wageningen, The Netherlands, 1981; Volume 63. [Google Scholar] Awan, Z.; Khaliq, T.; Akhtar, M.; Imran, A.; Irfan, M.; Ahmed, M.J.; Ahmad, A. Building Climate-Resilient Cotton Production System for Changing Climate Scenarios Using the DSSAT Model. Sustain. Sci. 2021, 131, 10495. [Google Scholar] [CrossRef] Wang, Z.; Ye, L.; Jiang, J.; Fan, Y.; Zhang, X. Review of Application of EPIC Crop Growth Model. Ecol. Model. 2022, 467, 109952. [Google Scholar] [CrossRef] Zheng, W.; Zhangzhong, L.; Xin, Z.; Wang, C.; Sun, S.; Niu, H. A Review on the Soil Moisture Prediction Model and Its Application in the Information System. In Proceedings of the 11th IFIP WG 5.14 International Conference, CCTA 2017, Jilin, China, 12–15 August 2017; Springer: Cham, Switzerland, 2019; pp. 352–364, ISBN 978-3-030-06136-4. [Google Scholar] Aguilera, H.; Moreno-Merino, L.; Wesseling, J.; Jiménez-Hernández, M.; Castaño Castaño, S. Soil Moisture Prediction to Support Management in Semiarid Wetlands during Drying Episodes. Catena 2016, 147, 709–724. [Google Scholar] [CrossRef] Acharya, U.; Daigh, A.; Oduor, P. Machine Learning for Predicting Field Soil Moisture Using Soil, Crop, and Nearby Weather Station Data in the Red River Valley of the North. Soil Syst. 2021, 5, 57. [Google Scholar] [CrossRef] Fang, H.; Zhang, Y.; Wei, S.; Li, W.; Ye, Y.; Sun, T.; Weiwei, L. Validation of Global Moderate Resolution Leaf Area Index (LAI) Products over Croplands in Northeastern China. Remote Sens. Environ. 2019, 233, 111377. [Google Scholar] [CrossRef] Ahansal, Y.; Bouziani, M.; Yaagoubi, R.; Sebari, I.; Sebari, K.; Kenny, L. Towards Smart Irrigation: A Literature Review on the Use of Geospatial Technologies and Machine Learning in the Management of Water Resources in Arboriculture. Agronomy 2022, 12, 297. [Google Scholar] [CrossRef] Chen, C.; Tan, J.; Yin, J.; Zhang, F.; Yao, J. Prediction for Soil Moisture in Tobacco Fields Based on PCA and RBF Neural Network. Nongye Gongcheng Xuebao/Trans. Chin. Soc. Agric. Eng. 2010, 26, 85–90. [Google Scholar] [CrossRef] Yang, X.; Zhang, C.; Cheng, Q.; Zhang, H.; Gong, W. A Hybrid Model for Soil Moisture Prediction by Using Artificial Neural Networks. Rev. De La Fac. De Ing. 2017, 32, 265–271. [Google Scholar] Fan, J.; Yue, W.; Wu, L.; Zhang, F.; Cai, H.; Xiukang, W.; Lu, X.; Xiang, Y. Evaluation of SVM, ELM and Four Tree-Based Ensemble Models for Predicting Daily Reference Evapotranspiration Using Limited Meteorological Data in Different Climates of China. Agric. For. Meteorol. 2018, 263, 225–241. [Google Scholar] [CrossRef] Hong, Z.; Kalbarczyk, Z.; Iyer, R. A Data-Driven Approach to Soil Moisture Collection and Prediction. In Proceedings of the 2016 IEEE International Conference on Smart Computing (SMARTCOMP), St. Louis, MO, USA, 1 May 2016; pp. 1–6. [Google Scholar] Prasad, R.; Deo, R.; Li, Y.; Maraseni, T. Soil Moisture Forecasting by a Hybrid Machine Learning Technique: ELM Integrated with Ensemble Empirical Mode Decomposition. Geoderma 2018, 330, 136–161. [Google Scholar] [CrossRef] Carranza, C.; Nolet, C.; Pezij, M.; Ploeg, M. Root Zone Soil Moisture Estimation with Random Forest. J. Hydrol. 2020, 593, 125840. [Google Scholar] [CrossRef] Wu, L.; Fan, J. Comparison of Neuron-Based, Kernel-Based, Tree-Based and Curve-Based Machine Learning Models for Predicting Daily Reference Evapotranspiration. PLoS ONE 2019, 14, e0217520. [Google Scholar] [CrossRef] [PubMed] Chen, W.; Zheng, Z.; Yu, J.; Wang, C.; Huang, R. Data-Driven Calibration of Soil Moisture Sensor Considering Impacts of Temperature: A Case Study on FDR Sensors. Sensors 2019, 19, 4381. [Google Scholar] [CrossRef] [PubMed] Kim, T.-Y.; Cho, S.-B. Predicting Residential Energy Consumption Using CNN-LSTM Neural Networks. Energy 2019, 182, 72–81. [Google Scholar] [CrossRef] Khaki, S.; Wang, L.; Archontoulis, S. A CNN-RNN Framework for Crop Yield Prediction. Front. Plant Sci. 2020, 10, 1750. [Google Scholar] [CrossRef] [PubMed] Li, Q.; Zhu, Y.; Shangguan, W.; Wang, X.; Li, L.; Yu, F. An Attention-Aware LSTM Model for Soil Moisture and Soil Temperature Prediction. Geoderma 2022, 409, 115651. [Google Scholar] [CrossRef] Cai, Y.; Zheng, W.; Xin, Z.; Zhangzhong, L.; Xue, X. Research on Soil Moisture Prediction Model Based on Deep Learning. PLoS ONE 2019, 14, e0214508. [Google Scholar] [CrossRef] Sajedian, I.; Kim, J.; Rho, J. Finding the Optical Properties of Plasmonic Structures by Image Processing Using a Combination of Convolutional Neural Networks and Recurrent Neural Networks. Microsyst. Nanoeng. 2019, 5, 27. [Google Scholar] [CrossRef] Yu, Y.; Si, X.; Hu, C.; Zhang, J. A Review of Recurrent Neural Networks: LSTM Cells and Network Architectures. Neural Comput. 2019, 31, 1235–1270. [Google Scholar] [CrossRef] Chen, Y.; Bruzzone, L.; Jiang, L.; Sun, Q. ARU-Net: Reduction of Atmospheric Phase Screen in SAR Interferometry Using Attention-Based Deep Residual U-Net. IEEE Trans. Geosci. Remote Sens. 2020, 59, 5780–5793. [Google Scholar] [CrossRef] Zhong, Z.; Li, Y.; Ma, L.; Li, J.; Zheng, W.-S. Spectral-Spatial Transformer Network for Hyperspectral Image Classification: A Factorized Architecture Search Framework. IEEE Trans. Geosci. Remote Sens. 2021, 60, 1–15. [Google Scholar] [CrossRef] Shewalkar, A.N. Comparison of RNN, LSTM and GRU on Speech Recognition Data; North Dakota State University: Fargo, ND, USA, 2018. [Google Scholar] Zhang, Y.; Liu, S.; Zhang, P.; Li, B. GRU- and Transformer-Based Periodicity Fusion Network for Traffic Forecasting. Electronics 2023, 12, 4988. [Google Scholar] [CrossRef] Aloysius, N.; Madathilkulangara, G.; Nedungadi, P. Incorporating Relative Position Information in Transformer-Based Sign Language Recognition and Translation. IEEE Access 2021, 9, 145929–145942. [Google Scholar] [CrossRef] Chen, D.; Yongchareon, S.; Lai, E.; Yu, J.; Sheng, Q.; Li, Y. Transformer with Bidirectional GRU for Nonintrusive, Sensor-Based Activity Recognition in a Multiresident Environment. IEEE Internet Things J. 2022, 9, 23716–23727. [Google Scholar] [CrossRef] Yu, J.; Tang, S.; Zhangzhong, L.; Zheng, W.; Wang, L.; Wong, A.; Xu, L. A Deep Learning Approach for Multi-Depth Soil Water Content Prediction in Summer Maize Growth Period. IEEE Access 2020, 8, 199097–199110. [Google Scholar] [CrossRef] Zhai, C.; Zhou, H.; Zhao, J. Experimental Study on Inter-Annual Water Requirement and Water Consumption of Drip Irrigation Maize in North of Xinjiang. Sci. Agric. Sin. 2017, 50, 2769–2780. [Google Scholar] [CrossRef] Guo, J.-L.; Yin, G.-H.; Gu, J.; Liu, Z.-X. Determination of Irrigation Scheduling of Spring Maize in Different Hydrological Years in Fuxin, Liaoning Province Based on CROPWAT Model. Chin. J. Ecol. 2016, 35, 3428–3434. [Google Scholar] [CrossRef] Zhou, S.; Hu, X.; Wang, W.; Zhang, Y. Water-Saving and Stable Yield Effects of Regulation on Soil Wetted Depth in Different Growth Stage of Spring Maize. Trans. Chin. Soc. Agric. Eng. 2016, 32, 125–132. [Google Scholar] Ghawi, R.; Pfeffer, J. Efficient Hyperparameter Tuning with Grid Search for Text Categorization Using kNN Approach with BM25 Similarity. Open Comput. Sci. 2019, 9, 160–180. [Google Scholar] [CrossRef] Ahmadianfar, I.; Bozorg-Haddad, O.; Chu, X. Gradient-Based Optimizer: A New Metaheuristic Optimization Algorithm. Inf. Sci. 2020, 540, 131–159. [Google Scholar] [CrossRef] Chen, T.; Guestrin, C. XGBoost: A Scalable Tree Boosting System. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Francisco, CA, USA, 13 August 2016; pp. 785–794. [Google Scholar] Disclaimer/Publisher’s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.  © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Share and Cite MDPI and ACS Style Zheng, W.; Zheng, K.; Gao, L.; Zhangzhong, L.; Lan, R.; Xu, L.; Yu, J. GRU–Transformer: A Novel Hybrid Model for Predicting Soil Moisture Content in Root Zones. Agronomy 2024, 14, 432. https://doi.org/10.3390/agronomy14030432 AMA Style Zheng W, Zheng K, Gao L, Zhangzhong L, Lan R, Xu L, Yu J. GRU–Transformer: A Novel Hybrid Model for Predicting Soil Moisture Content in Root Zones. Agronomy. 2024; 14(3):432. https://doi.org/10.3390/agronomy14030432 Chicago/Turabian Style Zheng, Wengang, Kai Zheng, Lutao Gao, Lili Zhangzhong, Renping Lan, Linlin Xu, and Jingxin Yu. 2024. \"GRU–Transformer: A Novel Hybrid Model for Predicting Soil Moisture Content in Root Zones\" Agronomy 14, no. 3: 432. https://doi.org/10.3390/agronomy14030432 Note that from the first issue of 2016, this journal uses article numbers instead of page numbers. See further details here. Article Metrics Citations No citations were found for this article, but you may check on Google Scholar Article Access Statistics Article access statistics Article Views 23. Feb 28. Feb 4. Mar 9. Mar 14. Mar 19. Mar 24. Mar 29. Mar 3. Apr 0 200 400 600 800 For more information on the journal statistics, click here. Multiple requests from the same IP address are counted as one view.   Agronomy, EISSN 2073-4395, Published by MDPI RSS Content Alert Further Information Article Processing Charges Pay an Invoice Open Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors For Reviewers For Editors For Librarians For Publishers For Societies For Conference Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe to receive issue release notifications and newsletters from MDPI journals Select options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated Disclaimer Terms and Conditions Privacy Policy"

Paper 7:
- APA Citation: Belenguer-Manzanedo, M., Alcaraz, C., Martínez-Eixarch, M., & Camacho, A. (2022). Soil accretion and carbon accumulation in deltaic rice fields. Ecological Modelling, 484, 110455.
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: The progressive reduction in the suspended load of the river due to the construction of dams in the river basin marked the decrease in the annual accretion rate predicted by the model throughout the pre-dam period (Fig. 5C).
  Extract 2: During model evaluation, mineral input during the post-dam period in rice fields from riparian and salt marsh habitats was set to the current estimated mineral input (0.01 g l-1 yr-1), due to their lower SOM content, while in fields with higher SOM content (M1, M2, P1, L1 and R2), it was set to larger values (0.1 – 0.6 g l-1 yr-1).
  Limitations: - Oversimplification of the organic fraction and sand and clay content may have influenced the model's accuracy in predicting SOC stock in organic-rich and sandy soils, respectively.
- The model does not represent sediment outflows from the fields, which implies that the predicted accretion rates were slightly overpredicted.
  Relevance Evaluation: 0.9-1.0: Exceptionally relevant - Comprehensively addresses all key aspects of the point you are making in your literature review. Explains your reasoning in a maximum of 3 sentences.
  Relevance Score: 1.0
  Inline Citation: (Belenguer-Manzanedo et al., 2022)
  Explanation: This is a highly relevant paper that meets the requirements of the review's intention and objective due to its specific focus on the potential impacts of river sediment reduction on rice production in the Ebro Delta and the potential role of soil organic matter in mitigating those impacts.

 Full Text: >
"Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Keywords 1. Introduction 2. Materials and methods 3. Results 4. Discussion 5. Conclusions Funding CRediT authorship contribution statement Declaration of Competing Interest Acknowledgements Appendix. Supplementary materials Data availability References Show full outline Figures (6) Tables (4) Table 1 Table 2 Table 3 Table 4 Extras (1) Document Ecological Modelling Volume 484, October 2023, 110455 Modeling soil accretion and carbon accumulation in deltaic rice fields Author links open overlay panel María Belenguer-Manzanedo a b, Carles Alcaraz a, Maite Martínez-Eixarch a, Antonio Camacho b, James T. Morris c, Carles Ibáñez a d Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.ecolmodel.2023.110455 Get rights and content Highlights • Delta rice paddies are threatened by subsidence and rising sea levels. • Past sediment input into the Ebro Delta rice fields facilitated vertical accretion of the soil. • Soil accretion and SOC profile of paddy soils in the Ebro Delta have been modelled. • Sediment and crop residue input promotes vertical accretion and SOC accumulation. • Scenarios of sediment input to rice fields are simulated. Abstract Rice cultivation is popular in low-lying areas such as deltas, but climate change threatens the viability of the crop. In recent decades, the resilience of deltas to sea level rise (SLR) has been influenced by the reduction of sediment load from rivers due to the construction of dams, disrupting natural deposition in deltaic plains. Sediment and organic matter accumulation in wetlands are key to vertical accretion in the face of SLR and soil organic carbon (SOC) sequestration. In this sense, deltaic rice fields can retain sediments as well as wetlands and promote SOC sequestration, which is effective in adapting to SLR. In the Ebro Delta, the sediments that reached the fields through irrigation channels were used to build up and form rice fields in the wetlands of the area. We hypothesize that this sedimentation has been key to vertical accretion and SOC sequestration in rice fields. These processes were simulated by developing a process-based cohort model inspired by accretion in marsh equilibrium models (MEM). The model was able to simulate the soil carbon profile of rice fields in the Ebro Delta, based on the soil-accretion concept and considering the spatial heterogeneity of the area. Its predictions of vertical accretion and carbon content were more accurate for mineral and clay-like soils than for organic and sandy soils. Topsoil decomposition rate and organic matter content were the parameters that most influenced predictions of total vertical accretion and final soil organic carbon stock. Simulations were carried out according to future climate change scenarios, considering restoration of river sediment flux, to evaluate effects on SOC sequestration and vertical accretion in rice fields. Results showed that only with significant river sediment restoration did rice fields show positive vertical accretion, which facilitates SOC sequestration. Previous article in issue Next article in issue Keywords Coastal rice fieldSoil modelingVertical accretionSOC sequestrationSedimentsCrop management 1. Introduction Rice is often cultivated in lowlands such as deltas; thus, rising sea levels threaten production due to increasing flooding risks, coastal erosion and soil salinization (Genua-Olmedo et al., 2016; McLean et al., 2001; Nicholls et al., 2007). It is estimated that during the 21st century, up to 50 % of the emerged area of deltas will become progressively covered by the sea (Syvitski et al., 2009), impacting both socioeconomic systems in these densely populated areas and ecosystem services (Brown and Nicholls, 2015). In this sense, loss of crop productivity would decrease the soil organic carbon (SOC) sequestration capacity of rice paddies, compromising the global priority of achieving food security and mitigating climate change (Lal, 2004). Fluvial sediment input in deltas plays an important role in soil accretion and SOC sequestration through burial of organic matter, and both processes are key for maintaining the elevation of soil in relation to sea level (Day et al., 1995; Fennessy et al., 2019). One main cause of coastal erosion of deltas is construction of dams along rivers, which traps sediment and prevents its deposition in deltas, which decreases the resilience of deltas in the face of sea level rise (SLR) (Brown et al., 2018; Syvitski et al., 2005). Natural mechanisms and river-delta management options have been proposed to adapt to SLR and subsidence, such as restoring suspended loads in rivers and promoting rising grounds in delta wetlands and rice fields (Giosan et al., 2014; Ibáñez et al., 2014). In addition, restoring sediment inputs to deltas may alleviate soil salinization in rice paddies by increasing vertical accretion (Genua-Olmedo et al., 2016). In rice fields, sediment trapping has been reported (Ibáñez et al., 2014; Slaets et al., 2016), but effects of mineral and organic matter input on soil dynamics have not been thoroughly studied. Rice fields in lowlands are considered semi-natural wetlands that provide ecosystem services through mechanisms similar to those in natural wetlands and that are key for hydrological cycles, where the water that floods comes from river diversions or rain (Natuhara, 2013). In the same way that coastal wetlands can be resilient to SLR and subsidence by accumulating mineral and organic matter (Morris et al., 2002), we hypothesize that rice paddies in deltas may have a similar capacity, but using different mechanisms. In saltmarshes, the feedback between water level and soil accretion is influenced by the tidal amplitude, which interrelates optimal growth of the plant community and sediment retention capacity through plant density (Morris et al., 2002). In rice fields, the arrival of sediments from irrigation channels could promote mineral-matter accretion and C accumulation by burying crop residues or protecting deeper organic layers from decomposition due to oxidation caused by plowing (Berhe et al., 2012; Fontaine et al., 2007; Morris et al., 2004). In addition, agricultural practices related mainly to SOC sequestration (i.e., incorporating straw in the soil and producing yields) (Liu et al., 2014) can also influence vertical accretion rates. Modeling ecosystem processes allows different scenarios to be simulated and is a useful tool for predicting results of processes in response to small changes in influential factors. For agrosystems, efforts have focused more on modeling processes related to relationships among production, nutrient dynamics, greenhouse gas emissions and SOC sequestration (DNDC, CENTURY, RothC (Coleman and Jenkinson, 1996; Li, 1996; Parton et al., 1998)) and have been widely applied to different types of agrosystems and useful for predicting SOC sequestration under different scenarios (e.g. climatic, land management). However, these modeled processes focus mainly on the topsoil, with less consideration of changes in soil organic carbon (SOC) stock that may occur in it and in the subsoil (Falloon and Smith, 2010). For example, one sub-model of RothC simulates subsoil SOM dynamics below the topsoil, focusing on vertical C movements (Jenkinson and Coleman, 2008); however, RothC does not simulate sedimentation factors related to SOM stabilization, even though it is an important mechanism in soil SOC sequestration (Chmura et al., 2003). The aim of this study was to develop a model of rice field soil dynamics based on the Marsh Equilibrium Model (MEM) (Morris et al., 2002), modified to reflect rice field conditions. The specific goals of this study were to 1) model soil dynamics in deltaic rice fields considering both soil organic and mineral matter, 2) simulate past soil accretion of representative deltaic rice fields undergoing progressive reduction of sediment inputs from irrigation channels and 3) predict future soil dynamics (i.e. SOC sequestration capacity and vertical accretion) under different scenarios of sediment input recovery, organic matter decomposition rate and crop yield. We used the model to simulate SOC sequestration and accretion rates in Ebro Delta rice fields because rice production is endangered by salt intrusion driven by SLR. Use of this model may help plan measures to adapt rice production in deltas to climate change. 2. Materials and methods 2.1. Study area The Ebro Delta is an important area for rice cultivation (ca. 21,000 ha) and one of the most valuable coastal wetlands in western Europe. In the last 150 years, rice farming has transformed the landscape by converting up to 87 % of the natural wetlands (e.g. coastal lagoons, marshes, salt meadows, peatlands and riverine forests) (Benito et al., 2014). At present, 65 % of the emerged delta area is devoted to rice, while 15 % is urban areas and 20 % remains natural wetlands. The Ebro River is one of the most important tributaries to the Mediterranean Sea. It is the river with highest discharge in Spain (415 m3 s-1 annual mean), although this discharge shows a decreasing trend and high interannual variability between dry and wet years. During the past century, construction of dams for hydroelectric and irrigation purposes reduced its mean flow by up to 40 %. In addition, construction of dams in the 1960s in the lower Ebro (ca. 100 km upstream of the delta) reduced the suspended load by 99 % (Rovira and Ibàñez, 2007), thus preventing downstream transport and deposition of the sediments in the deltaic plain. Before dam construction, the hydrological connectivity through irrigation channels to the rice fields played a crucial role in sediment input to the Ebro Delta rice fields, first facilitating their creation in saltmarsh areas and then promoting their productivity via nutrient inputs and soil accretion. Rice in the Ebro Delta is cultivated in a single growing season, starting when the fields are flooded at the end of April, followed by sowing in early May and ending with harvest in September-October (followed by incorporating straw into the soil in October-November). Rice fields are irrigated by gravity through a network of irrigation channels fed by the Ebro River during the growing season and part of the fallow season. Post-harvest practices have been changing due to a variety of agri-environmental policies. Before the 1990s, each farmer decided how to manage straw, with burning being the most popular practice. Since the 1990s, however, incorporation of straw into the soil has been encouraged. In addition, from 1996 to 2015, flooding of fields in autumn and winter was promoted to favor waterfowl. Currently, each farmer decides whether to flood fields after harvest. Mean rice yield increased from ca. 4,000 to 6,000 kg ha-1 after chemical fertilizers and pesticides were introduced; however, annual yield varies widely, ranging from 5,000 to 10,000 kg ha-1 (Encuesta sobre Superficies y Rendimientos Cultivos [ESYRCE], 2023). 2.2. Soil data Eight rice fields were selected as representative of the converted wetland habitats in order to cover deltaic spatial heterogeneity: coastal lagoons (L1), saltmarshes (S1, S2), peatlands (P1), salt meadows (M1, M2) and riparian environments (R1, R2) (Fig. 1). Data on vertical SOC distribution and bulk density were obtained from soil cores 55 mm in diameter and up to 1 m deep. Bulk density was determined every 2 cm when the soil was compact, whereas in loose soils, such as the topsoil (0 – 20 cm) or those subsoil layers with sandy textures, a homogenized subsample was taken. SOC was determined by elemental analysis (FlashSmart Thermofisher). In addition, soil texture data was available every 10 cm. See Table 1 for a detailed description of the soils. Download : Download high-res image (1MB) Download : Download full-size image Fig. 1. Map of the study site with sampling points. Shadowed areas refer to the potential area of the wetland ecosystems before rice production (Benito et al., 2014). Table 1. Soil physical-chemical properties of sampling points. TS: topsoil (0–20 cm); SS: subsoil (20–50 cm); SOC: soil organic carbon; BD: bulk density. Field Geographic coordinates Converted habitat SOC (%) BD (g cm-3) Clay (%) Silt (%) Sand (%) TS SS TS SS TS SS TS SS TS SS R1 40.706833 N 0.633501 E Riparian 1.15 – 1.83 0.35 – 0.91 0.93 – 2.90 1.08 – 2.46 29 20 – 29 44 43 – 51 27 28 – 29 R2 40.712755 N 0.771201 E Riparian 1.63 – 3.47 0.46 – 1.88 1.03 – 1.47 0.75 – 2.41 19 16 – 25 41 39 – 54 40 21 – 45 S1 40.706833 N 0.633501 E Salt marsh 1.37 – 3.01 0.37 – 1.04 0.77 – 1.39 1.06 – 1.75 7 2 – 7 9 2 – 6 84 87 – 93 S2 40.755939 N 0.801327 E Salt marsh 1.60 – 2.97 0.47 – 1.20 1.04 – 1.54 1.32 – 1.75 24 8 – 22 28 4 – 51 48 27 – 88 M1 40.743939 N 0.641601 E Salt meadow 2.00 – 2.29 1.56 – 2.22 0.96 – 0.98 0.72 – 2.68 34 30 – 33 35 30 – 31 31 36 – 40 M2 40.783744 N 0.686113 E Salt meadow 2.00 – 2.51 1.65 – 2.88 0.88 – 1.30 0.83 – 1.91 21 21 – 28 29 29 – 38 50 36 – 50 L1 40.664996 N 0.67487 E Coastal lagoon 1.47 – 3.35 0.90 – 1.81 0.98 – 1.37 1.06 – 1.14 7 6 – 10 15 4 – 16 78 76 – 90 P1 40.670248 N 0.616601 E Peatland 3.42 – 5.04 1.32 – 5.64 0.38 – 1.05 0.33 – 1.34 24 25 – 41 43 34 – 35 33 25 – 41 2.3. Model description The model is process-oriented and cohort-structured, inspired by the marsh cohort model and Marsh Equilibrium Model (MEM) (Morris and Bowden, 1986; Morris et al., 2002), and specifically designed to assess the influence of biomass and sediment deposition in vertical accretion and SOC sequestration in rice fields. Soil accretion is driven by sediment inputs transported through irrigation channels and inputs of organic matter from crop biomass residues (straw and roots). The model developed simulates soil accretion from parent soils that existed before wetland conversion for rice production (ca. 100 years ago in the Ebro Delta). Three modules were developed –topsoil, subsoil and parent soil– which we attributed to different layers of soil accretion after wetland conversion (Fig. 2). The modules were developed based on effects of agricultural practices on soil structure and the inputs and outputs of organic and mineral matter specific to each layer, which influences the formation and transformation of cohorts within each module. In this way, external and internal inputs are identified and quantified. External inputs include sediment from the river (topMinei, j) and the residual biomass of the crop (topSOMi, j), which is added to the topsoil module. Internal inputs refer to the transfer of organic and mineral matter between the modules. Therefore, each cohort consists of a pool of soil organic matter (SOM) and mineral matter (Fig. 2). Download : Download high-res image (371KB) Download : Download full-size image Fig. 2. Diagram of the crop soil accretion and cohort structure of the model. SOM: soil organic matter. 2.3.1. Dynamics of soil accretion Soil accretion is based on the gradual accumulation of organic and mineral matter in natural wetlands, as influenced by plowing of the topsoil, which disturbs the deposition order and homogenizes the topsoil. Accretion is reflected by the formation of new subsoil layers below the topsoil due to an increase in the depth of the topsoil (dZj) that exceeds the plowing depth. Thus, in each time step (j), a new subsoil cohort (i) is formed based on the balance of inputs of crop residues and sediments and outputs from decomposition (Table 2, Eq. 1). Table 2. Equations used to simulate biological and physical processes of soil accretion in a crop system. i: age and layer, j: year or time step. Processes Equation Notation in the text Vertical change: dZj Eq. 1 New subsoil layer formation (dZ ≥ 0) Eq. 2 Organic Cohort in Subsoil: subSOMi,j Mineral Cohort in Subsoil: subMinei,j Reincorporation from subsoil to topsoil dZ ≤ 0 Eq. 3 Subsoil Organic Cohort depleted: subSOMi,j+1 Subsoil Mineral Cohort depleted: subMinei,j+1 Reincorporation of organic fraction: topSOMi,j Reincorporation of Mineral Fraction: topMinei,j SOM decomposition Eq. 4 Topsoil SOM decomposition Subsoil SOM decomposition Crop residue input Straw input: Sj Eq. 5 Root input: Rj Eq. 6 Mineral Input to the fields: MIj Eq. 7 Pre-dam period Eq. 8 Post-dam period SOC stock Eq. 9 Bulk Density: BDi,j Eq. 10 Organic matter content: LOIi,j Eq. 11 BDi,j [g cm-3]: Bulk density of the soil; dZ [cm]: Annual depth change of topsoil layer; fs [proportion]: Proportion of the straw that is incorporated in the soil; HI [proportion]: Harvest index k’1 [proportion]: SOM fraction that remains annually in topsoil; k’2 [proportion]: SOM fraction that remains annually in subsoil; kr[proportion]: Root biomass fraction that remains after one year; ks [proportion]: Straw biomass fraction that remains in the field after one year; Lj [g yr-1]: Annual river suspended load; LOIi,j[%]: SOM content calculated as loss on ignition; MI 1,j [g cm-2]: Annual mineral input in the field; PD [cm]: Plowing layer depth; q[l s-1 ha-1]: Rice field inflow; Qj [l yr-1]: Annual mean river discharge; Rj [g cm-2]: Root biomass input; Rp[proportion]: Proportion of roots compared to the dry weight of aboveground biomass; Sj [g cm-2]: Straw biomass input; SOC Stock [kg m-2]: Accumulated SOC; subMine i,j [g cm-2]: Mineral content in subsoil layer; subSOM i,j [g cm-2]: SOM content in subsoil layer; topMine1, j [g cm-2]: Mineral content in topsoil; topSOM1, j [g cm-2]: SOM content in topsoil; Yj [g cm-2]: Annual yield; δ1 [g cm-3]: Organic matter bulk density; δ2 [g cm-3]: Mineral matter bulk density. Cohort dimensions are defined dynamically by the inputs and outputs. The dimension is represented as a soil volume with a horizontal area of 1 cm2 times a variable depth. For topsoil, depth equals the plowing depth (1 cm2 × depth), which is determined by the depth to which the layer is homogenized. Subsoil depth varies and is determined by the annual change in depth of the topsoil (dZ) and the parent soil, whose depth is assumed to be infinite (Fig. 2). The contents of organic and mineral matter in topsoil and subsoil layers vary dynamically depending on dZj. If dZj exceeds 0, a new subsoil cohort will be created with a depth equal to dZj. The new subsoil cohort consists of organic and mineral portions (subSOMi, j, subMinei, j)), which contain proportional pools of the topsoil cohort (topSOM1, j and topMinei, j, respectively) (Table 2, Eq. 2). If the topsoil volume is less than the volume of the plowing depth (when input < output), the missing volume is taken from the subsoil cohort in order from shallowest to deepest, and may reach the parent soil, until the topsoil volume is filled to equal the volume of the plowing depth (Table 2, Eq. 3). 2.3.2. Soil organic matter decomposition For SOM decomposition, a single compartment of heterogeneous SOM decomposition was chosen, (Table 2, Eq. 4). Thus, the proportion of SOM that remains after one year is determined by a constant decomposition rate (k). For topsoil and subsoil cohorts, the range of k was set to represent different decomposition dynamics (and C stability), with higher rates for topsoil modules and lower rates for subsoil modules, based on differences in decomposition rates in agrosystems (Bayer et al., 2006), which vary as a function of soil properties and agricultural management (Rumpel and Kögel-Knabner, 2010; Six et al., 2002). The rates set for SOM decomposition were taken from the literature and ranged from 0.900 to 0.990 yr−1 (Koch and Stockfisch, 2006) for the topsoil (k’1) and 0.990 – 0.999 yr−1 for the subsoil (k’2), assuming that increasing depth acts as a stabilization mechanism that decreases decomposition rates (Qin et al., 2019) (Table 3). Table 3. Summary of model parameters and values used in simulations. Input parameter Values References Initial soil organic matter [%] 1, 4, 7, 10, 13, 16, 19, 22, 25, 30 Fennessy et al. (2019); Genua-Olmedo et al. (2022) MI [g cm-2] 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6 This study k’1 0.90, 0.93, 0.95, 0.97, 0.99 (Koch and Stockfisch, 2006) k’2 0.990, 0.993, 0.995, 0.997, 0.999 Assumed from Qin et al. (2019) Y [g m-2] 100, 200, 400, 600, 800, 1000, 1200 This study fs [proportion] 0, 0.2, 0.4, 0.6, 0.8, 1 This study fs [proportion]: Proportion of the straw that is incorporated in the soil; k’1 [proportion]: SOM fraction that remains annually in topsoil; k’2 [proportion]: SOM fraction that remains annually in subsoil; MI 1,j [g cm-2]: Annual mineral input in the field; Yj [g cm-2]: Annual yield. 2.3.3. Organic matter input: crop yield and residue management Organic inputs in the form of crop residues (straw (Sj) and roots (Rj)) are derived from the annual yield (Yj), the proportion of the straw remaining after one year of decomposition and the amount of straw incorporated in the soil. The range of Yj was based on reported yields (500 – 1000 g m-2) (Genua-Olmedo et al., 2022; Fabregat, 2006) but expanded to 100 – 1200 g m-2 to test model sensitivity. Annual straw incorporation was calculated from Yj by applying a harvest index (HI) of 0.5, which is the proportion of dry grain biomass in aboveground dry biomass from a previous study of Ebro Delta rice fields (Belenguer-Manzanedo et al., 2022). The straw remaining after one year of decomposition (ks) was set to 0.4 based on previous studies of rice straw decomposition rates in the Ebro Delta (Forès et al., 1988). In addition, straw management practices were represented by a straw incorporation factor (fs) (Table 2, Eq. 5). For the current study, two periods were distinguished based on past agri-environmental measures. Before 1990, because farmers decided how to manage straw, fs was set to a value from 0 to 1 to represent variability in management (i.e., burning, animal grazing or incorporation) (Table 3). After 1990, because all straw remained in the field, ks was set to 1. For the amount of root biomass incorporated into the soil after one year (Rj), the proportion of root biomass was derived from the yield according to an agronomic index (root proportion (Rp)(Huang et al., 2007)) multiplied by the proportion of biomass that remains after one year of decomposition (kr) (Table 2, Eq. 6). Root proportion kr was assumed to equal 0.7 (Abiven et al., 2005; Lu et al., 2003). Since rice fields were created in different wetland habitats, the initial amount of SOM was set using field data to consider heterogeneity in SOM content. Based on data from Fennessy et al. (2019) for wetland soils in the Ebro Delta, within the range of the initial SOM content of the parent soil (1 – 30 %), the lowest SOM contents (1 – 7 %), which correspond to mineral soils, were related to converted marshes and riparian ecosystems, while higher SOM contents (15 – 30 %) were related to converted lagoon or peatland ecosystems. The organic fraction was estimated as loss on ignition (Table 2, Eq. 11). A conventional van Bemmelen factor of 1.724 was applied assuming that organic matter contains 58 % of organic C. 2.3.4. Mineral input Mineral input (MIj) refers to the amount of sediment deposited each year in the field. MIj in Ebro Delta rice fields was assumed to be proportional to the suspended load carried by the river. The annual load deposited was obtained by dividing the Ebro River's annual suspended load (Lj) by its annual runoff (Qj) (Table S1), obtained from the database of the Ebro River basin authority (CHE). It was then multiplied by a constant inflow rate to the field (q) which was set to 1.7 l s-1 based on previous observations (unpublished data) to obtain the mineral input per unit area in the rice field (Table 2, Eq. 7). In the past 100 years, due to dam construction in the Ebro River basin, the suspended load and flow of the Ebro River have decreased greatly (Rovira et al., 2015). Consequently, two periods of suspended load were assessed: pre-dam (1914 – 1970), in which the suspended load progressively decreased, and post-dam (1971 – 2014), in which the suspended load remained low and constant (Fig. 3). The suspended load was set according to a linear regression for the pre-dam period and to a constant value for the post-dam period (Table 2, Eq. 8). Additionally, higher mineral inputs were tested for MIc (Table 2) to consider other sediment requirements (e.g., to compensate for SLR and simulated future scenarios of sediment recovery through sediment bypass in the reservoirs (Genua-Olmedo et al., 2022; Rovira and Ibàñez, 2007)). Download : Download high-res image (451KB) Download : Download full-size image Fig. 3. Ebro River annual discharge (Q) (bars) and estimated mineral input in rice fields (dots) per year from 1914 to 2014. The dashed line shows the linear regression for the period before dam construction. 2.4. Model predictions 2.4.1. Soil organic carbon stock The SOC stock was predicted separately for the topsoil and each subsoil layer (Table 2, Eq. 9). To this end, bulk density was calculated using the mixing model of Morris et al. (2016) (Table 2, Eq. 10). The bulk densities of organic (δ1) and mineral matter (δ2) measured in marsh soils of the coastal United States (0.085 and 1.99 g cm-3, respectively) were used to estimate the organic fraction as loss on ignition (Table 2, Eq. 11). As before, a conventional van Bemmelen factor of 1.724 was applied. Comparison between predicted and observed SOC stocks was restricted to a depth of 50 cm. If predicted accretion was less than 50 cm, i.e., total depth of the topsoil and the increment of each subsoil layer (dZ), the missing volume was filled using the volume taken from the parent soil (initialized at the beginning of the simulation). 2.4.2. Vertical accretion Vertical accretion equaled the sum of the organic and mineral volumes of each module minus the volume taken from the parent soil when dZ < 0. The annual accretion rate equaled the total volume divided by the number of time steps (i.e., 100 in this study). 2.5. Model calibration and evaluation The model was calibrated using simulations that combined six input parameters whose values were selected according to the available bibliography and our own data (Table 3). The model was then evaluated based on comparing observed and predicted SOM profiles. Performance was assessed in two steps. First, observed and simulated SOC profiles for each field were compared. Simulations were selected when the Pearson correlation coefficient (r) between observed and predicted SOC profiles exceeded 0.69 and the slope of the regression between them ranged from 0.85 to 1.15. Second, the degree of support for each candidate simulation was determined using the second-order Akaike Information Criterion (AICc). AICc was then rescaled for each field (i.e. soil core) by selecting the simulations with ΔAICc ≤ 4 (Burnham et al., 2011). Finally, the input parameters that yielded the most accurate predictions of the observed SOC profile for each core were compared according to physical-chemical and biogeographical properties. The sensitivity of model predictions was analyzed for representative simulations of rice field establishment in the Ebro Delta. Vertical accretion, annual accretion rate, change in SOC content in the topsoil and final SOC stock were evaluated by combining the parameters k’1, initial SOM and mineral input. 2.6. Scenario projection: changes in grain yield, decomposition rate and mineral input as a function of initial SOM content Crop yield, the topsoil organic matter decomposition rate, mineral input and initial SOM content were combined to simulate possible effects of climate change, such as changes in soil respiration or soil salinization, which influence both decomposition rates and rice productivity. Rice-yield scenarios were set to 600 – 800 g m-2 to represent current yields and 200 – 400 kg m-2 to represent 50 % losses in order to represent effects of factors that threaten production, such as higher soil salinity due to SLR (Genua-Olmedo et al., 2016). For the topsoil organic matter decomposition rate, low and high decomposition scenarios were represented by setting k’1 to 0.95 – 0.99 or 0.90 – 0.95, respectively, the latter to simulate increases in temperature that are expected to increase SOM decomposition (Kirschbaum, 1995). Finally, differences in mineral input were simulated in four scenarios –very low (i.e., current input), low, moderate and high (0.01, 0.1 – 0.2, 0.3 – 0.4 and 0.5 – 0.6 g cm-2, respectively)– to simulate partial restoration of sediment transport (suspended load) by implementing sediment bypass systems in the lower Ebro River reservoirs (Rovira and Ibáñez, 2007). All scenarios were run for 100 years starting with an initial SOM content of 3 %, 6 %, 9 % or 12 % to represent the SOM contents of current rice paddies. The baseline scenario is set as 0.01 g cm-2 mineral inputs and 600 – 800 g m-2 of crop production combined with all decomposition and initial SOM values. 3. Results 3.1. Model evaluation A total of 7,900 out of 110,250 simulations met the selection conditions between predicted and observed SOC content A total of 928 simulations were selected as very likely (ΔAICc < 4), of which 798 corresponded to profile L1, and 6–64 corresponded to each of the remaining profiles (Table 4). Prediction accuracy was higher for soil profiles R1, R2, M1 and S1 than for profiles P1, L1, M2 and S2 (Table 4). The selected simulations showed a narrow range for each of the six input parameters, except for the subsoil decomposition rate (Table 4). In this sense, initial SOM matter was low (1 % and 4 %) for profiles with more mineral parent soils, such riparian (R1, and R2) and saltmarsh (S1) habitats (Table 1), and ranged from 4 to 22 % in the well-predicted M1 profile (salt meadow). For profiles with lower accuracy (i.e., higher ΔAICc), such as organic-rich soils of P1 (peatland), L1 (lagoon) and M2 (salt meadow) (Table 4), the initial SOM contents selected showed a wider range and higher values, from 7, 1 and 4 % of initial SOM, respectively, up to 30 %. Table 4. Model calibration results, selected input parameters and model predictions. Empty Cell Field Empty Cell R1 R2 S1 S2 M1 M2 L1 P1 Calibration results Total no. of models 1834 1334 178 29 680 883 2725 240 Models selected (AICc ≤ 4) 6 7 12 9 16 16 798 64 Intercept -0.14 – 0.21 -0.09 – 0.61 -0.14 – 0.16 0.39 – 0.84 -1.3 – -0.77 -1.37 – -0.66 -0.04 – 6.75 -3.34 – -1.61 AIC range -29.1 – -26.9 -17.7 – 13.9 -14.8 – -10.9 5 – 8.8 -21.1 – -17.2 -6.71 – -2.9 -5.4 – -1.4 17.1 – 21.1 AIC weights 0.83 0.62 0.83 0.82 0.52 0.54 0.71 0.73 Parameters selected Initial soil organic matter 1 4 1 10 – 25 4 – 22 4 – 30 1 – 30 7 – 30 Mineral input (MI) 0.01 0.2 – 0.4 0.01 0.01 0.5 – 0.6 0.1 – 0.4 0.1 – 0.3 0.01 – 0.4 k’1 0.90 – 0.93 0.95 – 0.99 0.90 – 0.99 0.93 – 0.97 0.90 – 0.95 0.93 – 0.99 0.93 – 0.99 0.95 – 0.99 k’2 0.990 – 0.999 0.990 – 0.999 0.990 – 0.999 0.990 – 0.995 0.990 – 0.999 0.990 – 0.999 0.990 – 0.999 0.990 – 0.999 Crop yield (Y) 1000 – 1200 600 – 1200 200 – 1200 600 – 1200 600 – 1200 400 – 800 600 – 1200 100 – 600 Straw incorporation rate (ks) 0.6 – 0.8 0.2 –1 0.6 – 1 0.8 – 1 0.2 – 0.6 0 – 1 0 – 1 0 – 1 Model predictions Maximum depth 43.7 – 47.9 52 – 56.9 43.1 – 46 33.8 – 41.5 45.3 –46.8 35 – 46.4 37.1 –88.1 34 – 36 Accretion rate (mm yr-1) 2.3 – 2.8 3.4 – 3.7 2.3 – 2.6 1.4 – 2.2 2.5 – 2.7 1.5 – 2.6 1.7 – 6.8 1.4 – 1.6 SOC stock (kg m-2) 5.18 – 6.82 7.26 –10.68 4.92 – 6.07 11.55 – 12.82 4.36 – 7.60 5.59 – 11.31 5.73 – 17.73 7.14 – 13.44 k’1 [proportion]: SOM fraction that remains annually in topsoil; k’2 [proportion]: SOM fraction that remains annually in subsoil; SOC: soil organic carbon. The mineral inputs content selected for the post-dam construction period were the most accurate for profiles S1, S2 and R1, set to 0.01 g cm-2 which coincides with current estimated mineral input (Table 4; Fig. 3). For field M1, the mineral input was higher (0.5 – 0.6 g cm-2), while P1, M2, L1 and R2 showed a wider range, with intermediate mineral inputs (0.01 – 0.4 g cm-2), all of them related to higher SOM content in the field. The range of topsoil decomposition rate varied among fields (with an unclear relation to the other modeled parameters) but did not differ (0.990 – 0.999) among subsoil decomposition rate profiles (Table 4). Crop yield ranged mainly from 600 to 1200 g m-2 (current range), and only P1 had a narrower range (100 – 400 g m-2). The straw incorporation fraction also showed field-specific ranges: R1, R2, S1 and S2 varied from 0.6 to 1, M1 and P1 from 0.2 to 0.6, and L1 and M2 showed the full range (i.e., 0 – 1). 3.2. Predicted SOC stocks and vertical accretion Predicted SOC stocks for all profiles ranged 5 – 18 kg m-2 (Table 4) and tended to be slightly underpredicted, except for that of S2, which was overpredicted (Fig. 4). Accuracy of predicted SOC stock differed between the topsoil vs. subsoil, being higher for the subsoil for R1, R2, M2, S1 and P1. Among subsoil layers, SOC stock was underpredicted for M1, but overpredicted for S2 and L1. Predicted SOC stock in the topsoil was the most accurate in profiles R2, S2 and L1. SOC stock was underpredicted to a similar degree for topsoil profiles R1, S1, R2, L1 and S2, while predicted SOC stocks for M1, M2 and P1 were one-third to one-half observed SOC stocks (Fig. 4). Download : Download high-res image (358KB) Download : Download full-size image Fig. 4. Predicted (boxplots) and observed (points) soil organic carbon (SOC) stock for (A) all soil (0 – 50 cm), (B) topsoil (0 – 20 cm) and (C) subsoil (20 – 50 cm). Whiskers represent 1.5 times the interquartile range. Predicted vertical accretion rates for the past 100 years ranged from 1.4 to 6.8 mm yr-1 (Table 4), with a mean of 3.4 mm yr-1. Both mineral-dominated (R1, R2, S1) and soils with higher mineral input (M1, L1) had more vertical accretion. Soils with initial SOM content of 1 – 4 % had 43 – 57 cm of vertical accretion, while soils with initial SOM content > 7 % had 34 – 47 cm (Table 4). 3.3. Sensitivity analysis of SOC stocks and vertical accretion Changes in organic and mineral matter inputs due to sediment reduction and straw incorporation influenced the accretion rate and total SOC content of soil profiles (Fig. 5A and E). The SOM decomposition rate in the topsoil (k’1) was the variable that influenced vertical accretion and total SOC stock the most (Fig. 5A, B and E). Vertical accretion ranged from 30 to 45 cm and 45 – 60 for k’1 = 0.90 and 0.99, respectively, in 100-year simulations (Fig. 5A and B). The accretion rate also decreased as the initial SOM content in the parent soil increased (Fig. 5C). Download : Download high-res image (431KB) Download : Download full-size image Fig. 5. Model predictions for Ebro Delta rice paddy soils. A) Vertical soil organic carbon (SOC) profile after 100 years with topsoil loss rate (k'1) of (A) 0.90 (brown) or (B) 0.99 (blue); C) Dynamics of vertical accretion rates over time; D) Dynamics of topsoil SOC content over time; E) Accumulated SOC stock after 100 years. Brown colors are for k'1 = 0.9, blue for k'1 = 0.99. Light and dark colors represent initial soil organic matter of 1 % and 10 %, respectively. Dashed lines are for post-dam-period mineral input = 0.01 g cm-2, solid lines for mineral input = 0.3 g cm-2. In the simulations, during the pre-dam period (1914 – 1970), when several dams were built in the upper and middle parts of the basin, accretion rate clearly decreased following the progressive reduction in mineral inputs (Fig. 5C). During the post-dam period (1970 – 2014), when three large dams were built in the lower Ebro River, the drastic reduction in sediment input (ca. 0.01 g yr-1) prevented soil accretion. However, the generalization of straw incorporation after 1990 promoted an increase in accretion rate of ca. 0.1 cm yr-1, which was also influenced by the SOM decomposition rate (Fig. 5C). The C content in the entire profile and the final SOC stock (Fig. 5E) were influenced by the decomposition rate: decreasing k’1 from 0.99 to 0.90 increased SOC sequestration by 3.5 and 5.0 times for mineral inputs of 0.01 and 0.3, respectively. For k’1 = 0.99, SOC stock differences were positively influenced by initial C content, thus SOC stock was higher in more organic soils, regardless of mineral input. However, for k’1 = 0.90 (i.e. higher decomposition rate), final SOC stock was higher in soils with lower initial SOM content but higher mineral input (Fig. 5). The amount of SOC in the topsoil decreased rapidly as initial SOM content increased and until the input of organic and mineral matter equaled their output (Fig. 5D). In addition, in soils with low initial SOM content, SOC dynamics depended on the decomposition rate. For k’1 = 0.90, SOC content decreased until equilibrium, whereas for k’1 = 0.99, SOC content increased. The increase in organic matter input due to straw incorporation gradually increased topsoil SOC content. Finally, a decrease in mineral input from 0.3 to 0.01 during the post-dam period decreased SOC content in the topsoil, although in both cases a gradual increase was predicted over the last 40 years (Fig. 5D). 3.4. Vertical accretion and SOC stock projections under different management scenarios In the baseline scenario (i.e., 0.01 g cm-2 mineral inputs and 600 – 800 g m-2 of crop production), vertical accretion was positive in mineral soils with low decomposition rates, but the change in elevation was lower (even becoming negative) in scenarios with high decomposition rates and more organic soils (Fig. 6A). Increasing mineral input from 0.01 g cm-2 (i.e., post-dam period) to 0.5 – 0.6 g cm-2 (i.e., pre-dam period or future restoration of sediment transport in the river), predictions changed from a mean decrease in elevation (-0.69 ± 1.3 mm yr-1) to vertical accretion (3.16 ± 0.81 mm yr-1). High decomposition rates resulted in accretion rates that were one-fifth as high under steady yields and one-third as high with a 50 % yield loss. Under the scenario of 50 % yield loss, the mean accretion rate was 0.19 ± 1.76 mm yr-1, one-sixth that under current crop yields, regardless of the decomposition rate. Download : Download high-res image (520KB) Download : Download full-size image Fig. 6. Mean model predictions for vertical accretion and soil organic carbon (SOC) stock after 100 years under different conditions of initial soil organic matter (SOM), mineral input, crop yield and topsoil organic carbon decomposition rate (k’1). Graphs are arranged vertically by lowest to highest mineral input: very low (0.01 g cm-2), low (0.1 – 0.2 g cm-2), moderate (0.3 – 0.4 g cm-2) and high (0.5 – 0.6 g cm-2). Graphs are divided horizontally by crop yield (steady (600 – 800 g m-2) vs. loss (200 – 400 g m-2) and again by k’1 (low (0.95 – 0.99) vs. high (0.90 – 0.95)). Asterisks indicate no increase in SOC stock. Error bars are the standard error. Under current conditions of mineral input, SOC stock would increase if current crop yields are maintained and decomposition rates are low. Regardless of the mineral input, the model predicted a mean SOC stock of 10.9 ± 1.2 kg m-2 with a lower decomposition rate and steady yields, but 4.6 ± 0.6 and 5.0 ± 0.4 kg C m-2 with a high decomposition rate or 50 % yield loss, respectively. In the worst-case scenario (50 % yield loss and high decomposition rate), SOC stocks were predicted to increase only at higher accretion rates averaging 1.91 ± 0.26 kg SOC m-2. 4. Discussion 4.1. Model fitness and limitations The model was calibrated to cover the spatial and temporal variability of the Ebro Delta rice field landscape considering 1) different initial SOM contents, related to the natural habitat before rice field establishment; 2) the decrease in sediment deposition transported by irrigation channels, caused by dam construction; 3) different rates of SOM decomposition and 4) differences in organic matter input, related to yields and agricultural management (straw incorporation). One novel feature of the model is the redistribution of organic and mineral matter in the soil profile due to plowing. Plowing influences not only the topsoil but can also expose subsoil C, which redistributes SOM profile (Baker et al., 2007; Olson and Al-Kaisi, 2015). Soils with higher SOM content are more sensitive to exposure of subsoil C by plowing due to subsidence by compaction of the soil. Subsidence in rice fields occurs the most in peatland-derived soils (Hoogland et al., 2012; Knotters et al., 2022). In this sense, the initial SOM content is important since it influences the vertical accretion rate and SOC stock. Thus, initial SOM content is related to the productivity and soil properties of the habitats that were converted into rice fields; thus, SOM content is higher in rice fields converted from peatlands, salt meadows and coastal lagoons, and lower in those converted from riparian vegetation and salt marshes (Fennessy et al., 2019; Morant et al., 2020). During model calibration, the initial SOM contents selected for the parent soils were consistent with the pre-existing reclaimed ecosystems, with lower contents selected for rice fields close to the river and in marshes (R1, R2 and S1) than for those in grasslands, coastal lagoons or peatlands (M2, L1 and P1). The accuracy of predicted SOM profiles was higher for soils with lower SOM content and a clay texture than for soils with a higher SOM or sand content. In organic-rich soils such as P1, M1 and M2, total SOC stocks were underpredicted, but most of the differences were due to predictions of the topsoil in contrast, total SOC stocks in sandy subsoils such as S2 and L1 were greatly overpredicted. These differences in model accuracy appear to be due to oversimplified modeling of the organic fraction, which would decrease the model's accuracy in predicting the SOC stock. Many factors such as particle size, nitrogen availability, soil moisture, temperature and SOM composition are normally included in SOC models that simulate biogeochemical C cycles, since they mediate both fresh organic matter inputs and SOM decomposition (see DNDC, CENTURY or Roth-C (Coleman and Jenkinson, 1996; Li, 1996; Parton et al., 1998)). These factors are related to SOM stabilization mechanisms such as the formation of micro- and macro-aggregates and organo-mineral associations that protect against bacterial decomposition (Cotrufo et al., 2019, 2013; Kallenbach et al., 2016; Six et al., 2004). Physical-chemical properties of organic soils favor the formation of micro-aggregates and organo-mineral associations, in which the presence of clay is associated with greater SOC recalcitrance (Kallenbach et al., 2016), which would explain the underprediction of SOC stocks in clay and peatland-derived soils. In this sense, sand and clay content may determine SOM decomposition rates (Angst et al., 2021). In comparison, we also attribute the overpredicted SOC stocks in sandy soils to oversimplification of the processes involved in C stabilization. In this case, sandy soils generally have a lower capacity for C stabilization due to the mineral properties of sand and the more porous soil structure, which provides less protection of SOM and easier leaching of organo-mineral colloids (Six et al., 2002; Zhang and He, 2004). Specifically for the Ebro Delta, soil texture is one of the factors influenced by the amount of organic matter in the entire profile and should be included in future versions of the model. The other novel feature of the model is the consideration of sediment input, which influences vertical accretion and SOC dynamics in rice fields. Predictions of total vertical accretion, which included inputs of organic matter (influenced by decomposition rates) and mineral matter, ranged from 1.4 to 6.8 mm yr-1, which lie in the range of 2.5 – 4.1 mm yr-1 reported by Ibáñez et al. (1997). This accretion considers changes in sediment transport during the period of paddy rice expansion in the Ebro Delta. The progressive reduction in the suspended load of the river due to the construction of dams in the river basin marked the decrease in the annual accretion rate predicted by the model throughout the pre-dam period (Fig. 5C). Likewise, natural wetlands of the Ebro Delta have also shown higher accretion in the medium term than in the short term, which is attributed to the construction of the dams (Fennessy et al., 2019). In addition, Ibáñez et al. (1997) estimated accretion rates of 4.7 – 7.4 mm yr-1 before dam construction and -0.2 mm yr-1 after dam construction based on suspended mineral load in rice-field drainage channels. In this sense, another limitation of the model is that it does not represent sediment outflows from the fields. This implies that the predicted accretion rates were slightly overpredicted, but they still lay within observed ranges. During model evaluation, mineral input during the post-dam period in rice fields from riparian and salt marsh habitats was set to the current estimated mineral input (0.01 g l-1 yr-1), due to their lower SOM content, while in fields with higher SOM content (M1, M2, P1, L1 and R2), it was set to larger values (0.1 – 0.6 g l-1 yr-1). Higher input of mineral matter into rice field soils with higher SOM content is explained in part by inputs of sediment to rice fields by some farmers to compensate for subsidence, avoid saline intrusion and facilitate agricultural work. In this context, soils with higher SOM content are more sensitive to subsidence or salinization; thus, farmers are likely to add sediment directly after insufficient arrival of sediment from the river, which justifies the larger values of mineral input selected. In contrast, more mineral or elevated soils, such as those derived from marshes (S1, S2) and close to the river (R1), do not have these problems (saline intrusion or swampy fields); thus, the sediment input comes only from irrigation and equals estimates based on suspended load in the river. 4.2. Soil accretion in rice fields The sensitivity analysis under Ebro Delta conditions (i.e., sediment reduction, spatial heterogeneity and straw incorporation) showed that parameters related to SOM strongly influenced the predicted accretion and final SOC sequestration rates. The decomposition rate was the main factor that influenced SOC content and accretion rate. The increase in the decomposition rate decreased accretion and SOC sequestration, but the initial SOM content influenced this effect. Total accretion after SOM decomposition was lower in soils with higher SOM content, since the SOM occupies more volume in the soil matrix than mineral matter (Morris et al., 2016; Neubauer, 2008). In this sense, crop management has been identified as key process to decrease SOM decomposition, which causes C loss and subsidence (Hatala et al., 2012; Knox et al., 2015). Thus, control of SOM decomposition in agricultural soils, which is determined largely by crop management, may strongly influence soil accretion (Bai et al., 2019). Increasing organic matter input by incorporating all crop residues can increase annual accretion rates; however, maintaining the accretion rate will depend on the stability of the newly incorporated organic matter and SOM (i.e., reducing decomposition rates). Incorporating residues (i.e., organic matter) into cropland soils has not been reported to promote soil accretion, but it does promote adaptation to SLR, as is the case for organic matter production and accumulation in marshes that bears most of the accretion (Calvo-Cubero et al., 2013; Neubauer, 2008). In addition, sediments help stabilize SOM (Neubauer, 2008). Given the similarity of accretion mechanisms in natural wetlands and rice fields, minimizing the decomposition of incorporated crop residues, along with the sediments input, would promote vertical accretion and SOC sequestration. Comparing soil formation in rice fields and natural wetlands of the Ebro Delta, observed vertical accretion is similar in both: 3.3 ± 1.1 mm yr-1 in rice fields vs. 4.8 ± 3.2 and 3.0 ± 2.2 mm yr-1 in brackish and saline wetlands, respectively (Fennessy et al., 2019). SOC sequestration rates in the Ebro Delta range from 204 ± 104 to 207 ± 183 g C m-2 yr-1 for brackish and saline wetlands (Fennessy et al., 2019), respectively, but have been lower compared to our estimations in rice fields over the past century (103.5 ± 33.3 g C m-2 yr-1). The lower SOC sequestration in rice fields than in wetlands could be attributed to crop management, since rice fields have primary productivity (851 – 968 g m-2 yr-1; calculated from Belenguer-Manzanedo et al. (2022)) similar to the mean primary productivity for brackish and saline wetlands (981 g m-2 yr-1; Curcó et al., 2002). This relative similarity between rice fields and wetlands suggests that sediment inputs to rice fields strongly influence vertical accretion and thus resilience in adapting to SLR across the delta. Thus, soil accretion through the organic matter accumulation and sediment input of rice cultivation could be proposed as an ecosystem service provided by lowland rice fields considered as semi-natural wetlands (Chivenge et al., 2020; Natuhara, 2013). 4.3. Implications for adaptation to climate change Climate change is expected to influence C sequestration in terrestrial ecosystems (Bai et al., 2019). Under current conditions, the predicted annual vertical accretion rate in the Ebro Delta rice fields was 2 mm yr-1; thus, predicted SOC sequestration would be ca. 60 – 120 g C m-2 yr-1, which lies within the range of the rates observed in California rice fields (84 – 283 g C m-2 yr-1; Hatala et al., 2012) and in the Ebro Delta (109 – 197 g C m-2 yr-1; Belenguer-Manzanedo et al., 2022). Rising temperatures are expected to increase soil respiration, which will increase loss of SOC and reduce the capacity for SOC sequestration (Crowther et al., 2016). Considering scenarios of a loss of 5 – 10 % of SOM per year, simulations predicted that SOC sequestration tends to zero under the baseline scenario of very low mineral input (Fig. 6). Regarding SLR effects, the current accretion rate (2 mm yr-1) would not compensate for the relative SLR of 7 mm yr-1 that is occurring in the Ebro Delta (Ibáñez et al., 2010). Consequently, soil salinity is expected to increase and cause rice yields to decrease (Genua-Olmedo et al., 2016). In this context, the model predicted that crop yield reductions of up to 50 % would result in no soil SOC sequestration in rice fields (Fig. 6). Therefore, it is crucial to increase sediment input to rice fields to ensure enough vertical accretion to avoid loss of production due to soil salinization and thereby ensure SOC sequestration capacity. Besides increasing rice productivity, incorporating all crop residues and implementing measures to reduce SOM decomposition would support positive accretion rates and be in line with proposed measures to increase SOC sequestration (Lychuk et al., 2021; Pareek, 2017). Predictions of this model indicate that mineral inputs would need to be restored to ensure SOC sequestration in the future. To cope with low sediment input, implementation of sediment bypass systems has been proposed in the lower Ebro reservoirs (Rovira and Ibàñez, 2007). In the Ebro Delta, cost estimates of flushing sediments downriver to counteract SLR range from 0.73 to 2.5 million € per year (Genua-Olmedo et al., 2022). In this sense, it may be advisable to prioritize sediment input in fields that have lower elevation and are more vulnerable to loss of SOC sequestration capacity, such as those closer to the coast and/or those with more organic soils, since the latter especially have lower predicted accretion rates and are more vulnerable to loss of SOC sequestration capacity (Fig. 6). In addition, restoring wetland habitats in the most vulnerable rice fields could be an effective measure to promote SOC sequestration and address SLR, since it has been shown that accretion in rice fields transformed back into wetlands can be as high as 1 cm yr-1, mainly due to accumulation of organic matter after establishment of plant communities (Calvo-Cubero et al., 2013). Therefore, due to the heterogeneity of the Ebro Delta landscape, application of management measures would be advisable with field-specific planning, for instance considering a field's SOM content, soil physical-chemical properties and elevation. 5. Conclusions A soil accretion model that predicts vertical accretion and SOC sequestration in rice paddies as a function of sediment deposition and crop production was developed to assess future impacts that threaten rice cultivation in deltas. Model predictions were more accurate for rice fields with low SOM content, suggesting that the model should be improved to better simulate soil dynamics in rice fields with higher SOM content and a sandier texture. We related inaccuracies to oversimplified SOC dynamics and suggest representing SOC-stabilization processes in more detail in future versions. To maintain rice-crop viability and SOC sequestration, crop management should adopt measures that simultaneously promote further stabilization and accumulation of organic matter and restore sediment inputs. Based on simulated projections of future sediment input after restoring sediment transport in the river, future rice-yield scenarios impacted by SLR and SOM losses due to rising temperatures suggest that restoring sediment inputs is key in the Ebro Delta system to promote SOC sequestration. Funding This study was supported by the Spanish Ministry of Economy and Competitiveness through the National Institute for Agricultural and Food Research and Technology (INIA) [grant no. RTA2014-00058-C03-03]; Life EBRO-ADMICLIM [grant no. ENV/ES/001182] granted to C.I.;Agencia Estatal de Investigación [grant no. PID 2019-104742RB-I00] granted to A.C.; FPI-INIA Predoctoral Scholarship from the Spanish Ministry of Science, Innovation and Universities, INIA [grant no. CPD2016-0059] granted to M.B-M and US NSF Award [grant no. 1654853] granted to J.T.M. CRediT authorship contribution statement María Belenguer-Manzanedo: Conceptualization, Software, Validation, Visualization, Investigation, Formal analysis, Methodology, Writing – original draft. Carles Alcaraz: Writing – review & editing, Software, Methodology, Supervision. Maite Martínez-Eixarch: Writing – review & editing, Investigation, Supervision. Antonio Camacho: Writing – review & editing, Funding acquisition. James T. Morris: Writing – review & editing, Software, Methodology. Carles Ibáñez: Conceptualization, Writing – review & editing, Funding acquisition. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgements The authors thank Lluís Jornet, Pep Cabanes, David Mateu and Nil Álvarez (IRTA-Marine and continental waters) for technical support in sampling and analysis assessment. We also acknowledge the logistical support provided by Kellogg's Origins Program and the farmers in this program for allowing us to sample their fields. The authors thank the reviewers of this manuscript for their valuable comments. Appendix. Supplementary materials Download : Download Word document (50KB) Data availability Data will be made available on request. References Abiven et al., 2005 S. Abiven, S. Recous, V. Reyes, R. Oliver Mineralisation of C and N from root, stem and leaf residues in soil and role of their biochemical quality Biol. Fertil. Soils, 42 (2) (2005), p. 119, 10.1007/s00374-005-0006-0 View in ScopusGoogle Scholar Angst et al., 2021 G. Angst, J. Pokorný, C.W. Mueller, I. Prater, S. Preusser, E. Kandeler, et al. Soil texture affects the coupling of litter decomposition and soil organic matter formation Soil Biol. Biochem., 159 (2021), Article 108302, 10.1016/j.soilbio.2021.108302 View PDFView articleView in ScopusGoogle Scholar Bai et al., 2019 X. Bai, Y. Huang, W. Ren, M. Coyne, P.A. Jacinthe, B. Tao, et al. Responses of soil carbon sequestration to climate-smart agriculture practices: a meta-analysis Glob. Chang. Biol., 25 (8) (2019), pp. 2591-2606, 10.1111/gcb.14658 View in ScopusGoogle Scholar Baker et al., 2007 J.M. Baker, T.E. Ochsner, R.T. Venterea, T.J. Griffis Tillage and soil carbon sequestration—what do we really know? Agric. Ecosyst. Environ., 118 (1) (2007), pp. 1-5, 10.1016/j.agee.2006.05.014 View PDFView articleView in ScopusGoogle Scholar Bayer et al., 2006 C. Bayer, T. Lovato, J. Dieckow, J.A. Zanatta, J. Mielniczuk A method for estimating coefficients of soil organic matter dynamics based on long-term experiments Soil Tillage Res., 91 (1) (2006), pp. 217-226, 10.1016/j.still.2005.12.006 View PDFView articleView in ScopusGoogle Scholar Belenguer-Manzanedo et al., 2022 M. Belenguer-Manzanedo, C. Alcaraz, A. Camacho, C. Ibáñez, M. Català-Forner, M. Martínez-Eixarch Effect of post-harvest practices on greenhouse gas emissions in rice paddies: flooding regime and straw management Plant Soil (2022), 10.1007/s11104-021-05234-y Google Scholar Benito et al., 2014 X. Benito, R. Trobajo, C. Ibáñez Modelling habitat distribution of mediterranean coastal wetlands: the Ebro Delta as case study Wetlands, 34 (4) (2014), pp. 775-785, 10.1007/s13157-014-0541-2 View in ScopusGoogle Scholar Berhe et al., 2012 A.A. Berhe, J.W. Harden, M.S. Torn, M. Kleber, S.D. Burton, J. Harte Persistence of soil organic matter in eroding versus depositional landform positions J. Geophys. Res.: Biogeosciences, 117 (G2) (2012), 10.1029/2011JG001790 Google Scholar Brown and Nicholls, 2015 S. Brown, R.J. Nicholls Subsidence and human influences in mega deltas: the case of the Ganges–Brahmaputra–Meghna Sci. Total Environ., 527-528 (2015), pp. 362-374, 10.1016/j.scitotenv.2015.04.124 View PDFView articleView in ScopusGoogle Scholar Brown et al., 2018 S. Brown, R.J. Nicholls, A.N. Lázár, D.D. Hornby, C. Hill, S. Hazra, et al. What are the implications of sea-level rise for a 1.5, 2 and 3°C rise in global mean temperatures in the Ganges-Brahmaputra-Meghna and other vulnerable deltas? Reg. Environ. Change, 18 (6) (2018), pp. 1829-1842, 10.1007/s10113-018-1311-0 View in ScopusGoogle Scholar Burnham et al., 2011 K.P. Burnham, D.R. Anderson, K.P. Huyvaert AIC model selection and multimodel inference in behavioral ecology: some background, observations, and comparisons Behav. Ecol. Sociobiol. (Print), 65 (1) (2011), pp. 23-35, 10.1007/s00265-010-1029-6 View in ScopusGoogle Scholar Calvo-Cubero et al., 2013 J. Calvo-Cubero, C. Ibáñez, A. Rovira, P. Sharpe, E. Reyes Mineral versus organic contribution to vertical accretion and elevation change in restored marshes (Ebro Delta, Spain) Ecol. Eng., 61 (2013), pp. 12-22, 10.1016/j.ecoleng.2013.09.047 View PDFView articleView in ScopusGoogle Scholar Chivenge et al., 2020 P. Chivenge, O. Angeles, B. Hadi, C. Acuin, M. Connor, A. Stuart, et al. Chapter 10 - ecosystem services in paddy rice systems L. Rusinamhodzi (Ed.), The Role of Ecosystem Services in Sustainable Food Systems, Academic Press (2020), pp. 181-201 View PDFView articleGoogle Scholar Chmura et al., 2003 G.L. Chmura, S.C. Anisfeld, D.R. Cahoon, J.C. Lynch Global carbon sequestration in tidal, saline wetland soils Global Biogeochem. Cycles, 17 (4) (2003), p. n/a-n/a, 10.1029/2002gb001917 Google Scholar Coleman and Jenkinson, 1996 K. Coleman, D.S. Jenkinson RothC-26.3 - A Model For the Turnover of Carbon in Soil Berlin, Heidelberg (1996) Google Scholar Cotrufo et al., 2019 M.F. Cotrufo, M.G. Ranalli, M.L. Haddix, J. Six, E. Lugato Soil carbon storage informed by particulate and mineral-associated organic matter Nat. Geosci., 12 (12) (2019), pp. 989-994, 10.1038/s41561-019-0484-6 View in ScopusGoogle Scholar Cotrufo et al., 2013 M.F. Cotrufo, M.D. Wallenstein, C.M. Boot, K. Denef, E. Paul The microbial efficiency-matrix stabilization (MEMS) framework integrates plant litter decomposition with soil organic matter stabilization: do labile plant inputs form stable soil organic matter? Glob. Chang. Biol., 19 (4) (2013), pp. 988-995, 10.1111/gcb.12113 View in ScopusGoogle Scholar Crowther et al., 2016 T.W. Crowther, K.E.O. Todd-Brown, C.W. Rowe, W.R. Wieder, J.C. Carey, M.B. Machmuller, et al. Quantifying global soil carbon losses in response to warming Nature, 540 (7631) (2016), pp. 104-108, 10.1038/nature20150 View in ScopusGoogle Scholar Curcó et al., 2002 A. Curcó, C. Ibàñez, J.W. Day, N. Prat Net primary production and decomposition of salt marshes of the Ebre Delta (Catalonia, Spain) Estuaries, 25 (3) (2002), pp. 309-324 View in ScopusGoogle Scholar Day et al., 1995 J.W. Day, D. Pont, P.F. Hensel, C. Ibañez Impacts of sea-level rise on deltas in the Gulf of Mexico and the Mediterranean: the importance of pulsing events to sustainability Estuaries, 18 (4) (1995), pp. 636-647, 10.2307/1352382 View in ScopusGoogle Scholar Fabregat, 2006 E. Fabregat L’impacte de l’arròs. El delta de l’Ebre a la dècada de 1860 Onada Edicions (2006) Google Scholar Falloon and Smith, 2010 P. Falloon, P. Smith Modelling soil carbon dynamics Soil Carbon Dyn.: Integr. Methodol. (2010), pp. 221-244, 10.1017/CBO9780511711794.013 View in ScopusGoogle Scholar Fennessy et al., 2019 M.S. Fennessy, C. Ibáñez, J. Calvo-Cubero, P. Sharpe, A. Rovira, J. Callaway, N. Caiola Environmental controls on carbon sequestration, sediment accretion, and elevation change in the Ebro River Delta: implications for wetland restoration Estuar. Coast Shelf Sci., 222 (2019), pp. 32-42, 10.1016/j.ecss.2019.03.023 View PDFView articleView in ScopusGoogle Scholar Fontaine et al., 2007 S. Fontaine, S. Barot, P. Barre, N. Bdioui, B. Mary, C. Rumpel Stability of organic carbon in deep soil layers controlled by fresh carbon supply Nature, 450 (7167) (2007), pp. 277-280, 10.1038/nature06275 View in ScopusGoogle Scholar Forès et al., 1988 E. Forès, M. Menendez, F.A. Comín Rice straw decomposition in rice-field soil Plant Soil, 109 (1988), pp. 145-146, 10.1007/bf02197596 View in ScopusGoogle Scholar Genua-Olmedo et al., 2016 A. Genua-Olmedo, C. Alcaraz, N. Caiola, C. Ibáñez Sea level rise impacts on rice production: the Ebro Delta as an example Sci. Total Environ., 571 (2016), pp. 1200-1210, 10.1016/j.scitotenv.2016.07.136 View PDFView articleView in ScopusGoogle Scholar Genua-Olmedo et al., 2022 A. Genua-Olmedo, S. Temmerman, C. Ibáñez, C. Alcaraz Evaluating adaptation options to sea level rise and benefits to agriculture: the Ebro Delta showcase Sci. Total Environ., 806 (2022), Article 150624, 10.1016/j.scitotenv.2021.150624 View PDFView articleView in ScopusGoogle Scholar Giosan et al., 2014 L. Giosan, J. Syvitski, S. Constantinescu, J. Day Climate change: protect the world's deltas Nature, 516 (7529) (2014), pp. 31-33, 10.1038/516031a View in ScopusGoogle Scholar Hatala et al., 2012 J.A. Hatala, M. Detto, O. Sonnentag, S.J. Deverel, J. Verfaillie, D.D. Baldocchi Greenhouse gas (CO2, CH4, H2O) fluxes from drained and flooded agricultural peatlands in the Sacramento-San Joaquin Delta Agric. Ecosyst. Environ., 150 (2012), pp. 1-18, 10.1016/j.agee.2012.01.009 View PDFView articleView in ScopusGoogle Scholar Hoogland et al., 2012 T. Hoogland, J.J.H. van den Akker, D.J. Brus Modeling the subsidence of peat soils in the Dutch coastal area Geoderma, 171-172 (2012), pp. 92-97, 10.1016/j.geoderma.2011.02.013 View PDFView articleView in ScopusGoogle Scholar Huang et al., 2007 Y. Huang, W. Zhang, W. Sun, X. Zheng Net primary production of Chinese croplands from 1950 to 1999 Ecol. Appl., 17 (3) (2007), pp. 692-701, 10.1890/05-1792 View in ScopusGoogle Scholar Ibáñez et al., 1997 C. Ibáñez, A. Canicio, J. Day, A. Curcó Morphologic development, relative sea level rise and sustainable management of water and sediment in the Ebre Delta, Spain J. Coast. Conserv., 3 (1) (1997), pp. 191-202, 10.1007/bf02905244 Google Scholar Ibáñez et al., 2014 C. Ibáñez, J. Day, E. Reyes The response of deltas to sea-level rise: natural mechanisms and management options to adapt to high-end scenarios Ecol. Eng., 65 (2014), pp. 122-130, 10.1016/j.ecoleng.2013.08.002 View PDFView articleView in ScopusGoogle Scholar Ibáñez et al., 2010 C. Ibáñez, P. Sharpe, J. Day, J. Day, N. Prat Vertical accretion and relative sea level rise in the Ebro Delta Wetlands (Catalonia, Spain) Wetlands, 30 (2010), pp. 979-988, 10.1007/s13157-010-0092-0 View in ScopusGoogle Scholar Jenkinson and Coleman, 2008 D. Jenkinson, K. Coleman The turnover of organic carbon in subsoils. Part 2. Modelling carbon turnover Eur. J. Soil Sci., 59 (2) (2008), pp. 400-413 CrossRefView in ScopusGoogle Scholar Kallenbach et al., 2016 C.M. Kallenbach, S.D. Frey, A.S. Grandy Direct evidence for microbial-derived soil organic matter formation and its ecophysiological controls Nat. Commun., 7 (1) (2016), p. 13630, 10.1038/ncomms13630 View in ScopusGoogle Scholar Kirschbaum, 1995 M.U.F. Kirschbaum The temperature dependence of soil organic matter decomposition, and the effect of global warming on soil organic C storage Soil Biol. Biochem., 27 (6) (1995), pp. 753-760, 10.1016/0038-0717(94)00242-S View PDFView articleView in ScopusGoogle Scholar Knotters et al., 2022 M. Knotters, K. Teuling, A. Reijneveld, J.P. Lesschen, P. Kuikman Changes in organic matter contents and carbon stocks in Dutch soils, 1998–2018 Geoderma, 414 (2022), Article 115751, 10.1016/j.geoderma.2022.115751 View PDFView articleView in ScopusGoogle Scholar Knox et al., 2015 S.H. Knox, C. Sturtevant, J.H. Matthes, L. Koteen, J. Verfaillie, D. Baldocchi Agricultural peatland restoration: effects of land-use change on greenhouse gas (CO2 and CH4) fluxes in the Sacramento-San Joaquin Delta Glob. Chang. Biol., 21 (2) (2015), pp. 750-765, 10.1111/gcb.12745 View in ScopusGoogle Scholar Koch and Stockfisch, 2006 H.J. Koch, N. Stockfisch Loss of soil organic matter upon ploughing under a loess soil after several years of conservation tillage Soil Tillage Res., 86 (1) (2006), pp. 73-83, 10.1016/j.still.2005.02.029 View PDFView articleView in ScopusGoogle Scholar Lal, 2004 R. Lal Soil carbon sequestration impacts on global climate change and food security Science, 304 (5677) (2004), pp. 1623-1627, 10.1126/science.1097396 View in ScopusGoogle Scholar Li, 1996 C. Li The DNDC model Paper presented at the Evaluation of Soil Organic Matter Models, Berlin, Heidelberg (1996) Google Scholar Liu et al., 2014 C. Liu, M. Lu, J. Cui, B. Li, C. Fang Effects of straw carbon input on carbon dynamics in agricultural soils: a meta-analysis Glob. Chang. Biol., 20 (2014), 10.1111/gcb.12517 Google Scholar Lu et al., 2003 Y. Lu, A. Watanabe, M. Kimura Carbon dynamics of rhizodeposits, root- and shoot-residues in a rice soil Soil Biol. Biochem., 35 (9) (2003), pp. 1223-1230, 10.1016/S0038-0717(03)00184-6 View PDFView articleView in ScopusGoogle Scholar Lychuk et al., 2021 T.E. Lychuk, R.L. Hill, R.C. Izaurralde, B. Momen, A.M. Thomson Evaluation of climate change impacts and effectiveness of adaptation options on nitrate loss, microbial respiration, and soil organic carbon in the Southeastern USA Agric. Syst., 193 (2021), Article 103210, 10.1016/j.agsy.2021.103210 View PDFView articleView in ScopusGoogle Scholar McLean et al., 2001 McLean, R., Tsyban, A., Burkett, V., Codignotto, J.O., Forbes, D., Mimura, N., et al. (2001). Coastal zones and marine ecosystems. In (pp. 343–379). Google Scholar Morant et al., 2020 D. Morant, A. Picazo, C. Rochera, A.C. Santamans, J. Miralles-Lorenzo, A. Camacho-Santamans, et al. Carbon metabolic rates and GHG emissions in different wetland types of the Ebro Delta PLoS ONE, 15 (4) (2020), Article e0231713, 10.1371/journal.pone.0231713 View in ScopusGoogle Scholar Morris et al., 2004 D.R. Morris, R.A. Gilbert, D.C. Reicosky, R.W. Gesch Oxidation potentials of soil organic matter in histosols under different tillage methods Soil Sci. Soc. America J., 68 (3) (2004), pp. 817-826, 10.2136/sssaj2004.8170 View in ScopusGoogle Scholar Morris et al., 2016 J.T. Morris, D.C. Barber, J.C. Callaway, R. Chambers, S.C. Hagen, C.S. Hopkinson, et al. Contributions of organic and inorganic matter to sediment volume and accretion in tidal wetlands at steady state Earth's Future, 4 (4) (2016), pp. 110-121, 10.1002/2015EF000334 View in ScopusGoogle Scholar Morris and Bowden, 1986 J.T. Morris, W. Bowden A mechanistic, numerical model of sedimentation, mineralization and decomposition for marsh sediments Soil Sci. Soc. America J., 50 (1986), pp. 996-1105 Google Scholar Morris et al., 2002 J.T. Morris, P.V. Sundareshwar, C.T. Nietch, B. Kjerfve, D.R. Cahoon Responses of coastal wetlands to rising sea level Ecology, 83 (10) (2002), pp. 2869-2877, 10.1890/0012-9658(2002)083[2869:Rocwtr]2.0.Co;2 View in ScopusGoogle Scholar Natuhara, 2013 Y. Natuhara Ecosystem services by paddy fields as substitutes of natural wetlands in Japan Ecol. Eng., 56 (2013), pp. 97-106, 10.1016/j.ecoleng.2012.04.026 View PDFView articleView in ScopusGoogle Scholar Neubauer, 2008 S.C. Neubauer Contributions of mineral and organic components to tidal freshwater marsh accretion Estuar. Coast. Shelf Sci., 78 (1) (2008), pp. 78-88, 10.1016/j.ecss.2007.11.011 View PDFView articleView in ScopusGoogle Scholar Nicholls et al., 2007 R.J. Nicholls, P.P. Wong, V.R. Burkett, J.O. Codignotto, J.E. Hay, R. McLean, et al. Coastal systems and low-lying areas. Climate change 2007: impacts, adaptation and vulnerability Coastal Systems and Low-lying Areas In: Climate Change 2007: Impacts, Adaptation and Vulnerability (2007) Google Scholar Olson and Al-Kaisi, 2015 K.R. Olson, M.M. Al-Kaisi The importance of soil sampling depth for accurate account of soil organic carbon sequestration, storage, retention and loss Catena, 125 (2015), pp. 33-37, 10.1016/j.catena.2014.10.004 View PDFView articleView in ScopusGoogle Scholar Pareek, 2017 N. Pareek Climate change impact on soils: adaptation and mitigation MOJ Eco Environ. Sci., 26 (3) (2017) Google Scholar Parton et al., 1998 W.J. Parton, M. Hartman, D. Ojima, D. Schimel DAYCENT and its land surface submodel: description and testing Glob. Planet. Change, 19 (1) (1998), pp. 35-48, 10.1016/S0921-8181(98)00040-X View PDFView articleView in ScopusGoogle Scholar Qin et al., 2019 S. Qin, L. Chen, K. Fang, Q. Zhang, J. Wang, F. Liu, et al. Temperature sensitivity of SOM decomposition governed by aggregate protection and microbial communities Sci. Adv., 5 (7) (2019), p. eaau1218, 10.1126/sciadv.aau1218 View in ScopusGoogle Scholar Rovira and Ibàñez, 2007 A. Rovira, C. Ibàñez Sediment management options for the lower Ebro River and its delta J. Soils Sediments, 7 (5) (2007), pp. 285-295, 10.1065/jss2007.08.244 View in ScopusGoogle Scholar Rovira et al., 2015 A. Rovira, C. Ibáñez, J.P. Martín-Vide Suspended sediment load at the lowermost Ebro River (Catalonia, Spain) Quaternary Int., 388 (2015), pp. 188-198, 10.1016/j.quaint.2015.05.035 View PDFView articleView in ScopusGoogle Scholar Rumpel and Kögel-Knabner, 2010 C. Rumpel, I. Kögel-Knabner Deep soil organic matter—A key but poorly understood component of terrestrial C cycle Plant Soil, 338 (1–2) (2010), pp. 143-158, 10.1007/s11104-010-0391-5 Google Scholar Six et al., 2004 J. Six, H. Bossuyt, S. Degryze, K. Denef A history of research on the link between (micro)aggregates, soil biota, and soil organic matter dynamics Soil Tillage Res., 79 (1) (2004), pp. 7-31, 10.1016/j.still.2004.03.008 View PDFView articleView in ScopusGoogle Scholar Six et al., 2002 J. Six, R.T. Conant, E.A. Paul, K. Paustian Stabilization mechanisms of soil organic matter: implications for C-saturation of soils Plant Soil, 241 (2) (2002), pp. 155-176, 10.1023/A:1016125726789 View in ScopusGoogle Scholar Slaets et al., 2016 J.I.F. Slaets, P. Schmitter, T. Hilger, T.D. Vien, G. Cadisch Sediment trap efficiency of paddy fields at the watershed scale in a mountainous catchment in northwest Vietnam Biogeosciences, 13 (11) (2016), pp. 3267-3281, 10.5194/bg-13-3267-2016 View in ScopusGoogle Scholar Syvitski et al., 2005 J.P. Syvitski, C.J. Vörösmarty, A.J. Kettner, P. Green Impact of humans on the flux of terrestrial sediment to the global coastal ocean Science, 308 (5720) (2005), pp. 376-380, 10.1126/science.1109454 View in ScopusGoogle Scholar Syvitski et al., 2009 J.P.M. Syvitski, A.J. Kettner, I. Overeem, E.W.H. Hutton, M.T. Hannon, G.R. Brakenridge, et al. Sinking deltas due to human activities Nat. Geosci., 2 (10) (2009), pp. 681-686, 10.1038/ngeo629 Google Scholar Zhang and He, 2004 M. Zhang, Z. He Long-term changes in organic carbon and nutrients of an ultisol under rice cropping in southeast China Geoderma, 118 (3) (2004), pp. 167-179, 10.1016/S0016-7061(03)00191-5 View PDFView articleView in ScopusGoogle Scholar Cited by (0) View Abstract © 2023 Elsevier B.V. All rights reserved. Recommended articles PESTIPOND: A descriptive model of pesticide fate in artificial ponds: II. Model application and evaluation Ecological Modelling, Volume 484, 2023, Article 110472 Aya Bahi, …, Julien Tournebize View PDF ‘metrix’: An R package for assessing the biological quality of water Ecological Modelling, Volume 484, 2023, Article 110473 Juan M. Cabrera, Julieta Capeletti View PDF Markov chain retrospective analysis or how to detect a position of the monitoring period in the course of postfire succession Ecological Modelling, Volume 484, 2023, Article 110478 Dmitrii O. Logofet, Alexander A. Maslov View PDF Show 3 more articles Article Metrics Captures Readers: 6 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply."

Paper 8:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: "Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Abstract Keywords 1. Introduction 2. Importance of small millets and scope for their improvement 3. Factors limiting the yield and productivity of small millets 4. Biotic factors affecting small millets 5. Antinutrient content in small millet grains 6. Genetic and genomic resources 7. Dissecting climate-resilient and nutritional traits in small millets 8. Next-generation tools for trait improvement in small millets 9. Biofortification of small millets for nutritional security 10. Future of machine learning (ML) approaches for small millets improvement 11. Success stories and future prospective of millet omics Author contribution statement Funding statement Data availability statement Declaration of interest's statement Appendix A. Supplementary data References Show full outline Cited by (3) Figures (5) Tables (5) Extras (3) Download all Multimedia component 1 Multimedia component 2 figs1 Volume 9, Issue 4, April 2023, e14502 Review article Genetic enhancement of climate-resilient traits in small millets: A review Author links open overlay panel Pooja Choudhary, Pooja Shukla, Mehanathan Muthamilarasan Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.heliyon.2023.e14502 Get rights and content Under a Creative Commons license open access Abstract Agriculture is facing the challenge of feeding the ever-growing population that is projected to reach ten billion by 2050. While improving crop yield and productivity can address this challenge, the increasing effects of global warming and climate change seriously threaten agricultural productivity. Thus, genomics and genome modification technologies are crucial to improving climate-resilient traits to enable sustained yield and productivity; however, significant research focuses on staple crops such as rice, wheat, and maize. Crops that are naturally climate-resilient and nutritionally superior to staple cereals, such as small millets, remain neglected and underutilized by mainstream research. The ability of small millets to grow in marginal regions having limited irrigation and poor soil fertility makes these crops a better choice for cultivation in arid and semi-arid areas. Hence, mainstreaming small millets for cultivation and using omics technologies to dissect the climate-resilient traits to identify the molecular determinants underlying these traits are imperative for addressing food and nutritional security. In this context, the review discusses the genomics and genome modification approaches for dissecting key traits in small millets and their application for improving these traits in cultivated germplasm. The review also discusses the success stories, future aspects, and potential risks of these techniques in breeding programs for improvement in small millets. 2023 ª The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
  Extract 2: Genetic enhancement of climate-resilient traits in small millets: A review
  Limitations: The context does not provide any limitations of the paper.
  Relevance Evaluation: 0.9-1.0: The context is completely relevant to the point you are making. The provided context defines the purpose of the paper in consideration, which is to provide an overview of genetic enhancement of climate resilient traits in small millets.
  Relevance Score: 0.95
  Inline Citation: >
  Explanation: The paper titled "Genetic enhancement of climate-resilient traits in small millets: A review" provides an overview of the potential and challenges of improving small millets for climate resilience and nutritional security. It discusses the current state of research and highlights the need for further studies to increase the genetic diversity and enhance the productivity of these important crops.

 Full Text: >
"Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Abstract Keywords 1. Introduction 2. Importance of small millets and scope for their improvement 3. Factors limiting the yield and productivity of small millets 4. Biotic factors affecting small millets 5. Antinutrient content in small millet grains 6. Genetic and genomic resources 7. Dissecting climate-resilient and nutritional traits in small millets 8. Next-generation tools for trait improvement in small millets 9. Biofortification of small millets for nutritional security 10. Future of machine learning (ML) approaches for small millets improvement 11. Success stories and future prospective of millet omics Author contribution statement Funding statement Data availability statement Declaration of interest's statement Appendix A. Supplementary data References Show full outline Cited by (3) Figures (5) Tables (5) Table 1 Table 2 Table 3 Table 4 Table 5 Extras (3) Download all Multimedia component 1 Multimedia component 2 figs1 Volume 9, Issue 4, April 2023, e14502 Review article Genetic enhancement of climate-resilient traits in small millets: A review Author links open overlay panel Pooja Choudhary, Pooja Shukla, Mehanathan Muthamilarasan Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.heliyon.2023.e14502 Get rights and content Under a Creative Commons license open access Abstract Agriculture is facing the challenge of feeding the ever-growing population that is projected to reach ten billion by 2050. While improving crop yield and productivity can address this challenge, the increasing effects of global warming and climate change seriously threaten agricultural productivity. Thus, genomics and genome modification technologies are crucial to improving climate-resilient traits to enable sustained yield and productivity; however, significant research focuses on staple crops such as rice, wheat, and maize. Crops that are naturally climate-resilient and nutritionally superior to staple cereals, such as small millets, remain neglected and underutilized by mainstream research. The ability of small millets to grow in marginal regions having limited irrigation and poor soil fertility makes these crops a better choice for cultivation in arid and semi-arid areas. Hence, mainstreaming small millets for cultivation and using omics technologies to dissect the climate-resilient traits to identify the molecular determinants underlying these traits are imperative for addressing food and nutritional security. In this context, the review discusses the genomics and genome modification approaches for dissecting key traits in small millets and their application for improving these traits in cultivated germplasm. The review also discusses biofortification for nutritional security and machine-learning approaches for trait improvement in small millets. Altogether, the review provides a roadmap for the effective use of next-generation approaches for trait improvement in small millets. This will lead to the development of improved varieties for addressing multiple insecurities prevailing in the present climate change scenario. Previous article in issue Next article in issue Keywords Small milletsNutri-cerealsGenomicsGenome editingClimate resilienceCrop improvement 1. Introduction Global food security and nutritional deficiencies are the two most challenging situations for the growing human population. Crop diversification helps to a great extent to achieve food security [1]. However, changing climatic conditions significantly influence food security by limiting crop production [2]. Globally, malnutrition or hidden hunger is another major problem increasing substantially in developing countries. The annual monocrops dominating the current agricultural system, such as wheat (Triticum spp.), rice (Oryza sativa), and maize (Zea mays), are calorie-dense and require extensive inputs of pesticides and fertilizers to maintain the yield every year [3]. Additionally, human populations inhabiting Africa and Asia lack access to different food crops, and the staple crops consumed by them fall short of supplying essential micronutrients, which is the prime cause of malnutrition [4]. In this context, crop diversification is the most effective approach to improve resistance against biotic factors and tolerance to abiotic stressors, leading to food and income security for farmers [5]. Diversifying mainstream staple crops with other crops would help achieve nutritional security and sustainable agriculture goals. Considering this, millets, also known as nutri-cereals, have the potential to provide adequate macro- and micro-nutrients compared to staple crops. Millets are a rich source of dietary fibers, essential amino acids and minerals, antioxidants, trace elements, protein, fats, and carbohydrates [6]. Additionally, millets have exceptional climate resilience traits, enabling them to survive and grow in various climatic and soil conditions [7]. Their excellent nutritional profile and climate resilience features make millets known as miracle grains [1]. Despite numerous superior qualities, millets are underutilized due to the substantial focus on major cereal crops worldwide. Thus, millets are referred to as “orphan cereal crops” by the scientific community [8]. Developing novel biotechnological approaches and breeding technologies provides a platform for exploiting millets' genetic diversity and accelerating trait improvement programs. These tools have the potential to mine the gene pools of crops to identify the agronomically important traits in millet. Presently the genome sequence of several millet crops is available to hasten the progress of crop improvement programs in these crops [[9], [10], [11]]. Breeding techniques complemented by new genomic and molecular approaches offer a platform to identify candidate genes or markers associated with stress tolerance. Several omics studies have been performed in small millets to understand stress-related mechanisms [[11], [12], [13], [14], [15]]. Numerous candidate genes having roles in yield enhancement, stress resilience, and other important agronomic features have been identified in small millets [16,17]. For instance, EcHNRT2, EcLNRT1, EcNADH-NR, EcGS, EcFd-GOGAT, and EcDof1 have been identified in finger millet to develop NUE (Nitrogen use efficiency) varieties [18]. EcDehydrin7 involved in drought stress was identified in finger millet, which could be used to develop drought and heat-tolerant crops [19]. SiARDP and SiLEA14, involved in salt and drought tolerance, were functionally characterized in foxtail millet [20,21]. Still, they are waiting for further comprehensive functional characterization using advanced biotechnological tools. Novel genome editing tools, such as zinc-finger nucleases (ZFNs), transcription activator-like effector nucleases (TALENs) and CRISPR/Cas, have been developed to revolutionize the crop improvement approaches [22]. However, the use of these technologies in small millets is yet to be standardized. Studies on different small millets have provided information about their phenotypic diversity, climate resilience features, genome-wide SNP markers, and the heritability of different important traits and markers for genetic diversity. However, these marker data have not been exploited successfully for improved variety development, and low yield remains a challenge for small millet cultivation. Currently, the advancement in genomics and genome modification technologies and computer-based approaches enables the application of novel tools for the varietal improvement of small millets. In this context, the review discusses current trends of next-generation tools and their application for small millet improvement. The review also discusses the success stories, future aspects, and potential risks of these techniques in breeding programs for improvement in small millets. 2. Importance of small millets and scope for their improvement ‘Small millets,’ also known as minor millets, is a generic name for coarse cereals, mainly cultivated in rain-fed areas of arid and semi-arid zones [8]. It includes foxtail millet (Setaria italica), barnyard millet (Echinochloa crusgalli), finger millet (Eleusine coracana), proso millet (Panicum miliaceum), little millet (Panicum sumatrense), kodo millet (Paspalum scrobiculatum), teff (Eragrostis tef), Job's tears (Coix lacryma-jobi), fonio (Digitaria exilis), browntop millet (Urochloa ramosa), and guinea millet (Brachiaria deflexa) [8,23]. Small millets belong to the Poaceae family but are superior to other major cereals in terms of nutritional qualities, climate resilience, and other agronomical traits. In addition, millets have excellent water-use and nitrogen-use efficiencies that help them survive under water-deficit conditions in rain-fed regions [24]. Given this, millets have a minimum dependency on irrigation and nitrogen fertilizers for better yield [25]. Due to their nutritional superiority and climate resilience features, small millets can supplement staple cereal crops. They are rich in micro- and macro-nutrients, proteins, essential amino acids, dietary fiber, and resistant starch (Table 1). In addition, small millets also have rich contents of phytochemicals, viz., alkaloids, flavonoids, phenolics, and saponins [26]. For example, kodo millet has the maximum content of phenolic compounds (10.3%), and finger millet is rich in reducing sugars (391.3 mg/g each) [26]. Ferulic acid, predominantly identified as free phenolic fractions, was recorded highest in kodo millet (99.35 mg/100 g), followed by finger millet and foxtail millet with 57.04 mg/100 g and 54.65 mg/100 g of ferulic acid, respectively [27]. Similarly, proso millet is the richest source of protein (12,610 mg/100 g) among millets [27]. Most small millets are gluten-free and have a low glycemic index [28]. However, several antinutrient factors like tannins, polyphenols and phytic acid present in millets limit the bioavailability of essential nutrients, hence limiting the consumption of millets [29]. It has been estimated that millets have 0.2–0.3% polyphenols, 0.48% phytates and 0.61% tannins, among which the presence of phytic acid is a matter of concern, as it affects the bio-accessibility of several major nutrients [30]. Table 1. Nutritional profile of small millet grains in comparison to major cereals [28,112]. CROP Protein (g/100 g) Fibre (g/100 g) Carbohydrate (g/100 g) Thiamine (mg/100 g) Riboflavin (mg/100 g) Major and trace mineral elements (in mg/100 g) K Ca P Mg Cr Zn Fe Cu Mn Barnyard millet 6.2 9.8 65.5 0.30 0.09 195 21 340 82 0.14 2.6 9.2 1.3 1.33 Finger millet 7.3 3.6 72.0 0.38 0.21 407.00 398 320 137 0.03 2.3 3.9 0.5 5.49 Foxtail millet 12.3 8.0 60.9 0.42 0.19 299.28 38 422 81 0.07 2.9 5.3 1.6 0.85 Kodo millet 8.3 9.0 65.9 0.33 0.10 181.785 31 215 166 0.08 1.5 3.6 5.8 2.9 Little millet 7.7 7.6 67.0 0.41 0.28 192.21 12 251 133 0.24 3.5 13.9 1.6 1.03 Pearl millet 11.8 2.3 67.0 0.38 0.21 275.675 46 379 137 0.02 3.1 8 1.1 1.15 Proso millet 12.5 7.2 70.4 0.59 0.11 177.315 23 281 117 0.04 2.4 4 5.8 1.2 Rice 11.8 0.2 78.2 0.41 0.04 35 21 433 177 - 6 2 0.2 0.974 Wheat 6.8 1.2 71.2 0.41 0.10 107 34 357 137 0.02 2.6 3.6 0.4 4.07 Sorghum 10.4 2.0 70.7 0.38 0.15 672 13.49 380 165 - 2.51 8.23 0.3 1.605 The cultivation of small millets is limited to small farmers of low-income countries due to the presence of various antinutrients and the limited exploitation of genetic resources for trait improvement. However, small millet cultivation provides grains for forage, enhances agricultural biodiversity, checks soil erosion in arid regions, and ensures higher carbon sequestration due to the C4 mode of photosynthesis [8]. In recent years, foxtail millet has emerged as a model crop for C4 plants among small millets. It, therefore, enables the breeding programs to explore complex agronomic traits in all C4 millet crops [31]. Interestingly, recent research by Yang et al. [32] has confirmed the development of mini foxtail millet with a mutation, xiaomi, which has a short life cycle and flowering time. This makes the xiaomi mutant an Arabidopsis-like C4 model plant. Except for foxtail millet, proso millet, and finger millet, inadequate germplasm conservation has been done for other small millets, which is a potential reason for limited trait improvement research programs on these crops [8]. Therefore, significant efforts must be made in other small millets to conserve and explore their germplasm before they are lost. The application of novel approaches is imperative to examine the agronomic traits followed by their improvement in small millets [33]. Trait improvement in small millets, particularly focusing on reducing antinutrients and improving yield, could promote their cultivation and consumption as nutri-cereals, which will help combat hidden hunger [33]. Germplasm resources of small millets are conserved in genebanks of different regions, led by Asian countries with 64.4% accessions [34]. Globally, germplasm resources of small millets are majorly conserved in the National Bureau of Plant Genetic Resources (NBPGR, India), Institute of Crop Science, Chinese Academy of Agricultural Sciences (ICS-CAAS), National Institute of Agrobiological Sciences, Japan, and Ethiopian Institute of Biodiversity [34]. The availability of genome sequence data of small millets can facilitate the development of mapping populations with desired traits. The availability of draft genome sequences for most millets is competent for large-scale genotyping and gene mining. For example, ICRISAT, in collaboration with Cornell University, has genotyped different small millets using genotyping-by-sequencing (GBS) and identified diversity in small millet population structure [35]. However, ploidy level and the presence of repetitive DNA greatly influence the success of genome sequencing in small millets. The emerging next-generation sequencing approaches complemented with extensive data analysis platforms are expected to provide great success in future. Further, the All India Coordinated Research Project on Small Millets (AICRP-Small millets) is actively performing small millet improvements through collaborative interaction of State Agricultural Universities, ICAR institutes and other voluntary centres [34]. Thus far, this coordinated effort has successfully released 248 varieties of small millets in India [36] (http://www.aicrpsm.res.in/). Prior to the genome sequence of small millets, molecular markers such as RAPD, RFLP, AFLP and SSRs were used to map genes associated with important traits. However, advanced genome sequencing approaches have enhanced the direct identification of genes. To date, several gene families have been identified and functionally characterized, such as MYB, NAC, WRKY, CDPK, WD40, AP2/ERF, ATG and LIM genes (Fig. 1) [[37], [38], [39], [40], [41], [42], [43]]. Additionally, several other stress-related genes have been identified, most of which have been studied in foxtail millet and finger millet. For example, SiLEA14 was significantly up-regulated in foxtail millet under osmotic and salt stress conditions [21]. Notably, seven drought stress-related proteins, namely, NAC2, U2-snRNP (small nuclear RiboNucleoProtein particles), CDPK, synaptotagmin, Aquaporins, MPK17-1 and Scythe protein, have been identified in small millets [44]. Further, EcDehydrin7, Ec-apx1, EcbHLH57, EcbZIP60, Ec-apx1, EcGBF3 and EcbZIP17 have been identified in finger millet, and their role in conferring stress tolerance has been studied in various model plants such as tobacco and Arabidopsis (Fig. 1) [45]. Download : Download high-res image (900KB) Download : Download full-size image Fig. 1. Overview of genes functionally characterized in small millets and their physiological functions under various stress conditions. 3. Factors limiting the yield and productivity of small millets Due to their diverse climate resilience features, small millets are mainly grown in arid and semi-arid regions. Of the total area under millets (76 million ha), 18–20 million ha is utilized worldwide for small millets cultivation [34]. Though biotic and abiotic stresses least influence small millets, a significant variation exists among different germplasms for stress tolerance in small millets [46]. Therefore, identifying and applying agronomically important traits for millet breeding programs is imperative. Several abiotic stresses, namely, drought, salinity, heat, lodging, etc., and biotic stresses, viz., fungal and bacterial diseases, significantly influence the small millet productivity (Fig. 2). Download : Download high-res image (753KB) Download : Download full-size image Fig. 2. Environmental stresses affecting small millets. Different abiotic and biotic factors that limits the yield and productivity of small millets is shown. Also, the anti-nutrients in millets are highlighted. 3.1. Water deficit stress Water scarcity is the most eminent problem in arid and semi-arid regions of many countries, which leads to severe drought stress in those areas. On a report by the United Nations, approximately 40% of the world's land is dry, which feeds almost 2 billion people [47]. Notably, the severity and frequency of drought stress have enhanced hitherto [48]. As the dominant crops of these areas, small millets production is adversely affected by drought stress. Ajithkumar et al. (2014) [49] showed a negative impact of drought stress on yield, membrane integrity, osmotic balance, water potential maintenance, and photosynthetic efficiency in pearl millet. Similarly, teff production is limited by drought conditions, which needs immediate action to improve mitigation and adaptation strategies [50]. Further, Matsuura and the research group [51] examined the impact of water deficit conditions on the vegetative and reproductive stages of proso millet, foxtail millet, and little millet. The foxtail millet showed an 80% reduction in yield after drought treatment at the pre-heading stage, whereas proso millet and little millet showed a 36 and 20% yield reduction [51]. Although post-heading drought stress leads to severely reduced productivity in proso and little millet only, minor impact was observed in foxtail millet. Therefore, the study suggested that foxtail millet has better drought tolerance mechanisms than proso and little millet. Further, drought stress in finger millet resulted in complete yield loss [52], and almost 77% of yield loss was reported in teff after confronting drought stress at the heading stage of growth [53]. Winkel et al. (1997) [54] investigated the adverse effect of drought conditions on different stages of pearl millet. They concluded that yield loss is severe when it experiences drought at the reproductive stage. The yield loss in millets varies yearly based on the drought stress severity; however, millets produce grains even under severe drought conditions, unlike other major cereals. Numerous agronomical traits are responsible for the drought tolerance features of small millets. Traits responsible for nitrogen-use efficiency, photosynthetic efficiency, early flowering, and rapid growth are important factors that help them escape drought conditions [55]. Other traits associated with water-use efficiency helps millets avoid drought stress by maintaining the water potential in cells [56]. Similarly, superior antioxidant qualities and osmolyte accumulation confer drought tolerance in millets [55]. In addition, several morphological, physiological, and biochemical traits have been identified in millets that are crucial for their drought tolerance. For example, Balsamo et al. (2006) [57] reported that bundle sheath lignification enhances teff tensile strength. Further, enhanced accumulation of osmolytes was observed in little millet under drought conditions [49]. Root architecture is another important morphological characteristic to survive drought conditions. Therefore, broader root architecture in teff allows it to survive drought stress [58,59]. Considering this, millets are widely grown in rain-fed regions of various developing countries. 3.2. Salinity stress Salinity is a major problem in the irrigated area of agricultural lands, severely affecting crop yield and nutritional status. Currently, almost 45 mha of total irrigated land is affected by salinity [60]. Millets are also categorized as glycophytes as they are not resistant to high salt concentrations [61]. Given this, Rasool et al. (2020) [62] and Shah et al. (2020) [63] investigated the effect of salinity on foxtail millet. Due to salt stress, they reported reduced biomass, photosynthetic efficiency, and water potential. Finger millet is salt tolerant, ensuring grain production under saline conditions [64]. Several finger millet genotypes have been investigated for their salt tolerance ability, which reported significant genotype-based variation in terms of tolerance in finger millet [65]. Salt stress adversely affects germination and seedling development in finger millet [66]. Similarly, four foxtail millet genotypes were investigated for their salt tolerance and showed variable morphological and anatomical changes among the sensitive and tolerant cultivars [67]. Further, a study by Rahim et al. (2020) [68] assessed the salt tolerance ability of pearl millet and showed a reduction in the number of tillers and growth under high salt concentrations. 3.3. Temperature stress Millets are heat tolerant; however, several molecular changes are induced under high temperatures. For example, photosynthetic efficiency, transpiration, and respiration are major biological processes that are sensitive to temperature and significantly impact yield [69]. Therefore, the annual rise in global temperature greatly influences crop productivity, which threatens food security. Finger millet cultivars are widely grown in areas with a maximum temperature of 36 °C; however, a further rise in temperature adversely affects yield [70]. The study reported significant variation in the germination of different germplasms of finger millet under increased temperature, suggesting the need for improved genotype development by breeding programs [70]. Further, pearl millet can produce grains at temperature up to 42 °C, where other crops fail to grow. However, changing climatic conditions and further increase in temperature will reduce the yield of pearl millet by 17% by 2050 [71]. Similarly, Knox et al. [72] estimated approximately a 10% loss in the yield of pearl millet in Asian regions. Djanaguiraman et al. [73] quantified the impact of high temperature on pollen, pistil, and germplasm variability. 3.4. Waterlogging stress Waterlogging is a major stress in areas with heavy precipitation that adversely impacts stomatal closure, photosynthesis, and root architecture by inhibiting gas diffusion [74]. Waterlogging causes almost 16% of yield loss in proso millet [74]. Similarly, a reduction in the yield of finger millet was reported under waterlogging, as it favours an anaerobic mode of metabolism that is not very economical in terms of ATP production [75]. Matsuura et al. (2016) [76] investigated the effect of waterlogging on proso millet, little millet, and foxtail millet and suggested that little millet showed better waterlogging tolerance than other millets. 3.5. Lodging effect Lodging, bending of the stem, is a severe problem in many small millet crops, which causes severe yield loss. Several climatic conditions, such as rain, wind, irrigation, or combined effect, can lead to lodging in millets. Lodging stress majorly influences the stem and root of the plant, hence regarded as stem lodging and root lodging, respectively [77]. Numerous studies have shown the negative impact of lodging stress on teff and foxtail millet. Teff is majorly susceptible to root lodging [78]. Similarly, lodging stress causes yield loss in foxtail millet [79]. Further, Opole et al. [80] showed the role of excessive fertilizer in causing lodging stress in finger millet, which severely reduces the yield. However, pearl millet showed tolerance to the lodging effect [81]. 4. Biotic factors affecting small millets Under vulnerable conditions, various biotic factors cause heavy losses in small millet production. Several pathogens such as Rhizoctonia solani, Pyricularia grisea, Pyricularia setariae, Ustilago crus-galli, Sphacelotheca destruens, Uromyces linearis, Uromyces eragrostidis, etc. have been reported in small millets [46] (Table 2). Among various pathogens, fungal diseases are more devastative for small millets, as they have broad spectrum of host. For example, smut and rust are commonly known to infect all the small millets including teff [46]. However, other diseases such as blast, leaf blight, udbatta, sheath rot, sheath blight and brown spot specifically infect one or few small millets [46]. Severe yield losses have been reported in small millets due to these pathogens. For example, 30–40% grain loss was reported in foxtail millet due to blast [82]. Similarly, blast disease causes over 50% loss of finger millet [83]. Blast disease caused by P. grisea, infects several small millets, including foxtail millet, finger millet, proso millet, barnyard millet and little millet. The average yield loss due to blast infection may extend to 90% in affected areas [84]. Further, teff rust is responsible for 10–40% yield losses annually [85]. Downy mildew of finger millet causes severe losses, with more than 50% yield loss in certain years [46]. Ragi mottle streak virus infects finger millet in India, where yield loss ranged from 50% to 100% in some affected regions [46]. Leaf blight is another common fungal disease of small millets. The fungi for blight disease in different small millets are Alternaria tenuissima (kodo millet), Cochliobolus setariae (foxtail millet), Drechslera nodulosa (little millet, tef), Exserohilum monoceras (barnyard millet), and Bipolaris panici-miliacei (proso millet) [46]. Several different fungi, such as Uromyces eragrostidis, Uromyces setariae-italicae, Uromyces linearis and Puccinia substriata are known to cause rust in small millets such as foxtail millet, finger millet, kodo millet and little millet [46]. Similarly, grain smut is a common disease of barnyard millet, little millet, finger millet and foxtail millet, whereas head smut majorly infects kodo millet, proso millet and teff [46]. Among small millets, no significant information is available about the disease of teff and fonio. Table 2. Common pathogens reported to cause diseases in small millets [184]. Crop Disease Pathogen Finger millet Blast Pyricularia grisea Rust Puccinia substriata Smut Melanopsichium eleusinis Downy mildew Sclerophthora macrospora Seedling & leaf blight Drechslera nodulosum Cercospora leaf spot Cercospora eleusinis Banded blight Rhizoctonia solani Wilt or foot rot Sclerotium rolfsii Bacterial leaf spot Xanthomonas eleusinae Ragi severe mosaic Sugarcane mosaic virus Ragi mottle streak Ragi mottle streak virus Ragi streak Maize streak virus (Eleusine strain) Foxtail millet Blast Pyricularia setariae Rust Uromyces setariae-italicae Smut Ustilago crameri Downy mildew Sclerospora graminicola Udbatta Ephelis sp. Bacterial leaf blight Pseudomonas avenae Kodo millet Head smut Sorosporium paspali Rust Puccinia substriata Udbatta Ephelis sp Barnyard millet Head smut Ustilago crus-galli Kernel smut Ustilago panici-frumentacei Bacterial leaf blight Pseudomonas avenae Proso millet Head smut Sphacelotheca destruens Bacterial leaf blight Pseudomonas avenae Little millet Rust Uromyces linearis Teff millet Rust Uromyces eragrostidis Damping off Helminthosporium poae 5. Antinutrient content in small millet grains Small millets are a rich source of various micro- and macro-nutrients, therefore considered important cereals to combat hidden hunger. However, different antinutrients such as tannins, polyphenols, and phytic acid reduce millets' nutritional qualities as they chelate various crucial cations like K+, Mg2+, Zn2+, and Ca2+ in the human body after consumption [86]. This activity reduces the bioavailability of these cations to several important enzymes and hampers the biological process mediated by these enzymes. Additionally, various enzyme inhibitors, such as amylase and protease inhibitors, cause indigestion of millet grains [87]. These anti-nutritional qualities of millets are also important reasons for their orphan status and ignorance by agricultural communities. Further, these anti-nutrients also reduce the bioavailability of several nutrients and minerals, which leads to harmful effects on the health of people whose nutritional requirements solely depend on these crops [29]. Kumar et al. [88] reported the presence of various anti-nutrients such as oxalates, phytic acid, non-starch polysaccharides-glucans, tannins, and protease inhibitors in finger millet. Earlier, Ramachandra et al. [89] investigated the content of tannins in finger millet and identified it to be in the range of 0.04–3.47%. However, varietal variation of tannin content was observed, therefore paving the path for germplasm improvement. Similarly, protease inhibitor activity and non-starch polysaccharides contents have been identified in various finger millet varieties [90,91]. Pradeep and Sreerama [92] investigated the effect of various treatments on the anti-nutrient composition of barnyard millet, proso millet, and foxtail millet. Currently, several processing techniques, such as decortication, germination, milling, roasting, puffing, cooking, and hydrothermal treatments, are widely utilized to reduce the anti-nutrients in millets [93]. Numerous studies have reported the success of these techniques in different millets [[94], [95], [96], [97]]. However, these techniques also cause a significant reduction in other nutrients and minerals [95,98]. Therefore, genetic approaches to enhance the bioavailability of nutrients and reduce anti-nutrients are imperative for increasing these crops' popularity and consumption. 6. Genetic and genomic resources Crop diversity is a primary requirement for sustainable agriculture and nutritional security. Diverse germplasm provides significant variability for crop improvement. Globally, approximately 133,849 accessions of small millets are conserved in genebanks (Supplementary Fig. S1) [34]. ICRISAT conserves around 10,193 germplasm accessions of all small millets from 50 countries [99]. Around 29,000 accessions of proso millet have been conserved worldwide, of which 849 germplasm are conserved at the International Crops Research Institute for Semi-Arid Tropics (ICRISAT) [100]. Over 8000 germplasm accessions each of kodo and barnyard millet, and around 3000 germplasm of little millet have been successfully stored in genebank [101]. Small millet crops are majorly tetraploid, except in foxtail millet and barnyard millet, which have diploid and hexaploidy levels, respectively [34]. These large collections of conserved small millet genotypes are grouped according to various parameters, such as region of origin and promising traits, by the genebank institutions like ICRISAT [99]. Each group represents a particular genetic diversity called “core collection” [99]. These core collections provide sufficient genetic diversity for crop improvement. The genetic diversity of small millets has been investigated with the help of several genetic markers, such as genome-wide small nucleotide polymorphism (SNP) markers (Table 3). This is facilitated by novel sequencing approaches such as genotyping by sequencing (GBS), restriction site-associated DNA (RAD) sequencing and whole genome resequencing [102]. Yue et al. (2016) [103] identified about 400,000 SNP markers and 35,000 simple-sequence repeats (SSRs) from proso millets. Similarly, random-amplification-of-polymorphic DNA (RAPD) markers have been identified in 96 kodo millet accessions [104]. Recently, the genotyping-by-sequencing (GBS) approach was used to identify novel SNP markers in 288 finger millet accessions from Zimbabwe and Ethiopia [105]. Around 2412 high-quality SNP markers were identified in proso millet, followed by a genome-wide association study to understand the genetic diversity among different accessions of proso millet from Western Europe, Eastern Asia, Americas, Southern Asia, Western Asia and Africa [106]. Further, 2977 SNP markers were used for a marker-trait association study in finger millet to understand the genetic diversity associated with seed protein content, grain yield and days to maturity [107]. Additionally, advanced phenomics methods could be integrated with genomics data to enhance the study of a diverse genetic pool of small millets. Thus, huge opportunities are available for researchers to unveil the genetic diversity of small millets, which certainly encourages crop improvement programs in millets. Table 3. Molecular markers developed for genotyping applications in small millets. Crop Markers Methods Major finding Reference Finger millet Genic and genomic SSRs Association mapping Four QTLs for finger blast and one QTL for neck blast resistance were identified [126] Genomic SSRs Association mapping Seven QTLs were associated with various agronomic traits including leaf blast resistance. [128] 23,000 single-nucleotide polymorphisms (SNPs) Genotyping-by-sequencing Genotyping-by-sequencing of 113 diverse finger millet accessions [185] 10,327 SSRs and 23,285 non-homeologous SNPs Roche 454 and Illumina HiSeq 2000 identified new polymorphic SSRs and SNPs [186] Whole-genome sequencing of cultivar ML-365 Whole genome and transcriptome 1196 Mb genome size covering 82% of crop genome. 85,243 genes were predicted and one half of the genome was found to be repetitive [11] Assembled the genome of cultivar PR202 via a novel pipeline Whole-genome NGS size of the assembled genome was about 1.2 Gb and predicted 62,348 genes [187] Foxtail millet highly polymorphic simple sequence repeat markers genome-wide microsatellite variant analysis 733 highly polymorphic SSR loci [188] EST-derived-SSR (eSSR) markers – 447 eSSR markers developed in foxtail millet [189] RAPD and ISSR markers – 135 RAPD and 77 ISSR [190] rhizoplane microbial biomarkers GWAS, MWAS and mGWAS 257 rhizoplane microbial biomarkers [191] SNPs GBS-ddRAD approach 10 K SNPs [113] SSRs Genome-wide identification 74 SSRs [192] Kodo millet SNPs genotyping-by-sequencing (GBS) 3461 SNPs [35] Proso millet SNPs genotyping-by-sequencing (GBS) 1882 SNPs [35] AFLP AFLP method 514 polymorphic AFLP markers [193] Little millet SSRs – 4443 genic-SSR [194] RAPD markers RAPD analysis 175 RAPD marker [195] Barnyard millet SSRs – 51 SSR markers [196] 7. Dissecting climate-resilient and nutritional traits in small millets Millets exhibit several important nutritional and climate-resilient traits, which have been identified so far by using novel omics and breeding approaches. Modern genetic and genomic tools facilitate the identification of these traits. The availability of whole genome sequence information of several small millets has further accelerated the crop improvement programs in millets [8]. As climate-resilient crops, millets are underexplored in this regard, though the looming climate changes necessitate trait improvement practices to be deployed to avoid crop failure [108]. Both genomic and genetic resources are necessary for trait improvement, where genomic information accelerate the identification and functional characterization of trait-responsive genes for their utilization in breeding programs (Fig. 3; Supplementary Fig. S2). Among small millets, the whole genome sequence is available for foxtail millet, finger millet, barnyard millet, teff, and green foxtail [9,11,[109], [110], [111]] (Fig. 4; Supplementary Table S1). This breakthrough research expedites the identification of novel genes responsible for various nutritional and climate resilience traits in small millets (Table 4). The availability of genomic resources has accelerated breeding programs targeting trait improvement in small millets. Genome-wide association study identified ten loci associated with nutritional elements, including calcium, zinc, phosphorus, sulfur, magnesium, boron, nickel, potassium, and manganese [112]. GWAS, through the GBS-ddRAD approach, identified markers associated with various traits such as grain yield (GY), flag leaf width (FLW), thousand-grain weight (TGW), etc. [113]. The Pearl Millet Inbred Germplasm Association Panel (PMiGAP) has collected 29 million genome-wide SNPs, which have been utilized to map various traits such as Fe and Zn content in grain, tolerance to drought yield, nitrogen-use efficiency, etc. [114]. Genetic loci associated with nitrogen responsiveness and yield traits have recently been identified in foxtail millet through GWAS [115]. Further, integrated breeding associated with genomics facilitated the identification of genetic factors related to seed protein content (SPC), grain yield (GY), and days to maturity (DM) in finger millet [107]. Similarly, genetic regulation of micronutrient content was studied by genotyping-by-sequencing (GBS) and GWAS to identify candidate genes associated with traits in finger millet [116]. Download : Download high-res image (438KB) Download : Download full-size image Fig. 3. Overview of recent trends in trait-improvement programs of small millets. Detailed figure is provided as Supplementary Fig. S2. Download : Download high-res image (313KB) Download : Download full-size image Fig. 4. Whole genome sequence data of small millets. Bar diagram showing the number of millet genomes sequenced compared to other major cereals. The data is retrieved from the NCBI Genome database (https://www.ncbi.nlm.nih.gov/genome/). Table 4. Summary of genetic transformation efforts performed in small millets for improving their yield-contributing, agronomic, and climate-resilient traits. Crop Promoter/Gene Promoter/Marker system Vector Transformation procedure Phenotype achieved Reference Finger millet CaMV35S/mtlD CaMV35S/UidA CaMV35S/hpt pCAMBIA 1380, pCAMBIA 1301 Agrobacterium-mediated Multiple stress tolerance [66] CaMV35S/SbVPPase CaMV35S/hpt pCAMBIA1301 Agrobacterium-mediated Salt tolerance [147] Ubi1/chi11 CaMV35S/hpt pCAMBIA1301 Agrobacterium-mediated resistance to leaf blast disease [142] CaMV35S/gus CaMV35S/hpt pCAMBIA1301 Agrobacterium-mediated – [141] Actin-1/PcSRP 250 mM NaCl TG0063 of pCAMBIA series Biolistic Salt tolerance [197] CaMV35S/PIN CaMV35S/pac pPUR Biolistic Leaf blast resistance [144] Foxtail millet 35S::SiFPGS2/Col-0 CaMV35S pART-CAM Agrobacterium-mediated Increased folate content [231] CaMV45S/gus CaMV35S/nptII CaMV35S/hpt pCAMBIA2300, pSB Agrobacterium-mediated [21] CaMV 35S/SiARDP CaMV 35S/hpt pS1300/pCoU Agrobacterium-mediated Abiotic stress tolerance [180] CaMV35S/SiLTP pCAMBIA2300/nptII pCAMBIA2300/pCOU Agrobacterium-mediated Abiotic stress tolerance [198] CaMV35S/SiPHT1;1,2 and 3 pFGC1008/nptII pFGC1008 Agrobacterium-mediated High affinity Pi transporters [199] CaMV35S/SiASR4 pCAMBIA2300/nptII pCAMBIA2300/pCOU Agrobacterium-mediated Abiotic stress tolerance [200] CaMV35S/SiMYB3; UBI/SiMYB3 pBI121/GUS; pCAMBIA1390/npt ii pBI121/pCAMBIA1390 Agrobacterium-mediated; vacuum infiltration method Tolerance to low-nitrogen stress [175] CaMV35S/SiREM6 CaMV35S/hpt pS1300 Agrobacterium-mediated; vacuum infiltration method Salt tolerance [174] Ubiquitin/SiMYB19 Ubiquitin/hpt pCAMBIA1390 Agrobacterium-mediated Salt and drought tolerance [176] CaMV35S/SiPf40 CaMV35S/hpt pCAMBIA1301 Agrobacterium-mediated Plant architecture [201] Ubi/SiMYB56 Ubi/pat pMWB014 Agrobacterium-mediated Drought tolerance [177] CaMV35S/SiATG8a CaMV35S/hpt pCAMBIA1302 Agrobacterium-mediated Tolerance to nitrogen starvation and drought [181] Ubi/SiACC-R – pCAMBIA3301 Agrobacterium-mediated Herbicide resistance and increased oil content [202] Ubi/SiWLIM2b Ubi/pat pMWB014 Agrobacterium-mediated Drought tolerance [203] CaMV35S/SiASR4 CaMV35S/SiASR4 CaMV35S/hpt pSuper1300 Agrobacterium-mediated Abiotic stress tolerance [200] CaMV35S/SiMADS51 CaMV35S/hpt pCAMBIA1302; pCAMBIA1305 Agrobacterium-mediated Drought tolerance [204] CaMV35S/SiCDPK24 CaMV35S/nptII pBI121 Agrobacterium-mediated Drought stress [42] CaMV35S/SiNAC110 CaMV35S/nptII pBI121 Agrobacterium-mediated Drought and salt tolerance [205] Ubi::DPY1-3FLAG; CaMV35S::SiBZR1-GFP; CaMV35S/DPY1 Ubi/hpt; CaMV35S/hpt pTCK303; pEarleyGate 103; pCAMBIA1305 Agrobacterium-mediated Plant architecture [206] U6a/SiBOR1 U6a/hpt pYLCRISPR-Cas9-MH Agrobacterium-mediated Grain yield [207] CaMV35S/SiGRF CaMV35S/hpt pCAMBIA1305 Agrobacterium-mediated Salt tolerance [208] Ubi/SiBRI1 Ubi/hpt pCAMBIA1305-eGFP Agrobacterium-mediated Stress tolerance [209] CaMV35S/SiHAK1 CaMV35S/nptII pBI121 Agrobacterium-mediated Salt tolerance [210] CaMV35S/SiPLDα1 CaMV35S/nptII pBI121 Agrobacterium-mediated Drought tolerance [211] CaMV35S/SiBZR1; CaMV35S/SiPLT-L1 CaMV35S/hpt; CaMV35S/hpt pCAMBIA1305/pGWB5 Agrobacterium-mediated Drought tolerance [204] Teff CaMV35S/PcGA2ox1 CaMV35S/nptII pGPTV Agrobacterium-mediated Semi-dwarfism [212] - Data not available. Different “omics” approaches, including transcriptomics, proteomics, and metabolomics, enable the quantitative and qualitative analysis of candidate genes to unravel the underlying regulatory networks (Fig. 3). RNA-seq analysis of little millet identified drought- and salt-responsive genes, which can be used as potential crop improvement candidates [15]. Similarly, the transcriptome analysis of finger millet reported several genes associated with drought tolerance and nutraceutical properties, which could be used as candidates for breeding programs [11]. Further, de novo transcriptome sequencing of pearl millet identified salt-responsive genes [117]. Another study by Jaiswal et al. (2018) [118] reported transcriptomic signatures associated with drought tolerance. Recently, small RNA sequencing analysis revealed the function of miRNAs under salt stress and identified their potential targets in pearl millet [119]. Rahman et al. [120] identified salinity-responsive candidate genes such as transporters, stress-related TFs, aquaporins, sodium/calcium exchangers, and signal transducers in finger millet through RNA sequencing. EcbZIP17 from finger millet showed increased growth and stress tolerance under abiotic stresses [121]. The study identified a NAC (no apical meristem) TF, EcNAC67, further functionally characterized in rice using Agrobacterium-mediated transformation [122]. Transcriptomics analysis identified 82 genes encoding calcium sensors in developing spikes of finger millet [123]. Recently, a presumptive model for calcium transport, known as the ‘Tripartite model,’ was suggested in finger millet [124]. Proteomics is another popular omics approach, which is now widely employed in millets to understand climate resilience and nutrition-associated traits. For example, comparative proteomics analysis identified drought-responsive proteins in foxtail millet [125]. Integrating large-scale data from all the omics approaches would facilitate the identification of potential candidate genes that could be manipulated using novel gene-editing tools to develop improved crops. Genomic studies in small millets have identified several potential markers associated with disease resistance. Field screening has been widely used for screening disease resistance germplasms in small millet [82]. However, these approaches are time-consuming and demand novel phenomics and computational approaches to screening resistant germplasms. Babu et al. [126] identified 58 SSR (simple sequence repeats) markers associated with blast resistance in finger millet. Recently, a genome-wide association study in foxtail millet identified markers associated with blast resistance [127]. Further, QTLs linked with blast resistance in finger millet were identified through association mapping [128]. Functional molecular markers-based resistance genes (R-genes) analogues were identified in finger millet [129]. However, the lack of a complete genome sequence in most small millets hinders the identification of genetic and genomic resources related to disease resistance. Therefore, new-generation biotechnological tools and computational approaches have great potential to accelerate such studies and crop improvement programs in small millets. 8. Next-generation tools for trait improvement in small millets The improvement of small millets could be a milestone in the “New Green Revolution”- a terminology coined to contemplate novel strategies of crop improvement which are necessary to combat the complex challenges of climate change and malnutrition. In the last few decades, attempts have been made to improve the traits and yield of millets. For example, the comprehensive evolution of pearl millet breeding from an open-pollinated to a hybrid approach has led to approximately a 4% enhancement in pearl millet yield [130]. Further, mutation-breeding in kodo millet has developed non-lodging cultivars, as lodging is a major constraint in its cultivation [131]. Classical breeding programs such as traditional, mutation, and transgenic breeding are very laborious and challenging (Fig. 3). Therefore, new breeding techniques assisted by gene editing (GE), epigenetic modification, and heritable targeted mutation must be applied for crop improvement. Advanced omics have provided substantial genetic and genomic resources, which can be exploited for genetic manipulation using third-generation gnome-editing tools [132]. Clustered regularly interspaced short palindromic repeat (CRISPR)/CRISPR-associated protein 9 (Cas9) nuclease system is a powerful gene-editing tool, which is now successfully employed in various crops, including rice (Oryza sativa [133], wheat (Triticum aestivum [134]) and maize (Zea mays [132]). However, this gene-editing tool has not been used for most small millet crops except foxtail millet [135] (Table 5). In this direction, a foxtail millet mutant, xiaomi, with a short generation time, was developed using the CRISPR system [32]. This mutant provides an efficient C4 model system, which can be utilized to study genes associated with important agronomic traits. Recently, a nano-particle based delivery system for plasmids, ribonucleoproteins (RNPs), and RNA is now developed for speedy trait improvement. However, this concept has not been utilized in millets, but this approach holds a promising future in these crops. Table 5. Summary of genome-editing experiments performed in foxtail millet. Genome editing approach Transformation procedure Target gene Trait Phenotype achieved Reference CRISPR-Cas9 Protoplasts SiPDS Carotenoid biosynthesis pathway Application of protoplast technology [213] Agrobacterium-mediated SiMTL Pollen‐specific phospholipase Haploid inducer lines [138] Agrobacterium-mediated SiPHYC Light receptor for photoperiod flowering Early flowering (heading date of 39 days) [32] The genetic manipulation of QTLs is challenging, though GE tools showed promising potential in QTLs editing to instigate desired alleles into several crops by eluding the requirement of excessive crossing [136]. For example, the CRISPR/Cas9 nuclease system facilitated the analysis of phenotypic variation generated by mutations in the cis-regulatory region in tomato [137]. Therefore, the CRISPR strategy could be employed to genetically manipulate multiple QTLs to produce desired phenotypic changes. Further, the generation of double haploids (DH) drastically reduces the generation times, thereby speeding up breeding [136]. Given this, the haploid inducer line of foxtail millet has been generated by CRISPR-Cas9 mediated manipulation of the SiMTL gene [138]. These doubled haploid lines provide a platform to exploit complex traits, including climate resilience, in C4 crops. This gene-editing assisted de novo domestication of polygenic traits such as climate resilience, and nutritional aspect is a new-generation breeding strategy for crops like small millets. Developing an efficient transformation and regeneration method is necessary for the successful generation of transgenics by gene editing. Though millets lag on efficient transformation, few millet transformation reports are available [139,140]. For example, Agrobacterium-mediated transformation and regeneration of transgenics have been performed in finger millet [[141], [142], [143]]. Latha et al. (2005) [144] reported the first transgenic finger millet harbouring prawn pin gene encoding PIN fungicide protein, which conferred resistance in response to Pyricularia grisea. Similarly, transgenic finger millet expressing rice chitinase (chi11) was developed through Agrobacterium-mediated transformation, which showed resistance against leaf blast disease [142]. Few other studies reported the development of transgenic finger millet showing salt and drought tolerance through expressing serine-rich protein (PcSrp) and mannitol-1-phosphate dehydrogenase (mtlD) [66,145]. Ramegowda et al. [146] reported the successful development of transgenic finger millet plants, f35S and fBx17, expressing OsZIP1, which showed significantly enhanced Zn and Mn accumulation in finger millet. Following this, a salt-tolerant transgenic finger millet overexpressing the vacuolar pyrophosphate (SbVPPase) gene from Sorghum bicolor was developed through Agrobacterium-mediated transformation [147]. Satish et al. (2017) [143] developed an improved Agrobacterium-mediated transformation for finger millet, which showed better regeneration in four finger millet cultivars. Further, several reports of foxtail transformation are also available [148,149]. Successful transformation using the biolistic method is reported in pearl millet [149]. Similarly, the biolistic method-based transformation has also been tested in barnyard millet [150]. Recently, Agrobacterium-mediated transformation has been reported in kodo millet [151]. Therefore, these successful attempts could set a platform to extend these studies to other small millet crops, accelerating their improvement. Understanding the genetic diversity of cultivated lines is a crucial part of crop improvement. Resequencing of cultivated lines of several crops such as maize, soybean, and rice has been performed to explore the genetic diversity in terms of SNPs and small insertions/deletions (InDels) that are utilized as markers in genomics-assisted breeding (GAB) [152,153]. Given this, the concept of pangenome has been introduced to capture comprehensive genetic diversities in a species. Recently, the super-pangenome approach has been developed, which means pangenome analysis of pangenomes of various species to explore genetic diversity at the genus level [154]. Despite its significant application in crop improvement, crop pangenomics has not been utilized with small millets. Therefore, pangenomics of wild varieties of small millets could help explore the complete genetic diversity of a genus level, accelerating the small millet improvement programs. 9. Biofortification of small millets for nutritional security Malnutrition is a major threat in the developing world, where cereals are the primary source of nutrients. Besides major cereals, millets are the major crops cultivated and consumed in semi-arid areas of developing countries. The superior nutritional qualities of millets proved their potential to combat hidden hunger. However, the presence of antinutrients restrains the bioavailability of essential nutrients after consumption. Till now, the biofortification of major cereals has been widely performed to enhance the nutritional qualities of these crops [86]. Subsequently, the biofortification of millets was also initiated to achieve enhanced accumulation and bioavailability of nutrients in millet grains [86]. At present, germplasm conservation for most small millets has been performed in various countries where India has maximum accessions [34]. However, the lack of germplasm functional characterization for nutrients-associated traits limits the biofortification attempts. Millets are a rich source of carbohydrates, and grains with 0% amylose are highly recommended for infants due to their easy digestibility [86]. However, a lack of information about molecular markers associated with the waxy gene in millets hampers the breeding programs to develop waxy mutants. Therefore, next-generation sequencing approaches could provide the genetic structure of waxy genes in millets [155]. Further, novel gene-editing techniques can generate targeted mutations in non-waxy cultivars for developing waxy cultivars. In this regard, molecular analysis of proso millet, foxtail millet, and barnyard millet has identified mutations in alleles of waxy genes [86,156]. The deficiency of essential amino acids in cereal proteins leads to malnutrition. Millets are a rich source of essential amino acids, where finger millet has the highest content [157]. Therefore, finger millet has excellent potential to be utilized as a model crop to understand the genetic mechanism of protein quality. Kemper et al. [158] identified a gene, o2 modifier (Opm), involved in the modulation of amino acid catabolism, which results in the accumulation of free lysine and tryptophan in the endosperm. Hence, molecular characterization of Opm genes using new advanced biotech approaches will lead to genetic improvement of other cereals and small millets. Further, advanced computational approaches have identified 16 prolamin-encoding genes in foxtail millet, which could be used as a candidate to enhance protein quality in other small millets [159]. Further, the accumulation of micronutrients such as zinc and iron can be improved in cereals and small millets by overexpressing zinc and iron transporters [146]. Similarly, calcium deficiency can be improved as advanced sequencing approaches have identified several calcium sensor genes in small millets [160]. Therefore, the expression and engineering of these calcium sensor genes will help develop calcium-fortified crops. As millets have great synteny with cereals, comparative genomics analysis with available genome sequence information of foxtail millet and other cereals facilitates the identification of orthologous genes associated with several important traits [34]. 10. Future of machine learning (ML) approaches for small millets improvement The modern scenario demands the optimization of large-scale data generated from numerous omics approaches in the agricultural sector. The big data produced by various techniques are difficult to manage because of their “5-V” requirements; 1) Velocity, 2) Volume, 3) Variety, 4) Veracity, and 5) Value [161]. Earlier, conventional statistical methods were extensively used to analyze the genetic diversity, genotypes of crops, yield components, climate resilience, the impact of biotic stress, parental combinations in hybrid breeding, and in vitro biotechnological approaches [162]. However, these conventional methods have low efficacy, as the large-scale data from genomics, transcriptomics, proteomics, metabolomics, and phenomics are non-deterministic and non-linear [162]. Machine learning, a subset of artificial intelligence, has a significant advantage over conventional methods. It can precisely differentiate the plant genotypes based on phenotypical and molecular markers and predict the critical quantitative traits for optimization in vitro breeding methods [162] (Fig. 5). The newly developed phenomics era is also greatly supported by machine learning algorithms. Different sets of algorithms are used to analyze nonlinear data from plant studies. For example, deep learning convolutional neural networks (CNN) facilitate automated phenotyping and disease assessment in plants [163]. Production and yield forecasting is another application of machine learning. Given this, artificial neural networks (ANN) of machine learning showed better performance than classical methods in the production forecasting of pearl millet in Karnataka [164]. Recently, the “Automatic and Intelligent Data Collector and Classifier” was developed by integrating IoT (Internet of Things) and the deep learning approach of machine learning to automatically gather the images and parametric data from rust and blast-infected pearl millet crops [165]. Similarly, a machine learning algorithm, deep learning CNN, was used to identify mildew disease in pearl millet [166]. Another quality testing system, “Mixed Cropping Seed Classifier and Quality Tester (MCSCQT)”, was developed to classify diseased and normal pearl millet and maize seeds [167]. Further, an artificial neural network (ANN) machine learning algorithm was used to develop a model to help farmers predict the suitable crop during the cropping season by using soil conditions and climatic parameters as input [168]. Interestingly, machine learning approaches have applications in predicting the nutrient use efficiencies of crops under field conditions [169]. The major application of machine learning in agriculture has been dedicated to disease and weed detection; however, its implementation in small millet cropping is still lacking. Therefore, a great scope of application of these novel computational techniques in small millet improvement exists. Download : Download high-res image (1MB) Download : Download full-size image Fig. 5. Applications of machine learning in trait improvement. Overview of diverse applications of machine learning in improving the key traits in small millets is shown. 11. Success stories and future prospective of millet omics Small millets ensure food sustainability due to their inherent climate-resilient features and nutritional superiority compared to rice and wheat. Therefore, crop diversification is essential to attain food and nutritional security in the current scenario. However, low yield, lack of genomic and genetic resources, and presence of several anti-nutrients demand the deployment of advanced biotechnology-based crop improvement approaches to enhance the cultivation of small millets. Owing to this, significant progress has been made in generating enormous genomic and genetic resources for these crops, which led to identifying several agronomically important traits that can be used for small millet improvement. Conventional breeding approaches have developed several cultivars of small millet with improved climate-resilience features, disease resistance, nutritional quality, yield, improved biomass, and stover quality [[170], [171], [172], [173]]. Currently, 248 varieties of six small millets (finger millet, foxtail millet, proso millet, kodo millet, barnyard millet, and little millet) in India and 19 proso millet in the USA have been released through landraces selection, pedigree selection, and mutation breeding [34]. Interestingly, several stress-tolerance and nutritional quality-related genes identified from small millets have been expressed in other crops, suggesting the applicability of their genetic resources in other crops. For example, the remorin encoding gene (SiREM6) from foxtail millet showed salt tolerance in Arabidopsis on overexpression [174]. Recently, overexpression of SiMYB3 in rice and Arabidopsis conferred tolerance to low nitrogen stress by improving the root architecture [175]. Similarly, overexpression of SiMYB19 enhances yield and salt tolerance in transgenic rice [176]. SiMYB56 overexpression in rice conferred drought tolerance at the reproductive and vegetative stages [177]. Overexpression of EcDehydrin7 from finger millet conferred drought tolerance in tobacco [178]. Late embryogenic abundant (LEA) protein-encoding gene, SiLEA14, from foxtail millet, conferred salt and osmotic stress tolerance in transgenic Arabidopsis and foxtail millet [21]. Numerous other studies have reported the functional characterization of important genes from small millets in other crops [[179], [180], [181], [182], [183], [211], [214], [215], [216], [217], [218], [219], [220], [221], [222], [223], [224], [225], [226], [227], [228], [229], [230]]. However, such efforts are lacking in small millets due to the absence of standardized transformation methods. Further, despite the availability of advanced breeding approaches, very limited trait improvement efforts have been made in most small millets, including fonio, guinea millet, browntop millet, and job's tears. This is mainly due to meagre germplasm conservation for these small millets, which restrains crop improvement efforts. However, the high-quality cross-transferability of markers demonstrates the potential scope of marker-assisted breeding in small millets crops with limited genomic resources. Conventional breeding programs have shown significant success in delivering improved cultivars of small millets, though many have to be explored in these crops. The advanced sequencing approaches could be employed to provide a complete genome sequence of several small millets, including kodo millet, job's tears, and little millet. Additionally, novel machine learning-assisted phenomics approaches could further accelerate the collection of genetic diversity data. Given the current looming climatic conditions and increasing malnutrition, the agricultural community has increased its focus on small millet improvement to achieve food, nutrition, and economic security. Author contribution statement All authors listed have significantly contributed to the development and the writing of this article. Funding statement Dr. Mehanathan Muthamilarasan was supported by the Institute of Eminence Grant awarded to the University of Hyderabad by the Ministry of Education, India [UoH-IoE-RC2-21-014]. Data availability statement No data was used for the research described in the article. Declaration of interest's statement The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Appendix A. Supplementary data Download all supplementary files included with this article What’s this? The following are the supplementary data related to this article: Download : Download Word document (15KB) Multimedia component 1. Download : Download Acrobat PDF file (3MB) Multimedia component 2. Download : Download high-res image (573KB) Download : Download full-size image (161KB) figs1. References [1] S. Srivastava, C. Arya Millets: malnutrition and nutrition security A. Kumar, M.K. Tripathi, D. Joshi, V. Kumar (Eds.), Millets and Millet Technology, Springer, Singapore (2021), 10.1007/978-981-16-0676-2_4 Google Scholar [2] O.O. Oluwole, O.S. Aworunse, A.I. Aina, et al. A review of biotechnological approaches towards crop improvement in African yam bean (Sphenostylis stenocarpa Hochst. Ex A. Rich.) Heliyon (2021), 10.1016/j.heliyon.2021.e08481 Google Scholar [3] M. Kreitzman, E. Toensmeier, K.M.A. Chan, et al. Perennial staple crops: yields, distribution, and nutrition in the global food system Front. Sustain. Food Syst., 4 (2020), p. 216, 10.3389/fsufs.2020.588988 Google Scholar [4] A. Wakeel, M. Farooq, K. Bashir, et al. Plant micronutrient use efficiency molecular and genomic perspectives in crop plants Micronutr. Malnutr. Biofortific.: Recent Adv. Future Perspect. (2018), pp. 225-243 View PDFView articleView in ScopusGoogle Scholar [5] M.A. Mustafa, T. Mabhaudhi, F. Massawe Building a resilient and sustainable food system in a changing world – a case for climate-smart and nutrient dense crops Global Food Secur., 28 (2021), Article 100477 View PDFView articleView in ScopusGoogle Scholar [6] P. Banerjee, S. Maitra The role of small millets as functional food to combat malnutrition in developing countries Indian J. Natural Sci., 10 (60) (2020), pp. 20412-20417 Google Scholar [7] R. Sharma, S. Sharma, B.N. Dar, et al. Millets as potential nutri-cereals: a review of nutrient composition, phytochemical profile and techno-functionality Int. J. Food Sci. Technol., 56 (8) (2021), pp. 3703-3718, 10.1111/ijfs.15044 View in ScopusGoogle Scholar [8] M. Muthamilarasan, M. Prasad Small millets for enduring food security amidst pandemics Trends Plant Sci., 26 (1) (2021), pp. 33-40 View PDFView articleView in ScopusGoogle Scholar [9] G. Zhang, X. Liu, Z. Quan, et al. Genome sequence of foxtail millet (Setaria italica) provides insights into grass evolution and biofuel potential Nat. Biotechnol., 30 (2012), pp. 549-554, 10.1038/nbt.2195 Google Scholar [10] R.K. Varshney, C. Shi, M. Thudi, et al. Pearl millet genome sequence provides a resource to improve agronomic traits in arid environments Nat. Biotechnol., 35 (10) (2017), pp. 969-976, 10.1038/nbt.3943 View in ScopusGoogle Scholar [11] S. Hittalmani, H.B. Mahesh, M. Deepak Shirke, et al. Genome and Transcriptome sequence of Finger millet (Eleusine coracana (L.) Gaertn.) provides insights into drought tolerance and nutraceutical properties BMC Genom., 18 (2017), p. 465 View in ScopusGoogle Scholar [12] C. Lata, P.P. Sahu, M. Prasad Comparative transcriptome analysis of differentially expressed genes in foxtail millet (Setaria italica L.) during dehydration stress Biochem. Biophys. Res. Commun., 393 (4) (2010), pp. 720-727 View PDFView articleView in ScopusGoogle Scholar [13] B. Xu, X. Gao, J. Gao, et al. Transcriptome profiling using RNA-seq to provide insights into foxtail millet seedling tolerance to short-term water deficit stress induced by PEG-6000 J. Integr. Agric., 18 (11) (2019), pp. 2457-2471, 10.1016/S2095-3119(19)62576-1 View PDFView articleView in ScopusGoogle Scholar [14] M. Jayakodi, M. Madheswaran, K. Adhimoolam, et al. Transcriptomes of Indian barnyard millet and barnyard grass reveal putative genes involved in drought adaptation and micronutrient accumulation Acta Physiol. Plant., 41 (2019), p. 66, 10.1007/s11738-019-2855-4 View in ScopusGoogle Scholar [15] R.R. Das, S. Pradhan, A. Parida De-novo transcriptome analysis unveils differentially expressed genes regulating drought and salt stress response in Panicum sumatrense Sci. Rep., 10 (2020), Article 21251, 10.1038/s41598-020-78118-3 View in ScopusGoogle Scholar [16] C. Lata, R. Shivhare Genetic determinants of abiotic stress tolerance in foxtail millet M. Prasad (Ed.), The Foxtail Millet Genome, Compendium of Plant Genomes, Springer International Publishing AG (2017) Google Scholar [17] W. Wambi, G. Otienno, W. Tumwesigye, et al. Genetic and genomic resources for finger millet improvement: opportunities for advancing climate-smart agriculture J. Crop Improv., 35 (2) (2021), pp. 204-233 CrossRefView in ScopusGoogle Scholar [18] A.K. Gupta, V.S. Gaur, S. Gupta, et al. Nitrate signals determine the sensing of nitrogen through differential expression of genes involved in nitrogen uptake and assimilation in finger millet Funct. Integr. Genom. (2013), pp. 179-190 CrossRefView in ScopusGoogle Scholar [19] R.K. Singh, M. Lakshmi Venkata Phanindra, V.K. Singh, et al. Isolation and characterization of drought responsive EcDehydrin7 gene from finger millet (Eleusine coracana (L.) Gaertn.), Indian J. Genet. Plant Breed., 74 (4) (2014), pp. 456-462 CrossRefView in ScopusGoogle Scholar [20] C. Li, J. Yue, X. Wu, C. Xu, J. Yu An ABA-responsive DRE-binding protein gene from Setaria italica, SiARDP, the target gene of SiAREB, plays a critical role under drought stress J. Exp. Bot., 65 (18) (2014), pp. 5415-5427 CrossRefView in ScopusGoogle Scholar [21] M. Wang, L. Ping, L. Cong, P. Yanlin, J. Xiyuan, Z. Dengyun, Z. Qian, Y. Jingjuan SiLEA14, a novel atypical LEA protein, confers abiotic stress resistance in foxtail millet BMC Plant Boil, 14 (1) (2014), pp. 1-16 CrossRefGoogle Scholar [22] R.K. Prajapat, M. Mathur, T.K. Upadhyay, et al. Genome editing for crop improvement Book Crop Improvement Edition 1st, Imprint CRC Press (2021), p. 13 eBook ISBN9781003099079 CrossRefGoogle Scholar [23] T.L. Goron, M.N. Raizada Genetic diversity and genomic resources available for the small millet crops to accelerate a New Green Revolution Front. Plant Sci., 6 (2015), p. 157 View in ScopusGoogle Scholar [24] D.Q. Fuller, R. Korisettar, P.C. Venkatasubbaiah, et al. Early plant domestications in Southern India: some preliminary archaeobotanical results Veg. Hist. Archaeobotany, 13 (2) (2004), pp. 115-129, 10.1007/s00334-004-0036-9 View in ScopusGoogle Scholar [25] Q. Yang, Z. Yu, C. Guimei, et al. Water use efficiency of foxtail Millet (Panicum italicum L.) under climate change conditions in Northwest regions of China Agrociencia, 50 (6) (2016) Google Scholar [26] B.R. Rao, M.H. Nagasampige, M. Ravikiran Evaluation of nutraceutical properties of selected small millets J. Pharm. BioAllied Sci., 3 (2) (2011), pp. 277-279, 10.4103/0975-7406.80775 View in ScopusGoogle Scholar [27] G. Goudar, M. Manne, G.J. Sathisha, P. Sharma, T. Reddy Mokalla, S. Bhushan Kumar, O. Ziouzenkova Phenolic, nutritional and molecular interaction study among different millet varieties Food Chem., 2 (2023), pp. 100-150 CrossRefGoogle Scholar [28] M. Muthamilarasan, A. Dhaka, R. Yadav, et al. Exploration of millet models for developing nutrient rich graminaceous crops Plant Sci., 242 (2016), pp. 89-97, 10.1016/j.plantsci.2015.08.023 View PDFView articleView in ScopusGoogle Scholar [29] M. Samtiya, K. Soni, S. Chawla, A. Poonia, S. Sehgal, T. Dhewa Key anti-nutrients of millet and their reduction strategies: an overview Act. Sci. Nutr. Health, 5 (12) (2021) Google Scholar [30] H.V. Sheethal, C. Baruah, R. Ananthan, T. Longvah Insights of nutritional and anti-nutritional retention in traditionally processed millets Front. Sustain. Food Syst. (2022), p. 735356, 10.3389/fsufs.2021.735356 View in ScopusGoogle Scholar [31] R. Peng, B. Zhang Foxtail millet: a new model for C4 plants Trends Plant Sci., 26 (3) (2021), pp. 199-201, 10.1016/j.tplants.2020.12.003 View PDFView articleView in ScopusGoogle Scholar [32] Z. Yang, H. Zhang, X. Li, et al. A mini foxtail millet with an Arabidopsis-like life cycle as a C4 model system Native Plants, 6 (9) (2020), pp. 1167-1178, 10.1038/s41477-020-0747-7 View in ScopusGoogle Scholar [33] R.K. Singh, M. Muthamilarasan, M. Prasad Biotechnological approaches to dissect climate-resilient traits in millets and their application in crop improvement J. Biotechnol., 327 (2021), pp. 64-73 View PDFView articleView in ScopusGoogle Scholar [34] M. Vetriventhan, V.C.R. Azevedo, H.D. Upadhyaya, et al. Genetic and genomic resources, and breeding for accelerating improvement of small millets: current status and future interventions Nucleus, 63 (2020), pp. 217-239, 10.1007/s13237-020-00322-3 View in ScopusGoogle Scholar [35] M. Johnson, S. Deshpande, M. Vetriventhan, H.D. Upadhyaya, J.G. Wallace Genome-wide population structure analyses of three minor millets: kodo millet, little millet, and proso millet Plant Genome, 12 (3) (2019) Google Scholar [36] AICSMIP Report on Compendium of Released Varieties in Small Millets [Internet]. Banglore,India http://www.dhan.org/smallmillets/docs/report/Compendium_of_Released_Varieties_in_Small_millets.pdf (2014) (Accessed 13 Mar 2019) Google Scholar [37] M. Muthamilarasan, R. Khandelwal, C.B. Yadav, et al. Identification and molecular characterization of MYB transcription factor superfamily in C4 model plant foxtail millet (Setaria italica L.) PLoS One, 9 (2014), Article e109920 CrossRefView in ScopusGoogle Scholar [38] S. Puranik, P.P. Sahu, S.N. Mandal, et al. Comprehensive genome-wide survey, genomic constitution and expression profiling of the NAC transcription factor family in foxtail millet (Setaria italica L.) PLoS One, 8 (2013), Article e64594 CrossRefView in ScopusGoogle Scholar [39] A.K. Mishra, M. Muthamilarasan, Y. Khan, et al. Genome-wide investigation and expression analyses of WD40 protein family in the model plant foxtail millet (Setaria italica L.) PLoS One, 9 (2014), Article e86852 CrossRefView in ScopusGoogle Scholar [40] C. Lata, A.K. Mishra, M. Muthamilarasan, et al. Genome-wide investigation and expression profiling of AP2/ERF transcription factor superfamily in foxtail millet (Setaria italica L.) PLoS One, 9 (2014), Article e113092 CrossRefView in ScopusGoogle Scholar [41] M. Muthamilarasan, V.S. Bonthala, R. Khandelwal, et al. Global analysis of WRKY transcription factor superfamily in Setaria identifies potential candidates involved in abiotic stress signaling Front. Plant Sci., 6 (2015), p. 910 View in ScopusGoogle Scholar [42] T.F. Yu, W.Y. Zhao, J.D. Fu, et al. Genome-wide analysis of CDPK family in foxtail millet and determination of SiCDPK24 functions in drought stress Front. Plant Sci., 9 (2018), p. 651 View in ScopusGoogle Scholar [43] W. Li, M. Chen, E. Wang, et al. Genome-wide analysis of autophagy-associated genes in foxtail millet (Setaria italica L.) and characterization of the function of SiATG8a in conferring tolerance to nitrogen starvation in rice BMC Genom., 17 (2016), p. 797 View in ScopusGoogle Scholar [44] H. Patil Arun, M. Dubey, G. Chandel Transcript analysis of differentially expressed genes in minor millets under water stress Int. J. Chem. Sci., 5 (6) (2017), pp. 1564-1568 Google Scholar [45] A. Tiwari, K. Kapil, S. Arushi, et al. Drought stress in millets and its response Mech. in Plant Defense Mech. (2022), 10.5772/intechopen.105942 Google Scholar [46] A. Nagaraja, B. Kumar, A.K. Jain, et al. Emerging diseases: need for focussed research in small millets J. Mycopathol. Res., 54 (1) (2016), pp. 1-9 Google Scholar [47] UN Global Drylands: A UN System-wide Response Prepared by the Environment Management Group, United Nations (2011) Google Scholar [48] Z. Tadele Drought Adaptation in Millets InTech, London, UK (2016) Google Scholar [49] I.P. Ajithkumar, R. Panneerselvam ROS scavenging system, osmotic maintenance, pigment and growth status of Panicum sumatrense roth. Under drought stress Cell Biochem. Biophys., 68 (3) (2014), pp. 587-595, 10.1007/s12013-013-9746-x View in ScopusGoogle Scholar [50] ABCIC Effects of climate change on Eragrostis teff in Ethiopia: a call for action to avert food security crisis ABCIC Policy Brief No. 1 (2011) Google Scholar [51] A. Matsuura, W. Tsuji, P. An, et al. Effect of pre- and post-heading water deficit on growth and grain yield of four millets Plant Prod. Sci., 15 (4) (2012), pp. 323-331 CrossRefView in ScopusGoogle Scholar [52] M. Maqsood, S.N.A. Ali Effects of drought on growth, develompent, radiation use efficiency and yield of finger millet (Eleucine coracana) Pakistan J. Bot., 39 (1) (2007), pp. 123-134 View in ScopusGoogle Scholar [53] A. Takele Genotypic variability in dry matter production, partitioning and grain yield of teff [Eragrostis teff (Zucc.) Trotter] under moisture deficit Ethiop. J. Sci., 20 (1997), pp. 177-188 Google Scholar [54] T. Winkel, J.F. Renno, W.A. Payne Effect of the timing of water deficit on growth, phenology and yield of pearl millet [Pennisetum glaucum (L.) R Br] grown in Sahelian conditions J. Exp. Bot., 48 (310) (1997), pp. 1001-1009, 10.1093/jxb/48.5.1001 View in ScopusGoogle Scholar [55] N.J. Kooyers The evolution of drought escape and avoidance in natural herbaceous populations Plant Sci., 234 (2015), pp. 155-162, 10.1007/s10535-018-0776-5 View PDFView articleView in ScopusGoogle Scholar [56] Y.J. Fang, L.Z. Xiong General mechanisms of drought response and their application in drought resistance improvement in plants Cell. Mol. Life Sci., 72 (4) (2015), pp. 673-689, 10.1007/s00018-014-1767-0 View in ScopusGoogle Scholar [57] R.A. Balsamo, C.V. Willigen, A.M. Bauer, et al. Drought tolerance of selected Eragrostis species correlates with leaf tensile properties Ann. Bot., 97 (6) (2006), pp. 985-991, 10.1093/aob/mcl068 View in ScopusGoogle Scholar [58] S.D. Merrill, D.L. Tanaka, J.D. Hanson Root length growth of eight crop species in Haplustoll soils Soil Sci. Soc. Am. J., 66 (2002), pp. 913-923 View in ScopusGoogle Scholar [59] M. Farooq, A. Wahid, N. Kobayashi, et al. Plant drought stress: effects, mechanisms and management 29 Sustainable Agriculture, Springer, Berlin/Heidelberg, Germany (2009), pp. 153-188 CrossRefGoogle Scholar [60] R. Munns, M. Tester Mechanisms of salinity tolerance Annu. Rev. Plant Biol., 59 (1) (2008), pp. 651-681, 10.1146/annurev.arplant.59.032607.092911 View in ScopusGoogle Scholar [61] N.U. Mushtaq, S. Saleem, A. Rasool, et al. Salt stress threshold in millets: perspective on cultivation on marginal lands for biomass Phyton, 90 (1) (2021), pp. 51-64 View in ScopusGoogle Scholar [62] A. Rasool, W.H. Shah, I. Tahir, et al. Exogenous application of selenium (Se) mitigates NaCl stress in proso and foxtail millets by improving their growth, physiology and biochemical parameters Acta Physiol. Plant., 42 (7) (2020), pp. 1-13, 10.1007/s11738-020-03109-w View in ScopusGoogle Scholar [63] W.H. Shah, A. Rasool, I. Tahir, et al. Exogenously applied selenium (Se) mitigates the impact of salt stress in Setaria italica L. and Panicum miliaceum L Nucleus (2020), pp. 1-13, 10.1007/s13237-020-00326-z View in ScopusGoogle Scholar [64] R. Kaliappan, M. Ramachandran, B. Rajagopal Effect of salinity on the South Indian field crops: germination and early vigour of ragi (Eluesine coracana (L.) Gaertn.) Madras Agric. J., 54 (1967), pp. 619-623 Google Scholar [65] H.B. Shailaja, S. Thirumeni Evaluation of salt-tolerance in finger millet (Eleusine coracana) genotypes at seedling stage Indian J. Agric. Sci., 77 (10) (2007), pp. 672-674 View in ScopusGoogle Scholar [66] R. Hema, R.S. Vemanna, S. Sreeramulu, et al. Stable expression of mtlD gene imparts multiple stress tolerance in finger millet PLoS One, 9 (2014), Article e99110, 10.1371/journal.pone.0099110 View in ScopusGoogle Scholar [67] N. Karjunita, N. Khumaida, S.W. Ardie Different root anatomical changes in salt-tolerant and salt-sensitive foxtail millet genotypes J. Agric. Sci., 41 (1) (2019) Google Scholar [68] Z. Rahim, G. Parveen, S. Gul, et al. Ameliorating effects of salt stress (KCl, NaCl) on growth and germination parameters of pearl millet (pennisetum americanum) Pakistan J. Agric. Sci., 33 (4) (2020), pp. 951-956 View in ScopusGoogle Scholar [69] M. Ayele, A. Blum, H.T. Nguyen Diversity for osmotic adjustment and root depth in TEFF [Eragrostis teff (Zucc) Trotter] Euphytica, 121 (2001), pp. 237-249, 10.1023/A:1012099914738 View in ScopusGoogle Scholar [70] L.N. Yogeesh, A.B. Naryanareddy, Y.A. Nanjareddy, et al. High temperature tolerant genotypes of finger millet (eleusine coracana L.) Nat. Environ. Pollut. Technol., 15 (4) (2016), pp. 1293-1296 View in ScopusGoogle Scholar [71] G.C. Nelson, M.W. Rosegrant, J. Koo, et al. Climate change: impact on agriculture and costs of adaptation Food Policy Report, IFPRI International Food Policy Research Institute, Washington, DC (2009), 10.2499/0896295354 Google Scholar [72] J.W. Knox, T.M. Hess, A. Daccache What are the projected impacts of climate change on food crop productivity in Africa and south Asia? 77 DFID Systematic Review Final Report, Cranfield University, Cranfield, Bedfordshire, U.K (2011) Google Scholar [73] M. Djanaguiraman, R. Perumal, I.A. Ciampitti, et al. Quantifying pearl millet response to high temperature stress: thresholds, sensitive stages, genetic variability and relative sensitivity of pollen and pistil Plant Cell Environ., 41 (2018), pp. 993-1007, 10.1111/pce.12931 View in ScopusGoogle Scholar [74] G. Linkemer, J.E. Board, M.E. Musgrave Waterlogging effects on growth and yield components in late-planted soybean Crop Sci., 38 (1998), pp. 1576-1584 View in ScopusGoogle Scholar [75] M.A. Hossain, S.N. Uddin Mechanisms of waterlogging tolerance in wheat: morphological and metabolic adaptations under hypoxia or anoxia Aust. J. Crop. Sci., 5 (2011), p. 1094 View in ScopusGoogle Scholar [76] A. Matsuura, P. An, K. Murata, et al. Effect of pre- and post-heading waterlogging on growth and grain yield of four millets Plant Prod. Sci., 19 (3) (2016), pp. 348-359, 10.1080/1343943X.2016.1146907 View in ScopusGoogle Scholar [77] M. Numan, D.D. Serba, A. Ligaba-Osena Alternative strategies for multi-stress tolerance and yield improvement in millets Genes, 12 (2021), p. 739, 10.3390/genes12050739 View in ScopusGoogle Scholar [78] P. Berry, M. Sterling, J. Spink, et al. Understanding and reducing lodging in cereals Adv. Agron., 84 (2004), pp. 215-269, 10.1016/S0065-2113(04)84005-7 Google Scholar [79] B. Tian, J. Wang, L. Zhang, et al. Assessment of resistance to lodging of landrace and improved cultivars in foxtail millet Euphytica, 172 (2010), pp. 295-302, 10.1007/s10681-009-9999-z View in ScopusGoogle Scholar [80] R.A. Opole Effect of Environmental Stress and Management on Grain and Biomass Yield of Finger Millet (Eleusine Coracana (L.) Gaertn.) Kansas State University, Manhattan, KS, USA (2012) Google Scholar [81] R. Shivhare, C. Lata Exploration of genetic and genomic resources for abiotic and biotic stress tolerance in pearl millet Front. Plant Sci., 7 (2016), 10.3389/fpls.2016.02069 Google Scholar [82] A. Nagaraja, J. Kumar, A.K. Jain, Y. Narasimhardu, T. Raghuchander, B. Kumar, B.H. Gowda Compendium of Small Millets Diseases (2007), p. 80 CrossRefView in ScopusGoogle Scholar [83] M. Odeph, W.W. Luasi, A. Kavoo, C. Mweu, M. Ngugi, F. Maina, N. Nzilani, W.M. Mbinda Occurrence, distribution and severity of finger millet blast caused by Magnaporthe oryzae in Kenya Afr. J. Plant Sci., 14 (4) (2020), pp. 139-149 Google Scholar [84] A. Nagaraja, S.G. Mantur Screening of Eleusine coracana germplasm for blast resistance J. Mycopath. Res., 45 (1) (2007), p. 6668 Google Scholar [85] W. Dawit, Y. Andnew The study of fungicides application and sowing date, resistance, and maturity of Eragrostis teff for the management of teff rust (Uromyces eragrostidis) Can. J. Plant Pathol., 27 (4) (2005), Article 521527 Google Scholar [86] A. Vinoth, R. Ravindhran Biofortification in millets: a sustainable approach for nutritional security Front. Plant Sci., 23 (8) (2017), p. 29, 10.3389/fpls.2017.00029 View in ScopusGoogle Scholar [87] B.N. Joshi, M.N. Sainani, K.B. Bastawade, et al. Pearl millet cysteine protease inhibitor. Evidence for the presence of two distinct sites responsible for anti-fungal and anti-feedant activities Eur. J. Biochem., 265 (1999), pp. 556-563, 10.1046/j.1432-1327.1999.00764.x View in ScopusGoogle Scholar [88] S.I. Kumar, C.G. Babu, V.C. Reddy, et al. Anti-nutritional factors in finger millet J. Nutr. Food Sci., 6 (2016), p. 3, 10.4172/2155-9600.1000491 Google Scholar [89] G. Ramachandra, T.K. Virupaksha, M. Shadaksharaswamy Relationship between tannin levels and in vitro - protein digestibility of finger millet (Eleusine coracana Gaertn) J. Agric. Food Chem., 25 (5) (1997), pp. 1101-1104, 10.1021/jf60213a046 Google Scholar [90] D.B. Wankhede, A. Shehnaj, M.R.R. Rao, et al. Carbohydrate composition of finger millet (Eleusine coracana) and foxtail millet (Setaria italica) Plant Foods Hum. Nutr., 28 (1979), pp. 293-303, 10.1007/BF01095511 View in ScopusGoogle Scholar [91] G. Chandrashekara, D.S. Raju, T.N. Pattabiraman Natural plant enzyme inhibitors, proteinase inhibitors in millets J. Sci. Food Agric., 33 (5) (1982), pp. 447-450, 10.1002/jsfa.2740330509 Google Scholar [92] P.M. Pradeep, Y.N. Sreerama Impact of processing on the phenolic profiles of small millets: evaluation of their antioxidant and enzyme inhibitory propertiesassociated with hyperglycemia Food Chem., 169 (2014), pp. 455-463, 10.1016/j.foodchem.2014.08.010 Google Scholar [93] L. Yousaf, D. Hou, H. Liaqat, et al. Millet: a review of its nutritional and functional changes during processing Int. Food Res. J., 142 (2021), Article 110197, 10.1016/j.foodres.2021.110197 View PDFView articleView in ScopusGoogle Scholar [94] M. Rani, D. Amane, L. Ananthanarayan Impact of partial replacement of rice with other selected cereals on idli batter fermentation and idli characteristics J. Food Sci. Technol., 56 (3) (2019), pp. 1192-1201, 10.1007/s13197-019-03582-3 View in ScopusGoogle Scholar [95] J.R.N. Taylor, J. Kruger Sorghum and millets: food and beverage nutritional attributes Sorghum and Millets, AACC International Press (2018), 10.1016/B978-0-12-811527-5.00007-1 AACCI Google Scholar [96] S. Shigihalli, U. Ravindra, P. Ravishankar Effect of processing methods on phytic acid content in selected white finger millet varieties Int. J. Curr. Microbiol. Appl. Sci., 7 (2) (2018), pp. 1829-1835, 10.20546/ijcmas.2018.702.220 Google Scholar [97] E.S. Chauhan, S. Sarita Effects of processing (Germination and popping) on the nutritional and anti-nutritional properties of finger millet (eleusine coracana) Curr. Res. Nutr. Food Sci., 6 (2) (2018), pp. 566-572, 10.12944/CRNFSJ.6.2.30 View in ScopusGoogle Scholar [98] L. Yousaf, D. Hou, H. Liaqat Millet: a review of its nutritional and functional changes during processing Int. Food Res. J., 142 (2021), Article 110197, 10.1016/j.foodres.2021.110197 View PDFView articleView in ScopusGoogle Scholar [99] T.L. Goron, M.N. Raizada Genetic diversity and genomic resources available for the small millet crops to accelerate a New Green Revolution Front. Plant Sci., 6 (2015), p. 157, 10.3389/fpls.2015.00157 View in ScopusGoogle Scholar [100] M. Vetriventhan, M.H.D. Upadhyaya Variability for productivity and nutritional traits in germplasm of kodo millet, an underutilized nutrient-rich climate smart crop Crop Sci., 59 (2019), pp. 1095-1106, 10.2135/cropsci2018.07.0450 View in ScopusGoogle Scholar [101] M. Singh, H.D. Upadhyaya Finger and Foxtail Millets, Genetic and Genomic Resources for Grain Cereals Improvement Academic Press (2016), pp. 291-319 CrossRefView in ScopusGoogle Scholar [102] P.S. Mundada, S.B. Kadam, A.A. Pable, et al. Recent Advances and Applicability of GBS, GWAS, and GS in Millet Crops, Genotyping by Sequencing for Crop Improvement (2022), pp. 270-294 CrossRefView in ScopusGoogle Scholar [103] H. Yue, L. Wang, H. Liu, W. Yue, X. Du, W. Song De novo assembly and characterization of the transcriptome of broomcorn millet (Panicum miliaceum L.) for gene discovery and marker development Front. Plant Sci., 7 (2016) Google Scholar [104] H.K. M'Ribu, K.W. Hilu Application of random amplified polymorphic DNA to study genetic diversity in Paspalum scrobiculatum L. (Kodo millet, Poaceae) Genet. Resour. Crop Evol., 43 (1996), pp. 203-210 View in ScopusGoogle Scholar [105] H. Brhane, T. Haileselassie, K. Tesfaye, et al. Novel GBS-based SNP markers for finger millet and their use in genetic diversity analyses Front. Genet., 26 (2022) Google Scholar [106] S. Boukail, M. Macharia, M. Miculan, et al. Genome wide association study of agronomic and seed traits in a world collection of proso millet (Panicum miliaceum L.) BMC Plant Biol., 21 (330) (2021) Google Scholar [107] A. Tiwari, D. Sharma, S. Sood, et al. Genome-wide association mapping for seed protein content in finger millet (Eleusine coracana) global collection through genotyping by sequencing J. Cereal. Sci., 91 (2020), Article 102888, 10.1016/j.jcs.2019.102888 View PDFView articleView in ScopusGoogle Scholar [108] M. Muthamilarasan, N.K. Singh, M. Prasad Multi-omics approaches for strategic improvement of stress tolerance in underutilized crop species: a climate change perspective Adv. Genet., 103 (2019), pp. 1-38, 10.1016/bs.adgen.2019.01.001 View PDFView articleView in ScopusGoogle Scholar [109] J.L. Bennetzen, J. Schmutz, H. Wang, et al. Reference genome sequence of the model plant Setaria Nat. Biotechnol., 30 (2012), pp. 555-561, 10.1038/nbt.2196 View in ScopusGoogle Scholar [110] L. Guo, J. Qiu, C. Ye, et al. Echinochloa crus-galli genome analysis provides insight into its adaptation and invasiveness as a weed Nat. Commun., 8 (2017), p. 1031, 10.1038/s41467-017-01067-5 Google Scholar [111] R. VanBuren, C. Man Wai, X. Wang, et al. Exceptional subgenome stability and functional divergence in the allotetraploid Ethiopian cereal teff Nat. Commun., 11 (1) (2020), p. 884, 10.1038/s41467-020-14724-z View in ScopusGoogle Scholar [112] V. Jaiswal, T. Bandyopadhyay, V. Gahlaut, et al. Genome-wide association study (GWAS) delineates genomic loci for ten nutritional elements in foxtail millet (Setaria italica L.) J. Cereal. Sci., 85 (2019), pp. 48-55 View PDFView articleView in ScopusGoogle Scholar [113] V. Jaiswal, S. Gupta, V. Gahlaut, et al. Genome-wide association study of major agronomic traits in foxtail millet (setaria italica L.) using ddRAD sequencing Sci. Rep., 9 (1) (2019), p. 5020, 10.1038/s41598-019-41602-6 View in ScopusGoogle Scholar [114] R.K. Srivastava, R.B. Singh, V.L. Pujarula, et al. Genome-wide association studies and genomic selection in pearl millet: advances and prospects Front. Genet., 28 (10) (2020), p. 1389, 10.3389/fgene.2019.01389 View in ScopusGoogle Scholar [115] T. Bandyopadhyaya, S.M. Swarbreck, V. Jaiswal, et al. GWAS identifies genetic loci underlying nitrogen responsiveness in the climate resilient C4 model Setaria italica (L.) J. Adv. Res. (2022), 10.1016/j.jare.2022.01.010 Google Scholar [116] S. Puranik, P.P. Sahu, S. Beynon, et al. Genome-wide association mapping and comparative genomics identifies genomic regions governing grain nutritional traits in finger millet (Eleusine coracana L. Gaertn.) New Phytol., 2 (6) (2020), pp. 649-662, 10.1002/ppp3.10120 View in ScopusGoogle Scholar [117] H. Shinde, K. Tanaka, A. Dudhate, et al. Comparative de novo transcriptomic profiling of the salinity stress responsiveness in contrasting pearl millet lines Environ. Exp. Bot., 155 (2018), pp. 619-627, 10.1016/j.envexpbot.2018.07.008 View PDFView articleView in ScopusGoogle Scholar [118] S. Jaiswal, T.J. Antala, M.K. Mandavia, et al. Transcriptomic signature of drought response in pearl millet (Pennisetum glaucum (L.) and development of web-genomic resources Sci. Rep., 8 (2018), p. 3382, 10.1038/s41598-018-21560-1 View in ScopusGoogle Scholar [119] H. Shinde, A. Dudhate, L. Anand, et al. Small RNA sequencing reveals the role of pearl millet miRNAs and their targets in salinity stress responses South Afr. J. Bot., 132 (2020), pp. 395-402, 10.1016/j.sajb.2020.06.011 View PDFView articleView in ScopusGoogle Scholar [120] H. Rahman, N. Jagadeeshselvam, R. Valarmathi, et al. Transcriptome analysis of salinity responsiveness in contrasting genotypes of finger millet (Eleusine coracana L.) through RNA-sequencing Plant Mol. Biol., 85 (4–5) (2014), pp. 485-503, 10.1007/s11103-014-0199-4 View in ScopusGoogle Scholar [121] C. Ramakrishna, S. Singh, S. Raghavendrarao, et al. The membrane tethered transcription factor EcbZIP17 from finger millet promotes plant growth and enhances tolerance to abiotic stresses Sci. Rep., 8 (2018), p. 2148, 10.1038/s41598-018-19766-4 View in ScopusGoogle Scholar [122] H. Rahman, V. Ramanathan, J. Nallathambi, et al. Over-expression of a NAC 67 transcription factor from finger millet (Eleusine coracana L.) confers tolerance against salinity and drought stress in rice BMC Biotechnol., 16 (1) (2016), p. 35, 10.1186/s12896-016-0261-1 View in ScopusGoogle Scholar [123] N. Mirza, G. Taj, S. Arora, et al. Transcriptional expression analysis of genes involved in regulation of calcium translocation and storage in finger millet (Eleusine coracana L. Gartn.) Gene, 550 (2) (2014), pp. 171-179, 10.1016/j.gene.2014.08.005 View PDFView articleView in ScopusGoogle Scholar [124] S.B. Kokane, R.K. Pathak, M. Singh, et al. The role of tripartite interaction of calcium sensors and transporters in the accumulation of calcium in finger millet grain Biol. Plant., 62 (2) (2018), pp. 325-334 CrossRefView in ScopusGoogle Scholar [125] J. Pan, Z. Li, Q. Wang, et al. Comparative proteomic investigation of drought responses in foxtail millet BMC Plant Biol., 18 (1) (2018), p. 315, 10.1186/s12870-018-1533-9 Google Scholar [126] B.K. Babu, P.K. Agrawal, D. Pandey, et al. Molecular analysis of world collection of finger millet accessions for blast disease resistance using functional ssr markers SABRAO J. Breed. Genet., 46 (2) (2014), pp. 202-216 View in ScopusGoogle Scholar [127] Z.J. Li, G.G. Jia, X.Y. Li, et al. Identification of blast-resistance loci through genome-wide association analysis in foxtail millet (Setaria italica (L.) Beauv.) J. Integr. Agric., 20 (8) (2021), pp. 2056-2064 View PDFView articleView in ScopusGoogle Scholar [128] M. Ramakrishnan, S.A. Ceasar, V. Duraipandiyan, et al. Tracing QTLs for leaf blast resistance and agronomic performance of finger millet (eleusine coracana (L.) gaertn.) genotypes through association mapping and in silico comparative genomics analyses PLoS One, 11 (7) (2016), Article e0159264, 10.1371/journal.pone.0159264 View in ScopusGoogle Scholar [129] P. Panwar, A.K. Jha, P.K. Pandey, et al. Functional markers based molecular characterization and cloning of resistance gene analogs encoding NBS-LRR disease resistance proteins in finger millet (Eleusine coracana) Mol. Biol. Rep., 38 (5) (2011), pp. 3427-3436, 10.1007/s11033-010-0452-0 View in ScopusGoogle Scholar [130] O.P. Yadav, S.K. Gupta, M. Govindaraj, et al. Genetic gains in pearl millet in India: insights into historic breeding strategies and future perspective Front. Plant Sci., 30 (12) (2021), Article 645038, 10.3389/fpls.2021.645038 View in ScopusGoogle Scholar [131] J.P. Jency, R. Rajasekaran, R.K. Singh, et al. Induced mutagenesis enhances lodging resistance and photosynthetic efficiency of kodomillet (Paspalum scrobiculatum) Agronomy, 10 (2) (2021), p. 227, 10.3390/agronomy10020227 Google Scholar [132] J. Zhang, X. Zhang, R. Chen, et al. Generation of transgene-free semidwarf maize plants by gene editing of gibberellin-oxidase20-3 using CRISPR/Cas9 Front. Plant Sci., 11 (2020), p. 1048, 10.3389/fpls.2020.01048 View PDFView articleGoogle Scholar [133] I. Fayos, A.C. Meunier, A. Vernet, et al. Assessment of the roles of OsSPO11-2 and OsSPO11-4 in rice meiosis using CRISPR/Cas9 mutagenesis J. Exp. Bot., 71 (22) (2020), pp. 7046-7058, 10.1093/jxb/eraa391 View in ScopusGoogle Scholar [134] J. Li, Z. Wang, G. He, et al. CRISPR/Cas9-mediated disruption of TaNP1 genes results in complete male sterility in bread wheat J. Genet. Genomics., 47 (2020), pp. 263-272, 10.1016/j.jgg.2020.05.004 View PDFView articleView in ScopusGoogle Scholar [135] A. Ceasar Genome-editing in millets: current knowledge and future perspectives Mol. Biol. Rep., 49 (2022), pp. 773-781, 10.1007/s11033-021-06975-w View in ScopusGoogle Scholar [136] H. Gao, M.J. Gadlage, H.R. Lafitte, et al. Superior field performance of waxy corn engineered using CRISPR-Cas9 Nat. Biotechnol., 38 (5) (2020), pp. 579-581, 10.1038/s41587-020-0444-0 View in ScopusGoogle Scholar [137] D. Rodríguez-Leal, Z.H. Lemmon, J. Man, et al. Engineering quantitative trait variation for crop improvement by genome editing Cell, 171 (2021), pp. 470-480 Google Scholar [138] Z. Cheng, Y. Sun, S. Yang, et al. Establishing in planta haploid inducer line by edited SiMTL in foxtail millet (Setaria italica) Plant Biotechnol. J, 19 (6) (2021), pp. 1089-1091, 10.1111/pbi.13584 View in ScopusGoogle Scholar [139] S.A. Ceasar, S. Ignacimuthu Genetic engineering of millets: current status and future prospects Biotechnol. Lett., 31 (2009), pp. 779-788, 10.1007/s10529-009-9933-4 View in ScopusGoogle Scholar [140] P. Sood, R.K. Singh, M. Prasad Millets genetic engineering: the progress made and prospects for the future Plant Cell Tissue Organ Cult., 137 (2019), pp. 421-439, 10.1007/s11240-019-01587-6 View in ScopusGoogle Scholar [141] S.A. Ceasar, S. Ignacimuthu Agrobacterium-mediated transformation of fnger millet (Eleusine coracana (L.) Gaertn.) using shoot apex explants Plant Cell Rep., 30 (2011), pp. 1759-1770, 10.1007/s00299-011-1084-0 View in ScopusGoogle Scholar [142] S. Ignacimuthu, S.A. Ceasar Development of transgenic finger millet (Eleusine coracana (L.) Gaertn.) resistant to leaf blast disease J. Biosci., 37 (1) (2012), pp. 135-147, 10.1007/s12038-011-9178-y View in ScopusGoogle Scholar [143] L. Satish, S.A. Ceasar, M. Ramesh Improved Agrobacteriummediated transformation and direct plant regeneration in four cultivars of fnger millet (Eleusine coracana (L.) Gaertn.) Plant Cell Tissue Organ Cult., 131 (2017), pp. 547-565, 10.1007/s11240-017-1305-5 View in ScopusGoogle Scholar [144] A.M. Latha, K.V. Rao, V.D. Reddy Production of transgenic plants resistant to leaf blast disease in fnger millet (Eleusine coracana (L.) Gaertn.) Plant Sci., 169 (2005), pp. 657-667 View PDFView articleView in ScopusGoogle Scholar [145] S. Mahalaksmi, G.S. Christopher, T.P. Reddy, et al. Isolation of a cDNA clone (PcSrp) encoding serine-rich-protein from Porteresia coarctata T. and its expression in yeast and fnger millet [Eleusine coracana (L.) Gaertn.] afording salt tolerance Planta, 224 (2016), pp. 347-359 Google Scholar [146] Y. Ramegowda, R. Venkategowda, P. Jagadish, et al. Expression of a rice Zn transporter, OsZIP1, increases Zn concentration in tobacco and finger millet transgenic plants Plant Biotechnol. Rep., 7 (2013), pp. 309-319 CrossRefView in ScopusGoogle Scholar [147] E. Anjaneyulu, P.S. Reddy, M.S.L. Sunita, et al. Salt tolerance and activity of antioxidative enzymes of transgenic finger millet overexpressing a vacuolar H+-pyrophosphatase gene (SbVPPase) from Sorghum bicolor J. Plant Physiol., 171 (2014), pp. 789-798, 10.1016/j.jplph.2014.02.001 View PDFView articleView in ScopusGoogle Scholar [148] L. Yinghui, Y. Jingjuan, Z. Qian, et al. Genetic transformation of millet (Setaria italica) by Agrobacterium-mediated J. Agric. Biotechnol., 13 (2005), pp. 32-37 Google Scholar [149] P. Sood, R.K. Singh, M. Prasad An efficient Agrobacterium mediated genetic transformation method for foxtail millet (Setaria italica L.) Plant Cell Rep., 39 (2020), pp. 511-525, 10.1007/s00299-019-02507-w View in ScopusGoogle Scholar [150] P. Gupta, S. Raghuvanshi, A. Tyagi Assessment of the efciency of various gene promoters via biolistics in leaf and regenerating seed callus of millets, Eleusine coracana and Echinochloa crusgalli Plant Biotechnol., 18 (4) (2001), pp. 275-282, 10.5511/plantbiotechnology.18.275 View in ScopusGoogle Scholar [151] R. Bhatt, P.P. Asopa, R. Jain, et al. Optimization of Agrobacterium-mediated genetic transformation in Paspalum scrobiculatum L. (kodo millet) Agronomy, 11 (6) (2021), p. 1104, 10.3390/agronomy11061104 View in ScopusGoogle Scholar [152] H.M. Lam, X. Xu, X. Liu, et al. Resequencing of 31 wild and cultivated soybean genomes identifies patterns of genetic diversity and selection Nat. Genet., 42 (12) (2010), pp. 1053-1059, 10.1038/ng.715 View in ScopusGoogle Scholar [153] R.A. Arthur, J.L. Bennetzen Discovery of lineage-specific genome change in rice through analysis of resequencing data Genetics, 209 (2) (2018), pp. 617-626, 10.1534/genetics.118.300848 View in ScopusGoogle Scholar [154] A.W. Khan, V. Garg, M. Roorkiwal, et al. Super-pangenome by integrating the wild side of a species for accelerated crop improvement Trends Plant Sci., 25 (2) (2020), pp. 148-158, 10.1016/j.tplants.2019.10.012 View PDFView articleView in ScopusGoogle Scholar [155] H. Bai, Y. Cao, J. Quan, et al. Identifying the genome-wide sequence variations and developing new molecular markers for genetics research by re-sequencing a Landrace cultivar of foxtail millet PLoS One, 8 (9) (2013), Article e73514, 10.1371/journal.pone.0073514 View in ScopusGoogle Scholar [156] T. Hoshino, T. Nakamura, Y. Seimiya, et al. Production of a fully waxy line and analysis of waxy genes in the allohexaploid crop, Japanese barnyard millet Plant Breed., 129 (4) (2010), pp. 349-355, 10.1111/j.1439-0523.2009.01668.x View in ScopusGoogle Scholar [157] S. Mbithi-Mwikya, J.V. Camp, Y. Yiru, et al. Nutrient and antinutrient changes in finger millet (Eleusine coracana) during sprouting LWT--Food Sci. Technol., 33 (2000), pp. 9-14, 10.1006/fstl.1999.0605 View PDFView articleView in ScopusGoogle Scholar [158] E.L. Kemper, G.C. Neto, F. Papes, et al. The role of Opaque2 in the control of lysine degrading activities in developing maize endosperm Plant Cell, 11 (1999), pp. 1981-1993, 10.1105/tpc.11.10.1981 View in ScopusGoogle Scholar [159] M. Muthamilarasan, M. Prasad Advances in Setaria genomics for genetic improvement of cereals and bioenergy grasses Theor. Appl. Genet., 128 (2015), pp. 1-14, 10.1007/s00122-014-2399-3 View in ScopusGoogle Scholar [160] U.M. Singh, M. Chandra, S.C. Shankhdhar, et al. Transcriptome wide identification and validation of calcium sensor gene family in the developing spikes of finger millet genotypes for elucidating its role in grain calcium accumulation PLoS One, 9 (2014), Article e103963, 10.1371/journal.pone.0103963 View in ScopusGoogle Scholar [161] T. Meng, X. Jing, Z. Yan, et al. A survey on machine learning for data fusion Inf. Fusion, 57 (2020), pp. 115-129 View PDFView articleView in ScopusGoogle Scholar [162] M. Niazian, G. Niedbała Machine learning for plant breeding and biotechnology Agriculture, 10 (10) (2020), p. 436 CrossRefGoogle Scholar [163] R. Barth, J. IJsselmuiden, J. Hemming, et al. Synthetic bootstrapping of convolutional neural networks for semantic plant part segmentation Comput. Electron. Agric., 161 (2019), pp. 291-304, 10.1016/j.compag.2017.11.040 View PDFView articleView in ScopusGoogle Scholar [164] N. Vijay, G.C. Mishra Time series forecasting using ARIMA and ANN models for production of pearl millet (BAJRA) crop of Karnataka India Int. J. Curr. Microbiol. Appl. Sci., 7 (12) (2018), pp. 880-889, 10.20546/ijcmas.2018.712.110 Google Scholar [165] N. Kundu, G. Rani, V.S. Dhaka, et al. IoT and interpretable machine learning based framework for disease prediction in pearl millet Sensors, 21 (16) (2021), p. 5386 CrossRefView in ScopusGoogle Scholar [166] S. Coulibaly, B. Kamsu-Foguem, D. Kamissoko, et al. Deep neural networks with transfer learning in millet crop images Comput. Ind., 108 (2019), pp. 115-120, 10.1016/j.compind.2019.02.003 View PDFView articleView in ScopusGoogle Scholar [167] N. Kundu, G. Rani, V.S. Dhaka Seeds classification and quality testing using deep learning and YOLO v5. DSMLAI '21': proceedings of the international conference on data science Mach. Learn. Artif. Intell. (2021), pp. 153-160, 10.1145/3484824.3484913 View in ScopusGoogle Scholar [168] J. Madhuri, M. Indiramma Artificial neural networks based integrated crop recommendation system using soil and climatic parameters Indian J. Sci. Technol., 14 (19) (2021), pp. 1587-1597 CrossRefGoogle Scholar [169] Y. Wang, T. Li, G. Jin, et al. Qualitative and quantitative diagnosis of nitrogen nutrition of tea plants under field condition using hyperspectral imaging coupled with chemometrics J. Sci. Food Agric., 100 (2020), pp. 161-167, 10.1002/jsfa.10009 View PDFView articleGoogle Scholar [170] B.T.S. Gowda, A. Seetharam, S. Viswanath, et al. Incorporation of blast resistance to Indian elite finger millet cultivars from African cv. lE 1012 SABRAO J., 18 (1986), p. 119‐ 120 Google Scholar [171] R.L. Ravikumar, A. Seetharam, B.T.S. Gowda Identification of sources of stable resistance to finger millet (Eleusine coracana Gaertn.) blast SABRAO J., 22 (1990), p. 117‐121 Google Scholar [172] D.S.P. Kumar, V.R. Sashidhar, R.L. Ravikumar, et al. Identification of true dwarfing genes in foxtail millet (Setaria italica Beauv.) Euphytica, 60 (1992), p. 207‐ 212 Google Scholar [173] B.J. Naik, B.T.S. Gowda, A. Seetharam Pattern of variability in relation to domestication of finger millet in Africa and India K.W. Riley, S.C. Gupta, A. Seetharam, J. Moshanga (Eds.), Recent Advances in Small Millets, Proc. Second IntI. Small Millets Workshop, Oxford‐IBH Publishing Company (1993), pp. 347-364 Google Scholar [174] J. Yue, C. Li, Y. Liu, et al. A remorin gene SiREM6, the target gene of SiARDP, from foxtail millet (Setaria italica) promotes high salt tolerance in transgenic Arabidopsis PLoS One, 9 (6) (2014), Article e100772, 10.1371/journal.pone.0100772 View in ScopusGoogle Scholar [175] L. Ge, Y. Dou, M. Li, et al. SiMYB3 in foxtail millet (setaria italica) confers tolerance to low-nitrogen stress by regulating root growth in transgenic plants Int. J. Mol. Sci., 20 (22) (2019), p. 5741, 10.3390/ijms20225741 View in ScopusGoogle Scholar [176] C. Xu, M. Luo, X. Sun, et al. SiMYB19 from foxtail millet (setaria italica) confers transgenic rice tolerance to high salt stress in the field Int. J. Mol. Sci., 23 (2) (2022), p. 756, 10.3390/ijms23020756 View PDFView articleGoogle Scholar [177] W. Xu, W. Tang, C. Wang, et al. SiMYB56 confers drought stress tolerance in transgenic rice by regulating lignin biosynthesis and ABA signaling pathway Front. Plant Sci., 18 (11) (2020), p. 785, 10.3389/fpls.2020.00785 View in ScopusGoogle Scholar [178] R.K. Singh, V.K. Singh, S. Raghavendrarao, et al. Expression of finger millet EcDehydrin7 in transgenic tobacco confers tolerance to drought stress Appl. Biochem. Biotechnol., 177 (1) (2015), pp. 207-216, 10.1007/s12010-015-1738-4 View in ScopusGoogle Scholar [179] V. Ramegowda, M. Senthil-Kumar, K.N. Nataraja, et al. Expression of a finger millet transcription Factor,EcNAC1, in tobacco confers abiotic stress-tolerance PLoS One, 7 (7) (2012), Article e40397, 10.1371/journal.pone.0040397 View in ScopusGoogle Scholar [180] C. Li, J. Yue, X. Wu, et al. An ABA-responsive DRE-binding protein gene from Setaria italica, SiARDP, the target gene of SiAREB, plays a critical role under drought stress J. Exp. Bot., 65 (18) (2014), pp. 5415-5427, 10.1093/jxb/eru302 View in ScopusGoogle Scholar [181] W.W. Li, M. Chen, L. Zhong, et al. Overexpression of the autophagy-related gene SiATG8a from foxtail millet (Setaria italica L.) confers tolerance to both nitrogen starvation and drought stress in Arabidopsis Biochem. Biophys. Res. Commun., 468 (4) (2015), pp. 800-806, 10.1016/j.bbrc.2015.11.035 View PDFView articleView in ScopusGoogle Scholar [182] S. Huang, L.Q. Hu, D.B. Xu, et al. Transcription factor SiNF-YA5 from foxtail millet (setaria italica) conferred tolerance to high-salt stress through ABA-independent pathway in transgenic Arabidopsis Acta Agron. Sin., 42 (12) (2016), pp. 1787-1797, 10.3724/SP.J.1006.2016.01787 View in ScopusGoogle Scholar [183] S. Singh, R. Chopperla, P. Shingote, et al. Overexpression of EcDREB2A transcription factor from finger millet in tobacco enhances tolerance to heat stress through ROS scavenging J. Biotechnol., 336 (2021), pp. 10-24, 10.1016/j.jbiotec.2021.06.013 View PDFView articleView in ScopusGoogle Scholar [184] A. Nagaraja, I.K. Das Disease Resistance in Pearl Millet and Small Millets, Biotic Stress Resistance in Millets Academic Press (2016), pp. 69-104 View PDFView articleView in ScopusGoogle Scholar [185] A. Kumar, D. Sharma, A. Tiwari, J.P. Jaiswal, N.K. Singh, S. Sood Genotyping-by-sequencing analysis for determining population structure of finger millet germplasm of diverse origins Plant Genome, 9 (2) (2016), pp. 1-15 Google Scholar [186] D. Gimode, D.A. Odeny, E.P. de Villiers EP, S. Wanyonyi, M.M. Dida, E.E. Mneney, A. Muchugi, J. Machuka, S.M. de Villiers Identification of SNP and SSR markers in finger millet using next generation sequencing technologies PLoS One, 11 (7) (2016) Google Scholar [187] M. Hatakeyama, S. Aluri, M.T. Balachadran, et al. Multiple hybrid de novo genome assembly of finger millet, an orphan allotetraploid crop DNA Res., 25 (1) (2018), pp. 39-47 CrossRefView in ScopusGoogle Scholar [188] S. Zhang, C. Tang, Q. Zhao, et al. Development of highly polymorphic simple sequence repeat markers using genome-wide microsatellite variant analysis in Foxtail millet [Setaria italica (L.) P. Beauv.] BMC Genom., 15 (78) (2014) Google Scholar [189] K. Kumari, M. Muthamilarasan, G. Misra, S. Gupta, A. Subramanian, S.K. Parida, D. Chattopadhyay, M. Prasad Development of eSSR-markers in setaria italica and their applicability in studying genetic diversity, cross-transferability and comparative mapping in millet and non-millet species PLoS One, 8 (6) (2013) Google Scholar [190] S. Shingane, J.V. Patil, S. Gomashe, D. Chand Assessing genetic diversity among foxtail millet (setaria italica (L.) P. Beauv.) accessions using RAPD and ISSR markers Int. J. Bioresour. Stress Manag., 9 (1) (2018), pp. 1-6 Google Scholar [191] Y. Wang, X. Wang, S. Sun, C. Jin, J. Su, J. Wei, X. Luo, J. Wen, T. Wei, S.K. Sahu, H. Zou GWAS, MWAS and mGWAS provide insights into precision agriculture based on genotype-dependent microbial effects in foxtail millet Nat. Commun., 13 (2022), p. 5913 View in ScopusGoogle Scholar [192] T. Liu, J. He, K. Dong, et al. Genome-wide identification of quantitative trait loci for morpho-agronomic and yield-related traits in foxtail millet (Setaria italica) across multi-environments Mol. Genet. Genom., 297 (2022), pp. 873-888 CrossRefView in ScopusGoogle Scholar [193] M. Yazdizadeh, L. Fahmideh, G. Mohammadi-Nejad, et al. Association analysis between agronomic traits and AFLP markers in a wide germplasm of proso millet (Panicum miliaceum L.) under normal and salinity stress conditions BMC Plant Biol., 20 (2020), p. 427, 10.1186/s12870-020-02639-2 View in ScopusGoogle Scholar [194] H. Desai, R. Hamid, Z. Ghorbanzadeh, N. Bhut, S.M. Padhiyar, J. Kheni, R.S. Tomar Genic microsatellite marker characterization and development in little millet (Panicum sumatrense) using transcriptome sequencing Sci. Rep., 11 (2021) Google Scholar [195] N. Tiwari, S. Tiwari, N. Tripathi Genetic characterization of Indian little millet (Panicum sumatrense) genotypes using random amplified polymorphic DNA markers Agric. Nat. Resour., 52 (4) (2018), pp. 347-353 View PDFView articleCrossRefView in ScopusGoogle Scholar [196] M. Manimekalai, M. Dhasarathan, A. Karthikeyan, et al. Genetic diversity in the barnyard millet (Echinochola frumentacea) germplasms revealed by morphological traits and simple sequence repeat markers Curr. Plant Biol., 14 (2018), pp. 71-78 View in ScopusGoogle Scholar [197] S. Mahalakshmi, G.S.B. Christopher, T.P. Reddy, et al. Isolation of a cDNA clone (PcSrp) encoding serine-rich-protein from Porteresia coarctata T. and its expression in yeast and finger millet (Eleusine coracana L.) affording salt tolerance Planta, 224 (2006), pp. 347-359, 10.1007/s00425-005-0218-4 View in ScopusGoogle Scholar [198] Y. Pan, J. Li, L. Jiao, et al. A non-specific Setaria italica lipid transfer protein gene plays a critical role under abiotic stress Front. Plant Sci., 7 (2016), p. 1752 View in ScopusGoogle Scholar [199] S.A. Ceasar, A. Baker, S. Ignacimuthu Functional characterization of the PHT1 family transporters of foxtail millet with development of a novel Agrobacterium -mediated transformation procedure Sci. Rep., 7 (2017), pp. 1-16, 10.1038/s41598-017-14447-0 Google Scholar [200] J. Li, Y. Dong, C. Li, et al. SiASR4, the target gene of SiARDP from Setaria italica, improves abiotic stress adaption in plants Front. Plant Sci., 7 (2017), p. 2053 Google Scholar [201] Y.X. Luan, B.S. Wang, Q. Zhao, et al. Ectopic expression of foxtail millet zip-like gene, SiPf40, in transgenic rice plants causes a pleiotropic phenotype affecting tillering, vascular distribution and root development Sci. China Life Sci., 53 (2010), pp. 1450-1458, 10.1007/s11427-010-4090-5 View in ScopusGoogle Scholar [202] Z. Dong, H. Zhao, J. He, et al. Overexpression of a foxtail millet Acetyl-CoA carboxylase gene in maize increases sethoxydim resistance and oil content Afr. J. Biotechnol., 10 (2011), p. 20 CrossRefGoogle Scholar [203] R. Yang, M. Chen, J.C. Sun, et al. Genome-wide analysis of LIM family genes in foxtail millet (setaria italica L.) and characterization of the role of SiWLIM2b in drought tolerance Int. J. Mol. Sci., 20 (6) (2019), p. 1303, 10.3390/ijms20061303 View in ScopusGoogle Scholar [204] Z. Zhao, S. Tang, W. Li, et al. Overexpression of a BRASSINAZOLE RESISTANT 1 homolog attenuates drought tolerance by suppressing the expression of PLETHORA-LIKE 1 in Setaria italica Crops J, 9 (5) (2021), pp. 1208-1213, 10.1016/j.cj.2021.02.006 View PDFView articleView in ScopusGoogle Scholar [205] L.N. Xie, M. Chen, D.H. Min, et al. The NAC-like transcription factor SiNAC110 in foxtail millet (Setaria italica L.) confers tolerance to drought and high salt stress through an ABA independent signaling pathway J. Integr. Agric., 16 (3) (2017), pp. 559-571 View PDFView articleView in ScopusGoogle Scholar [206] M. Zhao, S. Tang, H. Zhang, et al. DROOPY LEAF1 controls leaf architecture by orchestrating early brassinosteroid signaling Proc. Natl. Acad. Sci. USA, 117 (35) (2020), 10.1073/pnas.2002278117 Google Scholar [207] H. Wang, S. Tang, H. Zhi, et al. The boron transporter SiBOR1 functions in cell wall integrity, cellular homeostasis, and panicle development in foxtail millet Crops J (2021), 10.1016/j.cj.2021.05.002 Google Scholar [208] J. Liu, C. Jiang, L. Kang, et al. Over-expression of a 14-3-3 protein from foxtail millet improves plant tolerance to salinity stress inArabidopsis thaliana Front. Plant Sci., 11 (2020), p. 449, 10.3389/fpls.2020.00449 View PDFView articleGoogle Scholar [209] Z. Zhao, S. Tang, Y. Zhang, et al. Evolutionary analysis and functional characterization of SiBRI1 as a Brassinosteroid receptor gene in foxtail millet BMC Plant Biol., 21 (2021), p. 291, 10.1186/s12870-021-03081-8 View in ScopusGoogle Scholar [210] H. Zhang, W. Xiao, W. Yu, et al. Foxtail millet SiHAK1 excites extreme high-affinity K+ uptake to maintain K+ homeostasis under low K+ or salt stress Plant Cell Rep., 37 (2018), pp. 1533-1546, 10.1007/s00299-018-2325-2 View in ScopusGoogle Scholar [211] Y. Peng, J. Zhang, G. Cao, et al. Overexpression of a PLDα1 gene from Setaria italica enhances the sensitivity of Arabidopsis to abscisic acid and improves its drought tolerance Plant Cell Rep., 29 (2010), pp. 793-802 CrossRefView in ScopusGoogle Scholar [212] E. Gebre, L. Gugsa, U. Schlüter, et al. Transformation of teff (Eragrostis tef) by Agrobacterium through immature embryo regeneration system for inducing semi-dwarfism South Afr. J. Bot., 87 (2013), pp. 9-17, 10.1016/j.sajb.2013.03.004 View PDFView articleView in ScopusGoogle Scholar [213] C.S. Lin, C.T. Hsu, L.H. Yang, et al. Application of protoplast technology to CRISPR/Cas9 mutagenesis: from single-cell mutation detection to mutant plant regeneration Plant Biotechnol. J., 16 (7) (2018), pp. 1295-1310, 10.1111/pbi.12870 View in ScopusGoogle Scholar [214] H.D. Upadhyaya, S. Ramesh, S. Sharma, et al. Genetic diversity for grain nutrients contents in a core collection of finger millet (Eleusine coracana (L.) Gaertn.) germplasm Field Crop. Res., 121 (1) (2011), pp. 42-52, 10.1016/j.fcr.2010.11.017 View PDFView articleView in ScopusGoogle Scholar [215] M. Vetriventhan, H.D. Upadhyaya Diversity and trait-specific sources for productivity and nutritional traits in the global proso millet (Panicum miliaceum L.) germplasm collection Crops J, 6 (2018), pp. 451-463, 10.1016/j.cj.2018.04.002 View PDFView articleView in ScopusGoogle Scholar [216] H.D. Upadhyaya, C.R. Ravishankar, Y. Narasimhudu, et al. Identification of trait-specific germplasm and developing a mini core collection for efficient use of foxtail millet genetic resources in crop improvement Field Crop. Res., 124 (3) (2011), pp. 459-467, 10.1016/j.fcr.2011.08.004 View PDFView articleView in ScopusGoogle Scholar [217] M. Ramakrishnan, S.A. Ceasar, K.K. Vinod, et al. Identification of putative QTLs for seedling stage phosphorus starvation response in finger millet (Eleusine coracana L. Gaertn.) by association mapping and cross species synteny analysis PLoS One, 12 (8) (2017), Article e0183261, 10.1371/journal.pone.0183261 View in ScopusGoogle Scholar [218] L. Krishnamurthy, H.D. Upadhyaya, J. Kashiwagi, et al. Variation in drought-tolerance components and their interrelationships in the minicore collection of finger millet germplasm Crop Sci., 56 (2016), pp. 1914-1926 CrossRefView in ScopusGoogle Scholar [219] L. Krishnamurthy, H.D. Upadhyaya, R. Purushothaman The extent of variation in salinity tolerance of the minicore collection of finger millet (Eleusine coracana L. Gaertn.) germplasm Plant Sci., 227 (2014), pp. 51-59, 10.1016/j.plantsci.2014.07.001 View PDFView articleView in ScopusGoogle Scholar [220] T.K. Babu, R.P. Thakur, H.D. Upadhyaya, et al. Resistance to blast (Magnaporthe grisea) in a mini-core collection of finger millet germplasm Eur. J. Plant Pathol., 135 (2013), pp. 299-311, 10.1007/s10658-012-0086-2 View in ScopusGoogle Scholar [221] R. Sharma, A.G. Girish, H.D. Upadhyaya, et al. Identification of blast resistance in a core collection of foxtail millet germplasm Plant Dis., 98 (4) (2014), pp. 519-524, 10.1094/PDIS-06-13-0593-RE View in ScopusGoogle Scholar [222] H.D. Upadhyaya, M. Vetriventhan, S.L. Dwivedi, et al. Proso, barnyard, little and kodo millets M. Singh, H.D. Upadhyaya (Eds.), Genet Genomic Resour Grain Cereal Improv, Academic Press, Oxford (2015), pp. 321-343 http://oar.icrisat.org/id/eprint/9321 Google Scholar [223] M. Vetriventhan, H.D. Upadhyaya, S.L. Dwived, et al. 7-Finger and foxtail millets M. Singh, H.D. Upadhyaya (Eds.), Genetic and Genomic Resources for Grain Cereals Improvement, Academic Press, San Diego (2016), pp. 291-319 View PDFView articleView in ScopusGoogle Scholar [224] C. Nigus Genetic variation of teff [Eragrostis teff (Zucc.) Trotter] genotypes for reaction to teff shoot fly [Atherigona hyalinipennis Van Emde], at Maysiye, Northern Ethiopia J. Plant Breed Crop Sci., 10 (2018), pp. 146-152 Google Scholar [225] N. Akbar, S. Gupta, A. Tiwari, et al. Characterization of metabolic network of oxalic acid biosynthesis through RNA seq data analysis of developing spikes of finger millet (Eleusine coracana): deciphering the role of key genes involved in oxalate formation in relation to grain calcium accumulation Gene, 649 (2018), pp. 40-49, 10.1016/j.gene.2018.01.071 View PDFView articleView in ScopusGoogle Scholar [226] M.S. Parvathi, K.N. Nataraja, Y.A.N. Reddy, et al. Transcriptome analysis of finger millet (Eleusine coracana (L.) Gaertn.) reveals unique drought responsive genes J. Genet., 98 (2018), p. 46 Google Scholar [227] J. Li, X. Li, Q. Yang, et al. Proteomic changes in the grains of foxtail millet (Setaria italica (L.) beau) under drought stress Spanish J. Agric. Res., 17 (2) (2019), Article e0802 CrossRefView in ScopusGoogle Scholar [228] C.G. de Oliveira Dal'Molin, C. Orellana, L. Gebbie, et al. Metabolic reconstruction of setaria italica: a systems biology approach for integrating tissue-specific omics and pathway analysis of bioenergy grasses Front. Plant Sci., 7 (2016), p. 1138, 10.3389/fpls.2016.01138 View in ScopusGoogle Scholar [229] S. Li, X. Dong, G. Fan, et al. Comprehensive profiling and inheritance patterns of metabolites in foxtail millet Front. Plant Sci., 9 (2018), p. 1716, 10.3389/fpls.2018.01716 View in ScopusGoogle Scholar [230] B.J. Agtuca, S.A. Stopka, T.R. Tuleski, et al. In-situ metabolomic analysis of setaria viridis roots colonized by beneficial endophytic bacteria MPMI (Mol. Plant-Microbe Interact.), 33 (2) (2020), pp. 272-283, 10.1094/MPMI-06-19-0174-R View in ScopusGoogle Scholar [231] Y. Zhang, C. Zhang, X. Man, et al. Functional characterization of the SiFPGS2 gene of foxtail millet in folate accumulation and root development Plant Growth Regul., 99 (2023), pp. 137-147, 10.1007/s10725-022-00904-y Google Scholar Cited by (3) Farmer-preferred traits and variety choices for finger millet in Uganda 2024, Frontiers in Sustainable Food Systems Early presence/introduction of African and East Asian millets in India: integral to traditional agriculture 2023, Nucleus (India) Validating the Nutraceutical Significance of Minor Millets by Employing Nutritional–Antinutritional Profiling 2023, Life © 2023 The Authors. Published by Elsevier Ltd. Recommended articles Versatility of Stenotrophomonas maltophilia: Ecological roles of RND efflux pumps Heliyon, Volume 9, Issue 4, 2023, Article e14639 Amandine Chauviat, …, Sabine Favre-Bonté View PDF The association between mannose binding lectin gene polymorphisms and the risk of neonatal sepsis: an updated meta-analysis Heliyon, Volume 9, Issue 4, 2023, Article e14905 Jinjin Ma, …, Changjun Ren View PDF Remediation of phthalate acid esters from contaminated environment—Insights on the bioremedial approaches and future perspectives Heliyon, Volume 9, Issue 4, 2023, Article e14945 Tarini Prasad Sahoo, Madhava Anil Kumar View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 3 Captures Readers: 39 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply."

Paper 9:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: 
  Extract 2: 
  Limitations: >
  Relevance Evaluation: High
  Relevance Score: 0.9442521600584775
  Inline Citation: >
  Explanation: Paper discusses the sub-topic of Anomaly detection and predictive maintenance using AI techniques in the section titled 'Anomaly detection and predictive maintenance using AI techniques'.

In the sub-topic, the authors highlight that anomaly detection and predictive maintenance are crucial components of the IoT/IIoT automated systems for real-time irrigation management.

They state that anomaly detection involves identifying deviations from normal behavior using AI techniques, while predictive maintenance uses AI to predict potential failures and enable timely intervention.

The authors provide a use case example of a vineyard irrigation system where anomaly detection and predictive maintenance techniques are used to optimize water usage, reduce energy consumption, and improve crop yields.

They present the main findings or results of the study in the following points:

- Anomaly detection and predictive maintenance using AI techniques can significantly enhance the efficiency and effectiveness of automated irrigation systems.
- These techniques can detect anomalies in sensor data, identify potential failures, and predict future events, enabling proactive maintenance and optimization.
- The use of AI in anomaly detection and predictive maintenance can help reduce costs, improve productivity, and increase sustainability in agricultural irrigation.

The main objective or research question of the study is to investigate the application and benefits of anomaly detection and predictive maintenance using AI techniques in automated irrigation systems.

The authors used a vineyard irrigation system as a case study to demonstrate the effectiveness of these techniques in optimizing water usage, reducing energy consumption, and improving crop yields.

The authors' approach to the study involved:

- Collecting sensor data from the irrigation system, including soil moisture, temperature, and flow rate.
- Analyzing the data using AI techniques to detect anomalies and predict potential failures.
- Implementing automated actions based on the analysis results to optimize irrigation schedules, detect leaks, and prevent equipment failures.

The authors' findings have implications for the development, implementation, and management of automated irrigation systems in agriculture and other industries.

They suggest that anomaly detection and predictive maintenance using AI techniques can significantly enhance the efficiency, effectiveness, and sustainability of these systems.

 Full Text: >
Open Access Research Book   |   Home Next Generation Internet of Things Distributed Intelligence at the Edge and Human Machine-to-Machine Cooperation Editors Ovidiu Vermesan SINTEF, Norway Joël Bacquet EU, Belgium Publisher Name: River Publishers eBook ISBN: 9788770220071 RIVER PUBLISHERS SERIES IN COMMUNICATIONS Series Editors: ABBAS JAMALIPOUR The University of Sydney Australia MARINA RUGGIERI University of Rome Tor Vergata Italy JUNSHAN ZHANG Arizona State University USA Indexing: All books published in this series are submitted to the Web of Science Book Citation Index (BkCI), to CrossRef and to Google Scholar. The “River Publishers Series in Communications” is a series of comprehensive academic and professional books which focus on communication and network systems. Topics range from the theory and use of systems involving all terminals, computers, and information processors to wired and wireless networks and network layouts, protocols, architectures, and implementations. Also covered are developments stemming from new market demands in systems, products, and technologies such as personal communications services, multimedia systems, enterprise networks, and optical communications. The series includes research monographs, edited volumes, handbooks and textbooks, providing professionals, researchers, educators, and advanced students in the field with an invaluable insight into the latest research and developments. For a list of other books in this series, visit www.riverpublishers.com Dedication “We keep moving forward, opening new doors, and trying new things, because we are curious, and curiosity keeps leading us down new paths.” —Walt Disney “Creativity takes courage.” —Henri Matisse Acknowledgement The editors would like to thank the European Commission for their support in the planning and preparation of this book. The recommendations and opinions expressed in the book are those of the editors and contributors, and do not necessarily represent those of the European Commission. Ovidiu Vermesan Joël Bacquet Preface Next Generation Internet of Things Distributed Intelligence at the Edge and Human Machine-to-Machine Cooperation The Internet of Things (IoT) and Industrial Internet of Things (IIoT) present opportunities for enterprises to improve efficiencies and enhance customer value. IoT/IIoT continues to evolve with new technologies and applications, embedding ubiquitous hyperconnectivity (5G and beyond), edge/fog computing, distributed ledger technologies (DLTs) and artificial intelligence (AI). IoT/IIoT operates in a continuum that connects the physical, digital, virtual and cyber worlds through intelligent ‘Digital Twins’ by generating constant streams of data that can be harnessed into actionable distributed intelligence at the edge, with human, machine-to-machine cooperation to improve life, work and interaction with the everyday world. Next-generation Tactile IoT/IIoT builds a real-time interactive system between the human and the machine and introduces a new evolution in human-machine (H2M) communication. Tactile IoT/IIoT enables the transfer of physical ‘senses’ (e.g. sense/touch, actuation, hepatic actions, etc.) in real-time form remotely and introduces a new paradigm shift to the skill-based/knowledge-based networks instead of content-based networks. New solutions are needed for addressing IoT distributed end-to-end security because there are many more IoT/IIoT devices to secure, compared with traditional IT infrastructure devices. Many IoT/IIoT devices are embedded into systems that can affect physical health and safety, in addition to traditional communications or computing systems, and they introduce a complex management environment, with diverse technology profiles, processing capabilities, use-cases, and physical locations. The chapters in the book present and discuss the next-generation IoT/IIoT research and innovation trends by addressing the enabling technologies, such as network technologies, edge/fog computing, distributed ledger technologies, AI, and the challenges for security, network management and integration for future IoT applications across industrial sectors. The IoT/IIoT development ahead implies a human-centric approach that involves a judicious and dynamic balancing of collaboration and competition in IoT ecosystems in a common quest for advancing the digital transformation of industry and economy for the benefit of society and citizens. Editors Biography Dr. Ovidiu Vermesan holds a PhD degree in microelectronics and a Master of International Business (MIB) degree. He is Chief Scientist at SINTEF Digital, Oslo, Norway. His research interests are in the area of mixed-signal embedded electronics and cognitive communication systems. Dr. Vermesan received SINTEF’s 2003 award for research excellence for his work on the implementation of a biometric sensor system. He is currently working on projects addressing nanoelectronics, integrated sensor/actuator systems, communication, cyber–physical systems and the IoT, with applications in green mobility, energy, autonomous systems and smart cities. He has authored or co-authored over 85 technical articles and conference papers. He is actively involved in the activities of the Electronic Components and Systems for European Leadership (ECSEL) Joint Technology Initiative (JTI). He has coordinated and managed various national, EU and other international projects related to integrated electronics. Dr. Vermesan actively participates in national, H2020 EU and other international initiatives by coordinating and managing various projects. He is the coordinator of the IoT European Research Cluster (IERC) and a member of the Steering Board of the Alliance for Internet of Things Innovation (AIOTI). Joël Bacquet is a senior official of DG CONNECT of the European Commission, taking care of the research and innovation policy for the Internet of Things. Before working in this field, he was programme officer in “Future Internet Experimental Platforms”, head of the sector “Virtual Physiological Human” in the ICT for health domain. From 1999 to 2003, he was head of the sector “networked organisations” in the eBusiness unit. He started working with the European Commission in 1993, in the Software Engineering Unit of the ESPRIT Programme. He started his carrier as visiting scientist for Quantel a LASER company in San José, California in 1981. From 1983 to 1987, he was with Thomson CSF (Thales) as software development engineer for a Radar System. From 1987 to 1991, he worked with the European Space Agency as software engineer on the European Space shuttle and international Space platform programmes (ISS). From 1991 to 1993 he was with Eurocontrol where he was Quality manager of an Air Traffic Control system. He is an engineer in computer science from Institut Supérieur d’Electronique du Nord (ISEN) and he has a MBA from Webster University, Missouri. List of Figures Figure 1.1 DEI 4 main actions. Figure 1.1 Overall EU IoT strategy. Figure 1.1 IoT-EPI Task Forces. Figure 1.1 Focus Area on Digitization. Figure 2.2 NGI Key Pillars. Figure 2.2 Inter-IoT Multi-layer architecture. Figure 3.3 Next Generation IoT Hyperconnected: 6As and 6Cs. Figure 3.3 Next Generation IoT evolution. Figure 3.3 Next Generation IoT technology convergence. Figure 3.3 Tactile Internet of Things model. Figure 3.3 Tactile Internet of Things representation. Figure 3.3 Tactile Internet of Things interactions. Figure 3.3 New applications for NGI and IoT/IIoT. Figure 3.3 Digital Twin representation. Figure 3.3 How Cloud IoT Edge works. Figure 3.3 Gartner’s Hype Cycle for emerging technologies 2018. Figure 3.3 Artificial Intelligence Roadmap. Figure 3.3 Outcomes of Artificial Intelligence. Figure 3.3 Artificial Intelligence methods. Figure 3.3 AI dependency on market size, pain points, and willingness to pay across different industries. Figure 3.3 Machine Learning (ML) and Deep Learning (DL) technology multi-layered stack. Figure 3.3 Key AI innovations according to the IDATE Technology 2025 survey. Figure 3.3 AI adoption/maturity vs. value at stake. Figure 3.3 Use of unstructured deep learning in the analysis of hospital patient data. Figure 3.3 AI and IoT/IIoT requirements for complex system integrated systems. Figure 3.3 Bandwidth and delay for services enabled by legacy networks and 5G. Figure 3.3 End-to-End Network Slicing for Multiple Industries Based on One Physical Infrastructure. Figure 3.3 Frequency ranges being studied for identification at World Radio Communication Conference 2019. Figure 3.3 Factors that could impact commercial adoption of Network Slicing. Figure 3.3 G Applications Market Potential and Readiness Matrix. Figure 3.3 G use in different industrial application areas. Figure 3.3 Key requirements for connectivity for factory of the future automation. Figure 3.3 International Mobile Telecommunications system requirements for the year 2020 (IMT-2020) mapped to 5G use cases. Figure 3.3 Global number of connected IoT devices. Figure 3.3 Evolution of the blockchain. Figure 3.3 Combining blockchain technology and the IoT with the use of IBM Watson and blockchain platforms. Figure 3.3 Using blockchain and the IoT to improve operations in the aviation industry. Figure 3.3 D IoT Layered Architecture. Figure 3.3 Total number of active device connections worldwide. Figure 3.3 The importance of Business Model Innovation with respect to external changes in the environment. Figure 4.4 ACTIVAGE Reference Architecture. Figure 4.4 IoT device assets and STRIDE representation. Figure 4.4 Privacy methodology. Figure 4.4 Process for carrying out a DPIA. Figure 4.4 Raspberry PI model 3 with TPM dedicated hat in white. Figure 4.4 ACTIVAGE monitoring platform – BaaS platform architectural overview. Figure 4.4 Request permissions for accessing personal data. Figure 5.5 INTER-IoT multi-layered architecture. Figure 5.5 Semantic Inter-Platform Ontology-to-Ontology translation through IPSM. Figure 5.5 Process schema of INTER-METH. Figure 5.5 MW2MW structure. Figure 5.5 Gateway structure and inner components. Figure 5.5 INTER-Health pilot. Figure 5.5 INTER-Health: BodyCloud and UniversAAL integration. Figure 5.5 INTER-Health System overview. Figure 5.5 INTER-LogP use case approach. Figure 5.5 Integration of IoT platforms of different port stakeholders through INTER-IoT. Figure 5.5 High-level view of the access control pilot. Figure 5.5 High-level scheme of the pilot for health accident assistance in port areas. Figure 5.5 AHA Interoperable DS (Smart Home Clusters). Figure 5.5 AHA Architecture for Interoperability. Figure 6.6 MONSOON Reference Architecture. Figure 6.6 Functional View of Plant Operational Platform. Figure 6.6 Functional View of Cross Sectorial Data Lab Platform. Figure 6.6 Components Mapping to Open-source Technologies. Figure 6.6 Containerization of Big Data Storage and Analytics Platform. Figure 6.6 Deployment view of Plant Operational Platform. Figure 6.6 Increase in cycle time and decrease in plastification at the same time. The same pattern has repeated multiple times in the unlabelled set of plastic data. CycCycTim is cycle time and CycPlstTim is plastification time. Figure 6.6 Intra-factory interoperability layer components and dependencies. Figure 6.6 LinkSmart® Learning Service Architecture sketch. Figure 6.6 Example application of GADPL. Figure 7.7 The high-level BRAIN-IoT concept. Figure 7.7 BRAIN-IoT development concept. Figure 7.7 BRAIN-IoT deployment concept. Figure 7.7 Iterative risk analysis methodology. Figure 7.7 Decentralised security and privacy capabilities. Figure 7.7 ENACT support of DevOps for trustworthy smart IoT systems. Figure 7.7 Key concepts of the IoTCrawler proposal. Figure 7.7 Overall architecture of the IoTCrawler framework. Figure 7.7 IoTCrawler use cases at a glance. Figure 7.7 Overview of SecureIoT Architecture. Figure 7.7 Layers of SecureIoT systems. Figure 7.7 SEMIoTICS architecture (deployment and logic views). Figure 7.7 The structure of layered SerIoT architecture. Figure 7.7 SOFIE Secure and Open Federation Architecture. Figure 7.7 Three SOFIE pilots. Figure 8.8 Myron Krueger’s Video Place (1974), and the Sony EyeToy (2003). Figure 8.8 Michael Naimark & MIT ArchMac’s Aspen Movie Map (1978–1980), and Google Street View (2007–). Figure 8.8 Jeffrey Shaw’s Legible City (1988) and E-fitzone exercise equipment (2008). Figure 8.8 Art+Com’s Terravision (1996) and Google’s Google Earth (2001, 2005–). Figure 8.8 Environmental Dress, by María Castellanos and Alberto Valverde. Figure 8.8 Flone, the flying phone by Lot Amorós, Cristina Navarro, Alexandre Oliver. Figure 8.8 THERO by Román Torre and Ángeles Angulo. Figure 8.8 The ideal showroom of IoT. Figure 8.8 Added-value weeding data. Figure 8.8 City farming for leafy vegetables. Figure 8.8 Poultry chain management. List of Tables Table 3.3 Key critical IoT communications requirements Table 3.3 Vertical industrial sectors – key requirements for critical IoT communications Table 4.4 STRIDE Table 4.4 DREAD ranking definition Table 4.4 DREAD ranking evaluation and analysis Table 4.4 Basic strategy analysis Table 4.4 Examples where DPIA is required Table 4.4 GDPR Analysis in view of its implementation Table 4.4 DREAD impact assessment Table 6.6 Classification results of different predictive models Table 7.7 BRAIN-IoT technical objectives Contents 1 IoT EU Strategy, State of Play and Future Perspectives Download As PDF 2 Future Trends in IoT Download As PDF 3 The Next Generation Internet of Things – Hyperconnectivity and Embedded Intelligence at the Edge Download As PDF 4 End-to-end Security and Privacy by Design for AHA-IoT Applications and Services Download As PDF 5 Use Cases, Applications and Implementation Aspects for IoT Interoperability Download As PDF 6 Smart Data and the Industrial Internet of Things Download As PDF 7 IoT European Security and Privacy Projects: Integration, Architectures and Interoperability Download As PDF 8 CREATE Your IoT Download As PDF 1. IoT EU Strategy, State of Play and Future Perspectives Mechthild Rohen European Commission, Belgium 1.1 Introduction Two years have passed since the publication of our Digitising European Industry (DEI) strategy, whose overall objective is to ensure that any industry in Europe, big or small, wherever situated and in any sector can fully benefit from digital innovations to upgrade its products, improve its processes and adapt its business models to the digital transformation. The underlying scenario is represented by the European platform of national initiatives on DEI, including digital innovation hubs, regulatory framework, skills and jobs, partnership and platforms (Figure 1.1). Figure 1.1 DEI 4 main actions. IoT is at the heart of the digitisation process of the economy and society and it is an essential building block of the DEI strategy and the Digital Single Market strategy. Therefore, the overall goal is for Europe to be at the forefront of supplying innovative IoT solutions and to become the world’s leading market for IoT products and services. As part of the DEI strategy, the goal for developing IoT leadership encompasses several building blocks funded under Horizon 2020: The IoT-European Platforms Initiative (IoT-EPI), addressing interoperability of IoT platforms, creating the ecosystem, using architectures, and integrating systems and networks for a multiplicity of novel applications; The Focus Area on IoT under Crosscutting Activities in the Horizon 2020 Work Programme 2016–2017, on experimentation with real-life solutions, tested at large scale with users; and The Focus Area on Digitising and transforming European industry and services under the Horizon 2020 Work Programme 2018–2020, which supports the DEI strategy on digitization of industrial sectors, integrating digital technologies and innovation across societal challenges (Figure 1.2). Figure 1.2 Overall EU IoT strategy. These building blocks are further elaborated below to provide with an overview of the state of play of the EU initiatives and activities. 1.2 Research and Innovation under Horizon 2020 The IoT-European Platforms Initiative (IoT-EPI) was formed to build a vibrant and sustainable IoT-ecosystem in Europe, maximising the opportunities for open platform development, interoperability and information sharing. At the core of the programme there are seven research and innovation projects and two coordination and support actions: Inter-IoT, BIG IoT, AGILE, SymbIoTe, TagItSmart, Vicinity, bIoTope, Be-IoT and UNIFY-IoT. With a total funding of EUR 50 million and a partner network of 120 organizations, these projects develop innovative solutions focusing on IoT architectures and semantic interoperability. Furthermore, they also foster technology adoption through the development of use cases in several industrial sectors, and community and business building activities. All projects ran within the time-frame of 2016–2018 – with one (Vicinity) extending until 2019. The IoT-EPI projects are cooperating to define the research and innovation mechanisms and to identify opportunities for collaboration in IoT ecosystems to maximise the opportunities for common approaches to platform development, interoperability and information sharing. The common activities are organised under six task forces that are conceived and developed under IoT-EPI (Figure 1.3). Figure 1.3 IoT-EPI Task Forces. Each of the six Task Forces have produced major results in terms of research, but also in terms of policy, which has created a real impact on the European IoT market [1]. Some of the key results include: The analysis of IoT platforms showing a market growing rapidly, but still fragmented, with hundreds of different and incompatible platforms. This report on IoT landscape has been further developed and published by the Alliance for Internet of Things Innovation (AIOTI) [2]; The publication of a white paper on IoT platform interoperability, compiling the lessons learnt and results from the seven projects [4]; The development of an open architecture and open IoT business model framework that has set the foundation of cooperation with the developers and entrepreneurs community, and that has mobilised SMEs and start-ups to join the ecosystem. In eleven open calls, with more than 100 external IoT-teams, the IoT-EPI has planned an investment of more than EUR 5.5 million until December 2018 to nurture an IoT ecosystem around the seven core projects; The development of policy recommendations for the uptake of IoT in Europe; and The set-up of an education platform using the results of the IoT-EPI projects. Besides the IoT-EPI Task Forces, adequate security, trust and privacy are key issues to be tackled in connection with IoT, and therefore a specific cluster of project addressing these issues has been launched under Horizon 2020 in 2017. Seven projects have been selected with a total EU contribution of EUR 37 million in order to develop and test solutions providing IoT security, trust and privacy (ENACT, IoTCrawler, SecureIoT, BRAIN-IoT, SOFIE, CHARIOT, SEMIoTICS, SerIoT). The projects address the key issues of end-to-end security and trust in open IoT Platforms, as well as advanced concepts for IoT security and prevention of cyber-attacks, including blockchains and distributed ledger technology, which are tested in a set of ambitious use cases. In addition, the projects deploy open IoT platforms and include a strong contribution to upcoming open standards in IoT security. 1.3 Deployment – IoT Focus Area and Focus Area on Digitization In order to foster the uptake of IoT in Europe and to enable the emergence of IoT ecosystems supported by open technologies, the European Commission launched an IoT Focus Area that supports the IoT European Large-Scale Pilots Programme (IoT-LSPs) on deployment of IoT at large in Europe. These IoT-LSPs started on 1 January 2017 and are funded with a budget of EUR 100 million. The IoT-LSPs cover the following domains: Smart living environments for ageing well (ACTIVAGE); Smart Farming and Food Security (IoF2020); Wearables for smart ecosystems (MONICA); Reference zones in EU cities (SYNCHRONICITY); and Autonomous vehicles in a connected environment (AUTOPILOT). With these pilots, the European Commission is supporting the testing and experimentation of new IoT related technologies with the involvement of and result validation by end users. These pilots are expected to accelerate the standards setting across different business sectors, boosting further the IoT technology and provide input to policy developments, such as data protection, privacy and security. Since January 2017, several successful results have been achieved. Each funded project is applying IoT approaches to specific real-life challenges across use cases, based on European relevance, technology readiness and socio-economic interest in Europe. More than 50 use cases have taken shape and are now fully running. This has also allowed the LSPs to work together in order to define common high-level architecture models. Another example is the well-defined and good cooperation among LSPs, which develop common mechanisms for the publication of open calls to enlarge their consortia with new partners, in particular SMEs. These open calls provide so-called cascading funds as financial support targeted to involve especially SMEs and start-ups to get access to pilot testing in an open and lean way. In the Horizon 2020 Work Programme 2018–2020, the European Commission aims to use the strong concept of a Focus Area on Digitisation (Digitising and transforming European industry and services), accounting for EUR 250 million funding and forming a significant part of ICT calls in the Horizon 2020 Work Programme 2018–2020. Success in implementation of the Focus Area will depend to a large extent on the capacity to work across the digital, societal and industrial topics that are grouped under this Focus Area. The Focus Area requires close cooperation of different services across different DGs, namely CONNECT, GROW, RTD, AGRI and ENER, to ensure coherent policy setting across areas which so far were siloed economic and policy areas, e.g. to support Digitisation under the Energy Union or the Common Agriculture Policy. Calls will close in November 2018 and resulting from this Focus Area, a further set of pilots will be launched in 2019 across different areas, such as health and care, energy efficiency, agriculture and industry 4.0. These pilots will accelerate standards setting across different business sectors, boosting further the investments and scalable market creation for IoT technology. This focus area will be funded by several parts of the Horizon 2020 programme, mainly by the Leadership in Enabling and Industrial Technologies and Societal Challenges pillars. Pilot activities will be supported in the areas of Smart Farming, Digitisation of Energy, Digital Health and Rural Platforms, as depicted in Figure 1.4. Figure 1.4 Focus Area on Digitization. 1.4 IoT within the Next Generation Internet – Preparing the Next Framework Programme for Research and Innovation IoT continues to evolve rapidly, in particular in response to the major trends, such as the ever-increasing volumes of data generated and extraction of knowledge through smart data analytics, as well as increasing levels of automation and decision making, made possible by smart sensors, devices and actuators combined with machine learning and artificial intelligence. In addition, there are new real-time requirements emerging, such as in industrial production and autonomous cars, which must be addressed. The capacity of communication networks is ever increasing with 5G deployment starting and processing power is still increasing exponentially, allowing for new distributed architectures (e.g. cognitive cloud, fog or edge computing) and solutions. Also, new approaches to reduce or eliminate intermediaries, by building on blockchains and distributed ledgers, and the power to control access to and sharing of data, lead to new value chains and business models, which will open new opportunities for European companies and user communities. This is all encapsulated in the vision of a Next Generation Internet, which is more human-centric in terms of identity, data protection and privacy, control and opportunity, addressing wider needs (from browsing to interconnection of billions of smart devices with new real-time requirements) and which is more secure and trusted by design as a critical infrastructure for society and business. 1.5 Conclusion The digital revolution has only just started – and it is speeding up. Technology is entering into a critical phase, where connectivity and intelligence will permeate all areas of the physical world, with profound economic and social effects. Europe must maintain a leading position in the digital world and ensure that everyone whether businesses, public sector and citizens, can benefit from it. The European Commission has just published its proposal for the next EU budget for 2021–2027 [5], where there is a substantial focus on an ambitious investment in digital to make this a reality. This proposal includes a 60% increase in budget for Horizon Europe, the next EU Framework Programme for Research and innovation, as well as a proposed new programme, i.e. the Digital Europe Programme with a EUR 9 billion funding to support the large scale uptake of digital technologies, including digital skills. IoT and its future evolution is central to many of these efforts and Europe can take the lead in realising its potential. References Digital Single Market – The Internet of Things, online at: https://ec.europa.eu/digital-single-market/en/internet-of-things Alliance for Internet of Things Innovation (AIOTI), online at: https://aioti.eu/ IoT European Large-Scale Pilots Programme (IoT-LSPs), online at: https://european-iot-pilots.eu/ IoT European Platforms Initiative (IoT-EPI), online at: https://iot-epi.eu/ EU budget for the future, online at: https://ec.europa.eu/commission/sites/beta-political/files/budget-proposals-research-innovation-may-2018_en.pdf 2. Future Trends in IoT Joël Bacquet, Rolf Riemenschneider and Peter Wintlev-Jensen European Commission, Belgium 2.1 Introduction The Next Generation Internet (NGI) initiative [1] aims at maintaining the European lead in advanced network infrastructures and fully exploit the opportunities offered by the connection to the physical work i.e the Internet of Things (IoT), powered by advanced computing capabilities and data infrastructure. The NGI and its link to IoT has to be at the service of people, industry and society, addressing present and specific societal challenges, combined with artificial intelligence (AI), secure transactions, sovereignty, edge computing, interactive technologies and social media, as depicted in Figure 2.1. Every technological design has to focus on making data and components easy to use and profitable in an open and democratic way to every single user. Figure 2.1 NGI Key Pillars. IoT technologies and applications bring fundamental changes in individuals’ and society’s view of how technology and business work in the world, and it is therefore an essential element of the Next Generation Internet. IoT is seen today as a disruptive technology for enabling new opportunities and triggering new services and applications. However, collecting massive amounts of data in everyday life poses huge challenges for the user to keep control of his data in terms of managing access, sharing and protection. Additionally, one of Europe’s greatest challenges is to keep the sovereignty of the underlying core infrastructure that computes and stores sensitive information, and protect IoT devices from misuse. The societal potential of IoT is extraordinary: better use of natural resources through smart farming, better food quality through devices enabling food traceability and control, better human health through devices linked to remote medicine and independent living, lower carbon emissions from autonomous driving and smart logistics, fewer accidents relying on connected driving, smart cities through smart use of massive data generated from a multitude of new sensors in a city. The scope of this chapter is to review novel IoT concepts that have been gathered from groups of experts in different fora, including specific workshops organised by the European Commission, inputs the European Research Cluster on the Internet of Things (IERC), the Alliance for Internet of Things Innovation (AIOTI) and the IoT-European Platforms Initiative (IoT-EPI) cluster. 2.2 Key Technological Game Changers for IoT Novel IoT architecture, platforms and solutions will emerge and will integrate new enabling technologies such as AI, secure Distributed Ledger Technologies (DLTs), or advanced communication networks, in order to meet new user requirements for performance, quality of services, trust and user control data. These IoT architectures, platforms and solutions will rely on the following game changers: Next generation IoT devices; Edge computing; Data-centric architectures; Community-driven business models; and A resilient and reliable infrastructure. Towards Next Generation IoT devices. The IoT platform development will move in the next phase with the emergence of tactile interface based on human-centric sensing and actuating, augmented and virtual reality combined with new IoT end-point capabilities capturing contextual environment. Interactive and conversational IoT platforms will emerge with innovative user interfaces interfering with things and humans. These interactive platforms will enable real-time control, physical (haptic) experiences, interactive, context aware, event-driven IoT services with more intelligence at the edge. In supporting trust and security, information flows stay close to the user, decisions are taken at the point of interest, where data is collected and locally processed. For this to happen, the applications need to combine edge computing, IoT and mobile autonomous systems using AI technologies as functionality enablers. Towards edge computing, shifting computing and data processing close to the source of data. The usual approach in most current IoT solutions is to execute data crunching in the cloud. In many scenarios this is the most suitable approach due to distributed nature of data collection. However, the value generated by many IoT devices decreases over time (e.g. for a thermostat control). With billions of IoT devices, it does not make sense to store all data in the cloud, but to limit data transfer to the cloud and store only information that is necessary to avoid data deluge. There are scenarios in which significant amount of data is collected at one location and the output of that local data processing is used to control a local process. In such cases, edge processing approach is desirable over processing in the cloud. For instance, this approach will require more computational capacity at device and gateway level to meet real-time requirements, preserve privacy and reduce the attack surface towards IoT devices by keeping most sensitive data local. This approach will imply a disruption from the vertical silo approach promoted by current commercial solutions, where all data are captured in cloud repositories and then fed back to the user. One of the most pertinent research tracks for edge computing will be to set the confidence level from information gathered from a cloud server, aggregated data from federated clouds and/or information retrieved from the internet. In the times of fake news, whilst experiencing novel possibilities of aggregating and manipulating data using AI, it poses unprecedented challenges for users and connected systems to set the appropriate confidence or criticality level of any external information. It remains a challenge for any future AI systems to make transparent how knowledge has been elicited that relies on trusted sources and algorithms. In contrast, edge computing novel architecture should support more decentralized decision and action support system available directly at the device level. In addition, edge computing solutions can create partial views on an environment to facilitate the decision-making process, perform data pruning, processing, anonymization, etc. Towards data-centric architectures, dealing with the exploding volume of data generated across the different application fields and relying on AI techniques for pre-processing of data. Data storage and data flow will stress capabilities of the IoT platforms, mainly due to the large number of devices and objects, with the need of storing, processing and exchanging large amount of data in due time. Data storage is directly linked with security and privacy components, and data markets, including the availability for the regular citizen and not only corporations and stakeholders, other than with Data Sovereignty (subject to the laws of the country in which data is retrieved and located). The application of AI (mainly machine learning) across the whole IoT pipeline will have its roots in the cloud but will have to be deployed at the edge level, embedded in the things or the gateways to meet time constraints. An IoT data centre like the IBM Watson will be capable of re/defining experience and learning, detecting recurring patterns and systematic failures, in particular it will be able to adapt a holistic risk assessment of a system state in a complex environment. As said, critical functions have to be replicated and delegated to a local agent that ensures the functioning of a system even if it is oﬄine. On the application/services side, AI-powered digital agents can act on behalf of the end users, interact with the most appropriate sensors and access the data related to the users’ current activities. Up to an extent, these agents can act autonomously and proactively, for a seamless bridging of the real and digital world. Real-time intelligence provided by such lightweight agents would enable smart devices to have better understanding of their surroundings, the user’s conditions and allow them to behave accordingly. Towards community-driven business models ensuring security and privacy, building on DLTs. Novel business models and services increasingly built on social networks that are associated with daily life needs like mobility, shopping or home care, might be linked to a building, a quartier or city. We have seen success stories in the economy, like Uber, Airbnb or eBay, that have grown exponentially and that build on the fundamentals of a sharing economy. These peer-to-peer (P2P) marketplaces are driven by common interest and shared values. In order to secure and enable growth of those P2P platforms, scale and secure technologies for authentication, authorization and accounting must evolve from isolated platforms to an ecosystem of connected platforms. DLT enables autonomy and ultimately, secures machine-to-machine (M2M) transactions without a central platform provider. Also, DLT can be a solution to manage the certificates for access to information from objects, including personal data, as well as smart contracts enabling new business models for P2P platform services. Things like money, loyalty points, intellectual property, certificates or even identity, can be sent across the globe, safely, (almost) instantly and without the need for a middle man/intermediary. Security and privacy mechanisms, based on blockchains or any other DLT, may provide new benefits and possibilities to the individual users to effectively and securely manage their personal data space, like authenticating the origin of the data and allowing the use of the data for specific stakeholders and applications, allowing the control of the re-selling of the data. The creation of micro-contracts and using cryptocurrencies may support the final benefit or revenues to the users. Traditional industrial sectors like energy, transport, or food chains may be transformed through P2P platform services, with an impact detrimental to today’s business models. It remains a challenge and obligation not to ignore but to embrace P2P platforms that contribute to the growth of a community and demonstrate the opportunities of emerging technologies like DLT or blockchains for IoT platforms. DLT holds promise to mediate interactions in future decentralized IoT environments, but next-generation DLT solutions are needed to make this a reality. Current distributed ledgers seem not to be scalable and had difficulties to handle a high transaction load. Towards resilient and reliable infrastructure. Future IoT services and applications will require infrastructures to support IoT device connectivity, data streaming and security with new requirements for service quality and reliability. Decentralized data governance and data security will be possible thanks to distributed architectures using DLT, where the control of personal data is significantly improved. But a trusted DLT platform will require beyond a protocol scalable, performant infrastructure and shared governance to establish trust and security. Another challenge for the infrastructure will be the treatment of IoT traffic which will be a major research and deployment issue, to increase availability, resilience and use of data coming from IoT. The emerging trends are related to distributed architectures, software defined technologies and new networking capabilities. 2.3 Interoperability IoT environments are rather complex with heterogeneous physical devices supporting various communication protocols, while they are possibly connected to an intermediary gateway and then to their virtual representations (i.e. services) running on different platforms. Thus, it is possible to interact with a single IoT device in many ways using its varied interfaces and representations. IoT platforms require interoperability on multiple levels, which means finding the characteristic functionalities of each layer and defining meta-protocols that can be mapped on the ones used in the platforms (i.e. on the level of syntactic interoperability, the characteristic functionality is resource access). A lot of work has been done in this field in particular in the IoT-EPI, which focuses mainly on architectures and semantic interoperability [2]. As an example, the INTER-IoT project [3] has defined an IoT multi-layer approach to provide semantic interoperability, as illustrated in Figure 2.2. Figure 2.2 Inter-IoT Multi-layer architecture. Nevertheless, research on a layer-oriented approach is still needed to address tighter interoperability at all layers of IoT systems (device, network, middleware, application, data and semantics) with a strong focus on guaranteeing trust, privacy and security aspects within this interoperability. The demands of the future internet, including future IoT applications and services, will require a much larger object space, resource efficient implementation in devices, object interaction across so far siloed application spaces, as well as support for intelligent and trusted mechanisms for service provision. Standards have to support interoperability for any object to be seamlessly connected. New connected objects allow users to optimize functions in their daily life (to be safe, for entertainment and comfort, or daily activity support). This requires that objects seamlessly and securely connect, but that they are also identified due to their functionality. On semantic interoperability, despite several efforts to find common ontologies to be reused and different standardization efforts (e.g. SAREF, W3C or ETSI), in a real interoperability environment, new ontologies have to be defined, to address specific deployment. Efforts have to be devoted to semantic translation or alignment in order to provide an easy support for ontology matching between IoT platforms. Work needs to continue on common vocabularies, data models and semantic mapping techniques that could become the key technologies for semantic interoperability via common efforts on the abstract core model for IoT domains. Under the new Focus Area on Digitisation in the Horizon 2020 Work Programme 2018–2020, the European Commission calls for a pilot on Interoperable Smart Homes and Grids under call DT-ICT-10-2018-19. IoT is expected to enable a seamless integration of home appliances with related home comfort and building automation services allowing to match user needs with the management of distributed energy across the grid. Through Digitisation of Energy, there will be much more assets connected to the grid, which are intelligently communicating with the grid. This comes with all kinds of complexities in terms of interoperability, but mainly due to a lot of different IoT platforms coming from different manufacturers and sectors, like building automation, heating, electrical vehicle charging, appliances, etc. The energy sectoral ecosystem finds itself in a transition period that entails the grid operator, the energy business and services, and the changing role of a consumer or prosumer. The interconnectivity of different systems and assets will become very powerful through IoT platforms if interoperability can be achieved across federated systems that enable the integration of data and novel services. 2.4 Boosting IoT Innovation and Deployment In future IoT solutions, the importance of data will prevail and further grow. Measuring the economic value of data is a key challenge, focusing on the understanding of the economic value of the data instances and streams in different IoT infrastructure deployment use-cases. The openness of localized sensor data will provide new means to boost the IoT market. Providers of such data will experience new revenue streams. Moreover, new form of marketplaces will be created; that of local data marketplaces, which will also boost innovation. Especially when considering use cases like smart cities, smart transportation or smart grids, where sensing information is characterized by lot of heterogeneous and sensitive data sources, the real benefit from such kind of data markets is seized when data is shared across private, public and industrial value chains. Apart from technology enablers for data marketplaces like DLT, the European Commission favours communities and ecosystems that provide incentives for sharing data on any kind of assets or resources to create an added value through new services and applications (e.g. shared parking, car-sharing, P2P energy, etc.). It remains a challenge for public decision makers to adapt the regulatory framework for new data economy towards a Free Flow of Data, harmonization of data access across borders, data protection and portability in support of a Digital Single Market. The IoT platform centric point of view will evolve to an ecosystem of platforms with IoT platforms, IoT nodes and sets of IoT things. Instead of IoT platform companies trying to lock-in their customers through closed system approaches, thus creating complex integration links, new common and open interoperation among all these structures will be needed. Ecosystem governance is necessary for controlling different degrees of interoperation and for managing the access to data and services across the whole ecosystem, especially for the use of personal data. 2.5 Conclusion IoT is a key technology transversal to all sectors of activity and will be fundamental for the NGI initiative. The next generation of IoT will build on a new generation set of devices and systems that will make use of new infrastructure enhancements, better sensing and actuating capabilities, end-to-end semantic knowledge, more powerful computation capabilities on the edge, intrinsic adoption of AI from the edge to the backbone, and the ability to set-up new relationships (like smart contracts, context awareness or intelligent behaviour) among things, services and people, while respecting the human-centric concerns in terms of privacy, security, openness, sustainability and control of personal data. The inputs collected from the relevant workshops and IoT stakeholder communities are key inspiring sources on the strategic directions needed to support future research, development and innovation of IoT in the context of the NGI initiative. These sources are major inputs to the elaboration of future research and innovation work programmes within Horizon 2020 and beyond. References The Next Generation Internet initiative, online at: https://www.ngi.eu/ IoT European Platforms Initiative – white paper on “Advancing IoT Platforms interoperability” INTER-IoT project, online at: http://www.inter-iot-project.eu/ 3. The Next Generation Internet of Things – Hyperconnectivity and Embedded Intelligence at the Edge Ovidiu Vermesan1, Markus Eisenhauer2, Martin Serrano5, Patrick Guillemin4, Harald Sundmaeker3, Elias Z. Tragos9, Javier Valiño6, Bertrand Copigneaux7, Mirko Presser8, Annabeth Aagaard8, Roy Bahr1 and Emmanuel C. Darmois10 1SINTEF, Norway 2Fraunhofer FIT, Germany 3ATB Institute for Applied Systems Technology Bremen, Germany 4ETSI, France 5Insight Centre for Data Analytics, NUI Galway, Ireland 6Atos, Spain 7IDATE, France 8Aarhus University, Denmark 9Insight Centre for Data Analytics, University College Dublin, Ireland 10CommLedge, France Abstract The Internet of Things (IoT) and the Industrial Internet of Things (IIoT) are evolving towards the next generation of Tactile IoT/IIoT, which will bring together hyperconnectivity, edge computing, Distributed Ledger Technologies (DLTs) and Artificial Intelligence (AI). Future IoT applications will apply AI methods, such as machine learning (ML) and neural networks (NNs), to optimize the processing of information, as well as to integrate robotic devices, drones, autonomous vehicles, augmented and virtual reality (AR/VR), and digital assistants. These applications will engender new products, services and experiences that will offer many benefits to businesses, consumers and industries. A more human-centred perspective will allow us to maximise the effects of the next generation of IoT/IIoT technologies and applications as we move towards the integration of intelligent objects with social capabilities that need to address the interactions between autonomous systems and humans in a seamless way. 3.1 Next Generation Internet of Things The IoT is enabled by heterogeneous technologies used to sense, collect, store, act, process, infer, transmit, create notifications of/for, manage and analyse data. The combination of emergent technologies for information processing and distributed security, e.g. AI, IoT, DLTs and blockchains, brings new challenges in addressing distributed IoT architectures and distributed security mechanisms that form the foundation of improved and, eventually, entirely new products and services. New systems in the IoT that use smart solutions with embedded intelligence, connectivity and processing capabilities for edge devices rely on real-time analysis of information at the edge. These new IoT systems are moving away from centralized cloud-computing solutions towards distributed intelligent edge computing systems. Traditional centralized cloud computing solutions are perfect for non-real-time applications that require high data rates, huge amounts of storage and processing power, are not strict to very low latency, cost money and can be used for heavy data analytics and AI processing jobs. On the other hand, distributed edge solutions introduce computations at the edge of the network where information is generated and are perfect for real-time services, since they exhibit very low latency (in the order of milliseconds) and can be used for simple ultra-fast analytics jobs. The collection, storage and processing of data at the edge of the network in a distributed way contributes also to the increased privacy of the user data, since no personal information is stored in backbone centralized servers and each user retains the full control of his data. Figure 3.1 Next Generation IoT Hyperconnected: 6As and 6Cs. IoT developments during recent years have been characterized by attributes that can be “labelled” the 6As: Anything (any device), to be transferred from/to Anyone (anybody), located Any place (anywhere), at Any time (any context), using the most appropriate physical path from Any path (any network) available between the sender and the recipient based on performance and/or economic considerations, to provide Any service (any business). The IoT paradigm is evolving and entire IoT ecosystems are now built upon innervation elements known as the 6Cs: Collect (heterogeneity of devices of various complexities and intelligence, that enhance the real-time collection of data generated from the connections of devices and information), Connect (ubiquitous distributed connections of heterogeneous devices and information, where the connections are the foundational component of the IoT), Cache (stored information in the distributed IoT computing/processing environment), Compute (advanced processing and computation of data and information), Cognize (information analytics, insights, extractions, real-time AI processing and Create (the creation of new interactions, services, experiences, business models and solutions). This is illustrated in Figure 3.1. Figure 3.2 Next Generation IoT evolution. The IoT transforms everyday physical objects in the surrounding environment into ecosystems of information that enrich people’s lives [97]. The IoT not only influences the future Internet landscape, with implications for security and privacy (personal freedoms), but it could also help to reduce the digital divide. The increased dependence of AI and the IoT on the connectivity network, together with the severity of security challenges, increases their vulnerabilities in parallel. The ongoing and future success of the Internet as a driver for economic and social innovation is linked to how new technologies will respond to these threats. Combining AI with the IoT promises new opportunities, ranging from new services and breakthroughs in science to the augmentation of human intelligence and its convergence with the physical and digital world. The next generation of IoT-combining technologies as presented in Figure 3.3, such as AI, DLTs, hyperconnectivity, distributed edge computing, end-to-end distributed security and autonomous systems – robotics will require increased human-centred safeguards and prioritised ethical considerations in their design and deployment. Next generation IoT evolution is illustrated in Figure 3.2. The IoT is bridging the gap between the virtual, digital and physical worlds by bringing together people, processes, data and things while generating knowledge through IoT applications and platforms. IoT achieves this addressing security, privacy and trust issues across these dimensions in an era where technology, computing power, connectivity, network capacity and the number and types of smart devices are all expected to increase. In this context, IoT is driving the digital transformation. Figure 3.3 Next Generation IoT technology convergence. As a global concept, the IoT requires a common high-level definition. The IoT is a paradigm involving multidisciplinary activities and has different meanings at different levels of abstraction through the information and knowledge value chain. Considering the wide background and the number of required technologies, from sensing devices, communication subsystems, data aggregation and pre-processing to object instantiation and finally service provision, proposing an unambiguous definition of the “IoT” is non-trivial. IoT is defined [60] as a dynamic global network infrastructure with self-configuring capabilities based on standard and interoperable communication protocols where physical and virtual ‘things’ have identities, physical attributes, and virtual personalities using intelligent interfaces for seamlessly integrating into the information network. In the IoT, ‘things’ are expected to become active participants in business, information and social processes where they are enabled to interact and communicate among themselves and with the environment by exchanging data and information ‘sensed’ about the environment, while reacting autonomously to the ‘real/physical world’ events and influencing it by running processes that trigger actions and create services with or without direct human intervention. Interfaces in the form of services facilitate interactions with these ‘smart things’ over the Internet, query and change their state and any information associated with them, considering security and privacy issues. In the context of industry digitisation, IoT/IIoT brings together the primary characteristics of Next Generation Internet (NGI) technology, mobile systems and ubiquitous connectivity with those of industrial control systems, sensing, actuating and control capabilities. Interoperability, platform integration and standardisation are essential for digitising industry applications. IoT/IIoT and industrial control systems have three quality dimensions – integrity, availability and confidentiality – which are essential for implementing applications in industrial vertical domains and across different vertical domains. Whereas the IoT emerged as an add-on to the already existing Internet, it is important to consider the emergence of an NGI where the IoT is deeply embedded and no longer a mere add-on. IoT devices and systems that build on enhanced sensing/actuating, reasoning capabilities and computational power at the edge are already becoming a natural part of an integrated NGI rather than simple extensions of the Internet. The IoT is promising in a hyperconnected world, where every object has the capability to sense its surrounding environment, transmit information, provide feedback or trigger an action through the application of AI processes in a distributed architecture with processing, intelligence and connectivity at the edge. It is becoming increasingly clear that the main benefit of IoT systems is the network effect, i.e., when different systems are integrated. As many different systems become integrated, the IoT must face complex interoperability challenges before it can create real cross-domain services with seamless movements of devices and data. However, a lack of stable implementations and the variety of devices available undermine the promised interoperability. A standard solution for IoT interoperability could result in several implementations whose effectiveness would need to be verified and certified; current practices for interoperability testing require different vendors, developers and service providers to participate in physical events. The integration of hyperconnectivity, IoT/IIoT, AI, DLTs and edge computing requires the NGI to address these challenges. This implies the identification of the right business models and the proper governance framework, which support data movement across systems and identify liability in case of any issues, as well as an understanding of the means to overcome the current technical fragmentation in the IoT. In many applications, the centralised services of cloud computing are being replaced with IoT edge-distributed solutions based on AI methods. With multi-access edge computing (MEC) and ubiquitous hyperconnectivity capabilities (5G and beyond), the IoT is now able to process large amounts of information, resulting from its connections, to be used for intelligent purposes by advanced AI algorithms, which can learn with less data and require fewer processing and memory resources. The cognitive transformation of IoT applications also allows the use of optimised solutions for individual applications and the integration of immersive technologies, i.e., virtual reality (VR) and augmented reality (AR). Such concepts transform the way individuals and robots interact with one another and with IoT platform systems. 3.2 Next Generation IoT Strategic Research and Innovation The Internet of Things European Research Cluster (IERC) concentrates the know-how regarding scientific production and research capacity for the Internet of Things in Europe; the IERC brings together EU-funded projects with the aim of defining a common vision for IoT technology and addressing European research challenges. The rationale is to leverage the large potential for IoT-based capabilities and promote the use of the results of existing projects to encourage the convergence of ongoing work; ultimately, the endpoints are to tackle the most important deployment issues, transfer research and knowledge to products and services, and apply these to real IoT applications. The objectives of IERC are to provide information on research and innovation trends, and to present the state of the art in terms of IoT technology and societal analysis, to apply developments to IoT-funded projects and to market applications and EU policies. The final goal is to test and develop innovative and interoperable IoT solutions in areas of industrial and public interest. The IERC objectives are addressed as an IoT continuum of research, innovation, development, deployment, and adoption. Every year, the IERC launches its Strategic Research and Innovation Agenda (SRIA), which is the outcome of discussions involving project representatives/coordinators, a collective group of experts from different stakeholders representing the different domains where IoT is relevant and industry representation that is not necessarily limited to IERC community participation. Such industry participation includes the Alliance for the Internet of Things Innovation (AIOTI), an industry-lead association representing the industrial European and non-European members. Enabled by the activities of the IERC, IoT is bridging physical, digital, virtual, and human spheres through networks, connected processes, and data, and turning them into knowledge and action, so that everything is connected in a large, distributed network. New technological trends bring intelligence and cognition to IoT technologies, protocols, standards, architecture, data acquisition, and analysis, all with a societal, industrial, business, and/or human purpose in mind. The IoT technological trends are presented in the context of integration of hyperconnectivity, digital transformation, actionable data, information and knowledge. The IERC works to provide a framework that supports the convergence of IoT architecture approaches; it will do so while considering the vertical definition of the architectural layers, end-to-end security, and horizontal interoperability. The SRIA is developed with the support of a European-led community of interrelated projects and their stakeholders, all of whom are dedicated to the innovation, creation, development, and use of IoT technology. Since the release of the first version of the SRIA, we have witnessed active research on several IoT topics. Updated releases of this SRIA build incrementally on previous versions [60, 62, 88] and highlight the main research topics associated with the development of IoT-enabling technologies, infrastructure, and applications [87]. The research activities include the IoT European Platforms Initiative (IoT-EPI) program that includes the research and innovation consortia that are working together to deliver an IoT extended into a web of platforms for connected devices and objects. The platforms support smart environments, businesses, services and persons with dynamic and adaptive configuration capabilities. The goal is to overcome the fragmentation of vertically-oriented closed systems, architectures and application areas and move towards open systems and platforms that support multiple applications. IoT-EPI is funded by the European Commission (EC) with EUR 50 million over three years (2016–2018) [67]. The research and innovation items addressed and discussed in the task forces of the IoT-EPI program, the IERC activity chains, and the AIOTI working groups form the basis of the IERC SRIA to address the roadmap of IoT technologies and applications; this is done in line with the major economic and societal challenges underscored by the EU 2020 Digital Agenda [87]. The IoT European Large-Scale Pilots Programme [68] includes the innovation consortia that are collaborating to foster the deployment of IoT solutions in Europe through integration of advanced IoT technologies across the value chain, demonstration of multiple IoT applications at scale and in a usage context, and as close as possible to operational conditions. The programme projects are targeted and goal driven initiatives that propose IoT approaches to specific real-life industrial/societal challenges. They are autonomous entities that involve stakeholders from supply side to demand side, and contain all the technological and innovation elements, the tasks related to the use, application and deployment as well as the development, testing and integration activities. The scope of IoT European Large-Scale Pilots Programme is to foster the deployment of IoT solutions in Europe through integration of advanced IoT technologies across the value chain, demonstration of multiple IoT applications at scale and in a usage context, and as close as possible to operational conditions. Specific Pilot considerations include: Mapping of pilot architecture approaches with validated IoT reference architectures such as IoT-A enabling interoperability across use cases. Contribution to strategic activity groups that were defined during the LSP kick-off meeting to foster coherent implementation of the different LSPs. Contribution to clustering their results of horizontal nature (interoperability approach, standards, security and privacy approaches, business validation and sustainability, methodologies, metrics, etc.). The IoT European Large-Scale Pilots Programme includes projects promoting the IoT innovation by means of market applications based on services’ demand and impact in the European market, technology readiness and socioeconomic interests in European society. The IoT European Large-Scale Pilots Programme is funded by the European Commission (EC) with EUR 100 million over three years (2017–2019) [68]. The IoT is creating new opportunities and providing competitive advantages for businesses in both current and new markets. IoT-enabling technologies have changed the things that are connected to the Internet, especially with the emergence of Tactile Internet and mobile moments (i.e., the moments in which a person or an intelligent device pulls out a device to receive context-aware service in real-time). Such technology has been integrated into connected devices, which range from home appliances and automobiles to wearables and virtual assistants. The IoT technologies and applications will bring fundamental changes in individuals’ and society’s views of how technology and business work in the world. A human-centred IoT environment requires tackling new technological trends and challenges. This has an important impact on the research activities that need to be accelerated without compromising the thoroughness, rigorous testing and needed time required for commercialisation. A hyperconnected society is converging with a consumer-industrial-business Internet that is based on hyperconnected IoT environments. The latter require new IoT systems architectures that are integrated with network architecture (a knowledge-centric network for IoT), a system design and horizontal interoperable platforms that manage things that are digital, automated and connected, functioning in real-time, having remote access and being controlled based on Internet-enabled tools. Research and development are tightly coupled. Thus, the IoT research topics should address technologies that bring benefits, value, context and efficient implementation in different use cases and examples across various applications and industries. IoT devices require integrated electronic component solutions that contain sensors/actuators, processing and communication capabilities. These IoT devices make sensing ubiquitous at a very low cost, resulting in extremely strong price pressure on electronic component manufacturers. The next generation IoT/IIoT developments, including human-centred approaches, are interlinked with the evolution of enabling technologies (AI, connectivity, security, etc.) that require strengthening trustworthiness with electronic identities, service and data/knowledge portability across applications and IoT platforms. This ensures an evolution towards distributed IoT architectures with better efficiency, scalability, end-to-end security, privacy and resilience. The virtualization of functions and rule-based policies will allow for free, fair flow of data and sharing of data and knowledge, while protecting the integrity and privacy of data. Vertical industry stakeholders will become more and more integrated in the connectivity-network value chain. Moreover, unified, heterogeneous and distributed applications, combining information and operation technologies (IT and OT), will expose the network to more diverse and specific demands. Intelligent/cognitive connectivity networks provide multiple functionalities, including physical connectivity that supports transfer of information and adaptive features that adapt to user needs (context and content). These networks can efficiently exploit network-generated data and functionality in real-time and can be dynamically instantiated close to where data are generated and needed. The dynamically instantiated functions are based on intelligent algorithms that enable the network to adapt and evolve to meet changing requirements and scenarios and to provide context- and content- suitable services to users. The intelligence embedded in the network allows the functions of IoT platforms to be embedded within the network infrastructure and data, and the knowledge generated by the intelligent connectivity network and by the users/things can be used by the network itself. This knowledge can be taken advantage of in applications outside of the network. The connectivity networks for next generation IoT/IIoT are transforming into intelligent platform infrastructures that will provide multiple functionalities and will be ubiquitous, pervasive and more integrated, further embedding telephone/cellular, Internet/data and knowledge networks. Advanced technologies are required for the NGI to provide the energy-efficient, intelligent, scalable, high-capacity and high-connectivity performance required for the intelligent and dynamically adaptable infrastructure to provide digital services – experiences that can be developed and deployed by humans and things. In this context, the connectivity networks provide energy efficiency and high performance as well as the edge-network intelligence infrastructure using AI, Machine Learning (ML), Deep Learning (DL), Neural Networks (NNs) and other techniques for decentralised and automated network management, data analytics and shared contexts and knowledge. Standardisation and solutions are needed for designing products to support multiple IoT standards or ecosystems and research on new standards and related APIs. Summarizing, although huge efforts have been made within the IERC community for the design and development of IoT technologies, the continuously changing IoT landscape and the introduction of new requirements and technologies creates new challenges or raise the need to revisit existing well-acknowledged solutions. Thus, below is a list of the main open research challenges for the future of IoT: IoT architectures considering the requirements of distributed intelligence at the edge, cognition, artificial intelligence, context awareness, tactile applications, heterogeneous devices, end-to-end security, privacy, trust, safety and reliability. IoT systems architectures integrated with network architecture forming a knowledge-centric network for IoT. Intelligence and context awareness at the IoT edge, using advanced distributed predictive analytics. IoT applications that anticipate human and machine behaviours for social support. Tactile Internet of Things applications and supportive technologies. Augmented reality and virtual reality IoT applications. Autonomics in IoT towards the Internet of Autonomous Things. Inclusion of robotics in the IoT towards the Internet of Robotic Things. Artificial intelligence and machine learning mechanisms for automating IoT processes. Distributed IoT systems using securely interconnected and synchronized mobile edge IoT clouds. Stronger distributed and end-to-end holistic security solutions for IoT, preventing the exploitation of IoT devices for launching cyber-attacks, i.e., remotely controlling IoT devices for launching Distributed Denial of Service (DDoS) attacks. Stronger privacy solutions, considering the requirements of the new General Data Protection Regulation (GDPR) [80] for protecting the users’ personal data from unauthorized access, employing protective measures (such as Privacy Enhancing Technologies – PETs) as closer to the user as possible. Cross-layer optimization of networking, analytics, security, communication and intelligence. IoT-specific heterogeneous networking technologies that consider the diverse requirements of IoT applications, mobile IoT devices, delay tolerant networks, energy consumption, bidirectional communication interfaces that dynamically change characteristics to adapt to application needs, dynamic spectrum access for wireless devices, and multi-radio IoT devices. Adaptation of software defined radio and software defined networking technologies in the IoT. 3.2.1 Digitisation Digitisation is being utilised in many fields, and, as time passes, the influence of digital approaches and techniques is becoming more apparent in several industrial sectors. Buildings and cities are becoming smarter the larger the number of digital services they offer, vehicles are becoming self-driving, design processes are becoming highly efficient and objects and spaces can be visualised before being materialized thanks to the available digital information. Devices with embedded sensors featuring complex logic are scattered everywhere; they measure light, noise, sound, humidity and temperature and are empowered to communicate with each other to form IoT ecosystems. A common element in all of these developments is that digitisation creates a great amount of information. A considerable part of this information reveals how objects work internally and as elements of more complex setups. Accordingly, many innovative technological installations offer creative solutions concerning how to collect and process this information and how to take necessary action. The challenge with this information is related to how things interact with each other and with the environment while exhibiting behaviour that is often similar to human behaviour. This behaviour cannot be accurately handled by robots, drones, etc., so this is where technologies, such as swarm logic and AI, come into play. Security-perceived threats almost always trigger interactive installations equipped to sense and react to surrounding parameters. Changes in these parameters can be visualised, increasing the chances of real threats being detected and asserted. Thanks to advanced visualisation techniques, the threat landscape is better defined. While security used to be primarily about securing information, the landscape has widened considerably. The timely transfer of information, threat identification, isolation and correct and traceable actions all rely on security protection. IoT ecosystems evolve, so too must security strategies, which have to account for the layered architecture, where all things, encryptions, communications and actions must be protected against a growing number of diverse attacks, whether via hardware, software or physical tampering. The IoT system can be seen as a group of agents with non-coordinated individual actions that can collectively use local information to derive new knowledge as a basis for some global actions. The intelligence lies both in agents (AI) and in their interactions (collective intelligence). At the core of swarm logic is the sharing of information and interactions with each other and the surroundings to derive new information. However, this collective intelligence is prone to a number of attacks, especially related to malicious nodes sending false information to influence the decision-making system. Thus, reputation and trust management systems should be in place to be able to identify malicious or misbehaving system agents/nodes and remove them from the system until they behave normally again. These types of attacks can be easily identified and corrected at the edge of the network without having to move all the information to the cloud. Swarm agents can locate and isolate the threat and then converge towards a common point of processing. This is visualised by depicting the real-time state of the agent’s movement. Swarm-designed security is inspired by nature; hence, if IoT can uncover behaviour patterns (of birds, ants, etc.), it may also be capable of meeting security challenges with well-functioning solutions. 3.2.2 Tactile IoT/IIoT The Tactile IoT/IIoT is a shift in the collaborative paradigm, adding human-centred perspective and sensing/actuating capabilities transported over the network to communications modalities, so that people and machines no longer need to be physically close to the systems they operate or interact with as they can be controlled remotely. Tactile IoT/IIoT combines ultra-low latency with extremely high availability, reliability and security and enables humans and machines to interact with their environment, in real-time, using haptic interaction with visual feedback, while on the move and within a certain spatial communication range. Faster Internet connections and increased bandwidth allow to increase the information garnered from onsite sensors within industrial IoT network. This requires new software and hardware for managing storing, analysing and accessing the extra data quickly and seamlessly through a Tactile IoT/IIoT applications. Hyperconnectivity is needed to take VR and AR to the next level for uniform video streaming and remote control/tactile Internet (low latency). The Tactile IoT/IIoT provides the capabilities to enable the delivery of real-time control and physical (haptic) experiences remotely. The capabilities of the Tactile IoT/IIoT support the creation of a personal spatial safety zone, which is able to interact with nearby objects also connected to the Tactile IoT/IIoT. If applied to traffic, in the long term, this safety zone will be able to protect drivers, passengers and pedestrians. Autonomous vehicles could detect safety-critical situations and react instantly to avoid traffic accidents and warn other objects of impending danger. In production environments, occupational safety levels will improve as production machines or robots detect and avoid the risk of harm to people in their vicinity [45]. A representation of the Tactile Internet of Things Model is shown in Figure 3.4. Figure 3.4 Tactile Internet of Things model. Source: Adapted from Prof Eckehard Steinbach, TU Munich. The Tactile IoT/IIoT is the next evolution that enables the control of the IoT/IIoT in real-time, with all human senses interacting with machines, by using various technologies both at the network and application level to enable and enhance the interaction in the cyberspace. At the edges, the Tactile IoT/IIoT will be enabled by the sensor/actuators and robotic “things”. Content and data are transmitted over a 5G network, while intelligence is enabled close to the user experience through mobile edge computing. At the application level, automation, robotics, telepresence, AR, VR and AI will be integrated in various IoT/IIoT use cases. The Tactile IoT/IIoT provides a medium for remote physical interaction in real-time, which requires the exchange of closed-loop information between virtual and/or real objects (i.e., humans, machines and processes). The IEEE P1918.1 working group defines the Tactile Internet as a “network or network of networks for remotely accessing, perceiving, manipulating or controlling real or virtual objects or processes in perceived real-time by humans or machines” [44]. The domains of Tactile IoT are illustrated in Figure 3.5. The Tactile Internet will benefit VR by providing the low-latency communication required to enable “Shared Haptic Virtual Environments”, where several users are physically coupled via a VR simulation to perform tasks that require fine-motor skills. Haptic feedback is a prerequisite for high-fidelity interaction, allowing the user to perceive the objects in the VR not only audio-visually but also via the sense of touch. This allows for sensitive object manipulations as required in tele-surgery, micro-assembly or related applications demanding high levels of sensitivity and precision. When two users interact with the same object, a direct force coupling brought into existence by the VR and the users can feel one another’s actions. High-fidelity interaction is only possible if the communication latency between the users and the VR is in the order of a few milliseconds. During these few milliseconds, the movements of the users need to be transmitted to the VR server, where the physical simulation is computed, and the result is returned to the users in the form of object status updates and haptic feedback. Typical update rates for the physical simulation and the display of haptic information are in the order of 1000 Hertz, which corresponds to an ideal round-trip communication latency of 1 millisecond (ms) [45]. Figure 3.5 Tactile Internet of Things representation. The use of 5G wireless communications for Tactile IoT/IIoT requires latencies of 1 ms or less. The speed of light in fibre is about 200 km/s. Tactile IoT/IIoT which are distributed over distances larger than about 200 km will require a low-latency IoT core network [50]. Tactile Internet has to meet a number of design requirements such as very low end-to-end latency of 1 ms, high reliability for real-time response, data security, availability and dependability of systems without violating the very low latency requirement due to additional encryption delays. These key design objectives of the Tactile Internet can only be accomplished by keeping tactile applications local, close to the users, which calls for a distributed (i.e., decentralized) service platform architecture based on cloudlets and mobile edge computing. Furthermore, scalable procedures at all protocol layers are needed to reduce the end-to-end latency from sensors to actuators. Importantly, the Tactile Internet will set demanding requirements for future access networks in terms of latency, reliability, and also capacity (e.g., high data rates for video sensors) [51]. Tactile Internet of Things interactions are illustrated in Figure 3.6. In the future, coworking with robots in IoT applications will favour geographical clusters of local production (“inshoring”) and will require human expertise in the coordination of the human-robot symbiosis with the purpose of inventing new jobs humans can hardly imagine or did not even know they wanted done. Fibre-wireless (FiWi) enabled Human-to-Robot (H2R) communications may be a stepping stone to merging mobile IoT/IIoT, and advanced robotics with automation of knowledge work and cloud technologies, which together represent the five technologies with the highest estimated potential economic impact in 2025 [51, 52]. Figure 3.6 Tactile Internet of Things interactions. Source: Adapted from 5G LAB. As presented in Figure 3.7 current Internet cannot guarantee new application delivery constraints. In this context the future technological developments of 5G as the neutral next generation World Wide Wireless Internet by integrating new technologies with a holistic integrated approach combining IPv6-based, machine-to-machine, mobile IoT, mobile edge computing, software defined networks (SDN), network functions virtualisation (NFV), Fringe Internet, Tactile IoT/IIoT, based on seamless worldwide networking interoperability and spectrum harmonisation need to address and solve these constrains for the new applications. Figure 3.7 New applications for NGI and IoT/IIoT [99]. 3.2.3 Digital Twins for IoT Digital twins are virtual representations of material assets. For the IoT, digital twins have never been trendier, as IoT vendors are using increasingly more advanced technology for their implementation, not least with an add-on marketing effect. The current solutions provided by some of the key IoT platforms have mainly been for the representation of physical objects, while such features as simulation, manipulation and optimisation are still missing. Thanks to technologies, such as blockchain, swarm logic and AI, digital twins now have these capabilities. In the pursuit of better security, digital twins can trigger and simulate threat scenarios in the digital world, as well as optimise the security strategy to handle such scenarios should they occur in the real world. The digital twin, as a virtual representation of the IoT’s physical object or system across its lifecycle, using real-time data to enable understanding, learning and reasoning, is a one element connecting the IoT and AI. The digital twin represents the virtual replica of the IoT physical device by acting like the real thing, which helps in detecting possible issues, testing new settings, simulating all kinds of scenarios, analysing different operational and behavioural scenarios and simulating various situations in a virtual or digital environment, while knowing that what is performed with that digital twin could also happen when it is done by the ‘real’ physical “thing”. Digital twins as part of IoT technologies and applications are being expanded to more applications, use cases and industries, as well as combined with more technologies, such as speech capabilities, AR for an immersive experience and AI capabilities, enabling us to look inside the digital twin by removing the need to go and check the ‘real’ thing. A digital twin representation is shown in Figure 3.8. Figure 3.8 Digital Twin representation. Source: Adapted Deloitte University Press. Digital twins for IoT must possess at minimum the following attributes: Correctness – give a correct replication of the IoT ecosystem and its devices Completeness – updated vis a vis the functionality in the real-world system Soundness – exhibit only the functionality available in the real-world system Abstractness – free from details specific to particular implementations Expandability – adapt easily to emerging technologies and applications Scalability – must be able to operate at any scale Parameterised – accessible for analysis, design and implementation Reproducible – be able to replicate the same result for the same input as the real system. The IoT’s digital twins can expand the interface between man and machine through their virtual representation and advanced technologies on levels, such as AI and speech, which enable people and devices/machines to take actions based on operational data at the edge (provided by IoT devices and edge computing processing). 3.3 Future Internet of Things Enabling Technologies 3.3.1 Edge Computing By 2023, the number of cellular IoT connections is forecast to reach 3.5 billion worldwide. The digitisation of assets, equipment, vehicles and processes in a factory means that the number of connected devices will increase exponentially. The estimated number of connected devices needed in a typical smart factory is 0.5 per square metre [1]. This calculation is based on potential use cases and assets that would benefit from a connection. This illustrates the distribution of cellular connectivity requirements (supporting the previously mentioned use cases) in a fully deployed smart factory. The share of each type of connected device [2] depends on whether the site has a low or high level of automation [3]. Evolving to a higher level of automation will increasingly lead to a higher share of 5G connected devices. Both high bandwidth and consistently low latency are necessary to support large data volumes and real-time critical data, as well as to ensure consistent and secure communication [20]. [1] Average number based on data from different manufacturing sites. In dense areas, the connection density could be up to one connected device per square metre. [2] The exact distribution figures for a specific manufacturing site depend on the communication needs. [3] The level of automation is a continuum from manual to fully automatic operations. This requires change in IoT digital infrastructures. According to Gartner, for example, 80 percent of enterprises will have shut down their traditional data centre by 2025, versus 10 percent in 2018. Workload placement, which is driven by a variety of business needs, is the key driver of this infrastructure evolution. In this context, edge computing sits at the peak of Gartner’s 2018 Hype Cycle for Cloud Computing and there is plenty of scope for false starts and disillusionment before standards and best practices are settled upon, and mainstream adoption can proceed. Edge computing delivers the decentralized complement to today’s hyperscale cloud and legacy data centres. To maximize application potential and user experience, technology innovation leaders plan distributed computing solutions along a continuum from the core to the edge. According to business-to-business (B2B) analysts MarketsandMarkets, the edge computing market will be worth $6.72 billion by 2022, up from an estimated $1.47 bn in 2017 – a Compound Annual Growth Rate (CAGR) of 35.4 per cent. Key driving factors are the advent of IoT and 5G networks, an increase in the number of “intelligent” applications and the growing load on cloud infrastructure. Among the vertical segments considered by MarketsandMarkets, Telecom and IT are expected to have the biggest market share during the 2017–2022 forecast period. That’s because enterprises faced with high network load and increasing demand for bandwidth will need to optimize and extend their Radio Access Network (RAN) to deliver an efficient Mobile (or Multi-access) Edge Computing (MEC) environment for their apps and services. The fastest-growing segment of the edge computing market during the forecast period, says MarketsandMarkets, is likely to be retail: high volumes of data generated by IoT sensors, cameras and beacons that feed into smart applications will be more efficiently collected, stored and processed at the network edge, rather than in the cloud or an on-premises data centre [19]. The use of intelligent edge devices requires reducing the amount of data sent to the cloud through quality filtering and aggregation, while the integration of more functions into intelligent devices and gateways closer to the edge reduces latency. By moving intelligence to the edge, local devices can generate value and optimise the processing of information and communication. This allows for protocol consolidation by controlling the various ways devices can communicate with each other. There are different edge computing paradigms, such as transparent computing, fog computing and mobile edge computing (MEC). MEC emerged in the context of 5G architectures and enables an open RAN as well as being able to host third party applications and content at the edge of the network. Fog computing, fog networking or fogging is a decentralized computing infrastructure in which data, processing, storage and applications are distributed in the most logical, efficient place between the data source and the cloud. Fog computing extends cloud computing and services to the edge of the network, bringing the advantages and power of the cloud closer to where information is created and acted upon. In a fog environment, intelligence is in the local area network. Information is transmitted from endpoints to a gateway, where it is then transmitted to sources for processing and return transmission. In edge computing, intelligence and power of the edge gateway or appliance are in devices such as programmable automation controllers. Edge computing allows the reduction of points of failure, as each edge device operates independently and determines which information to store locally and which to send to the cloud for further analysis. Fog computing is scalable and offers a view of the network as multiple data points feed information into it. Fog computing enables high-performance, interoperability and security in a multi-vendor computing-based ecosystem and is focusing on resource allocation at the service level, while transparent computing concentrates on logically splitting the software stack (including OS) from the underlying hardware platform to provide cross-platform and streamed services for a variety of devices. One more difference compared to MEC is the need to support exotic I/O and accelerator aware provisioning, real-time, embedded targets as well as real-time networks such as Time Sensitive Networks (TSN), e.g., IEEE 802.1. Another edge computing technology is represented by CMU’s Cloudlet, which enables new classes of mobile applications that are both compute-intensive and latency-sensitive in an open ecosystem based on cloudlets. The Cloudlets have lately been transformed to Open Edge Computing [4] based on OpenStack [5]. Open Edge Computing has the vision that any edge node will offer computational and storage resources to any user in close proximity using a standardized mechanism. Edge computing technologies are characterized by openness, as operators open the networks to third parties to deploy applications and services, while their differences enable edge computing technologies to support broader IoT applications with various requirements. [4] http://openedgecomputing.org/ [5] https://www.openstack.org/ The connectivity requirements of the manufacturing industry are matched by the capabilities of cellular networks. To enable smart manufacturing, there are different network deployment options depending on the case-by-case needs and the digitisation ambitions of the factory. One option is using virtualization and Dedicated Core Networks (DECOR) to map local private networks and virtual networks running within a mobile operator’s public network. A 4G and 5G network with dedicated radio base stations and Evolved Packet Core in-a-box can be deployed on the premises to ensure that traffic stays local to the site. In this case, on-premises cellular network deployment with local data breakout ensures that critical production data do not leave the premises, using Quality of Service (QoS) mechanisms to fulfil use case requirements and optimize reliability and latency. Critical applications can be executed locally, independent of the macro network, using cellular network deployment with edge computing [20]. The Multi-access Edge Computing (MEC) standard is developed in the ETSI Industry Specification Group/ISG Multi-access Edge Computing (ETSI ISG MEC) [96]. The ETSI ISG MEC is the leading voice in standardization and industry alignment concerning MEC. It is a key building block in the evolution of mobile-broadband networks, complementing Network Function Virtualisation (NFV) and Software Defined Network (SDN), and is: A key enabler for IoT and mission-critical, vertical solutions Widely recognized as one of the key architectural concepts and technologies for 5G Able to enable many 5G use cases without a full 5G roll-out (i.e. with 4G networks) Enabling a myriad of new use cases across multiple sectors as well as innovative business opportunities. The ETSI ISG MEC work on Phase 2 is extending the applicability of MEC technology and rendering MEC even more attractive to operators, vendors and application developers. One example of deployment is the Cloud IoT Edge that extends Google Cloud’s data processing and machine learning to edge devices (e.g., robotic arms, wind turbines, oil rigs, etc.) so they can act on the data from their sensors in real-time and predict outcomes locally. Cloud IoT Edge can run on Android Things or Linux-based operating systems. It is composed of two runtime components, Edge IoT Core and Edge ML, and takes advantage of Google’s purpose-built hardware accelerator ASIC chip, Edge TPUTM. The Edge TPU is a purpose-built small-footprint ASIC chip designed to run TensorFlow Lite machine-learning models on edge devices. Cloud IoT Edge is the software stack that extends Google’s cloud services to IoT gateways and edge devices. Cloud IoT Edge a runtime component for gateway-class devices (with at least one CPU) to store, translate, process and extract intelligence from edge data, while interoperating with the rest of Google’s Cloud IoT platform (see Figure 3.9) [21]. Figure 3.9 How Cloud IoT Edge works [21]. Computing at the edge of the mobile network defines IoT-enabled customer experiences and requires a resilient and robust underlying network infrastructure to drive business success. IoT assets and devices are connected via mobile infrastructure and cloud services are provided to IoT platforms to deliver real-time and context-based services. Edge computing uses the power of local computing and different types of devices to provide intelligent services. Data storage, computing and control can be separated and distributed among the connected edge devices (servers, micro servers, gateways, IoT nodes, etc.). Edge computing advantages, such as improved scalability, local processing, contextual computing and analytics, make it well suited to IoT application requirements. Edge computing technologies like MEC – offering low latency, proximity, high bandwidth, real-time insight into radio network information and location awareness – enable the development of many new types of IoT applications and services for industrial sectors. Augmented Reality (AR) mobile applications have inherent collaborative properties in terms of data collection in the uplink, computing at the edge and data delivery in the downlink [17]. AR information requires low latency and a high rate of data processing in order to provide correct information depending on the location of the device. The processing of information can be performed on a local MEC server instead of a centralized server to provide the user experience required. IoT devices generate additional messaging on telecommunication networks and require gateways to aggregate messages and ensure low latency and security. An architecture used for leveraging MEC to collect, classify and analyse the IoT data streams is presented in [18]. The MEC server manages different protocols and distribution of messages and processes the analytics. The MEC environment supports the creation of new value chains and new type of ecosystems, which provide new opportunities for mobile operators and application and content providers. Information transmission costs and latency limitations of mobile connectivity pose challenges to many IoT applications that rely on cloud computing. Mobile edge computing enables IoT applications to deliver real-time and context-based mobile moments to users of IoT solutions, while managing the cost base for mobile infrastructure. The benefits are improved performance, deployment of intelligence and analytics at the edge, reduced overload of the communication networks, low latency, compliance, satisfaction of concerns related to data privacy and data security and reduced operational costs. Several challenges listed below, however, have to be addressed when considering edge-computing implementations [91]: Mobile edge computing provides real-time network and context information, including location, while giving application developers and business leaders access to cloud computing capabilities and a cloud service environment that is closer to their actual users. Mobile edge computing implementation and integration pose the challenge of providing a distributed architecture with improved robustness, reliability and local intelligence, as well as processing that enables the autonomous execution of processes, rules and algorithms. Mobile edge computing is an important network infrastructure component for blockchain. The continuous replication of “blocks” via devices on this distributed data centre poses a tremendous technological challenge. Mobile edge computing reveals one opportunity to address this challenge. The need to optimize and reduce connectivity, data migration and bandwidths costs associated with sending data to the cloud, while implementing local intelligence, processing and distributed storage. Edge computing solutions for avoiding intermittent connectivity, low bandwidth and/or high latency at the network edge considering the increased numbers of smart edge devices running software for machine learning or AI software Optimization of the communication with nodes in the intervening edge computing infrastructure. Regarding future IoT applications, it is expected that more of the network intelligence will reside closer to the source. This will push for the rise of edge cloud/fog and MEC-distributed architectures, as most data will be too noisy, latency-sensitive or expensive to be transferred to the cloud. Edge computing technologies for IoT require developers to address issues such as unstable and intermittent data transmission via wireless and mobile links, efficient distribution and management of data storage and computing, edge computing interfacing with the cloud computing to provide scalable services and, finally, mechanisms to secure IoT applications. The edge computing model requires a distributed architecture and needs to support various interactions and communication approaches to be used broader in consumer/business/industrial domains. To do this, it needs to provide peer-to-peer networking, edge-device collaboration (self-organizing, self-aware, self-healing, etc.), distributed queries across data stored in edge devices as well as in the cloud and temporary storage locations, distributed data management, (e.g., for defining where, what, when and how long, in relation to data storage) and information governance (e.g., information quality, discovery, usability, privacy, security, etc.). In this context, the research challenges in this area are: Open distributed edge computing architectures and implementations for IoT and IIoT (IT/OT convergence for IoT applications as traditionally the operational technologies (OT) used to manage and automate industrial equipment are placed at the edge of the network, while information technologies (IT) are more centralized). Integrated IoT distributed architecture for IT/OT integration to be used with new business models needed for interpreting or contextualizing IoT data for decision-making, while leveraging integrated data and standard processes to drive outcomes. Modelling and performance analysis for edge computing in IoT. Built-in end-to-end distributed security at every level of the architecture, in addition to mechanisms for monitoring and managing computing and networking endpoints for IoT systems. Heterogeneous wireless communication and networking in edge computing for IoT to handle multiple connectivity solutions using different protocols. Providing different orchestration solutions (e.g., operating both vertically and horizontally with vertical orchestrators to handle services in a specific domain, while horizontal orchestrators manage services across different domains providing integration among them) for edge computing to implement a platform to support both IT and OT activities in IIoT. Orchestration techniques for providing compute resources in separate islands, where it is possible to process information and provide services at the local level for a period of time without a coordinate computation and communication. Resource allocation and energy efficiency in edge computing for IoT. QoS and quality of experience (QoE) provisioning in edge computing for IoT. Trustworthiness distributed end-to-end security and privacy issues in edge computing for IoT. Federation and cross-platform service supply in transparent computing for IoT. 3.3.2 Artificial Intelligence Artificial intelligence concerns activity devoted to making machines intelligent, with intelligence understood as a quality that enables an entity to function appropriately and with foresight in its environment [43]. Intelligent IoT devices are considered intelligent machines, while the collective attributes of a machine (i.e., computer, robot or other device) capable of performing functions, such as learning, decision-making or other intelligent human behaviours, are defined as AI. IoT-based sensor data generated in healthcare, bioinformatics, information sciences and policy- and decision-making in governments and enterprises can be processed using methods that rely on AI to provide new data insights and generate new types of knowledge. The benefits of both AI and the IoT can be expanded when the technologies are combined, both on the edge devices’ end and core servers’ end. AI machine-learning methods can obtain insights from the data to analyse and predict the future connections of IoT devices in advance. AI is playing a starring role in the IoT because of its ability to quickly bring insights from data. ML offers the ability to automatically identify patterns and detect anomalies in the data that smart sensors and devices generate: information such as temperature, pressure, humidity, air quality, vibration and sound. Companies are finding that machine learning can provide significant advantages over traditional business intelligence tools for analysing IoT data, including being able to make operational predictions up to 20 times sooner and with greater accuracy than threshold-based monitoring systems [25]. Figure 3.10 Gartner’s Hype Cycle for emerging technologies 2018. AI techniques extend machine learning strategies that can be applied to intelligent IoT devices for complex decisions based on detecting patterns, self-learning, self-healing, context-awareness and autonomous decision-making. These will involve and affect the future implementations of digital twin models and continuous learning with roles in autonomous vehicles applications, the IoRT and predictive maintenance. Democratized AI, defined as the possibility to put the AI techniques under the reach of everyone, is one of five trends, along with digitalized ecosystems, do-it-yourself biohacking, transparently immersive experiences and ubiquitous infrastructure, that is driving Gartner’s latest Hype Cycle for emerging technologies (see Figure 3.10) [42], derived from 35 individual technologies. The five trends blur the lines between human and machine with the AI group containing technologies such as AI platform as a service (PaaS), artificial general intelligence, autonomous driving (Levels 4 and 5), autonomous mobile robots, conversational AI platform, deep neural nets, flying autonomous vehicles, smart robots and virtual assistants. The technologies enabling the next generation IoT are included under all five areas and comprise AI, edge AI, autonomous systems, blockchain, digital twins, augmented reality (AR), 5G, neuromorphic hardware and IoT platforms. The ubiquitous infrastructures of edge computing and the always-on, always-available, limitless infrastructure environment are enabling technologies that form the basis for the next generation IoT landscape. When combined, AI and IoT transform both the Internet, the global economy and societal interactions. Within the next decade, it is expected that AI and machine learning to be embedded in various forms of technology that incorporate information exchange, analysis and knowledge. The opportunities created range from new services and breakthroughs in science, to the augmentation of human and machine intelligence and their convergence with the digital, virtual and cyber worlds. The future challenges related to the delegation of decision-making to machines and IoT autonomous systems, lack of transparency and whether technological change will outpace the development of governance and policy norms need to be addressed and solutions must be provided. The evolution of basic forms of AI from assisted, augmented, autonomous to collaborative is illustrated in Figure 3.11. In this context, the development of software and IoT devices capable of making ethical judgements as part of autonomous collaborative systems is emerging. As IoT autonomous systems are developing and combined with the ubiquity of AI in applications, such as the Internet of Vehicles for driverless vehicles, artificial ethical agents could become a legal necessity. Figure 3.11 Artificial Intelligence Roadmap. The combined developments in AI and the IoT enable new ways of interacting with connected objects through voice or gesture, while AR and virtual reality (VR) are powered by data generated by the IoT. Sensor/actuator technologies, the IoT, AI and increased connectivity bandwidth (ubiquitous, reliable and secure connectivity) are pushing the development of the Tactile IoT based on the convergence of these technologies where the lines between the digital and the physical blur. The disruptive nature of AI comes from the speed, precision, and capacity of augmenting humanity. When AI is defined through seven outcomes as presented in Figure 3.12, the business value of AI projects gain meaning and can easily show business value through a spectrum of outcomes [54, 55]: Perception describes what is happening now. Notification is a way of providing answers to questions through alerts, workflows, reminders and other signals that help deliver additional information through combined manual input and machine learning. Suggestion recommends action. This is built on past behaviours and modifications over time that are based on weighted attributes, decision management and machine learning. Automation repeats recurrent actions. It is leveraged as machine learning matures over time and tuning takes place. Prediction informs what to expect. It builds on deep learning and neural networks to anticipate and test for behaviours. Prevention helps avoid negative outcomes. It applies cognitive reckoning to identify potential threats. Situational awareness explains what must be known immediately. It resembles mimicking human capabilities in decision making. AI methods to search for information in data and for learning from past and predict the future is illustrated in Figure 3.13. Figure 3.12 Outcomes of Artificial Intelligence. Source: Constellation Research. Figure 3.13 Artificial Intelligence methods. Companies face a difficult task when deciding which opportunities to pursue, among the hundreds available, but they can narrow their options through a structured approach. The first step involves picking an industry and identifying the potential for disruption within the industry, which is estimated by looking at the number of AI use cases, start-up equity funding, and the total economic impact of AI, defined as the extent to which solutions reduced costs, increased productivity, or otherwise benefited the bottom line in a retrospective analysis of various applications. The greater the economic benefit, the more likely that customers will pay for an AI solution. Figure 3.14 shows the data compiled for 17 industries for AI-related metrics [46]. AI is a promising technological innovation, raising already high expectations for 2025. The IoT is the source of data for AI and machine learning applications, as fleets of connected IoT devices, autonomous vehicles and robots need to be automated to allow them to react to environmental conditions in real-time. By 2021, AI will support more than 80% of emerging technologies, while, in the following year, it will support more than 80% of enterprise IoT projects, according to Gartner. By 2020, it will create 2.3 million jobs, although 50% of organizations will lack the relevant AI and data talent. Figure 3.14 AI dependency on market size, pain points, and willingness to pay across different industries. Source: Adapted from McKinsey & Company, [46]. While software has been a predominant factor in most corporate and investor interest for many years, hardware has become important again with the growth of AI. The cloud continues to be an option for various applications, not least due to its scale advantage, and the choice between cloud or edge solutions will depend on the IoT use cases and applications. Regarding cloud hardware, the market remains fragmented. The hardware preference of customers and suppliers vary for application-specific integrated circuit (ASIC) technology and graphics processing units (GPUs). The low latency connectivity at the edge is critical, driving the current development and growing role for inference at the edge. ASICs — with their superior performance per watt — provide a more optimized user experience, including lower power consumption and higher processing, for many applications. Enterprise edge is covered by several technologies, such as field programmable gate arrays, GPUs and ASIC technology. The ML and DL technology stack is divided into nine layers [46], across services, training, platform, interface, and hardware as presented in Figure 3.15. Figure 3.15 Machine Learning (ML) and Deep Learning (DL) technology multi-layered stack. Source: Adapted from McKinsey & Company, [46]. Despite rather old technological foundations, in recent years, machine learning has brought about important progress for applications such as computer vision or natural language processing. It has also recently attracted sizeable investments with an explosion in VC money and a growing focus (through buy outs and investments) amongst Internet companies. The key AI innovations are presented Figure 3.16. The most anticipated AI applications for 2025 move beyond the current focus on language and vision by targeting advanced data analytics capacities and enabling decision-making applications. Figure 3.16 Key AI innovations according to the IDATE Technology 2025 survey. Source: IDATE DigiWorld. Unprecedented abilities in Data Analytics If computers are starting to catch up with humans in their ability to detect objects in images, applying deep learning to a field where algorithms are already ahead of most humans, such as data analytics, promises potentially momentous breakthroughs. Figure 3.17 AI adoption/maturity vs. value at stake. Source: Adapted from McKinsey & Company, [46]. Applying deep learning to data analytics enables complex pattern recognition and prediction. This is especially noteworthy in the case of “unsupervised training” machine learning, that is, when the algorithm is fed with unstructured data and tries to spot interesting patterns on its own. Several industries offer the strongest opportunities for AI: public sector, banking, retail, and automotive as presented in Figure 3.17. While the public sector’s prominence may seem surprising in an age where governments are cutting budgets, many officials see the value of AI in improving efficiency and efficacy, and they are willing to provide funding. As they plan their AI strategies, suppliers may focus their investments on potential consumers of AI solutions who are willing to be the first domino [46]. An important domain concerning the application of deep learning data analytics is the health sector. Using deep learning approaches can help in health record data analysis to improve diagnostics, risk analysis and preventive medication. Examples of health applications include reconstructing brain circuits, predicting the activity of potential drug molecules or predicting the effects of mutations in non-coding DNA on gene expressions. The Mount Sinai Hospital (see Figure 3.18) recently highlighted the potential for using unstructured deep learning in the secondary use of electronic health records in order to predict health status, as well as to help prevent disease or disability. The interest in deep learning approaches is especially strong in the case of traditional data analysis methodologies, which have been applied with limited success, as it can improve prediction results. Figure 3.18 Use of unstructured deep learning in the analysis of hospital patient data. Source: Nature/Mount Sinai Hospital. The IoT as Key Data provider for AI Access to relevant data sets (often derived from vertical industries) in order to train the deep learning algorithms will be critical. The development of the IoT can play a critical role in providing access to the relevant data sets for training future AI including the digital twin models. Shrinking computer chips and improved manufacturing techniques have led to cheaper and more powerful sensors. As the number of sensors employed in IoT ecosystems increases rapidly, so do the amounts of raw data produced, in turn calling for new computational models to handle this by employing intelligence at the edge for information processing. The new computational models need to cope not only with larger quantities but also with increased complexity of the raw data in terms of their syntax and semantics. Machine learning and deep learning are able to collect and process data from billions of sensors. Algorithmic developments in AI are coupled with increased data resources and computational demands that are served mainly today by cloud infrastructures. New developments to address AI algorithms for processing data at the edge are underway. Despite the rapid advances of AI in vision, speech recognition, natural language processing and dialog, there is still room for improvement when developing end-to-end intelligent systems that must encapsulate multiple competencies and deliver services in real-time using limited resources. In this direction, the developments are focusing on designing and delivering embedded and hierarchical AI solutions in the combined IoT/IIoT, edge and cloud computing environments that provide real-time decisions, using less data and computational resources, while orchestrating the access to each type of resource in a way that enhances the accuracy and performance of the models. The distributed AI concept builds on top of a hierarchy where low-level, context-agnostic models, which run on the IoT and on IoT devices, can dynamically feed higher-order models running on higher-capacity resources, so as to better capture the context knowledge. Due to the adoption of AI methods and techniques making use of a wide range of available resources (IoT/IIoT/edge/cloud), IoT applications are now able to offer a trade-off between accuracy and performance, depending on the overall requirements. Complex IoT applications allow distributed intelligence embedded in limited resource sensors at the edge of the network, providing an effective demonstrator of the potential of AI as a service model. There is a need to identify AI and machine learning (ML) methodologies for temporal data to build distributed learning systems that can scale from the IoT/IIoT to edge and cloud resources. The development of connected vehicles, smart cities and connected health are especially likely to provide access to the massive amounts of data required by deep learning approaches. However, other domains of IoT deployments, such as the industrial Internet are increasingly generating data sets that could fit the deep learning approach. The number of data points that manufacturing facilities generate and the ability to find correlations and pattern and recommend decisions among these IoT data could be addressed by deep learning or other AI methods approaches. AI and IoT/IIoT requirements for complex integrated systems In complex IoT applications, the same conditions will seldom apply twice to the same situation, even when they involve the same process; the context and the operation conditions in a specific environment, such as the stress and fatigue of the equipment, always contribute to the creation of an entirely new set of input values for the model. To cope with this expected richness of the model, feedback and training data need to be requested continuously and by a multitude of manufacturing equipment, resulting in a default global (and hence, cross-border) AI model. Deep learning approaches can aggregate the underlying model inputs and gradually build the necessary user and context profiles, but the models (low and higher order) need to continuously adapt to the influx of new data. A multi-parametric model of manufacturing equipment profiles requires the federation of a multitude of underlying models and data (functional, behavioural, environment, operational, informational, etc.), orchestrated in a distributed and decentralized fashion so as to ensure that the evaluation is happening close to the data sources (ensuring real-time reactions) in an efficient and collaborative fashion. Thus, the applications across industrial sectors integrating AI and IoT need to address a multitude of requirements in order to fulfil the integration of functional and non-functional attributes for such complex systems. The requirements for complex IoT/IIoT systems that have embedded artificial intelligence (AI) techniques and methods can be summarized as presented in Figure 3.19 and the following list: Figure 3.19 AI and IoT/IIoT requirements for complex system integrated systems. Explainability: Enables human users to understand the decisions made by AI systems and the rationale behind them. This ability will make it easier to track down eventual failures and assess decisions’ strengths and weaknesses. Ultimately, this will increase the trust in the systems’ decisions. This ability will have to integrate with human-computer interface techniques which are able to track complex reasoning processes. Availability: Enables IoT applications to provide data and resources in a timely manner for a set percentage of time (i.e., the uptime) as well as retain their core functionality, even if the system has undergone a security attack. Industrial IoT applications may target mission-critical tasks along the production line; system outages will therefore have direct economic impact. In the near future, it is also envisaged that IoT systems, due to embedded AI, will be able to perform autonomously via online learning over their lifetime and remove even the downtime needed for maintenance. AI systems should be available in terms of integration into new applications and process steps. Trustworthiness: Enables IoT systems to be trusted, only allowing authenticated devices or services that can be uniquely identified to participate in the decision-making processes of the system. This makes it possible to report the source of vulnerabilities and inconsistencies. As more and more AI-enabled systems become connected through the IoT, trustworthiness becomes an indispensable requirement. Precisely due to the AI, trustworthiness will become multi-dimensional, far beyond verifying identity. Consequently, trust will no longer be ‘true’ or ‘false’, but rather about degrees of trustworthiness that will control the access levels of devices/users to critical services. Security: Enables systems to guarantee distributed end-to-end security, which is essential to ensure robustness against all types of attack vectors in the IoT. This includes securing the AI system itself as well as securing communication between edge computing IoT devices with encryption and authentication mechanisms against attacks with manipulated input data. Safety: Enables systems to protect persons and objects during operation. AI systems that operate physically next to and collaboratively with humans through robots or other machines must not exhibit random or unpredictable behaviour. Safety by design is essential, entailing compliance with relevant safety standards. Importantly, the employed AI and IoT systems must be robust against implausible data and operate with extremely low latency to quickly and appropriately react to unforeseen events (i.e., to prevent accidents). Privacy: Enables IoT and AI-based systems that operate on mission- and business-critical data to keep this data private. This entails both limiting access to and placing restrictions on certain types of information with the goal of preventing unauthorized access (confidentiality) as well as protecting data from being modified or corrupted without detection. Such data must therefore be processed locally at the edge and only leverage data available within privacy limits (smart data). Transparency: Enables IoT and AI-based systems to provide insight into devices and processes in situations such as auditing, inspections to assess vulnerabilities, or when security breaches arise. This may be supported by digital twins that represent the complete system state at any point in time. AI methods for data visualization can further enhance transparency and contribute to making the systems state easier to understand. Fairness: Enables IoT systems which embed AI technologies to support or automate decision processes while adhering to the same fairness and compliance standards as humans. Inclusiveness: Enables AI-based IoT systems to allow human intervention even in the most automated decision and communication processes. This is essential to avoid the formation of isolated non-AI capable sub-systems within a process, production system or supply chain. Collaboration: Enables AI-based IoT systems to self-organize around a common goal; for example, in the presence of a threat, as well as to collaborate with humans, both physically (e.g., human-robot collaboration) and by exchanging information (human-machine interfaces). Collaboration is an emergent property of complex interactions and dynamics, increasingly present in industry. Industry-grade AI will not be concentrated on a single device or system. Instead, many different AI-enabled subsystems will be distributed (distributed AI) across IoT nodes, embedded devices and other edge devices (embedded AI). Integration: Enables IoT-embedding AI systems to exhibit an open and flexible perspective by consolidating insights from all existing systems and processes. Bridging possible gaps is a key prerequisite of the establishing AI methods in the industry according to a sustainable roadmap. Reliability: Enables IoT systems to operate without systems outages and regular human intervention. Reliability is essential for productivity and is a key prerequisite for AI systems that are put into continuous operation with short maintenance time in mission-critical production environments. Resiliency: Enables IoT with embedded AI to always operate in stable states, including to return to such states after failures. Resilience is essential for their safe support for our digital economy. In the future, they should even be able to detect failure and initiate measures for compensating it. Accountability: Enables IoT systems with embedded AI systems that support or even replace human decisions to be accountable to their customers, partners and regulators. Normally, accountability features will be integrated “by design” and will be available via the supplier of these systems. Verifiability: Enables IoT and AI-based systems to demonstrate the functionality and properties they are supposed to have. AI systems for industrial applications must fulfil the same standards as legacy systems and will be applied to safety-, mission- and business-critical tasks. This requires that AI embedded systems can be validated (to reach correct results), verified (verifiable AI) and certified (certifiable AI) for the targeted applications. The research challenges for implementing AI at the edge of networks for IoT applications are as follows: Mechanisms for collecting and aggregating data and information and developing edge models that generate insights from the data available in real-time by providing methods and techniques to train models in the edge environment with appropriately distributed storage capabilities ‘AI-friendly’ processors to address the AI workloads for IoT applications requiring AI computationally intensive capabilities; research and development concerning architectural concepts to shift central control to the edge and the use of modified graphics processor units, hybrid processors and AI-based processors, embedding accelerators and neural networks for processing specific AI algorithms New energy- and resource-efficient methods for image recognition and geospatial processing using AI at the edge, based on machine learning and other AI techniques Edge computing implementation based on neuromorphic computing and in-memory computing to process unstructured data, such as images or video, used in IoT applications Edge computing implementations based on distributed approaches for IoT computing systems at the edge Distributed IoT end-to-end security for AI-based solutions that process data at the edge using a group of edge nodes to work together on a particular task, thereby ensuring that no security holes or attacks are possible AI for smart data storage in edge-based IoT AI for software-defined networking in edge-based IoT Swarm intelligence algorithms for edge-based IoT/IIoT Machine learning, deep learning and multi-agent systems for edge-based IoT/IIoT Cognitive aspects of AI in edge-based IoT/IIoT Neural networks for AI in edge-based IoT/IIoT Distributed heterogeneous memory systems design for AI in edge-based IoT/IIoT 3.3.3 Networks and Communication It is predicted that the adoption of low-power short-range networks for wireless IoT connectivity will increase through 2025 and will coexist with wide-area IoT networks [82], while 5G networks will deliver 1,000 to 5,000 times more capacity than 3G and 4G networks today. IoT technologies are extending known business models, leading to the proliferation of different ones as companies push beyond the data, analytics and intelligence boundaries. IoT devices will be contributing to and strongly driving this development. Changes will first be embedded in given communication standards and networks and subsequently in the communication and network structures defined by these standards. 5G and the IoT promise new capabilities and use cases, which are set to impact not only consumer services but also many industries embarking on their digital transformations. New massive IoT cellular technologies, such as NB-IoT and Cat-M1, are taking off and driving growth in the number of cellular IoT connections, with a CAGR of 30 percent expected between 2017 and 2023. These complementary technologies support diverse LPWAN use cases over the same underlying LTE network [20]. 3.3.3.1 Network technology – hyperconnectivity beyond 5G The development of critical communication capabilities will be an essential enabler for the development of the IoT. It will enable IoT use cases to go beyond data collection and respond to complex scenarios requiring precise actuation, automation and mission critical communications. The next generation technological enhancements to telecommunication networks, brought about by 5G, will allow new connectivity to become the catalyst for next generation IoT services by creating innovations such as advanced modulation schemes for wireless access, network slicing capabilities, automated network application lifecycle management, software-defined networking and network function virtualization, as well as providing support for edge- and cloud-optimized distributed network applications. The requirements of critical IoT communications are numerous and diverse, ranging from the increased reliability and resilience of the communication network, to ultra-low latencies and high capacity, while also integrating the context of the mission with the ability to respond to strict energy efficiency constraints or to cover large outdoor areas, deep indoor environments or vehicles moving at high speeds. Bandwidth and delay for services enabled by legacy networks and 5G are presented in Figure 3.20. Figure 3.20 Bandwidth and delay for services enabled by legacy networks and 5G. Source: Adapted from [95]. Table 3.1 Key critical IoT communications requirements Requirements Details Reliability High availability of the network Low packet losses Resilience Ability to function in degraded conditions Low convergence time Energy efficiency Projected lifespan of equipment batteries Low latencies End-to-end latencies of communication systems under 10 ms and sometimes inferior (under 5 ms or even under 1 ms). Coverage Coverage of very a large area (rural) Deep indoor coverage Coverage of moving vehicles Ability to deploy and use private networks Security Authentication of communications Encryption of communications Attack detections Capacity Ability of the network to operate with a very large number of users Source: IDATE. Starting with LTE Advanced, cellular communication standards have begun responding to these requirements by developing new technologies. These first developments are opening new possibilities, especially for public safety operations, but they are still limited in scope. They notably lack the ability to provide the ultra-low latencies required by many critical use cases. The development of 5G is seen as central to enabling critical IoT communications; indeed, many of the planned 5G features (from network slicing and massive multi-user multiple-input, multiple-output (MIMO) to new messaging services, cellular vehicles-to-everything or improved relay capabilities) represent highly important advances for critical scenarios, including reliable, low latencies. The critical IoT communications requirements are presented in Table 3.1. End-to-end (E2E) network slicing is a foundation to support diversified 5G services and is key to 5G network architecture evolution. Based on Network Functions Virtualisation (NFV) and Software Defined Network (SDN), physical infrastructure of the future network architecture consists of sites and three-layer data centres (DCs). Sites support multiple modes (such as 5G, LTE, and Wi-Fi) in the form of macro, micro, and pico base stations to implement the RAN real-time function. These functions have high requirements for computing capability and real-time performance and require the inclusion of specific dedicated hardware. Three-layer cloud DC consists of computing and storage resources. The bottom layer is the central office DC, which is closest in relative proximity to the base station side. The second layer is the local DC, and the upper layer is the regional DC, with each layer of arranged DCs connected through transport networks. According to diversified service requirements, networks generate corresponding network topologies and a series of network function sets (network slices) for each corresponding service type using NFV on a unified physical infrastructure. Each network slice is derived from a unified physical network infrastructure, which greatly reduces subsequent operators’ network construction costs. Network slices feature a logical arrangement and are separated as individual structures, which allows for heavily customizable service functions and independent operation and management [47]. Advanced ML and AI techniques can also be used for optimizing the connectivity of future mobile heterogeneous IoT devices to allow them to support efficiently a number of diverse services. ML techniques can be used to identify the optimal radio technology in mobile IoT devices considering the load and the services they support. Additionally, in future cognitive radio-based IoT devices, ML techniques can be used to optimize the spectrum channel and width, the devices will use and create a self-organizing network of cooperating devices to improve spectrum utilization [92–94]. Figure 3.21 End-to-End Network Slicing for Multiple Industries Based on One Physical Infrastructure [47]. As illustrated in Figure 3.21, Enhanced Mobile Broad Band (eMBB), Ultra Reliable Low Latency Communications (uRLLC), and Machine Type Communications (mMTC) are independently supported on a single physical infrastructure. eMBB slicing has high requirements for bandwidth to deploy cache in the mobile cloud engine of a local DC, which provides high-speed services located in close proximity to users, reducing bandwidth requirements of backbone networks. uRLLC slicing has strict latency requirements in application scenarios of self-driving, assistant driving, and remote management. RAN Real-Time and non-Real-Time processing function units must be deployed on the site side providing a beneficial location preferably based in close proximity to users. Vehicle-to-Everything (V2X) server and service gateways must be deployed in the mobile cloud engine of the central office DC, with only control-plane functions deployed in the local and regional DCs. mMTC slicing involves a small amount of network data interaction and a low frequency of signalling interaction in most MTC scenarios. This consequently allows the mobile cloud engine to be deployed in the local DC, and other additional functions and application servers can be deployed in the regional DC, which releases central office resources and reduces operating expenses [47]. Highly dependent upon both the creation of new technologies and the deployment of new communication networks (requiring both important investments all along the value chain), critical IoT capabilities are unlikely to be largely available before 2025. The 5G spectrum high bands are expected to be deployed include the 28 GHz band, as well as the 26 GHz, 37 GHz and 39 GHz bands. The 28 GHz band may be used in certain countries by the end of 2018 or early 2019, while the other high bands are estimated to be available in late 2019. Low bands below 1 GHz are of interest due to their favourable radio wave propagation characteristics, as they provide coverage in remote areas and into buildings. A new band in the 600 MHz range is expected to be made available by the end of 2018 for 5G services. Part of the mid-bands between 1 GHz and 7 GHz are expected to be allocated in several countries. Mid-bands within the 3.3 GHz to 5 GHz range will likely be made available around 2020 and are seen as important spectrum resources for terrestrial 5G access networks. The midbands are particularly beneficial as they offer a favourable “middle ground” between propagation characteristics (coverage) and bandwidth (capacity). There are several spectrum bands already in use by service providers. In general, all the current 3GPP bands including low bands (600 MHz, 700 MHz, 800 MHz, 850 MHz and 900 MHz) and mid-bands (1.5 GHz, 1.7 GHz, 1.8 GHz, 1.9 GHz, 2.1 GHz, 2.3 GHz and 2.6 GHz) are being considered for 5G services in the future. These bands, and composite arrangements of these bands, will be central to delivering 5G coverage and capacity for enhanced mobile broadband, IoT, industrial automation and mission-critical business cases, as well as for Public Protection and Disaster Relief (PPDR) services. In addition, 3 GPP has recently started a separate Study Item to investigate the feasibility of using the 6.5 GHz band (5,925 MHz to 7,125 MHz) for 5G services [20]. Frequency ranges being studied for identification at World Radio Communication Conference 2019 [95] are presented in Figure 3.22. Figure 3.22 Frequency ranges being studied for identification at World Radio Communication Conference 2019 [95]. IoT applications, based on AR and VR, will revolutionize customer experience in gaming, retail shopping and other customer-centric applications. Consumer experience will be enhanced by high data rates, while extremely low latencies will be achieved. However, these developments are of interest to many industries, including the automotive, manufacturing, health, energy and public service sectors. There are several factors that could impact commercial adoption of Network Slicing as presented in Figure 3.23. The adoption of Network Slicing influences the IoT applications and the selection of connectivity solutions. In this context, industry activities to standardise Network Slicing should focus on minimising the complexity of the technical solution so that adoption can be made relatively easy, the IoT use cases need to be defined to drive economies of scale and reduce unitary cost of deployment and the operators need to make the cost of deploying Network Slicing marginal to the broader investment case for 5G [49]. The development of a critical IoT is mainly a business-to-business (B2B) and business-to-business-to-consumer (B2B2C) demand, and strongly driven by the digital transformation of vertical industries and expanding the traditional cellular technology development (which relies heavily on consumer brands). Figure 3.23 Factors that could impact commercial adoption of Network Slicing [49]. The global market is thus limited in volume, with market estimates according to IDATE of about 60 million units by 2030; but this will be compensated by high average revenue per units (ARPUs) as the technology will respond to a critical demand in many industries in terms of generating important cost reductions and new revenue opportunities. Table 3.2 Vertical industrial sectors – key requirements for critical IoT communications Verticals Critical IoT Scenarios Demand Strength Key Requirements Automotive Automated cars +++ Latency, reliability, coverage (large scale and mobility), point-to-point communication (V2V, V2I) Health Robotics ++ Latency, reliability, energy efficiency. Industrial IoT Automation, time-critical automation, remote control ++ Latency, reliability, coverage (deep indoor) point-to-point communication, Energy efficiency and local (private) deployments Energy Fault prevention and alert, grid backhaul network ++ Latency, reliability, point-to-point communication, large-scale coverage Public safety Mission-critical communications ++ Reliability, coverage, resilience, energy efficiency. Agriculture, forestry, environment Automation + Latency, reliability, energy efficiency, coverage of rural areas Source: IDATE. The leading market in volume will be the automotive sector, in which the development of the most advanced autonomous cars will use critical IoT capabilities to perform tasks, such as complex intersection control, dynamic area management, and cooperative cruise control and platooning. The automotive industry is already strongly involved in the standardization process of 5G with the set-up of the 5G Automotive Association (5GAA). Other verticals of importance include connected health, in which critical IoT capabilities promise the generalization of teleoperations and robotics surgery. Manufacturing will also be strongly impacted, as critical IoT capabilities are among the building blocks of the smart factory (enabling advanced automation and remote control). The key requirements for critical IoT communications in different industrial sectors are presented in Table 3.2. The 5G use cases can be realized to provide solutions in the B2C, B2B, B2B2X and IoT market segments. In B2C market, operators offer the services such as high definition video (TV, movies, streaming live sports) or home security solutions directly to the end consumers. In B2B market, operators offer the services such as mobility solutions and Cloud services to the businesses (SMEs, large corporations) where the services are typically consumed by the employees of the business. In B2B2X market, the services such as ‘In stadium’ high definition video service are offered to businesses like stadium operators and they in turn offer the service to their premium customers. In IoT market, operators can leverage the low latency, high reliability, high bandwidth and massive connections capabilities to offer several vertical industry use cases like connected vehicles, smart utilities and remote surgery types of applications by participating in the industry specific ecosystems and innovating new business models. Figure 3.24 illustrates the 5G applications market potential and readiness matrix presenting the connectivity and value-added services opportunities in different sectors [98]. Figure 3.24 5G Applications Market Potential and Readiness Matrix [100]. Figure 3.25 5G use in different industrial application areas. Figure 3.26 Key requirements for connectivity for factory of the future automation. Figure 3.27 International Mobile Telecommunications system requirements for the year 2020 (IMT-2020) mapped to 5G use cases [95]. International Mobile Telecommunications system requirements for the year 2020 mapped to 5G use cases [95] are presented in Figure 3.27. These promising prospects are attracting many actors to define their future role in the critical IoT market. The capabilities of 5G will indeed lead to more complex value chains with more actors providing connectivity and bundling connectivity with vertical specific services. It is seen by telecommunication companies as an opportunity to diversify and offer vertical specific services, but the rest of the value chain is also eager to benefit from new revenue streams: from equipment providers betting on small cell networks, to over-the-top (OTT) players looking over unlicensed networks or pure vertical players integrating connectivity in their new services. Figure 3.25 illustrates the use of 5G connectivity in different industrial application areas. Industrial sectors will depend on smart wireless technologies like 5G and LTE advanced for efficient automation of equipment, predictive maintenance, safety, process tracking, smart packing, shipping, logistics and energy management. Smart sensor technology offers unlimited solutions for industrial IoT for smarter, safe, cost effective and energy efficient industrial operation. A number of key requirements for factory of the future automation scenarios for connectivity are presented in Figure 3.26. 5G communications could be considered a disruptive element enabling the vision of a truly global IoT, given that one of the key features of 5G is the focus on the integration of heterogeneous access technologies, including satellite communication systems. Satellites could play an important role in providing ubiquitous coverage and reliability in remote areas and enabling new IoT services. IoT devices are not equipped with satellite connectivity, while IoT protocols are not designed with satellite requirements in mind. Thus, cross-layer optimization is required to allow the collection of IoT data from satellites, load balance and the oﬄoading of terrestrial networks, in turn enabling smooth integration of IoT and satellite networks. 5G offers a more reliable network and will deliver a secure network for the IIoT by integrating security into the core network architecture. Industrial facilities will be among the major users of private 5G networks. Future networks have to address the interference between different cells and radiation and develop new management models to control roaming, while exploiting the coexistence of different cells and radio access technologies. New management protocols controlling the user assignment with regard to cells and technology will have to be deployed in the mobile core network for better efficiency in accessing the network resource. Satellite communications need to be considered as a potential radio access technology, especially in remote areas. With the emergence of safety applications, minimizing latency and the various protocol translations will benefit end-to-end latency. Densification of the mobile network strongly challenges the connection with the core network. Future networks should however implement cloud utilization mechanisms in order to maximize efficiency in terms of latency, security, energy efficiency and accessibility. In this context, there is a need for higher network flexibility, which combines cloud technologies with software-defined networks and network function virtualization, which will enable network flexibility to integrate new applications and configure network resources to an adequate degree (sharing computing resources, splitting data traffic, security rules, QoS parameters, mobility etc.). The evolution and pervasiveness of present communication technologies have the potential to grow to unprecedented levels in the near future by including the Web of Things (WoT) into the developing IoT. Network users will be humans, machines and things, and groups of them. Figure 3.28 Global number of connected IoT devices [27]. 3.3.3.2 Communication technology Global connection growth is mainly driven by IoT devices, both on the consumer side (e.g., smart home) and on the enterprise/B2B side (e.g., connected machinery). The number of IoT devices that are active is expected to grow to 10 billion by 2020 and 22 billion by 2025. Figure 3.28 presents the global number of connected IoT devices categorised by the communication/protocol technology [27]. These trends require the extension of the spectrum in the 10–100 GHz range and unlicensed band and technologies, such as WiGig or 802.11ad, which are mature enough for massive deployment and can be used for cell backhaul, point-to-point or point-to-multipoint communication. Modular integrated connectivity creates a scalable mobile platform (modems for 2G/3G/4GLTE), enabling high-speed data and voice and various onboard selected LoRa, Sigfox, On Ramp Wireless, NWave/Weightless SIG, 802.11 Wi-Fi/Wi-Fi Aware, Bluetooth, ZigBee, 6LowPAN, Z-Wave, EnOcean, Thread, wMBus protocols with the simultaneous use of multiple ISM radio bands (i.e., 169/433/868/902 MHz, 2.4 GHz and 5 GHz). Connectivity modules are based on integrated circuits (ICs), reference designs and feature-rich software stacks created according to a flexible modular concept, which properly addresses various application domains. The load of the network will differ, with some models using the unbalanced load of the ad hoc network from the core network point of view, and others using network-based solutions by balancing the topology from the core network point of view. In this case, the identified network requirements to be supported are the calculation of the optimal ad hoc network topology, by using monitoring information, and the notification of appropriate actions. Wireless Personal Area Networks (WPANs) The highest number of IoT devices is connected through short-range technology (WPAN), which typically does not exceed 100 m in the maximum range. These include Bluetooth-connected devices, such as headsets, as well as ZigBee- and Z-Wave-connected devices, which can mostly be found in smart homes, e.g., for connecting smoke alarms or thermostats [27]. Zigbee 3.0 is a networking solution used on top of IEEE 802.15.4 radio technology, which includes Wi-Fi and IP Internet capability. Zigbee 3.0 has meshing capability and is used as an IoT connectivity solution for a range of smart home and industrial applications, including lighting, security, thermostats and remote controls. It is secure and supports battery-free devices, meshing, low latency and energy harvesting (e.g., motion, light, piezo, Peltier). Zigbee 3.0 also includes Zigbee Green Power, which was developed as an ultra-low-power wireless standard to support energy-harvesting IoT devices and is effective for IoT devices that are only sometimes on the network (i.e., when they have power), enabling them to go on and off the network securely, so they can be off most of the time. 6LowPAN is a network protocol that defines encapsulation and header compression mechanisms. The standard has the freedom of a frequency band and a physical layer and can also be used across multiple communications platforms, including Ethernet, Wi-Fi, 802.15.4 and sub-1 GHz ISM. The protocol is implementing open IP standards including TCP, UDP, HTTP, COAP, MQTT and web sockets, and offers end-to-end addressable nodes, allowing a router to connect the network to IPs. 6LowPAN is a mesh network that is robust, scalable and self-healing. Mesh router devices can route data destined for other IoT devices, while hosts are able to sleep for long periods of time. Wireless Local Area Networks (WLANs) Another large category comprises WLANs, which offer a range of connectivity up to 1 km. Wi-Fi is the most common standard in this category and experiencing significant growth, mostly through the use of home assistants, smart TVs and smart speakers, but also increasingly through use in industrial settings such as factories (although it continues to play a minor role in those settings compared to other technologies) [27]. With the introduction of Wi-Fi 6 (802.11ax standard), the connectivity performance is enhanced for the use of IoT devices and businesses and operators running large-scale deployments. Wi-Fi 6 brings more capabilities to support next generation connectivity uses. Wi-Fi 6 offers faster speeds for all devices on the 2.4 GHz and 5 GHz spectra, with a raw throughput speed boost of as much as 37%. Wi-Fi 6 IoT devices can shut down Wi-Fi connections most of the time using the Target Wake Time feature and connect only briefly as scheduled in order to transmit data they have gathered since the last time this was performed, thus extending battery life. Wi-Fi 6 uses orthogonal frequency-division multiple access (OFDMA) to improve the efficiency of multi-user multiple-input, multiple-output (MIMO) streams. MIMO works both on the uplink and on the downlink and can simultaneously receive data from different devices on different channels (maximum of eight in Wi-Fi 6) at once. The Target Wake Time feature improves sleep and wake efficiency, reduces power consumption and decreases congestion on crowded networks. In Wi-Fi 6, the theoretical maximum bandwidth of a single stream is 3.5 Gbit/s, and up to four streams can be delivered to a single device, which means a maximum of up to 14 Gbit/s. Low-Power Wide Area Networks (LPWANs) A large chunk of the future growth in the number of IoT devices is expected to come from LPWANs. By 2025, it is expected that more than two billion devices will be connected through LPWANs. The technology, which promises extremely high battery life and a maximum communication range of over 20 kilometres, is used by the three main competing standards, LoRa, Sigfox and NB-IoT, which are currently being rolled out worldwide with more than 25 million devices already connected to date, the majority of which are smart meters [27]. Another research report predicts that there will be 2.7 billion LPWAN IoT connections by 2029 [28]. LPWANs operate in the unlicensed industrial, scientific and medical (ISM) spectrum at 900 MHZ, 2.4 GHz and 5 GHz. LoRa is the standard protocol of the LoRa Alliance (open, non-profit association established in 2015 with more than 500 members). LoRa has a bandwidth of 250 kHz and 125 kHz and a maximum data rate of 50 Kbps, enabling bidirectional communication albeit not simultaneously, and has a maximum payload of 243 bytes. The range is up to 5 km in urban areas and 20 km in rural areas depending on the application. There are around 50 million LoRa-based end nodes and 70,000 LoRa gateways that have already been deployed worldwide [29]. LoRa networks use gateway devices to work and manage the network for connecting IoT devices. Sigfox operates and commercializes its own proprietary communications technology, which is an ultra-narrowband (100 Hz) with a maximum data rate of 100 bps. It also operates in the unlicensed ISM spectrum and its small payload (maximum 12 bytes) means it can offer greater coverage geographically, reaching up to 10 km in urban areas and 40 km in rural areas. Sigfox offers bidirectional connections, with the downlink from base stations to end IoT devices occurring following uplink communication. The daily uplink messages are limited to 140. Weightless (Weightless-N, Weightless-W and Weightless-P) operates in the unlicensed spectrum and is an open standard (Weightless SIG) designed to operate in a variety of bands, with all the unlicensed sub-GHz ISM bands, while featuring a 100 kbps maximum data rate on uplink and downlink. Weightless can handle 2,769 end points per base station on standard smart meter set-ups (200 bytes uploaded every 15 min). NB-IoT coexists with GSM and LTE and is a 3GPP LTE standard, based on licensed cellular networks providing a 200 kHz bandwidth and a 200 kbps maximum data rate, which offers bidirectional communication, albeit not simultaneously, and has unlimited messages with a maximum payload 1,600 bytes. The global shipments of NB-IoT devices will have a compound annual growth rate of 41.8% from 106.9 million units in 2018 to 613.2 million in 2023 [30]. LTE-M is another 3GPP providing extended coverage by using an installed LTE base with the same spectrum, radios and base stations. It is implemented as a 4G technology with an important role in 5G. The uplink/downlink transfers 1 Mbps and, due to low latency and full duplex operation, can carry voice traffic. LTE-M supports more demanding IoT mobile devices, which require real-time data transfer (e.g., transport, wearable), while NB-IoT supports more IoT static sensors and devices. Cellular and non-cellular LPWA network connections will grow globally at a 53% CAGR until 2023, driven by market growth in smart meters and asset trackers. In 2017, smart meters and asset trackers contributed to almost three quarters of all LPWA network connections, dominated by non-cellular LPWA network technologies. By 2023, non-cellular LPWA will cede its market-share dominance to NB-IoT and LTE-M, as cellular LPWA moves to capture over 55% of LPWA connections. Private LPWA networks, built to address a single vertical application or an individual enterprise, have been popular choices for over a decade and accounted for 93% of LPWA connections in 2017. LoRa and other non-cellular LPWA technologies have benefited from the decreasing cost of ICs, low implementation costs and flexibility of private networks, which can be tailored to meet specific enterprise IoT applications. As the geographic footprint of public networks rapidly expands, cellular and non-cellular public networks will capture over 70% of LPWA connections by 2023 [31]. Future IoT devices will require network agnostic solutions that integrate mobile, NB-IoT, LoRa, Sigfox, Weightless etc. and high-speed wireless networks (Wi-Fi), particularly for applications spanning multiple jurisdictions. LPWA networks have several features that make them particularly attractive for IoT devices and applications, which require low mobility and low levels of data transfer: Low power consumption that enable devices to last up to 10 years on a single charge Optimized data transfer that supports small, intermittent blocks of data Low device unit costs Few base stations required to provide coverage Easy installation of the network Dedicated network authentication Optimized for low throughput, long or short distance Sufficient indoor penetration and coverage Wired Few people think of wired connections when they think of the IoT. In many settings, a wired device connection is still the most reliable option that provides very high data rates at very low cost, albeit without much mobility. Particularly in industrial settings, fieldbus and Ethernet technologies use wired connections to a large extent, and it is expected that they will continue to do so in the future [27]. Sensor/actuator units that are installed within a building automation system can use wired networking technologies like Ethernet. Power Line Communication (PLC) is a hard-wired solution that uses existing electrical wiring instead of dedicated network cables and for industrial applications has significant advances. According to the frequency bands allocated for operation PLC systems can be divided into narrowband PLC (NBPLC), and broadband PLC (BPLC). NBPLC refers to low bandwidth communication, utilising the frequency band below 500 kHz and providing data rates of tens of kpbs, while BPLC utilises a wider frequency band, typically between 2 MHz and 30 MHz, and allows for data rates of hundreds of Mbps. BPLC is recommended for smart home applications requiring high-speed data transfer applications like Internet, HDTV, and audio, while the use of NBPLC systems is more appropriate for remote data acquisition, automatic measuring systems, renewable energy generation, advanced metering, street lighting, plug-in electric vehicles, etc. BPLC has higher speed, that reduce the data collection period and ensures a real-time remote-control command, but its stability and reliability are still determined by the quality of power lines. Another way to classify PLC is as PLC over AC lines and PLC over DC lines. Most companies are currently providing AC-PLC solutions, PLC in DC lines also has applications for distributed energy generation, and transportation (electronic controls in airplanes, automobiles and trains). Cellular / M2M 2G, 3G and 4G technology, for a long time, were the only option for remote device connectivity. As LPWA and also 5G gain momentum, it is expected that these legacy cellular standards will cede their share to new technologies as they present a more lucrative opportunity to many end users [27]. 5G 5G is under development and the technology, which promises a new era of connectivity through its massive bandwidth and extremely low latency, is now heavily promoted by governments, particularly China. The Chinese government views 5G adoption as a competitive asset in the quest to move the equilibrium of technological innovation from the US and Europe towards China. In the US, the first pre-standard 5G networks will provide fixed wireless access (FWA) services to residential and small business users by the end of this year. While many more use cases will be targeted once the final standard is ratified in 2020, we should already see first adopters next year and expect quick growth from there [27]. 5G includes two of the tree scenarios, massive machine type communications (mMTC) and ultra-reliable and low latency communications (URLLC), which support IoT applications for industries with available, ultra-low latency links for next generation IoT services. The Internet as network technology is focusing on the internet working among underlay technologies in order to provide end-to-end services. Telecoms/communication and Internet/computer communication are converging via telephone/cellular and Internet/data networks. The TCP/IP paradigm started as an overlay of network technologies, while TCP/IP is nowadays integrated in pre-existent network infrastructures and starting to include transport and application functionality in the network as well. 5G is including the wired/core section of the network, as well as LANs, to architecturally integrate cloud/fog/edge systems, based on software network functions, providing differentiated service support. The next generation Internet and 5G are converging into a fully integrated interoperable network, where people and IoT physical, digital and virtual devices interact in real-time. 5G connectivity is one important element in building real-time interactive systems and implementing a tactile IoT/IIoT in order to provide the communication infrastructure with low latency, very short transit time, high availability, reliability and security. LTE evolution will continue, while LTE and 5G will co-exist in upcoming years. The availability of device hardware and attractive service pricing will influence the adoption of 5G for various IoT applications across different industrial sectors. 5G monetization is a critical success factor for the deployment of 5G and monetization models must be supported by different pricing models. Some of the monetization models to be considered are [98]: Monetize network, infrastructure and business services by leveraging the network and infrastructure capabilities: Operators provide services such as Network as a Service, Information broadcasting, Cloud services with high QoS that attract premium in B2B segments. Operators become platform providers for a variety of micro-services, assuring low latency where needed by providing them on the edge. With this model, application developers and vendors could simply define how they want their applications to perform and let the connectivity provider make it happen. Operators enable the developers to monetize their applications that connect to many millions of devices and in turn will be able to secure revenues from developers and the end users of these devices. Leveraging the infrastructure, vertical industrial solutions can be offered by establishing ecosystems with complex partnerships and revenue sharing models. Key for success is to make the economics work for both the operators and other participants in the ecosystem to bring useful solutions to the market quickly. Monetize value: 5G creates opportunity for operators to monetize the ‘value’ created by services with revenue sharing type of models rather than being simply the connectivity provider. Applications such as translation services, home automation can be monetized by putting compute functionality on the ultra-low latency edge networks and thus putting it on the Cloud without compromising on latency. Advertisements in the new digital services like high definition content offers new monetization opportunities for operators. Data monetization: Operators have access to customer data – customer priorities and interactions, network data – usage, pattern, massive number of device related data. This massive amount of data along with data analytics creates new opportunities for operators to monetize insights. Wireless Neighbourhood Area Networks (WNANs) WNANs sit between WLAN and long-range technologies, such as cellular, in terms of communication range. Typical proponents of this technology include mesh networks such as Wi-SUN or JupiterMesh. In some cases, the technology is used as an alternative to LPWA/cellular (e.g., in utilities’ field area networks) and in other cases such as a complementary element (e.g., for deep indoor metering where nothing else reaches) [27]. Wi-SUN is an open standards-based field area network (FAN) used for the IoT and can support applications such as advanced metering infrastructure, distribution automation, intelligent transport and traffic systems, street lighting, and smart home automation. The suite of IoT technologies is based on IEEE 802.15.4, TCP/IP and related standard protocols with a bandwidth of up to 300 kbps, a low latency of 20 ms, power efficiency (less than 2 mA when resting; 8 mA when listening), resilience, scalability (networks to 5,000 devices; 10 million end points worldwide) and using security mechanisms based on public key certificates, AES, HMAC, dynamic key refresh and hardened crypto. The PHY layer is based on IEEE 802.15.4g, which provides bidirectional communication. The network layer is IPv6 with 6LoWPAN adaptation supporting star and mesh topologies, as well as hybrid star/mesh deployments. These different types of networks are needed to address IoT products, services and techniques so as to improve the grade of service (GoS), quality of service and quality of experience (QoE) for end users. Customization-based solutions are addressing the IIoT while moving to a managed wide-area communications system and ecosystem collaboration. Intelligent gateways will be needed at lower cost to simplify the infrastructure complexity for end consumers, enterprises and industrial environments. Multifunctional, multiprotocol processing gateways are likely to be deployed for IoT devices and combined with Internet protocols and different communication protocols. These different approaches show that device interoperability and open standards are key considerations in the design and development of internet-worked IoT systems. Ensuring the security, reliability, resilience and stability of Internet applications and services is critical to promoting the concept of a trusted IoT, based on the features and security provided by devices at various levels of the digital value chain. 3.3.4 Distributed Ledger Technology/Blockchain Technology A distributed ledger is a record of transactions or data that is maintained in a decentralized form across different systems, locations, organizations or devices. It allows data or funds to be effectively sent between parties in the form of peer-to-peer transfers without relying on any centralized authority to broker the transfer. A distributed consensus mechanism allows members of the network (nodes) to establish a common “truth”. There are different mechanisms for this: in the case of Bitcoin and other “cryptocurrencies”, a computationally complex “proof-of-work” algorithm is used to protect the integrity of the network against change to the public “blockchain” by making it impractical for malevolent players to alter the chain. Whilst Bitcoin operates on a public blockchain, there is also the possibility to operate distributed ledgers privately where network participants are provided with relevant permissions to either read or write to (i.e., append) the ledger [33, 34]. Blockchain is a technological disruption in secured infrastructures. It is based on a combination of encrypted algorithms and duplicated data storage on a network of computers. Used as a secured infrastructure, it can meet the demand for security from various industries. From a technological perspective, blockchain is a data storage infrastructure technology. It makes it possible to store data securely (each entry is authenticated, irreversible and duplicated), with decentralized control: there is no central authority that controls the information on the chain. This is achieved using encryption technologies (hash function and asymmetric cryptography) and a computer network of independent nodes. Blockchain technologies were initially designed to be used with the Bitcoin cryptocurrency, where they were employed to create a reliable ledger of all financial transactions. But blockchain technology is also developing in ways that are opening new prospects: The use of blockchains as a ledger of transactions (the initial use case) The use of blockchains to accurately archive and date important pieces of information The introduction of smart contracts: automated conditional transactions that are executed without human intervention or the involvement of a trusted third party The advent of decentralized applications: applications that use the blockchain as their execution infrastructure, without a centralized IT platform The information architecture used by Bitcoin technology provides a source for the development, contextualization, exchange and distributed security of data needed for the IoT. Blockchains for the IoT transform the way business transactions are conducted globally within a trustworthy environment to automate and encode business transactions while preserving enterprise-level privacy and security for all parties in the transaction. Blockchain solutions are, for instance, being developed to identify IoT objects and to sign automatic and decentralized contracts between connected devices. The benefits of blockchains for the IoT are providing mechanisms for building trust between stakeholders in an IoT application and IoT devices with blockchain cryptography, to reduce the risk of collusion and tampering, to facilitate cost reductions by removing the overheads associated with middlemen and intermediaries, and to accelerate transactions by reducing the settlement time from days to almost real-time. Considerations in the application of distributed ledgers for the IoT include addressing the storage space, the computing power of the devices, security, communication power, transaction confirmation time, consensus mechanisms, congestions, costs/fees and price volatility. IoT applications using distributed ledger technologies (DLTs) must evaluate several attributes regarding the implementation of use cases, which must take into account the retention in the distributed ledger, multiparty sharing needs, the trade-off between retrieval and flexibility performance for the ledger database features and the trade-off in real-time, as there is a time lapse between the moment when data or transactions are generated and when the consensus mechanism confirms that the information is part of the ledger. The evolution of the blockchain is illustrated in Figure 3.29. Figure 3.29 Evolution of the blockchain. Source: Adapted from IDATE DigiWorld, Blockchain, October 2016. IoT devices will be used in building blockchain-based solutions to support applications aimed at improving operational efficiency, transforming the user experience and adopting new business models in a secure, private and decentralised manner, so that all stakeholders benefit. This is especially the case for blockchain applications that can track and control property: from asset management applications (IoT devices being used to track assets along the logistics chain) to a radical transformation of business relationships, transitioning to a world where any property or object can easily be rented out to another user securely and without the need to interact directly with the user (the user signs a smart rental contract, which, once the payment has been made, gives him/her access to the lock for a set period of time). The IoT can make use of blockchain-based computing platforms (e.g., iExec, Golem, Sonm, Hypernet, Ripple) or Hyperledger, which is an open source Linux Foundation platform. Recently, the Enterprise Ethereum Alliance, a blockchain standards organization, and Hyperledger announced that they have joined each other’s groups [22, 23]. Other solutions offered by Ripple, BigchainDB and Sovrin exist [37–39]. The Hyperledger platform [22, 24] connects data from the IoT via specific adapters in order to integrate a variety of existing sensors and protocols, as well as integrate and connect transactions that are related to these sensors with blockchain systems that might belong to different stakeholders. The platform allows for the use of cognitive artificial intelligence (AI) components to infer new insights from these combined data. Further research is needed to define how to optimally combine blockchains, cognitive AI and the IoT for various industry domains. Figure 3.30 Combining blockchain technology and the IoT with the use of IBM Watson and blockchain platforms [41]. Figure 3.31 Using blockchain and the IoT to improve operations in the aviation industry [40]. Combinations of blockchain technology and the IoT into an IoT-driven blockchain, as used in the aviation industry, are presented in [40, 41] (see Figures 3.30 and 3.31). The combination of blockchains and the IoT provides several benefits in supply chains such as: tracking objects as they travel along the export/import supply chain, while enforcing shipping and lines of credit contracts and expediting incremental payments; maintaining an indelible history of parts and end assembly through supply chains, potentially including critical events that affect life or scheduled maintenance; providing decentralized edge computing to securely run computing workloads, such as analytics, on edge devices owned by third parties; interconnecting IoT devices by allowing distributed devices to request and pay for services through distributed role management and micropayments, as well as regulatory compliance, in order to track equipment or process history in an indelible record, and enabling easy sharing of this information with regulatory agencies or insurers [41]. IOTA is a next generation blockchain focused on use in the IoT as a “ledger of things”. IOTA uses a revised distributed ledger design known as a “tangle”, which aims to be massively scalable as well as avoid the cost of replicating all data to all nodes [35, 36]. Hypernet is proposing new architecture and has implemented a new programming model beneath the blockchain layer to handle distributed computation problems, which require inter process communication. Hypernet is based on the principle of distributed average consensus (DAC), and the combination with blockchains allows for the efficient distribution of compute jobs, while effectively managing processing units in dropping on and off the network. The platform creates a secure backbone, where buyers and providers of computational power can engage, based on trust. The on-chain (scheduled) and off-chain (DAC) technology layers of Hypernet fit together, with both driven by consensus. Golem, iExec and Sonm have built their concept on traditional computing architectures developed specifically to be used in data centres. These data centre architectures pose challenges to a distributed network used in the IoT as the amount of network communication and data transfer overhead is very high and the architectures do not tolerate computers randomly dropping in and out of the network. As data centre architectures are optimised for one particular topology, they cannot be used on a distributed network, as the network topology is unknown. Blockchain-based systems require devices in the blockchain to have the resources run the blockchain software and process blockchain data. However, distributed ledgers are open, with devices connected to a distributed ledger known as “nodes”. Each “block” within the ledger has a maximum size of 1 MB and IoT devices used to hold a full copy of the ledger need to have processing and storage capabilities necessary to hold at least a few “full nodes” containing the complete ledger. IoT security issues are relevant when using blockchain technology, as there is a need for proper security credentials to view a transaction and IoT device commissioning and secure key management are challenging issues in the case of IoT devices. Addressing and solving the limitations of blockchain technology in the future could allow for the integration of blockchain-based platforms for the IoT. Furthermore, considering that a blockchain contains the transaction and can also contain the contract, the IoT device can process financial information, buying/selling data from/to another IoT device or system, which could produce a transactional system less prone to the problems of resilience. The blockchain model has several limitations for the use with IoT devices as blockchain processing tasks are computationally intensive and timeconsuming, while IoT devices have limited processing and storage resources to directly participate in a blockchain. Lower-end IoT edge devices with limited storage space, communications bandwidth and processing power are not especially suitable to support resource-intensive distributed ledgers but can utilize the services of a distributed ledger network (e.g., by using an API). IoT gateway devices, such as an IoT home gateway, could potentially support blockchains (e.g., Raspberry Pi as a “full node”). The requirement for large amounts of disk storage adds cost and complexity, making it more likely that this would be reserved for higher-end gateway products. Lower-end IoT gateways and connections with limited bandwidth are more likely to access the distributed ledger network using an API. High-end IoT edge nodes, such as industrial controllers, smart building controllers and enterprise systems should be able to run capable distributed ledger solutions. Maintaining a local copy of the distributed ledger provides for local high-performance access to the data held on the ledger, as well as continuity in the case that connectivity to the Internet may be disrupted. IoT mobile edge computing nodes (i.e., deployed in the carrier network) can be used to build new distributed ledger solutions typically offered by telecoms operators to enterprise customers as a permissioned distributed ledger [33]. The research challenges for implementing DLTs and blockchains at the edge of networks for IoT applications are as follows: Techniques for increased scalability, as DLTs and blockchains do no scale as required by IoT applications for use in a distributed system. Solutions for dealing with the required processing power, as IoT devices do not have the processing and storage capabilities required to perform encryption for all the objects involved in a blockchain-based ecosystem. Connecting large numbers of IoT devices requires large volumes and very low cost, while the majority of these IoT devices are not capable of running the required encryption algorithms at the desired speed. Techniques to speed up the process of validating the transactions for IoT devices. Storage capabilities (e.g., internal flash memory or external NOR or NAND flash) to be used to store transactions and device IDs, as well as the ledger on the nodes as the ledger increases in size as time passes. Addressing the complexities of the convergence of DLTs, blockchains and IoT technologies and providing simpler implementations at the system level. Interoperability issues when combining data sources from different applications, while considering the lack of data model standards for industrial vertical markets. Legal and compliance issues for hybrid transactions management across different industrial sectors. Security, privacy and trust of blockchain and decentralized schemes. Performance optimization of blockchain and decentralized schemes. Lightweight protocols and algorithms based on blockchains. Blockchain-based lightweight data structures for IoT data. Blockchain-based IoT security solutions. Blockchains in 5G. Blockchains in edge and cloud computing. 3.4 Emerging IoT Security Technologies IoT-based businesses, applications and services are scaling up and going through various digital transformations in order to deliver value for money and remain competitive. In this context, they are becoming increasingly vulnerable to disruption from denial-of-service attacks, identity theft, data tampering and other threats. Emerging distributed end-to-end security technologies enhance the ability of an IoT ecosystem and its devices to exhibit complex behaviour independently or collectively in the presence of threats, in a pursuit to achieving end-to-end security. By using such technologies as blockchain, swarm logic and AI, IoT can offer security by design and end-to-end security solutions never implemented before. Techniques such as simulation and optimisation allow for the integration of security early in the design, where a diversity of security breach scenarios can be tested and guarded before they occur in real life. Interoperability, scalability and security are three of the most essential attributes of IoT environments and ecosystems, which are absent or not fully addressed in today’s architectures. Several technologies have succeeded in offering sound and complete solutions to these matters, although not without challenges still remaining. A new 3D IoT layered architecture capturing the IoT systems functions and cross-cutting functions is presented in Figure 3.32. Among them, blockchain technology has been developed for scale and with interoperability in mind; hence, it is often generalized as DLT. Its security mechanism, based on public ledger and consensus, is applied across the stack and the network, whether this is centralized, decentralized or distributed. Nevertheless, in spite of all security advancements, guarding against single scenarios of fraud, hacking and other breaches still remains a challenge. Different IoT topologies require different security configurations and strategies, and this is especially true at the edges, where devices can be diverse, less traditional, small and possibly out of reach for security updates. The edges are therefore vulnerable, providing entry points for malicious attacks, which are difficult to track and therefore easily propagate throughout the whole IoT ecosystem. Figure 3.32 3D IoT Layered Architecture. As edge devices are often unsophisticated devices, it may be difficult to build security into the design. However, it is here that swarm technology may come to the rescue. Edge devices may form clusters, where they collaborate and share resources and functions in the presence of perceived danger. Each edge device, now belonging to a cluster, will exhibit collective intelligence and be able to evolve and adapt to new requirements and threat situations. Swarm technology helps to identify the threat and define its landscape. In the evolving IoT market, security goes beyond securing the information exchanged among the IoT nodes. The entire operation of an IoT ecosystem depends on protection at all levels, from single devices to communications. Moreover, devices must exhibit a high level of resilience against a growing range of attacks, including hardware, software and physical tampering. Security is therefore critical to IoT technologies and applications, and end-to-end security is essential to enabling the implementation of trustworthy IoT solutions for all stakeholders in IoT ecosystems and IoT value networks to enable the development, deployment and maintenance of systems in IoT applications and provide a common framework to enable the growth of IoT value network solutions. The standard security services that are valid for the Internet framework and technology, such as authentication, confidentiality, integrity, non-repudiation, access control and availability, should be extended to also apply to IoT technologies but adapted with their particularities and constraints in mind. Identification: is the act of allowing a device or service to be specifically and uniquely identified without ambiguity. This may take the form of RFID tag identifiers, IP addresses, global unique identifiers, functional or capability identifiers, or data source identifiers. Authentication: is the act of confirming the truth of an attribute of an entity or a single piece of data by using passwords, PINs, smart cards, digital certificates, or biometrics to sign in. In contrast with Identification, Authentication is the process of actually confirming the Identity of a device or confirming that data arriving or leaving are genuine and have not been tampered with or forged. Authorization: is the function of specifying access rights to resources and ensuring that any request for data or control of a system is managed within these policies. Authorization mechanisms tend to be centralized, which may be a challenge in IoT systems that tend to be increasingly decentralized, without an authority involved. Whatever the degree of democratized authorization, where more entities can grant permissions, the authorization system must be consistent, persistent and attack resistant. Availability: has two definitions within the IoT domain. Firstly, as with mainstream Information Assurance, the system must provide data and resources in a timely manner for a set percentage of the time (e.g. 99.99% uptime availability). Secondly, in the IoT it is critical that many devices are available or retain their critical functionality, even if the system has undergone an attack. Confidentiality: is a set functionality that limits access or places restrictions on certain types of information, with the goal of preventing unauthorized access. Confidentiality is usually achieved through encryption and cryptographic mechanisms and is essential within an IoT ecosystem where a large amount of information is exchanged among the nodes. Integrity: is a critical measure in information assurance and is defined as providing consistency or a lack of corruption within the IoT system. It requires the final information received to correspond with the original information sent and that data cannot be modified without detection. Malicious modification of the information exchanged may disrupt the correct functioning of an entire IoT ecosystem. Non-repudiation: is an aspect of authentication that enables systems to have a high level of mathematical confidence that data, including identifiers, are genuine. This ensures that either a transmitting or receiving party cannot later deny that the request occurred (cannot later “repudiate”) and provides data integrity around the system. This is of particular importance in terms of tracking illegal activities within an IoT system, as it allows for accountability to be enforced. Whether Non-repudiation needs to be enforced under certain circumstances will depend on the particular applications. A Root of Trust: is an immutable boot process within an IoT system based on unique identifiers, cryptographic keys and on-chip memory, to protect the device from being compromised at the most fundamental level. The Chain of Trust extends the Root of Trust into subsequent applications and use cases. Given that IoT systems rely on a large number of devices that collect and process information, it is paramount to ensure their credibility so that they are honest and leverage correct outputs. Secure Update: enables IoT systems and devices to install new firmware from authorized sources without the firmware being compromised. Software updates are critical processes and are susceptible to a number of threats and attacks. During an update, the device receives the firmware wirelessly and installs it, removing the previous version. However, to reassure that the process is being done properly and securely, the sender of the firmware should be verified as trusted, the firmware should be validated as not compromised, the initial security keys should be protected, etc. Additionally, depending on the services that the device offers, the downtime during a firmware update may need to be kept at a minimum. If not properly protected, devices may be open to manipulation, typically through the installation of malicious code on a device. 3.5 IoT/IIoT Technology Market Developments IoT/IIoT components, communication, systems, platforms, solutions applications and services markets are developing steadily, posing new challenges for research and innovation concerning IoT technologies addressing next generation developments. The IoT chip market is expected to register a CAGR of over 13.68% during the forecast period of 2018–2023. The report profiles end user segments (such as healthcare, building automation and automotive segments) in the IoT chip market in various regions. Chipsets designed for IoT systems have unique factors including the need for optimal energy efficiency. The network effect is clearly evident as the impact of increasingly interconnected IoT systems will cause an acceleration in overall demand for chipsets due to the interdependency of platforms, gateways and devices [26]. The number of connected devices that are in use worldwide now exceeds 17 billion, with the number of IoT devices at seven billion (not including smartphones, tablets, laptops or fixed-line phones). Global connection growth is mainly driven by IoT devices – both on the consumer side (e.g., smart home) and on the enterprise/B2B side (e.g., connected machinery). The number of IoT devices that are active is expected to grow to 10 billion by 2020 and 22 billion by 2025 (see Figure 3.33). The global market for IoT (end user spending on IoT solutions) is expected to grow by 37% from 2017 to $151 billion. Due to the market acceleration regarding the IoT, those estimates have been revised upwards and it is now expected that the total market will reach $1,567 billion by 2025. Software and platforms are expected to continue to drive the market as more data are moved to the cloud, new IoT applications are brought to market, and analytics continue to gain in importance [27]. Figure 3.33 Total number of active device connections worldwide [27]. 3.5.1 Digital Business Model Innovation and IoT as a Driver The growing digitisation of businesses as well as societies has facilitated an increase in the amount of data made available and to be adopted and explored in the development of businesses. Digitisation is creating a second economy that is vast, automatic and invisible – thereby bringing the biggest change since the Industrial Revolution [1]. Data has become massive and has moved from static data to real-time data streams created by the IoT based on a large number of transactions of millions of sensors and devices across the ecosystems of many organizations, even now moving from the central paradigm of the cloud more and more towards the edge in a distributed manner [2]. Some studies estimate an increase in annually created, replicated and consumed data from around 1,200 exabytes in 2010 to 40,000 in 2020 [3], with a growing proportion of data generated and consumed by machines [3]. In businesses, IoT data can be applied, for instance, to target customers more effectively; make better pricing decisions; predict failures; and optimise the use of assets, production or logistics. To fully exploit IoT in business we need to understand how businesses integrate technology [2]. 3.5.1.1 Business models and business model innovation Business models are intended to make sense of how businesses work. Business models are abstracted in different ways in the literature. Business models are discussed in [6] as a narrative that describes the customer, customer value, revenue collection of the model and the delivery of this value. Another level of abstraction is presented in [11]. In this reference the business model is described as an archetype of 55 different business model building blocks that can be combined in various ways to accommodate the business model in which the business operates. The most popular and most adopted break-through on another level of abstraction is the graphical framework. The most widely adopted graphical framework is the Business Model Canvas presented in [10]. The business model literature points to the fact that the technological development of the Internet and recent developments of ICT has boosted the usage of the business model concept and innovation in general. According to [9] in the context of innovation, the term Business Models is used to either commercialize new technology or ideas and as a source of innovation to the business model itself, that can lead to a competitive advantage. Figure 3.34 The importance of Business Model Innovation with respect to external changes in the environment. The use and importance of business model innovation is stated in [12] and illustrated in Figure 3.34: Business Model Innovation will continue to become increasingly important for ensuring sustained competitiveness of both large and small businesses. Business Model Innovation is expected to serve as a facilitator of new market exploration and an important source of competitive advantage. Continuous adaptation of business models is imperative to ensure organizational fit with the environment. However, there are significant research gaps combining technology trends with business model innovation: Empirical evidence remains patchy and often builds on observations of businesses that have successfully implemented new business models without knowing how the innovation has been created in the first place. Business Model Innovation frameworks are technology agnostic and often abstract the complexity of ecosystems, technology development/operations and organisations challenges. 3.5.1.2 The use of IoT for digital business development IoT and digital technologies are central for digital business development and the disruptive business innovation tendencies of this decade and probably also decades to come. Consequently, Nambisan et al. [4] conceptualise digital innovation as “the creation of (and consequent change in) market offerings, business processes, or models that result from the use of digital technologies” and therefore, digital innovation management refers to the “practices, processes, and principles that underlie the effective orchestration of digital innovation”. Thus, we need to examine how different company types, industries and sectors apply digital technologies to design digital businesses and digital business models. 3.5.1.3 The design and implementation processes of digital business development Through digitisation of the business functions through IoT, data can be provided to enhance and develop each of these functions and thus the entire value chain. In practice this is demonstrated in the dramatic change of the marketing functions focus on online, social media and mobile marketing and less of a focus on traditional advertising, thus creating stronger interactions and continuous data collections with customers through social networks. Through the online environment, assortment and pricing decisions is made easier and much more flexible. Logistics and logistics streams are key to competitive delivery and services, and the marketing and logistic functions therefore need to cooperate more effectively in order to deliver superior customer value, and at a lower and more competitive cost [2]. With standards to represent different forms of data (text, numbers, pictures and video) facilitating communication via Bluetooth and the internet has led to the evolution of new products and services, and thus data has become a commodity. Thus, we need to explore the specific processes that go into the adoption and implementation of digital business development viewed from both a business and technology angle. The effect and business opportunities of digitisation across ecosystems. Digitisation affects entire ecosystems, their business models and the underlying business functions of a company’s value chain. With intelligent devices becoming interconnected in IoT, new developments have created associated infrastructure and an expanding knowledge base, and these innovative combinations are being reflected in enterprises’ “digital” business models [5]. Thus, we need to examine which metric and measurement systems are applied and require development to better assess the tangible as well as intangible value creation and capture of digital business development. How technology, organisation and business interact is still poorly understood. Most studies have focussed on successful businesses and have been conducted within a discipline like business, innovation, technology or organisation. The literature provides some patchy evidence which shows Business Model Innovation (BMI) as a cross-disciplinary activity, connected with technology. It is also clear that IoT is a strong driver for business development and digitisation in industry, with many new applications and services emerging and driving new business models. We call for more concerted efforts to link business and technology at the applied research level and to devise new methods of studying IoT. Acknowledgments The IoT European Research Cluster – European Research Cluster on the Internet of Things (IERC) maintains its Strategic Research and Innovation Agenda (SRIA), considering its experiences and the results from the on-going exchange among European and international experts. The present document builds on the 2010, 2011, 2012, 2013, 2014, 2015, 2016 and 2017 Strategic Research and Innovation Agendas. The IoT European Research Cluster SRIA is part of a continuous IoT community dialogue supported by the EC DG Connect – Communications Networks, Content and Technology, E4 – Internet of Things Unit for the European and international IoT stakeholders. The result is a lively document that is updated every year with expert feedback from on-going and future projects financed by the EC. Many colleagues have assisted over the last few years with their views on the IoT Strategic Research and Innovation agenda document. Their contributions are gratefully acknowledged. List of Contributors over the Years of IERC Activities: Abdur Rahim Biswas, IT, CREATE-NET, WAZIUP Alessandro Bassi, FR, Bassi Consulting, IoT-A, INTER-IoT Alexander Gluhak, UK, Digital Catapult, UNIFY-IoT Amados Daffe, SN/KE/US, Coders4Africa, WAZIUP Antonio Kung, FR, Trialog, CREATE-IoT Antonio Skarmeta, ES, University of Murcia, IoT6 Arkady Zaslavsky, AU, CSIRO, bIoTope Arne Bröring, DE, Siemens, BIG-IoT Arthur van der Wees, Arthurs Legal, CREATE-IoT Bruno Almeida, PT, UNPARALLEL Innovation, FIESTA-IoT, ARMOUR, WAZIUP Carlos E. Palau, ES, Universitat Politècnica de Valencia, INTER-IoT Charalampos Doukas, IT, CREATE-NET, AGILE Christoph Grimm, DE, University of Kaiserslautern, VICINITY Claudio Pastrone, IT, ISMB, ebbits, ALMANAC Congduc Pham, FR, Université de Pau et des Pays de l’Adour, WAZIUP Dimitra Stefanatou, Arthurs Legal, CREATE-IoT Elias Tragos, IE, Insight Centre for Data Analytics, UCD and FORTH-ICS, RERUM, FIESTA-IoT Emmanuel C. Darmois, FR, COMMLEDGE, CREATE-IoT Eneko Olivares, ES, Universitat Politècnica de Valencia, INTER-IoT Fabrice Clari, FR, inno TSD, UNIFY-IoT Franck Le Gall, FR, Easy Global Market, WISE IoT, FIESTA-IoT, FESTIVAL Frank Boesenberg, DE, Silicon Saxony Management, UNIFY-IoT François Carrez, UK, University of Surrey, FIESTA-IoT Friedbert Berens, LU, FB Consulting S.à r.l, BUTLER Gabriel Marão, BR, Perception, Brazilian IoT Forum Gert Guri, IT, HIT, UNIFY-IoT Gianmarco Baldini, IT, EC, JRC Giorgio Micheletti, IT, IDC, CREATE-IoT Giovanni Di Orio, PT, UNINOVA, ProaSense, MANTIS Harald Sundmaeker, DE, ATB GmbH, SmartAgriFood, CuteLoop Henri Barthel, BE, GS1 Global Ivana Podnar, HR, University of Zagreb, symbIoTe JaeSeung Song, KR, Sejong University, WISE IoT Jan Höller, SE, EAB Jelena Mitic DE, Siemens, BIG-IoT Jens-Matthias Bohli, DE, NEC John Soldatos, GR, Athens Information Technology, FIESTA-IoT José Amazonas, BR, Universidade de São Paulo, Brazilian IoT Forum Jose-Antonio, Jimenez Holgado, ES, TID Jun Li, CN, China Academy of Information and Communications Technology, EU-China Expert Group Kary Frãmling, FI, Aalto University, bIoTope Klaus Moessner, UK, UNIS, IoT.est, iKaaS Kostas Kalaboukas, GR, SingularLogic, EURIDICE Latif Ladid, LU, UL, IPv6 Forum Levent Gürgen, FR, CEA-Leti, FESTIVAL, ClouT Luis Muñoz, ES, Universidad De Cantabria Manfred Hauswirth, IE, DERI, OpenIoT, VITAL Marco Carugi, IT, ITU-T, ZTE Marilyn Arndt, FR, Orange Markus Eisenhauer, DE, Fraunhofer-FIT, HYDRA, ebbits Martin Bauer, DE, NEC, IoT-A Martin Serrano, IE, DERI, OpenIoT, VITAL, FIESTA-IoT Martino Maggio, IT, Engineering – Ingegneria Informatica Spa, FESTIVAL, ClouT Maurizio Spirito, IT, Istituto Superiore Mario Boella, ebbits, ALMANAC, UNIFY-IoT Maarten Botterman, NL, GNKS, SMART-ACTION Ousmane Thiare, SN, Université Gaston Berger, WAZIUP Pasquale Annicchino, CH, Archimedes Solutions, CREATE-IoT Payam Barnaghi, UK, UNIS, IoT.est Philippe Cousin, FR, FR, Easy Global Market, WISE IoT, FIESTA-IoT, EU-China Expert Group Philippe Moretto, FR, ENCADRE, UNIFY-IoT, ESPRESSO, Sat4m2m Raffaele Giaffreda, IT, CNET, iCore Ross Little, ES, Atos, CREATE-IoT Roy Bahr, NO, SINTEF, UNIFY-IoT, CREATE-IoT Sébastien Ziegler, CH, Mandat International, IoT6 Sergio Gusmeroli, IT, Engineering, POLIMI, OSMOSE, BeInCPPS Sergio Kofuji, BR, Universidade de São Paulo, Brazilian IoT Forum Sergios Soursos, GR, Intracom SA Telecom Solutions, symbIoTe Sonia Compans, FR, ETSI, CREATE-IoT Sophie Vallet Chevillard, FR, inno TSD, UNIFY-IoT Srdjan Krco, RS, DunavNET, IoT-I, SOCIOTAL, TagItSmart Steffen Lohmann, DE, Fraunhofer IAIS, Be-IoT Sylvain Kubler, LU, University of Luxembourg, bIoTope Takuro Yonezawa, JP, Keio University, ClouT Toyokazu Akiyama, JP, Kyoto Sangyo University, FESTIVAL Veronica Barchetti, IT, HIT, UNIFY-IoT Veronica Gutierrez Polidura, ES, Universidad De Cantabria Xiaohui Yu, CN, China Academy of Information and Communications Technology, EU-China Expert Group Contributing Projects and Initiatives SmartAgriFood, EAR-IT, ALMANAC, CITYPULSE, COSMOS, CLOUT, RERUM, SMARTIE, SMART-ACTION, SOCIOTAL, VITAL, BIG IoT, VICINITY, INTER-IoT, symbIoTe, TAGITSMART, bIoTope, AGILE, Be-IoT, UNIFY-IoT, ARMOUR, FIESTA, ACTIVAGE, AUTOPILOT, CREATE-IoT, IoF2020, MONICA, SYNCHRONICITY, U4IoT, BRAIN-IoT, ENACT, IoTCrawler, SecureIoT, SOFIE, CHARIOT, SEMIoTICS, SerIoT. References Arthur, W. B. (2011). “The second economy”. McKinsey Quarterly, Vol. 4, No. 1, pp. 90–99. Google Scholar Aagaard, A. (2018). “Digital business models – driving transformation and innovation”. Palgrave MacMillan. Google Scholar Gantz, J., and Reinsel, D. (2012). “The digital universe in 2020: big data, bigger digital shadows, and biggest growth in the Far East”, International Data Corporation, Framingham. Google Scholar Nambisan, S., Lyytinen, K., Majchrzak, A., and Song, M. (2017). “Digital innovation management: reinventing innovation management research in a digital world”. MIS Quarterly, Vol. 41, No. 1, pp. 223–238. Google Scholar Kiel, D., Arnold, C., Collisi, M., and Voigt, K. I. (2016). “The impact of the industrial Internet of Things on established business models”. In Proceedings of the 25th International Association for Management of Technology (IAMOT) Conference, Orlando, Florida, USA, May 15–19. Google Scholar Magretta, J. (2002). “Why business models matter”. Harvard Business Review, Vol. 80, No. 5, pp. 86–92. Google Scholar Amit, R., and Zott, C. (2012). Creating value through business model innovation. MIT Sloan Management Review, Vol. 53, No. 3, p. 41. Google Scholar Afuah, A., and Tucci, C. L. (2001). Internet business models and strategies. New York: McGraw-Hill, p. 358. Dodgson, M., Gann, D. M., and Phillips, N. (Eds.). (2013). The Oxford handbook of innovation management. OUP Oxford. Osterwalder, A., and Pigneur, Y. (2010). Business model generation: a handbook for visionaries, game changers, and challengers. Wiley. Google Scholar Gassmann, H., Frankenberger, K., and Csik, M. (2014). “The St. Gallen business model navigator”. Working paper: University of St. Gallen: ITEM-HSG. Knab, S., and Rohrbeck, R. (2014). “Why intended business model innovation fails to deliver: insights from a longitudinal study in the German smart energy market.” Proceedings of the R&D Management Conference, Stuttgart, Germany, June 3–6, 2014. Google Scholar Vermesan, O., and Friess, P. (Eds.). (2016). Digitising the Industry Internet of Things Connecting the Physical, Digital and Virtual Worlds, ISBN: 978-87-93379-81-7, River Publishers, Gistrup. Google Scholar Vermesan, O., and Friess, P. (Eds.). (2015). Building the Hyperconnected Society – IoT Research and Innovation Value Chains, Ecosystems and Markets, ISBN: 978-87-93237-99-5, River Publishers, Gistrup. Google Scholar Outlier Ventures Research, Blockchain-Enabled Convergence – Understanding The Web 3.0 Economy, Online: https://gallery.mailchimp.com/65ae955d98e06dbd6fc737bf7/files/Blockchain_Enabled_Convergence.01.pdf What is a blockchain? https://www2.deloitte.com/content/dam/Deloitte/ch/Documents/innovation/ch-en-innovation-deloitte-what-is-blockchain-2016.pdf Lin, S., Cheng, H. F., Li, W., Huang, Z., Hui, P., and Peylo, C. (2017). Ubii: physical world interaction through augmented reality, IEEE Trans. Mob. Comput. Vol. 16. pp. 872–885. Google Scholar Sun, X., and Ansari, N. (2016). EdgeIoT: mobile edge computing for the Internet of Things, IEEE Commun. Vol. 54, pp. 22–29. Google Scholar Edge Computing Market, MarketsandMarkets Report, 2017, Online: https://www.marketsandmarkets.com/Market-Reports/edge-computing-market-133384090.html Ericsson Mobility Report, June 2018, Online: https://www.ericsson.com/assets/local/mobility-report/documents/2018/ericsson-mobility-report-june-2018.pdf Cloud IoT Edge, Online: https://cloud.google.com/iot-edge/ Google Scholar Hyperledger, Online: https://www.hyperledger.org/ Enterprise Ethereum Alliance (EEA), Online: https://entethalliance.org/ Hyperledger Fabric, Online: https://www.ibm.com/blockchain/hyperledger/fabric-support Herr, G., Lyon, J., and Gillen, S. (2016). “Industrial intelligence: cognitive analytics in action,” presentation at EMEA Users Conference, Berlin. Research and Markets, Online: https://www.researchandmarkets.com/ State of the IoT 2018: number of IoT devices now at 7B – Market accelerating, IoT analytics, Online: https://iot-analytics.com/state-of-the-iot-update-q1-q2-2018-number-of-iot-devices-now-7b/ IDTechEx, Comparison of Low Power Wide Area Networks (LPWAN) for IoT 2018–2019, Online: https://www.idtechex.com/research/articles/comparison-of-low-power-wide-area-networks-lpwan-for-iot-2018-2019-00014777.asp SEMTECH, Online: https://www.semtech.com/ Ryberg, T., BERG INSIGHT, NB-IoT networks are here, now it’s time to make business, Online: https://www.iot-now.com/2018/07/04/85156-nb-iot-networks-now-time-make-business/ NB-IoT, CAT-M, SIGFOX and LoRa Battle for Dominance Drives Global LPWA Network Connections to Pass 1 Billion By 2023, ABIresearch, 2018, Online: https://www.abiresearch.com/press/nb-iot-cat-m-sigfox-and-lora-battle-dominance-drives-global-lpwa-network-connections-pass-1-billion-2023/ Wi-SUN FAN Overview, Online: https://tools.ietf.org/id/draft-heile-lpwan-wisun-overview-00.html Opportunities and Use Cases for Distributed Ledgers in IoT, GSMA 2018, Online: https://www.gsma.com/iot/wp-content/uploads/2018/09/Opportunities-and-Use-Cases-for-Distributed-Ledgers-in-IoT-f.pdf Nakamoto, S., Bitcoin: A Peer-to-Peer Electronic Cash System, Online: https://bitcoin.org/bitcoin.pdf Popov, S., (2018). The Tangle, Online: https://assets.ctfassets.net/r1dr6vzfxhev/2t4uxvsIqk0EUau6g2sw0g/ 45eae33637ca92f85dd9f4a3a218e1ec/iota1_4_3.pdf IOTA, Online: https://iota.org Ripple, Online: https://ripple.com Sovrin, Online: https://sovrin.org BigchainDB, Online: https://www.bigchaindb.com Gutierrez, C. (2017). Boeing Improves Operations with Blockchain and the Internet of Things, Online: https://www.altoros.com/blog/boeing-improves-operations-with-blockchain-and-the-internet-of-things/ Gutierrez, C., and Khizhniak, A. (2017). Improving Supply Chain and Manufacturing with IoT-Driven Blockchains, Online: https://www.altoros.com/blog/ibm-aims-to-improve-manufacturing-and-supply-chain-by-coupling-iot-and-blockchain/ Panetta, K. (2018). 5 Trends Emerge in the Gartner Hype Cycle for Emerging Technologies, Online: https://www.gartner.com/smarterwithgartner/5-trends-emerge-in-gartner-hype-cycle-for-emerging-technologies-2018/ Nilsson, N. J. (2010). The Quest for Artificial Intelligence: A History of Ideas and Achievements, Cambridge, UK Cambridge University Press. Google Scholar IEEE, Tactile Internet Emerging Technologies Subcommittee, Online: http://ti.committees.comsoc.org/ The Tactile Internet ITU-T Technology Watch Report ITU-T, 2014, Online: https://www.itu.int/dms_pub/itu-t/oth/23/01/T23010000230001PDFE.pdf Google Scholar Batra, G., Queirolo, A., and Santhanam, N. (2018). McKinsey & Company, Artificial intelligence: The time to act is now, Online: https://www.mckinsey.com/industries/advanced-electronics/our-insights/artificial-intelligence-the-time-to-act-is-now Google Scholar 5G Network Architecture A High-Level Perspective, (2016). White Paper, HUAWEI Technologies Co., Ltd., Online: https://www-file.huawei.com/-/media/CORPORATE/PDF/mbb/5g_nework_architecture_whitepaper_en.pdf?la=en&source=corp_comm 5G Security Architecture White Paper, (2017). HUAWEI Technologies Co., Ltd., 2017, Online: https://www-file.huawei.com/-/media/CORPORATE/PDF/white%20paper/5g_security_architecture_white_paper_en-v2.pdf?la=en&source=corp_comm Network Slicing Use Case Requirements, GSMA, April 2018, Online: https://www.gsma.com/futurenetworks/wp-content/uploads/2018/07/Network-Slicing-Use-Case-Requirements-fixed.pdf Szymanski, T. H. (2016), Securing the Industrial-Tactile Internet of Things with Deterministic Silicon Photonics Switches, IEEE Access, Vol. 4, pp. 8236–8249. Google Scholar Maier, M., Chowdhury, M., Prasad Rimal, B., and Pham Van, D. (2016). The Tactile Internet: Vision, Recent Progress, and Open Challenges, IEEE Communications Magazine, Vol. 54, No. 5, pp. 138–145. Google Scholar Maier, M. (2014). “FiWi Access Networks: Future Research Challenges and Moonshot Perspectives,” Proc. IEEE Int’l. Conf. Commun. (ICC), Workshop on Fiber-Wireless Integrated Technologies, Systems and Networks, Sydney, Australia, pp. 371–375. Google Scholar Chowdhury, M., and Maier, M. (2017). Collaborative Computing for Advanced Tactile Internet Human-to-Robot (H2R) Communications in Integrated FiWi Multirobot Infrastructures, IEEE Internet of Things Journal, Vol. 4, No. 6, pp. 2142–2158. Google Scholar Spectrum of Seven Outcomes for AI, Online: https://www.constellationr.com/ Wang, R. (2016). Monday’s Musings: Understand The Spectrum Of Seven Artificial Intelligence Outcomes, Online: http://blog.softwareinsider.org/2016/09/18/mondays-musings-understand-spectrum-seven-artificial-intelligence-outcomes/ Chan, R., Consensus Mechanisms used in Blockchain. https://www.linkedin.com/pulse/consensus-mechanisms-used-blockchain-ronald-chan Ekblaw, A. et al. (2016). A Case Study for Blockchain in Healthcare: “MedRec” prototype for electronic health records and medical research data, https://www.healthit.gov/sites/default/files/5-56-onc_blockchainchallenge_mitwhitepaper.pdf Google Scholar Crosby, M. et al. (2015). BlockChain Technology. Beyond Bitcoin. Berkeley, University of California, http://scet.berkeley.edu/wp-content/uploads/BlockchainPaper.pdf Samman, G. S. (2016). How Transactions Are Validated On A Distributed Ledger, https://www.linkedin.com/pulse/how-transactions-validated-distributed-ledger-george-samuel-samman ITU-T, Internet of Things Global Standards Initiative, http://www.itu.int/en/ITU-T/gsi/iot/Pages/default.aspx International Telecommunication Union – ITU-T Y.2060 – (06/2012) – Next Generation Networks – Frameworks and functional architecture models – Overview of the Internet of things Vermesan, O., Friess, P., Guillemin, P., Sundmaeker, H. et al., (2013). “Internet of Things Strategic Research and Innovation Agenda”, Chapter 2 in Internet of Things – Converging Technologies for Smart Environments and Integrated Ecosystems, River Publishers, ISBN: 978-87-92982-73-5 Google Scholar Yole Développement, Technologies & Sensors for the Internet of Things, Businesses & Market Trends 2014–2024, 2014, Online: http://www.yole.fr/iso_upload/Samples/Yole_IoT_June_2014_Sample.pdf Parks Associates, Monthly Wi-Fi usage increased by 40% in U.S. smartphone households, Online: https://www.parksassociates.com/blog/article/pr-06192017 Gluhak, A., Vermesan, O., Bahr, R., Clari, F., Macchia, T., Delgado, M. T., Hoeer, A. Boesenberg, F., Senigalliesi, M., and Barchetti, V. (2016). “Report on IoT platform activities”, 2016, Online: http://www.internet-of-things-research.eu/pdf/D03_01_WP03_H2020_UNIFY-IoT_Final.pdf McKinsey & Company, Automotive revolution – perspective towards 2030. How the convergence of disruptive technology-driven trends could transform the auto industry, 2016. Google Scholar IoT Platforms Initiative, Online: https://www.iot-epi.eu/ IoT European Large-Scale Pilots Programme, Online: https://european-iot-pilots.eu/ Où porterons-nous les objets connectés demain?, Online: http://lamontreconnectee.net/les-montres-connectees/porterons-objets-connectes-demain/ Moore, S. (2016). Gartner survey shows wearable devices need to be more useful, Online: http://www.gartner.com/newsroom/id/3537117 Digital Economy Collaboration Group (ODEC), Online: http://archive.oii.ox.ac.uk/odec/ Maidment, D. (2014). Advanced Architectures and Technologies for the Development of Wearable Devices, White paper, Online: https://www.arm.com/files/pdf/Advanced-Architectures-and-Technologies-for-the-Development-of-Wearable.pdf Accenture. Are you ready to be an Insurer of Things?, Online: https://www.accenture.com/_acnmedia/Accenture/Conversion-Assets/DotCom/Documents/Global/PDF/Strategy_7/Accenture-Strategy-Connected-Insurer-of-Things.pdf#zoom=50 Connect building systems to the IoT, Online: http://www.electronics-know-how.com/article/1985/connect-building-systems-to-the-iot Kejriwal, S., and Mahajan, S. (2016). Smart buildings: How IoT technology aims to add value for real estate companies The Internet of Things in the CRE industry, Deloitte University Press, Online: https://www2.deloitte.com/content/dam/Deloitte/nl/Documents/real-estate/deloitte-nl-fsi-real-estate-smart-buildings-how-iot-technology-aims-to-add-value-for-real-estate-companies.pdf Google Scholar ORGALIME Position Paper, 2016, Online: http://www.orgalime.org/sites/default/files/position-papers/Orgalime%20Comments_EED_EPBD_Review%20Policy%20Options_4%20May%202016.pdf Hagerman, J. (2014). U.S. Department of Energy, Buildings-to-grid technical opportunities, https://energy.gov/sites/prod/files/2014/03/f14/B2G_Tech_Opps–Intro_and_Vision.pdf Google Scholar Ravens, S., and Lawrence, M. (2017). Defining the Digital Future of Utilities – Grid Intelligence for the Energy Cloud in 2030, Navigant Research White Paper, Online: https://www.navigantresearch.com/research/defining-the-digital-future-of-utilities Roland Berger Strategy Consultants, Autonomous Driving, (2014). Online: https://www.rolandberger.com/publications/publication_pdf/roland_berger_tab_autonomous_driving.pdf Roland Berger Strategy Consultants, (2017). Automotive Disruption Radar – Tracking disruption signals in the automotive industry, Online: https://www.rolandberger.com/publications/publication_pdf/roland_berger_disruption_radar.pdf Google Scholar The EU General Data Protection Regulation (GDPR) (Regulation (EU) 2016/679). RERUM, EU FP7 project, www.ict-rerum.eu Gartner Identifies the Top 10 Internet of Things Technologies for 2017 and 2018, Online: http://www.gartner.com/newsroom/id/3221818 A Look at Smart Clothing for 2015, Online: http://www.wearable-technologies.com/2015/03/a-look-at-smartclothing-for-2015/ Best Smart Clothing – A Look at Smart Fabrics, (2016), Online: http://www.appcessories.co.uk/best-smart-clothing-a-look-at-smart-fabrics/ Brunkhorst, C. (2015). “Connected cars, autonomous driving, next generation manufacturing – Challenges for Trade Unions”, Presentation at IndustriAll auto meeting Toronto 14th Oct. 2015, Online: http://www.industriall-union.org/worlds-auto-unions-meet-in-toronto Market research group Canalys, Online: http://www.canalys.com/ Digital Agenda for Europe, European Commission, Digital Agenda 2010–2020 for Europe, Online: http://ec.europa.eu/information_society/digital-agenda/index_en.htm Vermesan, O., Friess, P., Woysch, G., Guillemin, P., Gusmeroli, S. et al., “Europe’s IoT Stategic Research Agenda 2012”, Chapter 2 in The Internet of Things 2012 New Horizons, Halifax, UK, 2012, ISBN: 978-0-9553707-9-3 Vermesan, O. et al., (2011). “Internet of Energy – Connecting Energy Anywhere Anytime” in Advanced Microsystems for Automotive Applications 2011: Smart Systems for Electric, Safe and Networked Mobility, Springer, Berlin, ISBN: 978-36-42213-80-9 Google Scholar Yuriyama, M., and Kushida, T., “Sensor-Cloud Infrastructure – Physical Sensor Management with Virtualized Sensors on Cloud Computing”, NBiS 2010: 1–8. Google Scholar Mobile Edge Computing Will Be Critical For Internet-of-Things and Distributed Computing, Online: http://blogs.forrester.com/dan_bieler/16-06-07-mobile_edge_computing_will_be_critical_for_internet_of_things_and_distributed_computing Stamatakis, G., Elias, T., and Apostolos, T. (2018). “Energy Efficient Policies for Data Transmission in Disruption Tolerant Heterogeneous IoT Networks.” Sensors 18.9: 2891. Google Scholar Stamatakis, G., Elias, Z. T., and Apostolos, T. (2015). “Periodic collection of spectrum occupancy data by energy constrained cognitive IoT devices.” Wireless Communications and Mobile Computing Conference (IWCMC), 2015 International. IEEE. Google Scholar Stamatakis, G., Elias, Z. T., and Apostolos, T. (2015). “A Two-Stage Spectrum Assignment Scheme for Power and QoS Constrained Cognitive CSMA/CA Networks.” Globecom Workshops (GC Wkshps), 2015 IEEE. IEEE. Google Scholar Test Considerations for 5G New Radio, White Paper, Keysight Technologies, April 2018, online at: http://literature.cdn.keysight.com/litweb/pdf/5992-2921EN.pdf ETSI ISG Multi-access Edge Computing, online at: https://portal.etsi.org/MEC Serrano, M., and Soldatos, J. (2015). “IoT is More Than Just Connecting Devices: The OpenIoT Stack Explained” IEEE Internet of Things Newsletter, September, 8th 2015. Google Scholar Nagavalli, Y. (2018). Huawei Software, September 2018, Prepare Now for the 5G Monetization Opportunity, online at: http://telecoms.com/intelligence/prepare-now-for-the-5g-monetization-opportunity/ Li, R. (2018). “Towards a New Internet for the Year 2030 and Beyond,” Third Annual ITU IMT-2020/5G Workshop and Demo Day, Geneva, Switzerland, July 18, 2018, online at: https://www.itu.int/en/ITU-T/Workshops-and-Seminars/201807/Documents/3_Richard%20Li.pdf 5G Applications Market Potential & Readiness Matrix, Huawei Wireless X Labs and ABI Research, 2018, online at: https://www-file.huawei.com/-/media/CORPORATE/PDF/x-lab/5G-Applications-Market-Potential_Readiness-Matrix.pdf?la=en&source=corp_comm 4. End-to-end Security and Privacy by Design for AHA-IoT Applications and Services Mario Diaz Nava1, Armand Castillejo1, Sylvie Wuidart1, Mathieu Gallissot2 , Nikolaos Kaklanis3 , Konstantinos Votis3, Dimitrios Tzovaras3, Anastasia Theodouli3, Konstantinos Moschou3, Aqeel Kazmi5, Philippe Dallemagne4, Corinne Kassapoglou-Faist4, Sergio Guillen7, Giuseppe Fico8, Yorick Brunet4, Thomas Loubier2, Stephane Bergeon2, Martin Serrano5, Felipe Roca6, Alejandro Medrano8 and Byron Ortiz Sanchez9 1STMicroelectronics, France 2Univ. Grenoble Alpes, CEA-LETI Minatec Campus 38000 Grenoble, France 3Information Technologies Institute, Centre for Research and Technology Hellas, Greece 4CSEM Centre Suisse d’Electronique et de Microtechnique SA, Switzerland 5Insight Centre for Data Analytics, NUI Galway, Ireland 6HOP UBIQUITOUS SL, Spain 7MYSPHERA, Spain 8Life Supporting Technologies-Universidad Politécnica de Madrid, Spain 9Televes SA, Spain Abstract The chapter aims at describing the cybersecurity and privacy methodologies and solutions that the architecture defined in the ACTIVAGE Large-Scale Pilot, and the corresponding implementation in nine Deployment sites should follow to secure the IoT system and protect the personal data from potential malicious cyber-attacks and threats. It further presents common definitions, methods and repeatable processes to analyse and address all potential threats in terms of cybersecurity and privacy that might occur during the exploitation phase of the project. 4.1 Introduction The Internet and mobile revolution have transformed our world. The Internet of Things (IoT) has significantly emerged over the last few years, aiming to change our lives by forming a massive ecosystem where interconnected devices and services collect, exchange and process data in order to adapt dynamically to a context to offer a variety of services. By 2020, market analysts expect between 20 and 50 billion connected devices in the world. With all the benefits originating from the use of IoT technology, also come a range of ever-increasing challenges and security threats including data manipulation, data theft, and cyber-attacks. For instance, the ransomware landscape has dramatically shifted in 2017 and organizations bore the brunt of the damage caused by new, self-propagating threats such as WannaCry and Petya. Most recently, a report from Symantec ISTR [1] revealed that there were 470 thousand ransomware infections in 2016 and 319 thousand in the first-half of 2017. The threats and risks related to the Internet of Things devices, systems and services are of manifold and they evolve rapidly. With a great impact on citizens’ safety, security and privacy, the threat landscape concerning the Internet of Things is extremely wide and evolves rapidly. Hence, it is important to understand what needs to be secured to develop sophisticated security measures to protect the IoT infrastructure. Information (or data) lies at the heart of an IoT system, feeding into a continuous cycle of sensing, decision-making, and actions. The billions of “things” can be the target of intrusions and interferences that might dramatically jeopardize personal privacy. Since IoT is seen as a key enabler for creating new services and improving overall quality of life, consumers need to have trust and confidence about their data being secured and protected, therefore, making the cybersecurity of IoT systems an essential part. Currently, there are no official guidelines available for trust of IoT devices, in addition, there is no regulatory compliance defined for minimum-security requirements. Despite the existence of many security guidelines in general, the literature lacks primary guidelines to help adopt security measures and standards for the IoT systems. The European Union (EU) is working on several fronts to promote cyber resilience across the EU. It published several proposals in a ‘cybersecurity package’ in September 2017 [2]. Furthermore, the EU set up the Large-Scale Pilots to deploy IoT systems in five main areas [3]. The main goals of these LSPs is to solve key practical issues such as interoperability, security and privacy, business models, validation of IoT powered applications and services at large-scale, etc. In this context, this chapter reports the initial outcomes obtained from security and privacy performed in the ACTIVAGE project [1] [4]. These activities contribute into mainly two areas: [1] ACTIVAGE project is a key factor in the IoT for the “Active and Healthy Ageing” (AHA) domain producing evidence of the IoT value on fostering the deployment of AHA solutions in Europe, through the integration of advanced IoT technologies across the value chain, demonstrating multiple AHA-IoT applications at large-scale in a usage context, in real operational conditions. IoT for the AHA domain is a strategic element for the creation of dynamic ecosystems to answer and prevent the challenges faced by health and social care systems. Differently from other sectors, “AHA-IoT” services are provided to persons taken individually and it takes place across all domains, as persons live in houses, neighbourhoods, cities, rural areas, mountains and valleys, access to transport systems, drive cars, go to shopping centres, airports, theatres, etc. Persons are the most extraordinary producers of individual’s data: production and consumption of personal data across domains has become the front-line of concern, data privacy, security, authentication, access consent, ownership, storage management. In summary, ACTIVAGE is an LSP that brings together the IoT and AHA communities to demonstrate the value of the first with respect to successful implementation of AHA solutions in terms of QoL for Citizens, Sustainability of Health and Social Care Systems and Economical and industrial Growth in Europe. Technological – a secure large-scale deployment of connected objects. Societal – related to the project context, which is to create a smart environment for the ageing well of elderly people allowing the collection of sensitive personal data. As in ACTIVAGE, the experimentations will involve around 7,000 users across 9 Deployment Sites (DSs) [2], the consortium has a great concern when it comes to the security and privacy related challenges and an opportunity to resolve these issues with the help of large-scale validation and testing. Platforms using public communication infrastructure will interconnect many IoT devices, which are inherently weakly secured. Several services will process confidential data by requiring control over the propagation of access control in the spirit of the General Data Protection Regulation (GDPR) [5]. GDPR is a primary law regulating how companies/organizations protect EU citizens’ personal data. [2] A Deployment site is a city or a region in the European Union in where a full large-scale pilot is set. This chapter gives an overview of the end-to-end security and privacy impact analysis performed in order to provide actionable recommendations. The outcomes are in the shape of guidelines and framework related to the cybersecurity and privacy aspects. The security risk analysis is conducted at each layer of an IoT system and its deployment procedure. The objective is twofold: to bring an awareness of the security risks to the stakeholders involved in each deployment site and the provision of solutions/recommendations – concerning the technologies and services to be deployed for security and privacy of the IoT infrastructure. The chapter aims at describing the cybersecurity and privacy methodologies and solutions that the ACTIVAGE architecture and the corresponding deployment sites should follow in order to secure the IoT system and data from potential malicious cyber-attacks and threats. It further presents common definitions, methods and repeatable processes to analyse and address all potential threats in terms of cybersecurity and privacy that might occur during the exploitation phase of the project. The whole process takes into account: Typical cybersecurity and privacy risks due to the IoT context. DSs particularities in terms of cybersecurity needs (e.g. data relevance). Relevance and effectiveness of cybersecurity and privacy mechanisms already foreseen by the DSs security managers. In this work, an IoT system is divided into four layers (domains): device, gateway, cloud and application. The security and privacy analysis is performed throughout the entire system starting from the device domain to the application domain. It also considers the overall system life cycle, i.e. the analysis process is applied not only for the operation phase but also at configuration, installation, maintenance and removal phases. The rest of the chapter is organized as follows. Section 4.2 presents the global objectives and requirements for cybersecurity and privacy in the context of AHA-IoT ecosystem. Section 4.3 presents the main recommendations on Cybersecurity and Privacy in IoT. Sections 4.4 and 4.5 present the methodologies undertaken for security and privacy and the recommendations in this context. Section 4.6 illustrates, through example use cases, some security and privacy solutions harnessed from the top-down approaches and their associated recommendations. Finally, Section 4.7 concludes this chapter. 4.2 Global Objectives and Requirements 4.2.1 Security In an information system, the key objectives and requirements are defined to prevent unauthorized access, use, disclosure, modification, or removal of important data or information. CIA (Confidentiality, Integrity and Availability) triad is a common and globally accepted model that is used to secure important information. The main cybersecurity objectives [6, 7] are: Confidentiality: no improper disclosure of information. Integrity: no improper modification of information (alteration, deletion or creation). Availability: no improper impairment of functionality. In order to reach above objectives, the typical cybersecurity properties or requirements are listed as follows: Authorization: the rules on who is allowed to read, modify or delete which information. User and entity authenticity: the assurance that the other party is the intended communication peer, no “man-in-the-middle” scenario. Integrity (data and service authenticity): the data is not altered during transmission (accidentally or intentionally). Confidentiality: the exchanged data cannot be overheard or made available to a third party. Timeliness and validity of the data: for example, protection against message replay. Non-repudiation of the transaction: the assurance that a transaction is auditable. In addition, system integrity requirements include a system protection against physical and logical attacks, a secure software update mechanism and the monitoring and reaction capability to system malfunction. The mechanisms to achieve these requirements are the following: Access Control: selective restriction of access to data or services. Entity authentication: for example, a cryptography-based “handshake” scheme. Message cryptographic protection: encryption and data authentication. Temporization of data: use of nonces, timestamps, counters against replay attacks. Code signing: use of cryptographic hash to validate authenticity and integrity of the code. Cryptographic key establishment: a scheme to allow key exchange between two parties. OS and hardware security: protection mechanisms such as root of trust, secure boot, etc. Additional requirements on the cybersecurity solutions are scalability and usability, which focus on the identification and access control methodology combined with usability of human interfaces. Furthermore, the system management deals with the management of the keys, the configuration, installation, replacement of devices, and the monitoring and malfunction detection. If security and privacy are already big challenges on IT systems, these challenges become much more important on the IoT systems considering that the attack surface has significantly been enlarged as well as the amount of data generated and handled [8]. Furthermore, the impact becomes more important considering that IoT devices have not enough processing capabilities, in contrast to IT systems, and they have a limited autonomy because they work most of the cases on batteries. They use generally different wireless connectivity solutions not compliant with existing security standards. Last but not the least, the nature of the applications, for instance AHA, requires a high level of security to keep end-to-end data integrity, confidentiality and service availability. The AHA users are very concerned by these aspects. Secure IoT systems with high level of personal data protection are mandatory to keep the users’ trust. These aspects are essential to deploy massively the IoT technologies in the coming years. 4.2.2 Privacy Concerning the objectives and recommendations for the privacy this work uses the General Data Protection Regulation (GDPR) (EU 2016/679) [3] as the basis. In addition, the Data Protection Impact Assessment (DPIA) process is used to put in place such regulation. The article 1 of GDPR defines the following objectives: [3] Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016. This Regulation lays down relating to the protection of natural persons with regards to the processing of personal data and rules relating to the free movement of personal data. This regulation protects fundamental rights and freedoms of natural persons and in particular their right to the protection of personal data. The free movement of personal data within the Union shall be neither restricted nor prohibited for reasons connected with the protection of natural persons with regard to the processing of personal data. The GDPR defines also the following requirements: The protection of the rights and freedoms of natural persons with regard to the processing of personal data requires that appropriate legal, technical and organizational measures be taken to ensure that the requirements of this Regulation are met. In order to be able to demonstrate compliance with this regulation, the data controller should adopt internal policies and implement measures that meet in particular the principles of data protection by design and data protection by default. Such measures could consist, inter alia, of: Minimizing the processing of personal data. Pseudonymising personal data as soon as possible. Transparency regarding the functions and processing of personal data. Enabling the data subject to monitor the data processing. Enabling the controller to create and improve security features. 4.3 Recommendations on Cybersecurity and Privacy in IoT 4.3.1 Security Security is a complex and critical concern for any manager of interconnected digital assets. Many private companies [9], public bodies [10] and standardization/harmonization institutes (e.g. RFC 2196 Site Security Handbook) have published recommendations aiming at improving the quality and consistency of the security levels across interconnected systems. Such recommendations target system managers, organization officers, service providers, infrastructure owners, product manufacturers, developers, end users and indirectly also attackers. In fact, as promoted by security experts, every security measure, mechanism and algorithm must rely on publicly available specifications. Recommendations are elaborated and publicized proactively [15, 11] and reactively [11]. Interestingly some of them are associated to supporting tools [10]. All these sets of recommendations present diverse facets of similar rules and recommendations. It is not possible to include the whole list in this chapter. However, recommendations insist on the fact that security is a continuous process with integrated improvement procedure, based on the continuous evaluation of the in-place security. Therefore, external inspection such as auditing is a must. Self-auditing and internal expertise are strongly required, but by far not enough. External companies offer services to analyse the implemented security, including security standards, such as ISO/IEC 27001 and 27002, the NIST Cybersecurity Framework. 4.3.2 Privacy When developing, designing and using applications, services and products that aim to process personal data to fulfil their task, the developers/producers of such products, services and applications are recommended to take into account the right to data protection. It is important to make sure that controllers and processors are capable enough to fulfil data protection obligations. Furthermore, the principles of data protection by design and by default should be also taken into consideration in the context of public tenders. A report by ENISA (the European Union Agency for Network and Information Society) elaborates on what needs to be done to achieve privacy and data protection by default [13]. It specifies that encryption and decryption operations must be carried out locally, not by a remote service, because both keys and data must remain in the power of the data owner if greater privacy needs to be achieved. The report specifies that outsourced data storage on remote clouds is practical and relatively safe, as long as only the data owner, not the cloud service, holds the decryption keys. In literature, there are additional principles and guidelines available that can be used to achieve privacy and data protection by default, also known as privacy by design. Privacy by design [14] is a concept, developed in the 90’s, to address the ever-growing and systemic effects of Information and Communication Technologies (ICTs), and of large-scale networked data systems. The objectives of privacy by design – ensuring privacy and gaining personal control over one’s information, and, for organizations, gaining a sustainable competitive advantage – may be accomplished by practicing the following 7 foundational principles: Proactive not reactive; preventative not remedial. Privacy as the default setting. Privacy embedded into design. Full functionality – positive-sum, not zero-sum. End-to-end security – full lifecycle protection. Visibility and transparency – keep it open. Respect for user privacy – keep it user-centric. 4.4 Security Approach 4.4.1 Methodology To achieve the objectives defined above, a number of activities are performed to lay down the security and privacy policies in the context of ACTIVAGE project. For the purpose of security, activities include: Perform a reference risk analysis in the ACTIVAGE IoT environment in order to identify the general ACTIVAGE security requirements, which depend on the criticality of applications or services. Countermeasures to mitigate risks are identified at this stage. Create and elaborate the ACTIVAGE security questionnaire. Analyse questionnaires’ responses and perform assessments for the DS’ security requirements. Define the security cartography and recommendations for each deployment site. The elaboration of the security questionnaire considered the following aspects: Collect relevant information allowing the identification of missing mechanisms to ensure full end-to-end cybersecurity and privacy for each of the DSs. Make it easy for the DSs security managers to reply. The DS security manager is in charge of the security and privacy aspects related to this DS. Make the DSs security managers aware of cybersecurity and privacy issues that have not yet been identified and support the other stakeholders to realize the high importance of these aspects that are critical considering the nature of the project, which includes data confidentiality, higher vulnerability by connecting “smart objects” to the system, etc. Figure 4.1 ACTIVAGE Reference Architecture. Security analysis is performed based on the following assumptions: All IoT devices and elements constituting the DS meet safety requirements according to the existing norms and regulations in conformance to their original purpose. This falls into the responsibility of the device manufacturer or SW provider/service provider and of the DS manager. e.g., an electrical heater used to ensure the comfort of elderly people must respect basic norms for electrical heaters. DS security managers know the basic norms and regulations rules with which the devices, SW and services used must comply. The managers should be able to provide the corresponding evidence and they should highlight any unconformity. Questionnaires take into account that the answers are given considering the country rules where the DS is deployed. Each of the service providers who plans to use the ACTIVAGE technology needs to upgrade and adapt the DS elements/settings/ components to the norms and the regulations in force at the time and in relation to the location of the commercial exploitation. The general risk analysis adopted the ACTIVAGE Reference Architecture shown in Figure 4.1 and was carried along the following typical steps: Identification and description of all the assets to be protected in the IoT system. Identification of all threats and vulnerabilities for each asset. Quantification of security risk caused by the threats and vulnerabilities, using a metric. Risk management: the decision on which risks to counter and which ones are acceptable. The risk analysis leads to the definition of the appropriate security measures. 4.4.1.1 Assets identification and description An Assets list was established as a guideline to be carefully analysed, completed (if needed) and used for each DS. It includes all data in the system, services, pieces of hardware, software, communication links and may be extended to intellectual property, brand reputation, buildings etc. The most important items in this list are given hereafter. Data assets include application and management data. The typesets and formats should be defined in the data model. Application data describe the elements or resources of the IoT system. They include, for example: Data describing all entities producing or consuming data (Identifiers and attributes of individuals, stakeholders, sensors). Data that are monitored and analysed by the IoT system in order to ensure the expected service (raw measurements, processed data elements). Decisions of the system that influence the subject’s environment (guidance or prescriptions for individuals, environmental instructions for smart sensors, configuration instructions for devices). Management data relate to system operation. They include, for example: Procedure, action plan descriptions (definition of all the planned actions in case of occurrence of an extreme event). Data storage organization definition (for example, a Grading Table, Detail Description predefines categories for data storage, such as Medical information, Medical report, Wellness information, Service, etc.). Access Rights Table, defining the access rights for each stakeholder profile. Transaction registers, logging the History of all operated transactions (communication channel, data, data user, time, etc.). Cryptographic material that may include log-in credentials, cryptographic secrets for authentication and encryption, root-of-trust information (e.g. trusted PKI public key), public key certificates, etc. Assets also include hardware and software elements. Communication channels. The connection between the devices and the IoT-Gateway is generally wireless (BLE, Z-wave; Zigbee, etc.). The connection between the IoT-Gateway and the Cloud can be an Internet connection. However, and many times, the IoT-Gateway is connected via Wi-Fi/Ethernet to a second Gateway that performs the Internet connection via 2G/3G/4G or a wired connection (XDSL, Cable, OF). On the application end, the connection between the user and the Cloud can be wired or wireless. The wired connection can be through the chain Lap and Desk Tops, LAN, Gateway. The Gateway allows connecting the user with the Internet network and this one to the Cloud. The wireless connection (2G/3G/4G) is done by having a direct connection between the Smart Phones and Tables directly to Internet having access to Web applications. Component hardware. For example, typical hardware assets to consider at the low domains (Device and Gateway) are data storage units, processing units, power management blocks, sensing and actuating blocks as well as all device interfaces (e.g. I/O, JTAG ports, etc.) and device casing. Maturity and configuration must be assessed. Component software and configuration information. Software must be analysed at all levels: OS, firmware, application embedded software, high-level application container. Boot mechanisms and system configuration at all IoT levels also need particular protection and are included in the assets list. Trust associations (end-to-end security). Establishing an end-to-end security association, between the data source and their final destination, provides a higher and often necessary level of data protection. The data are not made available at any of the intermediate hops, since they are encrypted at their source and only the final data user is able to decrypt them. 4.4.1.2 Security risk analysis tools: Product or service compliance class, STRIDE, DREAD The IoT Security Compliance Framework [15] and other guideline documents issued by the IoT Security Foundation are used to enhance best security practices during development and installation of an IoT product (or system or service). The Framework includes the definition of Compliance Classes for products and a series of criteria in order to validate their security depending on the targeted class. Applicability of the requirements on a product depends on its compliance class, which is expressed as a number between 0 to 4, increasing with security level. To define compliance classes, three levels of risk impact, BASIC, MEDIUM and HIGH, are defined for each of the three security objectives, namely confidentiality, integrity and availability. For instance, MEDIUM confidentiality corresponds to “Devices process sensitive information (including Personally Identifiable Information – PII); limited impact if compromised” and is required from class 2. The risk analysis methodology followed in ACTIVAGE to identify the threats is based on the STRIDE Methodology, see Table 4.1. This Threat classification model was developed by Microsoft [18, 19], and helps answering the question “what can go wrong in the system?” The risk mitigation technologies (Cybersecurity measures or Cybersecurity controls) against a STRIDE threat to apply on the system element under consideration depend on the element type, perspective (developer, administrator) and assessed risk level (DREAD rate). Recommendations by foundations or standard bodies give guidelines in this task, providing lists of Cybersecurity requirements depending on risk level (or compliance class) as well as best-practice tips [16, 17]. Table 4.1 STRIDE Threat Concerned Security Property Spoofing Authentication Tampering Integrity Repudiation Non-repudiation Information disclosure Confidentiality Denial of service Availability Elevation of privilege Authorization In the case study described here below, we identify the Cybersecurity controls to apply to each system element and gives an indication of: The compliance classes for which the control must be applied. The applicability level, which is defined as mandatory (the requirement shall be met, as it is vital to secure the product category) or as advisory (the requirement should be met unless there are sound reasons such as economic viability or hardware complexity, in which case the reasons for deviating from the requirement must be documented). Figure 4.2 IoT device assets and STRIDE representation. 4.4.1.3 ACTIVAGE as example of Risk Analysis The Threat analysis is performed on Device, Gateway, Cloud and Application domains following the proposed IoT reference architecture. As an example, the STRIDE analysis applied to an IoT reference Device is detailed below. Proposed Assets description of an IoT reference Device, see Figure 4.2: HW description, configuration integrity for IoT devices: Connectivity (description and maturity): Communication Channel CC1 Processing (description and maturity): P1 Data Storage (description and maturity): DS1 Individual Subject id, Devices Id, Raw Data (Individual Subject, Environmental, Devices and Services). Processed Data (Individual Subject, Environmental, Devices and Services). Instructions (Users, Environmental, Devices and Services). Data grading table in (DS1) & Access right table in (DS1). In Device Data Flow (DF), the following analysis must be performed on: Connectivity/Communication channels: BLE, Wi-Fi, LoRa, NB-IoT Nature of Data: Individual Subject, Devices, Raw & Processed Data, Instructions (Users, Environmental, Devices & Services). In this example, the threats concerning the related asset are identified in red bold characters in Figure 4.2: In DS1: Tampering, Repudiation, Information disclosure and Denial of service. In P1: Spoofing, Tampering, Repudiation, Information disclosure, Denial of service and Elevation of Privilege. In CC1: Tampering, Information disclosure and Denial of service. Subsequently, an evaluation of the vulnerability of the IoT Device is performed. The question to be answered is: “What will be the impact of the attacks on the assets?” All the threats for every element are rated using DREAD method ranked from 1 to 3 point, where the DREAD rate refers to all the risks as defined in Table 4.2. Table 4.2 DREAD ranking definition Risk Risk Property Description/point Damage potential How great can be the damage? 1pt (low): Leaking trivial information 2pts (medium): Leaking sensitive information 3pts (high): Can subvert the security system Reproducibility How easy to reproduce? 1pt (low): Very difficult to reproduce, even with knowledge of the security hole 2pts (medium): Can be reproduced, but only with a timing window and a particular situation 3pts (high): Can be reproduces every time and doesn’t require any particular situation Exploitability How easy to realize this threat? 1pt (low): Requires an extremely skilled person and in-depth knowledge every time to exploit 2pts (medium): A skilled programmer could make the attack, then repeat the steps 3pts (high): A novice programmer could make the attack in a short time Affected users How many users are affected? 1pt (low): Very small % of users, obscure feature; affects anonymous users 2pts (medium): Some users, non-default configuration 3pts (high): All users, default configuration, key customer Discoverability How easy to find this vulnerability? 1pt (low): The bug is obscure, and it’s unlikely that users will work out damage potential 2pts (medium): located in a seldom-used part, and only a few users should come across it 3pts (high): The vulnerability is located in the most commonly feature and is very noticeable See below a DREAD ranking based of on the proposed case study. Table 4.3 DREAD ranking evaluation and analysis Threat Applicable DREAD Rate Evaluation Analysis Spoofing 2,3,2,2,1 → 2 Weak Password Tampering 3,2,1,2,1 → 1.8 Repudiation 1,2,2,2,1 → 1.6 Information disclosure 3,2,1,2,1 → 1.8 Denial of Service 3,3,3,1,1 → 2.2 Physical port accessible Elevation of Privilege 3,2,2,1,1 → 1.8 The result of the assessment can be compared to the minimum requirement of compliance class. As soon as the weaknesses are identified, the strategy to address the risk must be explicitly detailed. Basic risk strategies are mitigation, acceptation or transfer to a third party. Table 4.4 Basic strategy analysis Threat Applicable Risk Strategy DREAD Rate Spoofing Mitigate Secure boot process 2,2,2,2,1 → 1.8 Tampering Accepted 3,2,1,2,1 → 1.8 Repudiation Accepted 1,2,2,2,1 → 1.6 Information disclosure Accepted 3,2,1,2,1 → 1.8 Denial of Service Mitigate All non-used ports are 3,2,1,1,1 → 1.6 physically inaccessible Elevation of Privilege Accepted 3,2,2,1,1 → 1.8 4.5 Privacy Approach 4.5.1 Introduction Nowadays, Privacy in Europe has gained a lot of visibility through the advent of the new General Data Protection Regulation (GDPR) entered in force on May 25th, 2018 in the European Union. Until recently, companies making business out of personal or other types of data systematically pushed privacy back. Entities promoting the privacy preservation and enforcement processes propose different approaches. In this chapter, the authors propose to develop a general methodology on Privacy to define a privacy impact analysis for a given IoT System and provide recommendations and guidelines in order to minimize the Privacy threats. The complete methodology is described hereafter. It is under deployment in the Deployment sites of the ACTIVAGE project. Moreover, and in complement of the Security methodology described in Section 4.4, the authors made an analysis of the GDPR to identify the Privacy modules/services/articles that should be implemented in any IoT system of the ACTIVAGE project. This analysis allowed identifying some use cases that are well suited to be implemented using a Blockchain based technology, as described in the Section 4.6.3. 4.5.2 Methodology to Perform Privacy Analysis and Recommendations Figure 4.3 shows the Privacy methodology proposed in order to perform risk privacy analysis on an IoT system. This is the methodology we have used in ACTIVAGE for this purpose. The expected outcomes are the identification of the countermeasures/recommendations for this IoT system to minimize the risks of privacy threats: data theft, data misuse or any other malicious usage. This methodology is addressed to any non-professional data protection manager to facilitate, him/her, the implementation of the GDPR regulation. Figure 4.3 Privacy methodology. This methodology consists in the execution of the following four main steps: Background – A good acknowledge of the following elements is required: What is the GDPR? What is a DPIA and how should be performed? What are the IoT System architecture and topology where the Data will be generated, stored, processed and exploited (and by whom) to identify security rights? In order to get the answers to these questions, the following documents are available [5, 20–24]. Identify personal data flow and storage – For any IoT system, it is required to know its complete and detailed architecture and topology as discussed in Section 4.4. This information allows “easily” the identification of assets, data flows, data storage, process units, users, etc. and their location. Perform Data Impact Performance Assessment – (DPIA) This step is key in the methodology. The importance of this step and the way to develop it are described with more details in the next paragraph. Provide Privacy Impact Analysis and Recommendations – This step provides the DPIA analysis results of the IoT system under study and the recommendations proposed to deploy the system with good Privacy properties. 4.5.3 Data Protection Impact Assessment (DPIA)4 [4] [4] This information contained in this paragraph was extracted from [20]. GDPR introduces the concept of a Data Protection Impact Assessment (DPIA) [5] [20] and strongly recommend carrying out one for each system concerned. This paragraph addresses the following questions: what is a DPIA?, when a DPIA is mandatory and how to carry it?, and what are the main elements containing a DPIA? [5] The term “Privacy Impact Assessment (PIA) is often used in other contexts to refer to the same concept”, for more information see [21–23]. 4.5.3.1 What is a DPIA? “A DPIA is a process designed to describe the processing, assess the necessity and proportionality of a processing and to help managing the risks to the rights and freedoms of natural persons resulting from the processing of personal data. DPIAs are important tools for accountability, as they help controllers not only to comply with requirements of the GDPR, but also to demonstrate that appropriate measures have been taken to ensure compliance with the Regulation. In other words, a DPIA is a process for building and demonstrating compliance”. Under the GDPR, non-compliance with DPIA requirements can lead to fines imposed by the competent supervisory authority. Failure to carry out a DPIA [6] can each result in an administrative fine of up to 10M€, or in the case of an undertaking, up to 2% of the total worldwide annual turnover of the preceding financial year, whichever is higher. [6] For instance, when the processing is subject to a DPIA, or carrying out a DPIA in an incorrect way, or failing to consult the competent supervisory authority where required. 4.5.3.2 When is a DPIA mandatory? Where a processing is “likely to result in a high risk to the rights and freedoms of natural persons”. Table 4.5 gives some examples where a DPIA is required. Table 4.5 Examples where DPIA is required Examples of Processing Possible Relevant Criteria DPIA Required? A hospital processing its patients’ genetic and health data (hospital information system). Sensitive data Data concerning vulnerable data subjects Yes The use of a camera system to monitor driving behavior on highways. The controller envisages using an intelligent video analysis system to single out cars and automatically recognize license plates. Systematic monitoring Innovative use or applying technological or organizational solutions Yes A company monitoring its employees’ activities, including the monitoring of the employees’ work station, internet activity, etc. Systematic monitoring Data concerning vulnerable data subjects Yes An online magazine using a mailing list to send a generic daily digest to its subscribers. — Not necessarily 4.5.3.3 When should the DPIA be carried out? “prior to the processing”. This is consistent with data protection by design and by default principles. The DPIA should be started as early as practical in the design of the processing operation even if some of the processing operations are still unknown. As the DPIA is updated throughout the lifecycle project. It will ensure that data protection and privacy are considered and promote the creation of solutions that promote compliance. 4.5.3.4 What is the DPIA minimum content? The GDPR does not formally define the concept of a DPIA as such, but it sets out its minimum features as follows: Its minimal content is specified as follows: A systematic description of the envisaged processing operations and the purposes of the processing, including, where applicable, the legitimate interest pursued by the controller. An assessment of the necessity and proportionality of the processing operations in relation to the purposes. An assessment of the risks to the rights and freedoms of data subjects. The measures envisaged to address the risks, including safeguards, security measures and mechanisms to ensure the protection of personal data and to demonstrate compliance with this Regulation taking into account the rights and legitimate interests of data subjects and other persons concerned. Its meaning and role are clarified: “In order to enhance compliance with this Regulation where processing operations are likely to result in a high risk to the rights and freedoms of natural persons, the controller should be responsible for the carrying-out of a data protection impact assessment to evaluate, in particular, the origin, nature, particularity and severity of that risk”. Figure 4.4 illustrates the generic iterative process for carrying out a DPIA. It should be underlined that the process depicted here is iterative: in practice, it is likely that each of the stages is revisited multiple times before the DPIA can be completed. Furthermore, this process should be regularly performed to evaluate the IoT system evolution over the time. Figure 4.4 Process for carrying out a DPIA. Practical recommendations (necessary but not sufficient) when carrying out a DPIA The basic recommendation is to collect only required personal data to minimize the risk of non-compliance. It excludes the “just in case” approach in which unjustified data is collected for future uses, even when they may be justified. It requires a complete audit of the data already in possession of the various stakeholders (processors, etc.), and the data must be kept based on the principle of usefulness for the subject and necessity for the service. 4.5.4 GDPR Analysis for Implementation To cope with GDPR in an IT system and more particularly on IoT based system (as such foreseen in ACTIVAGE where security and privacy are of high importance according to AHA applications supported), a first analysis was performed on the set of articles constituting the GDPR. They were analysed and classified as follows: Legal: Articles related with legal issues. Technical: Articles requiring a technical implementation. Accountability: Articles related to the organization/company Governance. Principles: Articles providing recommendations to be considering in the GDPR implementation. Table 4.6 gives the details of this analysis. It is composed of three columns indicating (from the left to the right): the type of article (Legal, Technical, etc.), the type of service and the article description concerned by the GDPR. Table 4.6 GDPR Analysis in view of its implementation Type of Article Provided Function or Service GDPR Article Legal/Principle Article 5 – Basic principles related to data Security Legal/Technical Establish access controls and protected regulated data. Article 6 – Lawfulness of processing Subject’s consent Legal/technical Establish access controls and protected regulated data. Article 7 – Conditions for consumer Consent Legal/technical Establish access controls and protected regulated data. Article 13 and 14 – Information and access to personal data Technical Automatically discover and classify GDPR affected data Article 15 – Right of access by the data subject. Enable to provide the data subject remote access to his or her personal data Article 16 – Right to rectification Be able to rectify specific data. Article 17 – Right to erasure (‘right to be forgotten’). Be able to discover and target specific data and automate removal Article 18 – Right to restriction of processing Article 20 – Portability rights Develop interoperable formats that enable data portability. Technical Audit and Traces control, protection against cyber-attacks and internal threats Article 30 – Records of processing activities. Implement technical and organizational measures to properly process personal data Technical Establish access controls and protected regulated data. Article 25 – Data protection by design and by default. Embrace accountability and privacy by design as a business culture Collect only the required data Give access only to the right people Availability to prove and demonstrate Legal/technical Management of incidents and notifications Article 33 – Notification of a personal data breach to the supervisory authority. Prevent and alert on data breach activity; have an incidence response plan in place Security Review Article 32 – Security of processing (Ensure confidentiality, integrity and availability). Ensure least privilege access; implement accountability via data owners; provide reports that policies and processes are in place and successful. Article 34 – Communication of a personal data breach to the data subject. Article 35 – Data protection impact assessment (DPIA/Risk analysis). Quantify regularly data protection risk profiles. Accountability Governance Article 37 – Designation of the data protection officer. Article 38 – Position of the data protection officer. Article 39 – Tasks of the data protection officer. On top of this first analysis, Varonis [7] recommends focusing on the following technical aspects during the implementation phase to meet the GDPR [25]: [7] Varonis is a pioneer in data security and analytics, specializing in software for data security, governance, compliance, classification, and analytics. Data classification – Know where personal data is stored on the IT/IoT system. This is critical for both protecting the data as well as following through on requests to correct and erase personal data. Metadata – With GDPR requirements for limiting data retention, basic information on when and why the data was collected are required, as well as its purpose. Personal data residing in IT/IoT systems should be periodically reviewed to see whether it needs to be saved for the future. Governance – GDPR highlights the need to get back to basics. For enterprise (or AHA data), this should include understanding who is accessing personal data in the AHA file system, who should be authorized to access, and limiting file permission based on users’ actual roles – i.e., role-based access controls. Monitoring – The breach notification requirement places a new burden on data controllers. Under the GDPR, the IT/IoT security mantra should be “always be monitoring”. Data protection controllers need to spot unusual access patterns against files containing personal data, and promptly report an exposure to the local data authority. Failure to do so can lead to enormous fines, particularly for multinationals with large global revenues. The analysis performed in this section contributed to identify several Privacy uses cases to be implemented using the innovative and pervasive Blockchain as a potential technology to provide robust and efficient IoT solutions on security and privacy. The following section describes these developments. 4.6 Security and Privacy Implementation 4.6.1 Introduction This section presents two use cases selected to illustrate the interest and the importance to follow a top-down approach for security and privacy. During the end-to-end security risk analysis and DPIA performed on the IoT systems of the ACTIVAGE project, this approach allowed the identification of the recommendations and solutions to put in place to improve the security of some IoT system components as well as the services/functions to cope with GDPR privacy requirements. It is clear that the Privacy services must run on top of a Secure IoT system. The first use case presents the countermeasures implemented to secure the data storage of the Raspberry PI Gateway used in some Deployment sites of ACTIVAGE. The second use case presents several scenarios where the Blockchain technology can be used to provide efficient solutions on security and privacy for the ACTIVAGE’s Deployment sites. 4.6.2 Securing a Gateway The Gateway in an IoT device to Cloud architecture is a key element as it marks the frontier between the public and private domains. In this position in the architecture, the Gateway is indeed both an entry path from inside to outside and reverse. In a worst-case scenario, somebody gaining access to a Gateway gains access to other Gateways, by reproducing the attack at a massive scale. In the ACTIVAGE context, Gateways are often deployed in homes, and thus it is not possible to master the physical access to the hardware. Moreover, the Gateway, in a residential place, might be stolen more easily than a server in a data centre might be. The Raspberry PI is a popular platform for its low cost, stability and good support. In experimental projects such as ACTIVAGE, it is the platform of choice to be used as a Gateway. The analysis done from ACTIVAGE questionnaires on IoT devices used in the 9 Deployment sites has shown that at least 4 out 9 deployment sites are considering using such hardware platforms as reference for their experiments. However, the Risk analysis performed on the Raspberry PI has identified potential weaknesses regarding security. A major weakness concerns the SD Card mass storage. Due to its removable nature, this mass storage can be easily accessed from a third-party system by simply removing the SD Card and plugging it to a computer. In this way, the content would be cleared and read/write operation unauthenticable making it easy for a hacker to read out and even replace sensitive information such as user’s password, SSH private keys or other credentials that could enable privileged access to the entire system. Table 4.7 illustrates the impact assessment of the different stride attributes for the mass storage of the gateway in the ACTIVAGE context (deployment in residential homes). The initial DREAD rates on the third column shows potential impacts. The last column shows new rates while mitigating the risks with a secure element. A first counter-measure for this weakness would be to encrypt the entire SD Card, thus, it requires storing the encryption key in a safe place, which is readable by the processor and the firmware while booting the OS located on the storage. A common solution for such a safe storage is to use a Trusted Platform Module (TPM). TPMs are standardized electronic components which have security related functions such as random number, hash and key generators, encryption and decryption hardware engines and offers facilities to store in secure manner keys or sensitive data such as Platform Configuration Registers. These components are used for example for secured boot in UEFI bios. Table 4.7 shows on the two last right columns the new DREAD rate while using such a component, with highest risks reduce to a safer impact level. Table 4.7 DREAD impact assessment Threat Class STRIDE Security Property DREAD Rate Mitigation Choices Mitigation Technology New DREAD Rate T Integrity (I) 2,2,2,1,2 => 1.8 Data storage shall be temper-resistant File system shall be adapted to the technology (read/write cycles) Data shall be backed up Use a secure element to store security information in order to: Encrypt application’s partition Manage strong authentication at network level and application level 2,2,2,1,2 => 1.8 R Confidentiality(C) 2,2,2,1,2 => 1.8 Read and write operation shall require authentication 2,1,1,1,2 => 1.4 I Confidentiality(C) 3,2,3,2,3 => 2.6 Data storage shall be encrypted 1,1,1,1,2 => 1.2 D Availability(A) 2,2,2,1,2 => 1.8 Removable storage devices shall be proscribed Data storage resources shall be monitored to avoid being saturated 2,2,2,1,2 => 1.8 E Authorization(I) 3,2,2,2,2 => 2.2 Write and Read permission shall be tuned in the file system 1,1,1,1,2 => 1.2 Figure 4.5 Raspberry PI model 3 with TPM dedicated hat in white. Figure 4.5 shows a prototype hat for a Raspberry PI embedding a TPM manufactured and assembled in this form by STMicroelectronics. Customization of the Linux Kernel for enabling TPM support was also made with the appropriate device tree modification. The TPM is provisioned with security credentials bound to the ACTIVAGE Public key Infrastructure (PKI), ensuring security credential lifecycle up to the revocation of gateways that are suspected to be compromised. This PKI delivers certificates that can be used for the OS and application layer, with state-of-art cryptography scheme. At the application level, ongoing work is focused on using the TPM secure function whenever possible. A first step consists in the partial encryption of the SD Card. Indeed, while the kernel is located on a clear partition for booting up, the application section is located into a LUKS partition which key is located onto the TPM. It prevents somebody reading the SD card from another platform. Future work will be to encrypt the entire SD card with the decryption within the boot loader. Other work consists in emulating a PKCS11 interface from the TPM. PKCS11 is a standardized public key cryptography standard specifically related to tokens. The use of this standard enables trustful communication for the establishment of TLS or SSL tunnels, which can be used for the traffic between the Gateway and the Cloud. Use of such tunnels enables encrypted and authenticated communications and prevents the Gateway from being detectable on public network as no IP ports need to be opened for incoming connections. Other use of this interface is under investigation for future work regarding IoT device provisioning. 4.6.3 Blockchain in Smart Homes Recently, the Blockchain technology has been applied for the healthcare industry [26] but also in IoT-based Smart Homes [27], reducing the time required to access patient information, enhancing interoperability and improving data quality, while reducing maintenance costs. A Blockchain is a continuously growing list of immutable records, called blocks, which are linked and secured using cryptography. Thus, the adoption of Blockchain is a very promising technology towards enhancing the security, privacy and trust. As described in the previous sections, ACTIVAGE gives special focus on GDPR compliance. Blockchain can act as a very useful tool towards achieving GDPR compliance [28], mainly by serving as a trusted decentralized repository for identification purposes. However, it has to be ensured that: a) no personal data are stored on the Blockchain, b) cryptographic data deletion should be used to give to the end-user the “right to be forgotten”. Blockchain can also enhance security as it can enable IoT devices to connect securely and reliably avoiding the threats of device spoofing and impersonation. Every IoT device can be registered in the Blockchain and will have an ID that will uniquely identify this device in the universal namespace. In the context of ACTIVAGE project, a trusted management solution, based on Blockchain technologies, has been proposed considering the results of other H2020 project implementations such as GHOST/H2020, myAirCoach/H2020. ACTIVAGE will find in this technology a convenient solution to cope with: Privacy regulation based on GDPR. The integrated healthcare and AHA implications for data and devices protection. An adequate trusted mechanism for IoT-based devices, users and systems within the smart Home environment. The concept of distributed ledger technologies can be introduced within ACTIVAGE to support different use case scenarios such as: Requesting/giving/updating permissions for accessing personal data of the involved user. Device registration. Timely firmware updates. User authentication & authorization. The secure data transfer between endpoints, users and healthcare network components. Figure 4.6 ACTIVAGE monitoring platform – BaaS platform architectural overview. Towards the formulation of a secure and trusted environment using information traceability mechanisms and the spreading of the data in AHA information systems, a related ACTIVAGE Blockchain framework has been introduced (see Figure 4.6) consisting of the following main components: BaaS Web UI (The Blockchain-as-a-Service (BaaS) Web UI) – It is a web front-end for accessing the functionalities provided by the Blockchain network that has been implemented within myAirCoach H2020 project. Middleware API – The Middleware API enables the communication between the ACTIVAGE Monitoring Platform and the Blockchain network. For this purpose, RESTful web services are used over the HTTPS protocol. Blockchain network – This is the network of Blockchain nodes where information regarding the various transactions are being stored. ACTIVAGE decentralised Monitoring Platform – This is a decentralised platform where raw data gathered from the sensors installed in the smart homes of the elderly users are stored and further analysed towards identifying patterns related to user activity (e.g. habits, sleeping times, etc.) and further identifying abnormal events that may be related to emergencies. Through the ACTIVAGE Monitoring Platform and all the other Blockchain components, a trusted environment is offered to the formal/informal carers/end-users as well as to the elderly users/patients. In the following paragraphs, several use case scenarios for using Blockchain technology within ACTIVAGE are described. 4.6.3.1 Register in BaaS/give consent In this scenario, the user accesses the registration form in the BaaS Web UI by clicking on the relevant link. After filling the registration form with their data and accepting the Terms of Service, a verification email is sent to their email address. By clicking on the hyperlink, included in the corresponding email, the user is redirected to the BaaS Web UI and their email is verified. After the email verification process, the user can Login the BaaS Web UI. The transaction related to user registration is logged in the Blockchain. 4.6.3.2 Register in the ACTIVAGE monitoring platform through BaaS A user is able to register to the ACTIVAGE Monitoring Platform from the BaaS Web UI. Thus, the user first logs in to BaaS with his/her account, goes to “Platforms > Not Registered Platforms”, chooses ACTIVAGE from the list and clicks on the “Register” button. Then, user is redirected to the ACTIVAGE Monitoring Platform and fills in the Registration Form. Similarly, to the previous scenario, an email verification process is followed for the completion of user registration in the ACTIVAGE Monitoring Platform. The next time that the user logs in the BaaS Web UI, ACTIVAGE is among his/her “Registered Platforms”. Again, the transaction related to user registration is logged in the Blockchain. 4.6.3.3 Register in the ACTIVAGE monitoring platform with BaaS In this scenario, user fills in the Registration Form in the ACTIVAGE Monitoring Platform (option: Register via BaaS). The ACTIVAGE Monitoring Platform sends the valid credentials of the user to the Middleware API through a RESTful Web Service. Then, the Middleware API sends the registration request to the user via email and redirects them to the BaaS Web UI Registration Form. The user registers using the BaaS Registration Form and this transaction of the newly Registered User is logged in the Blockchain network. 4.6.3.4 Registration of new devices and software updates In ACTIVAGE, Blockchain can be applied not only for the secured registration and authorization of users, but also for the envisaged IoT-based devices that are being installed in the smart Home environment supporting also the timely update of firmware, patches, etc., in order to be performed only by authorized users. 4.6.3.5 Login/Logout When the user logs in/out to/from the ACTIVAGE Monitoring Platform, a corresponding request for user login/logout is automatically sent to the middleware API over a RESTful Web Service. The Middleware API updates the list with online Users that are kept within the Blockchain by adding/removing the User to/from the list. Thus, all login/logout processes are logged in the Blockchain network. Figure 4.7 Request permissions for accessing personal data. 4.6.3.6 Request/Give/Update permissions for accessing personal data In this scenario, depicted in Figure 4.7, a caregiver asks for permission to access the personal data of an elderly person through the ACTIVAGE monitoring platform. This request is sent to the Middleware API, which logs it in the Blockchain by also sending a request for permission approval to the elderly via email. By using the hyperlinks included in the email, the elderly is directed to the BaaS Web UI where he/she can accept or reject the request and the corresponding approval/rejection is also logged in the Blockchain network. Through the Middleware API, the result is sent back to the ACTIVAGE Monitoring Platform and based on the decision of the elderly the caregiver is able or unable to access the personal data of the elderly. These scenarios give a good overview of the possibilities offered using Blockchain technology in AHA applications and more particularly its implementation and validation through the ACTIVAGE project in order to ensure security and privacy in its deployment sites. 4.7 Conclusions In this chapter, two complementary methodologies were presented one for security and the other for privacy in order to address the challenges presented in the previous paragraphs. They were developed to help the IoT System developers of ACTIVAGE to secure their systems and implement correctly personal data protection to cope with the GDPR requirements. These methodologies follow a twofold approach a top down and an end-to-end. These approaches concern from one side the security risk analysis to identify in advance potential threats and find the countermeasures to mitigate/avoid them. From the other side, a privacy approach to put in place the GDPR following a DPIA analysis to identify the system characteristics and evaluate the risks related to the personal data and its protection. This work, developed in the frame of the ACTIVAGE project, can be also reused for any other IoT system considering the high constrains on security and privacy required by AHA applications. Finally, the solutions presented give a good overview of the possibilities offered by the use of the Secure element component to secure IoT devices (Gateways and Sensor nodes) and the Blockchain technology in AHA applications. Both technologies will take an important place in the implementation and validation of the security and privacy requirements of the ACTIVAGE’s Deployment sites to provide secure IoT systems with a high level of personal data protection and thus to increase the users’ trust. Future work will put in place and validate these methodologies and the potentials solutions to secure the 9 Deployment sites of ACTIVAGE project as well as the protection of the personal data of each of the seven thousands of patients “elderly people” participating in the project. Acknowledgement This research project has received funding from the European Union’s Horizon 2020 research and innovation programme ACTIVAGE under grant agreement N∘ 732679. The activities concerning the Secure Gateway has received funding from the French National Research Agency in the framework of the “Investissements d’avenir” program (ANR-10-AIRT-05)”. References Internet Security Threat Report ISTR Ramsonware 2017 An ISTR Special Report July 2017. Proposal for a Regulation OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL on ENISA, the “EU Cybersecurity Agency”, and repealing Regulation (EU) 526/2013, and on Information and Communication Technology cybersecurity certification “Cybersecurity act”), online at: https://eur-lex.europa.eu/legal-content/EN/TXT/?qid=1505290611859&uri=COM:2017:477:FIN Internet of Things European Large-Scale Pilots Programme, online at: https://european-iot-pilots.eu ACTIVAGE Large-Scale Pilot project, online at: https://www.activageproject.eu/ General Data Protection Regulation (GDPR) REGULATION (EU) 2016/679 OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC Official journal of the European Union, online at: https://gdpr-info.eu/ Google Scholar NIST FIPS 199, Standards for Security Categorization of Federal Information and Information Systems (February 2004), online at: https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.199.pdf NIST SP 800-53A, NIST Special Publication 800-53A. Revision 4. Assessing Security and Privacy. Controls in Federal Information. Systems and Organizations (December 2014), online at: https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-53Ar4.pdf Mahmoud Elkhodr, Seyed Shahrestani and Hon Cheung, The Internet of Things: New Interoperability, Management and Security Challenges International Journal of Network Security & Its Applications (IJNSA) Vol. 8, No. 2, March 2016. Managing security recommendations in Microsoft Azure Security Center, online at: https://docs.microsoft.com/en-us/azure/security-center/securitycenter-recommendations Baseline Security Recommendations for IoT – Interactive tool, European Union Agency for Network and Information Security, online at: https://www.enisa.europa.eu/topics/iot-and-smart-infrastructures/iot/baseline-security-recommendations-for-iot-interactive-tool CERN Computer Security Recommendations, in CERN Computer Security, online at: https://security.web.cern.ch/security/recommendations/en/index.shtml Security Recommendations to Prevent Cyber Intrusions, US-CERT, Official website of the Department of Homeland Security, on line at, https://www.us-cert.gov/ncas/alerts/TA11-200A Privacy and Data protection by Design ENISA, Retrieved 2017 04-04, online at: https://www.enisa.europa.eu Ann Cavoukien, Privacy by Design, The 7 foundational Principles Information & Privacy Commissioner Ontario, Canada Originally Published: August 2009, Revised: January 2011. IoT Security Compliance Framework, Release 1.0 2016, IoT Security Foundation IoT Trust Framework, v2.0 – Released Jan 5, 2017, OTA (Online Trust Framework) Top 10 IoT security issue categories, OWASP proposal. Stride THREAT Modelling developed by Microsoft: https://msdn.microsoft.com/enus/library/ee823878 Ronen, A. Shamir, A. O. Weingarten and C. O’Flynn, “IoT Goes Nuclear: Creating a ZigBee Chain Reaction,” 2017 IEEE Symposium on Security and Privacy (SP), San Jose, CA, 2017, pp. 195–212. doi: 10.1109/SP.2017.14 Google Scholar Guidelines on Data Protection Impact Assessment (DPIA) and determining whether processing is “likely to result in a high risk” for the purposes of Regulation 2016/679; Adopted on 4 April 2017. Google Scholar Recommendations for a privacy impact assessment framework for the European Union, Deliverable D, online at: http://www.piafproject.eu/ref/PIAF D3 final.pdf Google Scholar RFID PIA Tool: GS1 EPC/RFID Privacy Impact Assessment Tool, online at: http://www.gs1.org/pia Data Protection Impact Assessment Template for Smart Grid and Smart Metering systems, Smart Grid Task Force 2012–14, March 18th, 2014. Mario Diaz Nava and al., “Report on IoT Devices” Deliverable 3.6 of ACTIVAGE/H2020/LSP, March 2018. GDPR A practical Guide, Varonis. Blockchain: A healthcare Industry view, online at: https://www.capge mini.com/wp-content/uploads/2017/07/blockchain-a healthcare industry view 2017 web.pdf Ali Dorri, Salil S. Kanhere, and Raja Jurdak, Blockchain in Internet of Things: Challenges and Solutions: A healthcare Industry view, online at: https://arxiv.org/ftp/arxiv/papers/1608/1608.05187.pdf Google Scholar Grant Thornton, GDPR & blockchain – Blockchain solution to General Data Protection Regulation, online at: https://www.grantthornton.global/globalassets/_spain_/links-ciegos/otros/gdpr--blockchain.pdf 5. Use Cases, Applications and Implementation Aspects for IoT Interoperability Regel Gonzalez-Usach1, Carlos E. Palau1, Matilde Julian1, Andrea Belsa1 , Miguel A. Llorente2 , Miguel Montesinos2 , Maria Ganzha3 , Katarzyna Wasielewska3 and Pilar Sala4 1Universitat Politècnica de València, Spain 2PRODEVELOP, Spain 3Systems Research Institute Polish Academy of Sciences, Poland 4MySphera, Spain Abstract Interoperability in IoT is currently a very complex and difficult challenge in IoT. Lack of interoperability drastically constrains potential benefits from the interconnection of smart objects and hampers the incipient evolution of IoT (Ambient Intelligent Environments, natural transparent human-oriented interfaces, integration with machine learning mechanisms, blockchain security and Artificial intelligence). INTER-IoT solution for interoperability enables platform-to-platform interoperability, across any IoT layer and any application domains. In this chapter, INTER-IoT solution for platforms’ integration is applied to relevant use cases in the domains of e-Health, AHA, AAL, Transport and Logistics. Furthermore, innovative aspects and elements of the INTER-IoT are explained, and the benefits of its implementation. 5.1 Introduction This chapter is about the enablement of IoT interoperability though a novel framework provided by the INTER-IoT project [1, 2]. In particular, it is focused on the uses cases and applications of the INTER-IoT framework, and on the innovative aspects of its implementation. Interoperability is one of the major challenges in IoT and has a vital importance in the exploitation of all the potential benefits that can be achieved through this new technology paradigm. Without interoperability, possibilities and benefits from the use of IoT are significantly constrained [3]. INTER-IoT project provides an open cross-layer framework with its own associated methodology and integration tools to enable interoperability among heterogeneous Internet of Things (IoT) platforms [2]. INTER-IoT will enable the quick and effective development of smart IoT applications and services, on top of heterogeneous IoT platforms interconnected, and independently from the domain (thus between one or several application domains). This chapter explains relevant uses cases of the INTER-IoT framework, focused on different application domains (Transportation & Logistics, e-Health, Active & Healthy Ageing, and others). In addition, it provides a state-of-the-art of the current situation of interoperability in IoT, and an overview of new approaches employed in the INTER-IoT implementation. 5.2 Current Interoperability State of the Art Regarding the implementation of IoT, insufficient interoperability among platforms tends to provoke major issues both at the technical and business levels [3, 4]. Typical problems are the impossibility of integrating non-interoperable IoT devices into non-homogeneous IoT platforms as well as the inability of developing applications and services over several platforms and different domains. Other important setbacks are the paucity of IoT technology penetration, avoidance of customers and companies in employing IoT technology, cost increases in general, impossibility of reusing of technical solutions and low user satisfaction. Furthermore, lack of interoperability slows and even impedes the incipient evolution of IoT. Ambient Intelligent Environments require seamless interoperability among elements and interfaces. Also, interoperability is essential for the creation of natural transparent human-oriented interfaces of Smart Systems, and it has vital importance for the IoT integration with Artificial Intelligence and the inclusion of new mechanisms such as blockchain security. In recent years, many solutions have been implemented at different levels, from the device layer to complete IoT platforms, due to a great interest of both business and research institutions in investigating and developing IoT technology. However, there is no reference standard for IoT and the development of one is not expected in the foreseeable future [3]. Hence, IoT deployments present high heterogeneity at all layers (device, networking, middleware, application service, data/semantics), which restricts interoperability among their elements and among them. Though many projects have dealt with the development of IoT architectures in diversified application domains, not many projects have addressed interoperability and integration issues among platforms (a clear exception are Butler and iCore [29]). Furthermore, no proposals up to the date of the INTER-IoT project approval have been put forward to deliver a general, fully reusable and systematic approach to solve multiple interoperability problems existing in the IoT platforms technology. The main goal of the INTER-IoT project is to offer a solution for the lack of interoperability in the Internet of Things by providing an open framework that facilitates “voluntary interoperability” among heterogeneous IoT platforms, at any level an IoT deployment (device, network, middleware, application or data & semantics), and across any IoT application domain [2, 6]. Therefore, INTER-IoT guarantees a transparent and effective integration of heterogeneous IoT technology [2, 5]. By using the proposed approach, IoT platform heterogeneity can be turned from a crucial problem to a great advantage, as there will be no need to wait for a unique standard for an interoperable IoT. Instead, interoperable IoT, even on a very large scale, can be created through a bottom-up approach. The majority of current existing sensor networks and IoT deployments work as standalone entities, and represent isolated islands of information, unable to communicate, interoperate and share information with other IoT systems and platforms due to the use of different standards and to their high inner heterogeneity. In the infrequent cases in which there is an integration effort of IoT elements, it is generally performed at the device or data layer, seeking only the collection of data from smart devices. However, there are many other levels of an IoT deployment, in which it is very beneficial to have interoperability, and many other relevant objectives. Differently from current interoperability approaches, INTER-IoT uses a layer-oriented approach to exploit in depth functionalities of each different layer (device, networking, middleware, application services, data & semantics) [1]. Among the different types and levels of interoperability, a main challenge is inter-platform interoperability, which is addressed on the INTER-IoT project. 5.3 Inter-IoT New Approaches for Implementation 5.3.1 Multilayer Approach Differently from current interoperability solutions, that typically follow a global approach, INTER-IoT uses a layer-oriented approach for performing a complete exploitation of each different layer functions [2]. Despite of the research and development challenge that the design of a layer-oriented approach represents, in comparison to a global approach, it can potentially provide a very tight and superior bidirectional integration between different IoT platforms. Therefore, a multilayer-oriented approach can potentially offer improved performance, adaptability, flexibility, modularity, reliability, privacy, trust and security. This layer-oriented approach is composed by several interoperability solutions, addressed specifically to each level or layer of an IoT deployment: Device-to-Device (D2D), Networking-to-Networking (N2N), Middleware-to-Middleware (MW2MW), Application & Services-to-Application & Services (AS2AS), Data & Semantics-to-Data & Semantics (DS2DS). Each interoperability infrastructure layer has a strong coupling with adjacent layers and provides an interface. Interfaces are controlled by a meta-level framework to provide unrestricted interoperability. Every interoperability mechanism can be accessed through an API. The interoperability infrastructure layers can communicate and interoperate through the interfaces. This cross-layering allows to achieve a deeper and more complete integration. Next, the different layers and associated tools are detailed: Device layer (D2D): Currently applications and platforms are tightly coupled, preventing their interaction with other applications and platforms, sensors and actuators communicate only within one system, certain platforms do not implement some important services (i.e. discovery), or do so in an incompatible way. Roaming elements can be missing or inaccessible. IoT Device software is never platform independent as companies create proprietary software. These facts present enormous difficulties for the achievement of interoperability. At the device level, D2D solution will allow the transparent inclusion of new IoT devices and the device-to-device interoperation with other smart objects (legacy). D2D interoperability will allow boosting the growth of IoT ecosystems. As a potential solution, INTER-IoT proposes a D2D gateway that allows any type of data forwarding, making the device layer flexible by decoupling the gateway into two independent parts: a physical part that only handles network access and communication protocols, and a virtual part that handles all other gateway operations and services. When connection is lost, the virtual part remains functional and will answer the API and Middleware requests. The gateway will follow a modular approach to allow the addition of optional service blocks, to adapt to the specific case. Network layer (N2N): Currently the immense amount of traffic flows generated by smart devices is extremely hard to handle. The scalability of the IoT systems is difficult. Also creating the interconnections between gateways and platforms is a complex task. N2N solution aims to provide transparent roaming (support for smart devices mobility) and their associated mobility information. It will also allow oﬄoading and roaming, what implies the interconnection of gateways and platforms through the network. INTER-IoT solution at network level uses paradigms such as SDN and NFV, and achieves interoperability through the creation of a virtual network, with the support of the N2N API. The N2N solution will allow the design and implementation of fully interconnected ecosystems. Middleware layer (MW2MW): At the middleware level, INTER-IoT solution will enable seamless resource discovery and management of IoT smart objects in heterogeneous IoT platforms. Interoperability at the middleware layer is achieved through the establishment of an abstraction layer and the attachment of IoT platforms to it. Different modules included at this level will provide services to manage the virtual representation of the objects, creating the abstraction layer to access all their features and information. Among the offered services, there are component-based interoperability solutions within the middleware based on communication using mediators, bridges and brokers. Brokers are accessible through a general API. Interoperability at this layer will allow a global exploitation of smart objects in large-scale multi-platform IoT systems [7]. Application & Services layer (AS2AS): INTER-IoT allows the use of various services among different IoT platforms. Our approach enables discovery, catalogue and composition of services from different platforms. AS2AS will also provide an API as an integration toolbox to facilitate the development of new applications that integrate existing heterogeneous IoT services. Semantics & Data layer (DS2DS): INTER-IoT solution for the DS2DS layer will allow a common meaning of data and information among different IoT systems and heterogeneous data sources, thus providing semantic interoperability. It is based on semantic translation of IoT platforms’ ontologies to/from a common IPSM modular ontology. The Inter Platform Semantic Mediator (IPSM) component will be responsible for performing ontology-to-ontology translations of the information using ontology alignments. It will be necessary to define explicit OWL-demarcated semantics for each IoT artifact that would like to interoperate, communicate and collaborate [8, 9]. Cross-Layer guarantees non-functional aspects that are required across all layers, such as privacy, security, quality of service (QoS) and trust. Figure 5.1 INTER-IoT multi-layered architecture. 5.3.2 Virtualization of each INTER-IoT Layer Interoperability Solution In order of providing the option of a quick set-up of each of the layers of the INTER-IoT framework, it is given the option of running a virtualized instance of each of them for rapidly implementing the INTER-IoT interoperability solution. This virtualization is performed by means of Docker [30] engine. Through the creation of Docker containers, the software layer components are separated from each other and from the underlying hardware and operating system. Despite of the virtualization, APIs to access to specific layers functionalities are secured, and protected through the use of security tokens and certificates, and by the assignment of specific permissions to each user or type of user. Each layer solution can be deployed and implemented standalone, as far as they are independent from other layers’ solutions. Thus, there is no need for a complete implementation to achieve interoperability on a specific layer. Though, the combined use of adjacent layers’ solutions multiplies benefits, as enables some functionalities among them related to multiple layers. 5.3.3 Universal Semantic Translation INTER-IoT offers a novel solution to provide automatic semantic translation among any pair of platforms [2]. DS2DS solution performs an ontology-to-ontology translation between two platforms, and thus it is able to provide universal semantic interoperability. The INTER-IoT approach for achieving semantic interoperability among heterogeneous IoT platforms is based on: The definition of explicit, OWL-demarcated, semantics for each IoT platform or artifact that is to interoperate, communicate and collaborate. An infrastructure that translates messages/data/communication from its native format to the common format used across the INTER-IoT infrastructure: an IoT Platform Semantic Mediator (IPSM) component that will be responsible for translating incoming information, representing semantics of artifact X to semantics of artifact Y. The IPSM will use ontological alignments to perform ontology-to-ontology translations. The existence of a common modular ontology of INTER-IoT, called GOIoTP [26]. The IoT Platform Semantic Mediator (IPSM) is a software component that performs semantic translation of data. In the context of the INTER-IoT, it is used to translate semantics of messages exchanged by IoT artifacts (platforms, gateways, applications, etc.) within the INTER-IoT software. It is composed of the IPSM Core and auxiliary components, i.e. Semantic Annotators, and exposes a REST API (for configuration). An additional Communication Infrastructure is required to enable communication between the IPSM and all other “artifacts” that are to use its semantic translation services. The Semantic Annotators are located between the “outside world” and the IPSM. Their role is to produce RDF triples from data that they receive, e.g. from Bridges (component of MW2MW layer and the INTER-IoT middleware), and forward them to the IPSM Core through the Communication Channels, instantiated within the Communication Infrastructure. The IPSM Core performs the semantic translation of the RDF data, by applying pre-stored alignments (representing relationships between input and output ontologies). An instance of the IPSM can concurrently “service” multiple “conversations” taking place in separate Communication Channels. To achieve this goal, it can communicate with multiple instances of Semantic Annotators at the same time. Furthermore, each Alignment Applicator services a single Communication Channel and applies a separate alignment within the context of such channel. Communication Channels work in publish-subscribe mode, which allows a single channel to serve both, one-to-one and one-to-many communication. Figure 5.2 Semantic Inter-Platform Ontology-to-Ontology translation through IPSM. 5.3.4 Methodology and Tools for Guiding the Implementation A novel aspect of INTER-IoT is that provides a methodology to guide and ease the INTER-IoT framework implementation. The INTER-METH methodology eases and offers guidance on the implementation of INTER-IoT in order to integrate different heterogeneous IoT platforms [10]. This makes it possible to achieve interoperability among the aforementioned IoT platforms and thus it enables to deploy fully functional IoT applications on top of them. There are currently no methodological approaches that might enable platform integration in a systematic and comprehensive way. It is a well-known truism that the utilization of an engineering methodology is of foremost importance at any domain (e.g. civil engineering, software engineering), maximizes, and ensures the effectiveness of the processes and actions to be performed. In sharp contrast with that, trying to manually apply complex techniques and methods in order to achieve platform integration would of necessity result in an unacceptably high rate of errors and bugs, which may instead be precluded via systematization and automation. The structure of the INTER-METH process can be seen in Figure 5.3. It is iterative in nature and comprises six successive stages: Analysis, Design, Implementation, Deployment, Testing and Maintenance. In principle, the output of each stage is the input of the following one. But in practice and depending on the particular circumstances being dealt with, is it possible to loop only specific steps of the process or else sets of successive ones, facilitating the adaptation to new components, and providing flexibility to this technique. Figure 5.3 Process schema of INTER-METH. Additionally, INTER-IoT provides a set of tools, named INTER-CASE, that guide the implementation of the INTER-IoT framework, explaining the methodology for each specific implementation case. This set of programs offer step-to-step assessment and guidance in this process. Figure 5.4 MW2MW structure. 5.3.5 Middleware for the Interconnection of Platforms This interoperability middleware has syntactic translators (bridges) that are able to convert the specific data format employed by an IoT platform to the INTER-IoT data format (JSON-LD), and vice versa. Thus, INTER-IoT middleware can provide syntactic interoperability among different IoT platforms. Platforms are therefore able to send or receive flows of information in a data format understandable for them. INTER-IoT MW2MW represents a solution for interconnecting platforms at middleware level, and to enable interoperability among them [7]. In regard to the middleware structure (Figure 5.4), south from the Communication and Control block, the bridges manage the communication with the underlying platforms by translating requests and answers from and into messages for the queue. Different bridges might need to use HTTP, REST, sockets or other technologies to talk to the platforms, but these will be translated northwards into messages. They also pass the message content to the IPSM, which is a service external to MW2MW that will allow for ontological and format translation between the platforms and a common language. In the services group of components, the most important are the Platform Registry and Capabilities, that contains the information of all connected Platforms including their type and service capabilities, the Resource Discovery that creates requests to obtain the necessary information from the platforms, and the Resource Registry, that contains a list of resources (e.g. devices) and their properties that can be quickly consulted. In the second phase, the Routing and Roaming Service will be expected to allow the communication with a particular device independently of the platform it is currently connected to, while Authentication and Accountability (not shown) would provide services for the security and monitoring of all the actions. 5.3.6 Virtual Gateway INTER-IoT provides a smart gateway that has the particularity that is partially virtual. This gateway provides IoT interoperability at the device level and has a modular design. Modularity in protocols and access networks is optimal. Any access network, protocol or middleware module can be inserted into the structure as long as its interface matches with the controller. The device is build up in a way that once the system structure is functional a split-up can be realized. Part of the device gateway can be placed in the virtual world to allow device activity to higher level at all time. The device dispatcher will take care of connecting or simulating the actual platform. When connection is lost, the virtual part remains functional and will answer to requests of API and INTER-IoT middleware. At the lowest level there are sensors and actuators. These are connected to the different input modules. These modules take care of connectivity with wireless smart objects. This smart software gateway provides interoperability among very different network technologies and protocols. In addition to Wi-Fi and Bluetooth, INTER-IoT gateway supports network protocols and technologies specifically designed for IoT, such as CoAP, MQTT, LoRa and IQRF, as well as advanced techniques for oﬄoading. Moreover, it is able to support the recent network protocol Multipath TCP [11], which is thought to be the successor of TCP in the Future Internet [12, 13], and it is massively used in smartphones due to its capability of bandwidth aggregation from different networks [13, 14] (e.g. such as 3G and Wi-Fi networks). Figure 5.5 Gateway structure and inner components. 5.4 Inter-Iot Use Cases and Applications INTER-IoT has two pilots INTER-LogP, as an interoperable solution in the seaport scenario, for port management, and INTER-Health, associated with the domain of e-Health. Figure 5.6 INTER-Health pilot. 5.4.1 e-Health (INTER-Health) The INTER-IoT approach is case-driven, and it is implemented and tested in realistic large-scale pilots. One of its pilots, INTER-Health, is focused on the use case of INTER-IoT on e-Health [10], and it is tested on an Italian National Health Centre for m-health, involving 200 patients equipped with body sensor networks, wearable sensors and mobile smart devices for health monitoring. This use case is based on the integration of two e-Health IoT platforms, and its goal is the development of an e-Health system through the integration of several IoT platforms and medical sensors. This system aims to monitor people’s lifestyle in a decentralized and mobile manner for the prevention of health issues such obesity, caused by unappropriated diet and lack of physical activity [15]. These monitoring processes are meant to be decentralized from the healthcare centre to the monitored subjects’ homes and supported in mobility by using on-body physical activity monitors. It is worth noting that, the strategic importance of such complete use case, is largely motivated by the fact that unhealthy lifestyles such as improper and hypercaloric diet and insufficient physical activity, are at the base of main chronic diseases [16, 17]. During the use case experimentation, the effectiveness of the novel system, in terms of lifestyle improvement indices, will be evaluated with respect to the current “manual” monitoring performed by conventional Healthcare Centres. 5.4.1.1 Lifestyle monitor: Medical perspective There are a variety of indicators to measure and observe for preventing and/or detecting obesity, following the medical protocol given by the World Health Organisation (WHO) [16, 17]. Through these indicators, it is possible to determine the health status in terms of appropriate or inappropriate weight (levels vary from underweight, normal weight, overweight to obesity). These measurements can be collected in health centres by a healthcare worker (dietist or doctor). These include objective measurements (body mass index, blood pressure, weight, height, waist circumference) and subjective indices (eating habits and the practise of physical activity) [15]. For these reasons, the goal of this use case is to monitor a person’s lifestyle in a decentralized manner with mobile sensors in order to prevent health issues. Specifically, the use case requires the monitoring of the following health indicators: The Body Mass Index (BMI) (weight/height2) is an objective indicator of the health state of the patient (underweight, normal weight, overweight, first level obesity, second level obesity and 3rd level obesity) of subjects, also allowing to make the diagnosis of overweight and obesity. The waist circumference is an objective indicator for the diagnosis of overweight and obesity; values over 80 cm in women and 94 cm in men are considered pathological. The physical activity practice is a subjective indicator that detect the amount (hours/daily and hours/week) and the type of physical activity (no activity; light, moderate and intense activity). This measure is used to detect a poor lifestyle with physical inactivity. The eating habits is a subjective indicator for measuring the quality and quantity of the diet. This measure is used to detect a poor lifestyle due to improper diet and high-calories. This use case will be deployed over the integrated system composed through the joint of the IoT e-Health platforms UniversAAL and BodyCloud. This will enable the computerized monitoring at the healthcare centre coupled with the monitoring at the patients’ homes [19], which would be supported by the UniversAAL remote services, while BodyCloud will allow to monitor subjects’ physical activity through BodyCloud mobile BSN services. 5.4.1.2 Platforms to integrate BodyCloud BodyCloud [18] is an IoT platform specifically addressed to the creation and management of Body Sensor Networks (BSNs). It has a Software-as-a-Service architecture, and it is capable of creating a smart gateway on smart phone devices that are able to receive and monitor health rates from medical wearable sensors. BodyCloud supports the management and storage of body sensor data streams and the oﬄine and online analysis, of the stored data using software services hosted in the Cloud in order to enable large-scale data sharing and collaborations among users and applications in the Cloud and deliver Cloud services via sensor-rich mobile devices. BodyCloud endeavours to support a variety of specialized processing tasks and multi-domain applications and offers decision support services to take further actions based on the analysed BSN data. The BodyCloud approach is based on four main components: The Body-side refers to an Android-based element for the monitoring of assisted living by means of smart wearable medical sensors, and the collection and upload of data to the Cloud through a smart phone that acts as a mobile gateway. The Cloud-side is a Software-as-a-Service element that provides Cloud services, such as storage. The Viewer-side refers to the Web browser-enabled component for the visualization of data. The Analyst side facilitates the analysis of data and the creation of BodyCloud applications. UniversAAL The IoT platform UniversAAL [2] (Universal Ambient Assisted Living) is specifically designed for the domain of Ambient Assisted Living and medical environments. UniversAAL is a platform that enables the creation of assistive systems by connecting different, heterogeneous technical devices to a single, unified network. UniversAAL also delivers the means to control this distributed system. Well-defined semantics is an important concern in medical and AAL environments, to lead to no ambiguity in measurements, units and terms employed [13]. In this regard, UniversAAL utilizes semantics in a very strict and well-defined manner, unlike many other IoT platforms, and employs W3C SSN ontology for IoT and smart devices. [2] http://www.universaal.info Complementary Platforms The aforementioned IoT platforms (i.e. BodyCloud and UniversAAL) have several high-level characteristics in common and differing aims and technology. Both are e-Health platforms that employ Bluetooth technology to interact with sensors. Moreover, both platforms employ Cloud data storage, cloud big data analysis and data visualization. Though, the two platforms have different specific objectives and are not interoperable from a technological point of view. Their specific objectives are complementary: UniversAAL is focused on non-mobile remote monitoring based on non-wearable measurement devices, whereas BodyCloud provides monitoring of subjects in mobility through wearable devices organized as body sensor networks (BSN). Thus, their integration would produce a full-fledged m-Health platform atop of which multitudes of m-Health services could be developed and furnished. Figure 5.7 INTER-Health: BodyCloud and UniversAAL integration. 5.4.1.3 INTER-IoT integration of health platforms The integration of UniversAAL and BodyCloud is achieved through their interconnection through INTER-IoT, as can be seen on Figure 5.7. This integration is done across three layers (device, application and semantics). The middleware layer of the resulting integrated IoT system is based entirely on UniversAAL thus no interconnection is required across different platforms. Therefore, INTER-IoT provides integration and transparent interconnection at the following levels: at device layer (D2D), enabling the new IoT system to communicate with the wireless medical devices supported by BodyCloud and with the fixed e-Health devices from the health centre or from the patients’ houses. at the application and services layer (AS2AS), the applications for handling patients’ reports the reports from UniversAAL are integrated in the overall systems in such a way that reports can be complemented with additional data from BodyCloud measurement applications. at the data and semantics layer (DS2DS), enabling semantic and syntactic interoperability among all platforms and systems. The integration scheme of the aforementioned IoT platforms by means of INTER-IoT can be seen on Figure 5.10. 5.4.1.4 INTER-Health technical functionalities The integrated IoT system has the following main functionalities: collection of objective (weight, height, body mass index, blood pressure or waist circumference) and subjective (questionnaires concerning the eating habits and the practice of physical activity) measures during the visits at the healthcare centre (based on UniversAAL); telemonitoring at the healthcare centre of subjective (questionnaires) and objective (weight, blood pressure, etc...) measures sent by the patients at home (based on UniversAAL platform); telemonitoring at the healthcare centre of the physical activities performed by patient at home with wearable devices (based on BodyCloud platform) report and visualization of all the measurements collected for analysis and interaction on treatments. Figure 5.8 INTER-Health System overview. 5.4.1.5 INTER-Health pilot The main goal of the INTER-Health pilot is demonstrating how to foster a healthy lifestyle and how to prevent chronic diseases by monitoring subjects’ physical characteristics, nutritional behaviour and activity [15, 19, 20]. The pilot consists of 200 test subjects: 100 subjects following traditional monitoring without IoT devices and 100 subjects with devices. The latter use the INTER-IoT solution. They attended a nutritional counseling session a medical and nutritional centre where their initial physical characteristics are measured, using IoT Devices on the premises (BMI, waist circumference, weight, blood pressure…). Each subject received a management program. Then at home, while they follow the program, they measure their characteristics using their phone and IoT devices. The subjects will visit the medical and nutritional centre each 6 month for check-ups. The healthcare professional in charge of monitoring each user will have access to the history of all the measurements through a dedicated web application. The assisted living environment created for INTER-Health enables the remote measurement of different physiological parameters by means of medical IoT devices such as weigh scale, blood pressure monitor and physical activity rate monitor [21, 22]. The aforementioned sensors interact with an IoT platform (BodyCloud or UniversAAL), and provide measurements through the connection with a smart gateway employing Bluetooth communication [23]. This smart gateway receives the measures from the devices and sends them to the platform via 2G/3G/4G/Wi-Fi/ADSL connectivity. The platform BodyCloud creates a smart gateway on a mobile phone, thus enables a smartphone to become an IoT gateway for the medical sensors. Doctors have access to a web medical application that allows them to follow up the monitoring of patients remotely at any moment, as well as to contact them via ITC communication tools (SMS, e-mail, telephone, and teleconference) and give medical assessment. 5.4.1.6 Benefits INTER-IoT integration guarantees an effective and efficient interoperability between heterogeneous IoT platforms such as the two described e-Health IoT Platforms (i.e., UniversAAL and BodyCloud). The proposed interoperable approach will enable the development of new cross-platform services. Thus, the main benefit of the proposed approach consists of the availability of a more powerful IoT healthcare platform for lifestyle monitoring to implement new applications and services that the individual platforms could not support. Finally, the aforementioned monitoring process can be decentralized from the healthcare centre to the monitored subjects’ homes, and supported in mobility by using on-body physical activity monitors connected to the novel fully integrated IoT environment. This approach, would reduce both the transfer costs of patients at medical centres and the waiting times, also obtaining constantly updated results to make the necessary adjustments in a faster and precise manner. From a final user perspective, INTER-Health use case significantly benefits from INTER-IoT solutions: For outpatients subjects: improving the survey quality of their health status; improve the definition of risk behaviour; provide information on diets and physical activity more relevant with the health status and with the risks of the subject compared to the traditional methods; increasing the sensitivity of the screening of subjects who need intervention from the local doctor or of the hospitals (second and third level obesity, diabetes, etc); reduce the time spent in face-to-face contact with the nutritional outpatient and the number of travels. For public health services: increase efficiency with the same resources used; increase effectiveness through standardization of objective and subjective measurements; turning subjective ones, such as activity practice, into objective ones (by exploiting IoT wearable systems); enlarge the number and type of subjects that appeal to nutritional outpatient. For local doctors: lighten the taking charge of healthy subjects by the local doctor for guaranteeing greater availability toward pathological subjects; overall, the local doctor becomes a vehicle from a lower general incidence of healthcare costs on the income of citizens, improve the care and diagnostics efficiency making directly available on the computer system of the local doctor, the data present on the platform used from the nutritional ambulatory. 5.4.2 Smart Transport & Logistics (INTER-LogP) INTER-IoT has a pilot, called INTER-LogP, focused on a use case of Smart Transport & Logistics. INTER-IoT offers an interoperable solution in the seaport scenario for port management [7, 24]. The main objective of this pilot is to provide a service to control port access, monitor traffic and assist the operations at the port. Several systems will be able to identify trucks and drivers using different devices. This information can be shared under certain predefined rules through interoperability between the platforms involved; it can be used to monitor trucks inside the port by the Port Authority platform (due to security and safety purposes), and to manage more efficiently resources in the terminal. Moreover, this information is employed to avoid queues in the access gates to the port and the terminal. The use IoT platforms in ports can potentially enable traffic and container monitoring, geolocation of cargo and vehicles, management of storage and cargo processes and improvement of services. These benefits can be multiplied through appropriate sharing of valuable information and cooperation among the different IoT platforms in port environments, creating synergies. This use case addresses the need of IoT platforms interoperation within port actors: such as container terminals, transport companies (road and maritime transportation), the port authority, and customers. This pilot has been deployed in the port of Valencia, the most important port of the Mediterranean. The pilot is mainly composed by an Access Control System, and a Health Emergency System, which are possible fruit of the interoperability among platforms provided by INTER-IoT. The platforms integrated through INTER-IoT belong to the main actors of the port: IoT platforms of the Port Authority, of one of the Port Container Terminal (NOATUM Valencia), and Intelligent Transportation Systems of several Road Haulier Companies. This interconnection is set at middleware level, employing the INTER-IoT MW2MW solution [7]. Figure 5.9 INTER-LogP use case approach. Figure 5.10 Integration of IoT platforms of different port stakeholders through INTER-IoT. Important platforms and systems involved are: In the Container Terminal : SEAMS : IoT platform for controlling container terminal machinery TOS : Terminal Operating System that controls and handles data associated to any terminal operation (Big Data) From the Port of Valencia : PORTCDM : Intelligent transportation system for the management of ships arrivals to the port From the Road Haulier Companies Different Intelligent Transportation Systems (ITS) This interconnection provides interoperability at middleware level, and flows of relevant information can be shared among platforms to enhance services and processes in the port. The enhancement of the access control to the port facilities is explained in the next subsection. Also, a new service combining e-Health emergencies and port transportation is described in this section. 5.4.2.1 Pilot for access control at the port area The interoperation of the platforms of main port stakeholders can bring very significant enhancement to the services related with the access control to the port facilities. Appropriate sharing of information and interoperation among them lead to a more efficient access control in terms of time and cost efficiency, security, safety, minor waiting times and improved management. Platforms integrated through INTER-IoT are from diverse entities from the port environment: the port, a container terminal (NOATUM) and several road haulier transportation companies. Relevant information shared among platforms are the location of trucks inside the port, information regarding load and unload operations, and access controls. The main benefits from these services are the collection and analysis of data regarding queues, congestion and temporary distribution of traffic, and to manage efficiently the resources. Relevant information obtained is the position of the trucks inside the port facilities, and its use it is important in the sake of safety and security. All these data can be shared between the port authority and the port terminals to improve operations. Figure 5.11 High-level view of the access control pilot. Figure 5.12 High-level scheme of the pilot for health accident assistance in port areas. 5.4.2.2 Pilot for health accident at the port area Starting from the access control pilot, trucks will be monitored once they enter in the port facilities. The Emergency Warning System (EWS) will be monitoring the data coming from the truck and the driver. In case it detects an accident or a medical problem, EWS will publish a notification to the port authority in a standard format (EDXL). Once the emergence control centre receives the notification, it will be possible to communicate with the driver through a push to talk protocol in the driver’s mobile. The main benefits we can get from this scenario are: apply in the port communications a standard format in accident reporting like EDXL, real-time identification of the location of the accident, direct communication with the closest control centre when an accident occurs and monitoring driver’s health if it is necessary. 5.4.3 Active and Healthy Ageing (ACTIVAGE) ACTIVAGE [27] is a H2020 LSP project that addresses the use of IoT technologies in the Active & Healthy Ageing (AHA) domain [25]. INTER-IoT framework is a core element in the ACTIVAGE system that enables interoperability at different levels and fulfills the ACTIVAGE’s needs of interoperability. 5.4.3.1 ACTIVAGE: Active and healthy ageing initiative ACTIVAGE project addresses the use of IoT technologies in the Active & Healthy Ageing (AHA) domain [25]. The objective of this project is to prolong and support the independent living of older adults in their cities and homes and responding to real needs of caregivers, service providers and public authorities. Hence, this project aims to improve the autonomy and quality of life of older adults and contribute to the sustainability of the health and care systems. The ACTIVAGE project has been designed as a Multi Centric Large-Scale Pilot consisting of nine interconnected Deployment Sites (DS) distributed over seven European countries. A DS can be defined as a cluster of stakeholders in the AHA value network, working together within a geographical space. Therefore, a DS includes users (elderly people, formal and informal caregivers), service providers, AHA services, health care/social care administration and technological infrastructures and technology providers. The DS make use of existing open and proprietary IoT platforms. Each DS utilizes a specific IoT platform, or two. The different IoT platforms employed in ACTIVAGE DS are FIWARE, SOFIA2, UniversAAL, SensiNact, OpenIoT, IoTivity and SENIORSOME. The following DS have been defined in the ACTIVAGE project: DS1: Galicia (Spain) will make use of the SOFIA2 platform. DS2: Valencia (Spain) will provide services based on a combination of data from UniversAAL and Fiware platforms. DS3: Madrid (Spain) will deploy services based on UniversAAL. DS4: Region Emilia Romagna (Italy) will make use of the Fiware platform. DS5: Greece will offer services based on the IoTivity platform DS6: Isére (France) will provide services based on the SensiNact platform. DS7: Woqaz (Germany) will develop services based on the UniversAAL platform. DS8: Leeds (UK) will deploy services based on the IoTivity platform. DS9: Finland will make use of the proprietary IoT platform SENIORSOME. Due to the lack of interoperability among IoT platforms, the definition of an interoperability framework is needed in order to create a European AHA ecosystem. Figure 5.13 AHA Interoperable DS (Smart Home Clusters). With this aim, ACTIVAGE will develop the ACTIVAGE IoT Ecosystem Suite (AIoTES), which is defined as a set of tools, techniques and methodology for interoperability between existing IoT platforms. The AIoTES Framework will provide interoperability among IoT platforms and ensure security and privacy. The different DS will connect to AIoTES and AHA applications will be deployed over this framework, thus allowing the integration of remote health-care services and wearable systems-based health-care services in mobility, which will include remote medical measurements, local mobile physical detection and processing, and on-line and off-line analysis of lifestyle data. ACTIVAGE aims to achieve interoperability at three stages: Intra-deployment site interoperability, which means that the services provided at each DS must be interoperable to each other. In order to achieve this, any the application should be able to access all the application data within the same DS. Moreover, the applications within a DS should support multiple IoT platforms and be able to be transferred between different platforms within s DS. Figure 5.14 AHA Architecture for Interoperability. Inter-deployment site interoperability: enables new services to be automatically incorporated into the ecosystem of the DS. This means that different DS should be able to exchange application data. Moreover, it should be possible to transfer an application that was designed for a DS to a different DS and new applications could be developed for multiple DS instead of being designed for a particular DS. Interoperable external adopted solutions: according to the needs of each specific DS, new solutions will be implemented within the DS. They will be interoperable according to the ACTIVAGE interoperability framework. These goals imply that the same data format must be used by the applications regardless of the IoT platforms being used in the DSs so as the applications can access any platform’s data. Moreover, applications initially development for a DS can be extended for any other DS only by adapting them to AIoTES instead of making an adaptation for each individual platform. Overall, multiple AHA applications and IoT platforms may coexist in the same DS, thus contributing to fulfil the main goal of a DS. Therefore, it is required inter-platform and intra-platform interoperability among the different IoT platforms of the DS of this AHA intiative (FIWARE, UniversAAL, SOFIA2, OpenIoT, IoTivity and Seniorsome). Furthermore, this interoperability must be both syntactic and semantic, to allow the understandability of the information across platforms and a common interpretation of data shared among them. In this regard, INTER-IoT is the key component that makes it possible for the ACTIVAGE deployment to enable and ensure platform interoperability in DSs. The required interoperability among IoT platforms is provided by the Semantic Interoperability Layer (SIL), which is a component of the AIoTES framework. INTER-IoT is the key component that provides inter-platform interoperability in this AHA deployment. Two components of INTER-IoT, namely, the MW2MW layer and the DS2DS layer (composed by the IPSM), have been incorporated in the SIL. The MW2MW layer connects to all the IoT platforms and provides a common abstraction layer to provide access to platform’s features and information. An important function of the MW2MW is to convert the data to a common syntax, which is based on JSON-LD. Once the data is in the common format, the IPSM performs semantic translations. As a result, AIoTES provides semantic and syntactic interoperability among the different platforms, and enables information sharing and interoperation among them. This data shared will be understandable for the receiver platform, not only in terms of data format but also regarding the meaning of the received information. In addition to these INTER-IoT components, the AIoTES framework includes an API, security and privacy protection components management functions. Security and privacy span across all the components of AIoTES in order to ensure the protection of sensitive data against unauthorized access. AIoTES management provides a set of tools that allow access to the information of a DS, such as platforms and devices, and mechanisms to facilitate the integration of the framework. Finally, AIoTES will provide a common API, which will allow a homogeneous access to the components of AIoTES in order to develop services and applications able to exchange data from different IoT platforms and produce new added value services. Hence, the AIoTES API will make possible the development of and ecosystem based on applications and services compatible with AIoTES. 5.4.3.2 Use Cases of ACTIVAGE AAL and AHA systems can very significantly benefit from interoperability [31, 32]. The following Reference Use Cases respond to specific user needs (senior people and caregivers), to improve their quality of life and autonomy, in a AHA context, that require IoT interoperability: Daily activity monitoring at home for informal caregivers support and for formal caregivers follow up in order to alert them about deviations of the elderly persons’ habits, allowing early interventions while extending independency. Wireless sensors like presence, magnetic contact, power measurement, proximity, are deployed at the home of the elderly. A gateway transmits the information to a Cloud where calculation on activities, trends and risks is performed. Integrated care for older adults under chronic conditions. This use case combines daily activity monitoring at home and the use of medical devices for health monitoring. The combination of IoT technologies with eHealth solutions in one single integrated IT system, and the integration of care protocols from entities traditionally working separately will promote the coordination among care providers, joint response to emergencies, better planning of resources and more effective interventions. This will lead to economic savings and a better quality of life for people with chronic disease. Monitoring assisted persons outside home and controlling risky situations. This use case combines wearable devices or smartphones and the Smart City infrastructure in order to promote socialization and activity. The Smart City infrastructure tracks the wearable devices and request for help if certain rules are met in order to help persons at risk. Emergency trigger. The system automatically reports an emergency when a critical situation is detected. Wireless or wired sensors and “panic” buttons distributed in the home environment in strategic situations linked to a gateway that forwards the emergency to a call-centre system. Other complex scenarios might involve the processing of data in the private or hybrid cloud and then the emergency is triggered. Compared to state-of-the-art systems at home, emergency works when the user requests for help, but also when the environment detects the emergency and the person cannot (unconsciousness, fall, gas). Exercise promotion for fall prevention and physical activeness using wearable and ambient sensors. Cognitive stimulation for mental decline prevention in order to extend the time elderly people live independently. This use case combines behavioural monitoring at home and outside, and interventions, such as the promotion of mental and physical exercises and gaming, making use of apps in tablets or smartphones and peripheral connected devices. Prevention of social isolation by means of communication tools at home. This use case promotes social interaction and mobility though the use of video-based system and apps connected to the Smart City infrastructure, which provides data about events, and linking to other peers. In addition, continuity between home (home sensors) and outdoors scenarios (smart phone as a sensor) provides seamless information about users’ social activity. Social engagement keeps depression and decline away. Comfort and safety at home. This use case includes climate and light control, perimeter safety, energy control and home automation. Support for transportation and mobility. This use case includes adapted route planning for elderly persons both in cities and between different cities. Routes can be computed making use of the Smart City data about traffic conditions and other mobility aspects and personalized according to goals such as exercise promotions or finding the easiest/fastest route. 5.4.4 Other Potential Use Cases INTER-IoT can be employed in any domain or across domains where there is a need of IoT interoperability. Thus, its use is not limited to the aforementioned use cases and can be utilized in the most various IoT environments, allowing very different aims that are enabled or partially enabled through interoperability. A clear example is the Smart Cities use case, which greatly benefits from the synergies and cooperation among different systems and platforms that provide different city services. In this case, there is an enormous need of interconnection that is limited by the typical interoperability problems in the IoT realm. The application of the INTER-IoT framework is able to solve the integration of heterogeneous platforms and systems within a Smart City, provide numerous benefits to the citizens and enable the creation of new useful services fruit of this interoperability. 5.5 Conclusions and Outlook In this chapter, it has been described the current problem of lack of interoperability in the heterogeneous Internet of Things realm, and the usefulness of INTER-IoT for solving this important problem and enabling the integration and interoperation of heterogeneous IoT platforms at all layers and across multiple domains. The effective application of INTER-IoT for solving the lack of interoperability among platforms has been explained and demonstrated in several use cases associated to different application domains. First, the usefulness of INTER-IoT has been analysed in a e-Health and AAL use case, in which the interoperability framework is implemented. In this regard, INTER-IoT enables the integration and interoperability of IoT platforms and provides a more powerful solution that the individual solution provided by each one of those platforms. These advantages are a consequence of the enablement of synergies and the sum of capabilities of all the integrated platforms. Second, INTER-IoT has been a key integrator element in an interoperable solution for efficient port management. This use case is focused on the domain of Transportation and Logistics. INTER-IoT enables the interconnection of several platforms at middleware level, and the syntactic and semantic interoperability of any information shared among them, despite of the different data formats, standards, message structure and semantics. Because of this interconnection of platforms and sharing of relevant data among key entities, several management processes in the port can be very significantly improved. Also, the interoperability provided by INTER-IoT demonstrates that enables the existence of new services, fruit of the new information sharing and the possibilities of cooperation among platforms. Third, INTER-IoT interoperability framework is employed in an AHA and AAL use case for enabling an assisted living environment in elder homes, to allow ancient people to live at home in a safe and autonomous way. INTER-IoT allows different IoT platforms to interoperate with the ACTIVAGE system around Europe, to enable this autonomous life of elderly people. Finally, other potential use cases are mentioned, as far as INTER-IoT framework can be successfully employed in any domain and use case that has a need of IoT interoperability at any level (e.g. Smart Cities). Regarding implementation aspects, INTER-IoT employs several innovative elements to provide enhanced functionality and has clear positive differentiators from other interoperability approaches. First, INTER-IoT has a layered approach to guarantee tight interoperability on each of the different layers (device, network, middleware, application, data and semantics), compared to a more global approach. Also, due to this multilayer approach, any of the INTER-IoT layer solutions can be employed in a standalone way, providing more flexibility and adaptation to specific IoT cases. Additionally, to guarantee a quick and easy implementation, INTER-IoT gives the option of running virtualized interoperability solutions for each layer through Docker. This virtualization enormously facilitates the deployment of the INTER-IoT solutions. Moreover, INTER-IoT has a huge concern on security, and layer solutions and APIs are securitized. The INTER-IoT interoperability framework provides innovative elements, such as a universal semantic platform-to-platforms translator, a middleware that enables the interconnection and interoperation of any platform at middleware level, despite of the standards and formats employed, and a partially virtualized gateway. Furthermore, INTER-IoT implementation is guided and eased through a novel methodology (INTER-METH) specifically designed with this aim. Interoperability in IoT, and more specifically among platforms, represents one of the most important challenges in IoT, and interoperability solutions such as INTER-IoT can potentially unlock immense benefits from the use of smart technology, and a huge integrator and enabler of services on top of IoT deployments. INTER-IoT can be used in the middle future to enable interoperability solutions among the most diverse use cases and domains in which IoT interoperability is required, solving modern society problems to let technology improve people’s daily life, and propel European economy. Also, INTER-IoT facilitates a key element for the evolution of IoT; interoperability is essential for the creation of natural human interfaces in IoT systems, the existence of Ambient Intelligent Environments or the integration of IoT with Artifical Intelligence. Acknowledgements This work has received funding from the European Union’s “Horizon 2020” research and innovation programme as part of the “Interoperability of Heterogeneous IoT Platforms” (INTER-IoT) grant agreement N∘687283 and as a part of “Activating Innovative Iot Smart Living Environments For Ageing Well” (ACTIVAGE) grant agreement N∘732679. List of Notations and Abbreviations: Notations Abbreviations API Application Programming Interface IoT Internet of Things BSN Body Sensor Network AAL Ambient Assisted Living SaaS Software as a Service ITS Intelligent Transportation System EWS Emergency Warning System AHA Active and Healthy Ageing LSP Large Scale Pilot DS Deployment Site References INTER-IoT European project, Research and Innovation action – Horizon 2020, online at: http://www.inter-iot-project.eu/ Ganzha, M., Paprzycki, M., Pawłowski, W., Szmeja, P., and Wasielewska, K. (2017). Semantic interoperability in the Internet of Things: An overview from the INTER-IoT perspective. Journal of Network and Computer Applications, 81, 111–124. Google Scholar Manyika, J., Chui, M., Bisson, P., Woetzel, J., Dobbs, R., Bughin, J., and Aharon, D. (2015). Unlocking the Potential of the Internet of Things. McKinsey Global Institute. Google Scholar S. Kubler, K. Framling et al. “IoT Platforms Initiative”, In Digitising the Industry Internet of Things Connecting the Physical, Digital and Virtual Worlds (Eds. Ovidiu Vermessan and Peter Freiss), Rivers Publishers Series in Communications, vol. 49, pp. 265–292, 2016. Google Scholar Savaglio, C., Fortino, G., and Zhou, M. (2016, December). Towards interoperable, cognitive and autonomic IoT systems: an agent-based approach. In Internet of Things (WF-IoT), 2016 IEEE 3rd World Forum on (pp. 58–63). IEEE. Google Scholar Soursos, S., Žarko, I. P., Zwickl, P., Gojmerac, I., Bianchi, G., and Carrozzo, G. (2016, June). Towards the cross-domain interoperability of IoT platforms. In Networks and Communications (EuCNC), 2016 European Conference on (pp. 398–402). IEEE. Google Scholar Yacchirema, D., Gonzalez-Usach., R, Esteve, M., and Palau, C. (2018, April) IoT interoperability applied to the domain of port and logistics, Transport Research Arena Conference 2018. Ganzha, M., Paprzycki, M., Pawłowski, W., Szmeja, P., and Wasielewska, K. (2016, April). Semantic technologies for the IoT-an Inter-IoT perspective. In Internet-of-Things Design and Implementation (IoTDI), 2016 IEEE First International Conference on (pp. 271–276). IEEE. Google Scholar Ganzha, M., Paprzycki, M., Pawłowski, W., Szmeja, P., and Wasielewska, K. (2017, September). Alignment-based semantic translation of geospatial data. In Advances in Computing, Communication and Automation (ICACCA)(Fall), 2017 3rd International Conference on (pp. 1–8). IEEE. Google Scholar Pace, P., Aloi, G., Gravina, R., Fortino, G., Larini, G., and Gulino, M. (2016, December). Towards interoperability of IoT-based health care platforms: the INTER-health use case. In Proceedings of the 11th EAI International Conference on Body Area Networks (pp. 12–18). ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering). Google Scholar Gonzalez-Usach, R., Pradilla, J., Esteve, M., and Palau, C. E. (2016, April). Hybrid delay-based congestion control for multipath tcp. In Electrotechnical Conference (MELECON), 2016 18th Mediterranean (pp. 1–6). IEEE. Google Scholar Gonzalez-Usach, R., and Kühlewind, M. (2012, August). Implementation and evaluation of coupled congestion control for multipath TCP. In Meeting of the European Network of Universities and Companies in Information and Communication Engineering (pp. 173–182). Springer, Berlin, Heidelberg. Google Scholar GONZALEZ-USACH, R. (2014). Design and Evaluation of a Delay-Based Algorithm for Multipath TCP (Doctoral dissertation). Google Scholar Gonzalez-Usach, R., Rene, O., (2018, April) Wi-Fi thermograph for remote cold chain monitoring with Multipath TCP support. In Transport Research Arena 2018. S.M.R. Islam, D. Kwak, M.H. Kabir, M. Hossain, K. Kwak “The Internet of Things for Health Care: A Comprehensive Survey”, IEEE Access, Vol. 3, pp. 678–708, 2015. Google Scholar World Health Organization, “Global status report on non-communicable diseases”, 2010. http://www.who.int/nmh/publications/ncdreport2010/en/ Google Scholar World Health Organization, “Obesity: Preventing and Managing the Global Epidemic”, WHO Obesity Technical Report Series 894, 2000. http://www.who.int/nutrition/publications/obesity/WHO TRS 894/en/ Google Scholar BodyCloud: A Cloud-assisted Software Platform for Pervasive and Continuous Monitoring of Assisted Livings using Wearable and Mobile Devices, http://bodycloud.dimes.unical.it C. Fernndez-Llatas, A. Martinez-Romero, A.M. Bianchi, J. Henriques, P. Carvalho, V. Traver “Challenges in personalized systems for Personal Health Care” IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI), IEEE, pp. 356–359, 2016. Google Scholar S.C. Mukhopadhyay, “Wearable Sensors for Human Activity Monitoring: A Review”, IEEE Sensors Journal, Vol. 15, Issue 3, pp. 1321–1330, 2015. Google Scholar R. Gravina, C. Ma, P. Pace, G. Aloi, W. Russo, W. Li, G. Fortino “Cloudbased Activity-aaService cyberphysical framework for human activity monitoring in mobility”, Future Generation Computer Systems, 2016. Google Scholar G. Fortino, R. Gravina, W. Li, C. Ma “Using Cloud-assisted Body Area Networks to Track People Physical Activity in Mobility”, International Conference on Body Area Networks (BodyNets 2015), pp. 85–91, 2015. Google Scholar Aloi, G., Caliciuri, G., Fortino, G., Gravina, R., Pace, P., Russo, W., and Savaglio, C. (2017). Enabling IoT interoperability through opportunistic smartphone-based mobile gateways. Journal of Network and Computer Applications, 81, 74–84. Google Scholar Gonzalez-Usach, R., Sarabia, D., Esteve, M., and Palau, C. (2018, April). Smart Interoperable Dynamic Lighting, Transport Research Arena Conference 2018. Bousquet, J., Kuh, D., Bewick, M., Standberg, T., Farrell, J., Pengelly, R., and Camuzat, T. (2015). Operational definition of active and healthy ageing (AHA): a conceptual framework. The journal of nutrition, health and aging, 19(9), 955–960. Google Scholar INTER-IoT Ontology, online at: http://docs.inter-iot.eu/ontology ACTIVAGE, online at: http://www.activageproject.eu/ UNIVERSAAL, online at: http://www.universaal.info Open IoT Platforms: iCore-Butler demo, online at: http://open-platforms.eu/app_deployment/butler-icore-integrated-common-demo/ Docker, online at: www.docker.com Gonzalez-Usach, R., Collado, V., Esteve, M., and Palau, C. E. (2017, May). AAL open source system for the monitoring and intelligent control of nursing homes. In Networking, Sensing and Control (ICNSC), 2017 IEEE 14th International Conference on (pp. 84–89). IEEE. Google Scholar Gonzalez-Usach, R., Yacchirema, D., Collado, V., and Palau, C. E. (2017, Nov). AmI open source system for the intelligent control for residences for the elderly. In InterIoT 2017 Conference. Google Scholar 6. Smart Data and the Industrial Internet of Things Christian Beecks, Hassan Rasheed, Alexander Grass, Shreekantha Devasya, Marc Jentsch, José Ángel Carvajal Soto, Farshid Tavakolizadeh, Anja Linnemann and Markus Eisenhauer Fraunhofer Institute for Applied Information Technology FIT, Schloss Birlinghoven, Sankt Augustin, Germany E-mail: Christian.Beecks@fit.fraunhofer.de Abstract Many modern production processes are nowadays equipped with cyber-physical systems in order to capture, manage, and process large amounts of sensor data including information about machines, processes, and products. The proliferation of cyber-physical systems (CPS) and the advancement of Internet of Things (IoT) technologies have led to an explosive digitization of the industrial sector. Driven by the high-tech strategy of the federal government in Germany, many manufacturers across all industry segments are accelerating the adoption of cyber-physical system and IoT technologies to gain actionable insight into their industrial production processes and finally improve their processes by means of data-driven methodology. In this work, we aim to give insights into our recent research regarding the domains of Smart Data and Industrial Internet of Things (IIoT). To this end, we are focusing on the EU projects MONSOON and COMPOSITION as examples for the Public-Private Partnership (PPP) initiatives Factories of the Future (FoF) and Sustainable Process Industry (SPIRE) and show how to approach data analytics via scalable and agile analytic platforms. Along these analytic platforms, we provide an overview of our recent Smart Data activities and exemplify data-driven analysis of industrial production processes from the process and manufacturing industries. 6.1 Introduction Many modern production processes are nowadays equipped with cyber-physical systems in order to capture, manage, and process large amounts of sensor data. These sensor data include information about machines, processes, and products and are encountered in form of data streams. These data streams from the production site are then frequently integrated into cloud-based solutions by means of Internet of Things technologies in order to allow comprehensive data-driven investigations and process optimizations. The proliferation of cyber-physical systems and the advancement of IoT technologies have led to an explosive digitization of the industrial sector. Driven by the high-tech strategy of the federal government in Germany, many manufacturers across all industry segments are accelerating the adoption of cyber-physical systems and Internet of Things technologies in order to gain actionable insight into industrial production processes and finally improve these processes by means of data-driven methodology. The IoT is one of the key enabler for intelligent manufacturing and production. It facilitates the intelligent connectivity of smart embedded devices in factories and shop floors. Endowing the manufacturing and production site with technologies from the IoT, which is then also referred to as the IIoT, has become a technical prerequisite for a sustainable and competitive industrial production of the future. Digitizing the industrial sector with cyber-physical systems, Internet of Things technologies, cloud computing services, and Smart Data analytics leads to the fourth industrial revolution, which is denoted as Industry 4.0. The importance of strengthen the European industry to become more sustainable and competitive is also taken into account by the European Commission. Within the EU Framework Programme for Research and Innovation the two Public-Private Partnership (PPP) initiatives Factories of the Future (FoF) and Sustainable Process Industry (SPIRE) aim to (i) help EU manufacturing enterprises to adapt to global competitive pressures by developing the necessary key enabling technologies across a broad range of sectors and (ii) support EU process industry in the development of novel technologies for improved resource and energy efficiency. Turning industrial Big Data into structured and useable knowledge is one of the major data-centric challenges for enhancing production processes. Integrating data from heterogeneous systems and gaining insight into voluminous amounts of streaming sensor data with high variety and velocity requires scalable methods and techniques. Structuring knowledge in a way that it can be used to manage and improve industrial production processes is one of the objectives of Smart Data analytics. By improving Big Data to a higher degree of quality, Smart Data analytics aims to understand the following aspects: Purpose: What problem to solve with the data? People: Who is involved? Processes: What are the surrounding processes? Platform: Which IT infrastructure is necessary for realization? The aforementioned aspects are also referred to as the 4Ps of Smart Data. They indicate the information to be gathered in addition to the sensor data from the production site in order to get a more complete understanding about the data and its surrounding entities. It is obvious that addressing the 4Ps within the Smart Data analytics process strongly relies on user-centered methods since many of the required information need to be discovered from non-documented data. The Fraunhofer Institute for Applied Information Technology FIT has been conducting research and development on user-friendly smart solutions that blend seamlessly in business processes for about 30 years and has a strong experience in digitization, Industry 4.0 projects and IoT solutions. Having about 160 researchers with different scientific background, the Fraunhofer Institute for Applied Information Technology FIT is organized into five research departments: The User-Centered Computing department develops IT systems and technologies that focus on their users throughout their complete life cycle. Current work focuses on usability engineering, web compliance, and accessibility. The Cooperation Systems department develops and evaluates groupware and community systems for virtual teams and organizations. Our work on hardware and software of Mixed and Augmented Reality systems focuses on support for cooperative planning tasks. The Life Science Informatics department designs and implements complex biomedical information systems and creates novel software solutions for manufacturers and users in health care, biotechnology, drug research and social services. Focal areas are image-based navigation systems, information-intensive optical instruments, visual information analysis, multi-parametric molecular sensor technology and diagnostics as well as bio-analogue analysis of changing images. The Risk Management and Decision Support department offers decision and process support for application domains whose processes can be characterized by their high level of complexity as well as their weak determination of process structures. The Fraunhofer Project Group Business & Information Systems Engineering, located in Augsburg and Bayreuth, has proven expertise at the interface of Financial Management, Information Management and Business & Information Systems Engineering. The ability to combine methodological know-how at the highest scientific level with a customer-focused and solution-oriented way of working, is our distinctive feature. As part of User-Centered Computing department, the User-Centered Ubiquitous Computing group develops systems providing effective personal assistance that dynamically respond to user demands and at the same time adapt to new work practices. The group is focusing on the application domains Industry 4.0, Smart Cities and Energy Efficiency/Smart Grids and approach novel applied solutions via methods from the domains User-Centered Design, Internet of Things Platforms, and Smart Data. In this chapter, we aim to give insights into our recent research into the domains of Smart Data and Industrial Internet of Things. To this end, we are focusing on the following EU projects: The MONSOON (MOdel based coNtrol framework for Site-wide OptimizatiON of data-intensive processes) project aims to establish a data-driven methodology to support the identification and exploitation potentials by applying multi-scale model based predictive controls in production processes. It offers an integrated real-time and dependable infrastructure easing in improving the efficient use and re-use of raw resources and energy across plant- and site-wide applications in heterogeneous and distributed production environments. EU funds it under SPIRE (Sustainable Process Industry through Resource and Energy Efficiency) research project that aims to develop an infrastructure in support of the process industries. The COMPOSITION (Ecosystem for COllaborative Manufacturing PrOceSses – Intra- and Interfactory Integration and AutomaTION) project has two main goals: The first goal is to integrate data along the value chain inside a factory into one integrated information management system (IIMS) combining physical world, simulation, planning and forecasting data to enhance re-configurability, scalability and optimisation of resources and processes inside the factory. The second goal is to create a (semi-)automatic ecosystem, which extends the local IIMS concept to a holistic and collaborative system incorporating and inter-linking both the Supply and the Value Chains. The COMPOSITION project is funded under the Factories of the Future PPP. In conjunction with both EU projects mentioned above, EXCELL is a twinning project addressing Big Data applications for cyber-physical systems in production and logistics Networks. The consortium of academics from Hungary, Great Britain, Belgium and Germany expands the scientific activities through central publications and active participation in scientific discourses. Priority Research Fields (PRFs) define the topic areas in which the partners work closely together to mutually train, support and empower each other with their knowledge and expertise. PRFs are for example cyber-physical systems and human system interaction, business-based Internet of Things and services, as well as data mining and data interoperability. In the remainder of this chapter, we will first describe our research activities and results with respect to the EU project MONSOON, which is an example for the process industry, in Section 6.2. Afterwards, we will continue with the EU project COMPOSITION, which is an example for the manufacturing/discrete industry, in Section 6.3. We finally conclude this chapter in Section 6.4. 6.2 Process Industry 6.2.1 Introduction The process industry is characterized by intense use of raw resources and energy, and thus represents a significant share of European industry in terms of energy, resources consumption and environment impact. In this area, even a small optimization can lead to high absolute savings, both economic and environmental. Predictive modelling techniques can be especially effective in optimization of production processes. However, the application of these techniques is not straightforward. Predictive models are built using the data obtained from production processes. In many cases, process industries must invest in the monitoring and data integration as well as in the development and maintenance of the underlying infrastructure for data analytics. Many other obstacles are also present, e.g., interoperability issues between software systems in production, difficulties in the physical monitoring of the production parameters, problems with the real-time handling of the data, or difficulties in defining relevant Key-Performance Indicators (KPIs) to support management. Therefore, the deployment of such predictive functions in production with reasonable costs requires consolidation of the available resources into shared cloud-based technologies. In the case of more flexible production environments, approaches that are even more significant are possible, such as the reinvention or redesign of the production processes. However, this is not applicable to major, capital-intensive process industries. In this case, the integration of innovations in the established production processes can be fundamental in their transformation from resource-consuming production into the “circular” model. 6.2.2 Reference Architecture The high-level conceptual view of the reference architecture that is developed within the scope of the project MONSOON is depicted in Figure 6.1. Figure 6.1 MONSOON Reference Architecture. The platform is able to inter operate with the heterogeneous existing systems deployed in process industries at different layers of the SCADA pyramid (Control, Supervision, Management, Enterprise). It includes sensors or controllers (PLCs), SCADA (Supervision control and data acquisition), Management Information Systems (MES) and Enterprise Resource Planning (ERP). There are two main components of the architecture. The Real-time Plant Operations Platform deployed on-site and supports data collection, storage and interaction with the production systems respecting relevant constraints and satisfying data-intensive conditions. The Cross-Sectorial Data Lab supports the development of new dynamic model base multi-scale controls. All the relevant data from the production site are transferred to the Data Lab where it is stored and processed for optimization of production process. To validate and demonstrate the results, two real environments are used within the project: an aluminium plant in France and a plastic factory in Portugal. We have identified two main use cases for both domains. For the aluminium sector, we focused on production of the anodes (positive electrodes) used in aluminium extraction by electrolysis. The first use case was targeted to predictive maintenance, where the main objective was to anticipate the breakdowns and/or highlight equipment/process deviations that affect the green anode final quality (e.g., anode density). The second use case dealt with the predictive anode quality control, where the goal was to identify bad anodes with a high level of confidence and scrap them to avoid sending them to the electrolysis area. For the plastic domain, the use cases are from the area of production of coffee capsules, produced in large quantities. In this type of production, it is important to produce the correct diameter and height of the coffee capsules and to make sure that the holes at the bottom of the capsules are formed properly. Moreover it is also expected to predict the failures of molding machines and their stoppages based on the process parameters and sensor measurements during molding processes. While the data analysis process for the plastic domain is described in Section 6.2.6, we provide a short description of main components of the MONSOON platform along with their interfaces in the next sections. 6.2.3 Plant Operational Platform The functional view of the architecture of the Plant Operations Platform is presented in Figure 6.2. It acts as an advanced semantic factory service bus and is in-charge of interacting with existing production systems deployed in a plant. The Plant Platform IT infrastructure and its associated Real-time Data Integration layer collect the operational raw data from the plant’s systems necessary to the execution of the predictive functions. The acquired operational raw data and associated relevant information is also routed to the data lab where it is stored and used for analytics. Figure 6.2 Functional View of Plant Operational Platform. 6.2.3.1 Real-time communication framework It configures the dependable real-time communication infrastructure necessary to support operations of prediction functions. The Monitoring Tools exploit and integrate existing solutions for real-time networking and QoS management and perform continuous (passive/active) monitoring of plant-wide process industry resources ensuring that communication-related malfunctions are properly detected. The Operation Data Visualization Dashboard provides a web user interface where operational managers can configure various real-time visualizations of operational data and monitor the deployed predictive functions. The visualized data can include operational data from the plant environment or predictions from the predictive functions executed in the Run-time Container. 6.2.3.2 Virtual process industries resources adapter The main function of the Virtual Process Industries Resources Adapter (VPIRA) is data integration, mediation and routing. The Connector allows the integration of data from various SCADA, MES and ERP systems deployed on the plant site. It ensures that all heterogeneous process industry resources and systems are easily accessed and managed. The Abstractor is a distributed and scalable data flow engine aiming for routing integrated data to multiple destinations, e.g., run-time container or data lab. Routing of data from the source to target connectors can be dynamic depending on the type of data or actual content. The data flows can be re-configured in a flexible way, connecting multiple sources to the multiple targets, overcoming any data heterogeneity problems. Besides the flexible configuration interface, the Virtual Process Industries Resources Adapter provide a flexible programming interface to simply implement connectors or processors for new types of data sources and formats. 6.2.3.3 Run-time container The Run-time Container executes the model based predictive functions and life-cycle management functions within the overall plant infrastructure. It ensures proper deployment and execution of predictive functions developed by means of the data lab, hence it manages all aspects of predictive functions life cycle. It is composed into four sub-components as described below: Data Orchestrator: coordinates the data flow between different components, such as transmit input data, store prediction result, and pass visualization result data to relevant components. Predictive Function: exports predictive function image from Function Repository and instantiate the execution of predictive function that perform real-time scoring of input operational data. It performs all operations required for the pre-processing of raw data into inputs for the specific predictive function and into process prediction output. Data Storage: stores the prediction results into a scalable database. The prediction results are also sent to the Operational Platform systems and the data lab for combining these real-time results with historical data analysis. Visualization Dashboard: displays prediction results and generates feedback instructions or alerts towards plant’s systems to inform/warn the site operators to adjust the process regulation parameters. 6.2.4 Cross Sectorial Data Lab Platform The Data Lab provides a collaborative environment where high amounts of data from multiple sites, and possibly from multitude of industry sectors, are collected, stored and processed in a scalable way. It enables multidisciplinary collaboration of experts allowing teams to jointly model, develop and evaluate distributed controls in rapid and cost-effective way. The Data Lab eases the definition of predictive control and life cycle management functions, allowing to work in a simulated environment or to exploit co-simulation by mixing stored data with data flowing in real-time from the real systems. The Data Lab thus supports data science and automation experts interested to optimization and scheduling aspects by providing the suitable environment to mine, process, re-play production data. It allows modelling of the whole production process across the SCADA layers including the specification of the data dictionary of all inputs and outputs of the processing steps and their relations to the overall KPIs. The semantic models capture the site knowledge base for given application cases and used data analytics methods allowing generalization of cases to existing good practices and transfer of the knowledge by adaptation of cases to new environment/site. The main outcome of the Data Lab is typically a single or multiple new predictive functions and life cycle management controls ready to be deployed in the Runtime Container of the Plant Operations Platform. Figure 6.3 Functional View of Cross Sectorial Data Lab Platform. The components of the Cross Sectorial Data Lab are shown in Figure 6.3 and explained in the sections below. 6.2.4.1 Big data storage & analytics platform The Big Data Storage and Analytics Platform provides resources and functionalities for storage as well as batch and real-time processing of the operational data from multiple site characterized as Big Data. The platform combines and orchestrates existing technologies from the Big Data and Analytic landscape and sets a distributed and scalable run-time infrastructure for the developed data analytics methods. It provides main integration interfaces between the site Operational Platform and the cloud Data Lab platform and the programming interfaces for the implementation of the data intensive analytics methods. The Big Data Storage and Analytics Platform consist of the following sub-components: Distributed Storage: provides a reliable, scalable file system with similar interfaces and semantics to access data as local file systems. Distributed Database: provides a structured view of the data stored in the platform using the standard SQL language, and supports standard RDBMS programming interfaces such as JDBC for Java or ODBC for Net platforms. Distributed Data Processing Framework: allows the execution of applications in multiple nodes in order to retrieve, classify or transform the arriving data. The framework provides Data Analytics APIs for processing large datasets via parallel and distributed computations. Data Ingestion: implements an interface for real-time communication between the Data Lab and Operation platforms. It also supports batch uploading of the historical data between the Data Lab and Operation platform. Security & Directory Service: provides user management and content authorization capabilities for the platform services. Management & Monitoring: provides the management, monitoring and provisioning of the platform services on the hosted environment. 6.2.4.2 Model development environment The Model Development Environment provides tools and interfaces that cover the whole life cycle of planning, implementation, testing, validation and deployment of predictive functions and life-cycle management controls into the plant production supporting simulation/co-simulation features. Development Tools: provide the main collaborative and interactive interface for data engineers, data analysts and data scientists to execute and interact with the data processing workflows running on the Data Lab platform. Using the provided interface, data scientists can organize, execute and share data, and code and visualize results without referring to the internal details of the underlying Data Lab run-time infrastructure. The interface is integrated in form of analytical “notebooks” where different parts of the analysis are logically grouped and presented in one document. These notebooks consist of code editors for data processing scripts and SQL queries, and interactive tabular or graphical presentations of the processed data. Semantic Modelling Framework: provides a common communication language between domain experts, stakeholders and data scientists. A collaborative web interface is provided for the creation and sharing of semantic models in order to use the knowledge expressed in such models for the optimization of the production processes in the Simulation and Resource Optimization Framework. Simulation Toolkit: supports validation and deployment of predictive functions in order to optimize overall KPIs defined for the production process. The estimation of overall impacts can be used to test various “what if” scenarios, or for the automatic discrete optimization of the production process by finding the optimal combination of predictive functions for various process phases. Resource Optimization Toolkit: optimizes the production process based on various indicators representing the performance of manufacturing process of the plant leveraging process data and knowledge extracted from analytics methods. Life-Cycle Management Plugin: serves as multi-disciplinary, transversal tool to evaluate environmental performance of a given production process for life-cycle environmental indicators, such as Global Warming Potential and Total Energy Requirement. Figure 6.4 Components Mapping to Open-source Technologies. 6.2.4.3 Function repository The Function Repository provides a storage for predictive functions together with all settings required for the deployment of predictive functions, where they are available for production deployment or for the simulations and overall optimization of the production processes. The predictive functions are packaged as container images so that entire predictive function pipeline (including pre-processing and task specific evaluation) can be implemented within a virtualized container. 6.2.5 Deployment The Data Lab Platform promises to combine and orchestrate existing technologies and open source frameworks from the Big Data landscape to establish a distributed and scalable run-time infrastructure for the data analytics methods. We present in Figure 6.4 the mapping of the platform components to existing and emerging open source technologies selected and used during the initial deployment. The initial deployment was performed with multiple virtual machines on an in-house physical infrastructure. It turned out that the overall deployment time and configuration management is the most critical aspect in realizing and operationalizing such a platform. It would be optimal to devise a uniform deployment strategy taking into account different deployment options for the platform such as on-premises, cloud/external provider or hybrid. It has also been learned that different demonstrative and use-case scenarios in both aluminium and plastic domains pose different infrastructure and data requirements. Hence, it is useful to define different deployment pipelines or modes for the platform where the right set of platform services are deployed and orchestrated accordingly instead of full stack deployment. Towards this goal, the Big Data Storage and Analytics Platform has been containerized to adapt a common deployment ground with the objective of easing the usage of common platform technologies and make integration with other services or applications easy. The containerization based on Docker framework is depicted in Figure 6.5. Figure 6.5 Containerization of Big Data Storage and Analytics Platform. The deployment of the Site Operational Platform with open source technologies mainly for Virtual Process Industries Resources Adaptor and Run-time Container is finally illustrated in Figure 6.6. It shows how predictive functions can be applied in factorial settings. Figure 6.6 Deployment view of Plant Operational Platform. 6.2.6 Data Analysis Data analysis in process industries mainly aims to reduce the wastage of time, resource and energy during production processes. This can be achieved by several means: avoiding equipment stoppages, maintaining optimum configurations, early detection of a chain of events causing an anomaly etc. Data analysis is simplified by the components of the Cross Sectorial Data Lab which provides a single platform for data fetching, accessing and artefact development. The data collected from the plastic molding machines are stored in the Big Data Storage & Analytic Platform. These data are used by the data scientists and the process experts for exploratory analysis in order to gain initial insights. The collaborative interface provided by the platform is used simultaneously by the process expert and the data scientists. The findings from the exploratory analysis is used as the basis for modelling the process leading to the development of predictive functions. These functions are stored in the Function Repository which are deployed later in factory premises for real-time predictions. Although this process is generic enough to be applied in any kind of industrial environment, we shall limit our discussion to the plastic industry. The objective of data analysis in the plastic industry is to anticipate the breakdowns and/or highlight equipment/process deviation that impacts the injection molding process and therefore to improve the quality of the produced coffee capsules. In general, there are two areas where waste parts can occur in plastic injection molding process: the molding tool and the molding process. During the long-term production of the coffee capsules, parameters of the injection molding process can slightly change due to various changes of the environment (temperature and humidity in the factory, deviations in the energy supply system, heating of oil temperature, deviations in the quality of the plastic granules, wearing of machine parts). The aim is to monitor technical parameters of the molding machine and raise an alarm if the deviation is increasing over the defined values. These long-term changes can also cause the stoppage of molding machines. Which in turn causes reduction of produced capsules. In addition, few of the initial cycles after restart are wasted during the calibration process producing defective capsules. 6.2.6.1 Data description Two kinds of data have been collected in the first year from GLN site during the production of coffee capsules. The first data set is collected automatically from a Euromap63 interface recorded on molding machines and the second data set is collected during the experiments conducted by a process expert during their visit to the production site. The first data set is unlabeled and contains sensor measurements of several coffee capsule production cycles. Each cycle lasts almost 7 seconds, except if it causes a breakdown. The data set has a total of 88 attributes representing temperatures, time taken for different stages, pressure, cylinder positions etc. All data were directly monitored by the injection molding machine and stored there. Of them, only 12 (heating belt temperatures, maximum cycle pressure, coolant temperatures, residual melt cushion, plastification time) are proposed as useful, and, particularly, their ranges/deviations over intervals instead of their values themselves are suggested to serve as explanatory variables. The second data set [1] is manually labelled and comprises information about 250 production cycles of coffee capsules from the injection molding machine and their quality information. It contains 36 attributes reflecting the machine’s internal sensor measurements for each cycle. These measurements include values about the internal states, e.g. temperature and pressure values, as well as timings about the different phases within each cycle. In addition, we also take into account quality information for each cycle, i.e., the number of non-defect coffee capsules which changes throughout individual production cycles. The quality of each capsule is inspected by the domain expert in different aspects. i.e. the capsules have permissible range of height and base diameter. Also each capsule should have uniform thickness and should not have holes. If any of these expectations are not met, the capsule is considered to be defective. If the number of produced high quality coffee capsules is larger than a predefined threshold, we label the corresponding cycle with high.quality, and otherwise we assign the label low.quality. The decision about the quality labels was made by domain experts. Exploratory analysis is performed on the unlabeled data in order to discover hidden insights. On the other hand, basic machine learning algorithms are applied to the labelled data to classify the cycles based on their quality. In the upcoming subsections we discuss these two different approaches on these data sets. 6.2.6.2 Preliminary trend analysis of unlabeled data The main aim of the preliminary analysis of is to get some initial overall insights that might be interesting for the process experts to be further analyzed. The first step was to understand the attributes and their correlations. This was followed by visual exploration of data with manual inspection followed by clustering the data to find significant relation between different cycles. Considering the huge amount of data generated by sensors, clustering usually takes lots of time. One strategy is to use the computation powers of the Data Lab clusters to perform these operations faster. If the algorithms for exploratory data analysis are deployed in the Data Lab, domain experts and data scientists can use the results simultaneously to get actionable insights. One of the insight was repeating set of parameters in the data. This was found by using matrix profiles. A pattern obtained by applying matrix profiles is the decrease in plastification time and at the same time, increase in cycle time. Plastic domain expert cross checked these patterns and found out that this happens whenever there is an equipment stoppage due to lack of lubrication. Though the characteristics of these incidents are known, early prediction of the possible stoppage has not been found out with data analysis. The corresponding patterns are shown in Figure 6.7. Figure 6.7 Increase in cycle time and decrease in plastification at the same time. The same pattern has repeated multiple times in the unlabelled set of plastic data. CycCycTim is cycle time and CycPlstTim is plastification time. Preliminary trend analysis helps us to extract the knowledge hidden in voluminous unlabelled data sets. This process can be automated to get the best results in minimum time. In addition, in the MONSOON project we include many stakeholders such as process experts, machine supervisors and ground workers to actively contribute to the production process optimization. This is achieved with the help of a centralized Big Data analytics platform. On deploying the knowledge discovery algorithms in the Big Data analytics platform, the stakeholders can give live feedbacks. The data scientists further use these feedbacks for deriving conclusions. This is an ongoing work as part of the project. 6.2.6.3 Machine learning for labelled data The goal of the machine learning process is to classify the injection molding cycles to high and low-quality cycles. As discussed earlier, the cycles are labelled as high.quality or low.quality based on the number of defective capsules produced in a cycle beyond a threshold defined by the process expert. The initial dataset is pre-processed as follows. The labelled data is first centred and scaled. Later, the number of attributes is reduced by excluding the ones with near zero variance. Principal Component Analysis is applied to the remaining attributes to get the projection of data in reduced number of dimensions. Basic classification algorithms, namely, k-Nearest Neighbour, Naïve Bayes, Classification and Regression Trees (CART), Random Forests and Support vector Machines (SVM) are investigated on the pre-processed data. SVM is investigated both with linear and RBF kernels. The performance of the models are measured in terms of balanced accuracy, precision, recall and F1 scores. K-fold cross validation is used to evaluate the performance. The number of folds is set to 5 and the number of repetitions is set to 100. We used 80% of the dataset is for training and 20% for testing. This investigation is performed via the CARET package in the programming language R. The results of our performance evaluation are summarized in Table 6.1. Table 6.1 Classification results of different predictive models Balanced Accuracy Precision Recall F1 score k-NN 0.697 0.638 0.686 0.657 Naïve Bayes 0.643 0.604 0.563 0.578 CART 0.637 0.595 0.566 0.573 Random Forest 0.653 0.619 0.570 0.589 SVM (linear) 0.632 0.626 0.488 0.540 SVM (RBF) 0.663 0.643 0.563 0.594 From the table above, we see that all predictive models reach an accuracy of minimum 63%. The highest accuracy is achieved by the k-Nearest Neighbour classifier predicting the correct quality labels for more than 69% of the data. Albeit these results were satisfying, these algorithms cannot be deployed straight away as the data used for this performance evaluation has been manually labelled by the experts. In the situations where the capsules are produced in millions per day, it is wiser to use the automatically labelled data for training the models and deploy them afterwards. One approach is to use the decision of the visual inspection systems in order to label the data. But this is not trivial since there is no one to one mapping between the optical inspection systems data and the actual cycle data. This is because multiple capsules belonging to different cycles and machines are passed to the automatic visual inspection system at once making it harder to identify individual cycles belonging to a particular machine. 6.2.7 Summary In this section, we have presented our recent research activities within the scope of the EU project MONSOON: As an example for the process industry, we have described the overall reference architecture facilitating cross-sectorial data analytics. As part of our ongoing work, we have also highlighted the analysis of sensor data arising from the plastic industry sector. In the following section, we will focus on the manufacturing industry. 6.3 Manufacturing/Discrete Industry 6.3.1 Introduction As an example for the manufacturing industry, we focus on the EU project COMPOSITION. This project addresses the requirements of modern production processes, which stress the need of greater agility and flexibility leading to faster production cycles, increased productivity, less waste and more sustainable production. At the factory level, decisions need to be supported by detailed knowledge about the production process and its interplay with external entities. Unfortunately, historical and live data that generates this knowledge is becoming more and more distributed and few solutions are available that can easily tackle the implied challenges. Moreover, factories are becoming less isolated in the productive tissue of nations and several suppliers and third-party service providers need to be contacted and coordinated to implement decisions taken at the factory level. In such a worldwide and dynamic environment, the ability of automatizing the preliminary coordination and negotiation activities involved in setting up supply chains for specific needs, in an open marketplace-like fashion, could greatly improve the ability of factories to quickly react to external challenges and driving forces. 6.3.2 Intra-factory Interoperability Layer Part of the COMPOSITION Architecture In this chapter, we will address the COMPOSITION architecture in the data analytics context. The intra-factory interoperability layer has two main goals: the first one is to provide an infrastructure to combine distributed data in the integrated information management system and to do data analytics, the second one is to ensure the conformity between communications among interconnected components. Figure 6.8 shows the relevant part of the architecture. Figure 6.8 Intra-factory interoperability layer components and dependencies. The components of the architecture are introduced and described in the following: The BMS is provided by a project development stakeholder and is the translation layer providing shop floor connectivity from sensors to the COMPOSITION system. Raw data storage is added for oﬄine debug purposes. The Middleware is the main recipient in which the interoperability of single components act. LinkSmart is a well-known middleware solution per se and is customized to satisfy the requirements of the COMPOSITION project. LinkSmart comprises the following components: The Service Catalog works as service index and provides security information for service intercommunication. The Event Aggregator parses messages to ensure homogeneity in data streams. Keycloak is a virtual layer that ensures authorization and authentication. Like all security related measures, it is deployed by the Security Framework. The broker-based intra-factory communication system manages all internal communication. The Big Data Analytics component provides Complex Event Processing (CEP) capabilities for the data provided by the intra-factory integration layer The Hidden Storage is an optional storage not accessible from the outside in which aggregated data are stored for debug purposes, i.e. re-bootstrapping already trained artificial neural networks belonging to the Deep Learning Toolkit and to the Dynamic Reasoning Engine. The Visual Analytics component is the reporting interface of the Decision Support System and Simulation and Forecasting Toolkit. The Dynamic Reasoning Engine is part of the Simulation and Forecasting Toolkit. The Decision Support System uses process models to guide the production process. Having a fist overview of the components of the COMPOSITION project and their dependencies, we continue with describing our approach to smart data analysis in the following section. 6.3.3 The Complex-Event Machine Learning methodology Manufacturing in assembly lines consist of a set of hundreds, thousands or millions of small discrete steps aligned in a production process. Automatized production processes or production lines thereby produce for each of those steps small bits of data in form of events. Although the events possess valuable information, this information loses its value over time. Additionally, the data in the events usually are meaningless if they are not contextualized, either by other events, sensor data or process context. To extract most value of the data, it must be processed as it is produced, to be more precise in real-time and on demand. Therefore, in case of Big Data Analyses we propose the usage of Complex-Event Processing for the data management coming from the production facilities. In this manner, the data is processed in the moment when it is produced, extracting the maximum value, reducing latency, providing reactivity, giving it context and avoiding the need of archiving unnecessary data. The Complex-Event Processing service is provided by the LinkSmart® Learning Agent (LA). The LA is a Stream Mining service that provides the utilities to manage real-time data for several purposes. On the one hand, the LA provides a set of tools to collect, annotate, filter, aggregate, or cache the real-time data incoming from the production facilities. This set of tools facilitates the possibility to build applications on top of real-time data. On the other hand, the LA provides a set of APIs to manage the real-time data lifecycle for continuous learning. Moreover, the LA can process the live data to provide complex analysis creating real-time results for alerting or informing about important conditions in the factory, that may be not be seen at first glance. Finally, the LA allows the possibility to adapt to the productions needs during the production process. The Complex-Event Machine Learning (CEML) [2] is a framework that combines Complex-Event Processing (CEP) [3] and Machine Learning (ML) [4] applied to the IoT. This means that the framework was developed to be deployed everywhere, from the edge of the network to the cloud. Furthermore, the framework can manage itself and works autonomously. The following section briefly describes the different aspects that CEML covers. The framework must automate the learning process and the deployment management. This process can be broken down in different phases: (1) the data must be collected from different sensors, either from the same device or in a local network. (2) The data must be pre-processed for attribute extraction. (3) The learning process takes place. (4) The learning must be evaluated. (5) When the evaluation shows that the model is ready, the deployment must take place. Finally, all these phases happen continuously and repetitively, while the environment constantly changes. Therefore, the model and the deployment must adapt as well. 6.3.3.1 Learning agents architecture We utilize LinkSmart® LA following a modular architecture with loosely coupled modules responsible for different tasks. Figure 6.9 illustrates the architecture of the LA. The data and commands come via communication protocols implemented by Connectors (Figure 6.9 shows two example implementations, REST and MQTT). The connectors transfer the information to the Feeders, which process the data accordingly to the API logic. This logic depends on whether it is an insertion of new raw data, request of simple data processing (statement) or a machine learning request (CEML request). The data is inserted into the execution environment (in this case EsperEngine [1]), while the data processing requests are deployed in the same engine for the processing of the raw data. The CEML request has a more complex behaviour. Each CEML request is managed by its own CEMLManager, which contains and coordinates the model(s), evaluator for each model, and several statements. Finally, all output of any process (Statement) in the execution pipeline (EsperEngine) is captured or managed by a Handler. If the process should be prepared and sent through a communication protocol, then it will be handled by a Complex-Event Handler: An Asynchronous Handler, if the protocol is asynchronous (e.g. MQTT); or Synchronous Handler, if the protocol is synchronous (e.g. HTTP). [1] Esper is an open-source Java-based software product for Complex event processing (CEP) and Event stream processing (ESP) that analyzes series of events for deriving conclusions from them. See http://www.espertech.com/ Figure 6.9 LinkSmart® Learning Service Architecture sketch. 6.3.3.2 Data propagation phase Data in the IoT is produced in several places, protocols, formats, and devices. Although this article does not address the problem of data heterogeneity in detail, the learning agents require a mechanism to acquire and manage the heterogeneity of the data. The mechanism must be scalable and, at the same time, the protocol should handle the asynchronous nature of IoT. Finally, the protocol must provide tools to handle the pub/sub characteristics of the CEP engines. Therefore, we have chosen MQTT [2], a well-established Client Server publish/subscribe messaging transport protocol. The topic based message protocol provides a mechanism to manage the data heterogeneity by making a relation between topics and payloads. It allows deployments in several architectures, OS, and hardware platforms; basic constraints at the edge of the network. The protocol is payload agnostic and as such allows for maximum flexibility to support several types of payloads. [2] MQTT is a machine-to-machine (M2M)/“Internet of Things” connectivity protocol. Source http://mqtt.org/ 6.3.3.3 Data pre-processing (munging) phase Usually ML is tied to stored datasets, which incurs several drawbacks. Firstly, the learning can take place only with persistent data. Secondly, usually the models generated are based on historical data, not current data. Both constrains, in the IoT, have direct consequences. It is neither feasible nor profitable to store all data. In addition, embedded devices do not have much storage capacity, which makes it impossible to use ML algorithms on them. Furthermore, IoT deployments are commonly exposed to ever-changing environments. Using historical data for off-line learning could cause outdated models to learn old patterns rather than current ones, producing drifted models. Although some IoT platforms like COMPOSITION support storage of historical data, it may be too time and space consuming to create large enough times series. Therefore, there is also a need for non-persistence manipulation tools. This is precisely what the CEP engine provides in the CEML framework. This means, the CEP engine decides which data and how the data is manipulated using predefined CEP statements deployed in the engine. Each statement can be seen as a topic, to which each learning model is subscribed. Any update of the subscribers provides a sample to be learnt in the learning phase. 6.3.3.4 Learning phase There is no pre-selection of algorithms in the framework. They are selected by the restrictions imposed by the problem domain. For example, in extreme constrained devices, algorithms such as Algorithm Output Granularity (AOG) [5] may be the right choice. In other cases where the model changes quickly, one-shot algorithms may be the best fit. Artificial Neural Networks are good for complex problems but only with stable phenomena. This means that the algorithm selection should be made case-by-case. Our framework provides mechanisms for the management and deployment of the learning models, and the process of how the model is fed with samples. In general, the process is based on incremental learning [6] albeit with online and non-persistent data. The process can be summarized as follows: the samples, without the target provided in the last phase, are used to generate a prediction. The prediction will then be sent to the next phase. Thereafter, the sample is applied to update the model. Thus, all updates are used for the learning process. 6.3.3.5 Continuous validation phase This section describes how the validation of the learning models is done inside the CEML. This phase does not influence the learning process nor validate the CEML framework itself. ML model validation is a challenging topic in real-time environments and the evaluation for distributed environments or embedded devices is not addressed extensively in the literature, which is why we think it needs further research. There are two addressed strategies. Either we holdout an evaluation dataset by taking a control subset for given time-frame (time window), or we use Predictive Sequential, also known as Prequential [7], in which we assess each sequential prediction against the observation. The following section describes the continuous validation we applied for a classification problem, even though it can be applied for other cases as well. Instead of accumulating a sample for validation, we analyse the predictions made before the learning takes place. All predictions are assessed each time an update arrives. The assessment is an entry for the confusion matrix [8], which is accumulated in an accumulated confusion matrix. The matrix contains the accumulation of all assessed predictions done before. In other words, the matrix does not describe the current validation state of the model, but instead the trajectory of it. Using this matrix, the accumulated validation metrics (e.g. Accuracy, Precision, Sensitivity, etc.) are being calculated. This methodology does have some drawbacks and advantages, explained more extensively in [9]. 6.3.3.6 Deployment phase The continuous validation opens the possibility for making an assessment of the status of the model each time a new update arrives, e.g. if it is accrued or not. Using this information, the CEML framework has the capability to decide if the model should or should not be deployed into the system at any time. If the model is behaving well, then it should be deployed, otherwise it should be removed from the deployment. The decision is made by user-provided thresholds w.r.t. evaluation metrics. If a threshold is reached, the CEML inserts the model into the CEP engine and starts processing the streams using the model. Otherwise, if the model do not reach the threshold, it is removed from the CEP engine. 6.3.3.7 Assessment In [6] 13 issues for learning in the IoT where left open. The CEML framework addresses 10 out of the 13 challenges as follows: Handling the continuous flow of data streams: This is done by the stream statements inside the CEP engine using continuous streams for learning an evaluating. Unbounded memory requirements: The use of CEP engines in stream windows allows the intelligent usage of the memory as is needed, dropping it otherwise. Transferring data mining results over a wireless network with limited bandwidth: This is partially handled. MQTT is a reliable low-bandwidth lightweight protocol developed for satellite monitoring of pipelines. Nevertheless, this paper does not address the physical layer. Modelling changes of mining results over time: The CEML is a continuous automatic learning mechanism. The learning models will adjust as they learn. Interactive mining environment to satisfy user requirements: The IoT Learning agent provide an REST API. Thus, update the learning request is possible, as well as, obtaining live or on-demand updates. Integration between data-stream management systems and ubiquitous data-stream mining approaches: The CEML provides a REST API for managing each kind of request independently. Thus, the learning request can be managed as a whole, including the involved streams. Besides, the streams can be managed individually as single stream statement. Additionally, the MQTT API provides a multi-cast API so that in distributed multi-agent deployment, the agents can be managed as one, as groups, or as one entity. The relationship between the proposed techniques and the needs of real-world applications: Legal, ethical and technical reasons are part of the motivation. E.g. the storage constrains or the legal constraints in the health domain. Data pre-processing in the stream-mining process: This is handled in the pre-processing phase of the CEML. The technological issue of mining data streams: The implementation presented here shows that the system behaves in a real-time environment. The formalization of real-time accuracy evaluation: This is addressed by the Double-Tumble-Window Evaluation. In addition to the Complex-Event Machine Learning approach based on the open-source IoT platform LinkSmart, we also describe another approach carried out in the scope of the project COMPOSITION in the next section. 6.3.4 Unsupervised Anomaly Detection in Production Lines In addition to the previously introduced framework, which primarily allows for an exploitation of supervised machine learning algorithms, this chapter focuses on an alternative unsupervised approach that was also implemented in the scope of the project COMPOSITION. This method was used as a further extension to optimize the detection of machine errors in production lines at early stages. In the last couple of years, the importance of cyber-physical systems in order to optimize industry processes, has led to a significant increase of sensorized production environments. Data collected in this context allows for new intelligent solutions to e.g. support decision processes or to enable predictive maintenance. One problem related to the latter case is the detection of anomalies in the behaviour of machines without any kind of predefined ground truth. This fact is further complicated, if a reconfiguration of machine parameters is done on-the-fly, due to varying requirements of multiple items processed by the same production line. As a consequence, a change of adjustable parameters in most cases directly leads to divergent measurements, even though those observations should not be regarded as anomalies. In the scope of the project COMPOSITION, the task of detecting anomalies for predictive maintenance within historical sensor data from a real reflow oven was investigated. While the oven is used for soldering surface mount electronic components to printed circuit boards based on continuously changing recipes, one related problem was the unsupervised recognition of potential misbehaviours of the oven resulting from erroneous components. The utilized data set comprises information about the heat and power consumption of individual fans. Apart from additional machine parameters like a predefined heat value for each section of the oven, it contains time-annotated sensor observations and process information recorded over a period of more than seven years. As one solution for this problem, we will present our approach named Generic Anomaly Detection for Production Lines, short GADPL. The hereafter-presented description of GADPL is based on the stage-wise implementation of the algorithm. After an initial clustering of similar input parameters and a consecutive segmentation, we will discuss the representation of individual segments and the corresponding measurement of dissimilarity. 6.3.4.1 Configuration clustering In many companies, as well as in the case of the project COMPOSITION, a single production line is often used to produce multiple items according to different requirements. Those requirements are in general defined by varying machine configurations consisting of one or more adjustable parameters, which are changed ‘on-the-fly’ during runtime. For a detection of deviations with respect to some default behaviour of a machine, this fact raises the problem of invalid comparisons between sensor measurements of dissimilar configurations. If a measurement or an interval of measurements is identified as an anomaly, it should only be considered as such, if this observation is related to the same configuration as observations representing the default behaviour. Therefore in advance to all subsequent steps, at first all sensor measurements have to be clustered according to their associated configuration. For the sake of simplicity, we are only discussing the process within a single cluster in the following subsections, although one has to keep in mind that each step is done in parallel for all clusters. 6.3.4.2 Segmentation As a result of the configuration-based clustering, the data is already segmented coarsely. However, since this approach describes unsupervised anomaly detection, the idea of a further segmentation is to create some kind of ground truth, which reflects the default behaviour of a machine. In this section, we will see how the segmentation is utilized to implement this idea. In an initial step, a maximum segmentation length is defined, in order to specify the time horizon, after which an anomaly can be detected. Assuming a sampling rate of 5 mins per sensor, the maximum length of a segment would consequently be (60 × 24)/5 = 288 to describe the behaviour on a daily basis. Although a decrease of the segment length implies a decrease of response time, it also increases the computational complexity and makes the detection more sensitive to invalid sensor measurements. In this context, it needs to be mentioned that in this stage segments are also spitted, if they are not continuous with respect to time as a result of missing values. Another fact that has to be considered is the transition time of configuration changes. While the input parameters associated with a configuration change directly, the observations might adapt more slowly and therefore blur the expressiveness of the new segment. To prevent this from happening, the transition part of all segments, which have been created due to configuration changes, is truncated. If segments become smaller than a predefined threshold, they can be ignored in the upcoming phases. 6.3.4.3 Feature extraction Having a set of segments for each configuration, the next step is to determine the characteristics of all segments. While the literature presents multiple approaches to describe the behaviour of time series, we will focus on common statistical features extracted from each segment. Nonetheless, the choice of features is not fixed, which is why any feature suitable for the individual application scenario can be used. One example for rather complex features could be the result of a kernel fitting in the context of Gaussian processes, accepting a decrease in performance. Since the goal is to capture comparable characteristics of a segment, we compute different real-valued features and combine them in a vectorised representation. In the case of the project COMPOSITION, we used the mean to describe the average level, the variance as a measure of fluctuation and the lower and upper quartiles as a coarse distribution-binning of values. Due to the expressiveness of features being dependent from the actual data, one possible way to optimize the selection of features is the Principal Component Analysis. Simply using a large number of features to best possibly cover the variety of characteristics might have a negative influence on the measurement of dissimilarity. The reason for this is the partial consideration of irrelevant features within distance computations. Moreover, since thresholds could be regarded as a more intuitive solution compared to additionally extracted features, this replacement would lead to a significant decrease in the number of recognized anomalies. Apart from the sensitivity to outliers, the reason is a neglect of the inherent behaviour of a time series. As an example, consider the measurements of an acoustic sensor attached to a motor that recently is sending fluctuating measurements, yet within the predefined tolerance. Although the recorded values are still considered as valid, the fluctuation with respect to the volume could already indicate a nearly defect motor. Finally, one initially needs to evaluate appropriate thresholds for any parameter of each configuration. 6.3.4.4 Dissimilarity measurement So far, we have discussed the exploitation of inherent information, extracted from segmented time series. The final step of GADPL is to measure the level of dissimilarity for all obtained representatives. Since no ground truth is available to define the default behaviour for a specific configuration, the algorithm uses an approximation based on the given data. One problem in this regard is the variability of a default behaviour, consisting of more than one pattern. Therefore, a naive approach as choosing the most occurring representative, would already fail for a time series consisting of two equally appearing patterns captured by different segments, where consequently half of the data would be detected as anomalous behaviour. As one potential solution GADPL instead uses the mean over a specified size of nearest neighbours, depicting the most similar behaviour according to each segment. The idea is that even though there might multiple distinct characteristics in the data, at least a predefined number of elements represent the same behaviour compared to the processed item. Otherwise, this item will even have a high average dissimilarity with respect to the most similar observations and can therefore be classified as anomaly. Here, for the vectorised feature representations, any suitable distance function is applicable. In the context of the project COMPOSITION we decided to use the Euclidean distance for a uniform distribution of weights, applied to normalized feature values. To further increase the performance of nearest neighbour queries, we exploited the R*-tree as a high-dimensional index structure. Given the dissimilarity for each individual representative together with a predefined anomaly threshold, GADPL finally emits potential candidates having an anomalous behaviour. Figure 6.10 Example application of GADPL. The application of GADPL is illustrated in Figure 6.10. The upper part shows the segmentation of time annotated power consumption data in percent. The lower part illustrates the result of the dissimilarity measurement, where the red rectangle indicates classified anomalies. 6.3.5 Summary In this section, we have presented our recent research activities within the scope of the EU project COMPOSITION. As an example for the manufacturing industry, we have briefly described the COMPOSITION architecture along with one of its main components: the open-source IoT platform Link-Smart. As part of our ongoing work, we have also described our corresponding research activities regarding the analysis of sensor data from manufacturing industry. 6.4 Summary and Conclusions In this work, we have given insights into our recent research activities with regard to the domains of Smart Data and Industrial Internet of Things. To this end, we have focused on the EU projects MONSOON and COMPOSITION as examples for the Public-Private Partnership (PPP) initiatives Factories of the Future (FoF) and Sustainable Process Industry (SPIRE). We have shown two different but conceptually similar architectures for scalable and agile data analytics. In addition, we have provided an overview of our recent Smart Data activities and have exemplified ongoing data-driven analysis of industrial production processes from the process and manufacturing industries. We conclude that data-driven investigations, either applied in process industry or manufacturing industry, require a solid platform for handling data analytics at scale. The proposed architecture of the Cross Sectorial Data Lab in combination with the open-source IoT platform LinkSmart seem to be promising developments, which are applicable to any industrial sector. Acknowledgements The projects underlying this work have received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement No 723650 (MONSOON) and grant agreement No 723145 (COMPOSITION). This work reflects only the authors’ views and the commission is not responsible for any use that may be made of the information it contains. References C. Beecks, S. Devasya and R. Schlutter, “Data Mining and Industrial Internet of Things: An Example for Sensor-enabled Production Process Optimization from the Plastic Industry,” International Conference on Industrial Internet of Things and Smart Manufacturing (accepted), 2018. J. Á. Carvajal Soto, M. Jentsch, D. Preuveneers und E. Ilie-Zudor, “CEML: Mixing and Moving Complex Event Processing and Machine Learning to the Edge of the Network for IoT Applications,” Proceedings of the 6th International Conference on the Internet of Things, pp. 103–110, 2016. D. Bonino, J. A. Carvajal Soto, M. T. Delgado Alizo, A. Alapetite, T. Gilbert, M. Axling, H. Udsen und M. Spirito, “Almanac: Internet of things for smart cities,” 2015 3rd IEEE International Conference on Future Internet of Things and Cloud (FiCloud), pp. 309–316, 2015. Google Scholar G. Cugola und A. Margara, “Processing flows of information: From data stream to complex event processing,” ACM Computing Surveys (CSUR), p. 15, 2012. Google Scholar C. Andrieu, N. De Freitas, A. Doucet und M. I. Jordan, “An introduction to MCMC for machine learning,” Machine learning, pp. 5–43, 2003. Google Scholar M. M. Gaber, S. Krishnaswamy und A. Zaslavsky, “Advanced Methods for Knowledge Discovery from Complex Data,” On-board Mining of Data Streams in Sensor Networks, pp. 307–335, 2005. N. A. Syed, S. Huan, L. Kah und K. Sung, “Incremental learning with support vector machines,” Citeseer, 1999. Google Scholar A. P. Dawid, “Present position and potential developments: Some personal views: Statistical theory: The prequential approach,” Journal of the Royal Statistical Society. Series A (General),pp. 278–292, 1984. Google Scholar G. J. Vachtsevanos, I. M. Dar, K. E. Newman und E. Sahinci, “Inspection system and method for bond detection and validation of surface mount devices.” USA Patent 5,963,662, 1999. 7. IoT European Security and Privacy Projects: Integration, Architectures and Interoperability Enrico Ferrera1, Claudio Pastrone1, Paul-Emmanuel Brun2, Remi De Besombes2 , Konstantinos Loupos3 , Gerasimos Kouloumpis3, Patrick O’ Sullivan3, Alexandros Papageorgiou3, Panayiotis Katsoulakos3, Bill Karakostas4, Antonis Mygiakis5, Christina Stratigaki5, Bora Caglayan6, Basile Starynkevitch7, Christos Skoufis8, Stelios Christofi8, Nicolas Ferry9, Hui Song9, Arnor Solberg10, Peter Matthews11, Antonio F. Skarmeta12, José Santa12, Michail J. Beliatis13, Mirko A. Presser13, Josiane X. Parreira14, Juan A. Martínez15, Payam Barnaghi16, Shirin Enshaeifar16, Thorben Iggena17, Marten Fischer17, Ralf Tönjes17, Martin Strohbach18, Alessandro Sforzin19, Hien Truong19, John Soldatos20, Sofoklis Efremidis20, Georgios Koutalieris21, Panagiotis Gouvas22, Juergen Neises23, George Hatzivasilis24, Ioannis Askoxylakis24, Vivek Kulkarni25, Arne Broering25, Dariusz Dober26, Kostas Ramantas27, Christos Verikoukis28, Joachim Posegga29, Domenico Presenza30, George Spanoudakis31, Danilo Pau32, Erol Gelenbe33,34, Sławomir Nowak34, Mateusz Nowak34, Tadeusz Czachórski34, Joanna Domańska34, Anastasis Drosou35, Dimitrios Tzovaras35, Tommi Elo36, Santeri Paavolainen36, Dmitrij Lagutin36, Helen C. Leligou37, Panagiotis Trakadas37 and George C. Polyzos38 1Istituto Superiore Mario Boella, Italy 2AIRBUS CyberSecurity, France 3INLECOM Systems Ltd, United Kingdom 4VLTN BVBA, Belgium 5CLMS Hellas, Greece 6IBM Ireland Ltd, Ireland 7Basile Starynkevitch, CEA, France 8EBOS Technologies Ltd, Cyprus 9SINTEF, NO 10TellU, NO 11CA Technologies, SP 12Department of Information and Communication Engineering, University of Murcia, Spain 13Department of Business Development and Technology, Aarhus University, Denmark 14Department of Corporate Technology, SIEMENS, Austria 15Odin Solutions S.L, Spain 16Department of Electrical and Electronic Engineering, University of Surrey, United Kingdom 17University of Applied Sciences Osnabrück, Germany 18AGT International, Germany 19NEC Laboratories Europe, Germany 20Athens Information Technology, Greece 21Intrasoft International, Luxembourg 22UBITECH LTD, Greece 23FUJITSU Europe, Germany 24Foundation for Research and Technology – Hellas (FORTH), Greece 25Siemens AG, Germany 26BlueSoft SP. z o.o., Poland 27Iquadrat, Spain 28Telecommunications Technological Centre of Catalonia (CTTC), Spain 29University of Passau, Germany 30Engineering Ingegneria Informatica S.p.A., Italy 31Sphynx Technology Solutions AG, Switzerland 32ST Microelectronics Srl., Italy 33Imperial College London, Great Britain & IITiS PAN, Poland 34IITiS PAN, Poland 35ITI-CERTH, Thessaloniki, Greece 36Aalto University, Finland 37Synelixis Solutions S.A., Greece 38Athens University of Economics and Business, Greece Abstract The chapter presents an overview of the eight that are part of the European IoT Security and Privacy Projects initiative (IoT-ESP) addressing advanced concepts for end-to-end security in highly distributed, heterogeneous and dynamic IoT environments. The approaches presented are holistic and include identification and authentication, data protection and prevention against cyber-attacks at the device and system levels. The projects present architectures, concepts, methods and tools for open IoT platforms integrating evolving sensing, actuating, energy harvesting, networking and interface technologies. Platforms should provide connectivity and intelligence, actuation and control features, linkage to modular and ad-hoc cloud services, The IoT platforms used are compatible with existing international developments addressing object identity management, discovery services, virtualisation of objects, devices and infrastructures and trusted IoT approaches. 7.1 BRAIN-IoT 7.1.1 BRAIN-IoT Project Vision In line with the optimistic forecasts released in last years, Internet of Things (IoT) products and services are being more and more deployed in mass-market and professional usage scenarios, becoming a reality in our day-by-day life. Commercial and pilot deployments world-wide are progressively demonstrating the value of IoT solutions in real conditions, but also rising some concerns with respect to dependability, security, privacy and safety constraints. The IoT technology and market landscape will become increasingly complex in the longer term i.e. 10+ years from now, especially after IoT technologies will have proven their full potential in business-critical and privacy-sensitive scenarios. An important shift is expected to happen as technology evolutions will allow to safely employ IoT systems in scenarios involving actuation and characterized by stricter requirements in terms of dependability, security, privacy and safety constraints, resulting in convergence between IoT and Cyber Physical Systems (CPS). Attracted by the trend, several organizations have started studying how to employ IoT systems also to support tasks involving actuation and control in business-critical conditions, resulting in a demand for more dependable and “smart” IoT systems. However, in order to turn such vision in reality, many issues must still be faced, including: Heterogeneity and (lack of) interoperability: a wide number of IoT platforms exist on the market, both cloud-based and locally hosted. Standardization and open-source initiatives are facilitating convergence among available platforms, which now employ similar usage patterns and increasingly converging sets of protocols, APIs, device models and data interchange formats. Nevertheless, full interoperability across platform still needs to be tackled on a case by case, platform by platform basis, due the wide amount of possible applications, design choices, customization options, formats and configurations that can be adopted by IoT developers and adopters. Difficulty of implementing “Smart Behaviours” in open collaboration context: while Machine Learning (ML) and Artificial Intelligence (AI) techniques are rapidly evolving to provide smart behaviours and solutions to increasingly complex problems, it is intrinsically difficult to generically “bind” such solutions to generic concrete IoT and CPS platforms and to make them collaborate for common tasks, since possible interactions between platforms remain unforeseen a priori. Security and safety: the distributed nature of IoT makes enforcement of good security practices intrinsically challenging. The market asks for IoT solutions suitable to safely support business-critical tasks, which can be deployed rapidly and with low costs. The emerging availability of actuation features in IoT systems calls for stricter security requirements. Nevertheless, many of today’s IoT-based products are implemented with low awareness of potential security risks. As a result, many IoT products lack even basic, state-of-the-art security mechanisms, resulting in critical effects when such flaws deployed to mass-market scenarios. Enforcement of Privacy and Data Ownership policies: as IoT products are increasingly purchased and deployed by corporate and private users in their homes, work places, factories and commercial areas, privacy issues and violations become more frequent. While policies are quickly catching up by enforcing a suitable framework of rules within the EU, a comprehensive solution able to give back control of privacy aspects to users is still missing – creating significant issues when unaware users accept that their data is moved in foreign countries, outside the safe shield provided by EU regulations. Business models colliding with long-term resilience and survivability of IoT services: many IoT solutions on the market adopt fully centralized, cloud-oriented approaches. This is often done e.g. to ensure that customers’ devices are forced to use forever a single commercial back-end service. Such lock-in approaches create artificial monopolies, negatively affecting user rights and the overall market competitiveness. This practice introduces singular point of failures in IoT systems, making survivability and resiliency features difficult to be granted in the long term, therefore sometimes resulting in negative experiences for end users. Market Fragmentation and incumbency of large players: the current market of IoT platform solution is still affected by fragmentation among the many IoT platforms available each focused in specific application domain or associated technology stacks. Moreover, some market segments (i.e. the cloud-based IoT platforms market) are notably dominated by few dominant players – often based outside the EU, thus hampering the potential business opportunities for EU companies. While EU-based initiatives and policies are doing significant amount of work to tackle such issues, often with very positive results, solutions suitable to tackle challenges arising for futuristic IoT usage scenarios are still missing. Future critical issues may be hiding under the hood already now and be ready to appear in the close future, putting at stake user acceptance and the credibility of the whole eco-system of IoT solutions vendors, integrators and adopters and hindering wider adoption of IoT solutions in potentially valuable markets. 7.1.2 Objectives In order to tackle the aforementioned challenges, the BRAIN-IoT (model-Based fRamework for dependable sensing and Actuation in INtelligent decentralized IoT systems) project focuses on complex scenarios, where actuation and control are cooperatively supported by populations of heterogeneous IoT systems. In such a complex context, many initiatives fall into the temptation of developing new IoT platforms, protocols, models or tools aiming to deliver the ultimate solution that will solve all the IoT challenges and become “the” reference IoT platform or standard. Instead, usually they result in the creation of “yet-another” IoT solution or standard. BRAIN-IoT will establish the principle that future IoT applications should never be supported by a single, unique, irreplaceable IoT platform. Rather future IoT services should exist within a federated/evolving environment that not only leverages current Industry Standards but is also capable of adapting to embrace future unforeseen industry developments. BRAIN-IoT aims at demonstrating that the lack of a single IoT standard and platform, which is generally recognized as the most notable weakness of IoT, can be turned into a strength and a guarantee for market competitiveness and user protection – if the proper framework for IoT dynamicity, security and privacy is in place. The breakthrough targeted by BRAIN-IoT is to establish a practical framework and methodology suitable to enable smart cooperative behaviour in fully de-centralized, composable and dynamic federations of heterogeneous IoT platforms. BRAIN-IoT builds on model-based approaches and open industry standards and aims at supporting rapid development and deployment of applications and services in professional usage scenarios characterized by strict constraints in terms of dependability, safety, security and privacy. The BRAIN-IoT vision is realized through seven Technical Objectives (TOs), as described in Table 7.1. Table 7.1 BRAIN-IoT technical objectives Technical Objective (TO) Description TO1: to enforce interoperability across heterogeneous IoT devices autonomously cooperating in complex tasks. BRAIN-IoT approach to interoperability is based on the adoption of shared semantic models, dynamically linked to concrete IoT devices (sensors, actuators, controls, etc.) operating autonomously in complex scenarios. Binding of models to concrete implementations leverages mapping to open industry standards for semantic device description. TO2: to enable dynamic smart autonomous behaviour involving actuation in IoT scenarios Building upon shared models (TO1) BRAIN-IoT facilitates the deployment of smart cooperative behaviour, realized by means of modular AI/ML features which can be dynamically deployed to heterogeneous IoT devices in mixed edge/cloud IoT environments. Smart behaviour features are enriched by distributed data processing, federated learning, virtualization/aggregation of data/events/objects, resolution of mixed-criticality situations and conflicts, verification and context-aware self-adaptation of connectivity and real-time event-oriented, reactive approaches. TO3: to enable the emergence of highly dynamic federations of heterogeneous IoT platforms able to support secure and scalable operations for future IoT use cases This is achieved by leveraging fully de-centralized peer-to-peer approaches providing linkage between modular, ad-hoc IoT self-hosted and cloud-based services through existing open standards. TO4: to establish Authentication, Authorization and Accounting (AAA) in dynamic, distributed IoT scenarios BRAIN-IoT introduces a holistic end-to-end trust framework for IoT platforms suitable to be employed in scenarios characterized by strict security and safety requirements, associated with actuation and semi-autonomous operations, and by special needs for secure identification, authentication of data and devices, encryption, non-deniability, as well as detection of cyber-attacks and protection against them. This is done by adopting established security protocols, joint with distributed security approaches derived by peer-to-peer systems e.g. block-chain. TO5: to provide solutions to embed privacy-awareness and privacy control features in IoT solutions BRAIN-IoT develops new patterns for interaction between users and IoT solutions, leveraging semantic mapping of privacy requirements towards data and service models in use in each specific use case, introducing privacy-related APIs and models. This enables the possibility to programmatically inform users about privacy policies in place, as well as enabling them to exercise fine-grained privacy controls. TO6: to facilitate rapid model-based development and integration of interoperable IoT solutions supporting smart cooperative behaviour BRAIN-IoT provides tools to ease rapid prototyping (development, integration) of smart cooperative IoT systems. This is achieved by extending available tools for development, integration, commissioning and management of IoT and Cyber-Physical systems. TO7: to enable commissioning and reconfiguration of decentralized IoT-based applications BRAIN-IoT enables end-users to dynamically commission and reconfigure their modular IoT instances, choosing among the available platforms, modules implementations and services. This is achieved by extending existing open marketplace of IoT services and data jointly with available catalogues providing open IoT enablers and integrating them with its federation framework. Figure 7.1 The high-level BRAIN-IoT concept. 7.1.3 Technical Approach The overall BRAIN-IoT concept is depicted in Figure 7.1 following the reference model proposed by Recommendation ITU-T Y.2060. BRAIN-IoT looks at heterogeneous IoT scenarios where instances of IoT architectures can be built dynamically combining and federating a distributed set of IoT services, IoT platforms and other enabling functionalities made available in marketplaces and accessible by means of open and standard IoT APIs and protocols. At the bottom of the conceptual architecture, the IoT Devices and Gateways layer represents all physical world IoT devices with sensing or actuating capabilities, computing devices and includes complex subsystems such as autonomous robots and critical control devices. It is worth observing that BRAIN-IoT specifically aims to support the integration into an IoT environment of devices and subsystems with actuation features that could possible give rise to mixed-criticality situations and require the implementation of distributed processing approaches. The BRAIN-IoT Management capabilities includes all the features needed to support the envisioned fully decentralized scenario dynamically integrating heterogeneous IoT Devices and Gateways as well as: IoT Services – third party services accessible through open interfaces and offering data or various functionalities including data storage, data statistics and analytics, data visualization; IoT Platforms – instances of open IoT platforms whose configuration and functionalities can be dynamically updated; IoT Modules – enabling functionalities (e.g., smart control features, data processing, data storage) that can be associated to a specific IoT platform instance and composed in order to meet given functional requirements. Concerning the IoT Modules, the ones supporting smart control features are particularly relevant for the BRAIN-IoT challenging scenarios encompassing heterogeneous sensors and actuators autonomously cooperating in complex, dynamic tasks, possibly across different IoT Platforms. BRAIN-IoT will then develop a library of IoT modules implementing algorithms promoting collaborative context-based behaviours, control solutions based on Machine Learning Control, real-time data analysis and knowledge extraction techniques. Concerning the IoT Platforms, BRAIN-IoT will support different existing IoT solutions including e.g., FIWARE and SOFIA. All the above IoT building blocks can be described by a set of open and extendable vocabularies as well as semantic and behavioural models. This actually allows moving forward an easier, automated and dynamic integration within the BRAIN-IoT environment of new and existing IoT Services, Platforms and Modules available for traditional IoT applications. In fact, BRAIN-IoT defines a new meta-language, namely the IoT Modelling Language (IoT-ML), which uses the above set of vocabularies and models to formally describe an IoT Instance i.e., how a given set of IoT services and Platforms are interconnected with each other and federated and which IoT Modules are associated to the considered IoT Platforms. IoT-ML will base on existing solutions provided by OMG and W3C. The Decentralized IoT Instances management is instead in charge of offering the capabilities needed to support the dynamic composition of a given set of IoT building blocks into a specific IoT Instance. The vision is to progress from the fog computing paradigm and create distributed IoT Micro-cloud environments hosting IoT Platforms and IoT Modules and advertising their runtime capabilities. The resulting Micro-cloud environments are enhanced with management capabilities that allow search and discovery operations and their dynamic federation to form a specific IoT instance. These capabilities pave the way toward highly dynamic scenarios where IoT Modules and relevant functionalities can be composed and migrated runtime from one IoT Platform to another, complex tasks can be dynamically distributed between the edge and the cloud IoT Platforms depending on variable requirements and where IoT Instances can be fully reconfigured adding/removing runtime new IoT building blocks from the federation. BRAIN-IoT will also provide peculiar management strategies and techniques permitting the dynamic deployment/transfer of Smart Control IoT Modules across mixed edge and cloud environments. The Decentralized IoT Instances management also handles advanced IoT Instances configurations, properly orchestrating external IoT services with other IoT building blocks active in the resulting BRAIN-IoT fog environment. Finally, monitoring components allow to continuously supervise the overall IoT Instance and relevant composite application. In this way, it is possible to check the status of the federated building blocks, provide alerting, reporting and logging mechanisms and, if needed, trigger an IoT Instance reconfiguration e.g., because of a failure in one of the adopted IoT Modules, Platforms or Services. All the described management capabilities will base on relevant industry standards i.e., W3C Web of Things and OSGi, and will be extended to support agile composition and orchestration. The scalability aspects will be taken into careful consideration to support effective discovery and search of a potential high number of IoT building blocks. The orchestration process is conceived in such a way that it is possible to import/link IoT Modules, Platforms and Services made available from a BRAIN-IoT Marketplace characterized by a relevant set of open APIs. One of the most peculiar aspects being considered in BRAIN-IoT is the management of actuation capabilities in the considered Fog environment. In this context, the possibility to easily develop the previously introduced smart control features is pretty relevant. To this aim, BRAIN-IoT will evolve from already existing solutions, such as Eclipse Papyrus, and develop Model Binding and Synthesis tools extended to support the BRAIN-IoT open vocabularies and models, the IoT-ML and other IoT related standards. The resulting toolset will be used to develop novel Smart Control Features that could be possibly published as IoT Modules in the BRAIN-IoT Marketplace, as depicted in Figure 7.2. Figure 7.2 BRAIN-IoT development concept. Finally, Figure 7.3. summarizes the above description of the BRAIN-IoT environment offering a view of possible configurations of an IoT Instance with different distribution of the IoT building blocks between edge and cloud. Figure 7.3 BRAIN-IoT deployment concept. 7.1.4 Security Architecture Concept From the security and privacy perspective, IoT currently presents two main inherent weaknesses: Security is not considered at the design phase, As of today, no solution is offering a complete end-to-end security approach for any kind of devices (from the temperature sensor, the smoke detector, to the robot). Existing systems don’t apply the “secure-by-design” concept where security is seen as one of the major constraint of the system. To provide secure IoT solutions, modelling and analysis need to be integrated in the design and validation of application scenarios and IoT architectures. If the focus moves to a scenario where different heterogeneous building blocks are dynamically composed, additional security and privacy concerns arise. As a consequence, BRAIN-IoT provides a methodology to address security in the considered fog environment, based on an iterative process, allowing to take into account new scenarios. More specifically, BRAIN-IoT extend the successful methods of attack tree modelling and quantitative analysis to support secure composable IoT systems. This extension enables transparent risk assessment of IoT security architectures, i.e., it will address the needs and potential risks involved in an IoT environment specifying when and where to apply security controls in an understandable way thus raising user-awareness and trustworthiness. The results of the analysis are specific technical requirement to implement for each use case/scenario in order to reach the targeted security level. Figure 7.4 Iterative risk analysis methodology. Second, existing security solution for IoT have many weaknesses, such as: Lot of flow disruption (with network component accessing data in clear text) Some protocol chooses to downgrade security algorithm to fit performance constraints, State-of-the-art solution are complex to set up in decentralized environment. In order to provide a new approach, BRAIN-IoT integrates innovative Decentralized Security and Privacy Capabilities including Authentication, Authorization and Accounting for the overall distributed fog environment and end-to-end security for IoT data-flows. This security layer is based on a combination of well-established standards, such as PKI, with more innovative solution, stateless oriented, to fit the constraints of any kind of IoT (low power, low bandwidth, etc.) Figure 7.5 Decentralised security and privacy capabilities. A cross-platforms framework facilitating the adoption of privacy control policies is also hosted in the BRAIN-IoT environment. The objective is to provide end users with the means to easily monitor and control which data to – collect and to who make it available. 7.1.5 Use Cases and Domain Specific Issues The overall depicted concept draws requirements and challenging use cases from IoT applications in two usage scenarios, namely Service Robotics and Critical Infrastructure Management, which provide the suitable setting to reflect future challenges in terms of dependability, need for smart behaviour, security and privacy/data ownership management which are expected to become more significant and impacting in the long-term (10+years). 7.1.5.1 Service robotics The Service Robotics use case will involve several robotic platforms, like the open-source Robotics Operating System (ROS), which need to collaborate to scan a given warehouse and to assist humans in a logistics domain. The term Service Robotics is generally related to the use of robots to support operations done by humans and the logistics domain is one of the more interesting, for the presence of several tasks, where the robots can help the workers, making their tasks easier and safer. As example, they can cooperate to move a heavy object from one place to another. At the same time, robots involved in the scenario should scan the whole warehouse and update in real-time informative interfaces for the managers and the workers (e.g. warehouse’s map), sharing the collected information. In addition, to the information related to the maps of the whole monitored area, the connected robots will also be equipped with a set of sensors, which will allow collecting interesting info, like room temperature, presence of humans or presence of obstacles in the robot path. Since several robots collaborate to collect the information, they can keep the status of the area updated in real-time and balance the effort required among them. At the beginning, the robots are configured with some default information, like the map of the warehouse. Then, this information is updated in real-time, while the robots perform their main tasks. The demonstration use-case proposed will include both real-time collection of data and control of the included robots. Particularly, the actuation of these robots will be an interesting test-bed for the platform, to demonstrate how the solutions developed by BRAIN-IoT allow to control remotely, in a standard way, the complex devices involved in this scenario. The BRAIN-IoT solution enables the service robotics scenario, demonstrating how the tool-chain and marketplace developed by the project can be used to enable the cooperation of the different robots. In the envisioned scenario, the BRAIN-IoT toolkit will be leveraged to design and test all the aspects of the use case: the behaviours of the robots, the interactions with humans and the cooperation of involved robots, to do specific tasks. The use of the BRAIN-IoT toolkit will enable to limit the development of new ad-hoc software components, indeed, where possible, the solution will be based on open-source components and services already developed in other IoT platforms, provided to the developers through the BRAIN-IoT’s marketplace and interconnected using the services and tools developed in the project. This scenario described will involve also several security aspects. Mechanisms of encryption and authentication will be adopted in the whole final solution, to guarantee the protection of the data exchanged and of the users’ privacy. To avoid inappropriate use of the robots by malicious users and to avoid possible incidents due to remote control (i.e. authorized workers that try to control the robots remotely, without a correct visual of what is happening in the warehouse), techniques of indoor localization are considered to guarantee that only workers located in specific zones near the robots can control them. Furthermore, the solution will protect the privacy of users, anonymizing the data collected, to avoid sharing users’ info, also if the data are stolen by malicious users. 7.1.5.2 Critical infrastructure management The Critical Water Infrastructure Monitoring and Control use case focuses on the management of the water urban cycle in metropolitan environment of Coruña. The base of this system will be made of a complex portfolio of probes, meters, sensors, devices and open-data sources deployed on the field, including: water, flow and pressure meters on the water mains; smart devices, which measure the main chemical-physical characteristics of water; pluviometers, which can monitor the level of rainwater in a specific zone, water circular pumps, which can be used to control the flow of liquids in heating systems. These devices will be geographically distributed, heterogeneous and will be provided by different owners: directly by the water utility, by end-users themselves or by third-party service providers, like, SMEs providing ancillary water services. For this reason, there will be many different data involved in these scenarios: meteorological open data, reservoir water level data, purification data, distribution data in the various subsystems, customer data in urban water supply processes, sewage collection and sewage treatment data in different subsystems. The collection of all these data will allow to provide value-added services, like showing to the client, commercial or not, the quality of the water provided to them or the possibility to react quickly to critical situation and to do predictive maintenance, through the ability to detect anomalous behaviours and to fix them, before they become an issue difficult to be fixed. The BRAIN-IoT solution will enable this scenario, allowing to collect data from all the different domains and to actuate the devices where needed. The WoT-based approach used for the design of the platform, will be leveraged to collect the data, provided by different public and private IoT platforms, using heterogeneous protocols and data formats. Furthermore, BRAIN-IoT focuses particularly to design and develop ways to control devices abstracted by these solutions. For example, the system needs to allow the managers to control the circulator pumps, regulating the fluid flow in heating system, to avoid problems or to react to some critical situation detected through the monitoring sensors. The collection of the data about water consumption from different sources generates risks about privacy protection. Indeed, the data can be shared with public entities or third-party services providers for several purposes, like statistical measures. To do this, the data need to be associated with all the potentially interesting contextual information (i.e. Position of the data, timeslot when the data have been measured and so on) but removing the association with all the personal info of the entity, related with that data. Finally, security mechanisms will be used for the actuation of devices that is potentially a dangerous task, which must be executed only by expert personal that need to know well what they are doing and the context in which the device is operating. For this reason, mechanisms of accounting, authentication and authorization will be used to guarantee that only authorized expert users are able to do these tricky operations. 7.2 Cognitive Heterogeneous Architecture for Industrial IoT – CHARIOT 7.2.1 Introduction Recently, cloud Computing as well as Internet of Things (IoT) technologies are rapidly advancing under the concept of future internet. Numerous IoT systems and devices are designed and implemented following industrial domain requirements but most of the times not considering recent risk relating to openness, scalability, interoperability as well as application independence, leading to a series of new risks relating to information security and privacy, data protection and safety. As a result, securing data, objects, networks, infrastructure, systems and people under IoT is expected to have a prominent role in the research and standardization activities over the next several years. CHARIOT EC co-funded, research project, clearly recognises and replies to this challenge, identifying needs and risks and implementing a next generation cognitive IoT platform that can enable the creation of intelligent IoT applications with intelligent shielding and supervision of privacy, cyber-security and safety threats, as well as complement existing IoT systems in non-intrusive ways and yet help guarantee robust security by placing devices and hardware as the root of trust. The scope of this article is to provide a detailed overview of the CHARIOT vision, technical objectives and overall solution, a high-level presentation of the system architecture as the project approaches in the design of the CHARIOT solution and platform. 7.2.2 Business Challenge and Industrial Baselines The CHARIOT project activities are aligned with actual business and industrial requirements on the recent needs on data safety, security and privacy over modern IoT systems following demands of highly increasing numbers of IoT devices. It is expected that by 2025, there will be 75 Billion IoT-connected devices World Wide while spending on IoT devices and services reached $2 trillion in 2017, with China, North America, and Western Europe accounting for 67% of all devices [8]. This growth in connected devices is anticipated accelerate due to a rise in adoption of cross-industry devices (LED lighting, HVAC systems, physical security systems and lots more). On top of this CHARIOT also recognizes various IoT security breaches that have been dominating headlines, while 96% of security professionals expect an increase in IoT breaches this year [13]. In the direction of a more secure IoT infrastructure, there have been some requests for government regulation of the IoT, asserting that IoT manufacturers and customers are not paying attention to the security of IoT devices [14]. CHARIOT has clearly recognized the above requirements and has an aligned set of objectives towards increase of security, privacy and safety of industrial IoT networks and components. 7.2.3 The CHARIOT EC, Research Project – Vision and Scope CHARIOT (Cognitive Heterogeneous Architecture for Industrial IoT) is an EC, co-funded, research project granted under the IoT-03-2017 – R&I on IoT integration and platforms as a Research and Innovation (RIA) EC topic. The CHARIOT consortium consists of research and innovation organisations from major research streams all merged into the CHARIOT solution providing the competence to deliver a ‘holistic approach addressing Privacy, Security and Safety of IoT operation in industrial settings with safety critical elements’. The consortium includes competences in the fields of Project management and IoT governance (INLECOM, UK), Cognitive Architectures & Platforms for IoT (IBM, Ireland), Static source code analysis tools (CEA, France), Analytics Prediction models and Dashboard development (EBOS, Cyprus) as well as IoT deployment architectures, cloud/fog technologies (VTLN, Belgium, TELCOSERV, Greece), security including cybersecurity (ISC, ASPISEC, Italy) and integration aspects (CLMS, Greece). CHARIOT provides a design method and cognitive computing platform supporting a unified approach towards Privacy, Security and Safety (PSS) of IoT Systems including the following innovations summarised below: A Privacy and security protection method building on state of the art Public Key Infrastructure (PKI) technologies to enable the coupling of a pre-programmed private key deployed to IoT devices with a corresponding private key on a Blockchain system. This includes the implementation of security services utilising a cryptography-based approach and IoT security profiles all integrated to the CHARIOT platform. A Blockchain ledger in which categories of IoT physical, operational and functional changes are both recorded and affirmed/approved by the various run-time engines of the CHARIOT ecosystem while leveraging existing blockchain solutions in innovative ways. Fog-based decentralised infrastructures for Firmware Security integrity checking leveraging Blockchain ledgers to enhance physical, operational and functional security of IoT systems, including actuation and deactivation. An accompanying IoT Safety Supervision Engine providing a novel solution to the challenges of securing IoT data, devices and functionality in new and existing industry-specific safety critical systems. A Cognitive System and Method with accompanying supervision, analytics and prediction models enabling high security and integrity of Industrials IoT. New methods and tools for static code analysis of IoT devices, resulting in more efficient secure and safer IoT software development and V&V. CHARIOT is closely following a business and industrially driven approach to align the developed technologies and outcomes to actual industrial needs in the fields of transport, logistics etc and in general domains of IoT applications. With this vision, CHARIOT, will apply its outputs and recent developments to three living labs in order to demonstrate its realistic and compelling heterogeneous solutions through industry reference implementations at representative scale, with the underlying goal of demonstrating that Secure, Privacy Mediated and Safety IoT imperatives are collectively met, in turn delivering a key stepping stone to the EU’s roadmap for the next generation IoT platforms and services. The actual living labs will be implemented in the industrial framework of TRENITALIA (rail), Athens International Airport (transport) and IBM Ireland (smart buildings) [9, 10]. 7.2.4 CHARIOT Scientific and Technical Objectives We present below a summary of the CHARIOT scientific and technical objectives as the main scope and outcomes of the CHARIOT unified design method and cognitive computing platform supporting a unified approach towards Privacy, Security and Safety (PSS) of IoT Systems, that places devices and hardware at the root of trust, in turn contributing to high security and integrity of industrial IoT. Objective 1: Specify a Methodological Framework for the Design and Operation of Secure and Safe IoT Applications addressing System Safety as a cross cutting concern. The CHARIOT design method will bridge the systems engineering gaps that currently exists between a) the formal safety engineering techniques applied in the development and testing of safety critical systems and b) the rapidly evolving and ad-hoc manner in IoT devices are developed and deployed. This includes classification and usage guidelines of relevant standards and platforms, introduction of new concepts and methods for coupling pre-programmed private security keys on the IoT device with a Blockchain system and ledger to enhance its security and privacy protection and guarantee that only authorised entities who have a matching key can influence operation, function and change, thereby invalidating the potential for a substantial spectrum of cyber-attacks and significantly before they become actual exploits. Developments will also include a specialized static source code analysis tool and cross-compiler to help avoid safety defects and add some meta-data into the binary permitting that binary executable to be suitably “filtered” or “authenticated” by gateways and, in turn, shielding against cyber-attacks while consolidate all the above into the CHARIOT IoT Design Method. Objective 2: Develop an Open Cognitive IoT Architecture and Platform (the CHARIOT Platform), that exhibits intelligent safety behaviour in the diverse and complex ways in which the safety critical system and the IoT system will interact in a secure manner. This includes the creation of an open IoT Cognitive Architecture for a “Web-of-Things” like environment, supporting a range of solutions and applications interacting with highly distributed, heterogeneous and dynamic IoT and critical safety system environments. Under this objective, CHARIOT will also provide interfacing to a topological representation and functional behaviour models of IoT system components and safety profiles as well as a integrated IoT Platform by enhancing the existing state of the art in cognitive computing platforms and build the additional CHARIOT safety and privacy features through open APIs and including security services utilising the Blockchain technology, the IoT security profiles and fog computing services. Objective 3: Develop a runtime IoT Privacy, Security and Safety Supervision Engine (IPSE) which will act continuously to understand and monitor the cyber-physical ecosystem made up of the IoT devices, safety critical systems and a PSS policy knowledge-base in real-time. This cognitive engine will ensure that potentially endangering behaviours of the IoT system are predicted and avoided and, where that is not possible, handled in an agreed manner in conjunction with safety critical systems runtime environments to avoid a breach of the safety constraints. IPSE will include four innovative cognitive applications: A Privacy Engine based on PKI and Blockchain technologies, a Firmware Security integrity checking, an IoT Safety Supervision Engine (ISSE) and an Analytics Prediction models and Dashboard. Objective 4: Test and validate against Industrial IoT safety in three Living Labs (LLs) addressing different industrial areas in IoT safety: in transport (rail and airports) and in buildings. The LLs will be used to demonstrate the capabilities of the proposed approach and provide compelling and representative industry use cases with associated test data that will effectively demonstrate an integrated end-to-end application for how the broader CHARIOT approach to security, privacy and safety will be applied in different industry-representative contexts at enterprise scale. Objective 5: Ensure large outcomes scale up through wide dissemination, exploitation actions and a Capacity Building Programme aiming at infrastructure sustainability, organisational development, and human capital development through training on the practical use of the CHARIOT Concepts, Capabilities, Services and Platform Offering. 7.2.5 Technical Implementation The technical implementations in CHARIOT will be performed in a series of phases, perfectly aligned to the project scientific objectives presented above. These include the design, development, integration and testing of several key-components as will be presented in the chapters that follow. 7.2.5.1 The CHARIOT Open IoT cognitive cloud platform The CHARIOT cognitive platform comprises of a set of functions, logical resources and services hosted in a cloud data centre supporting a range of cognitive solutions and application interacting with an ecosystem of highly distributed, heterogeneous and dynamic IoT and critical safety system environments. This module provides connectivity and intelligence, supporting actuation and control features as required by the final applications. It takes advantage of an existing IoT platform (IBM’s Watson IoT [15]) to demonstrate concept and capability and will also support integration with other safety, privacy and machine-learning cloud services via relevant open APIs, thus supporting third party integration and innovation. Through such interfaces, the CHARIOT platform will subsequently be compatible with existing international developments, addressing object identity management, fog, discovery services, virtualisation of objects, devices and infrastructures and trusted IoT approaches. The CHARIOT platform is being designed respecting open principles. While the open nature of the architecture does not preclude the adoption of specific vendor technologies in the initial platform Proof-of-Concept (PoC) implementation for the living labs, the architecture will be intentionally designed with open interfaces such that individual middleware and components can be easily substituted with alternatives in future implementations. The platform will also explore the development and deployments of probes to provide methods of collecting information on the IoT devices and on the safety-critical-systems in real-time, in turn facilitating the creation of a topological representation and functional behaviours of the IoT systems by the Safety Supervision Engine. The cognitive engine will be used to test the concept of adapting autonomously, instructing the “system” to behave in intended ways and perform required updates and changes through authorised actors. Based on a pattern of events evidenced in ledgers, the cognitive system will adapt/instruct the IoT system(s) to adapt in appropriate ways based on leveraging innovative machine learning and data mining approaches. PKI and Blockchain Technologies Leveraging existing blockchain technologies along with traditional PKI schematics enables CHARIOT to revolutionize the field of identity management and access control. Blockchain acts as the backbone of the system by enabling trust between the various CHARIOT services as well as between the gateways and the IoT sensors within the network. The implementation will be based on a permissioned blockchain that will become the mediator of any communications occurring within the network. 7.2.5.2 Static code analysis and firmware security tool A significant component of the CHARIOT overall solution is the development and enhancement of a free software cross-compilation toolset – leveraging on existing open source technologies – for IoT engineers designing IoT systems and developing source code running on them. Strong highly safety-critical IoT software requires a costly, but extensive, formal methods approach [11], in which developers agree to put a lot of efforts in formally specifying then analysing their source code and using proof assistants to ensure lack of bugs (w.r.t. some explicitly, detailed and formalized specification). But the CHARIOT project aims to help less life-critical IoT software developers by providing them with a tool to help them in developing IoT software and better use of existing free software IoT frameworks. This will be an open software toolset that assists IoT software developers, particularly as not experts in computer science but a competent engineer in a specific industrial domain (railroad, automotive, smart building, maritime, etc.), so even heuristic source code analysis techniques (leveraging above some formal methods approaches) can improve his/her coding productivity. This tool will be developed as part of the CHARIOT solution and a plugin/extension module for GCC based compilers that the software industry is currently using and will be executed at compilation/linking stage and will use meta-programming techniques to foster “declarative” high-level programming styles. This will enable the developers (as the IoT device firmware developers) to identify most safety critical functions executed at the IoT device or gateway level. Also, firmware compiled with that toolset will carry some cryptographic signature to enable filtering of firmware updates in the gateway. 7.2.5.3 Integrated IoT privacy, security and safety supervision engine This engine is a set of novel runtime components which act in concert to understand and monitor the cyber-physical ecosystem made up of the IoT gateway and devices, the safety critical systems and safety/security policy knowledge-base. The Privacy Engine utilises existing security protocols and technologies such as Blockchain to provide a strong foundation for the trusted interchange of information about and between the participants in the system-of-systems. The Safety Engine also analyses the IoT topology and signal metadata relative to the relevant safety profiles and applies closed-loop machine-learning techniques to detect safety violations and alert conditions. The objective of this engines is to develop a cognitive engine that will leverage the Cyber-Physical topological representation of the system-of-systems combined with the security/safety-polices to provide a real-time risk map will allow for both static analysis and continuous monitoring to assess safety impact and appropriate response actions. The supervision engine will be responsible for interacting with the CHARIOT IoT platform, providing the centralised intelligence and control functionality for applying the necessary privacy, security, and safety policies to all components in the IoT system of systems, monitor IoT devices and systems to detect abnormalities in their behaviour and analyse their causes, maintain an internal topological representation of the constantly evolving IoT system of systems and collect and represent PSS policies and the threat intelligence in the topology to provide a real-time risk map, impact assessment and triggering of appropriate response actions. The engine will also maintain safety, security and privacy even when unknown devices and sensors are connected to the network, ensuring that they do not interfere to the normal operation of existing IoT components, assess the topology to detect whether the IoT ecosystem has entered or is predicted to be advancing towards an abnormal (unsafe/insecure) state, and automatically activate a safety remediation in response to this unsafe state, to reduce the impacts on users and other IoT components and restrict abnormal operations and allow operations of safe functions to maintain at reduced level the operation of the controlled system. 7.2.5.4 Analytics prediction models user interface This system component is an innovative cognitive web application, which constitutes together with other relevant components – such as the Privacy and the IoT Safety Supervision Engine – the IPSE. The application collects the data received by the various IoT gateways and sensors in the fog network and using appropriate algorithms, Analytics Prediction models will be created and presented through a user friendly configurable dashboard. This module will be the advanced-intelligence dashboard for both understanding of the IoT ecosystem topology and for post data analytical purposes to assist in the refinement and improvements of PSS policies while at the same time act as the interface between the CHARIOT platform and the system operator/user. 7.2.6 System Demonstration, Validation and Benchmarking The overall system operation will be demonstrated and validated via full integration to the actual operating environments and infrastructures of three industrial sites over precise key-performance-indicators that contribute to the separate business environment and value. The three key selected sites (living labs, LLs) will be: a) Trenitalia (transport – rail) b) IBM Ireland business campus (smart buildings) and c) Athens international airport (transport – airport). Details on the three separate cases have been included below: 7.2.6.1 Living lab 1: Trenitalia The primary objective in this LL is to enhance the safe operation of the Italian railways service. This includes, reduction of risk to passengers and personnel, compliance with appropriate regulations, and creation of a safe and efficient operating environment in the railways. At the same time this use case will focus on utilizing the feed from IoT used to monitor electrical and mechanical components dedicated on assessing energy consumption and dispatch them to the on-board control servers and the land-based central control system. The application of the CHARIOT tool will facilitate the timely recognition of sensors malfunction, along with prediction of maintenance requirements. 7.2.6.2 Living lab 2: IBM business campus In this LL, the objective will be to enable the continued IoT evolution of the IBM technology campus from a set of individuals “automated/smart” buildings into to a truly cognitive IoT environment that provides a safer and more efficiently managed working environment for all IBM staff, customers and visitors and also to use the knowledge gained to help drive advancements in Cognitive IoT to a global scale by reflecting it in IBM products and services. 7.2.6.3 Living lab 3: Athens international airport The application of CHARIOT in this Living Lab will address safety of airport Infrastructures, enhance protection of Athens airport’s facilities from physical and cyber threats. To achieve this, CHARIOT will enhance airports capability on early detection/prediction of hazardous situations, in parallel with reduction in false positive alarms that disrupt airport operations. 7.2.7 Summary and Discussion This chapter provides the overall concept of the CHARIOT project and business orientation. It summarizes the project scope and business value as derived from actual industrial needs in the framework of safety, security and privacy of industrial IoT. CHARIOT started in January 2018 and it currently in the stage of requirements extraction and definition of the system overall architecture as this is aligned with the project end-users (living labs) that drive and validate the technological developments. Currently, CHARIOT is also defining the technical and methodological framework of the overall solution adapted for the cases of the three living labs that is going to evolve into the concise implementations for the next project phases, in a systematic approach to Privacy, Security, and Safety in Industrial IoT environments, using a strategic/objectives driven systematic way, in a process of continuous improvement. CHARIOT intends to have a first implementation of the system within the first months of 2019 and will integrate this to all infrastructures involved and as planned. This project has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement No 780075”. The authors acknowledge the research outcomes of this publication belonging to the CHARIOT consortium. 7.3 ENACT: Development, Operation, and Quality Assurance of Trustworthy Smart IoT Systems Until now, IoT system innovations have been mainly concerned with sensors, device management and connectivity, with the mission to gather data for processing and analysis in the cloud in order to aggregate information and knowledge [16]. This approach has conveyed significant added value in many application domains, however, it does not unleash the full potential of the IoT [82]. The next generation IoT systems need to perform distributed processing and coordinated behaviour across IoT, edge and cloud infrastructures [17], manage the closed loop from sensing to actuation, and cope with vast heterogeneity, scalability and dynamicity of IoT systems and their environments. Moreover, the function and correctness of such systems has a range of criticality from business critical to safety critical. Thus, aspects related to trustworthiness such as security, privacy, resilience and robustness, are challenging aspects of paramount importance [16]. Therefore, the next generation of IoT systems must be trustworthy above all else. In ENACT, we will call them trustworthy smart IoT systems, or for short; trustworthy SIS. Developing and managing the next generation trustworthy SIS to operate in the midst of the unpredictable physical world represents daunting challenges. Challenges, for example, that include that such systems always work within safe operational boundaries [18] by controlling the impact that actuators have on the physical world and managing conflicting actuation requests. Moreover, the ability of these systems to continuously evolve and adapt to their changing environments are essential to ensure and increase their trustworthiness, quality and user experience. DevOps is a philosophy and practices that covers all the steps from concept to delivery of a software product. In ENACT we see DevOps advocating a set of software engineering best practices and tools, to ensure Quality of Service while continuously evolving complex systems, foster agility, rapid innovation cycles, and ease of use [19]. DevOps has been widely adopted in the software industry. However, there is no systematic DevOps support for trustworthy smart IoT systems today [18–20]. The aim of ENACT is to enable DevOps in the domain of trustworthy smart IoT systems. 7.3.1 Challenges The key research question of ENACT is thus the following: “how we can tame the complexity of developing and operating smart IoT systems, which (i) involve sensors and actuators and (ii) need to be trustworthy?”. Our fundamental approach is to evolve DevOps methods and techniques as baseline to address this issue. We thus refine the research question as follows: “how we can apply and evolve the DevOps tools and methods to facilitate the development and operation of trustworthy smart IoT applications?”. Challenge 1: Support continuous delivery of trustworthy SIS. Currently there is little effort spent on providing solutions for the delivery and deployment of application across the whole IoT, edge and cloud space. In particular, there is a lack of languages and abstractions that can be used to support the orchestration of software services and their continuous deployment on heterogeneous devices [21] together with the relevant security mechanisms and policies. Challenge 2: Support the agile operation of trustworthy SIS. The operation of large-scale and highly distributed IoT systems can easily overwhelm traditional operation teams. Other management models such as NoOps and Serverless Computing are evolving to solve this problem. Whatever the operations management model the major challenges will be to improve efficiency and the collaboration with development teams for rapid and agile evolution of the systems. Currently, there is a lack of mechanisms dedicated to smart IoT systems able to (i) monitor their status, (ii) indicate when their behaviour is not as expected, (iii) identify the origin of the problem, and (iv) automate typical operation activities. Furthermore, the impossibility of anticipating all the adaptations a system may face when operating in an open context, creates an urgent need for mechanisms that will automatically maintain the adaptation rules of a SIS. Challenge 3: Support continuous quality assurance strengthening trustworthiness of SIS. Maintaining quality of service is a complex task that needs to be considered throughout the whole life-cycle of a system. This complexity is increased in the smart IoT system context where it is not feasible for developers and operators to exhaustively explore, anticipate or resolve all possible context situations that a system may encounter during its operation. This is due to the open context in which these systems operate and as a result can hinder their trustworthiness. Quality of Service is particularly important when the system can have an impact on the physical world through actuators. In addition, testing, security assurance as well as the robustness of such systems is challenging [20]. 7.3.2 The ENACT Approach DevOps seeks to decrease the gap between a product design and its operation by introducing software design and development practices and approaches to the operation domain and vice versa. In the core of DevOps there are continuous processes and automation supported by different tools at various stages of the product life-cycle. In particular, the ENACT DevOps Framework will meet the challenges below and support the DevOps practices during the development and operation of trustworthy smart IoT systems. ENACT will provide innovations and enablers that will feature trustworthy IoT systems built by implementing the seven stages of the process as depicted in Figure 7.6. Plan: The ENACT approach is to introduce a new enabler to support the risk-driven and context-aware planning of IoT systems development, including mechanisms to facilitate the selection of the most relevant and trustworthy devices and services to be used in future stages. Figure 7.6 ENACT support of DevOps for trustworthy smart IoT systems. Code: The ENACT approach is to leverage the model-driven engineering approach and in particular to evolve recent advances of the ThingML [21] language and generators to support modelling of system behaviours and automatic derivation across vastly heterogeneous and distributed devices both at the IoT and edge layers. Build and Deploy: The ENACT approach is to provide a new deployment modelling language to specify trustworthy and secure orchestrations of sensors, actuators and software components, along with the mechanisms to identify and handle potential actuation conflicts at the model level. The deployment engine will automatically collect the required software components and integrate the evolution of the system into the run-time environment across the whole IoT, Edge and Cloud space. Test: ENACT enablers will allow continuous testing of smart IoT systems in an environment capable of emulating and simulating IoT and edge infrastructure by targeting the constraints related to the distribution and infrastructure of IoT systems. This system is intended to be able to simulate some basic attacks or security threats. Operate: The ENACT approach will provide enablers for the automatic adaptation of IoT systems based on their run-time context, reinforced by online learning. Such automatic adaptation will address the issue of the management complexity. The complexity of open-context IoT systems can easily exceed the capacity of human operation teams. Automatic adaptation will improve the trustworthiness of the smart IoT system execution. Monitor: The ENACT approach is to deliver innovative mechanisms to observe the: status, behaviour, and security level of the running IoT systems. Robust root cause analysis mechanisms will also be provided. In addition to the DevOps related contributions identified above, the ENACT DevOps Framework will provide specific cross-cutting innovations related to trustworthiness, which can be seamlessly applied, in particular based on the following ENACT concepts: Resilience and robustness: The ENACT approach is to provide novel solutions to make the smart IoT systems resilient by providing enablers for diversifying IoT service implementations, and deployment topologies (e.g., implying that instances of a service can have a different implementation and operate differently, still ensuring consistent and predictable global behaviour). This will lower the risk of privacy and security breaches and significantly reduced impact in case of cyber-attack infringements. Security, privacy and identity management: The ENACT approach is to provide support to ensure the security of trustworthy SIS. This not only includes smart preventive security mechanisms but also the continuous monitoring of security metrics and the context with the objective to trigger reactive security measures. 7.3.3 ENACT Case Studies Three use cases from the Intelligent Transport Systems (Rail), eHealth and Smart Building application domains will guide, validate and demonstrate the ENACT research. 7.3.3.1 Intelligent transport systems This use case will assess the feasibility of IoT services in the domain of train integrity control, in particular for the logistics and maintenance of the rolling stock and on-track equipment. In this domain, the infrastructure and the resources that should be used are usually expensive and require a long-time in planning and execution. Therefore, the usage of the rail systems must be optimised at maximum, following security and safety directives due to the critical and strategic characteristics of the domain. This use case will involve logistic and maintenance activities. Within the ENACT scope, it will be focused on the logistics activities. A logistic and maintenance scenario will be defined with the aim to provide information about the wagons that form the rolling stock. This scenario will cover not only optimizing cargo storing and classification, but also providing the appropriate resources to assure the correct functioning of the system. These will be only possible if the train integrity is confirmed when the different wagons are locked and moving together. This situation will assure the proper transportation of cargo or passengers, avoiding possible accidents. This use case will involve an infrastructure consisting of large sets of on-board sensors (e.g., Integrity Detector, Asset data info, Humidity and temperature sensors) and multiple gateways interacting with cloud resources. 7.3.3.2 eHealth The eHealth use case will develop a digital health system for supporting and helping various patients staying at home to the maximum extent possible either during treatment or care. Elderly people are one type of subject in this case study. The Digital health system will feature elderly care to allow the subjects to live at home as long as possible. Another type of patients that we consider is Diabetes patients that need to follow their glucose level and regularly be followed up by health personnel. The digital health system will both control equipment normally present in smart homes to make life comfortable (automatic light control, door locks, heater control, etc.), and control various types of medical devices and sensors. These devices and sensors support the care and wellness for the specific patient and consist of a wide variety of types, including: blood pressure meter, scales, fall detection sensors, glucose meter, video surveillance, medicine reminder, indoor and out-door location etc). In addition, the system needs to integrate with other systems to provide information or alarms for example to response centres, care-givers, physicians, next of kin etc., and to feed information to medical systems such as electronic patient journals (EPJ). The pivotal role of the system’s Edge Computing will be what we denote “the medical gateway” which integrates sensors and devices, controls the edge and ensures the right data are provided to the various stakeholders and to integrated systems such as EPJ. 7.3.3.3 Smart building This use case will make use of smart building sensors, actuators and services. To this aim two sets of applications covering Smart Energy Efficiency and Smart Elderly Care will be developed within a Care Centre environment. Energy efficiency of new and existing buildings is crucial to achieve carbon emission reduction, and as we increasingly spend more time indoors, adequate levels of user comfort need to be guaranteed by the smart buildings. This implies a trade-off between energy use and the different aspects of users’ comfort. They will be tested in the KUBIK, a smart building especially designed for testing new solutions for sustainable buildings. The use case will simulate a care centre consisting of small apartments where a group of elderly people live together. This care centre use case includes sensors and actuators that monitor and control the environment in order to ensure the safety of the facilities, to perform energy efficiency measures and also to support the care-takers in monitoring the wellbeing of users. The trend for smart buildings is to provide an increasing range of services supported by an increasing number of IoT sensors and actuators. Example of such services or applications include thermal comfort, visual comfort, energy efficiency, security, etc. Applications in this space need to share building infrastructure and may have conflicting objectives. The solution requires a clear hierarchy between the different actuation scenarios. 7.4 Search Engines for Browsing the Internet of Things – IoTCrawler Efficient and secure access to Big IoT Data will be a pivotal factor for the prosperity of European industry and society. However, today data and service discovery, search, and access methods and solutions for the IoT are in their infancy, like Web search in its early days. IoT search is different from Web search because of dynamicity and pervasiveness of the resources in the network. Current methods are more suited for fewer (hundreds to millions), static or stored data and services resources. There is yet no adaptable and dynamic solution for effective integration of distributed and heterogeneous IoT contents and support of data reuse in compliance with security and privacy needs, thereby enabling a true digital single market. Previous reports show that a large part of the developers’ time is spent on integration. In general, the following issues limit the adoption of dynamic IoT-based applications: The heterogeneity of various data sources hinders the uptake of innovative cross-domain applications. The large amount of raw data without intrinsic explanation remains meaningless in the context of other application domains. Missing security and neglected privacy present the major concern in most domains and are a challenge for constrained IoT resources. The large-scale, distributed and dynamic nature of IoT resources requires new methods for crawling, discovery, indexing, physical location identification and ranking. IoT applications require new search engines, such as bots that automatically initiate search based on user’s context. This requires machine intelligence. The complexity involved in discovery, search, and access methods makes the development of new IoT enabled applications a complex task. Some ongoing efforts, such as Shodan and Thingful provide search solutions for IoT. However, they rely mainly on a centralised indexing and manually provided metadata. Moreover, they are rather static and neglect privacy and security issues. To enable the use of IoT data and to exploit the business potential of IoT applications, an effective approach needs to provide: An adaptive distributed framework enabling abstraction from heterogeneous data sources and dynamic integration of volatile IoT resources. Security, privacy and trust by design as integral part of all the processes from publication, indexing, discovery, and subscription to higher-level application access. Scalable methods for crawling, discovery, indexing and ranking of IoT resources in large-scale cross-platform and cross-disciplinary systems and scenarios. Machine initiated semantic search to enable automated context dependent access to IoT resources. Monitoring and analysing the Quality of Service (QoS) and Quality of Information (QoI) to support fault recovery and service continuity in IoT environments. IoTCrawler is an EU H2020 project that addresses the above challenges by proposing efficient and scalable methods for crawling, discovery, indexing and ranking of IoT resources in large-scale cross-platform and cross-disciplinary systems and scenarios. It develops enablers for secure and privacy-aware discovery and access to the resources, and monitors and analyses QoS and QoI to rank suitable resources and to support fault recovery and service continuity. The project evaluates the developed methods and tools in various use-cases, such as Smart City, Social IoT, Smart Energy and Industry 4.0. The key elements of IoTCrawler are shown in Figure 7.7. Figure 7.7 Key concepts of the IoTCrawler proposal. [40] 018 IEEE. The project aims to create scalable and flexible IoT resource discovery by using meta-data and resource descriptions in a dynamic data model. This means, for example, that if a user is interested in measuring temperature in a certain location, the result (e.g. list of sensors) should only contain sensors that can measure temperature, but the user may accept sensors that closely fulfil her/his application requirements even though all other characteristics may not be favourable (e.g. cost of acquisition may be high and sensor response time may be slow). For this reason, the system should understand the user priorities, which are often machine-initiated queries and search requests, and provide the results accordingly by using adaptive and dynamic techniques. 7.4.1 Architecture of IoTCrawler IoTCrawler provides novel approaches to support an IoT framework of interoperable systems including security and privacy-aware mechanisms, and offers new methods for discovery, crawling, indexing and search of dynamic IoT resources. It supports and enable machine-initiated knowledge-based search in the IoT world. Figure 7.8 depicts the IoTCrawler framework and highlights its key components, which are detailed next. 7.4.1.1 IoT framework of interoperable (distributed) systems The diversity of the market has resulted in a variety of sophisticated IoT platforms that will continue to exist. However, to evolve and enable the full benefits of IoT, these platforms need access to data, information and services across various IoT networks and systems within an integrated ecosystem of IoT resources. IoTCrawler envisions a cooperation of platforms and systems to provide smart integrated IoT based services. Nevertheless, instead of defining an overarching hyper-platform on top, the integration proposed by IoTCrawler is carried out by the definition of a common interface, enabling this way cooperation and interconnection of various platforms by making their data and services discoverable and accessible to other applications and services. An IoTCrawler-enabled platform can internally be implemented in different ways, since it only has to support the common and open interfaces to join the ecosystem. The open IoT interfaces are split in two planes that are called control and data planes. The control plane will coordinate and control the data and information processing in the platforms (monitoring and quality analysis). The data plane will allow for IoT data flow exchange between platforms (crawling, indexing and search). Figure 7.8 Overall architecture of the IoTCrawler framework. [40] 2018 IEEE. 7.4.1.2 Holistic security, privacy and trust An ecosystem of IoT platforms brings immense benefits but also potential risks for users and stakeholders. The very principle that makes the IoT so powerful – the potential to share data instantly with everyone and everything – creates huge security and privacy risks. Since IoT systems are, by their nature, distributed and operate often in unprotected environments, the maintenance of security, privacy, and trust is a challenging task. IoTCrawler addresses quality, privacy, trust and security issues by employing a holistic and end-to-end approach to the data and service publication to search and access workflow. Device and connectivity management will ensure that the end devices only connect to trusted access networks. IoTCrawler develops solutions for mitigating privacy intrusion and data correlation based on data collected from multiple sources. Both technical and information governance procedures and guidelines are defined and implemented. This makes sure that the technical solutions are in place for avoiding the security and privacy risks, and also appropriate information governance procedures and best practices and measures are followed in development, deployment and utilisation of the use-cases and third-party applications. 7.4.1.3 Crawling, discovery and indexing of dynamic IoT resources Information access and retrieval on the early days of the Internet and the Web mainly relied on simple functions and methods. For example, Yahoo’s first search engine was simply based on the “grep” function in Unix or the AltaVista search engine initially did not have a ranking mechanism. The Internet and the Web have gone a long way in the past two decades to improve the way we access the information on the Web. While the current information and search retrieval on the Web is far from ideal, there are several sophisticated methods and solutions that provide crawling, indexing, ranking and search and retrieval of extremely large volumes of information on the Internet. The new generations of Web search engines have now focused on information extraction, personalised and customised knowledge and extraction techniques and solutions. Some early works are demonstrated by Google’s knowledge graph, Wolfram Alpha and Microsoft Bing. The current information access and retrieval methods on the IoT are still at the same stage that the Web and the Internet were in their early days. Information retrieval on the large-scale IoT systems is currently based on the assumption that the sources are known to the devices and consumers or it is assumed that opportunistic methods will send discovery and negotiation messages to find and interact with other relevant resources in their outreach (e.g. Google’s recent Physical Web project is designed based on this assumption). Overall, IoT systems have more ad-hoc resources that do not comply with document and URL processing and indexing norms; the resources, such as mobile phones and sensing devices, can publish data and then move to another location or disappear. Service and data crawling and discovery for smart connected devices and services will also involve automated associations and integration to provide an extensible framework for information access and retrieval in IoT. IoTCrawler focuses on providing reliable, quality and resource-aware and scalable mechanisms for data and services publishing, crawling, indexing in very large-scale distributed dynamic IoT environments. 7.4.1.4 Machine-Initiated semantic search In the past, search engines were mainly used by human users to search for content and information. In the newly emerging search model, information is provided depending on the users’ (human user or a machine) context and requirements (for example, location, time, activity, previous records, and profile). The information access can be initiated without the user’s explicit query or instruction but used on its necessity and relevance (context-aware search). This will require machine interpretable search results in semantic forms. Moreover, social media, physical sensors (numerical streaming values), and Web documents must be better integrated, and the search results should become more machine interpretable information rather than remaining as pure links (e.g. the Web search engines mainly return a list of links to the pages as their results; with some exceptions on popular questions and topics). IoTCrawler enables context-aware search and automated processing of data by semantic annotation of the data streams, thus making their characteristics and capabilities available in a machine processable way. There are several existing works that provide methods and techniques for semantic annotations and description of the IoT devices, services and their messages and data. However, most of these methods rely on centralised solutions and complex query mechanisms that hinder their scalability and wide scale deployment and use for the IoT. IoTCrawler supports an ecosystem of multiple platforms and develops dynamic semantic annotation and reasoning methods that will allow continuous and seamless integration of new devices and services by exploiting and adapting existing annotations based on similarity measures. The automatic discovery has to consider the current context. Context-awareness requires the integration and analysis of social, physical and cyber data. IoTCrawler develops enablers for context-aware IoT search. Hence the requirements of the different applications are mapped to the solutions by selecting resources considering parameters such as security and privacy level, quality, latency, availability, reliability and continuity. IoTCrawler improves reliability and robustness by fault recovery mechanisms and mitigation of malfunctioning devices using device activation/deactivation in the associated area. The fault recovery also requires mechanisms to support communication among networked IoT resources located in diverse locations and across different platforms, and to provide secure and efficient re-distribution of information in case of failure. 7.4.2 Use Cases IoTCrawler is currently evaluating its technologies in four real world use-cases: Smart Cities, Social IoT, Smart Energy, and Industry 4.0 (see Figure 7.9). Further use-cases will be identified and ranked in co-creation workshops with the relevant stakeholders within the project. Figure 7.9 IoTCrawler use cases at a glance. 7.4.2.1 Smart city The city of Aarhus has been considered as a target for smart city deployment in the project. IoTCrawler helps to overcome the negative perceptions of Internet of Things and Smart Cities by developing smart city experimentation tools for Aarhus’ City Lab that can make citizens and companies engaged and be curious about smart city solutions. IoTCrawler also provides the enabling technologies to discover new data sources in Aarhus for Open Data platforms and has the potential to become a reference platform supporting IoT data and service sharing as part of the sharing economy. To track the performance of a smart city, IoTCrawler develops enablers for monitoring activity and quality of the sensors. This can be used to set up KPI’s for City Labs and to track its performance. The smart city deployment of Murcia is also considered in IoTCrawler, exploiting the large sensor platform installed. 7.4.2.2 Social IoT Social IoT relates to using sensors deployed at sports and entertainment events in order to quantify the performance of professionals or experience of participants. This enables participants to engage in events beyond simply watching, thus creating a unique personal record of their experience, and in combination with social and digital media allows event manager to create new insights and content for their audience. IoTCrawler has access to over 800 events, including fashion events (e.g. New York Fashion week), culinary events, sports events (e.g. Basketball Final Four), or events such as Miss Universe. For each event, sensors are deployed at local venues and participants and spectators are equipped with wearable devices. This results in a range of diverse data sets that are collected, analysed, stored, and used, e.g. for content creation. Discovering and semi-automatically describing existing sensors, data sets and streams using IoTCrawler technologies has the potential to significantly increase the overall value of the dataset access and their integration, making it accessible to a larger group of people and enabling new applications. As described above, the data sets include raw sensor data and processed analytic results. However, data processing often involves data from other third-party sources. For this reason, play-by-play data is used to correlate analytical results to match events, and social media sources can be used to link to user generated content. IoTCrawler’s discovery, indexing and search enablers have the potential to significantly reduce the effort associated with the integration of sensor technologies, and other external data sources. 7.4.2.3 Smart energy Smart Buildings play an important role in distributed energy systems as they turn from energy consumers to the so-called “energy prosumers”. In future energy systems, Smart Buildings actively interact with the Smart Grids in order to stabilise them or participate in energy trading as well as for structural condition monitoring and proactive maintenance. For this purpose, buildings offer semantically annotated properties of the technical equipment within especial energy flexibilities (i.e. for shifting electrical and thermal loads). In this frame, this use-case employs the technologies developed in IoTCrawler to dynamically discover the flexibilities of Smart Buildings and analyse their potential as well as their demand for applications that are necessary to manage and offer energy to the Smart Grid or the energy market. This information can be used by energy retailers or grid operators to deploy best fitting applications to individual buildings. The project uses semantic enrichment of grid data and data analytics to enhance smart grid applications and reduce the need for manual engineering and setup of systems. 7.4.2.4 Industry 4.0 Industry 4.0 includes advances such as predictive maintenance, energy prediction, or human-robot collaboration. The results of IoTCrawler will be used to improve predictive maintenance planning for horizontal machining centres in aerospace and Die&Mould industries. Currently, data integration consumes more than 80% of the time in the industry. IoTCrawler has the potential to significantly accelerate the development and deployment of Industry 4.0 analytics solutions, by discovering and semi-automatically integrating machine metadata, sensor data provided by the machines and information stored in related enterprise databases. Extending the discovery to actuator services (e.g. air conditioning, heating, and machine operation) allows to link actions for avoiding load peaks to energy analytics pipeline. IoTCrawler also increases workers’ safety by identifying critical conditions (e.g. gas exposition) in the permanent sensor data stream of drones, and forward such condition markers to monitoring teams and production management subsystems. 7.4.3 Main Innovations in the Areas of Research The literature within key areas of the IoTCrawler proposal is reviewed next, indicating the main innovations of the work within the general framework described above. 7.4.3.1 Search and discovery Being essential for any network architecture, one of the key components of the proposed architecture is the search and discovery operation. Distributed Hash Table (DHT) is used to provide a high scalability in storage and a flexible support for query and update operations. DHT is a totally decentralised system that stores data objects for easy and quick access (query) and update (store). DHTs are built on top of overlay networks into which network objects are spread and identified with unique keys, e.g. the well-studied overlay network and DHT Chord mechanism [22], which is the direct ancestor of Kademlina [23] (BitTorrent’s DHT). Overlay networks and DHTs are well suited to form the basement of a proper discovery mechanism, such as the Overlay Management Backbone (OMB) approach [24]. To add suitable schema evolution to the information/content discovery, description mechanisms such as the Resource Description Framework (RDF) and JSON-LD [25] are needed. Combining a DHT mechanism with RDF, the work in [26] proposes to use an adapted version of RDQL [27] to perform the queries. The main problems of this approach are that it consumes a lot of storage space and that it is not efficient for simple searches. SPARQL [28] is the de facto query language for RDF, by providing a coherent and simple search mechanism. The IoTCrawler approach exploits the remarkable qualities of the overlay network and DHT described above to build a distributed discovery infrastructure. However, the nodes are deployed in separate domains to distribute both the storage/finding load and the management of information access. 7.4.3.2 Security for IoT In spite of the emergence of different cross-world initiatives in recent years (IERC, ITU-T SG20, IEEE IoT Initiative4 or IPSO Alliance are just some of them), there is a lack of a unified vision on security and privacy considerations in the IoT paradigm, which embraces the whole lifecycle of smart objects that are making up the digital landscape of the future. In the IoT, data confidentiality and authentication, access control within the networks, privacy and trust among users and things are among some of the key issues [29]. IoTCrawler explores the use of advanced cryptographic techniques based on Attribute-Based Encryption (ABE). Specifically, it analyses the application and extension of the Ciphertext-Policy Attribute-Based Encryption (CP-ABE) as a flexible and promising cryptographic scheme in order to enable information to be shared while confidentiality is still preserved. In CP-ABE, the cipher-text embeds the access structure to describe which private-keys can decrypt it, and the same private-key is labelled with descriptive attributes. IoTCrawler addresses the integration of CP-ABE with different signatures schemes to provide end-to-end integrity to the information that is shared for anticipatory purposes. Users are given means to define how their personal information is shared and under which circumstances using a policy-based approach. Additionally, IoTCrawler investigates the integration of this solution within the search and discovery process for IoT. The Blockchain paradigm [30] is also included in IoTCrawler. A Blockchain is a distributed database that maintains a continuously growing set of transactions in a way that is designed to be secure, transparent, highly resistant to outages, auditable, and efficient, at the same time it is distributed. However, despite the benefits that Blockchain technologies offer, we still need to overcome two major challenges in IoTCrawler. First, privacy, since transactions tend to be public, and encryption to protect transactions’ contents is not enough because it still allows the remaining nodes in the system to learn about the occurrence of a particular exchange in the system; and, second, scalability, because existing permission-less blockchains (e.g. Bitcoin) are only able to scale to a considerable number of nodes at the expense of attained throughput, e.g. Bitcoin’s throughput is about seven transactions per second. Moreover, IoTCrawler will leverage Trusted Execution Environments (TEEs) to enhance the security primitives deployed in the proposed framework, given that existing TEEs suffer from a number of shortcomings, especially with respect to their security and privacy provisions. In the area of Authentication, Authorisation and Accounting (AAA), IoTCrawler proposes a lightweight access control scheme based on Capability Tokens for IoT as presented in [31, 32], where these tokens act as a proof of possession providing a straightforward validation mechanism without requesting a third party. We propose a mechanism for interoperability of different authentication and authorisation solutions based on a bridge to third party elements, such as the standard stacks as LDAP and FIWARE Service Enablers to support a lightweight federation-like approach. 7.4.3.3 Data validation and quality analysis The assessment of Quality of Data can basically be evaluated in five common dimensions: Completeness, Correctness, Concordance, Plausibility and Currency. In [33] the authors provide a table of different terms used to describe one of the dimensions of data quality. Furthermore, they provide a mapping between data quality dimensions and data quality assessment methods. In [34] Sieve is introduced, a framework to flexibly express quality assessment methods and fusion methods. The STAR-CITY project [35] describes a system for semantic traffic analytics. Based on various heterogeneous data sources (e.g., Dublin bus activity, events in Dublin city), their system is able to predict future traffic conditions with the goal to make traffic management easier and to support urban planning. One of the major challenges in the assessment of quality metrics to sensory IoT data is the lack of ground truth. The authors of [36] and [37] developed and evaluated a concept for the assessment of node trustworthiness in a network based on data plausibility checks. They propose that every node performs a plausibility check to identify malicious nodes sending faulty data. Similar to this work, they use data sources in order to find “witnesses” for a given sensor reading. The authors in [38] propose three different approaches to deal with a missing ground truth in social media: spatiotemporal, causality, and outcome evaluation. Their concept to use spatiotemporal evaluation to predict future behaviour of humans is like the proposed IoTCrawler approach, disregarding that we evaluate past events. Prior work of the authors emphasised the importance of an appropriate distance model reflecting infrastructure, e.g., roads, and physics, i.e. traffic or air movements [39]. The approach in IoTCrawler refines the state of the art by utilising sensor and domain independent correlation and interpolation models whilst incorporating knowledge of the city infrastructure to evaluate data stream plausibility. 7.4.4 Conclusion This part presents the key ideas and the architecture of a crawling and discovery engine for the Internet of Things resources and their data. We describe our work in the context of the H2020 IoTCrawler project, which proposes a framework to make possible the effective search over IoT resources. The system goes beyond the state of the art through adaptive, privacy-aware and secure algorithms and mechanisms for crawling, indexing and search in distributed IoT systems. Innovative technological developments are proposed as enablers to support any IoT scenario. We discuss four use cases of the platform, which are presented in the areas of Smart Cities, Social IoT, Smart Energy and Industry 4.0. The project is currently implementing the envisaged framework, at the same time the main interoperability issues are considered to support the real-life uses cases identified. This work has been sponsored by the European Commission, through the IoTCrawler project (contract 779852), and the Spanish Ministry of Economy and Competitiveness through the Torres Quevedo program (reference PTQ-15-08073). 7.5 SecureIoT: Multi-Layer Architecture for Predictive End-to-End Internet-of-Things Security The proliferation and rising sophistication of Internet of Things (IoT) infrastructures and applications comes with a wave of new cybersecurity challenges. This is evident in several notorious security incidents on IoT devices and applications, which have occurred during the last couple of years. These include the “Lizard Stressor” attacks on home routers (January 2015), the 1.4 million cars that were recalled by Chrysler due to potential hacking of their control software (July 2015), Tesla’s autopilot crash (July 2016), as well as the first large scale distributed denial of service (DDoS) attack based on IoT devices (October 2016). Most of these incidents are directly associated with the complexity, heterogeneity and dynamic behaviour of emerging IoT deployments, which poses security challenges, which can be hardly addressed by state of the art platforms. Some of the most prominent of these challenges, include: The fact that they provided limited support for end-to-end security, since they lack mechanisms that address IoT security at all levels, i.e. from the field and devices level to the edge and cloud levels. Moreover, existing security solutions tend to be framed within a single platform and ecosystem and cannot effectively operate in scenarios involving multiple platforms and ecosystems [41]. Their inability to deal with very volatile and dynamic environments comprising networks of smart objects. State-of-the-art IoT platforms and their security mechanisms provide within cloud-based environments that ensure cybersecurity for large numbers of IoT devices. Nevertheless, they make only limited provisions for dynamic applications involving networks of smart objects (i.e. objects with (semi)autonomous behaviour). In the latter, IoT devices and smart objects are likely to join or leave, while security and privacy policies can also change dynamically and without prior notice. Hence, to support large scale interactions across multiple IoT platforms and networks of smart objects, there should be some means of predicting and anticipating the security behaviour and trustworthiness of an IoT entity (e.g., device, platform, groups of objects) prior to interacting with it. SecureIoT is motived by the need to support cyber-security in scenarios involving cross-platform interactions and interactions across networks of smart objects (i.e. objects with semi-autonomous behaviour and embedded intelligence), which require more dynamic, scalable, decentralized and intelligent IoT security mechanisms. To this end, it introduces a multi-layer, data-driven security architecture, which collects and processes information from the field, edge and cloud layers of an IoT system, in order to identify security threats at all these layers and accordingly to drive notifications and early preparedness to confront them. Furthermore, SecureIoT foresees cross-layer coordination mechanisms and will employees advanced analytics towards a holistic and intelligent approach that will predict and anticipate secure incident in order to timely confront them. Also, SecureIoT introduces a range of security interoperability mechanisms in order to support cross-vertical and cross-platform cyber-security scenarios. The SecureIoT architecture serves as basis for the provision of security services to IoT developers, deployers and platform providers, including a risk assessment, a compliance auditing and a secure programming support service. In this context, the rest of this chapter is structured as follows: Section 2 introduces the SecureIoT architecture and its main principles. Section 3 discusses the security services to be offered by the project, while Section 4 presents some use cases that will be used to validate the project’s results. 7.5.1 SecureIoT Architecture 7.5.1.1 SecureIoT architecture overview Figure 7.10. provides a high-level overview of the security architecture of the project. The architecture provides placeholders for predictive IoT security mechanisms, which can be contributed by different security experts in order to protect IoT infrastructures and services. In the scope of SecureIoT the partners will specify and implement such mechanisms in the areas of security monitoring and predictive analysis, which will serve as a basis for supporting the project’s use cases. Nevertheless, the project’s architecture is more general and therefore able to accommodate additional algorithms and building blocks. The architecture complies with the reference architectures specified by the Industrial Internet Consortium (IIC) and the OpenFog consortium [42], as it specifies: (i) The field level, where IoT devices (including smart objects) reside; (ii) The fog/edge level, which controls multiple devices close to the edge of the network. Note that the fog/edge level might be the first security layer in an IoT application, especially when resource constrained devices are deployed; (iii) The enterprise and platform levels, which reside at the core and where application and platform level security measures are applicable. Moreover, the SecureIoT architecture will also specify: Figure 7.10 Overview of SecureIoT Architecture. Interfaces for (security) data collection at all levels of the security architecture, including monitoring probes that are deployed at all levels. Data analytics modules (including AI and predictive analysis) at all levels, which extract insights about the future security state of the IoT infrastructure and applications. Semi-automated Policy Enforcement Points (PEPs), which are driven by predictive insights and enforce policies at different levels. PEPs will provide the means for enforcing security and cryptographic functionalities, configuring IoT platforms and devices for enhanced security, as well as for distributing security sensitive datasets. Multi-level security mechanisms and measures, which combine security monitoring, analytics and insights from multiple levels. Applicable policies and security measures are driven by regulations (e.g., GDPR), directives (e.g., NIS, ePrivacy) and standards (such as ISO27001 [43]). The ultimate goal of the architecture is to provide concrete services such as the SECaaS. The delivery of these services is facilitated by the development and maintenance of a security knowledge base, where metadata about IoT entities (i.e. objects platforms etc.) are registered along with knowledge collected and summarized based on multiple publicly available threat intelligence sources. Note that the security services of the architecture are offered as a service based on a Security-as-a-Service (SECaaS) paradigm. This however does not imply that the security services are solely deployed in the cloud. Rather, they can be offered based on a combination of cloud-based SaaS (Software-as-a-Service) security services and FaaS (Fog-as-a-Service) functions provided at the fog level. 7.5.1.2 Intelligent data collection and monitoring probes Assessing and optimizing the security posture of IoT components require the collection and the processing of their respective monitoring and configuration data. The produced monitoring data will allow IoT stakeholders to assess the security posture of their IoT platforms, to predict security issues, to enforce policies for hardening systems, to prevent network misuse, to quantify business risk, and to collaborate with partners to identify and mitigate threats. The collection of these data requires the development of dedicated probes and monitoring layers at different levels of the deployed IoT platform (device, network, edge and core) to capture a comprehensive and a complete view of its operations and interactions. In SecureIoT, monitoring probes will be provided to support the collection of log data, including network flows and software configurations, at the component, services and network levels. A key characteristic of SecureIoT’s security monitoring infrastructure (and related probes) will be its built-in intelligence in the data collection and pre-processing mechanisms, which will be implemented over the SecureIoT monitoring probes that will interfaces to different IoT platforms. As part of this intelligence, the data collection mechanisms will ensure data quality, data filtering, as well as adaptive selection of the needed data sources based on dynamic changes to the configuration of the IoT platforms, applications and smart objects. In order to implement this intelligence, the monitoring probes will be enhanced with data streaming analytics mechanisms, which will be able to process security-related information sources on the fly (i.e. almost at real-time) in order to adapt the filtering and data collection accordingly. This data collection intelligence will facilitate fast processing, as well as the implementation of predictive analytics schemes. 7.5.1.3 SecureIoT systems layers and information flows Figure 7.11. presents the layers of a SecureIoT compliant system, with emphasis on the flow of information from an IoT platform to the SecureIoT SECaaS services. The following layers are presented: Figure 7.11 Layers of SecureIoT systems. A layer of an individual IoT platform or system, which typically comprises network, devices/field, edge/fog, cloud and application-level components. These components are usually part of the target IoT platform or systems that needs to be secured based on SecureIoT. A data collection layer, which comprises the above-mentioned security monitoring probes. Note that probes will be specified and developed for all parts and components of the IoT system i.e. from the network and devices components all the way up to the IoT applications’ components. A data analytics layer, which is destined to process the data derived from the various probes. This layer is empowered by data analytics algorithms, but also by a range of cybersecurity templates, which specify rules and patterns of the security incidents that are to be identified. Taking network-level attacks as example, templates for specific types of network attacks will be specified such as TCP SYN attacks, UDP flood attacks, HTTP POST DoS (Denial of Service) attacks [43]. Each of the templates will comprise the rules and conditions under which the attacks will be identified. Likewise, templates for other types of attacks, including application specific ones will be specified and used. Along with these templates, the data analytics layer will comprise a contextualization component, which will be used to judge whether the attacks indicators are abnormal for the given IoT platform and application context. A cross-platform layer, which is destined to aggregate and correlate information derived from multiple-IoT platforms. It will serve as a basis for identifying attack indicators in cross-platform scenarios. All of the above layers and components will leverage the services of a knowledge base that will comprise information and knowledge about IoT-related cybersecurity attacks. It will be also used to drive the operation of the IoT security templates and the contextualization component. 7.5.1.4 Mapping to RAMI 4.0 layers SecureIoT is destined to support cybersecurity scenarios in both consumer and industrial settings. In order to strengthen the industrial relevance of the project’s architecture, the project will provide a mapping of the main building blocks of the SecureIoT architecture to the Reference Architecture Model Industry4.0 (RAMI 4.0) [45]. While this mapping is work in progress, the following associations and mappings are envisaged: The SecureIoT field layer, maps to the Field and Control Device hierarchy levels of RAMI4.0, as well as to its Asset Integration layer. The SecureIoT edge layer, maps tot eh Station and Workcenter hierarchy levels of RAMI4.0, as well as to its Asset, Integration and Communication layers. The SecureIoT cloud layer, maps to the Workcenter, Enterprise and Connected World hierarchy levels of RAMI4.0, as well as to its Information, Functional and Business layers. The SecureIoT application layer, maps to the Enterprise and Connected World hierarchy levels of RAMI4.0, as well as to its Business layer. The SecureIoT data collection layer, maps to the Field Device, Control Device, Station and Work Centers hierarchy levels of RAMI4.0, as well as to its Communication and Information layers. The SecureIoT analytics layer, maps to the Enterprise and Connected World hierarchy levels of RAMI4.0, as well as to its Information layer. The SecureIoT management layer, maps to the Enterprise and Connected World hierarchy levels of RAMI4.0, as well as to its Information, Functional and Business layers. 7.5.2 SecureIoT Services Based on its architecture, the project will offer risk assessment, compliance auditing and programmers’ support services as outlined in the following paragraphs. 7.5.2.1 Risk assessment (RA) services The SecureIoT RA services will aim at an efficient balance between realizing opportunities for gains, while minimizing vulnerabilities and losses. They will strive to ensure that an acceptable level of security is provided at an affordable cost. The SecureIoT framework will quantify risks in terms of a “likelihood factor”, which will be calculated based on combination of the probability and impact of any identified vulnerabilities. This “likelihood factor” will be appropriately weighted and ultimately normalized based on a risk calculation model in-line with NIST’s Common Vulnerability Scoring System (CVSS). Special emphasis will be paid in evaluating the criticality of risks associated with the behaviour and the operation of smart objects, as well as of services spanning multiple platforms. SecureIoT will therefore formulate a formal methodology and an accompanying model that will produce risk quantifications based on the identified vulnerabilities, potential threats and the impact estimation per potentially successful exploitation. SecureIoT will develop a risk quantification engine based on an expert system, which will provide flexibility in implementing different rules and assign different rates to the various risks. 7.5.2.2 Compliance auditing services This service will be delivered as a tool available to solution deployers, operators and end-users. Based on information collected through the security analytics, including the information of the IoT knowledge base. It will provide support for a set of security and privacy controls on the IoT infrastructures at multiple levels. The tool will be configured to support auditing of IoT infrastructures and services, against existing sets of security and privacy controls. The auditing will identify non-compliant behaviours and will provide recommendations about areas that require attention. Several prominent sets of security and privacy rules that will be supported concerning controls and measures specified in the scope of the GDRP regulation, NIS and ePrivacy directives. 7.5.2.3 Programming support services This service will enable developers to secure applications as part of their programming efforts. In particular, it will enable them to: (a) Enforce Distributed Access Control; (b) Ensure the cryptographic protection of data; and (c) Physical distribute sensitive data for enhanced security. These activities will be supported based on programming annotations, which will specify distributed access control, cryptographic protection and physical data distribution activities. A series of source generation, bytecode transformation and runtime reflection actions will be undertaken at specified Policy Enforcement Points (PEPs), which will be implemented at various levels i.e. the device, edge, core and application layers of the SecureIoT architecture. To this end, along with the security monitoring probes, the SecureIoT architecture will provide the means for configuring elements at the PEPs. 7.5.3 Validating Use Cases The project’s architecture and services will be validated in three use cases, which are briefly discussed in the following paragraphs. 7.5.3.1 Industrial plants’ security The use case will focus on plant networks for operations and support – e.g. SCADA, MES, PLCs, etc. – and enterprise networks connected to IoT-platforms providing support for automation and supply chain collaboration. The technical approach of the industrial IoT use case is twofold as reliability and availability of real world production must not be brought at risk. The following security challenges will be addressed, based on the SecureIoT services: Secure operations of connected factories with thread prediction: The SecureIoT risk assessment service will be therefore used to predict security issues arising from deployed automation technologies in a multi-vendor environment. Furthermore, SecureIoT’s prediction and mitigation services will enable the plant control to draw the right conclusions and prepare for attacks before they emerge. Compliance and Protection of product/user data in a multi-vendor environment: Factories need to protect product and user data sets. SecureIoT will be used in order to enforce privacy and data protection policies. Likewise, the compliance auditing SecureIoT service will be also used to identify and remedy gaps in the industrial IoT environment. Predictive Maintenance and Avoiding Machine Break-Downs in “Human in the Loop” Scenarios: Predictive maintenance requires trustworthy exchange, storage and processing of sensor and asset management datasets. Security analytics of IoT application level entities will be exploited as part of the SecureIoT risk assessment service in order to proactively identify issues with transmission and protection of datasets involved in the predictive maintenance process, in order to ensure the reliability of the process and avoid damages/losses in scenarios where machines foretell their lifetime and initiative actions in the supply chain (e.g., ordering of spare parts, scheduling of maintenance). 7.5.3.2 Socially assistive robots This use case will focus on security challenges associated with the integration of a socially assistive robot (i.e. QT robot from SecureIoT partner LuxAI) with a cloud-based IoT platform. This integration will target the delivery of personalized ambient assisted living functionalities, such as personalized rehabilitation and coaching exercises. In order to support these applications a dense IoT network, enable continuous interaction between IoT devices, robots, human users and the environment will be established. The integration challenge will however lie on keeping track of the state of the robot and the environment, as well as on implementing distributed task assignment strategies (such as the Consensus-Based Bundle Algorithm (CBBA)), which enable the distribution of application logic across different smart objects. The following security challenges will be addressed: Network and message security: The SecureIoT risk assessment and mitigation services will be used to identify threats associated with communications and network performance in order to appropriately adapt the operation of the application (e.g., stop the training if needed and deliver proper alerts to users). Prediction and avoidance of dangerous/risky situations: SecureIoT will monitor the robots’ operation both at the software level (i.e. through information flow tracking) in order to identify possible hacking of the robot, but also at the application level in order to detect abnormal operation/behaviour that can lead at risk. Secure programming environment for robotics missions: The programming interfaces of the robot will be enhanced with SecureIoT programming model and annotations in order to enable the developer of a rehabilitation mission to enforce policies specified in some policy language such as XACML (eXtensible Access Control Markup Language). Compliance to GDPR: An analysis of the application for GDPR compliance will take place, including automated identification of non-compliance risks (based on the SecureIoT risk assessment) and subsequent implementation of GDRP compliant policies based on the secure programming XACML-based mechanisms. 7.5.3.3 Connected car use cases This use case concerns security in connected cars scenarios, including: (i) Usage Based Insurance scenarios where vehicle data are analysed to assess driver behaviour and hence determine risks in order to better tailor insurance premiums for the customers; and (ii) Warnings on traffic and road conditions, that involve analysing data coming from multiple vehicles to understand the traffic conditions in different locations. From the point of view of cybersecurity for the usage-based insurance, it is important to ensure that the data transmitted is only accessible by the responsible organisation (privacy) and that the system cannot be corrupted such that a risky driver appears to be low risk. Moreover, the integrity of the data is a key requirement to ensure that insurance premiums are calculated fairly based on objectively assessed risk using accurate and trusted data. Likewise, for the traffic and road condition warnings it is vital that the data sent to the car is an accurate interpretation of the data provided from each vehicle. It This is because the system could be used maliciously to create congestion if the data is corrupted. Moreover, integrity of software running in the connected car is crucial. Recent attacks or security alarms raised has been focused on taking control over IoT devices and gateways. Over the air firmware update could be used as a countermeasure mechanism after an anomalous (or malware) detection. To address these challenges, the SecureIoT risk assessment framework will be employed, including predictive risk assessment functionalities. In case of identified issues, preventive measures will be activated (i.e. enforcement of data protection policies, provision of alerts to end-users, instigation and scheduling of over the air updates). 7.5.4 Conclusion SecureIoT is a first of a kind attempt to introduce a standards-based architecture for end-to-end IoT security. The project’s architecture is aligned to recent standards for industrial IoT security, including standards of the Industrial Internet Consortium and the OpenFog consortium. It makes provisions for collecting and analysing data from all layers of an IoT platform, while at the same time catering from cross platform and cross layer security analysis. Moreover, the SecureIoT architecture provides the means for defining and executing security actions at specific PEPs, as a means of enforcing policies and instigating mitigation actions. Based on this architecture, the project will implement risk assessment, compliance and the programming support services. SecureIoT is currently in its requirements engineering and specification phase, while it has also commenced its architecture specification activities. As part of the latter, the project will provide a mapping of its architectural concepts to the RAMI4.0 reference model. Moreover, the project will start the implementation of the data collection and data analytics mechanisms that will underpin the realization of the architecture and of its services. The project holds the promise to enhance the functionalities and lower the costs for securing IoT applications spanning multiple IoT platforms and smart objects. We will aspire to disseminate more detailed results through publications, presentations and other activities of the IERC cluster in the coming ten months. This work has been carried out in the scope of the H2020 SecureIoT project, which is funded by the European Commission in the scope of its H2020 programme (contract number 779899). The authors acknowledge valuable help and contributions from all partners of the project. 7.6 SEMIoTICS 7.6.1 Brief Overview SEMIoTICS aims to develop a pattern-driven framework, built upon existing IoT platforms, to enable and guarantee secure and dependable actuation and semi-autonomic behaviour in IoT/IIoT applications. Patterns will encode proven dependencies between security, privacy, dependability, and interoperability (SPDI) properties of individual smart objects and corresponding properties of orchestrations involving them. The SEMIoTICS framework will support cross-layer intelligent dynamic adaptation, including heterogeneous smart objects, networks and clouds, addressing effective adaptation and autonomic behaviour at field (edge) and infrastructure (backend) layers based on intelligent analysis and learning. To address the complexity and scalability needs within horizontal and vertical domains, SEMIoTICS will develop and integrate smart programmable networking and semantic interoperability mechanisms. The practicality of the above approach will be validated using three diverse usage scenarios in the areas of renewable energy (addressing IIoT), healthcare (focusing on human-centric IoT), and smart sensing (covering both IIoT and IoT); and will be offered through an open Application Programming Interface (API). SEMIoTICS consortium consists of strong European industry (Siemens, Engineering, STMicroelectronics), innovative SMEs (Sphynx, Iquadrat, BlueSoft) and academic partners (FORTH, Uni Passau, CTTC) covering the whole value chain of IoT, local embedded analytics and their programmable connectivity to the cloud IoT platforms with associated security and privacy. The consortium is striving for a common vision of creating EU’s technological capability of innovative IoT landscape both at European and international level. 7.6.2 Introduction Global networks like IoT create an enormous potential for new generations of IoT applications, by leveraging synergies arising through the convergence of consumer, business and industrial Internet, and creating open, global networks connecting people, data, and “things”. A series of innovations across the IoT landscape have converged to make IoT products, platforms, and devices, technically and economically feasible. However, despite these advancements the realization of the IoT potential requires overcoming significant business and technical hurdles. This includes several system aspects, including dynamicity, scalability, heterogeneity, and E2E security and privacy [46–48], as they are described below. IoT are dynamic, ever-evolving and often unpredictable environments. This relates to both IoT infrastructures as a whole (e.g. rapid development of new smart objects and IoT applications introducing new requirements to existing infrastructures and networks) and individual IoT applications (e.g. new users and types of objects connecting to said applications). This necessitates dynamically adaptive behaviour at runtime, at the IoT infrastructure, the IoT applications, and locally at the smart objects integrated by them. Intrinsic requirements (e.g. scale, latency) dictate the need for, at least, semi-autonomic adaptation at all layers. The fast-growing number of interconnected users, smart objects and applications requires high scalability of the IoT infrastructure and network layers. At the network, the vastly increased demands require highly efficient programmable connectivity, service provisioning and chaining in ways that guarantee the much-needed end-to-end (E2E) optimizations, addressing dynamic IoT application requirements. Scalability at the IoT infrastructure level requires seamless discovery and bootstrapping of smart objects, as well as highly efficient orchestration, event processing and analytics and IoT platform integration. Despite advancements in standardization, there is still limited semantic interoperability within IoT applications and platforms. Semantic interoperability requires three key abilities: (a) to recognize and balance the heterogeneous capabilities and constraints of smart objects, (b) to interpret data generated by such objects correctly, and (c) to establish meaningful connections between heterogeneous IoT platforms. Smart objects, IoT applications, and their enabling platforms are often vulnerable to security attacks and changing operating and context conditions that can compromise their security [49]. They also generate, make use of, and interrelate massive personal data in ways that can potentially breach legal and privacy requirements [49]. Preserving security and privacy properties remains a particularly challenging problem, due to the difficulty of: (a) analysing vulnerabilities in the complex E2E compositions of heterogeneous smart objects, (b) selecting appropriate controls (e.g., different schemes for ID and key management, different encryption mechanisms, etc.), for smart objects with heterogeneous resources/constraints, and (c) preserving E2E security and privacy under dynamic changes in IoT applications and security incidents, in the context of the ever-evolving IoT threat landscape [50]. The above challenges give rise to significant complexities and relate to the implementation and deployment stack of IoT applications to address them. The overall aim is: demands without considering the data volume. Taking into consideration this ratio, green IT technologies have important environmental and economic benefits. Circular Economy (CE) advocates a continuous development cycle that reforms the currently prominent ‘take-make-dispose’ linear economic mode by preserving and enhancing the natural capital. SEMIoTICS will also provide the intelligence analytics capabilities and Information Communication Technologies (ICT) that are required for turning IoT data into a worthy asset for CE-centric businesses (e.g. [51]). 7.6.3 Vision The main goal of the SEMIoTICS project is to develop a pattern-driven framework, built upon existing IoT platforms. The proposed framework will enable and guarantee the secure and dependable actuation and semi-automatic behaviour in IoT/IIoT applications. Specifically, the SEMIoTICS vision in delivering smart, secure, scalable, heterogeneous network and data-driven IoT is based on two key features: Pattern-driven approach: Patterns are re-usable solutions to common problems and building blocks to architectures. In SEMIoTICS, patterns encode proven dependencies between security, privacy, dependability and interoperability (SPDI) properties of individual smart objects and corresponding properties of orchestrations (composition) involving them. The encoding of such dependencies enables: (i) the verification that a smart object orchestration satisfies certain SPDI properties, and (ii) the generation (and adaptation) of orchestrations in ways that are guaranteed to satisfy required SPDI properties. The SEMIoTICS approach to patterns is inspired from similar pattern-based approaches used in service-oriented systems [52, 53], cyber physical systems [54] and networks [55, 56]. Multi-layered Embedded Intelligence: Effective adaptation and autonomic behaviour at field (edge) and infrastructure (backend) layers depends critically on intelligent analysis and learning the circumstances where adaptation actions did not work as expected. Intelligent analysis is needed locally for semi-autonomous, prompt reaction, but taking into account IoT smart objects limited resources (thus requiring specialized lightweight algorithms) [55, 57]. It should also be possible to fuse local intelligence to enable and enhance analysis and intelligent behaviour at higher levels (e.g. using results of local analysis of “thing events” to globally predict and anticipate failure rates) [58]. 7.6.4 Objectives The SEMIoTICS project will target IoT applications with heterogeneous smart objects, various IoT platforms and different SPDI requirements. Seven main objectives are identified by the SEMIoTICS project including: The development of patterns for orchestration of smart objects and IoT platform enablers with guaranteed SPDI properties The development of semantic interoperability mechanisms for smart objects, networks, and IoT platforms, like semantic information broker that resolve the semantics of correlated ontologies and common APIs that enable cross-platform programming and interaction The development of dynamically and self-adaptable monitoring mechanisms, supporting integrated and predictive monitoring of smart objects in a scalable manner The development of core mechanisms for multi-layered embedded intelligence, IoT application adaptation, learning and evolution, and E2E security, privacy, accountability and user control The development of IoT-aware programmable networking capabilities based on adaptation and Software-Defined Networking (SDN)/Network Function Virtualization (NFV) orchestration The development of a reference prototype open architecture demonstrated and evaluated in both IIoT (renewable energy) and IoT (healthcare), as well as in a horizontal use case bridging the two landscapes (smart sensing), and delivery of the respective open API The adaptation of EU technology offerings internationally These objectives are accomplished, considering the intrinsic requirements of three main use case scenarios for an industrial wind park, an e-health system, and a smart sensing setting. 7.6.5 Technical Approach Figure 7.12 shows our initial vision of the logical architecture of SEMIoTICS framework and how it relates to smart objects, IoT applications, and existing IoT platforms, and how does it map onto a generic deployment infrastructure consisting of private and public clouds, networks, and field devices. Within the figure, blue boxes show components of the framework that are to be developed by SEMIoTICS; white boxes indicate components of IoT applications managed by the framework. The key role of the SEMIoTICS framework in the IIoT/IoT implementation stack is to support the secure, dependable and privacy-preserving connectivity and interoperability of IoT applications and smart objects used by them, and the management, monitoring and adaptation of these applications, objects and their connectivity. Figure 7.12 SEMIoTICS architecture (deployment and logic views). 7.6.5.1 Enhanced IoT aware software defined networks The sheer number of smart objects that are expected to connect to the Internet by 2020 (more than 50bn smart objects) will increase network traffic dramatically and introduce more diversity of network traffic (from elephant flows to mice flows). This makes the development of networking techniques that are significantly more scalable and agile than today’s networks an absolute necessity. Networks will need to dynamically reconfigure their resources and maintain network connectivity. Also, applications running on top of smart connected devices will need to be resource and network-aware, in order to take full advantage of underlying network programmability. In summary, IoT requires more agile networks. SDN can provide a solution to this problem. It allows network programmability, which can be used to decouple network control from the forwarding network (aka data) plane and to make the latter directly programmable by the former. Integrating IoT and SDN will increase network efficiency as it will make it possible for a network to respond to changes or events detected at the IoT application layer through network reconfiguration. If a spontaneous concentration of people in a specific place is detected by an IoT application, for example, the application can send a request to the SDN controller to reconfigure the network and provide more bandwidth to the area before network congestion occurs. As another example, consider an IoT application where sensor readings are transmitted periodically. In such cases, network resources on the path connecting the sensors to the backend IoT application can be reserved during the reporting cycles to enable efficient flows and released outside them. SEMIoTICS aims to develop a middleware layer between the IoT applications and the SDN-controlled field network, abstracting the underlying protocol implementations and SDN APIs. This will allow IoT applications to trigger the network reconfiguration through pattern-driven adaptations. In this view, SDN becomes another component in the IoT implementation stack which, like other components, can be dynamically configured through SPDI patterns [56]. 7.6.5.2 Localized analytics for Semi-Autonomous IIoT operation An IDC FutureScape report [59] for IoT reported that by 2018, 40 percent of IoT data will be stored, processed, analysed and acted where they are created before they are transferred to the network. There are two main reasons for this: big data volume and fast reaction. First of all, IoTs/IIoTs are generating an unprecedented volume and variety of data depending on the vertical use case. Not all these data need to be sent always to the cloud for storage and processing. Indeed, the volume of the data makes it in many cases extremely difficult to process them globally in an efficient manner and hinders learning the relations that are hidden in the data. For this reason, we need to enrich the generated and collected data with semantic information at the source and intermediate stations, process them locally with machine learning algorithms to extract the most important features of the data and only then transfer the learned local features to the cloud for further, global, processing and feature analysis. Hence, new approaches, techniques, and corresponding designs need to be developed to store, analyse, and derive insight from these data sets. This has already been identified as a challenge by the industry, e.g. Forrester [60] highlighting the need of IoT applications for distributed analytics since centralized analytics cannot cope for many IoT usage scenarios, and Gartner [61] emphasizing the importance of IoT edge architecture and IT/OT integration for achieving such distributed and layered data analysis. The second reason driving the need for localized analytics is fast reaction. By the time the data makes its way to the cloud for analysis and some analysis results have been obtained and transferred back to the field layer, so much time has passed that the opportunity to act effectively on the obtained analysis results at the field layer (e.g. smart actuation) is usually long gone. Again, this is a crucial requirement for the industry – Forbes and Moor Insights & Strategy (MI&S) [62] expects that machine learning-enabled reaction to changes in the current environmental/system context to be essential for IoT solutions. By 2020 MI&S believes that the machine learning at edge combined with central machine learning in cloud arrangements will exist in a large number of solutions and will account for a great deal of the innovation in IoT world – giving a substantial market advantage to the providers of such solutions. By doing a fast analysis on the local data (whose volume is much reduced compared to the entire data produced by the IIoT/IoT system and thus should be analysable with substantially fewer resources), an IIoT/IoT system can react quickly to context changes and adapt to them, in ways that optimise the use of both its own resources and the environment’s, and eventually improving the overall user experience. SEMIoTICS will develop localized analytics at the edge for semi-autonomous operation with smart actuation and use the results of the localized analytics to help improve the subsequent, global analysis that will be performed on the cloud for learning across the whole system and extraction of global patterns – itself a task whose results can be used by local analytics mechanisms to improve their performance and be able to proactively react to situations that had not been observed at that local point in the past but had occurred at other parts of the system. 7.6.6 Security Architecture Concept As aforementioned, the SEMIoTICS vision is articulated around the development of a framework for smart object and IIoT/IoT application management based on trusted patterns, monitoring and adaptation mechanisms, enhanced IoT centric networks and multi-layered embedded intelligence. These core elements of our approach are described below. 7.6.6.1 Pattern-based trustworthy IIoT/IoT The key element enabling the SEMIoTICS approach is the use of architectural SPDI patterns. These patterns define generic ways of composing (i.e., establishing the connectivity between) and configuring the heterogeneous smart objects and software components that may exist at all layers of the IoT applications implementation stack, including: sensors and actuators; smart devices; software components at the network, cloud, IoT enabling platforms and/or other middleware layer; as well as software components at the IoT application layer. To do so, patterns specify abstract and generic smart object interaction and orchestration protocols, enhanced (if necessary) by transformations to ensure the semantic compatibility of data. Furthermore (and more importantly), the smart object interaction and orchestration protocols encoded by the patterns must have proven ability (i.e., an ability proven through formal verification or demonstrated through testing and/or operational evidence) to achieve not only a semantically viable interoperability between the smart objects that they compose but also specific SPDI properties, which may be required of compositions. The compositions defined by patterns are both vertical and horizontal, i.e., they can involve smart objects at the same (horizontal) or different layers (vertical) layer of the IoT implementation stack. As an example of a pattern that guarantees “data integrity” – i.e., absence of unauthorized modifications of data – consider the integrity preserving cascade composition pattern discussed in [63, 64]. According to this pattern in a sequential composition of processes P1, …, Pn where the input data of Pi are meant to be the output data of Pi-1, and the communication between Pi-1 to Pi (i=2,…, n) is based on an orchestrator O which facilitates data transfers from Pi-1 to Pi, overall data integrity is preserved if data integrity is preserved within each Pi, within O and across all communications from PiS to O and vice versa. The integrity cascade composition pattern applies both to horizontal compositions (e.g., in software services workflows as in [63, 64]) and vertical composition (e.g., in transfer of data in invocation of operations of IoT enabling middleware). Another (more complex) example of a pattern fitting the SEMIoTICS vision is the synchronously controlled distribution line (SCDL) pattern discussed in [54]. SCDL guarantees that a distributed asynchronous sensor system installed upon a physical pipeline (e.g., a pipeline of an electricity distribution network) will operate in virtual synchrony and provide a guaranteed density of readings (i.e., a bounded minimum number of readings per distant and per time unit). The pattern suggests a composition consisting of: (i) sensors connected to a controller through a middleware component that realizes a bounded reliable message delivery protocol; (ii) a controller with the capability to authenticate sensors, store readings received from them in fixed length intervals, and substitute missing or corrupted sensor readings with synthetic readings computed through the linear interpolation of readings from their closest adjacent sensors and the end of reading intervals. The application of the SCDL pattern is proven to guarantee the consumption of readings at the end of the reading interval where they fit, make them available in a synchronous manner, filter out illegitimate readings and produce readings of the required density for the pipeline. In SCDL pattern, these properties are guaranteed even in the presence of missing or corrupted raw data, as long as there is a minimal number of legitimate sensor readings. Examples of additional patterns have been given in [52] and [56]. These include patterns for confidentiality in service orchestrations and patterns for availability in Software Defined Networks, respectively. Inspired by these earlier works, SEMIoTICS patterns will develop patterns specifying: Composition structures for integrating smart objects and components of IoT enabling platforms (e.g., platform enablers) in a manner that guarantees SPDI properties. The E2E SPDI properties that the compositions expressed by the pattern preserve. The component level SPDI properties that the types of smart objects and/or components orchestrated by the pattern, must satisfy in order to preserve the end-to-end SPD properties. Additional conditions that need to be satisfied for guaranteeing end-to-end SPDI properties. These may, for example, include configuration conditions that need to be satisfied by the IoT platforms and the networks providing the connectivity between them, for guarantying the end-to-end availability properties of IoT application (composition). Monitoring checks that must be monitored at runtime in order to verify that any assumptions about the individual smart objects and components that are orchestrated by a pattern or other operational conditions, which are critical for the preservation of the end-to-end SPDI properties of the pattern, hold at runtime. Adaptation actions that may be undertaken to adapt IoT applications, which realise the composition structure of the pattern, at runtime. Such actions may, for example, include the replacement of individual smart objects within a composition; the adaptation of the process realizing the composition; the modification of the configuration of the network services used to connect the smart objects of the composition and/or the deployment platforms upon which these objects run. Adaptation actions are specified along with guard conditions determining when they can be executed (guards are monitored, and adaptation is triggered when they are satisfied). SEMIoTICS will also develop a generic engine supporting the execution of patterns at runtime to realize the overall process of monitoring, forming, adapting and managing smart object orchestrations in IoT applications. 7.6.6.2 Monitoring and adaptation The SEMIoTICS framework will support evolving runtime management and adaptation of IoT applications and smart objects [55–58]. Adaptation will be triggered by monitoring the guard conditions of the patterns used by the IoT application of interest, and applying the actions defined in the patterns when such conditions are satisfied. The SEMIoTICS framework will also monitor and analyse the effectiveness of patterns and the adaptation actions undertaken in reference to the contextual and operational conditions in which they were undertaken. This will be to identify deficiencies or failures in applying the patterns, to diagnose the reasons which may have caused deficiencies or failures and avoid the application of the same pattern(s) under the same conditions in subsequent phases. The use of a specific type of network connectivity or a specific type of sensor object amongst alternative options may, for example, prove to be a non-optimal option for network performance or sensor signal reliability under particular conditions. Similarly, certain data transformations may prove excessively time consuming for achieving the required scalability in an IoT application. Monitoring will also be necessary to ensure that any component level SPDI properties assumed by the pattern are upheld whilst the pattern is active (i.e., in use) in an IoT application. Beyond the basic monitoring of the contextual circumstances surrounding the operation of different smart objects and IoT applications, the SEMIoTICS framework will incorporate learning and evolution mechanisms supporting the analysis of any adaptation and configuration actions undertaken for an IoT application. This will be necessary in order to identify whether the application of patterns is effective over time (e.g., it does indeed prevent the occurrence of breaches of SPDI properties) and what might be the reasons for not being effective when this is the case. 7.6.7 Use Cases SEMIoTICS will target three IoT application scenarios: two verticals in the areas of energy and health care and one horizontal in the areas of intelligent sensing. These scenarios have been selected since they involve: (a) different and heterogeneous types of smart objects (i.e., sensors, smart devices, actuators) and software components; (b) different vertical and horizontal IoT platforms; and (c) different types of SPDI requirements. Due to these dimensions of variability, our scenarios provide comprehensive coverage of technical issues, which should be accounted for in developing the SEMIoTICS approach and infrastructure, and to this end provide an effective way for driving the R&D work programme of SEMIoTICS and evaluating and demonstrating its outcomes. 7.6.7.1 Renewable energy – Wind energy Current state of the art of Wind Turbine Controller in a Wind Park control network is typically an embedded or highly integrated operating system, which follows rigorously development and pre-qualification prior to deployment in the real world. As a result of this slow process, new features, adding new sensors, actuators and related advancements require several months or even years to be fully matured and operational in the field. Taking local action on sensing and analysing structured data to find the inclination of a steel tower – When the nacelle is turned during a cable untwisting event (Sensing), the gravity acceleration (Ag) component measured by an accelerometer in longitude direction (Ay) will vary as a function of the inclination (Inc) of the steel tower. O&M personnel in remote control center wants to know the inclination of all the steel towers on a number of specific wind farms, as these details will have to be shared with the customer to monitor the deformation and fatigue of the steel. To find the inclination of a steel tower, a full cable-untwist procedure has to be activated. This happens, depending on wind conditions, 3–4 times a month. It is also possible to manually instruct the wind turbine to perform the unwind procedure. At the time of the unwindingprocedure a hi-frequency set of data is recorded. A relatively large amount of data is required to calculate the inclination. This datasheet needs to be sent back to the remote control center to model and calculate the inclination. In SEMIoTICS, localized edge analytics will be applied which will result in semi-autonomous IIoT behavior as only the container containing the algorithm and result of the inclination calculation is transferred to between the wind turbine and the remote control centre. The unnecessary data traffic between each turbine and remote control centre is greatly reduced. Without the localized analytics functionality, all the hi-frequency acceleration and nacelle position data should have transferred to remote control centre resulting in suboptimal operation. Smart Actuation by sensing unstructured video/audio data – Within the turbine, there are many events which can be captured by IIoT sensors such as Grease leakage detection during normal operation or unintended noise detection when the turbine rotor is changing the direction in the line of wind to maximize energy production. The sensing of this unstructured data and acting locally to prevent any damage to the parts of the turbine in the long run will be of key importance. Localized analytics, as proposed in SEMIoTICS, which will lead in smart actuation to protect the critical infrastructure of renewable energy resources. SEMIoTICS implements: Industrial Things semantic discovery, Bootstrapping of IIoT devices and Gateway Inventory of the things at the SDN controller REST-based Intent interface for network-agnostic cloud applications Security at every layer Local data analytics at the Sensors, Actuators and Gateway 7.6.7.2 Healthcare This healthcare use case is an attempt to come up with usable, acceptable and sustainable IoT solution for assisted mobility through falls prevention leading to active and healthy ageing. Falls in older adults are a significant cause of morbidity and mortality and are an important class of preventable injuries. This use case specifically focuses on advanced fall prevention and management solution aimed at both senior citizens and adults with Mild Cognitive Impairment or mild Alzheimer’s disease and their (informal) caregivers. The objective of this scenario is to extend the existing IoT platform like AREAS with Assisted Mobility Module (AMM) which is a dedicated module for the management of, and integration of information from, a network of IT services and hardware devices constituting an advanced fall prevention and management solution aimed at both senior citizens and adults with Mild Cognitive Impairment or mild Alzheimer’s disease and their (informal) caregivers. Given the figures introduced at the beginning, the social dimension of the solution is reflected in the improved quality of life for people that are susceptible to falls, given that AMM will prolong the time they can work and live independently. The envisaged evolution of the AMM will see the inclusion of additional robotic elements, in particular, the system will include a: Robotic Assistant (RA) connected to a network of embedded IoT devices and services for monitoring (and maintaining a diary of) a patient’s activities, health status and treatment, as well as for supporting cognitive skills training, notifying/reminding the patient of upcoming treatments (e.g. medication schedules) and visits. Personal assistant robots may help the patients with their daily activities like walking trail and other routine. SEMIoTICS will contribute in the: Integration of distributed IoT devices with higher degree of autonomy (i.e. robotic devices) Exploitation of computational resources both in the cloud and at the edge Security and privacy of patient data, safety of a patient 7.6.7.3 Generic IoT & smart sensing Today’s IoT embedded devices are often described as smart devices. “Smart” usually shall be associated to some Things that show some form of intelligence, bright behaviour during their operations. Unfortunately, current meaning and their reality is that they are locally programmable and always connected to some cloud infrastructure (e.g. typically through a wireless connection such as Wi-Fi or Bluetooth Low Energy) to send raw data. Therefore, these devices transmit sensed data to the cloud without any analytic being performed locally and without showing remarkable forms of computational intelligence. An IoT thing is intelligent is it has capabilities to learn from and act upon the data (at least without supervision) it is sensing. Sometimes, they also receive back from the cloud some form of actuation (control) instructions, which are determined by a centralized server-based analysis of sensed and other data. A typical example, on domotic applications, is the one where several sensing nodes stream some relevant raw data at given interval (e.g. temperature, humidity, pressure) to a cloud service. An example is the Microsoft Azure or IBM Bluemix cloud platforms and related ecosystem. In this scenario, the intelligent data processing always resides remotely, and the communication channel is (implicitly) assumed to be always present and open. The use case provides: Evolution of platform technologies enabling local analytics computing (i.e. edge computing) Enhanced IoT system scalability and increased robustness Open market enhanced middleware portfolio for intelligent embedded devices and innovative businesses opportunities SEMIoTICS’s research efforts focus in the: Support for tight integration at device level of sensing and computational elements in close tight cooperation on dedicated embedded HW (i.e. edge computing) Increased system scalability and computational partitioning to enhance system responsiveness and stability by exploiting self-adapting online learning mechanisms Enhanced architectural models redefining system from bottom to top for handling the continuous and discrete sensing. 7.6.8 Summary SEMIoTICS aims to develop an open IIoT/IoT framework, interoperating with existing IIoT/IoT platforms (e.g. FIWARE, MindSphere) and programmable networking, through their exposed APIs. The SEMIoTICS framework will also integrate IIoT and IoT sensing and actuating technologies. A core element of the SEMIoTICS approach is the development and use of patterns for orchestration of smart objects and IoT platform enablers in IoT applications with guaranteed SPDI properties. Patterns constitute an architectural concept well founded in software systems engineering. SEMIoTICS advocates the patterns approach to systems engineering, but uses a novel pattern type (i.e., SPDI patterns) to guarantee semantic interoperability, security, privacy and dependability in large scale IIoT/IoT applications integrating smart objects. Said patterns will be supported by mechanisms featuring integrated and predictive monitoring of smart objects of all layers of the IoT implementation stack in a scalable manner, as well as core mechanisms for multi-layered embedded intelligence, IoT application adaptation, learning and evolution, and end-to-end security, privacy, accountability, and user control. This approach will enable and guarantee secure and dependable actuation and semi-autonomic behaviour in IoT/IIoT applications, supporting cross-layer intelligent dynamic adaptation, including heterogeneous smart objects, networks and clouds. 7.7 SerIoT The Internet of Things or Internet of Everything envisages billions of physical things or objects (sensors and actuators) connected to the Internet via heterogeneous access networks. IoT is emerging as the breakthrough technology introducing the next wave of innovations, including revolutionary applications, significantly improving and optimizing our daily life. The IoT is capable to create a complex Network of Networks system through IP protocol and Mobile Network connectivity, allowing “things” to be read, controlled and managed at any time and at any place. This brings such technical issues as the lack of a shared infrastructure, lack of common standards, problems with the flexibility, scalability, adaptability, maintenance, and updating the IoT devices, etc. Especially important are security concerns, resulting from all of the listed technological aspects [77, 78]. In case of lack of the IoT related security standards and commonly accepted technological solutions, every vendor creates their own solutions. Moreover, the solutions currently used in IT systems are mostly unsuitable for direct application in IoT, e.g. authentication based on central server that works well for small scale systems but does not provide sufficient mechanisms for future large scale IoT ecosystems. On the other hand, attacks on the IoT platforms will have significant economic, energetic and physical security consequences, beyond the traditional Internet lack of security. 7.7.1 SerIoT Vision and Objectives SerIoT aims to conduct research for the delivery of a secure, open, scalable and trusted IoT architecture. The solution will be implemented and tested as a complete, generic solution to create and manage large scale IoT environment operating across IoT platforms and paying attention on security problems. A decentralized approach, based on peer to peer, overlay communication is proposed [69]. SerIoT will optimize the security of IoT platforms in a cross-layered manner. The concept of Software Defined Networks (SDN) is used and SDN controllers are organized in hierarchical structure [74, 75]. The objectives of SerIoT include to provide the prototype implementation of a self-cognitive [66–68], SDN based core network, easily configurable to adapt to any IoT platform, including advanced analytics modules, self-cognitive honeypots and secure routers. The solution will be supported by appropriate technologies such as Decision Support System (DSS) supplementing controller’s functionality. The DSS will be able to detect the potential threats and abnormalities. The system will be supplemented with comprehensive and intuitive visual analytics and mitigation strategies that will be used according to the detected threats. It will be validated in the final phase of the project through representative use cases scenarios, involving heterogeneous EU wide SerIoT network system. 7.7.2 SerIoT Architecture Concept The SerIoT architecture [65] is based on a software-managed network implementing SDN technology and is divided into the following layers and modules (See Figure 7.13.). Figure 7.13 The structure of layered SerIoT architecture. The IoT Data Acquisition layer is comprised of the low-level IoT-enabled components that create the infrastructure backbone, including honeypots, dedicated engines and storage capabilities and the SDN secure routers. The SDN routers will use OpenFlow communication and will be based on Open Switch implementation being significantly extended to cooperate with related SerIoT modules and security mechanism. The backbone network will be divided into domains (subnets). Every subnet constitutes an autonomic SDN network, controlled by the SDN controller and extended according to SerIoT needs. Controllers will be organized into hierarchical structure [76]. The first level controller is responsible for the routing within the subnet using gathered data. It will be also able to route packets to neighbouring subnets (via the appropriate border node). In the case of destinations outside their own subnet and neighbouring subnets, routing requests will be sent to a second (or third, fourth, etc.) level controllers. The controllers will continuously gather information to feed the analytics module. These components will be connected to visual analytics module and support decision making system. The Ad-hoc Anomaly detection layer will provide a number of security mechanisms, executed across IoT devices, honeypots and SDN routers. Anomaly detection techniques based on local traffic characteristics (as dynamic changes in queue lengths) will be regularly probed by smart “cognitive packets” sent by the SDN controller and feeding the controller routing decisions. The controller will have the ability to detect suspicious and risky paths, and re-schedule the routing paths over secure, preferable connections according to secure aware routing, but also energy and Qality of Service (QoS) aware routing [71–73]. The Visual Analytics and Decision Support tools will deal with the interactive decision support applications that will be delivered to the end-users, able to effectively detect potential abnormalities at different levels of the network. The end-user tool will be developed together with a novel visual analytics framework, dealing with the effective management and visualization of data. The Mitigation and Counteraction Module will be responsible for implementing decisions taken by the Decision Support tools. The module will use dedicated software and network components as SDN routers, honeypots and IoT devices. The SerIoT platform will ensure the separation of enterprise and private data. The system will provide monitoring mechanisms and anomaly detection techniques, using a cross-layer data collection infrastructure that will allow effective information transmission and data aggregation for analysis. A prototype honeypot with the ability to analyse network traffic and detecting anomalies will be developed. This new architecture for ensuring security, based on SDN technology, should bring a significant progress in comparison to current solutions. The innovatory approach used in SerIoT network will be using Cognitive Packets [70] for gathering network data on QoS, security state and energy usage, and Cognitive Packet Network routing engine, based on Random Neural Networks (RNN) [79, 80]. The concept is a combination of neural-networks-based routing and source routing. It was successfully applied in SDN network [71], and in the SerIoT project will be extended both in terms of data used as input for routing engine and of scale of the networks. Security data will be used as input for learning of RNN, along with QoS and energy usage data, to allow finding secure and efficient routes for every SDN flow. 7.7.3 Use Cases The solutions of the SerIoT project will be evaluated in individual laboratory test-beds and also in an integrated EU wide test-bed which will interconnect significant use cases developed by SerIoT industry partners. SerIoT aims to design and to deploy four innovative use cases arising from three significant for the global economy domains where the use of IoT is rapidly increasing: (i) Smart Cities domain will be covered by two ambitious use cases where Surveillance and Intelligent Transportation IoT networks will be evaluated, (ii) Flexible Manufacturing domain with the detection of physical attacks on wireless sensor networks, and finally (iii) a novel Food Chain Scenario will be exploited demonstrating mobility security issues. Each of the use cases considers one or several scenarios. A scenario is intended to describe and specify the system behaviour according to a specific situation, or in other words to describe the situation in which a specific system should work and how the system works and interacts with the different users: Use Case 1 (Surveillance) scenarios: Facilities monitoring Embedded intelligence in buses Use Case 2 (Intelligent Transport Systems ITS in Smart Cities) scenarios: Automated driving Public transport maintenance Public transport security Road side ITS stations Use Case 3 (Flexible Manufacturing Systems) scenarios: Wireless robots in warehouse Critical infrastructure protection Use Case 4 (Food Chain) scenario: Fresh food deadline control 7.7.4 Industrial and Commercial Involvement SerIoT has strong support regarding industrial know-how and implementation. Among the Consortium partners there are eight industrial or small/medium size enterprises (SME) with diverse and complementary technological and research expertise, covering the full spectrum of research and innovation activities anticipated in the project [65]. Six of these partners are large industrial societies able to support the multi-disciplinary topics introduced in SerIoT, i.e. IoT telecom/network infrastructure & Industry 4.0 Use Cases by DT/T-Sys, IoT anomaly detection by ATOS, IoT applications & platform by DT/T-Sys., design-driven & cross-layer analytics by ATOS. Moreover, SMEs involved in the consortium are among the leading and innovative companies in their sectors. Hence, a large amount of innovation foreseen in the project will be also carried by SMEs. What all SerIoT SME partners share in common is their proven ability to apply research results into successful and well established commercial products (e.g. HOP Core, Wear & Extended innovative solution by HOPU). Having in mind their strong commitment in delivering new services in their customers, industrial & SME partners have identified complementary private investments to support the SerIoT business perspectives. Moreover, specific dissemination actions will be carried out, through already established communication channels, networks and working groups in order to ensure that the new & open solutions of the project will be conveyed to major stakeholders in Europe and Worldwide. 7.7.5 Summary In this paper we outline the EU H2020 SerIoT project that addresses IoT security challenges. As a scientific project, SerIoT will provide a new approach to understand the threats to IoT based infrastructures and deliver methods to solve the security problems in the IoT. Pioneering research and development based on holistic approaches will be conducted. A generic IoT framework based on an adaptation of the concept of Software Defined Networks with Cognitive Packets will be developed as well as the new methods for intrusion detection with the use of a cross-layer approach. Visual analytics tools for analysing threats in IoT ecosystem will be used. 7.8 SOFIE – Secure Open Federation for Internet Everywhere The main goal of the SOFIE [83] project is to enable diversified applications from various application areas to utilise heterogeneous IoT platforms and autonomous things across technological, organisational and administrative borders in an open and secure manner, making reuse of existing infrastructure and data easy. SOFIE is guided by the needs of three pilot use cases with diverse business requirements: food supply-chain, mixed reality mobile gaming, and energy markets. Furthermore, we will explore the synergies among these areas, building a foundation for cross-application-area use of existing IoT platforms and data. SOFIE will design, implement and pilot a systematic, open and secure way to establish new business platforms that utilise existing IoT platforms and distributed ledgers. With “openness”, we mean flexible and administratively open business platforms, as well as technically decentralised federation to enable the interoperability of different IoT platforms, ledgers, and autonomous devices. To realise this vision, SOFIE brings together large system vendors and integrators (ENGINEERING and Ericsson), high tech SMEs delivering highly innovative products and solutions (GuardTime, Synelixis) and prestigious universities (Aalto University and the Athens University of Economics and Business). The results of the project will be guided by these three use cases and will be tested in an equal number of real-life trials. For this purpose, the consortium includes ASM TERNI S.p.A., a public multi-utility company and Emotion who will trial SOFIE developments in the energy sector, OPTIMUM, a leading SME in the area of supply chain IT systems, which (together with SYNELIXIS) will trial SOFIE in the realisation of a farm-to-fork scenario and Rovio Entertainment Corporation, which will lead the SOFIE trial in a mixed reality mobile gaming context. 7.8.1 Objectives The SOFIE consortium has broken down the high-level goal into the following specific and tangible objectives: Define a secure, open, decentralised and scalable IoT federation architecture for sensing, actuation, and smart behaviour. In order to stay open and interoperable, emerging standard interfaces should be used between the components and towards the outside world. Make IoT data and actuation accessible across applications and platforms in a secure and controlled way. SOFIE must provide the means to reuse data, within the limits set by its owner, across applications. Develop a solution to provide integrity, confidentiality and auditability of IoT data, events and actions. SOFIE shall define and implement ledger-independent transactions that can be simultaneously entered into various closed and open blockchains and other persistent ledgers. Develop an IoT federation framework to facilitate creation of IoT business platforms. The framework can be used to create business platforms, including those for the three pilot use cases. Deploy and evaluate the SOFIE federation framework in three field trials. Evaluate the commercial viability of the SOFIE federation approach based on the three field trials and research on business models. Establish the SOFIE IoT federation approach as a major enabler for the IoT industry through dissemination, standardization, education, workshops and pilots. 7.8.2 Technical Approach SOFIE combines several IoT platforms and distributed ledgers into a federated IoT platform supporting the reuse of existing IoT infrastructure and data by various applications and businesses. Figure 7.14 illustrates the overall architectural approach. Figure 7.14 SOFIE Secure and Open Federation Architecture. SOFIE achieves decentralization of business platforms through the use of DLTs. Since the properties of various DLTs, such as scalability, throughput, resilience, and openness, are significantly different, SOFIE relies on using multiple different DLTs in parallel. To allow transactions to be recorded into multiple blockchains or other ledgers, SOFIE will design and implement the inter-ledger transaction layer. We will build upon existing leading-edge work, including the W3C-associated Inter-ledger Protocol (ILP), applying the results to the IoT domain, and developing them further. The transactions will be implemented as multi-stage smart contracts whose resolution depends on the transactions being correctly recorded in all the participating ledgers, but without requiring that all the ledgers support smart contracts. The inter-ledger transaction layer will be used for three main purposes: Describe the (“things”) data in the existing IoT platforms, enabling financially tied IoT actuation between organisations and storing security-related data. Enable secure and traceable IoT actuation. The idea is to negotiate and use smart contracts that may span multiple ledgers to record intention or desire to actuate, to trigger actuation, to permanently record both actuation instances and the related sensor values, and to trigger any financial transactions, thereby supporting smart behaviour. Enable interoperability between diverse existing IoT platforms. This is achieved by augmenting the existing IoT platforms with a federation adapter. These together allow applications to: discover what data and things are available in the IoT platforms; acquire the necessary permissions for access (e.g. by promising to pay or placing a pledge); access the data and/or request actuation in a secure, recorded, and compensated manner; and verify whether the requested actuation took place or not. Beneath the inter-ledger transaction layer are distributed ledgers. These include commonly used blockchains such as Ethereum, and private commercial blockchains such as KSI Blockchain developed by SOFIE partner Guardtime [81]. The SOFIE federation approach is designed to be technology-agnostic, allowing systems with different APIs and data formats to interoperate to the extent allowed by the applicable security policies. Some of the existing IoT platforms already support interoperability across different protocols and standards. Examples of this include FIWARE through its IoT adapters [84], such as the already existing LWM2M and oneM2M adapters, and W3C WoT, where the IoT servient concept supports both proprietary APIs and various protocol adapters. While most of the data will reside within existing IoT systems, a key aspect of SOFIE is the so-called smart contract, available in some blockchains, such as Ethereum. From the SOFIE point of view, a smart contract is simply a computer program and its associated computational state that “lives” in a blockchain. 7.8.3 Security Architecture The SOFIE security architecture provides end-to-end security (confidentiality and integrity), identification, authentication and authorization, and supports users’ privacy and control over their data. Most existing solutions already provide decent end-to-end security within the system and system-specific authentication. Therefore, SOFIE concentrates on innovating in the areas of data sovereignty, privacy and federated key management, authentication, and authorization. IoT data can often be personal and therefore governed by a new EU’s GDPR legislation. Ensuring compliance with the GDPR is a major design requirement for the SOFIE security architecture. SOFIE plans to use MyData [85] together with Sovrin Foundation identity blockchain [86] to allow individuals to better control how their personal data is used. In order to support data sovereignty and privacy, SOFIE adopts a three-level approach to the storage of data. First, there is a private data store managed entirely by the stakeholder. A private blockchain (such as Guardtime’s KSI Blockchain) forms the second level data that is shared between collaborating stakeholders (for examples producer, reseller, and supermarket in the food chain use case). Finally, some data (such as hashes of transaction trees from the lower level) will be stored in a public blockchain, such as Ethereum or Bitcoin. Such an approach allows fine grained control of the data, from total openness (e.g. to bring transparency to certain public services) to very tight access control (e.g. to protect trade secrets or the privacy of people). In either case, integrity and non-repudiation of the data is guaranteed. 7.8.4 Use Cases The SOFIE approach will be tested in three different use cases described below. The food chain pilot aspires to demonstrate the field-to-fork scenario towards security in food production and consumption. SOFIE applications and realization of a community-supported heterogeneous end-to-end agricultural food chain will be demonstrated and evaluated. The use case will combine multiple types of ground, micro-climate, soil, leaf and other information stations, existing IoT platforms, mobility, location-based services (LBS), food tracking information, smart micro-contracts, and decentralized autonomous organizations implemented with smart contracts. The consumer may trace the entire history of the product based on the QR or RFID tag on the package, even in the shop before buying the product. Consumers can reliably verify not only the farmer from whom the product originates, but also the entire production and supply chain history associated with each food item, starting from the source of the seeds, the quality of the soil and the air in the producer’s premises, the amount of water that has been consumed, the fertilization process, the method and time of growing, the weather conditions, the transportation mode and distance, the storage conditions etc. This gives consumers the ability to make decisions about their food based on health and ethical concerns, including environmental sustainability, fair labour practices, the use of fertilizers and pesticides, and other similar issues. In the Mixed Reality Mobile Gaming Pilot, virtual and real worlds will be combined. Mobile gaming is a rapidly growing market, popular games, such as Pokémon Go, are already taking advantage of augmented reality and SOFIE aims to take such interaction further. SOFIE will integrate a mobile game with the real world using a federated IoT platform aiming to: a) enable the gamers to interact with the real world via sensors and actuators, b) take advantage of existing and emerging IoT infrastructure (e.g. building automation), c) enable payments in virtual and real currencies between the gamers, games, and other parties, and d) create new business opportunities for various parties, including gaming companies, as well as the owners of buildings and public spaces (e.g. malls) and various businesses (e.g. shops and cafés). The gamers will be both moving in the physical world and interacting with it through the games. Existing IoT infrastructure, for instance movement sensors and control of lighting and passage, will be included in the game world through the federated SOFIE platform. Owners of spaces and businesses will be able to bring their existing or new IoT infrastructure into the gaming world, while the blockchain-based marketplace will allow for all kinds of business models, including In-Game Assets (IGA) trading. The energy pilot aims at optimized Demand Response and at supporting electricity marketplaces and micropayments. The energy pilot consists of two parts: first, a real-field pilot will demonstrate the capability of creating smart micro-contracts and micro-payments in a fully distributed energy marketplace, located in Terni, Italy. The pilot will cover the end-to-end scenario form electricity production, distribution, storage and consumption. During the scenario electricity produced by renewable sources (PVs) will be fed into the low voltage (LV) electricity network. Most of this electricity will be normally consumed by energy customers (i.e. houses, offices, etc). However, the surplus of the generated power would generate reverse power flows through the LV distribution network substation. The electricity distribution network is designed to handle only unidirectional electricity flows, thus reverse flows may generate significant problems. To avoid this abnormal operation, electrical vehicles (EVs) will be offered significant promotional benefits to match their EV charging needs with the network time and space balancing requirements. The EV chargers will be communicating with the EV drivers, with the car battery management system, the local energy generation and consumption, and the smart meters to predict if the requested charging service/network grid stabilization will be available in due time. Second, a laboratory and interoperability pilot based on real-data from smart energy meters deployed in the greater area of Tallinn, Estonia. The trial will be based on the Estfeed open software platform [87] for energy consumption monitoring and management from the customer (consumers/prosumers) side, which is capable of interacting with the power network and to provide data feeds for efficient use of energy. Figure 7.15 Three SOFIE pilots. To assess cross-SOFIE interoperability, SOFIE pilots will be federated as shown in Figure 7.15. In the cross-pilot, the emphasis will be on the demonstration of the exploitation of data stored/cached in different locations to be accessed across different platforms, as well as the development of applications exploiting different underlying infrastructures. The SOFIE interfaces abstraction will allow virtual entities in one platform to be exploited by applications from a different platform, while data semantics and analytics will facilitate the data exploitation. Initial consideration of scenarios to be tested include: Energy and gaming pilots exploiting data protection/privacy (e.g., for building access), energy pilots (EV) exploiting smart agriculture data with respect to environmental conditions and payments and contracts across pilots (e.g., getting food discounts from gaming achievements). 7.8.5 Conclusions The SOFIE federation approach will help make the existing siloed IoT platforms interoperable, enabling cross-platform applications and reuse of data in a secure and scalable manner. SOFIE will offer data sovereignty in GDPR-compliant way, giving users more control of their data. Through the usage of distributed ledgers, SOFIE will promote open business platforms, allowing creation of new kinds of decentralised open marketplaces, which no single entity – public or private – can technically control and thus exercise sole pricing power over them. This in turn will lower the barrier of entry for small businesses and individuals. The SOFIE federation framework will be released as open-source and SOFIE partners have the capacity to deliver and boost the penetration of SOFIE offerings in the market and relevant standardization bodies. List of Notations and Abbreviations Notations Abbreviations AAA Authentication, Authorisation and Accounting ABE Attribute-Based Encryption CP-ABE Ciphertext-Policy Attribute-Based Encryption DHT Distributed Hash Table IoT Internet of Things JSON-LD JavaScript Object Notation for Linked Data KPI Key Performance Indicator QoS Quality of Service QoI Quality of Information OMB Overlay Management Backbone RDF Resource Description Framework RDQL RDF Data Query Language TEEs Trusted Execution Environments API Application Programming Interface bD by-Design CE Circular Economy E2E End-to-End GDPR General Data Protection Regulation EU European Union ICT Information Communication Technologies IoT Internet of Things IIoT Industrial IoT ML Machine Learning NFV Network Function Virtualization SDN Software-Defined Networking SPDI Security, Privacy, Dependability and Interoperability References International Telecommunication Union (ITU), report on Climate Change, Oct. 2008. G. Koutitas, P. Demestichas, ‘A review of energy efficiency in telecommunication networks’, Proc. In Telecomm. Forum (TELFOR), pp. 1–4, Serbia, Nov. 2009. Gartner Report, Financial Times, 2007. I. Cerutti, L. Valcarenghi, P. Castoldi, ‘Designing power-efficient WDM ring networks’, ICST Int. Conf. on Networks for Grid Applic., Athens, 2009. Google Scholar W. Vereecken, et. al., ‘Energy Efficiency in thin client solutions’, ICST Int. Conf. on Networks for Grid Applic., Athens, 2009 Google Scholar J. Haas, T. Pierce, E. Schutter, ‘Datacenter design guide’, White Paper, The Green grid, 2009. Intel, ‘Turning challenges into opportunities in the data center’, White Paper, online at: www.intel.com/Intel.pdf Adel S. Elmaghraby, Michael M. Losavio, “Cyber security challenges in Smart Cities: Safety, security and privacy”, Journal of Advanced Research Volume 5, Issue 4, Pages 491–497, July 2014. Google Scholar CHARIOT Grant Agreement number 780075, Annex 1, Part A. CHARIOT Grant Agreement number 780075, Annex 1, Part B. VESSEDIA Project website, https://vessedia.eu/ (last access May 2018). Google Scholar CHARIOT Project website, http://www.chariotproject.eu/ (last access May 2018). How To Make 2017 The Year Of IoT Security, William H. Saito, Forbes, 2017. With the Internet of Things, we’re building a world-size robot. How are we going to control it?, Bruce Schneier, New York Magazine, January 2017. The Internet of Things becomes the Internet that thinks with Watson IoT, https://www.ibm.com/internet-of-things, (last access May 2018). IEC: IoT 2020: Smart and secure IoT platform. IEC white paper (2016) Google Scholar NESSI: Cyber physical systems: Opportunities and challenges for software, services, cloud and data. NESSI white paper (2015). NESSI: SOFTWARE CONTINUUM: Recommendations for ICT Work Programme 2018+. NESSI report (2016). Humble, J., Farley, D.: Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation. Addison-Wesley Professional (2010). Google Scholar Taivalsaari, A., Mikkonen, T.: A roadmap to the programmable world: software challenges in the iot era. IEEE Software 34(1) (2017) 72–80. Google Scholar Morin, B., Fleurey, F., Husa, K.E., Barais, O.: A generative middleware for heterogeneous and distributed services. In: 19th International ACM SIGSOFT Symposium on Component- Based Software Engineering (CBSE), IEEE (2016) 107–116. Google Scholar I. Stoica, R. Morris, D. Karger, M. F. Kaashoek, and H. Balakrishnan, “Chord: A scalable peer-to-peer lookup service for internet applications,” in Proceedings of the 2001 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communications, (New York, NY, USA), pp. 149–160, ACM, 2001. P. Maymounkov and D. Mazieres, “Kademlia: A peer-to-peer information system based on the xor metric,” in Proceedings of the First International Workshop on Peer-to-Peer Systems, (London, UK), pp. 53–65, Springer-Verlag, 2002. Google Scholar L. Cheng, et al., “Self-organising management overlays for future internet services,” in Proceedings of the 3rd IEEE International Workshop on Modelling Autonomic Communications Environments, (Berlin, Germany), pp. 74–89, Springer-Verlag, 2008. Google Scholar G. Klyne and J. J. Carroll, “Resource Description Framework (RDF): Concepts and Abstract Syntax,” 2004. http://www.w3.org/TR/rdf-concepts/ M. Cai, M. Frank, B. Yan, and R. MacGregor, “A subscribable peer-to-peer RDF repository for distributed metadata management,” Web Semantics: Science, Services and Agents on the World Wide Web, vol. 2, no. 2, pp. 109–130, 2004. Google Scholar A. Seaborne, “RDQL – A Query Language for RDF,” 2004. http://www.w3.org/Submission/RDQL/ Google Scholar E. Prud’hommeaux and A. Seaborne, “SPARQL Query Language for RDF,” 2008. http://www.w3.org/TR/rdf-sparql-query/ Google Scholar Jan Henrik Ziegeldorf, Oscar García Morchon, Klaus Wehrle. “Privacy in the Internet of Things: threats and challenges,” Security and Communication Networks 7(12): 2728–2742, 2014. Google Scholar S. Nakamoto, “Bitcoin: A P2P Electronic Cash System,” 2009. Hernandez-Ramos, J.L.; Pawlowski, M.P.; Jara, A.J.; Skarmeta, A.F.; Ladid, “L. Toward a Lightweight Authentication and Authorization Framework for Smart Objects,” IEEE J. Select. Areas Commun., 33, 690–702, 2015. Google Scholar José L. Hernández-Ramos, Antonio J. Jara, Leandro Marín, and Antonio F. Skarmeta Gómez, “DCapBAC: embedding authorization logic into smart things through ECC optimizations,” International Journal of Computer Mathematics, 93(2): 345–366, 2014. Google Scholar N. G. Weiskopf and C. Weng, “Methods and dimensions of electronic health record data quality assessment: enabling reuse for clinical research,” Journal of the American Medical Informatics Association, vol. 20, no. 1, pp. 144–151, 2013. Google Scholar P. N. Mendes, H. Muhleisen, and C. Bizer, “Sieve: Linked data quality assessment and fusion,” in Proceedings of the 2012 Joint EDBT/ICDT Workshops, ser. EDBT-ICDT ’12. New York, NY, USA: ACM, 2012, pp. 116–123. Google Scholar F. Lecue, S. Tallevi-Diotallevi, J. Hayes, R. Tucker, V. Bicer, M. Sbodio, and P. Tommasi, “Smart traffic analytics in the semantic web with star-city: Scenarios, system and lessons learned in dublin city,” Web Semantics: Science, Services and Agents on the World Wide Web, vol. 27, pp. 26–33, 2014. Google Scholar N. Bissmeyer, S. Mauthofer, K. M. Bayarou, and F. Kargl, “Assessment of node trustworthiness in VANETs using data plausibility checks with particle filters,” in Vehicular Networking Conference (VNC), 2012 IEEE, Nov 2012, pp. 78–85. Google Scholar N. Bissmeyer, J. Njeukam, J. Petit, and K. M. Bayarou, “Central misbehavior evaluation for VANETs based on mobility data plausibility,” in Proceedings of the Ninth ACM International Workshop on Vehicular Inter-networking, Systems, and Applications, ser. VANET ’12. New York, NY, USA: ACM, 2012, pp. 73–82. Google Scholar R. Zafarani and H. Liu, “Evaluation without ground truth in social media research,” Communications of the ACM, vol. 58, no. 6, pp. 54–60, 2015. Google Scholar R. Toenjes, D. Kuemper, and M. Fischer, “Knowledge-based spatial reasoning for IoT-enabled smart city applications,” in 2015 IEEE International Conference on Data Science and Data Intensive Systems. IEEE, 2015, pp. 736–737. Google Scholar Antonio F. Skarmeta, et al. “IoTCrawler: Browsing the Internet of Things” in IEEE 2018 Global Internet of Things Summit (GIoTS). Google Scholar Bröring, A., S. Schmid, C.-K. Schindhelm, A. Khelil, S. Kaebisch, D. Kra-mer, D. Le Phuoc, J. Mitic, D. Anicic, E. Teniente (2017): Enabling IoT Ecosystems through Platform Interoperability. IEEE Software, 34(1), pp. 54–61. OpenFog Consortium “OpenFog Reference Architecture for Fog Computing”, February 2017. International Standardization Organization, “ISO 27001: Information Se-curity Management System Requirements”, Geneva, Switzerland, 2013. B. Nagpal, N. Singh, N. Chauhan and R. Murari, “A survey and taxonomy of various packet classification algorithms,” 2015 International Conference on Advances in Computer Engineering and Applications, Ghaziabad, 2015, pp. 8–13. doi: 10.1109/ICACEA.2015.7164675. Google Scholar Z. Ma, A. Hudic, A. Shaaban and S. Plosz, “Security Viewpoint in a Reference Architecture Model for Cyber-Physical Production Systems,” 2017 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW), Paris, 2017, pp. 153–159. doi: 10.1109/EuroSPW.2017.65 Google Scholar A. Botta, W. De Donato, V. Persico, A. Pescapé, “Integration of Cloud computing and Internet of Things: A survey,” Futur. Gener. Comput. Syst., vol. 56, pp. 684–700, 2016. Google Scholar M. A. Razzaque, M. Milojevic-Jevric, A. Palade, S. Cla, “Middleware for internet of things: A survey,” IEEE Internet Things J., vol. 3, no. 1, pp. 70–95, 2016. I. Lee, K. Lee, “The Internet of Things (IoT): Applications, investments, and challenges for enterprises,” Bus. Horiz., vol. 58, no. 4, pp. 431–440, 2015. Google Scholar Kert M. et al., “State of the Art of Secure ICT Landscape,” NIS Platform WG 3, V2, April 2015 ENISA, “Threat Landscape Report.” 2016, online at: https://www.enisa.europa.eu/publications/enisa-threat-landscape-report-2016 G. Hatzivasilis, et al., “The industrial Internet of Thins as an enabler for a Circular Economy Hy-LP: a novel IIoT protocol, evaluated on a wind park’s SDN/NFV-enabled 5G industrial network.” Computer Communications, Elsevier, vol. 119, pp. 127–137, April 2018. Google Scholar L., Pino, “Pattern Based Design and Verification of Secure Service Compositions.” IEEE Transactions on Services Computing (2017). Google Scholar L. Pino, G, Spanoudakis, A. Fuchs, S. Gurgens, “Discovering Secure Service Compositions,” 4th International Conference on Cloud Computing and Services Sciences (CLOSER 2014), Barcelona, Spain, April 2014. Google Scholar A. Maña, E. Damiani, S. Gürguens, G. Spanoudakis, “Extensions to Pattern Formats for Cyber Physical Systems,” Proceedings of the 31st Conference on Pattern Languages of Programs (PLoP’14. Monticello, IL, USA. Sept. 2014. Google Scholar K. Fysarakis, et al. “RtVMF: A Secure Real-Time Vehicle Management Framework,” in IEEE Pervasive Computing, vol. 15, no. 1, pp. 22–30, Jan.-Mar. 2016. doi: 10.1109/MPRV.2016.15. Google Scholar N. Petroulakis, G. Spanoudakis, I. Askoxylakis, “Patterns for the design of secure and dependable software defined networks,” Computer Networks 109 (2016): 39–49. Google Scholar G. Hatzivasilis, I. Papaefstathiou, C. Manifavas, “Real-time management of railway CPS,” 5th EUROMICRO/IEEE Workshop on Embedded and Cyber-Physical Systems (ECYPS), IEEE, Bar Montenegro, June 2017. G. Hatzivasilis, I. Papaefstathiou, D. Plexousakis, C. Manifavas, N. Papadakis, “AmbISPDM: managing embedded systems in ambient environment and disaster mitigation planning,” Applied Intelligence, Springer, pp. 1–21, 2017. Google Scholar IDC FutureScape, “Worldwide Internet of Things 2017 Predictions,” Nov 2016. Google Scholar Forrester, “IoT Applications Require Distributed Analytics, Centralized Analytics Won’t Work For Many IoT Use Cases,” March 29, 2017, online at: https://www.forrester.com/report/IoT+Applications+Require+Distributed+Analytics/-/E-RES133723 Gartner, “7 Technologies Underpin the Hype Cycle for the Internet of Things, 2016, The challenges of creating, implementing and preparing for the IoT,” Nov 2016, online at: http://www.gartner.com/smarterwithgartner/7-technologies-underpin-thehype-cycle-for-the-internet-of-things-2016/ Forbes and Moor Insights & Strategy, “The Internet of Things and Machine Learning,” 2016, online at: https://www.forbes.com/sites/moorinsights/2016/03/16/the-internet-of-things-and-machine-learning/#a83d2d13fb16 L, Pino, G. Spanoudakis, “Finding Secure Compositions of Software Services: Towards A Pattern Based Approach,” 5th IFIP Int. Conference on New Technologies, Mobility and Security, Istanbul, Turkey, May 2012. Google Scholar L. Pino, G. Spanoudakis, A. Fuchs, S. Gurgens, “Discovering Secure Service Compositions,” 4th International Conference on Cloud Computing and Services Sciences (CLOSER 2014), Barcelona, Spain, April 2014. Google Scholar J. Domanska, E. Gelenbe, T. Czachorski, A. Drosou, D. Tzovaras Research and Innovation Action for the Security of the Internet of Things: The SerIoT Project, to appear in Proceedings of the ISCIS2018 Security Work-shop, Springer CCIS, 2018. Google Scholar E. Gelenbe, Zhiguang Xu, and Esin Seref, Cognitive packet networks, Tools with Artificial Intelligence 1999. Proceedings. 11th IEEE International Conference on, pp. 47–54, 1999. Google Scholar E. Gelenbe, Cognitive Packet Network, US Patent 6,804,201, 2004. Google Scholar E. Gelenbe, Steps toward self-aware networks, Commun. ACM 52(7): 66–75, 2009. Google Scholar O. Brun, L. Wang, and E. Gelenbe, Big Data for Autonomic Intercontinental Overlays, IEEE Journal on Selected Areas in Communications 34(3): 575–583, 2016. Google Scholar L. Wang and E. Gelenbe, Real-Time Traffic over the Cognitive Packet Network, Computer Networks Conference 2016: 3–21 Google Scholar F. Francois and E. Gelenbe, Towards a cognitive routing engine for software defined networks, ICC 2016: 1–6, IEEE Xplore, 2016. Google Scholar E. Gelenbe and T. Mahmoodi, Energy-aware routing in the cognitive packet network, ENERGY, 7–12, 2011. Google Scholar E. Gelenbe and C. Morfopoulou, A Framework for Energy-Aware Routing in Packet Networks, Computer Journal 54(6): 850–859, 2011. Google Scholar M. Jammal, T. Singh, A. Shami, R. Asal, and Y. Li, Software defined networking: State of the art and research challenges, Computer Networks, vol. 72, pp. 74–98, Oct. 2014. Google Scholar W. Stallings, Foundations of modern networking: SDN, NFV, QoE, IoT, and Cloud, Pearson Education, 2015. Google Scholar Y. Liu, A. Hecker, R. Guerzoni, Z. Despotovic, and S. Beker, On optimal hierarchical SDN, Proc. IEEE Int. Conf. on Communications (ICC), pp. 5374–5379, June 2015. Google Scholar N. Zhang, S. Demetriou, X. Mi, W. Diao, K. Yuan, P. Zong, F. Qian, X. Wang, K. Chen, Y. Tian, C. A. Gunter, K. Zhang, P. Tague, Y. Lin, Understanding IoT Security Through the Data Crystal Ball: Where We Are Now and Where We Are Going to Be, CoRR, arXiv:1703.09809, 2017. Google Scholar Symantec Internet Security Threat Report, vol. 23, Symantec Corporation, Tech. Rep., March 2018. E. Gelenbe, Reseaux neuronaux aleatoires stables, Comptes Rendus de l’Academie des Sciences. Serie 2, 310 (3): 177–180, 1990. Google Scholar E. Gelenbe, Learning in the recurrent random neural network, Neural Computation, 5 (1): 154–164, 1993 Google Scholar Ahto Buldas, Andres Kroonmaa, Risto Laanoja, “Keyless Signatures’ Infrastructure: How to Build Global Distributed Hash-Trees”, In: Hanne Riis Nielson, Dieter Gollmann., Secure IT Systems – 18th Nordic Conference, NordSec 2013, Proceedings. LNCS 8208, Springer, 2013. Google Scholar https://ec.europa.eu/digital-single-market/en/internet-of-things https://www.sofie-iot.eu https://www.fiware.org/ https://mydata.org https://www.sovrin.org http://estfeed.ee/en/analyses/ BRAIN-IoT Project website, http://www.brain-iot.eu/ (last access June 2018). 8. CREATE Your IoT Luis Miguel Girao1, So Kanno2, Maria Castellanos3 and Patricia Villanueva4 1Artshare – Investigacao, Tecnologia e Arte, Portugal 2Artist, Japan 3uh513, Spain 4LaBoral Centrode Arte y Creación Industrial, Spain Abstract This chapter describes the background and origin of the artistic series CREATE Your IoT. The series is a very special one as it is being created and hosted at the heart of the Large-Scale Pilots Programme of the European Union (LSPs). The series puts artworks at the core and makes them the motive for dialogue between all actual and potential stakeholders in use-cases of the LSPs aiming at pointing out ways of how other innovative actions can be implemented on top of the developments made available by LSPs. The text looks at how art and technology are intrinsically related, how art practices historically expanded their field of action to make the world and life a canvas and how more recently the influence of artistic ideas in the creation of new products, services and processes is irrevocable. More specific examples of this connection between technology and the arts in the field of ICT and IoT are presented. Finally, an updated report on ongoing artistic actions in the context of the CREATE IoT coordination and support action are presented. 8.1 Introduction Technologies and the arts have always been closely related. Indeed, this relationship is invoked with every mention of the word technology, which has its origins in the Ancient Greek tékhnē, meaning art. In this project, we will explore the contemporary relationship between technology and the arts, reflecting on how they can influence each other and the conditions under which their synergies can flourish. New technologies have shaped artistic practices since the dawn of history. Demand for tools to accomplish specific tasks has compelled technology to develop in new directions. Potentially, the first tool one can conceive Homo erectus to have created, after winning the fight between the weight of their brain and gravity, was the invention of the stick – to more easily pick fruit from trees. The stick as an extension of the arm. The paint brush as an extension of the stick – an artistically driven technological innovation – is naturally conceivable as well. More recently, Andy Clark and David Chalmers conceived the iPhone as an extension of the mind [1]. Understanding Steve Jobs as the most contemporary artist of the past century then becomes key to pursuing the transformations of the timeless intertwining between technologies and the arts. “The ability to produce art was an indication that humans had begun to think in more abstract terms. It’s a thought process that enabled us to come up with the science and technology that enabled our species to become so successful.” —BBC article by Pallab Gosh, Oct. 2014 [2] This quote comes from BBC Science correspondent Pallab Gosh, who was reporting on recent discoveries in a rural area on the Indonesian island of Sulawesi, where cave art from 40,000 years ago was found. The discoveries are the first of their kind outside the European continent, thus putting into question the positioning of Europe, and Western culture for that matter, as pioneering human development [3]. “The emergence of art marks the beginning of a surge in the development of human intelligence. The people who produce art are able to reflect their thoughts in the form of pictures and symbols”, reports Gosh. Indeed, the ability to transform “abstract knowledge” into “knowledge of perception” is a unique characteristic of human intelligence. This ability fulfils the human need for making sense of what happens/happened by creating narratives. There is also a need to freeze moments in time: the need for creating images one can grasp and hold on to, the need for making sense of life, the need for giving meaning to life – meaningfulness. The attribution of meaning to technologies is a relevant aspect for understanding the intertwining of technologies and the arts. For example, the invention of photography in the 19th century is possibly the event that had the most impact in the course of the history of art. On the one hand, it liberated painters from the duty of portraying personalities and started a movement of abstraction in painting that gave origin to great diversity of styles in the 20th century. On the other hand, it created a new tool for expression that is nowadays one of the most established forms of artistic expression. In sum, new meanings were attributed to the technique of painting and to a new technology – photography – which lead to new forms of images with its associated novel techniques. For instance, Pointillism can be interpreted as the first step towards a digital format of images, similar to what we nowadays call pixels. 8.2 CREATE Your IoT Artistic practices are thinking processes as well as they generate reproducible knowledge. The peculiarity of the knowledge generated by the arts using technology is that by reverse engineering the final products of those creations, one can fully understand its functionality. One of the characteristics of the practice of art is that artists act first and rationalize later. The actual context of the relationship between ICT and art allows for an unprecedented integration of subjectivity in the context of technological research. 8.2.1 The Practice of Art as a Thinking Process Urgency is a condition sine qua non in the attribution of the artistic quality to a practice. For a practice to be considered as artistic, it has to originate in that primordial urgency. Karl Phillip Moritz (1756–1793), in his writings Artistic Imitation of the Beautiful, defined this urgency or artistic impetus as drive and not as idea, concept or a representation [4]. This reverses the Leibniz–Wolffian hierarchy of human faculties by valuing the artistic, by considering the irrational and subconscious as the true source of human agency. Philosophers such as Schopenhauer, Nietzsche and others support that culture initiated by Moritz in which the “dark and undefined” balances with and is as relevant as the “clear and distinct” [5]. According to Landgraf, Moritz sees urgency as being about the productivity of nature that serves as media. It links the artist and the artwork as well as driving the creative process. Artistic creativity allows for the mediation between an undefined non-representational stimulus, i.e. realisation, and the artistic objectification or communication of the stimulus, i.e. manifestation. Artistic is that which is created by an artistic practice, and that distinguishes it from any other knowledge generation practice, such as scientific practice. The core of artistic practice is the urgency for creation, composed of two poles: realisation and manifestation. They are the indivisible components of artistic urgency. Realisation is the need to make things happen while manifestation is the need to create beings. Realisation is the core of practice itself. It is the action of making. It is movement, the energy of exteriorization. It is embodying in an outward form. Manifestation is the core of creation. It is openness to revelation. It is recognising a being, the energy of interiorization. It is embodying in an inward form. The Portuguese poet, Helder, expresses an extraordinary image of Manifestation: I now dive and ascend as a glass. I bring up that image of internal water. Poem pen dissolved in the primordial direction of the poem. Or the poem going up the pen, passing through its own impulse, poem returning. Extract from Sumula (sum and substance), by Herberto Helder translated by Luis Miguel Girao (not published). Herberto Helder (1930–2015), in the excerpt above, describes the bipolar coexistence of Realisation and Manifestation with a special focus on the latter. He describes the inwards embodiment of the pen by a poem. The “primordial direction of the poem” is towards the pen and the poet himself. “The poem going up the pen, passing through its own impulse” represents the impulsive nature of the need of making of the poet, Realisation. By “passing through its own impulse”, the poem embodies the pen and reveals itself to the poem which, in turn, writes it on the paper. Manifestation nurtures Realisation, which in turn nurtures Manifestation, in a non-starting and non-ending cycle of urgency. Helder understands the artwork, the poem, as a being. The poem has its own life and manifests itself through the poet, the pen and the paper: “poem returning”. The return of the poem is the process of Manifestation that, however, is dependent on the poet’s need for objectification: Realisation, his need to make things happen, in order to materialise as a form. In a particular way, Helder expresses how “Nietzsche saw thinking itself: as a dance of concepts and the pen”, as pointed out by Roy Ascott (1934–) in Telematic Embrace [6], when describing telematic networks as a “planetary field for the dance of data”. Telematics, as envisioned by Ascott, allows for the disappearance of “senders” and “receivers”, so that they all become “users”, creative participants. He established the concept of “distributed authorship” in digital networks following up on the ideas of Barthes’ “dispersed authorship” in his Le Plaisir du Text [7] and Derrida’s free play of sense. Seconding the notion of thinking of culture as started by Moritz and followed by Nietzsche is Agostinho da Silva (1906–1994). In one episode of the TV series Conversas Vadias, broadcast by the Portuguese national broadcaster, RTP, between 8th March and 31st May 1990, the Portuguese philosopher stated: We could carry on our shoulders a machine that thinks, or rather a machine that detects ideas that roam around the world. —Agostinho da Silva, 1990. [1] [1] https://arquivos.rtp.pt/conteudos/conversa-com-baptista-bastos/ from minute 22 onwards. (last accessed on 13/08/2017) Translated by Luis Miguel Girao. This statement by da Silva is not an affirmation, but rather a proclamation of doubt. It was made after the interviewer, the writer Armando Baptista-Bastos (1933–2017), asked Professor da Silva why he normally advised his students not to think. His answer was the above quoted proclamation of doubt. According to da Silva, “we still don’t know” whether we produce thoughts or whether thoughts come to our minds. In case of doubt, his choice was not to think. Da Silva, in a communicative way aimed at addressing the masses, pointed out, as Morris did, that ‘detecting ideas’ is also valid for the generation of knowledge. He was trying to bring to the general public a discussion that has been going on for centuries about noumena and phenomena. One of the high points of the discussion about noumena and phenomena is the critique by Arthur Schopenhauer (1788–1860) of Immanuel Kant’s (1724–1804) use of the word noumena: But it was just this distinction between abstract knowledge and knowledge of perception, entirely overlooked by Kant, which the ancient philosophers denoted by noumena and phenomena. (See Sextus Empiricus, Outlines of Pyrrhonism, Book I, Chapter 13, ‘What is thought (noumena) is opposed to what appears or is perceived (phenomena).’) This contrast and utter disproportion greatly occupied these philosophers in the philosophemes of the Eleatics, in Plato’s doctrine of the Ideas, in the dialectic of the Megarics, and later the scholastics in the dispute between nominalism and realism, whose seed, so late in developing, was already contained in the opposite mental tendencies of Plato and Aristotle. But Kant who, in an unwarrantable manner, entirely neglected the thing for the expression of which those words phenomena and noumena had already been taken, now takes possession of the words, as if they were still unclaimed, in order to denote by them his things-in-themselves and his phenomena” [8]. Schopenhauer again makes a clear distinction between “what is thought” and “what appears or is perceived”. This distinction has been fundamental to the discussion on the practice of art as a thinking process and its potential contributions for knowledge-generation systems [2]. It is relevant to understand and recognise the opposed concepts of noumena and phenomena in order to understand the uniqueness of the practice of art in making both concepts coexist simultaneously, as expressed above in the definition of artistic urgency. [2] Knowledge-generation systems refer to organisms that bring together contributions from different fields of study to research a specific subject. The overall vision is that the integration of the practice of art in these interdisciplinary, multidisciplinary or transdisciplinary groups of researchers is crucial for the development of research. www.starts.eu (last accessed on 14/08/2017). Robert Pepperell, author of Post Human Condition [9], has resumed the discussion on noumena and phenomena by proposing the concept of phenoumenon. The notion of phenoumenon as the basic assumption for understanding the practice of art as a thinking process that “includes (all) our thoughts about reality which are part of a continuous phenoumenon” [10]. The great contribution of the practice of art for the generation of knowledge is transforming noumena into phenomena through Realisation and Manifestation by being both simultaneously: a phenoumenon. In other words, art is simultaneously embodying inwards and outwards. This means transforming “abstract knowledge” into “knowledge of perception” by producing technology-based artworks whose reasoning can be reversed. That is, making things happen and creating beings. 8.2.2 Art is Life (Integration) “Art is Life, Life is Art” —Wolf Vostell (1932–1998) Vostell was a German painter and sculptor and is considered a pioneer of happening and Fluxus. Fluxus was an international and interdisciplinary group of artists that, in the late 1960s, produced performance “events”, happenings, including concrete poetry, visual art, urban planning, architecture, design, literature and publishing. Fluxus has sometimes been described as intermedia, a category into which composers such as Niblock fall. The ideas and practices of John Cage influenced Fluxus, especially his understanding of the work as a site of interaction between artist and audience [11]. For Vostell, a human’s physical action, the handling of things, was already considered art. What happens, the happening, is already art only if one wants it to be and one affirms it. Artworks no longer need an envelope or frame. Art steps out of its frame, normally the gallery, and melts immediately into the stream of life. The dilution of the boundaries between daily life and the places determined for art was one of the main objectives of the Fluxus movement. This was partially achieved, especially at the beginning of the movement. Yet, arguably, the institutionalisation of art has been unavoidable, and it naturally took advantage of this sort of movement to expand its area of action. Nonetheless, nowadays we can experience very interesting forms of art practice, such as street theatre, viral theatre, pop-rock bands and performances, and even some fashion industry-related events, happenings or products such as flashmobs, which somehow integrate art in daily life contexts. One of the most common Fluxus happenings is the hammering of a piano as symbol of the destruction of the institutionalisation of the arts. This thesis builds upon a further development of this act, which is the destruction of desktop or laptop computers, as a symbol of the institutionalization of digital technologies. It is also the expression of the idea that ubiquity, in the form of the Internet of Things, amongst others, could allow the spread of artistic ideas, works or concepts embedded in new technologies themselves. Such a movement would allow for a worldwide dissemination of artistic ideas impregnated in society and economy via technological innovation. This idea is further developed in artistic interventions in the European Commission STARTS Initiative and the Internet of Things Large-Scale Pilots. Those interventions are an expansion of some activities already happening in the field of arts and ubiquity. In that context, it has become common practice to organise workshops in which ideas to be congregated in public participation are developed. Contextualising digital practices within architectural spaces and exploring the opportunities of experiencing and perceiving domestic environments with the use of media and computing technologies have been used as methods for the design of reflexive and intimate interiors that provide informational, communicational, affective, emotional and supportive properties according to embedded sensorial interfaces and processing systems. To properly investigate these concepts, a fundamental criterion is magnified and dissected: dwelling, as an important ingredient in this relationship entails the magical power to merge physical environment with the psyche of inhabitants. For this reason, a number of views providing necessary conditions to include matters of affectivity, ubiquity and layering complexity of interior space have been highlighted [12]. Integrative art is the integration of artistic practice into daily life. The way it is envisaged in this chapter is through the technology described above. Nowadays, integrative art is not a common practice amongst artists in the sense that is envisaged here. However, some relevant examples are emerging. An example of artistic critical approach in IoT is the work of artist James Brindle who is trying to build his own self-driving car and published all the code developed in pursuit of the DIY self-driving car [3]. Brindle says: [3] https://github.com/stml/austeer “Self-driving cars bring together a bunch of really interesting technologies – such as machine vision and intelligence – with crucial social issues such as the atomization and changing nature of labour, the shift of power to corporate elites and Silicon Valley, and the quasi-religious faith in computation as the only framework for the production of truth-and hence, ethics and social justice.(…) The attempt to build my own car is a process of understanding how the dominant narratives of these technologies are produced, and could be changed.” 8.2.3 ICT and Art Golan Levin, one of the most prominent individuals of the emerging field of ICT and art, very clearly demonstrated how artistic projects presented ICT solutions well before they became known: Figure 8.1 Myron Krueger’s Video Place (1974), and the Sony EyeToy (2003). Figure 8.2 Michael Naimark & MIT ArchMac’s Aspen Movie Map (1978–1980), and Google Street View (2007–). Figure 8.3 Jeffrey Shaw’s Legible City (1988) and E-fitzone exercise equipment (2008). Figure 8.4 Art+Com’s Terravision (1996) and Google’s Google Earth (2001, 2005–). The artist and technologist states that he wrote his article New Media Artworks: Prequels to Everyday Life, [4] as consequence of the following: [4] http://www.flong.com/blog/2009/new-media-artworks-prequels-to-everyday-life/ “I struggled to justify the value of new-media arts research to an audience of Silicon Valley business people; while simultaneously, some new-media artist friends of mine discovered that their work had been ‘appropriated’ by a large corporation.” This example reveals one of the most important gaps in the generation of new businesses models in global markets: the one existing between creativity and business. The US, moreover, is home of crucial players in the field, such as the most relevant academic publisher in the field, Leonardo, and SEAD, the network for Sciences, Engineering, Arts and Design. However, the European context nurtures the development of institutions such as Ars Electronica that distinguished Golan Levin with its Prix; the same institution also distinguished Linus Torvalds, considering the collective process that led to Linux as an artistic expression. It is this same European context that recognized the emergence of ICT & ART so as to allow for the worldwide establishment of STARTS, the European Commission initiative in Science, Technology and the Arts, as a recognized field of Research and Technological Development. A considerable number of organisations, institutions and programmes promoting activities linking ICT and art proliferate in the European Union. Some of these institutions are worldwide leaders such as Ars Electronica (AT), ZKM (DE) or IRCAM (FR), to name but a few. However, it is from small organisations and individuals that the most innovative projects or actions originate. As an example, the Finnish artistic/researcher Laura Beloff, who has been operating as an individual focused on the development of wearable technologies, has recently been appointed the Head of Section–Interaction Design and Computer Game Development at IT University in Copenhagen, Denmark. The Finnish Bioart Society that she founded and directs was one of the participants of a workshop on bioart, promoted by the FBI in California, USA. Laura is one of many artists that are becoming institutionally prominent not in the field of the arts but in the field of ICT. Small organisations seem in fact to be the strategic focus of promoters, as funding in the field is mostly directed more to groups of people than to individuals. Medialab-Prado (ES), Kitchen Budapest (HU), F.A.C.T. (GB), Pervasive Media (UK), iDAT (UK), iMAL (BE) and CIANT (CZ) seem to be good examples of organizations promoting more relevant activities. More and more ideas of collaboration, co-creation, shared knowledge and participation are present in their initiatives. The concept of lab, from OpenLab, to FabLab and Living Lab, has been instrumental in the diffusion of techniques of digital fabrication and physical prototyping, allowing everybody to go, learn and create. From pieces of 3D printing to lines of code for multimedia installations, activities linking ICT and art seem to follow a model of establishing an artistic context for creative participation, be it in the form of interactive installations or workshops to learn how to make or to create. It seems that we are moving from models of engaging the arts to illustrate and communicate science, such as the one implemented at CERN, to the ideas of living labs, such as the iMinds’ own iLab.o or Barcelona Laboratori Cultural, promoted by Josep Perelló, who was previously responsible for the Science Area on behalf of the University of Barcelona at Arts Santa Mònica centre in Barcelona (SP). There are already a considerable number of small and medium businesses developing around these activities, such as Libelium (ES). The concept of providing creative learning platforms as a new business model is actually expanding as a strategy. What started as an artistic project is becoming the standard for rapid prototyping in physical computing: Arduino (IT). This development platform created and has been maintaining a large community of developers around itself, based on the establishment of an easy-to-use programming language, a playful set of online tutorials and an active online form. The same model has been applied in Processing or openFrameworks. The community started with a majority of artists and expanded to become of a majority of technologists. Almost every electronics store in big European cities sells Arduino and related products. The expansion of this model is becoming visible in big companies such as Farnell and its community platform Element 14 or the DIGI. Also, in this last case, the new XBee project gallery is a result of the collaboration of Rob Faludi (US) with the electronics corporation. At the University of Cambridge’s Computer Laboratory (GB), what is becoming the next platform for development was created: The Raspberry Pi. In education, the most interesting model seems to be related to the concepts of ubiquity and the internet of things. i-DAT24 of the University of Plymouth (UK) has been promoting exemplary initiatives such as the Confluence Project: a group of students of schools located at North Devon’s UNESCO Biosphere Reserve, in collaboration with artists and technologists, developed and implemented remote wireless networks from which they created online data visualisations. In research, the most relevant worldwide network of researchers in the field of Art, Science, Technology and Consciousness Studies is the Planetary Collegium. The network has nodes in Lucerne, Trento and Shanghai. The main hub is at the University of Plymouth. A considerable number of conferences on the crossings of ICT and arts happen all over the world, the most relevant being, for example, ISEA, Ars Electronica, Siggraph, HCI International and Transmediale. At the level of social innovation, the growing intersection between the application of ICT and art in the field of disability is notable. The Artabilitation (DK) group has been joining a relevant number of researchers in this area, including the exemplary case of Rolf Gehlhaar. Gehlhaar developed a number of digital interfaces for musical expression, some of them recently integrated into the British Paraorchestra. The orchestra opened the Queen’s Christmas Speech of 2012 and played at the Paralympics closing ceremony in London, in 2012. The European Commission has been supporting a number of projects engaging the arts as described in the call for tender. However, the most relevant recent activities come from DG CONNECT which promoted the ICT ART CONNECT workshops and related events, which have been dedicated to better understanding how to integrate the arts with ICT. The COST Arts and Technologies Event took place in Zagreb, from the 25th to the 28th of November 2013. The COST Arts & Technologies (CAT) workshop assumes that there are large potential gains in integrating arts on the one hand with technologies on the other, to a larger extent than has been done so far. Combining artistic creativity with technological expertise should in itself have a great potential to lead to new products, services and social innovations. The workshop aimed at enabling innovative integration of arts and multi-, inter-, and transmedia technologies and their actual and potential integration with industries and society as a way of enhancing competitiveness and creativeness of European innovation in arts and technologies. [5] [5] http://www.cost.eu/events/cat The CAT workshop gave rise to a relevant collective white paper entitled Organisms for Change and Transformation. [6] [6] http://www.cost.eu/download/47808 DG CONNECT of the European Commission has been promoting key initiatives in the context of the Digital Single Market (DSM), under the umbrella of the STARTS Initiative. However, bearing in mind long-term targets such as 2050, it will be in the context of the now developing Framework Programme Horizon Europe of the European Commission that further development of STARTS will have to develop. In order to find conditions for the nurture of these future activities, areas of opportunity need to be found within this context. The present understanding seems that regional development will be instrumental. The reason behind this assumption is that the regions of Europe strategically dedicated to this area of innovative development will be determined to a large extent by this programme. The context of the Cultural and Creative Industries (CCIs) seems to be the ideal host for the ideas forthcoming from the potential research results from the future of STARTS. Nonetheless, it seems that the focus of this emerging field should probably not lie in the utilization of ICT for digital content, cultural industries and creativity. The utilization of the arts as a means to communicate aspects of science on its own also does not seem to be innovative enough for the purposes of the emerging field in question: this practice has emerged and spread worldwide, as these activities have been happening worldwide since the last century and are already quite established as described. The engagement of the arts with ICT are also instrumental in allowing the active participation of a large number of European citizens to create and live their own lives in a better way. Protocols such as Open Data and Open Source allow for digitally mediated forms of social innovation both at the level of opinion-making participation as well as at the level of self-employment. From this perspective, the creation and establishment of new business models and entrepreneurship becomes an active form of social innovation. This implies nurturing not only the visionary and exploratory characteristics of artistic practices, but also furthering their wider capability of research and development. These ideas are clearly aligned with actual objectives such as Inclusive Societies by which “The European cities have to be at the heart of policies aiming to create growth, jobs and a sustainable future” and “the increasing socio-economic importance of digital inclusion, research and large-scale innovation actions will promote inclusive ICT solutions and the effective acquisition of digital skills leading to the empowerment of citizens and a competitive workforce.” In her report on H2020, MEP Maria da Graça Carvalho proposes “education and science, arts and humanities as fundamental drivers of social and economic progress and well-being”. Social innovation generates new goods, services, processes and models that meet societal needs and create new social relationships. It is important to understand how social innovation and creativity may lead to change in existing structures and policies and how they can be encouraged and scaled up. Grass-roots online and distributed platforms networking citizens and allowing them to collaborate and co-create solutions based on an extended awareness of the social, cultural, political and environmental context can be a powerful tool to support the objectives of Europe 2020. Moreover, aspects of participation are also at the core of the programme: “…address social-network dynamics and crowd-sourcing and smart-sourcing for co-production of solutions addressing social problems, based on open data sets. They will help to manage complex decision-making, in particular the handling and analysis of huge quantities of data for collaborative policy modelling, simulation of decision-making, visualisation techniques, process modelling and participatory systems (…) as well as to analyse changing relationships between citizens and the public sector. Increased levels of complexity, the implications of questions posed by technology, advanced computation, life sciences and bio-engineering impinge upon areas of knowledge traditionally related with human studies, such as philosophy, theology, and legal, political and economic thought should be addressed. It is important to combine art, science and entrepreneurship; new forms of urban expression; knowledge, art and entrepreneurialism related to the integration of multiculturalism and integration of migratory flows; multilingualism.” The same applies for creativity and innovation: “Exploring processes which provide a favourable background to creativity and innovation. Providing a better understanding of the social, cultural, economic and political context for innovation shall be a priority. In particular, the role of youth perception of the opportunities for innovation in the current economic environment of high unemployment in many EU regions shall be carefully understood in relation to education and to the risk of brain-drain.” Finally, cultural heritage and European identity are also important: “The aim is to contribute to an understanding of Europe’s intellectual basis […] European collections, including digital ones, […] should be made accessible through new and innovative technologies and integrated information services to researchers and citizens to enable a look to the future through the archive of the past and to contribute to the European participative intelligence.” In sum, an understanding of the crossroads of science, technology and the arts on all these levels is crucial to fostering post-crisis processes of recovery in the European Union. At the heart of the Fourth Industrial Revolution lies the outstanding feature of the automation of mechanisation. Artificially intelligent computerised machines liberate humans from mechanistic tasks in chain with machines. The actual concept of a hybrid system integrates humans into industrial chains where subjectivity is a need. In this general context, disciplinary specialisation in research is giving way to transversal and holistic approaches, with the assurance that intelligent machines are in place to perform highly precise and effective tasks. Humans are no longer needed to perform complex operations but instead, they become indispensable to trigger and correlate highly complex operations, where knowledge convened by subjective processes is crucial for the achievement of results. Research and development practices are no longer methodological processes of confirming expectations or hypothesis, but now become flexible processes of discovery due to the availability of easier means of experimentation and repetition. Sciences of cognition set a very good example of that expressed above. They often cross knowledge from different disciplines, they depend on high-tech imaging and measuring equipment and their results are mostly dependent on subjective reports. Therefore, they demand an articulation of many different disciplines and their experiments are led by enquiry on subjective aspects of perception. Already in this field of research, the integration of artistic practices is an emerging factor. Art practices are transdisciplinary by nature, independently of the channels of expression used. Throughout history artists have specialised in developing technologies and implementing techniques in the design of artistic experiences. Therefore, in the present context of experimental integration of subjectivity, artists are emerging as relevant contributors in research and development of technology. Technologies being a consequence of scientific developments, artistic practices become interesting experimental methods for the generation of new knowledge. Strategies are needed for the integration of these new ways of thinking amongst different scientific communities, leading to true social and economic innovation. Historically narrowing our perspective over more recent events, one can say that the existing collaborations among artists and scientists are a consequence of the work of Frank Malina. He was at the origin of NASA’s Jet Propulsion Laboratories, of which he was the first director. In 1968, in Paris, as a way of pursuing his interest in kinetic art, he founded the Leonardo Journal, which is still the leading publication on the crossings of arts, sciences and technologies. His son, Roger Malina, continuing his father’s work, is one of the most prominent agents in the field, by running the Leonardo project as well as triggering other actions such as SEAD. SEAD is looking into congregating best practices of collaborations in science, engineering, arts and design. However, all actions in the field tend to make the old-fashioned model prevail, where every single actor of the collaborative system conserves and develops his or her own speciality, which of course enhances political aspects of real and productive collaboration. Their results are mostly limited to theoretical papers, and in cases that could result in practical applications, issues of generating economic value such as intellectual property generation and protection are generally dismissed. Not to mention how far these practices stay from aspects of creation of new products, services, and of the business aspects of generating new jobs and self-employment. Nurturing the expansion of fields of action of each discipline and solving conflicts resulting from their overlapping of functions are the instruments to achieve transdisciplinary. However, the main question still remains: How to integrate arts and sciences in truly productive ways, both in the direction of the generation of new philosophical knowledge, as well as in the direction of the creation of new technology-based businesses, in order to make the European Union the world leader of emerging markets and creating future ones? The adoption of artistic practices such as research methodologies is instrumental for the integration of subjectivity in the production of scientific, reproducible knowledge, allowing for a holistic approach, not only to the emergence of future sciences, but also of future technologies, leading to close-to-market results, especially concerning the intersection of the arts and information and communication technologies. Therefore, the main benefits of STARTS are in its features of nurturing socio-economic innovation by mediation of digital information and communication technologies. By promoting the intersection of scientific and artistic practices, inevitably leading to new methodologies and processes of generating new knowledge, STARTS aims to transform the way research and development communities face their own research targets: at one stage, to make them more open to novelty, exploration mechanisms, creativity and imagination; at another, to make them focus on concrete research outputs, in the form of close-to-market prototyping. The main targets of STARTS should be to disperse the idea that blue-sky, thinking-based research can generate added value, not just because of its inherent novelty, but because this novelty, by being tracked at intermediate states of development, will lead to new scientific and technological developments. Innovation at the social level where scientists and artists interact will lead to both new knowledge and new technologies, in accordance with actual demands of society and markets. In other words, STARTS aims to benefit European research communities by merging scientific and artistic research and innovation (R&I) practices into producing new philosophical knowledge and new technologies, as well as making R&I practitioners aware that having both of the above combined might allow for the creation of new markets, based on new business models, new products and new services. At the time writing, STARTS has three dedicated projects running and a relevant intervention in the Large Scale Pilots Initiative. Vertigo is promoting the integration of artists in knowledge generation systems by attributing grants for artistic residencies in research projects. Wearsustain is promoting the creation of new artistic driven prototypes. The STARTS Prize attributes yearly two distinctions for technological innovation through the arts. CREATE-IoT, the coordination project of the Large-Scale Pilot projects (LSPs) of the EU, also integrates the arts. CREATE-IoT has a crucial role in STARTS by promoting the notion of co-creation based on artistic practices within the LSPs and by introduction of the Experience Readiness Level indicator. 8.2.4 Next Things_Next Starts Between December 2017 and April 2018, in Gijon, Spain, the exhibition Next Things_Next Starts showed for the first time the results of the research and production residency programme called Next Things organised by LABoral Centro de Arte y Creación Industrial in conjunction with Telefónica R+D over a five-year period with the mission to forge new connections and collaborations between art, science, technology and society. Following an open call issued to artists and other creatives, the most innovative ideas and projects related with the Internet of Things were chosen. The award consisted of organizing and funding a six-month residency – two months at LABoral, in Gijon and four at Telefónica I+D, in Barcelona – to materialise their ideas and projects. The exhibition was centred on the critical role played by creativity and social involvement in processes of innovation. Along with scientific and technical know-how and learning, art is a catalyst that helps transform knowledge into objects or processes. The showcased projects presented the paths which are opened up when combining creative thinking with the possibilities of open technology. The five critical and innovative projects chosen for the programme rethink and open a debate on contemporary situations stemming from technological advances. Through the creative use of new technologies, these projects propose prototypes for new solutions and working spaces. The exhibition was a first for STARTS in learning from previous experiences on artistic residencies in research contexts. The artists awarded with the prize were: Laura Malinverni and Lilia Villafuerte; Lot Amorós, Cristina Navarro and Alexandre Oliver; Sam Kronick; María Castellanos and Alberto Valverde; Román Torre and Ángeles Angulo. Here we present only three of those works as they represent a useful spectrum as examples for the integration of artists in the context of the IoT European Large-Scale Pilots. Environmental Dress represents the tendency of artists to engage with global matters such as climate change. Furthermore, the project demonstrates the capability of artists to technically implement elaborate systems as well as reiterating the importance of open source code and hardware. Figure 8.5 Environmental Dress, by María Castellanos and Alberto Valverde. “We are surrounded by polluting agents and other factors that have a direct impact on our everyday lives, our mood and, ultimately, on our behaviour. Variations in noise, temperature, atmospheric pressure, ultraviolet radiation or amounts of carbon monoxide are some of the challenges we have to face on a daily basis. At the end of the day, they are agents that influence our temper and our behaviour with others. Environment Dress is a piece of smart clothing that uses a number of sensors to measure the aggressiveness of our surrounding environs, detecting environmental variables and alerting us to them. Our body’s natural sensors are unable to measure and anticipate factors such as an increase in ultraviolet radiation, dust or noise, and others. The interface geo-locates environmental analyses and allows users to register their mood through a smartphone app. In consequence, we can establish the relationship between both variables and determine whether an increase in ultraviolet radiation can make the person who wears the dress feel better or whether an increase in noise level can make him or her feel more uncomfortable in a certain place. Finally, all these data are shown on an emotional map, pinpointing the most pleasant and unpleasant areas in a city.” (Source: catalogue of NEXT THINGS_NEXT STARTS Exhibition, LABoral, Gijon, Spain). Flone is representative of the need of artists to make technology accessible. In a subject matter such drones, with profound implications on security and privacy, the exposure and dissemination of how drones’ function is crucial, from an artistic point of view. Figure 8.6 Flone, the flying phone by Lot Amorós, Cristina Navarro, Alexandre Oliver. “Flone, The Flying Phone, is a platform to make smartphones fly, involving an innovative drone which combines digital manufacturing, personal empowerment and the use of a smartphone to remotely control the device. Flone is a self-built, low-cost biodegradable drone, conceived as an open source digital design. Some of its design elements (shape, size, material, lack of screws) make it accessible and adaptable for many people to conquer air space. The use of open software and documentation and the simplicity of making it democratise the knowledge needed to manufacture a drone and claim air space as a common domain. Flone aims at opening up the range of applications of air social robotics. This multimedia drone, a mobile multipurpose machine, moves through the public air space thanks to various smartphone sensors (camera, microphone, GPS, accelerometers, gyroscopes) and actuators (LED flash and speaker) together with wireless connections (Bluetooth, Wi-Fi and 4G). The members of this project have imparted workshops in countless schools, art centres and universities in several countries. Dozens of individuals have replicated this project worldwide and made a flone for themselves.” (Source: catalogue of NEXT THINGS_NEXT STARTS Exhibition, LABoral, Gijon, Spain). Thero reiterates the urgency of giving control to end users of the decision of being connected. Having the option to consciously connect or disconnect to the internet is nowadays extremely important mainly because a great number of people are not aware that they are constantly connected through their devices. Figure 8.7 THERO by Román Torre and Ángeles Angulo. “As a concept, THERO wishes to raise our digital privacy to the status of a precious and sacred object. Accordingly, the object has been given a highly aesthetic treatment, with the geometry and clean lines of an idol or talisman endowed with a value beyond its material qualities: the value of freedom and the right to digital anonymity. THERO is presented as a heavy sculpture which contains a device that blocks and encrypts our digital communications by allowing the user to directly manipulate the object. By manually rotating its structure, THERO is capable of managing our digital contact with the outside space. The piece basically consists of a router to which we can wirelessly connect all our digital devices. It can be handled physically to offer various levels of privacy: blocking pages we do not want to visualise or which demand excessive attention from us, encrypting our communication by using the TOR network, completely blocking access to the network, cutting all communication with the outside in order to only browse locally. The piece opens up a space for reflection on our actions and their subsequent traces and significance in the net. THERO tries to lower the abstract barrier of the digital tool by means of a number of physical actions that make us more aware of our use of the Internet. The presence of THERO in our homes would give corporeity to the need for privacy in our digital interactions. In essence, THERO gives us the power to decide when we want and when we do not want to be visible.” (Source: catalogue of NEXT THINGS_NEXT STARTS Exhibition, LABoral, Gijon, Spain). The most important conclusion from the Next Things programme is the management of intellectual property in this type of context of collaboration of tech companies and artists: keep it all open source. 8.2.5 Artists and the IoT European Large-Scale Projects In the CREATE-IoT project a methodology for integrating ICT and the arts – or better put: to include artistic practices in the ICT development cycle – was designed to be fully adaptable. Its implementation in the LSPs will result from specific combinations of its methods according to the specificities, not only of each one of the LSPs they will be tailored for, but of each of the particular LSPs’ use cases. The methodology is designed to be applied in the specific areas of innovation of the IoT LSPs initiative: food and farming, healthy aging, public mass events, self-driven vehicles and smart cities. The basic principles are implemented in the ICT framework through a sequence of actions that will be selected from the range of artistic related activities and their correlation with the ICT cycle. The actions of integration of artistic practices in the LSPs are being done mostly around their use cases. The reason for this option is to demonstrate that artistic practices are useful in connecting humans and technology, towards a human-centred approach to technology as an enabler of better lives in general. The methodology is developed around the development of artworks to trigger dialogue with the LSPs and raise some questions that might help improve their final solutions. The underlying idea is that the services provided by the LSPs can trigger socio-economic innovation if made available to SMEs and individuals. The first step was the integration of an artist in residency in the CREATE-IoT project. So Kanno, a Japanese artist proposed creating the The ideal showroom of IoT. The ideal showroom of IoT is a two-part composition, a participatory installation. It shows the possibility of sensing, recognising and determining the world through the perspective of objects. A living room full of IoT devices is set out to let visitors experience this shift: sensors and cameras are interweaved into a well-known environment. The second part is providing a new point of view to perceive a post-IoT age perspective onto things and technology. Figure 8.8 The ideal showroom of IoT. The installation is set up in two parts: The first is a living room with many small computers, cameras and sensors installed. Most of them are not obvious and are hidden. These systems try to capture information of the visitors. A robot in the room will welcome the visitors. It will introduce and explain the context of the work as well as trying to have a conversation with visitors. In second room, there’s a laboratory set up, with a desk and VR headset. Visitors will experience the living room now from different perspectives. When putting on the VR headset, the visitor will have the view from the hidden cameras or robot. Experiencing the same situation again through an object-related perspective should give the visitors a new perspective on IoT and personal robots. In this residency between CREATE-IoT and So Kanno, a new artistic work is being developed, challenging the fundamental issues of interest in the Internet of Things. CREATE-IoT provides access to the artist for key people, companies, concepts and technologies associated with Trust in the Internet of Things. Key elements will be made available to the artist regarding the development of a trusted environment for the development of IoT and comprehensive technical and non-technical solutions regarding privacy, security and trust issues. The development of the new artwork involves various levels of research and development. Existing IoT products are explored and researched and selected regarding the functions they include for the installation. Technology used for the project are IoT devices with hidden cameras, smart speaker systems, personal robots and VR technology. In the development of the art work, the consumer products will be manipulated and adjusted for the artistic purpose. The developed system will integrate the video stream of hidden IoT security cameras. The IoT devices and robot will be accessed and controlled through a VR headset experience. The second step is the development of model of artistically mediated co-creation process around an artwork. Towards the creation of exemplary case studies, the LSPs IoF2020, ACTIVAGE, SYNCHRONICITY are being developed in order to realise artistic-led co-creation hackathons as a support to some of the use cases of these pilots. The aim of these hackathons is to artistically enhance the context of those use cases and stimulate creativity of all participants. The concrete target is to better understand the role of artists in pushing for innovative approaches either in the technology in question or its applications. Impact on uptake, adoption and acceptance will also be observed, as well as the potential of new businesses built on top of the technologies made available by the LSPs under study. At the moment, the use cases that are being considered for action are part of IoF2020: Figure 8.9 Added-value weeding data. This use-case collects location-specific camera data to provide insights on the number of vegetables growing on the field, the plants’ growth status and best harvesting moment, weed prevalence, nutrient shortages and drought stress. From an artistic point of view, it is interesting to understand how agriculture is becoming less anthropocenic. Figure 8.10 City farming for leafy vegetables. IoT technology in city farming enables the production of high-quality vegetables in a predictable and reliable manner, unaffected by plant diseases, free from pesticides and independent of seasonal influences. From an artistic point of view, it is interesting to imagine better lives that could allow free-time to have contact with the vegetables we eat. Figure 8.11 Poultry chain management. The focus of this use case is mainly on the growth of poultry with respect to animal welfare. This starts with an adequate environment in which the birds feel comfortable, as well as good-quality feed and water. These are extremely important aspects from an artistic point of view. Some years ago, the artistic community started to be concerned with this type of challenges, especially after the film Baraka. An example of the possible impact of these actions in the IoF2020 would be to see in its open calls a focus on more human-centred technology based on the technologies made available by the project. That is one of the underlying principles of the choices use cases to work with. 8.2.6 CREATE Your IoT The present result of the work undertaken is a series of works entitled CREATE Your IoT. Drawing inspirations from the title of the coordination and support action to the LSPs, CREATE-IoT, the series aims at expanding it by pointing out ways of how other innovative actions can be implemented on top of the developments made available by LSPs. It emphasizes the co-creative aspect of the all LSPs but in an alternative sense than that of citizen participation as promoted by the U4IoT CSA. In the series, artworks are the core and are motive for dialogue between all actual and potential stakeholders in use-cases. The CREATE Your IoT Series is at the moment composed of two artworks under development. The Connected Hennery and The Migrant Home. The artworks are being designed to allow the integration of multiple technologies made available by the LSPs. For example, The Migrant Home could host technologies from all LSPs MONICA, AUTOPILOT, IoF2020, ACTIVAGE, SYNCHRONICITY. The Connected Hennery is a reflection about the use case of the Poultry chain management of IoF2020. Inspired by the motto of that use case to respect animal welfare, the artwork starts by giving the chicken the control of the location of their home. It follows recent tendencies of permaculture, within which mobile henneries are substitutes for tractors in the cleaning of agricultural land. In permaculture, chicken inhabiting a defined piece of land clean it and fertilize it. Farmers, by simply moving the hennery around their land, make it ready for cultivation. The digital system of The Connected Hennery analyses the position and movement of chicken inside the hennery and predicts in which direction they would like to progress next, freeing the farmer from that work task. Furthermore, other sensors implemented in the hennery allow easier monitoring for the farmer in order to simplify and more effectively manage her/his intervention in the maintenance of the hennery. The CREATE Your IoT Series is looking at decentralized models of production of chicken and at its potential as added value for the associated use cases of the LSPs. Food suppliers are looking at how consumers are more and more interested in biological and organic products and how can they adapt to keep their leadership of the supply markets. This leads these suppliers to create their own production experiments in order to better understand how to create new products the fit customers’ demands. It is for this sort of context that works such The Connected Hennery are being developed in order to promote the LSPs towards end users. The Migrant Home is still in the early phases of concept development. At this stage it is looking at how an IoT mobile house can be transformed into a home for migrants for short-term jobs/enterprises connected with urban and rural niche developments, for instance recovery of rural and urban cultural heritage. Preliminary experience of the development of the CREATE Your IoT Series reveals that Open Standards and Architectures in the LSPs are crucial to make the technologies developed accessible and allow for the development of new business models. 8.3 Conclusion The actual context of the relationship between ICT and art allows for an unprecedented integration of subjectivity in the context of technological research. The integration of subjective approaches is fundamental in making human-centred technological innovation. Human-centred technological applications fill in the gap between what is possible from a pure technological point of view and what people can encounter as useful in their daily lives to make those lives better. The LSPs represent a unique opportunity for the spread of creative approaches to technological solutions and those approaches can help to potentiate the results of the LSPs in terms of new applications and associated business models. It is this reciprocal relationship that will allow on one side for an expansion of the field of action of the LSPs and on the other for the LSPs of potential fields for innovation to be informed. The instruments of those actions are the co-creation hackathons. They will develop around the artworks of the CREATE Your IoT Series to trigger new solutions based on the technologies made available by the LSPs. References R. Menary, The Extended Mind, online at: https://mitpress.mit.edu/books/extended-mind P. Ghosh, Cave paintings change ideas about the origin of art, online at: http://www.bbc.com/news/science-environment-29415716. The quote is a transcription of the video of the article and not from its text. Google Scholar M. Aubert, Brumm, A., Ramli, M., Sutikna, T., Saptomo, E. W., Hakim, B., Morwood, M. J., van den Bergh, G. D., Kinsley, L., Dosseto, A., 2014. Pleistocene cave art from Sulawesi, Indonesia. Nature 514, 223–227. Google Scholar J. M. Bernstein, (Ed.), 2003. Classic and romantic German aesthetics, Cambridge texts in the history of philosophy. Cambridge University Press, Cambridge, UK, New York. Google Scholar E. Landgraf, 2011. Improvisation as art: conceptual challenges, historical perspectives, New directions in German studies. Continuum, New York, NY. Google Scholar R. Ascott, E. A. Shanken, 2007. Telematic embrace: visionary theories of art, technology, and consciousness, 1. paperback print. ed. Univ. of California Press, Berkeley. Google Scholar R. Barthes, 1973. Le plaisir du texte, Points Essais. Éd. du Seuil, Paris. A. Schopenhauer, 1969. The world as will and representation. Dover Publications, New York. R. Pepperell, 1995. The post-human condition. Intellect, Oxford, England. A. P. Almeida, 2007. O universo dos sons nas artes plásticas, Teses. Edições Colibri, Lisboa.     Table of Contents     RIVER PUBLISHERS SERIES IN COMMUNICATIONS Dedication Acknowledgement Preface Editors Biography List of Figures List of Tables Contents +1 IoT EU Strategy, State of Play and Future Perspectives +2 Future Trends in IoT +3 The Next Generation Internet of Things – Hyperconnectivity and Embedded Intelligence at the Edge +4 End-to-end Security and Privacy by Design for AHA-IoT Applications and Services +5 Use Cases, Applications and Implementation Aspects for IoT Interoperability +6 Smart Data and the Industrial Internet of Things +7 IoT European Security and Privacy Projects: Integration, Architectures and Interoperability +8 CREATE Your IoT

Paper 10:
- APA Citation: Devkota, M., Devkota, K. P., & Yigezu, Y. A. (2022a). Conservation agriculture improves agronomic, economic, and soil fertility indicators for a clay soil in a rainfed Mediterranean climate in Morocco. Agricultural Systems, 201, 103470.

Devkota, M., Singh, Y., Yigezu, Y. A., Bashour, I., Mussadek, R., & Mrabet, R. (2022b). Conservation Agriculture in the drylands of the Middle East and North Africa (MENA) region: past trend, current opportunities, challenges and future outlook. Advances in Agronomy, 172.
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: This study comprehensively analyzed the genotype × environment × management effect using four years of experimental data on durum wheat productivity and wheat use efficiency in a rainfed Mediterranean environment of Morocco.
  Extract 2: Significant year effect with seeding time, water management and genotype (with four contrast rainfall growing seasons; Table 2) on grain yield, major yield attributes and WUEs indicates the need for customized seeding time, water management and suitable genotype for improving wheat production with resilience.
  Limitations: The authors only focused on durum wheat and did not evaluate other wheat types. The study was also conducted in a specific region of Morocco, so the results may not be generalizable to other regions with different climatic conditions.

The study lacks an interaction of fertilizer management with seeding time, water management and genotype, therefore further study is suggested to understand the contribution of fertilizer management and its interactions for improving wheat productivity in such climatic conditions.
  Relevance Evaluation: {'apa_citation': 'Devkota, M., Devkota, K. P., & Yigezu, Y. A. (2022a). Conservation agriculture improves agronomic, economic, and soil fertility indicators for a clay soil in a rainfed Mediterranean climate in Morocco. Agricultural Systems, 201, 103470.\n\nDevkota, M., Singh, Y., Yigezu, Y. A., Bashour, I., Mussadek, R., & Mrabet, R. (2022b). Conservation Agriculture in the drylands of the Middle East and North Africa (MENA) region: past trend, current opportunities, challenges and future outlook. Advances in Agronomy, 172.', 'extract_1': 'This study comprehensively analyzed the genotype × environment × management effect using four years of experimental data on durum wheat productivity and wheat use efficiency in a rainfed Mediterranean environment of Morocco.', 'extract_2': 'Significant year effect with seeding time, water management and genotype (with four contrast rainfall growing seasons; Table 2) on grain yield, major yield attributes and WUEs indicates the need for customized seeding time, water management and suitable genotype for improving wheat production with resilience.', 'inline_citation': '(Devkota et al., 2022a, 2022b)', 'limitations': 'The authors only focused on durum wheat and did not evaluate other wheat types. The study was also conducted in a specific region of Morocco, so the results may not be generalizable to other regions with different climatic conditions.\n\nThe study lacks an interaction of fertilizer management with seeding time, water management and genotype, therefore further study is suggested to understand the contribution of fertilizer management and its interactions for improving wheat productivity in such climatic conditions.', 'relevance_score': 0.9}
  Relevance Score: 0.902
  Inline Citation: (Devkota et al., 2022a, 2022b)
  Explanation: The present study aimed to assess the integrated effect of genotypes (G), environment (E), and management (M) on the productivity and WUE of durum wheat in Morocco, where the authors implemented a multi-year experiment with an irrigation system and 10 different genotypes. Results indicated that supplemental irrigation significantly increased wheat yield and biomass production, and optimizing the sowing time can minimize water-limited yield gaps. The study also highlighted the importance of genotype selection as well as the integration of adapted agronomic practices.

 Full Text: >
"Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Keywords 1. Introduction 2. Materials methods 3. Results 4. Discussion 5. Conclusions CRediT authorship contribution statement Declaration of Competing Interest Acknowledgements Appendix A. Supplementary material Data Availability References Show full outline Cited by (2) Figures (6) Tables (8) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6 Show all tables Extras (1) Supplementary material European Journal of Agronomy Volume 151, November 2023, 126972 Genotype and agronomic management interaction to enhance wheat yield and water use efficiency in the Mediterranean rainfed environment of Morocco: I. Field data analysis Author links open overlay panel Mina Devkota a, Krishna Prasad Devkota a, Mohammed Karrou b, Vinay Nangia a Show more Share Cite https://doi.org/10.1016/j.eja.2023.126972 Get rights and content Under a Creative Commons license open access Highlights • Average rainfall has decreased with increasing inter- and intra-seasonal variability. • Water management and planting time remains major determinant for yield in drylands. • Supplementary irrigation reduced yield gap by 2.12–3.27 t ha-1 compared to rainfed. • Customized G x E x M improve the resilience and sustainability of wheat production. Abstract Durum wheat (Triticum turgidum subsp. durum), considered better drought tolerant, is the most cultivated wheat in Morocco and in the Middle East and North Africa (MENA) region. The region, including Morocco, predominantly has rainfed production systems, declining water supply, and increasing trends and effects of rainfall variability and climate extremes leading to poor crop yield and yield stability. The objectives of this study were to understand major factors determining wheat yield and water use efficiency (WUE); assess the interaction of genotype × environment × management on crop yield and field- and crop-water use efficiencies; and determine the water-limited yield gaps of genotypes under different agronomic management practices in the Mediterranean climate of Morocco. Four years (2015/16–2018/19) of on-station experiments investigating genotype (ten genotypes including seven advanced line and three commercial varieties), seeding time (17 November vs. 29 December), and water management (rainfed vs. supplementary irrigation), was conducted at Merchouch research station, Morocco. The results showed that durum wheat yield mostly varied due to year (rainfall) by 43%, followed by water management × year (23%), year × seeding time (15%), and genotype (7%), with the highest yield (7.15 t ha−1) observed in 2018 (wet year) and the lowest in 2019 (dry year). Across years, not only the rainfall amount but also its distribution during the crop growing season caused yield variability. In low-rainfall years, supplementary irrigation (28–166 mm) increased yield by 2.12–3.27 t ha−1 compared to rainfed conditions. The significant (p < 0.01) year × seeding time × genotype effect on grain yield and WUEs indicates that the response of genotype and seeding time varied with rainfall amount and distribution as the water-limited yield gap in rainfed conditions appeared to be more than 2 t ha−1. In both supplementary irrigated and rainfed systems, the machine learning model showed the effect of different climatic (rainfall and temperature) and management (seeding time, genotype, and irrigation) factors determining yield, yield attributes, and WUEs. The total rainfall remained the most important factor explaining variation in rainfed wheat yield followed by the temperature at flowering, mid- and early-season rainfall, and genotype in order of importance. Similarly, seasonal rainfall was the most important factor explaining variation in grain yield followed by early-season rainfall, days to flowering, temperature at flowering, irrigation amount, seeding time, and genotype in supplementary irrigated durum wheat. Our study clearly shows that yield is highly related to rainfall in rainfed drylands, and the selection of high WUE variety and crop management practices are the key to improving the resilience and sustainability of durum wheat in Morocco and similar production environments in the MENA region. Previous article in issue Next article in issue Keywords Yield gapGenotype × Environment × ManagementRandom ForestWater limited yield gapSupplemental irrigationSeeding time 1. Introduction Wheat (durum, Triticum turgidum subsp. durum and bread, Triticum aestivum) is the major food crop grown on 16.8 million ha of rainfed area in 21 Middle East and North Africa (MENA) region countries (FAOSTAT, 2023). The region has high food and cultural value of wheat mainly for preparing bread, couscous, pasta, and other traditional cuisines. Data from FAOSTAT show that in 2020 the MENA region produced 40.9 million tons of wheat but also imported 42.8 million tons of wheat and wheat products worth 11.5 billion USD, and the import increased to 0.77 million tons year−1 (∼311 million USD) during 2000–2020. Wheat yield in the MENA region (except Egypt, Kuwait, and Saudi Arabia) is low (2.0 ± 0.72 t ha−1) and varies considerably among countries and years, and highly depends on irrigation regimes and rainfall amount and its distribution (FAOSTAT, 2023, Devkota et al., 2022b). In the region, the annual wheat productivity growth rate has only been 6 kg ha−1 year−1 (FAOSTAT, 2023) in the last 20 years, while the yield gap between experimental station and farmers’ yields is 1.2–1.7 t ha−1 and between simulated and farmers’ yields is 2.1–3.1 t ha−1 (Pala et al., 2011). Biophysical factors such as rainfed production systems with increasing rainfall variability in timing, amount and intensity and a considerable decrease in annual rainfall; increase in temperature; increasing frequencies of droughts, winds, and extreme events (Pala et al., 2011, Schilling et al., 2012); and poor land and crop management practices (Devkota et al., 2022b, Devkota and Yigezu, 2020, Kassam et al., 2012, Mrabet et al., 2012) are the major constraints for higher yields in the Mediterranean rainfed environment. In Morocco, wheat is grown on 2.8 million ha under rainfed conditions (FAOSTAT, 2023). In the country, winter cereals occupy more than 55% of agricultural areas, with common and durum wheat accounting for about 75% (Bouras et al., 2020). Durum wheat, considered more tolerant to drought than common wheat, is one of the oldest and most cultivated wheat in the MENA region and under Mediterranean climatic conditions (Padovan et al., 2020, Xynias et al., 2020). In Morocco, wheat is cultivated in diverse soil and climatic conditions with a range of rainfall patterns (El Mourid and Karrou, 1996, Pala et al., 2011). The variation in the amount and distribution of seasonal rainfall (Devkota et al., 2022a), and alteration of the hydrological cycle as a result of climate change (Bates et al., 2008), are mostly responsible for the temporal and spatial yield variability in Morocco and also in the MENA region. Previous studies have reported plenty of opportunities to improve wheat productivity by closing the yield gaps adopting good agronomic management for both rainfed and irrigated wheat (Devkota and Yigezu, 2020, Pala et al., 2011). Wheat is highly sensitive to water deficit and temperature fluctuation during the reproductive and grain-filling periods (Alghabari et al., 2014, Farooq et al., 2011). In the region, most rainfall occurs during autumn and winter and crops are frequently exposed to water deficit (moderate stress) around anthesis and grain filling (Giunta et al., 1993), and drought generally limits wheat yields (Yang et al., 2021). Under such conditions, adjustment in planting time and application of supplementary irrigation can improve productivity and yield stability (Karrou, 2013, Karrou and Oweis, 2012, Pala et al., 2011). Given the limited ability to utilize new sources of water and the declining rainfall amounts (Nicholson et al., 2018) in the present and also the future, efficient use of available rainfall water is needed for sustaining wheat production – for this optimal seeding time is the key. When water resources are available, supplemental irrigation in rainfed areas can boost wheat productivity by 3–4 times, and the enhancement of supplementary irrigation facility or efficient utilization of rainfall water is key for increasing yield (Pala et al., 2011). Similarly, considering the biophysical environment, to achieve stable yields with resilience under variable climatic conditions, it is critical to develop appropriate genetic and integrated agronomic management practices (Padovan et al., 2020). Appropriate sowing time and better cultivar choice are among the key factors allowing the sensitive stages of wheat to escape adverse environmental conditions (Bassu et al., 2009, Ferrise et al., 2010, Tapley et al., 2013). Adjustment of seeding time and choice of appropriate variety are low-cost key factors for improving wheat yield (Bassu et al., 2009, Heng et al., 2007). Previous studies have shown that advancing planting time helps raise wheat productivity by improving crop establishment and allowing crops to fully utilize rainwater (Heng et al., 2007, Piggin et al., 2015, Toumi et al., 2016) and avoid frost, heat, or drought stress during anthesis and grain filling (Ababaei and Chenu, 2020). Further, yield potential and resource utilization efficiency vary with variety, soil type, and climatic conditions (Wang et al., 2015). The growth, phenological development, maturity duration, and yield potential of a variety determine its potential for adaptation in a given environment and any breeding program needs to manipulate the genetic combination to customize varieties for the targeted environment and management practices (Dowla et al., 2018, Reynolds et al., 1999). To address these issues, several research efforts have been made to develop wheat varieties tolerant to drought and high-temperature stress (Alemu et al., 2021, Sadras and Podems, 2020). However, due to significant genotype × environment × management interaction, development of suitable and broadly adapted varieties is complicated (Bänziger and Cooper, 2001, Basford and Cooper, 1998). It is also important to understand major climatic, management, genotype, and genotype x management factors determining crop growth, productivity, and water use efficiency (WUE) to achieve stable yields under variable and changing production environments. The MENA region, including the study area, had high inter and intra-variability in rainfall patterns and temperature (World Bank, 2021). Under such conditions, applying supplemental irrigation and optimal planting time can help to minimize water-limited yield gaps and stabilize yield, especially in low and variable-rainfall years (Kheir et al., 2021, Shen et al., 2021). Previous genotype × environment × management studies focussed more on developing agronomic management practices to improve the productivity of the specific genotype. However, selection of genotypes that are best fit on the specific agronomic practices and production environment, which is considered an adaptation strategy under climate crises, is missing. Thus, the objectives of this study were to assess the interaction of seeding time, water management and genotype on durum wheat productivity and WUE; determine the contribution of different production factors on yield and WUE using machine learning; and determine the water-limited yield gaps under different genotype and management conditions from medium term (four years with contrasting rainfall) field experimentation in the rainfed Mediterranean environments of Morocco. 2. Materials methods 2.1. Experimental site, soil, and climate Field experiments were conducted for four years at the ICARDA research farm in Merchouch (33°36′41″N, 6°42′45″W, 390 m a.s.l.), 75 km east of Rabat, Morocco for four crop growing seasons (November–June) of 2015/2016, 2016/2017, 2017/2018, and 2018/2019; hereafter referred to as 2016, 2017, 2018, and 2019, respectively. The climate of the study site is typically Mediterranean with hot and dry summers and cold and wet winters, and highly variable annual rainfall across years. The long-term (1985–2021) annual rainfall in the experimental site Merchouch was 440 mm with mean annual air temperatures of 19.2 °C (maximum 22.7 °C and minimum 15.85 °C) (Fig. 1). Weather parameters such as temperature, rainfall, evapotranspiration (ET) for the experimental year were taken from the automated weather measuring device using iMETOS 3.3 (https://metos.at/en/ imetos 33/) installed in the research station. Download : Download high-res image (245KB) Download : Download full-size image Fig. 1. Experimental site and long-term (20 years) climatic condition (annual precipitation (mm) and average temperature (oC)) of experimental site Merchouch, Morocco. The soil in the experimental site is classified as a gray Vertisol of clay-loam texture (47.6% clay and 41% loam content) with large cracks appearing during the dry season. The soil has 1.65% organic carbon, 105 mg kg−1 available K2O, and 34 mg kg−1 assimilable P2O5. 2.2. Experimental design and treatments The experiment used a split-split plot design with three replications per treatment. Seeding time, i.e., timely (early November) vs. late (late December) was applied as the main plots; water management, i.e., rainfed vs. supplemental irrigation, was applied as a sub-plot factor; and genotype, i.e., 10 different genotypes, was applied as sub-sub-plots. In total, there were 40 treatments and 120 experimental plots. Genotypes were shown in 7 m × 2.6 m plots with row spacing of 20 cm (12 rows). Details of the experimental layout are presented in Fig. 2. Download : Download high-res image (571KB) Download : Download full-size image Fig. 2. Detail layout of the experimental plot in International Center for Agriculture Research for Dry Areas (ICARDA) Research Station, Merchouch, Morocco. Different colors represent water management. The first seeding plots were seeded on 17 November (SD1) and the second seeding plots were seeded on 29 December (SD2) each year. For the water management treatment, supplemental irrigation was applied through drip (the irrigation belt was patch-type with dripper flow rate of 2.3 L h−1, working pressure of 0.2 MPa and placed between two rows of wheat) based on soil field capacity. In supplemental irrigation, irrigation scheduling was carried out through in-situ measurement of soil moisture content by installing TDR (Time-domain reflectometry) based sensors TRIME-IT/-EZ (Germany). The TDR tubes with 1.5 m length were installed in all plots up to 90 cm depth after crop establishment in each growing season. Soil moisture was recorded at weekly intervals and irrigation water was applied when available soil moisture content in the soil profile dropped to 60%. The amount of water applied was calculated from the irrigation duration and the water discharge rate from each dripper. Total amount of water applied in the supplemental irrigation treatment is presented in Table 1. Table 1. Amount of irrigation water applied (mm) in different years in the treatment of supplementary irrigation for both seeding dates 17 November seeding (SD1) and 29 December seeding (SD2). Values in brackets indicate frequency of irrigation. Year SD1 (17 November) SD2 (29 December) 2015/16 175 (5) 166 (4) 2016/17 160 (4) 160 (3) 2017/18 34.78 (2) 28.15 (1) 2018/19 79 (4) 132 (4) Seven advanced lines and recently released durum wheat (Triticum turgidum ssp. durum) genotypes developed by ICARDA were included in the experiment, and three commercially grown released varieties, i.e., Karim, Louiza, and Faraj were used as local check. The genotypes had similar growing periods (<7 days difference in days to maturity). Detailed genotype/variety description has been presented in supplementary Table SI1. 2.3. Crop management practices Before commencing the experiment, the fields were plowed once using a moldboard plow in September followed by two plowings using a cultivator before seeding. All recommended agronomic practices for the region, except irrigation application, were carried out at appropriate times. A seeding density of approximately 250 seeds m−2 was maintained using a calibrated pneumatic plot seeder for sowing (Wintersteiger Company). To break the continuous wheat cycle, the experimental area was divided into two equal parts: half of the area was allocated for treatment evaluation (10 genotypes x 2 seeding dates x 2 water management), and the remaining half of the area was allocated to homogenize the plot by seeding triticale in mid-December as green manure crop that was incorporated into the soil before grain filling in each year. In the following year, the experiment was established on the homogenized plot, and in the adjacent plot triticale was planted as a cover crop to homogenize the field. A uniform fertilizer rate of 120 kg N ha−1, 60 kg P2O5 ha−1, and 30 kg K2O ha−1 was applied to avoid any nutrient stress as per the local recommended package for all growing seasons. The whole quantity of phosphorus and potassium was applied as a basal dose through 12:32:16 N:P:K Complex Fertilizer (NPK complex fertilizer 12:32:16% N:P:K) at seeding. The remaining nitrogen was top-dressed in two equal splits at tillering (Ammonium nitrate, 33% N) and jointing stage (Urea, 46% N). Weed, disease, and insect control were uniformly managed during the crop growing seasons. 2.4. Measurements and calculations 2.4.1. Phenology, yield, and yield attributes Days to emergence, anthesis, and maturity were recorded each year for each treatment based on whole plot observation. For harvesting, two border rows (each side of the plot) and 50 cm each from the top and bottom parts of the plots) were removed manually, and two rows of one-meter length from two points of each plot were harvested manually to estimate biomass weight, grain weight and yield attributes (total number of effective spikes, and grains per spike). After this, a plot combine harvester operated to harvest the remaining area and grain weight was recorded. Grain yield (kg ha-1) was computed from both, i.e., manually and machine harvested areas, and there was good agreement. For each plot, the final grain yield was calculated from the total grain weight of 6 m x 2.2 m (manual and mechanically harvested) area and expressed in kg per hectare. To determine the number of grains per spike, 20 spikes were taken randomly, oven-dried, and weighed – after which the grains were separated from the spikes, weighed, and the number counted. Thousand kernel weight (TKW) was determined based on the oven-dried weight of 500 grains. Harvest index (HI) was computed from the ratio of oven-dried grain to total aboveground biomass. 2.4.2. Water use efficiency Water use efficiency was computed in terms of field-WUE (kg grain mm-1 water input from irrigation and rainfall) and crop-WUE (kg grain mm-1 evapotranspiration). In supplementary irrigated treatments, field-WUE was computed using total rainfall and amount of irrigation applied (total water), while in the rainfed system, it was computed considering total rainfall received during the crop growing period. Crop-WUE was computed using daily measured evapotranspiration. During the experimental season, daily evapotranspiration (ETo) was measured using the automated weather measuring device iMETOS 3.3 installed close to the research plot (within a 200 m distance). 2.5. Machine learning analytics Random Forest (RF) machine learning analytics (Breiman, 2001, Breiman and Cutler, 2012) was used to determine the major predictors for six major variables, i.e. grain yield, WUE, total aboveground biomass, spikelet density, grains per spike, and TKW for rainfed and irrigated systems separately. We employed the ‘randomForest’ package in R Version 4.3.1 to identify their determinants (based on relative importance, i.e., %IncMSE metric – see Breiman and Cutler, 2012). Days to flowering, irrigation amount, rainfall (early-, mid-, and late-season), seeding time, genotype, temperature during flowering, and total rainfall during the crop growing period were also used as covariates. The measured rainfall and temperature data during the crop growing period were used. The RF model was trained using 80% of the data, with 20% reserved for independent model validation. 2.6. Statistical analysis This study evaluated 10 durum wheat genotypes under rainfed and supplementary irrigation (water management) systems with two seeding dates for four years. Analysis of variance (ANOVA) was performed for yield, WUEs, major yield attributes, and water-limited yield gaps using GenStat 21st edition. Results were presented year-wise as the year effect was significant for year x water management, year x seeding time, and year x varieties. Before conducting ANOVA, the normality distribution of the data for each year was examined for yield and yield attributes and WUEs using Shapiro-Wilk and Bartlet’'s homogeneity test. The treatment mean differences were analysed using the least significant difference (LSD) at p < 0.05, < 0.01, and < 0.001 levels of significance. Mean, standard deviation, coefficient of variation, and percentage difference were calculated wherever applicable. Percent contribution of different main and interaction factors to the overall variation in yield, total above-ground biomass production and water use efficiencies of the evaluated treatments was obtained by partitioning the ANOVA sum of squares and computing the ratio of a variation of a factor to the total variance and converted to percentage. Water-limited yield gaps for tested treatments were derived from the difference between the maximum attainable yield without water limitation minus the yield of each plot in the respective year (Van Ittersum et al., 2013). The maximum attainable yield without water limitation was derived by fitting an output (yield)–input (total water input) response boundary curve from supplementary irrigated treatment to identify the highest attainable yield without water limitation. Also, the random forest regression model (Breiman, 2001, Breiman and Cutler, 2012) was used to determine the determinants of yield and yield attributes and WUE under rainfed and supplementary irrigation systems mainly using different climatic (rainfall and temperature) and management (seeding time, genotype, and irrigation) factors as covariate. 3. Results 3.1. Inter- and intra-rainfall and temperature variability during experimental years The study years had high inter- and intra-rainfall variability (Table 2). The seasonal rainfall was higher in 2018 than in 2016, 2017, and 2019. In 2016, cropping season rainfall was equally distributed in the early-, mid-, and late-seasons. In 2017, 94% of the season’s rainfall was during early- and mid-season, while the late season remained dry. In 2019, most of the season’s rainfall was received in the early season, while mid- and late- seasons received only 16% and 18%, respectively. In contrast, 2018 was a wet year with significant mid- and late-season rainfall. The average temperature during grain filling (April–May) was the lowest in 2018 (13.9–15.9 °C), while was the highest during 2017 season (18–20.8 °C) (Table 2). Table 2. Cumulative rainfall (mm) during different crop growing seasons, i.e., early- (October-December), mid- (January-February), late-season (March-May); and average temperature (oC) during March, April, and May (flowering to grain filling period) for experiment conducted during 2015/16–2018/19 cropping seasons. Growing year Cumulative rainfall (mm) Average temperature (oC) Early season Mid-season Late season Seasonal March April May 2015/16 87 (34) 79 (31) 90 (35) 256 11.7 15.1 18.5 2016/17 137 (50) 127 (46) 12 (4) 276 13.1 18 20.8 2017/18 93 (19) 172 (35) 231 (46) 496 12.7 13.9 15.9 2018/19 197 (66) 49 (16) 54 (18) 300 14.55 14.6 20.3 Note: The values in the parenthesis are % of the seasonal rainfall during different growing seasons. 3.2. Yield and yield attributes of wheat affected by genotype and agronomic management There was a significant year (Y), seeding time (SD), water management (Wm), and genotype (G) main effects for grain yield, spike density, grains per spike, TKW, HI, and field- and crop-WUE except for seeding time effects for grain yield, HI, and field-WUE (Table 3). Effects of year, water management, and year × seeding time accounted for 43%, 23%, and 15% of the yield variation in the experiment, respectively. The effect of genotype accounted for 5.6% of variation for spike density, 5% for TKW, 3.5% for HI, and 3.1% for grains per spike. Significant year × seeding time, year × water management, and year × genotype effects were observed for almost all traits, except for year x water management in spike density. The year × seeding time × water management and year × seeding time × genotype interactions were significant only for yield and WUEs (both field and crop) (Table 3). Table 3. Analysis of variance (ANOVA) showing grain yield, total aboveground biomass (TAGB), yield attributes, field- and crop-water use efficiencies, and yield gap; and percentage in total variance accounted by year (environment), seeding date (SD), water management (Wm), and genotype (G) evaluated in two seeding dates and two water management methods over four growing seasons (2016–2019) in Merchouch, Morocco. The numbers in the table are percent contribution of different factors. Source of variance DF Grain yield (t ha-1) TAGB (t ha-1) Spike density m-2 Grain spike-1 TKW (g) HI (%) Field-WUE (kg mm-1) Crop-WUE (kg mm-1) Yield gap (t ha-1) Year (Y) 3 42.7 *** 21.23 *** 32.5 *** 35.6 *** 40.5 *** 12.6 ** 5.3 * 63.7 *** 42.7 *** Replication within year 8 0.4 ns 1.44 ns 1.9 ns 0.6 ns 0.2 ns 3.9 ns 1.6 ns 0.3 ns 0.4 ns Seeding date (SD) 1 0.7 ns 1.07 ns 2.3 ** 12.9 *** 7.4 *** 0.1 ns 0.2 ns 0.3 ns 0.07 Y × SD 3 14.8 *** 10.28 * 18.3 *** 3.5 ** 1.8 * 13.7 * 22.8 ** 15.3 *** 14.8 *** Pooled error (a) 8 1.3 3.90 1.1 1.3 1.0 4.9 0.1 0.7 1.3 Water management (Wm) 1 22.5 *** 22.68 *** 5.7 *** 1.3 * 16.9 *** 4.6 *** 5.9 ** 9.7 *** 22.5 *** SD × Wm 1 0.2 * 0.76 * 0.3 ns 0.4 * 0.5 * 0.4 ns 6.8 *** 0.1 * 0.2 * Y × Wm 3 7.4 *** 7.33 *** 0.2 ns 7.3 *** 4.8 *** 3.1 *** 12.5 *** 2.7 *** 7.4 * Y × SD × Wm 3 0.7 * 1.47 * 0.3 ns 0.5 ns 1.7 ** 0.8 ns 10.2 ** 0.3 * 0.7 * Pooled error (b) 16 0.8 2.07 1.5 1.3 1.2 1.8 6.4 0.5 0.8 Genotype (G) 9 1.2 *** 1.01 ns 5.6 *** 3.1 *** 5.1 *** 3.5 *** 1.6 *** 1.2 *** 1.2 *** SD × G 9 0.4 ** 0.53 ns 0.5 ns 0.9 ns 0.1 ns 1.7 ns 1.1 ** 0.3 *** 0.4 *** Wm × G 9 0.2 * 0.65 ns 0.3 ns 0.8 ns 0.3 ns 0.7 ns 0.8 * 0.2 ** 0.2 * Y × G 27 1.6 ** 1.67 ns 3.1 * 2.4 * 2.8 *** 4.9 * 2.7 *** 1.4 *** 1.6 *** SD x Wm x G 9 0.1 ns 0.48 ns 0.3 ns 1.2 ns 0.7 * 1.4 ns 0.3 ns 0.1 ns 0.1 ns Y × SD × G 27 1.0 ** 1.34 ns 1.9 ns 1.4 ns 1.5 ns 3.6 ns 2.6 *** 0.9 *** 1.0 *** Y × Wm × G 27 0.3 ns 2.54 * 1.4 ns 1.0 ns 1.0 ns 1.6 ns 1.1 ns 0.1 ns 0.3 ns Y × SD × Wm × G 27 0.3 ns 1.98 ns 1.3 ns 1.3 ns 0.9 ns 3.9 ns 1.4 ns 0.2 ns 0.3 ns Pooled error (c) 288 3.3 17.54 21.3 23.4 11.6 32.8 10.6 2.0 3.3 Total error (residual) † - 5.4 23.5 24.0 25.9 13.9 39.5 17.1 3.2 5.4 * , ** , *** indicates significant at P < 0.05, < 0.01 and < 0.001, respectively, ns= non-significant. DF= Degree of freedom; TKW=Thousand grain weight; † Residuals (unaccounted contribution) 3.2.1. Main effects Overall, the average yield and biomass production varied significantly with weather differences (year) over the study years (Table 4), with the highest yield in 2018 (7.15 t ha−1) followed by 2017 (4.82 t ha−1) and the lowest in 2019 (3.42 t ha−1) (Table 5). On average, supplemental irrigation increased grain yield by more than 2.0 t ha−1 compared to rainfed (5.9 vs. 3.88 t ha−1), while there was no significant main effect of seeding time on grain yield (5.06 t ha−1 for November seeding vs. 4.72 t ha−1 for December). On average, genotype G7 produced the highest yield (5.14 t ha−1) followed by G8 (5.12 t ha−1), G1 and G9 (5.07 t ha−1), and the lowest for G6 (4.43 t ha−1). A similar trend was observed for WUEs and yield attributes (Table 5). Table 4. Analysis of variance (ANOVA) showing the contribution of seeding date x water management x genotype on grain yield, total aboveground biomass, and crop water use efficiency in total variance in different growing seasons from 2016 to 2019. Numbers in the table are percent contribution of different factors. Source of variance DF Grain yield Total aboveground biomass Crop water use efficiency 2016 2017 2018 2019 2016 2017 2018 2019 2016 2017 2018 2019 Replication 2 0.3 ns 0.8 ns 0.8 ns 1.2 ns 2.6 ns 0.6 ns 3.3 ns 1.0 ns 0.2 ns 0.3 ns 0.5 ns 2.7 ns Seeding date (SD) 1 14.0 ns 26.5 * 32.9 * * 41.3 * 8.1 ns 35.2 * 1.7 ns 12.7 * 9.9 ns 60.6 * 57.7 * * 20.6 * Error (a) 2 2.0 3.8 0.3 1.6 6.4 6.8 3.7 1.7 2.4 1.9 0.1 3.1 Water management (Wm) 1 75.6 *** 54.3 *** 0.5 ns 39.3 *** 45.6 *** 29.7 ** 1.2 ns 44.6 *** 75.5 *** 26.7 *** 0.4 ns 49.8 ** SD × Wm 1 0.9 * 0.0 ns 1.8 ns 4.1 * 6.1 * 0.2 ns 0.4 ns 0.5 ns 1.9 * 0.7 ns 1.2 ns 1.6 ns Error (b) 4 0.3 2.7 1.0 1.8 2.0 4.6 2.2 2.2 0.4 1.3 0.7 3.2 Genotype (G) 9 0.6 ns 1.3 ns 38.1 *** 1.9 ** 1.7 ns 1.1 ns 12.2 * 4.9 * 1.6 * 1.4 ** 24.4 *** 3.3 ** SD × G 9 0.3 ns 2.6 ** 12.7 *** 1.7 ** 1.3 ns 2.9 ns 7.4 ns 2.1 ns 0.5 ns 2.0 ** 7.9 *** 3.9 ** Wm × G 9 0.4 ns 0.8 ns 0.7 ns 1.5 ** 1.6 ns 2.0 ns 11.4 * 7.0 * 0.9 ns 0.4 ns 0.4 ns 2.1 * SD x Wm x G 9 0.4 ns 0.8 ns 1.3 ns 1 ns 3.1 ns 3.5 * 6.9 ns 1.8 ns 0.5 ns 0.4 ns 0.8 ns 1.6 ns Error (c) 72 5.1 6.4 10.1 4.5 21.4 13.3 49.8 21.4 6.2 4.1 6.0 8.0 Total error (Residual) † 119 7.4 12.9 11.3 7.9 29.9 24.8 55.6 25.4 8.9 7.3 6.8 14.3 * , ** , *** indicates significant at P < 0.05, < 0.01 and < 0.001, respectively, ns= non-significant. DF= Degree of freedom; †Residuals (unaccounted contribution) Table 5. The main effect of environment (year), seeding time (SD1- 17 November and SD2- 29 December), water management and genotypes on grain yield, total aboveground biomass accumulation (TAGB), number of spikes, grains per spike, thousand grain weight (TKW) crop water use efficiency (Crop-WUE) in Merchouch, Morocco. Values are mean + standard deviation. Treatments Grain yield (t ha-1) TAGB (t ha-1) No. of spikes (No. m-2) Grains spike-1 TKW (g) Crop-WUE (kg mm-1) Year 2016 4.18 + 1.8 13.28 + 5.2 349 + 108 31 + 9 47 + 8 14.0 + 6.1 2017 4.82 + 1.7 13.84 + 3.6 411 + 122 32 + 10 39 + 7 15.3 + 3.2 2018 7.15 + 1.0 18.04 + 2.4 441 + 94 32 + 10 53 + 3 15.2 + 3.0 2019 3.42 + 1.7 12.81 + 4.2 242 + 114 48 + 10 48 + 7 17.0 + 5.2 Seeding date SD1 5.06 + 1.9 14.96 + 4.3 381 + 131 31 + 11 49 + 8 15.2 + 6.0 SD2 4.72 + 2.3 14.03 + 4.6 340 + 133 40 + 12 44 + 8 15.6 + 3.1 Water management Irrigated 5.90 + 1.5 16.64 + 3.3 393 + 129 37 + 12 50 + 7 16.5 + 4.2 Rainfed 3.88 + 2.1 12.34 + 4.5 329 + 130 34 + 12 43 + 9 14.3 + 5.1 Genotype G1 5.08 + 2.3 14.62 + 5.0 317 + 121 38 + 11 49 + 9 15.7 + 4.1 G2 4.86 + 2.2 14.12 + 4.9 345 + 141 36 + 11 48 + 8 15.2 + 5.0 G3 4.91 + 2.1 14.71 + 4.0 357 + 136 34 + 11 50 + 8 15.4 + 4.2 G4 4.87 + 2.2 14.01 + 4.1 347 + 131 37 + 13 46 + 10 15.2 + 5.0 G5 4.87 + 2.1 14.38 + 3.9 365 + 118 35 + 12 46 + 7 15.4 + 5.1 G6 4.43 + 1.8 13.92 + 4.1 356 + 131 33 + 13 45 + 8 14.4 + 5.0 G7 5.14 + 2.1 14.93 + 4.3 445 + 156 34 + 12 44 + 8 16.4 + 5.0 G8 5.12 + 2.2 14.68 + 4.4 345 + 128 38 + 11 47 + 7 15.9 + 4.1 G9 5.07 + 2.2 14.11 + 4.0 357 + 130 39 + 12 46 + 9 15.9 + 5.2 G10 4.53 + 1.8 15.45 + 5.7 374 + 98 33 + 11 44 + 7 14.5 + 4.2 Note: Details of genotype (G) presented in SI1 3.2.2. Interaction effects 3.2.2.1. Effect of year × water management There was a significant year × water management interaction for grain yield, biomass production, WUEs, and yield attributes (Table 3, Table 4). The supplementary irrigation increased grain yield by 2.12–3.27 t ha−1 (Fig. 3 and Table 5) and biomass by 3.98–7.08 t ha−1, except in 2018 (Table 5) when seasonal rainfall exceeded the potential evapotranspiration (Fig. 4); hence the lowest number of supplementary irrigations was applied during this season (Table 1). The field-WUE was significantly affected by supplementary irrigation except in 2017 and 2018 when supplementary irrigation increased it by 0.77 kg mm−1 compared to the rainfed system (Table 5). However, crop-WUE was significantly higher under supplementary irrigation than under rainfed also in 2017. Both field- and crop-WUE varied greatly across years and also genotype (except 2016 in SD1, 2016, 2017 and 2018 in SD2 for field-WUE; and Crop-WUE in in 2016 and 2017 on SD2 ) (Table 6). Although there was no significant effect of supplemental irrigation on spike density, it was higher under the supplementary irrigation than in rainfed systems in all years. Similarly, grains per spike and TKW were higher for supplementary irrigation than rainfed except in 2018 (Table 4). Download : Download high-res image (119KB) Download : Download full-size image Fig. 3. Average grain yield of wheat under rainfed and supplementary irrigation planted in two seeding dates (SD1- 17 November; SD2- 29 December seeding) over four years at Merchouch, Morocco. The vertical bar represents standard error. Download : Download high-res image (909KB) Download : Download full-size image Fig. 4. Total water input (mm) and cumulative evapotranspiration (ETo) (mm) during crop growing season in two seeding dates under rainfed and supplementary irrigation for four different growing seasons (2015/16–2018/19). Figures in the first column for 1st seeding and the second column for 2nd seeding dates. Table 6. Interaction between year and water management on grain yield, total biomass (AGB), harvest index (HI), field and crop water use efficiencies, and yield attributes evaluated in two seeding dates and two water management methods over four growing seasons (2016–2019) in Merchouch, Morocco. Parameters 2016 2017 2018 2019 LSD at p = 0.05 Irrigated Rainfed Irrigated Rainfed Irrigated Rainfed Irrigated Rainfed Grain yield (t ha-1) 5.82a‡ 2.55b 6.09a 3.54b 7.22a 7.08a 4.48a 2.36b 0.58 AGB (t ha-1) 16.82a 9.74b 15.83a 11.85b 18.30a 17.78a 15.63a 9.99b 1.95 HI (%) 41.9a 35.1b 36.5a 29.2b 40.1a 40.4a 34.1a 32.2a 3.3 Field-WUE (kg mm-1) 17.9a 10.2b 15.6a 15.2a 14.9a 15.6a 17.8a 16.3b 1.2 Crop-WUE (kg mm-1) 15.6a 7.2b 18.2a 11.1b 29.2a 28.6a 14.8a 8.5b 1.84 Spike m-2 381 317 444 378 465 418 281 204 ns Grain spike-1 36.2a 25.7b 32.25a 27.8b 31.3a 32.8a 51.9a 44.1b 2.88 TKW (g) 51.82a 41.83b 43.01a 34.09b 53.86a 53.11a 51.52a 43.63b 2.78 ‡Same letter denotes non-significant difference between rainfed and irrigated in respective year 3.2.2.2. Interaction effect of year × seeding time × water management There was a significant year × seeding time × water management interaction for grain yield, total aboveground biomass accumulation, field-WUE, and yield attributes (Table 4). In a low-rainfall year, grain yield increased by 1.47–3.63 t ha−1 with the application of supplementary irrigation under both timely and late seeding (Fig. 3). 3.2.2.3. Effect of year × genotype × seeding time on grain yield and field-WUE The effect of seeding time on grain yield was highly dependent on the rainfall distribution. Irrespective of other effects, the range in average grain yield of genotypes was 4.43–5.14 t ha−1. There was a significant year × genotype × seeding time interaction for grain yield and field-WUE, indicating that the effect of genotype and seeding time varied with rainfall amount and distribution (Table 6). In 2016, grain yield and field-WUE did not significantly differ among the tested genotypes for both seeding dates. In 2017, G1, G3, and G5 were the top three high-yielding genotypes, and G10 produced a low yield for early seeding, while there was no significant difference among the tested genotypes for late seeding. In 2018, G1, G8, and G9 were top-yielding genotypes for early seeding and G1, G8, and G7 were top-yielding for late seeding. Genotype G10 produced low yield under both early and late seeding. In 2019, G9, G7, and G4 were the top three high-yielding genotypes and G10 produced a low yield in early seeding. G7, G10, and G8 were the top three high-yielding genotypes for late seeding, and G4 produced the lowest yield. A similar trend for grain yield was observed for field-WUE (Table 6). 3.3. Water-limited yield gaps of genotypes With supplemental irrigation, the attainable yield gap was reduced by about 2 t ha−1 compared to the rainfed system (Table 7). Similarly, advancing the seeding time reduced the attainable yield gap by 0.35 t ha−1 compared to late seeding. Significant genotype and water management effects were observed for the water-limited attainable yield gaps. Genotype G6 showed higher yield gaps under both rainfed and supplemental irrigation (Fig. 6). Genotypes G7, G8, and G9 had relatively reduced yield gaps under both rainfed and irrigated conditions compared to other genotypes. Table 7. Effect of wheat genotype and seeding time (SD1- 17 November and SD2- 29 December) on wheat grain yields and field and crop water use efficiencies over four crop growing seasons (2016 – 2019) in on-station experiments at Merchouch, Morocco. Genotype Grain yield (t ha-1) Field water use efficiency (kg mm-1) Crop water use efficiency (kg mm-1) 17 November (SD1) 29 December (SD2) 17 November (SD1) 29 December (SD2) 17 November (SD1) 29 December (SD2) Empty Cell 2016 2017 2018 2019 2016 2017 2018 2019 2016 2017 2018 2019 2016 2017 2018 2019 2016 2017 2018 2019 2016 2017 2018 2019 G1 3.71a‡ 6.19a 7.76a 4.15ab 4.91a 3.60a 8.13a 2.16ab 12.4a 17.8a 15.2a 18.3bcd 16.3a 13.3a 18.5a 13.5bc 10.6ab 22.0a 29.9a 13.1abc 13.1a 8.5a 35.8a 9.0b G2 3.51a 5.75a 6.33 cd 4.63ab 4.81a 4.07a 7.67ab 2.14ab 12.1a 16.4ab 12.4abc 20.3abcd 15.7a 14.6a 17.4a 12.8bc 9.9ab 20.6ab 24.2de 14.2abc 12.9a 9.6a 33.1ab 9.0b G3 3.59a 6.07a 6.86abc 4.09b 4.98a 3.64a 7.83ab 2.25ab 12.1a 17.3a 13.5ab 17.8 cd 16.8a 13.3a 17.8a 14.3b 9.9ab 21.6a 26.4bcd 12.5abc 13.1a 8.6a 33.7ab 9.3b G4 3.48a 5.64ab 6.73bc 4.79ab 4.83a 4.15a 7.54ab 1.82b 12.3a 16.1ab 13.2ab 21.3abc 15.9a 15.3a 17.1a 10.1c 10.3ab 20.5ab 26.3bcd 15.5a 13.1a 9.8a 33.7ab 7.7b G5 3.60a 6.04a 5.95 cd 4.72ab 5.05a 3.69a 7.70ab 2.20ab 12.1a 17.3a 11.6abc 20.9abcd 17.0a 13.3a 17.5a 13.8b 10.5ab 20.7ab 22.6ef 14.5ab 13.4a 8.8a 32.6b 9.1b G6 3.03a 5.54ab 4.54e 4.56ab 4.65a 3.57a 7.28ab 2.26ab 10.4a 16.0ab 8.9c 20.8abcd 15.6a 13.1a 16.6a 14.3b 9.0ab 19.1ab 17.2 g 14.2abc 12.7a 8.5a 32.1b 9.7ab G7 3.65a 5.83a 6.56 cd 4.86ab 4.93a 4.23a 8.12a 2.97a 12.5a 16.4ab 12.9ab 21.5ab 16.5a 15.2a 18.5a 18.0a 10.2ab 21.2ab 25.6cde 14.6ab 13.1a 10.0a 33.9ab 12.4a G8 3.72a 5.93a 7.71a 4.09b 4.76a 4.23a 8.14a 2.43ab 12.8a 16.8ab 15.1a 18.1bcd 15.6a 16.0a 18.5a 13.9b 10.9a 20.0ab 28.8ab 12.2bc 12.7a 10.0a 33.7ab 10.1ab G9 3.33a 5.36ab 7.53ab 5.05a 5.06a 3.91a 7.83ab 2.50ab 11.2a 15.0ab 14.8ab 22.1a 17.0a 14.4a 17.8a 14.7ab 9.5ab 18.4bc 28.1abc 14.7ab 13.4a 9.3a 31.9b 10.4ab G10 3.13a 4.73b 5.70d 4.07b 4.88a 4.14a 7.03b 2.58ab 10.4a 13.6 b 11.2bc 17.7d 16.0a 15.2a 16.0a 15.8ab 7.7b 16.0c 20.5 f 11.4c 11.9a 9.8a 28.2c 9.8ab Grand mean 3.48 5.71 6.57 4.50 4.89 3.92 7.73 2.33 11.8 16.3 12.9 19.9 16.2 14.4 17.6 14.1 9.9 20.0 25.0 13.7 12.9 9.3 32.9 9.7 CV (%) SD 28.37 - - - - - - 37.13 - - - - - - - 33.97 - - - - - - - Empty Cell Wm 21.88 - - - - - - 31.69 - - - - - - - 20.28 - - - - - - - Empty Cell Genotype 10.25 - - - - - - 12.61 - - - - - - - 9.93 - - - - - - - LSD (p = 0.05) SD x G 0.92 - - - - - - 3.57 - - - - - - - 3.04 - - - - - - - ‡Same letter denotes non-significant difference among genotypes in respective year and seeding date. Note: Details of genotype (G) presented in SI1 3.4. Prediction and causal factors of grain yield, total biomass production, WUE, and yield components 3.4.1. Rainfed system In the rainfed system, the RF model well explained variance for grain yield (92%), yield components (60–90%), and field-WUE (84%) with good agreement between predicted and observed values in the test data. The RMSE of the model was 544 kg ha−1, which is 11% of the average observed grain yield. The model showed the effect of different climatic (rainfall and temperature) and management (e.g., seeding time, genotype, and irrigation) factors on yield, yield attributes, and field-WUE (Fig. 5). Total seasonal rainfall was the most important factor explaining variation in wheat yield followed by temperature at flowering, mid- and early-season rainfall, and genotype in order of importance. Similarly, early-season rainfall was the most important factor explaining variation in total biomass production followed by mid- and total-seasonal rainfall and temperature during flowering in the order of importance. Total-, early-, and mid-season rainfall were important factors explaining variation in spike density at harvest. Similarly, grain per spike was influenced by flowering temperature and mid- and total-seasonal rainfall in order of importance. In order of importance, the TKW was influenced by mid- and late-season rainfall and genotype. Similarly, mid-, late-, and total-seasonal rainfall and temperature at flowering in order of importance were the major determinants for field-WUE in rainfed systems. Download : Download high-res image (418KB) Download : Download full-size image Fig. 5. Importance of different variables (%) in explaining variation in grain yield (kg ha-1), total aboveground biomass production (TAGB, kg ha-1), spike density (spikes m-2), grains spike-1 (number), thousand grain weight (TKW, g), and field water use efficiencies (field-WUE; kg grain mm-1 water) in the rainfed production system – results from the random forest (RF) model. Values in parenthesis are percentage variation explained (1st) and the R2 (2nd). Note: rainfall amount (mm) early season- October to December, mid-season – January to February, late-season- March to May; total rainfall- rainfall amount during crop growing season; Genotypes: 10 different genotypes evaluated; seeding time- timely (early November) vs. late (late December). 3.4.2. Supplementary irrigation system In the irrigated production system, the RF model well explained variance for grain yield (76%), yield components (51–63%), and field-WUE (88%) with good agreement between predicted and observed values in test data. The RMSE of the model was 604 kg ha−1, which is 9% of the average observed grain yield. The model showed that seasonal rainfall was the most important factor explaining variation in grain yield followed by early-season rainfall, days to flowering, temperature at flowering, irrigation amount applied, seeding time, and type of genotype used (Fig. 6). Similarly, grain yield was the most important factor explaining variation in field-WUE followed by days to flowering, irrigation amount, and mid- and early-season rainfall in the order of importance. With supplemental irrigation, the amount of rainfall and days to flowering were observed as important factors determining grain yield, field-WUE, spike density, grains per spike and TKW. Similarly, temperature during flowering is also considered as one of the important factors determining grain yield, spike density, and TKW. This indicated that varieties with longer vegetative growth, heat and drought tolerant characteristics are important for improving crop productivity and quality (grain size) in Mediterranean drylands in Morocco. Download : Download high-res image (399KB) Download : Download full-size image Fig. 6. Importance of different variables in explaining variation in grain yield (kg ha-1), total biomass production (kg ha-1), spike density (spikes m-2), grains spike-1 (number), thousand grain weight (TKW, g), and field water use efficiency (Field-WUE, kg mm-1) in the irrigated production system – results from the random forest (RF) model. Values in parenthesis are percentage variation explained (1st) and the R2 (2nd). Note: rainfall amount (mm) early season- October to December, mid-season – January to February, late-season- March to May; total rainfall- rainfall amount during crop growing season; Genotypes: 10 different genotypes evaluated; seeding time- timely (early November) vs. late (late December). 4. Discussion This study comprehensively analyzed the genotype × environment × management effect using four years of experimental data on durum wheat productivity and WUEs in a rainfed Mediterranean environment of Morocco. Significant year effect with seeding time, water management, and genotype (with four contrast rainfall growing seasons; Table 2) on grain yield, major yield attributes and WUEs indicates the need for customized seeding time, water management, and suitable genotype for improving wheat production with resilience. More than 7.0 t ha−1 yield of durum wheat in 2018 (Table 4) with the highest seasonal rainfall (496 mm) and lowest average yield (2.3 t ha-1) in 2019 with lowest and poorly distributed rainfall (Table 2) under rainfed conditions also justifies the importance of gowning season rainfall (mainly amount and its distribution) and accordingly suitable agronomic solutions for improving productivity. Also, out of four, three growing seasons have water stress where evapotranspiration exceeded the total rainfall in rainfed (Fig. 4), however application of 80–150 mm water through drip irrigation (Table 1) had increased grain yield by 2–3 t ha-1, indicates the need of demand-based supplementary irrigation for stable yield in such variable climatic condition. The machine learning analysis also showed that the amount of rainfall and flowering time temperature remained major factors determining yield and WUE (Fig. 5). In Morocco, ∼85% of the wheat area is under rainfed with an average productivity of 1.85 + 0.63 t ha-1 (recent 10 years, i.e., 2012–2021 average productivity) (FAOSTAT, 2023). The average productivity under farmers’ management can be increased by 1.5 t ha-1 (considering at least 50% of the productivity achieved in the experimental station in our study) if the provision of supplementary irrigation in extreme drought conditions is available. From the analysis of the recent 10 years (2012–2021) FAOSTAT data, on average, Morocco is importing 44% of wheat grain (4.30 +1.09 MT year-1) to fulfill the country's need. Considering this scenario (average yield increment of 1.5 t ha-1), if there is the provision of supplementary irrigation in 1 M ha, total annual wheat production in the country can be increased by 23% and reduced the import by 35%. The significant year × seeding time (Table 3) indicates the effect of seeding time varies across year as a proxy of rainfall distribution and amount. Our yearly variance decomposition analysis found the contribution of seeding time (to the total variance) ranged from 14% to 41% for grain yield, 8–35% for total aboveground biomass, and 10–61% for crop-WUE (derived from Table 4). Also, the significant seeding time × water management effect justifies the effect of seeding time varies with water availability (either through rainfall or supplemental irrigation). Compared to 2016 and 2017, the lowest yield under rainfed conditions in 2019 (2.36 t ha−1; Table 5), where 197 mm (66%) of total rainfall occurred during the early season (Table 2) and distribution was poor. Majority of the wheat yield variability in rainfed conditions can be explained by crop growth rate (Balaghi et al., 2008), total seasonal rainfall and rainfall during the critical growth stages (Latiri et al., 2010), and previous crop, residual soil moisture, and genotype resilience to rainfall variability (Devkota et al., 2022a). The significant year × seeding time effect (Table 3), especially the higher yield in 2017 and 2019 for rainfed conditions under SD1, while the higher yield under SD2 in 2016 (>3 t ha−1) with the lowest seasonal rainfall (256 mm), shows that seeding time need to be adjusted according to rainfall variability. Our study found that early seeding with supplemental irrigation can provide a more stable yield, where SD1 with supplemental irrigation had yield variability (coefficient of variation, CV) of 17% compared to 50% under rainfed; and SD2 had CV of 34% with supplementary irrigation and CV of 60% under rainfed). However, more than 1.0 t ha-1 higher yield under SD2 (29 December seeding) than under 17 November (SD1) in 2018 (good rainfall year) indicates higher yield (>7.0 t ha-1) can be obtained even if seeding by the end of December in the year with well-distributed rainfall and cool temperature during flowering and grain filling (Table 2). Also, rainfall just before and during the early grain-filling period is critical for higher yields (Heng et al., 2007). Under the drier conditions with late seeding, higher temperatures shortened crop growth duration and grain filling period, accelerated leaf senescence, and reduced grain setting, thus reduced yield. In our study, late planting reduced aboveground biomass accumulation, spikelet density, grains per spike, and TKW. This finding is consistent with the results of Rezzouk et al. (2022) for durum wheat in the Mediterranean climatic condition of Spain. Thus, in drylands, customized seeding time based on weather forecasting (considering rainfall amount, rainfall frequency, and temperature) can maximize the effective use of available water, which leads to improved crop productivity and resilience. Similarly, yield performance and WUEs varied due to main effects of water management and genotype and its interaction with year (Table 3, Table 7; Fig. 3). This result has been supported by the results of machine learning (Fig. 4, Fig. 5); where year/rainfall/supplementary irrigation interactions accounted for the highest contribution to grain yield and WUEs. Out of four, three growing seasons received below-average rainfall and the application of supplemental irrigation in low rainfall years increased grain yield by > 3.0 t ha-1 (Table 6). Also, analysis of variance decomposition showed the contribution of supplemental irrigation ranged from 0.5% (in wet year 2018) to 76% (in the dry year 2016, where seasonal rainfall was 256 mm). As expected, application of supplemental irrigation reduced the water-limited yield gaps (Table 8) and improved WUEs (Table 6) compared to rainfed, further justifies that availability of supplemental irrigation or rainfall amount is the major determinant of wheat yield. Consistent with this finding, significant effects of supplemental irrigation in increasing yields of durum wheat and other crops (bread wheat, faba bean, chickpea, and lentil) under rainfed conditions were reported in the dry Mediterranean region of Syria (Karrou, 2013, Karrou and Oweis, 2012). However, with declining water availability, water for supplemental irrigation may not be available in such rainfed drylands. Also, with the climate change patterns in the Mediterranean region, frequency of occurrence of drought is increasing in recent years and will be more severe in the future (Lange, 2020). Hence it is important to develop integrated climate-smart crop management practices considering season’s rainfall and availability of supplemental irrigation. Table 8. Interaction between genotypes and water management and genotypes and seeding date on yield gaps (maximum yield- individual treatment yield). Genotype Seeding date Water management 17 November (SD1) 29 December (SD2) Empty Cell 2016 2017 2018 2019 2016 2017 2018 2019 Rainfed Irrigated G1 4.80a‡ 2.32b 0.75e 4.36ab 3.60a 4.91a 0.38b 6.36ab 4.41b 2.46c G2 5.00a 2.76b 2.18bc 3.88ab 3.70a 4.45a 0.84ab 6.37ab 4.78ab 2.51c G3 4.93a 2.44b 1.65cde 4.42a 3.53a 4.87a 0.68ab 6.26ab 4.52ab 2.67bc G4 5.03a 2.87ab 1.78 cd 3.72ab 3.68a 4.36a 0.97ab 6.70a 4.72ab 2.56bc G5 4.91a 2.47b 2.56bc 3.79ab 3.46a 4.82a 0.82ab 6.32ab 4.63ab 2.65bc G6 5.48a 2.97ab 3.97a 3.95ab 3.86a 4.94a 1.23ab 6.25ab 4.86ab 3.30a G7 4.86a 2.69b 1.95bc 3.65ab 3.58a 4.28a 0.39b 5.54b 4.48b 2.25c G8 4.79a 2.58b 0.80e 4.43a 3.75a 4.28a 0.38b 6.08ab 4.42b 2.35c G9 5.18a 3.15ab 0.98de 3.46b 3.45a 4.60a 0.68ab 6.01ab 4.55ab 2.33c G10 5.38a 3.78a 2.81b 4.44a 3.63a 4.37a 1.48a 5.93ab 4.94a 3.01ab Grand mean 5.04 2.80 1.94 4.01 3.63 4.59 0.79 6.18 4.63 2.61 CV (%) SD 41.81 - - - - - - - - Empty Cell Wm 19.55 - - - - - - - - Empty Cell Genotype 13.84 - - - - - - - - LSD (p = 0.05) SD x G 0.92 - - - - - - 0.58 - ‡ Same letter denotes non-significant difference among genotypes in each year and seeding date. Note: Details of genotype (G) presented in SI1 The significant genotype × water management interaction in yield and yield attributes indicated that expression of plant traits such as total aboveground biomass accumulation, spikelet density, HI, grains per spike, and TKW (Table 6), which actively contribute to yield, are affected by efficient water management. Genotypes G7 followed by G8 consistently performed better in both rainfed and irrigated environments across the year and low water-limited yield gaps. This suggests that selection of varietal traits that increase yield and field-WUE under favorable and low moisture conditions is important for such variable rainfed drylands (Yu et al., 2021). Our result showed that the contribution of genotypes in the total yield variance was highest (38%) in the wet year (2018) and the lowest in the driest year (0.6%) (Table 4). This result indicates the tested genotypes have higher yield gain under favorable conditions and demands for developing suitable drought-tolerant varieties for variable weather and low rainfall environments. However, the contribution of genotype cannot be underestimated as genotype potential is suppressed by climatic and management factors (stresses) and water plays a major role, while in irrigated conditions, the current genotypes can express their full potential (Ojeda et al., 2022, Ojeda et al., 2021). Comparatively low contribution of genotype in our experiment could be genotypes were bred under favorable environments. A focused special breeding program considering traits like drought tolerance, short duration, extensive root growth, deeper root system, good branching, dwarf plants with less but erect leaves, moderate tillering, resistance to pests and diseases, and efficient photosynthetic system might increase yield with resilience in the rainfed Mediterranean region (Farooq et al., 2009). In dry Mediterranean environments, genotypes characterized by yield traits such as long coleoptile length (benefits under deep seeding conditions and early ground cover; Spielmeyer et al., 2007), long grain-filling period, high tillering, and heat and water stress tolerance could be useful traits to guarantee good yield (Mwadzingeni et al., 2016). A few genotypes consistently produced higher yields under both rainfed and irrigated systems (Table 8); however, the interannual variation in rainfall and temperature altered genotype performance under the rainfed system. In this study, supplementary irrigation improved the biomass (+35%), HI (+11%), spike density (+19%), grains per spike (+16%), TKW (+16%), field-WUE (+16%), and crop-WUE (+40%) (Table 4), where 28–166 mm of supplemental irrigation was applied (depending on rainfall amounts) (Table 1). Even with late planting conditions, irrigation helped to improve yield attributes, mostly by providing soil moisture and reducing canopy temperature (Amani et al., 1996). The experimental results are supported by the results of machine learning, where in both irrigated and rainfed systems, the magnitude of the effect of different climates (rainfall and temperature) followed by management (seeding time, genotype, and irrigation) were the major determinants of yield, yield attributes, and WUEs. The random forest model result (Fig. 5, Fig. 6) showed total rainfall was the most important factor explaining variation in rainfed wheat yield, followed by the temperature at flowering, mid- and early-season rainfall, and genotype in order of importance. For yield and major yield attributes, seasonal rainfall remained the most important factor explaining variation in grain yield followed by early-season rainfall, days to flowering, temperature at flowering, irrigation amount, seeding time, and genotype in irrigated durum wheat. The early season rainfall remained a major factor determining total biomass production and spike density in wheat production. In a mixed crop-livestock system, biomass production is equally important as grain yield, hence it is important to consider genotype and management practices that help to improve grain yield and biomass production in rainfed drylands. Similarly, with supplemental irrigation, the amount of rainfall, days to flowering and temperature during flowering were observed as important factors determining grain yield, field-WUE, spike density, grains per spike, and TKW. This showed that varieties with a longer vegetative growing period, heat and drought tolerant character are important for improving crop productivity and quality of durum wheat in Mediterranean drylands in Morocco. 'Dry soils are as hungry as they are thirsty’, hence fertilizer management is also an important factor to improve productivity and WUE with resilience (Bouabid et al., 2020). Under the condition of low moisture, many nutrient elements are less mobile even if available in the soil and the management varies based on the soil moisture, site, and year (climate) (Savin et al., 2022). However, this study lacks an interaction of fertilizer management with seeding time, water management and genotype, therefore further study is suggested to understand the contribution of fertilizer management and its interactions for improving wheat productivity in such climatic conditions. 5. Conclusions Crop production in the rainfed drylands of Morocco is constrained by inadequate and often erratic rainfall, variable temperature, and the lack of context-specific management practices. This study aimed to understand major factors determining wheat yield and water use efficiency; and how wheat genotypes can be combined with agronomic management such as seeding time and water management for improving crop yield and water use efficiency in the Mediterranean climate of Morocco. Water management (rainfall amount) was a major yield-determining factor in rainfed drylands, advancing seeding time coupled with suitable genotype reduced water-limited yield gaps. In the context of declining water availability, precision use of available water helps to increase the area under supplemental irrigation for improving the productivity and resilience of wheat production in the Mediterranean climate in Morocco. The significant year × seeding time, year × water management, year × genotype, and year × genotype × seeding time interactions clearly indicated that a single and static solution does not work in drylands, and requires dynamic climate prediction, climate-smart technology adoption, and policy support. Advancing the seeding time improves crop yield and water use efficiency as it better utilizes the season’s rainfall. Better choice of resilient varieties, efficient use of available water through the application of supplemental irrigation, and adjustment of sowing time are among the key factors with the potential to combat adverse production conditions. Hence, the genotype with drought- and heat-stress tolerant traits coupled with the site- and soil-specific customized bundled agronomic solutions are needed to improve the resilience and sustainability of wheat production in the Mediterranean rainfed drylands of Morocco and similar production environment in the MENA region. CRediT authorship contribution statement Mina Devkota: Conceptualization, Data curation, Formal analysis, Methodology, Software, Supervision, Validation, Visualization, Writing - original draft, Writing - review & editing. Krishna Devkota: Conceptualization, Data curation, Formal analysis, Methodology, Software, Validation, Visualization, Writing - original draft, Writing - review & editing. Mohammed Karrou: Conceptualization, Methodology, Writing - review & editing. Vinay Nangia: Methodology, Resources, Writing - review & editing. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgements This work was supported by the CGIAR Program on Wheat - CRP WHEAT and CGIAR Initiative on Fragility to Resilience in Central and West Asia and North Africa (F2R-CWANA, ICARDA agreement number 200289) and Excellence in Agronomy (EiA). Appendix A. Supplementary material Download : Download Word document (15KB) Supplementary material . Data Availability Data will be made available on request. References Ababaei and Chenu, 2020 B. Ababaei, K. Chenu Heat shocks increasingly impede grain filling but have little effect on grain setting across the Australian wheatbelt Agric. For. Meteorol., 284 (2020), Article 107889, 10.1016/j.agrformet.2019.107889 View PDFView articleView in ScopusGoogle Scholar Alemu et al., 2021 A. Alemu, A. El Baouchi, S. El Hanafi, Z. Kehel, K. Eddakhir, W. Tadesse Genetic analysis of grain protein content and dough quality traits in elite spring bread wheat (Triticum aestivum) lines through association study J. Cereal Sci., 100 (2021), Article 103214, 10.1016/j.jcs.2021.103214 View PDFView articleView in ScopusGoogle Scholar Alghabari et al., 2014 F. Alghabari, M. Lukac, H.E. Jones, M.J. Gooding Effect of Rht alleles on the tolerance of wheat grain set to high temperature and drought stress during booting and anthesis J. Agron. Crop Sci., 200 (2014), pp. 36-45, 10.1111/jac.12038 View in ScopusGoogle Scholar Amani et al., 1996 I. Amani, R.A. Fischer, M.P. Reynolds Canopy temperature depression association with yield of irrigated spring wheat cultivars in a hot climate J. Agron. Crop Sci., 176 (1996), pp. 119-129 View in ScopusGoogle Scholar Balaghi et al., 2008 R. Balaghi, B. Tychon, H. Eerens, M. Jlibene Empirical regression models using NDVI, rainfall and temperature data for the early prediction of wheat grain yields in Morocco Int. J. Appl. Earth Obs. Geoinf., 10 (2008), pp. 438-452, 10.1016/j.jag.2006.12.001 View PDFView articleView in ScopusGoogle Scholar Bänziger and Cooper, 2001 M. Bänziger, M. Cooper Breeding for low input conditions and consequences for participatory plant breeding examples from tropical maize and wheat Euphytica, 122 (2001), pp. 503-519 View in ScopusGoogle Scholar Basford and Cooper, 1998 K.E. Basford, M. Cooper Genotype× environment interactions and some considerations of their implications for wheat breeding in Australia. This review is one of a series commissioned by the Advisory Committee of the Journal Aust. J. Agric. Res., 49 (1998), pp. 153-174 View in ScopusGoogle Scholar Bassu et al., 2009 S. Bassu, S. Asseng, R. Motzo, F. Giunta Optimising sowing date of durum wheat in a variable Mediterranean environment F. Crop. Res., 111 (2009), pp. 109-118, 10.1016/j.fcr.2008.11.002 View PDFView articleView in ScopusGoogle Scholar Bates et al., 2008 Bates, B., Kundzewicz, Z., Wu, S., 2008. Climate change and water. Intergovernmental Panel on Climate Change Secretariat. Google Scholar Bouabid et al., 2020 R. Bouabid, B. Soudi, M. Badraoui Nitrogen Dynamics and Management in Rainfed Drylands Issues and Challenges Soil and Fertilizers, CRC Press (2020), pp. 285-315 CrossRefGoogle Scholar Bouras et al., 2020 E.H. Bouras, L. Jarlan, S. Er-Raki, C. Albergel, B. Richard, R. Balaghi, S. Khabba Linkages between rainfed cereal production and agricultural drought through remote sensing indices and a land data assimilation system: a case study in Morocco Remote Sens, 12 (2020), pp. 1-35, 10.3390/rs12244018 View in ScopusGoogle Scholar Breiman, 2001 L. Breiman Random forests Mach. Learn, 45 (2001), pp. 5-32 Google Scholar Breiman and Cutler, 2012 L. Breiman, A. Cutler Breiman and Cutler’s random forests for classification and regression Packag. “randomForest” (2012), p. 29, 10.5244/C.22.54 Google Scholar Devkota and Yigezu, 2020 M. Devkota, Y.A. Yigezu Explaining yield and gross margin gaps for sustainable intensification of the wheat-based systems in a Mediterranean climate Agric. Syst., 185 (2020), Article 102946 View PDFView articleView in ScopusGoogle Scholar Devkota et al., 2022a M. Devkota, K.P. Devkota, S. Kumar Conservation agriculture improves agronomic, economic, and soil fertility indicators for a clay soil in a rainfed Mediterranean climate in Morocco Agric. Syst., 201 (2022), Article 103470, 10.1016/j.agsy.2022.103470 View PDFView articleView in ScopusGoogle Scholar Devkota et al., 2022b M. Devkota, Y. Singh, Y.A. Yigezu, I. Bashour, R. Mussadek, R. Mrabet Conservation Agriculture in the drylands of the Middle East and North Africa (MENA) region: past trend, current opportunities, challenges and future outlook Adv. Agron. (2022), p. 172 Google Scholar Dowla et al., 2018 M.A.U. Dowla, I. Edwards, G. O’Hara, S. Islam, W. Ma Developing wheat for improved yield and adaptation under a changing climate: optimization of a few key genes Engineering, 4 (2018), pp. 514-522 Google Scholar El Mourid and Karrou, 1996 M. El Mourid, M. Karrou Agriculture in arid and semi-arid regions of Morocco: challenges and prospects Al Awamia, 92 (1996), pp. 69-81 Google Scholar FAOSTAT, 2023 FAOSTAT, 2023. United Nations Food and Agricultural Organisation. 〈https://www.fao.org/faostat/en/#compare〉. Last accessed: 22 March 2023. Google Scholar Farooq et al., 2009 M. Farooq, A. Wahid, N. Kobayashi, D. Fujita, S.M.A. Basra Plant drought stress: effects, mechanisms and management Sustain. Agric. (2009), pp. 153-188 CrossRefGoogle Scholar Farooq et al., 2011 M. Farooq, H. Bramley, J.A. Palta, K.H.M. Siddique Heat stress in wheat during reproductive and grain-filling phases CRC. Crit. Rev. Plant Sci, 30 (2011), pp. 491-507, 10.1080/07352689.2011.615687 View in ScopusGoogle Scholar Ferrise et al., 2010 R. Ferrise, A. Triossi, P. Stratonovitch, M. Bindi, P. Martre Sowing date and nitrogen fertilisation effects on dry matter and nitrogen dynamics for durum wheat: an experimental and simulation study F. Crop. Res., 117 (2010), pp. 245-257, 10.1016/j.fcr.2010.03.010 View PDFView articleView in ScopusGoogle Scholar Giunta et al., 1993 F. Giunta, R. Motzo, M. Deidda Effect of drought on yield and yield components of durum wheat and triticale in a Mediterranean environment F. Crop. Res., 33 (1993), pp. 399-409, 10.1016/0378-4290(93)90161-F View PDFView articleView in ScopusGoogle Scholar Heng et al., 2007 L.K. Heng, S. Asseng, K. Mejahed, M. Rusan Optimizing wheat productivity in two rain-fed environments of the West Asia-North Africa region using a simulation model Eur. J. Agron., 26 (2007), pp. 121-129, 10.1016/j.eja.2006.09.001 View PDFView articleView in ScopusGoogle Scholar Karrou, 2013 M. Karrou Combined effect of tillage system, supplemental irrigation and genotype on bread wheat yield and water use in the dry Mediterranean region Afr. J. Agric. Res, 8 (2013), pp. 5398-5404, 10.5897/AJAR2013.7741 Google Scholar Karrou and Oweis, 2012 M. Karrou, T. Oweis Water and land productivities of wheat and food legumes with deficit supplemental irrigation in a Mediterranean environment Agric. Water Manag., 107 (2012), pp. 94-103, 10.1016/j.agwat.2012.01.014 View PDFView articleView in ScopusGoogle Scholar Kassam et al., 2012 A. Kassam, T. Friedrich, R. Derpsch, R. Lahmar, R. Mrabet, G. Basch, E.J. González-Sánchez, R. Serraj Conservation agriculture in the dry Mediterranean climate F. Crop. Res., 132 (2012), pp. 7-17, 10.1016/j.fcr.2012.02.023 View PDFView articleView in ScopusGoogle Scholar Kheir et al., 2021 A.M.S. Kheir, A.A. Alrajhi, A.M. Ghoneim, E.F. Ali, A. Magrashi, M.G. Zoghdan, S.A.M. Abdelkhalik, A.E. Fahmy, A. Elnashar Modeling deficit irrigation-based evapotranspiration optimizes wheat yield and water productivity in arid regions Agric. Water Manag., 256 (2021), Article 107122, 10.1016/j.agwat.2021.107122 View PDFView articleView in ScopusGoogle Scholar Lange, 2020 M.A. Lange Climate change in the Mediterranean: environmental impacts and extreme events IEMed Mediterr. Yearb. (2020), pp. 30-45 View in ScopusGoogle Scholar Latiri et al., 2010 K. Latiri, J.P. Lhomme, M. Annabi, T.L. Setter Wheat production in Tunisia: progress, inter-annual variability and relation to rainfall Eur. J. Agron., 33 (2010), pp. 33-42, 10.1016/j.eja.2010.02.004 View PDFView articleView in ScopusGoogle Scholar Mrabet et al., 2012 R. Mrabet, R. Moussadek, A. Fadlaoui, E. Van Ranst Conservation agriculture in dry areas of Morocco F. Crop. Res, 132 (2012), pp. 84-94 View PDFView articleView in ScopusGoogle Scholar Mwadzingeni et al., 2016 L. Mwadzingeni, H. Shimelis, E. Dube, M.D. Laing, T.J. Tsilo Breeding wheat for drought tolerance: progress and technologies J. Integr. Agric., 15 (2016), pp. 935-943, 10.1016/S2095-3119(15)61102-9 View PDFView articleView in ScopusGoogle Scholar Nicholson et al., 2018 S.E. Nicholson, C. Funk, A.H. Fink Rainfall over the African continent from the 19th through the 21st century Glob. Planet. Change, 165 (2018), pp. 114-127 View PDFView articleView in ScopusGoogle Scholar Ojeda et al., 2021 J.J. Ojeda, E.E. Rezaei, B. Kamali, J. McPhee, H. Meinke, S. Siebert, M.A. Webb, I. Ara, F. Mulcahy, F. Ewert Impact of crop management and environment on the spatio-temporal variance of potato yield at regional scale F. Crop. Res., 270 (2021), Article 108213, 10.1016/j.fcr.2021.108213 View PDFView articleView in ScopusGoogle Scholar Ojeda et al., 2022 J.J. Ojeda, G. Hammer, K.W. Yang, M.R. Tuinstra, P. deVoil, G. McLean, I. Huber, J.J. Volenec, S.M. Brouder, S. Archontoulis, S.C. Chapman Quantifying the effects of varietal types × management on the spatial variability of sorghum biomass across US environments GCB Bioenergy, 14 (2022), pp. 411-433, 10.1111/gcbb.12919 View in ScopusGoogle Scholar Padovan et al., 2020 G. Padovan, P. Martre, M.A. Semenov, A. Masoni, S. Bregaglio, D. Ventrella, I.J. Lorite, C. Santos, M. Bindi, R. Ferrise, C. Dibari Understanding effects of genotype × environment × sowing window interactions for durum wheat in the Mediterranean basin F. Crop. Res., 259 (2020), Article 107969, 10.1016/j.fcr.2020.107969 View PDFView articleView in ScopusGoogle Scholar Pala et al., 2011 M. Pala, T. Oweis, B. Benli, E. De Pauw, M. El Mourid, M. Karrou, M. Jamal, N. Zencirci Assessment of wheat yield gap in the Mediterranean: case studies from Morocco, Syria and Turkey Int. Cent. Agric. Res. Dry. Areas (ICARDA) (2011), pp. 921-963 Aleppo, Syria Google Scholar Piggin et al., 2015 C. Piggin, A. Haddad, Y. Khalil, S. Loss, M. Pala Effects of tillage and time of sowing on bread wheat, chickpea, barley and lentil grown in rotation in rainfed systems in Syria F. Crop. Res., 173 (2015), pp. 57-67 View PDFView articleView in ScopusGoogle Scholar Reynolds et al., 1999 M.P. Reynolds, S. Rajaram, K.D. Sayre Physiological and genetic changes of irrigated wheat in the post–green revolution period and approaches for meeting projected global demand Crop Sci., 39 (1999), pp. 1611-1621 CrossRefView in ScopusGoogle Scholar Rezzouk et al., 2022 F.Z. Rezzouk, A. Gracia-Romero, S.C. Kefauver, M.T. Nieto-Taladriz, M.D. Serret, J.L. Araus Durum wheat ideotypes in Mediterranean environments differing in water and temperature conditions Agric. Water Manag. (2022), p. 259, 10.1016/j.agwat.2021.107257 Google Scholar Sadras and Podems, 2020 Sadras, V., Podems, D., 2020. CGIAR Research Program 2020 Reviews: WHEAT. Google Scholar Savin et al., 2022 R. Savin, C.M. Cossani, R. Dahan, J.Y. Ayad, R. Albrizio, M. Todorovic, M. Karrou, G.A. Slafer Intensifying cereal management in dryland Mediterranean agriculture: rainfed wheat and barley responses to nitrogen fertilisation Eur. J. Agron. (2022), p. 137, 10.1016/j.eja.2022.126518 Google Scholar Schilling et al., 2012 J. Schilling, K.P. Freier, E. Hertig, J. Scheffran Climate change, vulnerability and adaptation in North Africa with focus on Morocco Agric. Ecosyst. Environ., 156 (2012), pp. 12-26, 10.1016/j.agee.2012.04.021 View PDFView articleView in ScopusGoogle Scholar Shen et al., 2021 H. Shen, K. Jiang, W. Sun, Y. Xu, X. Ma Irrigation decision method for winter wheat growth period in a supplementary irrigation area based on a support vector machine algorithm Comput. Electron. Agric., 182 (2021), Article 106032, 10.1016/j.compag.2021.106032 View PDFView articleView in ScopusGoogle Scholar Spielmeyer et al., 2007 W. Spielmeyer, J. Hyles, P. Joaquim, F. Azanza, D. Bonnett, M.E. Ellis, C. Moore, R.A. Richards A QTL on chromosome 6A in bread wheat (Triticum aestivum) is associated with longer coleoptiles, greater seedling vigour and final plant height Theor. Appl. Genet., 115 (2007), pp. 59-66 CrossRefView in ScopusGoogle Scholar Tapley et al., 2013 M. Tapley, B.V. Ortiz, E. Van Santen, K.S. Balkcom, P. Mask, D.B. Weaver Location, seeding date, and variety interactions on winter wheat yield in southeastern United States Agron. J., 105 (2013), pp. 509-518, 10.2134/agronj2012.0379 View in ScopusGoogle Scholar Toumi et al., 2016 J. Toumi, S. Er-Raki, J. Ezzahar, S. Khabba, L. Jarlan, A. Chehbouni Performance assessment of AquaCrop model for estimating evapotranspiration, soil water content and grain yield of winter wheat in Tensift Al Haouz (Morocco): application to irrigation management Agric. Water Manag., 163 (2016), pp. 219-235 View PDFView articleView in ScopusGoogle Scholar Van Ittersum et al., 2013 M.K. Van Ittersum, K.G. Cassman, P. Grassini, J. Wolf, P. Tittonell, Z. Hochman Yield gap analysis with local to global relevance-a review F. Crop. Res., 143 (2013), pp. 4-17 View PDFView articleView in ScopusGoogle Scholar Wang et al., 2015 X.Y. Wang, X.G. Yang, S. Sun, W.J. Xie Comparison of potential yield and resource utilization efficiency of main food crops in three provinces of Northeast China under climate change Ying Yong Sheng tai xue bao= J. Appl. Ecol., 26 (2015), pp. 3091-3102 View in ScopusGoogle Scholar World Bank, 2021 World Bank. 2021. Climate Risk Profile: Morocco. 〈https://climateknowledgeportal.worldbank.org/sites/default/files/2021–09/15725-WB_Morocco%20Country%20Profile-WEB.pdf〉. Google Scholar Xynias et al., 2020 I.N. Xynias, I. Mylonas, E.G. Korpetis, E. Ninou, A. Tsaballa, I.D. Avdikos, A.G. Mavromatis Durum wheat breeding in the Mediterranean region: current status and future prospects Agronomy, 10 (2020), p. 432 CrossRefView in ScopusGoogle Scholar Yang et al., 2021 W. Yang, W. Liu, Y. Li, S. Wang, L. Yin, X. Deng Increasing rainfed wheat yield by optimizing agronomic practices to consume more subsoil water in the Loess Plateau Crop J., 9 (2021), pp. 1418-1427, 10.1016/j.cj.2021.01.006 View PDFView articleView in ScopusGoogle Scholar Yu et al., 2021 L. Yu, X. Zhao, X. Gao, R. Jia, M. Yang, X. Yang, Y. Wu, K.H.M. Siddique Effect of natural factors and management practices on agricultural water use efficiency under drought: a meta-analysis of global drylands J. Hydrol., 594 (2021), Article 125977 View PDFView articleView in ScopusGoogle Scholar Cited by (2) Green fabricated silver nanoparticles as a new eco-friendly insecticide for controlling stored cowpea bug Callosobruchus maculatus (Coleoptera: Bruchidae) 2024, Biocatalysis and Agricultural Biotechnology Show abstract Genotype × environment × agronomic management interaction to enhance wheat yield in the Mediterranean rainfed environments of Morocco: II. Process based modeling 2023, European Journal of Agronomy Show abstract © 2023 The Authors. Published by Elsevier B.V. Recommended articles Nitrogen leaching under alternative forages grazed by sheep European Journal of Agronomy, Volume 151, 2023, Article 126991 Sarmini Maheswaran, …, Peter D. Kemp View PDF Improved yield-salinity relationship considering salt and root distribution dynamics European Journal of Agronomy, Volume 151, 2023, Article 127003 Yuehong Zhang, …, Qi Hu View PDF Monitoring defoliation rate and boll-opening rate of machine-harvested cotton based on UAV RGB images European Journal of Agronomy, Volume 151, 2023, Article 126976 Yiru Ma, …, Ze Zhang View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 2 Captures Readers: 5 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply."

</subsection_point_Point 8>

<previous_sections>

A systematic review of automated systems for real-time irrigation management

1. INTRODUCTION
The challenge of feeding a growing population with finite resources is becoming increasingly pressing. By 2050, the world population is expected to reach 9.7 billion, necessitating a 70% increase in food production (Falkenmark and Rockstrom, 2009). Irrigation plays a crucial role in enhancing crop yields and agricultural productivity to meet this growing demand. Studies have shown that irrigation can significantly increase crop water productivity, contributing to increased food production (Ali and Talukder, 2008; Playan and Mateos, 2005). However, water scarcity poses a significant challenge, with many regions facing water deficits and the need for improved water management practices (Falkenmark and Rockstrom, 2009). Optimizing irrigation schedules and doses based on crop requirements and environmental conditions is essential for maximizing yield and quality while minimizing water use (Zhang et al., 2024). The necessity of scalable water-efficient practices for increasing food demand cannot be overstated. Techniques such as regulated deficit irrigation, magnetically treated water, and the use of drought-tolerant crops like sorghum have shown promise in improving water productivity and ensuring food security (Mehmood et al., 2023; Putti et al., 2023; Hadebe et al., 2016). As the global food challenge intensifies, it is imperative to critically evaluate the current state and future potential of irrigation management systems to guide research, innovation, and implementation efforts towards fully autonomous, scalable solutions.

Despite the importance of irrigation in addressing the global food challenge, traditional irrigation management techniques, such as manual scheduling and timer-based systems, have significant limitations. These methods are often labor-intensive, inefficient, and less adaptable to changing conditions (Savin et al., 2023). Manual and timer-based scheduling can lead to high operational costs and inefficient water use (Raghavendra, Han, and Shin, 2023). The reliance on manual intervention and predetermined schedules limits their adaptability to changing environmental conditions, crop water requirements, and soil moisture levels (Kaptein et al., 2019). Sensor-based irrigation systems offer an alternative, enabling real-time adjustments based on soil water status measurements (Kaptein et al., 2019). However, the adoption of these systems in commercial settings has been limited, often requiring extensive input from researchers (Kim et al., 2014; Lea-Cox et al., 2018; Ristvey et al., 2018). The limitations of traditional irrigation management techniques highlight the need for scalable, automated solutions for greater efficiency in irrigation management. Automated systems that collect real-time data, analyze it, and make autonomous irrigation decisions can lead to improved water use efficiency and increased crop productivity (Champness et al., 2023; Wu et al., 2022). To fully understand the potential of automated systems, it is necessary to examine the automation of each part of the irrigation management pipeline and analyze the effectiveness and efficiency of integrated end-to-end solutions.

The emergence of smart irrigation management and IoT marks a significant shift from historical irrigation practices. Modern approaches rely on vast data and analysis algorithms, leveraging technologies such as remote sensing, sensor networks, weather data, and computational algorithms (Atanasov, 2023; Bellvert et al., 2023; Kumar et al., 2023). IoT plays a vital role in collecting vast amounts of data through sensors, data transmission, and tailored networks, enabling real-time monitoring and control of irrigation systems (Liakos, 2023; Zuckerman et al., 2024). These advancements in data collection and analysis have the potential to revolutionize irrigation management, allowing for more precise and efficient water use. However, challenges such as processing diverse data sources, data integration, and lack of integrated data analysis hamper the full benefit of IoT in irrigation management (Dave et al., 2023). The current fragmented approach in smart irrigation, focusing on individual components rather than the entire system, limits the potential for fully autonomous, real-time end-to-end irrigation management (Togneri et al., 2021). To address these challenges and fully realize the potential of smart irrigation management, there is a need for automating and integrating each section of the irrigation management pipeline, from sensor/weather data collection and transmission to processing, analysis, decision-making, and automated action (McKinion and Lemmon, 1985). This integration requires a thorough investigation of the role of interoperability and standardization in enabling seamless communication and compatibility between components within the automated irrigation management pipeline.

Machine learning (ML) plays a significant role in processing vast data, predicting plant stress, modeling climate effects, and optimizing irrigation in smart irrigation management systems. ML algorithms can analyze data collected from sensors and weather stations to determine optimal irrigation schedules (Vianny et al., 2022). However, the potential of ML is often constrained by manual steps, such as data interpretation, decision-making on irrigation timing and volume, and system adjustments. Automating ML integration to allow direct action from insights to irrigation execution, removing bottlenecks and achieving real-time adaptability, is crucial for fully autonomous irrigation management (Barzallo-Bertot et al., 2022). By integrating ML into automated systems, the irrigation management pipeline can become more seamless and efficient, enabling real-time decision-making and action based on data-driven insights. To achieve this level of automation and integration, it is essential to identify gaps and propose solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.

To achieve seamless integration across the automated irrigation management system, interoperability and standardization are critical. Interoperability allows different system components, such as sensors, actuators, and software, to communicate and exchange data effectively, while standardization ensures that data is represented in a consistent format (Santos et al., 2020). Standardized protocols and data formats are essential for achieving seamless integration and ensuring compatibility between components in real-time irrigation management systems (Robles et al., 2022; Hatzivasilis et al., 2018). Existing and emerging standards, such as OGC SensorThings API and ISO 11783, have applicability to real-time irrigation management systems (Hazra et al., 2021). However, challenges such as data quality, scalability, reliability, and security need to be addressed to fully realize the potential of interoperability and standardization in automated irrigation management systems (Hazra et al., 2021). Addressing these challenges is crucial for enabling the seamless integration of components within the automated irrigation management pipeline, which is essential for achieving fully autonomous, scalable irrigation management. A comprehensive evaluation of the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline is necessary to guide future research and implementation efforts.
The primary objective of this systematic review is to critically evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies for enhancing agricultural water use efficiency and crop productivity.
Specific objectives include:
•	Examining the automation of each part of the irrigation management pipeline and the seamless integration of each section in the context of irrigation scheduling and management.
•	Analyzing the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
•	Investigating the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.
•	Identifying gaps and proposing solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.
By addressing these objectives, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.

2. REVIEW METHODOLOGY
•	Question-driven framework to guide the literature review of real-time, autonomous irrigation management systems
•	Key research questions posed, each with the motivation behind investigating them and a starting hypothesis to evaluate against the examined literature
•	Table presenting the major objectives, specific objectives, questions, motivations, and hypotheses
3. DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING
3.1. Irrigation management data
The success of automated irrigation management systems relies heavily on the collection, transmission, and analysis of various types of data. The most applicable data types for irrigation management include soil moisture, canopy temperature, weather data, and plant physiological parameters (Farooq et al., 2019; Li et al., 2019; Olivier et al., 2021; Evett et al., 2020). These data are typically collected from a range of sources, including in-field sensors, remote sensing platforms, weather stations, and manual measurements (Li et al., 2019; Karimi et al., 2018).
Soil moisture data is arguably the most critical type of data for irrigation management, as it directly reflects the water available to plants and can be used to determine the optimal timing and amount of irrigation (Olivier et al., 2021; Intrigliolo & Castel, 2006). Soil moisture sensors, such as tensiometers, capacitance probes, and time-domain reflectometry (TDR) sensors, can provide real-time measurements of soil water content at various depths (Farooq et al., 2019). These sensors can be deployed in a network configuration to capture spatial variability in soil moisture across a field (Karimi et al., 2018).
Canopy temperature data is another valuable type of data for irrigation management, as it can be used to assess plant water stress and adjust irrigation accordingly (Evett et al., 2020). Infrared thermometers and thermal cameras can be used to measure canopy temperature, which is influenced by factors such as air temperature, humidity, wind speed, and plant water status (Li et al., 2019). When plants experience water stress, they tend to close their stomata to reduce water loss, leading to an increase in canopy temperature (Evett et al., 2020). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
Weather data, including temperature, humidity, precipitation, wind speed, and solar radiation, are essential for predicting crop water requirements and scheduling irrigation events (Akilan & Baalamurugan, 2024). Weather stations equipped with various sensors can provide real-time measurements of these parameters, which can be used as inputs for crop water requirement models, such as the FAO-56 Penman-Monteith equation (Li et al., 2019). These models estimate crop evapotranspiration (ET) based on weather data and crop-specific coefficients, allowing for the calculation of irrigation requirements (Intrigliolo & Castel, 2006). By integrating weather data into automated irrigation systems, irrigation schedules can be dynamically adjusted based on changing environmental conditions, ensuring that crops receive the optimal amount of water at the right time (Akilan & Baalamurugan, 2024).
When collecting and utilizing these data types, several considerations must be taken into account, including the volume, frequency, format, and source of the data (Farooq et al., 2019). The volume of data generated by automated irrigation systems can be substantial, especially when high-resolution sensors are deployed at a large scale (Bastidas Pacheco et al., 2022). This necessitates the use of efficient data storage, processing, and transmission technologies to handle the data load (Farooq et al., 2019). The frequency of data collection is another important consideration, as it directly impacts the temporal resolution of the data and the ability to detect rapid changes in plant water status or environmental conditions (Bastidas Pacheco et al., 2022). Bastidas Pacheco et al. (2022) demonstrated that collecting full pulse resolution data from water meters provides more accurate estimates of event occurrence, timing, and features compared to aggregated temporal resolutions, highlighting the importance of selecting appropriate data collection frequencies to ensure the quality and usefulness of the data for irrigation management.
The format of the data is also crucial, as it determines the compatibility and interoperability of the data with various analysis tools and platforms (Farooq et al., 2019). Standardized data formats, such as JSON, XML, or CSV, can facilitate data exchange and integration between different components of the automated irrigation system (Zhang et al., 2023). The source of the data is another important consideration, as it can impact the reliability, accuracy, and spatial coverage of the data (Farooq et al., 2019). For example, in-field sensors provide highly localized measurements, while remote sensing platforms, such as satellites or drones, can provide data at larger spatial scales (Li et al., 2019). By combining data from multiple sources, automated irrigation systems can achieve a more comprehensive understanding of crop water requirements and optimize irrigation management accordingly (Farooq et al., 2019).
Data quality, accuracy, and reliability are paramount in irrigation management, as they directly impact the effectiveness of decision-making processes and the efficiency of water use (Gupta et al., 2020). Inaccurate or unreliable data can lead to suboptimal irrigation decisions, resulting in crop stress, yield losses, or wasted water resources (Ramli & Jabbar, 2022). Gupta et al. (2020) emphasized the critical importance of data security and privacy in smart farming systems, as the leakage of sensitive agricultural data can cause severe economic losses to farmers and compromise the integrity of the automated irrigation system. The authors also highlighted the need for robust authentication and secure communication protocols to prevent unauthorized access to smart farming systems and protect data in transit (Gupta et al., 2020).
Ramli and Jabbar (2022) addressed the challenges associated with implementing real-time, automated irrigation systems, including data quality, scalability, reliability, and security. They proposed solutions and best practices based on the analysis of case studies and real-world implementations, such as the use of redundant sensors, data validation techniques, and secure communication protocols (Ramli & Jabbar, 2022). The authors also emphasized the importance of regular maintenance and calibration of sensors to ensure the accuracy and reliability of the collected data (Ramli & Jabbar, 2022).
Researchers have investigated the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in automated irrigation systems (Karim et al., 2023; Rady et al., 2020; Cui, 2023). Karim et al. (2023) explored the effectiveness of various data compression techniques, such as lossless and lossy compression algorithms, in reducing the size of data packets transmitted over wireless networks. The authors found that lossless compression techniques, such as Huffman coding and Lempel-Ziv-Welch (LZW), can significantly reduce data size without compromising data quality, while lossy compression techniques, such as JPEG and MP3, can further reduce data size by introducing acceptable levels of distortion (Karim et al., 2023).
Rady et al. (2020) developed a novel data compression algorithm specifically designed for irrigation data, which achieved significant compression ratios without compromising data quality. The authors demonstrated that their algorithm could reduce the amount of data transmitted over wireless networks, thereby improving the efficiency of the irrigation system and reducing costs (Rady et al., 2020). Cui (2023) investigated the use of data aggregation and filtering techniques to reduce the number of transmissions and save bandwidth in automated irrigation systems. The author proposed a data aggregation scheme that combines multiple sensor readings into a single value, such as the average soil moisture over a specified time interval, to reduce the frequency of data transmissions (Cui, 2023). Additionally, the author explored the use of data filtering techniques, such as Kalman filters and particle filters, to remove noise and outliers from sensor data, improving the accuracy and reliability of the transmitted information (Cui, 2023).
Data standardization and harmonization are crucial for facilitating seamless integration and interoperability between the various components of automated irrigation management systems (Zhang et al., 2023; Ermoliev et al., 2022). Zhang et al. (2023) developed a novel cyberinformatics technology called iCrop, which enables the in-season monitoring of crop-specific land cover across the contiguous United States. The authors highlighted the importance of data standardization and harmonization in the context of iCrop, as it allows for the efficient distribution of crop-specific land cover information based on the findable, accessible, interoperable, and reusable (FAIR) data principle (Zhang et al., 2023). By adopting standardized data formats and protocols, such as the Open Geospatial Consortium (OGC) standards, iCrop enables the seamless integration of various data sources and facilitates the interoperability of the system with other agricultural decision support tools (Zhang et al., 2023).
Ermoliev et al. (2022) proposed a linkage methodology for linking distributed sectoral/regional optimization models in a situation where private information is not available or cannot be shared by modeling teams. The authors emphasized the need for data standardization to enable decentralized cross-sectoral coordination and analysis, as it allows for the consistent representation and exchange of data between different models and stakeholders (Ermoliev et al., 2022). By adopting standardized data formats and interfaces, the proposed linkage methodology can facilitate the integration of various optimization models and support the development of comprehensive decision support systems for sustainable resource management (Ermoliev et al., 2022).
Metadata plays a vital role in providing context and enabling better data interpretation and decision-making in automated irrigation management systems (Jahanddideh-Tehrani et al., 2021). Metadata refers to the additional information that describes the characteristics, quality, and context of the primary data, such as the sensor type, calibration parameters, measurement units, and timestamp (Jahanddideh-Tehrani et al., 2021). Jahanddideh-Tehrani et al. (2021) highlighted the importance of metadata in water resources management, as it enables decision-makers to use the data to the best of its capabilities by understanding factors such as when water data was collected and what factors might have contributed to the measurements. The authors emphasized the need for standardized metadata formats and guidelines, such as the Dublin Core Metadata Initiative (DCMI) and the ISO 19115 standard, to ensure the consistency and interoperability of metadata across different water information systems (Jahanddideh-Tehrani et al., 2021).
In the context of automated irrigation management systems, metadata can provide valuable information about the data collection process, sensor performance, and environmental conditions that can aid in data interpretation and decision-making (Cota & Mamede, 2023). For example, metadata about the sensor type and calibration parameters can help assess the accuracy and reliability of the collected data, while metadata about the weather conditions and soil properties can provide context for interpreting the data and adjusting irrigation strategies accordingly (Cota & Mamede, 2023). By incorporating metadata into the data management and analysis pipeline of automated irrigation systems, decision-makers can make more informed and context-aware decisions, leading to improved water use efficiency and crop productivity (Jahanddideh-Tehrani et al., 2021).

3.2. Edge Computing and Fog Computing
Edge computing and fog computing have emerged as transformative technologies in the realm of real-time irrigation management systems, offering significant potential for improving efficiency, scalability, and reliability (Abdel Nasser et al., 2020; Tran et al., 2019). Edge computing refers to the practice of processing data near the edge of the network, close to the source of the data, while fog computing is a decentralized computing infrastructure that extends cloud computing capabilities to the network edge (Hassija et al., 2019). These technologies bring computation and analytics closer to the data source, reducing the need for data to travel to the cloud and enabling faster processing and decision-making (Hassija et al., 2019; Zhang et al., 2020).
The potential of edge computing and fog computing in real-time irrigation management is immense. Abdel Nasser et al. (2020) proposed a two-layer system for water demand prediction using automated meters and machine learning techniques, demonstrating the potential of edge computing in improving the efficiency and scalability of irrigation management. The system collects and aggregates data from distributed smart meters in the first layer, while the second layer uses LSTM neural networks to predict water demand for different regions of households. By leveraging edge computing, the system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management (Abdel Nasser et al., 2020).
Tran et al. (2019) conducted a comprehensive review of real-time, end-to-end automated irrigation management systems, highlighting the role of fog computing in addressing data transmission challenges and enabling seamless integration across the irrigation management pipeline. The authors emphasize that real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs. However, they also identify several challenges that need to be addressed, such as data quality, scalability, reliability, and security, which can be effectively tackled by implementing fog computing architectures (Tran et al., 2019).
Edge computing offers several benefits in real-time irrigation management systems, including reduced latency, real-time decision-making, and reduced reliance on cloud connectivity (Mishra, 2020; Zhang et al., 2020). By processing data closer to the source, edge computing enables faster response times and more efficient data handling (Mishra, 2020). Mishra (2020) highlights that edge computing reduces latency by processing data closer to the source, enabling real-time decision-making and lessening reliance on cloud connectivity by shifting processing to local or edge devices.
Zhang et al. (2020) explore the application of edge computing in agricultural settings, demonstrating its potential to improve the efficiency and accuracy of irrigation systems. The authors discuss how edge computing has prospects in various agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. They also emphasize that the emergence of edge computing models, such as fog computing, cloudlet, and mobile edge computing, has transformed the management and operation of farms (Zhang et al., 2020).
Fog computing plays a crucial role in distributing processing and storage across the network, enhancing the scalability and reliability of automated irrigation systems (Premkumar & Sigappi, 2022; Singh et al., 2022). Premkumar and Sigappi (2022) evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation. Their study emphasizes the potential of fog computing in distributing processing and storage across the network, improving the efficiency and scalability of irrigation systems. The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture, demonstrating the effectiveness of fog computing in enhancing the performance of automated irrigation systems (Premkumar & Sigappi, 2022).
Singh et al. (2022) discuss the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability in agricultural management systems. The authors argue that by implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness. They also highlight that fog computing can address the challenges faced by real-time data transmission in agricultural management systems, such as latency, bandwidth limitations, and data security (Singh et al., 2022).
The integration of edge and fog computing in real-time irrigation management systems is crucial for achieving fully automated, scalable, and reliable solutions. As the demand for autonomous irrigation management grows, these technologies will play a pivotal role in enabling faster decision-making, reduced latency, improved resource utilization, and seamless integration across the irrigation management pipeline (Tran et al., 2019; Zhang et al., 2020). By bringing computation and analytics closer to the data source and distributing processing and storage across the network, edge and fog computing can significantly enhance the efficiency and effectiveness of automated irrigation systems, contributing to the overall goal of addressing the global food challenge through optimized water resource management and increased agricultural productivity (Abdel Nasser et al., 2020; Premkumar & Sigappi, 2022; Singh et al., 2022).

3.3. Automation of Data Collection
The automation of data collection is a critical component in the development of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. It enables the efficient gathering of vital information about crop health, environmental conditions, and water requirements, which is essential for enhancing agricultural water use efficiency and crop productivity. Two key aspects of automated data collection are the use of advanced sensing technologies for non-invasive plant stress detection and the implementation of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.
Advanced sensing technologies, such as hyperspectral imaging and thermal sensing, have emerged as powerful tools for non-invasive plant stress detection in automated irrigation management systems. These technologies provide valuable information about crop traits, enabling early and accurate detection of plant health issues (Triantafyllou et al., 2019). Triantafyllou et al. (2019) propose a comprehensive reference architecture model that incorporates advanced sensing technologies in the sensor layer for real-time plant stress detection, highlighting their importance in providing non-invasive plant stress detection. Similarly, Hossain et al. (2023) present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that leverages advanced sensing technologies to optimize water use and improve crop yield, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
Hyperspectral imaging can capture subtle changes in plant physiology that are indicative of stress, while machine learning algorithms can be employed to extract meaningful patterns from the spectral data and classify different stress types (Araus et al., 2014). Thermal sensing can detect changes in canopy temperature, which is influenced by factors such as plant water status (Li et al., 2019). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
The integration of advanced sensing technologies in automated irrigation management systems has the potential to revolutionize precision agriculture. Jiang et al. (2019) demonstrate the effectiveness of a deep learning-based model in accurately detecting leaf spot diseases, highlighting the importance of image augmentation and deep learning algorithms in enhancing the model's performance.
Wireless sensor networks (WSNs) and energy-efficient communication protocols have the potential to significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. WSNs offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems, providing remote monitoring and automated control capabilities (Mehdizadeh et al., 2020). Nishiura and Yamamoto (2021) propose a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields, reducing operational costs and enhancing the efficiency of data collection. Similarly, Higashiura and Yamamoto (2021) introduce a network system that employs UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands, optimizing data collection and reducing travel distance and time.
Energy-efficient communication protocols are crucial for ensuring reliable data transmission in challenging environmental conditions and extending the lifespan of sensor nodes (Mehdizadeh et al., 2020). Al-Ali et al. (2023) investigate the potential of WSNs and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems, discussing the challenges and opportunities of using these technologies to improve the efficiency and reliability of real-time data collection in irrigation management. Mehdizadeh et al. (2020) emphasize the need for careful consideration of factors such as data accuracy, energy consumption, and network reliability when designing effective WSNs for irrigation management, enabling timely irrigation decisions and improved crop yields.
The automation of data collection through the use of advanced sensing technologies and wireless sensor networks is essential for achieving fully autonomous, scalable irrigation management. By enabling non-invasive plant stress detection and large-scale, long-term data collection, these technologies contribute to the overall goal of optimizing water resource management and increasing agricultural productivity. The integration of these technologies in real-time, end-to-end automated irrigation management systems has the potential to enhance agricultural water use efficiency and crop productivity, ultimately contributing to the development of fully autonomous, scalable irrigation management solutions.

3.4: Real-Time Data Transmission Protocols and Technologies
Real-time data transmission is a critical component of automated irrigation management systems, as it enables the timely delivery of sensor data to the cloud for processing and decision-making. The exploration of suitable protocols and network architectures is essential for ensuring efficient and reliable data transmission in these systems, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
The Message Queuing Telemetry Transport (MQTT) protocol has emerged as a popular choice for real-time data transmission in IoT networks, including those used for automated irrigation management. MQTT is a lightweight, publish-subscribe protocol designed for constrained devices and low-bandwidth networks (Author, 2019). Its simplicity and low overhead make it well-suited for IoT applications where data transmission speed and energy efficiency are critical (Saranyadevi et al., 2022). MQTT provides three Quality of Service (QoS) levels, ensuring data reliability in real-time scenarios (Author, 2019). Chen et al. (2020) proposed novel algorithms to improve data exchange efficiency and handle rerouting in MQTT-based IoT networks for automated irrigation management systems. Their TBRouting algorithm efficiently finds the shortest paths for data transmission, while the Rerouting algorithm effectively handles the rerouting of topic-based session flows when a broker crashes. The combination of these algorithms can significantly improve the performance and reliability of automated irrigation management systems (Chen et al., 2020).
Client-server IoT networks, such as those based on MQTT, play a crucial role in real-time data transmission for automated irrigation management systems. In these networks, sensors and devices (clients) publish data to a central broker (server), which then distributes the data to subscribed clients (Verma et al., 2021). This architecture enables efficient data collection, processing, and dissemination, facilitating the integration of various components within the automated irrigation management pipeline. Verma et al. (2021) proposed an architecture for healthcare monitoring systems using IoT and communication protocols, which provides a comprehensive overview of existing approaches and highlights challenges and opportunities in the field. Although focused on healthcare, the insights from this study can be applied to automated irrigation management systems, emphasizing the importance of interoperability and standardization for seamless integration (Verma et al., 2021).
In addition to MQTT, other application layer protocols such as XMPP, CoAP, SOAP, and HTTP have been explored for real-time data transmission in IoT networks. Each protocol has its strengths and weaknesses, making them suitable for different applications and scenarios. XMPP (Extensible Messaging and Presence Protocol) is an open-standard protocol that supports real-time messaging, presence, and request-response services (Saint-Andre, 2011). CoAP (Constrained Application Protocol) is a specialized web transfer protocol designed for use with constrained nodes and networks in the Internet of Things (Shelby et al., 2014). SOAP (Simple Object Access Protocol) is a protocol for exchanging structured information in the implementation of web services, while HTTP (Hypertext Transfer Protocol) is the foundation of data communication for the World Wide Web (Fielding et al., 1999).
Motamedi and Villányi (2022) compared and evaluated wireless communication protocols for the implementation of smart irrigation systems in greenhouses, considering factors such as power consumption, range, reliability, and scalability. They found that ZigBee is the most suitable local communication protocol for greenhouse irrigation due to its large number of nodes and long range, while MQTT is the recommended messaging protocol for smart irrigation systems due to its TCP transport protocol and quality of service (QoS) options. GSM is a reliable and cost-effective global communication protocol for greenhouse irrigation, providing wide coverage and low cost (Motamedi & Villányi, 2022).
Syafarinda et al. (2018) investigated the use of the MQTT protocol in a precision agriculture system using a Wireless Sensor Network (WSN). They found that MQTT is suitable for use in IoT applications due to its lightweight, simple, and low bandwidth requirements. The average data transmission speed using the MQTT protocol was approximately 1 second, demonstrating its effectiveness for real-time data transmission in precision agriculture systems (Syafarinda et al., 2018).
The choice of application layer protocol for real-time irrigation management depends on factors such as data transmission speed, reliability, and energy efficiency. MQTT and RTPS (Real-Time Publish-Subscribe) are both suitable for real-time data transmission in IoT systems, but they have different strengths and weaknesses. MQTT is a better choice for applications that require low latency and high throughput, while RTPS is a better choice for applications that require high reliability and low latency (Sanchez-Iborra & Skarmeta, 2021). The exploration of MQTT and client-server IoT networks, along with the comparison of various application layer protocols, provides valuable insights into the suitability of these technologies for real-time data transmission in automated irrigation management systems.
In summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.

3.5. Challenges and Solutions in Real-Time Data Transmission
Following the exploration of data collection, processing at the edge and fog, and automation in previous sections, we now turn to the critical aspect of real-time data transmission. While essential for automated irrigation management, this stage presents unique challenges that must be addressed to ensure system efficiency and reliability.
Obstacles in Real-Time Data Transmission
Agricultural environments present unique challenges for real-time data transmission, directly impacting the effectiveness of automated irrigation systems. Environmental factors can significantly disrupt wireless communication. Adverse weather conditions such as heavy rain, fog, and high winds can weaken or even block radio signals, leading to data loss and compromised system performance. Physical obstacles like trees, buildings, and uneven terrain further complicate signal propagation, creating reliability issues (Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). These environmental challenges necessitate robust communication protocols and network architectures that can ensure consistent and reliable data flow.
In addition to environmental factors, technical limitations also present significant obstacles. Large-scale agricultural operations often demand long-distance data transmission, which can be hindered by the limited range of certain wireless communication protocols. Network congestion, occurring when multiple sensors transmit data concurrently, can lead to delays and potential data loss, further complicating real-time decision-making (Hameed et al., 2020). To mitigate these issues, researchers have investigated the potential of cognitive radio networks (CRNs) and dynamic spectrum access (DSA) for optimizing spectrum utilization and reducing interference (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). CRNs enable devices to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency. DSA, on the other hand, facilitates the dynamic allocation of unused spectrum, enhancing spectrum utilization and reducing congestion.
Furthermore, data security and privacy are paramount concerns in real-time irrigation systems. The sensitive nature of agricultural data, such as crop yields and farm management practices, necessitates robust security measures to prevent unauthorized access and data breaches (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential to protect data integrity and ensure the trustworthiness of the system.
Investigating Data Optimization Techniques
To enhance the efficiency and reliability of real-time data transmission in automated irrigation systems, researchers have explored a range of data optimization techniques. Data compression techniques aim to reduce the size of data packets transmitted over the network, minimizing bandwidth requirements and improving transmission speed (Rady et al., 2020; Karim et al., 2023). Lossless compression algorithms, such as Huffman coding and LZW, preserve data integrity while effectively reducing data size, ensuring that no information is lost during transmission (Cui, 2023). Lossy compression algorithms, such as JPEG and MP3, offer higher compression ratios but introduce a controlled level of data loss, which may be acceptable for certain applications where some loss of precision is tolerable (Karim et al., 2023). The choice between lossless and lossy compression depends on the specific application and the trade-off between data size and accuracy.
Data aggregation techniques provide another effective approach to optimize data transmission. By aggregating multiple sensor readings into a single representative value, such as average soil moisture or temperature, the number of transmissions can be significantly reduced, conserving bandwidth and energy resources (Cui, 2023). This is particularly beneficial in large-scale irrigation systems where numerous sensors are deployed across vast areas, generating substantial amounts of data. Additionally, data filtering techniques play a crucial role in improving data quality and reliability. Kalman filters and particle filters can effectively remove noise and outliers from sensor data, ensuring that only accurate and relevant information is transmitted and used for decision-making (Cui, 2023). This is essential for preventing erroneous data from influencing irrigation decisions and potentially leading to suboptimal water management.
Sensor calibration, drift correction, and fault detection are essential for maintaining data accuracy and reliability (Dos Santos et al., 2023). Regular calibration ensures that sensors provide accurate measurements over time, while drift correction techniques account for gradual changes in sensor readings due to environmental factors or aging. Fault detection mechanisms can identify and address sensor malfunctions or anomalies, preventing erroneous data from influencing irrigation decisions and potentially harming crops or wasting water.
Addressing the Challenges
Effectively addressing the challenges in real-time data transmission requires a multifaceted approach that encompasses environmental, technical, and data-related considerations. Implementing robust and adaptive communication protocols is crucial for overcoming interference and signal degradation caused by weather conditions and physical obstacles. Selecting appropriate protocols, such as LoRa or ZigBee, with suitable range and penetration capabilities can ensure reliable data transmission in challenging agricultural environments (Motamedi & Villányi, 2022). Additionally, employing techniques like frequency hopping and error correction codes can further improve communication resilience and mitigate data loss.
Optimizing network architecture is another key consideration. Deploying a distributed network architecture with edge and fog computing capabilities can significantly enhance data processing and transmission efficiency (Abdel Nasser et al., 2020; Tran et al., 2019). Edge devices can perform initial data processing and aggregation tasks, reducing the amount of data transmitted to the cloud and minimizing latency, while fog nodes can provide additional processing power and storage closer to the data source, enhancing scalability and reliability. This distributed approach alleviates the burden on the central cloud server and allows for more responsive and efficient irrigation management.
Data optimization techniques play a vital role in reducing bandwidth requirements and improving transmission efficiency. The choice of data compression, aggregation, and filtering techniques should be tailored to the specific requirements of the irrigation system, considering factors such as data type, accuracy needs, and available bandwidth. By carefully selecting and implementing these techniques, the overall performance and effectiveness of real-time irrigation systems can be significantly enhanced, leading to more sustainable water management practices and improved agricultural productivity.
By addressing these challenges and implementing appropriate solutions, real-time data transmission can become a reliable and efficient component of automated irrigation systems, contributing to the overall goal of achieving sustainable and productive agriculture in the face of growing food demands and water scarcity.

3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
Real-time irrigation management systems heavily rely on the efficient and reliable transmission of data from sensors and weather stations to the cloud for processing and decision-making. However, agricultural environments present unique challenges to wireless communication, including adverse weather conditions, physical obstacles, and the limitations of wireless technologies. These challenges necessitate robust and adaptive solutions to ensure the consistent and timely flow of data, enabling truly autonomous irrigation scheduling.
Environmental factors, such as heavy rain, fog, and strong winds, can significantly disrupt wireless communication by attenuating or even blocking radio signals, leading to data loss and compromised system performance (Ed-daoudi et al., 2023; Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). Dense vegetation, buildings, and uneven terrain create further complications by causing multipath propagation and shadowing effects (Yim et al., 2018; Gautam and Pagay, 2020). The study by Yim et al. (2018) on LoRa networks in a tree farm environment exemplifies these challenges, revealing reduced communication range and data reliability compared to theoretical expectations. This underscores the need for carefully selecting and optimizing communication protocols and network parameters to ensure reliable data transmission in such environments.
The study by Guzinski et al. (2014a) using a modified TSEB model further highlights the importance of high-resolution data in accurately capturing the spatial and temporal dynamics of energy fluxes influenced by environmental factors. This emphasizes the need for advanced data acquisition and processing techniques that can effectively represent the complexities of agricultural settings.
The limitations of traditional wireless communication technologies, such as limited range and network congestion, pose additional challenges for large-scale agricultural operations. Long-distance data transmission can be hindered by range limitations, while network congestion arising from numerous sensors transmitting concurrently can lead to delays and data loss, hindering real-time decision-making (Hameed et al., 2020). Addressing these challenges requires the exploration of advanced networking technologies that can optimize spectrum utilization, mitigate interference, and improve reliability and efficiency.
Cognitive Radio Networks (CRNs) and Dynamic Spectrum Access (DSA) offer promising solutions for optimizing wireless communication in agricultural settings. CRNs empower devices with the ability to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). Research has explored the potential of CRNs in predicting Radio Frequency (RF) power to avoid noisy channels and optimize spectrum utilization (Iliya et al., 2014; Iliya et al., 2014). These studies demonstrate the effectiveness of combining optimization algorithms with artificial neural networks (ANNs) to enhance the accuracy and generalization of RF power prediction, enabling CRNs to make informed decisions about channel selection and avoid interference.
DSA complements CRN technology by dynamically allocating unused spectrum, further enhancing spectrum utilization and reducing congestion (Shi et al., 2023). The numerical model developed by Shi et al. (2023) showcases the potential of CRNs and DSA for optimizing wireless communication in challenging environments.
The integration of CRNs and DSA into the IoT network architecture requires careful consideration of spectrum sensing techniques, network topology, and data security. Research on cooperative spectrum sensing suggests that distributed approaches, where sensor nodes collaborate and share information, can significantly improve the accuracy and efficiency of spectrum sensing, particularly in dynamic environments (Trigka and Dritsas, 2022; Khalid & Yu, 2019). This collaborative approach enables a more comprehensive understanding of the radio environment and facilitates the identification of available frequency bands for data transmission.
The choice of network topology also impacts the performance and scalability of CRN-based irrigation systems. Mesh networks, where sensor nodes are interconnected and relay data for each other, offer enhanced resilience and coverage compared to star topologies where nodes communicate directly with a central gateway (Akyildiz & Vuran, 2010). However, mesh networks can be more complex to manage and may introduce additional routing overhead. The trade-off between network resilience and complexity needs to be carefully evaluated to select the most appropriate topology for a specific agricultural setting.
Data security and privacy are paramount concerns in IoT-based irrigation systems due to the sensitive nature of agricultural data (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential for protecting data integrity and ensuring system trustworthiness. Research on secure spectrum leasing and resource allocation algorithms for CR-WSN-based irrigation systems has demonstrated the potential of these technologies for enhancing security and efficiency (Hassan, 2023; Afghah et al., 2018).
In conclusion, the development of effective and reliable real-time irrigation management systems requires a comprehensive approach that addresses the challenges of data transmission in agricultural environments. The integration of robust and adaptive communication protocols, optimized network architectures, and advanced networking technologies like CRNs and DSA, along with a focus on data security and privacy, can contribute significantly to achieving the goal of autonomous and efficient irrigation scheduling.
4. AUTOMATED DATA PROCESSING IN THE CLOUD
4.1. Data Quality and Preprocessing
Data quality is paramount in automated irrigation systems as it directly influences the effectiveness of decision-making and water use efficiency. Issues like missing values, inconsistencies, and outliers arising from sensor malfunctions, environmental interference, or network problems (Lv et al., 2023) can significantly impact the performance of machine learning models used for irrigation scheduling and management.
Real-time data cleaning techniques are essential for addressing these challenges. Kalman filtering proves particularly effective in handling missing values and correcting erroneous readings by recursively estimating the system's state based on previous measurements and current sensor data, taking into account noise and uncertainty (Kim et al., 2020). Moving average techniques, by averaging consecutive data points, provide a more stable representation of the underlying trend, filtering out short-term fluctuations (Chhetri, 2023). For outlier detection, adaptive thresholding methods offer a dynamic approach, adjusting thresholds based on the statistical properties of the data to effectively identify anomalies and minimize false positives (Bah et al., 2021). These techniques are crucial in maintaining the integrity of real-time data streams and ensuring the accuracy of subsequent analyses.
Adaptive data preprocessing is essential for managing the diversity of data sources and formats commonly found in irrigation systems. Data normalization techniques, such as min-max scaling or z-score normalization, ensure that all features contribute equally to the analysis by transforming data values to a common scale (Pradal et al., 2016). This is crucial for preventing features with larger values from dominating the analysis and ensuring that all features are given equal consideration. Similarly, feature scaling methods, like standardization or normalization, optimize the range of feature values to improve the performance and convergence of machine learning models (Tortorici et al., 2024). By scaling features to a similar range, the influence of outliers is reduced, and the model's ability to learn from the data is enhanced.
Data fusion techniques play a critical role in integrating information from diverse sources, creating a more comprehensive and reliable dataset for irrigation management. Dempster-Shafer theory, a generalization of probability theory, allows for the expression of both uncertainty and the degree of conflict in evidence, making it suitable for fusing uncertain and conflicting data from heterogeneous sources (Sadiq and Rodriguez, 2004). This is particularly relevant in irrigation systems where data from different sensors may provide slightly different or even contradictory information due to sensor variations or environmental factors. Bayesian inference offers another powerful framework for combining information from multiple sources, updating the probability of a hypothesis as new evidence becomes available. By applying these techniques, data from soil moisture sensors, canopy temperature sensors, weather stations, and other sources can be integrated to provide a holistic understanding of crop water requirements and environmental conditions, leading to more informed and accurate irrigation decisions.
The impact of data quality extends beyond model accuracy to the robustness of machine learning models under varying conditions. Robust models should maintain consistent performance even when faced with data inconsistencies or unexpected situations. Techniques like data augmentation and domain adaptation can enhance model robustness by exposing the model to a wider range of data variations during training. Data augmentation involves generating additional training data by applying transformations or introducing noise to existing data, making the model more resilient to noise and variations in the real-world data. Domain adaptation techniques aim to adapt a model trained on one domain (e.g., a specific crop or geographic location) to perform well on another domain with different data characteristics. This is particularly relevant in irrigation management, where models may need to be applied to different crops, soil types, or climatic conditions.
The choice of data cleaning, preprocessing, and fusion techniques should be carefully considered based on the specific characteristics of the irrigation system and the available data. By selecting and implementing appropriate techniques, the accuracy, reliability, and robustness of machine learning models can be significantly improved, leading to more efficient and sustainable irrigation management practices.
4.2. Scalable and Autonomous Deployment using Containerization Strategies
The transition from data collection and transmission to efficient data processing requires a robust infrastructure capable of handling diverse workloads and data volumes. Containerization technologies, specifically Docker and Kubernetes, offer a promising solution for deploying and scaling data processing and machine learning modules within cloud environments like AWS, Azure, and GCP (Vargas-Rojas et al., 2024; Rosendo et al., 2022; Solayman & Qasha, 2023). Docker provides a standardized way to package applications and their dependencies into self-contained units known as containers, ensuring consistent and reproducible execution across different platforms (Rosendo et al., 2022). Kubernetes, acting as a container orchestrator, manages their deployment, scaling, and networking across a cluster of machines (Rosendo et al., 2022). This combination presents several advantages for automated irrigation management systems.
Firstly, containerization facilitates efficient resource utilization and scalability. By encapsulating applications and their dependencies, containers enable the isolation of resources and prevent conflicts between different modules (Vargas-Rojas et al., 2024; Solayman & Qasha, 2023). This isolation allows for the efficient allocation of resources, such as CPU, memory, and storage, to each container based on its specific needs. Kubernetes further enhances scalability by allowing for the automatic scaling of containers based on real-time demand, ensuring the system can adapt to varying workloads and data volumes, preventing bottlenecks, and ensuring responsiveness to changing conditions (Karamolegkos et al., 2023).
Secondly, containerization promotes portability and reproducibility. By packaging applications and their dependencies into a single unit, containers make it easy to move and deploy them across different cloud environments without the need for environment-specific configurations (Rosendo et al., 2022; Solayman & Qasha, 2023). This portability simplifies the development and deployment process, reducing the time and effort required to set up and manage the system. Additionally, containers ensure reproducibility by providing a consistent execution environment, regardless of the underlying infrastructure. This eliminates variability and ensures that the system will behave consistently across different deployments (Zhou et al., 2023).
Optimizing container orchestration and resource allocation is crucial to minimizing latency and maximizing throughput in real-time data processing pipelines. Techniques like auto-scaling and dynamic resource allocation play a critical role in this context (Hethcoat et al., 2024; Werner and Tai, 2023; Kumar et al., 2024). Auto-scaling automatically adjusts the number of container instances based on real-time demand, ensuring that sufficient resources are available to handle peak workloads while avoiding over-provisioning during periods of low demand (Hethcoat et al., 2024; Kumar et al., 2024). Dynamic resource allocation enables the fine-grained adjustment of resources allocated to each container based on its specific needs and the current workload (Werner and Tai, 2023). This ensures efficient resource allocation and provides each container with the necessary resources to perform its tasks effectively.
Performance monitoring tools, such as Kubernetes Metrics Server and Prometheus, are essential for gaining insights into the performance of containers and the overall system (Hethcoat et al., 2024; Kuity & Peddoju, 2023). These tools provide valuable data on key performance indicators, such as CPU and memory usage, network traffic, and application-specific metrics. By monitoring this data, administrators can identify bottlenecks, optimize resource allocation strategies, and continuously improve system performance (Hethcoat et al., 2024). This data-driven approach ensures that automated irrigation management systems can operate efficiently and reliably.
By integrating containerization technologies with optimization techniques and performance monitoring, automated irrigation management systems achieve the scalability, autonomy, and efficiency required for effective real-time data processing and decision-making. This approach facilitates a seamless and responsive system that can adapt to changing conditions and contribute to the overall goal of optimizing water resource management and increasing agricultural productivity.

4.3. Deploying ML Models for Data Processing
Transitioning from data collection, preprocessing, and transmission, the deployment of machine learning (ML) models marks a pivotal stage in the automated irrigation management pipeline. This stage entails utilizing cloud platforms to facilitate real-time data processing and inference, enabling data-driven decision-making for optimal irrigation management and ultimately contributing to fully autonomous, scalable irrigation management.
Several architectures and frameworks exist for deploying ML models on cloud platforms, each offering unique advantages and catering to different requirements. TensorFlow Serving, for instance, provides a high-performance system specifically designed for serving TensorFlow models (Abadi et al., 2016). This framework enables efficient and scalable inference, making it suitable for real-time applications where low latency and high throughput are crucial. For instance, in a large-scale irrigation system with numerous sensors generating data continuously, TensorFlow Serving can efficiently handle the high volume of inference requests and provide timely predictions for irrigation scheduling. Similarly, Apache MXNet Model Server offers a flexible and efficient solution for deploying models trained with MXNet, supporting a wide range of deep learning models and inference backends (MXNet Developers, 2015). This versatility makes it suitable for complex irrigation systems that may utilize different types of ML models for various tasks, such as predicting crop water requirements, detecting plant stress, or forecasting weather conditions. ONNX Runtime, on the other hand, provides a cross-platform inference engine compatible with various ML frameworks, including PyTorch, TensorFlow, and MXNet (Microsoft, 2017). This versatility enables the deployment of models in diverse environments, facilitating interoperability and reducing the need for model conversion. For example, an irrigation system that uses models trained in different frameworks can utilize ONNX Runtime to deploy them on a single platform without the need for time-consuming and error-prone model conversion processes.
Choosing the appropriate architecture or framework depends on several factors, including the specific ML framework used for model training, the desired level of performance and scalability, and the need for cross-platform compatibility. For instance, if the primary concern is low latency and high throughput for real-time inference, TensorFlow Serving might be the optimal choice for TensorFlow models. However, if flexibility and support for various deep learning models are required, Apache MXNet Model Server could be more suitable. In cases where cross-platform compatibility is essential, ONNX Runtime offers a versatile solution.
Once the ML model is deployed, optimizing its performance and resource utilization becomes crucial for ensuring the efficiency of integrated end-to-end automated irrigation systems. Model compression techniques, such as pruning and quantization, offer effective methods for reducing the size and computational requirements of ML models without compromising accuracy (Premkumar & Sigappi, 2022). Pruning involves eliminating unnecessary connections or neurons from the model, effectively streamlining its structure and reducing computational complexity. This can be particularly beneficial for deep learning models, which often have a large number of parameters and can be prone to overfitting. By removing redundant or less important connections, pruning can improve modelgeneralizability and reduce inference time. Quantization, on the other hand, involves reducing the precision of model parameters, typically from 32-bit floating-point numbers to lower-precision formats such as 8-bit integers. This reduction in precision leads to smaller model sizes and faster inference speeds, making it particularly beneficial for resource-constrained environments or real-time applications. For instance, in edge computing scenarios where ML models are deployed on devices with limited computational resources, quantization can enable efficient inference without sacrificing accuracy.
Furthermore, hardware acceleration through the utilization of GPUs or TPUs can significantly enhance model performance by leveraging specialized hardware designed for parallel processing (Premkumar & Sigappi, 2022). GPUs, with their massive parallelism and high memory bandwidth, excel at accelerating matrix operations and convolutions, which are fundamental computations in many deep learning models. This acceleration can significantly reduce inference time and enable real-time processing of sensor data for timely irrigation decisions. TPUs, specifically designed for deep learning workloads, offer even greater performance and energy efficiency for specific model architectures. These hardware accelerators can drastically reduce inference time, enabling near real-time decision-making and enhancing the responsiveness of automated irrigation systems. For example, in a scenario where immediate response to changing weather conditions or soil moisture levels is critical, hardware acceleration can ensure that irrigation decisions are made and executed promptly.
In addition to model compression and hardware acceleration, distributed training techniques play a crucial role in optimizing the training process for large-scale ML models. Techniques such as Horovod and BytePS enable the distribution of training across multiple machines, effectively parallelizing the process and reducing training time (Premkumar & Sigappi, 2022). This is particularly beneficial for complex models with a large number of parameters or when dealing with large datasets. By leveraging distributed training, irrigation management systems can train more sophisticated models and improve their predictive capabilities, leading to more accurate and efficient irrigation decisions. For instance, a system that utilizes a deep learning model with millions of parameters can benefit from distributed training to reduce training time from days to hours, enabling faster model iteration and improvement.
Integrating the deployed ML models with other components of the automated irrigation management pipeline is essential for achieving a fully autonomous and cohesive system and addressing the need for seamless integration across the automated irrigation management system. Standardized protocols, such as MQTT and CoAP, provide lightweight and efficient communication channels for exchanging data between these components (Poojara et al., 2023; Jimenez et al., 2020a; Gour et al., 2023). MQTT, with its publish-subscribe architecture, enables real-time data streaming and event-driven communication, making it suitable for transmitting sensor data, control signals, and inference results (Raikar & M, 2023). This enables the ML model to receive real-time updates on soil moisture, weather conditions, and plant health, allowing for dynamic adjustments to irrigation schedules based on the latest data. CoAP, designed for constrained devices and low-power networks, offers a web-transfer protocol for resource-constrained environments, enabling efficient communication between sensors, actuators, and the ML models (Raikar & M, 2023). This is particularly relevant in situations where sensors or actuators have limited processing power or battery life, as CoAP minimizes communication overhead and energy consumption. Additionally, RESTful APIs provide a standardized interface for accessing and controlling the ML models, enabling seamless integration with other software components and facilitating system management and monitoring (Wang et al., 2022). This allows for easy integration with existing farm management systems or third-party applications, creating a unified platform for comprehensive irrigation management.4.4. Online Learning in the Cloud
The complexities of real-time data processing in irrigation management necessitate the exploration of advanced techniques to continuously learn and adapt to the dynamic nature of agricultural environments. Online learning algorithms offer a promising solution, enabling the continuous update and improvement of machine learning models based on incoming real-time data. This adaptability is crucial for addressing the challenges of changing environmental conditions, such as weather patterns and crop growth stages, and optimizing irrigation decision-making to enhance water usage efficiency and crop productivity.
Several online learning algorithms have demonstrated potential for real-time data processing and model adaptation in the context of irrigation management. Stochastic Gradient Descent (SGD) facilitates the incremental update of model parameters with each new data point, allowing for efficient adaptation to changing data distributions (Bottou, 2010). This incremental learning process ensures that the model remains responsive to the latest conditions, minimizing the risk of outdated predictions and improving the accuracy of irrigation decisions. Passive-Aggressive algorithms, on the other hand, adjust model parameters only when a misclassification occurs, providing a computationally efficient approach for handling large data streams (Crammer et al., 2006). These algorithms offer a robust approach to handling noisy data, a common challenge in real-world sensor readings, by making small adjustments only when the model's prediction deviates significantly from the actual value (Fei et al., 2019). Online Random Forests extend the concept of random forests to the online setting, enabling the incremental construction and update of decision trees as new data arrives (Saffari et al., 2009). The continuous evolution of the ensemble ensures that the model remains relevant to the changing environment, capturing intricate relationships between variables and leading to more informed irrigation decisions.
Research in various domains highlights the importance of online learning for real-time data stream analytics. Snyder et al. (2020) explored the application of online learning techniques for identifying relevant tweets in real-time, improving situational awareness for first responders. The proposed interactive learning framework allows users to continuously label the relevance of incoming tweets, enabling the real-time refinement of the underlying machine learning model. This user-guided approach aligns well with the dynamic nature of irrigation management, where models need to continuously adjust to varying environmental conditions and crop water requirements. Similarly, research in the field of cyber-physical systems (CPS) underscores the need for online learning algorithms to effectively extract insights and knowledge from continuously generated data streams (Fei et al., 2019). These capabilities are crucial for enabling feedback loops between physical processes and cyber elements, facilitating the integration and optimization of CPS in irrigation management systems.
To implement online learning in cloud-based irrigation management systems, various architectures and frameworks can be considered. Apache Spark Streaming, Apache Flink, and AWS Kinesis provide scalable and fault-tolerant platforms for processing real-time data streams, allowing for the development of online learning pipelines that continuously ingest and analyze data to update machine learning models (Zaharia et al., 2012; Carbone et al., 2015; Amazon Web Services, 2023). These frameworks leverage serverless computing paradigms, automatically scaling resources based on the volume and velocity of incoming data, ensuring efficient resource utilization and responsiveness to fluctuations in demand (Fei et al., 2019).
Effectively managing the exploration-exploitation trade-off is crucial for optimizing online learning in irrigation management. Techniques such as Multi-armed bandits (Sutton & Barto, 2018), Bayesian optimization (Shahriari et al., 2016), and Reinforcement Learning (RL) (Sutton & Barto, 2018) can be employed to balance the allocation of resources between exploring new irrigation strategies and exploiting the current best-performing approaches. These techniques enable the identification of optimal irrigation policies, adapting to changing environmental conditions and maximizing long-term rewards.
In conclusion, online learning techniques, coupled with scalable cloud-based architectures, offer a powerful solution for real-time data processing and continuous adaptation in irrigation management systems. By leveraging algorithms like SGD, Passive-Aggressive, and Online Random Forests, along with stream processing frameworks like Apache Spark Streaming, Apache Flink, and AWS Kinesis, irrigation management systems can effectively handle the complexities of real-time data, optimize water usage, and enhance crop productivity in the face of dynamic environmental conditions.

5. GENERATING AND APPLYING IRRIGATION INSIGHTS 
5.1. Real-Time Generation of Actionable Irrigation Insights
•	Advanced predictive models, such as deep learning (e.g., LSTM, CNN) and ensemble methods (e.g., Random Forests), for precise, site-specific irrigation recommendations
•	Integration of IoT sensor data (e.g., soil moisture probes, weather stations) and cloud-based data sources (e.g., weather forecasts, satellite imagery) using data fusion techniques (e.g., Kalman filtering) to enhance insight accuracy and resolution
•	Strategies for handling data heterogeneity, uncertainty, and quality issues in real-time insight generation, such as data preprocessing and outlier detection
•	Techniques for reducing computational complexity and latency, such as edge computing (e.g., fog computing), model compression (e.g., quantization), and hardware accelerators (e.g., GPUs)
5.2. Automated Application of Irrigation Insights
•	Architectures and protocols for seamless integration of ML-generated insights with IoT-enabled irrigation control systems, such as MQTT and CoAP for lightweight, real-time communication
•	Analysis of industry-leading products and services, such as smart irrigation controllers (e.g., Rachio) and cloud-based irrigation management platforms (e.g., CropX)
•	Strategies for ensuring reliability, security, and scalability of automated insight application, such as redundant communication channels and secure edge-to-cloud architectures
•	Case studies of successful implementations of closed-loop, autonomous irrigation systems in research and commercial settings, highlighting technologies used and benefits achieved

6. INTEGRATION, INTEROPERABILITY, AND STANDARDIZATION 
6.1. Interoperability and Standardization
•	Importance of interoperability and standardization in enabling seamless integration of automated irrigation components
•	Overview of existing and emerging standards for IoT devices, communication protocols, and data formats in precision agriculture (e.g., ISOBUS, agroXML, SensorML)
•	Role of standardization bodies and industry consortia in promoting interoperability (e.g., AgGateway, Open Ag Data Alliance, Agricultural Industry Electronics Foundation)
•	Challenges in adopting and implementing standards across diverse hardware and software platforms
•	Strategies for encouraging widespread adoption of standards and best practices for interoperability in automated irrigation systems
6.2. Integration with Existing Irrigation Infrastructure
•	Challenges and strategies for retrofitting legacy irrigation systems with IoT sensors, actuators, and communication devices
•	Hardware compatibility issues and solutions (e.g., adapters, modular designs)
•	Software and firmware updates to enable integration with automated decision-making systems
•	Data integration and normalization techniques for merging legacy and new data sources
•	Economic and practical considerations for transitioning from manual to automated irrigation management
•	Cost-benefit analysis of upgrading existing infrastructure vs. implementing new systems
•	Phased implementation approaches to minimize disruption and optimize resource allocation
•	Training and support requirements for farmers and irrigation managers adopting automated systems
•	Case studies and real-world examples of successful integration of automated irrigation with existing infrastructure
6.3. Integration with Other Precision Agriculture Technologies
•	Synergies between automated irrigation and complementary technologies
•	Remote sensing (satellite, UAV, and ground-based) for crop monitoring and evapotranspiration estimation
•	Soil moisture sensors and weather stations for real-time, localized data collection
•	Variable rate application systems for precise irrigation delivery based on crop requirements
•	Yield mapping and analytics for assessing the impact of automated irrigation on crop productivity
•	Architectures and frameworks for integrating diverse data sources and technologies into a unified precision agriculture ecosystem
•	Edge computing and fog computing paradigms for real-time data processing and decision-making
•	Cloud-based platforms for data storage, analysis, and visualization
•	API-driven approaches for modular integration of third-party services and applications
•	Challenges and solutions for ensuring data quality, consistency, and security across integrated precision agriculture systems
•	Data cleaning, preprocessing, and harmonization techniques
•	Blockchain and distributed ledger technologies for secure, tamper-proof data sharing and traceability
•	Access control and authentication mechanisms for protecting sensitive data and resources
•	Future trends and research directions in the integration of automated irrigation with advanced precision agriculture technologies (e.g., AI-driven crop modeling, robotics, and autonomous vehicles)
6.4. Cybersecurity Considerations for Integrated Automated Irrigation Systems
•	Unique security risks and vulnerabilities associated with IoT-based automated irrigation systems
•	Potential for unauthorized access, data tampering, and system manipulation
•	Implications of security breaches for crop health, water resource management, and farm productivity
•	Best practices and strategies for securing automated irrigation systems
•	Secure device provisioning and authentication (e.g., hardware security modules, certificates)
•	Encryption and secure communication protocols (e.g., TLS, DTLS)
•	Firmware and software updates to address emerging security threats
•	Network segmentation and access control to limit the impact of breaches
•	Role of cybersecurity standards and frameworks in guiding the development and deployment of secure automated irrigation systems (e.g., NIST CSF, IEC 62443)
•	Importance of user awareness, training, and incident response planning in maintaining the security of integrated automated irrigation systems

7. MONITORING AND ENSURING SYSTEM RELIABILITY
7.1. Resilience and Fault Tolerance in Automated Irrigation Systems
•	Strategies for ensuring robustness and reliability in the face of failures, disruptions, or unexpected events
•	Redundancy: Implementing redundant components, such as duplicate sensors (e.g., soil moisture sensors, weather stations), controllers (e.g., PLCs, microcontrollers), and communication channels (e.g., cellular, satellite, LoRaWAN) to maintain system functionality during component failures
•	Failover mechanisms: Designing seamless failover mechanisms that automatically switch to backup components or systems in case of primary system failure, such as hot-standby controllers or multi-path communication protocols (e.g., mesh networks, software-defined networking)
•	Self-healing capabilities: Incorporating AI-driven self-healing mechanisms that can detect, diagnose, and recover from faults without human intervention, using techniques like reinforcement learning, Bayesian networks, or self-organizing maps
•	The role of distributed architectures and edge computing in enhancing system resilience
•	Decentralizing critical functions and data processing to minimize the impact of single points of failure, using fog computing or multi-agent systems
•	Leveraging edge computing to enable localized decision-making and control, reducing dependence on cloud connectivity and improving response times, using technologies like Raspberry Pi, NVIDIA Jetson, or Intel NUC
•	Anomaly detection and predictive maintenance using AI techniques
•	Employing unsupervised learning algorithms (e.g., autoencoders, clustering) to detect anomalies in sensor data, system performance, and water usage patterns
•	Developing predictive maintenance models using techniques like long short-term memory (LSTM) networks, convolutional neural networks (CNNs), or gradient boosting machines (GBMs) to anticipate and prevent potential system failures based on historical data and real-time monitoring
7.2. Advanced Monitoring Techniques for Automated Irrigation Systems
•	Remote monitoring using IoT-enabled sensors and computer vision
•	Deploying a heterogeneous network of IoT sensors to collect real-time data on soil moisture (e.g., capacitive, tensiometric), temperature (e.g., thermocouples, thermistors), humidity (e.g., capacitive, resistive), and plant health (e.g., sap flow, leaf wetness)
•	Integrating high-resolution cameras (e.g., multispectral, hyperspectral) and computer vision algorithms for visual monitoring of crop growth, disease detection (e.g., using deep learning-based object detection and segmentation), and irrigation system performance (e.g., leak detection, sprinkler uniformity)
•	Transmitting sensor and camera data to cloud-based platforms (e.g., AWS IoT, Google Cloud IoT, Microsoft Azure IoT) for remote access and analysis using protocols like MQTT, CoAP, or AMQP
•	Innovative approaches for real-time system health assessment
•	Developing novel algorithms and metrics for evaluating the health and performance of automated irrigation systems, such as entropy-based measures, network resilience indices, or multi-criteria decision analysis (MCDA) frameworks
•	Combining data from multiple sources (e.g., sensors, weather forecasts, satellite imagery) using data fusion techniques (e.g., Kalman filters, Dempster-Shafer theory) to create a comprehensive view of system health
•	Employing advanced data visualization techniques (e.g., interactive dashboards, augmented reality) to present system health information in an intuitive and actionable format
7.3. Closed-Loop Control and Feedback Mechanisms
•	Exploring the concept of closed-loop control in autonomous irrigation systems
•	Implementing feedback loops that continuously monitor system performance and adjust irrigation schedules based on real-time data, using control techniques like proportional-integral-derivative (PID), model predictive control (MPC), or fuzzy logic control (FLC)
•	Integrating machine learning algorithms (e.g., reinforcement learning, genetic algorithms) to optimize closed-loop control strategies over time, adapting to changing environmental conditions and crop requirements
•	Designing effective feedback mechanisms for user interaction and system optimization
•	Providing user-friendly interfaces (e.g., mobile apps, web dashboards) for farmers to input preferences, constraints, and expert knowledge into the automated irrigation system, using techniques like participatory design or user-centered design
•	Incorporating user feedback and domain expertise to refine irrigation strategies and improve system performance
8. CASE STUDIES AND REAL-WORLD IMPLEMENTATIONS OF FULLY AUTONOMOUS IRRIGATION SYSTEMS
8.1. Fully Autonomous Irrigation Systems in Diverse Agricultural Settings
•	Row Crops: maize, wheat, soybean with real-time soil moisture monitoring and weather-based irrigation scheduling for fully automated precision irrigation
•	Orchards: citrus, apple, almond with plant health monitoring and precision water application for fully autonomous orchard management
•	Greenhouses: tomato, lettuce, herbs with automated drip irrigation and climate control integration for fully automated greenhouse operations
•	Urban Farming: rooftop gardens, vertical farms with IoT-enabled hydroponic systems and remote management for fully autonomous urban crop production
8.2. Integration of Advanced System Components for End-to-End Automation
•	Wireless sensor networks: soil moisture probes, weather stations, plant health monitoring cameras with low-power, long-range communication for fully automated data acquisition
•	Secure data transmission: LoRaWAN, NB-IoT, 5G, satellite communication for reliable, real-time data transfer from field to cloud in fully autonomous irrigation systems
•	Intelligent data processing: edge computing for local data filtering, cloud platforms for scalable storage and analysis, machine learning algorithms for predictive insights in fully automated irrigation management
•	Autonomous decision-making: advanced irrigation scheduling algorithms, precise valve control, closed-loop feedback systems for optimal water management in fully autonomous irrigation systems
8.3. Quantitative Performance Evaluation of Fully Automated Irrigation Systems
•	Water use efficiency: percent reduction in water consumption compared to conventional methods, improved water productivity (yield per unit of water) achieved through fully autonomous irrigation
•	Crop yield and quality improvements: percent increase in yield, enhanced crop uniformity, improved nutritional content attributed to fully automated precision irrigation
•	Labor and energy savings: quantified reduction in labor hours for irrigation management, decreased energy consumption for pumping due to optimized scheduling in fully autonomous systems
•	Economic viability: detailed return on investment analysis, payback period calculations, comprehensive cost-benefit analysis for fully autonomous irrigation management systems
8.4. Lessons Learned and Challenges Encountered in Deploying Autonomous Irrigation Systems
•	Technical challenges and solutions: ensuring reliable data transmission in remote locations, addressing interoperability issues between diverse system components, optimizing power consumption for extended battery life, adapting algorithms to local soil and weather conditions in fully autonomous irrigation systems
•	Operational and logistical hurdles: streamlining installation and maintenance procedures, providing effective user training, seamlessly integrating with existing farm management practices and legacy systems for fully automated irrigation management
•	Regulatory and socio-economic considerations: navigating complex water use regulations, addressing data privacy and security concerns, ensuring equitable access and affordability for smallholder farmers adopting fully autonomous irrigation technologies
8.5. Best Practices and Recommendations for Successful Implementation
•	Designing scalable, modular, and adaptable autonomous irrigation systems to accommodate future growth and changing requirements for fully automated water management
•	Prioritizing user-centered design principles and actively engaging stakeholders throughout the development and deployment process of fully autonomous irrigation solutions
•	Adopting open standards and communication protocols to enable seamless integration of system components and interoperability with third-party platforms in fully automated irrigation setups
•	Implementing robust data validation, filtering, and quality control mechanisms to ensure data integrity and reliability for decision-making in fully autonomous irrigation systems
•	Establishing clear data governance policies and security frameworks to protect sensitive information and maintain user trust in fully automated irrigation management
•	Developing intuitive user interfaces and decision support tools to facilitate easy adoption and effective use of fully autonomous irrigation systems
•	Collaborating with local extension services, agribusinesses, and technology providers for knowledge transfer, technical support, and continuous improvement of fully automated irrigation solutions
8.6. Synthesis of Case Studies and Implications for Autonomous Irrigation Adoption
•	Cross-case analysis of key performance indicators and critical success factors for fully autonomous irrigation scheduling systems in various contexts
•	Identification of common themes, challenges, and innovative solutions across diverse implementations of end-to-end fully automated irrigation management
•	Assessment of the potential for replicability and scaling of successful fully autonomous irrigation projects in different regions and farming systems
•	Implications for future research priorities, technology development roadmaps, and policy interventions to support widespread adoption of fully autonomous irrigation technologies

CONCLUSION/FUTURE DIRECTIONS AND UNANSWERED QUESTIONS
•	Summarize the key insights gained from the question-driven review, emphasizing how each section contributes to the overarching goal of achieving real-time, end-to-end automation in irrigation management
•	Based on the questions addressed, propose new research directions and unanswered questions
•	Identify key research gaps and propose concrete research questions and hypotheses for advancing the field of real-time, automated irrigation management
•	Highlight the need for collaborative research efforts across disciplines, such as computer science, agricultural engineering, and environmental science, to address the complex challenges of automated irrigation systems
•	Emphasize the need for further innovation and exploration in real-time, automated irrigation systems




</previous_sections>

</documents>
<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper. 

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: stated in: <subsection_title>
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>

<subsection_point_Point 4>
Point: Self-healing capabilities: Incorporating AI-driven self-healing mechanisms that can detect, diagnose, and recover from faults without human intervention, using techniques like reinforcement learning, Bayesian networks, or self-organizing maps

Papers to support point:

Paper 1:
- APA Citation: None
  Main Objective: To evaluate the efficiency of a self-healing method that utilizes AI-driven self-healing mechanisms to autonomously address faults within automated irrigation systems, without requiring human intervention.
  Study Location: None
  Data Sources: None
  Technologies Used: AI techniques, reinforcement learning, Bayesian networks, self-organizing maps
  Key Findings: The study demonstrates the capability of the proposed self-healing method in autonomously detecting, diagnosing, and recovering from system faults without the need for human intervention, using techniques such as reinforcement learning, Bayesian networks, or self-organizing maps.
  Extract 1: "The core premise is to develop and evaluate the efficiency of a self-healing method that leverages AI-driven self-healing mechanisms to autonomously detect, diagnose, and recover from any faults present in the automated irrigation system without necessitating human intervention."
  Extract 2: "The study employs various AI techniques such as reinforcement learning, Bayesian networks, or self-organizing maps to achieve this self-healing capability."
  Limitations: None
  Relevance Evaluation: The proposed method addresses a crucial aspect of real-time automated irrigation management systems - the ability to autonomously detect, diagnose, and recover from faults without human intervention. This aligns directly with the stated point of focus in the literature review: incorporating AI-driven self-healing mechanisms into automated systems for real-time irrigation management. Thus, the study possesses high relevance to the topic at hand, directly informing an integral aspect of the research area.
  Relevance Score: 0.95
  Inline Citation: None
  Explanation: This section dives into the particular details of the current study. The core premise is to develop and evaluate the efficiency of a self-healing method that leverages AI-driven self-healing mechanisms to autonomously detect, diagnose, and recover from any faults present in the automated irrigation system without necessitating human intervention. The study employs various AI techniques such as reinforcement learning, Bayesian networks, or self-organizing maps to achieve this self-healing capability.

 Full Text: >
"Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Keywords 1. Introduction 2. Problem statement and preliminaries 3. PFTC based on a novel TBSM 4. AFTC on the basis of TDE and adaptive fractional TBSM 5. Simulation results 6. Conclusion Credit author statement Declaration of competing interest References Show full outline Cited by (31) Figures (12) Show 6 more figures Tables (6) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6 Renewable Energy Volume 174, August 2021, Pages 86-101 Fault tolerant control of wind turbines with simultaneous actuator and sensor faults using adaptive time delay control Author links open overlay panel Mahmood Mazare, Mostafa Taghizadeh, Pegah Ghaf-Ghanbari Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.renene.2021.04.077 Get rights and content Highlights • Proposing a new adaptive time delay Fault Tolerant Control (FTC) structure. • Adaptive continuous Collective Pitch Control (CPC). • Fault diagnosis using Time Delay Estimation (TDE) as an effective algorithm. • Verifying effectiveness of the proposed CPC by implementing in FAST environment. Abstract In this paper, a new Active Fault Tolerant Control (AFTC) is proposed using adaptive fractional-based Terminal Back-stepping Sliding Mode (TBSM) control strategy for pitch angle control of a variable speed wind turbine in the presence of actuator and sensor faults. In order to detect, isolate and accommodate the faults, Time Delay Estimation (TDE) is used as an online fault estimation algorithm. To eliminate the chattering of conventional sliding mode, supper twisting sliding mode algorithm is applied, which also ensures finite time convergence and high precision. Moreover, wind speed profiles are generated using TurbSim, and the controller is implemented on a simplified two-mass wind turbine model. To verify the validity of the proposed scheme, the simulations are also performed in FAST environment, and finally, the simulation results are presented which reveal the effectiveness of the proposed controller in the presence of faults, uncertainties and turbulent wind fields. Previous article in issue Next article in issue Keywords Wind turbinePitch angle controlFault tolerant controlFractional order terminal back-steppingFASTTime delay estimation 1. Introduction With the ever-increasing energy demand and growing concern for environmental issues, sustainable solutions have attracted tremendous attention, among which wind energy has demonstrated outstanding characteristics, such as availability and low cost [1]. By the end of 2019, the total capacity for wind energy globally has reached over 651 GW, indicating a 10% increase compared to 2018 [2]. Wind turbines, as the main wind energy conversion system, have a complex and nonlinear dynamics, and work under stochastic wind disturbances, and centrifugal, gravitational and gyroscopic loads [3]. Relying on several rotating and non-rotating components and sensors, in addition to working in harsh environments make them prone to faults and failures, leading to low reliability. To prevent unpredicted failures, maintenance schedules are planned, which not only increase cost, but also reduce the power generation due to required downtime [4]. These challenges have been the motivation behind numerous researches in the realm of wind turbines, from nominal control to fault detection, isolation, and fault-tolerant control. Among the wind turbine subsystems, pitch control system plays a pivotal role in its performance by adjusting the power output, limiting power capture under high wind, mitigating operational load, stalling, and aerodynamic braking [5]. The pitch actuator faults are mostly due to pressure drop in hydraulic system or high air content in the oil, as a result of which the actuators’ dynamics slow down. This deteriorates the pitching performance and can cause fluctuations on generator speed and power and also loss of turbine stability [6]. Fault Detection and Isolation (FDI), and Fault-Tolerant Control (FTC) are effective methods that improve reliability, lower the maintenance cost, reduce downtime, prevent catastrophic failures, and yet despite the presence of faults, preserve system performance at the desired level. FTC approaches are generally categorized into two groups, Passive (PFTC) and Active (AFTC). PFTC schemes have fixed control structures, designed to be robust against uncertainties and faults, while AFTC approaches use the fault information from Fault Detection (FD) unit and reconfigure or redesign the controller, accordingly; so that acceptable performance and stability of the system can be retained. Not relying on fault detection, the PFTC approaches demonstrate fast response, but limited robustness. FDI techniques are performed with two approaches: model-based or signal processing methods. The latter approach requires the access to a huge bank of historical data with full fault scenarios, used as the input of diagnosis system. The model-based FDI are conducted based on a variety of methods including Sliding Mode Observer (SMO) [7], Kalman filters [8,9], intelligent techniques like fuzzy or neural network modeling and identification methods, as well as time delay estimation (TDE). Intelligent techniques suffer from high computational cost and difficult implementation, and SMO method requires the pre-knowledge about bounds of faults which in most practical cases are not known. Time delay estimation is a simple, model-free, yet robust approach which can be effectively applied for fault detection [10]. Simple design, high robustness against disturbances and uncertainties, insensitivity to parameter variation, as well as the ability to tackle faults have made the Sliding Mode Control (SMC)-based FTC methods an attractive control option for wind turbines. Nevertheless, the conventional SMC suffers from chattering and infinite time convergence to equilibrium point. Chattering can cause actuators to overheat, excite high frequency oscillations, and result in high wear of moving mechanical components. A variety of methods have been proposed to address these problems. To ameliorate chattering High Order SMC (HOSM) techniques and also Fractional Order (FO) SMC [11] are applied. The convergence rate drawback of SMC is addressed by proposing Terminal Sliding Mode Control (TSMC) scheme [12]. However, it suffers from two drawbacks: i) low convergence rate when the system state is far away from the equilibrium point. ii) Singularity problem. These problems were solved in Fast Terminal SMC (FTSMC) [13] and Nonsingular Terminal SMC (NTSMC) [14]. Besides chattering reduction, fractional calculus can enhance accuracy [15,16]. Compared to integer order controllers, fractional order ones are more robust, and also more stable, since they take the stationary error and the overshoot percentage into account [17]. Recently, many authors have integrated fractional calculus with SMC in order to improve its performance [18,19]. In Ref. [18], fractional order SMC strategy was proposed for a permanent magnet synchronous motor. Another fractional order SMC was developed in Ref. [19] to enhance the performance of anti-lock braking system. Furthermore, a fractional-order PI controller was developed to control a variable-speed wind turbine [20]. This approach has also been employed to enhance the robustness of AFTC. In Ref. [9] an AFTC based on fractional-order TSMC was designed and its estimation accuracy was enhanced using virtual actuators. Back-Stepping (BS) is another control approach that has been widely applied to control nonlinear systems. Owing to its systematic and recursive nature, back-stepping scheme is flexible in designing controllers for high-order nonlinear systems. Despite the shortcomings of the conventional version, such as sluggish motion and slow convergence, it can improve transient system performance [21]. Chakravarty [22] showed that by integrating back-stepping with second-order SMC, the post-fault transient performance of the AFTC improves, without sacrificing the control energy. Recently, the application of FTC in pitch control of wind turbines has grown increasingly. A fault diagnosis and fault tolerant control strategy for pitch actuator in wind turbines was proposed in Ref. [23]. They designed their controller by combining a disturbance compensator with a controller which is formulated in the discrete time domain, while the performance of the proposed controller was validated in FAST simulator. In Ref. [24], model predictive FTC is presented for wind turbines in partial-load region in the presence of uncertainties, disturbances and actuator/sensor faults. The authors, used a robust LMI-based adaptive method in order to estimate sensor faults, while a robust passive FTC is considered to reconstruct actuator faults. An observer-based FTC method was developed for the pitch system of wind turbine being under actuator and sensor faults [25]. A sliding mode approach and a proportional-integral observer were used in their study to track the blade pitch. Stability analysis was performed using linear matrix inequality (LMI) and Lyapunov method. An adaptive AFTC strategy is designed for wind power generation that ensures a smooth and robust control process in both normal and faulty conditions of actuator [26]. Moreover, an AFTC method entailing the robust estimation and compensation for wind turbine actuator and sensor faults was introduced in Ref. [27]. Their proposed control method comprised two parts: An active disturbance rejection control method, and a descriptor SMO. To validate the results, the controller was implemented in FAST environment. This paper proposes a new AFTC using adaptive fractional-based Terminal Back-stepping Sliding Mode (TBSM) control scheme with nonsingular integral properties for pitch angle control of a wind turbine in the presence of sensor and actuator faults. Integrating BS, SMC, and FO control approaches ensures high robustness, improves post-fault transient performance and gives higher degrees of freedom. For stability analysis, Lyapunov theory is applied and the effectiveness of the proposed controller is studied by its implementation on a detailed aero-elastic wind turbine simulator (FAST) designed by NREL National Wind Technology Center. Moreover, the wind profiles are generated using TurbSim. This paper is structured as follows. Section 2 describes the problem and preliminaries by defining the wind turbine model, introducing the system faults that will be considered in this study and giving the preliminaries and notations required for controller design. The proposed Passive FTC is described in section 3 and the Active FTC is presented in section 4. Simulation results are reported in section 5 and the conclusion is drawn in section 6. 2. Problem statement and preliminaries 2.1. Wind turbine model The powertrain of wind turbines comprises three main components, namely rotor blades, gear box and generator. Wind energy develops aerodynamic forces on blades, resulting in the following aerodynamic torque on the rotor. (1) where , , , and represent air density, rotor radius and its angular velocity, and wind speed, respectively. Moreover, denotes the torque coefficient, and generally is defined as a two-dimensional map which depends on pitch angle of the blade and the tip-speed ratio . The aerodynamic power captured by the blades is defined as, (2) where, symbolizes the power coefficient, defined by, (3) (4) Obviously, the following equation holds for torque and power coefficients. (5) Power coefficient for the under-studied wind turbine is presented in Fig. 1. Through regulating , the amount of captured wind energy is managed by pitch control system. Download : Download high-res image (608KB) Download : Download full-size image Fig. 1. Wind turbine nonlinear power coefficient . For hydraulic pitch control systems, each actuator is considered as a linear second-order system with the following transfer function. (6) where , and introduce the reference pitch angle, damping ratio and natural frequency, respectively. The mechanical part of drivetrain system can be modeled as a nonlinear two-mass spring damper system as shown in Fig. 2. Its dynamic model can be represented by the following state space equations [28]. (7) in which shows torsional angle. The definition of other parameters and their corresponding values for the reference turbine are listed in Table 1. Defining the state and the input vectors as, (8) the dynamic model of the wind turbine in the presence of faults and disturbances, can be rewritten as, (9) where , , and are the nonlinear term, control input coefficient, and fault and disturbance vectors, respectively. indicates the fault profile, which occurs at . Download : Download high-res image (147KB) Download : Download full-size image Fig. 2. Wind turbine two-mass model. Table 1. Parameters of 1.5 MW CART experimental wind turbine [29]. Parameter Unit Definition Value Rotor radius Air density Rotor inertia Generator inertia Drive-train spring factor Drive-train damping factor Gearbox ratio Pitch actuator time constant – Nominal power output Rated rotor speed Rated generator torque – Pitch angle limit – Pitch rate limit – Wind turbine efficiency 2.2. Fault description Generally, depending on their time profile, faults are categorized into incipient or abrupt types. Incipient faults occur slowly and grow gradually, while abrupt faults happen suddenly and unexpectedly. In spite of the fact that the abrupt faults are mostly easy to detect, they have the potential to impose severe effects on the system [30]. From severity point of view, faults can be divided into extreme or non-extreme. For extreme faults, immediate actions like off-grid procedures or shutdown are taken. On the other hand, for non-extreme cases, FTC strategies can be applied to maintain the turbine performance at an acceptable level [31]. Studies reveal that a great portion of failures are minor, and also the most prevalent failure occurs in pitch/hydraulic system [32]. As illustrated in Fig. 3, the hydraulic pitch system mainly comprises a pump, some valves, and a blade pitch motion mechanism. A controller takes the error signal between the actual and reference rotor speed and transmits the control signal to a servo valve that controls the actuator position. Pitch system fault has various causes, whether in control, or in hydraulic subsystem. Sensor faults occur in control subsystem, while pump wear, hydraulic leakage, and high air content in the oil affect the hydraulic subsystem. Download : Download high-res image (247KB) Download : Download full-size image Fig. 3. Structure of the hydraulic blade pitch system. Pitch sensor bias and gain degrades the performance of the controller, so that the system is unable to follow the desired input. In extreme cases when the pitch sensor completely fails, the blades are feathered. Bias in generator speed sensor also causes the pitch angle to deviate from its desired value, or the actuator experience runaway. High air content in oil can lead to slow pitch control action causing fluctuations in generator speed and power, and loss of system stability [7]. Moreover, incorrect pitch angle generates asymmetrical forces on the blades and intensifies structural loading of its platform. Hydraulic leakage can be divided into external and internal. External leakage happens at either side of the actuator, but the internal one takes place between the two hydraulic cylinder chambers. High internal leakage causes the actuator lose its ability to apply effective load, and external leakage may lead to a sluggish response [33]. 2.2.1. Pitch sensor fault The bias fault is prevalent in wind turbines and can be introduce to the system as a result of pitch sensor malfunction or inaccurate system calibration. Sensor fault is categorized as incipient and can be distinguished from the rate of biased signal and its range [28]. Biased output deteriorates the closed-loop system performance, and affects the pitch angle measurement. In the presence of bias fault, the dynamic model of the pitch actuator, Eq. (6), changes to the following equation. (10) in which subscripts , , and stand for bias, reference, and delay. The measured signal is written as, (11) where is measurement noise. 2.2.2. Pitch actuator faults The main faults of the hydraulic pitch actuators are: pump wear, hydraulic leakage and high air content in the oil. These faults affect the system dynamics differently and their influence is reflected in natural frequency ( ) and damping ratio ( ) of the pitch system. The numerical values of the actuator dynamic parameters for the reference wind turbine model, are summarized in Table 2. Table 2. Various faults effect on pitch system dynamics [28]. Faults Notes No fault (fault free) 11.11 0.6 • nominal value of the air content in the oil: 7%. High air content in the oil 5.73 0.45 • an incipient fault • a reversible process (the air content in the oil may disappear without any necessary repair) • air content in the oil:15%. Pump wear 7.27 0.75 • irreversible • slow process • up to 75% pressure drop Hydraulic leakage/Pressure drop 3.42 0.9 • an incipient fault • irreversible • faster than the pump wear • pressure drop for too fast leakage • up to 50% pressure drop • Under too low hydraulic pressure the system is unable to move the blades and therefore, the actuator sticks in its current position resulting in blade seize. 2.2.2.1. Pump wear As an incipient fault, pump wear happens at slow rate and causes low pump pressure. It changes the dynamics of pitch system as follows. (12) where shows the level of wear. Zero value indicates the normal condition, while its upper bound corresponds to 75% pump pressure. 2.2.2.2. Hydraulic leakage Hydraulic leakage is also an incipient fault, but happens faster than pump wear. This fault varies the system parameter as follows. (13) where . In normal operation, , and when the hydraulic pressure experiences 50% loss, . 2.2.2.3. High air content in oil High air content in oil is another incipient fault, whose effect on the system is described as below. (14) Unlike the previously mentioned faults, high air content in oil can disappear. So, can take negative values, too. Zero and one values for show 7% and 15% air content, respectively. If the hydraulic leakage persists, the pitch actuators may become uncontrollable. To prevent this situation, it should be detected before the hydraulic pressure drops to 50% of its nominal value. In addition, to accommodate this type of fault, the wind turbine needs a shut down before it completely loses its controllability. Other types of faults, namely pump wear and high air content in oil, are accommodated in similar manner, and they can be addressed by FTC methods [28]. 2.3. Preliminaries of fractional calculus In this section, the fundamental definitions of fractional order calculus and some of its key properties are presented, which are necessary for the controller design. Definition 1 The fractional integral with fractional order of function is defined as [34]: (15) where is the Gamma function and is the initial time. Definition 2 The Reimann-Liouville fractional derivative of αth-order of function is defined as follows [34]: (16) Property 1 The Reimann-Liouville fractional derivative operator commutes with (17) Theorem 1 Let be an equilibrium point for the following non-autonomous fractional-order system. (18) Assume that there exists a Lyapunov function and class-K functions (i = 1, 2, 3) satisfying [35]: (19) where . Then, the system is asymptotically stable [36]. Lemma 1 Assume that a continuous positive-definite function satisfies the differential Inequality [37]. (20) 3. PFTC based on a novel TBSM This section deals with passive fault-tolerant control design based on a novel TBSM approach for pitch angle control of a wind turbine in the presence of faults. 3.1. Fractional order-based Terminal Back-Stepping sliding mode controller with nonsingular property To guarantee the robustness of the controller in the presence of external disturbances and uncertainties, a control scheme has been proposed by combining back-stepping, sliding mode, and fractional order calculus. The tracking error of rotor speed is defined as, (21) where is the rated rotor speed. Taking time derivative of Eq. (21) yields the rotor speed dynamics as, (22) It can be proved that there exists a diffeomorphism transformation so that the wind turbine system given in Eq. (9) is equivalent to the system in its normal form with stable zero dynamics. This means that, taking time derivative of guarantees that the wind turbine system is stable and non-singular over its entire operating points [38,39]. Thus, the second-order derivative of results in, (23) where and represent the effects of faults and uncertainties, and , are [29]: (24) Now, a virtual control law is defined as, (25) where is a constant. is defined as, (26) Stability of under the virtual control law is analyzed by considering the following positive-definite Lyapunov function, . (27) Time derivative of after substituting Eqs. (22), (25), and (26) is obtained as, (28) Based on SMC theory, the following fractional order sliding manifold is proposed. (29) where and are constant parameters. For the controller to have nonsingular property, it is required that , and are chosen odd integers satisfying . The time derivative of the sliding surface is written as, (30) Now, if is calculated by taking time derivative of Eq. (26) and is replaced in Eq. (30), the following equation is obtained. (31) and taking Eq. (23) into account, it is rewritten as, (32) The next step is to design reaching mode control scheme using a reaching control law . This can be derived as follows: ‌ (33) It should be noted that is non-singular for all operating points [29]. The fractional order term in control signal, , enhances the controller robustness. Applying fractional order calculus to SMC gives an extra degree of freedom compared to integer order SMC, thus better control performance is achieved. Using Lemma 1, the stability of wind turbine system with fractional TBSM is proved. Finally, the TBSM-based control law is obtained as, (34) where , and are positive scalars and are optimized using Harmony Search Algorithm (HSA) [40]. Theorem 2 By applying the proposed structure defined by Eq. (34), the wind turbine system is stable and the rotor speed converges to the fractional sliding manifold. Proof: Stability analysis of the proposed controller is conducted based on SMC theory, and to do so, a positive definite Lyapunov function is chosen as follows: (35) Taking time derivative of this equation results in, (36) which can be expanded by substituting Eqs. (28) and (32) as, (37) Substituting the control law from Eq. (34) leads to, (38) which after simplification can be written in the following form. (39) To prove the stability of a system according to Lyapunov theory, time derivative of the chosen positive definite Lyapunov function must be negative definite. From Eq. (39) it is evident that all terms are negative except the first term, , which does not have a specific sign. To prove the negative definite property of and asymptotical stability of the system under the control law, Eq. (34), positive definite matrix rules are used. Substituting the proposed fractional sliding surface, Eq. (29), into Eq. (39) results in: (40) By defining and so that , the following inequality holds. (41) Taking the following positive upper bound of each term into account, (42) If the constant parameters satisfy above condition, will be positive definite and then in Eq. (41) will be negative definite. As mentioned in Ref. [41], and are also negative definite and and are positive constants. Therefore, according to Lyapunov stability theory, the wind turbine system will be stable. Theorem 1 proved that rotor speed reaches the proposed fractional sliding surface, while the convergence of fractional sliding surface is not discussed. In Theorem 2, the convergence of fractional sliding surface is investigated. The new generalized Lyapunov stability theory and Lemmas proposed in Ref. [36] are used to investigate the convergence of sliding manifold defined in Eq. (29). 4. AFTC on the basis of TDE and adaptive fractional TBSM Previous section was devoted to designing a PFTC scheme which does not rely on fault information. The influence of fault on the wind turbine system is considered as the effect of uncertainty, and no FD system is required. In spite of the fact that its independence from FD information increases its response speed, it needs to be able to address a wide range of faults. For this reason, its sliding gain should be chosen bigger than the upper bound of faults. This guarantees the stability and convergence of the tracking error, and overcomes some limitations such as unavailability of bounds of faults in practical applications. However, large sliding gain can potentially intensify the controller chattering. To overcome the drawbacks of the previous PFTC controller, in this section, an AFTC based on TDE and adaptive fractional TBSM is presented. FD system entails a TDE for detecting, isolating and approximating the unknown uncertainties and faults. Then, the information of the FD system is used to reconfigure the control system. 4.1. Adaptive control law In practice, wind turbines are often subjected to harsh environment with highly turbulent wind fields. There are large fluctuations in aerodynamic forces and moments, which may lead to unexpected failures of turbine components if not handled properly. Performance of the control system highly depends on reliability of the plant model. In wind turbines, nevertheless, the system parameters are usually not completely known due to inherent nonlinearities of the model, unmolded modes, manufacturing and assembling tolerances, and external operating uncertainties. Adaptive control approach is a promising solution which makes the system capable of dealing with various uncertainties by online updating parameters so that the error between the reference and plant output forces get close to zero [42]. Thus, the adaptation law is proposed as follows: (43) Theorem 3 Considering the adaptive control law, Eq. (43), the wind turbine system with the proposed control law is stable and its rotor speed tends to its rated value. Proof: A positive definite Lyapunov function is chosen as: (44) where and are the estimation error of control parameters. Time derivative of is obtained as, (45) Substituting Eq. (28) and Eq. (32) into Eq. (45) yields, (46) If the control law, Eq. (43), is substituted in Eq. (46), will be as follows. (47) After some simplifications and eliminations, Eq. (47) becomes, (48) Based on the descriptions mentioned about the sign of , it can be inferred that is negative definite. Thus, the wind turbine system is stable and the rotor speed converges to its desired value when the adaptive control law, Eq. (43), is applied. 4.2. Fault diagnosis using TDE Abrupt faults such as hydraulic leakage grow fast and eventually make the system uncontrollable. Thus, a mere parameter estimation for the pitch system does not suffice and the fault needs to be detected such that the wind turbine can be shut down while the pitch system is still controllable. Moreover, AFTC relies on fault detection to compensate for the effect of faults. Therefore, for incipient faults that can be accommodated through AFTC schemes, fault detection is of high importance. In this section a fault detection scheme is designed to distinguish faults based on parameter estimation. For sufficiently small time delay value, uncertainty and fault, and , can be regarded as continuous or piecewise continuous functions with the following approximation. (49) Therefore, the approximation for and are considered as, (50) By adding these two approximate functions and replacing their equivalent values from Eq. (49) the following TDE is obtained. (51) This TDE acts as a robust FD observer, which can effectively detect and isolate the actuator faults in the presence of uncertainties. It is noteworthy that the FD system not only must be sensitive against any type of fault, but also must be robust against uncertainties. To ensure this property, a threshold should be chosen, so that when then , and (52) This implies that system is in normal condition and the residual is always smaller than . Properly choosing guarantees the robustness of FD system. It should be noted that when the residual overshoots its corresponding threshold, the fault is detected and isolated. 4.3. AFTC design In this part, an AFTC is proposed based on adaptive fractional order TBSM and TDE. It is assumed that the uncertainties and actuator faults can be lumped in the following form. (53) where is the TDE error. So, Eq. (23) can be rewritten as, (54) where represents the effect of TDE on rotor speed dynamics. Assumption 1 the TDE error has an upper bound, , which seems to be realistic if is sufficiently small. The derivative of sliding surface, Eq. (32), is rewritten as: (55) Then, control law on the basis of time delay control and fractional back-stepping terminal sliding mode is: (56) where is a positive constant. 4.4. Stability analysis To prove the stability of the AFTC, the following positive definite Lyapunov function is considered. (57) Time derivative of Eq. (57) after substituting the control law from Eq. (43), and simplification is obtained as, (58) Introducing sliding surface into Eq. (58) yields, (59) Optimal control gains are derived applying Harmony Search Algorithm (HSA). The objective function of this optimization is chosen as the sum of integral time absolute error (ITAE) of rotor speed and control input rate. For more conformity with reality and to improve optimization procedure, HSA has been linked to FAST and then, optimal parameters are obtained as presented in Table 3. Block diagram of the proposed AFTC is shown in Fig. 4. (60) Table 3. Optimum controller parameters. Parameter Value Parameter Value Download : Download high-res image (286KB) Download : Download full-size image Fig. 4. Block diagram of the proposed AFTC. Sign function is a strong switcher and causes undesirable chattering, which is the fundamental flaw of the conventional sliding mode controller from which both the proposed PFTC and AFTC suffer. Its detrimental effects on the performance of the controller can be overcome by eliminating it through two ways. The first one is to use a continuous function such as which at the same time can cause inaccuracy and detract the robustness of the controller. Second, the best and most efficient approach is to apply supper-twisting sliding mode algorithm which not only eliminates the chattering but also can enhance the accuracy. Hence, the reaching control law is modified as follows [43]: (61) where, (62) The complete stability of the STW algorithm is presented in Ref. [43]. 4.5. Extended-order states and perturbation observer To estimate the time varying nonlinearities and uncertainties, an extended-order observer is designed. It is assumed that both nonlinear terms in Eq. (9) are unknown, then the lumped term comprising all nonlinearities, disturbances, uncertainties and faults is considered as follows: (63) where is the nominal constant gain which is chosen as the mean value of . Then, the system dynamics, Eq. (23), is rewritten as: (64) By defining and and a state variable the mathematical model of the extended order observer is written as follows: (65) By defining , the nonlinear observer is introduced as: (66) where , and are the estimated value of , observer gain and input error of the nonlinear function; is the precision index, and represents the width of the linear area of a nonlinear function. Remark 1 This observer guarantees the finite time error convergence regardless of the control law, which means that the observer and the controller can be designed individually. Remark 2 Fault estimation also can be determined from the following equality: (67) It should be noted that in order to detect and isolate the actuator faults, this fault estimation can be taken into account. Remark 3 In general, PFTC offers fast response compared to AFTC, since it does not rely on fault detection process. However, the proposed AFTC can potentially compensate the fault impact without any delay, which is achieved by the robust FD system, capable of reducing the time delay between the fault occurrence and accommodation. Remark 4 TDE algorithm in this paper can compensate not only the uncertainties in healthy and normal conditions, but also the influence of both uncertainties and faults in faulty conditions. Remark 5 Besides chattering of control signals, in practice the sensor signals are also inextricably intertwined with noise. To eliminate both of these effects, extended-order states and perturbation observer is applied as an effective choice. 5. Simulation results In this section, a set of simulations are conducted to investigate the performance of the proposed controller for both healthy and faulty operating conditions. The controller is designed based on the two-mass model of the wind turbine and is validated on a sophisticated model in FAST simulator. As states in FAST user guide, the pitch actuator dynamics are not included in this model, which means that the blades can follow the reference pitch angle without any time delay. To compensate for this paucity, an additional actuator dynamic block is added to the existing model. For the sake of brevity, exclusively the results of FAST simulation are presented in this paper. Through Turbsim, six wind speed profiles with 15, 18, and 21 m/s mean speed and 5% and 15% turbulence intensity for each case was generated and separately applied to the model. For the most of the simulations, except for the ones with stated wind profiles, the case of 18 m/s mean speed and 15% turbulence intensity is used and also . Faulty condition is simulated with three different faults, including hydraulic leakage, high air content in the oil, and pump wear. To emulate measurement noise, a Gaussian noise with zero mean and given standard deviation is added to the output. Depending on the sensor type and measurement difficulty, the standard deviation of noise varies. The applied standard deviation for the noise of different sensors is presented in Table 4. Table 4. Standard deviation of sensor noise [28]. Fault Standard Deviation generator speed 0:0158 rad/s generator torque 45 Nm pitch angle 0:2 deg In order to get a better overview of the overall performance of the proposed controller, two other FTC-based controllers, namely, feedback linearization (FL) and sliding mode control (SMC), are also designed and implemented for comparison. To evaluate the robustness of the controller and the accuracy of perturbation estimation, the simulated and estimated state values for both healthy and faulty conditions in the presence of turbulent wind fields are presented in Fig. 5. The results for rotor speed and its corresponding estimation error are depicted in Fig. 5.a and b, which clearly show the close compliance of the results and confirm the effectiveness of the estimation method. Furthermore, it is noteworthy that under the influence of wind disturbance and measurement noise, and even after the occurrence of faults, the rotor speed remains bounded, proving the robust property of the proposed control scheme. Perturbation estimation also demonstrates a good agreement with simulated signal, as depicted in Fig. 5.c. Pitch angle for both fault-free and faulty operations are reported in Fig. 5.d. Obviously, after fault occurrence at , the system follows the same trend as the healthy condition, except for a fluctuation after the moment of fault occurrence which is soon compensated. This further highlights the robustness of the control scheme. Download : Download high-res image (822KB) Download : Download full-size image Fig. 5. Results under turbulent wind test. In order to further demonstrate the effectiveness of the state estimation observer, a fit function between estimated and actual rotor speed is calculated by Eq. (68). (68) The obtained value of 96.34% for this function approves validity of the estimation. The Root Mean Square (RMS) Error of rotor speed for the wind turbine with the proposed PFTC and AFTC exposed to various wind profiles is shown in Fig. 6. The results clearly prove the outperformance of the AFTC and this is more evident for higher wind speeds. Download : Download high-res image (144KB) Download : Download full-size image Fig. 6. RMSE of rotor speed with the AFTC and PFTC schemes. Fig. 7 illustrates the generator speed and power output under turbulent wind field. The stable oscillation of the outputs, even after fault occurrence proves the robustness of the proposed controller, against exogenous disturbances and faults. Download : Download high-res image (544KB) Download : Download full-size image Fig. 7. Generator output under turbulent wind test. Furthermore, to evaluate the performance of the controller in terms of rotor velocity and generator power, the normalized integral absolute error is chosen as the performance indices [23]: (69) where represents the reference power. These indices are calculated for the three controllers through FAST simulation and the corresponding results are illustrated in Fig. 8. When the fault occurs, the errors tend to increase, however, with the adaptive TBSM they remain small. Download : Download high-res image (319KB) Download : Download full-size image Fig. 8. Rotor speed and generator power performance indices. Sensitivity of the system against parameter uncertainty also indicates the system robustness. To evaluate the sensitivity of the proposed controller, the simulations are performed for three different parameter sets, representing 10%, 20%, and 30% uncertainty, and in Table 5 the obtained output error on rotor speed is compared with the results of FLC and SMC schemes. Evidently, the proposed controller shows the least sensitivity. Table 5. RMS of rotor speed error for different uncertainties. Controller/uncertainty 10% 20% 30% TBSM 0.3282 0.3297 0.3266 SMC 0.4361 0.4442 0.4697 FLC 1.0763 1.2923 1.6782 As indicated in Table 6, the STD of rotor speed error of the novel TBSM also shows almost no variation under different parameter uncertainties, while for other controllers, this variation is more tangible. Table 6. STD of rotor speed error for different uncertainties. Controller/uncertainty 10% 20% 30% TBSM 0.000523 0.000529 0.000524 SMC 0.000613 0.000634 0.000662 FLC 0.000786 0.000843 0.000891 FD system detects the faults from the residuals when they exceed their predefined values. Here, the residuals are determined based on TDE and illustrated in Fig. 9. Evidently, when the fault occurs, the residuals overshoot their corresponding thresholds, and FD system is able to detect and isolate the faults. It is noteworthy that before , while the model is exposed to wind profile, the residuals remain bounded between their thresholds. Download : Download high-res image (601KB) Download : Download full-size image Fig. 9. Residuals under the effect of faults. Besides maximizing power capture by wind turbines, FTC is also responsible for preventing unexpected mechanical loads in the presence of faults. Fatigue loads acting on the wind turbine components are highly influenced by the controller performance. This means that the performance of the FTC is a determining factor on components life span. For a comprehensive evaluation of the performance of the control system, it is required to evaluate the wind turbine structural dynamics and loading and make sure that they are within their safe ranges. The time series of blade-root out-of-plane and flap-wise moments are calculated and presented in Fig. 10. The results show that the time series embodies various load cycles with different frequencies (combination of excitation and natural frequencies). Download : Download high-res image (619KB) Download : Download full-size image Fig. 10. Blade-root out-of-plane and flap-wise moments for the proposed controller. For the sake of comparison, the structural dynamic loads on the tower are illustrated in Fig. 11. It includes RMS of tower side-to-side and fore-aft bending moments, accelerations and deflections for the turbine with three controllers in the presence of three different faults. It is evident from the results that the proposed AFTC has efficiently reduced the structural loads, compared to the other controllers. The similar trend is also observed for tower acceleration and deflection. Download : Download high-res image (575KB) Download : Download full-size image Fig. 11. RMS of tower deflection, acceleration, and moment for different wind fields. To investigate the performance of the AFTC-TBSM in a variety of perturbations, the faulty turbine system is exposed to various wind fields and the RMS values for tower moments, accelerations and deflections are presented in Fig. 12. The results reveal that different faults can be tolerated effectively through the proposed control scheme in the presence of diverse wind profiles. Download : Download high-res image (842KB) Download : Download full-size image Fig. 12. RMS of tower deflection, acceleration, and moment for different wind fields. 6. Conclusion This paper aimed to present a novel AFTC based on TDE to control the pitch angle of a wind turbine in the presence of faults, uncertainties and disturbances. The proposed AFTC comprises a TDE-based FD system and a combination of back-stepping, terminal sliding mode and fractional order control to increase the robustness. Stability of the closed-loop system was proved by Lyapunov theory. In order to verify the validity of proposed controller, it was applied to the detailed FAST simulator for two distinct cases, i.e. faulty and healthy conditions. Simulations revealed the effectiveness of the proposed AFTC. Overall, compared with the existing schemes, the proposed AFTC possesses some advantages and improvements including, easy implementation of the proposed TDE-based FD system, fast finite time convergence and higher precision due to applying supper-twisting algorithm, compensating uncertainties and faults, and independence from the prior knowledge of the faults. Credit author statement Category 1 Conception and design of study: Mahmood Mazare, Mostafa Taghizadeh, Pegah Ghaf-Ghanbari acquisition of data: Mahmood Mazare Analysis of data: Mahmood Mazare, Mostafa Taghizadeh, Pegah Ghaf-Ghanbari Category 2 Drafting the manuscript: Mahmood Mazare, Mostafa Taghizadeh, Pegah Ghaf-Ghanbari Revising the manuscript: Mahmood Mazare, Pegah Ghaf-Ghanbari Category 3 Approval of the version of the manuscript to be published (the names of all authors must be listed): Mahmood Mazare, Mostafa Taghizadeh, Pegah Ghaf-Ghanbari Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. References [1] A. Azizi, H. Nourisola, S. Shoja-Majidabad Fault tolerant control of wind turbines with an adaptive output feedback sliding mode controller Renew. Energy, 135 (2019), pp. 55-65 View PDFView articleView in ScopusGoogle Scholar [2] Global Wind Report (2019) https://gwec.net/global-wind-report-2019/ Google Scholar [3] A. Wright, L. Fingersh Advanced Control Design for Wind Turbines; Part I: Control Design, Implementation, and Initial Tests (2008) Google Scholar [4] H. Habibi, I. Howard, S. Simani Reliability improvement of wind turbine power generation using model-based fault detection and fault tolerant control: a review Renew. Energy, 135 (2019), pp. 877-896 View PDFView articleView in ScopusGoogle Scholar [5] T. Burton, N. Jenkins, D. Sharpe, E. Bossanyi Wind Energy Handbook (second ed.), Wiley (2011) Google Scholar [6] P.F. Odgaard, J. Stoustrup, M. Kinnaert Fault-tolerant control of wind turbines: a benchmark model IEEE Trans. Contr. Syst. Technol., 21 (4) (2013), pp. 1168-1182 View in ScopusGoogle Scholar [7] J. Lan, R.J. Patton, X. Zhu Fault-tolerant wind turbine pitch control using adaptive sliding mode estimation Renew. Energy, 116 (2018), pp. 219-231 View PDFView articleView in ScopusGoogle Scholar [8] S. Cho, Z. Gao, T. Moan Model-based fault detection, fault isolation and fault-tolerant control of a blade pitch system in floating wind turbines Renew. Energy, 120 (2018), pp. 306-321 View PDFView articleView in ScopusGoogle Scholar [9] G. Noshirvani, J. Askari, A. Fekih Fractional-order fault-tolerant pitch control design for a 2.5 MW wind turbine subject to actuator faults Struct. Contr. Health Monit., 26 (10) (2019), Article e2411 View in ScopusGoogle Scholar [10] M. Van, S.S. Ge, H. Ren Finite time fault tolerant control for robot manipulators using time delay estimation and continuous nonsingular fast terminal sliding mode control IEEE Transact. Cybernet., 47 (7) (2017), pp. 1681-1693 View in ScopusGoogle Scholar [11] S. Ebrahimkhani Robust fractional order sliding mode control of doubly-fed induction generator (DFIG)-based wind turbines ISA (Instrum. Soc. Am.) Trans., 63 (2016), pp. 343-354 View PDFView articleView in ScopusGoogle Scholar [12] Z. Man, A.P. Paplinski, H.R. Wu A robust MIMO terminal sliding mode control scheme for rigid robotic manipulators IEEE Trans. Automat. Contr., 39 (12) (1994), pp. 2464-2469 Google Scholar [13] X. Yu, M. Zhihong Fast terminal sliding-mode control design for nonlinear dynamical systems IEEE Transact. Circ. Syst. I: Fundament. Theor. Appl., 49 (2) (2002), pp. 261-264 View in ScopusGoogle Scholar [14] Y. Feng, X. Yu, Z. Man Non-singular terminal sliding mode control of rigid manipulators Automatica, 38 (12) (2002), pp. 2159-2167 View PDFView articleView in ScopusGoogle Scholar [15] C. Yin, Y. Chen, S.-m. Zhong Fractional-order sliding mode based extremum seeking control of a class of nonlinear systems Automatica, 50 (12) (2014), pp. 3173-3181 View PDFView articleView in ScopusGoogle Scholar [16] C. Yin, B. Stark, Y. Chen, S.-m. Zhong, E. Lau Fractional-order adaptive minimum energy cognitive lighting control strategy for the hybrid lighting system Energy Build., 87 (2015), pp. 176-184 View PDFView articleView in ScopusGoogle Scholar [17] Y. Chen Ubiquitous fractional order controls? IFAC Proceedings Vol., 39 (11) (2006), pp. 481-492 View PDFView articleView in ScopusGoogle Scholar [18] B. Zhang, Y. Pi, Y. Luo Fractional order sliding-mode control based on parameters auto-tuning for velocity control of permanent magnet synchronous motor ISA Trans., 51 (5) (2012), pp. 649-656 View PDFView articleView in ScopusGoogle Scholar [19] Y. Tang, X. Zhang, D. Zhang, G. Zhao, X. Guan Fractional order sliding mode controller design for antilock braking systems Neurocomputing, 111 (2013), pp. 122-130 View PDFView articleCrossRefView in ScopusGoogle Scholar [20] M. Seixas, R. Melício, V. Mendes Offshore wind turbine simulation: multibody drive train. Back-to-back NPC (neutral point clamped) converters. Fractional-order control Energy, 69 (2014), pp. 357-369 View PDFView articleView in ScopusGoogle Scholar [21] C. Wang, C. Wen, Y. Lin Decentralized adaptive backstepping control for a class of interconnected nonlinear systems with unknown actuator failures J. Franklin Inst., 352 (3) (2015), pp. 835-850 View PDFView articleView in ScopusGoogle Scholar [22] A. Chakravarty, C. Mahanta Actuator fault-tolerant control (FTC) design with post-fault transient improvement for application to aircraft control Int. J. Robust Nonlinear Control, 26 (10) (2016), pp. 2049-2074 CrossRefView in ScopusGoogle Scholar [23] Y. Vidal, C. Tutivén, J. Rodellar, L. Acho fault diagnosis and fault-tolerant control of wind turbines via a discrete time controller with a disturbance compensator Energies, 8 (5) (2015) Google Scholar [24] K. Ghanbarpour, F. Bayat, A. Jalilvand Dependable power extraction in wind turbines using model predictive fault tolerant control Int. J. Electr. Power Energy Syst., 118 (2020), p. 105802 View PDFView articleView in ScopusGoogle Scholar [25] M.S. Shaker, A.A. Kraidi Robust fault-tolerant control of wind turbine systems against actuator and sensor faults Arabian J. Sci. Eng., 42 (7) (2017), pp. 3055-3063 CrossRefView in ScopusGoogle Scholar [26] A. Wu, B. Zhao, J. Mao, B. Wu, F. Yu Adaptive active fault-tolerant MPPT control for wind power generation system under partial loss of actuator effectiveness Int. J. Electr. Power Energy Syst., 105 (2019), pp. 660-670 View PDFView articleView in ScopusGoogle Scholar [27] L. Wang, M. Cai, H. Zhang, F. Alsaadi, L. Chen Active fault-tolerant control for wind turbine with simultaneous actuator and sensor faults Complexity (2017), p. 2017 Google Scholar [28] T. Esbensen, C. Sloth Fault Diagnosis and Fault-Tolerant Control of Wind Turbines Aalborg University, Denmark (2009) Google Scholar [29] Y. Ren, L. Li, J. Brindley, L. Jiang Nonlinear PI control for variable pitch wind turbine Contr. Eng. Pract., 50 (2016), pp. 84-94 View PDFView articleView in ScopusGoogle Scholar [30] R. Chaaban, D. Ginsberg, C.-P. Fritzen Structural load analysis of floating wind turbines under blade pitch system faults N. Luo, Y. Vidal, L. Acho (Eds.), Wind Turbine Control and Monitoring, Springer International Publishing, Cham (2014), pp. 301-334 CrossRefView in ScopusGoogle Scholar [31] D. Li, P. Li, W. Cai, Y. Song, H. Chen Adaptive fault-tolerant control of wind turbines with guaranteed transient performance considering active power control of wind farms IEEE Trans. Ind. Electron., 65 (4) (2018), pp. 3275-3285 View in ScopusGoogle Scholar [32] J. Carroll, A. McDonald, D. McMillan Failure rate, repair time and unscheduled O&M cost analysis of offshore wind turbines Wind Energy, 19 (6) (2016), pp. 1107-1119 CrossRefView in ScopusGoogle Scholar [33] L. An, N. Sepehri Hydraulic actuator leakage fault detection using extended kalman filter Int. J. Fluid Power, 6 (1) (2005), pp. 41-51 CrossRefView in ScopusGoogle Scholar [34] I. Podlubny Fractional Differential Equations : an Introduction to Fractional Derivatives, Fractional Differential Equations, to Methods of Their Solution and Some of Their Applications Academic Press, San Diego (1999) Google Scholar [35] Y. Li, Y. Chen, I. Podlubny Stability of fractional-order nonlinear dynamic systems: Lyapunov direct method and generalized Mittag–Leffler stability Comput. Math. Appl., 59 (5) (2010), pp. 1810-1821 View PDFView articleView in ScopusGoogle Scholar [36] N. Aguila-Camacho, M.A. Duarte-Mermoud, J.A. Gallegos Lyapunov functions for fractional order systems Commun. Nonlinear Sci. Numer. Simulat., 19 (9) (2014), pp. 2951-2957 View PDFView articleView in ScopusGoogle Scholar [37] O. Barambones, V. Etxebarria Energy-based approach to sliding composite adaptive control for rigid robots with finite error convergence time Int. J. Contr., 75 (5) (2002), pp. 352-359 View in ScopusGoogle Scholar [38] A. Kumar, K. Stol Simulating Feedback Linearization control of wind turbines using high-order models Wind Energy, 13 (5) (2010), pp. 419-432 CrossRefView in ScopusGoogle Scholar [39] S.C. Thomsen Nonlinear Control of a Wind Turbine Technical University of Denmark, Kongens Lyngby, Denmark (2006), p. 136 Google Scholar [40] M. Mazare, M. Taghizadeh, M.G. Kazemi Optimal hybrid scheme of dynamic neural network and PID controller based on harmony search algorithm to control a PWM-driven pneumatic actuator position J. Vib. Contr., 24 (16) (2017), pp. 3538-3554 Google Scholar [41] M. Mohadeszadeh, H. Delavari Synchronization of uncertain fractional-order hyper-chaotic systems via a novel adaptive interval type-2 fuzzy active sliding mode controller Int. J. Dynam. Contr., 5 (1) (2017), pp. 135-144 CrossRefView in ScopusGoogle Scholar [42] Y. Yuan, J. Tang Adaptive pitch control of wind turbine for load mitigation under structural uncertainties Renew. Energy, 105 (2017), pp. 483-494 View PDFView articleView in ScopusGoogle Scholar [43] J.A. Moreno, M. Osorio A Lyapunov Approach to Second-Order Sliding Mode Controllers and Observers 2008 47th IEEE Conference on Decision and Control (2008), pp. 2856-2861 View in ScopusGoogle Scholar Cited by (31) Pitch angle control of wind turbines using model-free auto-tuned fractional order proportional derivative ATFOPD controller 2024, Computers and Electrical Engineering Show abstract Adaptive output dynamic feedback control for nonaffine pure-feedback time delay system with unknown backlash-like hysteresis 2024, Journal of the Franklin Institute Show abstract Fault-tolerant controller design based on adaptive backstepping for tower cranes with actuator faults 2024, ISA Transactions Show abstract Path following fault-tolerant control of distributed drive autonomous unmanned vehicle via adaptive terminal sliding mode 2024, Journal of the Franklin Institute Show abstract Composite fault reconstruction and fault-tolerant control design for cyber-physical systems: An interval type-2 fuzzy approach 2023, ISA Transactions Show abstract Adaptive neural network fixed-time sliding mode control for trajectory tracking of underwater vehicle 2023, Ocean Engineering Show abstract View all citing articles on Scopus View Abstract © 2021 Elsevier Ltd. All rights reserved. Recommended articles Modeling and experiment validation of a seawater micro hydropower system for marine animal telemetry tag Renewable Energy, Volume 174, 2021, pp. 73-85 Jianjun Wang, Zheng Cui View PDF A study on the influence of schooling patterns on the energy harvest of double undulatory airfoils Renewable Energy, Volume 174, 2021, pp. 674-687 Qiyu Ma, …, Diangui Huang View PDF Sensor fault-tolerant control of DFIG based wind energy conversion systems International Journal of Electrical Power & Energy Systems, Volume 117, 2020, Article 105563 K.S. Xiahou, …, Q.H. Wu View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 26 Captures Readers: 10 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply."

Paper 2:
- APA Citation: Li, C., Li, Z., & Shen, W. (2023). A self-organizing map aided fault diagnosis and self-healing scheme for wireless sensor networks in precision agriculture. IEEE Sensors Journal, 23(10), 10035-10044.
  Main Objective: To develop a novel self-organizing map (SOM)-based fault diagnosis and self-healing scheme for wireless sensor networks in precision agriculture applications.
  Study Location: Unspecified
  Data Sources: Simulation data
  Technologies Used: Self-organizing maps (SOMs), Fault diagnosis, Self-healing mechanisms, Wireless sensor networks (WSNs)
  Key Findings: The proposed SOM-based fault diagnosis and self-healing scheme effectively detects and diagnoses faults in wireless sensor networks using self-organizing maps (SOMs). The scheme utilizes adaptive recovery mechanisms to restore the network's functionality and performance, improving resilience and reliability. Simulations demonstrate the superiority of the proposed approach compared to traditional methods, highlighting its potential for real-world automated irrigation systems.
  Extract 1: "The proposed SOM-based fault diagnosis and self-healing scheme outperforms traditional methods both in terms of accuracy and efficiency. It provides an effective and practical solution to handle complex and dynamic fault scenarios in WSNs, improving the overall reliability and stability of the network."
  Extract 2: "The SOM-based approach enables real-time fault detection and adaptive recovery mechanisms, allowing the automated irrigation system to quickly respond to faults and maintain optimal performance with minimal downtime or data loss."
  Limitations: The paper does not directly evaluate the proposed approach in the context of real-world automated irrigation systems. However, the simulation results provide strong evidence of the potential of the approach in this domain.
  Relevance Evaluation: This paper is highly relevant to the point of focus on self-healing capabilities in automated irrigation systems. It introduces a novel SOM-based approach for fault diagnosis and self-healing in WSNs, which can directly apply to the context of automated irrigation systems. The paper demonstrates the effectiveness of the proposed approach through extensive simulations, highlighting its potential for improving the resilience and self-healing abilities of automated irrigation systems.
  Relevance Score: 0.9
  Inline Citation: (Li et al., 2023)
  Explanation: The referenced paper proposes a novel self-organizing map (SOM) aided fault diagnosis and self-healing scheme for wireless sensor networks (WSNs) in precision agriculture applications. The proposed scheme utilizes SOM for real-time fault detection and adaptive recovery mechanisms to enhance the resilience and reliability of WSNs.

 Full Text: >

Paper 3:
- APA Citation: Author, A. A. (Year). Title of paper. Journal Title, Volume(Issue), Pages.
  Main Objective: To investigate the use of AI-driven self-healing mechanisms for enhancing resilience and fault tolerance in automated irrigation systems.
  Study Location: Unspecified
  Data Sources: Literature review
  Technologies Used: Reinforcement learning, Bayesian networks, self-organizing maps
  Key Findings: Self-healing mechanisms can improve the resilience and fault tolerance of automated irrigation systems by enabling them to detect, diagnose, and recover from faults autonomously. AI-driven techniques such as reinforcement learning, Bayesian networks, and self-organizing maps can be used to implement self-healing capabilities in automated irrigation systems.
  Extract 1: "Self-healing systems have the ability to detect, diagnose, and recover from faults without human intervention. This can be achieved by using techniques such as reinforcement learning, Bayesian networks, or self-organizing maps."
  Extract 2: "Self-healing capabilities can improve the resilience and fault tolerance of automated irrigation systems, making them more reliable and efficient."
  Limitations: The study focuses primarily on the theoretical aspects of self-healing mechanisms and does not provide empirical evidence from real-world implementations.
  Relevance Evaluation: This study is highly relevant to the point of focus on self-healing capabilities in automated irrigation systems. It provides valuable insights into the application of AI-driven techniques for achieving resilience and fault tolerance. The study contributes to the understanding of how self-healing mechanisms can improve the reliability and efficiency of automated irrigation systems.
  Relevance Score: 0.9
  Inline Citation: (Author, Year)
  Explanation: The study investigates the use of self-healing mechanisms in automated irrigation systems to enhance resilience and fault tolerance. It explores the potential of reinforcement learning, Bayesian networks, and self-organizing maps for self-healing capabilities, aiming to enable systems to detect, diagnose, and recover from faults autonomously.

 Full Text: >
Web Store Add shortcut Name URL Customize Chrome

Paper 4:
- APA Citation: Elnadi, Y., Refaat, T., Daoud, R., & Amer, H. (2021). Fault Tolerance for Access Point Failures in Smart Greenhouse Networked Control Systems. IEEE EUROCON 2021 - 19th International Conference on Smart Technologies.
  Main Objective: To investigate fault tolerance in automated irrigation systems, particularly focusing on self-healing capabilities that can detect, diagnose, and recover from faults autonomously.
  Study Location: Unspecified
  Data Sources: Not mentioned in the provided context
  Technologies Used: Reinforcement learning, Bayesian networks, self-organizing maps
  Key Findings: Self-healing mechanisms can enhance the resilience and reliability of automated irrigation systems by detecting, diagnosing, and recovering from faults without human intervention. Techniques such as reinforcement learning, Bayesian networks, and self-organizing maps can be employed to implement self-healing capabilities.
  Extract 1: "Incorporating AI-driven self-healing mechanisms that can detect, diagnose, and recover from faults without human intervention, using techniques like reinforcement learning, Bayesian networks, or self-organizing maps"
  Extract 2: The authors propose using "reinforcement learning, Bayesian networks, or self-organizing maps" to achieve self-healing capabilities in automated irrigation systems.
  Limitations: The paper does not provide empirical results or case studies to demonstrate the effectiveness of the proposed self-healing mechanisms. It is primarily focused on theoretical concepts and approaches.
  Relevance Evaluation: This paper is highly relevant to the point of discussion on self-healing capabilities in automated irrigation systems. It provides insights into specific techniques and approaches that can be used to implement self-healing mechanisms, which is a key aspect of enhancing the resilience and reliability of automated irrigation systems. The paper aligns well with the intention of the literature review to explore innovative strategies for fault tolerance and autonomous irrigation management.
  Relevance Score: 0.9
  Inline Citation: (Elnadi et al., 2021)
  Explanation: The paper investigates fault tolerance in automated irrigation systems, with a focus on self-healing mechanisms that can detect, diagnose, and recover from faults without human intervention. It proposes using techniques like reinforcement learning, Bayesian networks, or self-organizing maps to achieve this.

 Full Text: >
"IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Conferences >IEEE EUROCON 2021 - 19th Inte... Fault Tolerance for Access Point Failures in Smart Greenhouse Networked Control Systems Publisher: IEEE Cite This PDF Yasmine Elnadi; Tarek Refaat; Ramez Daoud; Hassanein Amer All Authors 1 Cites in Paper 98 Full Text Views Abstract Document Sections I. Introduction II. Related Work III. System Architecture IV. Simulation Results V. Conclusion Authors Figures References Citations Keywords Metrics Abstract: Greenhouses offer the ability to cultivate various crops in what would otherwise be harsh and unfavorable environments. Networked Control Systems (NCSs) can be utilized within greenhouses, to monitor and control various metrics, such as temperature, humidity, and soil moisture. While the utilization of wireless sensors offers a high degree of flexibility, it adds the risk of Access Point (AP) failure. This paper investigates the issue of AP failure in a Greenhouse NCS and proposes a fault-tolerant model. Single as well as double AP failures are considered. All scenarios in the fault-tolerant model are simulated using the Riverbed Modeler and system performance is evaluated in terms of the Packet Loss Rate (PLR). It is shown that, for all possible AP failures in the fault model, the proposed fault-tolerant architecture succeeds in meeting system requirements. Published in: IEEE EUROCON 2021 - 19th International Conference on Smart Technologies Date of Conference: 06-08 July 2021 Date Added to IEEE Xplore: 15 September 2021 ISBN Information: DOI: 10.1109/EUROCON52738.2021.9535545 Publisher: IEEE Conference Location: Lviv, Ukraine SECTION I. Introduction Greenhouses provide a controlled environment to facilitate crop cultivation. Temperature, humidity, light intensity, and ventilation are just an example of the variables that require regular monitoring and regulation, to maximize environment suitability for different plant species. Greenhouse sizes can vary significantly, ranging from small backyard-sized to one that can span multiple hectares. Monitoring and regulation of the various factors mentioned earlier, can determine both the efficacy and efficiency of the greenhouse. As such, smart greenhouses are a topic of interest for precision agriculture [1]. Various sensor nodes can replace manual monitoring of the environment conditions, such as temperature, humidity, and light conditions [2], [3]. Incorporating Internet-of-Things (IoT) capabilities offers the ability to remotely access, store and analyze sensor data [4]-[6]. IoT capabilities can also offer remote calibration/adjustment of the environment conditions [3], [7]. Based on the sensor data, adjustments can be made, such as remotely adjusting actuator nodes to, for example, fine-tune fans and irrigation valves [8], [9]. Fault tolerance is another research aspect that can drastically improve smart greenhouse efficiency. A fault tolerant NCS can increase reliability and yield of a greenhouse [2]. Previous studies have investigated the application of Wireless Sensor Networks (WSN) and Networked Control Systems for precision agriculture systems. One such case focused on a hierarchical Networked Control System (NCS) of sensors, controllers, and actuators, in two greenhouses [2]. The study also investigated and demonstrated fault tolerance at the controller level. In [10], an in-depth analysis of the fault tolerant model presented in [2] was investigated proving system reliability and availability during controller failures. It further extended the greenhouse NCS to incorporate a layer of IoT capabilities, connecting the NCS to a cloud-side backend through the Internet for data analysis and remote controlling [10]. This paper will study an Ethernet/Wi-Fi-based, smart greenhouse distributed NCS, in terms of fault tolerance at the Wi-Fi Access Point (AP) level [11], [12]. The smart greenhouse NCS consists of a varied and large number of sensor nodes to sample the greenhouse environment; a controller to process the sensor data and issue control commands; actuators to enact the control commands and adjust the environment accordingly. The Wi-Fi APs in the proposed model are the crucial bottleneck where all sensor data gather prior to being forwarded (via Switched Ethernet) to the controller. As such, it is of importance to study the fault tolerance at the AP level. It will be shown that the proposed architecture can withstand single as well as double AP failures. The rest of the paper is organized as follows. In Section II, related works are presented. Section III outlines the NCS architecture, the fault model, proposed failure handling, and the scenarios to be simulated. Finally, Section IV presents the simulation results and Section V concludes this paper. SECTION II. Related Work Greenhouse monitoring and regulatory systems fall under the umbrella of Precision Agriculture systems. There are various studies that have investigated such systems. This section offers a summary of some of the most relevant studies. Reference [13] proposed a solution to monitor a small to medium size greenhouse based on GSM and RF technology. Monitoring nodes and sink nodes were designed using RF modules, Huawei wireless modules and Atmega16A. Another study was conducted in [14] regarding the impact of environmental changes on flowers, by proposing a greenhouse monitoring system. The system architecture utilized ZigBee technology to transmit sensor data to a controller, then transferring the information over USB, for display on a graphical interface [15]. In [16], a low-cost and low-power WSN architecture is suggested for greenhouse applications. Greenhouse WSNs were also studied in [17], [18]. One of the most and recent advancements of greenhouse agriculture is its integration with a layer of IoT. In [6], a WSN model was implemented to monitor a greenhouse. The greenhouse has a group of sensor nodes that measure environmental changes and send their measured data to the greenhouse coordinator. The greenhouse coordinator is connected physically to the Internet gateway. Similarly, in [1], data collected by the controller is analyzed and stored in a cloud database, which the user can easily access remotely. In [19], a monitoring system using a low-cost IoT platform Node MCU module, was proposed. The design aims to collect all the sensor data, send it to the Node MCU module for processing, and then send its control commands to the actuators inside the greenhouse. Additionally, it has a wireless Internet connection to send the collected environmental parameters to the farmers smartphones for remote monitoring. As for a remotely controlled greenhouse, an IoT application for smart agriculture was developed in [7] from which the environmental changes inside the greenhouse are remotely monitored and controlled. From the collected data, proper control actions are taken for greenhouse windows and doors. Similarly, in [4], an IoT layer is deployed inside a greenhouse through its connection to a controller and internet gateway over ZigBee. This greenhouse has several distributed sensors and actuator nodes. It sends its information to the user presenting them on a GUI and receiving the control commands to be executed inside the greenhouse. In [8], a system architecture for a vegetable greenhouse consisting of four modules, was proposed. The first module is the data collection module using different sensors and the second module is the control module using different actuators. The third module is the control core module that is responsible for collecting the sensor data wirelessly, forwarding data to the gateway, and then analyzing the data to take the proper control commands to be executed by the actuators. The fourth module is the power module which is used to power up the system using solar energy. Water valves for irrigation were controlled in [5] through the developing of a wireless moisture sensor network. The soil moisture sensors are continually monitoring the soil and accordingly send their collected data to the controller from which water valves are turned on or off. A ZigBee transceiver is used to send these readings to a gateway, and the gateway is responsible for transmitting the data using Wi-Fi or GSM modules to the central unit where the data is displayed to the user on any Internet-enabled device. SECTION III. System Architecture A. Smart Greenhouse Description In this paper, an existing greenhouse architecture is studied in the context of building a reliable Networked Control System (NCS) and developing a novel fault-tolerant model to protect the system from AP failures. The dimension of the greenhouse is 200m×40m, and it is divided into five cells with identical dimensions (40m × 40m). Each cell has 40 sensor nodes that are evenly distributed. The total number of sensor nodes inside the greenhouse is 200. This greenhouse architecture is actually a Networked Control System (NCS) with smart sensors, actuators and a controller. Each cell in the greenhouse has a group of sensor nodes and actuators that are distributed within the cell. The sensor node is a microcontroller that hosts 9 different sensors with different sampling data rates. The difference in the sampling rates depends on how critical the measured parameter is. These sensors measure different environmental parameters which are temperature, humidity, light, dew, salinity, soil moisture and pesticide level. Finally, the most critical sensors are fire and CO2 sensors [2]. Table I shows the different sampling rates for the used sensors. TABLE I. Sensors Sampling Rates The sensor nodes microcontroller has a Wi-Fi interface so that data can be collected and sent wirelessly to a local AP within the greenhouse cell which transfers these collected data to a centralized controller. The wireless protocol is IEEE 802.11n and the frequency band is 5GHz. Due to the abundance of frequency channels, each cell has its own non-interfering channel. In addition, every cell has 4 cameras placed at its corners that capture live video with a transmission rate of 12 FPS and 5MP resolution. These cameras are connected to the controller of the greenhouse via Ethernet cable to reduce the interference between the high-rate data traffic and the sensor traffic. There are four actuators in each cell in the greenhouse which are used to control lighting, irrigation, fans and curtains. Also, there is a fire extinguisher actuator for the whole greenhouse. They are all connected to the controller via Ethernet. Each actuator performs its action with a different rate, based on the criticality of the action. All the actuators take actions every 30 seconds except the fire actuator which takes its action every 1 second. Every cell in the greenhouse has its own AP which relays the collected data from the sensor nodes to the controller with a 10mw transmit power (see Fig. 1 and Fig. 2). Then the controller processes these data locally and sends its control commands to the actuators in the greenhouse [2]. Fig. 1. Sensor nodes, cameras, and APs in a single greenhouse cell. Show All Fig. 2. Greenhouse cells with Wi-Fi APs, connected via Switched Ethernet to the controller. Show All B. Fault Model Access points are crucial because they are the only link between the sensors and the controller. Assume AP four in cell four has failed, part of the data at the controller will be missing and this might lead to wrong control actions at the actuators. The controller needs to get the entire data to take proper control actions in a timely manner. This is the aim of this research paper, to study AP failures: single AP failures, double adjacent AP failures, and double non-adjacent AP failures. Fig. 3 illustrates one of the main double adjacent AP failure cases. A fault-tolerant model is proposed to mitigate these failures achieving proper data management while maintaining minimum packet loss. Fig. 3. Greenhouse cells with failed APs in cells four and five. Show All C. Fault Handling In case of AP failures, two methods were studied for transferring the wireless data sent from the sensor nodes in the failed cell to the controller. The first method is for the sensors’ data to be automatically redirected to the nearest operational AP. For example, if cell one has an AP failure, all the collected data from the sensors will be automatically redirected to AP two in cell two because it is the nearest operational one. The second method is to equally distribute the sensors’ data of the failed cell between two working APs. For instance, if AP three in cell three failed, the sensor data will be equally distributed between AP two and four in cells two and four, respectively. Since there are no obstacles inside the greenhouse, the communication model will be assumed to be the free space model. While it may be ‘indoor’ operation, the environment inside the greenhouse can be considered equivalent to an outdoor setting, with line-of-sight between all nodes. In order to validate and test the performance of the wireless sensor network inside the greenhouse in case of any AP failures, four different simulation scenarios were studied to cover all the expected situations that might occur during the greenhouse operation. These scenarios are the fault-free scenario, single AP failure scenarios, double adjacent AP failure scenarios and double non-adjacent AP failure scenarios. D. Simulation Scenarios Fault-free scenario: In this scenario, all five APs in the greenhouse are functioning properly. The sensor nodes send their data wirelessly to their APs and then the APs relay the collected data to the controller for processing and taking the proper control decision by sending commands to the appropriate actuators. Single AP failure scenarios: In these scenarios, system performance was tested during the failure of any of the five APs inside the greenhouse. There are five scenarios where one AP fails at a time. The failure might occur to AP one in cell one or AP two in cell two and so on. Certain scenarios were chosen to be simulated which represent all five cases. These scenarios represent a failure occurring at one of the edge cells of the greenhouse or a failure occurring in one of the middle cells. Table II shows all five scenarios while Table III shows the simulated scenarios. TABLE II. All Expected Single AP Failure Scenarios TABLE III. Simulated Scenarios with a Single AP Failure Double adjacent AP failure scenarios: In these scenarios, two adjacent APs fail simultaneously. Table IV below presents all possible combinations of double adjacent AP failures. Fig. 4 also shows the data handling in the case of cells four and five failing. Fig. 4. Data handling for failed APs in cells four and five. Show All TABLE IV. Double Adjacent AP Failure Scenarios Table V shows the simulated scenarios. The scenario with failed APs in cells two and three is identical to the one with failed APs in cells three and four. Similarly, the scenario with failed APs in cells four and five is identical to the one with failed APs in cells one and two. TABLE V. Simulated Scenarios for Double Adjacent AP Failures Double non-adjacent AP failure scenarios: In these scenarios, there are two APs simultaneously experiencing a failure. These two APs are non-adjacent and separated either by one working AP, two working APs or three working APs. It is important to have at least one working AP adjacent to any of the failed APs to achieve efficient data transfer. Table VI shows all the possible combinations for these failures. TABLE VI. Double Non-Adjacent AP Failure Scenarios Double non-adjacent AP failure (separated by one working AP): In this case, there are two mirror scenarios; the first one has failed APs in cells one and three while the other one has failed APs in cells three and five. Only the second one is simulated along with another scenario with failed APs in cells two and four. Table VII shows the simulated scenarios. Double non-adjacent AP failure (separated by two working APs): The scenario with failures in APs one and four is similar to the one with failures in APs two and five. Table VIII shows the simulated scenario for this case. Double non-adjacent AP failure (separated by three working APs): There is only one scenario where two nonadjacent APs failed and separated by three functioning APs, namely when APs one and five fail simultaneously. TABLE VII. Simulated Scenarios for Two Non-Adjacent AP Failures Separated by One Working AP TABLE VIII. Simulated Scenario for Two Non-Adjacent AP Failures Separated by One Working AP Since it is a free space environment, the failed nonadjacent APs being separated by one, two, or three working APs, can be represented by one scenario: Failures in cells one and three. As such, Table IX presents a set of scenarios that comprehensively cover all possible single and double AP failures. TABLE IX. List of All Simulated Scenarios E. Performance Evaluation Metric In order to evaluate system performance, the Packet Loss Rate (PLR) will be the metric used in this research. According to [20], the PLR should not exceed 2%. Packet loss means that some data will be dropped during the transmission. This can make the controller take incorrect control actions due to the missing sensor data or, alternatively, not take the appropriate actions [10]. SECTION IV. Simulation Results For all scenarios, the simulations were performed using Riverbed Modeler simulation tool [21]. If the PLR is ≤2%, this would be an indication that the performance of the system is satisfactory. In order to calculate the PLR, the average wireless data received from all sensor nodes to the controller, is calculated. As mentioned in Table I, sensor nodes have three different sampling rates. Next, it is shown how the average expected data received at the controller, is calculated. Based on the varying sampling rates of the different sensor nodes, the periodicity of the entire system is 30 seconds. The packet loss and average data received are calculated within the 30 seconds. The number of sensor nodes inside the greenhouse is 200. In 30 seconds: (30/5) ×1×200 + (30/1) ×2×200 + (30/30) ×6×200 =12000 + 1200 + 1200 = 14400 Bytes Hence, 14400/30 sec = 480 Bytes/sec Therefore, the expected average data received at the controller is 480 Bytes/sec. Then by applying a confidence analysis on the received data, the packet loss rate (PLR) can be calculated as in [22]. PLR= N tx − N rx N tx ×100% (1) View Source where N tx and N rx , are the total number of sent and received packets, respectively. In the fault free scenario, Riverbed simulations indicate that the PLR is zero which means that the packets sent from the sensor nodes to the controller are received entirely without any losses. Table X shows that, during the failure of AP two, the transmitted data from sensors to controller can be either sent to AP one or be equally distributed between APs one and three. It is obvious from this Table that either distributing the collected data between two working APs or redirecting them to only one AP, maintain a low PLR and achieve successful transmission (PLR is below the 2% threshold value). When APs four and five fail, the collected data was automatically redirected as follows. Cell four sent its data to cell two and cell five sent its data to cell three. The PLR was less than 2% and the scenario was successful. Finally, Table XI shows all the proposed scenarios with their corresponding PLR. The PLR (%) [µ−Δ, µ+Δ] corresponds to the range calculated after a 95% confidence analysis is performed, for each scenario, where µ is the mean PLR experienced in terms of data received by the controller, ±Δ (the PLR confidence range, above and below the mean). TABLE X. PLR for the Same Scenario with Different Data Handling TABLE XI. PLR for All Simulated Scenarios Table XI shows a summary of the results obtained from all simulated scenarios. It is clear that the PLR for all scenarios is below the 2% threshold value. This proves that this fault-tolerant greenhouse NCS succeeded in meeting system requirements. The situation where one cell can carry its own load and take over the load of another failed cell, has been demonstrated successfully. Furthermore, Riverbed simulations have shown that a cell can carry the load of not only its direct neighbor, but instead, that of one cell farther. In all simulations, it was demonstrated that all PLR values are far below the 2% threshold, with 95% confidence. SECTION V. Conclusion Smart Greenhouses embrace the Internet-of-Things, and capitalize on technological advances to monitor, regulate, and control their internal environment variables. Through on and off-site (remote) control, a Networked Control System (NCS) can greatly improve the operating efficiency and yield of a smart greenhouse. This paper investigated a Greenhouse NCS composed of Wi-Fi sensors and access points, sampling various environment stimuli. The sensor data is forwarded via the access points over Switched Ethernet, to a controller, which, after processing, sends actuation decisions to wired actuators. The model also includes various monitoring cameras, that transmit their feed to the controller over the network. The study focused on the aspect of fault tolerance at the access point level, being the main rendezvous point for all sensor data. A fault model was presented, focusing on single and double access point failure, along with a scheme to handle such failures. Using Riverbed Modeler, simulations showed that the system can effectively tolerate up to two access points failures while maintaining an acceptable packet loss rate (PLR). Authors Figures References Citations Keywords Metrics More Like This Communication and control co-design for wireless sensor networked control systems Proceeding of the 11th World Congress on Intelligent Control and Automation Published: 2014 Design of networked control system based on wireless sensor networks 2009 International Conference on Information and Automation Published: 2009 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."

Paper 5:
- APA Citation: (Effah, O. T., Thiare, O., & Wyglinski, A. M. (2023). A tutorial on agricultural IoT: Fundamental concepts, architectures, routing, and optimization. IoT, 4(3), 265-318.)
  Main Objective: To provide a comprehensive and critical evaluation of the current state of the art in real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies.
  Study Location: None
  Data Sources: None
  Technologies Used: reinforcement learning, Bayesian networks, or self-organizing maps
  Key Findings: The paper presents an in-depth contextualized tutorial on Agricultural IoT (Agri-IoT), covering the fundamental concepts, assessment of routing architectures and protocols, and performance optimization techniques via a systematic survey and synthesis of the related literature.
  Extract 1: 
  Extract 2: 
  Limitations: None
  Relevance Evaluation: Relevant: The explanation directly addresses the requirements of self-healing capabilities for the routing protocol in precision irrigation management.
  Relevance Score: 0.9
  Inline Citation: (Author, Year)
  Explanation: Self-healing capabilities: Incorporating AI-driven self-healing mechanisms that can detect, diagnose, and recover from faults without human intervention, using techniques like reinforcement learning, Bayesian networks, or self-organizing maps.

 Full Text: >
"This website uses cookies We use cookies to personalise content and ads, to provide social media features and to analyse our traffic. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you’ve provided to them or that they’ve collected from your use of their services. Consent Selection Necessary Preferences Statistics Marketing Show details                 Deny Allow selection Allow all   Journals Topics Information Author Services Initiatives About Sign In / Sign Up Submit   Search for Articles: IoT All Article Types Advanced   Journals IoT Volume 4 Issue 3 10.3390/iot4030014 Submit to this Journal Review for this Journal Propose a Special Issue Article Menu Academic Editors Antonio Cano-Ortega Francisco Sánchez-Sutil Subscribe SciFeed Recommended Articles Related Info Link More by Authors Links Article Views 1915 Citations 2 Table of Contents Abstract Introduction and Tutorial Contributions The Agri-IoT Ecosystem Design and Implementation of Agri-IoT Networks Unique Characteristics and Challenges of WSN Sublayer of Agri-IoT State of the Art on Routing Protocols for WSN-Based Agri-IoT Applications State of the Art on FM Techniques for Classic WSN Sublayer of IoT State of the Art on Real-World, Canon WSN-Based Agri-IoT Testbed Solutions Case Study: Cluster-Based Agri-IoT (CA-IoT) for Precision Irrigation Design of WSN-Specific CA-IoT Routing Protocol Open Issues and Future Works: Cluster-Based WSN-Specific Agri-IoT Networks Conclusion and Future Works Author Contributions Funding Data Availability Statement Conflicts of Interest Abbreviations References share Share announcement Help format_quote Cite question_answer Discuss in SciProfiles thumb_up Endorse textsms Comment first_page settings Order Article Reprints Open AccessReview A Tutorial on Agricultural IoT: Fundamental Concepts, Architectures, Routing, and Optimization by Emmanuel Effah 1,*,†, Ousmane Thiare 2,† and Alexander M. Wyglinski 3,† 1 Computer Science and Engineering Department, University of Mines and Technology, Tarkwa P.O. Box 237, Ghana 2 Department of Informatics, Gaston Berger University, Saint-Louis PB 234, Senegal 3 Robotics Engineering Department, Worcester Polytechnic Institute, Worcester, MA 01609, USA * Author to whom correspondence should be addressed. † These authors contributed equally to this work. IoT 2023, 4(3), 265-318; https://doi.org/10.3390/iot4030014 Submission received: 15 June 2023 / Revised: 12 July 2023 / Accepted: 17 July 2023 / Published: 27 July 2023 (This article belongs to the Topic IoT for Energy Management Systems and Smart Cities) Download keyboard_arrow_down     Browse Figures Versions Notes Abstract This paper presents an in-depth contextualized tutorial on Agricultural IoT (Agri-IoT), covering the fundamental concepts, assessment of routing architectures and protocols, and performance optimization techniques via a systematic survey and synthesis of the related literature. The negative impacts of climate change and the increasing global population on food security and unemployment threats have motivated the adoption of the wireless sensor network (WSN)-based Agri-IoT as an indispensable underlying technology in precision agriculture and greenhouses to improve food production capacities and quality. However, most related Agri-IoT testbed solutions have failed to achieve their performance expectations due to the lack of an in-depth and contextualized reference tutorial that provides a holistic overview of communication technologies, routing architectures, and performance optimization modalities based on users’ expectations. Thus, although IoT applications are founded on a common idea, each use case (e.g., Agri-IoT) varies based on the specific performance and user expectations as well as technological, architectural, and deployment requirements. Likewise, the agricultural setting is a unique and hostile area where conventional IoT technologies do not apply, hence the need for this tutorial. Consequently, this tutorial addresses these via the following contributions: (1) a systematic overview of the fundamental concepts, technologies, and architectural standards of WSN-based Agri-IoT, (2) an evaluation of the technical design requirements of a robust, location-independent, and affordable Agri-IoT, (3) a comprehensive survey of the benchmarking fault-tolerance techniques, communication standards, routing and medium access control (MAC) protocols, and WSN-based Agri-IoT testbed solutions, and (4) an in-depth case study on how to design a self-healing, energy-efficient, affordable, adaptive, stable, autonomous, and cluster-based WSN-specific Agri-IoT from a proposed taxonomy of multi-objective optimization (MOO) metrics that can guarantee an optimized network performance. Furthermore, this tutorial established new taxonomies of faults, architectural layers, and MOO metrics for cluster-based Agri-IoT (CA-IoT) networks and a three-tier objective framework with remedial measures for designing an efficient associated supervisory protocol for cluster-based Agri-IoT networks. Keywords: Bluetooth Low-Energy (BLE); cluster-based Agricultural IoT (CA-IoT); fault management (FM); multi-objective optimization (MOO); wireless sensor network-based Agricultural IoT (WSN-based Agri-IoT) 1. Introduction and Tutorial Contributions Currently, agriculture is the world’s largest business, employing over one-third of the economically active global population and over 70% of the economically active population in Africa [1,2]. The impacts of high population growth rates and climate change-induced drought (according to Figure 1) on food security, unemployment threats and reduced crop quantity/quality make smart Agricultural Internet-of-Things technology (Agri-IoT) via precision farming and greenhouses the most promising remedy. However, the existing benchmarking Agri-IoT solutions can only be acquired, deployed, and managed by farmers with sufficient financial resources, an electricity grid, Wi-Fi/cellular coverage, and technical expertise in IoT, which is generally not the case in Ghana and Sub-Saharan Africa. These call for a paradigm shift in farming techniques, and the most promising game-changers are precision farming and greenhouses whose underlying technology is a robust, affordable, autonomous, and optimized, innovative WSN-based Agri-IoT [3] that satisfies the critical design expectations presented in Figure 2. Figure 1. Seasonal failure probability-2014 [4] depicting the extent of climate change impact on Africa’s farmlands. Figure 2. Generalized design expectations of WSN-based Agri-IoT technology. Although few surveys and tutorials have been authored on this subject, they present mere classifications of communications trends on classical IoT [2,5,6,7,8] without any context-specific technical considerations of the critical design expectations in Figure 2. For instance, the authors in [2,6,7] examined IoT’s communication infrastructure, platforms, standards, development trends, and possible network solutions in agriculture. Similarly, the roles of industrial IoT (thus, identification-based IoT (example, RFID [6], WSN [9], QR codes [5], barcodes) and communication-based IoT (example, ZigBee [5], Z-wave [6], MQTT [5,6], LoRa [10], SigFox [11], BLE [12], Li-Fi [5], Wi-Fi [13], Near-Field Communication (NFC) [5], and power line area network) were reviewed in terms of current research trends, applications, and main challenges in [5]. Although RFID tags and WSNs have similar data acquisition capacities, the authors concluded that WSN technology is more energy-efficient and suitable for Agri-IoT than the costly RFID technologies [5]. Overall, Agri-IoT technology has not yielded its intended paradigm transformation in the agricultural sector due to several technical challenges that have not received adequate contextual research considerations [14]: The agricultural setting is a unique area where conventional IoT technologies do not apply. Existing Agri-IoT solutions are location-restricted because they are mostly based on Wi-Fi or cellular communication technologies and electricity grids with constrained coverages in Africa. A typical African agricultural setting lacks access to reliable electricity and the Internet for cellular/Wi-Fi-based technologies, and the intended users (farmers) of Agri-IoT technology are low-income earners with limited technological expertise. Common Agri-IoT applications mainly utilize architecture-restricted, high-resource-demanding routing techniques (e.g., routing over low-power and lossy networks protocol (RPL)) and communication standards (e.g., 4G, 5G, ZigBee, LoRa, Wi-FI, and long-term evolution (LTE)) [15], which are difficult to access in typical African farms. Consequently, Agri-IoT users in Africa expect a context-relevant solution that is affordable, simple to deploy and operate by non-experts, location-unrestricted, supportive of large-scale farm management, and based on freely available technologies that do not require licensing. Thus, they are unlike popular IoT use cases such as medical, vehicular, and industrial IoT, whose designs are mainly affected by critical factors including security, stable connectivity, and interference, respectively, Agri-IoT is compelled to drive on affordable battery-powered SNs, which make architecture, low-power communication technology, power optimization, cost, fault tolerance, multihop routing, scalability, and environmental impact critical design factors in order to address its resource or deployment-induced challenges [12,16,17]. High susceptibility to faults and failures: Agri-IoT networks are vulnerable to faults and failures since the resource-constrained SNs are densely deployed in hostile environments to autonomously operate via a network supervisory protocol with limited post-deployment maintenance services. This supervisory protocol must incorporate sufficient power optimization, auto-fault management (FM), and self-adaptability techniques in order to achieve the desired performance expectation. Due to the lack of an in-depth and context-relevant tutorial that bridges the gap between theoretical taxonomies and real-world designs, most canon Agri-IoT testbed solutions, such as those authored in [1,10,11,17,18,19,20], suffered abrupt failures during outdoor deployments. Agri-IoT technology lacks comprehensive context-based synthesis from SN design to field deployment. The power- and resource-constrained SNs that form the WSN-based Agri-IoT network in the aforementioned context require limited data transmission rates, computational capabilities, memory capacities, communication distance, and operational stability. Consequently, the associated routing protocol [9,12,17,21], communication technology, and routing architecture [22,23,24] must support mechanisms that ensure packet size and communication distance moderation [16], efficient channel access management (CAM), and SN’s tasks management. It is not a mere application of conventional IoT to a farm, as many authors attempted [1,10,11,12,17,18,19,20,23,25,26], which lacked application-specific requirements such as dense network inter-connectivity, higher information perceptibility, comprehensive intelligence services, remote monitoring, smart decision making, and the execution of precise control/actuation actions on the farm. Superficial consideration of desired communication technologies of Agri-IoT without considering the cluster-based architecture: To date, Agri-IoT-related surveys and tutorials focused on high-power-demanding communication technologies (Wi-Fi and cellular-based technologies), the centralized architecture-constrained ZigBee standard, and the operation principles of conventional IoT as authored in [1,10,11,14,18,19] without an in-depth consideration of the unique case of Agri-IoT. It is well established that the cluster-based architecture is the best candidate for Agri-IoT application [12,16,17,24]; however, there are no systematic evaluations to cement this fact. For instance, most benchmarking WSN-based IoT testbed solutions are founded on the ZigBee IEEE 802.15.4 communication standard and high-resource-demanding Wi-Fi, cellular-based, and 6LoWPAN/IPv6 routing standards. These standards also thrive on wired or fixed IP-based infrastructural backbones, total Internet/electricity coverage, and highly complex graph-based and centralized routing protocols [1,10,11,14,18,19], leading to a lack of global significance because Africa, which is the focus of this study, has less than 50% electricity/Internet coverage [27]. Also, ZigBee, Wi-Fi and cellular-based communication technologies with centralized or flooding-based routing architecture [1,10,11,14,18,19] are capital-intensive, complex to manage, location-restricted, energy-inefficient, and over-reliant on fixed supporting infrastructure. Therefore, an in-depth contextual assessment of how low-power communication standards such as LoRa, SigFox, and Bluetooth Low-Energy (BLE) evolve in cluster-based Agri-IoT (CA-IoT) networks can be of immeasurable benefits to the IoT community and farmers. The role of Agri-IoT in eliminating food insecurity, improving crop quality, alleviating global poverty, and increasing agricultural production volumes has been underestimated [2,7,8,10,16,28,29]. The agricultural sector, which has been hindered by climate change, is the largest global employer [3]. To revitalize this sector, CA-IoT has emerged with the most promising opportunities to address food and employment insecurity issues and improve crop quality and economic conditions for the farmers. However, these benefits have not been fully realized due to insufficient research publicity. To the best of our knowledge, no survey or tutorial articles have sufficiently considered these technical issues and provided sufficient technical guidelines for the designers of Agri-IoT systems to make well-informed decisions in order to achieve satisfactory network performance. Additional realistic research is needed regarding the contextual evaluation of SN design and deployment factors, fundamental network design concepts and requirements, multi-objective optimization (MOO) analysis of the parameters for designing the associated routing protocol, and efficient operational metrics of the WSN sublayer of the Agri-IoT using the cluster-based architecture. In addition, the assessment of the possibility of using low-power and accessible wireless communication technologies such as BLE via cluster-based architecture to achieve a complete infrastructure-less, cheaper, energy-efficient, self-healing, adaptive, and robust Agri-IoT network is imperative. Furthermore, a broader contextual overview covering all vital aspects such as the fundamental concepts of Agri-IoT, technical design requirements of SNs and WSN-based Agri-IoT, surveys of the benchmarking communication standards, routing protocols, and testbed solutions, and an in-depth case study on how to design a self-healing, energy-efficient, adaptive, and CA-IoT based on the performance and users expectations are illustrated in Figure 2. Such a reference document can help support researchers when they attempt to accurately model and optimize the performance of Agri-IoT [14] so that the performance gap between the simulated networks and the realized Agri-IoT testbed solutions [1] can be addressed. By way of addressing these technical challenges, this tutorial presents the following contributions: Perform an in-depth synthesis and review (1) the basic concepts of Agri-IoT, (2) the comprehensive design considerations of these networks, (3) the technical design requirements of Agri-IoT, and (4) the up-to-date research progress on routing techniques, communication standards, and testbed solutions of WSN-based Agri-IoT. Systematically survey the benchmarking of WSN-based IoT networks’ communication standards, FM techniques, routing and MAC protocols, and realization testbeds to respectively uncover the appropriate communication requirements for Agri-IoT, unveil the root faults and possible remedies in the WSN sublayer, derive a generalized taxonomy of routing architectures, and define appropriate routing paradigms for WSN-based Agri-IoT using the core PHY layer design metrics: affordability, self-healing capacity, energy-efficiency, location independence, and network adaptability. Systematic synthesis of canon cluster-based routing protocols to uncover the plethora of possible research gaps, derive a realistic taxonomy of MOO metrics and propose possible MOO remedies that can be implemented using CA-IoT routing architecture freely available low-power communication standards. Proposition of MOO-induced guidelines in the form of open issues that can help Agri-IoT designers to build adaptive, robust, fault-tolerant, energy-efficient, affordable, and optimized CA-IoT networks in both simulation and real-world implementations. Overall, this tutorial is motivated to provide a contextualized, in-depth understanding of this technology and assist the reader in designing robust, affordable, and optimized Agri-IoT networks that can act as reliable game-changers to avert the stipulated challenges. Also, the critical design, deployment, and QoS requirements of WSN-based Agri-IoT networks from theoretical modeling to real-world deployment are unveiled in order to bridge the existing gap between the theory and practice of this technology [1,14]. The remainder of this paper is organized into the following sections: Section 2 provides a brief background comparative overview of WSN, IoT, and Agri-IoT technologies, while Section 3 focuses on their components, protocols, architectural layers, and proposed architectural layers for WSN-based Agri-IoT technology. Section 4 presents the detailed contextual design and implementation requirements of Agri-IoT networks, while Section 5 deduces the unique characteristics, challenges, and proposed performance expectations of the associated routing protocols for the WSN sublayer of Agri-IoT. Section 6, Section 7 and Section 8 present systematic surveys on routing protocols, FM techniques, and the canon real-world testbed implementations of WSN-based Agri-IoT solutions. Section 9 examines how the above discussions have evolved using a case study of cluster-based Agri-IoT (CA-IoT) for precision irrigation.Section 10 unveils open issues and future works, while Section 11 concludes the paper. 1.1. Comparative Overview of WSN, IoT, and Agri-IoT Technologies A comparative overview of the underlying technologies (i.e., WSN, IoT, and Agri-IoT) forming the WSN-based Agri-IoT are compared from the perspective of architectural variations, users’ expectations, and design and implementational differences in Table 1. Table 1. Comparison of WSN, IoT, and Agri-IoT technologies. As depicted in Figure 3, WSNs are formed by spatially distributed, autonomous, resource-constrained SNs that wirelessly interconnect to communicate their sampled data to a BS for further monitoring or event tracking purposes without necessarily requiring the Internet. The main components of the WSN are the SNs, the BS/gateway, and the event sampling/routing software that supervises the entire network process. A node may route data directly or via relay SNs to the BS based on its location and assigned tasks. The BS locally takes actionable decisions and execution of the actuation actions. Although the WSNs are resource-constrained and fault-vulnerable, they constitute the inevitable part of this technology [2] and the underlying innovation of the WSN-based Agri-IoT framework. In contrast, classic IoT consists of IoT devices that sense and transmit their sampled information directly or via telemetry to the Internet for monitoring or event-tracking purposes, mostly via the centralized routing architecture. Like BS in WSNs, IoT devices can connect to the Internet/IoT cloud via fixed-line (thus, for a factory), 5G/4G/LTE cellular/mobile networks, or Wi-Fi for further processing, storage, and decisions/actions. Figure 3. Generalized Agri-IoT framework consisting of: field layout overview of Agri-IoT framework (a), sample of classic Agri-IoT in the state of the art (b), and key components of an SN or a BS (c). As presented in Figure 4, WSN-based Agri-IoT is an information- and knowledge-intensive intelligent feedback control system for farm monitoring, data sampling/computing, resource optimization, automation of farm operation (e.g., precision irrigation, chemical application, livestock monitoring, and disease management [16]), and actionable decision making via a variety of battery-powered and wirelessly connected SNs with sensing, processing, and communication capacities [2,29,30]. Unlike the WSN, Agri-IoT and IoT sample data to an Internet-based cloud. The SNs that form the WSN sublayer are spatially distributed and self-configured to achieve a myriad of remote sensing, surveillance/monitoring, and control applications via automated sensing, wireless communication, and computing, making informed decisions and performing actuation control [31] using precise, accurate, and timely sampled information about a real-world phenomenon [32]. Figure 4. Conceptual framework: Agri-IoT-based farm monitoring and control cycle. The main hardware components of an Agri-IoT framework, as presented in Figure 3 and Table 2, include the WSN (i.e., comprising the field-deployed SNs or IoT devices), a base station (BS) or gateway or actuator controller, cloud servers, and the user’s monitoring/control devices. The on-farm participants (e.g., SNs and BS) in Agri-IoT are mostly battery-powered and must be equipped with sensing, computing, and communication abilities to form infrastructure-less, robust, self-healing, and self-configured WSNs for data collection and event management [33]. The core units of the SNs in Figure 3c and the BS are compared and contrasted in Table 2. As the framework in Figure 3a depicts, the IoT devices can sense, process, and transmit their sampled data directly to the Internet or IoT cloud without a gateway, whereas the SNs in WSN-based Agri-IoT perform likewise via a BS. This resource-sufficient BS interfaces between the IoT cloud/user and the WSN or actuator control system. It can also process the received data and locally execute actionable decisions via the actuator of the farm event being monitored. The received data can also be relayed to the analytical data engines in the IoT cloud via a wired and wireless medium for further processing and actions [13]. The resource-constrained WSN sublayer mainly uses data-centric protocols due to the SNs’ high deployment densities, high network dynamics, and limited power supply of SNs. Although data-centric protocols are fragile and not standardized, they are more suitable than the high resource-demanding ID-based IPv4 or IPv6 protocols in the addressing space of the WSN-based Agri-IoT. Table 2. Comparison of SN and BS. Agri-IoT combines WSN and IoT technologies into contextualized intelligent farm management systems to achieve higher event data quality and offer remote monitoring and control. WSN-based Agri-IoT consists of the WSN sublayer, the gateways, the cloud servers, and the remote interface application, as illustrated in Figure 3a and Figure 5. Uniquely, the current trends of Agri-IoT mandate that both intra-SN and BS–cloud communication are based on low-power, ubiquitous, and freely available wireless standards [2]. Also, most Agri-IoT solutions support bidirectional communications between the BS/gateway and the cloud/users, whereby the BS updates the cloud/user database and receives actionable/control remote messages from the user or cloud analytical decision results for actuation purposes. The WSN-based Agri-IoT is the most dominant technology in the global smart farming use cases in the agricultural sector. The core tasks of SNs in a WSN-based Agri-IoT application, which are frequently supervised by the associated routing protocol, include network construction/management, data sensing, data processing/aggregation, fault tolerance, and communication [9,12]. Also, the routing architecture must be supported by the associated communication platform and the application-specific requirements of the network. Figure 5. Proposed Agri-IoT architectural layers with core components of Agri-IoT ecosystem and the “things” taxonomy. Unlike IoT and WSN whose design expectations are application-specific, WSN-based Agri-IoT requires holistic integrations of the expectations in Figure 2. 1.2. Classifications of IoT Applications and Specific Roles of Agri-IoT Generally, IoT technology is application-specific. However, it has limitless applications and roles in the smart world agenda. Based on their intended purpose, WSN-based IoT systems can be broadly classified into condition monitoring and event-tracking categories [34], as illustrated in Figure 6. Figure 6. Generalized taxonomy of IoT applications. The monitoring-based applications involve real-time event data collection and analysis, supervision, and operational control of systems. In contrast, tracking-based applications track changes in the phenomenon of interest, such as the locations of objects, persons, transported goods, animals, and vehicles. Both application domains can be subdivided into industrial, environmental, and societal IoT applications in Figure 6, where specific examples are provided for each application domain. For instance, monitoring-based applications may include indoor/outdoor environmental monitoring [6], industrial process monitoring [5,29], process control [2], greenhouse automation [7], precision agriculture (e.g., irrigation management, crop disease prediction, prediction of production quality, and pest and disease control) [2,8], biomedical or health monitoring [8], electrical grid network monitoring/control [12,29], military location monitoring [9], and so forth. Conversely, specific examples of tracking-based applications may include habitat tracking, traffic tracking, plant/animal condition tracking, and military target tracking, as outlined in Figure 6. 1.3. Agri-IoT Roles and Use-Cases The concept of intelligent farming involves data acquisition, data processing/planning, and smart control using the WSN and IoT technologies, big data, and cloud computing techniques to provide profitable solutions, as presented in Figure 7. These principal roles in Figure 7 define their use cases. For instance, monitoring the state of crops or the climate of the field using Agri-IoT technology can allow farmers to know precisely the amount of pesticides, water, and fertilizers required to attain optimal crop quality and production volume. However, the QoS requirements, the routing techniques, architectural requirements, and the operational dynamics differ from one use case to another. This tutorial focused on the critical and unique design requirements of WSN-based Agri-IoT, which is the backbone of the smart agricultural initiative [35]. The resulting use-cases in Figure 7 can be explained as follows: Figure 7. The roles of Agri-IoT in smart farming with specific use cases. Agri-IoT for Climate Condition or Agronomical Monitoring: This Agri-IoT system mostly comprises BS (i.e., weather stations) and a deployed WSN. The analytical data engines mine the sampled climate or crop condition data in the cloud to predict future climate conditions and farm automation plans. The most suitable crop and precise farming practices can then be predefined to improve agriculture production capacity and quality. Agri-IoT for Precision Farming: This is the most famous application of Agri-IoT, whereby farming practices (e.g., irrigation, fertilizer application, etc.) are precisely and accurately controlled to optimize these resources. Here, the SNs are mostly fitted with soil sensors to collect a vast array of microclimatic data (e.g., soil moisture, temperature, and salinity) that can enable farmers to estimate optimal amounts of water, fertilizers, and pesticides needed by the crops to minimize resources’ costs and produce healthier crops. Additionally, the BS controls the event actuation system via accurate data-driven real-time decisions on the crops using climate data, crop growth data, and disease infection data. Agri-IoT for Greenhouse Automation: The Agri-IoT-based approach provides more accurate real-time information on greenhouse conditions, such as lighting, temperature, soil condition, and humidity, unlike manual greenhouse management. This allows precise remote monitoring and control or automation of all farming practices. Agri-IoT for Livestock Monitoring and Management: In this system, SNs are attached to livestock to monitor their real-time health, track their physical location, and log their performance. This helps the farmer identify and isolate sick animals to avoid contamination and reduce staffing expenses. Agri-IoT for Predictive Analytics: This Agri-IoT system provides highly relevant real-time data that can be analyzed to make essential predictions, such as crop harvesting time, risk of disease infection, yield volume, yield quality, and yield vulnerability, for proper planning. Agricultural Drones (Agri-Drones): Agri-Drones, such as DroneSeed, are fitted with mobile SNs and farming tools to collect agricultural data or perform activities such as field surveillance, crop planting, pest control, farm spraying, crop monitoring, etc. For example, for Agri-Drones, all the above use cases utilize the WSN-based Agri-IoT framework. 2. The Agri-IoT Ecosystem The authors in [1,14] established that the existing real-world attempts of Agri-IoT could not meet both performance and user users’ expectations because they are founded on the fundamental concepts and the operational principles of classic IoT and WSN technologies. To effectively achieve the expectations in Figure 2, it is imperative to conduct a systematic assessment of the related architectural layers in classic IoT and propose a suitable option for the WSN-based Agri-IoT ecosystem. Generally, the conventional IoT ecosystem consists of the network architectural layers and the data management platforms [2,7,8], which are further grouped into devices (sensors, actuators, and gateways/BS), network (BS to cloud), platforms/applications’ cloud, and agents/users. Due to the domain-specific requirements of IoT applications and the incorporation of numerous heterogeneous devices with application-specific requirements, there are generally no unified or standardized IoT architectural layers. Therefore, most application-defined layers are frequently adapted from the canon architectural layers, which include the three-layer [5], the cloud-based [7], the service-oriented architecture (SOA) [2,7], and the fog-based [2,7,29], as illustrated in Figure 8. Figure 8. Different architectural layers in the state of the art of IoT ecosystem. The fog-based architecture was adapted from the three-layer parent architecture to include cloud computing by offering computing, storage, and network information between the clients and the cloud services [29] in a decentralized manner. Here, cloud computing and fog/edge computing architectures only differ in where data computing occurs. These layers are not unified because the respective network layers do not cover all underlying technologies that transfer data to all IoT platforms [5]. Additionally, they are based on complicated centralized and flooding-based routing architectures, high-resource-demanding and capital-intensive Wi-Fi/cellular-based communication technologies. As well, they require wired infrastructural support in the farm, which is too complex, location-restricted, and capital-intensive for most low-income and non-expert farmers to implement and manage. Consequently, they are unsuitable candidates for the resource-constrained SNs in WSN-based Agri-IoT. By implication, there are no reference guidelines for designing Agri-IoT participants and supervisory protocols, controlling the speed of packet delivery, smoothing out SN’s integration, unifying technology, and creating standardized Agri-IoT reference models, among other considerations. In contrast, an Agri-IoT ecosystem, depicted in Figure 3, consists of: Agri-IoT network architectural layers: This shows how the physical network elements, network operation principles, and operational techniques interact throughout the entire ecosystem. Network supervisory software/routing protocol and routing architectures: This contains the virtual arrangement of multiple network elements [8] and the event sampling/routing protocol that constructs the routing architecture, supervises sampling and moderates all communications in the PHY layer. Data management platform: It hosts all high-resource-demanding data analytic engines, event databases, and remote control algorithms in a cloud model. 2.1. Proposed Architectural Layers for WSN-Based Agri-IoT In designing an efficient Agri-IoT system of global significance, it is imperative to propose suitable architectural layers and evaluate how the various components interact in these layers. With the emerging advances in low-power, freely available, and boundless communication standards (e.g., BLE) and unfulfilled potentials of CA-IoT network [12,16], a new framework of cluster-based architectural layers for the WSN-based Agri-IoT ecosystem is proposed in the left side of Figure 5. The center portion of Figure 5 presents the key components/technologies required in each layer, while the Things taxonomies of hardware components from the related literature [4,8,29] are depicted on the right portion of Figure 5. The underlying layers in our four-tier layers in Figure 5 can be elaborated on as follows: Integrated Application and Management Layer: This operates all agriculture-related applications that interface between the user (for example, farmer) and the Agri-IoT system to make decisions and execute remote actions to keep their crops or animals healthy. This layer manages the entire Agri-IoT system and its application-specific functionality, high-resource-demanding applications, and core business model in the cloud. This layer’s security requirements are crucial to the next sublayer; however, these are beyond the scope of this research. The business or management sublayer maintains end-to-end data integrity and security by ensuring that data are transferred to the correct user. It also ensures that the correct user executes the actuation. Information Management Layer: This handles data processing, storage, and other specialized cloud services and functionality that make precise, actionable decisions. In Agri-IoT, the sensory data are preprocessed locally to optimize communication power but can be further processed using analytic engines in the cloud for better decision making and remote monitoring and control. This layer can be embedded in the above application layers and hosted in the cloud in a typical Agri-IoT ecosystem. Network Management Layer: This layer discovers, connects, and translates devices over a network, and it coordinates with the above application layers. It also contains the BS, which interfaces the resource-constrained WSN and cloud information network. By convention, the WSN sublayer must utilize low-power communication standards such as Zigbee, SigFox, LoRa, BLE, Z-Wave, SigFox, and IEEE P802.11ah (low-power Wi-Fi), while the BS-to-Cloud connectivity can be achieved via the traditional cellular networks, satellite networks, Wi-Fi, LAN, WAN, and LoRa, among others. Unlike classic IoT, Agri-IoT requires that the BS-to-Cloud connectivity utilize low-power communication standards. Also, since every communication standard for the resource-limited WSN sublayer comes with unique resource specifications and design tradeoffs between power consumption, routing architectural constraints, and bandwidth [4,14,17], the best connectivity option must be selected to achieve the desired application goals. Consequently, the stated WSN-based connectivity technologies can be classified using several distinct parameters, such as energy consumption rates, uplink/downlink data rates, packet size, SN-count per BS (gateway), network routing topology, the SNs’ sensing range, the SNs’ transmitter/receiver power, frequency bandwidth, channel width, etc. (refer to the right portion of Figure 5). Physical/Perception/Things Layer: This layer refers to the field and all devices such as SNs, actuators, RFID tags, sensors, and edge devices that interact with the environment. This layer senses and collects the necessary information from the connected devices in the WSN sublayer to the BS. In Agri-IoT networks, the sampled microclimatic data can be processed and stored on the local BS, the cloud, or both. The activities in the cloud or application layers are beyond the scope of this tutorial. 2.2. Associated Hardware Components and Technologies Required in the Proposed Architectural Layers To precisely model and design an Agri-IoT network of desired expectations (refer to Figure 2) using the proposed architectural layers shown in Figure 5, the knowledge of the principal components and technologies used in each of these layers and how they interact and adapt for their intended functions is imperative. As depicted in the middle of Figure 5, the Agri-IoT ecosystem is composed of the following core components/technologies: Things: The Things unit is the physical interface between the tracked/monitored asset and the BS or actuator controller, which aligns with the physical or perception layer. It comprises the monitored/tracked asset (for example, field, crop, or animal), the SNs, or the entire IoT devices making up the WSN (for example, SNs, actuators, IoT-enabled devices, WSNs, and other smart devices), the event sampling, and routing technology in the WSN. Since the SNs constituting this unit are resource-constrained, freely available communication standards such as Zigbee, BLE, Z-Wave, and IEEE P802.11ah (low-power Wi-Fi) are the most suitable for both SN–SN and SN–BS communications. The Things unit accesses the cloud/Internet via gateways (BS). Gateway (BS): The BS interfaces the WSN out in the field and the applications situated in the cloud servers. This unit aligns with the network management and actuator control layer shown in the middle of Figure 5. The WSN sublayer may have more than one BS(s), each with the capacity to handle most resource-demanding computational tasks besides actuation execution, network construction, scheduling of event sampling, and network supervision services. They may also allow bidirectional communication with the cloud/user and WSN. Similar to standalone IoT devices, the BS can be equipped with 4G/5G/LTE/NB-IoT, cellular-based, Wi-Fi, LoRaWAN, or wired ethernet communication technologies to interact with the cloud, and low-power communication standards such as LoRa, low-power Wi-Fi, SIGFOX, UMTS, BLE, and Zigbee (Figure 5) to communicate with the sensor field. However, Agri-IoT networks require that both upper-layer and lower-layer communication technologies of the BS should be low-power, freely available, easy to deploy and manage, and platform-independent. The BS may preprocess or relay the raw data to the cloud for remote data processing. The BS(s) locations are strategically chosen to optimize network communication costs. IoT Cloud: The Cloud unit aligns with the applications layer. It consists of an on-premises or remote server farm that hosts the applications layer, event data analytic engines, security protocols, robust IoT applications, user interface, and event database. The high resource-demanding data-processing tasks are mostly executed by well-equipped cloud-hosted applications to manage and store huge amounts of data, provide monitoring and data analytical services, enable communication with devices, and manage information access. The merits of edge computing can be exploited to ensure that large amounts of data are post-processed off-device to reduce the response times of the cloud. User Interface: With the aid of a web or mobile app, the user or farmer can live-monitor the farm’s conditions and execute control actions. Additionally, a presentation or business intelligence layer may be added to coordinate the activities of non-technical business users through dashboards and reports rather than with the application layer itself. 2.3. Quality Expectations of Agri-IoT’s Architectural Layers Although there is no unified, certified, and flexible Agri-IoT architecture layer, any suitable options deduced from the benchmarking architectures in Figure 8 must satisfy certain quality requirements, including: Simultaneous data acquisition, analysis, and control from many sensors or actuators. Minimization of huge raw data transmissions via data aggregation techniques to maximize actionable information quality. Provision of reliable network architecture that supports energy-efficient routing, stable connectivity, self-adaptability, fault tolerance, operational simplicity/flexibility, platform independence, affordability, and location independence of Agri-IoT designs. Support for automated/remote device management and updates. Easy integration of each layer with existing applications and other IoT solutions via specified APIs. Utilization of freely available, location-unrestricted, cheap, energy-efficient, and simple to deploy and manage by non-experts [4,29] underlying communication technologies in the PHY and network layers as well as based on open standards to guarantee interoperability. 3. Design and Implementation of Agri-IoT Networks Despite the technical challenges associated with the WSN-based Agri-IoT, its potential contributions in the agricultural sector largely surpass the least complex, capital-intensive, pure IoT-based solutions, as illustrated in Figure 3b and Figure 7. Due to the broader applicability and higher significance of the WSN-based Agri-IoT networks relative to the classic IoT networks, this study focuses on the former technology whose design and implementation involve four crucial phases, namely: Custom-building of robust, affordable, energy-efficient, location-independent, and adaptive SNs and a BS that can form an infrastructure-less and easily manageable WSN. The SNs and the BS must consist of cost-effective, architecture-defined, and context-defined components so that the system operates stably and efficiently, becomes affordable to farmers, and easily integrates to any real-world scenario without any expensive, fixed/wired backbone connections. The low-power capabilities of the SNs help to easily integrate them into any precision farms and greenhouses to operate over the entire crop season without many technical hindrances. Physical deployment of the SNs in the field, selection of the WSN’s communication technology, and design of a suitable supervisory protocol to coordinate the construction of appropriate event routing architecture, the duty-cycle schedule of event sampling to the BS, fault management, data management, and network maintenance. Additionally, a range of techniques such as network participant mobility, cross-layer design, MAC techniques, data aggregation, self-healing techniques, nodes’ duty-cycle schedule, security measures, localization, and communication specifications of the SNs can also be exploited in the associated routing protocols. Selection of appropriate BS/gateway communication technology and design of a suitable higher protocol to update the cloud database and execute the actuation actions based on users’ requests or decisions on processed event data. Design of data analytical engines and applications in the cloud and users’ remote monitoring and control interface app, which is beyond the scope of this tutorial. These call for a systematic application-specific assessment of the hardware components selected for every use case. 3.1. Sensor Nodes Design Considerations As illustrated at the bottom of Figure 3, a node for the WSN-based Agri-IoT network consists of four main units, which include the following: Sensing Unit: This unit interfaces with the physical environment and records the physical phenomenon of interest. The type of sensor is application-specific and can be contact-based or non-contact-based. For instance, the STEMMA soil moisture sensor and the DHT22 sensor can be used to sample environmental temperature and humidity (refer to Figure 3c). Controller Unit: This unit hosts the processor, storage, and connection pins for the other units and all auxiliary peripherals. The suitable controllers for building Agri-IoT SNs are Arduino-based and Raspberry-Pi-based (refer to the bottom of Figure 3) due to their ability to withstand extreme weather conditions. However, other off-the-shelf, application-specific controllers such as the ProPlant Seed Rate Controller, John Deere GreenStar Rate Controller, Viper Pro multi-function field computer, Radion 8140, Trimble Field-IQ, etc. are also available. Communication Unit: This unit is the principal determinant of the node’s power consumption, operational stability, and affordability, as well as the routing architecture in the associated supervisory protocol. The bottom of Figure 3 shows the available communication technologies, but an Agri-IoT-based SN demands an energy-efficient, affordable, freely available, simple, and reliable communication standard. Consequently, LoRa, BLE, ZigBee, LoRaWan, and SigFox are the best candidates based on the support of the routing architecture of the resulting WSN, but the selection must be justified from the technology requirement metrics via a decision matrix. Power Unit: Since the SNs are mostly battery-powered, the appropriate battery size and probable energy-harvesting techniques must be determined during the SNs’ design according to the intended network lifespan and stability requirements. Modern trends in battery power banks with integrated solar-based energy-harvesting systems and power ratings above 30,000 Ah are available. When selecting hardware components, adequate caution should be taken to avoid unit incompatibility, high operational complexities, unsuitable operational thresholds, and high energy consumption, among others. This implies that high component survivability and operational stability under different environmental conditions and the application specificities are vital to monitor. 3.2. Wireless Spectrum and Core Communication Platforms of WSN-Based Agri-IoT The wireless electromagnetic (EM) spectrum, which has invisible, finite radio frequencies for wireless communication, can be licensed and sold exclusively by specific providers or unlicensed for free usage. For instance, the Industrial, Scientific, and Medical (ISM) frequency band (e.g., Bluetooth classic, BLE, Wi-Fi, ZigBee, and LoRaWAN) is an unlicensed microwave frequency band clustered around 2.4 GHz and globally reserved for applications such as Agri-IoT. Table 3 presents the various bands and their applications. A suitable candidate for a given Agri-IoT application is based on several factors, such as communication and the route architectural requirements, power consumption, cost, and environmental adaptability impacts. Table 3. Wireless spectrum with the core communication platforms/applications. 3.3. Factors to Consider When Deploying SNs and Designing the Supervisory Sampling/Routing Protocol After custom-building or selecting off-the-shelf SNs, the next activity is to deploy the SNs on the field and design a contextualized supervisory protocol to coordinate the aforementioned network’s activities. The SNs’ deployment in the field can be either random or deterministic. Both options require different methods to optimize the resulting network’s performance. For instance, under the deterministic approach, the optimal parameters such as node uniformity and density must be predefined based on the distance thresholds of the associated communication technology (i.e., connectivity/distance range), the SNs’ resource optimization mechanisms, the type of routing architecture, and the sensing range of the physical parameter to be measured. Since communication is the principal power consumer, the best ways to conserve power are to minimize communication distance and data sizes as well as operate the SNs in the appropriate sleep–active duty cycles using a cluster-based routing architecture [9,24,26]. Beyond the physical installation of the SNs at their most suitable in-range locations, the remaining activities, such as network construction, event sensing, data management, FM, network maintenance, sleep–active duty-cycle scheduling of SNs for sampling, network adaptability to turbulent and scalable conditions, power-optimization mechanisms, and network reconfiguration, among others, are controlled by the associated routing protocol [12,16,17,26,36]. This places crucial merits on the physical locations of the SNs in the field, thorough synthesis of network design factors, and assessment of available routing architectures/techniques, since this protocol manages all post-deployment tasks. This can be summarized into the core objectives of the routing protocol and its architecture, which include power optimization, self-healing of any faults without the obstruction of its normal operation, and self-adaptability to all turbulent and scalable conditions. From the analysis above, we can derive the critical primary factors to consider when designing a routing protocol for Agri-IoT networks, which are presented in Figure 9 and grouped into the following categories: SNs specifications, security issues, application-specific factors, communication standard compatibility and capacities, and other auxiliary factors. At the PHY layer level, which is the focus of this tutorial, these critical factors can translate into the stipulated core design objectives, which can be addressed via phase-based multi-objective optimization (MOO) formulation frameworks [12,23,24,37]. Figure 9. Principal design factors for Agri-IoT networks. Hardware Specifications of SNs and BS Agri-IoT Device: The functional and resource capacities of participants’ hardware units must be considered before their respective tasks in the protocol are assigned. For instance, the selected sensors’ quality must suit the type of event information and its accuracy, the available communication platforms, and the general purpose of the Agri-IoT solution. Also, the communication standard must support the routing architecture and SNs’ resource- and deployment-induced limitations. The crucial communication-based parameters of the SNs are illustrated in Table 4. Table 4. Comparison of common communication platforms of the WSN sublayer of Agri-IoT. Cost or Affordability of the Resulting Agri-IoT System: In addition to being infrastructure-less, flexible, self-healing, adaptive, and energy-efficient, a WSN-based Agri-IoT must consist of cost-effective hardware and software components so that the system is affordable for farmers, since existing real-world solutions are too expensive and complicated [1,14]. Additionally, the installation, operational, and maintenance costs of the resulting WSN-based Agri-IoT network must be kept to a minimum so that it can be easily acquired. Security Issues in Agri-IoT: Security is still a challenge in classic IoT systems that handle sensitive information, especially during cloud communications. Although Agri-IoT networks lack the requisite resource capacities in most large-scale, broadcast-based, distributed, and infrastructure-less WSN systems to achieve adequate data confidentiality, authenticity, integrity, and other security requirements, the security of the agricultural data is rarely a priority [2,4]. Nevertheless, the associated routing architecture, such as the clustering architecture, has an embedded capacity to resolve on-site security issues. In addition, both on-site and remote information access types (e.g., via a smartphone or desktop computer) must be selected based on solid internal infrastructure and security precautions to secure unwanted access to sensitive information. The Application-Specific Factors: As indicated in Figure 9, the application-defined factors vary based on the Agri-IoT application, the field settings, network maintenance practices, intended event routing architecture, and network participants’ mobility, among other factors. However, the routing protocol must incorporate all relevant operational efficiency factors of the routing software design objectives. Since the collected field data itself cannot make sense without using analytic data engines and predictive algorithms in machine learning, the BS or the application layer in the cloud should define appropriate data-processing frameworks to obtain accurate, actionable decisions from the collected data. Communication Standards of Agri-IoT Devices: The power-constrained WSN sublayer of Agri-IoT network places hard restrictions on operational states of SNs’ radio transceivers, code space, and processing cycles as well as memory capacities of SNs to enhance power savings [9,12,23]. The type of communication technology selected for a typical Agri-IoT is the principal predictor of its routing architecture, affordability, simplicity, adaptability, power-saving capacity, location independence, self-healing capacity, and event data quality [12,16]. Consequently, power and routing architectural limitations constrain the network design requirements. Despite the aforementioned technical challenges on the network’s operational efficiency, interconnected SNs that form the WSN are expected to withstand extra operational disruptions caused by unfavorable weather conditions in the field [2,4]. Consequently, the de facto PHY-layer communication standards for this low-power, low bandwidth, and distance-limited communication Agri-IoT devices/SNs have been the energy-efficient platforms such as BLE, LoRa, Sigfox, and NB-IoT. Also, a suitable MAC technique is imperative in the routing architecture to curb all channel access challenges. For instance, the ZigBee/IEEE 802.15.4 standard focuses on the physical and the MAC layer specifications for WSNs, and it also supports the sleep–active or duty-cycle scheduled operation modes of SNs to enhance energy savings in centralized or mesh-based architectures. BLE does likewise in the highly endowed cluster-based routing architecture. Consequently, Agri-IoT network designers must make the most appropriate and critical decisions regarding the network’s communication requirements when designing the routing protocol. Using Table 4, WSN-based Agri-IoT designers can make realistic design decisions regarding energy-efficient multihop routing, architectural requirements of routing protocol, bandwidth, routing table capacities, total communication cost, and the desired MAC technique. Additionally, the physical conditions within the agricultural environment such as atmospheric dust concentration, physical obstruction to wireless signal transmissions, and the terrain need to be considered. Auxiliary Factors and Available Software Tool: Finally, the auxiliary factors can be non-exhaustive depending on the designer’s financial capacity, user interface, information requisition model, cloud activities, operational expectations, and the available software tools. Additionally, an assortment of PHY-Layer design software tools for Agri-IoT experiments (thus, in both simulations and real-world testbed deployments) that can be used include NS-3 [9,38], OMNeT++, MATLAB/Simulink [9,12,39], Python [16], PAWiS [39], GloMoSim/QualNet [39,40], OPNET [12,39], SENSE [37,39], J-Sim [39], Ptolemy II [39], Shawn [9,39], and PiccSIM [12,39,41], among others. The key features that are frequently considered when selecting any of these software platforms include Python or MATLAB/Simulink compatibility for software model and hardware prototype integration during real-world operation, compatibility with low-power communication standards (e.g., BLE, LoRa, ZigBee, and SIGFOX), operating system support, programming language implementation, the density of simultaneously simulated or field-deployed SNs, co-simulation with other hardware, documentation, easy access to upgraded versions, and installation challenges [39]. MATLAB/Simulink and Python are the most commonly used experimental tools, since these software tools are well-equipped with the stipulated features. 4. Unique Characteristics and Challenges of WSN Sublayer of Agri-IoT Unlike the traditional IoT, which generally relies on fixed hardware to route network traffic, a WSN sublayer of Agri-IoT combines automated sensing, computation, actuation, and wireless communication tasks into the SNs that are spatially distributed across the farm to autonomously form an infrastructure-less WSN [31]. A node may perform additional tasks such as local data processing (data aggregation), network construction, data redundancy, error control, data routing (e.g., in multihop networks), and network maintenance practices based on the network size, application specificity, and associated routing techniques. Also, the WSN can be equipped to observe heterogeneous conditions such as temperature, humidity, sound, color, location, light, vibration, and motion, using a wide variety of sensors contained within a task-scalable SN. Therefore, assuming that the accuracy and precision of event data in upper layers are preserved, the Agri-IoT’s lifespan and its operational efficiency are rooted in the WSN’s robustness. Thus, a deeper contextual exegesis into the design and maintenance of this sublayer is imperative. As opposed to conventional IoT and wireless ad hoc communication networks, the operational efficiency of the WSN sublayer, as well as Agri-IoT, hinge upon some application-specific characteristics and resource-constrained factors such as: Higher SN Deployment Densities: Generally, SNs are densely deployed in either a deterministic or random manner to provide the desired redundancies, spatial variability of soil, topography, distributed monitoring and processing, accurate and precise event reporting, and fault tolerance. However, this mostly leads to undesirable transmission overlaps, data redundancies from the simultaneous reporting of the same data, routing interferences, and packet collisions due to connectivity issues and the coexistence of common standards in the ISM band [42]. Limited Power Supply: The SNs are frequently battery-powered, which does not only constrain their data transmission rate, computational capabilities, and communication distance but also subjects Agri-IoT to possible SN-out-of-service and data outlier faults due to rapid power depletion beyond certain thresholds [26,43]. Consequently, network power management through data-management-related, architectural-related, and communication-related parameters has been one of the principal research focuses in WSN-based IoT applications to improve network lifetime. Fault Management (FM) (i.e., fault detection, fault tolerance, or fault avoidance): The resource-constrained WSN is highly vulnerable to faults and failures due to high deployment densities and a lack of post-deployment maintenance services [25]. Although faults are inevitable in Agri-IoT for the stipulated reasons, their occurrence rates and effects on the network’s functionality can be minimized, avoided, or tolerated without hindering the normal functionality of the network if the associated WSN’s routing protocol is well-equipped with efficient self-healing and fault-avoidance (power-saving) mechanisms [12]. Self-Adaptability and Scalability: Although WSNs are application-specific, the topological dynamism is inevitable due to node failures, node mobility, and scalable conditions. Therefore, the associated routing protocol and network architecture must adapt to these dynamic conditions using apt auto-reconfiguration and reactive multihop event routing techniques [44,45]. Network Architecture: The underlying routing protocol of the WSN sublayer constructs a network architecture that can be flat, hierarchical (e.g., clustering, chain-based, and tree architectures) or location-based. This routing architecture prescribes the possible measures to achieve efficient local data processing, network maintenance, scalability, minimized communication overhead, prolonged network lifespan, and reduced network management complexities [25,36]. Therefore, a suitable network topology indirectly determines the resulting network’s flexibility, scalability, reliability, communication strategy/costs, and the quality of the reported event data [12]. Mostly Requires On-site Actuation: Regardless of where data are managed in a typical WSN-based Agri-IoT, the actionable decision signal must be sent to execute on-farm actuation. Proposed Design Objectives of WSN-Based Routing Protocols for Agri-IoT and Realization Mechanisms From the systematic evaluation of the unique characteristics and challenges of the WSN sublayer, a three-tier cluster-based framework that constitutes the condensed expected core design objectives and their corresponding remedial strategies of WSN-based routing protocols for Agri-IoT applications is demonstrated in Figure 10. Suppose the corresponding remedies in Figure 10 are implemented in the associated routing protocol. In that case, the desired power optimization, self-healing, and auto-adaptability expectations can transitively yield the desired event data quality and operational stability requirements or the global performance expectations of the resulting network. Figure 10. Proposed design objectives and strategies of WSN-based Agri-IoT routing protocols. The importance of this three-tier framework can be expanded on as follows: An adaptive and scalable WSN-based routing protocol, as proposed in Figure 10, normally constructs a routing architecture that supports multihop routing, self-reconfiguration, self-healing, and local network administration at a minimal routing table size, communication cost, and and control message complexity requirement. Since communication is the principal power consumer, the operation of the routing protocol must invlove fewer control messages. Also, it must adapt to network turbulence due to SN failures. The cluster-based architecture exhibits the highest potential compared to related architectures [9,16,17,26]. The cluster heads (CHs) efficiently coordinate these activities by registering and tolerating all dynamism resulting from SN-out-of-service faults, increasing the network size and SN density. Due to the high vulnerability of SNs to faults and failures, it is imperative to deploy suitable FM techniques that can detect, tolerate, or avoid possible root faults such as SN-out-of-service and data outliers [25]. The adaptive clustering approach can effectively resolve SN-out-of-service faults, while the threshold-based decision theory at the local nodes and global levels can be suitable candidates for event data outlier detection and correction in the PHY layer. Since power mismanagement is the root cause of most faults and failures, the best fault-avoidance techniques optimize the nodes’ power consumption rates. Figure 10 also outlines the suitable measures for power optimization in the WSN sublayer of Agri-IoT. In clustering approaches, power consumption in the constrained WSN can be managed via message complexity control, connectivity-related metrics, and communication-related parameters by exploiting the clustering architecture [46]. In addition to local data processing (data aggregation, data redundancy, and error checks) and local network administration (FM, adaptability to network dynamics), suitable MOO and multihop routing frameworks can be derived using the clustering architecture, total communication cost, and optimal cluster quality metrics to serve as a design optimization guide for the simulation and real-world implementations of the WSN phase of Agri-IoT. To achieve the expectations in Figure 10, there is a need for an architecture-specific multi-objective assessment of the WSN’s design cycle; from this, the associated parameters and theoretical models can be derived and then theoretically optimized and validated experimentally. A novel holistic MOO framework can help realize these expected goals in both simulation and real-world Agri-IoT implementations. Consequently, there exists the need to carry out a systematic survey and assessment on existing routing architectures, FM schemes, and routing protocols, and how these evolved in existing real-world realization testbeds of Agri-IoT. Such an in-depth literature synthesis can help assess these qualitative performance indicators constituting the root QoS metrics in Figure 10 as well as deduce application-specific guidelines for improving CA-IoT networks using a precision irrigation system as a case study. 5. State of the Art on Routing Protocols for WSN-Based Agri-IoT Applications In Agri-IoT, it is not simply a matter of applying IoT to a farm; contextual due diligence on architecture, communication standard, cost, actuator, performance stability, control, and environmental impacts augment the routing protocol requirements. This section presents a systematic synthesis of WSN-applicable routing protocols under network architecture, the route discovery process, and protocol operation as illustrated in Figure 11. To help Agri-IoT designers make well-informed decisions concerning architectural selection, we classified the canon protocols based on routing architecture, route-discovery process, and operations in order to uncover their strengths, weaknesses, and contextual reasons why they can be adopted for Agri-IoT applications. Generally, event routing in every protocol can either be source-initiated or destination-initiated, and the optimal path selection from the constructed routing architecture can also be broadcast-based, probabilistic, cluster-based, or parameter-determined using location-related, weight-based, and content-based metrics [13]. Also, routing protocols must commonly resist link failures using mechanisms that ensure balanced network-wide power depletion rates, energy-efficient multihop routing, and effective implementation of the indispensable QoS metrics presented in Figure 10. The related routing protocols can be classified as illustrated in Figure 11. Figure 11. Taxonomy of WSN-based routing protocols of Agri-IoT. 5.1. Architectural-Based Routing Protocols This class of protocols presented in Figure 11 and Figure 12 can be sub-grouped into flat-based centralized or direct communication and decentralized [47] (e.g., flooding/peer-to-peer/graphical/mesh-like architectures), hierarchical/cluster-based/tree architectures, and the location-based protocols [37]. Figure 12. Sample network architectures: centralized-data-centric, cluster-based, and graph/flooding-based architectural frameworks of WSN sublayer. The centralized protocols route data to the BS via single-hop routing, while the flooding and graph-based protocols flood data through multihop routing. The graph-based routing protocols construct a reactive or proactive graphical routing architecture with 𝐺(𝑉,𝐸) where a node and path represent the vertex and edges, respectively. This method relies on resource-intensive routing techniques from graph theory used in classic IoT and ad hoc networks to transmit event data to the BS. In contrast, the clustering/tree topology depicted in Figure 12 groups the SNs into either static or dynamic clusters, each with an optimally selected CH to minimize the communication distances of the cluster’s member nodes (MN). The CH is then tasked with aggregating the received readings from its MNs, executing error and measurement redundancy checks, and communicating directly (single-hop routing) or via a relay CH (RCH) using a multihop routing technique to the sink node or BS. However, the RCHs must be assigned fewer MNs to balance the network’s power depletion rates, since aggregated packet forwarding inflicts extra energy burden on the RCHs [37]. Additionally, the CH can be equipped to perform extra roles such as FM, coordination of the reclustering process, network maintenance, relaying of aggregated packets in large-scale networks, and management of network dynamism [12]. In general, cluster-based routing protocols differ in terms of CH selection methods and coincide in terms of intra-cluster and inter-cluster multihop routing, local data processing by the CHs, and CH role rotation [47], which ensure balanced network-wide power depletion, prevent abrupt power exhaustion, and lead to exponential energy savings [37]. Although the flat-based architectures, such as centralized and flooding (see Figure 12), can be easily implemented in real-world small-scale Agri-IoT networks, they suffer severe packet collisions, communication bottlenecking at the BS, and high inaptness for scalable or turbulent large-scale WSNs where energy efficiency is a priority. Again, an optimized clustering approach can provide an ideal topology for addressing the proposed expectations in Figure 10, and it can also offer extra benefits such as minimized communication cost, stabilized network topology, efficient load management, improved network maintenance, and improved network traffic and channel access management [37,48]. The main challenge of the clustering method is how to achieve the desired cluster quality (e.g., optimal cluster count and cluster size) so that the computational, bandwidth, memory, and routing table capacities of the resource-constrained CHs are not exceeded. Typical examples of clustering protocols are the LEACH family of protocols, which include RCEEFT, ESAA, DEEC, SEP, and PEGASIS in [12]. In location-based routing architectures, routing decisions are made either reactively (e.g., Ad hoc On-demand Distance Vector—AODV) or proactively (e.g., RPL—Routing over Low-Power and Lossy Networks protocol), using the SNs’ location information. This normally results in a decentralized, graphical architecture. Since the SNs that form the WSN are spatially deployed in the field without any IP-addressing schemes, location information is needed in order to establish communication between the nodes in a location-based architecture. The location information helps eliminate unwanted transmissions by collecting data from a specific region of interest. This architecture suffers from routing delays, high infrastructural cost, extreme difficulties in deployment and management, and high energy waste due to SNs’ long idling durations. However, they are the most commonly used protocol in existing ZigBee-based Agri-IoT testbed solutions [1,10,14,17]. Since this approach yields non-energy-aware architectures, it is not suitable for Agri-IoT applications [12]. It is evident from the above discussions that Agri-IoT-based network architectures must be defined by the associated routing protocol using the design requirements in Figure 9 as well as the application-defined requirements [49] in order to enhance the performance expectations in Figure 10. In addition, the routing architecture must not compromise on the quality, precision, and accuracy of the event information. It must be in unison with the application-specific requirements to address possible deployments- and network-induced challenges, such as network turbulence and SN mobility. 5.2. Route Discovery-Based Protocols As shown in Figure 11, route discovery-based protocols focus on when the route for data transmission is built and can be grouped into proactive, reactive, and hybrid protocols. In proactive routing protocols, the routes are pre-created before they are needed. These protocols are table-driven, since every node stores a large routing table containing a list of all possible destinations, next-hop neighbors to those destinations, and the associated costs of all next-hop options. Proactive protocols such as the RPL and the APTEEN family of protocols [15] make local routing decisions using the routing table’s content. For instance, the RPL operates as a distant-vector protocol for IPv6 low-power devices, utilizes the ZigBee/IEEE 802.15.4 standard on established IP infrastructure, and also supports the 6LoWPAN adaptation layer. RPL creates a multihop tree routing hierarchy of SNs, such that nodes can send data through their respective parent nodes to the BS/sink node in a flooded manner (Figure 12). Similarly, the BS or sink node can send a unicast message to a specific SN in order to complete a bidirectional operational framework of RPL. The optimal communication costs and routes are estimated by ranking the associated objective function (OF) metrics, which can be single-objective optimization, SOO metrics, or MOO metrics. This routing over LLNs (RoLL) restricts densely deployed and resource-limited SNs to communicate using peer-to-peer or extended star network topologies [13]. Technically, RPL builds a directed acyclic graph (DAG) with no outgoing edges from the root element (e.g., BS) to eliminate loops. RPL is the primary underlying routing protocol in most failed Agri-IoT testbed attempts. Although the proactive or RPL-based family of protocols are robust, reliable, scalable, and can relatively operate at minimized control messages with the help of timers, they are not suitable for Agri-IoT networks due to these technical challenges: The core of RPL/proactive protocols still suffers from key challenges such as energy wastage, a lack of adaptability/scalability, reliability, congestion, and security issues. Specifically, the energy expended by RPL-inherited protocols to create routes (e.g., establish and maintain routing tables) and transmit data can be too high for resource-constrained SNs in recent Agri-IoT applications. The underlying technology of RPL (e.g., ZigBee, 6LoWPAN, or IPv6) was designed for energy-sufficient devices with high processing and memory capacities. Therefore, RPL is inapt for typical resourced-constrained Agri-IoT networks (refer to Table 5). They require costly fixed IP infrastructural supports and utilize the centralized routing architecture, which becomes practically impossible to manage as the network scales. Table 5. Comparison of some cardinal hierarchical WSN-based routing protocols for Agri-IoT in state of the art. Conversely, the source-initiated reactive or on-demand routing protocols only create the routes on-demand by a source to send data to a receiver. Reactive protocols (e.g., Ad hoc On-demand Distance Vector, AODV Protocol [13]) have no specific procedures for creating and updating routing tables with route information at regular intervals. For instance, the AODV is a loop-free, self-starting, and reactive routing protocol meant for LLNs (e.g., WSN-based IoT) that are characterized by node mobility, link failures, and packet losses. AODV mainly consists of the route discovery process (RREQ and RREP messages) and route maintenance (RERR and HELLO messages). Although reactive or AODV-based protocols can adapt to network dynamics and eliminate periodic updates, the associated flooding-based route–search process incurs severe overheads resulting in high control message complexity, high route acquisition latency, and high energy wastages due to longer SN idling periods. Consequently, these protocols are unsuitable for power-constrained WSN-based Agri-IoT applications. The hybrid-based routing protocols merge the features of both reactive and proactive routing processes. However, hybrid protocols such as APTEEN [13] also require expensive fixed infrastructural support, which renders them unsuitable for Agri-IoT, even if the combined merits of reactive and proactive protocols are exploited. A comparative assessment of the strengths and weaknesses of the parent WSN-based routing protocols for Agri-IoT applications is illustrated in Table 5. 5.3. Operation-Based Routing Protocols Finally, routing protocols can be classified based on the operation or communication model employed, which may include: Negotiation-Based Protocols: These protocols exchange negotiation messages or use meta-data negotiations between neighboring SNs before the actual data transfers to reduce redundant transmissions in the network. A typical example is the SPIN family of protocols [13]. Multipath-Based Protocols: These use multiple routes simultaneously to accomplish higher resilience to route failure (i.e., fault tolerance) and load balancing. Query-Based Routing Protocols: These are receiver-initiated protocols whereby a destination node broadcasts a query to initiate a data-sensing task from a node through the network. A node having the data being queried sends it in response to the query. Coherent and Non-Coherent Protocols: The coherent routing method forwards data for aggregation after a minimum local pre-processing. However, in non-coherent routing, the nodes locally process the raw data before routing to the BS for further processing. QoS-Based Routing Protocols: These protocols’ purpose is to satisfy a specific QoS metric or multiple QoS metrics such as low latency, energy efficiency, or low packet loss. These protocols ensure a balance between energy consumption and data quality in every event-reporting task. In addition to route architectural construction and data transmission, efficient MAC must be embedded in the routing protocol to manage the wireless medium access and the duty-cycle/sampling schedules of the deployed SNs in Agri-IoT networks. As opposed to classic IoT, the MAC techniques in Agri-IoT are architecture-defined by the associated routing protocol to meet the energy efficiency requirements of the network via channel access management (CAM) and the moderation of the active–sleep duty cycles of the deployed SNs to save extra energy. The next subsection presents a concise overview of MAC techniques and their roles in WSN-based Agri-IoT networks. 5.4. MAC Techniques and Requirements for Agri-IoT Next to node deployment, the routing protocol defines the network architecture and selects a suitable MAC technique and a communication pattern for the routing architecture. Unlike classic IoT, requirements for Agri-IoT applications include a low control message complexity and low latency MAC technique that moderates sampling schedules, access to a shared medium, transceiver operation modes, (e.g., packet transmission and reception, retransmission, collision, over-hearing, overhead handling, and idle listening) active–sleep duty cycles of the deployed SNs, and transceiver channels. Thus, an MAC protocol for WSN-based Agri-IoT applications must be architecture-specific and adaptive to network dynamics such as data transmission errors, interferences/packet collisions, and regular interfacing of the active–sleep duty-cycled schedules of the SNs’ transceiver states (e.g., transmitting state, receiving state, idle state, and sleep state [52]) during packet transmission and reception in order to improve network throughput, energy efficiency, latency, and other QoS metrics. Unlike MAC protocols for classic IoT, an efficient MAC technique for Agri-IoT must ensure exponential energy savings via channel assignment management (CAM) and active–sleep duty-cycle coordination in both time and channel perspectives. Based on these common dual tasks of Agri-IoT-based MAC (thus, duty-cycle optimization—DCO and channel access management—CAM), existing IoT-based MAC techniques can be classified as illustrated in Figure 13 and the state of the art in Table 6. Figure 13. Proposed functionality-based MAC classification framework. Table 6. Summary of state of the art on duty-cycle and CAM MMAC protocols. The CAM role eliminates packet collisions, overhearing, and over-emitting to ensure the desired functional balance, while the DCO task minimizes idle listening. A comparative assessment of related MAC methods used in recent WSN-based Agri-IoT applications in Table 6 affirms the need for further research on the functionality balance between DCO and CAM as well as a context-based MMAC approach for the LEACH family of protocols used in Agri-IoT applications. 5.5. Overall Perspective This section systematically surveyed core Agri-IoT-based routing protocols and evaluated the parent protocols (i.e., RPL, AODV, and LEACH/cluster-based families of protocols) for classic WSN-based IoT networks, of which LEACH-based methods are the best candidates for the resource-limited WSN-based Agri-IoT. However, the RPL and AODV have received more research considerations in terms of realizations in both simulations and practice [9,12,21]. Although the cluster-based architecture has unique endowments for realizing the proposed expectations in Figure 2 and Figure 10, it lacks an in-depth design synthesis in the current state of the art that can uncover its contextualized performance optimization modalities for real-world Agri-IoT applications. In addition, the deployment requirements with trending technologies such as BLE, LoRaWAN, SigFox, 5G, LoRa via Satellite, and NB-IoT under both simulation and real-world operational conditions is imperative. Consequently, the following sections present in-depth overviews on FM, the benchmarking of WSN-based Agri-IoT testbed solutions, clustering methods in the existing state of the art, and how the possible deductions from these syntheses can evolve in a typical case-study such as a WSN-specific Agri-IoT routing protocol for precision irrigation. 6. State of the Art on FM Techniques for Classic WSN Sublayer of IoT Since faults and failures are inevitable in the WSN sublayer of Agri-IoT networks (refer to Figure 10), it is imperative to reevaluate the faults, causes, types, strengths/weaknesses of existing FM (i.e., fault detection—FD, fault tolerance—FT, and fault-avoidance—FA) schemes, revisit their founding assumptions [71], and make appropriate recommendations for Agri-IoT network designers. In this section, we establish the root source/cause(s) of faults in the WSN sublayer by assessing the behaviors of the different fault types, examining the extent to which the existing FM schemes address these root faults, and exploring how these schemes will evolve in realistic WSN-based Agri-IoT networks based on their core assumptions, control message overheads/complexities, and energy-saving capacities. From this thorough assessment, this section proposes practical fault-avoidance-based FM techniques for the next generation of WSN-based Agri-IoT. 6.1. Systematic Overview of Faults, Sources, and Taxonomy of Faults in Agri-IoT According to the fault–error–failure cycle depicted in Figure 14, a fault can be defined as any impairment that causes a system to produce erroneous results or leads to the failure of the entire system or specific components [72]. The prevalence of faults in WSN-based Agri-IoT is primarily due to the SN component malfunction, lack of post-deployment maintenance, or resource exhaustion [73], which can lead to either impaired event data quality (thus, sensory data error/outlier) or SN-out-of-service (thus, the shortened lifespan of SNs) [25]. Figure 14. Fault–error–failure cycle [72]. Due to the high susceptibility of WSNs to faults, the supervisory routing protocol is expected to incorporate efficient FM mechanisms that can guarantee optimum event data quality and network availability. By implication, FM algorithms for WSNs must not be stand-alone as currently seen in the state of the art [73]; instead, they must be an integral aspect of the routing protocol that agrees with the core participants of the PHY layer, such as the SN, wireless communication medium, and the BS. As illustrated on the left of Figure 15, the WSN sublayer is the most prevalent source of faults in the Agri-IoT ecosystem, in which the SNs are the central origin of faults that can propagate to the upper layers [25,43,73]. This is because the BS is resource-sufficient mainly, and the link’s reliability also hinges upon the SNs’ availability, as indicated in Figure 15. At the local SN’s level, each unit depicted at the bottom of Figure 3 is a potential source of fault/failure, but the degree of prevalence is frequently accelerated whenever power consumption is mismanaged through the disregard of any of the network design requirements and deployment conditions presented in later sections. Figure 15. Faults in the WSN sublayer of Agri-IoT: sources and fault propagation model. The different taxonomies of faults in the state of the art of the WSN sublayer [44,71,73,74,75,76,77], as illustrated on the left side of Figure 16, can be compared as follows: Figure 16. Classification of faults in the state of the art and proposed fault taxonomies for WSN-based Agri-IoT. Hard or permanent fault refers to the inability of a node to stay active and communicate due to resource exhaustion or component malfunction, while in soft or static faults, nodes continue to work and communicate with other nodes, but they sense, process, or transmit erroneous data [44,74]. The authors in [75,78] categorized faults as permanent (refers to SN-out-of-service faults), transient (caused by temporary conditions), intermittent (shows sporadic manifestations due to unstable behavior of hardware and software), and potential (due to depletion of hardware resources [78]). Data inconsistency faults can also result from faulty sensing, processing, and communication, which is frequently caused by power depletion below a certain threshold, while power failure occurs when a node exhausts its battery power completely [43,77,79]. The authors in [73] classified faults into software and hardware faults based on software and hardware impairments, respectively. According to [71], faults can be either time-based, due to the depreciation of hardware components with time, or behavioral-based, due to SNs’ inability to cope with harsh environmental and operating conditions. From the above definitions and the fault taxonomies on the left side of Figure 16, it can be deduced that hard, permanent, and static faults are practically manifested as SN-out-of-service, while soft, dynamic, and data-inconsistency faults can be observed as data outliers. Both SN-out-of-service and data outliers are consequences of unit malfunction or resource exhaustion and can be permanent or intermittent in behavior. Both conditions can impair the quality of event data and the global actionable decisions of the network. Therefore, the quality of FM schemes can be evaluated based on their capacities to effectively detect, tolerate, or avoid SN-out-of-service and data outlier faults. In summary, most FM schemes in the state of the art focus on their effects, instead of the root faults, which are the flaws in existing FM schemes [25]. Additionally, since the SN is the sole network device responsible for event sensing, data computation, packet forwarding, and communication in the WSN sublayer of Agri-IoT, it is the principal source of faults in Agri-IoT networks. A new fault classification framework shown in Figure 16 can be deduced from the above analysis. Secondly, it is discernible that SNs’ power mismanagement is the most prevalent origin of faults [43,80,81], which then propagate to the backend or application level (refer to the right side of Figure 15). For instance, communication, sensing, and computational accuracies of a node can be impaired when the battery energy falls below certain thresholds [43]. Also, network faults can be traced to power exhaustion and node failures, which create holes in the topology that divide the network into multiple disjointed segments [43]. On that account, faults can be avoided in WSN-based Agri-IoT if the energy-saving strategies presented in Figure 9 and Figure 10 are effectively implemented. Additionally, any FM scheme or fault-monitoring mechanism, be it proactive, reactive, passive, or active, must incorporate the following underlying qualities: thresholds that represent the probable fault conditions without false alarms, fault discovery, minimized message/time complexities, and self-healing and self-reconfiguration to neutralize the effects of the faults [43]. FM Framework and Architectures in WSN Sublayer of Agri-IoT As illustrated in Figure 17, every FM scheme consists of three main steps, which include fault detection (FD), fault diagnosis, and fault recovery/tolerance (FT) [82,83], which always require input information. These steps are implemented in a decision-making framework that involves four major processes: data/information collection, FD model formulation, FD decision and fault classification, and tolerance of its effects using any of the FT mechanisms shown in Figure 17. Thus, the FD model detects the fault, the fault discovery technique distinguishes that fault from false alarms, while the FT mechanism helps to auto-heal and recover from the faults or failures [84]. Mainly, SN-out-of-service faults are detected and tolerated using self-reconfiguration techniques, whereas data outlier faults must strictly follow Figure 17. Figure 17. FM framework in WSN sublayer of Agri-IoT. In addition, FM schemes can be implemented using either a centralized or distributed architecture [44,85,86]. In a centralized scheme, the FD/FT protocol is hosted and managed on the BS, whereas the distributed scheme hosts and manages this algorithm on the local SNs [87,88] (see Figure 17). The centralized approach is simpler for small-scaled networks but suffers many technical challenges, such as common point failure due to heavy message traffic at the BS and high SN energy waste. In contrast, the distributed approach saves power and controls message traffic on the BS because it allows local decision and self-FD/FT with or without neighboring. According to Figure 17, the distributed architecture can be implemented in three major ways [43,89,90,91], which include self-detection, neighbor coordination, and the clustering approach. Since the basic design requirement of a WSN-based Agri-IoT is to maintain the healthy functionality and longevity of the SNs and the BS, any post-deployment impairments that cannot be self-fixed must be tolerated to not interfere with the core function of the network. Therefore, any automated FT mechanism that can be achieved through the self-reconfiguration and self-management for enhanced network availability, reliability, and dependability is encouraged in the WSN sublayer [92]. According to Figure 17, an efficient WSN-based Agri-IoT, therefore, requires a calculated mix of FT mechanisms based on the intended application. 6.2. Systematic Survey of Fault Management Schemes in WSN-Based IoT FM in Agri-IoT networks has not received adequate conceptualized research considerations. As a result, existing Agri-IoT solutions inherit the FM propositions from the traditional WSN-based IoT networks, which have proven to be unsuitable [14]. This subsection presents a concise overview of these FM schemes, including their strengths, weaknesses, and underlying theories/concepts. It then proposes a more suitable remedy for WSN-based Agri-IoT technology. In canon centralized FM schemes (see references in [93,94,95,96,97]), the underlying FM algorithm is hosted and managed on the BS, while the local SNs host and manage the FM algorithm in distributed architectures [87,88]. Although the centralized approach is simpler for small-scale networks, it suffers many technical challenges, such as common point failure due to heavy message traffic at the BS, management difficulties, and high energy wastages on distant routing. This clearly explains why most outdoor Agri-IoT testbed experiments in [1,10,11,14,18,19] experienced severe FM complications to the extent that the networks became infeasible to operate or manage at higher scalability levels. However, the distributed approach (see references in [74,76,77,91,98,99,100,101,102,103]) saves power and controls message traffic and workload on the BS because it allows local decisions as well as local-FD/FT with or without neighboring nodes. The distributed FD/FT scheme can also be self-executed, neighbor-coordinated, or clustering-aided [89,90,91]. Although the clustering-based FM architecture has promising potential to improve energy conservation, network adaptability, and ease of implementation, it has not been extensively researched and exploited. Again, distributed FD schemes are mainly established on the assumption that the failure of SNs is spatially uncorrelated, while event information is spatially correlated. Therefore, the FD’s decision framework is frequently modeled using sensory data or statistical properties of the spatial or temporally correlated SNs [79,104,105,106] from the immediate neighborhood of a node [74,103] or data from farther SNs [107]. To date, the applicability of these solutions to the Agri-IoT context has attracted several technical challenges. Consequently, the strengths and weaknesses of the main results of the benchmarking FM schemes, their underlying assumptions, and how they addressed the critical fault-affinity factors such as energy conservation, FT/FA, control message complexity, and processor burden of the SNs, are presented in the comparative evaluation summary of Table 7. Table 7. Comparative summary of FM schemes for WSN-based IoT networks. 6.3. Theories/Concepts of Benchmarking FM Schemes and Their Shortcomings The conceptual models/theories of the canon FD decision frameworks and the associated shortcomings can be expressed as follows: Statistical approaches such as Neyman–Pearson formulation [116], Bayesian statistics [77,103], and normal distribution test types (e.g., Thompson Tau statistical test [105]) are high-resource-demanding techniques that may apply to classic IoT. Still, they are unsuitable for power-constrained Agri-IoT devices or SNs. In addition to being stand-alone and without application specificity, these methods operate at high computational and control message complexities. Their operational efficiencies increase with increasing data dimensionality and also require a priori knowledge of data distribution, which is not possible in many real-life applications of Agri-IoT networks. Additionally, they rely on predefined thresholds to make local and global FD decisions. Therefore, regardless of the extensive research considerations of these methods, they are generally not suitable for low-power IoT applications, of which Agri-IoT is no exception. Graph-based FM techniques lack precise criteria for outlier detections [83,109], suffer higher computational complexities, and also make unrealistic assumptions about the data distribution. In addition, these approaches (e.g., De Bruijn graph theory [109] and depth-based techniques) are unsuitable for multidimensional and huge datasets. Machine learning decision concepts such as the k-out-of-n and majority decision rule concepts [93], naive Bayes, iterative algorithms [107], and neural network-based techniques, among others, are susceptible to high dimensional datasets, suffer high computational cost, and rely on sensitive model parameters. In addition to the stipulated shortcomings, these benchmarking FM methods usually ignore the sensory data correlation (i.e., attribute correlation, spatial correlation, and temporal correlation) properties of SNs, require high communication overhead with high FD delays [83], and normally operate in an offline manner, which is inconsistent with the modus operandi of typical Agri-IoT. Hence, they are unsuitable for the recent low-power Agri-IoT applications. 6.4. Open Issues on Existing FM Solutions for Classic WSN-Based IoT Networks and Recommended Design Guidelines for Achieving Efficient FM in WSN-Based Agri-IoT A fault in the WSN sublayer of Agri-IoT networks can be manifested as a data outlier and SN-out-of-service or node failure, both of which must be detected and resolved locally or globally using the spatially correlated event information and efficient threshold-based decision frameworks. Although there has been extensive research concerning FM schemes for the WSN sublayer, several technical challenges that require urgent contextual research considerations exist. They include the following: Most faults in the PHY layer of Agri-IoT originate from the SNs’ power exhaustion, which implies that the best fault-avoidance techniques are those that optimize power consumption. However, most FM schemes waste more energy and make the network prone to more faults/failures via high control messages and computational complexities. Most FM schemes exist as stand-alone frameworks without architectural considerations and are founded on unrealistic assumptions, which make them difficult to incorporate into existing routing protocols. The cluster-based routing architecture is endowed with many untapped local/global FM potentials and fault-avoidance capacities for the next-generation Agri-IoT. However, these promising potentials have received the least contextualized research considerations. Existing FM solutions are meant for resource-sufficient and expensive classic WSN-based IoT, not resource-constrained, context-specific use cases like Agri-IoT networks. Regarding these technical challenges, this tutorial presents the following design guidelines for building efficient and realistic FM schemes for WSN-based Agri-IoT: FM schemes must rely on realistic and contextual assumptions in order to detect and auto-tolerate sensory data outliers and SN-out-of-service faults in real-time routing protocols with minimal message, computational, and memory complexities. Such FM schemes will be suitable for all power-constrained WSN-based Agri-IoT applications. Future works on FM schemes must be embedded into specific routing protocols so that their adaptability to topological dynamism and scalability in terms of network sizes and node densities can be assessed in an unsupervised manner. Therefore, fault detection and fault-tolerance schemes based on simple threshold-based theories are the best candidates for this context, since the threshold boundaries of agronomical metrics can be accurately computed from the historical data of the location. FM schemes must incorporate redundancy check mechanisms by exploiting spatial and temporal correlations among sensory data. FM schemes should maintain a good balance between local and global FDs as well as a reasonable detection rate and false alarm rate. 7. State of the Art on Real-World, Canon WSN-Based Agri-IoT Testbed Solutions It is well documented that WSN-based Agri-IoT is the most reliable remedy for mitigating the negative impacts climate change has had on agricultural production, for which many architectural designs and testbed prototypes have been proposed [12,36]. In addition, since the autonomous, resource-constrained SNs in Agri-IoT are expected to operate without post-deployment maintenance checks, the issues of FM, power optimization, and self-organization during SN design and network deployment cannot be ignored in existing testbed solutions [12,117]. Essentially, the results from most research projects on Agri-IoT relied on simulation experiments [1,10,14], which have retained the gap between the philosophy of this technology and the comprehension of its real-world behavior for a more accurate performance assessment. This section presents a systematic performance assessment of the few real-world WSN-based Agri-IoT testbed solutions currently based on the classic WSN-based IoT principles. To understand how the benchmarking realization testbeds of Agri-IoT in [1,10,11,14,18,19] fared in real-world operational conditions, the results from their respective performances are systematically evaluated and summarized in Table 8. It was discovered that the current benchmarking testbed solutions in [1,10,11,14,18,19] are capital-intensive because they are reliant on fixed/location-restricted backbone infrastructures (see the middle of Figure 3), too complicated to deploy and manage by even expert users, based on unrealistic indoor conditions which do not commensurate real-world environmental conditions, and based on the high- power-demanding centralized or flooding architectures which further complicate network manageability when up-scaled. A concise and systematic survey of these benchmarking real-world Agri-IoT networks and their flaws in the state of the art is summarized in Table 8. Table 8. Comparative analysis of WSN-based Agri-IoT testbed solutions. Additionally, it can be established from the comparative assessment of the benchmarking Agri-IoT testbeds in Table 8 [10,11,18,19] that the embedded communication technology, event routing architecture, and the SNs’ power management are the core factors that made them capital-intensive and complicated to both experts and low-income farmers. Additionally, self-healing, reconfigurability, and adaptability mechanisms to faults were not deployed [1,14,17]; hence, faulty and turbulent conditions could not be tolerated. Furthermore, since the battery-powered SNs rely on expensive Wi-Fi and cellular communication technologies that are not freely accessible at all locations, the SNs exhausted their battery supply a few days after deployment. Similarly, those that relied on ZigBee/IEEE 802.15. 4 communication technologies with power-intensive 6LoWPAN or IPv6 protocols restricted the resulting network to drive on the problematic centralized or flooding architectures without any efficient FM techniques. As a result, these solutions used costly fixed IP infrastructural supports and the centralized routing architecture, making them practically impossible to manage as the networks scaled. This is why the SNs unstably exhausted their battery power and abruptly abridged network lifespans [1,10,11,14,18,19]. Therefore, the freely available low-power wireless technologies (e.g., LoRa, BLE, 5G, Z-wave, NB-IoT, and SigFox) that are founded on a suitable routing topology are the best candidates for making this ubiquitous application [1,16] cheap [1,20] and simple for all users. Thus, the cluster-based topology is more pivotal to addressing the above challenges of Agri-IoT [10,17] than the traditional cellular and WiFi technologies that are inaccessible in many farms, depending on their locations [10,20]. However, besides distance-power constraints, architectural support, and network manageability challenges, these freely accessible wireless communication technologies have specific limitations, which include: ZigBee technology achieves the desired power savings only when deployed in star or centralized topology [14], and it operates at its low-power distance range (10–100 m) in line-of-sight mode depending on the environmental characteristics. LoRa is limited to low-density and fixed network sizes (non-scalable), a low data rate, and a low message capacity [14]. It may require registration and expensive antennae, depending on its operation location. SigFox supports a very low data rate and requires registration. LoRa and SigFox possess complex implementations because they both require specific modules to function and gateways. WiFi, GPRS, cellular technologies, and NB-IoT are high power consumption standards and location-/architecture-restricted. BLE has a short communication range but supports clustering architecture, which is the most optimal architecture for ensuring the best operational efficiency of WSN-based Agri-IoT deployments, since this architecture allows cluster isolation and management. Therefore, a research opportunity exists for a flexible, ubiquitous, realistic, energy-efficient, self-healing, simple, low-cost, cluster-based, and wireless outdoor-based testbed that consists of infrastructure-less, task-scalable, and wirelessly configurable experimental SNs and a BS. It should also be deployed, re-deployed, monitored, controlled, and managed by non-experts to operate stably throughout the entire crop-growing season. 8. Case Study: Cluster-Based Agri-IoT (CA-IoT) for Precision Irrigation As earlier established in Figure 2, the design and implementation of Agri-IoT networks are driven by unique critical factors, which are mainly determined by the associated routing architecture, communication technology, actuation management mechanisms, and environmental impacts. In the operation phase, these factors constitute the specific objectives in Figure 10, which the supervisory routing protocol must address in order to optimize performance efficiency and stability. As systematically established above, the LEACH-inherited cluster-based architecture has the most promising potential to address these technical challenges. It helps to attain high power optimization via communication distance and packet minimization, efficient network administration/adaptability, high event data quality through auto-FM, and local data quality management, as indicated in Figure 10. So, this section presents a systematic analysis of how the merits of this architecture evolve in CA-IoT for precision irrigation use cases. Using the framework in Figure 12, the cluster-based architecture was pre-examined to uncover how the fundamental Agri-IoT design requirements and goals presented in the reference frameworks in Figure 2, Figure 9 and Figure 10 can unfold into realistic multi-parametric optimization metrics. The conceptual architectural framework of the proposed network, as illustrated in Figure 18, can be implemented using Arduino-based or Raspberry Pi(RPi)-based microcontrollers, BLE and LoRa for intra-cluster, inter-cluster, and BS–cloud communications, respectively, and DHT22/STEMMA soil moisture sensors for measuring the respective ambient and soil microclimatic parameters. Also, a unit cluster from Figure 18 detailing the key network components of MNs, CH, BS, and the field-deployed precision irrigation system is shown in Figure 19. It is assumed that the core units constituting the MNs, CH, and BS, as illustrated in Figure 19, are optimally selected and designed after Figure 2. Using Figure 18 and Figure 19 as the reference architectural frameworks for achieving our contextualized objectives, this section presents an in-depth systematic assessment and characterization of the scores of canon cluster-based routing protocols of conventional WSN-based IoT applications so that the desired MOO metrics can be appropriately deduced and adapted for the design of the associated routing for our case study. Figure 18. Conceptual architectural framework of the proposed CA-IoT for precision irrigation management. Figure 19. CA-IoT use case cluster illustrating the key network components: MNs, CH, and BS. 8.1. Characterization of Canon Clustering-Based Routing Protocols and Deduction of MOO Metrics A systematic survey (refer to Table 9) and characterization of LEACH-based routing protocols were conducted using the clustering process, CH features, and cluster features, as indicated in Figure 20, in order to conceive the core MOO metrics for the proposed CA-IoT network framework. The clustering process, CH features, and cluster features define the performance optimalities and the quality of the sampled data of the resulting architecture. Figure 20. Characterization of cluster-based networks and deduced taxonomy of MOO metrics for optimizing Agri-IoT networks. Table 9. Comparative summary of Agri-IoT-applicable clustering-based routing protocols using characterization parameters. As depicted in Figure 20a, the cluster features define the underlying connectivity issues, such as cluster quality indices (thus, cluster count, cluster size) and intra-cluster and inter-cluster communication types (thus, single-hop or multihop or both) [23,24]. From the network design viewpoint, the cluster quality depends on the optimality of the CH count and cluster sizes, which in turn rely on the core design parameters, such as the spatial density and uniformity of the deployed nodes, the specification of the wireless communication standard, the routing architecture, and the size of the network [47]. Since the deployment of SNs in a typical Agri-IoT can be controlled, the stipulated cluster quality properties can be optimized to resolve connectivity issues in Figure 20b. In a randomly deployed field, these cluster quality parameters can be optimized using a pairing-based SN duty-scheduling mechanisms [9,12]. Secondly, the CH features can be static, mobile, or role-rotated in both homogeneous or heterogeneous networks [9,12] based on the SNs’ resource hierarchy. Additionally, the CHs can be assigned different tasks, such as data aggregation, FM, coordinating network reconfiguration or duty cycling, and network maintenance, depending on their resource capacities and network requirements. This case study is based on static SNs and the distributed network construction approach (see references in [9,12,33,126,127,128,129,130,131,132]), where the SNs locally manage the entire clustering process, and a CH is elected without the entire network’s information. As shown in Figure 20a, the clustering process can be characterized by the clustering method/network type (thus, centralized or distributed), the CH selection method, reclustering or network adaptability to topological or scalable conditions, and the complexities (thus, control message and computational complexities) of the entire network operation cycle. Unlike the static approach with fixed CH, the adaptive clustering approach selects CH based on the current network conditions and rotates this role. However, both approaches can incorporate self-reclustering techniques to self-heal SN-out-of-service faults. Data outlier faults can be best detected and corrected using threshold-based decision theory or spatial correlation methods with the least complexities. Due to the large-scale and high deployment densities of WSN-based Agri-IoT, the distributed clustering process is more suitable for enhancing local FM, scalability, network management, and power optimization than the centralized approaches [37,47]. Generally, the CA-IoT network can be optimized by formulating the deduced optimal decision metrics in Figure 20a into a MOO framework and multihop routing model in order to provide the guidelines for the design of the WSN sublayer of Agri-IoT. From the comparative evaluations of Figure 10 and Figure 20a, a taxonomy of MOO metrics for designing an efficient WSN-based CA-IoT network is proposed in Figure 20b. To enhance the clarity of the state of the art on cluster-based protocols and justify the need for the proposed MOO metrics, a comparative summary based on the characterization parameters is presented in Table 9. 8.2. CH Election Techniques A CH selection process is very critical to the resulting network’s performance efficiency. In addition to centralized networks and the computationally expensive fuzzy-based clustering approaches [133,134], the efficiencies of all LEACH-inherited protocols are mainly dependent on their CH selection techniques [47,49]. Therefore, the correct estimation of the cluster quality metrics (i.e., CHs count and cluster size) is pivotal in attaining the objectives in Figure 10. With the aid of nodes’ residual energy and location metrics, the optimal CH count and cluster size can be preset before network deployment. Currently, these metrics are randomly selected using a probabilistic approach in LEACH-inherited protocol [9,21] or derived using a deterministic or an attribute-based method [47,135]. However, the probabilistic clustering, such as the LEACH-inherited protocols, is expected to perform better in terms of network lifespan, minimal clustering overhead, improved connectivity, network/coverage stability, low latency, collision-free routing, load balancing, high network stability span, and algorithmic simplicity if the optimal CH count was predefined correctly [136]. However, the CH count is randomly predefined in these protocols [9,21], which undermines the CH’s stability and the resulting architecture’s optimality. This challenge can be addressed via common CH selection metrics including Euclidean distance, intra-cluster/inter-cluster communication costs, energy-harvesting capacities, and probabilistic factors. To date, the related attempts in [49,126,137,138,139] only relied on the SNs’ residual energy and location information to re-elect CHs after the initial CH count is defined, which cannot be ideal for WSN-based Agri-IoT. For instance, an active SN in a particular round decides whether or not to become a CH by choosing a random number ( 𝑟 𝑛 ) ranging between 0 and 1 and comparing the number with a specified threshold 𝑇ℎ . A node, therefore, becomes a CH for that round if 𝑟 𝑛 <𝑇ℎ , where 𝑇ℎ is expressed as: 𝑇ℎ= ⎧ ⎩ ⎨     𝑝 𝑑 1− 𝑝 𝑑 ×((𝑓𝑖𝑟𝑠𝑡−𝑟𝑜𝑢𝑛𝑑)𝑚𝑜𝑑 1 𝑝 𝑑 , 0, if 𝑛∈𝐺 otherwise (1) where 𝑝 𝑑 is the desired percentage of CHs or CH count per round, and G is the number of SNs that have not been a CH in the previous 1/𝑝 rounds. The authors in [119] proposed a three-layered LEACH (TL-LEACH) that operates in three functional phases—CH election, MN recruitment, and data transfer—to enhance the energy efficiency of LEACH. Their first-level CH election approach modified Equation (1) into an enhanced threshold 𝑇(𝑖) , which is expressed as: 𝑇(𝑖)= ⎧ ⎩ ⎨   (𝑟+1)×𝑚𝑜𝑑( 1 𝑝 ×𝑝), 0, if 𝑖∈𝐺 otherwise (2) where p is the CH count, r is the current round number, and G is the number of SNs that have not been a CH in the previous 1/𝑝 rounds. The second-level CHs are selected from the first-level CHs based on the shortest distance to the BS to function as aggregated packet forwarders or relay CHs (RCHs). The authors in [120] introduced energy ( 𝐸(𝑖) ) and distance ( 𝐷(𝑖) ) attributes into Equation (1) to improve the load-balancing merit of LEACH. The resulting 𝑇ℎ is expressed as: 𝑇ℎ= ⎧ ⎩ ⎨     𝑝 𝑑 1− 𝑝 𝑑 [𝑟×𝑚𝑜𝑑 1 𝑝 𝑑 ] ×[𝐸(𝑖)+(1−𝐷(𝑖))], 0, if 𝑛∈𝐺 otherwise (3) Multihop routing via relay CHs (RCHs) was recommended for distant CHs in the future scope of [120]. In the LEACH presented with a distance-based threshold (LEACH-DT) algorithm in [121], the probability of becoming a CH depends on the relative distance between a node and the BS. This algorithm differs from the LEACH algorithm because the desired percentage of CHs ( 𝑝 𝑖 ) is predefined using Equation (5), while the threshold 𝑇(𝐼,𝑟) is expressed as: 𝑇(𝑖,𝑟)= ⎧ ⎩ ⎨     𝑝 𝑖 1− 𝑝 𝑖 ×[𝑟×𝑚𝑜𝑑 1 𝑝 𝑖 ] , 0, if  𝐺 𝑖 (𝑟)=0 if  𝐺 𝑖 (𝑟)=1 (4) Note that the terms retain their usual definitions, namely: 𝑝(𝑖)=𝑘 𝜉 𝑖 ∑ 𝑁 𝑗=1 𝜉 𝑗 ,0≤ 𝑝 𝑖 ≤1, (5) where 𝜉 𝑖 =1/ 𝐸 𝐶𝐻                × 𝑑 𝑖 − 𝐸 𝑛𝑜𝑛−𝐶𝐻                              , (6) The variable 𝑑 𝑖 depicts the distance between node i and the BS, and 𝐸 𝐶𝐻 and 𝐸 𝑛𝑜𝑛−𝐶𝐻 are the average residual energies in CHs and non-CHs, respectively. The authors further established the need for a multihop routing approach in simulations and real-world WSNs to validate the countless theoretical propositions and benefits. In the decentralized energy-efficient hierarchical cluster-based routing algorithm (DHCR) [123], SNs compete to become CHs. First, the BS broadcasts a trigger message at a specific range. The receiving nodes then compete to become a CH by disseminating a new message containing their residual energies and distances from the BS. Using this information, a neighboring node i within the target range receives the message and calculates its 𝐶𝐻 𝑆 𝑛𝑓𝑢 𝑛 𝑖 as: 𝐶𝐻 𝑆 𝑛𝑓𝑢 𝑛 𝑖 =𝑎× 𝐸𝑟 𝑒 𝑖 𝐸 𝑚𝑎𝑥 +𝑏× 1 𝐷𝑖𝑠−𝑇𝑜−𝐵 𝑆 𝑖 , (7) where 𝐸𝑟 𝑒 𝑖 and 𝐸 𝑚𝑎𝑥 are the residual and initial energy levels of node i, respectively; 𝐷𝑖𝑠−𝑇𝑜−𝐵 𝑆 𝑖 is the distance between node i and the BS, and a and b are real random values between 0 and 1 such that 𝑎+𝑏=1 . The values of 𝐷𝑖𝑠−𝑇𝑜−𝐵 𝑆 𝑖 of node i and its neighbors are compared, and the node with the highest 𝐷𝑖𝑠−𝑇𝑜−𝐵 𝑆 𝑖 value is selected as the CH. A first-level CH broadcasts its residual energy, neighboring node count, and distance from the BS via a specific route. The next-level CHs receive the information and similarly repeat the procedure to ensure that every node determines a redistributor CH to the BS at the same time. A redistributor CH has more energy and fewer neighbors (neighboring degrees). However, the Hamilton energy-efficient routing protocol (HEER) [124] creates an entire cluster of nodes, aggregates data, and transmits them to the BS via a Hamiltonian path that has been created by the entire cluster of nodes and controls the cluster size by selecting one node as the CH using the probability function p, which can be expressed as: 𝑝= 𝐿 𝑚𝑒𝑠𝑠𝑎𝑔𝑒 𝐹 𝑚𝑎𝑥 (8) where 𝐿 𝑚𝑒𝑠𝑠𝑎𝑔𝑒 is the size of every node, and 𝐹 𝑚𝑎𝑥 is the maximum size of a frame. The HEER protocol creates the clusters only once in the first round based on LEACH, and it role-rotates the CHs per the energy on the Hamiltonian path after a determined period. Similarly, the two-phased EAMR protocol [125] randomly preselects the CH. A CH also selects its closest CH as its redistributor CH. The clusters are static over the entire network lifetime, and the CH role rotates randomly within the clusters according to a cluster replacement threshold. The new CH inherits the redistributor role if the old CH had one. Overall, since the node location, residual energy, and sleep schedule are indispensable in the CH selection process, the CH selection methods proposed by the authors in [9,12,36,120,140] are recommended WSN-based Agri-IoT applications. 8.3. Challenges of Existing MOO Frameworks and Recommended Future Works As Figure 9 and Figure 10 illustrate, the performance efficiency of an infrastructure-less WSN-based Agri-IoT mainly depends on the embedded MOO remedies in the associated supervisory routing protocol [12]. Several MOO frameworks have been researched since Agri-IoT networks are subjected to multiple design and operational constraints. A MOO framework is expected to formulate multiple objective functions from a set of MOO metrics to simultaneously optimize these multiple objectives, such as the maximal energy savings, highest connectivity, best latency, highest reliability, and balanced SN power depletion rates across the network. Although the MOO methods are the best candidates for Agri-IoT, the existing MOO solutions used in Agri-IoT are adopted from traditional WSN-based IoT without any contextual evaluation [12,16,26]. Consequently, they have not fulfilled their intended purposes due to several technical challenges, including the following: They are limited to non-cluster-based network architectures, which implies that the promising potentials of the clustering architecture are not adequately exploited [9,12,50,51]. They are frequently implemented in the operational phase of the network, which makes it challenging to find global optimal solutions with a balanced tradeoff among conflicting objective functions. The performance optimality of the Agri-IoT network starts from the SN design. They rely on high-resource-demanding algorithms, such as mathematical programming-based scalarization methods, multi-objective genetic algorithms (MOGAs), heuristics/metaheuristics-based optimization algorithms, and other advanced optimization techniques [23,26,48], making them unsuitable for the battery-powered SNs in Agri-IoT. There are no contextual MOO guidelines based on Figure 20 to govern the PHY-layer design of Agri-IoT to achieve global optimal solutions with a balanced tradeoff among conflicting objectives. Consequently, there are conflicting scenarios in existing MOO solutions [50]. Therefore, there is an urgent demand for a realistic low-power MOO framework for CA-IoT networks that is founded on the core WSN design metrics and MOO taxonomy metrics in Figure 10 and the top of Figure 20, respectively. The following section assesses how evaluations and deductions evolve in a typical event sampling and routing protocol in a CA-IoT network for precision irrigation system management. 9. Design of WSN-Specific CA-IoT Routing Protocol This section proposes a CA-IoT-based supervisory routing protocol that supports static SNs, rotatable/fixed CH roles, and enhanced SN resource management under the deterministic deployment approach. This can improve energy savings, connectivity, distance moderation, and multihop inter-cluster communication in the resulting network. The operational cycle and the embedded activities of our WSN-based CA-IoT protocol for precision irrigation application, as illustrated in Figure 21, include the following: Figure 21. Proposed operation cycle for designing our CA-IoT network’s routing protocol. Network Construction or Setup Phase: This phase involves network modeling, CH election, and cluster formation, which is explained in Figure 21. The active–sleep duty-cycle scheduling ensures the SNs only switch to active mode during their scheduled sampling durations. In randomly deployed WSNs, redundant event reporting can be avoided using a correlated pairing-based active–sleep duty-cycle scheduling approach in [12]. The optimal CH count and cluster size must be predefined from the resource capacities of the SNs. After the initial CH election, the MNs are recruited and assigned their respective sampling and intra-cluster communication timeslots. Sampling, Data Management, and Transmission Phase: The tasks executed in this phase include event sampling, intra-cluster and inter-cluster data transmissions, data outlier FM, and event data redundancy management. Since microclimatic soil parameters do not change swiftly [1,14], sampling can only be scheduled during the day at 3-hourly time intervals. In addition to power optimization, the clustering approach provides superb potential for both local and global FM using threshold-based FM theory and spatial correlation techniques. Based on the architecture in Figure 19 and the resource limitations of the SNs, it is recommended that the communication beyond the BS or gateway can utilize LoRa or Wi-Fi AirBox, whereas the intra-cluster and inter-cluster communications must be the freely available low-power BLE technology, since it is the most suitable for the clustering architecture. Network Maintenance and Reclustering Phase: This phase resolves all unforeseen topological dynamics caused by the SNs’ failures, network scalability, node mobility, and unexpected operational flaws, without interfering with the normal network functionality via adaptive reclustering, self-healing, and multihop routing techniques [12,23,24]. Here, a parent CH coordinates the election of child CHs (CCHs). While all non-CCHs switch to sleep mode, the CCHs recruit new MNs using location and residual energy parameters, assign them their respective sampling timeslots, and repeat Phase 2 afterward, as shown in Figure 21. SN-out-of-service faults are auto-detected and tolerated in this phase. Additionally, Figure 21 uniquely incorporates correlated pairing-based duty cycling, constant control message complexity FM/data redundancy scheme, network construction/maintenance, and cluster quality measures that can ensure unprecedented energy savings and event data quality. This clustering approach can further minimize energy wastage via a suitable MAC method, a low-power wireless communication standard, data aggregation with data redundancy checks, and CH role rotation, among other factors. Although the various sections of the deduced MOO metrics have been implemented in our CA-IoT operational cycle, the most desired performance can be optimally attained when the MOO metrics are modeled into their respective objective functions, and their optimal values are determined and implemented in both simulation and testbed experiments in future works. Also, a realistic multihop routing framework can also be inculcated into this protocol for large-scale applications. 10. Open Issues and Future Works: Cluster-Based WSN-Specific Agri-IoT Networks This tutorial has firmly established that the WSN-based Agri-IoT is an indispensable component of smart or precision farming and greenhouses, despite its resource- and deployment-induced challenges [12,26,141]. Unlike the conventional IoT, Agri-IoT is compelled to drive on batteries and affordable task-scalable SNs. However, it must meet the expectations in Figure 2 to guarantee a stable performance. The cluster-based routing technique has emerged with promising potential to mitigate these challenges. However, results from existing testbed solutions in this study show otherwise due to the absence of a contextualized in-depth overview of Agri-IoT as well as the following open issues which have not received extensive contextual research considerations in Agri-IoT applications: The cluster-based routing architecture for WSN-based Agri-IoT has not received holistic and practical research considerations as far as FM, power optimization, and network adaptability are concerned. Therefore, there is a demand for multi-parametric optimization frameworks and guidelines for designing and implementing the WSN sublayer. Concerning FM, most proposed schemes in the canon state of the art are stand-alone, have high control message and computational complexities (energy-inefficient), and are mostly incompatible with the clustering architecture [25,52]. The desired FM schemes for CA-IoT applications should be equipped with fault-avoidance mechanisms and the capacity to detect and self-heal root faults (SN-out-of-service and sensory data outliers [25]), not their effects. Multihop routing, which is a requirement to attain the desired energy savings and network adaptability in large-scale CA-IoT networks, is asserted to be more energy-efficient only in simulation experiments [33,120,121,123,124,125,128,129,130] but not in real-world implementation [22,23,24]. This imbalance is due to a lack of a comprehensive and reliable theoretical multihop routing framework that is based on the total communication costs of multihop routing. There is a demand for a more realistic and holistic MOO framework that can optimize the operational efficiency metrics such as cluster size, cluster counts, density/uniformity of nodes, communication distance, and activity schedule/duration, right from the network design phase to the operational phase of Agri-IoT networks. Although the current literature supports adaptive clustering with CH role rotation ideology, there exists the need for an optimal initial CH-count estimator in order to improve the stability of CH elections and the architecture. Thus, the cluster quality indices (e.g., optimal cluster count and size) must be predetermined before defining them in the associated CH election method, since CH stability is compromised in most clustering methods [9,21,119,120,121,123,124]. Most protocols in the state of the art rely on perfect homogeneous networks, which is unrealistic due to variations in modular specifications and resource utilization and the fact that different SNs may have different communication and data computational roles. Therefore, a more realistic, contextualized, and adaptive clustering approach that leverages the gap between the philosophy and practice of Agri-IoT applications is needed. In addition to the parent LEACH protocol [21,61] which is a complete suite application comprising routing, MAC, and physical characteristics for wireless communication in WSNs, most benchmarking MAC protocols purposed for traditional IoT applications are shelved, since they are developed in solitude without application specificity and network architectural considerations. A custom-built and holistic protocol suite for Agri-IoT remains a research opportunity. 11. Conclusion and Future Works This tutorial presented: (1) a systematic overview of the fundamental concepts, technologies, and architectural standards of WSN-based Agri-IoT; (2) an evaluation of the technical design requirements of a robust, ubiquitous, self-healing, energy-efficient, adaptive, and affordable Agri-IoT; (3) a comprehensive survey of the benchmarking FM techniques, communication standards, routing protocols, MMAC protocols, and WSN-based testbed solutions; and (4) an in-depth case study on how to design a self-healing, energy-efficient, affordable, adaptive, stable, and cluster-based WSN-specific Agri-IoT from a proposed taxonomy of MOO metrics that can guarantee optimized network performance. Furthermore, this tutorial established new taxonomies of faults, architectural layers, and MOO metrics for CA-IoT networks. Using the open technical issues, it recommended application-specific requirements of Agri-IoT, general design expectations, and remedial measures, and it evaluated them in CA-IoT for precision irrigation in order to optimally exploit the proposed MOO metrics in a typical CA-IoT design in both simulation and real-world deployment scenarios. Overall, this tutorial can serve as a new reference document for the IoT community and Agri-IoT designers, since it adequately examined all critical aspects of WSN-based Agri-IoT networks from theoretical modeling to real-world implementation. Author Contributions The First Author contributed 60% while the second the third Authors contributed 20% each. Conceptualization, E.E.; methodology, A.M.W.; writing, review and editing, E.E., O.T. and A.M.W.; supervision, O.T. and A.M.W.; project administration, E.E.; and funding acquisition, E.E., and O.T. All authors have read and agreed to the published version of the manuscript. Funding The work was carried out with the financial support of icipe- World Bank Financing Agreement No D347-3A and the World Bank Korea Trust Fund Agreement No TF0A8639 for the PASET Regional Scholarship and Innovation Fund. The views expressed herein do not necessarily reflect the official opinions of the donors. Data Availability Statement This research has no such data. Conflicts of Interest The authors declare no conflict of interest. Abbreviations SN Sensor Node WSN Wireless Sensor Network IoT Internet of Things Agri-IoT Agricultural Internet-of-Things CA-IoT Cluster-based Agricultural Internet of Things FD/FT Fault Detection and Fault Tolerance FA Fault Avoidance FM Fault Management MOO Multi-Objective Optimization BS Base Station MMAC Multichannel Medium Access Control MAC Medium Access Control BLE Bluetooth Low-Energy CH Cluster Head RCH Relay Cluster Head MN Member Node AODV Ad hoc On-demand Distance Vector RPL Routing over Low-Power and Lossy Networks protocol CAM Channel Access Management DCO Duty-Cycle Optimization References Kumar, P.; Reddy, S.R.N. Lessons Learned From the Deployment of Test-Bed for Precision Agriculture. In Proceedings of the International Conference on Sustainable Computing in Science, Technology & Management (SUSCOM-2019), Jaipur, India, 26–28 February 2019; pp. 25686–25697. [Google Scholar] [CrossRef] Abbasi, M.; Yaghmaee, M.H.; Rahnama, F. Internet of Things in agriculture: A survey. In Proceedings of the 2019 3rd International Conference on Internet of Things and Applications (IoT), Isfahan, Iran, 17–18 April 2019; pp. 1–12. [Google Scholar] Gennari, P.; Moncayo, J.R. World Food and Agriculture Statistical Pocketbook; Food and Agriculture Organization of the United Nations: Rome, Italy, 2018; Volume 1, pp. 1–248. [Google Scholar] Shiferaw, B.; Tesfaye, K.; Kassie, M.; Abate, T.; Prasanna, B.M.; Menkir, A. Managing vulnerability to drought and enhancing livelihood resilience in Sub-Saharan Africa: Technological, institutional and policy options. Weather. Clim. Extrem. 2014, 3, 67–79. [Google Scholar] [CrossRef] [Green Version] Devi, K.H.; Gupta, M.V. IoT Application, A Survey. Int. J. Eng. Technol. 2018, 7, 891–896. [Google Scholar] [CrossRef] [Green Version] Stoces, M.; Vaněk, J.; Masner, J.; Pavlík, J. Internet of Things (IoT) in Agriculture—Selected Aspects. AGRIS On-Line Pap. Econ. Inform. 2016, 8, 83–88. [Google Scholar] [CrossRef] [Green Version] Lova, R.; Vijayaraghavan, V. IoT Technologies in Agricultural Environment: A Survey. Wireless Pers. Commun. 2020, 113, 2415–2446. [Google Scholar] [CrossRef] Farooq, M.S.; Riaz, S.; Abid, A.; Abid, K.; Naeem, M.A. A Survey on the Role of IoT in Agriculture for the Implementation of Smart Farming. IEEE Access 2019, 7, 56237–156271. [Google Scholar] [CrossRef] Tauseef, S.; Nadeem, J.; Talha, Q. Energy Efficient Sleep Awake Aware (EESAA) intelligent Sensor Network routing protocol. In Proceedings of the 15th International Multitopic Conference (INMIC), Islamabad, Pakistan, 13–15 December 2012; pp. 317–322. [Google Scholar] [CrossRef] [Green Version] Hartung, R.; Kulau, U.; Gernert, B.; Rottmann, S.; Wolf, L. On the Experiences with Testbeds and Applications in Precision Farming. In Proceedings of the 15th ACM Conference on Embedded Network Sensor Systems, Delft, The Netherlands, 5 November 2017; pp. 54–61. [Google Scholar] Langendoen, K.; Baggio, A.; Visser, O. Murphy loves potatoes: Experiences from a pilot sensor network deployment in precision agriculture. In Proceedings of the 20th IEEE International Parallel & Distributed Processing Symposium, Rhodes, Greece, 25–29 April 2006; Volume 51, pp. 8–13. [Google Scholar] [CrossRef] [Green Version] Effah, E.; Thiare, O. Realistic Cluster-Based Energy-Efficient and Fault-Tolerant (RCEEFT) Routing Protocol for Wireless Sensor Networks (WSNs). In Advances in Information and Communication; Springer: Cham, Switzerland, 2020; pp. 320–337. [Google Scholar] Nasser, N.; Karim, L.; Ali, A.; Anan, M.; Khelifi, N. Routing in the Internet of Things. In Proceedings of the GLOBECOM 2017—2017 IEEE Global Communications Conference, Singapore, 4–8 December 2017; pp. 1–6. [Google Scholar] Jawad, H.M.; Nordin, R.; Gharghan, S.K.; Jawad, A.M.; Ismail, M. Energy-Efficient Wireless Sensor Networks for Precision Agriculture: A Review. Sensors 2017, 8, 1781. [Google Scholar] [CrossRef] [Green Version] Clausen, T.; Herberg, U.; Philipp, M. A critical evaluation of the IPv6 Routing Protocol for Low Power and Lossy Networks (RPL). In Proceedings of the 2011 IEEE 7th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob), Shanghai, China, 10–12 October 2011; pp. 365–372. [Google Scholar] Effah, E.; Thiare, O.; Wyglinski, A.M. Multi-Objective Modeling of Clustering-Based Agricultural Internet of Things. In Proceedings of the 2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall), Victoria, BC, Canada, 18 November–16 December 2020. [Google Scholar] [CrossRef] Effah, E.; Thiare, O.; Wyglinski, A.M. Energy-Efficient Multihop Routing Framework for Cluster-Based Agricultural Internet of Things (CA-IoT). In Proceedings of the 2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall), Victoria, BC, Canada, 18 November–16 December 2020. [Google Scholar] [CrossRef] Khan, R.; Ali, I.; Zakarya, M.; Ahmad, M.; Imran, M.; Shoaib, M. Technology-Assisted Decision Support System for Efficient Water Utilization: A Real-Time Testbed for Irrigation Using Wireless Sensor Networks. IEEE Access 2018, 6, 25686–25697. [Google Scholar] [CrossRef] Ahmed, N.; De, D.; Hussain, I. Internet of Things (IoT) for Smart Precision Agriculture and Farming in Rural Areas. IEEE Internet Things J. 2018, 5, 4890–4899. [Google Scholar] [CrossRef] Effah, E.; Dorgloh, W. GSM-Controlled Irrigation System (GSMCIS) for Vegetable Farmers in Ghana. Ghana J. Technol. 2016, 1, 21–24. [Google Scholar] Mehmood, A.; Mauri, J.L.; Noman, M.; Song, H. Improvement of the Wireless Sensor Network Lifetime Using LEACH with Vice-Cluster Head. Ad Hoc Sens. Wirel. Netw. 2015, 28, 1–17. [Google Scholar] Haenggi, M.; Puccinelli, D. Routing in Ad Hoc Networks: A Case for Long Hops. IEEE Commun. Mag. 2005, 43, 93–101. [Google Scholar] Pešović, U.M.; Mohorko, J.J.; Benkič, K.; Čučej, Ž.F. Single-hop vs. multi-hop—Energy efficiency analysis in wireless sensor networks. In Proceedings of the 18th Telekomunikacioni forum TELFOR 2010, Belgrade, Serbia, 23–25 November 2010; pp. 471–474. [Google Scholar] Haenggi, M. Twelve Reasons not to Route over Many Short Hops. In Proceedings of the IEEE 60th Vehicular Technology Conference, Los Angeles, CA, USA, 26–29 September 2004; pp. 1–4. [Google Scholar] Effah, E.; Tiare, O. Survey: Faults, Fault Detection and Fault Tolerance Techniques in Wireless Sensor Networks. Int. J. Comput. Sci. Inf. Secur. 2018, 16, 1–14. [Google Scholar] Ferentinos, K.; Tsiligiridis, T. Adaptive design optimization of wireless sensor networks using genetic algorithms. Comput. Netw. 2007, 51, 1031–1051. [Google Scholar] World Bank. Access to electricity (% of population)—Sub-Saharan Africa. In The World Bank and UN Data on SSA; The World Bank: Washington, DC, USA, 2021; pp. 1–3. [Google Scholar] Elleuchi, M.; Boujelben, M.; Saleh, M.S.B.; Obeid, A.M.; Abid, M. Tree based routing protocol in WSNs: A comparative performance study of the routing protocols DEEC and RPL. Future Technol. Publ. 2016, 5, 7–16. [Google Scholar] Al-Fuqaha, A.; Guizani, M.; Mohammadi, M.; Aledhari, M.; Ayyash, M. Internet of Things: A Survey on Enabling Technologies, Protocols and Applications. IEEE Commun. Surv. Tutor. 2015, 17, 2347–2376. [Google Scholar] [CrossRef] Loukatos, D.; Manolopoulos, I.; Arvaniti, E.-S.; Arvanitis, K.G.; Sigrimis, N.A. Experimental Testbed for Monitoring the Energy Requirements of LPWAN Equipped Sensor Nodes. IFAC-PapersOnLine 2018, 51, 309–313. [Google Scholar] [CrossRef] Akyildiz, I.F.; Su, W.; Sankarasubramaniam, Y.; Cayirci, E. A survey on sensor networks. IEEE Commun. Mag. 2002, 40, 102–114. [Google Scholar] [CrossRef] [Green Version] Jovanovic, M.D.; Djordjevic, G.L.; Nikolic, G.S.; Petrovic, B.D. Multichannel Media Access Control for Wireless Sensor Networks: A survey. In Proceedings of the 2011 10th International Conference on Telecommunication in Modern Satellite Cable and Broadcasting Services (TELSIKS), Nis, Serbia, 5–8 October 2011; pp. 741–744. [Google Scholar] [CrossRef] Xu, L.; O’Hare, G.; Collier, R. A Smart and Balanced Energy-Efficient Multihop Clustering Algorithm (Smart-BEEM) for MIMO IoT Systems in Future Networks. Sensors 2017, 17, 1574. [Google Scholar] Fei, Z.; Li, B.; Yang, S.; Xing, C.; Chen, H.; Hanzo, L. A Survey of Multi-Objective Optimization in Wireless Sensor Networks: Metrics, Algorithms, and Open Problems. IEEE Commun. Surv. Tutor. 2017, 19, 550–586. [Google Scholar] McBratney, A.O. Future Directions of Precision Agriculture. Precis. Agric. 2005, 6, 7–23. [Google Scholar] [CrossRef] Effah, E.; Thiare, O. Estimation of Optimal Number of Clusters: A New Approach to Minimizing Intra-Cluster Communication Cost in WSNs. Int. J. Innov. Technol. Explor. Eng. 2018, 8, 521–524. [Google Scholar] Asim Zeb, A.K.M.; Islam, M.; Zareei, M.; Mamoon, I.A.; Mansoor, N.; Baharun, S.; Katayama, Y.; Komaki, S. Clustering Analysis in Wireless Sensor Networks: The Ambit of Performance Metrics and Schemes Taxonomy. Int. J. Distrib. Sens. Netw. 2016, 12, 4979142. [Google Scholar] Younis, O.; Fahmy, S. HEED: A hybrid, energy-efficient, distributed clustering approach for ad hoc sensor networks. IEEE Trans. Mob. Comput. 2004, 3, 660–669. [Google Scholar] Rajaram, M.L.; Kougianos, E.; Mohanty, S.P.; Choppali, U. Wireless Sensor Network Simulation Frameworks: A Tutorial Review: MATLAB/Simulink bests the rest. IEEE Consum. Electron. Mag. 2016, 5, 63–69. [Google Scholar] [CrossRef] Gurpreet, K.; Sukhpreet, K. Enhanced M-Gear Protocol for Lifetime Enhancement in Wireless Clustering System. Int. J. Comput. Appl. 2016, 147, 30–34. [Google Scholar] Yen, H. Optimization-based channel constrained data aggregation routing algorithms in multi-radio wireless sensor networks. Sensors 2009, 9, 4766–4788. [Google Scholar] [PubMed] [Green Version] Le, T.T.T.; Moh, S. Link Scheduling Algorithm with Interference Prediction for Multiple Mobile WBANs. Sensors 2017, 17, 2231. [Google Scholar] [CrossRef] [Green Version] Darwish, I.M.; Elqafas, S.M. Enhanced Algorithms for Fault Nodes Recovery in Wireless Sensors Network. Int. J. Sens. Netw. Data Commun. 2016, 6, 150. [Google Scholar] Manisha, M.; Deepak, N. Fault Detection in Wireless Sensor Networks. IPASJ Int. J. Comput. Sci. 2015, 3, 6–10. [Google Scholar] Banerjee, I.; Chanak, P.; Rahaman, H.; Samanta, T. Effective fault detection and routing scheme for wireless sensor networks. Comput. Electr. Eng. 2014, 40, 291–306. [Google Scholar] [CrossRef] Sharma, P.; Kaur, I. A Comparative Study on Energy Efficient Routing Protocols in Wireless Sensor Networks. Int. J. Comput. Sci. Issues 2015, 8, 98–106. [Google Scholar] Faniana, F.; Rafsanjanibc, M. Cluster-based routing protocols in wireless sensor networks: A survey based on methodology. J. Netw. Comput. Appl. 2019, 142, 111–142. [Google Scholar] Iqbal, M.; Naeem, M.; Anpalagan, A.; Ahmed, A.; Azam, M. Wireless Sensor Network Optimization: Multi-Objective Paradigm. Sensors 2015, 15, 17572–17620. [Google Scholar] [PubMed] Mamalis, B.; Gavalas, D.; Konstantopoulos, C.; Pantziou, G. Clustering in Wireless Sensor Networks. In RFID and Sensor Networks; CRC Press: Boca Raton, FL, USA, 2009; pp. 324–364. [Google Scholar] Kalkha, H.; Satori, H.; Satori, K. Performance Evaluation of AODV and LEACH Routing Protocol. Adv. Inf. Technol. Theory Appl. 2016, 1, 113–118. [Google Scholar] Dwivedi, A.K.; Kushwaha, S.; Vyas, O.P. Performance of Routing Protocols for Mobile Adhoc and Wireless Sensor Networks: A Comparative Study. Int. J. Recent Trends Eng. 2009, 2, 101–105. [Google Scholar] Fjellin, J.E. Medium Access Control (MAC) in WSN. Unpublished Lecture Notes. 12 October 2018. pp. 1–27. Available online: https://www.uio.no/studier/emner/matnat/ifi/nedlagte-emner/INF5910CPS/h11/undervisningsmateriale/20111101_mac_in_wsn.pdf (accessed on 16 July 2023). Ye, W.; Heidemann, J.; Estrin, D. Medium access control with coordinated adaptive sleeping for wireless sensor networks. IEEE/ACM Trans. Netw. 2004, 12, 493–506. [Google Scholar] [CrossRef] [Green Version] Kabara, J.; Calle, M. MAC Protocols Used by Wireless Sensor Networks and a General Method of Performance Evaluation. Int. J. Distrib. Sens. Netw. 2012, 8, 834784. [Google Scholar] [CrossRef] [Green Version] Buettner, M.; Yee, G.V.; Anderson, E.; Han, R. X-MAC: A Short Preamble MAC Protocol for Duty-Cycled Wireless Sensor Networks. 2006, pp. 307–320. Available online: http://portal.acm.org/citation.cfm?id=1182807.1182838 (accessed on 16 July 2023). Kuntz, R.; Gallais, A.; Noel, T. Auto-adaptive MAC for energy efficient burst transmissions in wireless sensor networks. In Proceedings of the 2011 IEEE Wireless Communications and Networking Conference, Cancun, Mexico, 28–31 March 2011; pp. 233–238. [Google Scholar] Polastre, J.; Hill, J.; Culler, D. Versatile low power media access for wireless sensor networks. In Proceedings of the Second International Conference on Embedded Networked Sensor Systems (SenSys’04), Baltimore, MD, USA, 3–5 November 2004; pp. 95–107. [Google Scholar] Ergen, S.C.; Varaiya, P. PEDAMACS: Power efficient and delay aware medium access protocol for sensor networks. IEEE Trans. Mob. Comput. 2006, 5, 920–930. [Google Scholar] [CrossRef] Tang, L.; Sun, Y.; Gurewitz, O.; Johnson, D.B. PWMAC: An energy-efficient predictive-wakeup MAC protocol for wireless sensor networks. In Proceedings of the 2011 IEEE INFOCOM, Shanghai, China, 10–15 April 2011; pp. 1305–1313. [Google Scholar] Gautam, G.C.; Chand, N. A Novel Cluster Based Time Synchronization Technique for Wireless Sensor Networks. Wirel. Sens. Netw. 2017, 9, 145–165. [Google Scholar] [CrossRef] Heinzelman, W.B.; Chandrakasan, A.P.; Balakrishnan, H. An application-specific protocol architecture for wireless microsensor networks. IEEE Trans. Wirel. Commun. 2002, 1, 660–670. [Google Scholar] [CrossRef] [Green Version] Ben-Othman, J.; Mokdad, L.; Yahya, B. An energy efficient priority-based QoS MAC protocol for wireless sensor networks. In Proceedings of the 2011 IEEE International Conference on Communications (ICC), Kyoto, Japan, 5–9 June 2011; pp. 1–6. [Google Scholar] Kumar, A. WiseMAC Protocol for Wireless Sensor Network-An Energy-Efficient Protocol. Master’s Thesis, National Institute of Technology, Rourkela, India, 2014; pp. 1–63. [Google Scholar] Karki, V.S.; Udupi, G.R.; Gadgil, A. Advanced WiseMAC Protocol for Wireless Sensor Network. Int. Res. J. Eng. Technol. 2015, 2, 771–778. [Google Scholar] Pak, W. Ultra-low-power media access control protocol based on clock drift characteristics in wireless sensor networks. Int. J. Distrib. Sens. Netw. 2017, 13, 1550147717722155. [Google Scholar] [CrossRef] Tang, L.; Sun, Y.; Gurewitz, O.; Johnson, D.B. EM-MAC: A dynamic multichannel energy-efficient MAC protocol for wireless sensor networks. In Proceedings of the Twelfth ACM International Symposium on Mobile Ad Hoc Networking and Computing, Paris, France, 17–19 May 2011; p. 23. [Google Scholar] Lim, J.B.; Jang, B.; Sichitiu, M.L. MCAS-MAC: A Multichannel asynchronous scheduled MAC protocol for Wireless Sensor Networks. Comput. Commun. 2014, 56, 98–107. [Google Scholar] Irandegani, M.; Bagherizadeh, M. Designing an asynchronous multi-channel media access control protocol based on service quality for wireless sensor networks. Int. J. Adv. Comput. Res. 2017, 7, 190–199. [Google Scholar] [CrossRef] van Hoesel, L.F.W.; Havinga, P.J.M. A Lightweight Medium Access Protocol (LMAC) for Wireless Sensor Networks: Reducing Preamble Transmissions and Transceiver State Switches. In Proceedings of the 1st International Workshop on Networked Sensing Systems, Tokyo, Japan, 1–6 January 2004. [Google Scholar] Incel, O.D. Multi-Channel Wireless Sensor Networks: Protocols, Design And Evaluation. Ph.D. Dissertation, University of Twente, Enschede, The Netherlands, 2009; pp. 1–162. [Google Scholar] Zhang, Z.; Mehmood, A.; Shu, L.; Huo, Z.; Zhang, Y.; Mukherjee, M. A Survey on Fault Diagnosis in Wireless Sensor Networks. IEEE Access 2018, 6, 11349–11364. [Google Scholar] [CrossRef] Parhami, B. Fault-Tolerant Computing; Lecture Notes; Electrical and Computer Engineering Department, University of California: Santa Barbara, CA, USA, 2018; pp. 1–2. [Google Scholar] Raghunath, K.M.K.; Rengarajan, N. Investigation of Faults, Errors and Failures in Wireless Sensor Network: A Systematical Survey. Int. J. Adv. Comput. Res. 2013, 3, 2249–7277. [Google Scholar] Jiang, P. A New Method for Node Fault Detection in Wireless Sensor Networks. Sensors 2009, 9, 1282–1294. [Google Scholar] [CrossRef] [Green Version] Koushanfar, K.; Potkonjak, M.; Sangiovanni-Vincentell, A. Fault tolerance techniques for wireless ad hoc sensor networks. Proc. IEEE Sens. 2002, 2, 1491–1496. [Google Scholar] Oyiza, O.S. Implementation of New Fault Tolerance Solution in Wireless Sensor Networks in A Multi-Channel Context. Master’s Thesis, Department of Computer Science, African University of Science and Technology, Galadima, Nigeria, 2016; pp. 1–36. [Google Scholar] Bhattacharya, R.; Chhanda, R. Wireless sensor networks—A study of fault detection and recovery based on OSI layers. Int. J. Conceptions Comput. Inf. Technol. 2013, 1, 7–14. [Google Scholar] Yu, M.; Mokhtar, H.; Merabti, M. Self-Managed Fault Management in Wireless Sensor Networks. In Proceedings of the Second International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies (UBICOMM’08), Valencia, Spain, 29 September–4 October 2008; pp. 13–18. [Google Scholar] Panda, M.; Khilar, P.M. Distributed Byzantine Fault detection technique in wireless sensor networks based on hypothesis testing. Comput. Electr. Eng. 2015, 48, 270–285. [Google Scholar] [CrossRef] Paradis, L.; Han, Q. A Survey of Fault Management in Wireless Sensor Networks. J. Netw. Syst. Manag. 2007, 15, 171–190. [Google Scholar] [CrossRef] Ding, M.; Chen, D.; Xing, K.; Cheng, X. Localized fault-tolerant event boundary detection in sensor networks. In Proceedings of the 24th Annual Joint Conference of the IEEE Computer and Communications Societies, Miami, FL, USA, 13–17 March 2005; Volume 2, pp. 902–913. [Google Scholar] Lee, W.L.; Datta, A.; Cardell-Oliver, R. Network Management in Wireless Sensor Networks. In Handbook of Mobile Ad Hoc and Pervasive Communication; American Scientific Publishers: Valencia, CA, USA, 2006; pp. 1–201. [Google Scholar] Zhang, Y.; Dragoni, N.; Wang, J. A framework and classification for fault detection approaches in Wireless Sensor Networks with an energy efficiency perspective. Int. J. Distrib. Sens. Netw. 2015, 2, 678029. [Google Scholar] Asim, M.; Mokhtar, H.; Merabti, M. self-managing fault management mechanism for wireless sensor network. Int. J. Wirel. Mob. Netw. 2010, 2, 184–197. [Google Scholar] [CrossRef] Heena, H.; Kapoor, S. Survey of Fault Detection Algorithm in WSN. SSRG Int. J. Comput. Sci. Eng. 2015, 5, 78–81. [Google Scholar] Kaur, E.J.; Kaur, E.P. A Survey on Fault Detection and Recovery Techniques in Wireless Sensor Networks. Int. J. Eng. Res. Gen. Sci. 2015, 3, 638–642. [Google Scholar] Zhang, Z.; Chong, E.K.P.; Pezeshki, A.; Moran, W.; Howard, S.D. Detection performance in balanced binary relay trees with node and link failures. IEEE Trans. Signal Process. May 2013, 61, 2165–2177. [Google Scholar] [CrossRef] Ho, J.; Tay, W.P.; Quek, T.Q.S.; Chong, E.K.P. Robust decentralized detection and social learning in tandem networks. IEEE Trans. Signal Process. 2015, 63, 5019–5032. [Google Scholar] [CrossRef] [Green Version] Nardelli, P.H.J.; de Lima, C.H.M.; Alves, H.; Cardieri, P.; Latva-aho, M. Throughput analysis of cognitive wireless networks with Poisson distributed nodes based on location information. Ad Hoc Netw. 2015, 33, 1–18. [Google Scholar] [CrossRef] [Green Version] Umebayashi, K.; Lehtomaki, J.J.; Yazawa, T.; Suzuki, Y. Efficient Decision fusion for cooperative spectrum sensing based on OR-rule. IEEE Trans. Wireless Commun. 2012, 11, 2585–2595. [Google Scholar] [CrossRef] Luo, X.; Dong, M.; Huang, Y. On distributed fault-tolerant detection in wireless sensor networks. IEEE Trans. Comput. 2006, 55, 58–70. [Google Scholar] [CrossRef] Kakamanshadi, G.; Gupta, S.; Singh, S. A survey on fault tolerance techniques in Wireless Sensor Networks. In Proceedings of the 2015 International Conference on Green Computing and Internet of Things (ICGCIoT), Greater Noida, India, 8–10 October 2015; pp. 168–173. [Google Scholar] [CrossRef] Pedro, H.; Nardelli, J.; Ramezanipour, I.; Alves, H.; de Lima, H.M.C.; Latva-aho, M. Average Error Probability in Wireless Sensor Networks With Imperfect Sensing and Communication for Different Decision Rules. arXiv 2016, arXiv:1508.02253v2. [Google Scholar] Lau, B.C.; Ma, E.W.; Chow, T.W. Probabilistic fault detector for wireless sensor network. Expert Syst. Appl. 2014, 41, 3703–3711. [Google Scholar] [CrossRef] Tang, P.; Chow, T.W. Wireless sensor-networks conditions monitoring and fault diagnosis using neighborhood hidden conditional random field. IEEE Trans. Ind. Inform. 2016, 12, 933–940. [Google Scholar] [CrossRef] Dhal, R.; Torres, J.A.; Roy, S. Detecting link failures in complex network processes using remote monitoring. Phys. Stat. Mech. Appl. 2015, 437, 36–54. [Google Scholar] [CrossRef] [Green Version] Titouna, C.; Ari, A.A.A.; Moumen, H. FDRA: Fault Detection and Recovery Algorithm for Wireless Sensor Networks. In Proceedings of the Mobile Web and Intelligent Information Systems, 15th International Conference, MobiWIS 2018, Barcelona, Spain, 6–8 August 2018; Springer: Cham, Switzerland, 2018; pp. 72–85. [Google Scholar] Krishnamachari, B.; Iyengar, S. Distributed Bayesian algorithms for fault-tolerant event region detection in wireless sensor networks. IEEE Trans. Comput. 2004, 53, 1. [Google Scholar] [CrossRef] Chen, Q.; Lam, K.-Y.; Fan, P. Comments on “Distributed Bayesian algorithms for fault-tolerant event region detection in wireless sensor networks”. IEEE Trans. Comput. 2005, 54, 1182–1183. [Google Scholar] [CrossRef] Ould-Ahmed-Vall, E.; Ferri, B.H.; Riley, G.F. Distributed Fault-Tolerance for Event Detection Using Heterogeneous Wireless Sensor Networks. IEEE Trans. Mob. Comput. 2012, 11, 1994–2007. [Google Scholar] [CrossRef] Lee, M.; Choi, Y. Fault detection of wireless sensor networks. Comput. Commun. 2008, 31, 3469–3475. [Google Scholar] Akbari, A.; Arash, A.D.; Khademzadeh, A.; Beikmahdavi, N. Fault Detection and Recovery in wireless Sensor Network Using Clustering. Proc. Int. J. Wirel. Mob. Netw. 2011, 3, 130–137. [Google Scholar] Chen, J.; Kher, S.; Somani, A. Distributed Fault Detection of Wireless Sensor Networks. In Proceedings of the 2006 Workshop on Dependability Issues in Wireless ad Hoc Networks and Sensor Networks, Los Angeles, CA, USA, 26 September 2006; pp. 1–11. [Google Scholar] Nandi, M.; Dewanji, A.; Roy, B.; Sarkar, S. Model Selection Approach for Distributed Fault Detection in Wireless Sensor Networks. IEEE Trans. Comput. 2014, 55, 1–12. [Google Scholar] Guclua, S.O.; Ozcelebia, T.; Lukkiena, J. Distributed Fault Detection in Smart Spaces Based on Trust Management. Procedia Comput. Sci. 2016, 83, 66–73. [Google Scholar] Ji, S.; Shen-fang, Y.; Ma, T.; Tan, C. Distributed Fault Detection for Wireless Sensor Based on Weighted Average. In Proceedings of the 2010 Second International Conference on Networks Security, Wireless Communications and Trusted Computing, Wuhan, China, 24–25 April 2010; pp. 57–60. [Google Scholar] DePaola, A.; Gaglio, S.; Re, G.; Milazzo, F.; Ortolani, M. Adaptive distributed outlier detection for wsns. IEEE Trans. Cybern. 2015, 45, 888–899. [Google Scholar] Li, W.; Bassi, F.; Dardari, D.; Kieffer, M.; Pasolini, G. Low-complexity distributed fault detection for wireless sensor networks. In Proceedings of the 2015 IEEE International Conference on Communications (ICC), London, UK, 8–12 June 2015; pp. 3469–3475. [Google Scholar] Taleb, A.A.; Mathew, J.; Kocak, T.; Pradhan, D.K. A Novel Fault Diagnosis Technique in Wireless Sensor Networks. Int. J. Adv. Netw. Serv. 2009, 2, 230–240. [Google Scholar] Myoupo, J.F.; Nana, B.P.; Tchendji, V.K. Fault-tolerant and energy-efficient routing protocols for a virtual three-dimensional wireless sensor network. Comput. Electr. Eng. 2018, 72, 949–964. [Google Scholar] Titouna, C.; Gueroui, M.; Aliouat, M.; Ari, A.A.A.; Adouane, A. Distributed fault-tolerant algorithm for wireless sensor networks. Int. J. Commun. Netw. Inf. Secur. 2017, 9, 241–246. [Google Scholar] Furquim, G.; Jalali, R.; Pessin, G.; Pazzi, R.W.; Ueyama, J. How to improve fault tolerance in disaster predictions: A case study about flash floods using IoT, ML and real data. Sensors 2018, 18, 907. [Google Scholar] Titouna, C.; Aliouat, M.; Gueroui, M. FDS: Fault Detection Scheme for Wireless Sensor Networks. Wirel. Pers. Commun. 2016, 86, 549–562. [Google Scholar] [CrossRef] Tosic, T.; Thomos, N.; Frossard, P. Distributed sensor failure detection in sensor networks. Signal Process. 2017, 93, 399–410. [Google Scholar] [CrossRef] [Green Version] Li, W.; Bassi, F.; Dardari, D.; Kieffer, M.; Pasolini, G. Defective Sensor Identification for WSNs Involving Generic Local Outlier Detection Tests. IEEE Trans. Signal Inf. Process. Over Netw. 2016, 2, 29–48. [Google Scholar] [CrossRef] Viswanathan, R.; Varshney, P.K. Distributed detection with multiple sensors—Part I: Fundamentals. Proc. IEEE 1997, 85, 54–63. [Google Scholar] [CrossRef] Bredin, J.; Demaine, E.; Hajiaghayi, M.; Rus, D. Deploying sensor networks with guaranteed capacity and fault tolerance. In Proceedings of the MobiHoc’05, Urbana-Champaign, IL, USA, 25–27 May 2005; pp. 309–319. [Google Scholar] Smaragdakis, G.; Matta, I.; Bestavros, A. SEP: A Stable Election Protocol for Clustered Heterogeneous Wireless Sensor Networks. OpenBU. 2004. Available online: https://open.bu.edu/handle/2144/1548 (accessed on 16 July 2023). Zhixiang, D.; Bensheng, Q. Three-layered routing protocol for WSN based on LEACH algorithm. In Proceedings of the 2007 IET Conference on Wireless, Mobile and Sensor Networks (CCWMSN07), Shanghai, China, 12–14 December 2007; pp. 72–75. [Google Scholar] [CrossRef] Liu, T.; Li, F. Power-efficient clustering routing protocol based on applications in wireless sensor network. In Proceedings of the 2009 5th International Conference on Wireless Communications, Networking and Mobile Computing, Beijing, China, 24–26 September 2009. [Google Scholar] Kang, S.; Nguyen, T. Distance based thresholds for cluster head selection in wireless sensor networks. IEEE Commun. Lett. 2012, 16, 1396–1399. [Google Scholar] [CrossRef] Rajeev, K.; Rajdeep, K. Evaluating the Performance of DEEC variants. Int. J. Comput. Appl. 2014, 97, 9–16. [Google Scholar] Sabet, M.; Naji, H. A decentralized energy-efficient hierarchical cluster-based routing algorithm for WSNs. AEU Int. J. Electron. Commun. 2015, 69, 790–799. [Google Scholar] [CrossRef] Yi, D.; Yang, H. HEER—A delay-aware and energy-efficient routing protocol for WSNs. Comput. Netw. 2016, 104, 155–173. [Google Scholar] [CrossRef] [Green Version] Cengiz, K.; Dag, T. Energy aware multi-hop routing protocol for WSNs. IEEE Access 2018, 6, 2622–2633. [Google Scholar] [CrossRef] Sasikumar, P.; Khara, S. K-Means Clustering In Wireless Sensor Networks. In Proceedings of the 2012 Fourth International Conference on Computational Intelligence and Communication Networks, Mathura, India, 3–5 November 2012; pp. 140–144. [Google Scholar] [CrossRef] Hassana, M.E.; Ziedanb, N.I. A Mobile BS and Multi-Hop LEACH-C Extension for WSNs. Am. Sci. Res. J. Eng. Technol. Sci. 2017, 36, 198–210. [Google Scholar] Farooq, M.O.; Dogar, A.B.; Shah, G.A. MR-LEACH: Multi-hop routing with low energy adaptive clustering hierarchy. In Proceedings of the 2010 Fourth International Conference on Sensor Technologies and Applications, Venice, Italy, 18–25 July 2010; pp. 262–268. [Google Scholar] Al-Sodairi, S.; Ounia, K. Reliable and energy-efficient multi-hop LEACH-based clustering protocol for WSNs. Sustain. Comput. Inform. Syst. 2018, 20, 1–13. [Google Scholar] Amiri, A. Extending Network Lifetime of Wireless Sensor Networks. Int. J. Comput. Netw. Commun. 2015, 7, 1–17. [Google Scholar] [CrossRef] Shanthi, G.; Sundarambal, M. Investigation of Multi Hop Sensor Node Data Aggregation in Building Management System. Res. J. Biotech 2017, 324–330. [Google Scholar] Akbar, M.; Javaid, N.; Imran, M.; Rao, A.; Younis, M.S.; Niaz, I.A. A multi-hop angular routing protocol for wireless sensor networks. Int. J. Distrib. Sens. Netw. 2016, 12, 1–7. [Google Scholar] [CrossRef] [Green Version] Sert, S.A.; Alchihabi, A.; Yazici, A. A Two-Tier Distributed Fuzzy Logic Based Protocol for Efficient Data Aggregation in Multihop WSNs. IEEE Trans. Fuzzy Syst. 2018, 26, 3615–3629. [Google Scholar] [CrossRef] Sert, S.A.; Yazici, A. Optimizing the performance of rule-based fuzzy routing algorithms in WSNs. In Proceedings of the 2019 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE), New Orleans, LA, USA, 23–26 June 2019; pp. 1–6. [Google Scholar] Mohrehkesh, S.; Weigle, M. Optimizing Communication Energy Consumption in Perpetual Wireless Nanosensor Networks. In Proceedings of the IEEE Globecom, Atlanta, GA, USA, 9–13 December 2013; pp. 545–550. [Google Scholar] Basagni, S. Distributed Clustering for Ad Hoc Networks. 1999, pp. 310–315. Available online: https://ieeexplore.ieee.org/document/778957 (accessed on 16 July 2023). Devi, G.Y.D. Clustering Algorithms In Wireless Sensor Networks—A Survey. Int. J. Electr. Electron. Comput. Syst. 2013, 1, 1–9. [Google Scholar] Tandon, R.; Dey, B.; Nandi, S. Weight Based Clustering in Wireless Sensor Networks. In Proceedings of the 2013 National Conference on Communications (NCC), New Delhi, India, 1–3 February 2013; pp. 1–5. [Google Scholar] Ducrocq, T.; Mitton, N.; Hauspie, M. Energy-based Clustering for Wireless Sensor Network Lifetime Optimization. In Proceedings of the WCNC—Wireless Communications and Networking Conference, Shanghai, China, 7–10 April 2013. [Google Scholar] Wan, R.; Xiong, N.; Loc, N.T. An energy-efficient sleep scheduling mechanism with similarity measure for WSNs. Hum. Cent. Comput. Inf. Sci. 2018, 8, 1–6. [Google Scholar] [CrossRef] [Green Version] Nanda, S.; Panda, G. Automatic clustering algorithm based on multi-objective Immunized PSO to classify actions of 3D human models. Eng. Appl. Artif. Intell. 2013, 26, 1429–1441. [Google Scholar] [CrossRef] Disclaimer/Publisher’s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.  © 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Share and Cite MDPI and ACS Style Effah, E.; Thiare, O.; Wyglinski, A.M. A Tutorial on Agricultural IoT: Fundamental Concepts, Architectures, Routing, and Optimization. IoT 2023, 4, 265-318. https://doi.org/10.3390/iot4030014 AMA Style Effah E, Thiare O, Wyglinski AM. A Tutorial on Agricultural IoT: Fundamental Concepts, Architectures, Routing, and Optimization. IoT. 2023; 4(3):265-318. https://doi.org/10.3390/iot4030014 Chicago/Turabian Style Effah, Emmanuel, Ousmane Thiare, and Alexander M. Wyglinski. 2023. \"A Tutorial on Agricultural IoT: Fundamental Concepts, Architectures, Routing, and Optimization\" IoT 4, no. 3: 265-318. https://doi.org/10.3390/iot4030014 Article Metrics Citations Crossref   2 Scopus   1 Google Scholar   [click to view] Article Access Statistics Article access statistics Article Views 8. Jan 18. Jan 28. Jan 7. Feb 17. Feb 27. Feb 8. Mar 18. Mar 28. Mar 0 500 1000 1500 2000 2500 For more information on the journal statistics, click here. Multiple requests from the same IP address are counted as one view.   IoT, EISSN 2624-831X, Published by MDPI RSS Content Alert Further Information Article Processing Charges Pay an Invoice Open Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors For Reviewers For Editors For Librarians For Publishers For Societies For Conference Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe to receive issue release notifications and newsletters from MDPI journals Select options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated Disclaimer Terms and Conditions Privacy Policy"

Paper 6:
- APA Citation: Ciani, L., Catelani, M., Bartolini, A., Guidi, G., & Patrizi, G. (2020). Influence of Raised Ambient Temperature on a Sensor Node Using Step-Stress Test. IEEE Transactions on Instrumentation and Measurement, 69(12), 9549-9556.
  Main Objective: To characterize the thermal behavior and identify potential weaknesses of wireless sensor nodes used in agriculture monitoring systems.
  Study Location: Unspecified
  Data Sources: Experimental data collected from the temperature step-stress test
  Technologies Used: Temperature step-stress test, current measurement, ADC and DAC analysis
  Key Findings: 1) The overheating of the sensor node during the active phase is not significant and does not affect reliability. 2) A temperature dependence of the current consumption leads to a current step at 60°C, causing higher consumption. 3) The ADC exhibits drift and increased standard deviation with increasing temperature. 4) The DAC shows stable behavior in the frequency range of interest, with minor oscillations at high frequencies.
  Extract 1: The experimental results show that the overheating of the sensor node with respect to the air temperature is not relevant from a reliability point of view.
  Extract 2: This overheating does not influence the reliability performances.
  Limitations: The study does not evaluate the long-term reliability of the sensor nodes under prolonged exposure to high temperatures or other environmental stresses.
  Relevance Evaluation: The paper is highly relevant to the outline point on "Self-healing capabilities: Incorporating AI-driven self-healing mechanisms that can detect, diagnose, and recover from faults without human intervention." While the study does not directly address AI-driven self-healing, it provides valuable insights into the thermal behavior and potential weaknesses of the sensor nodes, which is essential knowledge for developing resilient and reliable automated irrigation systems.
  Relevance Score: 0.9
  Inline Citation: (Ciani et al., 2020)
  Explanation: The study primarily focuses on the thermal characterization and resilience of wireless sensor nodes in agriculture monitoring systems. Using a temperature step-stress test, the researchers assess the effects of elevated temperatures on various components of the sensor nodes, including current consumption, sensor behavior (ADC and DAC), and potential faults.

 Full Text: >
"IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Transactions on Instrume... >Volume: 69 Issue: 12 Influence of Raised Ambient Temperature on a Sensor Node Using Step-Stress Test Publisher: IEEE Cite This PDF Lorenzo Ciani; Marcantonio Catelani; Alessandro Bartolini; Giulia Guidi; Gabriele Patrizi All Authors 9 Cites in Papers 390 Full Text Views Abstract Document Sections I. Introduction II. Prototype Under Test III. Measurement Setup and Methods for Thermal Characterization IV. Experimental Results V. Conclusion Authors Figures References Citations Keywords Metrics Abstract: The monitoring of environmental condition, together with soil parameter, is extremely important in precision farming technologies. One of the best solutions to implement environmental monitoring system in agriculture is to use a wireless mesh network to cover large area and ensure fault tolerance. A low-cost and low-power sensor node for mesh architectures has been developed and tested in this work. The node is based on a system on a chip microcontroller and few sensors to acquire air temperature, air humidity, soil temperature, soil moisture, and solar radiation. Generally, the effects of temperature on the dynamic metrological performance and on the reliability of wireless sensor network are not adequately dealt with. Moreover, no international standard for the environmental test of wireless sensor networks is available. In this article, a temperature step-stress test profile was implemented to characterize the behavior of the prototype at different temperature, from 20 °C up to 80 °C (step of 5 °C) using a climatic chamber. The aim of the test was to characterize which are the effects of the overheating on the current consumption, the sensor response, the analog-to-digital converter, and the digital-to-analog converter. The experimental test highlights some minor anomalies. However, all the unexpected behaviors are not caused by permanent failure mechanisms that lead to failure in the whole node. They are simple drifts that disappear when temperature returns to the standard environmental conditions. Published in: IEEE Transactions on Instrumentation and Measurement ( Volume: 69, Issue: 12, December 2020) Page(s): 9549 - 9556 Date of Publication: 02 July 2020 ISSN Information: DOI: 10.1109/TIM.2020.3006600 Publisher: IEEE SECTION I. Introduction In the last years, the attention on the concept of agricultural 4 is significantly increased due to the development of high performance and low-power monitoring systems [1]. In particular, the use of monitoring and automatic systems allowed the rapid expansion of smart farm [2]–[6]. The main factors that hinder this development are the environmental harsh conditions, the large area of the farm, the energy consumption, and the system cost. The introduction of new technologies and high-quality components designed to endure harsh environment conditions (e.g., in the presence of significant temperature excursions, humidity, vibrations, and mechanical shocks) allow to extend the possibility to create new self-made automated systems tailored to various experimental conditions [7]. Wireless sensor networks (WSNs) for agricultural application represent a useful solution to monitor environmental conditions and soil parameters on large areas because they enable real-time decision making with regard to critical issues [8]–[11]. There are many articles in recent literature that analyses the different aspects of the network design in agriculture. Another widely discussed topic is the optimization of power consumption in wireless sensor nodes (see, for instance, but not only [12]–[14]). One of the most easy and practical solutions is to alternate the operation mode of the nodes between the active and sleep periods to save energy [15]. Nevertheless, an extension of the active phase due to high number of nodes or connectivity problems could lead to an overheating of the hardware which is generally not adequately dealt with when this kind of design implementations is presented. There are many articles that debate the design of new sensor networks and sensor nodes, as well as lots of works focus on the characterization of several types of components under different stresses. For instance, many articles analyze the effects of temperature on different kind of components, such as air temperature sensors [16], medium-voltage cable joints [17], semiconductor components [18], mechanical components [19], LEDs [20], [21], and capacitors [22]. Quite the opposite, very few works deal with the characterization of the complete designed system under stress conditions. Generally, the effects of temperature and other stresses on the dynamic metrological performance and on the reliability of WSN are not adequately dealt with. Some works such as [23]–[25] analyze the effects of raising temperature on WSN focusing mainly on communications problems, while its effects on the sensor node hardware are rarely considered. Moreover, no international standard for the environmental test of WSNs is available and customized standards for the testing of electronic devices are not implemented in agricultural applications. For these reasons, starting from the preliminary experimental results shown in [26], this article focuses on agriculture monitoring system proposing a temperature step-stress test to characterize the behavior of the complete monitoring device under thermal effects. The main novelty of the article is to propose a test procedure for environmental monitoring system based on temperature stress that could be easily extended to any kind of WSN applied in different applications. The proposed test procedure will offer a more robust and reliable design of a WSN. In particular, a low-power and low-cost wireless sensor network is designed and tested using a climatic chamber to analyze the system in environmental harsh condition. The article is organized as follows. Section II presents the development of the device under test (DUT). Section III describes the measurement setup and the temperature profile implemented. Section IV illustrates and discusses the measurement results. SECTION II. Prototype Under Test The developed wireless sensor network is a mesh topology network characterized by a root node and some sensor nodes used for data collection. The Wi-Fi protocol and a multiple hop (multihop) transmission allow to cover large area and share the data to an online server using only one sink node (also called root node henceforth). Therefore, each node in wireless mesh network (WMN) transmits its own packets and simultaneously serves as relay for other nodes through the dynamic routing tables as shown in Fig. 1. Fig. 1. Deployment of the nodes in the analyzed wireless mesh sensor network used for environmental monitoring in agriculture field. Show All In order to have a complete autonomous system, each node of the network is composed by a solar panel, lithium batteries, electronic boards, and sensors as shown in Fig. 2. Fig. 2. Analyzed system used as the sensor node in the proposed network. The node is composed by a solar panel, two lithium batteries, a 2.4-GHz antenna, some sensors, and two electronic boards. All the components except the solar panel are closed inside a waterproof customized case. Show All The main part of the electronic boards is the ESP32 dual-core microcontroller manufactured by “Espressif Systems” mounted on the “DevKitC v4” evaluation board used for software programming by means of USB-to-UART bridge controllers, pin interface, and power supply by means of an AMS1117 low-dropout regulator (LDO). The ESP32 is designed to support Wi-Fi and dual-mode Bluetooth (v4.2 BR/EDR and BLE). In particular, the IEEE 802.11/n Wi-Fi protocol is implemented. The microcontroller is equipped with two eight-channel 12-bit SAR ADC and two 8-bit DACs. The evaluation board is in turn mounted on a customized interface board used to connect the batteries, the power boards, and the sensors. The prototype is equipped with an air temperature and humidity sensor, a soil temperature sensor, a soil moisture sensor, and a global solar radiation sensor as shown in Fig. 3. The board is developed to function in two different operation phases. A “sleep phase” in which sensors, processing units, and Wi-Fi protocol are deactivated to save energy. An “active phase” or “operative phase” where the nodes are working acquiring data from sensors, elaborating them, and transmitting the information by means of the Wi-Fi protocol to the sink node. Fig. 3. Representation of the implemented sensor nodes: the white board is the prototype developed to connect the commercial ESP32 and the sensors. Show All This behavior allows to minimize the duty cycle, overheating, and power consumption, and it is justified by the fact that the meteorological data slowly change during the day. Particularly, the developed system is based on a sleep phase of 10 min and an active phase demanded by the root node of 1 min. SECTION III. Measurement Setup and Methods for Thermal Characterization Temperature and most generally all the environmental conditions affect the performances of the electronic devices causing fatigue and fracture. Both functional and reliability performance are deeply influenced by this kind of stresses, and for this reason, it is mandatory to test and characterize this kind of components under thermal effects [27]–[30]. This article proposes a temperature step-stress test for the environmental characterization of a sensor node used in smart agriculture monitoring system. A preliminary functional failure analysis is required to understand every possible failure mechanism that could lead to faults and malfunctions of the system. According to the international standard JEDEC JEP122F [31], the typical and most common failure mechanisms of electronic devices are open/short circuit, dielectric charging, electrostatic discharge, intrinsic breakdown, diffusion, corrosion, and silicon fracture. A temperature test is proposed to investigate the behavior of the DUT at different temperature inside the range of guaranteed operability (up to 85 °C for the Espressif ESP32 DevKitC board). The following international standards were used to define the test profile. IEST-RP-PR-003.1 (2012) [32] defines and describes the accelerated life testing, including the temperature step-stress test. ISO 16750–4 (2010) [33] illustrates the environmental test conditions for electrical and electronic equipment. IEC 60068-2-14 (2011) [34] provides general procedures for temperature testing. MIL-STD 810G (2008) [35] contains engineering direction for considering the influences that environmental stresses have on material throughout all phases of its service life. JEDEC JESD22 A104E (2014) [36] provides guidelines for temperature testing of semiconductor devices. The profile resembles the ones proposed in the previous standards and is tailored on the practical application scenario. During the pretest adjustment, it is very important to place the sample in such a position with respect to the air stream such that there is substantially no obstruction to the flow of air across and around each sample. The test starts at room temperature (approximately 20 °C) that is maintained constant for 10 min in order to ensure at least one active phase of the system. Then the temperature is raised by 5 °C at low rate to allow components’ temperature to increase together with the chamber temperature. The complete raise time including settling time is 10 min. The following step is 20 min of exposition time at the reached temperature to ensure two active phases of the node after temperature stability. The test continues repeating the two previous phases until the exposition time at 80 °C. After that, the temperature is lowered to 20 °C at low rate to ensure gradual cooling of the components (between 0.5 and 1 °/min). The step test described in the previous procedure is illustrated in Fig. 4. Fig. 4. Proposed temperature step-stress test profile for thermal characterization of the sensor node in a climatic chamber. Show All The aim of the test is to characterize the behavior of three boards under temperature effects. In particular, the test focuses on the current consumption of two sensor nodes, one supplied using the LDO provided by the manufacturer of the evaluation board (identified using the term “Former LDO” henceforth) and the other one supplied using an “AP2114H LDO” (identified using the term “New LDO” henceforth). Moreover, the behavior of the various sensors is investigated and compared during the test. These two boards are equipped with the same firmware, and they work in the classical operational conditions of a sensor node described in Section II (active and sleep phases). The third board is used for the characterization of the ADC and DAC thermal drifts. This DUT works only in the active phase, and it sends data directly to the PC without interacting with the network composed by the other nodes under test. The complete test bed implemented for the thermal characterization of the sensor node is illustrated in Fig. 5. The following equipments are used. A laptop connected to the root node in order to acquire the data coming from the network. The PC is also used as the interface for the multimeters. A root node that manages the functionality of the network and stores data measured by the tested nodes. A temperature chamber characterized by a temperature range between 20 °C and 300 °C. A datalogger “8430-20 memory HiLogger” by “Hioky” equipped with ten k-type thermocouples used to monitor the temperature of the devices inside the chamber. A dc power supply generator used to supply the electronic boards instead of the batteries. An RTB2002 two-channel digital oscilloscope by “Rohde&Schwarz” used for the DAC test. Three 3440 digital multimeters by “PeakTech” used to measure the current consumption of the nodes. A 500-mA dc current source used to emulate the behavior of the solar radiation sensor. An arbitrary waveform generator used to provide the input signal for the ADC test. Fig. 5. Implemented test bed for thermal characterization of the prototype. Each red square indicates an equipment used in the test. Show All SECTION IV. Experimental Results This section reports the experimental results achieved during the temperature step-stress test profile. A. Temperature Measurements The test was carried out using ten thermocouples to monitor the temperature in different locations inside the chamber. Particularly, one channel was placed together with the PT100 thermistor used as control signal for chamber setting, while another one was located in the opposite side of the chamber. Six channels are used to monitor the microcontrollers, the LDOs, and the electronic boards of the two sensor nodes. The last two thermocouples are placed together with the air temperature sensors and the soil temperature sensors of the DUTs. The complete temperature acquisition is illustrated in Fig. 6. The figure shows that all the signals follow the profile described in the previous section, except for the soil temperature that gradually increases because of the thermal inertia of the soil. Interestingly, many temperature spikes were observed in some of the acquired channels, as shown in detail in Fig. 7. Each spike represents the active phase of the nodes due to the increase in current dissipation to acquire and send data. Fig. 6. Temperature monitoring during test acquired using a ten-channel datalogger equipped with a k-type thermocouple. Show All Fig. 7. Details of the ten-channel datalogger highlighting the increase in the temperature of microprocessors (yellow and purple) and LDOs (green and light blue) during the active phase. Show All Fig. 7 highlights a detail of the monitored temperature in approximately 1 h between 40 °C and 45 °C. The temperature increase during the active phases is marked only on the six channels used to observe the behavior of the two DUTs. There are three different overheating trends. The highest spikes are caused by the LDOs that increase their temperature of approximately 5 °C with respect to the chamber temperature. The lowest spikes (overheating of 2 °C) are related to the temperature of the two boards, while the microprocessor temperatures increase by 3 °C. The most striking result to emerge from the data is that these increases are repeated at each active phase, regardless of the temperature of the chamber. The overheating of the sensor node is not relevant from a reliability point of view because of the limited transmission phase. B. Current Consumption The results illustrated in this subsection are referred to the two DUTs used in the classical operational conditions of a sensor node. During the step-stress test, the current consumption of the two boards was measured using two different multimeters. The aim of the test was to investigate whether the New LDO provides significant upgrades with respect to the one provided by the manufacturer of the evaluation board (Former LDO). Fig. 8 presents an overview of the conducted test, showing the current consumption (blue and green signals) on the left y -axis and the temperature used to control the chamber (red line) on the right y -axis. The current of the two DUTs follows a cyclic trend alternating a very low consumption during the sleep phase and a current spike during the active phase. No significant difference between the two currents was evident. Fig. 8. Comparison between the current consumption of the two boards (blue and green lines) on the left y -axis, while the right y -axis shows the temperature variation during the test (red line). Show All Instead, what can be clearly seen in Fig. 9 is that the New LDO provides a general improvement of the consumption. Fig. 9. Details of the current consumption acquired at 55 °C highlighting the sleep and active phases of the sensor node equipped with the Former LDO (blue line) and the other one equipped with the New LDO (red line). Show All What stands out in the zoomed-in of two generic active phases is that the update of the LDO allows to reduce the current dissipation both in the sleep and active phases. Fig. 9 also highlights that the active phase could be in turn divided into two subphases: in the first one, the Wi-Fi is OFF and the sensors acquire data, while in the second one, the Wi-Fi is turned on to ensure the data transmission, with a consequent current increase. The Wi-Fi is kept OFF during the initial stage of the active phase to minimize the consumption and save batteries’ life. There is also a current spike during the “Wi-Fi ON” subphase up to 300 mA that is linked to a particular phase of the Wi-Fi transmission. The comparison of the two current consumptions provided in Table I reveals that the improvement achieved with the New LDO is even more significant during the active phase with respect to the sleep phase. Taking the temperature stability of 30 °C as an example, Table I reports the average current value during the three identified zones. TABLE I Comparison Between the Average Current Consumption of the DUTs in the Different Zones of Work at 30° C The single most striking observation to emerge from the data analysis is the presence of a current step-up during the sleep phase of the two sensor nodes, as shown in Fig. 10. When the chamber reached 58 °C, the current of the board equipped with the New LDO (green line) suddenly increased to approximately 4.5 mA. The same behavior was also observed in the other board (blue line) at approximately 63 °C with the identical variation. Fig. 10. Details of the current consumption in the middle part of the test showing the observed current step. The current dissipated by the board equipped with the Former LDO (blue line) and by the one equipped with the New LDO (green line) is plotted on the left y -axis, while the temperature (red line) is plotted on the right y -axis. Show All During the cooling phase, the current returned to the original value in the same way (first the Former LDO and then the New LDO). The step-down happens at a temperature of the chamber slightly lower than the step-up due to thermal inertia of the components. Turning now to the experimental evidence on the active phase, the average current consumption of the two tested boards is illustrated in the left y -axis of Fig. 11 (blue dots and blue stars denote the Former LDO and New LDO, respectively). Fig. 11. Average current consumption during the active phase: comparison between the mean current of the two tested boards (blue dots and blue stars) on the left y -axis and temperature trend (red line) on the right y -axis. Show All Each value in Fig. 11 refers to the mean value of the current during the respective active phase. As already observed in Table I, Fig. 11 highlights the general improvement achieved by the New LDO. As observed for the sleep phase, the current step is also present during the active phase in both electronic boards. The amplitude of the current variations and the temperature at which they happen are the same for the active and sleep phases. Additional test with different setup was performed to identify the cause of this anomaly. The current step was observed regardless of: the alternation of the active and sleep phases (see Figs. 10 and 11); the presence or not of the LDO (tested connecting the power supply directly to the ESP32 chip); and the presence or not of the interface board used to manage the analog sensors. In summary, this test highlights a dependence between temperature and current consumption. More in detail, when temperature overcomes a certain threshold value (air temperature of approximately 60 °C), the current suddenly increases by 4.5 mA. This unexpected behavior could be dangerous since it is a remarkable increase that could lead to a fast discharge of the batteries. The cause of this current step is due to the increase in the reverse current of the Schottky diode (BAT760-7) with temperature. The purpose of this diode is to protect the programming device connected through USB when the board is supplied by both USB connection and external supplier. The increase of the reverse current in the considered temperature range is higher enough to enable the USB-to-UART interface controller leading to a 4.5-mA increase of current consumption. However, this overconsumption does not cause any hardware or software permanent damage. The implemented stress profile activated no failure mechanisms in the DUTs, and the boards continue to provide reliable and accurate information during all the tests and during the posttest inspections. Even though the introduction of the New LDO does not solve the current step anomaly, it provides a significant improvement in terms of energy saving. C. Thermal Characterization of the ADC This section is referred to the analysis of the ADC thermal behavior using the third DUT. The electronic board was not part of the mesh network, but it was directly connected to the PC using serial communication. Two channels of the ADC were tested as follows. The first channel was connected directly to a constant reference voltage provided by the arbitrary waveform generator. The second channel was used to emulate the data acquisition from the solar radiation sensor which provides a current as output. The current generator serves as input of the transimpedance amplifier connected to the ADC. Both channels show a similar behavior under temperature stress, providing lower output data when temperature increases. Taking, for example, channel 1 connected to the voltage reference, Fig. 12 highlights the thermal dependence showing the acquisition at three different temperatures: 25 °C (blue dots), 50 °C (red dots), and 80 °C (green dots). Comparing all the data in this figure, it is possible to see that, the higher is the temperature, the lower is the average of the RAW data and the higher is the standard deviation of the ADC output. Fig. 12. Multiple ADC acquisition at three different temperatures: 25 °C (blue dots), 50 °C (red dots), and 80 °C (green dots). Show All This temperature drift is even more evident in Fig. 13, where the average of the multiple acquisition at each temperature (left y -axis—blue dots) is compared with the temperature stress (right y -axis—red line). Fig. 13 also shows a symmetric trend: when the temperature inside the chamber decreases, the ADC acquisition tends to return to its original value. Fig. 13. Mean value of the 256 multiple ADC acquisitions at each temperature on the left y -axis (blue dots) and temperature variation during the test on the right y -axis (red line). Show All Using the transimpedance amplifier up to 65 °C, the same results were obtained for the second tested channel. For temperature higher than this value, the acquisition chain stops working and produces a zero-voltage output. Since there are no other differences between the two channels, this malfunction must be caused by the transimpedance amplifier. During the cooling phase, when temperature is decreased under 65 °C, the ADC starts providing an output again, with the same trend observed in the first channel. This result is not worrying since it happens at high temperatures, which are very hard to reach in agriculture applications. In summary, this test highlights a deep thermal dependence of both the average acquisition value and the standard deviation of the ADC output. A multisampling solution mitigates the increase in the standard deviation, but it cannot solve the problem of the drift in the average value. It also highlights that the integrated circuit used as transimpedance amplifier does not work at temperature higher than 65 °C, even if no failure mechanisms have been activated. In fact, when temperature returns lower than 65 °C, the amplifier provides the same output of that before the test. D. Frequency Behavior of the DAC This section is referred to the analysis of the DAC thermal behavior using the third DUT. The DAC of the board is used to supply the soil moisture sensor for a very short time in order to acquire the measurement. Both the ESP32 DACs were tested, each one generating the same two signals in sequence: a 50-Hz positive square wave using the maximum dynamic of the DAC. a single positive rectangular pulse to emulate a Dirac delta function of maximum allowable amplitude and allowable duration according to ESP32 performances. Fig. 14 shows the fast Fourier transform (FFT) of the square wave acquired using the oscilloscope at 2 MSa/s at different temperature. Each signal was acquired after temperature stability in the chamber. The figure was cropped up to 10 kHz to highlight the first significant harmonics deleting the high-frequency noise. Fig. 14. Single-sided FFT of the square wave generated by the internal DAC at different temperature. The magnitude of all the spectra is normalized with respect to the first peak (fundamental frequency). Show All Fig. 14 evidence that there is no temperature dependence of the DAC output in the considered range. The FFT resumes that in the first ten terms, the maximum variation of the magnitude with respect to the temperature is 0.05 dB, proving a very high stability. Turning now to the rectangular pulse, Fig. 15 illustrates the two-side FFT of the signal acquired at 1.25 GSa/s. As seen before, the figure was cropped between −1 and 1 MHz to eliminate the nonsignificant contributions. Fig. 15. Two-sided FFT of the pulse generated by the internal DAC at different temperature. The magnitude of all the spectra is normalized with respect to the highest peak (frequency is equal to 0 Hz). Show All The main lobe of the FFT does not evidence any variations in magnitude and duration at any temperature, while the sidelobe presents some minimal alterations in magnitude and frequency. More in detail, the maximum variation in the second lobe is approximately 1.5 dB, while in the next lobe, it is approximately 2.5 dB. Despite these slight oscillations at high frequency, this anomaly is not so relevant because the magnitude of the sidelobe is much lower than the main lobe. SECTION V. Conclusion Precision farming technologies has rapidly increased in the last few years, leading to a significant expansion in the development of new meteorological stations. In this scenario, WMN represents a fundamental role to ensure fault tolerance and large transmission coverage. This work describes the characterization of a low-cost and low-power sensor node for environmental monitoring network used in agriculture application. This article proposes a customized temperature step-stress test based on several international standards for electronic devices. The profile was tailored on the practical application. The implemented setup has been used to investigate the effects of raising ambient temperature on the transmission phase, the current consumption, and the ADC and DAC outcomes. The experimental results show that the overheating of the sensor node with respect to the air temperature is not relevant from a reliability point of view. In fact, during the active phase, the temperature of the LDO and microcontroller slightly increases only for a couple of minutes and then returns approximately equal to air temperature. This overheating does not influence the reliability performances. Moving now to the current analysis, the test highlights a temperature dependence of the current consumption that leads to a current step of approximately 4.5 mA at 60 °C. This anomaly causes a higher consumption with respect to the standard conditions. The introduction of a New LDO to supply the microprocessor does not eliminate the step, but it leads to a consistent decrease in the current dissipation. Despite the observed step, no failure mechanisms have been activated by the temperature stress, and the boards continue to provide accurate and reliable data. The ADC thermal analysis evidence some unexpected behaviors. In particular, a relevant ADC drift over temperature was observed along with an increase in the standard deviation of the acquisitions. Moreover, the integrated circuit used as transimpedance amplifier stopped working at temperature higher than 65 °C. Both these anomalies are interesting results but are not caused by significant failures. In fact, decreasing the temperature after reaching 80 °C, the anomalies gradually mitigate, and the ADC provides a symmetric output compared to the rising phase. Quite the opposite, analyzing the FFT of the 50-Hz square wave, the behavior of the DAC over temperature has proved to be very stable in the frequency range interested in the application field. Some minor oscillations, when temperature increases, were observed only at high frequency in the FFT of the rectangular pulse. Authors Figures References Citations Keywords Metrics More Like This Outlier Detection and Decision Tree for Wireless Sensor Network Fault Diagnosis 2021 13th International Conference on Information & Communication Technology and System (ICTS) Published: 2021 Model-Based Techniques for Data Reliability in Wireless Sensor Networks IEEE Transactions on Mobile Computing Published: 2009 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."

Paper 7:
- APA Citation: Smith, J. (2023). Integration and Interoperability of Automated Irrigation Systems: A Focus on Resilience and Self-Healing Capabilities. Agricultural Systems, 123(1), 15-24.
  Main Objective: To investigate the challenges and strategies for integrating automated systems with existing irrigation infrastructure and other precision agriculture technologies, highlighting the importance of interoperability and standardization in enabling seamless communication and compatibility.
  Study Location: Unspecified
  Data Sources: Literature review, case studies
  Technologies Used: AI-driven self-healing mechanisms, reinforcement learning, Bayesian networks, self-organizing maps
  Key Findings: Integrating AI-driven self-healing mechanisms into automated irrigation systems can enhance resilience and fault tolerance, reducing the need for human intervention. AI techniques can monitor system performance, detect anomalies, and initiate corrective actions based on historical data and learned patterns. Implementing self-healing capabilities contributes to the development of fully autonomous, scalable irrigation management systems.
  Extract 1: Fault tolerance and self-healing capabilities are critical for fully autonomous irrigation systems, ensuring uninterrupted operation and optimal crop growth.
  Extract 2: AI-driven self-healing mechanisms leverage machine learning algorithms to monitor system performance, detect anomalies, and initiate corrective actions based on historical data and learned patterns.
  Limitations: The paper could benefit from more detailed case studies or experimental results to demonstrate the effectiveness of AI-driven self-healing mechanisms in real-world irrigation scenarios.
  Relevance Evaluation: The paper is highly relevant to the point of self-healing capabilities in automated irrigation systems within the context of integration, interoperability, and standardization. It offers practical approaches to fault detection, diagnosis, and recovery using AI techniques, aligning with the review's intention to explore strategies for seamless integration and enhance resilience.
  Relevance Score: 0.9
  Inline Citation: (Smith, 2023)
  Explanation: This paper provides insights into the integration and interoperability of automated irrigation systems, focusing on the importance of self-healing capabilities to ensure resilience and fault tolerance. It advocates for the use of AI-driven self-healing mechanisms to enhance system reliability and reduce the need for human intervention.

 Full Text: >

Paper 8:
- APA Citation: Author, A. A. (2023). Enhancing the Resilience and Fault Tolerance of Automated Irrigation Systems using AI-Driven Self-Healing Mechanisms. Journal of Agricultural Engineering, 54(1), 1-10.
  Main Objective: The main objective of this study is to investigate the use of AI-driven self-healing mechanisms to enhance the resilience and fault tolerance of automated irrigation systems.
  Study Location: Unspecified
  Data Sources: Literature review, Simulation data
  Technologies Used: Reinforcement learning, Bayesian networks, Self-organizing maps
  Key Findings: The study found that AI-driven self-healing mechanisms can effectively improve the resilience and fault tolerance of automated irrigation systems. Reinforcement learning, Bayesian networks, and self-organizing maps were identified as promising techniques for achieving self-healing capabilities.
  Extract 1: "The integration of AI-driven self-healing mechanisms in automated irrigation systems offers numerous advantages, including the ability to detect and diagnose faults in real-time, reducing the risk of crop damage and ensuring uninterrupted irrigation."
  Extract 2: "Self-organizing maps (SOMs) have been successfully applied in automated irrigation systems for fault detection and isolation, demonstrating promising results in enhancing system resilience."
  Limitations: The paper mainly focuses on theoretical concepts and simulations rather than providing extensive real-world implementation and evaluation results.
  Relevance Evaluation: The paper is highly relevant to the specific point within the context of the literature review. It provides valuable insights into the use of AI-driven self-healing mechanisms for enhancing the resilience and fault tolerance of automated irrigation systems. The paper discusses various techniques such as reinforcement learning, Bayesian networks, and self-organizing maps for achieving self-healing capabilities, which directly addresses the point of focus in the literature review.
  Relevance Score: 0.9
  Inline Citation: (Author, 2023)
  Explanation: Sure, here is my analysis of the paper's relevance to the specific point mentioned in <point_focus> within the context of the overall literature review intentions and the specific section and sub-section in which the point is located, presented in the requested JSON format:

 Full Text: >
Web Store Add shortcut Name URL Customize Chrome

Paper 9:
- APA Citation: Doe, J. (2023). Enhancing Resilience and Fault Tolerance in Automated Irrigation Systems Using AI-Driven Self-Healing Mechanisms. Journal of Agricultural Engineering, 10(1), 1-12.
  Main Objective: To investigate the use of AI and machine learning techniques for enhancing the resilience and fault tolerance of automated irrigation systems.
  Study Location: Unspecified
  Data Sources: Literature review, case studies
  Technologies Used: Reinforcement learning, Bayesian networks, self-organizing maps
  Key Findings: AI-driven self-healing mechanisms can improve the resilience and reliability of automated irrigation systems. Reinforcement learning, Bayesian networks, and self-organizing maps are promising techniques for implementing self-healing capabilities. Real-time implementation and scalability of self-healing mechanisms remain challenges that need to be addressed.
  Extract 1: "Self-healing mechanisms, when coupled with AI, can autonomously detect, diagnose, and recover from faults in real-time, thereby improving the resilience and reliability of automated irrigation systems."
  Extract 2: "The use of reinforcement learning, Bayesian networks, and self-organizing maps provides a promising approach to implementing self-healing capabilities in automated irrigation systems."
  Limitations: The paper does not provide a comprehensive evaluation of different AI techniques for self-healing in automated irrigation systems. It also does not address the challenges of real-time implementation and scalability of these self-healing mechanisms.
  Relevance Evaluation: The paper is highly relevant to the point of focus on self-healing capabilities in automated irrigation systems. It provides valuable insights into the use of AI and machine learning techniques for achieving fault tolerance and autonomous recovery. The paper also aligns well with the overall literature review intention of evaluating the current state and future potential of automated irrigation management systems.
  Relevance Score: 0.9
  Inline Citation: (Doe, 2023)
  Explanation: The paper focuses on the integration of AI and machine learning techniques to enhance the resilience and fault tolerance of automated irrigation systems. It proposes self-healing mechanisms that can autonomously detect, diagnose, and recover from faults without the need for human intervention. The paper highlights the use of reinforcement learning, Bayesian networks, and self-organizing maps for implementing these self-healing capabilities.

 Full Text: >
Web Store Add shortcut Name URL Customize Chrome

Paper 10:
- APA Citation: Johansen, K. (2022). AI-Driven Self-Healing for Automated Irrigation Systems. Journal of Agricultural Engineering, 9(1), 1-10.
  Main Objective: To investigate the potential of AI-driven self-healing mechanisms to enhance the reliability and resilience of automated irrigation systems.
  Study Location: Unspecified
  Data Sources: Environmental data, sensor readings, historical data
  Technologies Used: Reinforcement learning, Bayesian networks, self-organizing maps
  Key Findings: The proposed AI-driven self-healing framework can effectively detect and recover from a variety of faults in automated irrigation systems, improving their reliability and resilience. The framework utilizes reinforcement learning algorithms to make informed decisions and trigger appropriate actions based on real-time data analysis.
  Extract 1: The authors propose a novel self-healing framework that leverages reinforcement learning algorithms to detect, diagnose, and recover from faults in real-time. The framework utilizes environmental data, sensor readings, and historical data to make informed decisions and trigger appropriate actions to maintain optimal irrigation performance.
  Extract 2: The proposed self-healing framework is evaluated using real-world data from an automated irrigation system deployed in a commercial greenhouse. The results demonstrate that the framework can effectively detect and recover from a variety of faults, including sensor failures, communication disruptions, and equipment malfunctions.
  Limitations: The study is limited to a specific automated irrigation system deployed in a commercial greenhouse, and the generalizability of the findings to other systems and environments may need further investigation.
  Relevance Evaluation: This paper is directly relevant to the point of focus on self-healing capabilities in automated irrigation systems. The authors provide a detailed overview of the challenges associated with fault detection and recovery in such systems and propose a novel AI-driven solution that addresses these challenges effectively. The paper contributes to the review by highlighting the importance of self-healing mechanisms in ensuring the reliability and resilience of automated irrigation systems, which is a critical aspect for their successful implementation in real-world scenarios.
  Relevance Score: 0.9
  Inline Citation: (Johansen, 2022)
  Explanation: In this paper, the authors investigate the potential of AI-driven self-healing mechanisms to enhance the reliability and resilience of automated irrigation systems. They propose a novel self-healing framework that leverages reinforcement learning algorithms to detect, diagnose, and recover from faults in real-time. The framework utilizes environmental data, sensor readings, and historical data to make informed decisions and trigger appropriate actions to maintain optimal irrigation performance.

 Full Text: >

</subsection_point_Point 4>

<previous_sections>

A systematic review of automated systems for real-time irrigation management

1. INTRODUCTION
The challenge of feeding a growing population with finite resources is becoming increasingly pressing. By 2050, the world population is expected to reach 9.7 billion, necessitating a 70% increase in food production (Falkenmark and Rockstrom, 2009). Irrigation plays a crucial role in enhancing crop yields and agricultural productivity to meet this growing demand. Studies have shown that irrigation can significantly increase crop water productivity, contributing to increased food production (Ali and Talukder, 2008; Playan and Mateos, 2005). However, water scarcity poses a significant challenge, with many regions facing water deficits and the need for improved water management practices (Falkenmark and Rockstrom, 2009). Optimizing irrigation schedules and doses based on crop requirements and environmental conditions is essential for maximizing yield and quality while minimizing water use (Zhang et al., 2024). The necessity of scalable water-efficient practices for increasing food demand cannot be overstated. Techniques such as regulated deficit irrigation, magnetically treated water, and the use of drought-tolerant crops like sorghum have shown promise in improving water productivity and ensuring food security (Mehmood et al., 2023; Putti et al., 2023; Hadebe et al., 2016). As the global food challenge intensifies, it is imperative to critically evaluate the current state and future potential of irrigation management systems to guide research, innovation, and implementation efforts towards fully autonomous, scalable solutions.

Despite the importance of irrigation in addressing the global food challenge, traditional irrigation management techniques, such as manual scheduling and timer-based systems, have significant limitations. These methods are often labor-intensive, inefficient, and less adaptable to changing conditions (Savin et al., 2023). Manual and timer-based scheduling can lead to high operational costs and inefficient water use (Raghavendra, Han, and Shin, 2023). The reliance on manual intervention and predetermined schedules limits their adaptability to changing environmental conditions, crop water requirements, and soil moisture levels (Kaptein et al., 2019). Sensor-based irrigation systems offer an alternative, enabling real-time adjustments based on soil water status measurements (Kaptein et al., 2019). However, the adoption of these systems in commercial settings has been limited, often requiring extensive input from researchers (Kim et al., 2014; Lea-Cox et al., 2018; Ristvey et al., 2018). The limitations of traditional irrigation management techniques highlight the need for scalable, automated solutions for greater efficiency in irrigation management. Automated systems that collect real-time data, analyze it, and make autonomous irrigation decisions can lead to improved water use efficiency and increased crop productivity (Champness et al., 2023; Wu et al., 2022). To fully understand the potential of automated systems, it is necessary to examine the automation of each part of the irrigation management pipeline and analyze the effectiveness and efficiency of integrated end-to-end solutions.

The emergence of smart irrigation management and IoT marks a significant shift from historical irrigation practices. Modern approaches rely on vast data and analysis algorithms, leveraging technologies such as remote sensing, sensor networks, weather data, and computational algorithms (Atanasov, 2023; Bellvert et al., 2023; Kumar et al., 2023). IoT plays a vital role in collecting vast amounts of data through sensors, data transmission, and tailored networks, enabling real-time monitoring and control of irrigation systems (Liakos, 2023; Zuckerman et al., 2024). These advancements in data collection and analysis have the potential to revolutionize irrigation management, allowing for more precise and efficient water use. However, challenges such as processing diverse data sources, data integration, and lack of integrated data analysis hamper the full benefit of IoT in irrigation management (Dave et al., 2023). The current fragmented approach in smart irrigation, focusing on individual components rather than the entire system, limits the potential for fully autonomous, real-time end-to-end irrigation management (Togneri et al., 2021). To address these challenges and fully realize the potential of smart irrigation management, there is a need for automating and integrating each section of the irrigation management pipeline, from sensor/weather data collection and transmission to processing, analysis, decision-making, and automated action (McKinion and Lemmon, 1985). This integration requires a thorough investigation of the role of interoperability and standardization in enabling seamless communication and compatibility between components within the automated irrigation management pipeline.

Machine learning (ML) plays a significant role in processing vast data, predicting plant stress, modeling climate effects, and optimizing irrigation in smart irrigation management systems. ML algorithms can analyze data collected from sensors and weather stations to determine optimal irrigation schedules (Vianny et al., 2022). However, the potential of ML is often constrained by manual steps, such as data interpretation, decision-making on irrigation timing and volume, and system adjustments. Automating ML integration to allow direct action from insights to irrigation execution, removing bottlenecks and achieving real-time adaptability, is crucial for fully autonomous irrigation management (Barzallo-Bertot et al., 2022). By integrating ML into automated systems, the irrigation management pipeline can become more seamless and efficient, enabling real-time decision-making and action based on data-driven insights. To achieve this level of automation and integration, it is essential to identify gaps and propose solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.

To achieve seamless integration across the automated irrigation management system, interoperability and standardization are critical. Interoperability allows different system components, such as sensors, actuators, and software, to communicate and exchange data effectively, while standardization ensures that data is represented in a consistent format (Santos et al., 2020). Standardized protocols and data formats are essential for achieving seamless integration and ensuring compatibility between components in real-time irrigation management systems (Robles et al., 2022; Hatzivasilis et al., 2018). Existing and emerging standards, such as OGC SensorThings API and ISO 11783, have applicability to real-time irrigation management systems (Hazra et al., 2021). However, challenges such as data quality, scalability, reliability, and security need to be addressed to fully realize the potential of interoperability and standardization in automated irrigation management systems (Hazra et al., 2021). Addressing these challenges is crucial for enabling the seamless integration of components within the automated irrigation management pipeline, which is essential for achieving fully autonomous, scalable irrigation management. A comprehensive evaluation of the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline is necessary to guide future research and implementation efforts.
The primary objective of this systematic review is to critically evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies for enhancing agricultural water use efficiency and crop productivity.
Specific objectives include:
•	Examining the automation of each part of the irrigation management pipeline and the seamless integration of each section in the context of irrigation scheduling and management.
•	Analyzing the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
•	Investigating the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.
•	Identifying gaps and proposing solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.
By addressing these objectives, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.

2. REVIEW METHODOLOGY
•	Question-driven framework to guide the literature review of real-time, autonomous irrigation management systems
•	Key research questions posed, each with the motivation behind investigating them and a starting hypothesis to evaluate against the examined literature
•	Table presenting the major objectives, specific objectives, questions, motivations, and hypotheses
3. DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING
3.1. Irrigation management data
The success of automated irrigation management systems relies heavily on the collection, transmission, and analysis of various types of data. The most applicable data types for irrigation management include soil moisture, canopy temperature, weather data, and plant physiological parameters (Farooq et al., 2019; Li et al., 2019; Olivier et al., 2021; Evett et al., 2020). These data are typically collected from a range of sources, including in-field sensors, remote sensing platforms, weather stations, and manual measurements (Li et al., 2019; Karimi et al., 2018).
Soil moisture data is arguably the most critical type of data for irrigation management, as it directly reflects the water available to plants and can be used to determine the optimal timing and amount of irrigation (Olivier et al., 2021; Intrigliolo & Castel, 2006). Soil moisture sensors, such as tensiometers, capacitance probes, and time-domain reflectometry (TDR) sensors, can provide real-time measurements of soil water content at various depths (Farooq et al., 2019). These sensors can be deployed in a network configuration to capture spatial variability in soil moisture across a field (Karimi et al., 2018).
Canopy temperature data is another valuable type of data for irrigation management, as it can be used to assess plant water stress and adjust irrigation accordingly (Evett et al., 2020). Infrared thermometers and thermal cameras can be used to measure canopy temperature, which is influenced by factors such as air temperature, humidity, wind speed, and plant water status (Li et al., 2019). When plants experience water stress, they tend to close their stomata to reduce water loss, leading to an increase in canopy temperature (Evett et al., 2020). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
Weather data, including temperature, humidity, precipitation, wind speed, and solar radiation, are essential for predicting crop water requirements and scheduling irrigation events (Akilan & Baalamurugan, 2024). Weather stations equipped with various sensors can provide real-time measurements of these parameters, which can be used as inputs for crop water requirement models, such as the FAO-56 Penman-Monteith equation (Li et al., 2019). These models estimate crop evapotranspiration (ET) based on weather data and crop-specific coefficients, allowing for the calculation of irrigation requirements (Intrigliolo & Castel, 2006). By integrating weather data into automated irrigation systems, irrigation schedules can be dynamically adjusted based on changing environmental conditions, ensuring that crops receive the optimal amount of water at the right time (Akilan & Baalamurugan, 2024).
When collecting and utilizing these data types, several considerations must be taken into account, including the volume, frequency, format, and source of the data (Farooq et al., 2019). The volume of data generated by automated irrigation systems can be substantial, especially when high-resolution sensors are deployed at a large scale (Bastidas Pacheco et al., 2022). This necessitates the use of efficient data storage, processing, and transmission technologies to handle the data load (Farooq et al., 2019). The frequency of data collection is another important consideration, as it directly impacts the temporal resolution of the data and the ability to detect rapid changes in plant water status or environmental conditions (Bastidas Pacheco et al., 2022). Bastidas Pacheco et al. (2022) demonstrated that collecting full pulse resolution data from water meters provides more accurate estimates of event occurrence, timing, and features compared to aggregated temporal resolutions, highlighting the importance of selecting appropriate data collection frequencies to ensure the quality and usefulness of the data for irrigation management.
The format of the data is also crucial, as it determines the compatibility and interoperability of the data with various analysis tools and platforms (Farooq et al., 2019). Standardized data formats, such as JSON, XML, or CSV, can facilitate data exchange and integration between different components of the automated irrigation system (Zhang et al., 2023). The source of the data is another important consideration, as it can impact the reliability, accuracy, and spatial coverage of the data (Farooq et al., 2019). For example, in-field sensors provide highly localized measurements, while remote sensing platforms, such as satellites or drones, can provide data at larger spatial scales (Li et al., 2019). By combining data from multiple sources, automated irrigation systems can achieve a more comprehensive understanding of crop water requirements and optimize irrigation management accordingly (Farooq et al., 2019).
Data quality, accuracy, and reliability are paramount in irrigation management, as they directly impact the effectiveness of decision-making processes and the efficiency of water use (Gupta et al., 2020). Inaccurate or unreliable data can lead to suboptimal irrigation decisions, resulting in crop stress, yield losses, or wasted water resources (Ramli & Jabbar, 2022). Gupta et al. (2020) emphasized the critical importance of data security and privacy in smart farming systems, as the leakage of sensitive agricultural data can cause severe economic losses to farmers and compromise the integrity of the automated irrigation system. The authors also highlighted the need for robust authentication and secure communication protocols to prevent unauthorized access to smart farming systems and protect data in transit (Gupta et al., 2020).
Ramli and Jabbar (2022) addressed the challenges associated with implementing real-time, automated irrigation systems, including data quality, scalability, reliability, and security. They proposed solutions and best practices based on the analysis of case studies and real-world implementations, such as the use of redundant sensors, data validation techniques, and secure communication protocols (Ramli & Jabbar, 2022). The authors also emphasized the importance of regular maintenance and calibration of sensors to ensure the accuracy and reliability of the collected data (Ramli & Jabbar, 2022).
Researchers have investigated the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in automated irrigation systems (Karim et al., 2023; Rady et al., 2020; Cui, 2023). Karim et al. (2023) explored the effectiveness of various data compression techniques, such as lossless and lossy compression algorithms, in reducing the size of data packets transmitted over wireless networks. The authors found that lossless compression techniques, such as Huffman coding and Lempel-Ziv-Welch (LZW), can significantly reduce data size without compromising data quality, while lossy compression techniques, such as JPEG and MP3, can further reduce data size by introducing acceptable levels of distortion (Karim et al., 2023).
Rady et al. (2020) developed a novel data compression algorithm specifically designed for irrigation data, which achieved significant compression ratios without compromising data quality. The authors demonstrated that their algorithm could reduce the amount of data transmitted over wireless networks, thereby improving the efficiency of the irrigation system and reducing costs (Rady et al., 2020). Cui (2023) investigated the use of data aggregation and filtering techniques to reduce the number of transmissions and save bandwidth in automated irrigation systems. The author proposed a data aggregation scheme that combines multiple sensor readings into a single value, such as the average soil moisture over a specified time interval, to reduce the frequency of data transmissions (Cui, 2023). Additionally, the author explored the use of data filtering techniques, such as Kalman filters and particle filters, to remove noise and outliers from sensor data, improving the accuracy and reliability of the transmitted information (Cui, 2023).
Data standardization and harmonization are crucial for facilitating seamless integration and interoperability between the various components of automated irrigation management systems (Zhang et al., 2023; Ermoliev et al., 2022). Zhang et al. (2023) developed a novel cyberinformatics technology called iCrop, which enables the in-season monitoring of crop-specific land cover across the contiguous United States. The authors highlighted the importance of data standardization and harmonization in the context of iCrop, as it allows for the efficient distribution of crop-specific land cover information based on the findable, accessible, interoperable, and reusable (FAIR) data principle (Zhang et al., 2023). By adopting standardized data formats and protocols, such as the Open Geospatial Consortium (OGC) standards, iCrop enables the seamless integration of various data sources and facilitates the interoperability of the system with other agricultural decision support tools (Zhang et al., 2023).
Ermoliev et al. (2022) proposed a linkage methodology for linking distributed sectoral/regional optimization models in a situation where private information is not available or cannot be shared by modeling teams. The authors emphasized the need for data standardization to enable decentralized cross-sectoral coordination and analysis, as it allows for the consistent representation and exchange of data between different models and stakeholders (Ermoliev et al., 2022). By adopting standardized data formats and interfaces, the proposed linkage methodology can facilitate the integration of various optimization models and support the development of comprehensive decision support systems for sustainable resource management (Ermoliev et al., 2022).
Metadata plays a vital role in providing context and enabling better data interpretation and decision-making in automated irrigation management systems (Jahanddideh-Tehrani et al., 2021). Metadata refers to the additional information that describes the characteristics, quality, and context of the primary data, such as the sensor type, calibration parameters, measurement units, and timestamp (Jahanddideh-Tehrani et al., 2021). Jahanddideh-Tehrani et al. (2021) highlighted the importance of metadata in water resources management, as it enables decision-makers to use the data to the best of its capabilities by understanding factors such as when water data was collected and what factors might have contributed to the measurements. The authors emphasized the need for standardized metadata formats and guidelines, such as the Dublin Core Metadata Initiative (DCMI) and the ISO 19115 standard, to ensure the consistency and interoperability of metadata across different water information systems (Jahanddideh-Tehrani et al., 2021).
In the context of automated irrigation management systems, metadata can provide valuable information about the data collection process, sensor performance, and environmental conditions that can aid in data interpretation and decision-making (Cota & Mamede, 2023). For example, metadata about the sensor type and calibration parameters can help assess the accuracy and reliability of the collected data, while metadata about the weather conditions and soil properties can provide context for interpreting the data and adjusting irrigation strategies accordingly (Cota & Mamede, 2023). By incorporating metadata into the data management and analysis pipeline of automated irrigation systems, decision-makers can make more informed and context-aware decisions, leading to improved water use efficiency and crop productivity (Jahanddideh-Tehrani et al., 2021).

3.2. Edge Computing and Fog Computing
Edge computing and fog computing have emerged as transformative technologies in the realm of real-time irrigation management systems, offering significant potential for improving efficiency, scalability, and reliability (Abdel Nasser et al., 2020; Tran et al., 2019). Edge computing refers to the practice of processing data near the edge of the network, close to the source of the data, while fog computing is a decentralized computing infrastructure that extends cloud computing capabilities to the network edge (Hassija et al., 2019). These technologies bring computation and analytics closer to the data source, reducing the need for data to travel to the cloud and enabling faster processing and decision-making (Hassija et al., 2019; Zhang et al., 2020).
The potential of edge computing and fog computing in real-time irrigation management is immense. Abdel Nasser et al. (2020) proposed a two-layer system for water demand prediction using automated meters and machine learning techniques, demonstrating the potential of edge computing in improving the efficiency and scalability of irrigation management. The system collects and aggregates data from distributed smart meters in the first layer, while the second layer uses LSTM neural networks to predict water demand for different regions of households. By leveraging edge computing, the system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management (Abdel Nasser et al., 2020).
Tran et al. (2019) conducted a comprehensive review of real-time, end-to-end automated irrigation management systems, highlighting the role of fog computing in addressing data transmission challenges and enabling seamless integration across the irrigation management pipeline. The authors emphasize that real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs. However, they also identify several challenges that need to be addressed, such as data quality, scalability, reliability, and security, which can be effectively tackled by implementing fog computing architectures (Tran et al., 2019).
Edge computing offers several benefits in real-time irrigation management systems, including reduced latency, real-time decision-making, and reduced reliance on cloud connectivity (Mishra, 2020; Zhang et al., 2020). By processing data closer to the source, edge computing enables faster response times and more efficient data handling (Mishra, 2020). Mishra (2020) highlights that edge computing reduces latency by processing data closer to the source, enabling real-time decision-making and lessening reliance on cloud connectivity by shifting processing to local or edge devices.
Zhang et al. (2020) explore the application of edge computing in agricultural settings, demonstrating its potential to improve the efficiency and accuracy of irrigation systems. The authors discuss how edge computing has prospects in various agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. They also emphasize that the emergence of edge computing models, such as fog computing, cloudlet, and mobile edge computing, has transformed the management and operation of farms (Zhang et al., 2020).
Fog computing plays a crucial role in distributing processing and storage across the network, enhancing the scalability and reliability of automated irrigation systems (Premkumar & Sigappi, 2022; Singh et al., 2022). Premkumar and Sigappi (2022) evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation. Their study emphasizes the potential of fog computing in distributing processing and storage across the network, improving the efficiency and scalability of irrigation systems. The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture, demonstrating the effectiveness of fog computing in enhancing the performance of automated irrigation systems (Premkumar & Sigappi, 2022).
Singh et al. (2022) discuss the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability in agricultural management systems. The authors argue that by implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness. They also highlight that fog computing can address the challenges faced by real-time data transmission in agricultural management systems, such as latency, bandwidth limitations, and data security (Singh et al., 2022).
The integration of edge and fog computing in real-time irrigation management systems is crucial for achieving fully automated, scalable, and reliable solutions. As the demand for autonomous irrigation management grows, these technologies will play a pivotal role in enabling faster decision-making, reduced latency, improved resource utilization, and seamless integration across the irrigation management pipeline (Tran et al., 2019; Zhang et al., 2020). By bringing computation and analytics closer to the data source and distributing processing and storage across the network, edge and fog computing can significantly enhance the efficiency and effectiveness of automated irrigation systems, contributing to the overall goal of addressing the global food challenge through optimized water resource management and increased agricultural productivity (Abdel Nasser et al., 2020; Premkumar & Sigappi, 2022; Singh et al., 2022).

3.3. Automation of Data Collection
The automation of data collection is a critical component in the development of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. It enables the efficient gathering of vital information about crop health, environmental conditions, and water requirements, which is essential for enhancing agricultural water use efficiency and crop productivity. Two key aspects of automated data collection are the use of advanced sensing technologies for non-invasive plant stress detection and the implementation of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.
Advanced sensing technologies, such as hyperspectral imaging and thermal sensing, have emerged as powerful tools for non-invasive plant stress detection in automated irrigation management systems. These technologies provide valuable information about crop traits, enabling early and accurate detection of plant health issues (Triantafyllou et al., 2019). Triantafyllou et al. (2019) propose a comprehensive reference architecture model that incorporates advanced sensing technologies in the sensor layer for real-time plant stress detection, highlighting their importance in providing non-invasive plant stress detection. Similarly, Hossain et al. (2023) present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that leverages advanced sensing technologies to optimize water use and improve crop yield, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
Hyperspectral imaging can capture subtle changes in plant physiology that are indicative of stress, while machine learning algorithms can be employed to extract meaningful patterns from the spectral data and classify different stress types (Araus et al., 2014). Thermal sensing can detect changes in canopy temperature, which is influenced by factors such as plant water status (Li et al., 2019). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
The integration of advanced sensing technologies in automated irrigation management systems has the potential to revolutionize precision agriculture. Jiang et al. (2019) demonstrate the effectiveness of a deep learning-based model in accurately detecting leaf spot diseases, highlighting the importance of image augmentation and deep learning algorithms in enhancing the model's performance.
Wireless sensor networks (WSNs) and energy-efficient communication protocols have the potential to significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. WSNs offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems, providing remote monitoring and automated control capabilities (Mehdizadeh et al., 2020). Nishiura and Yamamoto (2021) propose a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields, reducing operational costs and enhancing the efficiency of data collection. Similarly, Higashiura and Yamamoto (2021) introduce a network system that employs UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands, optimizing data collection and reducing travel distance and time.
Energy-efficient communication protocols are crucial for ensuring reliable data transmission in challenging environmental conditions and extending the lifespan of sensor nodes (Mehdizadeh et al., 2020). Al-Ali et al. (2023) investigate the potential of WSNs and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems, discussing the challenges and opportunities of using these technologies to improve the efficiency and reliability of real-time data collection in irrigation management. Mehdizadeh et al. (2020) emphasize the need for careful consideration of factors such as data accuracy, energy consumption, and network reliability when designing effective WSNs for irrigation management, enabling timely irrigation decisions and improved crop yields.
The automation of data collection through the use of advanced sensing technologies and wireless sensor networks is essential for achieving fully autonomous, scalable irrigation management. By enabling non-invasive plant stress detection and large-scale, long-term data collection, these technologies contribute to the overall goal of optimizing water resource management and increasing agricultural productivity. The integration of these technologies in real-time, end-to-end automated irrigation management systems has the potential to enhance agricultural water use efficiency and crop productivity, ultimately contributing to the development of fully autonomous, scalable irrigation management solutions.

3.4: Real-Time Data Transmission Protocols and Technologies
Real-time data transmission is a critical component of automated irrigation management systems, as it enables the timely delivery of sensor data to the cloud for processing and decision-making. The exploration of suitable protocols and network architectures is essential for ensuring efficient and reliable data transmission in these systems, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
The Message Queuing Telemetry Transport (MQTT) protocol has emerged as a popular choice for real-time data transmission in IoT networks, including those used for automated irrigation management. MQTT is a lightweight, publish-subscribe protocol designed for constrained devices and low-bandwidth networks (Author, 2019). Its simplicity and low overhead make it well-suited for IoT applications where data transmission speed and energy efficiency are critical (Saranyadevi et al., 2022). MQTT provides three Quality of Service (QoS) levels, ensuring data reliability in real-time scenarios (Author, 2019). Chen et al. (2020) proposed novel algorithms to improve data exchange efficiency and handle rerouting in MQTT-based IoT networks for automated irrigation management systems. Their TBRouting algorithm efficiently finds the shortest paths for data transmission, while the Rerouting algorithm effectively handles the rerouting of topic-based session flows when a broker crashes. The combination of these algorithms can significantly improve the performance and reliability of automated irrigation management systems (Chen et al., 2020).
Client-server IoT networks, such as those based on MQTT, play a crucial role in real-time data transmission for automated irrigation management systems. In these networks, sensors and devices (clients) publish data to a central broker (server), which then distributes the data to subscribed clients (Verma et al., 2021). This architecture enables efficient data collection, processing, and dissemination, facilitating the integration of various components within the automated irrigation management pipeline. Verma et al. (2021) proposed an architecture for healthcare monitoring systems using IoT and communication protocols, which provides a comprehensive overview of existing approaches and highlights challenges and opportunities in the field. Although focused on healthcare, the insights from this study can be applied to automated irrigation management systems, emphasizing the importance of interoperability and standardization for seamless integration (Verma et al., 2021).
In addition to MQTT, other application layer protocols such as XMPP, CoAP, SOAP, and HTTP have been explored for real-time data transmission in IoT networks. Each protocol has its strengths and weaknesses, making them suitable for different applications and scenarios. XMPP (Extensible Messaging and Presence Protocol) is an open-standard protocol that supports real-time messaging, presence, and request-response services (Saint-Andre, 2011). CoAP (Constrained Application Protocol) is a specialized web transfer protocol designed for use with constrained nodes and networks in the Internet of Things (Shelby et al., 2014). SOAP (Simple Object Access Protocol) is a protocol for exchanging structured information in the implementation of web services, while HTTP (Hypertext Transfer Protocol) is the foundation of data communication for the World Wide Web (Fielding et al., 1999).
Motamedi and Villányi (2022) compared and evaluated wireless communication protocols for the implementation of smart irrigation systems in greenhouses, considering factors such as power consumption, range, reliability, and scalability. They found that ZigBee is the most suitable local communication protocol for greenhouse irrigation due to its large number of nodes and long range, while MQTT is the recommended messaging protocol for smart irrigation systems due to its TCP transport protocol and quality of service (QoS) options. GSM is a reliable and cost-effective global communication protocol for greenhouse irrigation, providing wide coverage and low cost (Motamedi & Villányi, 2022).
Syafarinda et al. (2018) investigated the use of the MQTT protocol in a precision agriculture system using a Wireless Sensor Network (WSN). They found that MQTT is suitable for use in IoT applications due to its lightweight, simple, and low bandwidth requirements. The average data transmission speed using the MQTT protocol was approximately 1 second, demonstrating its effectiveness for real-time data transmission in precision agriculture systems (Syafarinda et al., 2018).
The choice of application layer protocol for real-time irrigation management depends on factors such as data transmission speed, reliability, and energy efficiency. MQTT and RTPS (Real-Time Publish-Subscribe) are both suitable for real-time data transmission in IoT systems, but they have different strengths and weaknesses. MQTT is a better choice for applications that require low latency and high throughput, while RTPS is a better choice for applications that require high reliability and low latency (Sanchez-Iborra & Skarmeta, 2021). The exploration of MQTT and client-server IoT networks, along with the comparison of various application layer protocols, provides valuable insights into the suitability of these technologies for real-time data transmission in automated irrigation management systems.
In summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.

3.5. Challenges and Solutions in Real-Time Data Transmission
Following the exploration of data collection, processing at the edge and fog, and automation in previous sections, we now turn to the critical aspect of real-time data transmission. While essential for automated irrigation management, this stage presents unique challenges that must be addressed to ensure system efficiency and reliability.
Obstacles in Real-Time Data Transmission
Agricultural environments present unique challenges for real-time data transmission, directly impacting the effectiveness of automated irrigation systems. Environmental factors can significantly disrupt wireless communication. Adverse weather conditions such as heavy rain, fog, and high winds can weaken or even block radio signals, leading to data loss and compromised system performance. Physical obstacles like trees, buildings, and uneven terrain further complicate signal propagation, creating reliability issues (Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). These environmental challenges necessitate robust communication protocols and network architectures that can ensure consistent and reliable data flow.
In addition to environmental factors, technical limitations also present significant obstacles. Large-scale agricultural operations often demand long-distance data transmission, which can be hindered by the limited range of certain wireless communication protocols. Network congestion, occurring when multiple sensors transmit data concurrently, can lead to delays and potential data loss, further complicating real-time decision-making (Hameed et al., 2020). To mitigate these issues, researchers have investigated the potential of cognitive radio networks (CRNs) and dynamic spectrum access (DSA) for optimizing spectrum utilization and reducing interference (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). CRNs enable devices to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency. DSA, on the other hand, facilitates the dynamic allocation of unused spectrum, enhancing spectrum utilization and reducing congestion.
Furthermore, data security and privacy are paramount concerns in real-time irrigation systems. The sensitive nature of agricultural data, such as crop yields and farm management practices, necessitates robust security measures to prevent unauthorized access and data breaches (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential to protect data integrity and ensure the trustworthiness of the system.
Investigating Data Optimization Techniques
To enhance the efficiency and reliability of real-time data transmission in automated irrigation systems, researchers have explored a range of data optimization techniques. Data compression techniques aim to reduce the size of data packets transmitted over the network, minimizing bandwidth requirements and improving transmission speed (Rady et al., 2020; Karim et al., 2023). Lossless compression algorithms, such as Huffman coding and LZW, preserve data integrity while effectively reducing data size, ensuring that no information is lost during transmission (Cui, 2023). Lossy compression algorithms, such as JPEG and MP3, offer higher compression ratios but introduce a controlled level of data loss, which may be acceptable for certain applications where some loss of precision is tolerable (Karim et al., 2023). The choice between lossless and lossy compression depends on the specific application and the trade-off between data size and accuracy.
Data aggregation techniques provide another effective approach to optimize data transmission. By aggregating multiple sensor readings into a single representative value, such as average soil moisture or temperature, the number of transmissions can be significantly reduced, conserving bandwidth and energy resources (Cui, 2023). This is particularly beneficial in large-scale irrigation systems where numerous sensors are deployed across vast areas, generating substantial amounts of data. Additionally, data filtering techniques play a crucial role in improving data quality and reliability. Kalman filters and particle filters can effectively remove noise and outliers from sensor data, ensuring that only accurate and relevant information is transmitted and used for decision-making (Cui, 2023). This is essential for preventing erroneous data from influencing irrigation decisions and potentially leading to suboptimal water management.
Sensor calibration, drift correction, and fault detection are essential for maintaining data accuracy and reliability (Dos Santos et al., 2023). Regular calibration ensures that sensors provide accurate measurements over time, while drift correction techniques account for gradual changes in sensor readings due to environmental factors or aging. Fault detection mechanisms can identify and address sensor malfunctions or anomalies, preventing erroneous data from influencing irrigation decisions and potentially harming crops or wasting water.
Addressing the Challenges
Effectively addressing the challenges in real-time data transmission requires a multifaceted approach that encompasses environmental, technical, and data-related considerations. Implementing robust and adaptive communication protocols is crucial for overcoming interference and signal degradation caused by weather conditions and physical obstacles. Selecting appropriate protocols, such as LoRa or ZigBee, with suitable range and penetration capabilities can ensure reliable data transmission in challenging agricultural environments (Motamedi & Villányi, 2022). Additionally, employing techniques like frequency hopping and error correction codes can further improve communication resilience and mitigate data loss.
Optimizing network architecture is another key consideration. Deploying a distributed network architecture with edge and fog computing capabilities can significantly enhance data processing and transmission efficiency (Abdel Nasser et al., 2020; Tran et al., 2019). Edge devices can perform initial data processing and aggregation tasks, reducing the amount of data transmitted to the cloud and minimizing latency, while fog nodes can provide additional processing power and storage closer to the data source, enhancing scalability and reliability. This distributed approach alleviates the burden on the central cloud server and allows for more responsive and efficient irrigation management.
Data optimization techniques play a vital role in reducing bandwidth requirements and improving transmission efficiency. The choice of data compression, aggregation, and filtering techniques should be tailored to the specific requirements of the irrigation system, considering factors such as data type, accuracy needs, and available bandwidth. By carefully selecting and implementing these techniques, the overall performance and effectiveness of real-time irrigation systems can be significantly enhanced, leading to more sustainable water management practices and improved agricultural productivity.
By addressing these challenges and implementing appropriate solutions, real-time data transmission can become a reliable and efficient component of automated irrigation systems, contributing to the overall goal of achieving sustainable and productive agriculture in the face of growing food demands and water scarcity.

3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
Real-time irrigation management systems heavily rely on the efficient and reliable transmission of data from sensors and weather stations to the cloud for processing and decision-making. However, agricultural environments present unique challenges to wireless communication, including adverse weather conditions, physical obstacles, and the limitations of wireless technologies. These challenges necessitate robust and adaptive solutions to ensure the consistent and timely flow of data, enabling truly autonomous irrigation scheduling.
Environmental factors, such as heavy rain, fog, and strong winds, can significantly disrupt wireless communication by attenuating or even blocking radio signals, leading to data loss and compromised system performance (Ed-daoudi et al., 2023; Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). Dense vegetation, buildings, and uneven terrain create further complications by causing multipath propagation and shadowing effects (Yim et al., 2018; Gautam and Pagay, 2020). The study by Yim et al. (2018) on LoRa networks in a tree farm environment exemplifies these challenges, revealing reduced communication range and data reliability compared to theoretical expectations. This underscores the need for carefully selecting and optimizing communication protocols and network parameters to ensure reliable data transmission in such environments.
The study by Guzinski et al. (2014a) using a modified TSEB model further highlights the importance of high-resolution data in accurately capturing the spatial and temporal dynamics of energy fluxes influenced by environmental factors. This emphasizes the need for advanced data acquisition and processing techniques that can effectively represent the complexities of agricultural settings.
The limitations of traditional wireless communication technologies, such as limited range and network congestion, pose additional challenges for large-scale agricultural operations. Long-distance data transmission can be hindered by range limitations, while network congestion arising from numerous sensors transmitting concurrently can lead to delays and data loss, hindering real-time decision-making (Hameed et al., 2020). Addressing these challenges requires the exploration of advanced networking technologies that can optimize spectrum utilization, mitigate interference, and improve reliability and efficiency.
Cognitive Radio Networks (CRNs) and Dynamic Spectrum Access (DSA) offer promising solutions for optimizing wireless communication in agricultural settings. CRNs empower devices with the ability to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). Research has explored the potential of CRNs in predicting Radio Frequency (RF) power to avoid noisy channels and optimize spectrum utilization (Iliya et al., 2014; Iliya et al., 2014). These studies demonstrate the effectiveness of combining optimization algorithms with artificial neural networks (ANNs) to enhance the accuracy and generalization of RF power prediction, enabling CRNs to make informed decisions about channel selection and avoid interference.
DSA complements CRN technology by dynamically allocating unused spectrum, further enhancing spectrum utilization and reducing congestion (Shi et al., 2023). The numerical model developed by Shi et al. (2023) showcases the potential of CRNs and DSA for optimizing wireless communication in challenging environments.
The integration of CRNs and DSA into the IoT network architecture requires careful consideration of spectrum sensing techniques, network topology, and data security. Research on cooperative spectrum sensing suggests that distributed approaches, where sensor nodes collaborate and share information, can significantly improve the accuracy and efficiency of spectrum sensing, particularly in dynamic environments (Trigka and Dritsas, 2022; Khalid & Yu, 2019). This collaborative approach enables a more comprehensive understanding of the radio environment and facilitates the identification of available frequency bands for data transmission.
The choice of network topology also impacts the performance and scalability of CRN-based irrigation systems. Mesh networks, where sensor nodes are interconnected and relay data for each other, offer enhanced resilience and coverage compared to star topologies where nodes communicate directly with a central gateway (Akyildiz & Vuran, 2010). However, mesh networks can be more complex to manage and may introduce additional routing overhead. The trade-off between network resilience and complexity needs to be carefully evaluated to select the most appropriate topology for a specific agricultural setting.
Data security and privacy are paramount concerns in IoT-based irrigation systems due to the sensitive nature of agricultural data (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential for protecting data integrity and ensuring system trustworthiness. Research on secure spectrum leasing and resource allocation algorithms for CR-WSN-based irrigation systems has demonstrated the potential of these technologies for enhancing security and efficiency (Hassan, 2023; Afghah et al., 2018).
In conclusion, the development of effective and reliable real-time irrigation management systems requires a comprehensive approach that addresses the challenges of data transmission in agricultural environments. The integration of robust and adaptive communication protocols, optimized network architectures, and advanced networking technologies like CRNs and DSA, along with a focus on data security and privacy, can contribute significantly to achieving the goal of autonomous and efficient irrigation scheduling.
4. AUTOMATED DATA PROCESSING IN THE CLOUD
4.1. Data Quality and Preprocessing
Data quality is paramount in automated irrigation systems as it directly influences the effectiveness of decision-making and water use efficiency. Issues like missing values, inconsistencies, and outliers arising from sensor malfunctions, environmental interference, or network problems (Lv et al., 2023) can significantly impact the performance of machine learning models used for irrigation scheduling and management.
Real-time data cleaning techniques are essential for addressing these challenges. Kalman filtering proves particularly effective in handling missing values and correcting erroneous readings by recursively estimating the system's state based on previous measurements and current sensor data, taking into account noise and uncertainty (Kim et al., 2020). Moving average techniques, by averaging consecutive data points, provide a more stable representation of the underlying trend, filtering out short-term fluctuations (Chhetri, 2023). For outlier detection, adaptive thresholding methods offer a dynamic approach, adjusting thresholds based on the statistical properties of the data to effectively identify anomalies and minimize false positives (Bah et al., 2021). These techniques are crucial in maintaining the integrity of real-time data streams and ensuring the accuracy of subsequent analyses.
Adaptive data preprocessing is essential for managing the diversity of data sources and formats commonly found in irrigation systems. Data normalization techniques, such as min-max scaling or z-score normalization, ensure that all features contribute equally to the analysis by transforming data values to a common scale (Pradal et al., 2016). This is crucial for preventing features with larger values from dominating the analysis and ensuring that all features are given equal consideration. Similarly, feature scaling methods, like standardization or normalization, optimize the range of feature values to improve the performance and convergence of machine learning models (Tortorici et al., 2024). By scaling features to a similar range, the influence of outliers is reduced, and the model's ability to learn from the data is enhanced.
Data fusion techniques play a critical role in integrating information from diverse sources, creating a more comprehensive and reliable dataset for irrigation management. Dempster-Shafer theory, a generalization of probability theory, allows for the expression of both uncertainty and the degree of conflict in evidence, making it suitable for fusing uncertain and conflicting data from heterogeneous sources (Sadiq and Rodriguez, 2004). This is particularly relevant in irrigation systems where data from different sensors may provide slightly different or even contradictory information due to sensor variations or environmental factors. Bayesian inference offers another powerful framework for combining information from multiple sources, updating the probability of a hypothesis as new evidence becomes available. By applying these techniques, data from soil moisture sensors, canopy temperature sensors, weather stations, and other sources can be integrated to provide a holistic understanding of crop water requirements and environmental conditions, leading to more informed and accurate irrigation decisions.
The impact of data quality extends beyond model accuracy to the robustness of machine learning models under varying conditions. Robust models should maintain consistent performance even when faced with data inconsistencies or unexpected situations. Techniques like data augmentation and domain adaptation can enhance model robustness by exposing the model to a wider range of data variations during training. Data augmentation involves generating additional training data by applying transformations or introducing noise to existing data, making the model more resilient to noise and variations in the real-world data. Domain adaptation techniques aim to adapt a model trained on one domain (e.g., a specific crop or geographic location) to perform well on another domain with different data characteristics. This is particularly relevant in irrigation management, where models may need to be applied to different crops, soil types, or climatic conditions.
The choice of data cleaning, preprocessing, and fusion techniques should be carefully considered based on the specific characteristics of the irrigation system and the available data. By selecting and implementing appropriate techniques, the accuracy, reliability, and robustness of machine learning models can be significantly improved, leading to more efficient and sustainable irrigation management practices.
4.2. Scalable and Autonomous Deployment using Containerization Strategies
The transition from data collection and transmission to efficient data processing requires a robust infrastructure capable of handling diverse workloads and data volumes. Containerization technologies, specifically Docker and Kubernetes, offer a promising solution for deploying and scaling data processing and machine learning modules within cloud environments like AWS, Azure, and GCP (Vargas-Rojas et al., 2024; Rosendo et al., 2022; Solayman & Qasha, 2023). Docker provides a standardized way to package applications and their dependencies into self-contained units known as containers, ensuring consistent and reproducible execution across different platforms (Rosendo et al., 2022). Kubernetes, acting as a container orchestrator, manages their deployment, scaling, and networking across a cluster of machines (Rosendo et al., 2022). This combination presents several advantages for automated irrigation management systems.
Firstly, containerization facilitates efficient resource utilization and scalability. By encapsulating applications and their dependencies, containers enable the isolation of resources and prevent conflicts between different modules (Vargas-Rojas et al., 2024; Solayman & Qasha, 2023). This isolation allows for the efficient allocation of resources, such as CPU, memory, and storage, to each container based on its specific needs. Kubernetes further enhances scalability by allowing for the automatic scaling of containers based on real-time demand, ensuring the system can adapt to varying workloads and data volumes, preventing bottlenecks, and ensuring responsiveness to changing conditions (Karamolegkos et al., 2023).
Secondly, containerization promotes portability and reproducibility. By packaging applications and their dependencies into a single unit, containers make it easy to move and deploy them across different cloud environments without the need for environment-specific configurations (Rosendo et al., 2022; Solayman & Qasha, 2023). This portability simplifies the development and deployment process, reducing the time and effort required to set up and manage the system. Additionally, containers ensure reproducibility by providing a consistent execution environment, regardless of the underlying infrastructure. This eliminates variability and ensures that the system will behave consistently across different deployments (Zhou et al., 2023).
Optimizing container orchestration and resource allocation is crucial to minimizing latency and maximizing throughput in real-time data processing pipelines. Techniques like auto-scaling and dynamic resource allocation play a critical role in this context (Hethcoat et al., 2024; Werner and Tai, 2023; Kumar et al., 2024). Auto-scaling automatically adjusts the number of container instances based on real-time demand, ensuring that sufficient resources are available to handle peak workloads while avoiding over-provisioning during periods of low demand (Hethcoat et al., 2024; Kumar et al., 2024). Dynamic resource allocation enables the fine-grained adjustment of resources allocated to each container based on its specific needs and the current workload (Werner and Tai, 2023). This ensures efficient resource allocation and provides each container with the necessary resources to perform its tasks effectively.
Performance monitoring tools, such as Kubernetes Metrics Server and Prometheus, are essential for gaining insights into the performance of containers and the overall system (Hethcoat et al., 2024; Kuity & Peddoju, 2023). These tools provide valuable data on key performance indicators, such as CPU and memory usage, network traffic, and application-specific metrics. By monitoring this data, administrators can identify bottlenecks, optimize resource allocation strategies, and continuously improve system performance (Hethcoat et al., 2024). This data-driven approach ensures that automated irrigation management systems can operate efficiently and reliably.
By integrating containerization technologies with optimization techniques and performance monitoring, automated irrigation management systems achieve the scalability, autonomy, and efficiency required for effective real-time data processing and decision-making. This approach facilitates a seamless and responsive system that can adapt to changing conditions and contribute to the overall goal of optimizing water resource management and increasing agricultural productivity.

4.3. Deploying ML Models for Data Processing
Transitioning from data collection, preprocessing, and transmission, the deployment of machine learning (ML) models marks a pivotal stage in the automated irrigation management pipeline. This stage entails utilizing cloud platforms to facilitate real-time data processing and inference, enabling data-driven decision-making for optimal irrigation management and ultimately contributing to fully autonomous, scalable irrigation management.
Several architectures and frameworks exist for deploying ML models on cloud platforms, each offering unique advantages and catering to different requirements. TensorFlow Serving, for instance, provides a high-performance system specifically designed for serving TensorFlow models (Abadi et al., 2016). This framework enables efficient and scalable inference, making it suitable for real-time applications where low latency and high throughput are crucial. For instance, in a large-scale irrigation system with numerous sensors generating data continuously, TensorFlow Serving can efficiently handle the high volume of inference requests and provide timely predictions for irrigation scheduling. Similarly, Apache MXNet Model Server offers a flexible and efficient solution for deploying models trained with MXNet, supporting a wide range of deep learning models and inference backends (MXNet Developers, 2015). This versatility makes it suitable for complex irrigation systems that may utilize different types of ML models for various tasks, such as predicting crop water requirements, detecting plant stress, or forecasting weather conditions. ONNX Runtime, on the other hand, provides a cross-platform inference engine compatible with various ML frameworks, including PyTorch, TensorFlow, and MXNet (Microsoft, 2017). This versatility enables the deployment of models in diverse environments, facilitating interoperability and reducing the need for model conversion. For example, an irrigation system that uses models trained in different frameworks can utilize ONNX Runtime to deploy them on a single platform without the need for time-consuming and error-prone model conversion processes.
Choosing the appropriate architecture or framework depends on several factors, including the specific ML framework used for model training, the desired level of performance and scalability, and the need for cross-platform compatibility. For instance, if the primary concern is low latency and high throughput for real-time inference, TensorFlow Serving might be the optimal choice for TensorFlow models. However, if flexibility and support for various deep learning models are required, Apache MXNet Model Server could be more suitable. In cases where cross-platform compatibility is essential, ONNX Runtime offers a versatile solution.
Once the ML model is deployed, optimizing its performance and resource utilization becomes crucial for ensuring the efficiency of integrated end-to-end automated irrigation systems. Model compression techniques, such as pruning and quantization, offer effective methods for reducing the size and computational requirements of ML models without compromising accuracy (Premkumar & Sigappi, 2022). Pruning involves eliminating unnecessary connections or neurons from the model, effectively streamlining its structure and reducing computational complexity. This can be particularly beneficial for deep learning models, which often have a large number of parameters and can be prone to overfitting. By removing redundant or less important connections, pruning can improve modelgeneralizability and reduce inference time. Quantization, on the other hand, involves reducing the precision of model parameters, typically from 32-bit floating-point numbers to lower-precision formats such as 8-bit integers. This reduction in precision leads to smaller model sizes and faster inference speeds, making it particularly beneficial for resource-constrained environments or real-time applications. For instance, in edge computing scenarios where ML models are deployed on devices with limited computational resources, quantization can enable efficient inference without sacrificing accuracy.
Furthermore, hardware acceleration through the utilization of GPUs or TPUs can significantly enhance model performance by leveraging specialized hardware designed for parallel processing (Premkumar & Sigappi, 2022). GPUs, with their massive parallelism and high memory bandwidth, excel at accelerating matrix operations and convolutions, which are fundamental computations in many deep learning models. This acceleration can significantly reduce inference time and enable real-time processing of sensor data for timely irrigation decisions. TPUs, specifically designed for deep learning workloads, offer even greater performance and energy efficiency for specific model architectures. These hardware accelerators can drastically reduce inference time, enabling near real-time decision-making and enhancing the responsiveness of automated irrigation systems. For example, in a scenario where immediate response to changing weather conditions or soil moisture levels is critical, hardware acceleration can ensure that irrigation decisions are made and executed promptly.
In addition to model compression and hardware acceleration, distributed training techniques play a crucial role in optimizing the training process for large-scale ML models. Techniques such as Horovod and BytePS enable the distribution of training across multiple machines, effectively parallelizing the process and reducing training time (Premkumar & Sigappi, 2022). This is particularly beneficial for complex models with a large number of parameters or when dealing with large datasets. By leveraging distributed training, irrigation management systems can train more sophisticated models and improve their predictive capabilities, leading to more accurate and efficient irrigation decisions. For instance, a system that utilizes a deep learning model with millions of parameters can benefit from distributed training to reduce training time from days to hours, enabling faster model iteration and improvement.
Integrating the deployed ML models with other components of the automated irrigation management pipeline is essential for achieving a fully autonomous and cohesive system and addressing the need for seamless integration across the automated irrigation management system. Standardized protocols, such as MQTT and CoAP, provide lightweight and efficient communication channels for exchanging data between these components (Poojara et al., 2023; Jimenez et al., 2020a; Gour et al., 2023). MQTT, with its publish-subscribe architecture, enables real-time data streaming and event-driven communication, making it suitable for transmitting sensor data, control signals, and inference results (Raikar & M, 2023). This enables the ML model to receive real-time updates on soil moisture, weather conditions, and plant health, allowing for dynamic adjustments to irrigation schedules based on the latest data. CoAP, designed for constrained devices and low-power networks, offers a web-transfer protocol for resource-constrained environments, enabling efficient communication between sensors, actuators, and the ML models (Raikar & M, 2023). This is particularly relevant in situations where sensors or actuators have limited processing power or battery life, as CoAP minimizes communication overhead and energy consumption. Additionally, RESTful APIs provide a standardized interface for accessing and controlling the ML models, enabling seamless integration with other software components and facilitating system management and monitoring (Wang et al., 2022). This allows for easy integration with existing farm management systems or third-party applications, creating a unified platform for comprehensive irrigation management.4.4. Online Learning in the Cloud
The complexities of real-time data processing in irrigation management necessitate the exploration of advanced techniques to continuously learn and adapt to the dynamic nature of agricultural environments. Online learning algorithms offer a promising solution, enabling the continuous update and improvement of machine learning models based on incoming real-time data. This adaptability is crucial for addressing the challenges of changing environmental conditions, such as weather patterns and crop growth stages, and optimizing irrigation decision-making to enhance water usage efficiency and crop productivity.
Several online learning algorithms have demonstrated potential for real-time data processing and model adaptation in the context of irrigation management. Stochastic Gradient Descent (SGD) facilitates the incremental update of model parameters with each new data point, allowing for efficient adaptation to changing data distributions (Bottou, 2010). This incremental learning process ensures that the model remains responsive to the latest conditions, minimizing the risk of outdated predictions and improving the accuracy of irrigation decisions. Passive-Aggressive algorithms, on the other hand, adjust model parameters only when a misclassification occurs, providing a computationally efficient approach for handling large data streams (Crammer et al., 2006). These algorithms offer a robust approach to handling noisy data, a common challenge in real-world sensor readings, by making small adjustments only when the model's prediction deviates significantly from the actual value (Fei et al., 2019). Online Random Forests extend the concept of random forests to the online setting, enabling the incremental construction and update of decision trees as new data arrives (Saffari et al., 2009). The continuous evolution of the ensemble ensures that the model remains relevant to the changing environment, capturing intricate relationships between variables and leading to more informed irrigation decisions.
Research in various domains highlights the importance of online learning for real-time data stream analytics. Snyder et al. (2020) explored the application of online learning techniques for identifying relevant tweets in real-time, improving situational awareness for first responders. The proposed interactive learning framework allows users to continuously label the relevance of incoming tweets, enabling the real-time refinement of the underlying machine learning model. This user-guided approach aligns well with the dynamic nature of irrigation management, where models need to continuously adjust to varying environmental conditions and crop water requirements. Similarly, research in the field of cyber-physical systems (CPS) underscores the need for online learning algorithms to effectively extract insights and knowledge from continuously generated data streams (Fei et al., 2019). These capabilities are crucial for enabling feedback loops between physical processes and cyber elements, facilitating the integration and optimization of CPS in irrigation management systems.
To implement online learning in cloud-based irrigation management systems, various architectures and frameworks can be considered. Apache Spark Streaming, Apache Flink, and AWS Kinesis provide scalable and fault-tolerant platforms for processing real-time data streams, allowing for the development of online learning pipelines that continuously ingest and analyze data to update machine learning models (Zaharia et al., 2012; Carbone et al., 2015; Amazon Web Services, 2023). These frameworks leverage serverless computing paradigms, automatically scaling resources based on the volume and velocity of incoming data, ensuring efficient resource utilization and responsiveness to fluctuations in demand (Fei et al., 2019).
Effectively managing the exploration-exploitation trade-off is crucial for optimizing online learning in irrigation management. Techniques such as Multi-armed bandits (Sutton & Barto, 2018), Bayesian optimization (Shahriari et al., 2016), and Reinforcement Learning (RL) (Sutton & Barto, 2018) can be employed to balance the allocation of resources between exploring new irrigation strategies and exploiting the current best-performing approaches. These techniques enable the identification of optimal irrigation policies, adapting to changing environmental conditions and maximizing long-term rewards.
In conclusion, online learning techniques, coupled with scalable cloud-based architectures, offer a powerful solution for real-time data processing and continuous adaptation in irrigation management systems. By leveraging algorithms like SGD, Passive-Aggressive, and Online Random Forests, along with stream processing frameworks like Apache Spark Streaming, Apache Flink, and AWS Kinesis, irrigation management systems can effectively handle the complexities of real-time data, optimize water usage, and enhance crop productivity in the face of dynamic environmental conditions.

5. GENERATING AND APPLYING IRRIGATION INSIGHTS 
5.1. Real-Time Generation of Actionable Irrigation Insights
•	Advanced predictive models, such as deep learning (e.g., LSTM, CNN) and ensemble methods (e.g., Random Forests), for precise, site-specific irrigation recommendations
•	Integration of IoT sensor data (e.g., soil moisture probes, weather stations) and cloud-based data sources (e.g., weather forecasts, satellite imagery) using data fusion techniques (e.g., Kalman filtering) to enhance insight accuracy and resolution
•	Strategies for handling data heterogeneity, uncertainty, and quality issues in real-time insight generation, such as data preprocessing and outlier detection
•	Techniques for reducing computational complexity and latency, such as edge computing (e.g., fog computing), model compression (e.g., quantization), and hardware accelerators (e.g., GPUs)
5.2. Automated Application of Irrigation Insights
•	Architectures and protocols for seamless integration of ML-generated insights with IoT-enabled irrigation control systems, such as MQTT and CoAP for lightweight, real-time communication
•	Analysis of industry-leading products and services, such as smart irrigation controllers (e.g., Rachio) and cloud-based irrigation management platforms (e.g., CropX)
•	Strategies for ensuring reliability, security, and scalability of automated insight application, such as redundant communication channels and secure edge-to-cloud architectures
•	Case studies of successful implementations of closed-loop, autonomous irrigation systems in research and commercial settings, highlighting technologies used and benefits achieved

6. INTEGRATION, INTEROPERABILITY, AND STANDARDIZATION 
6.1. Interoperability and Standardization
•	Importance of interoperability and standardization in enabling seamless integration of automated irrigation components
•	Overview of existing and emerging standards for IoT devices, communication protocols, and data formats in precision agriculture (e.g., ISOBUS, agroXML, SensorML)
•	Role of standardization bodies and industry consortia in promoting interoperability (e.g., AgGateway, Open Ag Data Alliance, Agricultural Industry Electronics Foundation)
•	Challenges in adopting and implementing standards across diverse hardware and software platforms
•	Strategies for encouraging widespread adoption of standards and best practices for interoperability in automated irrigation systems
6.2. Integration with Existing Irrigation Infrastructure
•	Challenges and strategies for retrofitting legacy irrigation systems with IoT sensors, actuators, and communication devices
•	Hardware compatibility issues and solutions (e.g., adapters, modular designs)
•	Software and firmware updates to enable integration with automated decision-making systems
•	Data integration and normalization techniques for merging legacy and new data sources
•	Economic and practical considerations for transitioning from manual to automated irrigation management
•	Cost-benefit analysis of upgrading existing infrastructure vs. implementing new systems
•	Phased implementation approaches to minimize disruption and optimize resource allocation
•	Training and support requirements for farmers and irrigation managers adopting automated systems
•	Case studies and real-world examples of successful integration of automated irrigation with existing infrastructure
6.3. Integration with Other Precision Agriculture Technologies
•	Synergies between automated irrigation and complementary technologies
•	Remote sensing (satellite, UAV, and ground-based) for crop monitoring and evapotranspiration estimation
•	Soil moisture sensors and weather stations for real-time, localized data collection
•	Variable rate application systems for precise irrigation delivery based on crop requirements
•	Yield mapping and analytics for assessing the impact of automated irrigation on crop productivity
•	Architectures and frameworks for integrating diverse data sources and technologies into a unified precision agriculture ecosystem
•	Edge computing and fog computing paradigms for real-time data processing and decision-making
•	Cloud-based platforms for data storage, analysis, and visualization
•	API-driven approaches for modular integration of third-party services and applications
•	Challenges and solutions for ensuring data quality, consistency, and security across integrated precision agriculture systems
•	Data cleaning, preprocessing, and harmonization techniques
•	Blockchain and distributed ledger technologies for secure, tamper-proof data sharing and traceability
•	Access control and authentication mechanisms for protecting sensitive data and resources
•	Future trends and research directions in the integration of automated irrigation with advanced precision agriculture technologies (e.g., AI-driven crop modeling, robotics, and autonomous vehicles)
6.4. Cybersecurity Considerations for Integrated Automated Irrigation Systems
•	Unique security risks and vulnerabilities associated with IoT-based automated irrigation systems
•	Potential for unauthorized access, data tampering, and system manipulation
•	Implications of security breaches for crop health, water resource management, and farm productivity
•	Best practices and strategies for securing automated irrigation systems
•	Secure device provisioning and authentication (e.g., hardware security modules, certificates)
•	Encryption and secure communication protocols (e.g., TLS, DTLS)
•	Firmware and software updates to address emerging security threats
•	Network segmentation and access control to limit the impact of breaches
•	Role of cybersecurity standards and frameworks in guiding the development and deployment of secure automated irrigation systems (e.g., NIST CSF, IEC 62443)
•	Importance of user awareness, training, and incident response planning in maintaining the security of integrated automated irrigation systems

7. MONITORING AND ENSURING SYSTEM RELIABILITY
7.1. Resilience and Fault Tolerance in Automated Irrigation Systems
•	Strategies for ensuring robustness and reliability in the face of failures, disruptions, or unexpected events
•	Redundancy: Implementing redundant components, such as duplicate sensors (e.g., soil moisture sensors, weather stations), controllers (e.g., PLCs, microcontrollers), and communication channels (e.g., cellular, satellite, LoRaWAN) to maintain system functionality during component failures
•	Failover mechanisms: Designing seamless failover mechanisms that automatically switch to backup components or systems in case of primary system failure, such as hot-standby controllers or multi-path communication protocols (e.g., mesh networks, software-defined networking)
•	Self-healing capabilities: Incorporating AI-driven self-healing mechanisms that can detect, diagnose, and recover from faults without human intervention, using techniques like reinforcement learning, Bayesian networks, or self-organizing maps
•	The role of distributed architectures and edge computing in enhancing system resilience
•	Decentralizing critical functions and data processing to minimize the impact of single points of failure, using fog computing or multi-agent systems
•	Leveraging edge computing to enable localized decision-making and control, reducing dependence on cloud connectivity and improving response times, using technologies like Raspberry Pi, NVIDIA Jetson, or Intel NUC
•	Anomaly detection and predictive maintenance using AI techniques
•	Employing unsupervised learning algorithms (e.g., autoencoders, clustering) to detect anomalies in sensor data, system performance, and water usage patterns
•	Developing predictive maintenance models using techniques like long short-term memory (LSTM) networks, convolutional neural networks (CNNs), or gradient boosting machines (GBMs) to anticipate and prevent potential system failures based on historical data and real-time monitoring
7.2. Advanced Monitoring Techniques for Automated Irrigation Systems
•	Remote monitoring using IoT-enabled sensors and computer vision
•	Deploying a heterogeneous network of IoT sensors to collect real-time data on soil moisture (e.g., capacitive, tensiometric), temperature (e.g., thermocouples, thermistors), humidity (e.g., capacitive, resistive), and plant health (e.g., sap flow, leaf wetness)
•	Integrating high-resolution cameras (e.g., multispectral, hyperspectral) and computer vision algorithms for visual monitoring of crop growth, disease detection (e.g., using deep learning-based object detection and segmentation), and irrigation system performance (e.g., leak detection, sprinkler uniformity)
•	Transmitting sensor and camera data to cloud-based platforms (e.g., AWS IoT, Google Cloud IoT, Microsoft Azure IoT) for remote access and analysis using protocols like MQTT, CoAP, or AMQP
•	Innovative approaches for real-time system health assessment
•	Developing novel algorithms and metrics for evaluating the health and performance of automated irrigation systems, such as entropy-based measures, network resilience indices, or multi-criteria decision analysis (MCDA) frameworks
•	Combining data from multiple sources (e.g., sensors, weather forecasts, satellite imagery) using data fusion techniques (e.g., Kalman filters, Dempster-Shafer theory) to create a comprehensive view of system health
•	Employing advanced data visualization techniques (e.g., interactive dashboards, augmented reality) to present system health information in an intuitive and actionable format
7.3. Closed-Loop Control and Feedback Mechanisms
•	Exploring the concept of closed-loop control in autonomous irrigation systems
•	Implementing feedback loops that continuously monitor system performance and adjust irrigation schedules based on real-time data, using control techniques like proportional-integral-derivative (PID), model predictive control (MPC), or fuzzy logic control (FLC)
•	Integrating machine learning algorithms (e.g., reinforcement learning, genetic algorithms) to optimize closed-loop control strategies over time, adapting to changing environmental conditions and crop requirements
•	Designing effective feedback mechanisms for user interaction and system optimization
•	Providing user-friendly interfaces (e.g., mobile apps, web dashboards) for farmers to input preferences, constraints, and expert knowledge into the automated irrigation system, using techniques like participatory design or user-centered design
•	Incorporating user feedback and domain expertise to refine irrigation strategies and improve system performance
8. CASE STUDIES AND REAL-WORLD IMPLEMENTATIONS OF FULLY AUTONOMOUS IRRIGATION SYSTEMS
8.1. Fully Autonomous Irrigation Systems in Diverse Agricultural Settings
•	Row Crops: maize, wheat, soybean with real-time soil moisture monitoring and weather-based irrigation scheduling for fully automated precision irrigation
•	Orchards: citrus, apple, almond with plant health monitoring and precision water application for fully autonomous orchard management
•	Greenhouses: tomato, lettuce, herbs with automated drip irrigation and climate control integration for fully automated greenhouse operations
•	Urban Farming: rooftop gardens, vertical farms with IoT-enabled hydroponic systems and remote management for fully autonomous urban crop production
8.2. Integration of Advanced System Components for End-to-End Automation
•	Wireless sensor networks: soil moisture probes, weather stations, plant health monitoring cameras with low-power, long-range communication for fully automated data acquisition
•	Secure data transmission: LoRaWAN, NB-IoT, 5G, satellite communication for reliable, real-time data transfer from field to cloud in fully autonomous irrigation systems
•	Intelligent data processing: edge computing for local data filtering, cloud platforms for scalable storage and analysis, machine learning algorithms for predictive insights in fully automated irrigation management
•	Autonomous decision-making: advanced irrigation scheduling algorithms, precise valve control, closed-loop feedback systems for optimal water management in fully autonomous irrigation systems
8.3. Quantitative Performance Evaluation of Fully Automated Irrigation Systems
•	Water use efficiency: percent reduction in water consumption compared to conventional methods, improved water productivity (yield per unit of water) achieved through fully autonomous irrigation
•	Crop yield and quality improvements: percent increase in yield, enhanced crop uniformity, improved nutritional content attributed to fully automated precision irrigation
•	Labor and energy savings: quantified reduction in labor hours for irrigation management, decreased energy consumption for pumping due to optimized scheduling in fully autonomous systems
•	Economic viability: detailed return on investment analysis, payback period calculations, comprehensive cost-benefit analysis for fully autonomous irrigation management systems
8.4. Lessons Learned and Challenges Encountered in Deploying Autonomous Irrigation Systems
•	Technical challenges and solutions: ensuring reliable data transmission in remote locations, addressing interoperability issues between diverse system components, optimizing power consumption for extended battery life, adapting algorithms to local soil and weather conditions in fully autonomous irrigation systems
•	Operational and logistical hurdles: streamlining installation and maintenance procedures, providing effective user training, seamlessly integrating with existing farm management practices and legacy systems for fully automated irrigation management
•	Regulatory and socio-economic considerations: navigating complex water use regulations, addressing data privacy and security concerns, ensuring equitable access and affordability for smallholder farmers adopting fully autonomous irrigation technologies
8.5. Best Practices and Recommendations for Successful Implementation
•	Designing scalable, modular, and adaptable autonomous irrigation systems to accommodate future growth and changing requirements for fully automated water management
•	Prioritizing user-centered design principles and actively engaging stakeholders throughout the development and deployment process of fully autonomous irrigation solutions
•	Adopting open standards and communication protocols to enable seamless integration of system components and interoperability with third-party platforms in fully automated irrigation setups
•	Implementing robust data validation, filtering, and quality control mechanisms to ensure data integrity and reliability for decision-making in fully autonomous irrigation systems
•	Establishing clear data governance policies and security frameworks to protect sensitive information and maintain user trust in fully automated irrigation management
•	Developing intuitive user interfaces and decision support tools to facilitate easy adoption and effective use of fully autonomous irrigation systems
•	Collaborating with local extension services, agribusinesses, and technology providers for knowledge transfer, technical support, and continuous improvement of fully automated irrigation solutions
8.6. Synthesis of Case Studies and Implications for Autonomous Irrigation Adoption
•	Cross-case analysis of key performance indicators and critical success factors for fully autonomous irrigation scheduling systems in various contexts
•	Identification of common themes, challenges, and innovative solutions across diverse implementations of end-to-end fully automated irrigation management
•	Assessment of the potential for replicability and scaling of successful fully autonomous irrigation projects in different regions and farming systems
•	Implications for future research priorities, technology development roadmaps, and policy interventions to support widespread adoption of fully autonomous irrigation technologies

CONCLUSION/FUTURE DIRECTIONS AND UNANSWERED QUESTIONS
•	Summarize the key insights gained from the question-driven review, emphasizing how each section contributes to the overarching goal of achieving real-time, end-to-end automation in irrigation management
•	Based on the questions addressed, propose new research directions and unanswered questions
•	Identify key research gaps and propose concrete research questions and hypotheses for advancing the field of real-time, automated irrigation management
•	Highlight the need for collaborative research efforts across disciplines, such as computer science, agricultural engineering, and environmental science, to address the complex challenges of automated irrigation systems
•	Emphasize the need for further innovation and exploration in real-time, automated irrigation systems




</previous_sections>

</documents>
<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper. 

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: stated in: <subsection_title>
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>

<subsection_point_Point 5>
Point: The role of distributed architectures and edge computing in enhancing system resilience

Papers to support point:

Paper 1:
- APA Citation: Cicirelli, F., Guerrieri, A., Spezzano, G., & Vinci, A. (2017). An edge-based platform for dynamic smart city applications. Future Generation Computer Systems, 76, 106–118. https://doi.org/10.1016/j.future.2017.05.034
  Main Objective: To present a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems.
  Study Location: Unspecified
  Data Sources: Survey data, Interviews, Case studies
  Technologies Used: IoT, machine learning
  Key Findings: There is a need for distributed architectures and edge computing to enhance system resilience, and for the development of standardized interoperable solutions.
  Extract 1: The edge computing concept is a computational paradigm that pushes acquired data away from the core of data centers to the outer edges of a network, closer to the data sources, potentially fostering benefits such as faster event response, better data bandwidth exploitation, increased reliability, scalability and maintenance support.
  Extract 2: The paper in consideration presents the design and implementation of a real case study, namely the Smart Street Cosenza, which is a smart street implemented in the town of Cosenza (Italy) that furnishes decentralized urban intelligence services to citizens, especially related to climatic and environmental wellness and anomalies detection.
  Limitations: The article is not directly focused on addressing the challenges and strategies for integrating automated systems with existing infrastructure and other precision agriculture technologies, as the focus is on the integration, interoperability, and standardization of automated irrigation management systems.
  Relevance Evaluation: {'extract_1': 'The edge computing paradigm has the aim to push the computation on acquired data away from the core of data centers to the outer edges of a network, close to the data sources.', 'extract_2': 'The paper in consideration presents the design and implementation of a real case study, namely the Smart Street Cosenza, which is a smart street implemented in the town of Cosenza (Italy) that furnishes decentralized urban intelligence services to citizens, especially related to climatic and environmental wellness and anomalies detection.', 'relevance_score': 0.9}
  Relevance Score: 0.9
  Inline Citation: Cicirelli, Guerrieri, Spezzano, & Vinci, 2017
  Explanation: The edge computing concept is a computational paradigm that pushes acquired data away from the core of data centers to the outer edges of a network, closer to the data sources, potentially fostering benefits such as faster event response, better data bandwidth exploitation, increased reliability, scalability and maintenance support. The article in consideration presents the design and implementation of a real case study, namely the Smart Street Cosenza, which is a smart street implemented in the town of Cosenza (Italy) that furnishes decentralized urban intelligence services to citizens, especially related to climatic and environmental wellness and anomalies detection. The paper describes the Smart Street in terms of design, development and deployed components, and remarks how edge computing is implemented by using the agent metaphor natively supported by iSapiens, the IoT tool used to implement the smart street functionalities.

 Full Text: >
Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Keywords 1. Introduction 2. Related work 3. iSapiens: a platform for Smart Cities 4. Design and implementation of the Smart Street Cosenza 5. Conclusions and future work Acknowledgments References Vitae Show full outline Cited by (109) Figures (16) Show 10 more figures Tables (4) Table 1 Table 2 Table 3 Table 4 Future Generation Computer Systems Volume 76, November 2017, Pages 106-118 An edge-based platform for dynamic Smart City applications Author links open overlay panel Franco Cicirelli, Antonio Guerrieri, Giandomenico Spezzano, Andrea Vinci Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.future.2017.05.034 Get rights and content Highlights • The iSapiens platform for Smart City application development is proposed. • Methodological guidelines for proper design of iSapiens applications are shown. • The design and implementation of a real Smart City prototype in Cosenza, Italy, is presented. Abstract A Smart City is a cyber–physical system improving urban behavior and capabilities by providing ICT-based functionalities. An infrastructure for Smart City has to be geographically and functionally extensible, as it requires both to grow up with the physical environment and to meet the increasing in needs and demands of city users/inhabitants. In this paper, we propose iSapiens, an IoT-based platform for the development of general cyber–physical systems suitable for the design and implementation of smart city services and applications. As distinguishing features, the iSapiens platform implements the edge computing paradigm through both the exploitation of the agent metaphor and a distributed network of computing nodes directly scattered in the urban environment. The platform promotes the dynamic deployment of new computing nodes as well as software agents for addressing geographical and functional extensibility. iSapiens provides a set of abstractions suitable to hide the heterogeneity of the physical sensing/actuator devices embedded in the system, and to support the development of complex applications. The paper also furnishes a set of methodological guidelines exploitable for the design and implementation of smart city applications by properly using iSapiens. As a significant case study, the design and implementation of a real Smart Street in the city of Cosenza (Italy) are shown, which provides decentralized urban intelligence services to citizens. Previous article in issue Next article in issue Keywords Smart CityCyber–physical systemInternet of ThingsUrban computingMulti agent systemsEdge computing 1. Introduction A Smart City is an urban environment made smart by using ICT technologies, so as to improve the quality of life of the inhabitants and the efficiency of the city infrastructures, and provide enhanced services to citizens [1]. A lot of applications are compliant with the smart city vision and comprehend structural health of buildings, waste management, air quality and noise monitoring, traffic congestion management, city energy consumption optimization, smart parking, smart lighting, automation and salubrity of public buildings, urban drainage systems, emergency detection and so forth [2], [3], [4], [5], [6], [7]. The realization of Smart City is a hot topic in the current research landscape [8], [9], and many city administrations are interested in solutions for enhancing their cities with smart services. The European Union is also supporting a big amount of projects on Smart Cities1 and several cities around the world are boosting politics to exploit smart technologies. Valuable examples in this direction are the cities of Amsterdam,2 San Francisco,3 Barcelona,4 and Copenhagen5 that are creating versatile ecosystems for comprehensive Smart Cities realization. Smart Cities development introduces several challenges, which are shared with the Internet of Things, Cyber–Physical Systems, and Smart Environments [10], [11], [12], [13]. Such challenges include issues like the integration of heterogeneous systems and technologies, scalability, fault tolerance, system maintenance [14], geographical and functional extensibility. In particular, geographical extensibility refers to the problem of the dynamic extension of existing Smart City services to areas not previously covered, or to new urban areas (e.g., related to the city growth), while functional extensibility refers to the problem of adding new services to the set of the existing ones. Despite the big interest around Smart Cities, the currently adopted solutions lack in design and development guidelines, approaches for the integration of heterogeneous services and infrastructures, as well as ICT solutions allowing a holistic Smart City development. Furthermore, even though urban environments are naturally distributed, most of the actual Smart City implementations relies on centralized approaches, where a big amount of data flow in a common data center that processes them and provides services to the citizens, or schedules actuations on physical infrastructures [8]. Finally, many realized services are developed as independent monolithic blocks, and the interaction among them is not considered.2 In this paper it is argued that benefits arise from the exploitation of the edge (fog) computing paradigm [15], [16], [17]. The edge computing paradigm has the aim to push the computation on acquired data away from the core of data centers to the outer edges of a network, close to the data sources. Side benefits of such computing paradigm include: (i) a faster reactivity to events which can be managed where they occur, (ii) a better exploitation of communication bandwidth, as data are locally processed and only the aggregated required information are propagated across the system, (iii) an increase of reliability and scalability, since the paradigm fosters the use of distributed algorithms. The contributions of the paper are manifold. Firstly, the iSapiens platform is proposed [18] as an agent-based [19], [20], [21] distributed platform for the management of a network of computing nodes spread over a city area. In iSapiens, the computation is executed both on the edge of the network, by the agents residing in each computational node, and in the Cloud for computation demanding tasks. The iSapiens platform is able to manage physical devices (i.e., sensors, actuators, or even complex objects) connected to its network nodes so as to hide their heterogeneity and specific communication protocols. As a second contribution, a set of design guidelines are provided which favors the realization of scalable and dynamically-extensible Smart City services. Moreover, the paper discusses about the advantages in using iSapiens, which provides important benefits such as extensibility, distributed computing, fault tolerance, heterogeneity management, and support for hardware/software maintenance. As a final contribution, the paper shows the realization of a Smart City prototype in the city of Cosenza (Italy), which provides decentralized urban intelligence services to citizens. The developed Smart City highlights how the proposed platform and guidelines can be applied for an effective Smart City prototyping. Geographical and functional extensibility issues are also taken into account within the case study. The rest of the paper is structured as follows: Section 2 discusses some related works in the context of Smart City; Section 3 describes the iSapiens platform and provides the methodological guidelines for the design of smart city services. Such Section also discusses about the benefits of the iSapiens platform coupled with the provided design guidelines; Section 4 shows the design and the realization of the Cosenza Smart Street. Finally, conclusions are drawn and the directions of ongoing work are portrayed. 2. Related work Cyber–Physical Systems and Smart Environments have been widely studied in literature so far [12], [22]. The most important goal of such systems is the improvement of the user experience in traditional environments under different points of view. In the context of urban environments, there is a growing number of Smart Cities whose final aim is to make an optimized use of the public resources, together with increasing the quality of the offered services still reducing the operational costs that the public administrations should sustain [8]. Such systems help citizens in a clever usage of their own cities. Smart Cities are usually considered as part of the so called Urban Internet of Things [23], which is the part of the Internet of Things that has been designed to support the Smart City realization and maintenance. Smart Cities and Smart City infrastructures have actually been already formalized [1], [24]. Anyway, real Smart City implementations are still not really comprehensive. The European Union is supporting a big amount of projects on the Smart Cities and several cities are encouraging politics to integrate smart technologies into the city to make it more eco-friendly and energy-efficient. Very good examples in this direction are the cities of Amsterdam, San Francisco, Barcelona, and Copenhagen that are creating ecosystems for the realization of comprehensive smart cities. Though the above presented cases are very positive examples, they all are represented by a plethora of applications that are not coordinated by a single platform which can allow the integration of the knowledge gathered from all the deployed sensors/systems. Several works in literature propose the integration of systems to produce whole smart cities. The paper in [25] presents the Oulu Smart City.6 Its first aim is to provide Oulu citizens with Wi-Fi connection and, through the tracking of the people in the city, to monitor pedestrian and vehicular flows. Even though the Oulu smart city presents a good design, it should be improved by the addition of services based on other sensing/actuation capabilities across the streets. In [26] authors have presented a framework for the implementation of information services to monitor public areas and infrastructures. In particular, they have shown a testbed on a subway scenario with the objective of (i) demonstrating that their system can flexibly help in the detection of anomalous events and (ii) simplifying communications in case of emergency. They realized a multi-technology architecture that collects data from various devices to infer high level knowledge (for emergency reason). The proposed framework is valuable, but practical examples are not satisfying and its re-use in different smart city scenarios has to be analyzed. In [9] authors integrate sensor nodes with the street lights around Cambridge to have powered nodes which sample multiple environmental sensors. They present a platform to reprogram and collect data through such sensor nodes. Anyway, authors do not talk about high level analysis of the gathered data. They only implement their case study for collection purposes. Several platforms for the realization of Smart Cities have been already implemented. Authors of [8] propose a general reference framework for the design of an urban IoT. It is based on a centralized architecture which exposes a set of web services. A real case study involving such framework has been implemented in Padova (Italy) where nodes have been deployed to monitor temperature, humidity, light, and benzene concentration in the air. Although this is a valuable example of both Smart City platform and case study, the proposed centralized architecture can present an extensibility problem for big cities. In [27] the SmartSantander project is presented, which is part of the Future Internet Research and Experimentation initiative of the European Commission. The project had the aim to implement a large scale network in the city of Santander to monitor environment pollution (air quality, noise levels and luminosity levels), outdoor parking, and automated irrigation systems. The architecture implemented presents three layers: IoT nodes, Gateways, and Server. Here the Server is the centralized data collector which offers services. Although the Smart City presents a very large case study, the centralized and not really structured architecture can provide some extensibility/maintenance problems. Moreover, here the data elaboration on the distributed nodes, with all the benefits that it can provide, is limited. The work in [28] introduces Sentilo, which is an open source IoT platform designed to manage sensors and actuators in the Smart Cities. Authors claim that Sentilo can be used for any city looking for openness and easy interoperability. Such platform uses Cloud Computing and Big Data tools to collect, store, and elaborate data from distributed sensors so providing Smart City extensibility. It has been sponsored by the Barcelona City Council and, after the deployment in Spain, its code has been released as open source. A drawback of such platform is the lack of computing on the edge of the platform to locally analyze the data from the city. Authors of [29] introduce an IoT middleware that has been implemented in the context of the EPIC (European Platform for Intelligent Cities) project. The proposed middleware has been designed to address in Smart Cities the issues regarding heterogeneity, interoperability, extensibility, and (re)configurability. Even though such middleware tackles important issues for Smart Cities, it does not consider (as many platforms in this area) the design of decentralized pre-processing components for computing and aggregating data on the edge. In [30], [31] a Smart City platform based on Big Data analysis to achieve extensibility is introduced. The proposed architecture provides three layers that have been implemented to (i) collect, analyze, and filter data; (ii) aggregate data to infer knowledge; (iii) provide users with an interface to gather elaborated data. Although very useful, such platform does not provide a low layer allowing the gathering of data from sensors distributed in a Smart City, so it needs to be built over another middleware that allows the sensors (actuators) management. Given the above analysis of the state of the art, it emerges the lack of a distributed platform and design guidelines for the comprehensive and systematic realization of reactive, fault tolerant, and extensible Smart City applications. To address such issues, this paper presents iSapiens as an agent-based platform providing useful features for designing and implementing distributed cyber–physical systems and smart environments. 3. iSapiens: a platform for Smart Cities iSapiens is an agent-based platform providing useful features for designing and implementing distributed cyber–physical systems [3], [32], [33] and smart environments [18], [34], [35], [36], [37] whose functionalities are realized by exploiting edge computing [15], internet of things [10], [38] and out-of-the-edge computing services. Such systems are characterized by the combined exploitation of software components with heterogeneous physical devices and protocols, so as to furnish final users with high level services and/or to enhance the behaviors of a specific environment. In the following subsections a description of the iSapiens platform is provided together with an introduction to the issues related to the design of smart city applications. 3.1. The iSapiens platform The iSapiens platform (see Fig. 1) relies on two main abstractions: Virtual Objects (VOs) and Agents. VOs are used to abstract and manage physical objects, hiding the heterogeneity of devices and protocols, and complying with the Internet of Things vision. Services and enhanced behaviors are obtained by exploiting software agents which execute in computational nodes close to the physical devices they have to control, thus implementing edge computation and enabling online analytics. To offer final services, agents can also exploit out-of-the-edge services, both developed for a specific application or third party provided. Such services can include offline analytics, such as predictive analysis, machine learning, and data mining or services requiring a centralized view of the whole system. From an architectural point of view, the platform is mainly composed by an in-network computing layer and a virtualization layer. The former contains the Agent Server that provides the runtime support for the agents execution. The latter consists of the Virtual Object Containers which allow the management of VOs. The agent server and the virtual object container together constitute an iSapiens server. An iSapiens server is allocated for execution on a dedicated computational node. The iSapiens platform allows the realization of distributed applications consisting of a set of interacting agents running on a set of computational nodes. Such nodes are scattered in the environment which has to be controlled or enhanced. All the computing nodes are supplied with a set of devices, such as sensors, actuators or other more complex (smart) objects. The virtual object container of a given node hosts all the VOs abstracting the devices directly connected to the node. The agents running in a node can exploit all the functionalities offered by the local VOs. Each component, either a device, a VO, an agent, or a whole computing node can be dynamically removed from, added into or updated to a running system. This important feature fosters application scalability and extendibility. All together, the iSapiens servers, that are hosted in the computing nodes deployed in the network, constitute the distributed iSapiens middleware. The current implementation of iSapiens relies on the Java technology. iSapiens also allows the exploitation of an off-network computing layer that offers Cloud/Internet computing services which are required for the implementation of resource-demanding tasks (both in terms of computation and memory), and for the implementation of those tasks requiring a comprehensive view of the deployed system. Such layer comprehends three different kind of services: third-party provided services, custom developed services and agent-based services developed by using iSapiens agents. The third-party services and the custom services are not tied to the use of any specific technology. In the following, we further describe the main features of VOs and agents, and how they are deployed on computational nodes hosting iSapiens servers. Download : Download high-res image (362KB) Download : Download full-size image Fig. 1. iSapiens platform layers. 3.1.1. Virtual object features VOs are the key elements to provide the developers with an effective tool for managing devices heterogeneity and fostering hardware maintenance. In fact, VOs provide to agents a transparent access to the physical part due to a well-established and common interface exposed as API. A VO allows agents to directly connect to a device without taking care about proprietary drivers or addressing fine-grained technological issues. The goal is to decouple, from a sensing/actuation point of view, functionalities from the equipment offering them. A change in the physical devices (e.g., for maintenance) and in the adopted communication protocols will affect virtual objects only. The VOs are managed by the Virtual Object Container, which permits the dynamic deployment of new VOs, and exposes them to the agent layer. The VOs support both asynchronous and synchronous data reading. The asynchronous method relies on an implementation of the publish/subscribe pattern. Essentially, a VO exposes an abstract representation (i.e., machine readable-description) of the features and capabilities of physical objects spread in the environment. Features of the physical devices are exported into the iSapiens platform as virtual object functionalities related to both the sensing and actuation activities. For instance, the VO associated to a smart door will expose the isOpened functionality, through which an agent can check the current status of the door, and the lock functionality for locking the door if needed. 3.1.2. Agent services and features An Agent [21] is an autonomous entity which runs in an Agent Server and executes its own behavior interacting with other (local or remote) agents. An agent is able to exploit all the functionalities exposed by the VOs hosted in the same iSapiens server where the agent executes. An Agent Server provides services for the support of the agent life cycle and allows dynamic creation of agents at runtime. Communication among agents relies on the exchange of asynchronous messages. Messages can be timed or untimed. Timed messages are augmented with a time information specifying the absolute time in which the message has to be actually delivered to the recipient agent. The iSapiens platform provides acquaintance message s which are used for establishing direct acquaintance relationship among agents. An acquaintance message carries information about the identity and the role of a given agent. Such messages can be used to dynamically (re)configure the agents relations after faults or when new agents are introduced/removed into/from the system, e.g., due to maintenance and extensions. A distributed yellow pages service is also provided to dynamically discover agents in order to establish acquaintance relationships. An agent can register itself to the yellow pages by providing a set of roles and a set of properties (i.e., a set of couples). A registered agent can be discovered by other interested agents by querying the yellow pages. 3.1.3. Application deployment Given a running set of iSapiens servers, the deployment of an application is carried out by using a Deployer entity. Such entity can dynamically create new agents and VO on a target server. Moreover, it can establish acquaintance relationships among agents and/or send application-dependent configuration messages. The Deployer is an external process executing outside the iSapiens servers network. It can operate also on a running agent-based application in order, e.g., to introduce new functionalities in the system. 3.2. Exploiting the iSapiens platform: design guidelines This section describes a set of design guidelines aiming at supporting the development of applications by using the iSapiens platform. An important goal is to promote both the separation of concerns and the modularity. The proposed guidelines mainly rely on the exploitation of abstraction layers, and specific agent roles as depicted in Fig. 2. In each layer it is possible to focus on specific issues having a different level of abstraction. The layer-based approach is usable both in a top-down and bottom-up software development schema. A top-down approach is suggested when an application is developed from scratch, while a bottom-up approach is typically used when an application is built on top of some pre-existing components. A description of the introduced abstraction layers is reported below. Download : Download high-res image (288KB) Download : Download full-size image Fig. 2. Design guidelines: abstraction layers vs. agent roles. Raw Data layer : it manages raw data directly related to physical quantities (e.g., distances, noise, temperature) both for sensing and actuation purposes. The managed data are not processed. Information layer : data coming from the previous layer can be filtered, structured and aggregated. This layer aims at organizing data in order to derive further information about the controlled system, or to produce synthetic data allowing a more convenient way to reason about the system. Knowledge layer : actuations to be performed, and/or environmental stimuli, are mapped onto more abstract concepts. The goal is to allow reasoning by using abstract concepts which are directly related to the specific domain (or context) of the application being developed. For instance, it is possible to introduce the concept of climatic health which depends on the value of the temperature and humidity actually existing in a given environment. Similarly, the concept of office security can be introduced in order to control a door office and make it alarmed after a certain hour. Wisdom layer : it permits to operate and reason at the highest abstraction level. Here, we have an holistic vision of all the concepts which are related to the developed application, and which govern the implemented system. The concepts previously introduced (or a subset of them) are orchestrated in order to pursue application goals. Gathered information and concepts can be complemented in order to augment system knowledge and to exploit such knowledge in order to operate upon the controlled system. For instance, if an application for managing safety at home is considered, information indicating that a person is found lying in the bathroom can be complemented in order to infer the concept afflicted by a malaise which can cause the concept of providing first aids to take place. Each layer is populated by agents having different roles. A role defines the responsibilities [39] an agent has in the system. The ellipses drawn in Fig. 2 associate the agent roles with the abstraction layers they are related to. Five agent roles were identified, and their description is provided in the following. Mirror agents : they are boundary entities turning VO functionalities into location-independent functionalities offered by agents, and must be co-located on the computational node hosting the VOs they have to interact. They do not introduce/modify new/existing VO functionalities thence they belong to the Raw data layer. Mirror agents mediate the use of the wrapped functionalities by enforcing, for instance, negotiation procedures and/or access policies useful for guaranteeing an exclusive use, or a time-based use, of the wrapped device. Boundary agents : they mediate the interactions between iSapiens agents and external service providers so as favoring system integration among iSapiens and third-party platforms. For instance, agents providing a weather-forecast functionality by using Internet-based services will have the Boundary role. Since external services can operate at different abstraction levels, boundary agents can belong to layers ranging from Raw data to Knowledge. Infrastructural agents : they offer general-purpose functionalities which are not tied to a specific application. For instance, these agents provide services managing information persistence (e.g., data storage in a DBMS) or services for the broadcast notification of events-of-interest. Infrastructural agents can belong to the abstraction levels ranging from Information to Knowledge. Operational agents : they offer functionalities tied to a specific application. Such functionalities can be achieved by composing and/or orchestrating functionalities offered by other agents. Operational agents can belong to the abstraction levels ranging from Information to Knowledge. In order to favor extensibility (both functional and geographical), fault tolerance and maintenance of the applications to develop, it is suggested the use of peer-to-peer/decentralized and bio-inspired algorithms, which are naturally fostered by the edge computing and agent paradigm. Service agents : they offer the final services exposed to the users according to the application goals. Such agents belong to the abstraction levels ranging from Knowledge to Wisdom. Usually, offered services are obtained by composition/coordination of the agents having other roles. 3.3. iSapiens for Smart City: features and benefits The features of the iSapiens platform (Section 3.1), paired with the set of guidelines previously introduced (Section 3.2), produce some useful side-benefits, explotable for the realization of smart city applications, which are highlighted in the following. System maintenance is favored as VOs, agent roles, and abstraction layers introduce modularity and separation of concerns in the developed application. When a modification of a software function is needed, only the specific components dealing with such functionality are required to be selectively updated. VOs permits an easy hardware replacement as they maintain the same interface independently of the managed device. The supported dynamic deployment mechanism facilitates the actualization of the maintenance operations on the system. With respect to a node crash, fault tolerance is primarily fostered by the proper combination of the edge computing paradigm and use of P2P or Decentralized algorithms suggested for the implementation of the main operations of the system. Thus, a crash of a node does not impair the whole system execution. Heterogeneity and integration issues, either at device and system level, are tackled by the exploitation of VOs and Boundary Agents, as described in the previous sections. Functional extensibility is supported as it is possible to (i) composing pre-existing functionalities, (ii) exploiting in different ways the existing devices, and (iii) adding new devices for providing new services. This benefit arises as the platform permits to dynamically add/remove agents and VOs to/from the system. The geographical extensibility is achieved as the platform supports the dynamical addition of both computational nodes and related sensor/actuator devices on new areas of interest which have to be covered. As the newly added computational node is running, together with VOs, the new agents deployed on the node can join the rest of the community by exploiting the Yellow Pages service and the acquaintance messages. The exploitation of the edge computing paradigm makes the network of iSapiens nodes a distributed computational platform which is capable of furnishing a pervasive computational power which is exploitable for the realization of complex distributed smart-city services. More in particular, the edge computing supports online analytics, which consists in a continuous elaboration on the stream of data coming from sources. All of this promotes reactivity and efficiency in terms of bandwidth consumption. When the computation is resource demanding or it cannot be realized solely on the edge, an offline analysis can be carried out by exploiting the cloud computing. Table 1 provides a comprehensive view of the main features and benefits tied to the use of the iSapiens platform. Table 1. The iSapiens platform: Benefits vs features. 4. Design and implementation of the Smart Street Cosenza This section describes the design and implementation of a real case study which is realized by using the iSapiens platform. Such case study is the Smart Street that has been developed in the town of Cosenza (Italy). The purpose of the implemented smart street is to offer a set of services aiming at improving the quality-of-life of the citizens and favoring the interactions between the citizens themselves and the offered services. The realized Smart Street Cosenza (SSC), furthermore, offers an infrastructure which is scalable and extensible both to the whole town and with new functionalities. In the following, the location of the SSC is presented, along with a detailed description of the offered services, the architecture of the realized infrastructure (hardware/software), its evolution, and the Smart Street itself at work. 4.1. Location and functionalities of the Smart Street The Smart Street has been developed in Cosenza, which is a town of Calabria, Southern Italy. The town per se has a population of around 70,000, while its urban area counts over 268,000 inhabitants. SSC extends for about 2.5 km, and covers the following adjacent target areas (see Fig. 3): Corso Mazzini, the main business street of the town; a bus station, located in Via Delle Medaglie D’Oro; the square named Piazza Bilotti; the area around a mall, located in Piazza Giacomo Mancini; part of one of the main road of Cosenza, named Viale Giacomo Mancini. Corso Mazzini is a pedestrian street which hosts a set of shops, restaurants, cafés, banks, other commercial activities and an open air museum. The bus station is the main node of the town public transportation system and is mainly frequented in the working hours. Piazza Bilotti is currently under construction and will host a parking area. The area around the mall in Piazza Giacomo Mancini is highly frequented, and, together with the adjacent Viale Giacomo Mancini, is car accessible and is an high-traffic area. The mall itself hosts an underground parking area. Download : Download high-res image (442KB) Download : Download full-size image Fig. 3. The Smart Street target areas: (A) Bus Station, (B) Piazza Bilotti, (C) Corso Mazzini, (D) Viale Giacomo Mancini, (E) Piazza Giacomo Mancini. Due to the nature of the chosen locations, which are highly frequented by pedestrians, a set of services for making aware the citizens and the administrators about the status of the areas, in terms of pollutant gases, noise and climatic comfort are given. These kinds of services can be useful to the administrators for taking countermeasures so as to mitigate potential health risks and laws infringements,7 and to the citizens, which can use them to avoid unsafe situations, e.g., an elder person subject to heart related illness can avoid areas with a prohibitive climatic status. As the SSC is extensible by design (see Section 3.2), other services can be straightforward added. For instance, services for parking support in the areas around the mall and the bus station, efficient management of street lights, traffic control system, automation for green area management, public transportation information can be implemented. Moreover, all these services, once developed for a prototypal Smart Street using the iSapiens platform, can be easily deployed on other areas of the town. In addition, all the implemented services can be integrated, improved, or replaced. 4.2. Smart Street Cosenza design As stated in the previous section, the set of services designed to be part of SSC concerns climate, noise and pollution assessment so as to make aware of such environmental condition both citizens and town administrators. Environmental assessment requires the deployment of sensors which measure environmental, climate and pollutant quantities as indicated in Table 2. To achieve the stated goal, a set of Smart Street functionalities has been identified and a set of agents has been designed (see Table 3) to provide such functionalities. The designed agents are grouped according to the roles described in Section 3.2. Table 2. Main sensors used for the Smart Street Cosenza divided by category. Category Sensor type Climate Temperature, Atmospheric Pressure, Humidity Pollution CO, , , Concentration Other Noise, Luminosity A set of agents having the Mirror role is devoted to abstract the physical sensors so as to mirror the VOs as agents. A specific Mirror agent is designed for each kind of sensor identified in Table 2. The raw data exposed by the Mirror agents are sent to the group of the Measure Aggregation agents, having the Operational role. The Measure Aggregation agents make computation on the data coming from the Mirror agents and provide value-added data aggregation. There exists a specific instance of a Measure Aggregation agent for each Mirror agent. Given a specific sensor type (e.g., temperature, humidity), a Measure Aggregation agent provides all the capabilities of its associated Mirror agent plus the global average and the global standard deviation of the specific sensor type computed in real-time on the whole network. The two operations are computed by exploiting the gossip-based aggregation algorithm proposed in [40]. Table 3. Agents implementing the Smart Street Cosenza. Agent Role Agent Classes Empty Cell Mirror SensorTemperature, SensorPressure, SensorHumidity, SensorLuminosity, SensorNoise, SensorCO, SensorCO2, SensorNO2, SensorO3 Infrastructural Persistence, Notification Operational Measure Aggregation Service Environmental Wellness, Climatic Wellness, Anomaly Detection More in particular, the subset of Measure Aggregation agents, which are tied to the same sensor type, cooperates in the global average/standard deviation computation. When the gossip-based algorithm ends, all the cooperating agents become aware of the global computed result. In order to compute the average, each agent maintains its current measured value and its local average (initially set to the measured value). The algorithm consists in the continuous exchange of local averages among neighbor agents (i.e., the agents located in the same computing node or the node’s neighborhood). Each time an agent receives the average from one of its neighbors, it updates its local average (just applying the average operator). Value exchanges and local computations are continuously done for an enough number of step s set so as to ensure that each local average, computed by every involved agent, converges to the actual global average (the algorithm convergence is proved in [40]). Given the global mean, the global standard deviation is computed similarly, by evaluating the average of the squared deviation from the mean of the local measures. This gossip-based strategy has been chosen as it is fully scalable, decentralized, and fault tolerant. Besides the Mirror and the Operational agents, two kinds of Service agent, namely the Wellness and the Anomaly Detection agents, have been designed and developed. Each of them furnishes a specific service so as to meet the stated goals of the SSC and exploits the functionalities offered by the Mirror and the Operational agents. In particular, the Wellness agents provide high level information about the pollution and climatic status of the SSC in different areas. Climatic wellness is provided as comfort levels, computed through the exploitation of the Summer Simmer Index8 and the Humidex9 index, both involving temperature and humidity measurements. The categories of the found comfort level in a specific area range from “no discomfort” to “dangerous”. Environmental pollution wellness relies on the gases concentration sensors (see Table 2), and exploits the Air Quality Index.10 In this case, the categories range from “good” to “hazardous”. The Anomaly Detection agents are devoted instead to detect possible anomalies related to the environmental condition. There exists one Anomaly Detection agent for each noise sensor (i.e., related Mirror Agent) on the SSC. Two kinds of anomalies, namely area anomalies and historic anomalies, can be detected by the Anomaly Detection agents. At first, an Anomaly Detection agent notifies the occurrence of an area anomaly by exploiting the global average and standard deviation computed by the set of Measure Aggregation agents. The average and the standard deviation are exploited to fully characterize a Gamma Probabilistic Distribution, and an anomaly is detected when the value of the specific sensor associated to the Anomaly Detection agent is higher than the 99th percentile of the characterized Gamma function. In this case, the global average information combined with the local measures are exploited to discover if some areas of the SSC behave differently with respect to the whole. Secondly, each Anomaly Detection agent can detect historic anomalies as follows. A day is divided into 144 time slots, each of them corresponding to a 10 min time interval. For each time slot, the Anomaly Detection agent maintains a couple computed on all the sensor values so far read in the same time slot. When a new sensor value is read, it is compared with the 99th percentile of the Gamma distribution characterized by the couple of the corresponding time slot, and, if it is greater than such threshold, an event of interest is generated and notified. After that, the related couple is incrementally updated computing the exponential weighted moving average and variance (EWMA) according to [41]. The Infrastructural agents are devoted to provide functionalities that are potentially useful for all the agents above described. In particular, a set of off-network services are provided by a purposely-developed service provider, named Smart Street Server. The Smart Street Server is hosted in a data center located outside the edge computing node network (i.e., the nodes hosting the sensors). The server receives data from in-network agents (i.e., Infrastructural agents), and manages the persistence by using a local DBMS. The stored data are made available to the final users through a web application. Two kinds of Infrastructure agents have been designed, namely the Persistence and Notification agents. Both the kinds of agents forward the information they receive to the application server for storage on the DBMS. The data forwarded by the Notification agents are immediately made available for visualization to the connected clients. A comprehensive architectural view of the system is shown in Fig. 4. The figure highlights the interactions among agents, VOs, and the Smart Street Server. Communications among entities are graphically represented by thin links. The agents are grouped by type for the sake of readability, and the communications among the Measure Aggregation agents based on gossiping are highlighted through the tag. Download : Download high-res image (559KB) Download : Download full-size image Fig. 4. Architectural view of the Smart Street Cosenza. 4.3. Operational steps for system deployment Fig. 4 highlights also how the components are dislocated on the computational nodes and the interactions occurring among them. The steps involved in the life of a generic component of the SSC, either hardware or software, are depicted in Fig. 5. Such steps are numbered from S1 to S4 and, for each of them, are also reported the iSapiens features used for their realization. Every component enters into the system through a deployment step (S1), and then it is initialized and becomes ready to work (S2). After that, the connections among interacting agents are established (S3) and, in the case of the gossip-based agents, a renewal of the acquaintance relationships (S4) is continuously carried out. In the initialization step, there is no specific iSapiens feature to exploit, but each component requires to be initialized through a specific configuration procedure. More in particular, the deployment of the agents and VOs over each computational node is obtained through the use of the dynamic deploying mechanism offered by the platform. The acquaintance relationships among the agents are established instead by using the Yellow Pages service and the acquaintance messages. With reference to Fig. 4, all the communication links among agents, that are not labeled with the tag, are established by sending proper acquaintance messages to the communicating agents. As an example, after the deployment and initialization of a new Wellness agent, a set of acquaintance messages are sent to it providing the knowledge of the Persistence agent, the Notification agent, and the relevant Measure Aggregation agents that the Wellness agent needs to know in order to behave properly. Instead, after the initialization of an agent involved in a gossip-based communication, the agent registers itself in the Yellow Pages and uses it to choose its neighborhood according to the gossip-based protocol. The neighborhood is renewed with a prefixed frequency (chosen during configuration) in step S4. This allows to implicitly handle the case in which Measure Aggregation agents dynamically enter or leave the system, as after a node crash or a new node joins the system. Each communication link without agents as endpoints is established during the component initialization as configuration info. From Fig. 4 emerges also that, by design, all the computing nodes are functionally equivalent, in the sense that there is no centralized functionality (with, obviously, the exception of the Smart Street Server). This last feature, together with the use of the gossip-based protocol, the acquaintance renewal policy and the dynamic deployment capability, makes the system able to meet fault-tolerance, scalability and extendibility requirements. Download : Download high-res image (234KB) Download : Download full-size image Fig. 5. Operational steps for components installation and execution. 4.4. Smart Street Cosenza implementation The realization of the SSC as it is today, has been done in an incremental way, both from a geographical and functional points of view, as successive incremental stages. The four incremental stages are described in Table 4, where, for each stage, the newly installed components, along with the interested city areas (as in Fig. 3) and a description of the performed actions (as in Fig. 5) is portrayed. In the table, the deployment of the Smart Street Server is not highlighted as it has been deployed and configured once, before the first stage. The SSC as it is in its current version, is constituted by a network of 15 computational nodes, interconnected through a dedicated Wi-Fi mesh network (IEEE 802.11n), directly deployed on the targeted areas (see Fig. 6, Fig. 6(a)). Each computational node is constituted by a low cost Raspberry Pi 2 model B board,11 embedding a 900MHz quad-core ARM Cortex-A7 CPU and 1GB of RAM, and mounting an USB Wi-Fi dongle for networking purposes. Each Raspberry Pi is properly enveloped in an IP64 weather resistant case and main powered, using the power infrastructure of the town. From a software perspective, each computational node runs Raspbian, a Linux distribution developed for Raspberry Pi and based on Debian 7.0, the Oracle Java Runtime Environment version 8, and the iSapiens middleware. Table 4. Deployment stages descriptions of the Smart Street Cosenza. Deployment stage Installed components Involved areas Stage description and correlation with the operational steps #1 Climatic Monitor on an initial area - iSapiens nodes;- sensor nodes for climatic monitoring;- VOs for the deployed sensor nodes;- related Mirror, Notification and Persistence agents;- related Aggregation agents. - Piazza Giacomo Mancini- Viale Giacomo Mancini The iSapiens nodes were installed (S1) and configured (S2) on the covered area. The sensor nodes were installed (S1) and the related VOs were deployed (S1, S2) on the iSapiens nodes. Finally, the agents for climatic monitoring were deployed (S1) and configured (S2). Direct knowledge between agents is achieved by using acquaintances (S3). The Aggregation agents started to exploit the neighbor renewal policy (S4). #2 Area coverage extension - iSapiens nodes;- sensor nodes for climatic monitoring;- VOs for the newly deployed sensor nodes;- related Mirror, Notification and Persistence agents;- related Aggregation agents. - Corso Mazzini- Piazza Bilotti- Bus Station The iSapiens computational nodes were installed (S1) and configured (S2) on the new areas. The sensor nodes were installed (S1, S2) and the related VOs were deployed (S1, S2) on the newly iSapiens nodes, without affecting the already operating infrastructure. The agents for climatic monitor were deployed (S1) and configured (S2), acquaintances were given as in the previous step (S3). The gossip based renewal policy took into account the newly added Aggregation Agents (S4). #3 Environmental pollution monitoring addition - sensor nodes for environmental pollution monitoring;- VOs for the newly deployed sensor nodes;- related Mirror, Notification and Persistence agents;- related Aggregation agents. - Viale Giacomo Mancini- Corso Giacomo Mancini- Corso Mazzini- Piazza Bilotti- Bus Station New sensor nodes for environmental pollutant monitoring were installed on all the areas (S1, S2). The related VOs were deployed on the related iSapiens nodes (S1, S2), without affecting the already operating infrastructure. The agents for pollution monitoring were deployed (S1) and configured (S2) on the affected iSapiens nodes, acquaintances were given as in stage #1 (S3), neighbor renewal behavior started for the added Aggregation agents (S4). #4 Anomaly Detection and Climatic Wellness management. - Agents for climatic wellness and anomaly detection. - Piazza Giacomo Mancini - Viale Giacomo Mancini- Corso Mazzini- Piazza Bilotti- Bus Station The agents for realizing the climatic wellness management and anomaly detection were deployed (S1) and configured (S2), acquaintances were established among both the previously-available and the newly-added agents (S3). All of this without affecting the already running infrastructure. With respect to the climatic and pollution comfort services, two sets of sensor nodes are deployed on the involved streets. The first one (type A) is composed by nodes hosting sensors for measuring temperature, humidity, luminosity and noise level. The second one (type B) is composed by nodes hosting sensors for measuring atmospheric pressure and the concentration of pollutant gases such as carbon dioxide ( ), carbon monoxide (CO), nitrogen dioxide ( ) and ozone ( ). Each sensor node is managed by its nearest computational node, and linked with it through the same Wi-Fi network. All the sensor nodes are powered by batteries, which are recharged “on site” by using solar panels. Solar panels have been used so as to have no need to modify the electric delivery infrastructure of the town for the deployment of the sensor nodes. The nodes are Libelium Waspmote Plug&sense,12 which are sensor nodes compatible with the Arduino platform, enclosed in an IP64 box. The air pollutant sensors are protected by a shield, which mitigates the effects of wind and direct sunlight exposition on the precision of the measurements. About 70 sensor nodes have been already deployed on the Smart Street areas, as in Fig. 6b. Fig. 7 shows a set of them deployed on street lights and walls. The maps in Fig. 6(a), Fig. 6(b) show, respectively, the position of the deployed computational and sensor nodes, which are denser in the areas where people activities is mainly carried out. Each computational node controls a portion of the SSC. The Smart Street Server runs on a Linux based server, located at the ICAR-CNR institute, Rende, Italy. The same server hosts a JBoss application server, which runs the Smart Street web application, and an instance of the MySQL DBMS, which is used for storage purposes. The web application can provide information about both the current and historical statuses of the SSC. Two screenshots of the web interface are shown in Fig. 8, which depicts the map view, showing the global status of the smart street in a given time, and the chart view, showing an historical chart of the measures of a given sensor in a given time interval. The SSC is running since early 2016. Download : Download high-res image (289KB) Download : Download full-size image Fig. 6(a). Download : Download high-res image (302KB) Download : Download full-size image Fig. 6(b). Fig. 6. Smart Street Cosenza. (a) Computational Nodes; (b) Sensors nodes. Green locations host one type A node and one type B node, blue locations hosts only a type A node. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.) Download : Download high-res image (210KB) Download : Download full-size image Fig. 7(a). Download : Download high-res image (232KB) Download : Download full-size image Fig. 7(b). Download : Download high-res image (203KB) Download : Download full-size image Fig. 7(c). Fig. 7. Deployed sensor nodes on the Smart Street Cosenza. Download : Download high-res image (239KB) Download : Download full-size image Fig. 8(a). Download : Download high-res image (192KB) Download : Download full-size image Fig. 8(b). Fig. 8. Two views of the web interface showing (a) the noise map of the Smart Street in a given moment and (b) the historical graph of the measures of a relative humidity sensor. 4.5. Smart Street Cosenza: Wellness and anomaly detection In this section, a set of charts related to the behavior of the Wellness agents and the Anomaly Detection agents are provided, so as to prove the usefulness of the deployed SSC. Fig. 9, Fig. 9(a), Fig. 9(b) show the values, respectively, of the Humidex and the Simmer Summer Index as computed by the Climatic Wellness agent tied to the Sensor Node 040, located at the beginning of Corso Mazzini, on July, 7th 2016. It was a summer day, where, as shown in the charts, the comfort levels provided by both the indexes result to be very low in the afternoon, so the population in that time could be informed accordingly of avoiding the area. In fact, the Climatic Wellness agent notified (through the Notification agent) the Smart Street Server of the detected dangerous situation. In Fig. 10, Fig. 10(a) are shown: (i) the global noise averages (averages on all the gathered noise sensor values at a given timestamp) computed in real-time by the Measure Aggregation agents, (ii) the 99th percentile of the Gamma function (characterized by the average and the standard deviation computed by the same Measure Aggregation agents), the max sensed noise value for each timestamp, and the area anomaly alerts generated by the Anomaly Detection agents as explained in Section 4.2. All the trend lines are related to the first week of June, 2016. Since the high values sensed, particular interest is given by the area anomalies detected in the evening of June, 3rd where the alerts have been generated by the Anomaly Detection agent related to the noise sensor at the node 013, located at the center of Corso Mazzini. The same agent has also detected, in the same evening, a set of historic anomalies (see Fig. 10b). In this situation, the agent has notified the Smart Street Server with two different alerts, highlighting a situation of high-interest which has to be checked by the SSC administrators. As truth assessment, we verified that, in the evening of June, 3rd in the place near the sensor node 013 an election rally was taken. Download : Download high-res image (142KB) Download : Download full-size image Fig. 9(a). Download : Download high-res image (156KB) Download : Download full-size image Fig. 9(b). Fig. 9. Smart Street Cosenza: Humidex (a) and SSI (b) trend chart of the sensor Node 040 on the July, 7th 2016. Download : Download high-res image (367KB) Download : Download full-size image Fig. 10(a). Download : Download high-res image (232KB) Download : Download full-size image Fig. 10(b). Fig. 10. Excerpt of data gathered from the Smart Street Cosenza: (a) Global Average Noise (dB) trend and area anomaly detections on the June, 1–7th 2016; (b) Noise (dB) trend and historic anomaly detections of the Sensor013 on the June, 3rd 2016. 5. Conclusions and future work In this paper we proposed the iSapiens edge-based platform as an effective IoT tool for the implementation of distributed Smart City applications. Edge computing is implemented by using the agent metaphor natively supported by iSapiens. The platform is able to hide the heterogeneity of the involved physical devices and protocols. A set of design guidelines were also proposed. Such guidelines support an effective exploitation of the offered iSapiens features and allow to reach useful benefits in developing Smart City services such as system extensibility, fault tolerance, integration of systems, and system maintenance. The resultant approach, based on the exploitation of both the iSapiens platform and the proposed design guidelines, was validated by the design and the implementation of a real case study, namely the Smart Street Cosenza (SSC). The SSC, deployed in the town of Cosenza (Italy), has the goal of providing decentralized urban intelligence services to citizens. In particular, the working system is able to furnish services which are related to climatic and environmental wellness, and to the detection of anomalies that may occur in the covered city area. The incremental evolution of SSC was discussed, showing, in particular, how the functional and geographical extensibility were effectively supported. Finally, an excerpt of the collected data and an example of the data analysis carried out by the deployed agents were shown. Future work is geared at: extending the SSC by covering new urban areas and by adding new services. More in particular, as an example of in-network services, a service for urban drainage network optimization is currently under development [3], [42] and a traffic control system is planned to be designed. Other services under development regard the use of data stream mining algorithms for real-time analysis, previsioning and mining on the SSC data; including in iSapiens a library of ready-to-use, general-purpose Infrastructural and Operational agents which, relying on bio-inspired and peer-to-peer algorithms, simplify the implementation of custom applications; integrating iSapiens with the Social Internet of Things platform [43], [44], [45], in order to provide social capabilities to objects and smart devices exploitable in smart city applications; using the proposed approach for developing other smart cyber–physical systems, such as Smart Homes, Smart Offices, and Smart Factories. Acknowledgments The authors are grateful to Antonio Francesco Gentile, Luigi Porto, and Davide Macrí for their valuable contributions to the development and deployment of the presented use case. The authors are also grateful to the administrators of the town of Cosenza for their support in the realization of the Smart Street. This work has been partially supported by RES-NOVAE - “Buildings, roads, networks, new virtuous targets for the Environment and Energy” project, funded by the Italian Government (PON 04a2_E) and by “Smart platform for monitoring and management of in-home security and safety of people and structures” project that is part of the DOMUS District, funded by the Italian Government (PON03PE_00050_1). References [1] Kunzmann K.R. Smart Cities: A New Paradigm of Urban Development Crios (1) (2014), pp. 9-20, 10.7373/77140 Google Scholar [2] Stolfi D.H., Alba E. Red swarm: Reducing travel times in smart cities by using bio-inspired algorithms Appl. Soft Comput., 24 (2014), pp. 181-195, 10.1016/j.asoc.2014.07.014 View PDFView articleView in ScopusGoogle Scholar [3] Giordano A., Spezzano G., Vinci A., Garofalo G., Piro P. A cyber-physical system for distributed real-time control of urban drainage networks in smart cities Internet and Distributed Computing Systems - 7th International Conference, IDCS 2014, Calabria, Italy, September 22–24, 2014, Proceedings (2014), pp. 87-98, 10.1007/978-3-319-11692-1_8 View in ScopusGoogle Scholar [4] Ceriotti M., Mottola L., Picco G.P., Murphy A.L., Guna S., Corra M., Pozzi M., Zonta D., Zanon P. Monitoring heritage buildings with wireless sensor networks: The torre aquila deployment Proceedings of the 2009 International Conference on Information Processing in Sensor Networks, IPSN ’09, 978-1-4244-5108-1, IEEE Computer Society, Washington, DC, USA (2009), pp. 277-288 View in ScopusGoogle Scholar [5] Asimakopoulou E., Bessis N. Buildings and crowds: Forming smart cities for more effective disaster management Innovative Mobile and Internet Services in Ubiquitous Computing, IMIS, 2011 Fifth International Conference on (2011), pp. 229-234, 10.1109/IMIS.2011.129 View in ScopusGoogle Scholar [6] Fortino G., Guerrieri A., O’Hare G.M.P., Ruzzelli A. A flexible building management framework based on wireless sensor and actuator networks J. Netw. Comput. Appl., 35 (2012), pp. 1934-1952, 10.1016/j.jnca.2012.07.016 View PDFView articleView in ScopusGoogle Scholar [7] Cesario E., Comito C., Talia D. Towards a Cloud-Based Framework for Urban Computing, The Trajectory Analysis Case 2013 International Conference on Cloud and Green Computing (2013), pp. 16-23, 10.1109/CGC.2013.11 View in ScopusGoogle Scholar [8] Zanella A., Bui N., Castellani A., Vangelista L., Zorzi M. Internet of Things for Smart Cities IEEE Internet of Things J., 1 (1) (2014), pp. 22-32, 10.1109/JIOT.2014.2306328 Google Scholar [9] Murty R.N., Mainland G., Rose I., Chowdhury A.R., Gosain A., Bers J., Welsh M. CitySense: An urban-scale wireless sensor network and testbed Technologies for Homeland Security, 2008 IEEE Conference on (2008), pp. 583-588, 10.1109/THS.2008.4534518 View in ScopusGoogle Scholar [10] Atzori L., Iera A., Morabito G. The internet of things: A survey Comput. Netw., 54 (15) (2010), pp. 2787-2805 View PDFView articleView in ScopusGoogle Scholar [11] Fortino G., Guerrieri A., Russo W. Agent-oriented smart objects development Computer Supported Cooperative Work in Design, CSCWD, 2012 IEEE 16th International Conference on (2012), pp. 907-912, 10.1109/CSCWD.2012.6221929 View in ScopusGoogle Scholar [12] Fortino G., Guerrieri A., Russo W., Savaglio C. Internet of things based on smart objects: Technology, middleware and applications Fortino G., Trunfio P. (Eds.), 978-3-319-00491-4, Springer International Publishing, Cham (2014), pp. 1-27, 10.1007/978-3-319-00491-4_1 View in ScopusGoogle Scholar [13] Cicirelli F., Fortino G., Guerrieri A., Spezzano G., Vinci A. Metamodeling of Smart Environments: from Design to Implementation, Advanced Engineering Informatics, ADVEI, Special Issue on Collaborative Systems (2017), 10.1016/j.aei.2016.11.005 Google Scholar [14] International standard - iso/iec 14764 ieee std 14764-2006 software engineering 2013; software life cycle processes 2013; maintenance ISO/IEC 14764:2006 (E) IEEE Std 14764-2006 Revision of IEEE Std 1219-1998 (2006), pp. 1-46, 10.1109/IEEESTD.2006.235774 [15] Garcia Lopez P., Montresor A., Epema D., Datta A., Higashino T., Iamnitchi A., Barcellos M., Felber P., Riviere E. Edge-centric computing: vision and challenges SIGCOMM Comput. Commun. Rev., 45 (5) (2015), pp. 37-42, 10.1145/2831347.2831354 Google Scholar [16] Bonomi F., Milito R., Zhu J., Addepalli S. Fog computing and its role in the internet of things Proceedings of the First Edition of the MCC Workshop on Mobile Cloud Computing, ACM (2012), pp. 13-16 CrossRefGoogle Scholar [17] Yannuzzi M., van Lingen F., Jain A., Parellada O.L., Flores M.M., Carrera D., Prez J.L., Montero D., Chacin P., Corsaro A., Olive A. A new era for cities with fog computing IEEE Internet Comput., 21 (2) (2017), pp. 54-67 View in ScopusGoogle Scholar [18] Cicirelli F., Fortino G., Guerrieri A., Spezzano G., Vinci A. Edge enabled development of Smart Cyber-Physical Environments Proceedings of the 2016 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2016 (2016) Google Scholar [19] Jennings N.R. On agent-based software engineering Artif. Intell., 117 (2) (2000), pp. 277-296, 10.1016/S0004-3702(99)00107-1 View PDFView articleView in ScopusGoogle Scholar [20] Cicirelli F., Nigro L. Control centric framework for model continuity in time-dependent multi-agent systems Concurrency Comput. Pract. Exp., 28 (12) (2016), pp. 3333-3356, 10.1002/cpe.3802 View in ScopusGoogle Scholar [21] Wooldridge M. An Introduction to Multiagent Systems John Wiley & Sons (2009) Google Scholar [22] Cook D.J., Das S.K. How smart are our environments? An updated look at the state of the art Pervasive Mob. Comput., 3 (2) (2007), pp. 53-73, 10.1016/j.pmcj.2006.12.001 View PDFView articleView in ScopusGoogle Scholar [23] Gubbi J., Buyya R., Marusic S., Palaniswami M. Internet of Things (IoT): A vision, architectural elements, and future directions Future Gener. Comput. Syst., 29 (7) (2013), pp. 1645-1660, 10.1016/j.future.2013.01.010 View PDFView articleView in ScopusGoogle Scholar [24] Jin J., Gubbi J., Marusic S., Palaniswami M. An information framework for creating a smart city through internet of things IEEE Internet of Things J., 1 (2) (2014), pp. 112-121, 10.1109/JIOT.2013.2296516 View in ScopusGoogle Scholar [25] Gil-Castineira F., Costa-Montenegro E., Gonzalez-Castano F., Lpez-Bravo C., Ojala T., Bose R. Experiences inside the ubiquitous oulu smart city Computer, 44 (6) (2011), pp. 48-55, 10.1109/MC.2011.132 View in ScopusGoogle Scholar [26] Filipponi L., Vitaletti A., Landi G., Memeo V., Laura G., Pucci P. Smart City: An Event Driven Architecture for Monitoring Public Spaces with Heterogeneous Sensors Sensor Technologies and Applications, SENSORCOMM, 2010 Fourth International Conference on (2010), pp. 281-286, 10.1109/SENSORCOMM.2010.50 View in ScopusGoogle Scholar [27] Sanchez L., Muñoz L., Galache J.A., Sotres P., Santana J.R., Gutierrez V., Ramdhany R., Gluhak A., Krco S., Theodoridis E., Pfisterer D. SmartSantander: IoT experimentation over a smart city testbed Comput. Netw., 61 (C) (2014), pp. 217-238, 10.1016/j.bjp.2013.12.020 View PDFView articleView in ScopusGoogle Scholar [28] Malcolm Bain. Sentilo - Sensor and Actuator Platform for Smart Cities, 2014. https://joinup.ec.europa.eu/community/eupl/document/sentilo-sensor-and-actuator-platform-smart-cities (Accessed: 21 April 2017) Google Scholar [29] Ballon P., Glidden J., Kranas P., Menychtas A., Ruston S., Van Der Graaf S. Is there a need for a cloud platform for european smart cities? eChallenges e-2011 Conference Proceedings, IIMC International Information Management Corporation (2011), pp. 1-7 View in ScopusGoogle Scholar [30] Khan Z., Anjum A., Kiani S.L. Cloud based big data analytics for smart future cities Proceedings of the 2013 IEEE/ACM 6th International Conference on Utility and Cloud Computing, IEEE Computer Society (2013), pp. 381-386 Google Scholar [31] Khan Z., Anjum A., Soomro K., Tahir M.A. Towards cloud based big data analytics for smart future cities J. Cloud Comput., 4 (1) (2015), p. 2 Google Scholar [32] Kim K.-D., Kumar P.R. Cyber–physical systems: A perspective at the centennial Proc. IEEE, 100 (Special Centennial Issue) (2012), pp. 1287-1308 View in ScopusGoogle Scholar [33] Giordano A., Spezzano G., Vinci A. A smart platform for large-scale networked cyber-physical systems Management of Cyber Physical Objects in the Future Internet of Things Methods, Architectures and Applications, Springer (2016) Google Scholar [34] Vermesan O., Friess P. Internet of Things: Converging Technologies for Smart Environments and Integrated Ecosystems River Publishers (2013) Google Scholar [35] Fortino G., Giordano A., Guerrieri A., Spezzano G., Vinci A. A data analytics schema for activity recognition in smart home environments Ubiquitous Computing and Ambient Intelligence. Sensing, Processing, and using Environmental Information - 9th International Conference, UCAmI 2015, Puerto Varas, Chile, December 1-4, 2015, Proceedings (2015), pp. 91-102 CrossRefView in ScopusGoogle Scholar [36] Cicirelli F., Fortino G., Guerrieri A., Spezzano G., Vinci A. A Meta-Model Framework for the Design and Analysis of Smart Cyber-Physical Environments Proceedings of the 2016 IEEE 20th International Conference on Computer Supported Cooperative Work in Design (2016) Google Scholar [37] Cicirelli F., Fortino G., Giordano A., Guerrieri A., Spezzano G., Vinci A. On the design of smart homes: A framework for activity recognition in home environment J. Med. Syst., 40 (9) (2016), p. 200 View in ScopusGoogle Scholar [38] Cicirelli F., Spezzano G. Concept Hierarchies for Sensor Data Fusion in the Cognitive IoT Proceedings of the 30th ECMS 2016 (2016) Google Scholar [39] Zambonelli F., Jennings N.R., Wooldridge M. Developing multiagent systems: the gaia methodology ACM Trans. Softw. Eng. Methodol., 12 (3) (2003), pp. 317-370, 10.1145/958961.958963 View in ScopusGoogle Scholar [40] Jelasity M., Montresor A., Babaoglu O. Gossip-based aggregation in large dynamic networks ACM Trans. Comput. Syst., 23 (3) (2005), pp. 219-252 CrossRefView in ScopusGoogle Scholar [41] MacGregor J.F., Harris T.J. The exponentially weighted moving variance J. Qual. Technol., 25 (2) (1993), pp. 106-118 CrossRefGoogle Scholar [42] Garofalo G., Giordano A., Piro P., Spezzano G., Vinci A. A distributed real-time approach for mitigating cso and flooding in urban drainage systems J. Netw. Comput. Appl., 78 (2017), pp. 30-42, 10.1016/j.jnca.2016.11.004 View PDFView articleView in ScopusGoogle Scholar [43] Atzori L., Iera A., Morabito G., Nitti M. The social internet of things (siot) - when social networks meet the internet of things: Concept, architecture and network characterization Comput. Netw., 56 (16) (2012), pp. 3594-3608, 10.1016/j.comnet.2012.07.010 View PDFView articleView in ScopusGoogle Scholar [44] Cicirelli F., Guerrieri A., Spezzano G., Vinci A., Briante O., Ruggeri G. iSapiens: A Platform for Social and Pervasive Smart Environments In the Proc. of the 2016 IEEE World Forum on Internet of Things (WF-IoT) (2016) Google Scholar [45] Cicirelli F., Guerrieri A., Spezzano G., Vinci A., Briante O., Ruggeri G., Iera A. An edge-based approach to develop large-scale smart environments by leveraging SIoT The 14th IEEE International Conference on Networking, Sensing and Control, ICNSC 2017 (2017) ISBN: 978-1-5090-4428-3, in press Google Scholar Cited by (109) A novel Edge architecture and solution for detecting concept drift in smart environments 2024, Future Generation Computer Systems Show abstract When edge intelligence meets cognitive buildings: The COGITO platform 2023, Internet of Things (Netherlands) Show abstract Deep learning models for cloud, edge, fog, and IoT computing paradigms: Survey, recent advances, and future directions 2023, Computer Science Review Show abstract Digital twin-supported smart city: Status, challenges and future research directions 2023, Expert Systems with Applications Show abstract CCNSim: An artificial intelligence enabled classification, clustering and navigation simulator for Social Internet of Things 2023, Engineering Applications of Artificial Intelligence Show abstract Editorial: AI and IoT applications of smart buildings and smart environment design, construction and maintenance 2023, Building and Environment View all citing articles on Scopus Franco Cicirelli, Ph.D, is a researcher at ICAR-CNR (Italy) since December 2015. He earned a Ph.D. in System Engineering and Computer Science at the University of Calabria (Italy). He was a researcher fellow at the University of Calabria (Italy) from 2006 to 2015. His research work mainly focuses on Software Engineering tools and methodologies for the modeling, analysis and implementation of complex time-dependent systems. Research topics are agent-based systems, distributed simulation, parallel and distributed systems, real-time systems, workflow management systems, Internet of Things and cyber–physical systems. His research activities involve also Petri Nets, Timed Automata and the DEVS formalism. Antonio Guerrieri received the Ph.D. degree in computer engineering from the University of Calabria, Italy, in 2012. He is currently serving as Researcher at ICAR-CNR, Italy. He spent six months as researcher at the Telecom Italia WSN Lab at Berkeley, California, and one year at the Clarity Centre, UCD (University College Dublin), Ireland. He has been involved in several research projects and is co-founder of SenSysCal S.r.l. His research interests are focused on high-level programming methodologies and frameworks for wireless sensor and actuator networks, building monitoring and control, body sensor networks, design and development of smart environments, smart objects, Internet of Things. Giandomenico Spezzano is a Research Director at the Institute of High Performance Computing and Networking of the Italian National Research Council (ICAR-CNR) Rende, Italy. His research interests include parallel architectures, grid computing, peer-to-peer computing, parallel and distributed data mining, pervasive computing and Internet of Things. Andrea Vinci, Ph.D., is a researcher at ICAR-CNR, Italy, where he has worked in various positions since 2012. He earned a Ph.D. in System Engineering and Computer Science at the University of Calabria (Italy). His research work mainly focuses on Internet of Things and Cyber–Physical Systems. In these areas, he has published works on the definitions of platforms and methodologies for the design and implementation of cyber–physical systems, on distributed algorithms for the efficient control of urban drainage networks, based on swarm intelligence and peer-to-peer techniques, and on Data Mining techniques for Ambient Intelligence. 1 https://eu-smartcities.eu/eu-projects. 2 http://amsterdamsmartcity.com/. 3 http://sfenvironment.org/. 4 http://smartcity.bcn.cat/en. 5 http://www.copcap.com/set-up-a-business/key-sectors/smart-city. 6 http://www.ubioulu.fi/en/home. 7 European Directive. The Environmental Noise Directive (2002/49/EG). Official Journal of the European Communities, 2002. http://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex%3A32002L0049 . 8 http://www.summersimmer.com/. 9 http://ec.gc.ca/meteo-weather/. 10 https://en.wikipedia.org/wiki/Air_quality_index. 11 https://www.raspberrypi.org/products/raspberry-pi-2-model-b/. 12 http://www.libelium.com/products/plug-sense/. View Abstract © 2017 Elsevier B.V. All rights reserved. Recommended articles Analyzing stochastic reward nets by model checking and parallel simulation Simulation Modelling Practice and Theory, Volume 116, 2022, Article 102467 Franco Cicirelli, Libero Nigro View PDF AI-guided resource allocation and rescue decision system for medical applications Future Generation Computer Systems, Volume 118, 2021, pp. 485-491 Ye Yu, …, Feng Yuan View PDF Smart Environment Monitoring System by Employing Wireless Sensor Networks on Vehicles for Pollution Free Smart Cities Procedia Engineering, Volume 107, 2015, pp. 480-484 Muhammad Saqib Jamil, …, Usman Munawar View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 104 Captures Readers: 211 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.

</subsection_point_Point 5>

<previous_sections>

A systematic review of automated systems for real-time irrigation management

1. INTRODUCTION
The challenge of feeding a growing population with finite resources is becoming increasingly pressing. By 2050, the world population is expected to reach 9.7 billion, necessitating a 70% increase in food production (Falkenmark and Rockstrom, 2009). Irrigation plays a crucial role in enhancing crop yields and agricultural productivity to meet this growing demand. Studies have shown that irrigation can significantly increase crop water productivity, contributing to increased food production (Ali and Talukder, 2008; Playan and Mateos, 2005). However, water scarcity poses a significant challenge, with many regions facing water deficits and the need for improved water management practices (Falkenmark and Rockstrom, 2009). Optimizing irrigation schedules and doses based on crop requirements and environmental conditions is essential for maximizing yield and quality while minimizing water use (Zhang et al., 2024). The necessity of scalable water-efficient practices for increasing food demand cannot be overstated. Techniques such as regulated deficit irrigation, magnetically treated water, and the use of drought-tolerant crops like sorghum have shown promise in improving water productivity and ensuring food security (Mehmood et al., 2023; Putti et al., 2023; Hadebe et al., 2016). As the global food challenge intensifies, it is imperative to critically evaluate the current state and future potential of irrigation management systems to guide research, innovation, and implementation efforts towards fully autonomous, scalable solutions.

Despite the importance of irrigation in addressing the global food challenge, traditional irrigation management techniques, such as manual scheduling and timer-based systems, have significant limitations. These methods are often labor-intensive, inefficient, and less adaptable to changing conditions (Savin et al., 2023). Manual and timer-based scheduling can lead to high operational costs and inefficient water use (Raghavendra, Han, and Shin, 2023). The reliance on manual intervention and predetermined schedules limits their adaptability to changing environmental conditions, crop water requirements, and soil moisture levels (Kaptein et al., 2019). Sensor-based irrigation systems offer an alternative, enabling real-time adjustments based on soil water status measurements (Kaptein et al., 2019). However, the adoption of these systems in commercial settings has been limited, often requiring extensive input from researchers (Kim et al., 2014; Lea-Cox et al., 2018; Ristvey et al., 2018). The limitations of traditional irrigation management techniques highlight the need for scalable, automated solutions for greater efficiency in irrigation management. Automated systems that collect real-time data, analyze it, and make autonomous irrigation decisions can lead to improved water use efficiency and increased crop productivity (Champness et al., 2023; Wu et al., 2022). To fully understand the potential of automated systems, it is necessary to examine the automation of each part of the irrigation management pipeline and analyze the effectiveness and efficiency of integrated end-to-end solutions.

The emergence of smart irrigation management and IoT marks a significant shift from historical irrigation practices. Modern approaches rely on vast data and analysis algorithms, leveraging technologies such as remote sensing, sensor networks, weather data, and computational algorithms (Atanasov, 2023; Bellvert et al., 2023; Kumar et al., 2023). IoT plays a vital role in collecting vast amounts of data through sensors, data transmission, and tailored networks, enabling real-time monitoring and control of irrigation systems (Liakos, 2023; Zuckerman et al., 2024). These advancements in data collection and analysis have the potential to revolutionize irrigation management, allowing for more precise and efficient water use. However, challenges such as processing diverse data sources, data integration, and lack of integrated data analysis hamper the full benefit of IoT in irrigation management (Dave et al., 2023). The current fragmented approach in smart irrigation, focusing on individual components rather than the entire system, limits the potential for fully autonomous, real-time end-to-end irrigation management (Togneri et al., 2021). To address these challenges and fully realize the potential of smart irrigation management, there is a need for automating and integrating each section of the irrigation management pipeline, from sensor/weather data collection and transmission to processing, analysis, decision-making, and automated action (McKinion and Lemmon, 1985). This integration requires a thorough investigation of the role of interoperability and standardization in enabling seamless communication and compatibility between components within the automated irrigation management pipeline.

Machine learning (ML) plays a significant role in processing vast data, predicting plant stress, modeling climate effects, and optimizing irrigation in smart irrigation management systems. ML algorithms can analyze data collected from sensors and weather stations to determine optimal irrigation schedules (Vianny et al., 2022). However, the potential of ML is often constrained by manual steps, such as data interpretation, decision-making on irrigation timing and volume, and system adjustments. Automating ML integration to allow direct action from insights to irrigation execution, removing bottlenecks and achieving real-time adaptability, is crucial for fully autonomous irrigation management (Barzallo-Bertot et al., 2022). By integrating ML into automated systems, the irrigation management pipeline can become more seamless and efficient, enabling real-time decision-making and action based on data-driven insights. To achieve this level of automation and integration, it is essential to identify gaps and propose solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.

To achieve seamless integration across the automated irrigation management system, interoperability and standardization are critical. Interoperability allows different system components, such as sensors, actuators, and software, to communicate and exchange data effectively, while standardization ensures that data is represented in a consistent format (Santos et al., 2020). Standardized protocols and data formats are essential for achieving seamless integration and ensuring compatibility between components in real-time irrigation management systems (Robles et al., 2022; Hatzivasilis et al., 2018). Existing and emerging standards, such as OGC SensorThings API and ISO 11783, have applicability to real-time irrigation management systems (Hazra et al., 2021). However, challenges such as data quality, scalability, reliability, and security need to be addressed to fully realize the potential of interoperability and standardization in automated irrigation management systems (Hazra et al., 2021). Addressing these challenges is crucial for enabling the seamless integration of components within the automated irrigation management pipeline, which is essential for achieving fully autonomous, scalable irrigation management. A comprehensive evaluation of the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline is necessary to guide future research and implementation efforts.
The primary objective of this systematic review is to critically evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies for enhancing agricultural water use efficiency and crop productivity.
Specific objectives include:
•	Examining the automation of each part of the irrigation management pipeline and the seamless integration of each section in the context of irrigation scheduling and management.
•	Analyzing the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
•	Investigating the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.
•	Identifying gaps and proposing solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.
By addressing these objectives, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.

2. REVIEW METHODOLOGY
•	Question-driven framework to guide the literature review of real-time, autonomous irrigation management systems
•	Key research questions posed, each with the motivation behind investigating them and a starting hypothesis to evaluate against the examined literature
•	Table presenting the major objectives, specific objectives, questions, motivations, and hypotheses
3. DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING
3.1. Irrigation management data
The success of automated irrigation management systems relies heavily on the collection, transmission, and analysis of various types of data. The most applicable data types for irrigation management include soil moisture, canopy temperature, weather data, and plant physiological parameters (Farooq et al., 2019; Li et al., 2019; Olivier et al., 2021; Evett et al., 2020). These data are typically collected from a range of sources, including in-field sensors, remote sensing platforms, weather stations, and manual measurements (Li et al., 2019; Karimi et al., 2018).
Soil moisture data is arguably the most critical type of data for irrigation management, as it directly reflects the water available to plants and can be used to determine the optimal timing and amount of irrigation (Olivier et al., 2021; Intrigliolo & Castel, 2006). Soil moisture sensors, such as tensiometers, capacitance probes, and time-domain reflectometry (TDR) sensors, can provide real-time measurements of soil water content at various depths (Farooq et al., 2019). These sensors can be deployed in a network configuration to capture spatial variability in soil moisture across a field (Karimi et al., 2018).
Canopy temperature data is another valuable type of data for irrigation management, as it can be used to assess plant water stress and adjust irrigation accordingly (Evett et al., 2020). Infrared thermometers and thermal cameras can be used to measure canopy temperature, which is influenced by factors such as air temperature, humidity, wind speed, and plant water status (Li et al., 2019). When plants experience water stress, they tend to close their stomata to reduce water loss, leading to an increase in canopy temperature (Evett et al., 2020). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
Weather data, including temperature, humidity, precipitation, wind speed, and solar radiation, are essential for predicting crop water requirements and scheduling irrigation events (Akilan & Baalamurugan, 2024). Weather stations equipped with various sensors can provide real-time measurements of these parameters, which can be used as inputs for crop water requirement models, such as the FAO-56 Penman-Monteith equation (Li et al., 2019). These models estimate crop evapotranspiration (ET) based on weather data and crop-specific coefficients, allowing for the calculation of irrigation requirements (Intrigliolo & Castel, 2006). By integrating weather data into automated irrigation systems, irrigation schedules can be dynamically adjusted based on changing environmental conditions, ensuring that crops receive the optimal amount of water at the right time (Akilan & Baalamurugan, 2024).
When collecting and utilizing these data types, several considerations must be taken into account, including the volume, frequency, format, and source of the data (Farooq et al., 2019). The volume of data generated by automated irrigation systems can be substantial, especially when high-resolution sensors are deployed at a large scale (Bastidas Pacheco et al., 2022). This necessitates the use of efficient data storage, processing, and transmission technologies to handle the data load (Farooq et al., 2019). The frequency of data collection is another important consideration, as it directly impacts the temporal resolution of the data and the ability to detect rapid changes in plant water status or environmental conditions (Bastidas Pacheco et al., 2022). Bastidas Pacheco et al. (2022) demonstrated that collecting full pulse resolution data from water meters provides more accurate estimates of event occurrence, timing, and features compared to aggregated temporal resolutions, highlighting the importance of selecting appropriate data collection frequencies to ensure the quality and usefulness of the data for irrigation management.
The format of the data is also crucial, as it determines the compatibility and interoperability of the data with various analysis tools and platforms (Farooq et al., 2019). Standardized data formats, such as JSON, XML, or CSV, can facilitate data exchange and integration between different components of the automated irrigation system (Zhang et al., 2023). The source of the data is another important consideration, as it can impact the reliability, accuracy, and spatial coverage of the data (Farooq et al., 2019). For example, in-field sensors provide highly localized measurements, while remote sensing platforms, such as satellites or drones, can provide data at larger spatial scales (Li et al., 2019). By combining data from multiple sources, automated irrigation systems can achieve a more comprehensive understanding of crop water requirements and optimize irrigation management accordingly (Farooq et al., 2019).
Data quality, accuracy, and reliability are paramount in irrigation management, as they directly impact the effectiveness of decision-making processes and the efficiency of water use (Gupta et al., 2020). Inaccurate or unreliable data can lead to suboptimal irrigation decisions, resulting in crop stress, yield losses, or wasted water resources (Ramli & Jabbar, 2022). Gupta et al. (2020) emphasized the critical importance of data security and privacy in smart farming systems, as the leakage of sensitive agricultural data can cause severe economic losses to farmers and compromise the integrity of the automated irrigation system. The authors also highlighted the need for robust authentication and secure communication protocols to prevent unauthorized access to smart farming systems and protect data in transit (Gupta et al., 2020).
Ramli and Jabbar (2022) addressed the challenges associated with implementing real-time, automated irrigation systems, including data quality, scalability, reliability, and security. They proposed solutions and best practices based on the analysis of case studies and real-world implementations, such as the use of redundant sensors, data validation techniques, and secure communication protocols (Ramli & Jabbar, 2022). The authors also emphasized the importance of regular maintenance and calibration of sensors to ensure the accuracy and reliability of the collected data (Ramli & Jabbar, 2022).
Researchers have investigated the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in automated irrigation systems (Karim et al., 2023; Rady et al., 2020; Cui, 2023). Karim et al. (2023) explored the effectiveness of various data compression techniques, such as lossless and lossy compression algorithms, in reducing the size of data packets transmitted over wireless networks. The authors found that lossless compression techniques, such as Huffman coding and Lempel-Ziv-Welch (LZW), can significantly reduce data size without compromising data quality, while lossy compression techniques, such as JPEG and MP3, can further reduce data size by introducing acceptable levels of distortion (Karim et al., 2023).
Rady et al. (2020) developed a novel data compression algorithm specifically designed for irrigation data, which achieved significant compression ratios without compromising data quality. The authors demonstrated that their algorithm could reduce the amount of data transmitted over wireless networks, thereby improving the efficiency of the irrigation system and reducing costs (Rady et al., 2020). Cui (2023) investigated the use of data aggregation and filtering techniques to reduce the number of transmissions and save bandwidth in automated irrigation systems. The author proposed a data aggregation scheme that combines multiple sensor readings into a single value, such as the average soil moisture over a specified time interval, to reduce the frequency of data transmissions (Cui, 2023). Additionally, the author explored the use of data filtering techniques, such as Kalman filters and particle filters, to remove noise and outliers from sensor data, improving the accuracy and reliability of the transmitted information (Cui, 2023).
Data standardization and harmonization are crucial for facilitating seamless integration and interoperability between the various components of automated irrigation management systems (Zhang et al., 2023; Ermoliev et al., 2022). Zhang et al. (2023) developed a novel cyberinformatics technology called iCrop, which enables the in-season monitoring of crop-specific land cover across the contiguous United States. The authors highlighted the importance of data standardization and harmonization in the context of iCrop, as it allows for the efficient distribution of crop-specific land cover information based on the findable, accessible, interoperable, and reusable (FAIR) data principle (Zhang et al., 2023). By adopting standardized data formats and protocols, such as the Open Geospatial Consortium (OGC) standards, iCrop enables the seamless integration of various data sources and facilitates the interoperability of the system with other agricultural decision support tools (Zhang et al., 2023).
Ermoliev et al. (2022) proposed a linkage methodology for linking distributed sectoral/regional optimization models in a situation where private information is not available or cannot be shared by modeling teams. The authors emphasized the need for data standardization to enable decentralized cross-sectoral coordination and analysis, as it allows for the consistent representation and exchange of data between different models and stakeholders (Ermoliev et al., 2022). By adopting standardized data formats and interfaces, the proposed linkage methodology can facilitate the integration of various optimization models and support the development of comprehensive decision support systems for sustainable resource management (Ermoliev et al., 2022).
Metadata plays a vital role in providing context and enabling better data interpretation and decision-making in automated irrigation management systems (Jahanddideh-Tehrani et al., 2021). Metadata refers to the additional information that describes the characteristics, quality, and context of the primary data, such as the sensor type, calibration parameters, measurement units, and timestamp (Jahanddideh-Tehrani et al., 2021). Jahanddideh-Tehrani et al. (2021) highlighted the importance of metadata in water resources management, as it enables decision-makers to use the data to the best of its capabilities by understanding factors such as when water data was collected and what factors might have contributed to the measurements. The authors emphasized the need for standardized metadata formats and guidelines, such as the Dublin Core Metadata Initiative (DCMI) and the ISO 19115 standard, to ensure the consistency and interoperability of metadata across different water information systems (Jahanddideh-Tehrani et al., 2021).
In the context of automated irrigation management systems, metadata can provide valuable information about the data collection process, sensor performance, and environmental conditions that can aid in data interpretation and decision-making (Cota & Mamede, 2023). For example, metadata about the sensor type and calibration parameters can help assess the accuracy and reliability of the collected data, while metadata about the weather conditions and soil properties can provide context for interpreting the data and adjusting irrigation strategies accordingly (Cota & Mamede, 2023). By incorporating metadata into the data management and analysis pipeline of automated irrigation systems, decision-makers can make more informed and context-aware decisions, leading to improved water use efficiency and crop productivity (Jahanddideh-Tehrani et al., 2021).

3.2. Edge Computing and Fog Computing
Edge computing and fog computing have emerged as transformative technologies in the realm of real-time irrigation management systems, offering significant potential for improving efficiency, scalability, and reliability (Abdel Nasser et al., 2020; Tran et al., 2019). Edge computing refers to the practice of processing data near the edge of the network, close to the source of the data, while fog computing is a decentralized computing infrastructure that extends cloud computing capabilities to the network edge (Hassija et al., 2019). These technologies bring computation and analytics closer to the data source, reducing the need for data to travel to the cloud and enabling faster processing and decision-making (Hassija et al., 2019; Zhang et al., 2020).
The potential of edge computing and fog computing in real-time irrigation management is immense. Abdel Nasser et al. (2020) proposed a two-layer system for water demand prediction using automated meters and machine learning techniques, demonstrating the potential of edge computing in improving the efficiency and scalability of irrigation management. The system collects and aggregates data from distributed smart meters in the first layer, while the second layer uses LSTM neural networks to predict water demand for different regions of households. By leveraging edge computing, the system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management (Abdel Nasser et al., 2020).
Tran et al. (2019) conducted a comprehensive review of real-time, end-to-end automated irrigation management systems, highlighting the role of fog computing in addressing data transmission challenges and enabling seamless integration across the irrigation management pipeline. The authors emphasize that real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs. However, they also identify several challenges that need to be addressed, such as data quality, scalability, reliability, and security, which can be effectively tackled by implementing fog computing architectures (Tran et al., 2019).
Edge computing offers several benefits in real-time irrigation management systems, including reduced latency, real-time decision-making, and reduced reliance on cloud connectivity (Mishra, 2020; Zhang et al., 2020). By processing data closer to the source, edge computing enables faster response times and more efficient data handling (Mishra, 2020). Mishra (2020) highlights that edge computing reduces latency by processing data closer to the source, enabling real-time decision-making and lessening reliance on cloud connectivity by shifting processing to local or edge devices.
Zhang et al. (2020) explore the application of edge computing in agricultural settings, demonstrating its potential to improve the efficiency and accuracy of irrigation systems. The authors discuss how edge computing has prospects in various agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. They also emphasize that the emergence of edge computing models, such as fog computing, cloudlet, and mobile edge computing, has transformed the management and operation of farms (Zhang et al., 2020).
Fog computing plays a crucial role in distributing processing and storage across the network, enhancing the scalability and reliability of automated irrigation systems (Premkumar & Sigappi, 2022; Singh et al., 2022). Premkumar and Sigappi (2022) evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation. Their study emphasizes the potential of fog computing in distributing processing and storage across the network, improving the efficiency and scalability of irrigation systems. The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture, demonstrating the effectiveness of fog computing in enhancing the performance of automated irrigation systems (Premkumar & Sigappi, 2022).
Singh et al. (2022) discuss the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability in agricultural management systems. The authors argue that by implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness. They also highlight that fog computing can address the challenges faced by real-time data transmission in agricultural management systems, such as latency, bandwidth limitations, and data security (Singh et al., 2022).
The integration of edge and fog computing in real-time irrigation management systems is crucial for achieving fully automated, scalable, and reliable solutions. As the demand for autonomous irrigation management grows, these technologies will play a pivotal role in enabling faster decision-making, reduced latency, improved resource utilization, and seamless integration across the irrigation management pipeline (Tran et al., 2019; Zhang et al., 2020). By bringing computation and analytics closer to the data source and distributing processing and storage across the network, edge and fog computing can significantly enhance the efficiency and effectiveness of automated irrigation systems, contributing to the overall goal of addressing the global food challenge through optimized water resource management and increased agricultural productivity (Abdel Nasser et al., 2020; Premkumar & Sigappi, 2022; Singh et al., 2022).

3.3. Automation of Data Collection
The automation of data collection is a critical component in the development of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. It enables the efficient gathering of vital information about crop health, environmental conditions, and water requirements, which is essential for enhancing agricultural water use efficiency and crop productivity. Two key aspects of automated data collection are the use of advanced sensing technologies for non-invasive plant stress detection and the implementation of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.
Advanced sensing technologies, such as hyperspectral imaging and thermal sensing, have emerged as powerful tools for non-invasive plant stress detection in automated irrigation management systems. These technologies provide valuable information about crop traits, enabling early and accurate detection of plant health issues (Triantafyllou et al., 2019). Triantafyllou et al. (2019) propose a comprehensive reference architecture model that incorporates advanced sensing technologies in the sensor layer for real-time plant stress detection, highlighting their importance in providing non-invasive plant stress detection. Similarly, Hossain et al. (2023) present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that leverages advanced sensing technologies to optimize water use and improve crop yield, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
Hyperspectral imaging can capture subtle changes in plant physiology that are indicative of stress, while machine learning algorithms can be employed to extract meaningful patterns from the spectral data and classify different stress types (Araus et al., 2014). Thermal sensing can detect changes in canopy temperature, which is influenced by factors such as plant water status (Li et al., 2019). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
The integration of advanced sensing technologies in automated irrigation management systems has the potential to revolutionize precision agriculture. Jiang et al. (2019) demonstrate the effectiveness of a deep learning-based model in accurately detecting leaf spot diseases, highlighting the importance of image augmentation and deep learning algorithms in enhancing the model's performance.
Wireless sensor networks (WSNs) and energy-efficient communication protocols have the potential to significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. WSNs offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems, providing remote monitoring and automated control capabilities (Mehdizadeh et al., 2020). Nishiura and Yamamoto (2021) propose a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields, reducing operational costs and enhancing the efficiency of data collection. Similarly, Higashiura and Yamamoto (2021) introduce a network system that employs UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands, optimizing data collection and reducing travel distance and time.
Energy-efficient communication protocols are crucial for ensuring reliable data transmission in challenging environmental conditions and extending the lifespan of sensor nodes (Mehdizadeh et al., 2020). Al-Ali et al. (2023) investigate the potential of WSNs and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems, discussing the challenges and opportunities of using these technologies to improve the efficiency and reliability of real-time data collection in irrigation management. Mehdizadeh et al. (2020) emphasize the need for careful consideration of factors such as data accuracy, energy consumption, and network reliability when designing effective WSNs for irrigation management, enabling timely irrigation decisions and improved crop yields.
The automation of data collection through the use of advanced sensing technologies and wireless sensor networks is essential for achieving fully autonomous, scalable irrigation management. By enabling non-invasive plant stress detection and large-scale, long-term data collection, these technologies contribute to the overall goal of optimizing water resource management and increasing agricultural productivity. The integration of these technologies in real-time, end-to-end automated irrigation management systems has the potential to enhance agricultural water use efficiency and crop productivity, ultimately contributing to the development of fully autonomous, scalable irrigation management solutions.

3.4: Real-Time Data Transmission Protocols and Technologies
Real-time data transmission is a critical component of automated irrigation management systems, as it enables the timely delivery of sensor data to the cloud for processing and decision-making. The exploration of suitable protocols and network architectures is essential for ensuring efficient and reliable data transmission in these systems, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
The Message Queuing Telemetry Transport (MQTT) protocol has emerged as a popular choice for real-time data transmission in IoT networks, including those used for automated irrigation management. MQTT is a lightweight, publish-subscribe protocol designed for constrained devices and low-bandwidth networks (Author, 2019). Its simplicity and low overhead make it well-suited for IoT applications where data transmission speed and energy efficiency are critical (Saranyadevi et al., 2022). MQTT provides three Quality of Service (QoS) levels, ensuring data reliability in real-time scenarios (Author, 2019). Chen et al. (2020) proposed novel algorithms to improve data exchange efficiency and handle rerouting in MQTT-based IoT networks for automated irrigation management systems. Their TBRouting algorithm efficiently finds the shortest paths for data transmission, while the Rerouting algorithm effectively handles the rerouting of topic-based session flows when a broker crashes. The combination of these algorithms can significantly improve the performance and reliability of automated irrigation management systems (Chen et al., 2020).
Client-server IoT networks, such as those based on MQTT, play a crucial role in real-time data transmission for automated irrigation management systems. In these networks, sensors and devices (clients) publish data to a central broker (server), which then distributes the data to subscribed clients (Verma et al., 2021). This architecture enables efficient data collection, processing, and dissemination, facilitating the integration of various components within the automated irrigation management pipeline. Verma et al. (2021) proposed an architecture for healthcare monitoring systems using IoT and communication protocols, which provides a comprehensive overview of existing approaches and highlights challenges and opportunities in the field. Although focused on healthcare, the insights from this study can be applied to automated irrigation management systems, emphasizing the importance of interoperability and standardization for seamless integration (Verma et al., 2021).
In addition to MQTT, other application layer protocols such as XMPP, CoAP, SOAP, and HTTP have been explored for real-time data transmission in IoT networks. Each protocol has its strengths and weaknesses, making them suitable for different applications and scenarios. XMPP (Extensible Messaging and Presence Protocol) is an open-standard protocol that supports real-time messaging, presence, and request-response services (Saint-Andre, 2011). CoAP (Constrained Application Protocol) is a specialized web transfer protocol designed for use with constrained nodes and networks in the Internet of Things (Shelby et al., 2014). SOAP (Simple Object Access Protocol) is a protocol for exchanging structured information in the implementation of web services, while HTTP (Hypertext Transfer Protocol) is the foundation of data communication for the World Wide Web (Fielding et al., 1999).
Motamedi and Villányi (2022) compared and evaluated wireless communication protocols for the implementation of smart irrigation systems in greenhouses, considering factors such as power consumption, range, reliability, and scalability. They found that ZigBee is the most suitable local communication protocol for greenhouse irrigation due to its large number of nodes and long range, while MQTT is the recommended messaging protocol for smart irrigation systems due to its TCP transport protocol and quality of service (QoS) options. GSM is a reliable and cost-effective global communication protocol for greenhouse irrigation, providing wide coverage and low cost (Motamedi & Villányi, 2022).
Syafarinda et al. (2018) investigated the use of the MQTT protocol in a precision agriculture system using a Wireless Sensor Network (WSN). They found that MQTT is suitable for use in IoT applications due to its lightweight, simple, and low bandwidth requirements. The average data transmission speed using the MQTT protocol was approximately 1 second, demonstrating its effectiveness for real-time data transmission in precision agriculture systems (Syafarinda et al., 2018).
The choice of application layer protocol for real-time irrigation management depends on factors such as data transmission speed, reliability, and energy efficiency. MQTT and RTPS (Real-Time Publish-Subscribe) are both suitable for real-time data transmission in IoT systems, but they have different strengths and weaknesses. MQTT is a better choice for applications that require low latency and high throughput, while RTPS is a better choice for applications that require high reliability and low latency (Sanchez-Iborra & Skarmeta, 2021). The exploration of MQTT and client-server IoT networks, along with the comparison of various application layer protocols, provides valuable insights into the suitability of these technologies for real-time data transmission in automated irrigation management systems.
In summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.

3.5. Challenges and Solutions in Real-Time Data Transmission
Following the exploration of data collection, processing at the edge and fog, and automation in previous sections, we now turn to the critical aspect of real-time data transmission. While essential for automated irrigation management, this stage presents unique challenges that must be addressed to ensure system efficiency and reliability.
Obstacles in Real-Time Data Transmission
Agricultural environments present unique challenges for real-time data transmission, directly impacting the effectiveness of automated irrigation systems. Environmental factors can significantly disrupt wireless communication. Adverse weather conditions such as heavy rain, fog, and high winds can weaken or even block radio signals, leading to data loss and compromised system performance. Physical obstacles like trees, buildings, and uneven terrain further complicate signal propagation, creating reliability issues (Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). These environmental challenges necessitate robust communication protocols and network architectures that can ensure consistent and reliable data flow.
In addition to environmental factors, technical limitations also present significant obstacles. Large-scale agricultural operations often demand long-distance data transmission, which can be hindered by the limited range of certain wireless communication protocols. Network congestion, occurring when multiple sensors transmit data concurrently, can lead to delays and potential data loss, further complicating real-time decision-making (Hameed et al., 2020). To mitigate these issues, researchers have investigated the potential of cognitive radio networks (CRNs) and dynamic spectrum access (DSA) for optimizing spectrum utilization and reducing interference (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). CRNs enable devices to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency. DSA, on the other hand, facilitates the dynamic allocation of unused spectrum, enhancing spectrum utilization and reducing congestion.
Furthermore, data security and privacy are paramount concerns in real-time irrigation systems. The sensitive nature of agricultural data, such as crop yields and farm management practices, necessitates robust security measures to prevent unauthorized access and data breaches (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential to protect data integrity and ensure the trustworthiness of the system.
Investigating Data Optimization Techniques
To enhance the efficiency and reliability of real-time data transmission in automated irrigation systems, researchers have explored a range of data optimization techniques. Data compression techniques aim to reduce the size of data packets transmitted over the network, minimizing bandwidth requirements and improving transmission speed (Rady et al., 2020; Karim et al., 2023). Lossless compression algorithms, such as Huffman coding and LZW, preserve data integrity while effectively reducing data size, ensuring that no information is lost during transmission (Cui, 2023). Lossy compression algorithms, such as JPEG and MP3, offer higher compression ratios but introduce a controlled level of data loss, which may be acceptable for certain applications where some loss of precision is tolerable (Karim et al., 2023). The choice between lossless and lossy compression depends on the specific application and the trade-off between data size and accuracy.
Data aggregation techniques provide another effective approach to optimize data transmission. By aggregating multiple sensor readings into a single representative value, such as average soil moisture or temperature, the number of transmissions can be significantly reduced, conserving bandwidth and energy resources (Cui, 2023). This is particularly beneficial in large-scale irrigation systems where numerous sensors are deployed across vast areas, generating substantial amounts of data. Additionally, data filtering techniques play a crucial role in improving data quality and reliability. Kalman filters and particle filters can effectively remove noise and outliers from sensor data, ensuring that only accurate and relevant information is transmitted and used for decision-making (Cui, 2023). This is essential for preventing erroneous data from influencing irrigation decisions and potentially leading to suboptimal water management.
Sensor calibration, drift correction, and fault detection are essential for maintaining data accuracy and reliability (Dos Santos et al., 2023). Regular calibration ensures that sensors provide accurate measurements over time, while drift correction techniques account for gradual changes in sensor readings due to environmental factors or aging. Fault detection mechanisms can identify and address sensor malfunctions or anomalies, preventing erroneous data from influencing irrigation decisions and potentially harming crops or wasting water.
Addressing the Challenges
Effectively addressing the challenges in real-time data transmission requires a multifaceted approach that encompasses environmental, technical, and data-related considerations. Implementing robust and adaptive communication protocols is crucial for overcoming interference and signal degradation caused by weather conditions and physical obstacles. Selecting appropriate protocols, such as LoRa or ZigBee, with suitable range and penetration capabilities can ensure reliable data transmission in challenging agricultural environments (Motamedi & Villányi, 2022). Additionally, employing techniques like frequency hopping and error correction codes can further improve communication resilience and mitigate data loss.
Optimizing network architecture is another key consideration. Deploying a distributed network architecture with edge and fog computing capabilities can significantly enhance data processing and transmission efficiency (Abdel Nasser et al., 2020; Tran et al., 2019). Edge devices can perform initial data processing and aggregation tasks, reducing the amount of data transmitted to the cloud and minimizing latency, while fog nodes can provide additional processing power and storage closer to the data source, enhancing scalability and reliability. This distributed approach alleviates the burden on the central cloud server and allows for more responsive and efficient irrigation management.
Data optimization techniques play a vital role in reducing bandwidth requirements and improving transmission efficiency. The choice of data compression, aggregation, and filtering techniques should be tailored to the specific requirements of the irrigation system, considering factors such as data type, accuracy needs, and available bandwidth. By carefully selecting and implementing these techniques, the overall performance and effectiveness of real-time irrigation systems can be significantly enhanced, leading to more sustainable water management practices and improved agricultural productivity.
By addressing these challenges and implementing appropriate solutions, real-time data transmission can become a reliable and efficient component of automated irrigation systems, contributing to the overall goal of achieving sustainable and productive agriculture in the face of growing food demands and water scarcity.

3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
Real-time irrigation management systems heavily rely on the efficient and reliable transmission of data from sensors and weather stations to the cloud for processing and decision-making. However, agricultural environments present unique challenges to wireless communication, including adverse weather conditions, physical obstacles, and the limitations of wireless technologies. These challenges necessitate robust and adaptive solutions to ensure the consistent and timely flow of data, enabling truly autonomous irrigation scheduling.
Environmental factors, such as heavy rain, fog, and strong winds, can significantly disrupt wireless communication by attenuating or even blocking radio signals, leading to data loss and compromised system performance (Ed-daoudi et al., 2023; Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). Dense vegetation, buildings, and uneven terrain create further complications by causing multipath propagation and shadowing effects (Yim et al., 2018; Gautam and Pagay, 2020). The study by Yim et al. (2018) on LoRa networks in a tree farm environment exemplifies these challenges, revealing reduced communication range and data reliability compared to theoretical expectations. This underscores the need for carefully selecting and optimizing communication protocols and network parameters to ensure reliable data transmission in such environments.
The study by Guzinski et al. (2014a) using a modified TSEB model further highlights the importance of high-resolution data in accurately capturing the spatial and temporal dynamics of energy fluxes influenced by environmental factors. This emphasizes the need for advanced data acquisition and processing techniques that can effectively represent the complexities of agricultural settings.
The limitations of traditional wireless communication technologies, such as limited range and network congestion, pose additional challenges for large-scale agricultural operations. Long-distance data transmission can be hindered by range limitations, while network congestion arising from numerous sensors transmitting concurrently can lead to delays and data loss, hindering real-time decision-making (Hameed et al., 2020). Addressing these challenges requires the exploration of advanced networking technologies that can optimize spectrum utilization, mitigate interference, and improve reliability and efficiency.
Cognitive Radio Networks (CRNs) and Dynamic Spectrum Access (DSA) offer promising solutions for optimizing wireless communication in agricultural settings. CRNs empower devices with the ability to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). Research has explored the potential of CRNs in predicting Radio Frequency (RF) power to avoid noisy channels and optimize spectrum utilization (Iliya et al., 2014; Iliya et al., 2014). These studies demonstrate the effectiveness of combining optimization algorithms with artificial neural networks (ANNs) to enhance the accuracy and generalization of RF power prediction, enabling CRNs to make informed decisions about channel selection and avoid interference.
DSA complements CRN technology by dynamically allocating unused spectrum, further enhancing spectrum utilization and reducing congestion (Shi et al., 2023). The numerical model developed by Shi et al. (2023) showcases the potential of CRNs and DSA for optimizing wireless communication in challenging environments.
The integration of CRNs and DSA into the IoT network architecture requires careful consideration of spectrum sensing techniques, network topology, and data security. Research on cooperative spectrum sensing suggests that distributed approaches, where sensor nodes collaborate and share information, can significantly improve the accuracy and efficiency of spectrum sensing, particularly in dynamic environments (Trigka and Dritsas, 2022; Khalid & Yu, 2019). This collaborative approach enables a more comprehensive understanding of the radio environment and facilitates the identification of available frequency bands for data transmission.
The choice of network topology also impacts the performance and scalability of CRN-based irrigation systems. Mesh networks, where sensor nodes are interconnected and relay data for each other, offer enhanced resilience and coverage compared to star topologies where nodes communicate directly with a central gateway (Akyildiz & Vuran, 2010). However, mesh networks can be more complex to manage and may introduce additional routing overhead. The trade-off between network resilience and complexity needs to be carefully evaluated to select the most appropriate topology for a specific agricultural setting.
Data security and privacy are paramount concerns in IoT-based irrigation systems due to the sensitive nature of agricultural data (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential for protecting data integrity and ensuring system trustworthiness. Research on secure spectrum leasing and resource allocation algorithms for CR-WSN-based irrigation systems has demonstrated the potential of these technologies for enhancing security and efficiency (Hassan, 2023; Afghah et al., 2018).
In conclusion, the development of effective and reliable real-time irrigation management systems requires a comprehensive approach that addresses the challenges of data transmission in agricultural environments. The integration of robust and adaptive communication protocols, optimized network architectures, and advanced networking technologies like CRNs and DSA, along with a focus on data security and privacy, can contribute significantly to achieving the goal of autonomous and efficient irrigation scheduling.
4. AUTOMATED DATA PROCESSING IN THE CLOUD
4.1. Data Quality and Preprocessing
Data quality is paramount in automated irrigation systems as it directly influences the effectiveness of decision-making and water use efficiency. Issues like missing values, inconsistencies, and outliers arising from sensor malfunctions, environmental interference, or network problems (Lv et al., 2023) can significantly impact the performance of machine learning models used for irrigation scheduling and management.
Real-time data cleaning techniques are essential for addressing these challenges. Kalman filtering proves particularly effective in handling missing values and correcting erroneous readings by recursively estimating the system's state based on previous measurements and current sensor data, taking into account noise and uncertainty (Kim et al., 2020). Moving average techniques, by averaging consecutive data points, provide a more stable representation of the underlying trend, filtering out short-term fluctuations (Chhetri, 2023). For outlier detection, adaptive thresholding methods offer a dynamic approach, adjusting thresholds based on the statistical properties of the data to effectively identify anomalies and minimize false positives (Bah et al., 2021). These techniques are crucial in maintaining the integrity of real-time data streams and ensuring the accuracy of subsequent analyses.
Adaptive data preprocessing is essential for managing the diversity of data sources and formats commonly found in irrigation systems. Data normalization techniques, such as min-max scaling or z-score normalization, ensure that all features contribute equally to the analysis by transforming data values to a common scale (Pradal et al., 2016). This is crucial for preventing features with larger values from dominating the analysis and ensuring that all features are given equal consideration. Similarly, feature scaling methods, like standardization or normalization, optimize the range of feature values to improve the performance and convergence of machine learning models (Tortorici et al., 2024). By scaling features to a similar range, the influence of outliers is reduced, and the model's ability to learn from the data is enhanced.
Data fusion techniques play a critical role in integrating information from diverse sources, creating a more comprehensive and reliable dataset for irrigation management. Dempster-Shafer theory, a generalization of probability theory, allows for the expression of both uncertainty and the degree of conflict in evidence, making it suitable for fusing uncertain and conflicting data from heterogeneous sources (Sadiq and Rodriguez, 2004). This is particularly relevant in irrigation systems where data from different sensors may provide slightly different or even contradictory information due to sensor variations or environmental factors. Bayesian inference offers another powerful framework for combining information from multiple sources, updating the probability of a hypothesis as new evidence becomes available. By applying these techniques, data from soil moisture sensors, canopy temperature sensors, weather stations, and other sources can be integrated to provide a holistic understanding of crop water requirements and environmental conditions, leading to more informed and accurate irrigation decisions.
The impact of data quality extends beyond model accuracy to the robustness of machine learning models under varying conditions. Robust models should maintain consistent performance even when faced with data inconsistencies or unexpected situations. Techniques like data augmentation and domain adaptation can enhance model robustness by exposing the model to a wider range of data variations during training. Data augmentation involves generating additional training data by applying transformations or introducing noise to existing data, making the model more resilient to noise and variations in the real-world data. Domain adaptation techniques aim to adapt a model trained on one domain (e.g., a specific crop or geographic location) to perform well on another domain with different data characteristics. This is particularly relevant in irrigation management, where models may need to be applied to different crops, soil types, or climatic conditions.
The choice of data cleaning, preprocessing, and fusion techniques should be carefully considered based on the specific characteristics of the irrigation system and the available data. By selecting and implementing appropriate techniques, the accuracy, reliability, and robustness of machine learning models can be significantly improved, leading to more efficient and sustainable irrigation management practices.
4.2. Scalable and Autonomous Deployment using Containerization Strategies
The transition from data collection and transmission to efficient data processing requires a robust infrastructure capable of handling diverse workloads and data volumes. Containerization technologies, specifically Docker and Kubernetes, offer a promising solution for deploying and scaling data processing and machine learning modules within cloud environments like AWS, Azure, and GCP (Vargas-Rojas et al., 2024; Rosendo et al., 2022; Solayman & Qasha, 2023). Docker provides a standardized way to package applications and their dependencies into self-contained units known as containers, ensuring consistent and reproducible execution across different platforms (Rosendo et al., 2022). Kubernetes, acting as a container orchestrator, manages their deployment, scaling, and networking across a cluster of machines (Rosendo et al., 2022). This combination presents several advantages for automated irrigation management systems.
Firstly, containerization facilitates efficient resource utilization and scalability. By encapsulating applications and their dependencies, containers enable the isolation of resources and prevent conflicts between different modules (Vargas-Rojas et al., 2024; Solayman & Qasha, 2023). This isolation allows for the efficient allocation of resources, such as CPU, memory, and storage, to each container based on its specific needs. Kubernetes further enhances scalability by allowing for the automatic scaling of containers based on real-time demand, ensuring the system can adapt to varying workloads and data volumes, preventing bottlenecks, and ensuring responsiveness to changing conditions (Karamolegkos et al., 2023).
Secondly, containerization promotes portability and reproducibility. By packaging applications and their dependencies into a single unit, containers make it easy to move and deploy them across different cloud environments without the need for environment-specific configurations (Rosendo et al., 2022; Solayman & Qasha, 2023). This portability simplifies the development and deployment process, reducing the time and effort required to set up and manage the system. Additionally, containers ensure reproducibility by providing a consistent execution environment, regardless of the underlying infrastructure. This eliminates variability and ensures that the system will behave consistently across different deployments (Zhou et al., 2023).
Optimizing container orchestration and resource allocation is crucial to minimizing latency and maximizing throughput in real-time data processing pipelines. Techniques like auto-scaling and dynamic resource allocation play a critical role in this context (Hethcoat et al., 2024; Werner and Tai, 2023; Kumar et al., 2024). Auto-scaling automatically adjusts the number of container instances based on real-time demand, ensuring that sufficient resources are available to handle peak workloads while avoiding over-provisioning during periods of low demand (Hethcoat et al., 2024; Kumar et al., 2024). Dynamic resource allocation enables the fine-grained adjustment of resources allocated to each container based on its specific needs and the current workload (Werner and Tai, 2023). This ensures efficient resource allocation and provides each container with the necessary resources to perform its tasks effectively.
Performance monitoring tools, such as Kubernetes Metrics Server and Prometheus, are essential for gaining insights into the performance of containers and the overall system (Hethcoat et al., 2024; Kuity & Peddoju, 2023). These tools provide valuable data on key performance indicators, such as CPU and memory usage, network traffic, and application-specific metrics. By monitoring this data, administrators can identify bottlenecks, optimize resource allocation strategies, and continuously improve system performance (Hethcoat et al., 2024). This data-driven approach ensures that automated irrigation management systems can operate efficiently and reliably.
By integrating containerization technologies with optimization techniques and performance monitoring, automated irrigation management systems achieve the scalability, autonomy, and efficiency required for effective real-time data processing and decision-making. This approach facilitates a seamless and responsive system that can adapt to changing conditions and contribute to the overall goal of optimizing water resource management and increasing agricultural productivity.

4.3. Deploying ML Models for Data Processing
Transitioning from data collection, preprocessing, and transmission, the deployment of machine learning (ML) models marks a pivotal stage in the automated irrigation management pipeline. This stage entails utilizing cloud platforms to facilitate real-time data processing and inference, enabling data-driven decision-making for optimal irrigation management and ultimately contributing to fully autonomous, scalable irrigation management.
Several architectures and frameworks exist for deploying ML models on cloud platforms, each offering unique advantages and catering to different requirements. TensorFlow Serving, for instance, provides a high-performance system specifically designed for serving TensorFlow models (Abadi et al., 2016). This framework enables efficient and scalable inference, making it suitable for real-time applications where low latency and high throughput are crucial. For instance, in a large-scale irrigation system with numerous sensors generating data continuously, TensorFlow Serving can efficiently handle the high volume of inference requests and provide timely predictions for irrigation scheduling. Similarly, Apache MXNet Model Server offers a flexible and efficient solution for deploying models trained with MXNet, supporting a wide range of deep learning models and inference backends (MXNet Developers, 2015). This versatility makes it suitable for complex irrigation systems that may utilize different types of ML models for various tasks, such as predicting crop water requirements, detecting plant stress, or forecasting weather conditions. ONNX Runtime, on the other hand, provides a cross-platform inference engine compatible with various ML frameworks, including PyTorch, TensorFlow, and MXNet (Microsoft, 2017). This versatility enables the deployment of models in diverse environments, facilitating interoperability and reducing the need for model conversion. For example, an irrigation system that uses models trained in different frameworks can utilize ONNX Runtime to deploy them on a single platform without the need for time-consuming and error-prone model conversion processes.
Choosing the appropriate architecture or framework depends on several factors, including the specific ML framework used for model training, the desired level of performance and scalability, and the need for cross-platform compatibility. For instance, if the primary concern is low latency and high throughput for real-time inference, TensorFlow Serving might be the optimal choice for TensorFlow models. However, if flexibility and support for various deep learning models are required, Apache MXNet Model Server could be more suitable. In cases where cross-platform compatibility is essential, ONNX Runtime offers a versatile solution.
Once the ML model is deployed, optimizing its performance and resource utilization becomes crucial for ensuring the efficiency of integrated end-to-end automated irrigation systems. Model compression techniques, such as pruning and quantization, offer effective methods for reducing the size and computational requirements of ML models without compromising accuracy (Premkumar & Sigappi, 2022). Pruning involves eliminating unnecessary connections or neurons from the model, effectively streamlining its structure and reducing computational complexity. This can be particularly beneficial for deep learning models, which often have a large number of parameters and can be prone to overfitting. By removing redundant or less important connections, pruning can improve modelgeneralizability and reduce inference time. Quantization, on the other hand, involves reducing the precision of model parameters, typically from 32-bit floating-point numbers to lower-precision formats such as 8-bit integers. This reduction in precision leads to smaller model sizes and faster inference speeds, making it particularly beneficial for resource-constrained environments or real-time applications. For instance, in edge computing scenarios where ML models are deployed on devices with limited computational resources, quantization can enable efficient inference without sacrificing accuracy.
Furthermore, hardware acceleration through the utilization of GPUs or TPUs can significantly enhance model performance by leveraging specialized hardware designed for parallel processing (Premkumar & Sigappi, 2022). GPUs, with their massive parallelism and high memory bandwidth, excel at accelerating matrix operations and convolutions, which are fundamental computations in many deep learning models. This acceleration can significantly reduce inference time and enable real-time processing of sensor data for timely irrigation decisions. TPUs, specifically designed for deep learning workloads, offer even greater performance and energy efficiency for specific model architectures. These hardware accelerators can drastically reduce inference time, enabling near real-time decision-making and enhancing the responsiveness of automated irrigation systems. For example, in a scenario where immediate response to changing weather conditions or soil moisture levels is critical, hardware acceleration can ensure that irrigation decisions are made and executed promptly.
In addition to model compression and hardware acceleration, distributed training techniques play a crucial role in optimizing the training process for large-scale ML models. Techniques such as Horovod and BytePS enable the distribution of training across multiple machines, effectively parallelizing the process and reducing training time (Premkumar & Sigappi, 2022). This is particularly beneficial for complex models with a large number of parameters or when dealing with large datasets. By leveraging distributed training, irrigation management systems can train more sophisticated models and improve their predictive capabilities, leading to more accurate and efficient irrigation decisions. For instance, a system that utilizes a deep learning model with millions of parameters can benefit from distributed training to reduce training time from days to hours, enabling faster model iteration and improvement.
Integrating the deployed ML models with other components of the automated irrigation management pipeline is essential for achieving a fully autonomous and cohesive system and addressing the need for seamless integration across the automated irrigation management system. Standardized protocols, such as MQTT and CoAP, provide lightweight and efficient communication channels for exchanging data between these components (Poojara et al., 2023; Jimenez et al., 2020a; Gour et al., 2023). MQTT, with its publish-subscribe architecture, enables real-time data streaming and event-driven communication, making it suitable for transmitting sensor data, control signals, and inference results (Raikar & M, 2023). This enables the ML model to receive real-time updates on soil moisture, weather conditions, and plant health, allowing for dynamic adjustments to irrigation schedules based on the latest data. CoAP, designed for constrained devices and low-power networks, offers a web-transfer protocol for resource-constrained environments, enabling efficient communication between sensors, actuators, and the ML models (Raikar & M, 2023). This is particularly relevant in situations where sensors or actuators have limited processing power or battery life, as CoAP minimizes communication overhead and energy consumption. Additionally, RESTful APIs provide a standardized interface for accessing and controlling the ML models, enabling seamless integration with other software components and facilitating system management and monitoring (Wang et al., 2022). This allows for easy integration with existing farm management systems or third-party applications, creating a unified platform for comprehensive irrigation management.4.4. Online Learning in the Cloud
The complexities of real-time data processing in irrigation management necessitate the exploration of advanced techniques to continuously learn and adapt to the dynamic nature of agricultural environments. Online learning algorithms offer a promising solution, enabling the continuous update and improvement of machine learning models based on incoming real-time data. This adaptability is crucial for addressing the challenges of changing environmental conditions, such as weather patterns and crop growth stages, and optimizing irrigation decision-making to enhance water usage efficiency and crop productivity.
Several online learning algorithms have demonstrated potential for real-time data processing and model adaptation in the context of irrigation management. Stochastic Gradient Descent (SGD) facilitates the incremental update of model parameters with each new data point, allowing for efficient adaptation to changing data distributions (Bottou, 2010). This incremental learning process ensures that the model remains responsive to the latest conditions, minimizing the risk of outdated predictions and improving the accuracy of irrigation decisions. Passive-Aggressive algorithms, on the other hand, adjust model parameters only when a misclassification occurs, providing a computationally efficient approach for handling large data streams (Crammer et al., 2006). These algorithms offer a robust approach to handling noisy data, a common challenge in real-world sensor readings, by making small adjustments only when the model's prediction deviates significantly from the actual value (Fei et al., 2019). Online Random Forests extend the concept of random forests to the online setting, enabling the incremental construction and update of decision trees as new data arrives (Saffari et al., 2009). The continuous evolution of the ensemble ensures that the model remains relevant to the changing environment, capturing intricate relationships between variables and leading to more informed irrigation decisions.
Research in various domains highlights the importance of online learning for real-time data stream analytics. Snyder et al. (2020) explored the application of online learning techniques for identifying relevant tweets in real-time, improving situational awareness for first responders. The proposed interactive learning framework allows users to continuously label the relevance of incoming tweets, enabling the real-time refinement of the underlying machine learning model. This user-guided approach aligns well with the dynamic nature of irrigation management, where models need to continuously adjust to varying environmental conditions and crop water requirements. Similarly, research in the field of cyber-physical systems (CPS) underscores the need for online learning algorithms to effectively extract insights and knowledge from continuously generated data streams (Fei et al., 2019). These capabilities are crucial for enabling feedback loops between physical processes and cyber elements, facilitating the integration and optimization of CPS in irrigation management systems.
To implement online learning in cloud-based irrigation management systems, various architectures and frameworks can be considered. Apache Spark Streaming, Apache Flink, and AWS Kinesis provide scalable and fault-tolerant platforms for processing real-time data streams, allowing for the development of online learning pipelines that continuously ingest and analyze data to update machine learning models (Zaharia et al., 2012; Carbone et al., 2015; Amazon Web Services, 2023). These frameworks leverage serverless computing paradigms, automatically scaling resources based on the volume and velocity of incoming data, ensuring efficient resource utilization and responsiveness to fluctuations in demand (Fei et al., 2019).
Effectively managing the exploration-exploitation trade-off is crucial for optimizing online learning in irrigation management. Techniques such as Multi-armed bandits (Sutton & Barto, 2018), Bayesian optimization (Shahriari et al., 2016), and Reinforcement Learning (RL) (Sutton & Barto, 2018) can be employed to balance the allocation of resources between exploring new irrigation strategies and exploiting the current best-performing approaches. These techniques enable the identification of optimal irrigation policies, adapting to changing environmental conditions and maximizing long-term rewards.
In conclusion, online learning techniques, coupled with scalable cloud-based architectures, offer a powerful solution for real-time data processing and continuous adaptation in irrigation management systems. By leveraging algorithms like SGD, Passive-Aggressive, and Online Random Forests, along with stream processing frameworks like Apache Spark Streaming, Apache Flink, and AWS Kinesis, irrigation management systems can effectively handle the complexities of real-time data, optimize water usage, and enhance crop productivity in the face of dynamic environmental conditions.

5. GENERATING AND APPLYING IRRIGATION INSIGHTS 
5.1. Real-Time Generation of Actionable Irrigation Insights
•	Advanced predictive models, such as deep learning (e.g., LSTM, CNN) and ensemble methods (e.g., Random Forests), for precise, site-specific irrigation recommendations
•	Integration of IoT sensor data (e.g., soil moisture probes, weather stations) and cloud-based data sources (e.g., weather forecasts, satellite imagery) using data fusion techniques (e.g., Kalman filtering) to enhance insight accuracy and resolution
•	Strategies for handling data heterogeneity, uncertainty, and quality issues in real-time insight generation, such as data preprocessing and outlier detection
•	Techniques for reducing computational complexity and latency, such as edge computing (e.g., fog computing), model compression (e.g., quantization), and hardware accelerators (e.g., GPUs)
5.2. Automated Application of Irrigation Insights
•	Architectures and protocols for seamless integration of ML-generated insights with IoT-enabled irrigation control systems, such as MQTT and CoAP for lightweight, real-time communication
•	Analysis of industry-leading products and services, such as smart irrigation controllers (e.g., Rachio) and cloud-based irrigation management platforms (e.g., CropX)
•	Strategies for ensuring reliability, security, and scalability of automated insight application, such as redundant communication channels and secure edge-to-cloud architectures
•	Case studies of successful implementations of closed-loop, autonomous irrigation systems in research and commercial settings, highlighting technologies used and benefits achieved

6. INTEGRATION, INTEROPERABILITY, AND STANDARDIZATION 
6.1. Interoperability and Standardization
•	Importance of interoperability and standardization in enabling seamless integration of automated irrigation components
•	Overview of existing and emerging standards for IoT devices, communication protocols, and data formats in precision agriculture (e.g., ISOBUS, agroXML, SensorML)
•	Role of standardization bodies and industry consortia in promoting interoperability (e.g., AgGateway, Open Ag Data Alliance, Agricultural Industry Electronics Foundation)
•	Challenges in adopting and implementing standards across diverse hardware and software platforms
•	Strategies for encouraging widespread adoption of standards and best practices for interoperability in automated irrigation systems
6.2. Integration with Existing Irrigation Infrastructure
•	Challenges and strategies for retrofitting legacy irrigation systems with IoT sensors, actuators, and communication devices
•	Hardware compatibility issues and solutions (e.g., adapters, modular designs)
•	Software and firmware updates to enable integration with automated decision-making systems
•	Data integration and normalization techniques for merging legacy and new data sources
•	Economic and practical considerations for transitioning from manual to automated irrigation management
•	Cost-benefit analysis of upgrading existing infrastructure vs. implementing new systems
•	Phased implementation approaches to minimize disruption and optimize resource allocation
•	Training and support requirements for farmers and irrigation managers adopting automated systems
•	Case studies and real-world examples of successful integration of automated irrigation with existing infrastructure
6.3. Integration with Other Precision Agriculture Technologies
•	Synergies between automated irrigation and complementary technologies
•	Remote sensing (satellite, UAV, and ground-based) for crop monitoring and evapotranspiration estimation
•	Soil moisture sensors and weather stations for real-time, localized data collection
•	Variable rate application systems for precise irrigation delivery based on crop requirements
•	Yield mapping and analytics for assessing the impact of automated irrigation on crop productivity
•	Architectures and frameworks for integrating diverse data sources and technologies into a unified precision agriculture ecosystem
•	Edge computing and fog computing paradigms for real-time data processing and decision-making
•	Cloud-based platforms for data storage, analysis, and visualization
•	API-driven approaches for modular integration of third-party services and applications
•	Challenges and solutions for ensuring data quality, consistency, and security across integrated precision agriculture systems
•	Data cleaning, preprocessing, and harmonization techniques
•	Blockchain and distributed ledger technologies for secure, tamper-proof data sharing and traceability
•	Access control and authentication mechanisms for protecting sensitive data and resources
•	Future trends and research directions in the integration of automated irrigation with advanced precision agriculture technologies (e.g., AI-driven crop modeling, robotics, and autonomous vehicles)
6.4. Cybersecurity Considerations for Integrated Automated Irrigation Systems
•	Unique security risks and vulnerabilities associated with IoT-based automated irrigation systems
•	Potential for unauthorized access, data tampering, and system manipulation
•	Implications of security breaches for crop health, water resource management, and farm productivity
•	Best practices and strategies for securing automated irrigation systems
•	Secure device provisioning and authentication (e.g., hardware security modules, certificates)
•	Encryption and secure communication protocols (e.g., TLS, DTLS)
•	Firmware and software updates to address emerging security threats
•	Network segmentation and access control to limit the impact of breaches
•	Role of cybersecurity standards and frameworks in guiding the development and deployment of secure automated irrigation systems (e.g., NIST CSF, IEC 62443)
•	Importance of user awareness, training, and incident response planning in maintaining the security of integrated automated irrigation systems

7. MONITORING AND ENSURING SYSTEM RELIABILITY
7.1. Resilience and Fault Tolerance in Automated Irrigation Systems
•	Strategies for ensuring robustness and reliability in the face of failures, disruptions, or unexpected events
•	Redundancy: Implementing redundant components, such as duplicate sensors (e.g., soil moisture sensors, weather stations), controllers (e.g., PLCs, microcontrollers), and communication channels (e.g., cellular, satellite, LoRaWAN) to maintain system functionality during component failures
•	Failover mechanisms: Designing seamless failover mechanisms that automatically switch to backup components or systems in case of primary system failure, such as hot-standby controllers or multi-path communication protocols (e.g., mesh networks, software-defined networking)
•	Self-healing capabilities: Incorporating AI-driven self-healing mechanisms that can detect, diagnose, and recover from faults without human intervention, using techniques like reinforcement learning, Bayesian networks, or self-organizing maps
•	The role of distributed architectures and edge computing in enhancing system resilience
•	Decentralizing critical functions and data processing to minimize the impact of single points of failure, using fog computing or multi-agent systems
•	Leveraging edge computing to enable localized decision-making and control, reducing dependence on cloud connectivity and improving response times, using technologies like Raspberry Pi, NVIDIA Jetson, or Intel NUC
•	Anomaly detection and predictive maintenance using AI techniques
•	Employing unsupervised learning algorithms (e.g., autoencoders, clustering) to detect anomalies in sensor data, system performance, and water usage patterns
•	Developing predictive maintenance models using techniques like long short-term memory (LSTM) networks, convolutional neural networks (CNNs), or gradient boosting machines (GBMs) to anticipate and prevent potential system failures based on historical data and real-time monitoring
7.2. Advanced Monitoring Techniques for Automated Irrigation Systems
•	Remote monitoring using IoT-enabled sensors and computer vision
•	Deploying a heterogeneous network of IoT sensors to collect real-time data on soil moisture (e.g., capacitive, tensiometric), temperature (e.g., thermocouples, thermistors), humidity (e.g., capacitive, resistive), and plant health (e.g., sap flow, leaf wetness)
•	Integrating high-resolution cameras (e.g., multispectral, hyperspectral) and computer vision algorithms for visual monitoring of crop growth, disease detection (e.g., using deep learning-based object detection and segmentation), and irrigation system performance (e.g., leak detection, sprinkler uniformity)
•	Transmitting sensor and camera data to cloud-based platforms (e.g., AWS IoT, Google Cloud IoT, Microsoft Azure IoT) for remote access and analysis using protocols like MQTT, CoAP, or AMQP
•	Innovative approaches for real-time system health assessment
•	Developing novel algorithms and metrics for evaluating the health and performance of automated irrigation systems, such as entropy-based measures, network resilience indices, or multi-criteria decision analysis (MCDA) frameworks
•	Combining data from multiple sources (e.g., sensors, weather forecasts, satellite imagery) using data fusion techniques (e.g., Kalman filters, Dempster-Shafer theory) to create a comprehensive view of system health
•	Employing advanced data visualization techniques (e.g., interactive dashboards, augmented reality) to present system health information in an intuitive and actionable format
7.3. Closed-Loop Control and Feedback Mechanisms
•	Exploring the concept of closed-loop control in autonomous irrigation systems
•	Implementing feedback loops that continuously monitor system performance and adjust irrigation schedules based on real-time data, using control techniques like proportional-integral-derivative (PID), model predictive control (MPC), or fuzzy logic control (FLC)
•	Integrating machine learning algorithms (e.g., reinforcement learning, genetic algorithms) to optimize closed-loop control strategies over time, adapting to changing environmental conditions and crop requirements
•	Designing effective feedback mechanisms for user interaction and system optimization
•	Providing user-friendly interfaces (e.g., mobile apps, web dashboards) for farmers to input preferences, constraints, and expert knowledge into the automated irrigation system, using techniques like participatory design or user-centered design
•	Incorporating user feedback and domain expertise to refine irrigation strategies and improve system performance
8. CASE STUDIES AND REAL-WORLD IMPLEMENTATIONS OF FULLY AUTONOMOUS IRRIGATION SYSTEMS
8.1. Fully Autonomous Irrigation Systems in Diverse Agricultural Settings
•	Row Crops: maize, wheat, soybean with real-time soil moisture monitoring and weather-based irrigation scheduling for fully automated precision irrigation
•	Orchards: citrus, apple, almond with plant health monitoring and precision water application for fully autonomous orchard management
•	Greenhouses: tomato, lettuce, herbs with automated drip irrigation and climate control integration for fully automated greenhouse operations
•	Urban Farming: rooftop gardens, vertical farms with IoT-enabled hydroponic systems and remote management for fully autonomous urban crop production
8.2. Integration of Advanced System Components for End-to-End Automation
•	Wireless sensor networks: soil moisture probes, weather stations, plant health monitoring cameras with low-power, long-range communication for fully automated data acquisition
•	Secure data transmission: LoRaWAN, NB-IoT, 5G, satellite communication for reliable, real-time data transfer from field to cloud in fully autonomous irrigation systems
•	Intelligent data processing: edge computing for local data filtering, cloud platforms for scalable storage and analysis, machine learning algorithms for predictive insights in fully automated irrigation management
•	Autonomous decision-making: advanced irrigation scheduling algorithms, precise valve control, closed-loop feedback systems for optimal water management in fully autonomous irrigation systems
8.3. Quantitative Performance Evaluation of Fully Automated Irrigation Systems
•	Water use efficiency: percent reduction in water consumption compared to conventional methods, improved water productivity (yield per unit of water) achieved through fully autonomous irrigation
•	Crop yield and quality improvements: percent increase in yield, enhanced crop uniformity, improved nutritional content attributed to fully automated precision irrigation
•	Labor and energy savings: quantified reduction in labor hours for irrigation management, decreased energy consumption for pumping due to optimized scheduling in fully autonomous systems
•	Economic viability: detailed return on investment analysis, payback period calculations, comprehensive cost-benefit analysis for fully autonomous irrigation management systems
8.4. Lessons Learned and Challenges Encountered in Deploying Autonomous Irrigation Systems
•	Technical challenges and solutions: ensuring reliable data transmission in remote locations, addressing interoperability issues between diverse system components, optimizing power consumption for extended battery life, adapting algorithms to local soil and weather conditions in fully autonomous irrigation systems
•	Operational and logistical hurdles: streamlining installation and maintenance procedures, providing effective user training, seamlessly integrating with existing farm management practices and legacy systems for fully automated irrigation management
•	Regulatory and socio-economic considerations: navigating complex water use regulations, addressing data privacy and security concerns, ensuring equitable access and affordability for smallholder farmers adopting fully autonomous irrigation technologies
8.5. Best Practices and Recommendations for Successful Implementation
•	Designing scalable, modular, and adaptable autonomous irrigation systems to accommodate future growth and changing requirements for fully automated water management
•	Prioritizing user-centered design principles and actively engaging stakeholders throughout the development and deployment process of fully autonomous irrigation solutions
•	Adopting open standards and communication protocols to enable seamless integration of system components and interoperability with third-party platforms in fully automated irrigation setups
•	Implementing robust data validation, filtering, and quality control mechanisms to ensure data integrity and reliability for decision-making in fully autonomous irrigation systems
•	Establishing clear data governance policies and security frameworks to protect sensitive information and maintain user trust in fully automated irrigation management
•	Developing intuitive user interfaces and decision support tools to facilitate easy adoption and effective use of fully autonomous irrigation systems
•	Collaborating with local extension services, agribusinesses, and technology providers for knowledge transfer, technical support, and continuous improvement of fully automated irrigation solutions
8.6. Synthesis of Case Studies and Implications for Autonomous Irrigation Adoption
•	Cross-case analysis of key performance indicators and critical success factors for fully autonomous irrigation scheduling systems in various contexts
•	Identification of common themes, challenges, and innovative solutions across diverse implementations of end-to-end fully automated irrigation management
•	Assessment of the potential for replicability and scaling of successful fully autonomous irrigation projects in different regions and farming systems
•	Implications for future research priorities, technology development roadmaps, and policy interventions to support widespread adoption of fully autonomous irrigation technologies

CONCLUSION/FUTURE DIRECTIONS AND UNANSWERED QUESTIONS
•	Summarize the key insights gained from the question-driven review, emphasizing how each section contributes to the overarching goal of achieving real-time, end-to-end automation in irrigation management
•	Based on the questions addressed, propose new research directions and unanswered questions
•	Identify key research gaps and propose concrete research questions and hypotheses for advancing the field of real-time, automated irrigation management
•	Highlight the need for collaborative research efforts across disciplines, such as computer science, agricultural engineering, and environmental science, to address the complex challenges of automated irrigation systems
•	Emphasize the need for further innovation and exploration in real-time, automated irrigation systems




</previous_sections>

</documents>
<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper. 

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: stated in: <subsection_title>
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>

<subsection_point_Point 7>
Point: Leveraging edge computing to enable localized decision-making and control, reducing dependence on cloud connectivity and improving response times, using technologies like Raspberry Pi, NVIDIA Jetson, or Intel NUC

Papers to support point:

Paper 1:
- APA Citation: Erazo-Mesa, E., Murillo-Sandoval, P. J., Ramírez-Gil, J. G., Quiroga Benavides, K., & Echeverri Sánchez, A. (2023). IS-SAR: An irrigation scheduling web application for Hass avocado orchards based on Sentinel-1 images. Irrigation Science, 1-18.
  Main Objective: To develop and evaluate an irrigation scheduling web application (IS-SAR) for Hass avocado orchards based on Sentinel-1 satellite images.
  Study Location: Valle del Cauca, Colombia
  Data Sources: Field data collected from monitoring trees in the study area, Sentinel-1 satellite images
  Technologies Used: Sentinel-1 satellite images, Water Cloud Model (WCM), Artificial Neural Network (ANN)
  Key Findings: - The ANN model outperformed the WCM in estimating surface soil water content.
- The IS-SAR web application provided accurate irrigation recommendations, in line with the observed soil water dynamics and applied irrigation.
  Extract 1: The IS-SAR web application combines a calibrated Water Cloud Model (WCM) and an Artificial Neural Network (ANN) to estimate surface soil water content and assist farmers in optimizing irrigation schedules. The application uses Sentinel-1 (S1) satellite images, acquired with a revisiting time of 7 days, to monitor soil water content in avocado orchards.
  Extract 2: The authors evaluated the performance of the WCM and ANN models using field data collected from monitoring trees in the study area. The results showed that the ANN model outperformed the WCM, with a lower Root Mean Square Error (RMSE) and higher correlation coefficient. The IS-SAR web application was further evaluated by simulating irrigation events in three avocado plots over a 5-month period. The results demonstrated that the application provided accurate irrigation recommendations, in line with the observed soil water dynamics and applied irrigation.
  Limitations: The study is limited to a specific region (Colombia) and crop (Hass avocado) and may not be directly applicable to other regions or crops without further calibration and validation. Additionally, the accuracy of the IS-SAR application is dependent on the quality of the S1 satellite data and may be affected by factors such as cloud cover and vegetation density.
  Relevance Evaluation: Exceptionally relevant - Comprehensively addresses all key aspects of the point with highly insightful, reliable, and up-to-date information and a must-include for the review.
  Relevance Score: 1.0
  Inline Citation: (Erazo-Mesa et al. 2023)
  Explanation: The study by Edwin Erazo-Mesa and colleagues (2023) presents the development of an irrigation scheduling web application, called IS-SAR, for Hass avocado orchards in Colombia, utilizing Sentinel-1 (S1) satellite images. The web application leverages a calibrated Water Cloud Model (WCM) and an Artificial Neural Network (ANN) to estimate surface soil water content and assist farmers in optimizing irrigation schedules.

 Full Text: >
"Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Log in Find a journal Publish with us Track your research Search Cart Home Irrigation Science Article IS-SAR: an irrigation scheduling web application for Hass avocado orchards based on Sentinel-1 images Original Paper Open access Published: 23 November 2023 (2023) Cite this article Download PDF You have full access to this open access article Irrigation Science Aims and scope Submit manuscript Edwin Erazo-Mesa , Paulo J. Murillo-Sandoval , Joaquín Guillermo Ramírez-Gil , Kevin Quiroga Benavides & Andrés Echeverri Sánchez   763 Accesses 2 Altmetric Explore all metrics Abstract As the Hass avocado crop expands exponentially in Colombia, concern about its increasing water use is on the rise. This research aimed to develop IS-SAR, a free-access web application to schedule irrigation for Valle del Cauca’s Hass growers. We calibrated the water cloud (WCM) and artificial neural network (ANN) models using field data measurements from Hass avocado orchard plots in Valle del Cauca (Colombia) and Sentinel 1 (S1) satellite imagery measurements and evaluated their performance computing the root-mean-square error (RMSE) and Pearson correlation coefficient ( ). IS-SAR estimates the surface soil water content from the most recent S1 image, becomes it in water depth, and recommends to users apply irrigation according to allowable depletion limits, computed from a spatially distributed at field capacity and permanent wilting point obtained from a soil database of the study area. Our results indicate that the surface soil water content was retrieved with a better performance by the ANN (RMSE = 0.05 m3 m−3, ), compared with the WCM (RMSE = 0.06 m3 m−3, ). IS-SAR simulations in validation orchard plots result in irrigation events of up to 107 L tree−1 for 3.4 h. The IS-SAR web application provides near-real-time irrigation information to assist Hass avocado growers in designing better irrigation routines and improving the regional understanding of water crop consumption. Similar content being viewed by others Producing Mid-Season Nitrogen Application Maps for Arable Crops, by Combining Sentinel-2 Satellite Images and Agrometeorological Data in a Decision Support System for Farmers. The Case of NITREOS Chapter © 2020 Exploring the Potential of Remote Sensing in Irrigation Management at District Scale. Study on Lis Valley, Portugal Chapter © 2021 DRAINMOD Applications to Design Drainage Systems in Libya Using Soil Salinity Data Predicted by GIS, Remote Sensing and Artificial Neural Networks Chapter © 2022 Introduction In a world demanding immediate actions for solving the water crisis (Naddaf 2023), implementing irrigation scheduling (IS) technologies could significantly contribute to efficient water use in agriculture (Zinkernagel et al. 2020). When farmers schedule irrigation, they are unaware that the water volume used to produce a kilogram of food would meet household water consumption per capita for several months (Mekonnen and Hoekstra 2020; Bo et al. 2021). This situation indicates a clear disparity between the level of water used by agriculture and that used by others (Flörke et al. 2018; Wang et al. 2023). The core of the most commonly used IS methods has remained invariable over time; using these methods requires acquiring specialized equipment, handling large volumes of climate data, measuring soil properties, or managing software (Gu et al. 2020). Innumerable farmers worldwide lack technical knowledge, economic, or access-to-data capabilities to perform any of these IS methods for their crops (Yohannes et al. 2019; Berthold et al. 2021). All these limitations are also evident for Hass avocado growers in Colombia. Beyond the economic benefits propelled by the rising global demand for Hass avocados, the volume of water required for their production in Colombia has grown exponentially. In 2018, Colombian Hass avocado production represented an estimated total water footprint of approximately 300 Mm3 (Sommaruga and Eldridge 2020); and in 2016, exported virtual water trade was 31 Mm3 (Caro et al. 2021). Although rainfall is the main source of water for the crop (Erazo-Mesa et al. 2021), supplementary water from irrigation is needed to reach optimal fruit development (Grajales 2017). Moreover, Diaz et al. (2021) identified a gap between incipient avocado growers' water management knowledge and the newest irrigation technologies. (Díaz et al. 2021), and regional environmental agencies have reported an increase in requests for crop irrigation water concessions (CVC 2021). One way to track IS parameters, bypassing some limitations of traditional IS methods, is through remote-sensing (RS) technologies (Tolomio and Casa 2020). RS technologies, scaled down to easy-to-use, cheap or free-access, and wide-coverage tools, have been demonstrated to be powerful tools for irrigators (Erazo-Mesa et al. 2022a). Synthetic-aperture radar (SAR) images have shown promising results for estimating the surface soil water content (SSWC), the water content in the first 5–10 cm of the soil depth (Li et al. 2021), at local and regional scales (Peng et al. 2021). SAR images have been used to estimate the occurrence of irrigation events, detect and map irrigated areas, and quantify applied volumes of water at a regional scale by employing SAR satellite projects for soil moisture and ocean salinity (SMOS), soil moisture active passive (SMAP), and advanced microwave scanning radiometer 2 (AMSR2) (Jalilvand et al. 2019; Dari et al. 2021) and at a plot scale using the Sentinel-1 (S1) project (Bousbih et al. 2018; Le Page et al. 2020; Ouaadi et al. 2020). Bousbih et al. (2018) and Han et al. (2020) estimated the SSWC using the water cloud model (WCM) for nonorchard crops, obtaining root-mean-square error (RMSE) values lower than 6.4 and 3.16% (Vol), respectively. Among the current challenges of using SAR images to schedule irrigation are the satellite revisit time, which is on average 4 days in countries at the equator, and the lack of correspondence between the effective root depth of some crops (for Hass avocados is 60 cm) and the superficial estimation of SSWC (Peng et al. 2021). To counterbalance the first limitation, some RS-based IS applications forecast irrigation parameters (Montgomery et al. 2015; Brinkhoff et al. 2019). Regarding the second limitation, some studies have modeled the soil water content at the root zone from SSWC for wheat (Babaeian et al. 2021) and Hass avocados (Erazo-Mesa et al. 2022b). Hass avocado growers could take advantage of SAR images, because SSWC dynamics are directly related to the superficial distribution of tree roots (Lahav and Whiley 2002), a thin layer of litter on the soil surface near the trunk in some cultures which retains moisture (Bernal-Estrada et al. 2020), coarse soils and irrigation systems (Salgado and Cautín 2008), and dense canopy during the productivity period (Bernal and Díaz 2020). This research aims to develop an irrigation scheduling web application for Hass avocado orchards located in Valle del Cauca (Colombia) based on S1 images. Theoretical background The development and successful implementation of IS-SAR required a robust theoretical foundation associated with the SSWC, WCM, Artificial Neural Networks (ANNs), and irrigation scheduling concepts. A comprehensive theoretical background is essential for multiple reasons. First, it underpins our understanding of the underlying principles and mechanisms governing soil water dynamics, which is fundamental to precise irrigation management. Second, a solid theoretical foundation allows for the informed selection and integration of the Water Cloud and ANN models, ensuring the accuracy and reliability of our approach. Third, it enables the development of effective irrigation scheduling strategies that optimize water resource utilization while minimizing environmental impacts. Soil surface water content (SSWC) Precise measurements of available water in the root zone are required for irrigation scheduling of crops. However, accounting for accurate estimations of soil water content in space and time at plot, farm, and regional scales is challenging. Microwave measurements from SAR satellites have demonstrated being sensitive to backscattering properties of the soil surface by which these can detect soil water content changes from topsoil (Karthikeyan et al. 2017). The radar sensor's soil cover type and wavelength mainly determine the depth at which the soil water content can be estimated (Babaeian et al. 2019). According to Babaeian et al. (2019), the theoretical penetration of the C-band signal, used here through the Sentinel-1 project, reaches 1.5 cm for agricultural soils. However, some studies have compared soil water content measurements in a range of 0–12 cm of soil depth with a backscattering coefficient from Sentinel-1 obtaining reasonable correlations (Bousbih et al. 2018; Han et al. 2020; Ouaadi et al. 2020). We define SSWC as the water content in the first 10 cm of the soil depth (Li et al. 2021). Erazo-Mesa et al. (2022b) studied the influence of soil water content ( ) at several depth ranges on the soil water balance at depths of 0–60 cm ( ) for three Hass avocado orchard plots in Valle del Cauca (Colombia) and determined that the 5–10 cm range depth correlated better with the soil water balance, which is named here as . Water cloud model (WCM) WCM describes how the microwave signal backscatters on vegetation–soil–water systems, representing the vegetation canopy as a cloud with identical droplets randomly distributed within the canopy. Initially introduced by Attema and Ulaby (1978) and with some variants from the original (Ouaadi et al. 2020), this semiempirical model splits the total backscattering coefficient from SAR images to a determined polarization ( ) (for this study VV and VH) and radar signal incidence angle into the microwave signal backscattered by vegetation , soil , and the soil-vegetation interphase (usually neglected) (Eq. 1) (1) Canopy structure, leaf size and distribution, and vegetation water content influence the strength, and their effects are indiscriminately introduced in the WCM by parameters and (Eq. 2 and 4) (Prévot et al. 1993). Parameter is usually computed from the leaf area index (LAI) using the function , where is a parameter to find in the model calibration, and is LAI (Han et al. 2020). Due to the heterogeneity of vegetation–soil–water systems, the impact of the surface soil backscattered signal is adjusted by a two-way vegetation attenuation effect and added to the WCM through the value. depends on surface roughness (inferred from parameters and in Eq. 3) and surface soil water content, called originally in the WCM but customized for this study as (Eq. 3). The contribution of in the signal backscattered by soil can be linearly (Han et al. 2020) or exponentially (Bousbih et al. 2018) expressed (Eq. 3) (2) and, (3) and, (4) Artificial neural network (ANN) An ANN is a bioinspired algorithm that operates by emulating how the neural system in the human brain builds reasoned decisions from previous knowledge and new information perceived by senses (Samek et al. 2019). From Widrow's Adaline to deep or convolutional neural networks, ANN fundamentals are nearly the same: a structured net of processing units (neurons) is sorted in layers, where connections among neurons are strengthened through training (Montesinos et al. 2022). ANNs have been used as an alternative to retrieve SSWC from SAR images with better agreement than semiempirical backscattering models (Bousbih et al. 2018; Mirsoleimani et al. 2019). A perceptron multilayer consists of a supervised ANN with m layers, n neurons by layer, and an algorithm that back-propagates the error. Irrigation scheduling Irrigation scheduling consists of apply the right amount of water in the proper moment to avoid that crop plants suffer water stress. Using the premise of maintaining the soil water in a crop within the desired limits (Eisenhauer et al. 2021), in this case the allowable depletion limit and field capacity, when the IS-SAR user computed the irrigation requirement can act in three ways (Fig. 1): (1) When is between field capacity and the irrigation triggering limit (i.e., available water was not depleted), supplemental irrigation can be performed; (2) when is situated left , exceeding the irrigation triggering limit, imminent irrigation must be applied; and 3) when is right of , soil accounts with excess water and irrigation are not needed (Fig. 1). The amount of water (water depth in millimeters) to be applied in actions 1 and 2 will be quantified by , where and are expressed in fractional units and 600 corresponds to the crop root effective maximum depth (in millimeters) (Fig. 1). Fig. 1 Irrigation actions according to the water content of a cultivated soil found by users in IS-SAR Full size image Materials and methods Influence area of IS-SAR and plots’ characteristics IS-SAR was implemented for Hass avocado growers located in the current and potential production area (PPA) in the department of Valle del Cauca (Colombia) (Fig. 2a). PPA has an extension in Valle del Cauca of 330,279 ha and is characterized by a mountain landscape in a range of altitudes from 1500 to 2500 m.a.s.l and slopes that exceed 25%. The mean temperature and annual rainfall range from 18 to 24 °C and 1000–2000 mm in PPA, respectively, and soils were formed from volcanic ashes of igneous and metamorphic rocks at altitudes above 1800 m.a.s.l. and sedimentary, igneous, and metamorphic rocks below 1800 m.a.s.l. (CVC and IGAC 2017). Approximately 400 growers distributed in 5216 ha in the north and center of Valle del Cauca manage Hass avocado orchards from 1 to 430 ha, predominating small farms (Díaz et al. 2021; MADR 2021). Fig. 2 Location of Colombia in South America (a), location of Valle del Cauca in Colombia (b), and location of the influence area of IS-SAR in Valle del Cauca (a) Full size image Our study is focused on a detailed pixel-level analysis of the S1 imagery (spatial resolution 100 m2). It is expected that the retrieved spectral response of S1 images results of a mixture of the avocado canopy, sparse pastures, and bare soil in 100 m2, in which are 2 to 4 avocado trees (49 m2 to 24.5 m2, respectively) given a tree density in the study plots. The low tree density is an advantage for modeling the surface soil water content for Hass avocado crops, compared with high-density crops where the contribution of soil to the backscattering coefficient close to harvest significantly decreases. Sentinel 2 imagery was also evaluated to calculate NDVI time-series data to be used as a proxy to derive LAI as input parameter for (Eq. 2). In the influence area of IS-SAR (Fig. 2a), the commercial 2-ha plots in Laurentina, Poncena, and Olival orchards were selected, which were cropped with Hass avocado at densities of 408, 238, and 204 trees ha−1, respectively (Fig. 2c, d, e). The canopy area and trunk diameter varied according to the age of trees. The average values measured for canopy area were 6.28 ± 3.30, 9.70 ± 3.35, and 1.43 ± 0.69 m2 for Laurentina (3.5 years), Poncena (5 years), and Olival plots (2.5 years), respectively, and average trunk diameters measured for Laurentina, Poncena, and Olival plots were 0.47 ± 0.08, 0.34 ± 0.11, and 0.52 ± 0.12 m, respectively. The soil properties measured in the laboratory for the three plots determined that these mostly have a sandy loam texture, with a sand content higher than 57% and a content clay content varying from 9 to 23%, and an average total available water of 0.08 cm3 cm−3. Three monitoring trees were selected for each plot, where soil matric potential at 15, 45, and 75 cm of depth was measured from 15 August 2020 to 15 August 2021 (Fig. 2c, d, and e) using granular matrix sensors. Moreover, climate data were recorded in this period using portable weather stations installed in the center of each plot. Regarding irrigation, a drip system was implemented for the Laurentina plot; Olival plot accounted for micro-sprinklers; and Poncena’s grower irrigated the trees one at a time with a hose. Approximately one fertigation events a week were implemented in Laurentina, totaling 44 in the study period (1245 mm). Conversely, irrigation was scheduled based on a visual manifestation of water deficit in trees in the Olival and Poncena plots. In Olival, no irrigation was needed during the study period, because rainfall met the water requirements of the crop, while in Poncena, the crops were irrigated five times (153 mm). The amount, date, and time of each irrigation event for Laurentina and Poncena were recorded. Annual precipitation of 1372, 1782, and 1275 mm for Laurentina, Olival, and Poncena plot were recorded, respectively. Methodological framework This study can be described in four major steps (Fig. 3). First, , , and were merged by date to calibrate the WCM and ANN models. Second, the best model that retrieved using S1 images was selected, and the best-adjusted linear regression parameters to predict soil water content at 0–60 cm ( ) from were found. Third, at field capacity ( ) and permanent wilting point ( ) were spatially modeled, and finally, IS-SAR was designed, evaluated, and uploaded online to Hass growers (Fig. 3). Each of these steps comprises other steps, which are shown in Fig. 3’s flowchart and described in detail later. All these procedures described in the following sections and the graphical outputs (package ggplot2) were coded in R scripts. Fig. 3 The four steps outlined in the methodological framework used in this study Full size image Step 1: Calibrating the WCM and ANN models Soil volumetric water content time-series and irrigation practice description And time-series were obtained from the Erazo-Mesa’s et al. (2022b) study who modeled the vertical water dynamics in the soil profile up to 90 cm at nine Hass avocado trees in the Laurentina, Olival, and Poncena plots (Fig. 2). Soil matric potential, climate, soil properties, and crop parameter data were monitored, the first two hourly, at the trees from 15 August 2020 to 15 August 2021 as inputs to calibrate the Richards equation, van Genuchten, and Mualem pore distribution models (Mualem 1976; van Genuchten 1980; Hillel 2014) through Hydrus-1D software (Simunek et al. 2012). Further details for the field equipment, Hydrus-1D modeling, and procedures to select the surface depth range for can be found in Erazo-Mesa et al. (2022b). Processing of Sentinel-1 images A collection of 152 Sentinel-1 C-band images at the Level-1 GRD was processed on Google Earth Engine (GEE) using the framework routine developed by Mullissa et al. (2021). With a spatial resolution of 10 m, VV and VH polarizations, and ascending–descending orbits, this collection was delimited by the geographic quadrant 76.869–75.990 W and 3.295–4.478 N and filtered from 15 August 2020 to 15 August 2021. The 152 S1 images were composed of 48 Sentinel 1A (S1A) and 106 Sentinel 1B (S1B) images from orbits 142 and 48 and acquired at 15:51 UTC and 04:21 UTC, respectively. The revisiting time was 12 and 7 days between S1A and S1B images, respectively, and averaged 4 days among consecutive S1 images. The procedures executed by Mullissa’s et al. (2021) framework routine included additional border noise correction, a multitemporal speckle filter, and radiometric terrain normalization using the NASA SRTM 30-m DEM, according to the incidence angle. Then, the in VV and VH polarizations (in dB units), (in degrees units), and acquisition date (in decimal format) were extracted from the images' pixels intersected with tree monitoring coordinates. S1 images and θ integration The time-series product of merging by date , , and was split into calibration (15 August 2020–15 February 2021) and validation (16 February 2021–15 August 2021) datasets. The calibration dataset, with 384 records, was used to calibrate the WCM and train the ANN, and the validation dataset, with 306 records, was used to select the best model. Inversion, NSGA-II implementation, and parameter optimization of WMC WCM calibration consists of finding the values of parameters , , , , and that minimize the difference between and . Although the normalized vegetation index (NDVI) at the tree monitoring coordinates was computed from Sentinel-2 images to calculate the LAI, the scarce free-cloud images in the study area impeded consolidating an NDVI time-series similar to that obtained from S1 images. Thus, parameter was optimized as the other WCM parameters. In this study, the WCM was calibrated using the optimization genetic algorithm NSGA-II (Deb et al. 2002), according to Kumar et al.’s (2012) suggestions. First, was computed using and from the calibration dataset and synthetic parameters , , , , and , provided by NSGA-II. The computed was compared iteratively (100 generations and a population size of 500) with through a three-objective optimization function (Eq. 5–7). In Eq. 5–7, is the RMSE function, is one minus the coefficient of determination ), is a function that computes the number of undefined/infinite outputted values (ideally zero), represents the paired values ( for a time , and is the number of calibration dataset pairs (5) (6) (7) Since no restriction in the sign and magnitude of , , , , and were reported in the forecited studies, they were set to vary between − 100 and + 100 in NSGA-II. The best combination of , , , , and was selected based on the crowding distance. NSGA-II implementation and validation were coded in an R script, wrapping the R function nsga2R (Tsou 2013) into a set of R functions to achieve the procedure previously described. ANN architecture and training To train the ANNs, 25 multilayer perceptron networks were configured, building two hidden layers and adding 1 to 5 neurons for each layer. These architectures were trained 200 times, for a total of 5000. The input variables for each architecture corresponded to , , and tree monitoring coordinates, and the output variable corresponded to . All these variables were scaled between 0 and 1. The calibration dataset was split into 60, 70, and 75% of the data for training and the remaining percentage was used to select the best architecture, which accounted for the lowest RMSE (Eq. 5) and the highest (right side of Eq. 6). ANN implementation was conducted using the function neuralnet from the neuralnet R package (Fritsch et al. 2019). Step 2: Selecting the best model Was computed using the validation dataset and the calibrated the WCM and trained ANN models and was added to the validation dataset. Then, RMSE (Eq. 5) and (right side of Eq. 6) were computed. Two selection criteria were considered to select the best model: the lowest RMSE and highest and the simplicity by either coding its mathematical formulation or importing its dependent libraries to the IS-SAR project. Step 3: Interpolating soil water content at field capacity and permanent wilting point And permanent wilting point at a depth of 30 cm, and geographic coordinates were extracted from a soil survey study that described 300 georeferenced soil profiles in the study area (Fig. 1) (CVC and IGAC 2017). A geostatistical analysis was implemented to obtain the and maps. This analysis consisted of exploring these data to identify outliers, selecting the theoretical semivariogram, interpolating using ordinary kriging, and validating the interpolation (Oliver and Webster 2015). In addition to RMSE and , mean error (ME), mean absolute error (MAE), and the comparison between the average of the observed ( ) and predicted-by-interpolation values ( ) were used to validate the and interpolations. The resulting maps were computed with a pixel size of 500 × 500 m. Step 4: Implementing IS-SAR Web application design IS-SAR is an interactive web map application based on Sentinel-1 images that contains navigating, locating, zooming in–out, and plotting controls. This application has a module displaying one of the three irrigation actions described in the section \"Irrigation scheduling\", according to the current soil water content in the target plotted by the user. IS-SAR was designed using Django (Python) and JavaScript web frameworks and GEE API repositories (back-end). HTML, CSS, and JavaScript were used to design the front end. IS-SAR is hosted on the GitHub contribute project https://github.com/Viinky-Kevs/IS-SAR-APP. Once users draw the target plot in IS-SAR, the application functions call the framework routine developed by Mullissa et al. (2021) to obtain and from the most recent S1 image and compute for the target plot area using the best model selected. Then, is retrieved from using the calibrated linear model. IS-SAR obtains the and values from the closest and map pixels to the user plot centroid and compares them with the average in the user-drawn plot to select the irrigation action and compute the amount of water required to apply the irrigation. Based on the 27 available S1 images from 14 August to 9 December 2021, the consistency of IS-SAR for irrigation scheduling in the study area was evaluated simulating the IS-SAR user executions for Laurentina, Olival, and Poncena plots. For each plot, simulations consisted of creating an account, loading to IS-SAR its boundary in shapefile format (done once), calculating the irrigation actions and the irrigation water depth (to actions 1 and 2), and recording these data into a database. Results WCM and ANN calibration and the best model selection The WCM and ANN were successfully calibrated using the entire monitoring tree dataset and split by tree to retrieve from , , and the tree coordinates (for ANN). In WCM calibration, the best solutions accounted for an NSGA-II convergence, , and infinitive crowding distance. After calibrating the WCM using the backscattering coefficient at VV and VH polarizations, was selected to retrieve , because the RMSE was lowest and was highest for the nine monitoring trees. The resulting values for the WCM parameters , , , , and varied from − 99.99 to 98.90. When comparing these among trees and plots, no recognizable pattern in the magnitude and sign of these parameters was found. Regarding ANN training, the error threshold and the maximum number of cycles were set to 0.02 (in 0–1 scaled units) and 1000, respectively. Therefore, the ANN training finished in a reasonable time (1 h), with an acceptable prediction error, and converged a high percentage of the tested ANN. The ANN architecture with the lowest RMSE and highest in the training stage for was 5:5 (5 neurons for the two hidden layers). The evaluated Hass avocado plots' soil water content at depths of 5–10 cm changed considerably over time (Fig. 4). varied from 0.11 m3 m−3, a value close to for monitoring tree O3 (Fig. 4f), to 0.49 m3 m−3, a value close to saturation for monitoring tree P2 (Fig. 4h). These changes were mainly produced by fallen rain and applied irrigation (Fig. 4c, f, and i), evapotranspiration, and sandy soils, which poorly retained moisture. averaged 56%, 97%, and 73% of the time above for Laurentina, Olival, and Poncena trees, respectively. These percentages suggest that fallen rain was frequent and abundant for the Olival plot and that irrigation was not needed, while irrigation was needed for the Laurentina and Poncena plots. Fig. 4 Surface soil water content retrieved from the Water Cloud Model (WCM), Artificial Neural Networks (ANN), and their comparison with that simulated by Hydrus-1D for the calibration and validation periods at monitoring trees of Laurentina (a–c), Olival (d–f), and Poncena (g–i) Full size image varied in the monitoring trees at a rate from 0.02 to 0.04 m3 m−3 between consecutive estimations (Fig. 4). Due to the low frequency of the data, the time-series presented a nonnatural behavior in its changes, hindering the identification of sudden increases and later decreases in moisture after inputs of water, as observed in the time-series (Fig. 4). The WCM and ANN models were consistent with the estimation in the calibration and validation periods, with an average absolute difference between models of 0.02, 0.03, and 0.03 m3 m−3 for the Laurentina, Olival, and Poncena monitoring trees, respectively (Fig. 4), and a maximum difference of 0.05 m3 m−3 for the monitoring tree O3 (Fig. 4f). An increasing error in the time-series was observed in the monitoring trees P2 and P3 for the validation period (Fig. 4h, i, respectively), coinciding with a high , a consequence of the frequent rainfalls in this period. The error and agreement between and , calculated for the WCM and ANN models in the calibration and validation periods, are shown in Table 1. The WCM estimated with a maximum RMSE of 0.04 m3 m−3 and 0.05 m3 m−3 per-tree calibration and validation, respectively, representing 17% (tree O1) and 15% (tree P2) of the average . The value broadly varied for the WCM among trees with a maximum of 0.33 for calibration and reported a value of 0.01 for five trees for validation. The ANN model slightly improved the WCM performance, obtaining maximum RMSEs of 0.03 m3 m−3 and 0.07 m3 m−3 for calibration and validation per tree, respectively, which represent 18% (tree O3) and 30% (tree O1) of the average . The for ANN was consistently higher than that for WCM for per-tree calibration with a value higher than 0.40, but this decreased for validation, obtaining a maximum value of 0.44. Regarding the performance per plot, the RMSE average for the two models was lower in Laurentina for calibration and validation, compared with the RMSE average of the other plots (Table 1). Table 1 Root-mean-square error (RMSE) and Pearson correlation coefficient ( ) for the calibration and validation of the water cloud model (WCM) and artificial neural network (ANN) for the nine monitoring trees in the study area Full size table Differences of 0.02 and 0.01 were calculated by comparing the RMSE of ANN and the WCM for calibration and validation, respectively, suggesting a better performance of ANN when all-trees data were used. Moreover, the value for the ANN exceeded 0.37 and 0.27, which were obtained by the WCM for validation and calibration, respectively. Although the trained ANN model performed consistently better than the WCM, the WCM was selected to retrieve from S1 images due to its simplicity in tracking the surface soil water content for the IS-SAR web application. The calibration and validation of the WCM and ANN models for all trees resulted in a higher RMSE and higher values than those obtained per tree. However, all-tree optimized WCM parameters integrally represent the dynamics in the study area. From surface soil water content to soil water content at depths of 0–60 cm The linear regression model implemented to obtain from resulted in Eq. 8, with an RMSE of 0.05 m3 m−3, value of 0.51, and (8) Soil water content at field capacity and permanent wilting point maps And maps were obtained with a spatial resolution of 500 × 500 m by applying the geostatistical steps described in Sect.  2.5 (Fig. 5). In the exploratory analysis, 45 outliers were removed for both variables, and after testing several transformation functions without improving the interpolation performance, and data were processed without transformation. The semivariogram analysis resulted in selecting the Spherical and Mattern models for and , respectively, with the parameters shown in Table 2. The found nugget values indicate a high variability among samples separated at very short distances. The and semivariogram ranges of 22 and 6 km imply that spatially distributed points of are autocorrelated at a greater distance than . The difference between the averaged observed ( ) and interpolated ( ) values for and was 0.01 and 0.01, respectively (Table 2). Fig. 5 Soil water content at the field capacity (a), permanent wilting point (b), and total available water (c) interpolated at the study area Full size image Table 2 Semivariogram model and cross-validation parameters in the geostatistical analysis for the field capacity and permanent wilting point in the study area Full size table In the resulting interpolated maps, varied from 0.17 to 0.37 m3 m−3 with an average value of 0.28 m3 m−3, varied from 0.10 to 0.29 m3 m−3 with an average value of 0.17 m3 m−3, and the total available water (i.e., ) varied from 0.03 to 0.24 m3 m−3 (Fig. 5). The lowest values were in the northwest and southwest of the study area, where Laurentina and Olival's monitoring trees were located (Fig. 5a). The location of the highest and lowest values coincided with that of . The zone with a low total available water is delimited by the range 0.030–0.094 and is distributed in 20.2% of the study area, where the monitoring trees are located (Fig. 5). IS-SAR web application IS-SAR is a web application for Hass avocado growers in the Valle del Cauca (Colombia) that need scheduled irrigation in their orchards. This application, accessible from http://www.is-sar.com, accounts for the calibrated WCM, two layers of and at a spatial resolution of 500 × 500 m, and a linear regression model to transform into to retrieve the soil water content in the target plot at the crop effective root depth of 0–60 cm using the most recent S1 image. To access the main IS-SAR page (Fig. 6b), users must create an account and log in (Fig. 6a). Then, users must locate their plot and draw it using the drawing polygon tool. IS-SAR computes , determine the irrigation action according to the position in the total available water and recommend the user the action to take and the water depth to apply (Fig. 6c). Fig. 6 Login page (a) and main application page (b) of the IS-SAR web application and simulation of irrigation scheduling for plot \"L2\": soil water spatial variability (c) and the amount of water to be applied for the selected irrigation action (d) Full size image To evaluate IS-SAR, 27 simulations were conducted in the Laurentina, Olival, and Poncena plots on dates coinciding with the S1 revisit time (Fig. 7). In the simulation period, in the Laurentina plot, 397 mm of irrigation was applied, plus 553 mm of rainfall kept the soil water close to field capacity and below the irrigation triggering limit. IS-SAR recommended applying supplementary irrigation (action 1) of 12 mm on average for the Laurentina plot, which is equivalent to applying, on average, one drip irrigation of 39 L tree−1 for 1.2 h (dripper flow of 4 L h−1) (Fig. 7a). Fig. 7 Irrigation water depth to be applied in IS-SAR simulation actions on dates coinciding with the S1 revisiting time for the Laurentina (a), Olival (b), and Poncena (c) plots Full size image Although no irrigation was applied in the Olival plot and the rainfall of 464 mm was smaller than that in Laurentina, this plot did not reach the irrigation triggering limit (Fig. 7b). In the case of applying irrigation when IS-SAR indicated the need for it, each Olival plot's tree should have received 91 L for 2.8 h. A water shortage at the supply source meant that irrigation was not applied in the Poncena plot for the simulation period. Then, the rainfall of 504 mm was not enough to keep the soil water content at field capacity, increasing to 107 L tree−1 over 3.4 h for each simulated irrigation event (Fig. 7c). Discussion Sentinel-1 and its implications in irrigation scheduling Considering the irrigation frequency in the Laurentina plot in the maximum crop water demand (approximately one fertigation event per week) and other Hass avocado orchards with similar irrigation system, climate and soil conditions (Grajales 2017), the S1 revisiting time of 7 days (Fig. 4) is suitable to track the soil water content and schedule and irrigate Hass avocado crops in Colombia, avoiding water stress. Similar IS-SAR satellite-based applications also account for week-based irrigation scheduling (Montgomery et al. 2015). Access to IS-SAR on the same days as the S1 revisit time, i.e., based on the S1 revisiting time calendar, could benefit avocado growers (Hill and Allen 1996; Fessehazion et al. 2014). Water cloud model and artificial neural networks LAI is an essential parameter for calibrating the WCM, because it relates to the backscattered signal from vegetation (Prévot et al. 1993). In the absence of LAI field data, the ten images resulting from filtering by cloudy percentage (< 60%) of the Sentinel 2 (S2) GEE collection for the study period were insufficient to build a robust NDVI time-series and compute the LAI of the monitoring trees. Therefore, our model is limited, because only S1 images were used to calibrate the water cloud and artificial neural network models. This variant for the WCM calibration differs from recent studies that used S1 and S2 images for calibrating the WCM (Bousbih et al. 2018; Ouaadi et al. 2020). In addition, the RMSE of 6% (vol) found for the WCM calibration and validation for sandy soils in this study, which have a reduced range of total available water, could increase the uncertainty of water depth computed in IS-SAR. Despite not having LAI data in the WCM calibration, the RMSE and values found after comparing the WCM and ANN model with the surface soil water content modeled by Hydrus-1D for sandy soils were similar to those reported by Bousbih et al. (2018) and Ouaadi et al. (2020). However, when a robust LAI model is integrated into the WCM, as Han et al. (2020) reported, the RMSE and values decrease and increase, respectively. Thus, LAI field data are required to improve the WCM calibration, reduce the error, and increase the agreement with the field SSWC data. In the same line with that found here, similar studies in sparce density tree crops have shown how the vegetation influences the soil moisture retrieved by SAR images. Chiraz et al. (2022) and Courault et al. (2022) found that the correlation of soil moisture with S1 measures under the canopy are lower compared with this when is measured on the row space among trees and Shashikant et al. (2021) found a strong correlation of vegetation descriptors with the WCM. In WCM calibration, the accuracy of SSWC retrieved from the backscattering coefficient with VH and VV polarizations depends on specific characteristics of the calibration sites, vegetation characteristics, and the inclusion of additional parameters such as soil texture and roughness. Although Bousbih et al. (2017) and Hajj et al. (2017) reported that was more sensitive to vegetation cover, Baghdadi et al. (2017), in the same line as that found here for sandy soils, found that was more precise than . Compared with the WCM, the ANN model retrieved SSWC with a lower RMSE and a higher value with the calibration and validation datasets. The addition of the monitoring tree coordinates (in decimal degree units) as input variables in the ANN training phase improved the performance of the model. Similar results were found by adding a priori rainfall and soil moisture condition information (El Hajj et al. 2017; Bousbih et al. 2018). IS-SAR web application IS-SAR is a novel web application to track the water content in soils cropped with Hass avocado and schedule irrigation at the plot level. No antecedents were found in irrigation scheduling web applications based on SAR images. Similar scheduling irrigation web applications use optical images (Montgomery et al. 2015; Calera et al. 2017) but cannot be used in Valle del Cauca due to its cloudy conditions throughout the year. IS-SAR, available for Hass avocado growers in the Valle del Cauca on http://www.is-sar.com, could be extended to be used in other Colombian regions using additional calibration points. Once implemented, the potential impacts of IS-SAR in Hass avocado orchards include improved irrigation scheduling, reduction in the applied irrigation water volumes, and a good match between water supply and crop water demand, all of which increase the use of digital agriculture practices (Erazo-Mesa et al. 2022a). In 10 of the 12 months in which the WCM was calibrated and in the 5 months in which IS-SAR was evaluated, the ENSO climate phenomenon La Niña increased rainfalls and decreased the crop irrigation water demand in the study area. In the context of scarce rainfall and an increase in Hass avocado irrigation demand caused by El Niño, the S1 revisiting time of 7 days would result in a long irrigation schedule. Although the WCM was calibrated using field data from nine monitoring trees, which provided a proper generalization of the soil water content dynamics in the study area, it is recommended to check with a soil moisture probe or similar device the correspondence between the in-field soil water content and the outputted values by IS-SAR. Notably, the more precise the and maps are, the more accurate the IS-SAR irrigation estimation. Moreover, IS-SAR depends on the correct and continuous operation of S1 satellites. The results of IS-SAR simulations shown in Fig. 7 coincided with the soil water dynamics, applied irrigation, and climate recorded and observed in the field from 15 August 2021 to 9 December 2021 for the Laurentina, Olival, and Poncena plots. Notably, the high amount of rainfall caused by La Niña and irrigation (for Laurentina) implied that the water irrigation depth did not accumulate, decreasing to critical soil water content values. Although the available water content at the three plots was similar, averaging 0.10 m3 m−3, the high field capacity and permanent wilting points in the Poncena plot soil retrieved from the corresponding maps caused this plot to exceed the irrigation triggering limit in all IS-SAR queries. Conclusions We developed a near-real-time irrigation information tool—IS-SAR—to assist Hass avocado growers in designing better irrigation tasks and understanding water crop consumption. The IS-SAR implementation allows us to conclude that the Sentinel-1 revisiting time of 7 days is appropriate to schedule Hass avocado irrigation in the current climate and soils of Valle del Cauca (Colombia). The ANN model performed better than the WCM in estimating SSWC due to its flexibility in adding a priori information. In permanently cloudy conditions, such as those presented in the Andean mountains of Valle del Cauca, LAI field data are required to improve the agreement with the field SSWC data. Under extreme wet conditions such as La Niña, further testing and evaluation of IS-SAR are needed. We are posing IS-SAR as a regional application to farmers who need to schedule irrigation for orchard and nonorchard crops. Data availability The data presented in this study are available upon request from the corresponding author. The data are not publicly available, because they are part of the research project, and the Research Group Regar is using the data for other analyses. References Attema EPW, Ulaby FT (1978) Vegetation modeled as a water cloud. Radio Sci 13:357–364. https://doi.org/10.1029/RS013i002p00357 Article   Google Scholar   Babaeian E, Sadeghi M, Jones SB et al (2019) Ground, proximal, and satellite remote sensing of soil moisture. Rev Geophys 57:530–616. https://doi.org/10.1029/2018RG000618 Article   Google Scholar   Babaeian E, Paheding S, Siddique N et al (2021) Estimation of root zone soil moisture from ground and remotely sensed soil information with multisensor data fusion and automated machine learning. Remote Sens Environ 260:112434. https://doi.org/10.1016/j.rse.2021.112434 Article   Google Scholar   Baghdadi N, El Hajj M, Zribi M, Bousbih S (2017) Calibration of the water cloud model at C-band for winter crop fields and grasslands. Remote Sens (basel) 9:1–13. https://doi.org/10.3390/rs9090969 Article   Google Scholar   Bernal JA, Díaz CA (2020) Actualización tecnológica y buenas prácticas agrícolas (BPA) en el cultivo de aguacate, 2nd edn. Corporación Colombiana de Investigación Agropecuaria (Agrosavia) Bernal-Estrada JA, Tamayo-Vélez ADJ, Díaz-Diez CA (2020) Dynamics of leaf, flower and fruit abscission in avocado cv. Hass in Antioquia, Colombia. Revista Colombiana de Ciencias Hortícolas 14:324–333. https://doi.org/10.17584/rcch.2020v14i3.10850 Berthold TA, Ajaz A, Olsovsky T, Kathuria D (2021) Identifying barriers to adoption of irrigation scheduling tools in Rio Grande Basin. Smart Agricult Technol 1:100016. https://doi.org/10.1016/j.atech.2021.100016 Article   Google Scholar   Bo Y, Zhou F, Zhao J, et al (2021) Additional surface-water deficit to meet global universal water accessibility by 2030. J Clean Prod 320:. https://doi.org/10.1016/j.jclepro.2021.128829 Bousbih S, Zribi M, El Hajj M et al (2018) Soil moisture and irrigation mapping in a semi-arid region, based on the synergetic use of Sentinel-1 and Sentinel-2 data. Remote Sens (basel) 10:1–22. https://doi.org/10.3390/rs10121953 Article   Google Scholar   Bousbih S, Zribi M, Lili-Chabaane Z, et al (2017) Potential of sentinel-1 radar data for the assessment of soil and cereal cover parameters. Sensors (Switzerland) 17:. https://doi.org/10.3390/s17112617 Brinkhoff J, Hornbuckle J, Lurbe CB (2019) Soil moisture forecasting for irrigation recommendation. IFAC-PapersOnLine 52:385–390. https://doi.org/10.1016/j.ifacol.2019.12.586 Article   Google Scholar   Calera A, Campos I, Osann A et al (2017) Remote sensing for crop water management: From ET modelling to services for the end users. Sensors (switzerland) 17:1–25. https://doi.org/10.3390/s17051104 Article   Google Scholar   Caro D, Alessandrini A, Sporchia F, Borghesi S (2021) Global virtual water trade of avocado. J Clean Prod 285:124917. https://doi.org/10.1016/j.jclepro.2020.124917 Article   Google Scholar   Chiraz MC, Olfa M, Hamadi H (2022) Remote sensing and soil moisture data for water productivity determination. Agric Water Manag 263:107482. https://doi.org/10.1016/j.agwat.2022.107482 Article   Google Scholar   Courault D, Doussan C, Lopez-Lozano R, et al (2022) Potentialities of sentinel products for monitoring water status of agricultural plots and phenology of cherry trees in Southeastern France. In: IGARSS 2022—2022 IEEE International Geoscience and Remote Sensing Symposium. IEEE, pp 5602–5605 CVC (2021) Boletín Actos Administrativos. https://www.cvc.gov.co/documentos/normatividad/boletin-actos-administrativos-ambientales/actos-administrativos-2021?page=0 CVC, IGAC (2017) Levantamiento Semidetallado de Suelos escala 1:25.000 de las cuencas priorizadas por la Corporación Autónoma Regional del Valle del Cauca - CVC. 945 Dari J, Quintana-Seguí P, Escorihuela MJ, et al (2021) Detecting and mapping irrigated areas in a Mediterranean environment by using remote sensing soil moisture and a land surface model. J Hydrol (Amst) 596:. https://doi.org/10.1016/j.jhydrol.2021.126129 Deb K, Pratap A, Agarwal S, Meyarivan T (2002) A fast and elitist multiobjective genetic algorithm: NSGA-II. IEEE Trans Evol Comput 6:182–197. https://doi.org/10.1109/4235.996017 Article   Google Scholar   Díaz L, Hurtado JJ, Charry A, Jäger M (2021) Brechas tecnológicas de la cadena productiva del aguacate Hass en el Valle del Cauca y descripción del estado del arte. Universidad Nacional de Colombia Eisenhauer DE, Martin DL, Heeren DM, Hoffman GJ (2021) Irrigation Systems Management. American Society of Agricultural and Biological Engineers El Hajj M, Baghdadi N, Zribi M, Bazzi H (2017) Synergic use of Sentinel-1 and Sentinel-2 images for operational soil moisture mapping at high spatial resolution over agricultural areas. Remote Sens (basel) 9:1–28. https://doi.org/10.3390/rs9121292 Article   Google Scholar   Erazo-Mesa E, Gómez EH, Sánchez AE (2022b) Surface soil water content as an indicator of Hass avocado irrigation scheduling. Agric Water Manag 273:107864. https://doi.org/10.1016/j.agwat.2022.107864 Article   Google Scholar   Erazo-Mesa E, Ramírez-Gil JG, Sánchez AE (2021) Avocado cv. Hass Needs Water Irrigation in Tropical Precipitation Regime: Evidence from Colombia. Water (Basel) 13:1942. https://doi.org/10.3390/w13141942 Erazo-Mesa E, Echeverri-Sánchez A, Ramírez-Gil JG (2022a) Advances in Hass avocado irrigation scheduling under digital agriculture approach. Revista Colombiana de Ciencias Hortícolas 16:e13456. https://doi.org/10.17584/rcch.2022v16i1.13456 Flörke M, Schneider C, McDonald RI (2018) Water competition between cities and agriculture driven by climate change and urban growth. Nat Sustain 1:51–58. https://doi.org/10.1038/s41893-017-0006-8 Article   Google Scholar   Fritsch S, Guenther F, Wright M, et al (2019) Package “neuralnet”: Training of Neural Networks. 1–15 Grajales L (2017) Uso racional del agua de riego en cultivo de aguacate Hass (Persea Americana) en tres zonas productoras de Colombia. 78 Gu Z, Qi Z, Burghate R et al (2020) Irrigation scheduling approaches and applications: a review. J Irrig Drain Eng 146:1–15. https://doi.org/10.1061/(asce)ir.1943-4774.0001464 Article   Google Scholar   Han D, Wang P, Tansey K et al (2020) Linking an agro-meteorological model and a water cloud model for estimating soil water content over wheat fields. Comput Electron Agric 179:105833. https://doi.org/10.1016/j.compag.2020.105833 Article   Google Scholar   Hill RW, Allen RG (1996) Simple irrigation scheduling calendars. J Irrig Drain Eng 122:107–111. https://doi.org/10.1061/(ASCE)0733-9437(1996)122:2(107) Article   Google Scholar   Hillel D (2014) Water Flow in Unsaturated Soil. Introduction to Environmental Soil Physics 149–166 Jalilvand E, Tajrishy M, Ghazi S, Brocca L (2019) Quantification of irrigation water using remote sensing of soil moisture in a semi-arid region. Remote Sens Environ 231:111226. https://doi.org/10.1016/j.rse.2019.111226 Article   Google Scholar   Karthikeyan L, Pan M, Wanders N et al (2017) Four decades of microwave satellite soil moisture observations: Part 1. A review of retrieval algorithms. Adv Water Resour 109:106–120. https://doi.org/10.1016/j.advwatres.2017.09.006 Article   Google Scholar   Kumar K, Prasad KSH, Arora MK (2012) Estimation of water cloud model vegetation parameters using a genetic algorithm. Hydrol Sci J 57:776–789. https://doi.org/10.1080/02626667.2012.678583 Article   Google Scholar   Lahav E, Whiley AW (2002) Irrigation and Mineral Nutrition. The Avocado: Botany, Production and Uses 259–297 Le Page M, Jarlan L, El Hajj MM et al (2020) Potential for the detection of irrigation events on maize plots using Sentinel-1 soil moisture products. Remote Sens (basel) 12:1–22. https://doi.org/10.3390/rs12101621 Article   CAS   Google Scholar   Li ZL, Leng P, Zhou C et al (2021) Soil moisture retrieval from remote sensing measurements: Current knowledge and directions for the future. Earth Sci Rev 218:103673. https://doi.org/10.1016/j.earscirev.2021.103673 Article   Google Scholar   MADR (2021) Cadena productiva Aguacate. Marzo de 2021. Bogotá D.C. Mekonnen MM, Hoekstra AY (2020) Sustainability of the blue water footprint of crops. Adv Water Resour 143:103679. https://doi.org/10.1016/j.advwatres.2020.103679 Article   Google Scholar   MelakeK F, JohnG A, ColinS E et al (2014) Performance of simple irrigation scheduling calendars based on average weather data for annual ryegrass. Afr J Range Forage Sci 31:221–228. https://doi.org/10.2989/10220119.2014.906504 Article   Google Scholar   Mirsoleimani HR, Sahebi MR, Baghdadi N, El Hajj M (2019) Bare soil surface moisture retrieval from sentinel-1 SAR data based on the calibrated IEM and dubois models using neural networks. Sensors (switzerland) 19:1–12. https://doi.org/10.3390/s19143209 Article   Google Scholar   Montesinos O, Montesinos A, Crossa J (2022) Fundamentals of artificial neural networks and deep learning. Multivariate statistical machine learning methods for genomic prediction 379–425 Montgomery J, Hornbuckle J, Hume I, Vleeshouwer J (2015) IrriSAT—weather based scheduling and benchmarking technology. In: Proceedings of the 17th ASA Conference. Building Productive, Diverse and Sustainable Landscapes. Australian Society of Agronomy Inc., pp 1015–1018 Mualem Y (1976) A new model for predicting the hydraulic conductivity of unsaturated porous media. Water Resour Res 12:513–522. https://doi.org/10.1029/WR012i003p00513 Article   Google Scholar   Mullissa A, Vollrath A, Odongo-Braun C et al (2021) Sentinel-1 sar backscatter analysis ready data preparation in google earth engine. Remote Sens (basel) 13:1954. https://doi.org/10.3390/rs13101954 Article   Google Scholar   Naddaf M (2023) The world faces a water crisis—4 powerful charts show how. Nature Oliver MA, Webster R (2015) Basic Steps in Geostatistics:The Variogram and Kriging. Springer Ouaadi N, Jarlan L, Ezzahar J et al (2020) Monitoring of wheat crops using the backscattering coefficient and the interferometric coherence derived from Sentinel-1 in semi-arid areas. Remote Sens Environ 251:112050. https://doi.org/10.1016/j.rse.2020.112050 Article   Google Scholar   Peng J, Albergel C, Balenzano A et al (2021) A roadmap for high-resolution satellite soil moisture applications—confronting product characteristics with user requirements. Remote Sens Environ 252:112162. https://doi.org/10.1016/j.rse.2020.112162 Article   Google Scholar   Prévot L, Champion I, Guyot G (1993) Estimating surface soil moisture and leaf area index of a wheat canopy using a dual-frequency (C and X bands) scatterometer. Remote Sens Environ 46:331–339. https://doi.org/10.1016/0034-4257(93)90053-Z Article   Google Scholar   Salgado E, Cautín R (2008) Avocado root distribution in fine and coarse-textured soils under drip and microsprinkler irrigation. Agric Water Manag 95:817–824. https://doi.org/10.1016/j.agwat.2008.02.005 Article   Google Scholar   Samek W, Montavon G, Vedaldi A et al (eds) (2019) Explainable AI: Interpreting. Springer International Publishing, Cham, Explaining and Visualizing Deep Learning Google Scholar   Shashikant V, Mohamed Shariff AR, Wayayok A et al (2021) Vegetation effects on soil moisture retrieval from water cloud model using PALSAR-2 for oil palm trees. Remote Sens (basel) 13:4023. https://doi.org/10.3390/rs13204023 Article   Google Scholar   Simunek JÅ, van Genuchten MTh, Sejna MÅ (2012) HYDRUS: Model Use, Calibration, and Validation. Trans ASABE 55:1263–1276. https://doi.org/10.13031/2013.42239 Sommaruga R, Eldridge HM (2020) Avocado Production: Water Footprint and Socio- economic Implications. EuroChoices 0:1–6. https://doi.org/10.1111/1746-692X.12289 Tolomio M, Casa R (2020) Dynamic crop models and remote sensing irrigation decision support systems: a review of water stress concepts for improved estimation of water requirements. Remote Sens (basel) 12:1–34. https://doi.org/10.3390/rs12233945 Article   Google Scholar   Tsou C-S (2013) Elitist Non-dominated Sorting Genetic Algorithm based on R. 1–10 van Genuchten MTh (1980) A closed-form equation for predicting the hydraulic conductivity of unsaturated soils. Soil Sci Soc Am J 44:892–898. https://doi.org/10.2136/sssaj1980.03615995004400050002x Article   Google Scholar   Wang Q, Zheng G, Li J et al (2023) Imbalance in the city-level crop water footprint aggravated regional inequality in China. Sci Total Environ 867:161577. https://doi.org/10.1016/j.scitotenv.2023.161577 Article   CAS   PubMed   Google Scholar   Yohannes DF, Ritsema CJ, Eyasu Y et al (2019) A participatory and practical irrigation scheduling in semiarid areas: the case of Gumselassa irrigation scheme in Northern Ethiopia. Agric Water Manag 218:102–114. https://doi.org/10.1016/j.agwat.2019.03.036 Article   Google Scholar   Zinkernagel J, Maestre-Valero JF, Seresti SY, Intrigliolo DS (2020) New technologies and practical approaches to improve irrigation management of open field vegetable crops. Agric Water Manag 242 Download references Acknowledgements The authors would like to thank Hass avocado growers from plots in Laurentina, Olival, and Poncena farms for their support. Special thanks to Corporación Autónoma Regional del Valle del Cauca—CVC for providing the soil survey database with the georeferenced soil profiles in the study area. Funding Open Access funding provided by Colombia Consortium. This research was granted by the Research Group Regar, Engineering Faculty, Universidad del Valle (SMP monitoring and weather station loans) and supported by the Laboratory of Soil and Water of Universidad del Valle (soil matric potential sensor calibration and soil physics determinations) and the Laboratory of Soils of Providencia S.A. (soil water retention curve determination). Author information Authors and Affiliations Escuela EIDENAR, Facultad de Ingeniería, Universidad del Valle, Calle 13 # 100-00, Edificio E39, Postal Code: 760032, Cali, Colombia Edwin Erazo-Mesa & Andrés Echeverri Sánchez Departamento de Topografía, Facultad de Ciencias del Hábitat, Diseño e Infraestructura, Universidad del Tolima, Postal Code: 730006299, Ibagué, Colombia Paulo J. Murillo-Sandoval Departamento de Agronomía, Facultad de Ciencias Agrarias, Universidad Nacional de Colombia Sede Bogotá, 111321, Bogotá, DC, Colombia Joaquín Guillermo Ramírez-Gil & Kevin Quiroga Benavides Contributions Conceptualization: EEM, AES, and JGRG; methodology: EEM, PJMS, AES, and KQB; data curation: EEM, PJMS, and KQG; writing, original draft preparation: EEM and PJMS; writing review and editing: EEM, AES, and JGRG; visualization: EEM, PJMS, AES, and JGRG; supervision: PJMS, AES, and JGRG; project administration: EEM and AES; funding acquisition: EEM and AES; all authors read and agreed to the published version of the manuscript. Corresponding author Correspondence to Edwin Erazo-Mesa. Ethics declarations Conflict of interest The authors have no conflicts of interest to declare relevant to this article's content. Additional information Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Rights and permissions Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. Reprints and permissions About this article Cite this article Erazo-Mesa, E., Murillo-Sandoval, P.J., Ramírez-Gil, J.G. et al. IS-SAR: an irrigation scheduling web application for Hass avocado orchards based on Sentinel-1 images. Irrig Sci (2023). https://doi.org/10.1007/s00271-023-00889-0 Download citation Received 23 May 2023 Accepted 08 October 2023 Published 23 November 2023 DOI https://doi.org/10.1007/s00271-023-00889-0 Share this article Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Use our pre-submission checklist Avoid common mistakes on your manuscript. Sections Figures References Abstract Introduction Theoretical background Materials and methods Results Discussion Conclusions Data availability References Acknowledgements Funding Author information Ethics declarations Additional information Rights and permissions About this article Advertisement Discover content Journals A-Z Books A-Z Publish with us Publish your research Open access publishing Products and services Our products Librarians Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility statement Terms and conditions Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"

Paper 2:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: This paper introduces the availability of the high-resolution Water Monitoring System (WMS) developed from a mix of sophisticated multi-spectral satellite imageries, analytic and data sciences, and cloud computing, for monitoring the changes in water levels and vegetation water stress at the local scale.
  Extract 2: We announce the availability of the high-resolution Water Monitoring System (WMS) and demonstrate its value for water and drought monitoring using the multi-source data and Google Earth Engine (GEE). We, therefore, describe and discuss the details of the workflow, web-based service, key processes of the proposed system, and testbed for Thailand’s river basin case study implementation.
  Limitations: ['The current development of the study has not yet offered near real-time drought monitoring information using hydrological and meteorological drought indices.', 'Different drought indices for drought monitoring have their limitations.', 'The particular attention should be paid to the physical properties of land cover in the adjacent areas of the groundwater wells, the hydraulic properties of aquifers, and human interventions.', 'This is especially a known issue for optical remote sensing imageries, such as Landsat 8 and Sentinel 2.', 'Strong seasonal changes of rainfall and atmospheric patterns is a dominant feature of the intertropical convergence zone (ITCZ) in the LMR and leads to the formation of different cloud patterns throughout the year.', 'This is, thus, the beta version WMS, which is a fully functional system and will evolve into a fully designed graphical user interface in the future version.', 'Given these demonstrations, they can enhance the methodological and developmental framework to support evidence-based policy making towards achieving the SDGs, formalizing coordinated multi-source observational data and digital technologies (remote sensing, GEE cloud computing, and user interface) for supporting national and local governments to improve the quality of their decision-making, and assisting the governments to increase efficiency and effectiveness in drought and water resource management.']
  Relevance Evaluation: {'extract_1': 'This paper introduces the availability of the high-resolution Water Monitoring System (WMS) developed from a mix of sophisticated multi-spectral satellite imageries, analytic and data sciences, and cloud computing, for monitoring the changes in water levels and vegetation water stress at the local scale.', 'extract_2': 'We announce the availability of the high-resolution Water Monitoring System (WMS) and demonstrate its value for water and drought monitoring using the multi-source data and Google Earth Engine (GEE). We, therefore, describe and discuss the details of the workflow, web-based service, key processes of the proposed system, and testbed for Thailand’s river basin case study implementation.', 'limitations': ['The current development of the study has not yet offered near real-time drought monitoring information using hydrological and meteorological drought indices.', 'Different drought indices for drought monitoring have their limitations.', 'The particular attention should be paid to the physical properties of land cover in the adjacent areas of the groundwater wells, the hydraulic properties of aquifers, and human interventions.', 'This is especially a known issue for optical remote sensing imageries, such as Landsat 8 and Sentinel 2.', 'Strong seasonal changes of rainfall and atmospheric patterns is a dominant feature of the intertropical convergence zone (ITCZ) in the LMR and leads to the formation of different cloud patterns throughout the year.', 'This is, thus, the beta version WMS, which is a fully functional system and will evolve into a fully designed graphical user interface in the future version.', 'Given these demonstrations, they can enhance the methodological and developmental framework to support evidence-based policy making towards achieving the SDGs, formalizing coordinated multi-source observational data and digital technologies (remote sensing, GEE cloud computing, and user interface) for supporting national and local governments to improve the quality of their decision-making, and assisting the governments to increase efficiency and effectiveness in drought and water resource management.'], 'relevance_score': 1.0}
  Relevance Score: 1.0
  Inline Citation: >
  Explanation: The literature review section under the sub-section, “7.1. Resilience and Fault Tolerance in Automated Irrigation Systems”, highlights that leveraging edge computing to enable localized decision-making and control can reduce reliance on cloud connectivity and improve response times. This is especially important in areas with limited or unreliable internet access. 

The paper titled “Leveraging Multi-Source Data and Digital Technology to Support the Monitoring of Localized Water Changes in the Mekong Region” focuses on developing a high-resolution, near real-time drought monitoring system using multi-source data and digital technology. The system is implemented as a web-based service that allows users to monitor water and drought conditions at a local scale (10–30 m spatial resolution). The paper presents a case study in the Chi River Basin, Thailand, to demonstrate the effectiveness of the system. The results show that the system can effectively monitor water and drought conditions, and can be used to support decision-making in water resources management. 

Specifically, the paper contributes to the literature review by providing a concrete example of how edge computing can be used to address the challenge of localized decision-making and control in automated irrigation systems. The paper's findings suggest that edge computing can be a valuable tool for improving the resilience and fault tolerance of automated irrigation systems, particularly in areas with limited or unreliable internet access.

 Full Text: >
"This website uses cookies We use cookies to personalise content and ads, to provide social media features and to analyse our traffic. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you’ve provided to them or that they’ve collected from your use of their services. Consent Selection Necessary Preferences Statistics Marketing Show details                 Deny Allow selection Allow all        Journals Topics Information Author Services Initiatives About Sign In / Sign Up Submit   Search for Articles: Sustainability All Article Types Advanced   Journals Sustainability Volume 14 Issue 3 10.3390/su14031739 Submit to this Journal Review for this Journal Propose a Special Issue Article Menu Academic Editors Andrzej Wałęga Anastasios Michailidis Subscribe SciFeed Recommended Articles Related Info Link More by Authors Links Article Views 1690 Citations 2 Table of Contents Abstract Introduction Materials and Methods Results Discussion Conclusions Author Contributions Funding Institutional Review Board Statement Informed Consent Statement Data Availability Statement Acknowledgments Conflicts of Interest References Altmetric share Share announcement Help format_quote Cite question_answer Discuss in SciProfiles thumb_up Endorse textsms Comment first_page settings Order Article Reprints Open AccessArticle Leveraging Multi-Source Data and Digital Technology to Support the Monitoring of Localized Water Changes in the Mekong Region by Orn-uma Polpanich 1, Dhyey Bhatpuria 2,*, Tania Fernanda Santos Santos 3 and Chayanis Krittasudthacheewa 2 1 Natural Resources and Sustainable Development, Department of Earth Sciences, Uppsala University, Villavägen 16, 752 36 Uppsala, Sweden 2 Stockholm Environment Institute, 10th Floor, Kasem Uttayanin Building, 254 Chulalongkorn University, Henri Dunant Road, Pathumwan, Bangkok 10330, Thailand 3 Stockholm Environment Institute, Latin America, Calle 71, #11-10, Edificio Corecol, Oficina 801, Bogotá 110231, Colombia * Author to whom correspondence should be addressed. Sustainability 2022, 14(3), 1739; https://doi.org/10.3390/su14031739 Submission received: 22 November 2021 / Revised: 25 January 2022 / Accepted: 29 January 2022 / Published: 2 February 2022 (This article belongs to the Special Issue Prospects in Sustainable Water Management) Download keyboard_arrow_down     Browse Figures Versions Notes Abstract The limited availability of high-resolution monitoring systems for the drought phenomena and water dynamics affected by weather anomalies hinders policy decisions in a multitude of ways. This paper introduces the availability of the high-resolution Water Monitoring System (WMS) developed from a mix of sophisticated multi-spectral satellite imageries, analytic and data sciences, and cloud computing, for monitoring the changes in water levels and vegetation water stress at the local scale. The WMS was tested in the Lower Mekong Region (LMR) case basin, Thailand’s Chi River Basin, in the period from January 2021 to April 2021, the dry season. The overall quality of the VHI, VCI, TCI, and NDVI drought simulation results showed a statistically positive Pearson correlation with the reservoir and dam water volume data (ranged between 0.399 and 0.575) but demonstrated a strong negative correlation with the groundwater level data (between −0.355 and −0.504). Further investigation and more detailed analysis of the influence of different physical environmental conditions related to change in groundwater level should be considered to increase scientific knowledge and understanding about the changing nature of the local system from local perspectives with the alternative use of drought indices in data-poor areas. Our result suggests that the WMS can provide quantitative spatiotemporal variations of localized and contextualized surface water changes as a preliminary analysis. The WMS results can offer guidance for finding a better smaller unit management that suits the local conditions, such as water resource management, disaster risk reduction measures (i.e., drought and flood), irrigation practice, land use planning, and crop management. The existing WMS is geared toward the early warning of water and agricultural development, progress on the SDGs, utilization of digital innovation, and improved abilities of decision-makers to monitor and foresee extreme weather events earlier and with high spatial accuracy. Keywords: drought; localized water; monitoring system; SDGs; Lower Mekong Basin; web data scraping; Google Earth Engine; Chi River Basin 1. Introduction Recurrent severe droughts seriously threaten food security, socio-economic condition, and ecosystems in the Lower Mekong Region (LMR) [1,2,3]. The 2019/20 drought in many locations of Thailand [4] and Vietnam’s Mekong delta [5,6] are the recent example, where fragmented institutional mandates and varying technical capabilities to monitor these extreme events led to a significantly to delayed response [7,8]. Meanwhile, climate change has magnified drought in both frequency and severity [9,10]. It aggravates the insecurity of water resources that causes a serious disparity between water supply and demand in the region [2,11,12]. The effects of the water imbalances have created inequalities in the distribution, allocation across competing users, and extensive use of groundwater, which could be a cause of institutional arrangement and political targeting for many countries [13]. These cascading socioeconomic and ecosystem impacts have disrupted efforts to achieve the target sets in at least 4 different Sustainable Development Goals (SDGs), particularly relating to SDG 6 Clean water and sanitation, SDG 11 Sustainable cities and communities, SDG 13 Climate actions, and SDG 14 Life on land. This increased risk of both drought and water security was profoundly notified by six riparian countries (China, Cambodia, Lao PDR, Myanmar, Thailand, and Vietnam) under the Joint Working Group (JWG) on Water Resources of the Lancang Mekong Cooperation (LMC) during the 2019 Second Special Meeting in Nong Khai, Thailand [14]. They initially agreed to undertake joint research on the 2019 drought to gain a more thorough understanding of the physical processes leading to the drought and their impacts. Decision-makers and water managers are aware of frequent extreme weather events, specifically increasing worse droughts and their intensifying impacts [14,15]. They, however, find it difficult to measure drought onsets and endings, even in water-rich countries because droughts are not weather or climatic anomalies [16]. Recent advances in data innovation and digital technologies are making their way into a wide range of applications for water resources management, for instance, [17,18,19,20,21,22,23,24,25,26,27,28]. Specifically, satellite data at varying spatial scales are likely being used as an alternative or complementary source of information to in situ monitoring networks in data-poor regions [29,30]. In many parts of the Lower Mekong Basin (LMB), satellite data is seemingly the only feasible source [31,32] that can provide critical information in support of managing water resources and monitoring the evolution of droughts, other hazards, and their impacts [30,33,34]. In response to the growing attention and need from decision-makers in the LMR, several satellite-based operational near-real-time systems for drought and water monitoring have been developed to provide static maps at a weekly drought condition with single meteorological or a few agricultural drought indicators at the national and regional scales. A few examples of such systems are The Thai Geo-Informatics and Space Technology Development Agency (https://drought.gistda.or.th/ accessed on 4 October 2021), SERVIR-Mekong (https://mdcw-servir.adpc.net/; https://rdcyis-servir.adpc.net/map accessed on 4 October 2021), and Mekong River Commission (http://droughtforecast.mrcmekong.org/maps accessed on 4 October 2021). At the global scale, the Center for Spatial Information Science and Systems/George Mason University (http://gis.csiss.gmu.edu/GADMFS/ accessed on 4 October 2021), the University of California, Irvine (http://drought.eng.uci.edu/ accessed on 4 October 2021), and the Food and Agriculture Organization of the United Nations (https://www.fao.org/giews/earthobservation/asis/index_1.jsp?lang=en#uvhi accessed on 4 October 2021) have a near real-time drought assessment products at the larger spatial scales (500 m to 11 km). Those existing drought monitoring systems are too coarse and have a limited operation period of satellite sensors to capture detailed spatial coverage conditions, due to complex topography and heterogeneity [35,36,37,38]. They are unfortunately unable to provide essential information in decision-making at the sub-national or basin scales [29,36]. As drought can be localized and increasingly take place on smaller scales [39,40]. This highlights the important need for a local understanding of the behavior of water movement, the vulnerability of crops under drought, and other climate and water problems, rather than global or regional levels. A high-resolution near real-time drought monitoring tool with more accurate measures of specific drought indices is, thus, required for decision-making and adaptation at the local scale. Nevertheless, tackling the challenges of drought needs an integrated approach to support water resource management and sustainable development [41]. In addition, developing any system usually requires considerable time, effort, and resources [28,42]. While observational data are individually collected and managed through very sparse agro-hydrometeorological monitoring networks by several agencies, a few are publicly available online at Thailand’s Hydro-Informatics Institute (https://www.thaiwater.net/v3/ accessed on 7 November 2021), Mekong River Commission (https://portal.mrcmekong.org/monitoring/river-monitoring-telemetry accessed on 7 November 2021), for instance, this identifies a strong need for better coordinated multi-source observational data across departments within a country [7]. Thus, we believe that an affordable development of an integrated system for drought monitoring can provide situational information to gain an improved understanding of the behavior of water movement, the vulnerability of crops under drought, and other climate and water problems at the local scale. The study, therefore, develops a web-based open-source system that will be of great help in reducing task duplication and to further enhance the ability of water managers and policymakers to achieve better water resource management, support concrete actions in timely responses, and catalyzing progress in achieving the listed SDGs and SDG 4 Digital innovation. Other users can also benefit from the WMS. Here, we announce the availability of the high-resolution Water Monitoring System (WMS) and demonstrate its value for water and drought monitoring using the multi-source data and Google Earth Engine (GEE). We, therefore, describe and discuss the details of the workflow, web-based service, key processes of the proposed system, and testbed for Thailand’s river basin case study implementation. We anticipate that this freely available web-based monitoring tool will provide evidence of the state and changes in surface and groundwater over time and inform water management decision-making and the enforcement of extreme event preparedness, mitigation, and emergency measures at the local level. 2. Materials and Methods The Water Monitoring System (WMS) was developed by the Stockholm Environment Institute (SEI) cross-center researchers (Asia and Latin America) between 2020 and 2021. The WMS entered a digital universe, where day-to-day decisions need to be based on empirical data and analytics, rather than past practice. By embracing new tools and technologies to better understand their complex operations, today’s stakeholders and decision-makers can save time and money, reduce water related risks, and become more efficient. To succeed with the data-driven approach, we need to start with accurate information that requires powerful monitoring tools backed by robust analytic capacities. That is where the WMS comes in. We are taking physical monitoring to new levels with our advanced data innovation, which provides unparalleled real-time visibility into local drought and water resource management. Using a combination of sophisticated multi-spectral sensors, which provides high resolution satellite imageries, data science analytics, and cloud computing, the WMS delivers unprecedented insights into how lower water resources and vegetation are observed. This is achieved by web-scraped multi-source data to accurately estimate water deficits or inundation and support timely decisions for managing climate-change-related water resource management, with a potential reduction of damages and investment costs and benefits for irrigation development, adaptation measures, and mitigation. Our proposed system is easily scalable and can be used to develop a monitoring system of individual surface and groundwater resources or entire local drought areas. The edge computing technology allows us to deploy them in situations where observational data are unavailable and unreliable. It all adds up to better control over local water resources and a deeper understanding of how to manage it, and that means healthier water systems, better management, and efficient operation. 2.1. Water Monitoring System (WMS) The schematic of the WMS is demonstrated in Figure 1. It comprises: (1a) a near real-time simulation framework using the Google Earth Engine (GEE) to monitor the evolution of drought and water conditions; (1b) an automated web data scraping and extraction in Python that is an archive of the publicly available surface and groundwater observation data from government websites; (1c) PostgreSQL, a relational database management system to store and process the input data of surface and groundwater as a foundation of the WMS database; and (1d) a web-based service that connects all modules and hosts the resultant archive of the GEE, a system database and a high-resolution spatial maps of drought indices. The WMS allows technical users who are highly trained in the fields of physical environment, geosciences, and water sciences to interact, communicate, and share our results in a non-scientific language with different interest groups, thus reaching a much wider audience. It also aims to provide evidence-based scientific support to the policymaking process for sub-national and local drought assessments, as well as changes of water conditions. Major modules are described in the subsections. Figure 1. Schematic overview of the configuration for the Water Monitoring System (WMS). 2.1.1. Near Real-Time Simulation in Google Earth Engine (GEE) The WMS is built on top of the GEE cloud-based platform for sub-national scale geospatial analysis. The freely available Landsat 8 (L8), with a 16-day revisit time [43], provided by the United States Geological Survey (https://www.usgs.gov/core-science-systems/nli/landsat/landsat-8?qt-science_support_page_related_con=0# accessed on 28 October 2021) and the Sentinel 2A/B (S2) from the European Space Agency (https://sentinel.esa.int/web/sentinel/missions/sentinel-2 accessed on 28 October 2021) images with a 5-day repeat period [44] are utilized and have been routinely downloaded since its inception in January 2021. Although the two images are atmospherically corrected and geo-referenced, based on the global position system (GPS) tier points [45], cloud contaminations and topographic effects produced by the presence of shadow noises remain the issues in the result of earth’s surface mapping and change analysis [46,47]. We implemented the cloud masking algorithm within GEE, which enables us to resolve the effects by removing pixels having cloud presence to meet crucial data use and can yield a higher composite of the satellite imagery. Estimates of drought and other environmental events have received enhanced attention over the last 30 years [48]. The visible (VIS) and near-infrared (NIR) wavebands calculating Vegetation Health Index (VHI) [48,49,50], Vegetation Condition Index (VCI) [51,52], Temperature Condition Index (TCI) [48], Normalised Difference Vegetation Index (NDVI) [53], and Normalised Difference Water Index (NDWI) [54,55] have been used in designing local drought monitoring techniques in the WMS. Vegetation Health Index (VHI) 𝑉𝐻𝐼= 𝛼∗𝑉𝐶𝐼+(1+𝛼)∗𝑇𝐶𝐼;𝑤ℎ𝑒𝑟𝑒 𝛼=0.5 Vegetation Condition Index (VCI) 𝑉𝐶𝐼= 𝑁𝐷𝑉 𝐼 𝑐𝑢𝑟𝑟𝑒𝑛𝑡  −𝑁𝐷𝑉 𝐼 𝑚𝑖𝑛 𝑁𝐷𝑉 𝐼 𝑚𝑎𝑥 −𝑁𝐷𝑉 𝐼 𝑚𝑖𝑛 ×100 Temperature Condition Index (TCI) 𝑇𝐶𝐼= 𝐿𝑆 𝑇 𝑚𝑎𝑥 −𝐿𝑆 𝑇 𝑐𝑢𝑟𝑟𝑒𝑛𝑡 𝐿𝑆 𝑇 𝑚𝑎𝑥 −𝐿𝑆 𝑇 𝑚𝑖𝑛 ×100 Normalized Difference Vegetation Index (NDVI) 𝑁𝐷𝑉𝐼=  𝑁𝐼𝑅−𝑅𝑒𝑑 𝑁𝐼𝑅+𝑅𝑒𝑑 where, LST is the land surface temperature, Red is the red band (0.64–0.67 µm), and NIR is the near infrared band (0.85–0.88 µm) of Landsat 8. These have been selected as the four indices for maintaining local drought monitoring [56]. An additional surface water analysis, the normalized difference water index (NDWI), is used to delineate the spatial distribution of open water areas. Rivers and rice fields were excluded from the layer using thresholding over multi-temporal and seasonally aggregated images. The data we processed include reservoirs, lakes, and other water bodies and its temporal changes from surface water data that are stored in the system database of the WMS. NDWI = (Green − NIR)/(Green + NIR) where, Green is the green band (0.543–0.578 µm) and NIR is the NIR band (0.855–0.875 µm) of Sentinel 2. For the current development, S2-based surface water area extraction was estimated. Cloud-masking was carried out based on the quality assessment (QA) band and cloud-pixel percentage. Metadata images that had less than 20 percent pixels with the presence of clouds were selected by filtering out clouds using the QA bands. Following the NDWI calculation, thresholding was applied to extract pixels with water presence. Rivers and inundated agricultural fields were removed using an assigned custom mask. The results of the GEE-based processing are a collection of the VHI, VCI, TCI, NDVI, and NDWI anomalies, which are stored in the Google cloud and presented in the form of maps at 10 to 30 spatial resolutions and graphical images. It provides near real-time monitoring of open water area dynamics and agriculture ecosystems, which is very useful to study of the irrigation, early warning, natural environmental health, agriculture, and river ecosystems and to understand the impact of the spatial distribution of the water stress on vegetation and its temporal evolution over longer time periods. 2.1.2. Automated Web Data Scraping and Extraction in Python Data scraped from multiple websites cannot be directly used by an analysis tool without human intervention. We therefore developed a custom web scraper program based on Python that is installed on the back-end system of the WMS to automatically read the code of a web page and decode it to extract the required data. Since there was a large amount of continuous observational data, we decided to use Python [57] in the development of the web scraper program. Our decision, therefore, was specifically made for the following reasons: it is a free, open-source programming language with a wide active developer base with several supporting packages and an application programming interface (API) to support the handling of large data, support system development, and connect with the preferred database PostgreSQL for data processing pipelines and to connect with GEE platform. We added the custom-developed scraper program to log in to daily updated public access environmental data, including open water level data and groundwater level data, that are disseminated from databases of national and international official sources. The web scraping program was oriented to collect observational data from the agro-hydrometeorological stations for point locations within the national agencies, focusing mainly on rivers, reservoirs, and groundwater well data from the LMR, and thereafter the collected data are stored in the WMS database in accordance with the design schema attributes and formats. 2.1.3. System Database in PostgreSQL Additionally, a back-end relational database management system was developed in the PostgreSQL that stores the web scraped data with the input format of comma-separated values (CSV; Figure 2). The PostgreSQL (https://www.postgresql.org/ accessed on 28 October 2021) was selected for the system because it is an advanced open-source object relational database management system that applies SQL language. The PostGIS extension of the PostgreSQL enhances its capabilities in storage and handing spatial datasets [58,59], thus allowing us to store large and sophisticated data safely and steadily that help to build the most complex database, run administrative tasks, and create integral environments to the WMS. Figure 2. The back-end database management system of the WMS. In the current development, the daily web-scraped data from each source are stocked in the system database in the web server. The data retrieval, including river, reservoir, and groundwater levels, has been processed to derive the spatial and temporal structure and the changing characteristics of open water areas. Since groundwater level data were from more than 100,000 points of observations scattered across the tested basin, it was more feasible to convert them to a finer regular grid using interpolation techniques for the analysis of changes in data over time. We, hence, adopted the inverse distance to power or inverse distance weighted (IDW) algorithm [60,61,62,63,64,65], which is found to give best results for interpolating the continuous earth’s surface. This was executed in Python using GDAL [66] grid functionalities. To calculate value Z at each grid node, the following formula was used. 𝑍= ∑ 𝑛 𝑖=1 𝑍 𝑖 𝑟 𝑝 𝑖 ∑ 𝑛 𝑖=1 1 𝑟 𝑝 𝑖 where 𝑍 𝑖 is a known value at a point i, ri is a distance from the grid node to point i, p is weighted power, and n is number of points in Search Ellipse. For the current study, p is 3 and both radii of the Search Ellipse are 5. The resulting interpolated raster is transferred to the Google cloud platform to enable its access through the GEE. 2.1.4. Web-Based Water Monitoring System We automated user access and the output processes of the WMS through a web-based interface to assess a suite of drought characteristics at the multiple timescales, from daily to annual, at a 10 to 30 m spatial resolution. The web-based interface has been designed to be user-friendly and easily visualize the results, while the processing chain is essentially a computational routine in the back-end system. Our real-time web-based water monitoring system is accessible over the web at the following URL: https://thailand-water-monitor.more-rivers.com/ (accessed date on 4 November 2021). Figure 3 depicts the interface with two highlighted parts. First (3a), a list of input variables is in the contents pane where users can specify a river basin, a time-series for monitoring water and drought conditions, a water index, and a vegetation drought index of interest to derive conditions of the open water areas and the evolution of droughts. This includes the reservoir usable water status, a collection of vegetation indices (VHI, VCI, TCI, and NDVI) and the groundwater level changes. The interaction is conducted via the clicking of choices, while moving of sliders allows users to see more or less of the underlying maps. The transparency, or opacity, of any index can be adjusted from 0% to 100%. The more transparent a layer is, the less visible it appears on the resultant map and the more visible the other layers appear. By default, the base map is 0% transparent which means it is fully visible. If users want to focus attention on a specific result of the index map layer, they might consider making it fully visible and adding transparency to the other layers. Second (3b), the right pane is the output window, where it shows an interactive global map for displaying spatially varying responses of open water area changes and drought conditions. The outputs can also be shown as an interactive time-series plot for the changes by switching between the Controls tab and Charts tab in the contents pane. Figure 3. (a) The right-hand pane contains available input variables of the current version of the web-based WMS interface for users. (b) The left-hand pane shows the base map and the results of spatiotemporal distribution of drought from simulations with the WMS. All figures and time-series plots are the output of the simulated spatial and temporal extents of areas vulnerable to potential extreme weather events at a selected location and overall statistics, respectively. Users can further evaluate the simulated results in the spirit of a data-driven decision-making processes. Specifically, they can access the current condition of open water areas and droughts, respond to hazards or early warnings more effectively, and provide a comparison of the current water and drought events to past events. The users can obtain a daily vegetation index map and an analysis of open water area changes, and these illustrate the spatial extent and index variation of drought and water through the web-based interface of the WMS. The system can be used by decision-makers and technical users to assess drought and water warning conditions and facilitate the management of actionable drought mitigation measures through near real-time monitoring of drought dynamics, in terms of both hydrological and vegetation variables. On the back-end system, the web-based application processes users’ inputs and triggers a simulation of water and drought assessment at a high spatial resolution. It can easily become an overwhelming task if one wants to simulate all indices at one time. Instead, in this case, the WMS prepares input files, calls the system executable program, and then retrieves outputs for producing spatial and temporal maps and time-series plots. It is, therefore, worth nothing that for a large-scale basin study with a selection of multiple indices, the latency between users’ inputs and output display can be large, due to the longer simulation time. Therefore, the WMS was designed to process users’ requests into the input files and quickly retrieve outputs after simulation for displaying results on the front-end user interface. 2.2. Testing the WMS in the Case Study Area Here, we present a case study in which we applied the WMS to Thailand’s river basins (Figure 4a). The case study provides a lens for the understanding of the WMS’s performance and reliability through the practical experience of functionalities, computation time, the simulated results, and the potential development for additional functionalities to deepen and broaden the results in the future. The results and discussions of the case study are presented in the next section, focusing on the highlighted application and utility of the WMS. Figure 4. (a) Map of the 25 major basins in Thailand and the territory of the Lower Mekong Basin. (b) Map of the Chi River Basin in northeastern Thailand reprinted from the web-based WMS interface. Specifically, the WMS was tested in the Chi River Basin (Figure 4b), which is located in northeastern Thailand. The basin has a population of around 6.6 million people in the total land area of 49,131.22 square kilometers (km2). It is composed of mountainous terrain where it forms the border between the Mun Basin in the south, the Mekong and Mun Basins in the east, and the Pasak watershed in the west. The topographic terrain varies between 170 m and 300 m with mountain ranges between 500 m and 1000 m, situated between 15°30′ and 17°30′ N latitude and 101°30′ and 104°30′ NE longitude and influenced by the tropical monsoon. The annual average temperature is 26.9 °C, and the mean annual precipitation is approximately 1170 millimeters (mm), increasing from west to east with a monthly average of 2.3–243.7 mm. Most of the basin population engages in agriculture on the 60% arable land where there are rice fields (41%), forest (31%), urban (2.9%), water bodies (2.5%) and other lands (3.5%). Rice farming is found in the middle and downstream of the Chi River Basin. Most rainfed rice is grown during the rainy season (June-December) and the second crop of rice is commonly planted under irrigation during the dry season (January-April). Cassava and sugarcane are harvested all year. The main cassava growing region is in the southwest and north basin, while sugarcane is produced in the northwestern, north, and southwest basins. The Chi River Basin is naturally prone to droughts and floods, due to the influence of the quite irregular and unreliable rainfall, and that makes the basin vulnerable to such hazards. The basin has experienced extensive rice growing and spatial land cover changes with a rapid urban transformation. These changes have resulted in the increased competition of water resources in different sectors. Climate change has already happened at a much faster rate and its devastating impacts have unintended consequences on the local natural systems and people living in poor and marginal conditions. Thus, the lack of a leading edge of knowledge on the local vulnerability and exposures to climate change, the observed impacts, future climate risks, and the associated potential limits adaptation and management at the sub-national levels [67,68,69]. 2.3. Correlation Analysis of the Simulated Drought Indices To compare how well the drought indices can assess the near real-time water dynamics and drought evolution in the present, we used two approaches. First, we snapped the simulated drought indices of the NDVI, VHI, VCI, and TCI to the same extent of the tested Chi River Basin. Every data layer contained different values of active pixels representing the tested basin. Within the GEE environment, we generated 300 random points across the Chi River Basin (Figure 5) and marked them as the agriculture or non-agriculture for training points, based on the LandCover data [70]. Areas with no clear determination were omitted from the correlation coefficient assessments. These points were further used to extract the pixel values of the drought indices stored in the GEE assets. For datasets in the database, a spatial query was executed to extract values of the groundwater level, reservoir water volume, and dam water volume. The values of the same point locations from different drought indices and database queried data were aggregated in a tabular format, providing simultaneous values of parameters, such as point number, date time, NDVI, VHI, etc. These data were aggregated to a 16-day time steps for each date stamp (n = 24) at the basin. Figure 5. Training data of the 300 random points across the tested Chi River Basin. As the second approach, we used the ggpairs function of the GGally R Package (https://cran.r-project.org/web/packages/GGally/index.html accessed on 10 January 2022) to evaluate the correlations between the groundwater level, reservoir water volume, and dam water volume data and the corresponding values of each index. A matrix of twenty-eight scatter plots was drawn and the Pearson correlation coefficients were calculated for visualizing the intercomparison between the eight variables at bi-weekly scale (16-days composite data) in the tested basin. Due to the first-year implementation of the WMS, we only sought to test whether vegetation greenness varied with groundwater level, reservoir water volume, and dam water volume from 1 January 2021 to 31 December 2021 across the Chi River Basin. 3. Results As Figure 6 shows, there was strong positive correlation between VHI with VCI (r = 0.908), with TCI (r = 0.802), and with NDVI (r = 0.772) for 2021. This implies that VHI is considered a good indicator, as it provides better comprehension between the relative effects of temperature changes (TCI) and vegetation responses (VCI). Figure 6 also demonstrates a positive correlation with a high statistical significance between the dam and reservoir water volume variations. The overall positive correlations were generally stronger between VHI and the changes of annual reservoir water volumes (RID_Resv; r = 0.498) than EGAT dam water volumes (r = 0.442) and RID_Dam water volumes (r = 0.399). The spatiotemporal patterns were very similar to the correlation obtained with the VCI, which had higher positive significance with the changes of annual RID_Resv (r = 0.501) than EGAT dam water volumes (r = 0.483) and RID_Dam water volumes (0.471). Generally, NDVI showed a statistically significant positive relationship with the surface water volume datasets of EGAT (r = 0.575), RID_Dam (r = 0.566), and RID_Resv (r = 0.520), accordingly. These demonstrate the advantage of using NDVI over the other drought indices, due to its capacity in identifying and exploring the variations and changes of surface water and vegetation. Figure 6. Correlation coefficient assessments of the drought indices with groundwater level, reservoir water volume, and dam water volume in the Chi River Basin in 2021. The scatter plots are the average of the outputs of the WMS, based on a 16-day time step. *, **, and *** denote statistically significant correlation at the p ≤ 0.05, ≤ 0.01, and ≤ 0.001 levels of probability, respectively. In contrast to the surface water changes, groundwater level (GW) had a statistically significant negative correlation with NDVI (r = −0.355), TCI (r = −0.391), VCI (r = −0.504), and VHI (r = −0.534). This means that a further analysis with long time-series of in-situ data and hydrologically and meteorologically sensitive parameters could help in forging their intercomparison. Figure 7 presents the WMS simulation results, showing the observational data (a) and the multi-temporal trend of the drought indices for the dry season in the Chi River Basin (b–f). To reduce the wait time for the WMS users to switch between datasets in real time to intercompare, datasets are preloaded, based on the user query. This usually takes 4 to 7 s, depending on the number of user requests and total number of active users on the application. The data points presented in (a) are the total number of reservoirs and dams sparsely located across the Chi River Basin and operated by the national departments in Thailand, named specifically the Electricity Generating Authority of Thailand (EGAT), the Royal Irrigation Departments (RID) and the international government agency the Mekong River Commission (MRC). Once these data points appear and upon hovering over a data point on the display map, it shows information on the station name, the usable water volume in million cubic meters (MCM), the storage capacity (MCM), and the percent (%) of usable water volume. Figure 7. The simulated outputs of (a) Usable water storage capacity over time, High resolution drought monitoring information based on (b) VHI, (c) VCI, (d) TCI, and (e) NDVI; and (f) Spatial groundwater-surface analysis based on IDW in the tested basin. The monitoring was conducted in the drier season between 28 January 2021, and 30 April 2021. The three bars on the left corner of the contents pane provide a reference for usable water (%; left), drought index variation (middle), and quantitative changes in groundwater levels (right). Across most of the Chi River Basin, drought is one of the major natural disasters affecting dimensional economies. The agriculture and its products of this basin play an important role for food security in the country, and this agricultural food production is highly affected by drought, which is associated with water deficits. It depends mostly on the arrival time and location of the Intertropical Convergence Zone (ITCZ). Overall, in (b–e), the results of the 4-month monitoring maps obtained from the 16-day composite data show that the basin was not suffering severe agricultural drought during the 2021 dry season when it was evaluated by scientifically accepted thresholds (scale from 0 to 1; of which >0.5 demonstrates no drought phenomena) [71,72]. The 2021 dry season observed a moderate agricultural drought period across the basin, where the bi-weekly VHI values were averaged over each of the total provinces in the Chi River Basin with a range between 0.32 and 0.43 (b). This responded to the varying color ramps of the data points at a specific location, for which red is the usable water surplus and brown is the water deficits. As (c) shows, the VCI did not show vegetation water stress in most regions, and only slightly below normal vegetation conditions (VCI ranged between 0.37 and 0.66) at the end of April 2021 were observed in the northwestern and southeastern Chi River Basin, mostly due to temperature stress (see also the TCI spatial distribution map in (d). Following the consideration, the largest TCI values during the 2021 dry season were calculated from the 16-day composite data of the 15 weeks. It was noticeable that the vegetation amount developed healthily during the dry season with more favorable weather (TCI valued between 0.59 and 0.80) for crop growth and successful farming. The main zones included vary favorable weather in the southwestern, north, and northeastern basin. Similarly, no disturbances were observed on the spatial distribution of the NDVI productivity, showing a good NDVI coverage range. In (e), the NDVI values ranged between 0.56 and 0.78. These indices characterizing VCI (moisture), TCI (thermal), VHI (vegetation health) and NDVI (vegetation condition) demonstrated healthy vegetation, which was associated with favorable moisture and thermal conditions, corresponding with a study showing no 2020/21 drought in Thailand so far. The interpolation map in (f) is displayed with a brown to blue color ramp map, which indicates deep to shallow groundwater areas. This result was obtained by using the complete sounding groundwater level data in the basin using IDW. It is visually evident that the spatial distribution of daily groundwater levels was located around the central parts of the Chi River Basin. These results are also given in the form of time-series plots, as shown in Figure 8. The Charts tab in the contents pane (a) controls the opening of the output window and takes users to multiple time-series plots of the open water areas and vegetation water stress estimates. The analytics in the graphical image make it easier for users to observe and gain a broad understanding of the statistics of the drought monitoring information and the multi-temporal trend of the surface waters in different point or pixel locations. However, it is worth nothing that the NDWI values obtained from the daily surface water data are only presented in the form of a time-series plot under the Usable Water plot (b), while ground water IDW interpolation, which is presented in maps, is yet included and displayed in the Vegetation Index plot (c). Figure 8. (a) Time-series comparison graph between observational data of the RID reservoir water volume, RID dam water volume, and EGAT dam water volume for 2021, and (b) between drought simulation of VHI, VCI, TCI, and NDVI indices. (c) The simulated results of high-resolution spatiotemporal map derived from the WMS. 4. Discussion The WMS has marked the first attempt in the development of near real-time monitoring system that integrates multi-source observational data scraping, GEE cloud computing, remote sensing technology, and user intuitive feedback for the monitoring of water changes and drought evolution in the LMR. This development has also laid a solid foundation for integrating accelerating progress on the SDGs. The methodological approach is implemented in an automated processing chain, which makes the products available through a dynamic web-based interface. We have concluded that there is no relevant research on the combination of water and drought monitoring at a 10–30 m spatial resolution in the region and it is still very limited in most parts of the world [36]. Moreover, the methodological approach for treating the establishing goals is believed to be the innovative aspect of the research, with potential scalability and operationality to other case studies. The promotion of this conceptualized methodology for an open-access high-resolution near real-time drought monitoring web-based platform is considered a merit of the current research and future development work. 4.1. Monitoring Information and Potential Limitations of Drought and Water Indices The WMS has been developed for drought simulation and changes in open water area information and offered several remotely sensed agricultural drought indices (VHI, VCI, TCI, NDVI, and NDWI) at a 10–30 m spatial resolution in the data poor region of the LMR (Figure 7). However, the current development of the study has not yet offered near real-time drought monitoring information using hydrological and meteorological drought indices. These could limit the capacity of drought simulation and incompletely characterize and monitor the spatial and temporal patterns of drought incidences in depth [71]. Different indices for drought monitoring have their limitations. For instance, NDVI is very sensitive to the atmospheric scattering effects directly on the earth’s surface [73]. NDWI has, thus, been suggested to use as a complementary index of open water area monitoring to in situ monitoring data and NDVI that can help improve the understanding of its useful and reduced limitations, giving better results and reducing the sensitivity of vegetation stress and open water area estimates [73,74,75]. Several different simulated drought indices, hence, provide different index variations, varying with the temporal and spatial patterns and revealing better drought characteristics [76,77]. 4.2. Practicality and Legality of Web Data Scraping Here, the web data scraper program proved very useful for delivering big data and facilitating the automatic harvesting of a plethora of environmental data [25,42], i.e., river depths, groundwater levels, reservoir and dam waters, on a daily basis, publicly and constantly published on the internet. Although the web scraping stands out as a significant advantage over traditional copy and paste approach by leveraging multi-source data and reducing task duplication, one of the bottlenecks in applying this approach is that it is not always easy to keep track of website structure of the national or international official sources. Each website has a particular structure, which may be subject to changes, i.e., graphical user interface (GUI), anytime, and that directly affected the scraping process of the program. Consequently, the back end of the WMS often requires few lines of code for tackling such changes and is periodically updated. This issue would be solved if there was a collaborative agreement for data or service sharing with the national and or international official sources to grant direct access to their database via HTTPs or FTP [78]. Controversially, the web data scraping approach remains a topic of debate and is strictly restricted in some parts of the world, despite environmental data being publicly provided on the internet. It is, therefore, essential to check for licensing or copyright restrictions on the extracted data and to share the custom-made scraper code with the scientific community. We, therefore, will publish the codes in Github so that others can discover, study, and build on what we have done. This was one of the establishing goals for the scalability of the WMS development in other regions. 4.3. Output Validation The correlation matrices revealed that dam and reservoir water volumes were positively correlated with the drought indices, but the overall TCI correlation values did not give a strong indication of the changes of surface water volumes and groundwater levels. This indicates the overall accuracy and validity of the WMS performance in multiple ways. First, the observational data we web-scraped from the national and international official sources can guide the appropriate remote sensing indices to best represent current and past events. Second, spatiotemporal distribution mapping services help the monitoring from point-based to region-based. Third, long-term series of hydrological and meteorological data can enrich the short time-series of remotely sensed data through simulation [79,80]. In our assessment, the WMS supplements existing knowledge of drought coherence in the LMR by assessing and providing quantitatively spatiotemporal variations (10–30 m) of local surface water changes and local drought evolution. Moreover, the WMS also highlights that the gridded drought datasets can be a reasonable alternative to observational station data for surface water change and drought assessments where observed data is not readily available. There was a negative correlation between the different drought indices, NDVI, TCI, VCI, VHI, and groundwater levels. This suggests that further investigation and more detailed analyses of the influence of different drought types on groundwater condition should consider other in-situ factors, such as precipitation, soil moisture, wind speed, temperature, clouds, vegetation coverage, and other weather variables. The particular attention should be paid to the physical properties of land cover in the adjacent areas of the groundwater wells, the hydraulic properties of aquifers, and human interventions. Comprehensive data and information on various parameters of the groundwater drought are needed for operational decision-making and planning, policy development, and infrastructure design at national and basin levels [21]. 4.4. Limitations of Optical Remote Sensing Imageries In the case application, there were gaps in the spatiotemporal information appearing in some parts of the Chi River Basin, due to a cloud contamination issue. This is especially a known issue for optical remote sensing imageries, such as Landsat 8 and Sentinel 2. Specifically, these imageries are subject to data loss due to cloud coverage hindering the retrieval of spatiotemporal information when using them from the visible to infrared optical spectrum [80,81,82,83]. It is, therefore, necessary to detect and remove clouds while pre-processing of the imageries to avoid inclusion of cloud-contaminated composite pixels into image processing [84]. Strong seasonal changes of rainfall and atmospheric patterns is a dominant feature of the intertropical convergence zone (ITCZ) in the LMR and leads to the formation of different cloud patterns throughout the year [85,86]. This, consequently, has a high determining impact in the region to acquire cloud-free imageries. Hence, it is essential to remove cloudy pixels from the imageries to have a reasonably consistent coverage over a location, preserving a non-cloudy patch of image while there is loss of data in the other areas. This is particularly exemplified in the monsoon months (June–November) when entire scenes are covered by clouds, rendering images useless for the generation of remote sensing indices and causing a gap in the analysis. It is a caveat that must considered when building an operational system. There have been few effective approaches of reducing the cloud issue when using Landsat-Sentinel 2 fusion or Optical-SAR fusion imageries, which have different overpass time-dates and, thus, can increase the number of cloud-free pixels [86,87,88]. 4.5. User Interface and Future Work At the moment, actual processing and visualization of vegetation water stress simulation within the developed WMS is assembled in a very simple and a user-friendly interface (i.e., sliders, study basin, vegetation index, etc.; see Figure 3). WMS allows user feedbacks on interface inputs and the core functions for creating drought and water monitoring information that allow the participation of users (mainly focusing on water managers and decision-makers), so they can evaluate the system performance and provide feedback from their direct experience. This is, thus, the beta version WMS, which is a fully functional system and will evolve into a fully designed graphical user interface in the future version. 4.6. Utilization and Maintenance of the WMS There is a continuous endeavor to create a resourceful WMS, with the goal of enhancing local vegetation water stress monitoring and generating timely and accurate drought information and characteristics of water dynamics. This development is highly scalable and provides tools, databases, and networking services that give government agencies an unprecedented opportunity to harness useful, real-time information about water and drought simulation. However, the government often lack the dedicated expertise and resources to collect, analyze, and create scientific information or products that can inform decision-making processes and assist multi-level policymakers to navigate the potential risks associated with water changes and drought evolution. Thus, the products are available to different interest groups for visualization and exploration [21,31]. The practical solution would be engaging the government with a team of developers in the development process. To utilize WMS and interpret its output, user requires a good knowledge about the variables in different drought algorithms, for instance, the correlation of vegetation and temperature dynamics during the annual cycle (NDVI) and the contributing factors of temperature and soil saturation affecting vegetation health (VCI and TCI) [16,48,56,75,76], that will help gain a more thorough understanding of the bio-physical processes and their relationships, causing potential impacts of vegetation water stress. 4.7. Supporting Water Management Decisions and the SDGs The WMS of this paper validated the usefulness of multi-source data and advanced digital technology for monitoring water dynamics and assessing vegetation water stress at the local scale. The WMS currently provides more readily and simplified drought simulation information about the complex and slow evolution of drought phenomena at a 10–30 m spatial resolution. The WMS can be used in a participatory process in order to improve effective communication and transparency with end-user decision makers, water managers, and the general public. The simulation information of the WMS can be taken as a primary analysis of drought and water level changes. Further, it can be used to quantify potential changes and their cascading impacts in agricultural production, irrigation, and water resources management. This level of information provides changes in scale and, over time, guides ways of dealing with an alarming situation, such as drought, flood, irrigation scheduling, land use planning, and crop management. This is considered to be an innovative methodological framework that enables it to fully explore the feedback of human decisions on the environmental dynamics and vice versa. The drought simulation information can be used to establish benchmarks or trigger points as a quantitative basis for making critical decisions, to design disaster risk reduction policies, and to monitor the effectiveness of the policies. It will also be important to have an indicator for preparedness and recovery time fitted in to the local environments. Given these demonstrations, they can enhance the methodological and developmental framework to support evidence-based policy making towards achieving the SDGs, formalizing coordinated multi-source observational data and digital technologies (remote sensing, GEE cloud computing, and user interface) for supporting national and local governments to improve the quality of their decision-making, and assisting the governments to increase efficiency and effectiveness in drought and water resource management. 5. Conclusions This paper shows that we have begun the development of the high-resolution drought monitoring system to provide evidence-based information to support decision-makers at the local scales (10–30 m). The WMS outputs can help establish or prepare proactive measures for water, agriculture, and drought management strategies on a near real-time basis. Using the developed WMS, local drought evolution and changes of small-scale river basins (<10,000 km2) can be practically assessed within 2 weeks. The results obtained from the WMS drought indices are useful for the primary analysis and can be further used to study different drought types and monitor the effects of droughts on vegetation growth (NDVI), vegetation moisture condition (VCI), land surface temperature (TCI), and vegetation health (VHI). This is a vital step for local food security, land and water management, and beyond. We anticipate that the beta version of the current WMS development will bring more progress in the application of high-resolution operational and research communities. We will continue to enhance the performance of water monitoring and drought hazards at the high spatial resolution, improve graphical visualization in the front-end interface, increase functionalities in the back- and front-end systems, and better assess spatial and temporal drought monitoring index variations. This newly developed WMS is geared toward the early warning of water and agricultural development and progress on the SDGs. Utilization of digital innovation and capacity development will be aggressively pursued with target users in the tested basin. The WMS will also widen the abilities of decision-makers to monitor and foresee extreme weather events earlier and with high spatial accuracy. The new high-resolution capacity of the WMS enables us to help with precision water and agriculture and the ability to move from the problem of detection to the mitigation of negative consequences due to water and drought anomalies. Continuously advancing digital technologies (GEE, remote sensing, and data sciences) will strengthen the ability to estimate the potential effectiveness of applied technology to optimize adverse impacts in a more proactive way. Author Contributions Conceptualization, O.-u.P.; methodology, O.-u.P., D.B. and T.F.S.S.; software D.B.; validation, O.-u.P. and D.B.; formal analysis, O.-u.P. and D.B.; investigation, O.-u.P. and D.B.; resources, O.-u.P. and D.B.; data curation, O.-u.P. and D.B.; writing—original draft preparation, O.-u.P.; writing—review and editing, O.-u.P., D.B., T.F.S.S. and C.K.; visualization, O.-u.P. and D.B.; supervision, O.-u.P. and C.K.; project administration, O.-u.P. and D.B.; funding acquisition, O.-u.P. and D.B. All authors have read and agreed to the published version of the manuscript. Funding The “an open source toolbox for integrated monitoring and assessment of droughts in developing countries”, Stockholm Environment Institute, Seed and Innovation Fund’s project number 10030500” funded the development of the WMS beta version and financed the preparation of the manuscript (June 2020–October 2021). Institutional Review Board Statement Not applicable. Informed Consent Statement Not applicable. Data Availability Statement Not applicable. Acknowledgments The authors thank the Stockholm Environment Institute (SEI) for their financial and administration support throughout the implementation of the project and the WMS development. We are grateful to the SEI GRC peers and the SEI Asia Centre seniors for comments and suggestions. We sincerely thank the project team for this successful development of the WMS beta version. Conflicts of Interest The authors declare no conflict of interest. References Singh, A.; Mishra, S.; Hoffpauir, R.J.; Marsh Lavenue, A.; Deeds, N.E.; Jackson, C.S. Final Analyzing Uncertainty and Risk in the Management of Water Resources for the State of Texas; Texas Water Development Board: Austin, TX, USA, 2010. [Google Scholar] Lovgren, S. Mekong River at its Lowest in 100 Years, Threatening Food Supply. Available online: https://www.nationalgeographic.com/environment/article/mekong-river-lowest-levels-100-years-food-shortages (accessed on 4 October 2021). Manorom, K. Thailand’s Big Water Challenge. Diplomat 2020. Southeast Asia. Available online: https://thediplomat.com/2020/03/thailands-big-water-challenge/ (accessed on 21 November 2021). Arunmas, P.; Apisitniran, L.; Kasemsuk, N. Falling water levels deliver a taste of things to come. Bangkok Post Newspaper 2020, Business. Available online: https://www.bangkokpost.com/business/1834279/falling-water-levels-deliver-a-taste-of-things-to-come (accessed on 21 November 2021). Saigoneer Serious Drought Expected to Hit Lower Mekong Countries through Early 2020. Available online: https://saigoneer.com/asia-news/17837-serious-drought-expected-to-hit-lower-mekong-countries-through-early-2020 (accessed on 4 October 2021). Taylor, M. Severe drought predicted for Thailand and neighbouring countries | The Thaiger. 2019. Available online: https://thethaiger.com/ (accessed on 30 October 2021). Polpanich, O.; Krittasudthacheewa, C.; Pumchawsaun, P.; Piman, T. Enhancing Data-Sharing Mechanism in the Mekong-Lancang River Basin: Opportunities and Challenges; Stockholm Environment Institute: Bangkok, Thailand, 2019. [Google Scholar] Friend, R.; Thinphanga, P. Urban Water Crises under Future Uncertainties: The Case of Institutional and Infrastructure Complexity in Khon Kaen, Thailand. Sustainability 2018, 10, 3921. [Google Scholar] [CrossRef] [Green Version] Van Loon, A.F.; Van Lanen, H.A.J. Making the distinction between water scarcity and drought using an observation-modeling framework. Water Resour. Res. 2013, 49, 1483–1502. [Google Scholar] [CrossRef] Li, Y.; Lu, H.; Yang, K.; Wang, W.; Tang, Q.; Khem, S.; Yang, F.; Huang, Y. Meteorological and hydrological droughts in Mekong River Basin and surrounding areas under climate change. J. Hydrol. Reg. Stud. 2021, 36, 100873. [Google Scholar] [CrossRef] United Nations Office for Disaster Risk Reduction (UNDRR). GAR Special Report on Drought 2021; UNDRR: Geneva, Switzerland, 2021. [Google Scholar] Yuan, L.; He, W.; Liao, Z.; Degefu, D.M.; An, M.; Zhang, Z.; Wu, X. Allocating Water in the Mekong River Basin during the Dry Season. Water 2019, 11, 400. [Google Scholar] [CrossRef] [Green Version] Payus, C.; Ann Huey, L.; Adnan, F.; Besse Rimba, A.; Mohan, G.; Kumar Chapagain, S.; Roder, G.; Gasparatos, A.; Fukushi, K. Impact of Extreme Drought Climate on Water Security in North Borneo: Case Study of Sabah. Water 2020, 12, 1135. [Google Scholar] [CrossRef] Mekong River Commission Secretariat (MRCS) Landmark MRC-China’s Joint Study Approved for Implementation, New Indicative Ending Date for Sanakham Dam Set. Available online: https://www.mrcmekong.org/news-and-events/news/pr-20210921/ (accessed on 20 October 2021). ASEAN. ASEAN Regional Plan of Action for Adaptation to Drought 2021–2025; ASEAN Secretariat: Jakarta, Indonesia, 2021; ISBN 978-623-6945-64-3. [Google Scholar] World Meteorological Organization (WMO); Global Water Partnership (GWP). Benefits of Action and Costs of Inaction: Drought Mitigation and Preparedness-a Literature Review (N. Gerber and A. Mirzabaev); Integrated Drought Management Programme (IDMP): Stockholm, Sweden, 2017. [Google Scholar] Chen, W.; He, B.; Ma, J.; Wang, C. A WebGIS-based flood control management system for small reservoirs: A case study in the lower reaches of the Yangtze River. J. Hydroinformatics 2016, 19, 299–314. [Google Scholar] [CrossRef] Jung, Y.; Shin, Y.; Won, N.-I.; Lim, K.J. Web-Based BFlow System for the Assessment of Streamflow Characteristics at National Level. Water 2016, 8, 384. [Google Scholar] [CrossRef] [Green Version] Zhang, D.; Chen, X.; Yao, H. Development of a Prototype Web-Based Decision Support System for Watershed Management. Water 2015, 7, 780–793. [Google Scholar] [CrossRef] Nam, W.-H.; Choi, J.-Y.; Yoo, S.-H.; Engel, B.A. A Real-Time Online Drought Broadcast System for Monitoring Soil Moisture Index. KSCE J. Civ. Eng. 2012, 13, 357–365. [Google Scholar] [CrossRef] Leb, C. Data Innovations for Transboundary Freshwater Resources Management: Are Obligations Related to Information Exchange Still Needed? Brill Res. Perspect. Int. Water Law 2020, 4, 3–78. [Google Scholar] [CrossRef] Mcdonald, S.; Mohammed, I.; Bolten, J.; Pulla, S.; Meechaiya, C.; Markert, A.; Nelson, J.; Srinivasan, R.; Lakshmi, V. Web-based decision support system tools: The Soil and Water Assessment Tool Online visualization and analyses (SWATOnline) and NASA earth observation data downloading and reformatting tool (NASAaccess). Environ. Model. Softw. 2019, 120, 104499. [Google Scholar] [CrossRef] [PubMed] Nijssen, B.; Shukla, S.; Lin, C.; Gao, H.; Zhou, T.; Ishottama; Sheffield, J.; Wood, E.F.; Lettenmaier, D.P. A Prototype Global Drought Information System Based on Multiple Land Surface Models. J. Hydrometeorol. 2014, 15, 1661–1676. [Google Scholar] [CrossRef] Savic, D.A.; Morley, M.S.; Khoury, M. Serious Gaming for Water Systems Planning and Management. Water 2016, 8, 456. [Google Scholar] [CrossRef] [Green Version] Sazib, N.; Mladenova, I.; Bolten, J. Leveraging the Google Earth Engine for Drought Assessment Using Global Soil Moisture Data. Remote Sens. 2018, 10, 265. [Google Scholar] [CrossRef] [Green Version] Shrestha, M.; Matheswaran, K.; Polapanich, O.-P.; Piman, T.; Krittasudthacheewa, C. A Stakeholder-Centric Tool for Implementing Water Management Strategies and Enhancing Water Cooperation (SDG 6.5) in the Lower Mekong Region. In Water, Climate Change, and Sustainability; Wiley Online Books; Pandey, V.P., Shrestha, S., Wiberg, D., Eds.; John Wiley & Sons, Inc.: Hoboken, NJ, USA, 2021; pp. 239–256. ISBN 9781119564522. [Google Scholar] Van Hoek, M.; Zhou, J.; Jia, L.; Lu, J.; Zheng, C.; Hu, G.; Menenti, M. A prototype web-based analysis platform for drought monitoring and early warning. Int. J. Digit. Earth 2020, 13, 817–831. [Google Scholar] [CrossRef] Zhang, D.; Fu, W.; Lin, Q.; Chen, X. WOF-SWAT: A Web-Based Open-Source Framework for Investigating the Hydrological Impacts of Climate Change and Human Activities Through Online Simulation and Visualization of SWAT Models. ISPRS Int. J. Geo-Inf. 2019, 8, 368. [Google Scholar] [CrossRef] [Green Version] Cammalleri, C.; Barbosa, P.; Vogt, J. V Evaluating simulated daily discharge for operational hydrological drought monitoring in the Global Drought Observatory (GDO). Hydrol. Sci. J. 2020, 65, 1316–1325. [Google Scholar] [CrossRef] Sheffield, J.; Wood, E.F.; Pan, M.; Beck, H.; Coccia, G.; Serrat-Capdevila, A.; Verbist, K. Satellite Remote Sensing for Water Resources Management: Potential for Supporting Sustainable Development in Data-Poor Regions. Water Resour. Res. 2018, 54, 9724–9758. [Google Scholar] [CrossRef] [Green Version] Polpanich, O.; Ghilmire, U.; Chuthong, J.; Piman, T. Country Modelling Baseline Data Report: Regional Survey of Water Modelling Capacity and Policy Impacts; Stockholm Environment Institute and Food and Agriculture Organization: Bangkok, Thailand, 2021. [Google Scholar] Du, T.L.T.; Bui, D.D.; Nguyen, M.D.; Lee, H. Satellite-Based, Multi-Indices for Evaluation of Agricultural Droughts in a Highly Dynamic Tropical Catchment, Central Vietnam. Water 2018, 10, 659. [Google Scholar] [CrossRef] [Green Version] Saha, T.R.; Shrestha, P.K.; Rakovec, O.; Thober, S.; Samaniego, L. A drought monitoring tool for South Asia. Environ. Res. Lett. 2021, 16, 54014. [Google Scholar] [CrossRef] Wang, X.; Xie, H. A Review on Applications of Remote Sensing and Geographic Information Systems (GIS) in Water Resources and Flood Risk Management. Water 2018, 10, 608. [Google Scholar] [CrossRef] [Green Version] Jung, H.C.; Kang, D.-H.; Kim, E.; Getirana, A.; Yoon, Y.; Kumar, S.; Peters-lidard, C.D.; Hwang, E. Towards a soil moisture drought monitoring system for South Korea. J. Hydrol. 2020, 589, 125176. [Google Scholar] [CrossRef] Kooistra, L.; Bergsma, A.; Chuma, B.; de Bruin, S. Development of a Dynamic Web Mapping Service for Vegetation Productivity Using Earth Observation and in situ Sensors in a Sensor Web Based Approach. Sensors 2009, 9, 2371–2388. [Google Scholar] [CrossRef] [Green Version] Rojas, O.; Vrieling, A.; Rembold, F. Assessing drought probability for agricultural areas in Africa with coarse resolution remote sensing imagery. Remote Sens. Environ. 2011, 115, 343–352. [Google Scholar] [CrossRef] Trnka, M.; Hlavinka, P.; Možný, M.; Semerádová, D.; Štěpánek, P.; Balek, J.; Bartošová, L.; Zahradníček, P.; Bláhová, M.; Skalák, P.; et al. Czech Drought Monitor System for monitoring and forecasting agricultural drought and drought impacts. Int. J. Climatol. 2020, 40, 5941–5958. [Google Scholar] [CrossRef] Aadhar, S.; Mishra, V. High-resolution near real-time drought monitoring in South Asia. Sci. Data 2017, 4, 170145. [Google Scholar] [CrossRef] [Green Version] Cumbie-Ward, R.V.; Boyles, R.P. Evaluation of a High-Resolution SPI for Monitoring Local Drought Severity. J. Appl. Meteorol. Climatol. 2016, 55, 2247–2262. [Google Scholar] [CrossRef] Zhang, X.; Chen, N.; Sheng, H.; Ip, C.; Yang, L.; Chen, Y.; Sang, Z.; Tadesse, T.; Lim, T.P.Y.; Rajabifard, A.; et al. Urban drought challenge to 2030 sustainable development goals. Sci. Total Environ. 2019, 693, 133536. [Google Scholar] [CrossRef] Gomes, V.C.F.; Queiroz, G.R.; Ferreira, K.R. An Overview of Platforms for Big Earth Observation Data Management and Analysis. Remote Sens. 2020, 12, 253. [Google Scholar] [CrossRef] [Green Version] Chander, G.; Markham, B.L.; Helder, D.L. Summary of current radiometric calibration coefficients for Landsat MSS, TM, ETM+, and EO-1 ALI sensors. Remote Sens. Environ. 2009, 113, 893–903. [Google Scholar] [CrossRef] Fletcher, K. Sentinel-2: ESA’s Optical High-Resolution Mission for GMES Operational Services (ESA SP-1322/2 March 2012); European Space Agency: Leiden, The Netherlands, 2012. [Google Scholar] Williamson, A.G.; Banwell, A.F.; Willis, I.C.; Arnold, N.S. Dual-satellite (Sentinel-2 and Landsat~8) remote sensing of supraglacial lakes in Greenland. Cryosph. 2018, 12, 3045–3065. [Google Scholar] [CrossRef] [Green Version] Gorelick, N.; Hancher, M.; Dixon, M.; Ilyushchenko, S.; Thau, D.; Moore, R. Google Earth Engine: Planetary-scale geospatial analysis for everyone. Remote Sens. Environ. 2017, 202, 18–27. [Google Scholar] [CrossRef] Mutanga, O.; Kumar, L. Google Earth Engine Applications. Remote Sens. 2019, 11, 591. [Google Scholar] [CrossRef] [Green Version] Kogan, F.N. Global Drought Watch from Space. Bull. Am. Meteorol. Soc. 1997, 78, 621–636. [Google Scholar] [CrossRef] Kogan, F.N. Operational Space Technology for Global Vegetation Assessment. Bull. Am. Meteorol. Soc. 2001, 82, 1949–1964. [Google Scholar] [CrossRef] Kogan, F.N. Remote sensing of weather impacts on vegetation in non-homogeneous areas. Int. J. Remote Sens. 1990, 11, 1405–1419. [Google Scholar] [CrossRef] Kogan, F.N. Droughts of the Late 1980s in the United States as Derived from NOAA Polar-Orbiting Satellite Data. Bull. Am. Meteorol. Soc. 1995, 76, 655–668. [Google Scholar] [CrossRef] [Green Version] Kogan, F.N. Application of vegetation index and brightness temperature for drought detection. Adv. Sp. Res. 1995, 15, 91–100. [Google Scholar] [CrossRef] Liu, W.T.; Kogan, F.N. Monitoring regional drought using the Vegetation Condition Index. Int. J. Remote Sens. 1996, 17, 2761–2782. [Google Scholar] [CrossRef] Du, Y.; Zhang, Y.; Ling, F.; Wang, Q.; Li, W.; Li, X. Water Bodies’ Mapping from Sentinel-2 Imagery with Modified Normalized Difference Water Index at 10-m Spatial Resolution Produced by Sharpening the SWIR Band. Remote Sens. 2016, 8, 354. [Google Scholar] [CrossRef] [Green Version] McFeeters, S.K. The use of the Normalized Difference Water Index (NDWI) in the delineation of open water features. Int. J. Remote Sens. 1996, 17, 1425–1432. [Google Scholar] [CrossRef] World Meteorological Organization (WMO); Global Water Partnership (GWP). Handbook of Drought Indicators and Indices; Svoboda, M., Fuchs, B.A., Eds.; Integrated Drought Management Tools and Guidelines Series 2; WMO and GWP: Geneva, Switzerland, 2016. [Google Scholar] Van Rossum, G. Python Reference Manual. 1995, 59. Available online: https://ir.cwi.nl/pub/5008/05008D.pdf (accessed on 4 October 2021). Holl, S.; Plum, H. PostGIS Version Geoinformatics 03/2009, 34–36. Available online: http://fluidbook.microdesign.nl/geoinformatics/03-2009/?page=34 (accessed on 4 October 2021). Nguyen, T. Indexing PostGIS databases and spatial Query performance evaluations. Int. J. Geoinformatics 2009, 5, 1–9. [Google Scholar] Fuentes, I.; Padarian, J.; Van Ogtrop, F.; Vervoort, R.W. Comparison of Surface Water Volume Estimation Methodologies that Couple Surface Reflectance Data and Digital Terrain Models. Water 2019, 11, 780. [Google Scholar] [CrossRef] [Green Version] Lee, H.; Kang, K. Interpolation of missing precipitation data using kernel estimations for hydrologic modeling. Adv. Meteorol. 2015, 2015, 935868. [Google Scholar] [CrossRef] [Green Version] Eischeid, J.K.; Pasteris, P.A.; Diaz, H.F.; Plantico, M.S.; Lott, N.J. Creating a serially complete, national daily time series of temperature and precipitation for the western United States. J. Appl. Meteorol. 2000, 39, 1580–1591. [Google Scholar] [CrossRef] Ferraguti, M.; Martínez-de la Puente, J.; Roiz, D.; Ruiz, S.; Soriguer, R.; Figuerola, J. Effects of landscape anthropization on mosquito community composition and abundance. Sci. Rep. 2016, 6, 29002. [Google Scholar] [CrossRef] [PubMed] [Green Version] Teegavarapu, R.S.; Chandramouli, V. Improved weighting methods, deterministic and stochastic data-driven models for estimation of missing precipitation records. J. Hydrol. 2005, 312, 191–206. [Google Scholar] [CrossRef] Xia, Y.; Fabian, P.; Stohl, A.; Winterhalter, M. Forest climatology: Estimation of missing values for Bavaria, Germany. Agric. For. Meteorol. 1999, 96, 131–144. [Google Scholar] [CrossRef] [Green Version] GDAL/OGR. Contributors GDAL/OGR Geospatial Data Abstraction software Library; Open Source Geospatial Foundation: Chicago, IL, USA, 2021. [Google Scholar] Kiguchi, M.; Takata, K.; Hanasaki, N.; Archevarahuprok, B.; Champathong, A.; Ikoma, E.; Jaikaeo, C.; Kaewrueng, S.; Kanae, S.; Kazama, S.; et al. A review of climate-change impact and adaptation studies for the water sector in Thailand. Environ. Res. Lett. 2021, 16, 23004. [Google Scholar] [CrossRef] Li, R.; Shi, J.; Ji, D.; Zhao, T.; Plermkamon, V.; Moukomla, S.; Kuntiyawichai, K.; Kruasilp, J. Evaluation and Hydrological Application of TRMM and GPM Precipitation Products in a Tropical Monsoon Basin of Thailand. Water 2019, 11, 818. [Google Scholar] [CrossRef] [Green Version] Prakongsri, P.; Santiboon, T. Effective Water Resources Management for Communities in the Chi River Basin in Thailand. Environ. Claims J. 2020, 32, 323–348. [Google Scholar] [CrossRef] Buchhorn, M.; Lesiv, M.; Tsendbazar, N.-E.; Herold, M.; Bertels, L.; Smets, B. Copernicus Global Land Cover Layers—Collection 2. Remote Sens. 2020, 12, 1022. [Google Scholar] [CrossRef] [Green Version] Gidey, E.; Dikinya, O.; Sebego, R.; Segosebe, E.; Zenebe, A. Analysis of the long-term agricultural drought onset, cessation, duration, frequency, severity and spatial extent using Vegetation Health Index (VHI) in Raya and its environs, Northern Ethiopia. Environ. Syst. Res. 2018, 7, 13. [Google Scholar] [CrossRef] [Green Version] Zhang, L.; Jiao, W.; Zhang, H.; Huang, C.; Tong, Q. Studying drought phenomena in the Continental United States in 2011 and 2012 using various drought indices. Remote Sens. Environ. 2017, 190, 96–106. [Google Scholar] [CrossRef] Qu, C.; Hao, X.; Qu, J.J. Monitoring Extreme Agricultural Drought over the Horn of Africa (HOA) Using Remote Sensing Measurements. Remote Sens. 2019, 11, 902. [Google Scholar] [CrossRef] [Green Version] Gao, B. NDWI—A normalized difference water index for remote sensing of vegetation liquid water from space. Remote Sens. Environ. 1996, 58, 257–266. [Google Scholar] [CrossRef] Mishra, A.K.; Singh, V.P. A review of drought concepts. J. Hydrol. 2010, 391, 202–216. [Google Scholar] [CrossRef] Zhang, J.; Mu, Q.; Huang, J. Assessing the remotely sensed Drought Severity Index for agricultural drought monitoring and impact analysis in North China. Ecol. Indic. 2016, 63, 296–309. [Google Scholar] [CrossRef] Wang, F.; Wang, Z.; Yang, H.; Zhao, Y.; Li, Z.; Wu, J. Capability of Remotely Sensed Drought Indices for Representing the Spatio–Temporal Variations of the Meteorological Droughts in the Yellow River Basin. Remote Sens. 2018, 10, 834. [Google Scholar] [CrossRef] [Green Version] Skoulikaris, C.; Krestenitis, Y. Cloud Data Scraping for the Assessment of Outflows from Dammed Rivers in the EU. A Case Study in South Eastern Europe. Sustainability 2020, 12, 7926. [Google Scholar] [CrossRef] Chen, Y.; Huang, C.; Ticehurst, C.; Merrin, L.; Thew, P. An Evaluation of MODIS Daily and 8-day Composite Products for Floodplain and Wetland Inundation Mapping. Wetlands 2013, 33, 823–835. [Google Scholar] [CrossRef] Huang, C.; Chen, Y.; Zhang, S.; Wu, J. Detecting, Extracting, and Monitoring Surface Water From Space Using Optical Sensors: A Review. Rev. Geophys. 2018, 56, 333–360. [Google Scholar] [CrossRef] Whitcraft, A.K.; Vermote, E.F.; Becker-Reshef, I.; Justice, C.O. Cloud cover throughout the agricultural growing season: Impacts on passive optical earth observations. Remote Sens. Environ. 2015, 156, 438–447. [Google Scholar] [CrossRef] Tahsin, S.; Medeiros, S.C.; Hooshyar, M.; Singh, A. Optical Cloud Pixel Recovery via Machine Learning. Remote Sens. 2017, 9, 527. [Google Scholar] [CrossRef] [Green Version] Frantz, D.; Haß, E.; Uhl, A.; Stoffels, J.; Hill, J. Improvement of the Fmask algorithm for Sentinel-2 images: Separating clouds from bright surfaces based on parallax effects. Remote Sens. Environ. 2018, 215, 471–481. [Google Scholar] [CrossRef] Zhu, Z.; Woodcock, C.E. Object-based cloud and cloud shadow detection in Landsat imagery. Remote Sens. Environ. 2012, 118, 83–94. [Google Scholar] [CrossRef] Sudmanns, M.; Tiede, D.; Augustin, H.; Lang, S. Assessing global Sentinel-2 coverage dynamics and data availability for operational Earth observation (EO) applications using the EO-Compass. Int. J. Digit. earth 2019, 13, 768–784. [Google Scholar] [CrossRef] [Green Version] Nguyen, M.D.; Baez-Villanueva, O.M.; Bui, D.D.; Nguyen, P.T.; Ribbe, L. Harmonization of Landsat and Sentinel 2 for Crop Monitoring in Drought Prone Areas: Case Studies of Ninh Thuan (Vietnam) and Bekaa (Lebanon). Remote Sens. 2020, 12, 281. [Google Scholar] [CrossRef] [Green Version] Chastain, R.; Housman, I.; Goldstein, J.; Finco, M.; Tenneson, K. Empirical cross sensor comparison of Sentinel-2A and 2B MSI, Landsat-8 OLI, and Landsat-7 ETM+ top of atmosphere spectral characteristics over the conterminous United States. Remote Sens. Environ. 2019, 221, 274–285. [Google Scholar] [CrossRef] Meraner, A.; Ebel, P.; Zhu, X.X.; Schmitt, M. Cloud removal in Sentinel-2 imagery using a deep residual neural network and SAR-optical data fusion. ISPRS J. Photogramm. Remote Sens. 2020, 166, 333–346. [Google Scholar] [CrossRef] [PubMed] Publisher’s Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.  © 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Share and Cite MDPI and ACS Style Polpanich, O.-u.; Bhatpuria, D.; Santos Santos, T.F.; Krittasudthacheewa, C. Leveraging Multi-Source Data and Digital Technology to Support the Monitoring of Localized Water Changes in the Mekong Region. Sustainability 2022, 14, 1739. https://doi.org/10.3390/su14031739 AMA Style Polpanich O-u, Bhatpuria D, Santos Santos TF, Krittasudthacheewa C. Leveraging Multi-Source Data and Digital Technology to Support the Monitoring of Localized Water Changes in the Mekong Region. Sustainability. 2022; 14(3):1739. https://doi.org/10.3390/su14031739 Chicago/Turabian Style Polpanich, Orn-uma, Dhyey Bhatpuria, Tania Fernanda Santos Santos, and Chayanis Krittasudthacheewa. 2022. \"Leveraging Multi-Source Data and Digital Technology to Support the Monitoring of Localized Water Changes in the Mekong Region\" Sustainability 14, no. 3: 1739. https://doi.org/10.3390/su14031739 Note that from the first issue of 2016, this journal uses article numbers instead of page numbers. See further details here. Article Metrics Citations Crossref   2 Scopus   2 Web of Science   1 Google Scholar   [click to view] Article Access Statistics Article access statistics Article Views 8. Jan 18. Jan 28. Jan 7. Feb 17. Feb 27. Feb 8. Mar 18. Mar 28. Mar 0 500 1000 1500 2000 For more information on the journal statistics, click here. Multiple requests from the same IP address are counted as one view.   Sustainability, EISSN 2071-1050, Published by MDPI RSS Content Alert Further Information Article Processing Charges Pay an Invoice Open Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors For Reviewers For Editors For Librarians For Publishers For Societies For Conference Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe to receive issue release notifications and newsletters from MDPI journals Select options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated Disclaimer Terms and Conditions Privacy Policy"

Paper 3:
- APA Citation: N/A
  Main Objective: Develop a remote sensing-based approach for generating a salt-affected irrigated cropland map in an arid and semi-arid region.
  Study Location: Unspecified
  Data Sources: ['Sentinel-1 data', 'Sentinel-2 data']
  Technologies Used: ['Sentinel-1 satellite imagery', 'Sentinel-2 satellite imagery']
  Key Findings: ['The combined Sentinel-1 and Sentinel-2 data provided the best results for salt-affected cropland mapping.', 'The proposed approach achieved high accuracy and robustness under different climatic conditions.', 'The findings have implications for precision agriculture, sustainable land management, and food security in arid and semi-arid regions.']
  Extract 1: 
  Extract 2: 
  Limitations: []
  Relevance Evaluation: {'extract_1': 'The model achieves high accuracy and robustness for salt-affected cropland mapping under different climatic conditions.', 'extract_2': 'The study not only provides a reliable and cost-effective approach for large-scale salt-affected cropland mapping, but also has significant implications for precision agriculture, sustainable land management, and food security in arid and semi-arid regions.', 'relevance_score': 0.975}
  Relevance Score: 1.0
  Inline Citation: N/A
  Explanation: In this research, a combination of spatial and spectral information is used to generate a salt-affected irrigated cropland map in an arid and semi-arid region. By utilizing the complementarity of Sentinel-1 and Sentinel-2 data, the model achieves high accuracy and robustness for salt-affected cropland mapping under different climatic conditions. The study not only provides a reliable and cost-effective approach for large-scale salt-affected cropland mapping, but also has significant implications for precision agriculture, sustainable land management, and food security in arid and semi-arid regions.

 Full Text: >
"This website uses cookies We use cookies to personalise content and ads, to provide social media features and to analyse our traffic. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you’ve provided to them or that they’ve collected from your use of their services. Consent Selection Necessary Preferences Statistics Marketing Show details                 Deny Allow selection Allow all             Journals Topics Information Author Services Initiatives About Sign In / Sign Up Submit   Search for Articles: Remote Sensing All Article Types Advanced   Journals Remote Sensing Volume 14 Issue 23 10.3390/rs14236010 Submit to this Journal Review for this Journal Propose a Special Issue Article Menu Academic Editors Carlos Antonio Da Silva Junior Luciano Shozo Shiratsuchi Subscribe SciFeed Recommended Articles Related Info Link More by Authors Links Article Views 1726 Table of Contents Abstract Introduction Materials and Methods Results Discussion Conclusions Supplementary Materials Author Contributions Funding Data Availability Statement Conflicts of Interest Appendix A References share Share announcement Help format_quote Cite question_answer Discuss in SciProfiles thumb_up Endorse textsms Comment first_page settings Order Article Reprints Open AccessArticle Generating Salt-Affected Irrigated Cropland Map in an Arid and Semi-Arid Region Using Multi-Sensor Remote Sensing Data by Deji Wuyun 1,2, Junwei Bao 1, Luís Guilherme Teixeira Crusiol 3, Tuya Wulan 1, Liang Sun 2, Shangrong Wu 2, Qingqiang Xin 1, Zheng Sun 2, Ruiqing Chen 2, Jingyu Peng 4, Hongtao Xu 5, Nitu Wu 6, Anhong Hou 1, Lan Wu 7 and Tingting Ren 1,8,* 1 Research Center of Agricultural Remote Sensing Engineering Technology in Inner Mongolia Autonomous Region, Institute of Rural Economic and Information, Inner Mongolia Academy of Agricultural & Animal Husbandry Sciences, Hohhot 010031, China 2 Institute of Agricultural Resources and Regional Planning, Chinese Academy of Agricultural Sciences, Beijing 100081, China 3 Embrapa Soja (National Soybean Research Center-Brazilian Agricultural Research Corporation), Londrina 86001-970, Brazil 4 Institute of Resources, Environment, Sustainable Development, Inner Mongolia Academy of Agricultural & Animal Husbandry Sciences, Hohhot 010031, China 5 Institute of Grassland Research, Chinese Academy of Agricultural Sciences, Hohhot 010010, China 6 Key Laboratory of Grassland Resources of the Ministry of Education, College of Grassland, Resources and Environment, Inner Mongolia Agricultural University, Hohhot 010011, China 7 College of Resources and Environmental Economics, Inner Mongolia University of Finance and Economics, Hohhot 010070, China 8 Asia Hub, Nanjing Agricultural University, Nanjing 210095, China * Author to whom correspondence should be addressed. Remote Sens. 2022, 14(23), 6010; https://doi.org/10.3390/rs14236010 Submission received: 8 October 2022 / Revised: 16 November 2022 / Accepted: 23 November 2022 / Published: 27 November 2022 (This article belongs to the Special Issue Deep and Machine Learning Applications in Remote Sensing Data to Monitor and Manage Crops Using Precision Agriculture Systems) Download keyboard_arrow_down      Browse Figures Review Reports Versions Notes Abstract Soil salinization is a widespread environmental hazard and a major abiotic constraint affecting global food production and threatening food security. Salt-affected cropland is widely distributed in China, and the problem of salinization in the Hetao Irrigation District (HID) in the Inner Mongolia Autonomous Region is particularly prominent. The salt-affected soil in Inner Mongolia is 1.75 million hectares, accounting for 14.8% of the total land. Therefore, mapping saline cropland in the irrigation district of Inner Mongolia could evaluate the impacts of cropland soil salinization on the environment and food security. This study hypothesized that a reasonably accurate regional map of salt-affected cropland would result from a ground sampling approach based on PlanetScope images and the methodology developed by Sentinel multi-sensor images employing the machine learning algorithm in the cloud computing platform. Thus, a model was developed to create the salt-affected cropland map of HID in 2021 based on the modified cropland base map, valid saline and non-saline samples through consistency testing, and various spectral parameters, such as reflectance bands, published salinity indices, vegetation indices, and texture information. Additionally, multi-sensor data of Sentinel from dry and wet seasons were used to determine the best solution for mapping saline cropland. The results imply that combining the Sentinel-1 and Sentinel-2 data could map the soil salinity in HID during the dry season with reasonable accuracy and close to real time. Then, the indicators derived from the confusion matrix were used to validate the established model. As a result, the combined dataset, which included reflectance bands, spectral indices, vertical transmit–vertical receive (VV) and vertical transmit–horizontal receive (VH) polarization, and texture information, outperformed the highest overall accuracy at 0.8938, while the F1 scores for saline cropland and non-saline cropland are 0.8687 and 0.9109, respectively. According to the analyses conducted for this study, salt-affected cropland can be detected more accurately during the dry season by using just Sentinel images from March to April. The findings of this study provide a clear explanation of the efficiency and standardization of salt-affected cropland mapping in arid and semi-arid regions, with significant potential for applicability outside the current study area. Keywords: irrigation district; cropland; quantile and quantile plots testing; dry season; Google Earth Engine 1. Introduction Soil salinization is a matter of concern in agriculture, as the excess salt hinders crop growth by obstructing the ability to uptake water. In another sense, it causes a loss in soil fertility and leads to the desertification of cropland [1,2]. According to the estimation released by the Food and Agriculture Organization (FAO), there are more than 424 million hectares of topsoil (0–30 cm) and 833 million hectares of subsoil (30–100 cm) are salt-affected around the globe (8.7% of the planet) [3]. Most of them can be found in naturally arid or semi-arid environments in Africa, Asia and Latin America [4]. Soils are easily affected by salt in arid and semi-arid regions where low rainfall and high evapotranspiration lead to the concentration of salts such as sodium, magnesium and calcium to form saline soils [5,6,7,8]. FAO launched the Global Map of Salt-Affected Soils in 2021, although the salt-affected soil of China has not been included in that. Nonetheless, estimates show that 20 to 50% of irrigated soils across all continents are too salty, implying that over 1.5 billion people face significant challenges in meeting rising food demand due to severe cropland salinity and cropland degradation [9]. Saline cropland is an essential part of reserve cropland in the Inner Mongolia Autonomous Region in China and is an integral part of the cropland restoration program [10]. The salt-affect soil in the Inner Mongolia Autonomous Region is mainly disturbed in the Xiliao River Plain in the east and Hetao Irrigation District (HID) in the west. The cropland of HID is dominated by saline soil and accounts for 30.5% of the saline cropland in Inner Mongolia [10]. In the early stage of the reclamation HID, flood irrigation without drainage facilities caused the secondary salinization of the field soil. For now, cropland salinization has gradually evolved into the main factor restricting the sustainable development of agriculture in HID. Therefore, the severe salinity cropland is a typical area for the agricultural management department’s soil rehabilitation program, which has attracted the interest of many academics [11,12]. The cropland soil salinity in HID is mainly adapted from the irrigation water of the Yellow River. Only 20% of the initial salt can be discharged through drainage, while 80% of the salt is kept in the soil of the irrigation area, showing a salinization trend [13]. Soil salinity will adversely affect plant growth, crop yields, and underground water quality, leading to soil erosion and land degradation [14]. The hazard of soil salinity is not limited to the environment but also includes the economy. For example, for the secondary salinization of the land in the Sultanate of Oman, the direct economic loss from mild to moderate salinity is about 1604 US dollars per hectare, and the direct economic loss from mild to severe salinity is as high as 4352 US dollars per hectare [15]. Thus, knowing the spatial distribution of salt-affected cropland is an urgent need to alleviate the contradiction between humans and land [16,17], which is also vital for promoting the high-quality development of the national agricultural economy [18]. At the same time, the eradicate because of dynamic and accessible restress from salinization after agricultural activities seriously endangers the sustainable development of agriculture and its productivity, which makes the timely detection of salt-affected cropland within HID with limited cropland resources particularly urgent [19,20,21]. Traditionally, soil salinity was measured by collecting soil samples and analyzing them in a laboratory to determine their solute concentration or electronic conductivity [22]. However, due to intensive sampling being time-consuming and expensive, the spatial variability of soil salinity is hardly fully characterized traditionally in a large area. Remote sensing data and techniques can more effectively provide economic and rapid tools and methods for mapping soil salinity [23]. Remote sensing data and its analyzing processes have gradually become the most convenient method of mapping soil salinity since black-and-white and color aerial photographs were used to describe salinity-stressed soils in the 1960s. Multispectral imagery such as Landsat [24], Sentinel [25], IKONOS [26], QuickBird [27] and UAV-Borne [28] are highly suitable for evaluating soil salinity. In the last three decades of research on monitoring saline soils, multispectral sensors have been mainly used. In addition, some researchers have emphasized the importance of ground sample data [29,30]. In practical applications, multispectral sensors also show limitations, as their spectral resolution and fewer bands affect the quality and quantity of information provided. Many current studies pointed out this limitation, thus monitoring the salinity using hyperspectral [31] and thermal infrared data [32], even Synthetic Aperture Radar (SAR) data [33] in the last few years. Nevertheless, the broad acquisition capability of Sentinel data, high spatial resolution (10 m), and the combination of active and passive remote sensing data can compensate for the deficiencies of multispectral data widely available for free. Remote sensing data with meter-level high resolution or sub-meter-level resolution (IKONOS, QuickBird, WroldView-2, GF series) have also been gradually introduced into salinity mapping research and have become indispensable data sources. Mapping the salinity of cropland combining high spatial resolution images and ground sampling data using machine learning algorithms is mainly carried out at the field scale or farm scale [34]. However, the validity and reliability of such a method need to be assessed in a larger area. Recent years have seen an increase in nonparametric machine learning techniques, particularly Random Forest (RF), to calculate soil salinity [35,36]. Since it can manage the high dimensionality and multicollinearity of remote sensing data with excellent classification accuracy and insensitivity to overfitting, RF is one of the most extensively used algorithms in land cover classification. Additionally, it has been stated that RF in the Google Earth Engine (GEE) platform provides unassailable benefits in the remote sensing classification of land cover in a large area [37,38]. Some researchers have demonstrated that RF outperforms other popular nonparametric machine learning algorithms, which can significantly increase soil salinity mapping accuracy [25,39]. However, many scholars have shown that using remote sensing technology to map cropland salinity in arid and semi-arid regions is challenging [23,24,40]. It is mainly because the bare ground and other sparse vegetation are easily confused with saline soil in spectral reflectance [33,41]. Alternatively, the method based on spectral reflectance may lead to unreliable results when the soil is moisturizing or the soil salts are not exposed on the soil surface in crystalline form but mixed with other soil components [42]. In this case, SAR data, frequently employed in detecting soil salinity, can capture information that is challenging to acquire using multispectral imagery. Various remote sensing data have already been used to study saline soil in HID. Nonetheless, the majority of these studies have focused on single sensors rather than multi-sensor images. Therefore, to comprehend the main mechanism causing agricultural salinization and degradation, a salt-affected map using a wide range of remote sensing data must be acquired in almost real time. To fill this gap, the following questions will be addressed in this study: Is the PlanetScope image of April appropriate for sample collection employing the Visual Interpretation strategy? If so, how can the samples’ validity—which includes cropland that is both saline and non-saline—be estimated? How to quickly and efficiently map salinized cropland using Sentinel-1 and Sentinel-2 data freely available in GEE? These questions are unavoidable in multi-sensor data-based mapping of salinized cropland, and addressing them is the primary goal of the current study. The specific objectives of this research are to: Create a cropland base map using global land cover data from ESA WorldCover while masking off roads and irrigation ditches collected from the electronic map of HID; Evaluate the validity of samples, comprising both saline and non-saline cropland, using the quantile and quantile plots testing method; Create a multi-variable dataset for salt-affected cropland identification using VV + VH dual polarization, reflectance bands, and vegetation indices; Determine the best solution for mapping salt-affected cropland in dry and wet seasons using the overall accuracies and indicators from the confusion matrix of various datasets. 2. Materials and Methods 2.1. The Study Area HID is located at the top of the northernmost Bay of the Yellow River and spans a region situated at 106°11′35″E–109°53′52″E and 40°10′30″–41°16′43″N. HID comprises five counties in Bayannur city with a total area of 17,243.23 km2 (Figure 1), with 733,333.33 hectares of cropland. The crop yield has been stable at more than 5 billion tons for a long time. It is Asia’s largest artesian irrigation area and one of China’s three largest irrigation areas. In addition, HID was included in the World Irrigation Engineering Heritage List in 2019. Spring wheat, corn, vegetables, citrus, and sunflowers are the main crops in HID (see phenology of main crops in HID in Table S1). Vegetables are grown in a few places after the spring wheat harvest, while other crops are sown as one-season crops. Figure 1. (a) Location of HID with histogram diagram of total evaporation and total precipitation in the last decade (meteorological data were obtained from ERA5_LAND data collection) and PlanetScope images acquired from 1 to 13 April in 2021 (shown in false color composited-R: NIR (Near-Infrared) band, G: Green band, B: Blue band). (b) The location of HID in China and the Inner Mongolia Autonomous Region. (c) Field photographs taken on April 2021, showing the salt on the soil surface before crops were planted. A typical temperate continental climate prevails in the study area. The number of hours of sunshine per year is 3210.8–3305.8; the total amount of solar radiation is 146–152 kcal per square centimeter; the average yearly temperature is 6.1–7.6 °C; the daily average temperature difference is 13–14 °C. Additionally, the average annual evaporation is 2200 mm, which is nearly twelve times the average annual precipitation of 180 mm. 2.2. Data 2.2.1. Filed Sampling The sample data for mapping saline cropland are based initially on the ground survey samples in previous studies. In contrast, the PlanetScope images acquired from April 2021 were utilized for delineating the reference samples using a visual interpretation strategy in this study, which was mainly because of the controlling measurements for preventing the COVID-19 epidemic during the critical period for collecting the ground truth samples. To accurately distinguish salt-affected soil from non-salt-affected soil on the cropland base map of HID, 1000 saline samples and 1000 non-saline samples were selected, as shown in Figure 2. High-resolution PlanetScope images were used as a reference to assess whether the soil was saline or non-saline, and each sample was labeled as either salinized or non-salinized, following the principle introduced in Figure 1. The study area is a typical arid irrigation farming area in northern China, with no winter crops grown throughout the year. This means the cropland surface in the irrigation area is bare outside from the previous year’s harvest to the sowing of the following year. Therefore, the soil salinity is in layers 0–10 cm from March to April, which means the salinity of soil is on the surface and can be distinguished by the naked eye. This phenomenon leads to the surface reflectance of the saline soil captured by the imagery is also significantly different from that of the healthy soil. Figure 2. (a) The distribution of the samples of saline and non-saline cropland, (b) the samples in the false color composited PlanetScope image (R: NIR band, G: Green band, B: Blue band). Moreover, to ensure the accuracy of the artificially delineated saline and non-saline cropland samples, the number and spatial distribution must be as consistent as possible. Therefore, after the initial sample data are selected, the validity of the samples needs to be checked to ensure that the samples can adequately represent the category to which they belong. In this part, the quantile and quantile plots testing method will be applied to validate whether the selected saline and non-saline samples obey the normal distribution (Section 2.4). 2.2.2. Remote Sensing Data Collection PlanetScope PlanetScope, operated by Planet, is a constellation of approximately 130 satellites that is able to image the entire land surface of the earth every day (a daily collection capacity of 200 million km²/day). PlanetScope images have a resolution of about 3 m per pixel. The four-band frame imager with a butcher-block filter provides Blue, Green, Red and NIR bands. The PlanetScope Ortho Scene Level 3B Product has been used for selecting samples visually since it is an orthorectified, scaled Top of Atmosphere (TOA) Radiance Surface Reflectance image product suitable for analytic and visual applications. Sentinel The European Space Agency (ESA) was renamed the EU Global Security Monitoring GMES as the Copernicus program, considering service duplication and discontinuity in 2012. Sentinel satellites are part of the Copernicus program. Sentinel-1 and Sentinel-2 are two Earth observation satellites currently in service with high-resolution sensors that can be shared globally. The Sentinel-1 mission consists of a constellation of two polar-orbiting satellites, Sentinel-1A and Sentinel-1B, operating day and night to perform C-band synthetic aperture radar imaging. SAR data with a 10 m resolution are available for 12 days revisit period. Commonly used Class 1 products include Single-Look Complex (SLC) and Ground Range Detection (GRD) products. SLC products preserve phase information and process at natural pixel spacing; GRD products incorporate detected amplitudes and multi-look to reduce speckle effects. Currently, only GRD products with Sentinel-1 data are integrated with GEE. The Sentinel-1 SAR imagery, in the Interferometric Wide (IW) mode, C-band, with dual polarization VV and VH, was acquired from 1 March 2020, to 31 April 2020, in coincidence with the field samples’ selection period. The Sentinel-2 mission consists of two solar polar-orbiting satellites, Sentinel-2A (23 June 2015–present) and Sentinel-2B (7 March 2017–present), distributed in a sun-synchronous orbit, each other into a 180° phase. Currently, Sentinel-2 mainly provides two product data: L1C and L2A. The L1C product is the reflectance data of TOA after orthorectification and sub-pixel geometric precision correction; the L2A product is the surface reflectance data product obtained using the Sen2cor tool officially provided by ESA to perform atmospheric correction on L1C. Data are available across Europe from October and globally from January 2017. Each Sentinel-2 satellite carries a multi-spectrometer MSI with 13 bands in the Visible, NIR, Narrow NIR and Short-Wave Infrared (SWIR) spectral ranges, including three Red Edge bands. Sentinel-2 Leve-1C and Leve-1A data products have been integrated into GEE (find details in Table A1). Considering that the Leve-1C product has more extended data availability, the Leve-1C TOA data product of Sentinel-2 has been selected for mapping saline cropland. 2.2.3. Ancillary Data An initial cropland base map was created using the ESA WorldCover global land cover data package, which was developed based on the Sentinel-1 and Sentinel-2 at 10 m resolution, and it may be accessed at https://viewer.esa-worldcover.org/worldcover, accessed on 16 October 2022. The cropland category is 40 in the ESA WorldCover global land cover data. 2.3. Generating the Cropland Base Map In this section, the roads and irrigation ditches with a resolution of 2.4 m provided by AutoNavi Electronic Maps will be used to mask out the non-cropland areas within the fields of HID. Firstly, the GDAL module of Python extracted the roads and irrigation ditches from the electronic maps and then converted them to the SHP file. Secondly, the RASTERIO in Python was captured to mask the non-cropland parts from the WorldCover global cropland cover data. 2.4. Quantile and Quantile Plots Testing Generally, the same type of ground objects should have the same or similar spectral reflectance characteristics in the same wavelength range of remote sensing images. The saline soils in arid regions mainly contain salts such as chlorides, sulfates and carbonates. Before the first irrigation of spring sowing in the Yellow River irrigation district, the salinity in the topsoil of 0–10 cm would be at the highest level, and saline elements would cover the soil surface, whitening the soil surface, as shown in Figure 1c. Spring wheat is the earliest sowing crop in the study area that cannot be grown in saline soil. Other crops, such as vegetables, corn and fruit, can be grown in soils with slight to moderate salinity. Sunflower is the main salt-tolerant crop and can even be planted in severe saline soil. Therefore, the 3 m resolution PlanetScope images obtained in early April (spring wheat grows in the Emergence Stage and can cover the ground surface) were chosen to collect sample data additionally to solve the problem that ground truth sample data are difficult to distribute evenly in a large area (Figure 2b). It can be assumed that the eigenvalues of the saline and non-saline samples in different wavelength ranges obey the normal distribution. Conversely, when a specific sample contains anomalies, its distribution will deviate from the normal distribution. Therefore, the quantile graphical method (Quantile and Quantile Plot, Q-Q plot) can be used for sample validity tests for elements inconsistent during sample selection caused by visual interpretation errors. The Q-Q plot is a graphical technique for determining if two datasets come from populations with a common distribution. A Q-Q plot is the quantiles of the first dataset against the quantiles of the second dataset. Thus, the point (x, y) on the graph represents the quantile of the second dataset (y-coordinate) and the same quantile of the corresponding first dataset (x-coordinate). Therefore, the Q-Q plot will approximately lie on the line y = x superior if the two distributions are the same or similar. In this study, the x-axis was set as the normal data quantiles of the sample’s reflectance value. In contrast, the y-axis was set as the normal theoretical quantiles to test whether the two categories of samples obey the normal distribution. The reflectance of the ten bands (B2, B3, B4, B5, B6, B7, B8, B8A, B11, B12) of the Sentinel-2 images observed from March to April 2021 (reduced to mean value on Google Earth Engine) are set as examples to illustrate the Q-Q plot (find the testing results in Section 3.2). 2.5. Modeling Strategy The technical frame of this study is illustrated in Figure 3. First, the reflectance bands of Sentinel-1 and Sentinel-2 images were selected via spatial resolution to ensure the generalization and robustness of the models. In this step, bands at 60 m resolution were dedicated primarily to detecting atmospheric features and therefore are not included in subsequent research. Thus, indices and texture variables based on spectral reflectance were created at 10 m resolution. On the other hand, the backscattering signal of the Sentinel-1 VV + VH dual-polarization also participated in the modelling process at 10 m resolution. Figure 3. Technical framework of this study. 2.5.1. Spectral Salinity Indices The wide range of wavelengths of the Sentinel-2 data has an excellent capability for remote sensing monitoring and mapping requirements of soil salinity [25]. Therefore, the mean values of Sentinel-2 spectral reflectance were included in the combined dataset to map the saline cropland in HID accurately. Table A1 (Section 2.2.2) lists the bands used in this study. Applying spectral indices to investigate cropland salinity is built upon the different spectral behavior associated with image pixels of the ground object [43]. The salinization can dramatically change soil surface characteristics, leading to a significant difference from healthy soil, especially during the best monitoring period before the growing season in the arid and semi-arid regions with low vegetation cover and more exposed soil. Moreover, the presence of salinity-tolerant crop coverage on the soil may also be a marker to reflect the soil salinization, thus allowing indirect mapping of salinity-stressed cropland [44]. On the other hand, unhealthy vegetation photosynthetic activity resulted in increased visible reflectance and decreased near-infrared reflectance (NIR) [25]. Therefore, several vegetation indices (VIs), such as Normalized Vegetation Index (NDVI), Soil-Adjusted Vegetation Index (SAVI), Optimized Soil Adjusted Vegetation Index (OSAVI) and Modified Soil-Adjusted Vegetation Index (MSAVI), were used to map soil salinity. Numerous academics have regarded the VIs performance as appropriate for estimating soil salinity using remote sensing images [45]. To create a multi-variable model to map the saline cropland in an arid and semi-arid area, a succession of VIs commonly used for monitoring soil salinity was proposed in this study. Corresponding to this, other researchers have created various salinity indices, including the Normalized Difference Salinity Index (NDSI) and Salinity Index (SI), to identify and map soil salinity. Table A2 provides specific information. On the other hand, for combinations of two or three wavelengths in remote sensing images, extensive information can be obtained from the indices determined by spectral reflectance at the 10 m resolution. 2.5.2. Gray Level Co-Occurrence Matrix Texture variables can provide valuable spatial information, reflecting the spatial distribution of the gray levels of remote sensing images and representing the spatial relationship between image features and the surrounding environment [46]. For instance, soil salinization in HID refers to the phenomenon in which the salt in the bottom soil or groundwater rises to the surface with capillary water. After the water evaporates, the salt accumulates in the surface layer. Thus, this phenomenon could significantly change the texture features of the land surface. The textures are essential for identifying objects or regions of interest, whether in photographs, aerial photos, or satellite images. GEE provides the Gray Level Co-occurrence Matrix (GLCM) function to calculate broad applicability textures and can be utilized in various image classification applications [47,48,49]. In this study, the 14 GLCM indicators proposed by Robert et al. [50] and four other indicators proposed by Conners et al. [51] were used to construct texture variables. The reflectance-based texture variables based on the B2 with the highest accuracy of the Sentinel-2 images were obtained in GEE for modeling the mapping strategy for saline cropland in HID. 2.5.3. Classifier and Accuracy Assessment Random Forest is one of the machine learning algorithms widely used in land cover classification [52] and has been applied to the remote sensing monitoring research of saline cropland gradually [53]. Furthermore, the importance evaluation function of the variables of Random Forest can screen out the variable that contributes the most to classification. Therefore, it can support further research on soil salinity monitoring. Random Forest can build a multi-layer decision tree and randomly select subsets and variables of training samples. The classification accuracy of the Random Forest classifier on the GEE platform uses the incremental step of 100 trees to reach the highest accuracy with 600 trees. In addition, 70% of random samples are used to train the classifier, and 30% of random samples are used to validate the accuracy of the saline cropland classification. Overall Accuracy (OA), Producer Accuracy (PA), and User Accuracy (UA) were used to evaluate the performance of Random Forest classifiers on the GEE. OA is the ratio of the total number of correctly classified pixels to the total number of pixels (the total number of pixels in the ground reference samples). UA corresponds to the probability that a randomly selected pixel from the map is classified as correct in the ground reference samples. PA corresponds to the likelihood that the reference sample is correctly classified on the map. The Kappa coefficient was previously considered an indicator that can be used for consistency checks and to measure classification effects. However, Foody [54] points out that the Kappa coefficient is not a measure of accuracy but an agreement beyond chance. Hence, it is unnecessary and should not be used in typical remote sensing applications. Therefore, Foody [54] argues that researchers should abandon the Kappa coefficient as a measure of accuracy instead of per-class accuracy estimation and confusion matrices to evaluate machine learning classification accuracy. Based on this, the Kappa coefficient is not used as a criterion for assessing the accuracies in this study. In addition, to test the robustness of the RF on GEE, the F1 scores (F1 = 2 × UA × PA/ (UA + PA)) of saline cropland and non-saline cropland were also calculated. The F1-score is the harmonic mean of producer and user accuracies. In studies where the classification samples are not perfectly balanced, the F1 score is a strong indicator for testing the stability of classification. The F1 score ranges from 0 to 1, with higher scores indicating better classification performance. 3. Results 3.1. Cropland Base Map The cropland base map without roads and irrigation ditches was generated through the two steps introduced in Section 2.3. As a result, the boundaries of fields are more prominent, and the problem of adhesion between field pixels in the study area is eliminated, as shown in Figure 4. There are 887,938.39 hectares of cropland in the study area. In addition, the area calculated from remote sensing results was compared with the data of The Third National Land Survey of China in 2020; a minimal difference between the modified cropland area and that of in land survey was found, and the specific data are relevant in Table 1. Therefore, the cropland base map is reliable and can be a basis for consecutive research. Figure 4. Cropland distribution in HID, (a) HID base map of modified cropland, (b) detailed map of initial cropland of ESA WorldCover global land cover data at 10 m resolution, (c) detailed SHP file of roads and ditches downloaded from AutoNavi Electronic Maps, (d) detailed map of modified cropland at 10 m resolution. Table 1. Cropland area derived from remote sensing data and areas included in The Third National Land Survey. 3.2. Sample Validity Test The samples’ pixel reflectance means values derived from the ten spectral bands of Sentinel-2 were acquired during the mapping period in this study (from March to April). Then, Origin 2018 was used to generate the Q-Q plot diagrams of the values of non-saline and saline cropland samples, as shown in Figure A1. In addition, the R-square (R2) between the normal data quantiles and normal theoretical quantiles is a practical approach to showing the validity of samples. The specific R2 values can be found in Table 2. Table 2. R2 values between normal data quantiles and normal theoretical quantiles of samples for the various bands of the Sentinel-2 image. It can be found that the samples of either non-saline or saline cropland obey the normal distribution in the validation results. The scatter points in the Q-Q diagram of the saline and non-saline cropland before the growing season (from March to April) tend to fall on the x = y reference line, and the R2 of all sample data is above 0.9. Whereas, the R2 values of both non-saline and saline cropland samples on the B2 appear lowest (0.93 and 0.90, respectively) in all bands. This is because salt-affected soil has a valley of absorption close to the blue wavelength. Because of this, the reflectance is also lower than at other wavelengths. The sample points on the other bands in Figure A1 lie on the line x = y except for the B2 band, demonstrating the linear relationship between the normal data quantiles and the normal theoretical quantiles. This indicates a high level of sample consistency between two distributions of sample data on the B3 to B12 (Green to SWIR2) bands. The results of the sample validity test show that the samples chosen in this study for two cropland classes before the growing season have adequate consistency and representativeness to meet the needs of the subsequent research. 3.3. Accuracy Assessment of Saline Cropland Mapping The other probability of mapping saline cropland in the dry or wet season was tested in this part. According to observing the total precipitation in the last decade (chart in Figure 1a), the precipitation peaks in August and September and has been set in the wet season, while there was less precipitation from March to April and can be set as the dry season. Therefore, the accuracies of each dataset, including (1) the Sentinel-1 dual-polarization VV + VH dataset, (2) textures of Sentinel-2 B2 band, (3) Sentinel-2 spectral band dataset, (4) indices built based on Sentinel-2, and (5) the dataset of combined Sentinel-1 and Sentinel-2 in different time intervals were assessed to present the performance of the modeling strategies in the dry and wet season. The box plot of validation results are presented in Figure A2, and the validation indicators are shown in Table A3. The results showed that the highest accuracy was achieved In the dry season from March to April, which was significantly higher than other time interval combinations. In comparison, no significant difference has been observed in the box plot of March, August and August to September. The result indicates that the two-month data combination in the dry season is the best solution for mapping saline cropland in HID. Thus, the dataset combined with March and April generated the salt-affected cropland map. Moreover, to clarify the best multi-variables with the highest accuracy for saline cropland mapping, the performances of the variables and their combinations were estimated, respectively, as shown in Figure 5 and Table A4. Figure 5. Classification accuracies of each variable and the combined datasets: Sentinel-1 indicates the mean value of Sentinel-1 dual-PolSAR (VV + VH) bands; Sentinel-2 suggests the combination of texture and indices derived from reflectance bands of Sentinel-2 and original mean values of spectral bands. S1_S2 combined indicates the combination of Sentinel-1 and Sentinel-2 datasets. As shown in Figure 5 and Table A4, the B2 band reflectance showed the highest accuracy (OA = 0.80) in the spectral bands of the Sentinel-2 data, which was followed by the B3 band. The Red Edge wavelength range is considered sensitive to green plants’ growth status [55]. Thus, the B5, B6 and B7 bands of Sentinel-2 data showed no obvious advantage for salt-affected soil mapping at 20 m resolution in this case, as shown in Figure 5. Notably, the visible band has higher advantages for identifying salt-affected soil than the Infrared band in the dry season. The VV + VH dual-polarization backscattering signal of Sentinel-1 data did not show competitive accuracy assessment results, with an overall accuracy of 0.68. The accuracy of the VH backscattering signal was higher than the VV backscattering signal, reaching 0.67 and 0.58, respectively. In addition, it can be seen in Table A4 that a very slight improvement (0.0019) has been detected in the assessment results by adding Sentinel-1 SAR data to Sentinel-2 spectral data. In this case, the mapping of salinity-affected crops is not significantly impacted by the VV + VH dual-polarization backscattering information. SAR data, however, can also be an essential supplemental data source in overcast and rainy regions where continuous optical images are challenging to obtain. Each index variable’s OA was greater than 70%, which denotes high accuracy. With an OA of 0.79, SI had the highest accuracy of any index, which was followed by MSAVI with an OA of 0.72. The degrees of accuracy for NDVI, SAVI, OSAVI, NDSI, and DVI are equivalent. These findings suggest that SI is the most appropriate indicator for saline cropland in salt-affected cropland mapping before the growing season in an arid and semi-arid region. In this situation, combining Sentinel-1 and Sentinel-2 (S1_S2 combined in Figure 5), modeling strategies provided the optimal solution for saline cropland mapping, with an OA of 0.8938. 3.4. The Map of Saline Cropland The dataset, including the spectrum reflectance, indices, texture information and PolSAR backscattering signal, produced the highest overall accuracy and F1 score (non-saline cropland is 0.91 and saline cropland is 0.87). Therefore, the Sentinel-1 and Sentinel-2 combined datasets were selected for mapping the saline cropland before the growing season in HID. Furthermore, the cropland in HID was classified into two categories, as aforementioned. As seen in Figure 6, the amount of non-saline cropland in HID is more than the area of saline cropland, with 58.30% and 41.70% of cropland, respectively. The stretch between Wuyuan County to the west bank of Ulansuhai Nur is the largest saline cropland zone in HID. Additionally, the concentration of saline soil increases with proximity to the Yellow River Basin. As seen in Figure 6, the cropland is generally dispersed in strips toward the south and north to the east of Ulansuhai Nur. The majority of the cropland in the north uses drip irrigation, and some portions are watered by groundwater. Figure 6. The distribution of non-saline and saline cropland with the percentage pie chart. In contrast, the salinization is relatively high in the area irrigated mainly by the Yellow River in the south. As a result, there is less salinization than in the southern region. Numerous studies have shown that flood irrigating with Yellow River water causes soil salinization in HID. Therefore, the higher salinization is in keeping with the actual situation in areas irrigated with water from the Yellow River. 4. Discussion 4.1. Indices in Salt-Affected Cropland Mapping Index variables were important in previous research on salt-affected soil monitoring and inversion. The analysis based on SI-MSAVI is the most renowned among them and has been shown to invert soil salinity [56,57,58] accurately. Likewise, NDVI and DVI, commonly used to monitor vegetation status, are also widely used in land salinization monitoring research and are critical indicators [59,60,61]. A mapping methodology for salinized cropland was developed in this study using several variables based on two bands (see Table A2 for details). The Red and NIR bands produce all other indices besides the SI. Figure 7 shows that even though the saline and non-saline samples have clear absorption valleys in the visible wavelength range, their reflectance values significantly differ. In comparison, the reflectance value in the NIR wavelength range is relatively high, but no clear difference has been observed. Near the two bands of water vapor (945 nm) and cirrus (1375 nm) of the Sentinel-2 image, there are more wide absorption valleys but practically overlapping curves in the SWIR wavelength range; however, near the SWIR1 and SWIR2 bands, the difference becomes more evident. Nevertheless, when employing a single SWIR band for accuracy assessment, the result does not achieve the high accuracy of the visible band due to the SWIR band’s resolution of 20 m. Figure 7. Reflectance curve of non-saline and saline cropland samples over the wavelength range of Sentinel-2 data in dry season. Commonly, SI measures the direct relationship between Electrical Conductivity (EC) and moisture. This ratio shows the salinity concentration in the available water [62]. By utilizing the more pronounced differences between the two cropland sample types in the Blue and Red bands, the SI index based on the visible band in this study was the variable with the highest contribution and achieved higher classification accuracy. However, other indices have similar classification accuracy since they are both constructed from red and NIR bands. While NDVI and NDSI represent normalized differences between the Red and NIR bands of the Sentinel-2 image, NDVI is the NIR minus the Red and NDSI is the inverse. Thus, a positive value of NDVI and a negative value of NDSI at the same pixel are equivalent. However, when NDVI or NDSI are not employed, the overall accuracy of the salt-affected cropland mapping slightly decreases (the accuracy decreases by 0.0019 when NDVI is removed, and the accuracy drops by 0.0058 when NDSI is removed). Consequently, NDVI and NDSI have equal correlation coefficients with the sample data, which means positive correlation coefficients for NDVI and negative correlation coefficients for NDSI). Additionally, NDSI was found to be more sensitive for detecting saline cropland in the wet season with OA at 0.66, which is slightly higher than the accuracy that NDVI can achieve in the wet season with OA at 0.65. 4.2. Multi-Sensor Data Application in Saline Cropland Mapping Soil salinization is a severe problem faced by land worldwide, and the affected area is vast [18]. However, there is no exact standard for monitoring solutions due to different data sources and statistical methods. Unlike non-salt-affected land and other ground features, soil salinization has distinct and unique spectral reflectance characteristics and tends to show higher reflectance on spectral images [40,63,64,65]. Satellite remote sensing technology has irreplaceable advantages (near real-time and covering a large area) and good application prospects for observing soil salinity. Therefore, using multispectral remote sensing images to monitor the soil-affected cropland in an area with complex land surface objects is feasible. On the other hand, microwave remote sensing has been widely used in the inversion of surface soil moisture and salinity for a long time [66,67]. Since the C-band polarization radar data of the Sentinel-1 satellite was introduced into civilian use, some breakthroughs have been made in soil moisture inversion research at the beginning [68,69]. However, the salinity change in the soil surface will affect the soil dielectric properties and thus will change the microwave emissivity of the land surface. Therefore, in addition to considering the impact of soil moisture alone, soil salinity has to be considered in areas with severe soil salinization [70,71,72]. As a result, the study of monitoring soil salinity using microwave remote sensing data has gradually attracted extensive attention [73,74]. The method combining the optical and microwave remote sensing data has been discussed preliminary in this study. However, many studies have shown that the identification ability of the backscattering coefficient will be significantly enhanced after the polarization decomposition of radar data. Nevertheless, the importance of radar data in this study is still minimal, which may be because the eigenvalues after polarization decomposition are more advantageous for identifying salt on the soil surface than the original backscattering coefficient. The GRD data provided in GEE do not have phase information, so it is impossible to realize GEE’s polarization decomposition. Hence, it is difficult to establish the eigenvalues after polarization decomposition in a large area to extract saline cropland. The application of remote sensing to earth observation is an essential means to understand the earth and study various natural phenomena in the future. Remote sensing technology is constantly developing, including many commercial satellite programs. As a result, the earth will be observed without a dead angle. In addition, the data volume will increase in geometric multiples; managing and using data efficiently and reasonably will be both a challenge and an opportunity for developing various algorithms and applications for salt-affected cropland monitoring. 4.3. Strongly Saline Cropland Abandonment in HID The ESA WorldCover global land cover data did not recognize some fields with severe salinization as cropland. However, it is a minor error, because these have been abandoned for many years. On the other hand, a few severely salinized croplands have been planted late for sunflower seeds because of their salt tolerance [75]. In either case, it points to the severely salinized cropland in HID under the high potential abandonment stress. Soil salinization has become an essential topic of global change research. The latest research shows that global soil salinization will be characterized by regional prominence, global intensification, and the coexistence of local salinization and intensification. Severely salinization is one of the most hazardous reasons why cropland is removed from production and then causes the abandonment globally of 0.3–1.5 million hectares per year [76]. It is generally recognized that a large proportion of salt-affected soils in irrigated areas occurs on land inhabited by smallholder farmers. However, salt-affected cropland degradation’s social and economic dimensions have received little attention compared to its biophysical aspects [77]. Well-known examples of salt-induced land degradation include the Aral Sea Basin (Amu-Darya and Syr-Darya River Basins) in Central Asian countries, the Indo-Gangetic Basin in India, the Indus Basin in Pakistan, the Yellow River Basin in China, the Euphrates Basin in Syria and Iraq, the Murray-Darling Basin in Australia, and the San Joaquin Valley in the United States. Severe salinity also reduces paddy yields in many previously productive land areas; many paddy fields in Jaffna Peninsula, Sri Lanka, have been abandoned and are currently becoming shrubland [78]. Nevertheless, there has been no comprehensive study on the contribution of soil salinity to reduced agricultural productivity and the abandonment of paddy lands in a region. A study based on the analysis of the spatiotemporal variation in cropland expansion and loss in Xinjiang over 20 years found that the abandonment was the primary reason for the loss of cropland, with soil salinization playing an increasingly major role in the cropland abandonment [79]. Furthermore, Wu et al. [80] found widespread abandonment of reclaimed land and tillage in Xinjiang. A major reason for this abandonment was soil salinization with as much as 12,680 km2 of cropland being affected. There was a strong sense of expansion in the land use pattern of humanity with a poor understanding of sustainable development in the last few decades in Inner Mongolia. As a result, the saline bare land in northeast China has been utilized to a certain extent. However, due to the lack of protective technology, paddy fields’ abandonment and salinization reappearance have also occurred in some areas after the high-intensity utilization of cropland. The extensive area saline cropland treatment was also implemented in 2022 with the government’s support since the abandoned cropland is an essential reserve in China. The efficient utilization of salinized land is vital to ensure national food security, especially under the current COVID-19 pandemic and the global background of frequent disasters; it is imminent to utilize the reserve cropland and control the salinity. 5. Conclusions In this study, after manual visual selection of samples, creation of a cropland base map of HID, and sample validity testing, a saline cropland identification model based on multi-sensor remote sensing data and the multi-variable dataset was built and achieved with high classification accuracy. One of these, the sample validity test method, was used for the first time in the saline cropland monitoring study and produced promising experimental results. The multi-variable dataset based on Sentinel-1 SAR and Sentinel-2 multispectral images from March to April furthermore exhibits strong performance in the remote sensing mapping of salt-affected crops. The methodology and results reported in this study may be advantageous for mapping saline cropland before the growing season in arid and semi-arid regions. They can therefore be encouraged and utilized in a broader area. Supplementary Materials The following supporting information can be downloaded at: https://www.mdpi.com/article/10.3390/rs14236010/s1, Table S1: Phenology of major crops in HID, Table S2: The accuracies of each dataset in the different time intervals during wet and dry season, Table S3: Classification accuracies of each variable and datasets for saline cropland mapping. Author Contributions Conceptualization, D.W. and A.H.; methodology, D.W., J.B. and L.G.T.C.; software, D.W.; validation, Z.S., R.C. and H.X.; formal analysis, D.W. and N.W.; investigation, J.B., J.P. and T.W.; resources, A.H.; data curation, D.W.; writing—original draft preparation, D.W.; writing—review and editing, L.S., D.W., L.G.T.C. and S.W.; visualization, Z.S., Q.X. and L.W.; supervision, L.G.T.C.; project administration, T.R.; funding acquisition, T.R. All authors have read and agreed to the published version of the manuscript. Funding This research was funded by Inner Mongolia Autonomous Region Science and Technology Plan Project (No. 2021GG0024) and The Introduction and Re-Innovation of The Japanese AgriLook System by Science and Technology Department of Inner Mongolia Autonomous Region. Data Availability Statement The earth engine code of the classification process of this study has been available on the website https://code.earthengine.google.com/148a08017e0f363c8b7414036a630313, accessed on 16 November 2022. Conflicts of Interest The authors declare no conflict of interest. The funders had no role in the design of the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript; or in the decision to publish the results. Appendix A Table A1. Spectral bands of Sentinel-2 MSI sensor for saline cropland mapping. Table A2. Information list of reference spectral indices. Table A3. The accuracies of each dataset in the different time intervals during wet and dry season. Table A4. Classification accuracies of each variable and datasets for saline cropland mapping. Figure A1. Q-Q test plots for samples’ consistency of different classes on the mean values of the different bands of Sentinel-2 image, which reduced by mean value from March to April 2021. Figure A2. Results of the box plot accuracy assessment for several dataset combinations in the dry and wet seasons. The dry season in HID is represented by Mar and Mar to Apr on the x-axis, whereas the wet season in HID is represented by Aug and Aug to Sep on the x-axis. References Butcher, K.; Wick, A.F.; DeSutter, T.; Chatterjee, A.; Harmon, J. Soil Salinity: A Threat to Global Food Security. Agronomy 2016, 108, 2189–2200. [Google Scholar] [CrossRef] Mohanavelu, A.; Naganna, S.R.; Al-Ansari, N. Irrigation Induced Salinity and Sodicity Hazards on Soil and Groundwater: An Overview of Its Causes, Impacts and Mitigation Strategies. Agriculture 2021, 11, 983. [Google Scholar] [CrossRef] FAO. World Map of Salt-Affected Soils Launched at Virtual Conference. 2021. Available online: https://www.fao.org/newsroom/detail/salt-affected-soils-map-symposium/en (accessed on 20 October 2021). Hussain, S.; Shaukat, M.; Ashraf, M.; Zhu, C.; Jin, Q.; Zhang, J. Climate Change and Agriculture, 1st ed.; IntechOpen: London, UK, 2019; pp. 1–26. ISBN 978-1-78985-667-5. [Google Scholar] Rhoades, J.D.; Chanduvi, F.; Lesch, S.M. Soil Salinity Assessment: Methods and Interpretation of Electrical Conductivity Measurements, 1st ed.; Food and Agriculture Organization of the United Nations: Rome, Italy, 1999; pp. 10–25. ISBN 92-5-104281-0. [Google Scholar] Bot, A.; Benites, J. The Importance of Soil Organic Matter: Key to Drought-Resistant Soil and Sustained Food Production, 1st ed.; Food and Agriculture Organization of the United Nations: Rome, Italy, 2005; pp. 10–25. ISBN 92-5-105366-9. [Google Scholar] Metternicht, G.; Zinck, J.A. (Eds.) Remote Sensing of Soil Salinization: Impact on Land Management, 1st ed.; CRC Press: Boca Raton, FL, USA, 2008; p. 377. ISBN 978-0-42919-177-0. [Google Scholar] Food and Agriculture Organization of the United Nations. Advances in the Assessment and Monitoring of Salinization and Status of Biosaline Agriculture: Report of an Expert Consultation Held in Dubai, 1st ed.; Food and Agriculture Organization of the United Nations: Abu Dhabi, United Arab Emirates, 2009; pp. 26–29. ISBN 92-5-105366-9. [Google Scholar] Re Soil Foundation Home Page. Available online: https://resoilfoundation.org/en/agricultural-industry/fao-salt-world-crops/ (accessed on 25 October 2021). Nachshon, U. Cropland Soil Salinization and Associated Hydrology: Trends, Processes and Examples. Water 2018, 10, 1030. [Google Scholar] [CrossRef] [Green Version] Wu, J.; Vincent, B.; Yang, J.; Bouarfa, S.; Vidal, A. Remote Sensing Monitoring of Changes in Soil Salinity: A Case Study in Inner Mongolia, China. Sensors 2008, 8, 7035–7049. [Google Scholar] [CrossRef] [Green Version] Miao, Q.; Zhou, L.; Gonçalves, J.M.; Duarte, I.M.; Li, R.; Shi, H. Effects of Sand Addition to Heavy Saline-Alkali Soil on the Infiltration and Salt Leaching in Hetao Irrigation District, China. Biol. Life Sci. Forum 2021, 3, 33. [Google Scholar] [CrossRef] Chang, X.M.; Wang, S.L.; Chen, H.R.; Fu, X.J.; Xu, N.N.; Yang, X.P. Spatiotemporal changes and influencing factors of soil salinity in Hetao Irrigation District. J. Irrig. Drain E-asce. 2018, 36, 1000–1005. (In Chinses) [Google Scholar] [CrossRef] Hamidov, A.; Helming, K.; Balla, D. Impact of agricultural land use in Central Asia: A review. Agron. Sustain. Dev. 2016, 6, 36. [Google Scholar] [CrossRef] [Green Version] Thiam, S.; Villamor, G.B.; Faye, L.C.; Jean, H.B.S.; Badabate, D.; Nicholas, K. Monitoring land use and soil salinity changes in coastal landscape: A case study from Senegal. Environ. Monit. Assess. 2021, 193, 259. [Google Scholar] [CrossRef] [PubMed] Shrivastava, P.; Kumar, R. Soil salinity: A serious environmental issue and plant growth promoting bacteria as one of the tools for its alleviation. Saudi J. Biol. Sci. 2015, 22, 123–131. [Google Scholar] [CrossRef] [PubMed] [Green Version] Naifer, A.; Al-Rawahy, S.A.; Zekri, S. Economic Impact of Salinity: The Case of Al-Batinah in Oman. IJARR 2011, 6, 134–142. [Google Scholar] [CrossRef] Measho, S.; Li, F.; Pellikka, P.; Tian, C.; Hirwa, H.; Xu, N.; Qiao, Y.; Khasanov, S.; Kulmatov, R.; Chen, G. Soil Salinity Variations and Associated Implications for Agriculture and Land Resources Development Using Remote Sensing Datasets in Central Asia. Remote Sens. 2022, 14, 2501. [Google Scholar] [CrossRef] Sheng, Y.; Liu, W.; Xu, H.; Gao, X. The Spatial Distribution Characteristics of the Cultivated Land Quality in the Diluvial Fan Terrain of the Arid Region: A Case Study of Jimsar County, Xinjiang, China. Land 2021, 10, 896. [Google Scholar] [CrossRef] Kamran, M.; Parveen, A.; Ahmar, S.; Malik, Z.; Hussain, S.; Chattha, M.S.; Saleem, M.H.; Adil, M.; Heidari, P.; Chen, J.T. An Overview of Hazardous Impacts of Soil Salinity in Crops, Tolerance Mechanisms, and Amelioration through Selenium Supplementation. Int. J. Mol. Sci. 2020, 21, 148. [Google Scholar] [CrossRef] [PubMed] [Green Version] Singh, A. Soil salinization management for sustainable development: A review. J. Environ. Manag. 2020, 277, 111–383. [Google Scholar] [CrossRef] Rhoades, J.D. Salinity: Electrical Conductivity and Total Dissolved Solids. In Methods of Soil Analysis, 1st ed.; Sparks, D.L., Page, A.L., Helmke, P.A., Loeppert, R.H., Soltanpour, P.N., Tabatabai, M.A., Johnston, C.T., Sumner, M.E., Eds.; Wiley: Washington, DC, USA, 1996; Volume 3, pp. 417–435. [Google Scholar] [CrossRef] Nawar, S.; Buddenbaum, H.; Hill, J.; Kozak, J. Modeling and Mapping of Soil Salinity with Reflectance Spectroscopy and Landsat Data Using Two Quantitative Methods (PLSR and MARS). Remote Sens. 2014, 6, 10813–10834. [Google Scholar] [CrossRef] [Green Version] Abdelgadir, A.; Rubab, A. Mapping soil salinity in arid and semi-arid regions using Landsat 8 OLI satellite data. RSASE 2019, 13, 415–425. [Google Scholar] [CrossRef] Wang, J.; Ding, J.; Yu, D.L.; Ma, X.K.; Zhang, Z.P.; Ge, X.Y.; Teng, D.X.; Li, X.H.; Liang, J.; Lizaga, I.; et al. Capability of Sentinel-2 MSI data for monitoring and mapping of soil salinity in dry and wet seasons in the Ebinur Lake region, Xinjiang, China. Geoderma 2019, 353, 172–187. [Google Scholar] [CrossRef] Amal, A.; Lalit, K.; Aldakheel, Y.Y. Assessing soil salinity using soil salinity and vegetation indices derived from IKONOS high-spatial resolution imageries: Applications in a date palm dominated region. Geoderma 2014, 230–231, 1–8. [Google Scholar] [CrossRef] Ayetiguli, S.; Zhao, S.H.; Wen, Y.M. Estimating soil salinity in Pingluo County of China using QuickBird data and soil reflectance spectra. Int. J. Appl. Earth Obs. 2014, 26, 156–175. [Google Scholar] [CrossRef] Hu, J.; Peng, J.; Zhou, Y.; Xu, D.; Zhao, R.; Jiang, Q.; Fu, T.; Wang, F.; Shi, Z. Quantitative Estimation of Soil Salinity Using UAV-Borne Hyperspectral and Satellite Multispectral Images. Remote Sens. 2019, 11, 736. [Google Scholar] [CrossRef] [Green Version] Kargas, G.; Chatzigiakoumis, I.; Kollias, A.; Spiliotis, D.; Massas, I.; Kerkides, P. Soil Salinity Assessment Using Saturated Paste and Mass Soil: Water 1:1 and 1:5 Ratios Extracts. Water 2018, 10, 1589. [Google Scholar] [CrossRef] [Green Version] Dutkiewicz, A.; Lewis, M.; Ostendorf, B. Evaluation and comparison of hyperspectral imagery for mapping surface symptoms of dryland salinity. Int. J. Remote Sens. 2009, 30, 693–719. [Google Scholar] [CrossRef] Ivushkin, K.; Bartholomeus, H.; Bregt, A.K.; Pulatov, A. Satellite Thermography for Soil Salinity Assessment of Cropped Areas in Uzbekistan. Land Degrad. Dev. 2017, 28, 870–877. [Google Scholar] [CrossRef] [Green Version] Mohammad, M.T.; Mahdi, H.; Kamran, E. Soil salinity mapping using dual-polarized SAR Sentinel-1 imagery. Int. J. Remote Sens. 2019, 40, 237–252. [Google Scholar] [CrossRef] Hateffard, F.; Balog, K.; Tóth, T.; Mészáros, J.; Árvai, M.; Kovács, Z.A.; Szűcs-Vásárhelyi, N.; Koós, S.; László, P.; Novák, T.J.; et al. High-Resolution Mapping and Assessment of Salt-Affectedness on Arable Lands by the Combination of Ensemble Learning and Multivariate Geostatistics. Agronomy 2022, 12, 1858. [Google Scholar] [CrossRef] Bouaziz, M.; Matschullat, J.; Gloaguen, R. Remote sensing indicators to identify low and moderately salt-affected soils based on MODIS Terra and geochemical data. Remote Sensing for Agriculture, Ecosystems, and Hydrology XII. Int. Soc. Opt. Photonics 2010, 7824, 78241I. [Google Scholar] Gislason, P.O.; Benediktsson, J.A.; Sveinsson, J.R. Random forests for land cover classification. Pattern Recognit. Lett. 2006, 27, 294–300. [Google Scholar] [CrossRef] Fathizad, H.; Ardakani, M.A.H.; Sodaiezadech, H.; Kerry, R.; Taghizadeh-Mehrjardi, R. Investigation of the spatial and temporal variation of soil salinity using random forests in the central desert of Iran. Geoderma. 2020, 365, 114233. [Google Scholar] [CrossRef] Wuyun, D.; Sun, L.; Chen, Z.X.; Hou, A.H.; Yu, L.F.; Crusiol, L.G.T.; Chen, R.Q.; Sun, Z. The Spatiotemporal Change of Cropland and Its Impact on Vegetation Dynamics in The Farming-Pastoral Ecotone of Northern China. Sci. Total Environ. 2021, 805, 150286. [Google Scholar] [CrossRef] Wuyun, D.; Sun, L.; Sun, Z.; Chen, Z.; Hou, A.; Crusiol, L.G.T.; Reymondin, L.; Chen, R.; Zhao, H. Mapping Fallow Fields Using Sentinel-1 And Sentinel-2 Archives Over Farming-Pastoral Ecotone of Northern China with Google Earth Engine. GiSci. Remote Sens. 2022, 59, 333–353. [Google Scholar] [CrossRef] Wu, W.; Zucca, C.; Muhaimeed, A.S.; Ayad, M.; Fadhil, A.Q.; Vinay, N.; Zhu, M.; Liu, G. Soil salinity prediction and mapping by machine learning regression in Central Mesopotamia, Iraq. Land Degrad. Dev. 2018, 29, 4005–4014. [Google Scholar] [CrossRef] AbdelRahman, M.A.E.; Afifi, A.A.; D’Antonio, P.; Gabr, S.S.; Scopa, A. Detecting and Mapping Salt-Affected Soil with Arid Integrated Indices in Feature Space Using Multi-Temporal Landsat Imagery. Remote Sens. 2022, 14, 2599. [Google Scholar] [CrossRef] Hien, L.T.T.; Gobin, A.; Lim, D.T.; Quan, D.T.; Hue, N.T.; Thang, N.N.; Binh, N.T.; Dung, V.T.K.; Linh, P.H. Soil Moisture Influence on the FTIR Spectrum of Salt-Affected Soils. Remote Sens. 2022, 14, 2380. [Google Scholar] [CrossRef] Peng, J.; Ji, W.J.; Ma, Z.Q.; Li, S.; Chen, S.C.; Zhou, L.Q.; Shi, Z. Predicting total dissolved salts and soluble ion concentrations in agricultural soils using portable visible near-infrared and mid-infrared spectrometers. Biosyst. Eng. 2016, 152, 94–103. [Google Scholar] [CrossRef] Fan, X.; Liu, Y.; Tao, J.; Weng, Y. Soil Salinity Retrieval from Advanced Multi-Spectral Sensor with Partial Least Square Regression. Remote Sens. 2015, 7, 488–511. [Google Scholar] [CrossRef] [Green Version] Prudnikova, E.; Savin, I.; Vindeker, G.; Grubina, P.; Shishkonakova, E.; Sharychev, D. Influence of Soil Background on Spectral Reflectance of Winter Wheat Crop Canopy. Remote Sens. 2019, 11, 1932. [Google Scholar] [CrossRef] [Green Version] Fan, X.; Weng, Y.; Tao, J. Towards decadal soil salinity mapping using Landsat time series data. Int. J. Appl. Earth Obs. 2016, 52, 32–41. [Google Scholar] [CrossRef] Miguel, A.C.S.; Martin, R.; Bernardus, H.J.D.J. Estimation of Tropical Forest Structure from SPOT5 Satellite Images. Int. J. Remote Sens. 2010, 31, 2767–2782. [Google Scholar] [CrossRef] Hasituya; Chen, Z.X.; Wang, L.M.; Wu, W.B.; Jiang, Z.W.; Li, H. Monitoring Plastic-Mulched Farmland by Landsat-8 OLI Imagery Using Spectral and Textural Features. Remote Sens. 2016, 8, 353. [Google Scholar] [CrossRef] [Green Version] Kayitakire, F.; Hamel, C.; Defourny, P. Retrieving Forest Structure Variables Based on Image Texture Analysis And IKONOS-2 Imagery. Remote Sens. Environ. 2006, 102, 390–401. [Google Scholar] [CrossRef] Pathak, V.; Onkar, D. A New Approach for Finding an Appropriate Combination of Texture Parameters for Classification. Geocarto Int. 2010, 25, 295–313. [Google Scholar] [CrossRef] [Green Version] Robert, M.H.; Shanmugam, K.; Dinstein, Its’Hak. Textural Features for Image Classification. T-SMC 1973, SMC-3, 610–621. [Google Scholar] [CrossRef] [Green Version] Conners, R.W.; Trivedi, M.M.; Harlow, C.A. Segmentation of a High-Resolution Urban Scene Using Texture Operators. CVGIP 1984, 25, 273–310. [Google Scholar] [CrossRef] Immitzer, M.; Vuolo, F.; Atzberger, C. First Experience with Sentinel-2 Data for Crop and Tree Species Classifications in Central Europe. Remote Sens. 2016, 8, 166. [Google Scholar] [CrossRef] Wang, J.Z.; Wu, J.L.; Jia, H.J. Analysis of Spatial Variation of Soil Salinization Using a Hydrochemical and Stable Isotopic Method in a Semiarid Irrigated Basin, Hetao Plain, Inner Mongolia, North China. Environ. Process. 2016, 3, 723–733. [Google Scholar] [CrossRef] Foody, G.M. Explaining the Unsuitability of The Kappa Coefficient in The Assessment and Comparison of The Accuracy of Thematic Maps Obtained by Image Classification. Remote Sens. Environ. 2020, 239, 111630. [Google Scholar] [CrossRef] Cui, Z.; Kerekes, J.P. Potential of Red Edge Spectral Bands in Future Landsat Satellites on Agroecosystem Canopy Green Leaf Area Index Retrieval. Remote Sens. 2018, 10, 1458. [Google Scholar] [CrossRef] [Green Version] Guo, B.; Han, B.; Yang, F.; Fan, Y.; Jiang, L.; Chen, S.; Yang, W.; Gong, R.; Liang, T. Salinization information extraction model based on VI–SI feature space combinations in the Yellow River Delta based on Landsat 8 OLI image. Geomat. Nat. Hazards Risk 2019, 10, 1863–1878. [Google Scholar] [CrossRef] [Green Version] El-Hamid, H.T.A.; Hong, G. Hyperspectral remote sensing for extraction of soil salinization in the northern region of Ningxia. Model. Earth Syst. Environ. 2020, 6, 2487–2493. [Google Scholar] [CrossRef] Douaoui, A.E.K.; Nicolas, H.; Walter, C. Detecting salinity hazards within a semiarid context by means of combining soil and remote-sensing data. Geoderma 2006, 134, 217–230. [Google Scholar] [CrossRef] Yengoh, G.T.; Dent, D.; Olsson, L.; Tengberg, A.E.; Tucker, C.J. Limits to the Use of NDVI in Land Degradation Assessment. In Use of the Normalized Difference Vegetation Index (NDVI) to Assess Land Degradation at Multiple Scales; Springer Briefs in Environmental Science; Springer: Cham, Switzerland, 2020. [Google Scholar] [CrossRef] Tiago, R.; Nadia, C.; Ana, R.O.; Ana, P.; Hanaa, D.; Lucian, S.; Mohammad, F.; Maria, G. Soil salinity assessment using vegetation indices derived from Sentinel-2 multispectral data. application to Lezíria Grande, Portugal. Agric. Water Manag. 2020, 241, 106387. [Google Scholar] [CrossRef] Zhu, K.; Sun, Z.; Zhao, F.; Yang, T.; Tian, Z.; Lai, J.; Zhu, W.; Long, B. Relating Hyperspectral Vegetation Indices with Soil Salinity at Different Depths for the Diagnosis of Winter Wheat Salt Stress. Remote Sens. 2021, 13, 250. [Google Scholar] [CrossRef] Khan, N.M.; Rastoskuev, V.V.; Sato, Y.; Shiozawa, S. Assessment of hydrosaline land degradation by using a simple approach of remote sensing indicators. Agric. Water Manag. 2005, 77, 96–109. [Google Scholar] [CrossRef] Zhang, J.; Li, P.F.; Wang, J.F. Urban Built-Up Area Extraction from Landsat TM/ETM+ Images Using Spectral Information and Multivariate Texture. Remote Sens. 2014, 6, 7339–7359. [Google Scholar] [CrossRef] [Green Version] Dehni, A.; Lounis, M. Remote sensing techniques for salt affected soil mapping: Application to the Oran region of Algeria. Procedia Eng. 2012, 33, 188–198. [Google Scholar] [CrossRef] [Green Version] Akhtar, A.; Shahbaz, K.; Hussain, N.; Hanjra, M.A.; Akbar, S. Characterizing soil salinity in irrigated agriculture using a remote sensing approach. Phys. Chem. Earth 2013, 55, 43–52. [Google Scholar] [CrossRef] Zewdu, S.; Suryabhagavan, V.K.; Balakrishnan, M. Geo-spatial approach for soil salinity mapping in Sego Irrigation Farm, South Ethiopia. J. Saudi Soc. Agric. Sci. 2017, 16, 16–24. [Google Scholar] [CrossRef] [Green Version] Wang, J.R.; Schmiege, T.J. An empirical model for the complex dielectric permittivity of soils as a function of water content. T-GE 1980, GE-18, 288–295. [Google Scholar] [CrossRef] [Green Version] Ulaby, F.T.; Moore, R.K.; Fung, A.K. Microwave Remote Sensing: Active and Passive. Volume 3-From Theory to Applications; Addison Wesley Publishing Company: New York, NY, USA, 1986; p. 433. ISBN 0-201-09355-3. [Google Scholar] Ulaby, F.T.; Long, D.G.; Blackwell, W.J.; Elachi, W.C.; Zebker, H. Microwave Radar and Radiometric Remote Sensing; University of Michigan Press: Ann Arbor, MI, USA, 2015; ISBN 978-0-472-11935-6. [Google Scholar] An, R.; Zhang, L.; Wang, Z.; Quaye-Ballard, J.A.; You, J.J.; Shen, X.J.; Gao, W.; Huang, L.J.; Zhao, Y.H.; Ke, Z.Y. Validation of the ESA CCI soil moisture product in China. Int. J. Appl. Earth Obs. 2016, 48, 28–36. [Google Scholar] [CrossRef] Cui, C.Y.; Xu, J.; Zeng, J.Y.; Chen, K.S.; Bai, X.J.; Lu, H.; Chen, Q.; Zhao, T.J. Soil moisture mapping from satellites: An intercomparison of SMAP, SMOS, FY3B, AMSR2, and ESA CCI over two dense network regions at different spatial scales. Remote Sens. 2018, 10, 33. [Google Scholar] [CrossRef] [Green Version] Wu, Y.R.; Wang, W.Z.; Zhao, S.J.; Liu, S.H. Dielectric properties of saline soils and an improved dielectric model in C-band. T-GE 2014, 53, 440–452. [Google Scholar] [CrossRef] Chi, T.; Li, B.; Mu, L.; Cao, G. Application study of the microwave emissivity spectra in the estimation of salt content of saline soil. Procedia Comput. Sci. 2017, 107, 727–732. [Google Scholar] [CrossRef] Romanov, A.N.; Khvostov, I.V. Emissivity peculiarities of the inland salt marshes in the south of Western Siberia. Int. J. Remote Sens. 2018, 39, 418–431. [Google Scholar] [CrossRef] Li, W.H.; Zhang, H.Z.; Zeng, Y.L.; Xiang, L.J.; Lei, Z.H.; Huang, Q.X.; Li, T.Y.; Shen, F.; Cheng, Q. A Salt Tolerance Evaluation Method for Sunflower (Helianthus annuus L.) at the Seed Germination Stage. Sci. Rep. 2020, 10, 10626. [Google Scholar] [CrossRef] [PubMed] Harper, R.J.; Dell, B.; Ruprecht, J.K.; Sochacki, S.J.; Smettem, K.R.J. Soils and Landscape Restoration; Academic Press: New York, NY, USA, 2021; pp. 193–208. ISBN 978-0-12813-194-7. [Google Scholar] Zekri, S.; Al-Rawahy, S.A.; Naifer, A. Socio-Economic Considerations of Salinity: Descriptive Statistics of the Batinah Sampled Farms. In Monograph on Management of Salt-Affected Soils and Water for Sustainable Agriculture; Mushtaque, A., Al-Rawahi, S.A., Hussain, N., Eds.; Sultan Qaboos University: Muscat, Oman, 2010; pp. 99–113. ISBN 201-1-31880-88. [Google Scholar] Gopalakrishnan, T.; Kumar, L. Linking Long-Term Changes in Soil Salinity to Paddy Land Abandonment in Jaffna Peninsula, Sri Lanka. Agriculture 2021, 11, 211. [Google Scholar] [CrossRef] Shi, X.Y.; Wang, H.J.; Song, J.H.; Lv, X.; Li, W.D.; Li, B.G.; Shi, J.C. Impact of saline soil improvement measures on salt content in the abandonment-reclamation process. Soil Tillage Res. 2021, 208, 104867. [Google Scholar] [CrossRef] Wu, S.; Zhou, K.; Liu, Z.; Zhang, L.; Qiao, M.; Yue, J.; Zhang, X. Study on thetemporal and spatial dynamic changes of land use and driving forces analyses of Xinjiang in recent 10 years. Arid. Land Geogr. 2005, 1, 52–58. (In Chinese) [Google Scholar] Publisher’s Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.  © 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Share and Cite MDPI and ACS Style Wuyun, D.; Bao, J.; Crusiol, L.G.T.; Wulan, T.; Sun, L.; Wu, S.; Xin, Q.; Sun, Z.; Chen, R.; Peng, J.; et al. Generating Salt-Affected Irrigated Cropland Map in an Arid and Semi-Arid Region Using Multi-Sensor Remote Sensing Data. Remote Sens. 2022, 14, 6010. https://doi.org/10.3390/rs14236010 AMA Style Wuyun D, Bao J, Crusiol LGT, Wulan T, Sun L, Wu S, Xin Q, Sun Z, Chen R, Peng J, et al. Generating Salt-Affected Irrigated Cropland Map in an Arid and Semi-Arid Region Using Multi-Sensor Remote Sensing Data. Remote Sensing. 2022; 14(23):6010. https://doi.org/10.3390/rs14236010 Chicago/Turabian Style Wuyun, Deji, Junwei Bao, Luís Guilherme Teixeira Crusiol, Tuya Wulan, Liang Sun, Shangrong Wu, Qingqiang Xin, Zheng Sun, Ruiqing Chen, Jingyu Peng, and et al. 2022. \"Generating Salt-Affected Irrigated Cropland Map in an Arid and Semi-Arid Region Using Multi-Sensor Remote Sensing Data\" Remote Sensing 14, no. 23: 6010. https://doi.org/10.3390/rs14236010 Note that from the first issue of 2016, this journal uses article numbers instead of page numbers. See further details here. Article Metrics Citations No citations were found for this article, but you may check on Google Scholar Article Access Statistics Article access statistics Article Views 8. Jan 18. Jan 28. Jan 7. Feb 17. Feb 27. Feb 8. Mar 18. Mar 28. Mar 0 500 1000 1500 2000 For more information on the journal statistics, click here. Multiple requests from the same IP address are counted as one view.   Remote Sens., EISSN 2072-4292, Published by MDPI RSS Content Alert Further Information Article Processing Charges Pay an Invoice Open Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors For Reviewers For Editors For Librarians For Publishers For Societies For Conference Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe to receive issue release notifications and newsletters from MDPI journals Select options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated Disclaimer Terms and Conditions Privacy Policy"

Paper 4:
- APA Citation: Raval, P., Patel, B., & Singh, U. P. (2023). An Edge Computing-Based Architecture and Framework for Smart Irrigation System Using Machine Learning. IEEE Internet of Things Journal, 10(2), 1565-1574.
  Main Objective: The main objective of this study was to develop a systematic methodology for developing automated irrigation systems using edge computing.
  Study Location: Unspecified
  Data Sources: N/A
  Technologies Used: Edge computing, IoT, Machine learning models
  Key Findings: The study's key findings indicate that edge computing can significantly improve the efficiency and reliability of automated irrigation systems. By addressing challenges such as data quality, scalability, and security, edge computing enables autonomous, efficient, and data-driven management of irrigation.
  Extract 1: "The proposed system can learn the patterns in real time and make accurate predictions for future events, which enables autonomous, efficient, and data-driven management of irrigation." (Raval et al.)
  Extract 2: "Edge computing also reduces the dependency on the cloud, which addresses concerns related to cloud outages, latency, bandwidth limitations, and security issues. This makes the system highly reliable." (Raval et al.)
  Limitations: The paper's focus on edge computing may limit its generalizability to other aspects of automated irrigation systems. Additionally, the methodology has not been tested on a large-scale irrigation project, which could affect the adoption and implementation of the proposed system.
  Relevance Evaluation: The paper by Raval et al. is directly relevant to the point being made in the literature review as it provides a comprehensive methodology for developing automated irrigation systems using edge computing. The study offers detailed insights into edge computing and its applications in irrigation, which can guide researchers and practitioners in the field of automated irrigation. The authors' emphasis on challenges and strategies for implementing real-time, automated irrigation systems aligns well with the section of the literature review that focuses on integration, interoperability, and standardization. Given the growing significance of edge computing and the need to address challenges in automated irrigation, this paper holds significant relevance to the review.
  Relevance Score: 0.95
  Inline Citation: (Raval et al., 2023)
  Explanation: Assessing the relevance of the paper in the context of the literature review is important. This paper by Raval et al. presents a systematic methodology for developing automated irrigation systems with edge computing. The authors provide detailed insights into edge computing in their study, making it relevant to the research areas of this review. This study could aid in the selection of suitable IoT devices, data processing techniques, and machine learning models for automated irrigation systems. The authors also highlight key challenges in implementing real-time, automated irrigation systems, such as data quality, scalability, reliability, and security. These are particularly pertinent to the section of the literature review that focuses on challenges and strategies for integrating automated systems with existing irrigation infrastructure. Thus, this study is both relevant to the review topic and complements other studies on automated irrigation.

 Full Text: >
"Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Abstract Keywords 1. Introduction 2. Study area 3. Data and platforms 4. Methodology 5. Results & discussions 6. Conclusions Declaration of competing interest Data availability References Show full outline Cited by (1) Figures (6) Tables (3) Table 1 Table 2 Table 3 Quaternary Science Advances Volume 12, October 2023, 100118 Long-term estimation of glacier mass balance using geospatial techniques in Western Himalayas, Ladakh, India Author links open overlay panel Shubham Bhattacharjee a, Arvind Chandra Pandey b, Rahul Dev Garg a Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.qsa.2023.100118 Get rights and content Under a Creative Commons license open access Abstract All glaciers are subject to mass fluctuations in the current context of climate change. For daily requirements like food, drink, irrigation, and the generation of hydroelectric power, these glaciers provide water to important basins including the Indus, Ganga, and Brahmaputra. Changes in glacier patterns are a blatant sign of local climate variability. Monitoring of glaciers requires long-term studies on glacier dynamics. Himalayan glaciers, because of their disposition in a complex topographic setting and inaccessible terrain render difficulty in the glacier observations in a continuous mode. Glacier mass fluctuations can be associated with glacier area shrinkage or expansion and concomitant snout shift. In the current study, two adjoining glaciers of different sizes, Pensilungpa and Drang Drung glaciers in the Zanskar Valley, Ladakh, India are selected. The period of the study was taken between the years 2000–2022. Earlier studies used a single day per year Accumulation Area Ratio (AAR) method to compute mass balance, which had limitations due to snow cover variability. The present study calculated and averaged all the AAR values for cloud-free images per year during the peak ablation period (mid-July to early September). Digital Elevation Model (DEM) difference technique was also employed for computing the mass budget between 2000 and 2021 b y utilizing two-time period DEMs. It was revealed that in the case of the AAR method, the Pensilungpa glacier showed 7 years of positive and 16 years of negative mass balance. The years 2003–2005 and 2011 to 2016 were depicted with negative mass balance with the highest value up to −0.752-m water equivalent (m.w.e.) for the year 2015. It has negligible areal fluctuations ranging from 0.01 to 0.6 km2. Drang Drung Glacier has shown 12 years of positive and 11 years of negative mass balance. The years 2002–2004 and 2009 to 2012 were depicted with positive mass balance with the highest value up to 0.305 m. w.e. Except, for the year 2009–2012 (areal increment ∼ 2.65 km2), years 2013–2015 showed a negative mass balance with negligible areal fluctuations. Mass balance estimation using DEM differencing method revealed an average estimated mass balance of −0.03 m. w.e. For Pensilungpa glacier though, it is 0.08 m. w.e. For Drang Drung glacier which shows good matches with the mass balance estimated using AAR method in m. w.e. Such contrasting behavior of mass balance suggests higher sensitivity of smaller glaciers to climate change. Previous article in issue Next article in issue Keywords Mass balanceAccumulation area ratio (AAR)Digital elevation model (DEM) differencingAreal fluctuationsSatellite imagery 1. Introduction The Himalayas, commonly known as the “Water Tower of Asia,” are home to one of the world's greatest mountain glacier networks (Bolch et al., 2012). The Himalayan glaciers, which have a wide range of topographical and morphological characteristics, are distinct from the Inner Asian and European Alpine glaciers in that they have fewer condensed valleys, slopes that can cause avalanches, and ablation zones that are heavily covered in debris (Benn and Lehmkuhl, 2000; Scherler et al., 2011). For daily requirements like food, drink, irrigation, and the generation of hydroelectric power, these glaciers provide water to important basins including the Indus, Ganga, and Brahmaputra (Immerzeel et al., 2012; Tawde et al., 2017). According to Lepparanta and Granberg (2010), changes in glacier patterns are a blatant sign of local climate variability and climate change. Along with meteorological influences, geography, and morphometric traits also control changes in glacier systems (Ghosh and Pandey, 2013). The Hindu Kush-Karakoram-Himalayan range has seen retreating glacier fronts since the middle of the 19th century (Bolch et al., 2012; Dehecq et al., 2019). Approximately 17% of the Himalayan mountain area is covered by glaciers (Ahmad et al., 2004). The climate change impact on the glacier system is the focal key for understanding and forecasting the global environment (Dehecq et al., 2019). Climate change directly influences the overall health (width, area, and mass) of the glaciers (Poddar and Pandey, 2014). Therefore, to understand the impact of climate change, the study of glaciated regions is of major concern (Bahuguna et al., 2014). Overall cumulative river basin runoff from the Himalayan catchment reflects the contribution from rivers and glacier melting (Immerzeel et al., 2009). During the last century on account of climate change, around 12.5% of the Himalayan glaciers have retreated (Bahuguna et al., 2014; Bhambri and Bolch, 2009; Prasad et al., 2009) with annual snout fluctuations between 16 and 35 m (Dobhal and Thayyen, 2004). During the years 1962–2001, parts of Zanskar Valley, Ladakh, India depicted with glacier areal retreat of 18.16% with a snout retreat of 6–33 m/year (Nathawat et al., 2008). According to recent studies, the Himalayas, the Alps, the Andes, and the Rocky Mountains have shown wide-scale retreats (Kulkarni et al., 2002). Mass balance estimation is imperative to understand the spatiotemporal changes in the glacier area, length, and volume. In order to map the impact of changing climate, studies related to growth/shrinkage, motion, thickness as well as the mass exchange of glaciers are important (Bhattacharjee and Pandey, 2023; Kaser et al., 2003). All glaciers signify climate change by indicating their mass fluctuations, which can be either decreasing or increasing (Lepparanta and Granberg, 2010). The position of the glacier snout and glacier area can be reflected by mass fluctuations. Studies of long-term mass balance are required for monitoring the health of any glacier (Bolch et al., 2012). Remote sensing methods have been used extensively to map glacial patterns in regions with rugged terrain conditions, rough weather, and logistic issues like the Himalayan glaciers (Racoviteanu et al., 2008; Li et al., 2014; Yang et al., 2010). In general, the mass budget of a valley glacier is calculated using the stratigraphic/glaciological method, the hydrological method, and the geodetic method (Ostrem and Stanley, 1969). In India, in-situ glaciological mass balance observations are confined to a few glaciers and are limited to a few years which makes satellite-based remote sensing techniques more reliable (Azam et al., 2018; Kulkarni, 1992; Macgregor et al., 2005; Wagnon et al., 2007). The utility of Equilibrium line altitude (ELA) and AAR methods to compute glacier mass balance over the Himalayas is well documented (Bhattacharjee and Pandey, 2021; Pandey et al., 2011; Poddar and Pandey, 2014; Kulkarni, 1992). Kulkarni (1992) showed the best fit AAR method by establishing regression relations between AAR and mass balance developed by field glaciological observations for the Himalayan range. The use of the AAR approach in a recent study by Bhattacharjee and Pandey (2021) in the Himalayan-Karakoram region on select 13 glaciers between 1996 and 2021 demonstrated an increasing trend of mass loss as the glaciers moved from the Karakoram Range to the Eastern Himalayas. The hydrological method was used for computing the mass balance of the Siachen glacier of Nubra Valley (Bhutiyani, 1999). Another traditional method is called DEM differencing which uses remote sensing and surveying imagery to compute mass balance estimates. It is an indirect approach for estimating mass balance that computes the difference between surface elevations from DEMs developed from historical topographic data and remotely sensed products such as Satellite pour l'Observation de la Terre (SPOT), Shuttle Radar Topography Mission (SRTM), and Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) (Berthier et al., 2007). Glacier mass changes were studied on select six glaciers in parts of Zanskar Valley, Ladakh, India using AAR-ELA methods over a continuous period from 2000 to 2010 with Landsat and Indian Remote Sensing (IRS) satellite images revealed that glaciers experienced negative mass balance for years 2000, 2001, 2004, and 2008. For the remaining years, glaciers gained mass which indicated as compared to the mass gain, mass loss was marginal (Poddar and Pandey, 2014). In Jammu & Kashmir (Greater Himalayan range), India, patterns of temporal glacier variability of 34 glaciers during 3 periods of observation based on IRS and Landsat satellite datasets were carried out. The results showed an area shrinkage of 1.5% for all glaciers during the first period (1975–1992) with a snout retreat rate of 3–42 m per year which further rose to 4% with a snout retreat rate of 0–88 m per year in the second period (1992–2001). The third period (2001–2007) has shown similar behavior to the second. (Pandey et al., 2011). A study using the AAR-ELA method in the parts of Zanskar Valley revealed a transition of mass balance measurements from positive (∼42.61 cm) to negative (∼−13.17 cm) between the years 1980–2000 and 2000–2011 (Ali et al., 2014). A study on glacier mass balance using the DEM differencing method over the central Nyainqentanglha Range for the duration of 1968–2013 using topographical maps, TanDEM-X and SRTM DEM revealed a significant mass loss of 0.46 ± 0.04 m. w.e. Per annum since 1968, with exceedingly more diminishing/thinning at the debris-covered part than the smoothened clean ice (Kunpeng et al., 2019). Mass balance estimates of glaciers of the Pamir mountains in central Asia shown by Zhou et al. (2019) using KH-9 imagery and SRTM DEM during the study period (1975–1999) revealed values of −0.03 ± 0.24 m. w.e. Per annum. The present study focuses on analyzing two adjoining glaciers of different sizes: Pensilungpa and Durung Drung glaciers in the Zanskar Valley, Ladakh, India. Mass balance was modeled over a continuous period from the years 2000–2022 using the AAR and DEM differencing methods for comparison. 2. Study area The study area (Fig. 1) incorporates Zanskar Valley (elevation ∼ 3700–6400 m), in the south of Ladakh, Greater Himalayan range, India. During extensively long winter periods (November to late April), most of the precipitation occurs as snowfall. The Zanskar Valley's southwestern and northeastern halves are where the highest and lowest relief regions exist. During the winter, which typically lasts from mid-October to May, nearly the whole valley is blanketed in a thick layer of snow. In the Zanskar Valley, the wintertime temperature hovers around −20° Celsius. May marks the start of the summer season, and temperatures rise pretty quickly. In comparison to other regions of Ladakh, the summer season lasts comparatively longer, till August. Heavy snowfall occurs in the more northern and western mountains during the winter, with moisture provided by mid-latitude westerlies (Owen and Benn, 2005). Although a good crop thrives in the broad valley of the Padam area throughout the summer, the high slope lacks any tree cover. Download : Download high-res image (1MB) Download : Download full-size image Fig. 1. Location map showing Pensilungpa and Drang Drung glaciers in Zanskar Valley, Ladakh, India. There are a series of glaciers in Zanskar Valley that can be easily mapped using satellite imagery. Two adjoining glaciers, Pensilungpa and Durung Drung have been selected at the northwest corner of the valley with longitudinal extensions from 76⁰12′E−76⁰26′E and latitudinal extensions from 33⁰41′N-33⁰51′N. Pensilungpa glacier is a small glacier (area = 15 km2) with the majority of its ablation zone being debris-covered (Table 1). The glacier is 8.34 km long which lies in an average relief of 5178 m. River Suru originates from the snout (altitude ∼ 4700 m) of this glacier. Drang Drung Glacier is a larger glacier (area = 71.5 km2) and is mostly debris-free (Table 1). The glacier is about 21 km long which lies in an average relief of 5185 m. River Stod originates from the snout (altitude ∼ 4160 m) of this glacier and flows in the opposite direction to the Suru River. Details on the morphometric parameters for both glaciers were presented in Table 1. Table 1. Parameterization of selected glaciers. Glaciers Area (km2) Perimeter (km) Length (km) Snout Altitude (m) Average Relief (m) Pensilungpa 15.2 42.91 8.34 4700 5178 Drang Drung 71.44 108.58 20.25 4160 5185 3. Data and platforms Landsat satellite data (resolution ∼ 30 m) acquired from the United States Geological Survey (USGS) Earth Explorer was used based on satellite scene availability and clarity with reference to snow cover, cloud, and shadow. Two-time period DEMs were also used. NASA-SRTM Global DEM v003 (horizontal resolution ∼ 30 m) for the year 2000 and ASTER DEM (ASTER 14 DMO) of resolution 30 m for the year 2021 was obtained from NASA Earth Data Explorer. Global air temperature data for the months of July and August from the National Centre for Atmospheric Research (NCAR) (resolution ∼ 0.5 × 0.5°) was used for temperature analysis. The datasets used in the present study, their resolution, purpose, and sources were given in Table 2. Table 2. Dataset procured in the present study. Satellite data Resolutions Time Period Purpose Source Landsat series (5 TM, 8 OLI) 30 m 2000–2022 Glacier mapping, extraction of accumulation/ablation zones USGS Earth Explorer (https://earthexplorer.usgs.gov/) SRTM DEM v003 30 m 2000 Reference DEM for elevation differencing USGS Earth Explorer ASTER DEM (14 DMO) 30 m 2021 Associated DEM for elevation differencing NASA Earthdata (https://search.earthdata.nasa.gov/) Air temperature 0.5 × 0.5° 2000–2022 Temperature variability National Centre for Atmospheric Research (NCAR) (https://rda.ucar.edu/) 4. Methodology 4.1. Mass balance 4.1.1. AAR method In the present study, Landsat satellite images (Fig. 2) from the period 2000 to 2022 were used to delineate and map glacier boundaries. For obtaining minimum snow cover and exposed glacier i.e. for the peak ablation period, images from mid-July to early September were preferred. Glacier boundaries have been mapped using a SWIR-red-green band combination. Before mapping glacier boundaries, the Normalized Difference Snow Index (NDSI) (equation (1)) was computed using visible (high reflectance of snow) and SWIR (total absorption) bands for effective differentiation of snow from bright soil, rock, and clouds, etc. (Hall et al., 1995). (1) NDSI = (Green – SWIR) / (Green + SWIR) Download : Download high-res image (299KB) Download : Download full-size image Fig. 2. Methodological flowchart for the present study. After obtaining the proper glacier boundary and respective atmospheric corrections, the satellite image was draped over the DEM for understanding the topographic variability. Indices like NDSI and band ratio (NIR/SWIR) have been used to distinguish accumulation from ablation zone. To minimize the effect of errors, digital image processing techniques such as adaptive (for detecting edges), crisp (for enhancing slope variability), and morphological (for smoothening) filters have been used. Unsupervised classification has also been performed for segregating accumulation with ablation areas. Earlier studies have used a single day per year AAR value for computing mass balance which can induce a lot of error due to the variability of snow cover (Kulkarni et al., 2004; Poddar and Pandey, 2014). For addressing this issue, AAR values were computed for all the cloud-free images between mid-July to early September and then averaged for discarding this single-day-per-year induced error. Calculation of accumulation area ratio was performed using the expression (equation (2)): (2) AAR = (Accumulation area) / (Total area) Kulkarni et al. (2004) developed a regression relationship (equation (3)) between in-situ-based mass balance data and AAR estimates for Shaune Garang and Gor Garang glaciers in the western Himalayas, yielding a correlation of 0.8. (3) Specific Mass balance (in cm.w.e) = 243.01*AAR-120.187 According to equation (3), there should be a neutral or almost zero mass balance when AAR equals 0.5, for the western Himalayas. Hence due to similar climatic patterns of the western Himalayas, the same equation was used to compute the long-term mass balance of both the adjoining glaciers of Zanskar Valley, as the field-based long-term mass balance is not available for the region. 4.1.2. DEM differencing method Ice, Cloud, and land Elevation Satellite (ICESat) altimetry data downloaded from National Snow and Ice Data Centre (NSIDC) for the same area was used for penetration bias correction. Generally, SRTM C-band penetrates through the medium which introduces penetration biases (Nuth and Kaab, 2011). Non-glaciated terrain is stable and cannot move. Thus, stable terrain was selected with the help of the slope. Over the stable terrain, SRTM elevation values were extracted into the ICESat points for computing absolute accuracy and discarding the penetration biases. The precision of the product produced by DEM differencing is hampered by the horizontal and vertical offsets associated with both DEMs as a result of their capture at different times by different satellites in distinct datums. Therefore, elevation-dependent bias was discarded after co-registering both DEMs to eliminate registration-oriented errors (Nuth and Kaab, 2011). First, non-stable topography (i.e. glaciers) was removed from both DEMs. Then, using the universal co-registration model (equation (4)), which considers terrain slope and aspect, the planimetric adjustment/co-registration of both DEMs for stable (non-glacierized) terrain was carried out (Nuth and Kaab, 2011). (4) dh = a.cos(b - ᴪ).tan.α + dH Where dh is the independent elevation difference, α is the terrain slope, and ᴪ is the terrain aspect. The cosine function's (a, b, and dH) parameters stand for shifts in the horizontal direction of the dh, a directional shift vector, and an overall elevation bias. These parameters were solved using the least-squares approach. The shift in the orientations of the horizontal (a) and directional vector (b) are negligible because both DEMs had the same spatial resolution (30 m), while the bias in elevation (dH) was adjusted using equation (4). In this scenario, three iterations were completed before the bias in elevation was close to zero. Elevation-dependent biases result from the spatially asymmetric distribution of GCPs in 3-D coordinate planes. The height-dependent bias was eliminated using a second-order polynomial correlation (equation (5)) provided by Nuth and Kaab (2011) that depicts the link between elevation and elevation difference over terrain without glaciers. Agarwal et al. (2017) also employed this trend correction. (5) dh = Σ kn.Zn + τ Where dh is the elevation difference, Z is the elevation, k, and τ are regression parameters and the order of the polynomial is represented by n (in this case 2). Some points in the stable terrain were collected and uncertainty in elevation difference was ascertained by computing Mean Absolute Deviation (MAD) (Xu et al., 2022). By subtracting the elevation of the years 2021 and 2000, the elevation change was calculated. Equation (6) (Cogley, 2011) was used to determine the glacier mass balance utilizing elevation change, glacier area, and glacial ice density: (6) Where is the mean glacier area for years 2000 and 2021, B is the glacier mass balance in m. w.e., is the change in glacier volume (calculated using elevation change), and and are the densities of the ice (∼850 kg/m3) and water (∼997 kg/m3). Uncertainty in mass balance has been carried out using equation (7) which is obtained by differentiating equation (6): (7) Uncertainty in the volume change can be obtained by using uncertainties in the ice thickness change and glacier boundary area. Uncertainty in the ice density was taken as ±60 kg/m3 and uncertainty in the mean glacier area can be computed using the method suggested by Pfeffer et al. (2014). 5. Results & discussions 5.1. Mass balance 5.1.1. AAR method Mapping of both Pensilungpa and Drang Drung glaciers was performed for the period 2000–2022. After obtaining accumulation areas of both glaciers (using the methodology detailed in Section 4), the study found that Pensilungpa glacier (Fig. 3a) observed 7 years of positive and 16 years of negative mass balance. The years 2003–2005 and 2011 to 2016 were depicted with negative mass balance with the highest value up to −75.23-cm water equivalent (cm.w.e.) for the year 2015. Additionally, the consistency of negative mass balance from the year 2020–2022 was also witnessed. The year 2008 shows a higher negative mass balance value up to 80 cm. w. e. Between positive mass balance years 2006, 2007, 2009, and 2010. Drang Drung glacier (Fig. 3b) shows 12 years of positive and 11 years of negative mass balance. The years 2002–2004 and 2009 to 2012 were depicted with positive mass balance with the highest value up to 30.5 cm. w. e. Except, for the years 2009–2012 (areal increment ∼ 2.65 km2), years 2013–2015 showed a negative mass balance with negligible areal fluctuations However, the consistency of negative mass balance from the year 2020–2022 was observed as was for the Pensilungpa Glacier. Download : Download high-res image (565KB) Download : Download full-size image Fig. 3. Mass balance of (a) Pensilungpa (b) Drang Drung glaciers during 2000–2022. Both glaciers witnessed similar mass balance patterns for some of the same years viz. 2000–2001, 2006–2007, 2013–2015, and 2020–2022 due to snowfall variability in the peak ablation period. After converting the specific mass balance from cm. w.e. To m. w.e., the results have been validated with field-based mass balance data of the Chotta Shigri glacier (Table 3) of Himachal Pradesh in Western Himalaya computed by Wagnon et al. (2007); JNU-SAC (2008); JNU-IFCPAR (2009); Jnu Dst (2011) for years 2008, 2009 and 2010. Table 3. Comparison of computed mass balance data with field-based data. Years Chhota Shigri glacier (Field based mass balance in m.w.e.) Pensilungpa glacier (in m.w.e.) Drang Drung glacier (in m.w.e.) 2008 −0.93 −0.813 −0.172 2009 0.13 0.499 0.305 2010 0.33 0.038 0.123 5.1.2. DEM differencing method The elevation difference map (Fig. 4) was generated from temporal DEMs along with the corresponding mass balance estimates. High elevation difference indicates an increase in elevation at that particular pixel due to snowfall, or avalanche. Over that time period, whereas negative elevation difference indicates a decrease in height due to melting, and deformation. Therefore, a positive elevation difference indicates positive mass balance and a negative elevation difference represents negative mass balance. The study revealed that the glacier elevation differences ranged from < −40 to 46 m. Average elevation changes for Pensilungpa glacier lay in the range from −11 to 15 m. Negative changes at the junction of the tributary glacier to the main glacier represent thinning and which leads to fragmentation of the glacier (Vijay and Braun, 2018). Drang Drung glacier (average elevation changes ∼ −18 to 17 m) depicted the dominance of positive elevation changes with negative changes near the snout region reflecting glaciation of the snout zone. Radiation absorption by clean ice and the higher temperature at lower altitudes seemed to be the possible reason for the maximum thinning at the terminus of the Drang Drung Glacier (Vijay and Braun, 2018). These elevation differences were validated by the results obtained for the Pensilungpa glacier shown by Pandey et al. (2012). They used the Survey of India (SOI) toposheet and ASTER DEM during the study period (1962–2007) which revealed an increment of 30–90 m of glacier elevation in the accumulation zone and a similar decrement in the ablation zone was witnessed. Download : Download high-res image (2MB) Download : Download full-size image Fig. 4. Elevation difference and mass balance estimation between 2000 and 2021. 5.1.3. Comparison of mass balance estimates Average values of mass balance over accumulation and ablation zones were extracted and compared with the calculated mass balance using the AAR method. AAR-based mass balance has given average values of −0.09 and 0.16 m. w.e. For Pensilungpa and Drang Drung glaciers. Average values of mass balance over the glaciers obtained from the DEM differencing method have shown −0.03 m. w.e. For Pensilungpa and 0.09 m. w.e. For Durung Drung glacier holding a good correlation with the values obtained by the AAR method. These results are validated by the mass balance results of glaciers of the Pamir mountains in central Asia shown by Zhou et al. (2019) using KH-9 imagery and SRTM DEM during the study period (1975–1999) which revealed values of −0.03 ± 0.24 m. w.e. Per annum. The results are also validated by the elevation difference of the glaciers in the Zanskar region shown by Vijay and Braun (2018) using interferometric SRTM and bistatic TanDEM-X DEMs during the study period (2000–2012) which revealed values of −0.19 ± 0.22 m/yr. The study also revealed that while computing height difference, some traces of a major height gap is observed in the range of −40 to −25 m in the lower accumulation reaches of Pensilungpa glacier and nearby snout areas of Drang Drung glacier which represents the development of longitudinal crevasses and supraglacial erosional features (Dobreva et al., 2017; Vijay and Braun, 2018). The crevasses can be considered an indicator of glacial deformation and future glacial lake formation. 5.2. Glacial dynamics Pensilungpa glacier area (Fig. 5a) increased during 2005 (∼15.6 km2), 2006 (∼15.58 km2), 2016 (∼15.15 km2), and 2017 (∼15.2 km2) and was mostly stable from 2000 to 2003 (∼14.65 km2), 2007 to 2015 (∼14.7 km2), and from 2018 to 2020 (∼14.57 km2). During the years 2000–2005, area change ranged between 0 and 0.6 km2 with snout fluctuation of 1 m/yr. The snout retreated up to 4.3 m/yr with a net areal retreat of 1 km2 between the years 2005 and 2019. The area change for Drang Drung Glacier (Fig. 5b) is small and varied between 71.8 and 71.2 km2. Glacier was stable from the year 2000–2009 (71.75–71.85 km2) with the snout retreating up to 2.8 m/yr. A net areal fluctuation of 0.6 km2 with an increased snout shift of 6 m/yr was observed between the years 2009 and 2019. Download : Download high-res image (806KB) Download : Download full-size image Fig. 5. Glacier area changes (a) Pensilungpa (b) Drang Drung glaciers during 2000–2022. During the years 2000–2003, the Pensilungpa Glacier area was stagnant and the mass balance increased a little. The mass balance increased incredibly in the year 2002 (∼22.32 cm. w.e.) due to the snowfall in the acquisition month of the satellite (Ghosh and Pandey, 2013). Glacier area increased during the period 2004–2006 and so did the mass balance (−40.5 to 21.42 cm. w.e.). Mass balance decreased rapidly between 2006 and 2008 (21.42 to −79.55 cm. w.e.) which was due to the rapid rate of glacier areal thinning. The year 2009 depicted a rapid rise in mass balance (∼36.22 cm. w.e.) due to the snowfall in the acquisition month of the satellite. During the years 2009–2011, the Pensilungpa Glacier area decreased so did the mass balance (36.22 to −3.42 cm. w.e.). An increasing-decreasing behavior in glacier area and mass balance was observed between the years 2011–2015. The mass balance increased incredibly between 2015 and 2017 (−72.42 to 9.92 cm. w.e.) due to the rapid rate of glacier areal increment. Glacier area decreased during the period 2017–2018 and so did the mass balance (9.92 to −70.62 cm. w.e.). Continuous series of negative mass balances were observed during the years 2020–2022 (−54.33 to −44.32 cm. w.e.) due to glacier areal thinning. The study by Rana et al. (2023) for Parkachik Glacier, Zanskar Valley also observed a major glacial retreat after the year 2015. During the years 2000–2006, the Drang Drung Glacier area was stagnant and the mass balance increased (−43.42 to 29.67 cm. w.e.). A similar pattern of areal fluctuations and mass balance was observed between the period 2006–2009. Glacier area decreased rapidly during the period 2009–2013 but the glacier maintained a stagnant mass balance (∼15.96 cm. w.e.) during 2009–2012 and further decreased (∼– 17.42 cm. w.e.) in the year 2013. The glacier area was stagnant during the period 2013–2015 and so did the mass balance (−17.42 to −18.76 cm. w.e.). The mass balance increased incredibly between 2015 and 2017 (−21.47 to 19.97 cm. w.e.) due to the rapid rate of glacier areal increment. An increasing-decreasing behavior in glacier area and mass balance was observed between the years 2017–2020. Years between 2020 and 2022 were depicted with an area decrement but the mass balance increased (−33.33 to −8.48 cm. w.e.). There was a decrement in the glacier mass balance after the year 2009 which is possibly linked with the areal shrinkage of the glacier. The linkages between glacial dynamics and mass balance indicated a direct relationship. Meanwhile, Pensilungpa Glacier due to its smaller size was more sensitive to glacier areal fluctuations. The sensitivity of small glaciers of Zanskar Valley to areal fluctuations was also observed by Rana et al. (2023). As Pensilungpa Glacier is partially debris-covered, hence the reason can also be attributed to the fact that glacier melting is also triggered by variable debris thickness (Mehta et al., 2021, 2023). 5.3. Air temperature Temperature conditions over both the glaciers (Fig. 6) in the lower ablation zone or glacier snout were analyzed, for the period of study (2000–2022) in the month of August. A temperature of around −6 °C was recorded in the years 2001, 2002, 2005, 2006, 2007, 2013, 2015, 2016, and 2020. An average temperature of −2 °C was mostly recorded during the study period and the years 2003 and 2017 recorded high-temperature up to 2 °C. The years 2003 and 2017 witnessed a sudden increase in temperature from −6 °C to 2 °C and then between the years 2003–2005, the temperature further decreased to −7 °C. The years 2020–2022 depicted a rise in temperature. Download : Download high-res image (386KB) Download : Download full-size image Fig. 6. Specific mass balance Vs Average Air Temperature. During the years 2000–2002, the air temperature decreased and the mass balance of the glaciers increased. The temperature increased from 2002 to 2004 but both glaciers have shown variable behavior. The Pensilungpa Glacier was depicted with a negative mass balance whereas Drang Drung Glacier was stagnant during 2002–2004. The years 2004–2007 have shown a similar pattern as the years 2000–2002 viz. A decrement in air temperature and an increment in mass balance of both the glaciers. But the increment was more prominent for Drang Drung Glacier as compared to Pensilungpa Glacier. It is interesting to note that between the years 2008–2012, the temperature shows increasing-decreasing behavior. Drang Drung Glacier mainly showed near positive mass balance between the years 2009–2012 and Pensilungpa Glacier showed negative mass balance between 2010 and 2012. Between the years 2012–2016, the temperature was depicted with an increasing-decreasing pattern but the variability in mass balance during the period for Pensilungpa Glacier was more negative as compared to Drang Drung Glacier. A cumulative increment in air temperature was observed between 2016 and 2020 but both glaciers have shown an increasing-decreasing behavior. But again, the increment in mass balance was more prominent for Drang Drung Glacier as compared to Pensilungpa Glacier. Between the years 2020–2022, the temperature rose continuously but the variability in mass balance during the period for Pensilungpa Glacier was more negative as compared to Drang Drung Glacier. The linkages between air temperature and mass balance mostly indicated an inverse relationship. Meanwhile, Pensilungpa Glacier was more sensitive to climate forcing. The sensitivity of small glaciers of Zanskar Valley to areal and temperature fluctuations was also observed by Ghosh and Pandey (2013). Possible limitations of the study are the absence of high-resolution DEMs for recent years, cloud hindrance issues for optical remote sensing images, resolution of the Landsat imagery (which hindered detailed glacier mapping) and air temperature dataset, and lack of field-based measurements for validations. Some possible recommendations and future aspects could be using Synthetic Aperture Radar (SAR) images for resolving the resolution and cloud cover constrain, and a detailed relationship of estimated mass balance with climate factors (temperature, precipitation/snowfall, etc). Exploring energy balance models for computing mass can also form future scope to check the accountability of radiation budgets of the glaciers. 6. Conclusions The present study demonstrates a methodology for comparative assessment of glacier mass balance using satellite data-based techniques suited for areas where in-situ data is not available. Mass balance results indicates the contrasting relationship between smaller and larger glaciers in the Zanskar Valley, Ladakh, India. Pensilungpa Glacier was depicted with more negative mass balane years as compared to Drang Drung Glacier. DEM differencing method indicates its reliability in elevation change aspects. These elevation changes uncover long-term glacier thinning, mass changes, and the evolution of glacial erosional landforms. Relationship with areal fluctuations and air temperature proves higher sensitivity of small glaciers to glacial dynamics and climate forcing. Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Data availability Data will be made available on request. References Agarwal et al., 2017 V. Agarwal, T. Bolch, T.H. Syed, T. Pieczonka, T. Strozzi, R. Nagaich Area and mass changes of Siachen glacier (east Karakoram) J. Glaciol., 63 (2017), pp. 148-163 CrossRefView in ScopusGoogle Scholar Ahmad et al., 2004 S. Ahmad, S. Hasnain, M. Selvan Morpho-metric characteristics of glaciers in the Indian Himalayas Asian J. Water Environ. Pollut., 1 (1&2) (2004), pp. 109-118 CrossRefGoogle Scholar Ali et al., 2014 I. Ali, A. Shukla, J. Qadir Monitoring glacial parameters in parts of zanskar basin, Jammu and Kashmir Book: Geostatistical and Geospatial Approaches for the Characterization of Natural Resources in the Environment: Challenges, Processes and Strategies Geostatistical and Geospatial Approaches for the Characterization of Natural Resources in the Environment Edition, Springer International Publishing, N. Janardhana Raju (2014), p. 1 Chapter: 138 Publisher Google Scholar Azam et al., 2018 M.F. Azam, P. Wagnon, E. Berthier, C. Vincent, K.O.J.I. Fujita, J.S. Kargel Review of the status and mass changes of Himalayan–Karakoram glaciers J. Glaciol., 64 (243) (2018), pp. 61-64 CrossRefView in ScopusGoogle Scholar Bahuguna et al., 2014 I.M. Bahuguna, B.P. Rathore, R. Brahmbhatt, M.C. Sharma, S. Dhar, S.S. Randhawa, K. Kumar, S.A. Romshoo, R.D. Shah, R.K. Ganjoo, A. Prof Are the himalayan glaciers retreating? Curr. Sci., 106 (7) (2014), pp. 1008-1013 View in ScopusGoogle Scholar Benn and Lehmkuhl, 2000 D.I. Benn, F. Lehmkuhl Mass balance and equilibrium-line altitudes of glaciers in high-mountain environments Quat. Int., 65–66 (2000), pp. 15-29 View PDFView articleView in ScopusGoogle Scholar Berthier et al., 2007 E. Berthier, Y. Arnaud, R. Kumar, S. Ahmad, P. Wagnon, P. Chevallier Remote sensing estimates of glacier mass balances in the Himachal Pradesh (Western Himalayas, India) Remote Sens. Environ., 108 (2007), pp. 327-338 View PDFView articleView in ScopusGoogle Scholar Bhambri and Bolch, 2009 R. Bhambri, T. Bolch Glacier Mapping: a review with special reference to the Indian Himalaya Prog. Phys. Geogr. (2009), pp. 672-704 CrossRefView in ScopusGoogle Scholar Bhattacharjee and Pandey, 2021 S. Bhattacharjee, A.C. Pandey Contrasting behaviour of temporal glacier changes and long term estimation of glacier mass balance across himalayan- Karakoram range Geocarto Int. (2021), 10.1080/10106049.2021.1923832 Google Scholar Bhattacharjee and Pandey, 2023 S. Bhattacharjee, A.C. Pandey Estimating thickness of Zemu glacier, Sikkim (India) using ice-flow velocity approach: a geoinformatics based perspective Spat. Inf. Res. (2023), 10.1007/s41324-023-00515-3 Google Scholar Bhutiyani, 1999 M.R. Bhutiyani Mass-balance studies on Siachen glacier in the Nubra Valley, Karakoram Himalaya, India J. Glaciol. (1999), pp. 1112-1118 Google Scholar Bolch et al., 2012 T. Bolch, A.V. Kulkarni, A. Kaab, C. Huggel, F. Paul, J.G. Cogley, H. Frey, J.S. Kargel, K. Fujita, M. Scheel, S. Bajracharya, M. Stoffel The state and fate of himalayan glaciers Science, 336 (6079) (2012), pp. 310-314 CrossRefView in ScopusGoogle Scholar Cogley, 2011 J.G. Cogley Present and future states of Himalaya and Karakoram glaciers Ann. Glaciol., 52 (2011), p. 69, 10.3189/172756411799096277 View in ScopusGoogle Scholar Dehecq et al., 2019 A. Dehecq, N. Gourmelen, A.S. Gardner, F. Brun, D. Goldberg, P.W. Nienow, E. Berthier, C. Vincent, P. Wagnon, E. Trouve Twenty-first century glacier slowdown driven by mass loss in High Mountain Asia Nat. Geosci., 12 (2019), pp. 22-27 CrossRefView in ScopusGoogle Scholar Dobhal and Thayyen, 2004 D.P. Dobhal, R. Thayyen Recession and morphogeometrical changes of dokriani glacier (1962 – 1995), garhwal Himalaya India Curr. Sci., 85 (6) (2004), pp. 692-696 View in ScopusGoogle Scholar Dobreva et al., 2017 I.D. Dobreva, M.P. Bishop, A.B.G. Bush Climate-glacier dynamics and topographic forcing in the Karakoram Himalaya: concepts, issues and research directions Water, 9 (2017), p. 405 CrossRefView in ScopusGoogle Scholar Ghosh and Pandey, 2013 S. Ghosh, A.C. Pandey Estimating the Variation in Glacier Area over the Last 4 Decade and Recent Mass Balance Fluctuations over the Pensilungpa Glacier, J&K, India. Global Perspective in Geography American Society of Science and Engineering (2013) ISSN:2328-2320 Google Scholar Hall et al., 1995 D.K. Hall, G.A. Riggs, V.V. Salomonson Development of methods for mapping global snow cover using Moderate Resolution Imaging Spectroradiometer (MODIS) data Remote Sens. Environ., 54 (1995), pp. 127-140 View PDFView articleView in ScopusGoogle Scholar Immerzeel et al., 2009 W.W. Immerzeel, Peter Droogers, Michael De Jong, B. Steven Large scale monitoring of snow cover and runoff simulation in Himalayan river basins using remote sensing Remote Sens. Environ., 113 (1) (2009), pp. 40-49 View PDFView articleView in ScopusGoogle Scholar Immerzeel et al., 2012 I.W. Immerzeel, L.P.H. Beek, M. Konz, A.B. Shrestha, M.F.P. Bierkens Hydrological response to climate change in a glacierized catchment in the Himalayas Clim. Change, 110 (3–4) (2012), pp. 721-736 CrossRefView in ScopusGoogle Scholar JNU-SAC, 2008 JNU-SAC Mass Balance Monitoring of Chhota Shigri Glacier, Annual Technical Report Submitted to SAC, ISRO Jawaharlal Nehru University, New Delhi (2008) Google Scholar JNU-IFCPAR, 2009 JNU-IFCPAR Mass Balance, Energy Balance and Hydrological Balance of Chhota Shigri Glacier, Himachal Pradesh, Technical Field Report Submitted to IFCPAR Jawaharlal Nehru University, New Delhi (2009) Google Scholar Jnu Dst, 2011 Jnu Dst Monitoring Studies on Chhota Shigri Glacier, Himachal Pradesh Progress Report submitted to Department of Science and Technology, Jawaharlal Nehru University, New Delhi (2011) Google Scholar Kaser et al., 2003 G. Kaser, A. Fountain, P. Jansson A manual for monitoring the mass balance of mountain glaciers Technical documents in Hydrology, 59 (2003) (Paris: UNESCO) Google Scholar Kulkarni et al., 2004 A.V. Kulkarni, B.P. Rathore, S. Alex Monitoring of glacier mass balance in the Baspa Basin using accumulation area ratio method Curr. Sci., 86 (1) (2004) Google Scholar Kulkarni et al., 2002 A.V. Kulkarni, J. Srinivasulu, S.S. Manjul, P. Mathur Field-based spectral reflectance to develop NDSI method for snow cover monitoring Journal of the Indian Society of Remote Sensing, 30 (2002), pp. 73-80 View in ScopusGoogle Scholar Kulkarni, 1992 A.V. Kulkarni Mass balance of Himalayan glaciers using AAR and ELA methods J. Glaciol., 38 (128) (1992), pp. 101-104 View in ScopusGoogle Scholar Kunpeng et al., 2019 W Kunpeng, L Shiyin, J Zongli, J Xu Glacier mass balance over the central Nyainqentanglha range during recent decades derived from remote sensing data J. Glaciol. (2019), pp. 422-439, 10.1017/jog.2019.20 Google Scholar Lepparanta and Granberg, 2010 M. Lepparanta, H.B. Granberg Physics of glacier remote sensing Remote Sensing of Glaciers, Taylor & Francis (2010) Google Scholar Li et al., 2014 X. Li, T.B. Yang, Q. Ji Study on glacier variations in the gangrigabu range Res. Soil Water Conserv., 21 (4) (2014), pp. 233-237 (in Chinese with English summary) Google Scholar Macgregor et al., 2005 K.R. Macgregor, C.A. Riihimaki, R.S. Anderson Spatial and temporal evolution of rapid basal sliding on Bench Glacier, Alaska, USA J. Glaciol., 51 (2005), pp. 49-63 CrossRefView in ScopusGoogle Scholar Mehta et al., 2021 M. Mehta, V. Kumar, S. Garg, A. Shukla Little Ice Age glacier extent and temporal changes in annual mass balance (2016–2019) of Pensilungpa Glacier. Zanskar Himalaya Reg. Environ. Change, 21 (38) (2021), pp. 1-18, 10.1007/s10113-021-01766 Google Scholar Mehta et al., 2023 M. Mehta, V. Kumar, P. Kumar, K. Sain Response of the thick and thin debris-covered glaciers between 1971 and 2019 in Ladakh Himalaya, India – a case study from Pensilungpa and Durung-Drung glaciers Sustainability, 15 (5) (2023), pp. 1-21 CrossRefGoogle Scholar Nathawat et al., 2008 M.S. Nathawat, A.C. Pandey, P.K. Rai, S. Ahmad, I.M. Bahuguna Spatio-temporal Dynamics of Glaciers in Doda Valley, Zanskar Range, Jammu & Kashmir, India. In Proceedings of the International Workshop on Snow, Ice Glacier and Avalanches, IIT Bombay (2008), pp. 256-264 Google Scholar Nuth and Kaab, 2011 C. Nuth, A. Kaab Co-registration and bias corrections of satellite elevation data sets for quantifying glacier thickness change Cryosphere, 5 (2011), pp. 271-290 CrossRefView in ScopusGoogle Scholar Ostrem and Stanley, 1969 G. Ostrem, A. Stanley Glacier Mass Balance Measurement: a Manual for Field and Office Work. Ottance, Ont., Department of Energy, Mines and Resource Water Resources and Electricity Board, Oslo, Norwegian (1969) Google Scholar Owen and Benn, 2005 L.A. Owen, D.I. Benn Equilibrium line altitude of the last glacial maxima for the Himalaya and Tibet: an assessment and evaluation of results Quat. Int., 138–139 (2005), pp. 55-78 View PDFView articleView in ScopusGoogle Scholar Pandey et al., 2011 A.C. Pandey, S. Ghosh, M.S. Nathawat Evaluating patterns of temporal glacier changes in greater himalayan range, jammu & Kashmir, India Geocarto Int., 26 (4) (2011), pp. 321-338 2011 CrossRefView in ScopusGoogle Scholar Pandey et al., 2012 A.C. Pandey, S. Ghosh, M.S. Nathawat, R.K. Tiwari Area change and thickness variation over Pensilungpa Glacier (J&K) using remote sensing Journal of Indian Society of Remote Sensing, 40 (2) (2012), pp. 245-255 CrossRefView in ScopusGoogle Scholar Pfeffer et al., 2014 W.T. Pfeffer, A. Arendt, A. Bliss, T. Bolch, J.G. Cogley, A.S. Gardner, J. Hogan, R. Hock, G. Kaser, C. Kienhdz, E.S. Miles, G. Moholdt, N. Molg, F. Paul, V. Radic, P. Rastner, B.H. Raup, J. Rich, M.J. Sharp The Randolph glacier inventory: a globally complete inventory of glaciers J. Glaciol., 60 (221) (2014), pp. 537-552 View in ScopusGoogle Scholar Poddar and Pandey, 2014 J. Poddar, A.C. Pandey Estimating the impact of changes in mass balance on variations in Glacier area and snout fluctuations in western Himalaya, J & K, India 2014 IGARSS, 978 (2014) 1- 4799-5775-0/14 Google Scholar Prasad et al., 2009 A.K. Prasad, K.H.S. Yand, H.M. El-Askary, M. Kafatos Melting of major Glaciers in the Western Himalayas: evidence of climatic changes from long term MSU derived tropospheric temperature trend (1979 – 2008) Ann. Geophys., 27 (2009), pp. 4505-4519 CrossRefView in ScopusGoogle Scholar Racoviteanu et al., 2008 A. Racoviteanu, M. Williams, R. Barry Optical remote sensing of glacier characteristics: a review with focus on Himalaya Remote Sens. Environ., 8 (2008), pp. 3355-3383 CrossRefView in ScopusGoogle Scholar Rana et al., 2023 A.S. Rana, P. Kunmar, M. Mehta, V. Kumar Glacier retreat, dynamics and bed overdeepenings of Parkachik Glacier, Ladakh Himalaya, India Ann. Glaciol. (2023), pp. 1-14, 10.1017/aog.2023.50 Google Scholar Scherler et al., 2011 D. Scherler, B. Bookhagen, M.R. Strecker Spatially variable response of Himalayan glaciers to climate change affected by debris cover Nat. Geosci., 4 (2011), pp. 156-159 CrossRefView in ScopusGoogle Scholar Tawde et al., 2017 S.A. Tawde, A.V. Kulkarni, G. Bala An estimate of glacier mass balance for the Chandra Basin, Western Himalaya, for the period 1984–2012 Ann. Glaciol., 58 (75pt2) (2017), pp. 99-109 CrossRefView in ScopusGoogle Scholar Vijay and Braun, 2018 S. Vijay, M. Braun Early 21st century spatially detailed elevation changes of Jammu & Kashmir glaciers (Karakoram-Himalaya) Global Planet. Change, 165 (April) (2018), pp. 137-146, 10.1016/j.gloplacha.2018.03.014 View PDFView articleView in ScopusGoogle Scholar Wagnon et al., 2007 P. Wagnon, A. Linda, Y. Arnaud, R. Kumar, P. Sharma, C. Vincent, J.G. Pottakkal, E. Berthier, A. Ramanathan, S.I. Hasnain, P. Chevallier Four years of mass balance on Chhota Shigri Glacier, Himachal Pradesh, India, a new benchmark glacier in the western Himalaya J. Glaciol., 53 (2007), pp. 603-611 CrossRefView in ScopusGoogle Scholar Xu et al., 2022 S. Xu, Y. Wang, Y. Wang, S. Qi, M. Zhou Glacier mass balance changes over the turgen daban range, western qilian Shan, from 1966/75 to 2020 Front. Earth Sci., 10 (2022), 10.3389/feart.2022.848895 Google Scholar Yang et al., 2010 W. Yang, T. Yao, B. Xu, L. Ma, Z. Wang, M. Wan Characteristics of recent temperate glacier fluctuations in the parlung zangbo river basin, southeast Tibetan plateau Chin. Sci. Bull., 55 (20) (2010), pp. 2097-2102 CrossRefView in ScopusGoogle Scholar Zhou et al., 2019 Y. Zhou, Z. Li, J. Li, R. Zhao, X. Ding Geodetic glacier mass balance (1975-1999) in the Central Pamir using SRTM DEM and KH-9 imagery J. Glaciol. (2019), 10.1017/jog.2019.8 Google Scholar Cited by (1) Two Decades of Glacier and Glacial Lake Change in the Dhauladhar Mountain Range, Himachal Himalayas, India (2000–2020) 2024, Journal of the Indian Society of Remote Sensing © 2023 The Authors. Published by Elsevier Ltd. Recommended articles Characteristics of earthquake swarm activity observed in the Palghar region of Indian Peninsula from January 2019 to October 2020 Quaternary Science Advances, Volume 12, 2023, Article 100099 Varun Sharma, …, Prasanta Chingtham View PDF Bone weathering in an Atlantic environment: preliminary results of the Global Weathering Project in Spain Quaternary Science Advances, Volume 12, 2023, Article 100112 A.B. Marín-Arroyo, …, Manuel R. González Morales View PDF Could facing techniques be compatible with optimal bone preservation surface? Quaternary Science Advances, Volume 12, 2023, Article 100105 Noé Valtierra, …, Andrea Díaz-Cortés View PDF Show 3 more articles Article Metrics Captures Readers: 7 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply."

Paper 5:
- APA Citation: Ali, M. (2023). Leveraging Edge Computing for Resilience and Fault Tolerance in Automated Irrigation Systems. Journal of Agricultural Engineering Research, 99(1), 1-10.
  Main Objective: To propose a decentralized architecture for automated irrigation systems using edge computing to enhance resilience and fault tolerance.
  Study Location: Unspecified
  Data Sources: Case study of a smart irrigation system in a greenhouse environment
  Technologies Used: Edge computing, Raspberry Pi, NVIDIA Jetson, Intel NUC
  Key Findings: Edge computing enables localized decision-making and control, reducing dependence on cloud connectivity and improving response times in automated irrigation systems. The case study demonstrates the effectiveness of the proposed approach in a practical setting, showcasing reduced response times and improved resilience.
  Extract 1: "The proposed architecture leverages edge computing devices like Raspberry Pi, NVIDIA Jetson, or Intel NUC to perform localized decision-making and control, reducing the reliance on cloud connectivity and improving response times."
  Extract 2: The case study of a smart irrigation system deployed in a greenhouse environment demonstrates the effectiveness of the proposed approach, showcasing reduced response times and improved resilience to network outages.
  Limitations: The paper primarily focuses on the benefits of edge computing in automated irrigation systems, but it does not delve into potential challenges or limitations associated with its implementation, such as security concerns or scalability issues.
  Relevance Evaluation: This paper is highly relevant to the point of focus as it specifically addresses the use of edge computing for localized decision-making and control in automated irrigation systems. The paper provides valuable insights into the benefits of edge computing, such as reduced dependence on cloud connectivity and improved response times, which are crucial for ensuring resilience and fault tolerance in these systems. The case study further strengthens the paper's relevance by demonstrating the practical application and effectiveness of the proposed approach.
  Relevance Score: 0.9
  Inline Citation: (Ali, 2023)
  Explanation: This paper focuses on the integration of edge computing in automated irrigation systems to enhance resilience and fault tolerance. The authors propose a decentralized architecture using edge devices like Raspberry Pi, NVIDIA Jetson, or Intel NUC to enable localized decision-making and control, reducing reliance on cloud connectivity and improving response times. The paper presents a case study of a smart irrigation system deployed in a greenhouse environment, demonstrating the effectiveness of the proposed approach.

 Full Text: >

Paper 6:
- APA Citation: Subathra, M. S. P., Blessing, C. J., Thomas George, S., Thomas, A., Dhibak Raj, A., & Ewards, V. (2019). Automated Intelligent Wireless Drip Irrigation Using ANN Techniques. In J. D. Peter, A. Alavi, & B. Javadi (Eds.), Advances in Big Data and Cloud Computing (pp. 555–568). Springer. https://doi.org/10.1007/978-981-13-1882-5_49
  Main Objective: To develop an automated, real-time drip irrigation system using Artificial Neural Networks (ANN) for efficient water management in tomato cultivation.
  Study Location: Coimbatore, Tamil Nadu, India
  Data Sources: Temperature, humidity, soil moisture, solar radiation, wind speed
  Technologies Used: Multilayer Perceptron Neural Network, Raspberry Pi controller, Wireless sensor network
  Key Findings: The Multilayer Perceptron (MLP) model had the least RMSE and was used for real-time water requirement calculation in the hardware system.

The proposed ANN technique effectively increased irrigation efficiency and reduced labor costs, water consumption, and electricity usage.
  Extract 1: "The developed MLP model can be used for prediction of evapotranspiration rates for particular location depending on the environmental factors. Also, the hardware model was tested in the real time under an experimental setup in university premises."
  Extract 2: "Thus, in conclusion, the proposed ANN technique increases the irrigation efficiency, which ultimately results in reducing the labor cost thus saving water and electricity."
  Limitations: The study was conducted in a specific region (Coimbatore, Tamil Nadu, India), and the results may not be directly applicable to other locations with different climatic conditions or soil types.

The study primarily focused on modeling reference evapotranspiration using ANN techniques. Further research could explore the integration of additional sensors and data sources to enhance the accuracy and reliability of the irrigation system.
  Relevance Evaluation: The study is highly relevant to the point in the literature review focusing on leveraging edge computing for localized decision-making and control in automated irrigation systems, particularly using technologies such as Raspberry Pi and NVIDIA Jetson. The study demonstrates the use of a Raspberry Pi controller to implement an MLP model for real-time calculation of water requirements in a drip irrigation system.
  Relevance Score: 0.9
  Inline Citation: (Subathra et al., 2019)
  Explanation: The study aims to develop an automated, real-time drip irrigation system using Artificial Neural Networks (ANN) techniques to enhance water management in tomato cultivation. The authors employed various ANN models, including Generalized Regression Neural Network, Radial Basis Function Neural Network, Probabilistic Neural Network, and Multilayer Perceptron Neural Network, to predict reference evapotranspiration (ETo) rates.

The Multilayer Perceptron (MLP) model was found to have the least Root Mean Square Error (RMSE) and was implemented in a hardware system using a Raspberry Pi controller. The system acquires environmental data, including temperature, humidity, and soil moisture, and uses the MLP model to calculate the water requirements for tomato plants. The results showed that the proposed ANN technique effectively increased irrigation efficiency and reduced labor costs, water consumption, and electricity usage.

 Full Text: >
"Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement Log in Find a journal Publish with us Track your research Search Cart Home Advances in Big Data and Cloud Computing Conference paper Automated Intelligent Wireless Drip Irrigation Using ANN Techniques Conference paper First Online: 12 December 2018 pp 555–568 Cite this conference paper Access provided by University of Nebraska-Lincoln Download book PDF Download book EPUB Advances in Big Data and Cloud Computing M. S. P. Subathra, Chinta Joyson Blessing, S. Thomas George, Abel Thomas, A. Dhibak Raj & Vinodh Ewards  Part of the book series: Advances in Intelligent Systems and Computing ((AISC,volume 750)) 889 Accesses 2 Citations Abstract The aim of this work is to address the water scarcity prevalent in our country through smart irrigation practices. In this work we take certain environmental factors such as soil moisture content into consideration for creating a sustainable and smart irrigation system. The models proposed here for the day to day estimation of evapotranspiration are derived by using the daily data parameters such as temperature, solar radiation, wind speed and humidity for a period of 4 years (2009–2013) from Karunya University’s meteorological station, at Coimbatore, Tamil Nadu, India. An Artificial Neural Network approach is adopted to run the software part using the environmental parameters and the output obtained from the ANN method with the least RMSE error is taken into account for the ETo value. The reliability of the computational models used are done based on the results achieved through two prominent empirical methods. These include Penman-Monteith equation and Hargreaves equation and comparing their respective Mean Square Errors (MSE) and also the Root Mean Square Errors (RMSE). Hargreaves method is suitable with the least RMSE error. In the hardware approach Hargreaves method has been implemented using Raspberry PI controller. The real-time data from the field controller is relayed to a hardware setup at the local base station. This is done through a wireless ZigBee protocol which eventually transmits the necessary data via a GPRS link to the remote station. The output volumetric water content was calculated using Crop coefficient ETC. Solenoid valves are remotely controlled to release a calculated value of water based on the data acquired at the local base station. This method of automated irrigation will mitigate the problems usually associated with farming and will finally result in generating greater yields of crop production. Keywords Evapotranspiration ETo Artificial neural network (ANN) ZigBee Access provided by University of Nebraska-Lincoln. Download conference paper PDF Similar content being viewed by others Automated Drip Irrigation System Using Neural Network Chapter © 2021 Intelligent Irrigation System Using Machine Learning Technologies and Internet of Things (IoT) Chapter © 2021 Automatic Smart Irrigation Method for Agriculture Data Chapter © 2023 1 Introduction Agriculture is man’s oldest known profession. Even in the Indian Economy Agriculture output is an important component in calculating the GDP growth apart from providing sustenance to the entire population. In rural India, agriculture acts as a primary source of employment and trade. With globalization and exponential rise in population, the agriculture industry is facing a lot of more pressure than ever before. In the agricultural sector, according to statistics estimates that 60% of all the water taken for irrigation is taken from reservoirs, lakes and rivers alone. With the revolution in technology farmers and agriculturists across the globe have taken to more mechanized ways of irrigation to ensure judicious use of water. Even though we have many ways of irrigation the onus is always on to find the most efficient way to use water. The primary goal of agriculture is to provide safe, fresh food and staples to the public at the most reasonable price possible. The day to day demand on the agricultural sector makes it necessary to automate the overall irrigation process. This type of automated irrigation considers factors such as temperature, humidity and also the topography of the surrounding environment are taken into consideration. Therefore, to achieve a successful and high quality harvest it is necessary to design an irrigation system which takes all these factors into consideration. The main objective of irrigation is to provide plants with sufficient water to prevent stress that may reduce the yield. The frequency and quantity of water needed depends upon local climatic conditions, crop and stage of growth, and soil moisture plant characteristics. The quantity of water required can be determined in different ways which do not require the knowledge of “Evapotranspiration (ET)” rates. By using the reference Evapotranspiration (ETo), the Evapotranspiration (ET) rates can be calculated. Though the number of equations available to estimate ETo are available in abundance, the FAO-56 Penman-Monteith (FAO-56 PM) [1] equation along with Hargreaves equation are used for this work. Soft computing methods have proved to be superior and reliable in forecasting and estimating ETo [2]. The primary aim of this study is to study and select from different evapotranspiration methods such as Penman Monteith and Hargreaves method, the best method to estimate the daily reference evapotranspiration by running it through Artificial Neural Network (ANN) model. The data used for these methods is sourced from a meteorological station situated in the southern part of India. The results achieved above are compared with the reference values calculated through the Penman Monteith method. The product achieved by multiplying the reference evapotranspiration (ETo) and the crop coefficient (Kc) forms the term crop evapotranspiration (ETc) [3]. In the hardware approach drip irrigation has been laid for 4 rows and sensors has been placed. Using wireless sensor network in a real-time field for tomato plant has been demonstrated using raspberry pi controller by considering the best technique (MLP) using Hargreaves method was used. The real-time data in order to calculate the water required for irrigation based on the respective crop’s ‘Evapotranspiration’ coefficient. 2 Drip Irrigation Drip irrigation is a process through which water and fertilizers used could be saved by allowing the aforementioned quantities to drip slowly, through a network of valves, pipes, tubes and emitters, thus reducing wastage of water and nutrients therefore improving the application efficiency in certain cases even up to 90%. The components involved include Pump, pipelines, fittings, lateral pipe, emitters, end cap, tee connector, straight connector. 3 Evapotranspiration 3.1 Evapotranspiration Both the processes of Evaporation and transpiration tend to occur simultaneously and it isn’t easy to differentiate between both. The amount of solar radiation, reaching the soil surface is primarily used to determine the evaporation from a cropped soil. As the crop grows, the amount of solar radiation received by the plant reduces due to the increase in canopy shade area. In the initial part of crop development, the primary loss of water is due to soil evaporation whereas in the later stages it is due to transpiration. The FAO Penman-Monteith method based on expert consultation was recommended as the sole standard method for computing the reference evapotranspiration. This method requires certain parameter such as sunshine hours, solar radiation air humidity, air temperature and wind speed data. 3.2 Penman-Monteith Equation The FAO Penman-Monteith equation determines the evapotranspiration from the hypothetical grass reference surface and [1] provides a standard to which evapotranspiration in different periods of the year or in other regions can be compared and to which the evapotranspiration from other crops can be related $$ {\\text{ETo}} = \\frac{{0 \\cdot 408\\Delta \\left( {R_{\\text{n}} - G} \\right) + \\gamma \\frac{900}{T + 273}U_{2} \\left( {e_{\\text{s}} - e_{\\text{a}} } \\right)}}{{\\Delta + \\gamma \\left( {1 + 0 \\cdot 34U_{2} } \\right)}} $$ (1) where, ETo reference evapotranspiration [mm day−1], Rn net radiation at the crop surface [MJ m−2 day−1], G soil heat flux density [MJ m−2 day−1], T air temperature at 2 m height [°C], u2 wind speed at 2 m height [m s−1], es saturation vapour pressure [kPa], ea actual vapour pressure [kPa], es–ea saturation vapour pressure deficit [kPa], D slope vapour pressure curve [kPa °C−1], g psychometric constant [kPa °C−1]. 3.3 Hargreaves Equation As [4] an alternative when solar radiation data, relative humidity data and/or wind speed data are missing, reference evapotranspiration, ETo (mm d-1), can be estimated using the Hargreaves equation [5]. The FAO-56 Hargreaves equation [3] for daily computation is given by: $$ {\\text{ETo}} = C_{H} (T_{{\\max} } {-}T_{{\\min} } )^{\\text{Eh}} \\left( {{\\text{T}}_{\\rm mean} + 17.8} \\right){\\text{Ra}} $$ (2) where Tmaxmaximum day temperature Tmin minimum day temperature, Ra extraterrestrial solar radiation, Environment constants Eh, CH 3.4 Crop Coefficient (ETc) The reference evapotranspiration rates are multiplied by a crop coefficient to calculate the crop evapotranspiration. Here the crop coefficient expresses the difference in evapotranspiration between the cropped and reference grass surface. The differences achieved with respect to the evaporation and transpiration between both the surfaces can be combined into a single coefficient or described separately [6]. Certain factors which determine the selection approach are the climatic data available, the time at which the calculations are executed, also the accuracy required, play a pivotal role. $$ {\\text{ET}}_{\\text{Crop}} = {\\text{ ETo}} *{\\text{Kc}}\\quad {\\text{mm}}/{\\text{day}} $$ (3) where ETo—Evapotranspiration, Kc-Crop Coefficient. The crop coefficient for tomato plant is given in Table 1. Table 1 Crop coefficient for tomato plant Full size table 4 Artificial Neural Network (ANN) ANN architecture is based on the structure and function of biological neural network. Similar to neurons in the brain ANN also consists of neurons which are arranged in various layers [7]. The popular neural network namely multilayer perceptron (MLP) consists of input layer to receive the external data to perform pattern recognition, output layer which gives the problem solution and hidden layer is an intermediate layer which separates the other layers. The adjacent neurons from input layer to output layer are connected through acyclic arcs. The MLP uses training algorithm to learn (Fig. 1). Fig. 1 Multilayer perceptron Full size image The datasets which modifies the neuron weights depending on the error rate between target and actual output. First, for model establishment, various networks like generalized regression neural network, radial basis function neural network, probabilistic neural network and multilayer perceptron network were selected because of its wide application and high accuracy [8]. Total 4 years of data of Karunya (Karunya University weather station) was taken and 3 years were considered for training and 1 year was considered for testing using different models of Artificial Neural Network. The statistical error was calculated for a given area and equation to predict the better model for evapotranspiration calculations. For a given data, the neural network acquires the data and generates an ETo value which is referenced with the one calculated by equations such as Penman and Hargreaves. The model with the least RMSE error is chosen and implemented (Fig. 2; Table 2). Fig. 2 Results for hargreaves equation Full size image Table 2 Statistical error achieved through penman and hargreaves model Full size table From the above table it is evident that among Generalized Regression Neural Network (GRNN), Probabilistic Neural Network, Radial Basis Function (RBF), the Root Mean Square Error (RMSE) is the least for the Multi-layer Perceptron Neutral Network model. Generalized Regression Neural Network (GRNN) is generally used extensively for function approximation and consists of layers such as radial basis layer and special linear layer. There is no need for an iterative training procedure here. It internally consists of four layers. Radial Basis Function Neural Network (RBF) has the abilities of quick training and generalization ability. The approximation of a non-linear object is done through RBF neural network. Multilayer Perceptron (MLP) is widely chosen for its ability ti solve tough and various issues. The output is influenced by several parameters to get the desired results. Probabilistic Neural Network (PNN) is a feed forward neural network, is used in pattern recognition problems and classification problems. This method ensures that mis-classification is minimized to a greater extent. 5 Study Area and Data The study area involves an agricultural plot rectangular in size amounting to 11 square yards, with 30 tomato plants and 30 inline emitters. These plants are supplied by LDPE (Low Density Polyethylene) tubes which are 12 mm in diameter. The data such as temperature, solar radiation, wind speed and humidity are acquired for a period of 5 years from the meteorological station of Karunya University at Coimbatore (Latitude of 10.9397487° and Longitude of 76.7458484°), Tamilnadu, India. It is located in the Western Ghats in southern part of India which is surrounded by high mountains. 6 Hardware Block Diagram 6.1 Hardware Implementation The hardware requirements for this setup require a Solar panel. Through the concept of photovoltaic effect, solar panels are used to generate electricity from the sun. A Lead Acid battery is used in this setup, this is dependable and inexpensive when calculated on a cost-per-watt base. Most common types of Lead Acid battery used are the gel type also known as Valve-Regulated Lead Acid (VRLA). The battery used in this system is Sealed Lead Acid battery to prevent the batteries from overcharging, a charge controller is used. This is basically a voltage cum current regulator which regulates the voltage and current coming from the solar panels to the battery. Charge controller used here is a 3 A controller for a Lead-acid Battery. In the area of sensor networks, devices such as Tran’s receivers play a very important role. It is necessary for sensor networks to use wireless modules to communicate and relay data. This setup uses one of the easiest modules named XBee wireless module. The Co-coordinator XBee is connected to the micro-controller board for transferring the data to processor. These are connected to the Transmitter and Receiver pins of the controller. An electronic component, model or subsystem whose primary aim is to act as a detector for detecting changes in the environment surrounding it and to further transmit the information to another processor or a data base is termed as a sensor. In Base station sensors used are Temperature, Humidity and Water Flow Sensor. The data of each sensor is logged in a coma separated value (csv) file in the system after a time interval. The first sensor used in this setup is a temperature and humidity sensor. This uses components such as a capacitive humidity sensor and thermistor to measure the surrounding air and transmits the digital signal on a data pin. One main disadvantage of this sensor is that the new data gets transmitted only once every 2 s. The temperature and humidity sensor used here works in the power range of 3–5 V and has maximum Input and Output current of 2.5 mA. The water flow sensor consists of parts such as a water rotor, valve body made out of plastic and a hall effect sensor. It works when the water flows through the rotor and the rotor rolls. The Hall Effect sensor further generates a consequent output based on the rotor rotation. This sensor was connected at the outlet-valve of the pump to measure the actual water applied to the plants each day. This sensor has a minimum dc working voltage of 4.5 V and a maximum working current of 15 mA. It has a DC working voltage of 5–24 V. Soil Moisture sensor is used to sense the moisture content in the soil at a particular place. It gives out the analog signal which is connected to the ADC of the XBee [9]. Their range ranges from 0 to 45% if volumetric water content in soil and has an accuracy of ±4% and power rating of 3 mA and 5 V DC supply. A relay circuit plays a crucial role in the hardware setup at the base station. A relay switch is used in this setup and the it has a coil which is driven by an NPN transistor switch. This switch acts in the cut-off region when base voltage of the transistor is zero. In such a condition no collector current flows into the base and no current flows through the relay coil too. Remote Sensor Node plays an important role in the whole system. This device is used to sense the soil moisture in the field and send the data to the base station. These are low power consuming unit with solar power and rechargeable Lithium ion battery for usage at time of inadequate solar radiation. These features include a programmable Charge Current Up to 1000 mA/Pre-set 4.2 V Charge Voltage with 1.5% Accuracy. A Raspberry pi is used as here which has a quad core ARMv8 processor with 1.2 GHz clock speed. This is preferred for systems which require multitasking with high [10] speed and memory, for processing and storing the data obtained from remote sensor nodes. The programming language used in raspberry pi is Python. Python is versatile and provides multi-threading, hence two or more programs can run at same time using CPU time sharing. Both the equations are run through python and the results are noted (Figs. 3 and 4). Fig. 3 Overall block diagram of system Full size image Fig. 4 Overall setup of the system Full size image 7 Working The working of the system all starts with the deployment of remote sensor node in the field near to the tomato plant root at 20 mm safe distance. It reads the soil moisture content for every pre-set time interval and sends it to the base station, where the packets of data received by the co-coordinator XBee are decrypted and data is obtained. The obtained values are Remote Node Battery Voltage and soil moisture with the node address. Upon receiving this, base station senses the environment temperature and Humidity and then logs the data into a CSV file and at the same time to the cloud server. The data upon reaching a certain count are then imported into a new program and the required parameters are calculated for finding the ETc required for the tomato plant. The calculations and crop parameters are given in Table 1. Then the water required is calculated and the pump is turned ON, post this operation the water flow from the laterals are continuously monitored using water flow sensor, and upon reaching the calculated amount of water needed the pump will be turned OFF. All these process details are updated to the server, upon which a user can view in their personal devices in the form of a webpage. The volumetric analysis performed allows an average of 9.1(L)/day of water for the tomato crop on a daily basis. The calculations are achieved by applying the formulas below [11]. $$ {\\text{ETo}} = C_{H} \\left( {T_{ {\\max} } - T_{ {\\min} } } \\right)^{\\text{Eh}} \\left( {{\\text{T}}_{\\rm mean} + 17.8} \\right){\\text{Ra}} $$ (4) Final Volume $$ v = \\left( {{\\text{Kc}}} {{\\text{ETo}}} - {\\text{rm}} \\right)(1 \\div 1 - {\\text{Lf}}(1 - {\\text{LR}}) \\div {\\text{Lf}}(1 - {\\text{LR}}) $$ (5) where rm: The average monthly rain volume (mm) Lf: Leaching efficiency coefficient as a function of the irrigation water applied LR: Leaching fraction given by the Humidity that remains in the soil $$ {\\text{LR}} = {\\text{ECw}} \\div (5{\\text{ECe}} - {\\text{ECw}}) $$ (6) ECw: the electrical conductivity of the irrigation water \\( ({\\text{ds }} . {\\text{ m}}^{( - 1)} ) \\) and ECe: the crop salt tolerance \\( ({\\text{ds }} . {\\text{ m}}^{( - 1)} ) \\). 7.1 Database Server A data base server is generally a computer program which is tasked with providing database services for other computer programs and computers. Several DBMS softwares provide database-server functionality and some exclusively rely on a client-server model in order to access the database (Fig. 5). Fig. 5 Flowchart representing the working of the system Full size image 7.2 Cloud Computing Cloud computing is a recently developed type of computing which is based on the concept of sharing computer re sources rather than having other network related hardware to handle applications. Cloud computing is offered by various companies either as open source or a licensed version, for example IBM’s Blue Cloud. Cloud computing is used in this setup to make the data acquired by the local base station accessible for anyone anywhere (Fig. 6). Fig. 6 Cloud connected system Full size image 8 Results and Discussion Results shown in the below figures are plotted from the data obtained or stored in the database after testing it for 24 h. Figure 7 shows the temperature variation for a day. Figure 8 Humidity variation for a day and Fig. 9. Soil Moisture variation for a day. Fig. 7 Temperature variation for a day Full size image Fig. 8 Humidity variation for a day Full size image Fig. 9 Soil moisture variation for a day Full size image 9 Conclusion In this work Information and Communication Technologies (ICT) are used extensively. The foremost concern in the Indian Agricultural sector is the lack of efficient irrigation techniques. Drip irrigation to a certain extent solves this issue. By considering cum monitoring environmental parameters such as temperature, relative humidity, sunshine hours, the water required can be calculated. This enables us to efficiently use the natural resources available to us ensures that a high yield is achieved. The work done here highlights the need for a Multi-layer Perceptron (MLP) enables irrigation network. The most relevant input variables for predicting the evapotranspiration are found to be Minimum Temperature, Maximum Temperature, and Minimum Humidity, Maximum Humidity, Wind Speed and Sunshine hours. The Penman and Hargreaves equation are used to calculate the Evapotranspiration rates and these models are run in a python program which is fed into the Raspberry pi. The Raspberry pi acts as an interface between the soil and the computations involved. It is found that wind speed has minimum effect on evapotranspiration prediction. From the trained models for P-M and Hargreaves equation, Hargreaves equation was more accurate. For Karunya data, Hargreaves equations the root mean square error (RMSE) and Mean square error (MSE) obtained were 6 and 2.5%, showing, high accuracy for MLP which utilizes the most relevant input variables. The developed MLP model can be used for prediction of evapotranspiration rates for particular location depending on the environmental factors. Also, the hardware model was tested in the real time under an experimental setup in university premises. Thus, in conclusion, the proposed ANN technique increases the irrigation efficiency, which ultimately results in reducing the labor cost thus saving water and electricity. References Pandey, P.K., Dabral, P.P., Pandey, V.: Evaluation of reference evapotranspiration methods for the northeastern region of India. Elsevier J. Int. Soil Water Conservation Res. 4, 52–63 (2016) Google Scholar   Shamshirband, S., Amirmojahedi, M., Goci, M., Akib, S., Petkovi, D., Piri, J., Trajkovic, S.: Estimation of reference evapotranspiration using neural networks and cuckoo search algorithm. Elsevier, J. Irrigation Drainage Eng. (2015) Google Scholar   Allen, R.G., Pereira, L.S. Raes, D., Smith, M., et al.: Crop evapotranspiration-guidelines for computing crop water requirements-FAO irrigation and drainage paper 56, vol. 300. FAO, Rome (1998) Google Scholar   www.rasberrypi.org Hargreaves, G.H., Samani, Z.A.: Reference crop evapotranspiration from temperature. Applied Engineering in Agriculture, American Society of Agricultural and Biological Engineers (1985) Google Scholar   Kim, S., Hung, S.K.: Neural networks and genetic algorithm approach for nonlinear evaporation and evapotranspiration modeling. J. Hydrol. 351, 299–317 (2008) Google Scholar   Antonopoulos, V.Z., Antonopoulos, A.V.: Daily reference evapotranspiration estimates by artificial neural networks technique and empirical equations using limited input climate variables. Elsevier J. Comput. Electron. Agric. 132, 86–96 (2017) Google Scholar   Huo, Z., Feng, S., Kang, S., Dai, X.: Artificial neural network models for reference evapotranspiration in an arid area of northwest China. Elsevier, J. Arid Env. (2012) Google Scholar   Gutiérrez, J., Villa-Medina, J.F. Nieto-Garibay, A., Porta, M.: Automated irrigation system using a wireless sensor network and GPRS module. IEEE Transactions on Instrumentation and Measurement (2014) Google Scholar   Cobaner, M.: Evapotranspiration estimation by two different neuro-fuzzy inference systems. Elsevier J. Hydrol. 398, 292–302 (2011) Google Scholar   Yahyaoui, I., Tadeo, F., Segatto, M.V.: Energy and water management for drip-irrigation of tomatoes in a semi-arid district. Elsevier, Agric. Water Manage (2017) Google Scholar   Download references Author information Authors and Affiliations Department of Electrical Sciences, Karunya Institute of Technology and Sciences, Coimbatore, 641114, Tamil Nadu, India M. S. P. Subathra, Chinta Joyson Blessing, S. Thomas George, Abel Thomas & A. Dhibak Raj Faculty of Computer Sciences and Technology, Karunya Institute of Technology and Sciences, Coimbatore, 641114, Tamil Nadu, India Vinodh Ewards Corresponding author Correspondence to M. S. P. Subathra . Editor information Editors and Affiliations Department of Computer Sciences Technology, Karunya Institute of Technology & Sciences, Coimbatore, Tamil Nadu, India J. Dinesh Peter Department of Civil and Environmental Engineering, University of Missouri, Columbia, MO, USA Amir H. Alavi School of Computing, Engineering and Mathematics, University of Western Sydney, Sydney, NSW, Australia Bahman Javadi Rights and permissions Reprints and permissions Copyright information © 2019 Springer Nature Singapore Pte Ltd. About this paper Cite this paper Subathra, M.S.P., Blessing, C.J., Thomas George, S., Thomas, A., Dhibak Raj, A., Ewards, V. (2019). Automated Intelligent Wireless Drip Irrigation Using ANN Techniques. In: Peter, J., Alavi, A., Javadi, B. (eds) Advances in Big Data and Cloud Computing. Advances in Intelligent Systems and Computing, vol 750. Springer, Singapore. https://doi.org/10.1007/978-981-13-1882-5_49 Download citation .RIS.ENW.BIB DOI https://doi.org/10.1007/978-981-13-1882-5_49 Published 12 December 2018 Publisher Name Springer, Singapore Print ISBN 978-981-13-1881-8 Online ISBN 978-981-13-1882-5 eBook Packages Intelligent Technologies and Robotics Intelligent Technologies and Robotics (R0) Share this paper Anyone you share the following link with will be able to read this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing initiative Publish with us Policies and ethics Sections Figures References Abstract Introduction Drip Irrigation Evapotranspiration Artificial Neural Network (ANN) Study Area and Data Hardware Block Diagram Working Results and Discussion Conclusion References Author information Editor information Rights and permissions Copyright information About this paper Publish with us Discover content Journals A-Z Books A-Z Publish with us Publish your research Open access publishing Products and services Our products Librarians Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility statement Terms and conditions Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"

Paper 7:
- APA Citation: Ayuningsih, E., Suryono, S., & Gunawan, V. (2020). Fuzzy rule-based systems for controlling plant growth parameters in greenhouses using fog networks. 2019 Fourth International Conference on Informatics and Computing (ICIC), 1-6.
  Main Objective: To develop a fuzzy rule-based system for controlling and monitoring climate parameters in a fog-based greenhouse, overcoming network latency issues and improving the efficiency of automated irrigation systems.
  Study Location: Unspecified
  Data Sources: Sensor data (temperature, soil moisture, air humidity, intensity)
  Technologies Used: Fog network, Fuzzy rule-based system, Raspberry Pi, NVIDIA Jetson, Intel NUC
  Key Findings: The study successfully implemented a fuzzy rule-based system to control drip watering duration in a greenhouse using a fog network, reducing network latency and improving the efficiency of the automated irrigation system.
  Extract 1: "The controlling system parameters of growing plants in greenhouse using fog network technology has been improved successfully. The system does not experience the latency problem during the collecting data in a real-time. The controlling systems in greenhouse is more efficient because it is supported by fog network technology."
  Extract 2: "Based on the result of calculations with fuzzy rule-based, the duration development is done using the PHP programming language with Arduino IDE, MQTT, Node Js. MySQL, and Sublime Text 3. Coding the application is done using the Google chrome web browser."
  Limitations: None
  Relevance Evaluation: The paper is highly relevant to the outline point, as it specifically addresses the use of edge computing, such as Raspberry Pi or NVIDIA Jetson, to enable localized decision-making and control in automated irrigation systems. It provides a detailed explanation of how edge computing can reduce dependence on cloud connectivity, improve response times, and enhance the efficiency of integrated end-to-end automated irrigation systems.
  Relevance Score: 0.9
  Inline Citation: None
  Explanation: The study aims to use fuzzy rule-based systems to control and monitor climate parameters in a greenhouse using a fog network, leveraging the benefits of fog computing to overcome network latency issues in real-time data collection. By incorporating expert knowledge and intuitive rules, the fuzzy rule-based system can adjust drip watering duration based on temperature, soil moisture, humidity, and light intensity variables.

 Full Text: >
"IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Conferences >2019 Fourth International Con... Fuzzy Rule-Based Systems for Controlling Plant Growth Parameters in Greenhouses Using Fog Networks Publisher: IEEE Cite This PDF Ekatri Ayuningsih; Suryono Suryono; Vincencius Gunawan All Authors 2 Cites in Papers 71 Full Text Views Abstract Document Sections I. Introduction II. Related Work III. Realization Fuzzy Rule-Based for System Controlling Plant Growth Parameters in Greenhouse Using Fog IV. Result and Discussion V. Conclusion Authors Figures References Citations Keywords Metrics Abstract: Greenhouse technology is very effective in increasing food resilience in various countries. In this study, greenhouse technology was implemented in chili plants. Chili was chosen because it is included in food security commodities that had to be improved, especially in Central Java, Indonesia. Control and monitoring systems need to be implemented to control the condition of greenhouse environment. Greenhouse control systems in previous studies used cloud computing technology and fuzzy methods. However, cloud computing has several disadvantages, one of them is the more devices connected to the application, the greater the probability of latency is encountered. Therefore, this study proposed fuzzy rule-based to control the growth parameters in greenhouses by using fog network. Fuzzy rule based is used to determine the length of drip watering time and fog network as a platform to overcome network latency problems when conducting data collection processes. The greenhouse control system with sensor nodes is built by connecting the system with the Microcontroller ESP8266-WIFI chip to carry out data acquisition and transmission of sensor data for temperature, soil moisture, air humidity, and intensity using WIFI networks to the fog server. In this study, the calibration of the accuracy of fuzzy rule-based manual calculation and system calculation is compared. From the tests performed, the Mean Absolute Percent Error (MAPE) between the calculation and using the MAPE is 0%. Published in: 2019 Fourth International Conference on Informatics and Computing (ICIC) Date of Conference: 16-17 October 2019 Date Added to IEEE Xplore: 10 February 2020 ISBN Information: DOI: 10.1109/ICIC47613.2019.8985857 Publisher: IEEE Conference Location: Semarang, Indonesia SECTION I. Introduction Greenhouse is a building which aims to modify the climate to meet the plants need. Greenhouse is generally used to produce crops outside the normal season [1]. The type of cover material in a greenhouse aims to make solar radiation easily absorbed by plants. Greenhouse cultivation method aims to make plants' growth out of the natural environment and to make the environment control more optimal [2]. Greenhouse technology is used to provide a controlled microenvironment for optimal plant growth so that it can protect plants from unfavorable weather conditions [3]. The control system needs to be done to control the environmental conditions of the greenhouse. The previous research which has been carried out by [4], in 2016 on the greenhouse control system used fuzzy logic type Mamdani. Fuzzy logic type Mamdani is implemented to regulate the duration drip of plants to be more dynamic based on the the input values of greenhouse temperature and humidity [4]. The Mamdani control system is carried out to adjust the temperature and humidity in the greenhouse which refers to climate factors presented by the sigmoid curve [4]. Fuzzy logic type Mamdani is usually suited to intuitive problems rather that to handle control systems. The sigmoid curve has a weakness where the membership value range is equal to one shorter by [5] using cloud computing technology. Greenhouse automation systems controls temperature, humidity, soil moisture effectively [5]. The system retrieve sensor acquisition data and send data to users through the cloud [5]. Cloud computing was designed using remote servers on the internet to manage, store and process data using a personal computer. Cloud computing has briefly transformed information technology dramatically by providing some enormous benefits for users of information technology, including eliminating information technology investments, scalability, proportional costs. However, cloud computing has a weakness: the more devices connected, the more network latency problems is experienced by the application [6]. Based on previous researches, [4] and [5], this study builds an information system using fuzzy rule-based to control and monitor climate parameters in fog-based greenhouses. Rule-based systems have benefit: the created rules can imitate human thinking and reasoning to facts that are known based on expert knowledge about the problems of a domain [7]. Fuzzy logic and rule based system can be combined to create rules that are very similar to natural languages, thus fuzzy rule-based can make information extracted from rules so that they are easier to understand [8]. Fuzzy rule-based systems can work in fog network and can provide problem information from the input provided [9]. The fuzzy rule-based system type Tsukamoto has the advantage of having high accuracy and high interpretation of data [10]. Fog computing is used as a computing paradigm between cloud data centers and IoT devices [11]. Fog uses a network device called fog node to process data collection form IoT so that it doesn't experience network latency problems. Fog computing is a promising computing technology that is able to overcome network latency problems during the process of collecting data form IoT [6]. In this study, the fog network is able to handle network latency problems in real-time while sensor data acquisition, and bandwidth is more efficient compared to cloud networks. Fuzzy rule-based is implemented to determine the proper rule for trip duration which is appropriate with the data of temperature variable, soil moisture, humidity and intensity variable. The data of variables was obtained from the result of the greenhouse observation. Thus, the controlling system in greenhouse is more efficient and more superior that the previous research. SECTION II. Related Work A. Fuzzy Rule-Based Fuzzy rule-based basically comes from fuzzy logic and fuzzy set theory [12]. Fuzzy logic and rule-based system are combined into fuzzy rule-based. Three are three popular types of fuzzy rule-based, they are Mamdani, Sugeno, and Tsukamoto. Fuzzy rule-based generally applied to problems classification, such as output or discrete values. Fuzzy rule-based system are a classic rule system that is one of the most important fields of fuzzy set application and fuzzy logic [8]. Fuzzy rule-based systems are successfully applied to various problem in different domains in the uncertainty and obscurity of problems [10]. Several forms of membership function are used in fuzzy rule-based, such as trapezoid, triangular and rectangular [8]. Trapezoid membership function can be seen as a generalizing triangle and rectangular membership function. At the testing stage, fuzzy classification involves five important steps namely fuzzification, application, implication, aggregation, and defuzzification. Triangle Fuzzy A[x], can be presented by A (a, b, c; 1) with the membership function μ [x] shown in Figure 1 [12]. Fig. 1. Triangle fuzzy membership function [12]. Show All The formula for the triangle membership function is as follows [12]. μ[x]= ⎧ ⎩ ⎨ ⎪ ⎪ ⎪ ⎪ 0, (x−a)/(b−a), 1, (c−x)/(c−b),   x≤a or x≥c;         a≤x≤b;                x=b;         b≤x≤c. (1) View Source Trapezoid fuzzy shown in Figure 2. Fig. 2. Trapezoid fuzzy membership function [13]. Show All The formula for the trapezoid membership function is as follows [13]. f T (x)= ⎧ ⎩ ⎨ ⎪ ⎪ ⎪ ⎪ 0, (x−a)/(b−a), 1, (d−x)/(d−c), x≤a or x≥d;          a<x<b;           b≤x≤c;            c<x<d. (2) View Source B. Fog Computing As a new computing paradigm, fog computing is able to expand cloud computing and services to the network edge. Fog computing has several advantages dealing with computation, communication, control, storage and service on the edge of the network. The fact is that computational computing is an extension of cloud computing, not as a substitute for cloud computing [14]. There are two categories of fog nodes namely Fog Gateway Nodes (FNG) and Fog Computational Nodes (FCN), as shown in Figure 3 [11]. Fig. 3. Fog organization [11]. Show All C. Greenhouse A greenhouse is a building that function to modify the climate based on plants' need. Greenhouse is used to produce food crops and flowers outside the normal season. Greenhouses has similar structures with conservatories: the rooms that usually attached to houses provide living space for plants and humans [1]. The shape of a greenhouse is characterized into five different types. Greenhouses are most commonly used in hot and arid environments, namely Quonsets, arch-tunnels, even-span and uneven-span [17]. D. Chilies Chilies require temperature, soil moisture, air humidity, and optimal intensity. Chili plants can growth well at temperature of 20–30 °C, Soil moisture of 60-80%, air humidity from 50 to 70 and intensity of 3,000-10,000 [18]. SECTION III. Realization Fuzzy Rule-Based for System Controlling Plant Growth Parameters in Greenhouse Using Fog A. Instrumentation The instruments used in this study consist of hardware and software. The hardware used to support the system building are computer and an Acer Aspire laptop. The specifications of Acer are intel processor core i3327U, Windows 10 Pro, and RAM 4.0 Gb. The other hardwares used to support the design of fog network architecture's building are sensors of SHT-11, YL-39, BH-1750, Microcontroller WIFI ESP8266, DAQ-SYSTEM, WIFI Router, and internet modem. The software is used to support the function of hardware system. The sofwares used in this study are PHP, Arduino IDE, Node JS, MySQL, Sublime Text 3, and Xampp. The data used for the study is the result of acquisition data from sensors SHT-11, YL-39, and BH-1750 B. Greenhouse Greenhouses are made using lightweight steel frames and on the roof using paranet with a size of 2 x 2 meters shown in Figure 4. Fig. 4. The design of the roof of a greenhouse. Show All Fig. 5. The design of the framework of the greenhouse. Show All C. Application of Fog Model The system for controlling plant growth parameters in a greenhouse uses a fog network consisting of sensor nodes and fog servers. The data needed in this study are temperature, humidity, soil moisture and intensity. The control system is built using an ESP8255 Microcontroller which has connected the sensor data acquisition system and data communication system using WIFI. The design of the fog network system for the greenhouse control system in this study is shown in Figure 4. This study uses three sensors, namely temperature and humidity sensors (SHT-11), soil moisture sensors (YL-39) and intensity sensors (BH-1750). The ESP8266 Microcontroller is programmed to read SHT-11 sensors, YL-39 sensors and BH-1750 sensors with the TWI protocol. The design of the fog network system for a climate control system in a greenhouse is shown in Figure 6. Fig. 6. Fog network system design in greenhouses. Show All In this study using two gateways, namely WIFI network for data communication in the fog area and internet network in the cloud area. Climate parameter data obtained from sensor data acquisition using the fog network. In this study Arduino IDE is set to produce data acquisition every once a minute. Message Queuing Telemetry Transport (MQTT) as a publisher block sends sensor acquisition data. After the sensor acquisition data is obtained, it is then stored in the database on the local monitor. Sensor acquisition data is sent by a cloud server to interface user for processing fuzzy rule-based using web-based programming. The system framework for controlling plant growth parameters in a greenhouse using fog networks are shown in Figure 7. Fig. 7. Control system framework. Show All D. Application of Fuzzy Rule-Based Fuzzy rule-based has four main stages, namely: fuzzification, application, implication, and aggregation. The rule based consists of 5 ∗ 5 ∗ 5 ∗ 5=625 rules, 5 rule for each variable: temperature, moisture, humidity, and intensity. The domain for the temperature variable is shown in TABLE I. Table I. Temperature variable The temperature variable is divided into five fuzzy sets, namely very cold, cold, normal, hot, and very hot. Those are presented uses a trapezoid and triangular curve with [0 50] [19]. The fuzzy sets of the temperature variable are shown in Figure 8. Fig. 8. Fuzzy sets of the temperature variable. Show All The domain for soil moisture variables is shown in Table II. Table II. Variable moisture The soil moisture variable is divided into five fuzzy sets, namely: very dry, dry, normal, wet, and very wet with [0 100] universal set which are presented using trapezoid and triangular curves [19]. The fuzzy sets of soil moisture variable are shown in Figure 9. Fig. 9. Fuzzy sets of soil moisture variable. Show All The domain for the humidity variable is shown in Table III. Table III. Variable humidity Humidity variable is divided into five fuzzy sets, namely: very low, low, normal, high, and very high with [0 100] [20] universal set. The fuzzy sets of humidity variable are shown in Figure 10. Fig. 10. Fuzzy sets of humidity variable. Show All The domain for the intensity variable is shown in Table IV. Table IV. Variable intensity The intensity variable is divided into 5 fuzzy sets, namely dark, rather dim, normal, bright, and very bright which are presented using trapezoid and triangular curves. Intensity variable with [0 60,000] [19] universal set. The fuzzy sets of intensity variable are shown in Figure 11. Fig. 11. Fuzzy sets of intensity variable. Show All The function of fuzzy membership for linguistic term are x 1 (Temperature), x 2 (soil moisture), x 3 (humidity), X 4 (intensity) which shown in Figure 8, Figure 9, Figure 10 and Figure 11. Fuzzy rules are used as follows. Rule 393: if x 1 is Hot and x 2 is Very Dry and x 3 is High and x 4 is Normal then duration drip = Very Long; Rule 418: i x 1 is Hot and x 2 is Dry and x 3 is High and x 4 is Normal then duration drip = Long; If x 1 =30.110001, x 2 =37, x 3 =76.273178 , and x 4 =: 5,192, then the steps is carried out as follows: Fuzzification Rule 393: f Hot (30.110001)=0.3, f Very Dry (37)=0.15, f High (76.273178)=0.87, f Normal (5,192)=0.63; Rule 418: f Hot (30.110001)=0.3, f Dry (37)=0.76, f High (76.273178)=0.87, f Normal (5,192)=0.63; View Source Application Rule 393: f Hot (30.110001)∧ f Very Dry (37)∧ f High (76.273178)∧ f Normal (5,192)=Min (0.3,0.15,0.87,0.63)=0.15; Rule 418: f Hot (30.110001)∧ f Dry (37)∧ f High (76.273178) ∧ f Normal (5,192)=Min(0.3,0.76,0.87,0.63)=0.3; View Source Implication Rule 393:fRule393 → Very Long (30.110001,37,76.273178, 5,192)=0.15; Rule418:fRule418 → Long (30.110001,37,76.273178, 5,192)=0.29; View Source Aggregation f Very Long (30.110001,37,76.273178,5,192)= fRule393 → Very Long (30.110001,37,76.273178,5,192)∨ fRule268 → Long (30.110001,37,76.273178,5,192) =Max(0.15)=0.15 fLong(30.110001,37,76.273178,5,192)= fRule418→Long(30.110001,37,76.273178,5,192)∨ fRule293→(30.110001,37,76.273178,5,192) =Max(0.3)=0.3 View Source Defuzzification Long The result of fuzzy rule-based calculation using system are x 1 =30.110001, x 2 =37, x 3 =76.273178, x 4 =5,192 show in Figure 12, Figure 13, Figure 14 and Figure 15. Fig. 12. Calculation of fuzzification stage from fuzzy rule-based. Show All Fig. 13. Calculation of application stage from fuzzy rule-based. Show All Fig. 14. Calculation of implication stage from fuzzy rule-based. Show All Fig. 15. Calculation aggregation and defuzzitication stage from fuzzy rule-based. Show All SECTION IV. Result and Discussion This research produces a software that is able to present output in the feature of sensor acquisition data which displayed on the web-based application dashboard and watering control. The controlling plant growth parameters system in greenhouses uses the fuzzy rule-based method based on fog network. Based on the result of calculations with fuzzy rule-based, the duration development is done using the PHP programming language with Arduino IDE, MQTT, Node Js. MySQL, and Sublime Text 3. Coding the application is done using the Google chrome web browser. A. Sensor Testing Testing the temperature and humidity sensors (SHT-11), soil moisture sensors (YL-39), intensity sensors (BH-1750) is carried out in a scenario where the sensor is placed in a greenhouse. The measurement results obtained after the SHT-11 sensor, YL-39 and BH-1750, tested are shown in Table V. Table V. Sensor testing B. Fuzzy Rule-Based Testing In this study, MAPE accuracy analysis was used to measure errors and calculate the presentation deviations of calculation using both manually and MAPE system. The MAPE formula [21] is as follows. MAPE=100 x  1 n Σ n t=1 ∣ ∣ ∣ At−Pt At ∣ ∣ ∣ (3) View Source Testing of mathematical calculation of fuzzy rule-based was done manually and systematically using MAPE analysis by entering the value of input temperature, soil moisture, humidity, and intensity. The result is shown in TABLE 17. Table 17. Mape accuracy analysis C. Control System Work Testing The TABLE 18 is the result of testing the drip watering devices. Table 18. The result of testing the success of the system work D. The Testing of Cloud and Fog Network Performance The result of transmission time shows that using fog network is faster that cloud network. The average of data's speed for fog network is 471 ms, while the speed of data transmission for cloud network is up to 1349 ms. The speed is affected by the network architecture, such as the using of fog network, the measurement data of object from sensors in the shorter range network. SECTION V. Conclusion The controlling system parameters of growing plants in greenhouse using fog network technology has been improved successfully. The system does not experience the latency problem during the collecting data in a real-time. The controlling systems in greenhouse is more efficient because it is supported by fog network technology. The simulation using fuzzy rule-based algorithm in PHP programming language obtained watering control can be done remotely and the duration of watering is also adjusted to the climate conditions in the greenhouse so that it can reduce the risk of dead plants due to the influence of uncertain climate factors. Authors Figures References Citations Keywords Metrics More Like This Evolving Fuzzy-Rule-Based Classifiers From Data Streams IEEE Transactions on Fuzzy Systems Published: 2008 Fuzzy Rule-Based Bayesian Reasoning Approach for Prioritization of Failures in FMEA IEEE Transactions on Reliability Published: 2008 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."

Paper 8:
- APA Citation: Alharbi, H. A., & Aldossary, M. (2021). Energy-Efficient Edge-Fog-Cloud Architecture for IoT-Based Smart Agriculture Environment. IEEE Access, 9, 110480–110492. https://doi.org/10.1109/ACCESS.2021.3101397
  Main Objective: The main objective of the study is to propose a new energy-efficient edge-fog-cloud architectural paradigm that promises to enhance the energy-efficient of smart agriculture systems and corresponding carbon emissions.
  Study Location: Unspecified
  Data Sources: Heterogeneous data collected from IoT sensors
  Technologies Used: Raspberry Pi, NVIDIA Jetson, Intel NUC
  Key Findings: The proposed architecture, validated using mathematical modeling and a heuristic algorithm, demonstrates significant reductions in overall power consumption, carbon footprints, and network traffic compared to traditional cloud-based architectures.
  Extract 1: Edge computing refers to a new computing model that implements the computation of sensors/actuators data at the edge of the network. With this concept, some applications and services that do not require a lot of computing resources can be processed in the edge layer (close to the data source) and no longer need to traverse the network to be processed by the fog or the cloud.
  Extract 2: Thus, edge computing can improve data transmission performance, ensure real-time processing, and reduce the computational load as well as the amount of data transmitted to and from the fog or cloud data centers [8].
  Limitations: None
  Relevance Evaluation: The paper is highly relevant to the point under discussion, as it focuses on leveraging edge computing to reduce dependence on cloud connectivity and improve response times in automated irrigation systems. The research utilizes technologies like Raspberry Pi, NVIDIA Jetson, and Intel NUC for localized decision-making and control.
  Relevance Score: 0.9
  Inline Citation: (Alharbi and Aldossary, 2021)
  Explanation: Alharbi and Aldossary present an edge-fog-cloud infrastructure for smart agriculture to improve energy efficiency and reduce carbon emissions in this article. Using IoT sensors to collect heterogeneous data, this architecture enables real-time data processing and analysis at the edge, fog, and cloud layers, ensuring that each component processes data most appropriately based on its capabilities and resource availability.

 Full Text: >
"IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 9 Energy-Efficient Edge-Fog-Cloud Architecture for IoT-Based Smart Agriculture Environment Publisher: IEEE Cite This PDF Hatem A. Alharbi; Mohammad Aldossary All Authors 50 Cites in Papers 5287 Full Text Views Open Access Comment(s) Under a Creative Commons License Abstract Document Sections I. Introduction II. Proposed Architecture for Smart Agriculture System III. MILP Model IV. MILP Model Design V. Results and Discussion Show Full Outline Authors Figures References Citations Keywords Metrics Abstract: The current agriculture systems compete to take advantage of industry advanced technologies, including the internet of things (IoT), cloud/fog/edge computing, artificial intelligence, and agricultural robots to monitor, track, analyze and process various functions and services in real-time. Additionally, these technologies can make the agricultural processes smarter and more cost-efficient by using automated systems and eliminating any human interventions, hence enhancing agricultural production to meet future expectations. Although the current agriculture systems that adopt the traditional cloud-based architecture have provided powerful computing infrastructure to distributed IoT sensors. However, the cost of energy consumption associated with transferring heterogeneous data over the multiple network tiers to process, analyze and store the sensor's information in the cloud has created a huge load on information and communication infrastructure. Besides, the energy consumed by cloud data centers has an environmental impact associated with using non-clean fuels, which usually release carbon emissions (CO 2 ) to produce electricity. Thus, to tackle these issues, we propose a new integrated edge-fog-cloud architectural paradigm that promises to enhance the energy-efficient of smart agriculture systems and corresponding carbon emissions. This architecture allows data collection from several sensors to process and analyze the agriculture data that require real-time operation (e.g., weather temperature, soil moisture, soil acidity, irrigation, etc.) in several layers (edge, fog, and cloud). Thus, the real-time processing could be held by the edge and fog layers to reduce the load on the cloud layer, which will help to enhance the overall energy consumption and process the agriculture applications/services efficiently. Mathematical modeling is conducted using mixed-integer linear programming (MILP) for a smart agriculture environment, where the proposed architecture is imp... (Show More) An IoT-based edge-fog-cloud architecture for smart agriculture system. Published in: IEEE Access ( Volume: 9) Page(s): 110480 - 110492 Date of Publication: 30 July 2021 Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2021.3101397 Publisher: IEEE Funding Agency: CCBY - IEEE is not the copyright holder of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and stipulations in the API documentation. SECTION I. Introduction The Internet of Things (IoT) is one of the emerging technologies that promise to transform the way on how people work and live. The term IoT refers to a network of physical objects “things” that contain embedded systems with connectivity and computing power to exchange data with other devices and systems over the Internet. By 2025, the number of IoT devices connected to the Internet is projected to be 100 billion, with an economic impact of more than $ 11 trillion [1]. The recent development of IoT devices presents a new dimension in the agriculture field, where the IoT has become an ideal choice for smart agriculture due to its highly scalable and ubiquitous architecture. Moreover, the IoT-based smart agriculture value is estimated to reach $ 18.45 billion in 2022, and 75 million IoT devices are used for the agricultural sector in 2020 [2]. Furthermore, smart farms are projected to have 12 million IoT points by 2023 [3]. Smart agriculture has started incorporating IoT solutions to improve operational efficiency, maximize yield, and minimize wastage through real-time field data collection, data analysis, and deployment of control mechanisms. Also, the diverse of IoT-based applications such as precision farming and smart irrigation is very helpful to the enhancement of agricultural processes. Thus, the IoT is considered as one of the promising solutions for embracing connected farms to address agriculture-based issues and increase the quality and quantity of agricultural production. IoT solutions are highly associated with cloud computing to process the huge amount of heterogeneous data sent or received by agriculture sensors/actuators [4]. Although cloud computing can handle smart agriculture applications, some of the applications and services produce a large amount of data and need to be processed in a real-time manner, which may cause a heavy load on the network, long response time, and poor quality of service, due to limited bandwidth [5]. Therefore, using the traditional cloud-based architecture may not be efficient to support these applications, which may also result in high energy consumption due to the transfer of agriculture data to and from the cloud. The Information and Communication Technology (ICT) industry is projected to account for 20% of the global electricity demand by 2025 [5]–[8], [9]. Usually, consuming electricity is accompanied by carbon emissions (CO2). fossil fuel usage is the primary source of CO2 [10]. Consequently, this causes the growth of carbon dioxide emissions. According to [11], ICT uses 730 Million ton (Mt) CO2 equivalents (CO2e) or 1.4% of worldwide carbon emissions. To overcome the above shortcomings, edge and fog computing architecture are introduced to process the real-time IoT applications and services at the proximity of data sources in an efficient way, which have several benefits (e.g., reduce energy consumption, network traffic and improve quality of service) compared to traditional cloud-based architecture, that does not exploit the latest paradigms such as fog and edge in the agriculture system [4], [6]. However, edge and fog computing are not a replacement for cloud computing, as cloud computing will still be preferable and suitable for analyzing and processing heavy tasks, as well as storing data in a long term. The collaboration between edge, fog, and cloud computing is the best practice to achieve smart agriculture solutions. Several related works in the literature, (e.g. in [12], [13]), have discussed various architectures, techniques, and methods applied for smart agriculture systems considering different technologies such as IoT, big data analytics, and cloud computing. However, none of the existing works focused on the edge-fog-cloud architecture intending to reduce the energy consumption, CO2 emission, and network traffic as considering the three computing layers (edge, fog, and cloud). Therefore, this paper presents a new approach for smart agriculture systems to develop an energy-efficient offloading of IoT agriculture applications over an edge-fog-cloud computing architecture, according to the resource requirements of each agriculture task. Also, this approach could help to enhance the solutions of many traditional agriculture issues by taking the advantage of edge and fog computing, which will improve the overall energy efficiency and reduce CO2 emission, network traffic of smart agriculture systems. The major contributions of this paper are summarized as follows: ∙ Develop an energy-efficient architecture based on mathematical modeling and heuristic algorithm to study the offloading of IoT applications from agriculture sensors to edge, fog, and geo-distributed cloud, while considering minimization of the overall power consumption of networking and processing of the IoT agriculture services. ∙ Optimize the offloading of IoT agriculture applications over an edge-fog-cloud architecture, which connected to the access network, metro area network, and wide area network, respectively, thus eliminating the associated power consumption and telecommunication network traffic. ∙ Evaluate the usability and the capability of the proposed architecture and its models, using the mixed-integer linear programming (MILP) model, and compared the results to the traditional approach. The remainder of this paper is organized as follows: Section II introduces the edge-fog-cloud system architecture and its interaction layers. Section III presents the mixed-integer linear programming (MILP) model for optimizing the offloading of IoT agriculture applications in the edge-fog-cloud architecture. The model’s design, scenarios, and the input parameters of the models are presented in Section IV. This is followed by discussing the optimization model results and analysis in Section V. In Section VI, we introduce energy-efficient agriculture IoT applications distribution heuristic over the edge-fog-cloud architecture (EEAIOT-EFC). Finally, Section VII concludes the paper and discusses future work. SECTION II. Proposed Architecture for Smart Agriculture System Today, the traditional cloud-based architecture for agriculture systems is inefficient to satisfy all the requirements of the current scenarios [4], [5], [7], [8], as it lacks the essential efficiency prerequisites such as energy consumption, CO2 emission, network traffic, and so on [6]. Consequently, there is a need to develop an energy-efficient architecture for a smart agriculture system to fulfill these requirements. This section provides an outline of the proposed edge-fog-cloud architecture and its role in providing dynamicity and efficiency based on different IoT agriculture applications. The proposed architecture of the smart agriculture system is shown in Fig. 1; and it consists of four essential layers, namely, IoT sensor layer, edge layer, fog layer, and cloud layer. The description of each layer of the proposed architecture is presented as follow: FIGURE 1. An IoT-based edge-fog-cloud architecture for smart agriculture system. Show All A. IoT Sensor Layer IoT sensors generate massive heterogeneous data to the gateways by using various sensors deployed in different areas of the agriculture field. Also, this layer can receive decisions from to control actuators (e.g., turning on/off irrigation system) [14]. In smart agriculture, there is a range of IoT sensor nodes used to identify several phenomena over the urban areas including but not limited to soil pH, soil temperature, soil moisture, soil electrical conductivity, and ambient temperature [15]. In the IoT agriculture system, low power wide area (LPWA) technologies have paved the way due to their low power consumption and wide area coverage. Long range (LoRa) is proved its efficiency, as a transmission protocol for IoT sensors. Besides its low power consumption, it ensures an extent of 10 kilometers coverage or more. In addition to LoRa, multiple wireless technologies can be used for smart agriculture urban areas such as narrowband (NB)-IoT, WiFi, Zigbee, and the 5G. The Zigbee technology has been successfully used in the field of agriculture at a low power cost. However, the limited distance coverage for wireless data transferring (about 20 meters) is reducing its efficiency. A comprehensive comparison of different IoT wireless network technologies (Zigbee, LoRa, NB-IoT, and 5G), is presented in Table 1. TABLE 1 IoT Wireless Network Technologies Comparison B. Edge Layer Edge computing refers to a new computing model that implements the computation of sensors/actuators data at the edge of the network. With this concept, some applications and services that do not require a lot of computing resources can be processed in the edge layer (close to the data source) and no longer need to traverse the network to be processed by the fog or the cloud. Thus, edge computing can improve data transmission performance, ensure real-time processing, and reduce the computational load as well as the amount of data transmitted to and from the fog or cloud data centers [8]. However, in case of unavailability/unsuitability of the resources in the edge layer, the sensors will automatically request to process their data in the fog or the cloud, and this will be done hierarchically. C. Fog Layer The fog computing concept was initially proposed by Cisco in 2014 to expand the resources of cloud computing to the edge of the telecommunications network. In this context, the fog layer has the responsibility to process and analyze data sent from IoT sensors, which helps to minimize the latency for agriculture applications and services. Also, the fog layer has the ability to process and analyze complex data more than the edge layer. Both fog and edge can provide computation, networking, and storage services in between the sensor layer and the cloud layer. It means that instead of executing all processing at the cloud layer, the fog and edge layers can process and analyze agricultural data locally and close to the sensor layer (based on their ability) to reduce latency and cost [5], [7]. D. Cloud Layer At the same level of importance as edge and fog, cloud computing is a vital enabler for the growth of IoT agriculture applications. It offers on-demand computing resources and services (e.g., storage, networking, and processing) in a scalable way. The cloud layer handles the agriculture data received from the sensor layer or the fog layer to process, analyze and store them into the cloud. Cloud computing can process and analyze heavy data, that requires more complex operations (e.g., big data processing and predictive analysis like weather forecasting, fire warning, and soil droughting), which exceeds the fog computing capability [6]. Also, it could provide a large-scale secure platform and cheap data storage services for the IoT agriculture applications [5], [8]. E. Telecommunication Networks The traditional telecommunication network architecture consists of three layers [16]: the core layer, the metro layer, and the access network layer. The wide area network (WAN) is the key network infrastructure that provides interconnection between different regions and cities. The Internet protocol (IP) over wavelength division multiplexing (WDM) is widely implemented in the core network as it can provide high scalability, large capacity, and fast communication network transfer speeds. Based on the reference hierarchy in Fig. 1, every core network has a direct connection with a metro area network (MAN), which covers a metropolitan area. Metro Ethernet is the technology commonly used in the metro network. It offers connectivity between the core network and users located in the access network. The local area network (LAN) supports Internet access to numerous user premises. We adopted the passive optical networks (PONs) which considered as the leading networking in the LAN network. SECTION III. MILP Model In this section, a new approach is developed based on mathematical mixed-integer linear programming (MILP) optimization model to study the energy-efficiency of offloading IoT agriculture applications over an edge-fog-cloud architecture, considering the three telecom network layers: LAN equipped with an edge layer, MAN equipped with a fog layer and the WAN equipped with a cloud layer. In the following, we introduce the parameters and variables of our proposed architecture. The architecture consists of the IoT sensor, edge, fog, and cloud layers. Then, we provide the mathematical model to find the optimum distribution of IoT agriculture applications to serve the offloaded requests from the IoT sensor layer based on their energy consumption over an edge-fog-cloud architecture. A. IoT Sensor Layer The parameters and variables that represent the IoT sensor layer, are shown in Tables 2 and 3. TABLE 2 IoT Parameters TABLE 3 IoT Variables IoT sensor layer power consumption (IoT) is composed of: ( ∑ s∈i IoT (number) s IoT (power) ) +( ∑ s∈i GW (number) s IoT (power) ) (1) View Source Equation (1) calculates the total power consumption of the IoT sensor layer, including IoT sensors and gateway devices. B. Edge, Fog, and Cloud Layers The following parameters and variables (in Tables 4 and 5) represent the IoT agriculture applications that will be placed in the edge, fog, or cloud layers, as well as the resulted traffic and power consumption. TABLE 4 Cloud, Fog, and Edge Networking and Processing Parameters TABLE 5 Cloud, Fog and Edge Networking and Processing Variables The power consumption of cloud/fog/edge nodes consist of: Cloud layer power consumption (Cloud): PUE (cloud) ( ∑ s∈N MIPS iot i,s PPMIPS (cloud) + ∑ s∈N PPbits (cloud) TU s,d )∀s=c (2) View Source Power consumption of fog layer (Fog): PUE (fog) ( ∑ s∈N MIPS iot i,s PPMIPS (fog) + ∑ s∈N PPbits (fog) TU s,d )∀s=f (3) View Source Power consumption of edge layer (Edge): PUE (edge) ( ∑ s∈N MIPS iot i,s PPMIPS (edge) + ∑ s∈N PPbits (edge) TU s,d )∀s=e (4) View Source Equations (2, 3, and 4) calculate cloud, fog, and edge computing layers total power consumption, including processing, and networking devices, taking into consideration the power usage effectiveness (PUE) of cloud, fog, and edge layers, respectively. C. Communication Networks As described in Section II-E, a typical telecom network is considered including WAN, MAN, and LAN networks. The traffic traverse through these layers as well as the corresponding power consumption are represented by the parameters and variables described below. 1) Local Area Network (LAN) The parameters and variables that define the LAN network are shown in Tables 6 and 7. TABLE 6 LAN Network Parameters TABLE 7 LAN Network Variables Local area networks power consumption (LAN) consists of: Total power consumption of LAN network: PUE (network) ( ∑ s∈N ONU (number) s ONU (power) ) +( ∑ s∈N OLT (number) s OLT (power) ) (5) View Source Equation (5) calculates the total power consumption of the LAN network, including Optical Network Units (ONU) and Optical Line Terminals (OLTs) devices, taking into consideration the network PUE. 2) Metro Area Network (MAN) The parameters and variables introduced to define the MAN are shown in Tables 8 and 9. TABLE 8 MAN Parameters TABLE 9 MAN Variables The metro area network power consumption (MAN) consists of: PUE (network) (( MR (number) s MR (power) s ) +( MS (number) s MS (power) s ))∀s=N (6) View Source Equation (6) calculates the total power consumption of the MAN network, including router ports and switch devices, taking into consideration the network PUE. 3) Wide Area Network (WAN) The parameters and variables introduced to define WAN network are shown in Tables 10 and 11. TABLE 10 WAN Network Parameters TABLE 11 WAN Network Variables The wide area network ( WAN ) [17] power consumption consists of: PUE (network) ( ∑ d∈N r (power) r d + ∑ m∈N ∑ n∈ Nm m :n≠m ∑ s∈N ∑ d∈N:s≠d r s,d m,n t (power) + ∑ m∈N ∑ n∈ Nm m :n≠m E (power) F m,n A m,n + ∑ d∈N S (power) d ) (7) View Source Equation (7) calculates the total power consumption of the WAN network, including core router ports, transponders, amplifiers, and switch devices, taking into consideration the network PUE. The MILP model, considering the equations from (1-7), represented by the following: The objective: Minimize total power consumption: WAN+MAN+LAN+IoT+Cloud+Fog+Edge (8) View Source Expression (8) calculates the power consumption of our proposed architecture as the sum of the power consumption of the WAN network, the MAN network, the LAN network, IoT, cloud, fog, and edge. Subject to the following constraints: IoT offloading constraints: ∑ s,d∈N UI i,s,d = ∑ s,d∈N T iot i,s,d ∀i∈I (9) View Source Constraint (9) guarantees that all the IoT offloaded traffic is processed at a cloud, fog, or edge destination node. IoT application in edge/fog/cloud constraints: ∑ s∈N T iot i,s,d ≥ Ψ i,d ∀d∈N,i∈I ∑ s∈N T iot i,s,d ≤ω Ψ i,d ∀d∈N, i∈I (10) (11) View Source Constraints (10) and (11) make sure that the binary variable Ψ i,d =1 if processing node d∈N is powered on to place the IoT application i∈I , otherwise Ψ i,d =0 . Physical link-activated: L s,d m,n ≥ L s,d m,n ≤ r s,d m,n ∀s,d, m, n∈N r s,d m,n ∀s,d, m, n∈N (12) (13) View Source Constraints (12) and (13) ensure that the physical link m,n∈c is activated if there is a traffic flow between the nodes s,d∈c transmitting through the physical links m,n∈c. Edge, fog, and cloud processing requirements: MIPS iot i,d = Ψ i,d MIPS iot i,d ∀d∈N,i∈I MIPS iot d = ∑ i∈I MIPS iot i,d ∀d∈N (14) (15) View Source Constraints (14) gives the processing requirements of IoT application i∈I in a cloud, a fog, and an edge layer. Constraint (15) gives the total processing of a cloud, a fog, and an edge layer d∈N . Traffic demand on WAN network: TU s,d = ∑ i∈I T iot i,s,d ∀s,d∈c (16) View Source Constraint (16) calculates the demand between WAN nodes due to the IoT applications placed in the clouds. Flow conservation constraint: ∑ m∈N:m≠n L s,d m,n − ∑ n∈N:m≠n L s,d m,n = ⎧ ⎩ ⎨ L s,d − L s,d 0 i=s i=d otherwise ∀s, d∈N:s≠d (17) View Source Constraint (17) define the flow conservation of WAN network. It ensures that the total inbound / outbound traffic in all WAN nodes is identical; apart from the source/sink nodes. Physical link capacity: ∑ s∈N ∑ d∈N:i≠j L s,d m,n ≤WB F m,n ∀m, n∈N (18) View Source Constraints (18) gives the physical link capacity by ensuring that the traffic in a link does not exceed the maximum capacity of fibers. Total number of router ports in a WAN network node: r d ≥ ∑ s∈c TU s,d B ∀d∈c (19) View Source Constraint (19) gives the router ports count at every WAN node. Total number of IoT gateways: GW (number) s ≥ IoT (number) s GW (users) ∀s∈i (20) View Source Constraint (20) gives the number of used gateways in each farm. Total number of ONU terminals: ONU (number) s ≥ ∑ i∈i ∑ d∈N UI i,s,d ONU (bitrate) ∀s∈N (21) View Source Constraint (21) gives the number of used ONU terminals in each farm. Total number of OLT: OLT (number) s ≥ ∑ i∈I ∑ d∈N UI i,s,d OLT (bitrate) ∀s∈N (22) View Source Constraint (22) gives the number of used OLT in node s . Total number of MAN routers: MR (number) s ≥2 ∑ i∈i ∑ d∈(f∩c) UI i,s,d MR (bitrate) ∀s∈N (23) View Source Constraint (21) gives the number of used routers in each MAN network s . Total number of MAN switches: MS (number) s ≥ ∑ i∈i ∑ d∈(f∩c) UI i,s,d MS (bitrate) ∀s∈N (24) View Source Constraint (22) gives the number of used switches in each MAN network s . Total Traffic in communication network: T d = ∑ i∈i ∑ d∈N UI i,s,d ∀s∈N (25) View Source Constraint (23) gives the total traffic in each node s . 4) Carbon Emissions (CO2) of IoT-Edge-FOG-Cloud Layers Carbon emissions [18] can be defined as the carbon emission intensity per an energy consumption and the unit of carbon emission intensity is kgCO2e / kWh. The research found that using solar, wind or nuclear plants creates a low carbon footprint compared with fossil fuels [19]. However, there are multiple limitations to the usage of low carbon sources including but not limited to the cost of installing these clean plants. Thus, in this work, we assume that only the IoT sensor layer and edge layer are powered by low carbon sources (i.e., solar plants panels) to reduce the power consumption of the proposed architecture. In the following Tables 12 and 13, we define parameters and variables related to carbon emissions. TABLE 12 Emission Parameters TABLE 13 Emission Variables Total carbon emission (CO) is composed of: (WAN O)+(MAN O)+(LAN O)+(IoT S) +(Cloud O)+(Fog O)+(Edge S) (26) View Source Considering that IoT sensors, gateway, and edge processing layers are powered by solar energy sources. While others are powered by oil energy sources. SECTION IV. MILP Model Design In this section we explain the scenarios and the design of the model conducted in order to evaluate the proposed architecture. A. Scenarios As shown in Fig. 1, different scenarios can be implemented with this proposed architecture to show its effectiveness. In this work, the following scenarios are considered in a hierarchical order based on the edge, fog, and cloud ability. Edge/fog layers can be deployed in the proposed architecture according to the resources required by the agriculture tasks. Essentially, all tasks from heterogeneous IoT devices/sensors in the agriculture field, using different IoT wireless network technologies will be offloaded to the network gateways and then directed to edge/fog or cloud layer. Each layer has pros and cons. For example, processing the tasks within the edge layer will save the power and traffic cost of request transmission from/to the fog or cloud layer. However, handling all types of tasks within the edge layer is not possible, as it has limited capacity. Therefore, fog and cloud layers can be the choice for processing heavy tasks (e.g., resource-intensive applications). In our model, we assume that a scheduler in the gateway of the IoT layer checks if the edge node has available resources and can handle the request of IoT applications (e.g., CPU capability - the number of million instructions per second (MIPS)), the tasks will then pass to the edge layer to process them. In case of insufficient/unavailability of processing the tasks in the edge layer, the request will be transferred to the fog layer and check if there is enough capacity. Otherwise, the tasks will be forwarded to the cloud layer for processing, which supports resource-intensive applications. Also, we have assumed that the cloud has enough resources and capability to handle all kinds of tasks. B. Input Parameters of the Models In the MILP model, we have configured four layers in a smart agriculture system, which is composed of the IoT sensor layer, edge layer, fog layer, and cloud layer. The configuration of edge, fog, and cloud layers depend on the type of tasks (e.g., number of MIPS) requested by each IoT sensor/device at the IoT sensor layer. The model input parameters of different layers (IoT sensor, edge, fog, and cloud layers), in addition to networks and carbon emissions parameters, are shown in Tables 14, 15, 16, 17, and 18, respectively. TABLE 14 IoT Sensor Layer Input Parameters TABLE 15 Cloud, Fog, and Edge Input Parameters TABLE 16 LAN, MAN, WAN Network Input Parameters TABLE 17 Carbon Emission Inputs for Each Fuel Type [17], [22] In our model, we assume that there are 100,000 sensors distributed in each farm The sensors task requirements are divided into three types (sensing 60%, processing 30%, heavy processing 10%). The sensing processing task is usually limited to handling offloaded reading data sent by the sensors (e.g., temperature reading or send control commands for the irrigation system). The processing task is the requirement of light processing (e.g., soil analytics and event detection). The heavy processing task is the requisite of higher processing power and resources (e.g., weather prediction and analysis). SECTION V. Results and Discussion In this section, we discuss the proposed energy-efficient edge-fog-cloud architecture. In addition to its energy efficiency, we evaluate our model to find the consequence CO2 emission, and network traffic compared to the traditional cloud-based architecture. We have evaluated the proposed architecture and models using MILP optimizer based on the AT&T network topology, as shown in Fig. 2. To solve the MILP model, we use the CPLEX solver over a laptop with an Intel Core i7–7660U CPU, running at 2.50 GHz, with 16 GB RAM. FIGURE 2. AT&T WAN network topology. Show All As shown in Table 1, we have categorized all IoT wireless network technologies used in this work based on their data rate, range, number of devices, power consumption of both gateway/base-station, and sensors. This work has identified that the power consumption of different IoT wireless network technologies almost the same, as shown in Fig. 3. The Zigbee technology delivers connectivity with low power consumption compared to other technologies. However, using Zigbee in the urban area is not the best choice as it only covers 20 meters, thus, hundreds or thousands of gateways are required to cover a large area. FIGURE 3. Comparison of different IoT wireless network technologies based on their energy consumption. Show All Since we aim to use a technology that covers a large area with the least amount of energy consumption. Therefore, LoRa has been chosen as an IoT wireless communication technology between the IoT sensors and the gateway, that covers long-distance communication, with low power consumption, and considers one of the most suitable technology for IoT agriculture applications, as shown in Fig. 3. A. Energy Consumption Fig. 4 illustrates the power consumptions of different tasks in the proposed edge-fog-cloud architecture versus the traditional cloud-based architecture. Also, it shows the placement location of each task/application in edge-fog-cloud architecture, as well as the power consumption values of each task individually. FIGURE 4. The energy consumption of the proposed architecture vs. the traditional cloud-based architecture, considering the IoT LoRa technology. Show All The results showed that the sensing tasks are offloaded to the edge layer, as it has enough capacity (i.e., sensing requires 500 MIPS, and the edge layer has the capability to process up to 1800 MIPS). The normal processing tasks are offloaded to the fog respectively, as the fog layer has sufficient resources (i.e., 4000 MIPS) to process the tasks (i.e., 2000 MIPS). All remaining requests are offloaded to the cloud layer as there is no capacity in edge neither fog layers to accommodate heavy processing tasks. Fig. 5 shows the power consumption of our proposed architecture compared to the traditional cloud-based architecture, considering different IoT wireless technologies. Also, the figure displays power saving achieved by the proposed architecture. It is clearly shown that our proposed architecture outperforms the traditional cloud-based architecture by up to 36% of the total power consumption. However, the power savings have slightly ranged between 33.6% and 35.6% based on the different IoT wireless technologies. The Zigbee shows a higher power saving as it capable of offloading sensor data with lower power consumption. FIGURE 5. The energy saving of the proposed architecture vs. the traditional cloud-based architecture, using different IoT wireless technologies. Show All B. CO2 Emission Fig. 6 illustrates the total carbon emissions of the proposed edge-fog-cloud architecture versus the traditional cloud-based architecture, considering powering the IoT sensor layer and edge layer by a solar power source. FIGURE 6. The total carbon footprint emission of the proposed architecture vs. the traditional cloud-based architecture. Show All It shows that our proposed architecture can reduce up to 42% of CO2 emission, for real-time IoT applications in agriculture systems. The results also show a comparable carbon emission using different IoT wireless technologies. The power consumption of these technologies has been eliminated, as all IoT sensors and gateways are power by a solar plant, that emits very low carbon footprints (solar plants emit only 0.048 kgCO2/kWh). C. Network Traffic Fig. 7 shows the total traffic in each network tier in our proposed architecture versus the traditional cloud-based architecture. The results showed that our proposed architecture is capable to reduce the total traffic by 14% and 86% in MAN and WAN tiers, respectively, compared to a cloud-based approach. FIGURE 7. The network traffic of the proposed architecture vs. the traditional cloud-based architecture. Show All In the traditional cloud-based architecture, the process of sending/retrieving the data to/from the cloud in real-time requires high-capacity bandwidth, which may cause a burden on the three network tiers. Thus, employing edge and fog computing has allowed processing most requests locally in edge or fog layers, which significantly decreases the flow of data traverse to the cloud and reduces network traffic, as shown in Fig. 7. SECTION VI. Energy Efficient Agriculture IoT Edge/Fog/Cloud Architecture Heuristic The problem over energy-efficient offloading of IoT applications in edge-fog-cloud architecture for smart agriculture environment is a non-deterministic polynomial (NP)-hard problem. For instance, if i is IoT applications count and n is the count of locations in edge-fog-cloud architecture, then we will have ( ∑ z=1 n n! (n−z)! ) combinations of possible applications locations to find the optimum locations that result in optimal power consumption. Thus, applying MILP to large-size problems is not feasible. Therefore, heuristic provides a simple and fast real-time implementation. Also, the optimal solution provided by the heuristic can provide validation to results obtained from MILP. To provide that, a heuristic algorithm was developed, referred to as energy-efficient agriculture IoT applications distribution heuristic over the edge-fog-cloud architecture (EEAIOT-EFC). In the EEAIOT-EFC heuristic, IoT application i is checked based on their total MIPS processing requirements. Firstly, the algorithm tries to place and run the application on the edge layer. If there is not enough MIPS capacity at the edge layer, then, agriculture IoT application is placed in the fog layer, if it has enough capacity. In case of unavailability resources in both edge and fog layers, the cloud layer will host the IoT application, as it has enough processing capability to handle all types IoT applications. After distributing all IoT applications, the power consumption of EEAIOT-EFC is determined. The heuristic flowchart process is shown in Fig. 8. FIGURE 8. Flowchart of EEAIOT-EFC heuristic. Show All The heuristic is assessed using a PC with an Intel Core i7–7660U CPU, running at 2.50 GHz, with 16 GB RAM. Similar to MILP, the AT&T network is considered a WAN network example. The heuristic took 5 seconds to evaluate the EEAIOT-EFC, and the MILP and EEAIOT-EFC show a comparable result, as shown in Fig. 9. The gaps between them are limited to 0.7% and 4.7% of the total power consumption under the proposed and the traditional cloud-based, respectively. FIGURE 9. Difference between the MILP model vs. EEAIOT-EFC heuristic. Show All SECTION VII. Conclusion and Future Works In this paper, the concept of an edge-fog-cloud architecture is introduced in the smart agriculture system, which solved existing real-time processing issues in terms of reducing energy consumption, CO2 emission, and network traffic, compared to the traditional cloud-based architecture. The proposed architecture employed the edge and fog layers, which are placed close to the agriculture fields to collect heterogeneous data from various kinds of IoT agriculture sensors and process them at these layers. Although the proposed architecture was significantly reduced the computational load and the amount of transmitted data to and from the cloud due to the use of edge and fog layers, however, the cloud layer is inevitably used to process the heavy and complex data/task requested by IoT agriculture devices/sensors. Most of the processing tasks are completed on the edge and fog layers, while few tasks are offloaded to the cloud layer for processing. In the paper, different metrics have been taken into consideration, including energy consumption, CO2 emission, and network traffic to study the performance and the outcomes of the proposed architecture. Using mathematical modeling, the proposed architecture is compared with the traditional cloud-based architecture. The model results showed that our proposed architecture can reduce the overall power consumption, carbon footprints, and network traffic by up to 43%, 36%, 86%, respectively. Moreover, we developed energy-efficient agriculture IoT applications distribution heuristic over the edge-fog-cloud architecture (EEAIOT-EFC) algorithm, which showed comparable results to the MILP model. Though this proposed solution is based on the idea of smart agriculture, it also can be suitable for other IoT applications and sectors, such as e-healthcare, smart city, and smart home. In the future, we intend to extend the proposed approach in a distributed real agricultural environment, considering machine-learning and decision-making algorithms to further understand the capability of the proposed work. ACKNOWLEDGMENT The authors would like to acknowledge the Deanship of Scientific Research, Taibah University, Medina, Saudi Arabia, for providing research resources and equipment. This work was supported by the Deanship of Scientific Research, Prince Sattam Bin Abdulaziz University, Al-Kharj, Saudi Arabia. Authors Figures References Citations Keywords Metrics More Like This IoT Farm: A Robust Methodology Design to Support Smart Agricultural System Using Internet of Things with Intelligent Sensors Association 2023 7th International Conference on Electronics, Communication and Aerospace Technology (ICECA) Published: 2023 Smart Agriculture Wireless Sensor Routing Protocol and Node Location Algorithm Based on Internet of Things Technology IEEE Sensors Journal Published: 2021 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."

Paper 9:
- APA Citation: Mahmud, K., Dey, S., Wickramasuriya, J., & Ghafoor, A. (2023). Edge Computing for Resilient and Fault-Tolerant Automated Irrigation Systems. In Proceedings of the 2023 IEEE International Conference on Automation, Robotics and Applications (ICARA) (pp. 1-6). IEEE.
  Main Objective: To investigate the use of edge computing to enhance resilience and fault tolerance in automated irrigation systems, enabling localized decision-making and control.
  Study Location: Unspecified
  Data Sources: Literature review, case studies
  Technologies Used: Edge computing, Raspberry Pi, NVIDIA Jetson, Intel NUC
  Key Findings: Edge computing reduces reliance on cloud connectivity, improves response times, increases system robustness, enables localized control, and ensures reliable irrigation management in areas with poor network connectivity.
  Extract 1: "Edge computing offers several advantages over cloud computing for real-time irrigation management. First, edge devices can process data locally, reducing the latency associated with sending data to the cloud and back. This is critical for applications where timely decisions are needed, such as adjusting irrigation schedules based on real-time sensor data."
  Extract 2: "Second, edge devices can be deployed closer to the field, reducing the risk of data loss due to network outages. This is important for ensuring reliable irrigation management, even in areas with poor or intermittent network connectivity."
  Limitations: The paper focuses primarily on the benefits of edge computing in automated irrigation systems but does not delve into potential challenges or limitations, such as the need for additional hardware, maintenance, and security considerations.
  Relevance Evaluation: The paper directly addresses the point of focus on leveraging edge computing for localized decision-making in automated irrigation systems. It provides valuable insights into the benefits of reducing cloud dependency and improving response times, which are crucial for ensuring reliable and efficient irrigation management. The paper contributes to the larger context of the literature review by highlighting the importance of resilience and fault tolerance in automated irrigation systems.
  Relevance Score: 0.9
  Inline Citation: (Mahmud et al., 2023)
  Explanation: This paper explores the integration of edge computing in automated irrigation systems to enhance resilience and fault tolerance. By deploying edge devices like Raspberry Pi, NVIDIA Jetson, or Intel NUC, data processing and decision-making can be performed locally, reducing reliance on cloud connectivity and improving response times. This decentralized approach increases the system's robustness and enables localized control, even in scenarios with intermittent or unreliable network connectivity.

 Full Text: >

Paper 10:
- APA Citation: N/A
  Main Objective: To provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems.
  Study Location: Unspecified
  Data Sources: Survey data, Interviews, Case studies, Literature review
  Technologies Used: IoT (Internet of Things), machine learning
  Key Findings: None
  Extract 1: "Addressing the global food challenge: The review aims to explore how automated, real-time irrigation management systems can contribute to the efficient use of water resources and enhance agricultural productivity to meet the growing demand for food."
  Extract 2: "Highlighting the role of interoperability and standardization: The review seeks to emphasize the importance of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline. It aims to identify existing and emerging standards and their applicability to real-time irrigation management systems."
  Limitations: None
  Relevance Evaluation: The paper is relevant to the point I am making in my literature review: examining automation across the entire pipeline, as it provides an in-depth analysis of the integration of automated irrigation management systems with IoT and machine learning technologies. It also highlights the importance of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline, which aligns with my research focus on the role of interoperability and standardization in facilitating seamless communication and compatibility.
  Relevance Score: 0.9
  Inline Citation: N/A
  Explanation: The provided article explores how automated, real-time irrigation management systems can contribute to the efficient use of water resources and enhance agricultural productivity to meet the growing demand for food. It also evaluates the current state of end-to-end automated irrigation management systems that integrate IoT (Internet of Things) and machine learning technologies, identifying gaps and proposing solutions for seamless integration across the entire automated irrigation management system to achieve fully autonomous, scalable irrigation management.

 Full Text: >
"Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Keywords 1. Introduction 2. Study area and materials 3. Methodology 4. Results and discussion 5. Conclusion Declaration of Competing Interest Acknowledgment Appendix A. Supplementary material References Show full outline Cited by (22) Figures (8) Show 2 more figures Tables (5) Table 1 Table 2 Table 3 Table 4 Table 5 Extras (1) Supplementary Data 1 International Journal of Applied Earth Observation and Geoinformation Volume 105, 25 December 2021, 102607 Assessing the effects of irrigated agricultural expansions on Lake Urmia using multi-decadal Landsat imagery and a sample migration technique within Google Earth Engine Author links open overlay panel Amin Naboureh a b, Ainong Li a, Hamid Ebrahimy c, Jinhu Bian a, Mohsen Azadbakht c, Meisam Amani d, Guangbin Lei a, Xi Nan a Show more Share Cite https://doi.org/10.1016/j.jag.2021.102607 Get rights and content Under a Creative Commons license open access Highlights • We assessed the impact of irrigation expansions on water resources in Lake Urmia. • We adopted a reference sample migration technique for historical LC monitoring. • We presented an automatic sample reference extraction technique for water class. • We found that excessive irrigation expansions can cause environmental issues. Abstract Irrigated agricultural expansion is one of the main reasons for water scarcity in the Lake Urmia basin. Although previous studies have analyzed the impact of cropland expansion on the Lake Urmia Shrinkage, there is a lack of comprehensive annual assessment of historical irrigation expansion in the Lake Urmia basin and its impact on water resources of this region. In this study, we developed an automatic and efficient workflow using Landsat and Gravity Recovery and Climate Experiment (GRACE) data, GRACE Follow-On (GRACE-FO) data, and a sample migration technique within the Google Earth Engine cloud computing platform to comprehensively investigate the impact of irrigated agricultural expansion on the shrinkage of Lake Urmia, as one of the most severe environmental crisis in the world. Additionally, using the global surface water data, we proposed a fully automatic procedure to obtain reference samples from water bodies. The Lake Urmia basin was first classified into the water, irrigated, and Non-Water/Irrigated classes using the random forest algorithm. The average overall accuracy of the produced annual land cover maps during 1987–2020 was 92.2%, representing the great potential of the developed method for land cover mapping. We found that the irrigated lands expanded by nearly 890 km2 during the study period. Coincident with this change, although the area of water bodies in Lake Urmia partially recovered after 2015 (reached from 1,050 km2 in 2015 to 3,370 km2 in 2020), it is currently far beyond its original condition (i.e., ∼5,400 km2, average record during 1987–2000). Moreover, the information of the Terrestrial Water Storage (TWS) from the GRACE and GRACE-FO data between 2003 and 2020 showed a dramatic decrease in TWS level (∼−11.5 cm). The findings of this research will assist the local stakeholders and authorities to better understanding the environmental costs of irrigation expansion in the Lake Urmia basin. Previous article in issue Next article in issue Keywords Land coverIrrigation expansionsLake UrmiaGoogle Earth EngineSample migrationLandsat 1. Introduction Water and food scarcity, which are interlinked with each other, have been extensively exacerbated by global warming and world population growth during past decades (Rosa et al., 2020). It also has been reported that rain-fed cropping systems could not meet agricultural commodities’ needs because the demand for food has increased in recent decades (Ayala et al., 2016). As such, expansion of irrigated cropping systems through exploiting surface water and groundwater has been adopted to respond to this issue in many areas of the world (Ayala et al., 2016, de Moraes et al., 2017). However, irrigated agricultural extensions can increase the pressure on water resources, particularly in arid and semi-arid areas, including the Lake Urmia basin in Iran. Lake Urmia, as one of the United Nations Educational, Scientific and Cultural Organization (UNESCO) biosphere reserves, has experienced an environmental tragedy in recent years (Khazaei et al., 2019). This lake has become an endangered ecosystem and experienced a dramatic decline in the area and water level due to both climatic change and anthropogenic interventions (Panahi et al., 2020, Chaudhari et al., 2018, Jaberizadeh, H., 2020, Wurtsbaugh et al., 2017). Among many consequences of the Lake Urmia shrinkage, the appearance of salt dust storms that threatens the lives of humans and species (Feizizadeh et al., 2021) is a serious threat that can directly damage agriculture, livestock, and cause significant loss of property and life. Salt dust storms can also bring indirect costs. For instance, it can lead to a loss of business, and increase or cause health issues. An increase in water salinization and a decrease in the quality of the natural environment are other negative side effects of intensive dust storms in this region. So far, several studies have been devoted to examine the roles of human activities and climate change on the shrinkage of Lake Urmia. For example, multiple studies assessed the role of climate variability on the shrinkage of Lake Urmia (Alborzi et al., 2018, Fathian et al., 2015), while some others compared the similarity of this disaster with other cases around the world (Destouni et al., 2013, Aghakouchak et al., 2015). The environmental impacts of Lake Urmia shrinkage (Feizizadeh et al., 2021, Garajeh et al., 2021), over extraction of groundwater (Amiri et al., 2016), and infrastructures developments were also broadly discussed in different studies (Sabbagh-Yazdi et al., 2020). Although there is no exact consensus on reporting the most influential driver of this issue, it is widely reported that the role of human intervention was more significant than climate change (Saemian et al., 2020, Sabbagh-Yazdi et al., 2020, Khazaei et al., 2019, Chaudhari et al., 2018). As an example of human intervention, the substantial impact of irrigated area expansion on the shrinkage of the lake has been reported (Balkanlou et al., 2020, Shirmohammadi et al., 2020). However, previous studies rather did not extract annual changes in irrigated agricultural and water areas and/or failed to extract small-scale changes. Moreover, previous studies mostly focused on cropland expansion (both rain-fed and irrigation), hence leaving a gap in the comprehensive analysis of the impact of irrigation expansion on the Lake Urmia tragedy. For example, Khazaei et al. (2019) and Saemian et al. (2020) assessed the role of agricultural area expansion on the water shrinkage of the basin using the yearly LC products of MODerate Resolution Imaging Spectrometer (MODIS) satellite. However, due to the coarse resolution of the MODIS products (250 m or 500 m), the estimated locations of small irrigated lands are fairly uncertain, and it is hard to extract changes at fine-scale from their results. In another study, Shirmohammadi et al. (2020) analyzed the impact of irrigation expansion on water scarcity in the Mordagh Chay basin, one of the Lake Urmia’s sub-basins between 1993 and 2015. Since the Mordagh Chay basin covers relatively a small area of Lake Urmia basin, it may not be accurate to extend the results of this study to the entire basin. In this regard, LC mapping by classification of the freely available Landsat collection (Landsat-5, 7, and 8), which provide long time-series satellite images from 1985 to present, can be a viable alternative to thoroughly investigate agricultural changes at fine scale around the world. When the objective is LC change analysis, it is important to have reliable reference data to train and validate machine learning algorithms (Stehman and Foody, 2019, Naboureh et al., 2020a). However, sufficient and reliable reference sample data are not always available especially in long-term LC change analyses (Chen et al., 2019, Naboureh et al., 2021). In this regard, the reference sample migration technique has been proposed as an effective solution to address this obstacle (Huang et al., 2020). In this manner, sample migration methods, which mostly try to transfer reference sample data from a specific reference time to another desired time, have been employed for LC mapping in different studies. For example, an automatic approach for LC mapping in a rapidly urbanizing state was introduced based on migrating data from the GlobeLand30 data (Lin et al., 2019). Moreover, a sample dataset (30-m resolution) collected in 2015 was used to produce a global LC map at 10-m resolution in 2017 (Chen et al., 2019). However, the migration of reference samples in LC mapping, in particular for long-term LC change monitoring, is in its infancy yet and needs more investigation from scholars. Timely and accurate information on irrigated agricultural areas and their spatial changes can help decision-makers at various disciplines, such as food security management, hydrologic modeling, and sustainable development (Deines et al., 2017). As a result, several studies have been devoted to characterize and investigate the impacts of the spatiotemporal changes of irrigated areas in different parts of the world (Demarez et al., 2019, Peña-Arancibia et al., 2014). In the case of Lake Urmia, although a few studies have so far examined the effects of agricultural activities on the shrinkage of the Lake Urmia basin, the impact of irrigated agricultural expansion on surface and groundwater levels of this Lake has not been well documented and presented. To this end, historical consistent field data along with powerful machine learning and cloud computing algorithms/platforms are required. Therefore, we proposed an efficient and robust workflow within the GEE platform to extract annual surface water bodies and irrigated agricultural areas and their changes in the Lake Urmia basin from 1987 to 2020 through an efficient sample migration framework. Moreover, we investigated the impacts of the irrigated agricultural expansion on TWS changes derived from the GRACE and GRACE-FO data. We also presented an automatic sample reference extraction technique for water class. 2. Study area and materials 2.1. Study area The Lake basin (Fig. 1), which covers an area of nearly 54,000 km2, is one of the main hydrological basins located in the North-West of Iran. As the second-largest inland salt lake worldwide, Lake Urmia receives water from 29 rivers and 39 floodways. The basin is home to more than 5 million people, where the economy of most people is largely dependent on agricultural production. The average water discharge into Lake Urmia declined from 2112 million cubic meters to 750 million cubic meters between 1960 and 2010, and the water level significantly decreased from 1278 m in 1995 to 1270 m in 2014 (Khazaei et al., 2019). Download : Download high-res image (276KB) Download : Download full-size image Fig. 1. The location of the study area. a) The elevation map of the Lake Urmia basin. b) Location of the Lake Urmia Basin in North-West of Iran. c) Changes in Lake water level elevation during 1987–2019. 2.2. Data collection and image pre-processing For the period of 1987 to 2020, all available Landsat (TM/ETM+/OLI) surface reflectance products between June 26th and October 1st (dry season), where most of rain-fed agricultural areas were already harvested and shared similar spectral reflectance to barren areas, were acquired to extract irrigated areas. Since the available Landsat-5 could not cover the whole study area in 2003, 2005, and 2008 (Fig. 2.a), on the one hand, and Landsat-7 from June 2003 to December 2011 were reported unsuitable for extracting water bodies due to scan line corrector failure issue (Tulbure and Broich, 2013), on the other hand, we discarded the mentioned years from our analyses. Overall, 1,733 Landsat images, including 1,112 Landsat-5, 104 Landsat-7, and 517 Landsat-8 images were processed to analyze the annual changes in three classes of water, irrigated, and Non-Water/Irrigated (NWI) from 1987 to 2020 (Fig. 2.c). The FMASK algorithm, which is available in the GEE platform, was applied to each image to remove snow, clouds, and cloud-shadows (Gorelick et al., 2017, Bian et al., 2020). Then, for each year, a stacked layer of the acquired Landsat images for the given year was generated. Finally, the 50th percentile (i.e., median) of the Landsat bands were calculated to create the mosaic images for LC classification. Download : Download high-res image (294KB) Download : Download full-size image Fig. 2. The Landsat image collection for study. a) Distribution of Landsat-5 images for the years 2003, 2005, and 2008. b) Number of the processed Landsat 5, 7, and 8 images (from June 26th and October 1st during 1987–2020). C) Path/raw coverage of the study area. 3. Methodology The proposed method has four main steps, which are illustrated in Fig. 3 and are briefly described below. More details of each step are also provided in the following subsections. Download : Download high-res image (266KB) Download : Download full-size image Fig. 3. Overall workflow of the employed methodology in this study. (1) Generating input features (i.e., cloud-free Landsat stacks, spectral indices, and topographic data) for annual LC classifications. (2) Producing reference sample datasets via fieldwork for the irrigated class, fieldwork and visual interpretation of very high-resolution images for the NWI class, and an automatic procedure for the water class. This step also contains extracting robust samples during two epochs of 1987–2008 and 2009–2020 based on a simple reference migration technique. (3) Implementing the Random Forest (RF) classifier for generating LC maps and validating the produced LC maps based on three well-known accuracy evaluation metrics. (4) Analyzing the TWS condition in the study area using the GRACE and GRACE-FO datasets. 3.1. Input features In this study, along with main spectral bands of Landsat, five spectral indices (Table 1) of the Normalized Difference Vegetation Index (NDVI), Enhanced Vegetation Index (EVI), Normalized Difference Water Index (NDWI), Modified Normalized Difference Water Index (MNDWI), and Soil-Adjusted Vegetation Index (SAVI) were also generated from the cloud-free Landsat stacks (see Section 2.2) to be used in the classification procedure. Moreover, we employed the topographic products of the elevation, aspect, and slope, which were generated using the Shuttle Radar Topography Mission data. Overall, we used six Landsat bands (Blue, Green, Red, Near-infrared, Short-wave infrared 1, and Short-wave infrared 2), five spectral indices, and three topographic products for LC classification of each year. Table 1. List of produced spectral indices (SWIR = short-wave infrared and NIR = near infrared). Index Formula Reference NDVI (NIR – Red)/(NIR + Red) (Rouse et al., 1974) EVI 2.5 × ((NIR-RED)/(NIR + 6 × Red-7.5 × Blue + 1)) (Carlson and Ripley, 1997) NDWI (Green – NIR)/(Green + NIR) (Mcfeeters, 1996) MNDWI (Green – SWIR1)/(Green + SWIR1) (Xu, 2006) SAVI ((NIR – Red)/(NIR + Red + 1.5)) × (1.5) (Huete, 1988) 3.2. Producing reference samples In the present study, three different procedures were used to generate high-quality reference sample data. For the water class, a fully Automatic Water Sample Generation (AWSG) method was developed using the yearly water maps provided by the Joint Research Center (JRC) (Pekel et al., 2016). Within the proposed method, a pixel had to meet two criteria to be included in the samples of the water class. First, it should be classified as water in all the annual JRC LC products of the examined epoch (1987–2008 or 2009–2020). Second, based on the suggestion of (Wang et al., 2020), we considered three spectral indices (i.e., MNDWI, NDVI, and EVI) for achieving better results. Accordingly, a given candidate pixel should also meet the following condition. (1) ((MNDWI > NDVI or MNDWI > EVI) and EVI less than 0.1) After these two steps, the obtained samples were visually double-checked to remove possible errors. The code for AWSG is available in the Supplementary data (part 1). Since it is very difficult to precisely distinguish irrigated areas from natural vegetated regions using the visual interpretation method, reference sample data for this class was collected by fieldwork during summer 2020. Moreover, sample data for the NWI class were collected using both fieldwork (summer 2020) and visual interpretation of very high spatial resolution satellite images. 3.2.1. Reference sample migration A sample migration workflow inspired by Huang et al. (2020) was designed to generate annual reference sample data of irrigated and NWI classes for previous years (2019–1987). To this end, first, the spectral information of candidate sample data (Spectral Angle Distance (SAD) and Euclidean Distance (ED)) from different spectral bands in the given reference year (e.g., 2020) and target years (e.g., 2019) were extracted from the generated final cloud-free mosaic images. Then, spectral differences of candidate sample data in the reference year and target year were calculated and those data that showed small spectral differences (i.e., less than a predefined threshold) were marked as unchanged samples. The predefined threshold value of each class was obtained based on a trial-and-error procedure. Furthermore, only spectrally unchanged sample data during 1987–2008 and 2009–2020 were extracted for further analysis. Finally, after a visual interpretation by raw Landsat images of the target year, spectrally unchanged sample data in two classes (irrigated and NWI) were identified in two separate sample datasets in epoch 1987–2008 (dataset-1) and 2009–2020 (dataset-2) (Table 2). Consequently, dataset-1 and dataset-2 were used to generate annual LC maps for the periods of 1987–2008 and 2009–2020, respectively. Table 2. The number of reference samples for different LC classes in different time periods Empty Cell Water Irrigated NWI Dataset-1 (1987–2008) 400 581 750 Dataset-2 (2009–2020) 250 581 750 Based on a detailed visual interpretation of very high-resolution satellite images and local knowledge, we selected 80 unchanged reference samples and 20 changed samples of irrigated class during the 2015–2020 period to obtain the optimal threshold value for spectral similarity checking as well as evaluating the efficiency of the sample reference technique. Accordingly, to maintain a fair analysis, three experiments were conducted for the years 2017, 2016, and 2015. As randomly splitting reference samples can lead to a low bias performance assessment of a classifier, each reference dataset was randomly divided into two equal groups (50–50%) of independent training and test samples. The training data were used for training the RF classifier and the test data were used for assessing the accuracy of the produced LC maps. 3.3. LC classification and accuracy assessment The training reference samples and the generated features were ingested into a RF classifier to produce the LC maps. RF was selected in this study due to its high performance in different LC mapping tasks (Rodriguez-Galiano et al., 2012). RF, as an ensemble of multiple independent individual decision trees, is an enhanced form of the bagging method (Breiman, 1996). It resamples the input datasets until the model reaches a stable situation which also declines the over-fitting risk. Obtaining the high classification accuracy using an RF classifier depends on optimization of two parameters, namely the number of variables (input features) for splitting at each tree node (mtry) and the number of produced trees (ntree) (Rodriguez-Galiano et al., 2012). Accordingly, after a trial-and-error procedure, mtry and ntree were set to 4 and 500, respectively. The test samples were utilized for the statistical accuracy assessment of the LC maps. To this end, the three well-known accuracy evaluation metrics, extracted from the confusion matrix (Foody, 2002), were employed. These metrics were the Overall Accuracy (OA), User Accuracy (UA), and Producer Accuracy (PA). The code for applying the proposed classification scheme is available in the Supplementary data (part 2). 3.4. TWS analysis In this study, the 5° GRACE Tellus monthly data was used to calculate annual TWS between 2003 and 2016. Since the GRACE Tellus data is provided by three different centers, namely Geo Forschungs Zentrum Potsdam (GFZ), U. Texas/Center for Space Research (CSR), and NASA Jet Propulsion Laboratory (JPL), a mean value of all three datasets was calculated following the recommendations in Forootan et al. (2017). Additionally, the GRACE-FO data from the CSR and JPL centers were used to estimate annual TWS for 2019 and 2020. It should be noted that since the GRACE-FO data are available for the winter and spring seasons of 2017 and 2018 (not the whole year), we discarded 2017 and 2018 from our analyses. Then, the annually averaged TWS data for 2003–2020 were used to explore the relationship among the changes of surface water, irrigated areas, and TWS data in the Lake Urmia basin. 4. Results and discussion 4.1. Reference sample generation The AWSG method was proposed to automatically generate water samples in this study. Within the AWSG method, a total of 400 samples for each year between 1987 and 2008 and 250 samples for each year between 2009 and 2020 were acquired. Since the presented methodology relies on the freely and publicly available JRC data and the GEE platform, the high cost and difficulty of traditional reference sample collection approaches for water class are obviated by AWSG. Another advantage of the proposed method is that the AWSG method not only can generate samples of water class for each year from 1985 to the present but also is able to produce stable samples of water class since 1985. On the other hand, after analyzing the spectral differences (SAD and ED) of the candidate samples and visual interpretation of raw Landsat images, we generated 581 and 750 samples for the irrigated and NWI classes, respectively, as unchanged samples during 1987–2020. We also picked 100 samples that are labeled as irrigated in 2020 and migrated them to the years 2017, 2016, and 2015 to thoroughly evaluate the efficiency of the adopted sample migration technique. The obtained high accuracies (Table 3) over three experiments revealed that the designed sample migration technique is a robust approach in dealing with the shortage of high-quality reference samples in LC mapping. The visual assessment illustrated that less than 5% of the candidate samples (5 samples in 2017, 3 samples in 2016, and 4 samples in 2015) were removed due to spectral differences between reference (i.e., 2020) and target year (i.e., 2017,2016, and 2015) while those samples did not experience LC changes. In general, the success of the proposed reference sample migration methodology was mostly attributed to the combination of spectral differences and visual interoperation, as their vital importance in sample migration had been reported (Ghorbanian et al., 2020). Overall, integration of the proposed sample migration methodology and AWSG can be considered as a robust practice to deal with the shortage of high-quality reference sample in long-term LC change analysis. Table 3. Accuracy evaluation of the adopted sample migration techniques for the irrigated class. Experiment 1 (2017) Experiment 2 (2016) Experiment 3 (2015) Empty Cell Stable changed Empty Cell Stable Changed Empty Cell Stable Changed Stable 75 5 Stable 77 3 Stable 76 4 Changed 0 20 Changed 0 20 Changed 0 20 OA = 95% OA = 97% OA = 96% 4.2. Land cover classification results and analysis To comprehensively evaluate the outcomes, the accuracies of the generated LC maps using the migrated reference samples were initially assessed using a visual interpretation with the available very high-resolution satellite images in Google Earth. Visually, it was observed that the final LC maps were noise-free and provide satisfactory depictions of all three classes. As demonstrated in Fig. 4, the proposed method was not only capable of precisely extracting water bodies but also properly discriminated the irrigated and NWI classes from each other. Download : Download high-res image (299KB) Download : Download full-size image Fig. 4. Visual assessment of the generated LC maps. a) An example of generated map along with satellite image for 2020. b) Three zoomed areas of the generated LC maps and corresponding satellite images. Regarding spatial changes from 1987 to 2020, most shrinkage occurred in the south part of the lake while the north part had the largest share of the stable surface water bodies (Fig. 5). As the 16-km Shahid Kalanatri causeway divides these two parts (Fig. 5-D), it was reported that the construction of this causeway in the early 1990s disrupted water circulation between the north part (lower salinity) and the south part (higher salinity) of the lake that increased the salinity and evaporation in the south part (Sabbagh-Yazdi et al., 2020). We also found that several dams have been constructed in the basin over the study period (the year of the construction for the major dams is presented in Fig. 5) where irrigated areas mostly expanded around these dams. Download : Download high-res image (300KB) Download : Download full-size image Fig. 5. Spatial distribution of changes in water and irrigated areas between 1978 and 2020. Moreover, three statistical accuracy metrics (i.e., OA, UA, and PA) were calculated for all the produced LC maps. Over the examined period, OA values of the LC maps varied between 90.1% and 94.2%, achieving an average OA of 92.2 % for all generated LC maps (Table 4). Regarding individual LC classes, the water class showed the highest average PA and UA. This can be explained twofold: the spectral response of the water class is more distinguishable than the other two LC classes, and the water spectral index (i.e. NDWI) has a high ability in extracting water class (Mcfeeters, 1996, Naboureh et al., 2020b). In general, all the assessed accuracy metrics of the classified LC maps were reasonably good considering the long-term change analysis performed using Landsat imagery (Zhu, 2017, Zhu and Woodcock, 2014). Table 4. Average values of user accuracy and producer accuracy of all generated maps during 1987–2020. Metrics Water Irrigated NWI User accuracy (%) 99.8 91.2 90.6 Producer accuracy (%) 99.7 85.2 94.5 4.3. Change in irrigated and water areas In this part, we assessed the changes in the areas of water and irrigated lands. Overall, as shown in Fig. 6 (a), the area of the irrigated class experienced an upward trend reaching 8,300 km2 in 2020 from 7,410 km2 in 1987. By further investigation, it was observed that the irrigated class slightly expanded until 2009 and, then, there was a sharp rise in 2010 (∼700 km2 increase), where the area reached 8,210 km2. Finally, it peaked at 8,300 km2 in 2020 after witnessing some fluctuations during 2010–2020. In contrast, there was a dramatic decrease in the area of water class, where the total water areas dropped from 5,390 km2 to 3,370 km2 during the period of 1987–2020. Download : Download high-res image (550KB) Download : Download full-size image Fig. 6. Irrigated and water land area change in the Lake Urmia basin. A) Annual changes in areas of water and irrigated lands between 1987 and 2020. B) Spatiotemporal variations of water and irrigated classes during 1987–2020. After a decade of fluctuations in the area of water class, the highest coverage of water area was recorded in 1998 (5,600 km2) covering approximately 11% of the whole basin (Fig. 6 (b)). Then, the lake started to substantially shrink, where in 2014 the area of the water class was around 1,050 km2 (∼2% of the whole basin). Despite a moderate expansion in the area of the water class after 2015 and reaching 3,370 km2 in 2020, Lake Urmia still needs a rise of nearly 2,000 km2 to return to its primary state in 1987 (5,400 km2). The moderate recovery of the lake after 2015 can be explained as the outcome of the Lake Urmia Restoration Program (LURP), which was established by the Iran government to revive the lake in 2013 based on a 10-year program (Saemian et al., 2020), and a substantial increase in precipitation in this area (Ghale et al., 2019). 4.4. Changes in TWS level By analysing the mean values of TWS from the three centers during the 2003–2016 period, it was observed that there was a remarkable drop in the TWS level in the study area (Table 5). The TWS level experienced an upward trend and reached from +2.2 cm to +5.1 cm between 2003 and 2004. Furthermore, there was a downward trend during the period of 2004 to 2009 (drop to −7 cm) which was followed by a sudden increase (with an increase of +1.5 cm, reached to −5.5 cm) in the amount of TWS in 2010. However, from 2010 to 2016, the level of TWS considerably declined and reached −16.4 cm at the end of the period. The lowest point of TWS was −17.5 cm in 2014, while the highest point was 5.1 cm in 2015. Finally, as shown in Table 5, the mean values of TWS experienced substantial growth for the years 2019 (−8.4) and 2020 (−9.3). Table 5. Mean annual values of TWS in the Lake Urmia basin between 2003 and 2016. Year 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2019 2020 Mean +2.2 +5.1 +4.7 +2.7 +0.6 −6.0 −7.0 −5.5 −10.6 −11.5 −11.2 −17.5 −17.4 −16.4 −8.4 −9.3 4.5. Investigating driving factors on Lake Urmia shrinkage It is generally accepted that the warming climate can exacerbate water scarcity (Rosa et al., 2020). In the case of Lake Urmia, Chaudhari et al. (2018) reported weak correlations on annual Lake water level with temperature (R2 = −0.36) and precipitation (R2 = 0.15) from 1980 to 2010. Khazaei et al. (2019) also argued that climate change cannot properly explain the Lake Urmia crisis and the impacts of human activities are more dominant. Moreover, the two neighbor lakes of this lake, namely Lake Van and Lake Sevan, with less than 200 km distance and almost similar size and climate conditions, have witnessed stabilized situations during the last decades (Fig. 7). Taravat et al., 2016, Sabbagh-Yazdi et al., 2020 reported only about 30 and 35 km2 reduction in surface water areas between 1975 and 2015 for the Lake Sevan and Lake Van, respectively. All these imply that the impact of anthropogenic activities on the Lake Urmia crisis is likely higher than the impact of climate change and variability. Download : Download high-res image (331KB) Download : Download full-size image Fig. 7. Satellite view and location of Lake Urmia, Lake Van, and Lake Sevan in 1987, 1997, and 2014. To investigate the impact of irrigated expansions on the Lake Urmia crisis, as an example on human activities, we analyzed the changes in irrigated lands, water areas, and TWS values in the basin. We also used Lake water level information obtained from the Iranian Water Resources Management (2019) during 1987–2019 where there was an over 5 m drop in water level of the lake (Fig. 1 (c)). It was observed that irrigated expansions negatively affected the surface and underground water levels in the Lake Urmia basin (Fig. 8). The expansion in the irrigated area and a decreasing trend in water area showed a moderate relationship (R2 = 0.52) during 1987–2020. Meanwhile, water level with R2 = 0.49 (during 1987–2019) and TWS with R2 = 0.44 (during 2003–2020) also moderately reacted to the expansions of the irrigated area in the Lake Urmia basin. Download : Download high-res image (184KB) Download : Download full-size image Fig. 8. The impact of irrigated agricultural expansions on the Lake Urmia crisis. a) Water area, (b) TWS, and (c) water level. During the last decades, consistent growth in population and investments in the agricultural sector have been reported in the Lake Urmia basin (Balkanlou et al., 2020). Based on the Statistical Center of Iran (2016), the population of the basin significantly increased from approximately 5 million to about 7.2 million from 1985 to 2016. All these changes and the growing food requirements in the region have led to irrigation expansion. As a result, extensive water abstraction, well drilling, and dam construction have been reported. Based on a report published by the Iranian Water Resources Management in 2019, nearly 60 dams have been built in the Lake Urmia basin during the last four decades which corresponds well with our results (Fig. 6). Jaberizadeh (2020) reported these constructions not only could not help to compensate for the water shortage in the Lake Urmia basin but also have led to deforestation and ecological transformations. It was also reported that the number of wells in the Lake Urmia basin has increased from 55,199 in 1984 to 106,200 in 2017 (Bashirian et al., 2020), which stressed the pressure on underground water. In this regard, Ghale et al. (2019) reported that the annual inflow from rivers to the lake has declined in the basin because of growing discharge water from dams and wells during the 1975–2019 period. Therefore, the Lake Urmia crisis was intensified by the expansion of irrigated agricultural lands and its associated issues (e.g., constructions of dams, drilling wells, river diversion/damming, and excessive water abstractions). This was in agreement with the findings of different studies where human activities have been introduced as one of the main driving factors of the Lake Urmia crisis (Ghale et al., 2019, Khazaei et al., 2019, Schulz et al., 2020, Chaudhari et al., 2018). However, it does not mean that the impacts of global warming and severe droughts are negligible. 5. Conclusion During recent years, the water crisis of Lake Urmia enormously damaged its ecosystem and socio-economic activities of the surrounding areas. Here, we presented the long-term annual LC changes based on Landsat images and the GEE platform to investigate the impact of irrigated agricultural expansion on water resources in the Lake Urmia basin. We also examined the feasibility of automatic generation of reference samples for the water class from the JRC data. Although this was the first attempt at long-term annual LC monitoring using a reference sample migration technique, the high OA of 92.2 % (on average) for all generated LC maps showed the efficiency of the proposed workflow. Through the performed analysis, it was observed that surface water, underground water, and the Lake water level were moderately impacted by the irrigated expansions. From 1987 to 2020, the irrigated lands of the basin increased by 890 km2 while surface water areas experienced a 2,020 km2 reduction. During 1987–2019, there was also nearly a 5 m drop in the Lake water level. Furthermore, an 11.5 cm reduction in TWS level witnessed during 2003–2020. In general, to set better environmental management policies, decision-makers and authorities should take into account the fact that irrigation expansion can cause serious environmental costs. CRediT authorship contribution statement Amin Naboureh: Conceptualization, Methodology, Software, Data curation, Writing – original draft, Funding acquisition. Ainong Li: Conceptualization, Supervision, Funding acquisition, Writing – review & editing. Hamid Ebrahimy: Conceptualization, Software, Investigation, Data curation, Writing – original draft. Jinhu Bian: Validation, Formal analysis, Funding acquisition. Mohsen Azadbakht: Data curation, Formal analysis, Writing – review & editing. Meisam Amani: Formal analysis, Writing – review & editing. Guangbin Lei: Formal analysis. Xi Nan: Formal analysis. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgment We thank the Editor, Associate Editor, and the anonymous reviewers for providing constructive comments, by which the current manuscript improved considerably. This research was jointly funded by the National Key Research and Development Program of China (2020YFA0608700), the Strategic Priority Research Program of CAS (XDA19030303), the National Natural Science Foundation project of China (41801370, 42090015), the Youth Innovation Promotion Association CAS (Grant 2019365), and the CAS-TWAS president’s fellowship for international doctoral students. Appendix A. Supplementary material The following are the Supplementary data to this article: Download : Download Word document (26KB) Supplementary Data 1. References Aghakouchak et al., 2015 A. Aghakouchak, H. Norouzi, K. Madani, A. Mirchi, M. Azarderakhsh, A. Nazemi, N. Nasrollahi, A. Farahmand, A. Mehran, E. Hasanzadeh Aral Sea syndrome desiccates Lake Urmia: call for action J. Great Lakes Res., 41 (2015), pp. 307-311 View PDFView articleView in ScopusGoogle Scholar Alborzi et al., 2018 A. Alborzi, A. Mirchi, H. Moftakhari, I. Mallakpour, S. Alian, A. Nazemi, E. Hassanzadeh, O. Mazdiyasni, S. Ashraf, K. Madani Climate-informed environmental inflows to revive a drying lake facing meteorological and anthropogenic droughts Environ. Res. Lett., 13 (2018), Article 084010 CrossRefView in ScopusGoogle Scholar Amiri et al., 2016 V. Amiri, M. Nakhaei, R. Lak, M. Kholghi Geophysical, isotopic, and hydrogeochemical tools to identify potential impacts on coastal groundwater resources from Urmia hypersaline Lake, NW Iran Environ. Sci. Pollut. Res., 23 (2016), pp. 16738-16760 CrossRefView in ScopusGoogle Scholar Ayala et al., 2016 L.M. Ayala, M. van Eupen, G. Zhang, M. Pérez-Soba, L.G. Martorano, L.S. Lisboa, N.E. Beltrao Impact of agricultural expansion on water footprint in the Amazon under climate change scenarios Sci. Total Environ., 569 (2016), pp. 1159-1173 Google Scholar Balkanlou et al., 2020 K.R. Balkanlou, B. Müller, A.F. Cord, F. Panahi, A. Malekian, M. Jafari, L. Egli Spatiotemporal dynamics of ecosystem services provision in a degraded ecosystem: a systematic assessment in the Lake Urmia basin, Iran Sci. Total Environ., 716 (2020), Article 137100 View PDFView articleView in ScopusGoogle Scholar Bashirian et al., 2020 F. Bashirian, D. Rahimi, S. Movahedi, R. Zakerinejad Water level instability analysis of Urmia Lake Basin in the northwest of Iran Arabian J. Geosci., 13 (2020), pp. 1-14 Google Scholar Bian et al., 2020 J. Bian, A. Li, G. Lei, Z. Zhang, X. Nan Global high-resolution mountain green cover index mapping based on Landsat images and Google Earth Engine ISPRS J. Photogramm. Remote Sens., 162 (2020), pp. 63-76 View PDFView articleView in ScopusGoogle Scholar Breiman, 1996 L. Breiman Bagging predictors Mach. Learn., 24 (1996), pp. 123-140 Google Scholar Carlson and Ripley, 1997 T.N. Carlson, D.A. Ripley On the relation between NDVI, fractional vegetation cover, and leaf area index Remote Sens. Environ., 62 (1997), pp. 241-252 View PDFView articleView in ScopusGoogle Scholar Chaudhari et al., 2018 S. Chaudhari, F. Felfelani, S. Shin, Y. Pokhrel Climate and anthropogenic contributions to the desiccation of the second largest saline lake in the twentieth century J. Hydrol., 560 (2018), pp. 342-353 View PDFView articleView in ScopusGoogle Scholar Chen et al., 2019 B. Chen, B. Xu, Z. Zhu, C. Yuan, H.P. Suen, J. Guo, N. Xu, W. Li, Y. Zhao, J. Yang Stable classification with limited sample: Transferring a 30-m resolution sample set collected in 2015 to mapping 10-m resolution global land cover in 2017 Sci. Bull., 64 (2019), pp. 370-373 View in ScopusGoogle Scholar de Moraes et al., 2017 M.C.P. de Moraes, K. de Mello, R.H. Toppa Protected areas and agricultural expansion: Biodiversity conservation versus economic growth in the Southeast of Brazil J. Environ. Manage., 188 (2017), pp. 73-84 Google Scholar Deines et al., 2017 J.M. Deines, A.D. Kendall, D.W. Hyndman Annual irrigation dynamics in the US Northern High Plains derived from Landsat satellite data Geophys. Res. Lett., 44 (2017), pp. 9350-9360 View in ScopusGoogle Scholar Demarez et al., 2019 V. Demarez, F. Helen, C. Marais-Sicre, F. Baup In-season mapping of irrigated crops using Landsat 8 and Sentinel-1 time series Remote Sens., 11 (2019), p. 118 CrossRefView in ScopusGoogle Scholar Destouni et al., 2013 G. Destouni, F. Jaramillo, C. Prieto Hydroclimatic shifts driven by human water use for food and energy production Nat. Clim. Change, 3 (2013), pp. 213-217 CrossRefView in ScopusGoogle Scholar Fathian et al., 2015 F. Fathian, S. Morid, E. Kahya Identification of trends in hydrological and climatic variables in Urmia Lake basin, Iran Theoret. Appl. Climatol., 119 (2015), pp. 443-464 CrossRefView in ScopusGoogle Scholar Feizizadeh et al., 2021 B. Feizizadeh, M.K. Garajeh, T. Lakes, T. Blaschke A deep learning convolutional neural network algorithm for detecting saline flow sources and mapping the environmental impacts of the Urmia Lake drought in Iran Catena, 207 (2021), Article 105585 View PDFView articleView in ScopusGoogle Scholar Foody, 2002 G.M. Foody Status of land cover classification accuracy assessment Remote Sens. Environ., 80 (2002), pp. 185-201 View PDFView articleView in ScopusGoogle Scholar Forootan et al., 2017 E. Forootan, A. Safari, A. Mostafaie, M. Schumacher, M. Delavar, J.L. Awange Large-scale total water storage and water flux changes over the arid and semiarid parts of the Middle East from GRACE and reanalysis products Surv. Geophys., 38 (3) (2017), pp. 591-615 CrossRefView in ScopusGoogle Scholar Garajeh et al., 2021 M.K. Garajeh, F. Malakyar, Q. Weng, B. Feizizadeh, T. Blaschke, T. Lakes An automated deep learning convolutional neural network algorithm applied for soil salinity distribution mapping in Lake Urmia, Iran Sci. Total Environ., 778 (2021), Article 146253 View PDFView articleView in ScopusGoogle Scholar Ghale et al., 2019 Y.A.G. Ghale, M. Baykara, A. Unal Investigating the interaction between agricultural lands and Urmia Lake ecosystem using remote sensing techniques and hydro-climatic data analysis Agric. Water Manag., 221 (2019), pp. 566-579 Google Scholar Ghorbanian et al., 2020 A. Ghorbanian, M. Kakooei, M. Amani, S. Mahdavi, A. Mohammadzadeh, M. Hasanlou Improved land cover map of Iran using Sentinel imagery within Google Earth Engine and a novel automatic workflow for land cover classification using migrated training samples ISPRS J. Photogram. Remote Sens., 167 (2020), pp. 276-288 View PDFView articleView in ScopusGoogle Scholar Gorelick et al., 2017 N. Gorelick, M. Hancher, M. Dixon, S. Ilyushchenko, D. Thau, R. Moore Google Earth Engine: Planetary-scale geospatial analysis for everyone Remote Sens. Environ., 202 (2017), pp. 18-27 View PDFView articleView in ScopusGoogle Scholar Huang et al., 2020 H. Huang, J. Wang, C. Liu, L. Liang, C. Li, P. Gong The migration of training samples towards dynamic global land cover mapping ISPRS J. Photogramm. Remote Sens., 161 (2020), pp. 27-36 View PDFView articleGoogle Scholar Huete, 1988 A. Huete A soil-adjusted vegetation index (SAVI) Remote Sens. Environ., 25 (1988), pp. 295-309 View PDFView articleView in ScopusGoogle Scholar iranian Water Resources Management, 2019 Iranian Water Resources Management 2019. Dams of Urmia Lake basin. http://daminfo.wrm.ir/fa/dam/tabularview. Google Scholar Jaberizadeh, H., 2020 Jaberizadeh, H. 2020. Investigating Water Crisis in Iran. Google Scholar Khazaei et al., 2019 Bahram Khazaei, Sina Khatami, Seyed Hamed Alemohammad, Lida Rashidi, Changshan Wu, Kaveh Madani, Zahra Kalantari, Georgia Destouni, Amir Aghakouchak Climatic or regionally induced by humans? Tracing hydro-climatic and land-use changes to better understand the Lake Urmia tragedy J. Hydrol., 569 (2019), pp. 203-217 View PDFView articleView in ScopusGoogle Scholar Lin et al., 2019 C. Lin, P. Du, A. Samat, E. Li, X. Wang, J. Xia Automatic Updating of Land Cover Maps in Rapidly Urbanizing Regions by Relational Knowledge Transferring from GlobeLand30 Remote Sens., 11 (2019), p. 1397 Google Scholar Mcfeeters, 1996 S.K. Mcfeeters The use of the Normalized Difference Water Index (NDWI) in the delineation of open water features Int. J. Remote Sens., 17 (1996), pp. 1425-1432 CrossRefView in ScopusGoogle Scholar Naboureh et al., 2020a Amin Naboureh, Ainong Li, Jinhu Bian, Guangbin Lei, Meisam Amani A Hybrid Data Balancing Method for Classification of Imbalanced Training Data within Google Earth Engine: Case Studies from Mountainous Regions Remote Sens., 12 (20) (2020), p. 3301, 10.3390/rs12203301 Google Scholar Naboureh et al., 2021 A. Naboureh, J. Bian, G. Lei, A. Li A review of land use/land cover change mapping in the China-Central Asia-West Asia economic corridor countries Big Earth Data, 5 (2021), pp. 237-257 CrossRefView in ScopusGoogle Scholar Naboureh et al., 2020b A. Naboureh, H. Ebrahimy, M. Azadbakht, J. Bian, M. Amani RUESVMs: An Ensemble Method to Handle the Class Imbalance Problem in Land Cover Mapping Using Google Earth Engine Remote Sens., 12 (2020), p. 3484 CrossRefGoogle Scholar Panahi et al., 2020 D.M. Panahi, Z. Kalantari, N. Ghajarnia, S. Seifollahi-Aghmiuni, G. Destouni Variability and change in the hydro-climate and water resources of iran over a recent 30-year period Sci. Rep., 10 (2020), pp. 1-9 Google Scholar Pekel et al., 2016 J.-F. Pekel, A. Cottam, N. Gorelick, A.S. Belward High-resolution mapping of global surface water and its long-term changes Nature, 540 (7633) (2016), pp. 418-422 CrossRefView in ScopusGoogle Scholar Peña-Arancibia et al., 2014 J.L. Peña-Arancibia, T.R. McVicar, Z. Paydar, L. Li, J.P. Guerschman, R.J. Donohue, D. Dutta, G.M. Podger, A.I. van Dijk, F.H. Chiew Dynamic identification of summer cropping irrigated areas in a large basin experiencing extreme climatic variability Remote Sens. Environ., 154 (2014), pp. 139-152 View PDFView articleView in ScopusGoogle Scholar Rodriguez-Galiano et al., 2012 V.F. Rodriguez-Galiano, B. Ghimire, J. Rogan, M. Chica-Olmo, J.P. Rigol-Sanchez An assessment of the effectiveness of a random forest classifier for land-cover classification ISPRS J. Photogramm. Remote Sens., 67 (2012), pp. 93-104 View PDFView articleView in ScopusGoogle Scholar Rosa et al., 2020 L. Rosa, D.D. Chiarelli, M. Sangiorgio, A.A. Beltran-Peña, M.C. Rulli, P. D’Odorico, I. Fung Potential for sustainable irrigation expansion in a 3° C warmer climate Proc. Natl. Acad. Sci., 117 (2020), pp. 29526-29534 CrossRefView in ScopusGoogle Scholar Rouse et al., 1974 J.W. Rouse, R.H. Haas, J.A. Schell, D.W. Deering Monitoring vegetation systems in the Great Plains with ERTS NASA Spec. Public., 351 (1974), p. 309 View in ScopusGoogle Scholar Sabbagh-Yazdi et al., 2020 S. Sabbagh-Yazdi, L. Ghelichkhany, K. Kalhor Numerical investigation of the effects of causeway opening configurations on horizontal currents of Lake Urmia Int. J. Environ. Sci. Technol., 17 (2020), pp. 1885-1898 CrossRefView in ScopusGoogle Scholar Saemian et al., 2020 P. Saemian, O. Elmi, B. Vishwakarma, M. Tourian, N. Sneeuw Analyzing the Lake Urmia restoration progress using ground-based and spaceborne observations Sci. Total Environ., 739 (2020), Article 139857 View PDFView articleView in ScopusGoogle Scholar Schulz et al., 2020 S. Schulz, S. Darehshouri, E. Hassanzadeh, M. Tajrishy, C. Schüth Climate change or irrigated agriculture–what drives the water level decline of Lake Urmia Sci. Rep., 10 (2020), pp. 1-10 View in ScopusGoogle Scholar Shirmohammadi et al., 2020 Bagher Shirmohammadi, Arash Malekian, Ali Salajegheh, Bahram Taheri, Hossein Azarnivand, Ziga Malek, Peter H. Verburg Scenario analysis for integrated water resources management under future land use change in the Urmia Lake region, Iran Land Use Policy, 90 (2020), p. 104299, 10.1016/j.landusepol.2019.104299 View PDFView articleView in ScopusGoogle Scholar Statistical center of iran, 2016 Statistical Center of Iran, 2016. Iran statistical yearbook. Google Scholar Stehman and Foody, 2019 S.V. Stehman, G.M. Foody Key issues in rigorous accuracy assessment of land cover products Remote Sens. Environ., 231 (2019), Article 111199 View PDFView articleView in ScopusGoogle Scholar Taravat et al., 2016 Alireza Taravat, Masih Rajaei, Iraj Emadodin, Hamidreza Hasheminejad, Rahman Mousavian, Ehsan Biniyaz A spaceborne multisensory, multitemporal approach to monitor water level and storage variations of lakes Water, 8 (11) (2016), p. 478, 10.3390/w8110478 View in ScopusGoogle Scholar Tulbure and Broich, 2013 M.G. Tulbure, M. Broich Spatiotemporal dynamic of surface water bodies using Landsat time-series data from 1999 to 2011 ISPRS J. Photogramm. Remote Sens., 79 (2013), pp. 44-52 View PDFView articleView in ScopusGoogle Scholar Wang et al., 2020 X. Wang, X. Xiao, Z. Zou, J. Dong, Y. Qin, R.B. Doughty, M.A. Menarguez, B. Chen, J. Wang, H. Ye Gainers and losers of surface and terrestrial water resources in China during 1989–2016 Nat. Commun., 11 (1) (2020), pp. 1-12 Google Scholar Wurtsbaugh et al., 2017 W.A. Wurtsbaugh, C. Miller, S.E. Null, R.J. Derose, P. Wilcock, M. Hahnenberger, F. Howe, J. Moore Decline of the world's saline lakes Nat. Geosci., 10 (2017), pp. 816-821 CrossRefView in ScopusGoogle Scholar Xu, 2006 H. Xu Modification of normalised difference water index (NDWI) to enhance open water features in remotely sensed imagery Int. J. Remote Sens., 27 (2006), pp. 3025-3033 CrossRefView in ScopusGoogle Scholar Zhu, 2017 Z. Zhu Change detection using landsat time series: A review of frequencies, preprocessing, algorithms, and applications ISPRS J. Photogrammetry Remote Sens., 130 (2017), pp. 370-384 View PDFView articleView in ScopusGoogle Scholar Zhu and Woodcock, 2014 Z. Zhu, C.E. Woodcock Continuous change detection and classification of land cover using all available Landsat data Remote Sens. Environ., 144 (2014), pp. 152-171 View PDFView articleView in ScopusGoogle Scholar Cited by (22) A scenario-based food security analysis and halophyte crop suitability assessment in dying lake environments impacted by climate change 2023, International Journal of Applied Earth Observation and Geoinformation Show abstract Evolution and use of remote sensing in ecological vulnerability assessment: A review 2023, Ecological Indicators Show abstract An integrated approach of deep learning convolutional neural network and google earth engine for salt storm monitoring and mapping 2023, Atmospheric Pollution Research Show abstract What is going on within google earth engine? A systematic review and meta-analysis 2023, Remote Sensing Applications: Society and Environment Citation Excerpt : This category clearly shows a wider use of Sentinel 2 imagery as outlier (Fig. 7), indicating a requirement for higher spectral and spatial accuracy compared to Landsat Series (Table 4). A growing topic under investigation is the mapping and monitoring of irrigated crops in arid environments (Yao et al., 2022; Han et al., 2022), including the effect of increasing irrigated area in the environment (Naboureh et al., 2021). An additional topic is related to crop detection, using several methods, such as RF machine learning algorithm embedded in GEE to retrieve pixels screening, training samples generation, analyses of Leaf Area Index and fraction of photosynthetically active radiation (Sun et al., 2022), ANN algorithm and Sentinel 1, Sentinel 2 images to produce an object-based ACI map (Amani et al., 2020b), or cropland mapping based on phenological metrics, environmental covariates, and machine learning (Htitiou et al., 2021; Cao et al., 2021). Show abstract Long-term detection and spatiotemporal variation analysis of open-surface water bodies in the Yellow River Basin from 1986 to 2020 2022, Science of the Total Environment Citation Excerpt : Fortunately, Google Earth Engine (GEE) can expedite a wide variety of remote sensing calculations in a way that has already benefited scholars who have needed to conduct this type of research in recent year. The superiority and convenience of using GEE has already been demonstrated by a variety of scientific studies (Naboureh et al., 2021; Ahady and Kaplan, 2022; Dong et al., 2016; Hird et al., 2017; Liu et al., 2018; Luo et al., 2022; Oliphant et al., 2019; Prasai et al., 2021; Tang et al., 2016; Zhang et al., 2017), which have verified that GEE can certainly provide powerful support for our research. Therefore, after comprehensively considering the cost and effect of the calculations and operations, a combination rule considering multiple indices was selected for conducting water detection in GEE. Show abstract Distinction of driver contributions to wetland decline and their associated basin hydrology around Iran 2022, Journal of Hydrology: Regional Studies Citation Excerpt : As expected, from the overall insignificant (γ = 0.95) P trends, wetland area correlations with T emerge as mostly somewhat stronger than those with P, except for the Maharloo & Bakhtegan basin. The very weak correlations of both T and P with Lake Urmia area likely reflected particularly dominant non-climate (and mainly human) drivers of wetland decline, which was consistent with previous findings for this basin (Khazaei et al., 2019; Naboureh et al., 2021). As changes in LULC could also affect landscape hydrology (Destouni et al., 2013; Song et al., 2018; Zhang et al., 2018a, 2018b; Trang et al., 2017), we investigated correlations of LULC with wetland decline, using ESA-CCI data for each wetland site reclassified to seven main LULC classes based on Chen et al. (2019) (see Table S2 in SM). Show abstract View all citing articles on Scopus © 2021 The Authors. Published by Elsevier B.V. Part of special issue Remote Sensing of Inland, Coastal and Oceanic Waters Edited by Hongtao Duan, Steven Loiselle, Lydia Olaka, Paolo Villa, Zhigang Cao View special issue Recommended articles Explicit and stepwise models for spatiotemporal fusion of remote sensing images with deep neural networks International Journal of Applied Earth Observation and Geoinformation, Volume 105, 2021, Article 102611 Yaobin Ma, …, Rongxin Tang View PDF Calving cycle of Ninnis Glacier over the last 60 years International Journal of Applied Earth Observation and Geoinformation, Volume 105, 2021, Article 102612 Yuan Cheng, …, Da Lv View PDF Increasing control of climate warming on the greening of alpine pastures in central Asia International Journal of Applied Earth Observation and Geoinformation, Volume 105, 2021, Article 102606 Lilin Zheng, …, Debin Lu View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 19 Captures Readers: 41 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply."

</subsection_point_Point 7>

<previous_sections>

A systematic review of automated systems for real-time irrigation management

1. INTRODUCTION
The challenge of feeding a growing population with finite resources is becoming increasingly pressing. By 2050, the world population is expected to reach 9.7 billion, necessitating a 70% increase in food production (Falkenmark and Rockstrom, 2009). Irrigation plays a crucial role in enhancing crop yields and agricultural productivity to meet this growing demand. Studies have shown that irrigation can significantly increase crop water productivity, contributing to increased food production (Ali and Talukder, 2008; Playan and Mateos, 2005). However, water scarcity poses a significant challenge, with many regions facing water deficits and the need for improved water management practices (Falkenmark and Rockstrom, 2009). Optimizing irrigation schedules and doses based on crop requirements and environmental conditions is essential for maximizing yield and quality while minimizing water use (Zhang et al., 2024). The necessity of scalable water-efficient practices for increasing food demand cannot be overstated. Techniques such as regulated deficit irrigation, magnetically treated water, and the use of drought-tolerant crops like sorghum have shown promise in improving water productivity and ensuring food security (Mehmood et al., 2023; Putti et al., 2023; Hadebe et al., 2016). As the global food challenge intensifies, it is imperative to critically evaluate the current state and future potential of irrigation management systems to guide research, innovation, and implementation efforts towards fully autonomous, scalable solutions.

Despite the importance of irrigation in addressing the global food challenge, traditional irrigation management techniques, such as manual scheduling and timer-based systems, have significant limitations. These methods are often labor-intensive, inefficient, and less adaptable to changing conditions (Savin et al., 2023). Manual and timer-based scheduling can lead to high operational costs and inefficient water use (Raghavendra, Han, and Shin, 2023). The reliance on manual intervention and predetermined schedules limits their adaptability to changing environmental conditions, crop water requirements, and soil moisture levels (Kaptein et al., 2019). Sensor-based irrigation systems offer an alternative, enabling real-time adjustments based on soil water status measurements (Kaptein et al., 2019). However, the adoption of these systems in commercial settings has been limited, often requiring extensive input from researchers (Kim et al., 2014; Lea-Cox et al., 2018; Ristvey et al., 2018). The limitations of traditional irrigation management techniques highlight the need for scalable, automated solutions for greater efficiency in irrigation management. Automated systems that collect real-time data, analyze it, and make autonomous irrigation decisions can lead to improved water use efficiency and increased crop productivity (Champness et al., 2023; Wu et al., 2022). To fully understand the potential of automated systems, it is necessary to examine the automation of each part of the irrigation management pipeline and analyze the effectiveness and efficiency of integrated end-to-end solutions.

The emergence of smart irrigation management and IoT marks a significant shift from historical irrigation practices. Modern approaches rely on vast data and analysis algorithms, leveraging technologies such as remote sensing, sensor networks, weather data, and computational algorithms (Atanasov, 2023; Bellvert et al., 2023; Kumar et al., 2023). IoT plays a vital role in collecting vast amounts of data through sensors, data transmission, and tailored networks, enabling real-time monitoring and control of irrigation systems (Liakos, 2023; Zuckerman et al., 2024). These advancements in data collection and analysis have the potential to revolutionize irrigation management, allowing for more precise and efficient water use. However, challenges such as processing diverse data sources, data integration, and lack of integrated data analysis hamper the full benefit of IoT in irrigation management (Dave et al., 2023). The current fragmented approach in smart irrigation, focusing on individual components rather than the entire system, limits the potential for fully autonomous, real-time end-to-end irrigation management (Togneri et al., 2021). To address these challenges and fully realize the potential of smart irrigation management, there is a need for automating and integrating each section of the irrigation management pipeline, from sensor/weather data collection and transmission to processing, analysis, decision-making, and automated action (McKinion and Lemmon, 1985). This integration requires a thorough investigation of the role of interoperability and standardization in enabling seamless communication and compatibility between components within the automated irrigation management pipeline.

Machine learning (ML) plays a significant role in processing vast data, predicting plant stress, modeling climate effects, and optimizing irrigation in smart irrigation management systems. ML algorithms can analyze data collected from sensors and weather stations to determine optimal irrigation schedules (Vianny et al., 2022). However, the potential of ML is often constrained by manual steps, such as data interpretation, decision-making on irrigation timing and volume, and system adjustments. Automating ML integration to allow direct action from insights to irrigation execution, removing bottlenecks and achieving real-time adaptability, is crucial for fully autonomous irrigation management (Barzallo-Bertot et al., 2022). By integrating ML into automated systems, the irrigation management pipeline can become more seamless and efficient, enabling real-time decision-making and action based on data-driven insights. To achieve this level of automation and integration, it is essential to identify gaps and propose solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.

To achieve seamless integration across the automated irrigation management system, interoperability and standardization are critical. Interoperability allows different system components, such as sensors, actuators, and software, to communicate and exchange data effectively, while standardization ensures that data is represented in a consistent format (Santos et al., 2020). Standardized protocols and data formats are essential for achieving seamless integration and ensuring compatibility between components in real-time irrigation management systems (Robles et al., 2022; Hatzivasilis et al., 2018). Existing and emerging standards, such as OGC SensorThings API and ISO 11783, have applicability to real-time irrigation management systems (Hazra et al., 2021). However, challenges such as data quality, scalability, reliability, and security need to be addressed to fully realize the potential of interoperability and standardization in automated irrigation management systems (Hazra et al., 2021). Addressing these challenges is crucial for enabling the seamless integration of components within the automated irrigation management pipeline, which is essential for achieving fully autonomous, scalable irrigation management. A comprehensive evaluation of the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline is necessary to guide future research and implementation efforts.
The primary objective of this systematic review is to critically evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies for enhancing agricultural water use efficiency and crop productivity.
Specific objectives include:
•	Examining the automation of each part of the irrigation management pipeline and the seamless integration of each section in the context of irrigation scheduling and management.
•	Analyzing the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
•	Investigating the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.
•	Identifying gaps and proposing solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.
By addressing these objectives, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.

2. REVIEW METHODOLOGY
•	Question-driven framework to guide the literature review of real-time, autonomous irrigation management systems
•	Key research questions posed, each with the motivation behind investigating them and a starting hypothesis to evaluate against the examined literature
•	Table presenting the major objectives, specific objectives, questions, motivations, and hypotheses
3. DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING
3.1. Irrigation management data
The success of automated irrigation management systems relies heavily on the collection, transmission, and analysis of various types of data. The most applicable data types for irrigation management include soil moisture, canopy temperature, weather data, and plant physiological parameters (Farooq et al., 2019; Li et al., 2019; Olivier et al., 2021; Evett et al., 2020). These data are typically collected from a range of sources, including in-field sensors, remote sensing platforms, weather stations, and manual measurements (Li et al., 2019; Karimi et al., 2018).
Soil moisture data is arguably the most critical type of data for irrigation management, as it directly reflects the water available to plants and can be used to determine the optimal timing and amount of irrigation (Olivier et al., 2021; Intrigliolo & Castel, 2006). Soil moisture sensors, such as tensiometers, capacitance probes, and time-domain reflectometry (TDR) sensors, can provide real-time measurements of soil water content at various depths (Farooq et al., 2019). These sensors can be deployed in a network configuration to capture spatial variability in soil moisture across a field (Karimi et al., 2018).
Canopy temperature data is another valuable type of data for irrigation management, as it can be used to assess plant water stress and adjust irrigation accordingly (Evett et al., 2020). Infrared thermometers and thermal cameras can be used to measure canopy temperature, which is influenced by factors such as air temperature, humidity, wind speed, and plant water status (Li et al., 2019). When plants experience water stress, they tend to close their stomata to reduce water loss, leading to an increase in canopy temperature (Evett et al., 2020). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
Weather data, including temperature, humidity, precipitation, wind speed, and solar radiation, are essential for predicting crop water requirements and scheduling irrigation events (Akilan & Baalamurugan, 2024). Weather stations equipped with various sensors can provide real-time measurements of these parameters, which can be used as inputs for crop water requirement models, such as the FAO-56 Penman-Monteith equation (Li et al., 2019). These models estimate crop evapotranspiration (ET) based on weather data and crop-specific coefficients, allowing for the calculation of irrigation requirements (Intrigliolo & Castel, 2006). By integrating weather data into automated irrigation systems, irrigation schedules can be dynamically adjusted based on changing environmental conditions, ensuring that crops receive the optimal amount of water at the right time (Akilan & Baalamurugan, 2024).
When collecting and utilizing these data types, several considerations must be taken into account, including the volume, frequency, format, and source of the data (Farooq et al., 2019). The volume of data generated by automated irrigation systems can be substantial, especially when high-resolution sensors are deployed at a large scale (Bastidas Pacheco et al., 2022). This necessitates the use of efficient data storage, processing, and transmission technologies to handle the data load (Farooq et al., 2019). The frequency of data collection is another important consideration, as it directly impacts the temporal resolution of the data and the ability to detect rapid changes in plant water status or environmental conditions (Bastidas Pacheco et al., 2022). Bastidas Pacheco et al. (2022) demonstrated that collecting full pulse resolution data from water meters provides more accurate estimates of event occurrence, timing, and features compared to aggregated temporal resolutions, highlighting the importance of selecting appropriate data collection frequencies to ensure the quality and usefulness of the data for irrigation management.
The format of the data is also crucial, as it determines the compatibility and interoperability of the data with various analysis tools and platforms (Farooq et al., 2019). Standardized data formats, such as JSON, XML, or CSV, can facilitate data exchange and integration between different components of the automated irrigation system (Zhang et al., 2023). The source of the data is another important consideration, as it can impact the reliability, accuracy, and spatial coverage of the data (Farooq et al., 2019). For example, in-field sensors provide highly localized measurements, while remote sensing platforms, such as satellites or drones, can provide data at larger spatial scales (Li et al., 2019). By combining data from multiple sources, automated irrigation systems can achieve a more comprehensive understanding of crop water requirements and optimize irrigation management accordingly (Farooq et al., 2019).
Data quality, accuracy, and reliability are paramount in irrigation management, as they directly impact the effectiveness of decision-making processes and the efficiency of water use (Gupta et al., 2020). Inaccurate or unreliable data can lead to suboptimal irrigation decisions, resulting in crop stress, yield losses, or wasted water resources (Ramli & Jabbar, 2022). Gupta et al. (2020) emphasized the critical importance of data security and privacy in smart farming systems, as the leakage of sensitive agricultural data can cause severe economic losses to farmers and compromise the integrity of the automated irrigation system. The authors also highlighted the need for robust authentication and secure communication protocols to prevent unauthorized access to smart farming systems and protect data in transit (Gupta et al., 2020).
Ramli and Jabbar (2022) addressed the challenges associated with implementing real-time, automated irrigation systems, including data quality, scalability, reliability, and security. They proposed solutions and best practices based on the analysis of case studies and real-world implementations, such as the use of redundant sensors, data validation techniques, and secure communication protocols (Ramli & Jabbar, 2022). The authors also emphasized the importance of regular maintenance and calibration of sensors to ensure the accuracy and reliability of the collected data (Ramli & Jabbar, 2022).
Researchers have investigated the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in automated irrigation systems (Karim et al., 2023; Rady et al., 2020; Cui, 2023). Karim et al. (2023) explored the effectiveness of various data compression techniques, such as lossless and lossy compression algorithms, in reducing the size of data packets transmitted over wireless networks. The authors found that lossless compression techniques, such as Huffman coding and Lempel-Ziv-Welch (LZW), can significantly reduce data size without compromising data quality, while lossy compression techniques, such as JPEG and MP3, can further reduce data size by introducing acceptable levels of distortion (Karim et al., 2023).
Rady et al. (2020) developed a novel data compression algorithm specifically designed for irrigation data, which achieved significant compression ratios without compromising data quality. The authors demonstrated that their algorithm could reduce the amount of data transmitted over wireless networks, thereby improving the efficiency of the irrigation system and reducing costs (Rady et al., 2020). Cui (2023) investigated the use of data aggregation and filtering techniques to reduce the number of transmissions and save bandwidth in automated irrigation systems. The author proposed a data aggregation scheme that combines multiple sensor readings into a single value, such as the average soil moisture over a specified time interval, to reduce the frequency of data transmissions (Cui, 2023). Additionally, the author explored the use of data filtering techniques, such as Kalman filters and particle filters, to remove noise and outliers from sensor data, improving the accuracy and reliability of the transmitted information (Cui, 2023).
Data standardization and harmonization are crucial for facilitating seamless integration and interoperability between the various components of automated irrigation management systems (Zhang et al., 2023; Ermoliev et al., 2022). Zhang et al. (2023) developed a novel cyberinformatics technology called iCrop, which enables the in-season monitoring of crop-specific land cover across the contiguous United States. The authors highlighted the importance of data standardization and harmonization in the context of iCrop, as it allows for the efficient distribution of crop-specific land cover information based on the findable, accessible, interoperable, and reusable (FAIR) data principle (Zhang et al., 2023). By adopting standardized data formats and protocols, such as the Open Geospatial Consortium (OGC) standards, iCrop enables the seamless integration of various data sources and facilitates the interoperability of the system with other agricultural decision support tools (Zhang et al., 2023).
Ermoliev et al. (2022) proposed a linkage methodology for linking distributed sectoral/regional optimization models in a situation where private information is not available or cannot be shared by modeling teams. The authors emphasized the need for data standardization to enable decentralized cross-sectoral coordination and analysis, as it allows for the consistent representation and exchange of data between different models and stakeholders (Ermoliev et al., 2022). By adopting standardized data formats and interfaces, the proposed linkage methodology can facilitate the integration of various optimization models and support the development of comprehensive decision support systems for sustainable resource management (Ermoliev et al., 2022).
Metadata plays a vital role in providing context and enabling better data interpretation and decision-making in automated irrigation management systems (Jahanddideh-Tehrani et al., 2021). Metadata refers to the additional information that describes the characteristics, quality, and context of the primary data, such as the sensor type, calibration parameters, measurement units, and timestamp (Jahanddideh-Tehrani et al., 2021). Jahanddideh-Tehrani et al. (2021) highlighted the importance of metadata in water resources management, as it enables decision-makers to use the data to the best of its capabilities by understanding factors such as when water data was collected and what factors might have contributed to the measurements. The authors emphasized the need for standardized metadata formats and guidelines, such as the Dublin Core Metadata Initiative (DCMI) and the ISO 19115 standard, to ensure the consistency and interoperability of metadata across different water information systems (Jahanddideh-Tehrani et al., 2021).
In the context of automated irrigation management systems, metadata can provide valuable information about the data collection process, sensor performance, and environmental conditions that can aid in data interpretation and decision-making (Cota & Mamede, 2023). For example, metadata about the sensor type and calibration parameters can help assess the accuracy and reliability of the collected data, while metadata about the weather conditions and soil properties can provide context for interpreting the data and adjusting irrigation strategies accordingly (Cota & Mamede, 2023). By incorporating metadata into the data management and analysis pipeline of automated irrigation systems, decision-makers can make more informed and context-aware decisions, leading to improved water use efficiency and crop productivity (Jahanddideh-Tehrani et al., 2021).

3.2. Edge Computing and Fog Computing
Edge computing and fog computing have emerged as transformative technologies in the realm of real-time irrigation management systems, offering significant potential for improving efficiency, scalability, and reliability (Abdel Nasser et al., 2020; Tran et al., 2019). Edge computing refers to the practice of processing data near the edge of the network, close to the source of the data, while fog computing is a decentralized computing infrastructure that extends cloud computing capabilities to the network edge (Hassija et al., 2019). These technologies bring computation and analytics closer to the data source, reducing the need for data to travel to the cloud and enabling faster processing and decision-making (Hassija et al., 2019; Zhang et al., 2020).
The potential of edge computing and fog computing in real-time irrigation management is immense. Abdel Nasser et al. (2020) proposed a two-layer system for water demand prediction using automated meters and machine learning techniques, demonstrating the potential of edge computing in improving the efficiency and scalability of irrigation management. The system collects and aggregates data from distributed smart meters in the first layer, while the second layer uses LSTM neural networks to predict water demand for different regions of households. By leveraging edge computing, the system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management (Abdel Nasser et al., 2020).
Tran et al. (2019) conducted a comprehensive review of real-time, end-to-end automated irrigation management systems, highlighting the role of fog computing in addressing data transmission challenges and enabling seamless integration across the irrigation management pipeline. The authors emphasize that real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs. However, they also identify several challenges that need to be addressed, such as data quality, scalability, reliability, and security, which can be effectively tackled by implementing fog computing architectures (Tran et al., 2019).
Edge computing offers several benefits in real-time irrigation management systems, including reduced latency, real-time decision-making, and reduced reliance on cloud connectivity (Mishra, 2020; Zhang et al., 2020). By processing data closer to the source, edge computing enables faster response times and more efficient data handling (Mishra, 2020). Mishra (2020) highlights that edge computing reduces latency by processing data closer to the source, enabling real-time decision-making and lessening reliance on cloud connectivity by shifting processing to local or edge devices.
Zhang et al. (2020) explore the application of edge computing in agricultural settings, demonstrating its potential to improve the efficiency and accuracy of irrigation systems. The authors discuss how edge computing has prospects in various agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. They also emphasize that the emergence of edge computing models, such as fog computing, cloudlet, and mobile edge computing, has transformed the management and operation of farms (Zhang et al., 2020).
Fog computing plays a crucial role in distributing processing and storage across the network, enhancing the scalability and reliability of automated irrigation systems (Premkumar & Sigappi, 2022; Singh et al., 2022). Premkumar and Sigappi (2022) evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation. Their study emphasizes the potential of fog computing in distributing processing and storage across the network, improving the efficiency and scalability of irrigation systems. The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture, demonstrating the effectiveness of fog computing in enhancing the performance of automated irrigation systems (Premkumar & Sigappi, 2022).
Singh et al. (2022) discuss the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability in agricultural management systems. The authors argue that by implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness. They also highlight that fog computing can address the challenges faced by real-time data transmission in agricultural management systems, such as latency, bandwidth limitations, and data security (Singh et al., 2022).
The integration of edge and fog computing in real-time irrigation management systems is crucial for achieving fully automated, scalable, and reliable solutions. As the demand for autonomous irrigation management grows, these technologies will play a pivotal role in enabling faster decision-making, reduced latency, improved resource utilization, and seamless integration across the irrigation management pipeline (Tran et al., 2019; Zhang et al., 2020). By bringing computation and analytics closer to the data source and distributing processing and storage across the network, edge and fog computing can significantly enhance the efficiency and effectiveness of automated irrigation systems, contributing to the overall goal of addressing the global food challenge through optimized water resource management and increased agricultural productivity (Abdel Nasser et al., 2020; Premkumar & Sigappi, 2022; Singh et al., 2022).

3.3. Automation of Data Collection
The automation of data collection is a critical component in the development of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. It enables the efficient gathering of vital information about crop health, environmental conditions, and water requirements, which is essential for enhancing agricultural water use efficiency and crop productivity. Two key aspects of automated data collection are the use of advanced sensing technologies for non-invasive plant stress detection and the implementation of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.
Advanced sensing technologies, such as hyperspectral imaging and thermal sensing, have emerged as powerful tools for non-invasive plant stress detection in automated irrigation management systems. These technologies provide valuable information about crop traits, enabling early and accurate detection of plant health issues (Triantafyllou et al., 2019). Triantafyllou et al. (2019) propose a comprehensive reference architecture model that incorporates advanced sensing technologies in the sensor layer for real-time plant stress detection, highlighting their importance in providing non-invasive plant stress detection. Similarly, Hossain et al. (2023) present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that leverages advanced sensing technologies to optimize water use and improve crop yield, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
Hyperspectral imaging can capture subtle changes in plant physiology that are indicative of stress, while machine learning algorithms can be employed to extract meaningful patterns from the spectral data and classify different stress types (Araus et al., 2014). Thermal sensing can detect changes in canopy temperature, which is influenced by factors such as plant water status (Li et al., 2019). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
The integration of advanced sensing technologies in automated irrigation management systems has the potential to revolutionize precision agriculture. Jiang et al. (2019) demonstrate the effectiveness of a deep learning-based model in accurately detecting leaf spot diseases, highlighting the importance of image augmentation and deep learning algorithms in enhancing the model's performance.
Wireless sensor networks (WSNs) and energy-efficient communication protocols have the potential to significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. WSNs offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems, providing remote monitoring and automated control capabilities (Mehdizadeh et al., 2020). Nishiura and Yamamoto (2021) propose a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields, reducing operational costs and enhancing the efficiency of data collection. Similarly, Higashiura and Yamamoto (2021) introduce a network system that employs UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands, optimizing data collection and reducing travel distance and time.
Energy-efficient communication protocols are crucial for ensuring reliable data transmission in challenging environmental conditions and extending the lifespan of sensor nodes (Mehdizadeh et al., 2020). Al-Ali et al. (2023) investigate the potential of WSNs and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems, discussing the challenges and opportunities of using these technologies to improve the efficiency and reliability of real-time data collection in irrigation management. Mehdizadeh et al. (2020) emphasize the need for careful consideration of factors such as data accuracy, energy consumption, and network reliability when designing effective WSNs for irrigation management, enabling timely irrigation decisions and improved crop yields.
The automation of data collection through the use of advanced sensing technologies and wireless sensor networks is essential for achieving fully autonomous, scalable irrigation management. By enabling non-invasive plant stress detection and large-scale, long-term data collection, these technologies contribute to the overall goal of optimizing water resource management and increasing agricultural productivity. The integration of these technologies in real-time, end-to-end automated irrigation management systems has the potential to enhance agricultural water use efficiency and crop productivity, ultimately contributing to the development of fully autonomous, scalable irrigation management solutions.

3.4: Real-Time Data Transmission Protocols and Technologies
Real-time data transmission is a critical component of automated irrigation management systems, as it enables the timely delivery of sensor data to the cloud for processing and decision-making. The exploration of suitable protocols and network architectures is essential for ensuring efficient and reliable data transmission in these systems, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
The Message Queuing Telemetry Transport (MQTT) protocol has emerged as a popular choice for real-time data transmission in IoT networks, including those used for automated irrigation management. MQTT is a lightweight, publish-subscribe protocol designed for constrained devices and low-bandwidth networks (Author, 2019). Its simplicity and low overhead make it well-suited for IoT applications where data transmission speed and energy efficiency are critical (Saranyadevi et al., 2022). MQTT provides three Quality of Service (QoS) levels, ensuring data reliability in real-time scenarios (Author, 2019). Chen et al. (2020) proposed novel algorithms to improve data exchange efficiency and handle rerouting in MQTT-based IoT networks for automated irrigation management systems. Their TBRouting algorithm efficiently finds the shortest paths for data transmission, while the Rerouting algorithm effectively handles the rerouting of topic-based session flows when a broker crashes. The combination of these algorithms can significantly improve the performance and reliability of automated irrigation management systems (Chen et al., 2020).
Client-server IoT networks, such as those based on MQTT, play a crucial role in real-time data transmission for automated irrigation management systems. In these networks, sensors and devices (clients) publish data to a central broker (server), which then distributes the data to subscribed clients (Verma et al., 2021). This architecture enables efficient data collection, processing, and dissemination, facilitating the integration of various components within the automated irrigation management pipeline. Verma et al. (2021) proposed an architecture for healthcare monitoring systems using IoT and communication protocols, which provides a comprehensive overview of existing approaches and highlights challenges and opportunities in the field. Although focused on healthcare, the insights from this study can be applied to automated irrigation management systems, emphasizing the importance of interoperability and standardization for seamless integration (Verma et al., 2021).
In addition to MQTT, other application layer protocols such as XMPP, CoAP, SOAP, and HTTP have been explored for real-time data transmission in IoT networks. Each protocol has its strengths and weaknesses, making them suitable for different applications and scenarios. XMPP (Extensible Messaging and Presence Protocol) is an open-standard protocol that supports real-time messaging, presence, and request-response services (Saint-Andre, 2011). CoAP (Constrained Application Protocol) is a specialized web transfer protocol designed for use with constrained nodes and networks in the Internet of Things (Shelby et al., 2014). SOAP (Simple Object Access Protocol) is a protocol for exchanging structured information in the implementation of web services, while HTTP (Hypertext Transfer Protocol) is the foundation of data communication for the World Wide Web (Fielding et al., 1999).
Motamedi and Villányi (2022) compared and evaluated wireless communication protocols for the implementation of smart irrigation systems in greenhouses, considering factors such as power consumption, range, reliability, and scalability. They found that ZigBee is the most suitable local communication protocol for greenhouse irrigation due to its large number of nodes and long range, while MQTT is the recommended messaging protocol for smart irrigation systems due to its TCP transport protocol and quality of service (QoS) options. GSM is a reliable and cost-effective global communication protocol for greenhouse irrigation, providing wide coverage and low cost (Motamedi & Villányi, 2022).
Syafarinda et al. (2018) investigated the use of the MQTT protocol in a precision agriculture system using a Wireless Sensor Network (WSN). They found that MQTT is suitable for use in IoT applications due to its lightweight, simple, and low bandwidth requirements. The average data transmission speed using the MQTT protocol was approximately 1 second, demonstrating its effectiveness for real-time data transmission in precision agriculture systems (Syafarinda et al., 2018).
The choice of application layer protocol for real-time irrigation management depends on factors such as data transmission speed, reliability, and energy efficiency. MQTT and RTPS (Real-Time Publish-Subscribe) are both suitable for real-time data transmission in IoT systems, but they have different strengths and weaknesses. MQTT is a better choice for applications that require low latency and high throughput, while RTPS is a better choice for applications that require high reliability and low latency (Sanchez-Iborra & Skarmeta, 2021). The exploration of MQTT and client-server IoT networks, along with the comparison of various application layer protocols, provides valuable insights into the suitability of these technologies for real-time data transmission in automated irrigation management systems.
In summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.

3.5. Challenges and Solutions in Real-Time Data Transmission
Following the exploration of data collection, processing at the edge and fog, and automation in previous sections, we now turn to the critical aspect of real-time data transmission. While essential for automated irrigation management, this stage presents unique challenges that must be addressed to ensure system efficiency and reliability.
Obstacles in Real-Time Data Transmission
Agricultural environments present unique challenges for real-time data transmission, directly impacting the effectiveness of automated irrigation systems. Environmental factors can significantly disrupt wireless communication. Adverse weather conditions such as heavy rain, fog, and high winds can weaken or even block radio signals, leading to data loss and compromised system performance. Physical obstacles like trees, buildings, and uneven terrain further complicate signal propagation, creating reliability issues (Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). These environmental challenges necessitate robust communication protocols and network architectures that can ensure consistent and reliable data flow.
In addition to environmental factors, technical limitations also present significant obstacles. Large-scale agricultural operations often demand long-distance data transmission, which can be hindered by the limited range of certain wireless communication protocols. Network congestion, occurring when multiple sensors transmit data concurrently, can lead to delays and potential data loss, further complicating real-time decision-making (Hameed et al., 2020). To mitigate these issues, researchers have investigated the potential of cognitive radio networks (CRNs) and dynamic spectrum access (DSA) for optimizing spectrum utilization and reducing interference (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). CRNs enable devices to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency. DSA, on the other hand, facilitates the dynamic allocation of unused spectrum, enhancing spectrum utilization and reducing congestion.
Furthermore, data security and privacy are paramount concerns in real-time irrigation systems. The sensitive nature of agricultural data, such as crop yields and farm management practices, necessitates robust security measures to prevent unauthorized access and data breaches (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential to protect data integrity and ensure the trustworthiness of the system.
Investigating Data Optimization Techniques
To enhance the efficiency and reliability of real-time data transmission in automated irrigation systems, researchers have explored a range of data optimization techniques. Data compression techniques aim to reduce the size of data packets transmitted over the network, minimizing bandwidth requirements and improving transmission speed (Rady et al., 2020; Karim et al., 2023). Lossless compression algorithms, such as Huffman coding and LZW, preserve data integrity while effectively reducing data size, ensuring that no information is lost during transmission (Cui, 2023). Lossy compression algorithms, such as JPEG and MP3, offer higher compression ratios but introduce a controlled level of data loss, which may be acceptable for certain applications where some loss of precision is tolerable (Karim et al., 2023). The choice between lossless and lossy compression depends on the specific application and the trade-off between data size and accuracy.
Data aggregation techniques provide another effective approach to optimize data transmission. By aggregating multiple sensor readings into a single representative value, such as average soil moisture or temperature, the number of transmissions can be significantly reduced, conserving bandwidth and energy resources (Cui, 2023). This is particularly beneficial in large-scale irrigation systems where numerous sensors are deployed across vast areas, generating substantial amounts of data. Additionally, data filtering techniques play a crucial role in improving data quality and reliability. Kalman filters and particle filters can effectively remove noise and outliers from sensor data, ensuring that only accurate and relevant information is transmitted and used for decision-making (Cui, 2023). This is essential for preventing erroneous data from influencing irrigation decisions and potentially leading to suboptimal water management.
Sensor calibration, drift correction, and fault detection are essential for maintaining data accuracy and reliability (Dos Santos et al., 2023). Regular calibration ensures that sensors provide accurate measurements over time, while drift correction techniques account for gradual changes in sensor readings due to environmental factors or aging. Fault detection mechanisms can identify and address sensor malfunctions or anomalies, preventing erroneous data from influencing irrigation decisions and potentially harming crops or wasting water.
Addressing the Challenges
Effectively addressing the challenges in real-time data transmission requires a multifaceted approach that encompasses environmental, technical, and data-related considerations. Implementing robust and adaptive communication protocols is crucial for overcoming interference and signal degradation caused by weather conditions and physical obstacles. Selecting appropriate protocols, such as LoRa or ZigBee, with suitable range and penetration capabilities can ensure reliable data transmission in challenging agricultural environments (Motamedi & Villányi, 2022). Additionally, employing techniques like frequency hopping and error correction codes can further improve communication resilience and mitigate data loss.
Optimizing network architecture is another key consideration. Deploying a distributed network architecture with edge and fog computing capabilities can significantly enhance data processing and transmission efficiency (Abdel Nasser et al., 2020; Tran et al., 2019). Edge devices can perform initial data processing and aggregation tasks, reducing the amount of data transmitted to the cloud and minimizing latency, while fog nodes can provide additional processing power and storage closer to the data source, enhancing scalability and reliability. This distributed approach alleviates the burden on the central cloud server and allows for more responsive and efficient irrigation management.
Data optimization techniques play a vital role in reducing bandwidth requirements and improving transmission efficiency. The choice of data compression, aggregation, and filtering techniques should be tailored to the specific requirements of the irrigation system, considering factors such as data type, accuracy needs, and available bandwidth. By carefully selecting and implementing these techniques, the overall performance and effectiveness of real-time irrigation systems can be significantly enhanced, leading to more sustainable water management practices and improved agricultural productivity.
By addressing these challenges and implementing appropriate solutions, real-time data transmission can become a reliable and efficient component of automated irrigation systems, contributing to the overall goal of achieving sustainable and productive agriculture in the face of growing food demands and water scarcity.

3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
Real-time irrigation management systems heavily rely on the efficient and reliable transmission of data from sensors and weather stations to the cloud for processing and decision-making. However, agricultural environments present unique challenges to wireless communication, including adverse weather conditions, physical obstacles, and the limitations of wireless technologies. These challenges necessitate robust and adaptive solutions to ensure the consistent and timely flow of data, enabling truly autonomous irrigation scheduling.
Environmental factors, such as heavy rain, fog, and strong winds, can significantly disrupt wireless communication by attenuating or even blocking radio signals, leading to data loss and compromised system performance (Ed-daoudi et al., 2023; Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). Dense vegetation, buildings, and uneven terrain create further complications by causing multipath propagation and shadowing effects (Yim et al., 2018; Gautam and Pagay, 2020). The study by Yim et al. (2018) on LoRa networks in a tree farm environment exemplifies these challenges, revealing reduced communication range and data reliability compared to theoretical expectations. This underscores the need for carefully selecting and optimizing communication protocols and network parameters to ensure reliable data transmission in such environments.
The study by Guzinski et al. (2014a) using a modified TSEB model further highlights the importance of high-resolution data in accurately capturing the spatial and temporal dynamics of energy fluxes influenced by environmental factors. This emphasizes the need for advanced data acquisition and processing techniques that can effectively represent the complexities of agricultural settings.
The limitations of traditional wireless communication technologies, such as limited range and network congestion, pose additional challenges for large-scale agricultural operations. Long-distance data transmission can be hindered by range limitations, while network congestion arising from numerous sensors transmitting concurrently can lead to delays and data loss, hindering real-time decision-making (Hameed et al., 2020). Addressing these challenges requires the exploration of advanced networking technologies that can optimize spectrum utilization, mitigate interference, and improve reliability and efficiency.
Cognitive Radio Networks (CRNs) and Dynamic Spectrum Access (DSA) offer promising solutions for optimizing wireless communication in agricultural settings. CRNs empower devices with the ability to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). Research has explored the potential of CRNs in predicting Radio Frequency (RF) power to avoid noisy channels and optimize spectrum utilization (Iliya et al., 2014; Iliya et al., 2014). These studies demonstrate the effectiveness of combining optimization algorithms with artificial neural networks (ANNs) to enhance the accuracy and generalization of RF power prediction, enabling CRNs to make informed decisions about channel selection and avoid interference.
DSA complements CRN technology by dynamically allocating unused spectrum, further enhancing spectrum utilization and reducing congestion (Shi et al., 2023). The numerical model developed by Shi et al. (2023) showcases the potential of CRNs and DSA for optimizing wireless communication in challenging environments.
The integration of CRNs and DSA into the IoT network architecture requires careful consideration of spectrum sensing techniques, network topology, and data security. Research on cooperative spectrum sensing suggests that distributed approaches, where sensor nodes collaborate and share information, can significantly improve the accuracy and efficiency of spectrum sensing, particularly in dynamic environments (Trigka and Dritsas, 2022; Khalid & Yu, 2019). This collaborative approach enables a more comprehensive understanding of the radio environment and facilitates the identification of available frequency bands for data transmission.
The choice of network topology also impacts the performance and scalability of CRN-based irrigation systems. Mesh networks, where sensor nodes are interconnected and relay data for each other, offer enhanced resilience and coverage compared to star topologies where nodes communicate directly with a central gateway (Akyildiz & Vuran, 2010). However, mesh networks can be more complex to manage and may introduce additional routing overhead. The trade-off between network resilience and complexity needs to be carefully evaluated to select the most appropriate topology for a specific agricultural setting.
Data security and privacy are paramount concerns in IoT-based irrigation systems due to the sensitive nature of agricultural data (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential for protecting data integrity and ensuring system trustworthiness. Research on secure spectrum leasing and resource allocation algorithms for CR-WSN-based irrigation systems has demonstrated the potential of these technologies for enhancing security and efficiency (Hassan, 2023; Afghah et al., 2018).
In conclusion, the development of effective and reliable real-time irrigation management systems requires a comprehensive approach that addresses the challenges of data transmission in agricultural environments. The integration of robust and adaptive communication protocols, optimized network architectures, and advanced networking technologies like CRNs and DSA, along with a focus on data security and privacy, can contribute significantly to achieving the goal of autonomous and efficient irrigation scheduling.
4. AUTOMATED DATA PROCESSING IN THE CLOUD
4.1. Data Quality and Preprocessing
Data quality is paramount in automated irrigation systems as it directly influences the effectiveness of decision-making and water use efficiency. Issues like missing values, inconsistencies, and outliers arising from sensor malfunctions, environmental interference, or network problems (Lv et al., 2023) can significantly impact the performance of machine learning models used for irrigation scheduling and management.
Real-time data cleaning techniques are essential for addressing these challenges. Kalman filtering proves particularly effective in handling missing values and correcting erroneous readings by recursively estimating the system's state based on previous measurements and current sensor data, taking into account noise and uncertainty (Kim et al., 2020). Moving average techniques, by averaging consecutive data points, provide a more stable representation of the underlying trend, filtering out short-term fluctuations (Chhetri, 2023). For outlier detection, adaptive thresholding methods offer a dynamic approach, adjusting thresholds based on the statistical properties of the data to effectively identify anomalies and minimize false positives (Bah et al., 2021). These techniques are crucial in maintaining the integrity of real-time data streams and ensuring the accuracy of subsequent analyses.
Adaptive data preprocessing is essential for managing the diversity of data sources and formats commonly found in irrigation systems. Data normalization techniques, such as min-max scaling or z-score normalization, ensure that all features contribute equally to the analysis by transforming data values to a common scale (Pradal et al., 2016). This is crucial for preventing features with larger values from dominating the analysis and ensuring that all features are given equal consideration. Similarly, feature scaling methods, like standardization or normalization, optimize the range of feature values to improve the performance and convergence of machine learning models (Tortorici et al., 2024). By scaling features to a similar range, the influence of outliers is reduced, and the model's ability to learn from the data is enhanced.
Data fusion techniques play a critical role in integrating information from diverse sources, creating a more comprehensive and reliable dataset for irrigation management. Dempster-Shafer theory, a generalization of probability theory, allows for the expression of both uncertainty and the degree of conflict in evidence, making it suitable for fusing uncertain and conflicting data from heterogeneous sources (Sadiq and Rodriguez, 2004). This is particularly relevant in irrigation systems where data from different sensors may provide slightly different or even contradictory information due to sensor variations or environmental factors. Bayesian inference offers another powerful framework for combining information from multiple sources, updating the probability of a hypothesis as new evidence becomes available. By applying these techniques, data from soil moisture sensors, canopy temperature sensors, weather stations, and other sources can be integrated to provide a holistic understanding of crop water requirements and environmental conditions, leading to more informed and accurate irrigation decisions.
The impact of data quality extends beyond model accuracy to the robustness of machine learning models under varying conditions. Robust models should maintain consistent performance even when faced with data inconsistencies or unexpected situations. Techniques like data augmentation and domain adaptation can enhance model robustness by exposing the model to a wider range of data variations during training. Data augmentation involves generating additional training data by applying transformations or introducing noise to existing data, making the model more resilient to noise and variations in the real-world data. Domain adaptation techniques aim to adapt a model trained on one domain (e.g., a specific crop or geographic location) to perform well on another domain with different data characteristics. This is particularly relevant in irrigation management, where models may need to be applied to different crops, soil types, or climatic conditions.
The choice of data cleaning, preprocessing, and fusion techniques should be carefully considered based on the specific characteristics of the irrigation system and the available data. By selecting and implementing appropriate techniques, the accuracy, reliability, and robustness of machine learning models can be significantly improved, leading to more efficient and sustainable irrigation management practices.
4.2. Scalable and Autonomous Deployment using Containerization Strategies
The transition from data collection and transmission to efficient data processing requires a robust infrastructure capable of handling diverse workloads and data volumes. Containerization technologies, specifically Docker and Kubernetes, offer a promising solution for deploying and scaling data processing and machine learning modules within cloud environments like AWS, Azure, and GCP (Vargas-Rojas et al., 2024; Rosendo et al., 2022; Solayman & Qasha, 2023). Docker provides a standardized way to package applications and their dependencies into self-contained units known as containers, ensuring consistent and reproducible execution across different platforms (Rosendo et al., 2022). Kubernetes, acting as a container orchestrator, manages their deployment, scaling, and networking across a cluster of machines (Rosendo et al., 2022). This combination presents several advantages for automated irrigation management systems.
Firstly, containerization facilitates efficient resource utilization and scalability. By encapsulating applications and their dependencies, containers enable the isolation of resources and prevent conflicts between different modules (Vargas-Rojas et al., 2024; Solayman & Qasha, 2023). This isolation allows for the efficient allocation of resources, such as CPU, memory, and storage, to each container based on its specific needs. Kubernetes further enhances scalability by allowing for the automatic scaling of containers based on real-time demand, ensuring the system can adapt to varying workloads and data volumes, preventing bottlenecks, and ensuring responsiveness to changing conditions (Karamolegkos et al., 2023).
Secondly, containerization promotes portability and reproducibility. By packaging applications and their dependencies into a single unit, containers make it easy to move and deploy them across different cloud environments without the need for environment-specific configurations (Rosendo et al., 2022; Solayman & Qasha, 2023). This portability simplifies the development and deployment process, reducing the time and effort required to set up and manage the system. Additionally, containers ensure reproducibility by providing a consistent execution environment, regardless of the underlying infrastructure. This eliminates variability and ensures that the system will behave consistently across different deployments (Zhou et al., 2023).
Optimizing container orchestration and resource allocation is crucial to minimizing latency and maximizing throughput in real-time data processing pipelines. Techniques like auto-scaling and dynamic resource allocation play a critical role in this context (Hethcoat et al., 2024; Werner and Tai, 2023; Kumar et al., 2024). Auto-scaling automatically adjusts the number of container instances based on real-time demand, ensuring that sufficient resources are available to handle peak workloads while avoiding over-provisioning during periods of low demand (Hethcoat et al., 2024; Kumar et al., 2024). Dynamic resource allocation enables the fine-grained adjustment of resources allocated to each container based on its specific needs and the current workload (Werner and Tai, 2023). This ensures efficient resource allocation and provides each container with the necessary resources to perform its tasks effectively.
Performance monitoring tools, such as Kubernetes Metrics Server and Prometheus, are essential for gaining insights into the performance of containers and the overall system (Hethcoat et al., 2024; Kuity & Peddoju, 2023). These tools provide valuable data on key performance indicators, such as CPU and memory usage, network traffic, and application-specific metrics. By monitoring this data, administrators can identify bottlenecks, optimize resource allocation strategies, and continuously improve system performance (Hethcoat et al., 2024). This data-driven approach ensures that automated irrigation management systems can operate efficiently and reliably.
By integrating containerization technologies with optimization techniques and performance monitoring, automated irrigation management systems achieve the scalability, autonomy, and efficiency required for effective real-time data processing and decision-making. This approach facilitates a seamless and responsive system that can adapt to changing conditions and contribute to the overall goal of optimizing water resource management and increasing agricultural productivity.

4.3. Deploying ML Models for Data Processing
Transitioning from data collection, preprocessing, and transmission, the deployment of machine learning (ML) models marks a pivotal stage in the automated irrigation management pipeline. This stage entails utilizing cloud platforms to facilitate real-time data processing and inference, enabling data-driven decision-making for optimal irrigation management and ultimately contributing to fully autonomous, scalable irrigation management.
Several architectures and frameworks exist for deploying ML models on cloud platforms, each offering unique advantages and catering to different requirements. TensorFlow Serving, for instance, provides a high-performance system specifically designed for serving TensorFlow models (Abadi et al., 2016). This framework enables efficient and scalable inference, making it suitable for real-time applications where low latency and high throughput are crucial. For instance, in a large-scale irrigation system with numerous sensors generating data continuously, TensorFlow Serving can efficiently handle the high volume of inference requests and provide timely predictions for irrigation scheduling. Similarly, Apache MXNet Model Server offers a flexible and efficient solution for deploying models trained with MXNet, supporting a wide range of deep learning models and inference backends (MXNet Developers, 2015). This versatility makes it suitable for complex irrigation systems that may utilize different types of ML models for various tasks, such as predicting crop water requirements, detecting plant stress, or forecasting weather conditions. ONNX Runtime, on the other hand, provides a cross-platform inference engine compatible with various ML frameworks, including PyTorch, TensorFlow, and MXNet (Microsoft, 2017). This versatility enables the deployment of models in diverse environments, facilitating interoperability and reducing the need for model conversion. For example, an irrigation system that uses models trained in different frameworks can utilize ONNX Runtime to deploy them on a single platform without the need for time-consuming and error-prone model conversion processes.
Choosing the appropriate architecture or framework depends on several factors, including the specific ML framework used for model training, the desired level of performance and scalability, and the need for cross-platform compatibility. For instance, if the primary concern is low latency and high throughput for real-time inference, TensorFlow Serving might be the optimal choice for TensorFlow models. However, if flexibility and support for various deep learning models are required, Apache MXNet Model Server could be more suitable. In cases where cross-platform compatibility is essential, ONNX Runtime offers a versatile solution.
Once the ML model is deployed, optimizing its performance and resource utilization becomes crucial for ensuring the efficiency of integrated end-to-end automated irrigation systems. Model compression techniques, such as pruning and quantization, offer effective methods for reducing the size and computational requirements of ML models without compromising accuracy (Premkumar & Sigappi, 2022). Pruning involves eliminating unnecessary connections or neurons from the model, effectively streamlining its structure and reducing computational complexity. This can be particularly beneficial for deep learning models, which often have a large number of parameters and can be prone to overfitting. By removing redundant or less important connections, pruning can improve modelgeneralizability and reduce inference time. Quantization, on the other hand, involves reducing the precision of model parameters, typically from 32-bit floating-point numbers to lower-precision formats such as 8-bit integers. This reduction in precision leads to smaller model sizes and faster inference speeds, making it particularly beneficial for resource-constrained environments or real-time applications. For instance, in edge computing scenarios where ML models are deployed on devices with limited computational resources, quantization can enable efficient inference without sacrificing accuracy.
Furthermore, hardware acceleration through the utilization of GPUs or TPUs can significantly enhance model performance by leveraging specialized hardware designed for parallel processing (Premkumar & Sigappi, 2022). GPUs, with their massive parallelism and high memory bandwidth, excel at accelerating matrix operations and convolutions, which are fundamental computations in many deep learning models. This acceleration can significantly reduce inference time and enable real-time processing of sensor data for timely irrigation decisions. TPUs, specifically designed for deep learning workloads, offer even greater performance and energy efficiency for specific model architectures. These hardware accelerators can drastically reduce inference time, enabling near real-time decision-making and enhancing the responsiveness of automated irrigation systems. For example, in a scenario where immediate response to changing weather conditions or soil moisture levels is critical, hardware acceleration can ensure that irrigation decisions are made and executed promptly.
In addition to model compression and hardware acceleration, distributed training techniques play a crucial role in optimizing the training process for large-scale ML models. Techniques such as Horovod and BytePS enable the distribution of training across multiple machines, effectively parallelizing the process and reducing training time (Premkumar & Sigappi, 2022). This is particularly beneficial for complex models with a large number of parameters or when dealing with large datasets. By leveraging distributed training, irrigation management systems can train more sophisticated models and improve their predictive capabilities, leading to more accurate and efficient irrigation decisions. For instance, a system that utilizes a deep learning model with millions of parameters can benefit from distributed training to reduce training time from days to hours, enabling faster model iteration and improvement.
Integrating the deployed ML models with other components of the automated irrigation management pipeline is essential for achieving a fully autonomous and cohesive system and addressing the need for seamless integration across the automated irrigation management system. Standardized protocols, such as MQTT and CoAP, provide lightweight and efficient communication channels for exchanging data between these components (Poojara et al., 2023; Jimenez et al., 2020a; Gour et al., 2023). MQTT, with its publish-subscribe architecture, enables real-time data streaming and event-driven communication, making it suitable for transmitting sensor data, control signals, and inference results (Raikar & M, 2023). This enables the ML model to receive real-time updates on soil moisture, weather conditions, and plant health, allowing for dynamic adjustments to irrigation schedules based on the latest data. CoAP, designed for constrained devices and low-power networks, offers a web-transfer protocol for resource-constrained environments, enabling efficient communication between sensors, actuators, and the ML models (Raikar & M, 2023). This is particularly relevant in situations where sensors or actuators have limited processing power or battery life, as CoAP minimizes communication overhead and energy consumption. Additionally, RESTful APIs provide a standardized interface for accessing and controlling the ML models, enabling seamless integration with other software components and facilitating system management and monitoring (Wang et al., 2022). This allows for easy integration with existing farm management systems or third-party applications, creating a unified platform for comprehensive irrigation management.4.4. Online Learning in the Cloud
The complexities of real-time data processing in irrigation management necessitate the exploration of advanced techniques to continuously learn and adapt to the dynamic nature of agricultural environments. Online learning algorithms offer a promising solution, enabling the continuous update and improvement of machine learning models based on incoming real-time data. This adaptability is crucial for addressing the challenges of changing environmental conditions, such as weather patterns and crop growth stages, and optimizing irrigation decision-making to enhance water usage efficiency and crop productivity.
Several online learning algorithms have demonstrated potential for real-time data processing and model adaptation in the context of irrigation management. Stochastic Gradient Descent (SGD) facilitates the incremental update of model parameters with each new data point, allowing for efficient adaptation to changing data distributions (Bottou, 2010). This incremental learning process ensures that the model remains responsive to the latest conditions, minimizing the risk of outdated predictions and improving the accuracy of irrigation decisions. Passive-Aggressive algorithms, on the other hand, adjust model parameters only when a misclassification occurs, providing a computationally efficient approach for handling large data streams (Crammer et al., 2006). These algorithms offer a robust approach to handling noisy data, a common challenge in real-world sensor readings, by making small adjustments only when the model's prediction deviates significantly from the actual value (Fei et al., 2019). Online Random Forests extend the concept of random forests to the online setting, enabling the incremental construction and update of decision trees as new data arrives (Saffari et al., 2009). The continuous evolution of the ensemble ensures that the model remains relevant to the changing environment, capturing intricate relationships between variables and leading to more informed irrigation decisions.
Research in various domains highlights the importance of online learning for real-time data stream analytics. Snyder et al. (2020) explored the application of online learning techniques for identifying relevant tweets in real-time, improving situational awareness for first responders. The proposed interactive learning framework allows users to continuously label the relevance of incoming tweets, enabling the real-time refinement of the underlying machine learning model. This user-guided approach aligns well with the dynamic nature of irrigation management, where models need to continuously adjust to varying environmental conditions and crop water requirements. Similarly, research in the field of cyber-physical systems (CPS) underscores the need for online learning algorithms to effectively extract insights and knowledge from continuously generated data streams (Fei et al., 2019). These capabilities are crucial for enabling feedback loops between physical processes and cyber elements, facilitating the integration and optimization of CPS in irrigation management systems.
To implement online learning in cloud-based irrigation management systems, various architectures and frameworks can be considered. Apache Spark Streaming, Apache Flink, and AWS Kinesis provide scalable and fault-tolerant platforms for processing real-time data streams, allowing for the development of online learning pipelines that continuously ingest and analyze data to update machine learning models (Zaharia et al., 2012; Carbone et al., 2015; Amazon Web Services, 2023). These frameworks leverage serverless computing paradigms, automatically scaling resources based on the volume and velocity of incoming data, ensuring efficient resource utilization and responsiveness to fluctuations in demand (Fei et al., 2019).
Effectively managing the exploration-exploitation trade-off is crucial for optimizing online learning in irrigation management. Techniques such as Multi-armed bandits (Sutton & Barto, 2018), Bayesian optimization (Shahriari et al., 2016), and Reinforcement Learning (RL) (Sutton & Barto, 2018) can be employed to balance the allocation of resources between exploring new irrigation strategies and exploiting the current best-performing approaches. These techniques enable the identification of optimal irrigation policies, adapting to changing environmental conditions and maximizing long-term rewards.
In conclusion, online learning techniques, coupled with scalable cloud-based architectures, offer a powerful solution for real-time data processing and continuous adaptation in irrigation management systems. By leveraging algorithms like SGD, Passive-Aggressive, and Online Random Forests, along with stream processing frameworks like Apache Spark Streaming, Apache Flink, and AWS Kinesis, irrigation management systems can effectively handle the complexities of real-time data, optimize water usage, and enhance crop productivity in the face of dynamic environmental conditions.

5. GENERATING AND APPLYING IRRIGATION INSIGHTS 
5.1. Real-Time Generation of Actionable Irrigation Insights
•	Advanced predictive models, such as deep learning (e.g., LSTM, CNN) and ensemble methods (e.g., Random Forests), for precise, site-specific irrigation recommendations
•	Integration of IoT sensor data (e.g., soil moisture probes, weather stations) and cloud-based data sources (e.g., weather forecasts, satellite imagery) using data fusion techniques (e.g., Kalman filtering) to enhance insight accuracy and resolution
•	Strategies for handling data heterogeneity, uncertainty, and quality issues in real-time insight generation, such as data preprocessing and outlier detection
•	Techniques for reducing computational complexity and latency, such as edge computing (e.g., fog computing), model compression (e.g., quantization), and hardware accelerators (e.g., GPUs)
5.2. Automated Application of Irrigation Insights
•	Architectures and protocols for seamless integration of ML-generated insights with IoT-enabled irrigation control systems, such as MQTT and CoAP for lightweight, real-time communication
•	Analysis of industry-leading products and services, such as smart irrigation controllers (e.g., Rachio) and cloud-based irrigation management platforms (e.g., CropX)
•	Strategies for ensuring reliability, security, and scalability of automated insight application, such as redundant communication channels and secure edge-to-cloud architectures
•	Case studies of successful implementations of closed-loop, autonomous irrigation systems in research and commercial settings, highlighting technologies used and benefits achieved

6. INTEGRATION, INTEROPERABILITY, AND STANDARDIZATION 
6.1. Interoperability and Standardization
•	Importance of interoperability and standardization in enabling seamless integration of automated irrigation components
•	Overview of existing and emerging standards for IoT devices, communication protocols, and data formats in precision agriculture (e.g., ISOBUS, agroXML, SensorML)
•	Role of standardization bodies and industry consortia in promoting interoperability (e.g., AgGateway, Open Ag Data Alliance, Agricultural Industry Electronics Foundation)
•	Challenges in adopting and implementing standards across diverse hardware and software platforms
•	Strategies for encouraging widespread adoption of standards and best practices for interoperability in automated irrigation systems
6.2. Integration with Existing Irrigation Infrastructure
•	Challenges and strategies for retrofitting legacy irrigation systems with IoT sensors, actuators, and communication devices
•	Hardware compatibility issues and solutions (e.g., adapters, modular designs)
•	Software and firmware updates to enable integration with automated decision-making systems
•	Data integration and normalization techniques for merging legacy and new data sources
•	Economic and practical considerations for transitioning from manual to automated irrigation management
•	Cost-benefit analysis of upgrading existing infrastructure vs. implementing new systems
•	Phased implementation approaches to minimize disruption and optimize resource allocation
•	Training and support requirements for farmers and irrigation managers adopting automated systems
•	Case studies and real-world examples of successful integration of automated irrigation with existing infrastructure
6.3. Integration with Other Precision Agriculture Technologies
•	Synergies between automated irrigation and complementary technologies
•	Remote sensing (satellite, UAV, and ground-based) for crop monitoring and evapotranspiration estimation
•	Soil moisture sensors and weather stations for real-time, localized data collection
•	Variable rate application systems for precise irrigation delivery based on crop requirements
•	Yield mapping and analytics for assessing the impact of automated irrigation on crop productivity
•	Architectures and frameworks for integrating diverse data sources and technologies into a unified precision agriculture ecosystem
•	Edge computing and fog computing paradigms for real-time data processing and decision-making
•	Cloud-based platforms for data storage, analysis, and visualization
•	API-driven approaches for modular integration of third-party services and applications
•	Challenges and solutions for ensuring data quality, consistency, and security across integrated precision agriculture systems
•	Data cleaning, preprocessing, and harmonization techniques
•	Blockchain and distributed ledger technologies for secure, tamper-proof data sharing and traceability
•	Access control and authentication mechanisms for protecting sensitive data and resources
•	Future trends and research directions in the integration of automated irrigation with advanced precision agriculture technologies (e.g., AI-driven crop modeling, robotics, and autonomous vehicles)
6.4. Cybersecurity Considerations for Integrated Automated Irrigation Systems
•	Unique security risks and vulnerabilities associated with IoT-based automated irrigation systems
•	Potential for unauthorized access, data tampering, and system manipulation
•	Implications of security breaches for crop health, water resource management, and farm productivity
•	Best practices and strategies for securing automated irrigation systems
•	Secure device provisioning and authentication (e.g., hardware security modules, certificates)
•	Encryption and secure communication protocols (e.g., TLS, DTLS)
•	Firmware and software updates to address emerging security threats
•	Network segmentation and access control to limit the impact of breaches
•	Role of cybersecurity standards and frameworks in guiding the development and deployment of secure automated irrigation systems (e.g., NIST CSF, IEC 62443)
•	Importance of user awareness, training, and incident response planning in maintaining the security of integrated automated irrigation systems

7. MONITORING AND ENSURING SYSTEM RELIABILITY
7.1. Resilience and Fault Tolerance in Automated Irrigation Systems
•	Strategies for ensuring robustness and reliability in the face of failures, disruptions, or unexpected events
•	Redundancy: Implementing redundant components, such as duplicate sensors (e.g., soil moisture sensors, weather stations), controllers (e.g., PLCs, microcontrollers), and communication channels (e.g., cellular, satellite, LoRaWAN) to maintain system functionality during component failures
•	Failover mechanisms: Designing seamless failover mechanisms that automatically switch to backup components or systems in case of primary system failure, such as hot-standby controllers or multi-path communication protocols (e.g., mesh networks, software-defined networking)
•	Self-healing capabilities: Incorporating AI-driven self-healing mechanisms that can detect, diagnose, and recover from faults without human intervention, using techniques like reinforcement learning, Bayesian networks, or self-organizing maps
•	The role of distributed architectures and edge computing in enhancing system resilience
•	Decentralizing critical functions and data processing to minimize the impact of single points of failure, using fog computing or multi-agent systems
•	Leveraging edge computing to enable localized decision-making and control, reducing dependence on cloud connectivity and improving response times, using technologies like Raspberry Pi, NVIDIA Jetson, or Intel NUC
•	Anomaly detection and predictive maintenance using AI techniques
•	Employing unsupervised learning algorithms (e.g., autoencoders, clustering) to detect anomalies in sensor data, system performance, and water usage patterns
•	Developing predictive maintenance models using techniques like long short-term memory (LSTM) networks, convolutional neural networks (CNNs), or gradient boosting machines (GBMs) to anticipate and prevent potential system failures based on historical data and real-time monitoring
7.2. Advanced Monitoring Techniques for Automated Irrigation Systems
•	Remote monitoring using IoT-enabled sensors and computer vision
•	Deploying a heterogeneous network of IoT sensors to collect real-time data on soil moisture (e.g., capacitive, tensiometric), temperature (e.g., thermocouples, thermistors), humidity (e.g., capacitive, resistive), and plant health (e.g., sap flow, leaf wetness)
•	Integrating high-resolution cameras (e.g., multispectral, hyperspectral) and computer vision algorithms for visual monitoring of crop growth, disease detection (e.g., using deep learning-based object detection and segmentation), and irrigation system performance (e.g., leak detection, sprinkler uniformity)
•	Transmitting sensor and camera data to cloud-based platforms (e.g., AWS IoT, Google Cloud IoT, Microsoft Azure IoT) for remote access and analysis using protocols like MQTT, CoAP, or AMQP
•	Innovative approaches for real-time system health assessment
•	Developing novel algorithms and metrics for evaluating the health and performance of automated irrigation systems, such as entropy-based measures, network resilience indices, or multi-criteria decision analysis (MCDA) frameworks
•	Combining data from multiple sources (e.g., sensors, weather forecasts, satellite imagery) using data fusion techniques (e.g., Kalman filters, Dempster-Shafer theory) to create a comprehensive view of system health
•	Employing advanced data visualization techniques (e.g., interactive dashboards, augmented reality) to present system health information in an intuitive and actionable format
7.3. Closed-Loop Control and Feedback Mechanisms
•	Exploring the concept of closed-loop control in autonomous irrigation systems
•	Implementing feedback loops that continuously monitor system performance and adjust irrigation schedules based on real-time data, using control techniques like proportional-integral-derivative (PID), model predictive control (MPC), or fuzzy logic control (FLC)
•	Integrating machine learning algorithms (e.g., reinforcement learning, genetic algorithms) to optimize closed-loop control strategies over time, adapting to changing environmental conditions and crop requirements
•	Designing effective feedback mechanisms for user interaction and system optimization
•	Providing user-friendly interfaces (e.g., mobile apps, web dashboards) for farmers to input preferences, constraints, and expert knowledge into the automated irrigation system, using techniques like participatory design or user-centered design
•	Incorporating user feedback and domain expertise to refine irrigation strategies and improve system performance
8. CASE STUDIES AND REAL-WORLD IMPLEMENTATIONS OF FULLY AUTONOMOUS IRRIGATION SYSTEMS
8.1. Fully Autonomous Irrigation Systems in Diverse Agricultural Settings
•	Row Crops: maize, wheat, soybean with real-time soil moisture monitoring and weather-based irrigation scheduling for fully automated precision irrigation
•	Orchards: citrus, apple, almond with plant health monitoring and precision water application for fully autonomous orchard management
•	Greenhouses: tomato, lettuce, herbs with automated drip irrigation and climate control integration for fully automated greenhouse operations
•	Urban Farming: rooftop gardens, vertical farms with IoT-enabled hydroponic systems and remote management for fully autonomous urban crop production
8.2. Integration of Advanced System Components for End-to-End Automation
•	Wireless sensor networks: soil moisture probes, weather stations, plant health monitoring cameras with low-power, long-range communication for fully automated data acquisition
•	Secure data transmission: LoRaWAN, NB-IoT, 5G, satellite communication for reliable, real-time data transfer from field to cloud in fully autonomous irrigation systems
•	Intelligent data processing: edge computing for local data filtering, cloud platforms for scalable storage and analysis, machine learning algorithms for predictive insights in fully automated irrigation management
•	Autonomous decision-making: advanced irrigation scheduling algorithms, precise valve control, closed-loop feedback systems for optimal water management in fully autonomous irrigation systems
8.3. Quantitative Performance Evaluation of Fully Automated Irrigation Systems
•	Water use efficiency: percent reduction in water consumption compared to conventional methods, improved water productivity (yield per unit of water) achieved through fully autonomous irrigation
•	Crop yield and quality improvements: percent increase in yield, enhanced crop uniformity, improved nutritional content attributed to fully automated precision irrigation
•	Labor and energy savings: quantified reduction in labor hours for irrigation management, decreased energy consumption for pumping due to optimized scheduling in fully autonomous systems
•	Economic viability: detailed return on investment analysis, payback period calculations, comprehensive cost-benefit analysis for fully autonomous irrigation management systems
8.4. Lessons Learned and Challenges Encountered in Deploying Autonomous Irrigation Systems
•	Technical challenges and solutions: ensuring reliable data transmission in remote locations, addressing interoperability issues between diverse system components, optimizing power consumption for extended battery life, adapting algorithms to local soil and weather conditions in fully autonomous irrigation systems
•	Operational and logistical hurdles: streamlining installation and maintenance procedures, providing effective user training, seamlessly integrating with existing farm management practices and legacy systems for fully automated irrigation management
•	Regulatory and socio-economic considerations: navigating complex water use regulations, addressing data privacy and security concerns, ensuring equitable access and affordability for smallholder farmers adopting fully autonomous irrigation technologies
8.5. Best Practices and Recommendations for Successful Implementation
•	Designing scalable, modular, and adaptable autonomous irrigation systems to accommodate future growth and changing requirements for fully automated water management
•	Prioritizing user-centered design principles and actively engaging stakeholders throughout the development and deployment process of fully autonomous irrigation solutions
•	Adopting open standards and communication protocols to enable seamless integration of system components and interoperability with third-party platforms in fully automated irrigation setups
•	Implementing robust data validation, filtering, and quality control mechanisms to ensure data integrity and reliability for decision-making in fully autonomous irrigation systems
•	Establishing clear data governance policies and security frameworks to protect sensitive information and maintain user trust in fully automated irrigation management
•	Developing intuitive user interfaces and decision support tools to facilitate easy adoption and effective use of fully autonomous irrigation systems
•	Collaborating with local extension services, agribusinesses, and technology providers for knowledge transfer, technical support, and continuous improvement of fully automated irrigation solutions
8.6. Synthesis of Case Studies and Implications for Autonomous Irrigation Adoption
•	Cross-case analysis of key performance indicators and critical success factors for fully autonomous irrigation scheduling systems in various contexts
•	Identification of common themes, challenges, and innovative solutions across diverse implementations of end-to-end fully automated irrigation management
•	Assessment of the potential for replicability and scaling of successful fully autonomous irrigation projects in different regions and farming systems
•	Implications for future research priorities, technology development roadmaps, and policy interventions to support widespread adoption of fully autonomous irrigation technologies

CONCLUSION/FUTURE DIRECTIONS AND UNANSWERED QUESTIONS
•	Summarize the key insights gained from the question-driven review, emphasizing how each section contributes to the overarching goal of achieving real-time, end-to-end automation in irrigation management
•	Based on the questions addressed, propose new research directions and unanswered questions
•	Identify key research gaps and propose concrete research questions and hypotheses for advancing the field of real-time, automated irrigation management
•	Highlight the need for collaborative research efforts across disciplines, such as computer science, agricultural engineering, and environmental science, to address the complex challenges of automated irrigation systems
•	Emphasize the need for further innovation and exploration in real-time, automated irrigation systems




</previous_sections>

</documents>
<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper. 

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: stated in: <subsection_title>
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>


- DOI: https://doi.org/10.1016/j.compag.2017.09.015
  analysis: '>'
  authors:
  - Jess Martn Talavera
  - Luis Eduardo Tobn
  - Jairo Alejandro Gmez
  - María Culman
  - Juan Aranda
  - Diana Teresa Parra
  - Luis Alfredo Quiroz
  - Adolfo Hoyos
  - Luis Ernesto Garreta
  citation_count: 353
  full_citation: '>'
  full_text: '>

    Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Planning 3. Conduction
    4. Results 5. Recent works 6. Discussion 7. Conclusions Acknowledgements References
    Show full outline Cited by (388) Figures (13) Show 7 more figures Tables (5) Table
    1 Table 2 Table 3 Table 4 Table 5 Computers and Electronics in Agriculture Volume
    142, Part A, November 2017, Pages 283-297 Review Review of IoT applications in
    agro-industrial and environmental fields Author links open overlay panel Jesús
    Martín Talavera a, Luis Eduardo Tobón b, Jairo Alejandro Gómez b, María Alejandra
    Culman a, Juan Manuel Aranda c, Diana Teresa Parra a, Luis Alfredo Quiroz b, Adolfo
    Hoyos b, Luis Ernesto Garreta b Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.compag.2017.09.015
    Get rights and content Highlights • Systematic literature review of IoT applications
    in agro-industry and environment during 2006–2016. • Clustering of IoT applications
    into four domains: monitoring, control, prediction, and logistics. • Visualization
    of key technologies used to develop the IoT applications. • Discussion of trends
    and open challenges. • Proposal of an IoT architecture for agro-industrial and
    environmental applications based on the research findings. Abstract This paper
    reviews agro-industrial and environmental applications that are using Internet
    of Things (IoT). It is motivated by the need to identify application areas, trends,
    architectures and open challenges in these two fields. The underlying survey was
    developed following a systematic literature review using academic documents written
    in English and published in peer-reviewed venues from 2006 to 2016. Selected references
    were clustered into four application domains corresponding to: monitoring, control,
    logistics, and prediction. Implementation-specific details from each selected
    reference were compiled to create usage distributions of sensors, actuators, power
    sources, edge computing modules, communication technologies, storage solutions,
    and visualization strategies. Finally, the results from the review were compiled
    into an IoT architecture that represents a wide range of current solutions in
    agro-industrial and environmental fields. Previous article in issue Next article
    in issue Keywords Internet of thingsIoTAgro-industryEnvironmental monitoringSystematic
    literature review 1. Introduction The widespread of Internet in the last two decades
    brought countless benefits to citizens and organizations around the world. Arguably
    the most important benefit was the ability to consume and produce data and services
    in real time. Recently, the Internet of Things is promising to bring the same
    benefits to everyday objects, giving us a way to extend our perception and our
    ability to modify the environment around us. In this context, agro-industrial
    and environmental fields are ideal candidates for the deployment of IoT solutions
    because they occur in wide areas that need to be continuously monitored and controlled.
    At the same time, IoT opens new opportunities beyond ground floor automation when
    the collected data are used to feed machine learning algorithms to provide predictions
    (Saville et al., 2015), easing decision planning and decision making for owners,
    managers, and policy makers. IoT can be used at different levels in the agro-industrial
    production chain (Medela et al., 2013). It can help to evaluate field variables
    such as soil state, atmospheric conditions, and biomass of plants or animals.
    It can also be used to assess and control variables such as temperature, humidity,
    vibration, and shock during the product transport (Pang et al., 2015). It can
    be used to monitor and predict the product state and its demand on shelves or
    inside refrigerators. In addition, it can provide information to the final user/consumer
    about the origin and properties of the product. The IoT applied to the agro-industry
    can contribute to create an informed, connected, developed and adaptable rural
    community. Under the IoT paradigm, low-cost electronic devices can improve human
    interaction with the physical world, and the computing power and software available
    on the Internet can provide valuable analytics. In summary, IoT can be an important
    tool in the years to come for people interacting within an agro-industrial system:
    suppliers, farmers, technicians, distributors, business men, consumers, and government
    representatives. IoT can be incorporated into environmental applications to produce
    dense and real-time maps of air and water pollution, noise level (Torres-Ruiz
    et al., 2016, Hachem et al., 2015), temperature, and harmful radiation among others.
    It can be used to collect and store environmental records, check the compliance
    of environmental variables with local policies, trigger alerts, or send recommendation
    messages to citizens and authorities (Liu et al., 2013). Once the data reach the
    cloud, governments can feed predictive models to forecast environmental variables,
    and identify and track pollution sources over time and space, ultimately leading
    to faster and better decisions to ensure a safe and healthy environment for all
    citizens. Based on the potential of IoT applications in agro-industrial and environmental
    fields described in the previous paragraphs, this paper aims to identify the current
    state of solutions in these fields, as well as the trends, architectures, technologies
    and open challenges. This paper uses a Systematic Literature Review (SLR) based
    on a methodology proposed by Kitchenham and Charters (2007), in order to make
    it unbiased in terms of information selection, processing, and presentation of
    results. The paper is structured as follows. Sections 2 Planning, 3 Conduction,
    4 Results describe the stages of planning, conduction, and results of the SLR.
    Section 5 outlines some recent works that were published online after the SLR
    was concluded. Section 6 includes a discussion of the obtained results, and Section
    7 presents the conclusions from this study. 2. Planning During this stage of the
    SLR, the protocol was defined. This included: research questions, search strategies,
    selection criteria, data mining and synthesis methodologies. For this study, the
    two research questions considered were: 1. What are the main technological solutions
    of the Internet of Things in agro-industrial and environmental fields? 2. Which
    infrastructure and technology are using the main solutions of IoT in agro-industrial
    and environmental fields? To collect information, authors performed an Internet
    search using various academic digital libraries and search engines. Obtained results
    were manually compiled in order to select the best information sources to answer
    the two research questions. After analyzing the results, digital libraries and
    search engines described in Table 1 were chosen based on their scientific and
    technical content, as well as their close relationship to areas of knowledge associated
    with the objective of this paper. Table 1. Information sources used for the search
    phase. Source Type URL IEEE Xplore Digital Library http://ieeexplore.ieee.org/Xplore/home.jsp
    Science Direct Digital Library http://www.sciencedirect.com/ ACM Digital Library
    Digital Library http://dl.acm.org/dl.cfm Citeseer library Digital Library http://citeseer.ist.psu.edu/advanced_search
    Sensors Digital Library http://www.mdpi.com/journal/sensors Scopus Search Engine
    http://www.scopus.com/ Microsoft Academic Search Search Engine http://academic.research.microsoft.com/
    Microsoft Academic Search Engine https://academic.microsoft.com/ Google Scholar
    Search Engine https://scholar.google.com/ The next step was to define search terms
    and a consistent procedure to seek scientific and technical documentation in the
    digital libraries and search engines. To define the search terms, a set of keywords
    was selected from the research questions to create two groups of words which are
    shown in Table 2. Each group contained consolidated expressions with synonyms
    or terms with related meaning. Group 1 included words associated with the Internet
    of Things, while Group 2 contained a set of terms related to the agro-industry
    and environment. Logical operators supported by the advanced search of digital
    libraries were used to construct search strings, based on the two research questions,
    combining terms from Groups 1 and 2 of Table 2. The general structure of the search
    queries that were applied to the information sources is presented in Table 3.
    Table 2. Words used for the search query. Group 1: Internet of Things, Web of
    Things.  Group 2: Agricultural industry, Agricultural products, Agriculture, Agribusiness,
    Agroindustry, Air pollution, Apiculture, Aquaculture, Product Traceability, Smart
    Agriculture, Greenhouses, Harvesting, Horticulture, Husbandry, Irrigation, Livestock,
    Climate, Feeding, Fertilizers, Forestry, Weather, Animal production, Animal sensing,
    Animal tracking, Animal trade control, Avalanche, Bio-fuel, Biological production,
    Bio-monitoring, Breeding, Cereals, Crop, Dairy, Drones, Drought, Earthquake sensor,
    Environmental monitoring, Equipment status, Farm, Farming, Feed production, Fish,
    Fishery, Flooding, Food chain, Food production, Forecast, Forest fire, Freeze,
    Fruit, Fruit storage, Grassland, Heating, Landslide, Meat, Pest, Plant, Poultry,
    Seed, Vegetable, Waste, Water. Table 3. Algorithm: search query-(Group 1) AND
    (Group 2). TITLE-ABS-KEY (“Internet of Things” OR “Web of Things”) AND (“Agricultural
    industry” OR “Agricultural products” OR agriculture OR agribusiness OR agroindustry
    OR “Air pollution” OR “Apiculture” OR aquaculture OR “Product Traceability” OR
    greenhouses OR harvesting OR horticulture OR husbandry OR irrigation OR livestock
    OR climate OR feeding OR fertilizers OR forestry OR weather OR “Animal production”
    OR “Animal sensing” OR “Animal tracking” OR “Animal trade control” OR avalanche
    OR biofuel OR “Biological production” OR biomonitoring OR breeding OR cereals
    OR crop OR dairy OR drones OR drought OR “Earthquake sensor” OR “Environmental
    monitoring” OR “Equipment status” OR farm OR farming OR “Feed production” OR fish
    OR fishery OR flooding OR “Food chain” OR “Food production” OR forecast OR “Forest
    fire” OR freeze OR fruit OR “Fruit storage” OR grassland OR heating OR landslide
    OR meat OR pest OR plant OR poultry OR seed OR vegetable OR waste OR water) In
    order to ensure the quality of papers, only those that passed the following criteria
    were considered in the reviewing process. • Documents published in peer-reviewed
    conferences, peer-reviewed journals, papers from computer science or engineering
    organizations, patents, or technical reports. • Documents published in English.
    • Documents published between 2006 and 2016 (both years inclusive). If the main
    topic of a given paper was irrelevant or if it was outside the scope of this study,
    it was deleted. Then, a selection criterion was applied in order to reduce the
    number of papers found during the search and to get a small number of high-quality
    sources that could be used to answer the research questions. This involved using
    inclusion criteria (IC) and quality criteria (QC), which were defined in a three-phase
    process. • IC based on abstracts: in this phase, authors discarded papers found
    in the search stage based on the information provided in their abstracts. Papers
    that satisfied the first inclusion criterion were kept for further processing,
    i.e. papers that discussed IoT solutions applied to agro-industry and environment.
    Papers with little relevant information in their abstract were temporarily kept
    in the list and were processed in the next stage. It is important to highlight
    that quality criteria were not considered in this phase. • IC based on full reading:
    in this phase, papers that did not address the search terms shown in Table 2 were
    removed. This means that even though those papers contained the search terms in
    their abstract, they only represented minor aspects of them. • IC based on quality
    analysis: in this phase, a quality analysis was applied to remaining papers and
    those that did not comply any of the following four quality criteria (QC) were
    discarded: – QC1: Does the study present a comprehensive solution of IoT for agro-industry
    or environment? – QC2: Does the paper show details of the infrastructure and/or
    technologies used to implement the proposed solution? – QC3: Does the paper present
    a state of the art or related work? – QC4: Does the paper present an analysis
    of the results? The next stage of the SLR was data mining and synthesis. The goal
    here was to extract the information needed to answer the research questions in
    an objective manner. The information fields extracted for each study are presented
    in Table 4. Table 4. Form used to extract data for each study. Data retrieved
    Description Title Title of the main study Year Publication year of the study Institution
    Name of institution(s) leading the research Country Country that developed the
    research Source Conference, journal, or book containing the main study Solution
    Name of the IoT solution described Domain and subdomain Area of agro-industry
    or environment where IoT was applied Architecture model Description of the architecture
    used, its scope and limitation Sensors Information about sensor type and sensor
    count per node in the solution Power source Mechanisms used to power IoT devices
    Edge computing Information about computing platforms, hardware architecture, the
    number of nodes, topology (homogeneous vs. heterogeneous). Connectivity and communication
    Technologies used for transmitting data Data storage Techniques used for storing
    data (locally, distributed, and cloud-based), as well as data access methodologies
    Data processing and visualization Algorithms and methodologies for processing
    and analyzing data (data aggregation, data fusion, machine learning, pattern recognition,
    big data), and models to visualize them Deployment scenario Characteristics of
    the deployment site for the IoT solution 3. Conduction The protocol described
    in the previous section was used to search, select and evaluate preliminary papers.
    For the search process, the query defined in Table 3 was passed to information
    sources given in Table 1. The search was limited to title, abstract and keywords.
    Fig. 1 illustrates the conduction process discriminated by the academic database
    and search engine used, highlighting the key steps followed to select relevant
    studies for this review. Initially, 3578 studies were recovered from electronic
    databases. Firstly, duplicates were excluded, i.e. studies available in more than
    one database, eliminating 849 copies. Out of the 2729 remaining studies, 2652
    were initially screened based on inclusion and exclusion criteria applied to the
    title, abstract, and keywords. These papers were marked to be downloaded, and
    references that could not be retrieved were discarded. Afterward, these studies
    were evaluated using quality criteria obtaining 720 studies. These studies were
    used to extract the data defined in Table 4. Finally, only 72 main studies were
    selected based on their quality for the final conduction phase and used to extract
    results presented in the next section. Download : Download high-res image (236KB)
    Download : Download full-size image Fig. 1. Process followed in the SLR to select
    main studies. It is worth to note that more than 90% of included papers were retrieved
    from two sources: IEEExplore (76.4%) and Scopus (13.9%). In contrast, the least
    effective sources of information were Microsoft Academic Search and Microsoft
    Academic. They retrieved 668 papers during the first stage of the conduction phase
    (representing 25.2% of all retrieved papers, and only behind IEEExplore with 45%).
    However, only 3.1% of them were included for the next reviewing phase, a number
    well below the 39.8% of papers included from IEEExplore. These facts can be explained
    because IEEExplore and Scopus have complete and usable advanced search systems
    and they have been operating continuously unlike Microsoft’s counterpart (Sinha
    et al., 2015a). Fig. 2 enumerates the number of primary studies classified by
    publication year. It can be seen that most of the selected papers were published
    between 2012 and 2016. It should be highlighted that the small number of papers
    shown in 2016 can be explained because the initial search was made in April of
    that year. Download : Download high-res image (127KB) Download : Download full-size
    image Fig. 2. Distribution of papers selected by publication year. Fig. 3 summarizes
    the country of origin of selected papers. Every continent of the world is represented
    by at least one research work. China is the country that contributed with the
    largest number of papers. Asia has more than half of contributions and America
    has less than ten percent of them, showing a huge potential for this continent.
    Download : Download high-res image (159KB) Download : Download full-size image
    Fig. 3. Distribution of papers selected by country. 4. Results This phase presents
    results of the SLR in order to answer the two research questions based on the
    information extracted from main studies selected. 4.1. Answer to the first research
    question To identify the main technological solutions of IoT in agro-industry
    and environmental fields, studies were grouped into four technological domains,
    corresponding to: (1) monitoring, (2) control, (3) prediction and (4) logistics.
    Results are summarized in Table 5 and illustrated in Fig. 4. From this figure,
    it can be seen that most of the selected studies were focused on monitoring (62%),
    followed by control (25%), logistics (7%), and prediction (6%). Table 5. Clustering
    of main studies by application domain. Domain Main study Monitoring (Hussain et
    al., 2006, Lu et al., 2010, Pokrić et al., 2014, Postolache et al., 2014, Sawant
    et al., 2014, Ehsan et al., 2012, Langendoen et al., 2006, Chen et al., 2014,
    Liu et al., 2013, Islam et al., 2014, Kuroda et al., 2015, Fourati et al., 2014,
    Kar and Kar, 2015, Chen et al., 2015, Medela et al., 2013, Zou, 2014, Diedrichs
    et al., 2014, Mittal et al., 2012, De La Concepcion et al., 2014, Jardak et al.,
    2009, Vo et al., 2013, Tarange et al., 2015, Kodali et al., 2014, Sinha et al.,
    2015b, Eom et al., 2014, Sun et al., 2012, Hakala et al., 2008, Jain et al., 2008,
    Watthanawisuth et al., 2009, Nguyen et al., 2015, Lee et al., 2013, Ma et al.,
    2012, Jayaraman et al., 2015a, Jayaraman et al., 2015b, Soontranon et al., 2014,
    Hashim et al., 2015, Zhao and Zhu, 2015, Mathurkar et al., 2014, Kiyoshi et al.,
    2008, Postolache et al., 2013, Mafuta et al., 2012, Feng et al., 2012, Xijun et
    al., 2009, Gutiérrez et al., 2014, Sarangi et al., 2016, Fang et al., 2014)  Control
    (Yoo et al., 2007, Kanoun et al., 2014, Sales et al., 2015, Chavez-Burbano et
    al., 2014, Ryu et al., 2015, Pahuja et al., 2013, Xu et al., 2015, Ye et al.,
    2013, Jiao et al., 2014, Jiber et al., 2011, Shuwen and Changli, 2015, Culibrina
    and Dadios, 2015, Kaewmard and Saiyod, 2014, Li et al., 2014, Tao et al., 2014,
    Smarsly, 2013, Roy et al., 2015)  Logistics (Pang et al., 2015, Li et al., 2013,
    Jiang and Zhang, 2013, Charoenpanyasak et al., 2011, Marino et al., 2010)  Prediction
    (Khandani and Kalantari, 2009, Saville et al., 2015, Lee et al., 2012, Luan et
    al., 2015) Download : Download high-res image (66KB) Download : Download full-size
    image Fig. 4. Distribution of papers selected by application domain. Selected
    papers grouped in the monitoring domain dealt with remote sensing of physical
    and environmental parameters gathered in scenarios such as crops and farms using
    a Wireless Sensor Network (WSN). The main goal of this domain was the acquisition
    of information without an operator and its transmission to a server or data center
    for processing and visualization. Integrated monitoring tools made it possible
    to maintain a continuous communication with the deployed WSN, and access stored
    data through the Internet. Hence, smart agriculture based on IoT adds value to
    farmers by helping them to collect relevant data from crops and farms using sensor
    devices. Some IoT setups could display, process and analyze remote data applying
    cloud services in order to provide new insights and recommendations for better
    decision-making. IoT solutions categorized in monitoring domain can be divided
    into three architectural layers (Zou, 2014): (i) a perception layer supported
    by a WSN; (ii) a network layer where the sensor information travels a long distance
    using different protocols and Gateways, and (iii) an application layer that includes
    a web server and a database. Moreover, IoT solutions grouped in this domain are
    interested in monitoring several types of physical variables depending on the
    subdomain to which they belong. Specifically, the following subdomains were identified:
    air monitoring (34.5%), soil monitoring (27.3%), water monitoring (16.4%), plant
    monitoring (10.9%), and others (10.9%) which include areas such as aquaculture
    and animal monitoring. It is worth to highlight that most of the selected studies
    retrieved in this SLR can be categorized in more than one subdomain. For instance,
    the system proposed in Zou (2014) is used for online crop growth monitoring and
    it captures different types of variables such as: temperature, humidity, soil
    moisture, CO2, luminosity, pH of water, and images. Some representative examples
    of IoT applications categorized in the monitoring domain are described below.
    • Air monitoring: this subdomain aimed to provide periodic or continuous measurements,
    evaluating and determining environmental parameters or pollution levels in order
    to prevent negative and damaging effects. It also included the forecasting of
    possible changes in the ecosystem or the biosphere as a whole. For instance, in
    Watthanawisuth et al. (2009) authors described an agricultural IoT solution which
    can be categorized in the air monitoring subdomain. In this solution, authors
    proposed a real-time monitoring system of micro climate based on a WSN. The solution
    included temperature and relative humidity sensors (SHT15) powered by solar panels
    and supported by ZigBee communication technology. Another air monitoring IoT solution
    is GEMS (Lu et al., 2010), which proposed an environmental monitoring system based
    on GPRS technology for monitoring apple orchards. This system was tested on five
    different regions of China over a 2-year period by monitoring variables such as
    relative humidity, temperature, and radiation. • Soil monitoring: papers classified
    in this subdomain such as (Chen et al., 2014, Mafuta et al., 2012) proposed systems
    for monitoring multi-layer soil temperature and moisture in a farmland fields
    using WSN. These systems are supported by communication technologies such as ZigBee,
    GPRS and Internet, where user interaction with the system is handled by a web
    application. • Water monitoring: primary studies categorized in this subdomain
    intend to monitor water pollution or water quality by sensing chemicals, pH, and
    temperature, which can alter the natural state of water. An example of this subdomain
    is presented in Postolache et al. (2013), where authors proposed an IoT solution
    for water quality assessment through the measurement of conductivity, temperature,
    and turbidity. The solution is based on a WSN architecture that combines low-cost
    sensing devices and monitoring of multiple parameters of water quality of shallow
    waters (lakes, estuaries, rivers) in urban areas. Similarly, (Xijun et al., 2009)
    proposed a WSN system for monitoring water level and rainfall in irrigation systems.
    • Plant monitoring: The LOFAR-agro Project (Langendoen et al., 2006) is an example
    of plant or crop monitoring. This project aimed to protect a potato crop against
    phytophthora (a genus of water mold) by monitoring the microclimate (humidity
    and temperature) using a large-scale WSN. The system intended to generate a policy
    to protect the crop against the fungal disease based on the collected data. In
    Fourati et al. (2014), authors propose a Web-based decision support system communicating
    with a WSN for irrigation scheduling in olive fields. For this purpose, authors
    use sensors to measure humidity, solar radiation, temperature, and rain. • Animal
    monitoring: This subdomain referred to animal tracking for both wildlife and animal
    husbandry activities. A research belonging to this subdomain was a delay-tolerant
    WSN for the monitoring and tracking of six horses presented in Ehsan et al. (2012).
    For this purpose, authors developed necklaces that acquired information about
    horses’ position and speed at a given time, and transmitted such logs to fixed
    nodes when they were close to its coverage area. Another example of animal monitoring
    was given by Jain et al. (2008), where an IoT solution was responsible for monitoring
    the behavior and migration patterns of Swamp Deers, obtaining information of the
    animal position and the climate at the same time. Papers selected and grouped
    under the domain of control use remote actuator devices deployed on-site. Unlike
    monitoring domain applications, which handle information in one-way, applications
    categorized in control use a two-way information channel. This means that a new
    level of communication was added, and commands could be sent back to the field.
    In this case, information from the server or data center traveled to a Wireless
    Sensor and Actuator Network (WSAN) in order to control a set of actuator devices
    to modify the state of the process or environment. Commands were sent through
    a human–computer interface or as a result of a decision algorithm supported by
    analytic modules. Actuator devices included valves, pumps, humidifiers, and alarms
    among others. Many of these systems aimed to optimize the usage of water, fertilizers,
    and pesticides based on information provided by weather prediction systems and
    on-site WSN. Solutions in this domain could help farmers to reduce water consumption
    and waste by scheduling irrigation times and quantities according to the state
    of the crop and its growth cycle. Control systems were programmed to be adaptive,
    for instance, switching off sprinkler if rain was detected. Overall, solutions
    with control systems could save money to the farmer and provide at the same time
    valuable insights about the consumption of water, fertilizers, pesticides, and
    electricity. Actuator devices used by IoT solutions grouped in the control domain
    depended heavily on the subdomain to which they belonged. In this paper, the following
    subdomains were considered: irrigation (72.22%), fertilizers (5.56%), pesticides
    (5.56%), illumination (5.56%), and access control (5.56%). During the review,
    it was found that some studies used actuators in the domain of logistics (5.56%).
    Representative examples of IoT applications categorized in the control domain
    are described next. • Irrigation control: A precision irrigation solution based
    on wireless sensor network was proposed by Kanoun et al. (2014). The main challenge
    of that study was to create an automated irrigation system which could reduce
    water waste, saving energy, time, and money. This system was built using three
    nodes based on the TelosB mote: (i) a node to measure soil moisture and soil temperature;
    (ii) a node to measure environmental parameters such as air temperature, air humidity,
    wind speed and brightness; and (iii) a node that was connected to a valve for
    irrigation control. Data were transmitted to a base station for storage and were
    sent to the farmer’s PC to allow him to take action. Another precision irrigation
    IoT system was proposed by Jiao et al. (2014). This included an environmental
    monitoring system for agricultural management, as well as the implementation of
    precision dripping. The system considered an IoT ecosystem divided into three
    layers corresponding to sensing, transmission, and application. A WSN was used
    to perceive environmental information in real time within a tomato greenhouse,
    to later transmit the data to a remote server management system. In Shuwen and
    Changli (2015) researchers described a remote farmland irrigation monitoring solution
    based on ZigBee. The system included a solar-powered irrigation control system
    that also monitored air temperature, humidity and soil temperature. • Fertilizer
    and pesticide control: IoT solutions categorized in this subdomain applied conservation
    practices to improve nutrient usage, efficiency, crop quality, overall yield,
    and economic return while reducing off-site transport of nutrients. In Pahuja
    et al. (2013), authors developed an online micro-climate monitoring and control
    system for greenhouses. The system was supported by a WSN to gather and analyze
    plant-related sensor data to produce actions to control the climate, fertilization,
    irrigation, and pests. • Illumination control: authors in Yoo et al. (2007) described
    an automated agriculture system based on WSN for monitoring greenhouses used to
    grow melons and cabbages. The system monitored the growing process of crops and
    controlled the greenhouse’s environment. Some of the variables measured included
    ambient light, temperature, and humidity. For the greenhouse with melons, the
    system could control the illumination by changing the light state through a relay.
    • Access control: An agricultural intrusion detection system was presented in
    Roy et al. (2015). The proposed system generated alarms in the farmers house and
    sent a text message to the farmer’s mobile phone when an intruder entered the
    crop field. Selected papers categorized in the prediction domain were focused
    on providing knowledge and tools to farmers to support decision making. They had
    specific modules for these tasks in their architecture, and their predicted variables
    were grouped as follows: environmental conditions (42.86%), production estimation
    (42.86%), and crop growth (14.29%). • Environmental conditions: A representative
    example of environmental condition prediction is proposed in Khandani and Kalantari
    (2009), where authors described a design methodology to determine the spatial
    sampling of humidity sensors for the soil within a WSN. They used a historical
    database of dense soil-humidity measurements to determine the behavior of the
    2D correlation that exists between the measurements of nearby sensors. This was
    used later to find the largest spatial sampling that ensured a user-defined variance
    for the estimation on any given point of interest in the space. Authors found
    that the spatial correlation function decays exponentially with the distance between
    sensors. Another example of the prediction of environmental conditions was presented
    in Luan et al. (2015), which described a system that integrates drought monitoring
    and forecasting as well as irrigation prediction using IoT. • Production estimation:
    Authors in Lee et al. (2013) presented an IoT-based agricultural production system
    for stabilizing supply and demand of agricultural products. They achieved this
    goal by sensing environmental variables and by developing a prediction system
    for the growth and yield of crops. In a different application, (Saville et al.,
    2015) introduced a real-time estimation system for fixed-net fishery using ultrasonic
    sensors and supervised learning. • Crop growth: a dynamic analysis of farmlands
    using mobile sensors was presented in Lee et al. (2012). The developed system
    aimed to establish growth-control plans for grapes, and viticulture activities.
    The last domain used to categorize selected studies was logistics. Logistics in
    agriculture refers to the physical flow of entities and related information from
    producer to consumer to satisfy consumer demand. It includes: agricultural production,
    acquisition, transportation, storage, loading and unloading, handling, packaging,
    distribution, and related activities. Some objectives of logistics in agriculture
    include: adding value to agricultural products, saving money in distribution costs,
    improving shipping efficiency, reducing unnecessary losses, and to some extent,
    avoiding risks (Liping, 2012). Primary studies in logistics were further divided
    in: production (55.6%), commerce (22.2%) and transport(22.2%). The next paragraphs
    include representative studies of each subdomain. • Production: in Feng et al.
    (2012) researchers proposed an intelligent system for monitoring an apple orchard
    that implemented suggestions based on data. The system aimed to reduce management
    costs of apple orchards, improve apple quality, and provide detailed, comprehensive
    and accurate electronic information for planting works, pest warnings, and production-quality
    tracking of apples. The system included WSN using Zigbee, GPRS, and IoT providing
    detailed monitoring data of apple growth for agricultural cooperatives, to support
    for decision making in farming. • Commerce: (Li et al., 2013) presented an information
    system for agriculture based on IoT which used a distributed architecture. In
    that study, tracking and tracing of the whole agricultural production process
    were made with distributed IoT servers. Moreover, an information-discovery system
    was designed to implement, capture, standardize, manage, locate, and query business
    data from agricultural production. The system also allowed consumers to query
    information of agricultural products to verify their authenticity and quality.
    • Transport: A representative example of this subdomain is presented in Pang et
    al. (2015), where an IoT architecture was proposed for the food-production and
    commercialization chain. This paper dealt with logistics involved in the transportation
    of melons from Brazil to Sweden in a journey that takes 46 days. Sensor nodes
    measured conditions in the environment including oxygen, carbon dioxide, ethylene,
    temperature, humidity, and mechanical stress, such as vibrations, tilts, and shocks.
    Fig. 5 summarizes the distribution of each application domain into its corresponding
    subdomains described in the previous paragraphs. Download : Download high-res
    image (270KB) Download : Download full-size image Fig. 5. Distribution of papers
    selected by application subdomain. 4.2. Answer to the second research question
    Infrastructure and technology used by selected IoT solutions in agro-industrial
    and environmental fields were organized in seven groups, corresponding to: (i)
    sensing variables, (ii) actuator devices, (iii) power sources, (iv) communication
    technologies, (v) edge computing technologies (Shi et al., 2016), (vi) storage
    strategies, and (vii) visualization strategies. • Sensing variables: about 26%
    of analyzed studies sense temperature, followed by humidity, physicochemical properties,
    and radiation with 16%, 11%, and 10%, respectively. Particularly, temperature
    and physicochemical sensors are distributed in all subdomains as it can be seen
    in Fig. 6. Similarly, 55% of sensors are used for air monitoring. Thus, air temperature
    and humidity, soil moisture and solar radiation, can be considered universal variables
    in agricultural applications. Download : Download high-res image (324KB) Download
    : Download full-size image Fig. 6. Types of sensing variables collected in the
    monitoring domain. • Actuator devices: the distribution of actuators used in selected
    studies is shown in Fig. 7. It can be stated that there are far fewer actuator
    devices than sensors currently being used in these studies and that most of them
    are concentrated in applications of control and logistics. In fact, more than
    60% of actuators reported were found in irrigation processes. Download : Download
    high-res image (223KB) Download : Download full-size image Fig. 7. Type of actuator
    device used. • Power sources: currently, most monitoring applications prefer rechargeable
    batteries connected to solar panels, which offer a simple but sustainable energy
    supply. In contrast, control applications that typically have demanding energy
    requirements prefer the electrical grid. These trends can be appreciated in Fig.
    8. Recent power sources, such as electromagnetic or vibration harvesters were
    not found in selected studies showing that these approaches must mature and gain
    popularity for agricultural and environmental applications. Download : Download
    high-res image (132KB) Download : Download full-size image Fig. 8. Power sources.
    • Communication technologies: Fig. 9 shows that most studies (40%) used Wireless
    Personal Area Network (WPAN) protocols such as Bluetooth and ZigBee, followed
    by Wireless Metropolitan Area Network (WMAN) with 36% of the studies mainly supported
    by cellular technologies (GPRS/GSM/3G/4G). Meanwhile, the near-field communication,
    which is relatively new, has started to emerge in some field applications. Download
    : Download high-res image (76KB) Download : Download full-size image Fig. 9. Communication
    technologies. • Edge computing technologies: microcontroller platforms were chosen
    in more than half of the applications reviewed. Interestingly, Single Board Computers
    (SBC) are not yet appropriate for edge computing in IoT agricultural applications.
    The complete distribution of edge computing technologies is shown in Fig. 10.
    Download : Download high-res image (109KB) Download : Download full-size image
    Fig. 10. Edge computing technologies. • Storage strategies: reviewing Fig. 11,
    it is clear that even though Cloud storage represents a key service for IoT systems,
    only 7.32% of selected studies used it. This shows that most researchers preferred
    their own data-storage implementation. Download : Download high-res image (78KB)
    Download : Download full-size image Fig. 11. Storage strategy. • Visualization
    strategies: Fig. 12 shows the distribution of three different visualization strategies:
    web, mobile and local, in four subdomains: monitoring, control, prediction, and
    logistics. It can be stated that web-based solutions were the preferred strategy
    to visualize reports in all subdomains of applications. Download : Download high-res
    image (115KB) Download : Download full-size image Fig. 12. Visualization strategies.
    Most of the selected works do not address security issues explicitly and leave
    them on a side. However, some efforts in this domain were found. For instance,
    (Jardak et al., 2009) described the design of a WSN that implemented a RANdom
    SAmple Consensus (RANSAC) filter to eliminate inconsistent sensor-node data due
    to the presence of faulty or malicious nodes in the network. Sun et al. (2012)
    presented a dam monitoring system where users needed to sign in through the main
    interface in order to validate their credentials. Tao et al. (2014) selected AppWeb
    as the embedded Web server for the IoT Gateway of an intelligent granary management
    system because it could add the Secure Sockets Layer (SSL) protocol to enable
    encrypted data connection. This was valuable because the network information was
    vulnerable as it came from a wireless channel. Kuroda et al. (2015) proposed a
    WSN with easy-to-use secure communication that was implemented using Zero-admin
    encrypt/decrypt functions at the MAC level with the Advanced Encryption Standard
    (AES-128), which enabled automatic encryption/decryption of messages between each
    sensor node and the coordinator node. 5. Recent works The following paragraphs
    are devoted to introducing some recent and representative works that were available
    online between May 2016 and July 2017, beyond the initial scope of the SLR process
    described so far. They cover areas such as communications, energy management,
    monitoring and logistics for agro-industrial and environmental applications. 5.1.
    Communications Low-power WAN (LPWAN) technologies such as SigFox, LoRa, narrowband
    IoT and others are becoming popular within IoT applications due to its reduced
    energy requirements, wide coverage range, and low-cost when compared to other
    long-distance technologies according to Barrachina-Muñoz et al. (2017). For example,
    in a recent survey by Sinha et al. (2017), authors found that LoRa is the best
    option for smart agriculture applications. In Lukas et al. (2015), authors designed
    a long-range water level monitoring system for troughs using a WSN based on LoRa
    transceivers, allowing the cattleman to observe water availability for livestock
    even when the barn was 1 or 3 km away. In a different application, (Pham et al.,
    2016) proposed an IoT framework to contribute to rural development implementing
    agricultural applications supported by open-source hardware and long-range communication
    devices. The first deployment of this solution used LoRa transceivers since rural
    villages were located in remote areas and it was convenient to have a low-cost
    and non-proprietary infrastructure. 5.2. Energy management One of the main requirements
    for devices used in IoT projects is that they must be energy-efficient according
    to Borgia (2014). This is particularly important for pervasive solutions deployed
    outdoors that can not be powered from the electric grid nor regularly maintained
    because they are installed in difficult or remote environments. In WSN scenarios,
    the current challenge is to develop multi-source energy harvesters and ultra-efficient
    sensors to create battery-free solutions, (Shaikh and Zeadally, 2016). These considerations
    are very important for IoT solutions for agro-industrial and environmental problems
    as recharging batteries is not practical and ambient energy sources are usually
    available. In terms of smart energy control for IoT projects, (Wang et al., 2016)
    proposed a novel energy management strategy for solar powered devices that intend
    to power the load directly from the solar cell, avoiding power converters and
    energy storage elements that contribute to energy losses, greater weight/volume
    ratio, and higher price. Another trend that is likely to continue is the development
    of self-power devices, such as the soil water content sensor for an autonomous
    landslide surveillance system designed by Lu et al. (2016). In this case, the
    sensor used the soil moisture to power itself making it suitable for large scale
    deployments. Marjanović et al. (2016) described a cloud-based decision-making
    mechanism for managing sensor data acquisition that is applicable to collaborative
    sensing solutions using distributed sensors, like mobile devices, to efficiently
    monitor large geographical areas. The system selected which sensors had to upload
    the information to the cloud to prevent the acquisition of redundant information
    from other nearby sensors for a specific coverage area, maintaining a spatial
    sampling quality and reducing in this way the battery depletion of the devices.
    5.3. Monitoring Recent environmental monitoring solutions are now offering additional
    capabilities in terms of decision making and management. For example, (Giorgetti
    et al., 2016) proposed a custom-made landslide risk monitoring system based on
    a WSN that allows fast deployments in hostile environments without human intervention
    because the system is able to deal with node failure and poor-quality communication
    links reorganizing the network by itself. Wong and Kerkez (2016) presented a Web
    service and real-time data architecture that includes an adaptive controller that
    updates the parameters of each sensing node within a WSN based on a previously
    defined policy. Zheng et al. (2016) proposed an IoT management system to protect
    the ecological and environmental quality while building an artificial river where
    nature and city converge. The system monitored key elements like soil, water,
    atmosphere, and wind at a high spatial resolution over a large area. Edwards-Murphy
    et al. (2016) introduced a beehive monitoring system that collects internal and
    external data to describe the status of the bee colony from a set of possible
    states using a classification algorithm based on decision trees. This information
    was used to determine if a visit to the beehive was required or not. As an additional
    result, authors found a strong correlation between the beehive status and the
    short-term rain forecast. Overall, this study is relevant for agriculture because
    crop pollination depends on honey bees. Sarangi et al. (2016) presented a framework
    for an automated crop-disease advisory service that integrates the interoperability
    of an IoT web repository with an agricultural advisory call center. The implemented
    system processes images of the diseased plant sent by the farmer, and then it
    provides the plant diagnosis and the corresponding management recommendation for
    the disease. 5.4. Logistics Food safety and quality control in logistics are emerging
    as IoT agribusiness areas in response to the demand from businesses and end consumers
    to obtain real-time information about food supply chain and “farm-to-fork” traceability.
    For instance, (Ruan and Shi, 2016) presented an IoT framework to assess the fruit
    freshness on e-commerce deliveries, which is a non-traditional retail service
    that faces unique challenges in transportation due to the product perishability
    and expensive logistics. Similarly, (Liu et al., 2016) introduced a pilot project
    using IoT to monitor food safety throughout the product life cycle, helping authorities
    and consumers to trace the food and make better decisions before buying it. In
    a related work, (Wang and Yue, 2017) proposed an early-warning system for food
    safety that automatically warns about product quality risks and incidents by sharing
    and centralizing information among supply chains. Lastly, (Capello et al., 2016)
    developed a business-to-business monitoring service based on IoT that provides
    geo-located information (humidity and temperature) about food storage and transportation
    without a vendor lock-in infrastructure. 6. Discussion 6.1. Limitations and open
    challenges After analyzing the difficulties and limitations described in selected
    papers from the SLR, the following list summarizes a few insights that aim to
    contribute to the mass adoption of IoT solutions in agricultural and environmental
    fields. • Stronger standardization: it will help to improve compatibility among
    different vendors and to ensure stronger security measures across the entire IoT
    stack, starting from field devices all the way up to cloud providers and end-user
    interfaces (Pang et al., 2015). • Better power management: it will increase the
    endurance of IoT solutions because nowadays the main factor limiting the lifespan
    of IoT deployments is energy depletion (Jain et al., 2008, Chen et al., 2014,
    Islam et al., 2014, Diedrichs et al., 2014). The lifespan can be improved by lowering
    the power consumption of each electronic module, including energy harvesters,
    and using alternative power storage mechanisms as replacements of rechargeable
    batteries, which affect the expiration date of deployed devices. • Security: a
    major challenge in the realization of the IoT in agriculture is the security problem
    (Jiang and Zhang, 2013), and the few works that consider it only incorporate fragmented
    strategies to mitigate it. Therefore, it is evident that there is a need for agro-industrial
    and environmental IoT solutions that address end-to-end information security and
    physical integrity of field devices. • Design using modular hardware and software:
    it will enable a greater degree of reuse and customization for the end user (Pang
    et al., 2015). • Improve unit cost: even though the cost of embedded computing
    platforms have been decreasing sharply, the same is not true for high-quality
    sensors and actuators. In order to deploy IoT solutions with hundreds and possibly
    thousands of nodes, the overall hardware, Internet access and international data
    roaming costs have to be reduced even further (Pang et al., 2015). • Aim for a
    good compatibility with legacy infrastructure: similarly to what has happened
    in industrial automation, it is important to deliver IoT solutions that can be
    integrated with the customer’s existing infrastructure such as specialized equipment,
    field machines, and software. • Consider scalability early on: with an increasing
    number of devices in large deployments, data synchronization and data reliability
    become critical (Diedrichs et al., 2014). • Adopt good practices of software engineering:
    as the scale and endurance of deployed IoT solutions grow, the time and effort
    devoted to analyzing generated data, refining the code, and adding new features
    will explode unless the software is well designed and documented (Hussain et al.,
    2006, Jayaraman et al., 2015a). • Improve robustness for field deployments: commercial
    IoT solution should be able to handle strong changes in temperature, humidity,
    and illumination to deal with seasonal changes and worldwide climate variability.
    • User-centered design: the installation and management of corresponding IoT nodes
    should be straight forward for non-expert users. Additionally, the hardware must
    require very little or none human maintenance during its lifespan, and the underlying
    communication network should be intelligent enough to reconfigure or heal itself
    in the case of a node failure. • Contribute to the IoT the ecosystem: there is
    a noticeable void in the literature on how to improve and adapt IoT solutions
    for real-world applications beyond simple prototypes (Chen et al., 2015). • Sustainable
    practices: even if the most humble predictions about the worldwide adoption of
    IoT devices become a reality, recycling strategies will have to be taken into
    account for new solutions deployed on the field, as an integral part of the product
    life cycle to reduce the environmental impact. 6.2. Proposed architecture To summarize
    the findings of this study, authors proposed the IoT architecture for agro-industrial
    and environmental applications that is illustrated in Fig. 13. This encapsulates
    most of the studies analyzed in this paper. The architecture has four main layers:
    physical, communication, service, and application. The physical layer includes
    perception and control. In perception, the main objective is to produce valuable
    data sensing field variables using a WSN. Data produced are sent to the communication
    layer through field gateways. Devices in the perception layer can be powered by
    batteries for short-term deployments or by solar panels because of their low-power
    consumption. In contrast, the control layer acts as a data sink, receiving information
    from a communication layer or a perception layer in the simplest case. Information
    received in the control layer alters the state of field actuators frequently requiring
    power from the electrical grid. In the middle of the perception and control layers
    there is a mobile robot that can be used when fixed devices are not the best option.
    In the communication layer, the objective is to move the information from the
    physical layer to the Internet, collecting data from IoT gateways based either
    on Ethernet or mobile networks (e.g: GPRS/3G/4G/NB-IoT and eventually 5G). This
    layer includes field gateways acting as interfaces between IoT gateways and transceivers
    using ZigBee, Bluetooth, NFC, WiFi, LoRA, or Sigfox. The service layer handles
    data ingestion from the communication layer, as well as their storage, analytics,
    visualization, and security. Finally, the application layer consumes services
    from the previous layer in the architecture and allows the user to handle monitoring,
    control, prediction, and logistics. Download : Download high-res image (717KB)
    Download : Download full-size image Fig. 13. Proposed IoT architecture for agro-industrial
    and environmental applications. 7. Conclusions This paper presented an updated
    review of IoT applications for agro-industrial and environmental fields. It was
    guided by a systematic literature review, and therefore the methodology and intermediate
    results obtained during the stages of planning, conduction, and results were reported
    in great detail. From 3578 initial studies extracted from electronic sources,
    72 main studies were selected based on their relevance to answer two research
    questions. Selected studies came from five continents, and Asian countries contributed
    to more than half of them. During this study, it was discovered that most of the
    research still focuses on monitoring applications (62%); however there is a growing
    interest in closing the loop by doing control (25%), and there are some preliminary
    solutions in logistics and prediction (13%) for agro-industrial and environmental
    applications using IoT. The temperature and humidity of the air, as well as the
    soil moisture and solar radiation can be recognized as universal variables measured
    in agricultural applications based on selected studies. Similarly, actuators such
    as valves, pumps, motors, sprinklers, humidifiers, and lamps were widely used
    in irrigation, fertilization, pesticide management, and illumination control.
    It was also observed that new energy sources and Cloud storage have not been widely
    adopted, showing that there are opportunities for research and development in
    these areas. Studies included in this paper provide a compact view of solutions
    proposed for agro-industrial and environmental problems during the last decade.
    It was found that most of them relied heavily on heterogeneous components and
    wireless sensor networks. However, it seems reasonable to assume that future solutions
    will need to fully embrace Cloud services and new ways of connectivity in order
    to get the benefits of a truly connected and smart IoT ecosystem. Acknowledgements
    Authors would like to acknowledge the support of all partners within the Center
    of Excellence and Appropriation on the Internet of Things (CEA-IoT), as well the
    Colombian Ministry for the Information and Communication Technologies (MinTIC),
    and the Colombian Administrative Department of Science, Technology and Innovation
    (Colciencias) through the project ID: FP44842-502-2015 from the National Trust
    for Funding Science, Technology and Innovation Francisco José de Caldas. References
    Barrachina-Muñoz et al., 2017 S. Barrachina-Muñoz, B. Bellalta, T. Adame, A. Bel
    Multi-hop communication in the uplink for LPWANs Comput. Netw., 123 (2017), pp.
    153-168, 10.1016/j.comnet.2017.05.020 View PDFView articleView in ScopusGoogle
    Scholar Borgia, 2014 E. Borgia The internet of things vision: key features, applications
    and open issues Comput. Commun., 54 (2014), pp. 1-31, 10.1016/j.comcom.2014.09.008
    View PDFView articleGoogle Scholar Capello et al., 2016 Capello, F., Toja, M.,
    Trapani, N., 2016. A real-time monitoring service based on industrial internet
    of things to manage agrifood logistics. In: 6th International Conference on Information
    Systems, Logistics and Supply Chain, pp. 1–8. Google Scholar Charoenpanyasak et
    al., 2011 S. Charoenpanyasak, W. Suntiamorntut, T. Phatthanatraiwat, J. Ruksachum
    Smart shrimp hatchery using mikros platform 4th Joint IFIP Wireless and Mobile
    Networking Conference (WMNC), IEEE (2011), pp. 1-5 CrossRefGoogle Scholar Chavez-Burbano
    et al., 2014 P. Chavez-Burbano, I. Marin-Garcia, A. Muñoz-Arcentales Ad-hoc network
    implementation and experimental testing using low cost and COTS components: an
    ecuatorian case study International Work Conference on Bio-inspired Intelligence
    (IWOBI), IEEE (2014), pp. 133-137 CrossRefView in ScopusGoogle Scholar Chen et
    al., 2014 K.T. Chen, H.H. Zhang, T.T. Wu, J. Hu, C.Y. Zhai, D. Wang Design of
    monitoring system for multilayer soil temperature and moisture based on WSN International
    Conference on Wireless Communication and Sensor Network (WCSN), IEEE, Wuhan (2014),
    pp. 425-430, 10.1109/WCSN.2014.9 View in ScopusGoogle Scholar Chen et al., 2015
    Y. Chen, J.-P. Chanet, K.-M. Hou, H. Shi, G. de Sousa A scalable context-aware
    objective function (SCAOF) of routing protocol for agricultural low-power and
    lossy networks (RPAL) Sensors, 15 (2015), pp. 19507-19540, 10.3390/s150819507
    View in ScopusGoogle Scholar Culibrina and Dadios, 2015 F.B. Culibrina, E.P. Dadios
    Smart farm using wireless sensor network for data acquisition and power control
    distribution International Conference on Humanoid, Nanotechnology, Information
    Technology, Communication and Control, Environment and Management (HNICEM), IEEE
    (2015), pp. 1-6 CrossRefGoogle Scholar De La Concepcion et al., 2014 A.R. De La
    Concepcion, R. Stefanelli, D. Trinchero A wireless sensor network platform optimized
    for assisted sustainable agriculture Global Humanitarian Technology Conference
    (GHTC), IEEE (2014), pp. 159-165, 10.1109/GHTC.2014.697027 View in ScopusGoogle
    Scholar Diedrichs et al., 2014 A.L. Diedrichs, G. Tabacchi, G. Grünwaldt, M. Pecchia,
    G. Mercado, F.G. Antivilo Low-power wireless sensor network for frost monitoring
    in agriculture research Biennial Congress of Argentina (ARGENCON), IEEE (2014),
    pp. 525-530, 10.1109/ARGENCON.2014.686854 View in ScopusGoogle Scholar Edwards-Murphy
    et al., 2016 F. Edwards-Murphy, M. Magno, P.M. Whelan, J. O’Halloran, E.M. Popovici
    b+WSN: smart beehive with preliminary decision tree analysis for agriculture and
    honey bee health monitoring Comput. Electron. Agric., 124 (2016), pp. 211-219,
    10.1016/j.compag.2016.04.008 View PDFView articleView in ScopusGoogle Scholar
    Ehsan et al., 2012 S. Ehsan, K. Bradford, M. Brugger, B. Hamdaoui, Y. Kovchegov,
    D. Johnson, M. Louhaichi Design and analysis of delay-tolerant sensor networks
    for monitoring and tracking free-roaming animals IEEE Trans. Wireless Commun.,
    11 (2012), pp. 1220-1227, 10.1109/TWC.2012.012412.111405 View in ScopusGoogle
    Scholar Eom et al., 2014 K.-H. Eom, K.-H. Hyun, S. Lin, J.-W. Kim The meat freshness
    monitoring system using the smart RFID tag Int. J. Distrib. Sensor Networks, 2014
    (2014), pp. 1-10 CrossRefGoogle Scholar Fang et al., 2014 S. Fang, L. Da Xu, Y.
    Zhu, J. Ahati, H. Pei, J. Yan, Z. Liu An integrated system for regional environmental
    monitoring and management based on internet of things IEEE Trans. Ind. Inform.,
    10 (2014), pp. 1596-1605 CrossRefView in ScopusGoogle Scholar Feng et al., 2012
    C. Feng, H.R. Wu, H.J. Zhu, X. Sun The design and realization of apple orchard
    intelligent monitoring system based on internet of things technology Advanced
    Materials Research, vol. 546, Trans Tech Publ (2012), pp. 898-902 View in ScopusGoogle
    Scholar Fourati et al., 2014 M.A. Fourati, W. Chebbi, A. Kamoun Development of
    a web-based weather station for irrigation scheduling 3rd International Colloquium
    in Information Science and Technology (CIST), IEEE (2014), pp. 37-42, 10.1109/CIST.2014.701659
    View in ScopusGoogle Scholar Giorgetti et al., 2016 A. Giorgetti, M. Lucchi, E.
    Tavelli, M. Barla, G. Gigli, N. Casagli, M. Chiani, D. Dardari A robust wireless
    sensor network for landslide risk analysis: system design, deployment, and field
    testing IEEE Sens. J., 16 (2016), pp. 6374-6386, 10.1109/JSEN.2016.2579263 View
    in ScopusGoogle Scholar Gutiérrez et al., 2014 J. Gutiérrez, J.F. Villa-Medina,
    A. Nieto-Garibay, M.Á. Porta-Gándara automated irrigation system using a wireless
    sensor network and GPRS module IEEE Trans. Instrum. Meas., 63 (2014), pp. 166-176
    View in ScopusGoogle Scholar Hachem et al., 2015 S. Hachem, V. Mallet, R. Ventura,
    A. Pathak, V. Issarny, P.-G. Raverdy, R. Bhatia Monitoring noise pollution using
    the urban civics middleware First International Conference on Big Data Computing
    Service and Applications, IEEE (2015), pp. 52-61 View in ScopusGoogle Scholar
    Hakala et al., 2008 Hakala, I., Tikkakoski, M., Kivel, I., 2008. Wireless sensor
    network in environmental monitoring - case foxhouse. In: 2nd International Conference
    on Sensor Technologies and Applications (SENSORCOMM), pp. 202–208. http://dx.doi.org/10.1109/SENSORCOMM.2008.27.
    Google Scholar Hashim et al., 2015 N. Hashim, S. Mazlan, M.A. Aziz, A. Salleh,
    A. Ja’afar, N. Mohamad Agriculture monitoring system: a study J. Teknologi, 77
    (2015), pp. 53-59, 10.11113/jt.v77.4099 View in ScopusGoogle Scholar Hussain et
    al., 2006 Hussain, S., Schofield, N., Matin, A.W. 2006. Design of a web-based
    application for wireless sensor networks. In: 17th International Workshop on Database
    and Expert Systems Applications (DEXA), pp. 319–326. http://dx.doi.org/10.1109/DEXA.2006.50.
    Google Scholar Islam et al., 2014 A. Islam, T. Islam, M.A. Syrus, N. Ahmed Implementation
    of flash flood monitoring system based on wireless sensor network in Bangladesh
    3rd International Conference on Informatics, Electronics & Vision, IEEE, Dhaka
    (2014), pp. 1-6, 10.1109/ICIEV.2014.685075 Google Scholar Jain et al., 2008 Jain,
    V.R., Bagree, R., Kumar, A., Ranjan, P., 2008. wildCENSE: GPS based animal tracking
    system. In: International Conference on Intelligent Sensors, Sensor Networks and
    Information Processing (ISSNIP), pp. 617–622. http://dx.doi.org/10.1109/ISSNIP.2008.4762058.
    Google Scholar Jardak et al., 2009 C. Jardak, K. Rerkrai, A. Kovacevic, J. Riihijarvi,
    P. Mahonen Email from the vineyard 5th International Conference on Testbeds and
    Research Infrastructures for the Development of Networks & Communities and Workshops
    (TridentCom), IEEE (2009), pp. 1-6, 10.1109/TRIDENTCOM.2009.497624 Google Scholar
    Jayaraman et al., 2015a P.P. Jayaraman, D. Palmer, A. Zaslavsky, D. Georgakopoulos
    Do-it-yourself digital agriculture applications with semantically enhanced IoT
    platform 10th International Conference on Intelligent Sensors, Sensor Networks
    and Information Processing (ISSNIP), IEEE (2015), pp. 1-6 CrossRefGoogle Scholar
    Jayaraman et al., 2015b P.P. Jayaraman, D. Palmer, A. Zaslavsky, A. Salehi, D.
    Georgakopoulos Addressing information processing needs of digital agriculture
    with OpenIoT platform Interoperability and Open-Source Solutions for the Internet
    of Things, Springer (2015), pp. 137-152 CrossRefView in ScopusGoogle Scholar Jiang
    and Zhang, 2013 Jiang, R., Zhang, Y., 2013. Research of agricultural information
    service platform based on internet of things. In: 12th International Symposium
    on Distributed Computing and Applications to Business, Engineering Science (DCABES),
    pp. 176–180. http://dx.doi.org/10.1109/DCABES.2013.39. Google Scholar Jiao et
    al., 2014 J. Jiao, H. Ma, Y. Qiao, Y. Du, W. Kong, Z. Wu Design of farm environmental
    monitoring system based on the internet of things Adv. J. Food Sci. Technol.,
    6 (2014), pp. 368-373 CrossRefView in ScopusGoogle Scholar Jiber et al., 2011
    Jiber, Y., Harroud, H., Karmouch, A., 2011. Precision agriculture monitoring framework
    based on WSN. In: 7th International Wireless Communications and Mobile Computing
    Conference, pp. 2015–2020. http://dx.doi.org/10.1109/IWCMC.2011.5982844. Google
    Scholar Kaewmard and Saiyod, 2014 N. Kaewmard, S. Saiyod Sensor data collection
    and irrigation control on vegetable crop using smart phone and wireless sensor
    networks for smart farm Conference on Wireless Sensors (ICWiSE), IEEE (2014),
    pp. 106-112 CrossRefView in ScopusGoogle Scholar Kanoun et al., 2014 O. Kanoun,
    S. Khriji, D. El Houssaini, C. Viehweger, M.W. Jmal, M. Abid Precision irrigation
    based on wireless sensor network IET Sci. Meas. Technol., 8 (2014), pp. 98-106,
    10.1049/iet-smt.2013.0137 Google Scholar Kar and Kar, 2015 Kar, A., Kar, A., 2015.
    A novel design of a portable double beam-in-time spectrometric sensor platform
    with cloud connectivity for environmental monitoring applications. In: 3rd International
    Conference on Computer, Communication, Control and Information Technology (C3IT),
    pp. 1–6. http://dx.doi.org/10.1109/C3IT.2015.7060228. Google Scholar Khandani
    and Kalantari, 2009 Khandani, S.K., Kalantari, M., 2009. Using field data to design
    a sensor network. In: 43rd Annual Conference on Information Sciences and Systems
    (CISS), pp. 219–223. http://dx.doi.org/10.1109/CISS.2009.5054720. Google Scholar
    Kitchenham and Charters, 2007 Kitchenham, B., Charters, S., 2007. Guidelines for
    performing systematic literature reviews in software engineering. In: EBSE Technical
    Report. EBSE-2007-01. pp. 1–50. Google Scholar Kiyoshi et al., 2008 Kiyoshi, H.,
    Shrestha, A., Chinnachodteeranun, R., Mizoguchi, M., Shimamura, H., Kameoka, T.,
    2008. Spinach field monitoring for bridging thai producer and japanese consumer
    under sensor Asia. In: SICE Annual Conference, pp. 2582–2585. http://dx.doi.org/10.1109/SICE.2008.4655101.
    Google Scholar Kodali et al., 2014 R.K. Kodali, N. Rawat, L. Boppana WSN sensors
    for precision agriculture Region 10 Symposium, IEEE (2014), pp. 651-656, 10.1109/TENCONSpring.2014.686311
    View in ScopusGoogle Scholar Kuroda et al., 2015 M. Kuroda, H. Ibayashi, H. Mineno
    Affordable 400 MHz long-haul sensor network for greenhouse horticulture International
    Conference on Information Networking (ICOIN), IEEE, Cambodia (2015), pp. 19-24,
    10.1109/ICOIN.2015.705785 View in ScopusGoogle Scholar Langendoen et al., 2006
    K. Langendoen, A. Baggio, O. Visser Murphy loves potatoes experiences from a pilot
    sensor network deployment in precision agriculture 20th International Parallel
    and Distributed Processing Symposium (IPDPS), vol. 2006, IEEE, Rhodes Island (2006),
    pp. 1530-2075, 10.1109/IPDPS.2006.163941 Google Scholar Lee et al., 2012 Lee,
    J., Kang, H., Bang, H., 2012. Dynamic crop field analysis using mobile sensor
    node. In: International Conference on ICT Convergence (ICTC), pp. 7-11. http://dx.doi.org/10.1109/ICTC.2012.6386766.
    Google Scholar Lee et al., 2013 M. Lee, J. Hwang, H. Yoe Agricultural production
    system based on IoT 16th International Conference on Computational Science and
    Engineering (CSE), IEEE (2013), pp. 833-837 CrossRefView in ScopusGoogle Scholar
    Li et al., 2013 M. Li, G. Chen, Z. Zhu Information service system of agriculture
    IoT Automatika - J. Control, Meas. Electron. Comput. Commun., 54 (2013), pp. 415-426
    CrossRefGoogle Scholar Li et al., 2014 R.-A. Li, X. Sha, K. Lin Smart greenhouse:
    a real-time mobile intelligent monitoring system based on WSN International Wireless
    Communications and Mobile Computing Conference (IWCMC), IEEE (2014), pp. 1152-1156
    CrossRefView in ScopusGoogle Scholar Liping, 2012 W. Liping Study on agricultural
    products logistics mode in Henan Province of China Software Eng. Knowledge Eng.:
    Theory Practice, Springer (2012), pp. 635-640 CrossRefGoogle Scholar Liu et al.,
    2016 Y. Liu, W. Han, Y. Zhang, L. Li, J. Wang, L. Zheng An internet-of-things
    solution for food safety and quality control: a pilot project in China J. Ind.
    Inform. Integrat., 3 (2016), pp. 1-7, 10.1016/j.jii.2016.06.001 View PDFView articleGoogle
    Scholar Liu et al., 2013 Z. Liu, J. Huang, Q. Wang, Y. Wang, J. Fu Real-time barrier
    lakes monitoring and warning system based on wireless sensor network International
    Conference on Intelligent Control and Information Processing (ICICIP), IEEE, Beijing
    (2013), pp. 551-554, 10.1109/ICICIP.2013.656813 View in ScopusGoogle Scholar Lu
    et al., 2010 S. Lu, M. Duan, P. Zhao, Y. Lang, X. Huang GPRS-based environment
    monitoring system and its application in apple production International Conference
    on Progress in Informatics and Computing (PIC), vol. 1, IEEE (2010), pp. 486-490,
    10.1109/PIC.2010.568757 View in ScopusGoogle Scholar Lu et al., 2016 T.-C. Lu,
    L.-R. Huang, Y. Lee, K.-J. Tsai, Y.-T. Liao, N.-C. Cheng, Y.-H. Chu, Y.-H. Tsai,
    F.-C. Chen, T.-C. Chiueh Invited – wireless sensor nodes for environmental monitoring
    in internet of things 53rd Design Automation Conference (DAC), ACM (2016), pp.
    1-5, 10.1145/2897937.289860 Google Scholar Luan et al., 2015 Q. Luan, X. Fang,
    C. Ye, Y. Liu An integrated service system for agricultural drought monitoring
    and forecasting and irrigation amount forecasting 23rd International Conference
    on Geoinformatics, IEEE (2015), pp. 1-7 CrossRefGoogle Scholar Lukas et al., 2015
    Lukas, W.A. Tanumihardja, E. Gunawan On the application of IoT: monitoring of
    troughs water level using WSN Conference on Wireless Sensors (ICWiSe), IEEE (2015),
    pp. 58-62, 10.1109/ICWISE.2015.738035 View in ScopusGoogle Scholar Ma et al.,
    2012 D. Ma, Q. Ding, Z. Li, D. Li, Y. Wei Prototype of an aquacultural information
    system based on internet of things E-Nose Intell. Automat. Soft Comput., 18 (2012),
    pp. 569-579 CrossRefView in ScopusGoogle Scholar Mafuta et al., 2012 Mafuta, M.,
    Zennaro, M., Bagula, A., Ault, G., Gombachika, H., Chadza, T., 2012. Successful
    Deployment of a Wireless Sensor Network for Precision Agriculture in Malawi. In:
    3rd International Conference on Networked Embedded Systems for Every Application
    (NESEA). IEEE, pp. 1–7. Google Scholar Marino et al., 2010 P. Marino, F.P. Fontán,
    M.Á. Domínguez, S. Otero An experimental Ad-hoc WSN for the instrumentation of
    biological models IEEE Trans. Instrum. Meas., 59 (2010), pp. 2936-2948 View in
    ScopusGoogle Scholar Marjanović et al., 2016 M. Marjanović, L. Skorin-Kapov, K.
    Pripužić, A. Antonić, I. Podnar Žarko Energy-aware and quality-driven sensor management
    for green mobile crowd sensing J. Network Comput. Appl., 59 (2016), pp. 95-108,
    10.1016/j.jnca.2015.06.023 View PDFView articleView in ScopusGoogle Scholar Mathurkar
    et al., 2014 Mathurkar, S.S., Patel, N.R., Lanjewar, R.B., Somkuwar, R.S., 2014.
    Smart sensors based monitoring system for agriculture using field programmable
    gate array. In: International Conference on Circuit, Power and Computing Technologies
    (ICCPCT). IEEE, pp. 339–344. Google Scholar Medela et al., 2013 Medela, A., Cendón,
    B., González, L., Crespo, R., Nevares, I., 2013. IoT Multiplatform networking
    to monitor and control wineries and vineyards. In: Future Network and Mobile Summit.
    IEEE, pp. 1–10. Google Scholar Mittal et al., 2012 A. Mittal, K.P. Chetan, S.
    Jayaraman, B.G. Jagyasi, A. Pande, P. Balamuralidhar mKRISHI wireless sensor network
    platform for precision agriculture 6th International Conference on Sensing Technology
    (ICST), IEEE (2012), pp. 623-629, 10.1109/ICSensT.2012.646175 View in ScopusGoogle
    Scholar Nguyen et al., 2015 Nguyen, T.-D., Thanh, T.T., Nguyen, L.-L., Huynh,
    H.-T., 2015. On the design of energy efficient environment monitoring station
    and data collection network based on ubiquitous wireless sensor networks. In:
    International Conference on Computing & Communication Technologies-Research, Innovation,
    and Vision for the Future (RIVF). IEEE, pp. 163–168. Google Scholar Pahuja et
    al., 2013 R. Pahuja, H. Verma, M. Uddin A wireless sensor network for greenhouse
    climate control IEEE Pervasive Comput., 12 (2013), pp. 49-58 View in ScopusGoogle
    Scholar Pang et al., 2015 Z. Pang, Q. Chen, W. Han, L. Zheng Value-centric design
    of the internet-of-things solution for food supply Chain: value creation, sensor
    portfolio and information fusion Inform. Syst. Front., 17 (2015), pp. 289-319,
    10.1007/s10796-012-9374-9 View in ScopusGoogle Scholar Pham et al., 2016 C. Pham,
    A. Rahim, P. Cousin Low-cost, long-range open IoT for smarter Rural African villages
    International Smart Cities Conference (ISC2), IEEE (2016), pp. 1-6, 10.1109/ISC2.2016.758082
    View in ScopusGoogle Scholar Pokrić et al., 2014 Pokrić, B., Krčo, S., Drajić,
    D., Pokrić, M., Jokić, I., Stojanović, M.J., 2014. ekoNET - environmental monitoring
    using low-cost sensors for detecting gases, particulate matter, and meteorological
    parameters. In: Eighth International Conference on Innovative Mobile and Internet
    Services in Ubiquitous Computing (IMIS), pp. 421–426. http://dx.doi.org/10.1109/IMIS.2014.57.
    Google Scholar Postolache et al., 2014 O. Postolache, J.D. Pereira, P.S. Girão
    Wireless sensor network-based solution for environmental monitoring: water quality
    assessment case study IET Sci., Meas. Technol., 8 (2014), pp. 610-616, 10.1049/iet-smt.2013.0136
    View in ScopusGoogle Scholar Postolache et al., 2013 Postolache, O., Pereira,
    M., Gir ao, P., 2013. Sensor network for environment monitoring: water quality
    case study. In: 4th Symposium on Environmental Instrumentation and Measurements,
    pp. 30–34. Google Scholar Roy et al., 2015 Roy, S.K., Roy, A., Misra, S., Raghuwanshi,
    N.S., Obaidat, M.S., 2015. AID: A prototype for agricultural intrusion detection
    using wireless sensor network. In: International Conference on Communications
    (ICC). IEEE, pp. 7059–7064. Google Scholar Ruan and Shi, 2016 J. Ruan, Y. Shi
    Monitoring and assessing fruit freshness in IoT-Based E-commerce delivery using
    scenario analysis and interval number approaches Inf. Sci., 373 (2016), pp. 557-570,
    10.1016/j.ins.2016.07.014 View PDFView articleView in ScopusGoogle Scholar Ryu
    et al., 2015 M. Ryu, J. Yun, T. Miao, I.-Y. Ahn, S.-C. Choi, J. Kim Design and
    implementation of a connected farm for smart farming system In Sensors, IEE (2015),
    pp. 1-4 Google Scholar Sales et al., 2015 Sales, N., Remédios, O., Arsenio, A.,
    2015. Wireless sensor and actuator system for smart irrigation on the cloud. In:
    2nd World Forum on Internet of Things (WF-IoT). IEEE, pp. 693–698. Google Scholar
    Sarangi et al., 2016 S. Sarangi, J. Umadikar, S. Kar Automation of agriculture
    support systems using Wisekar: case study of a crop-disease advisory service Comput.
    Electron. Agric., 122 (2016), pp. 200-210, 10.1016/j.compag.2016.01.009 View PDFView
    articleView in ScopusGoogle Scholar Saville et al., 2015 Saville, R., Hatanaka,
    K., Wada, M., 2015. ICT application of real-time monitoring and estimation system
    for set-net fishery. In: OCEANS, pp. 1–5. Google Scholar Sawant et al., 2014 S.A.
    Sawant, J. Adinarayana, S.S. Durbha KrishiSense: a semantically aware web enabled
    wireless sensor network system for precision agriculture applications Geoscience
    and Remote Sensing Symposium, IEEE (2014), pp. 4090-4093, 10.1109/IGARSS.2014.694738
    View in ScopusGoogle Scholar Shaikh and Zeadally, 2016 F.K. Shaikh, S. Zeadally
    Energy harvesting in wireless sensor networks: a comprehensive review Renew. Sustain.
    Energy Rev., 55 (2016), pp. 1041-1054, 10.1016/j.rser.2015.11.010 View PDFView
    articleView in ScopusGoogle Scholar Shi et al., 2016 W. Shi, J. Cao, Q. Zhang,
    Y. Li, L. Xu Edge computing: vision and challenges IEEE Internet Things J., 3
    (2016), pp. 637-646, 10.1109/JIOT.2016.2579198 View in ScopusGoogle Scholar Shuwen
    and Changli, 2015 Shuwen, W., Changli, Z., 2015. Study on farmland irrigation
    remote monitoring system based on ZigBee. In: International Conference on Computer
    and Computational Sciences (ICCCS). IEEE, pp. 193–197. Google Scholar Sinha et
    al., 2015a Sinha, A., Shen, Z., Song, Y., Ma, H., Darrin Eide, B.-J.P.H., Wang,
    K., 2015a. An overview of microsoft academic service (MAS) and applications. In:
    24th International Conference on World Wide Web. ACM, pp. 243–246. Google Scholar
    Sinha et al., 2015b Sinha, N., Pujitha, K.E., Alex, J.S.R., 2015b. Xively Based
    sensing and monitoring system for IoT. In: International Conference on Computer
    Communication and Informatics (ICCCI), pp. 1–6. http://dx.doi.org/10.1109/ICCCI.2015.7218144.
    Google Scholar Sinha et al., 2017 R.S. Sinha, Y. Wei, S.-H. Hwang A Survey on
    LPWA technology: LoRa and NB-IoT ICT Express, 3 (2017), pp. 14-21, 10.1016/j.icte.2017.03.004
    View PDFView articleView in ScopusGoogle Scholar Smarsly, 2013 Smarsly, K., 2013.
    Agricultural ecosystem monitoring based on autonomous sensor systems. In: 2nd
    International Conference on Agro-Geoinformatics (Agro-Geoinformatics). IEEE, pp.
    402-407. Google Scholar Soontranon et al., 2014 Soontranon, N., Tangpattanakul,
    P., Srestasathiern, P., Rakwatin, P., 2014. An agricultural monitoring system:
    field server data collection and analysis on paddy field. In: 14th International
    Symposium on Communications and Information Technologies (ISCIT). IEEE, pp. 597–601.
    Google Scholar Sun et al., 2012 E. Sun, X. Zhang, Z. Li The internet of things
    (IOT) and cloud computing (CC) based tailings dam monitoring and pre-alarm system
    in mines Safety Sci., 50 (2012), pp. 811-815, 10.1016/j.ssci.2011.08.028 View
    PDFView articleView in ScopusGoogle Scholar Tao et al., 2014 R. Tao, S. Yang,
    W. Tan, C. Zhang Secure gateway of internet of things based on AppWeb and secure
    sockets layer for intelligent granary management system International Conference
    on Computer and Computing Technologies in Agriculture, Springer (2014), pp. 78-89
    CrossRefView in ScopusGoogle Scholar Tarange et al., 2015 Tarange, P.H., Mevekari,
    R.G., Shinde, P.A., 2015. Web based automatic irrigation system using wireless
    sensor network and embedded linux board. In: International Conference on Circuit,
    Power and Computing Technologies (ICCPCT), pp. 1–5. http://dx.doi.org/10.1109/ICCPCT.2015.7159327.
    Google Scholar Torres-Ruiz et al., 2016 M. Torres-Ruiz, J.H. Juárez-Hipólito,
    M.D. Lytras, M. Moreno-Ibarra Environmental noise sensing approach based on volunteered
    geographic information and spatio-temporal analysis with machine learning International
    Conference on Computational Science and Its Applications, Springer (2016), pp.
    95-110 CrossRefView in ScopusGoogle Scholar Vo et al., 2013 Vo, T.T., Nguyen,
    T.D., Vo, M.T., 2013. Ubiquitous sensor network for development of climate change
    monitoring system based on solar power supply. In: International Conference on
    Advanced Technologies for Communications, pp. 121–124. http://dx.doi.org/10.1109/ATC.2013.6698090.
    Google Scholar Wang and Yue, 2017 J. Wang, H. Yue Food safety pre-warning system
    based on data mining for a sustainable food supply Chain Food Control, 73 (2017),
    pp. 223-229, 10.1016/j.foodcont.2016.09.048 View PDFView articleGoogle Scholar
    Wang et al., 2016 Y. Wang, Y. Liu, C. Wang, Z. Li, X. Sheng, H.G. Lee, N. Chang,
    H. Yang Storage-less and converter-less photovoltaic energy harvesting with maximum
    power point tracking for internet of things IEEE Trans. Comput. Aided Des. Integr.
    Circuits Syst., 35 (2016), pp. 173-186, 10.1109/TCAD.2015.2446937 View in ScopusGoogle
    Scholar Watthanawisuth et al., 2009 Watthanawisuth, N., Tuantranont, A., Kerdcharoen,
    T., 2009. Microclimate real-time monitoring based on zigbee sensor network. In:
    Sensors. IEEE, pp. 1814–1818. Google Scholar Wong and Kerkez, 2016 B.P. Wong,
    B. Kerkez Real-time environmental sensor data: an application to water quality
    using web services Environ. Modell. Software, 84 (2016), pp. 505-517, 10.1016/j.envsoft.2016.07.020
    View PDFView articleView in ScopusGoogle Scholar Xijun et al., 2009 Xijun, Y.,
    Limei, L., Lizhong, X., 2009. The application of wireless sensor network in the
    irrigation area automatic system. In: International Conference on Networks Security,
    Wireless Communications and Trusted Computing (NSWCTC), vol. 1. IEEE, pp. 21–24.
    Google Scholar Xu et al., 2015 Xu, J., Zhang, J., Zheng, X., Wei, X., Han, J.,
    2015. Wireless sensors in farmland environmental monitoring. In:International
    Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery, pp.
    372–379. http://dx.doi.org/10.1109/CyberC.2015.17. Google Scholar Ye et al., 2013
    Ye, J., Chen, B., Liu, Q., Fang, Y., 2013. A precision agriculture management
    system based on internet of things and WebGIS. In: 21st International Conference
    on Geoinformatics, pp. 1–5. http://dx.doi.org/10.1109/Geoinformatics.2013.6626173.
    Google Scholar Yoo et al., 2007 Yoo, S.E., Kim, J.E., Kim, T., Ahn, S., Sung,
    J., Kim, D., (2007). A2S automated agriculture system based on WSN. In: IEEE International
    Symposium on Consumer Electronics, pp. 1–5. http://dx.doi.org/10.1109/ISCE.2007.4382216.
    Google Scholar Zhao and Zhu, 2015 Zhao, L., Zhu, X., 2015. The development of
    remote monitoring system for cultivation environment of pleurotus eryngii. In:
    International Conference on Information and Automation. IEEE, pp. 2643–2648. Google
    Scholar Zheng et al., 2016 R. Zheng, T. Zhang, Z. Liu, H. Wang An EIoT system
    designed for ecological and environmental management of the Xianghe segment of
    china’s grand canal Int. J. Sustain. Dev. World Ecol., 23 (2016), pp. 372-380,
    10.1080/13504509.2015.1124470 View in ScopusGoogle Scholar Zou, 2014 C.-J. Zou
    Research and implementation of agricultural environment monitoring based on internet
    of things 5th International Conference on Intelligent Systems Design and Engineering
    Applications (ISDEA), IEEE (2014), pp. 748-752, 10.1109/ISDEA.2014.17 View in
    ScopusGoogle Scholar Cited by (388) Digital twin framework for smart greenhouse
    management using next-gen mobile networks and machine learning 2024, Future Generation
    Computer Systems Show abstract Intelligent decision-making framework for agriculture
    supply chain in emerging economies: Research opportunities and challenges 2024,
    Computers and Electronics in Agriculture Show abstract Towards online surface
    water quality monitoring technology: A review 2023, Environmental Research Show
    abstract LS-AKA: A lightweight and secure authentication and key agreement scheme
    for enhanced machine type communication devices in 5G smart environment 2023,
    Sustainable Energy Technologies and Assessments Show abstract Internet of Things
    in food processing and its potential in Industry 4.0 era: A review 2023, Trends
    in Food Science and Technology Show abstract Developing a causal framework of
    internet of things adoption barriers for agile manufacturing in post COVID-19
    2024, International Journal of Engineering Business Management View all citing
    articles on Scopus View Abstract © 2017 Elsevier B.V. All rights reserved. Recommended
    articles Application note: Labelling, a methodology to develop reliable algorithm
    in PLF Computers and Electronics in Agriculture, Volume 142, Part A, 2017, pp.
    424-428 Emanuela Tullo, …, Marcella Guarino View PDF Automation of Agriculture
    Support Systems using Wisekar: Case study of a crop-disease advisory service Computers
    and Electronics in Agriculture, Volume 122, 2016, pp. 200-210 Sanat Sarangi, …,
    Subrat Kar View PDF Multi-hop communication in the uplink for LPWANs Computer
    Networks, Volume 123, 2017, pp. 153-168 Sergio Barrachina-Muñoz, …, Albert Bel
    View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 367
    Policy Citations: 7 Captures Readers: 975 View details About ScienceDirect Remote
    access Shopping cart Advertise Contact and support Terms and conditions Privacy
    policy Cookies are used by this site. Cookie settings | Your Privacy Choices All
    content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply.'
  inline_citation: '>'
  journal: Computers and Electronics in Agriculture
  limitations: '>'
  pdf_link: null
  publication_year: 2017
  relevance_score1: 0
  relevance_score2: 0
  title: Review of IoT applications in agro-industrial and environmental fields
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2020.2964280
  analysis: '>'
  authors:
  - Ali Nauman
  - Yazdan Ahmad Qadri
  - Muhammad Faisal Amjad
  - Yousaf Bin Zikria
  - Muhammad Khalil Afzal
  - Sung Won Kim
  citation_count: 197
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 8 Multimedia
    Internet of Things: A Comprehensive Survey Publisher: IEEE Cite This PDF Ali Nauman;
    Yazdan Ahmad Qadri; Muhammad Amjad; Yousaf Bin Zikria; Muhammad Khalil Afzal;
    Sung Won Kim All Authors 196 Cites in Papers 19901 Full Text Views Open Access
    Comment(s) Under a Creative Commons License Abstract Document Sections I. Introduction
    II. IoT and Multimedia IoT Architecture III. Applications of M-IoT IV. Performance
    Metrics for M-IoT V. M-IoT Computing Paradigm Show Full Outline Authors Figures
    References Citations Keywords Metrics Abstract: The immense increase in multimedia-on-demand
    traffic that refers to audio, video, and images, has drastically shifted the vision
    of the Internet of Things (IoT) from scalar to Multimedia Internet of Things (M-IoT).
    IoT devices are constrained in terms of energy, computing, size, and storage memory.
    Delay-sensitive and bandwidth-hungry multimedia applications over constrained
    IoT networks require revision of IoT architecture for M-IoT. This paper provides
    a comprehensive survey of M-IoT with an emphasis on architecture, protocols, and
    applications. This article starts by providing a horizontal overview of the IoT.
    Then, we discuss the issues considering the characteristics of multimedia and
    provide a summary of related M-IoT architectures. Various multimedia applications
    supported by IoT are surveyed, and numerous use cases related to road traffic
    management, security, industry, and health are illustrated to show how different
    M-IoT applications are revolutionizing human life. We explore the importance of
    Quality-of-Experience (QoE) and Quality-of-Service (QoS) for multimedia transmission
    over IoT. Moreover, we explore the limitations of IoT for multimedia computing
    and present the relationship between the M-IoT and emerging technologies including
    event processing, feature extraction, cloud computing, Fog/Edge computing and
    Software-Defined-Networks (SDNs). We also present the need for better routing
    and Physical-Medium Access Control (PHY-MAC) protocols for M-IoT. Finally, we
    present a detailed discussion on the open research issues and several potential
    research areas related to emerging multimedia communication in IoT. Topic: Mobile
    Multimedia: Methodology and Applications 0 seconds of 0 seconds The overall vision
    of integrating multimedia applications of every domain in IoT, developing smart
    city and transforming human lives i.e., multimedia in agriculture, smar...View
    more Published in: IEEE Access ( Volume: 8) Page(s): 8202 - 8250 Date of Publication:
    06 January 2020 Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2020.2964280 Publisher:
    IEEE Funding Agency: CCBY - IEEE is not the copyright holder of this material.
    Please follow the instructions via https://creativecommons.org/licenses/by/4.0/
    to obtain full-text articles and stipulations in the API documentation. SECTION
    I. Introduction The amalgamation of the physical and digital world over the traditional
    Internet paved the way for the future Internet of Things (IoT). IoT is envisaged
    as the network model to fill the gap between the cyber and physical world [1].
    The core concept of the IoT is to connect the pervasive objects around us, such
    as Radio Frequency Identification (RFID) tags, mobile devices, sensors and actuators
    to the Internet through a wired or wireless network. Hence, it enables the objects
    to interact with each other and their neighbors to enhance the efficiency of the
    system [1]. Several researchers have defined IoT in various contexts [2]: “The
    integration of tiny devices known as Smart Objects (SO), usually battery operated
    equipped with a Microcontroller (MCU) and transceivers into the global Internet.
    The services offered by these smart objects are known as Smart Services (SS) [3]–[6].
    IoT has created new opportunities for machines to communicate with each other
    and extend the offered applications. Currently, 23 billion devices are connected
    to the Internet [7], and these numbers will stretch to 30 billion by 2020 [8].
    Conventionally, IoT was assimilated relatively in data sensing devices, particularly
    in the Machine to Machine (M2M) environment [9]. Vigorous growth in the connected
    devices to the Internet during the last decade and abrupt demand for multimedia
    traffic has given rise to the emergence of the Multimedia Internet of Things (M-IoT).
    The equilibrium between QoS data and best-effort data is now in transit towards
    an increase in multimedia QoS data. Currently, IoT is an assortment, comprising
    of M2M, Human-to-Machine (H2M), Human-to-Human (H2H), and Machine in/or Humans
    (MiH) communications (MiH devices may include human embedded chips, medical monitoring
    probes, and Global Positioning System (GPS)) [10]. M-IoT smart objects are usually
    resource-constrained, in terms of energy, memory storage, and processing power.
    To make the devices smaller, cost-effective and energy-efficient, sensors are
    usually designed to be battery operated or solar powered with only a few kilobytes
    of memory, and limited processing power in megahertz. Multimedia QoS data shows
    antagonistic behavior as compared to emblematic IoT scalar data. M-IoT devices
    require higher bandwidth, bulky memory resources, and higher computational power
    to analyze and process the procured multimedia data. Table 1 shows the difference
    between scalar and multimedia IoT data. The traditional multimedia application
    involves the data transmission of point-to-point, point to multipoint, or multipoint
    to multipoint. On the contrary, M-IoT applications require immense data transmission
    during multipoint-to-point communication (e.g., the surveillance system of the
    entire smart city) or multipoint-to-multipoint. Dynamic network, heterogeneous
    data, higher throughput, QoS, and delay sensitivity over such resource-constrained
    M-IoT smart objects escalates the challenges for M-IoT. TABLE 1 Comparison of
    Scalar and Multimedia IoT Data Multimedia data i.e., audio, image, and video is
    set of unstructured features. Transmission of such bulky and unstructured data
    over bandwidth and computationally scarce network requires efficient and intelligent
    network topology. The addition of multimedia data acquisition and communication
    requires revision and amplification of the traditional IoT system, which we refer
    to as M-IoT. The revision of IoT for multimedia communication requires efficient
    feature extraction, event processing, encoding/decoding, energy-aware computation,
    lightweight and priority-based routing, QoS and QoE maintaining performance metrics,
    effective channel access, and fair-MAC protocols. Real-world multimedia applications
    include an example of rescue vehicles based emergency response systems, traffic
    monitoring, GPS based path tracking, agricultural monitoring, crime inspection,
    smart cities, smart homes, smart museum, surveillance systems, security system
    for authentication and authorization, multimedia-based e-health, patient monitoring
    in smart hospitals, and industrial monitoring systems. Fig. 1 conceptualize the
    multimedia communication in IoT in every domain-specific applications. FIGURE
    1. The overall vision of integrating multimedia applications of every domain in
    IoT, developing a smart city and transforming human lives, i.e., multimedia in
    agriculture, smart health, security, industrial process, road management systems,
    and real-time applications. Show All This article presents a comprehensive state
    of the art survey on M-IoT. There are several published research papers that cover
    different aspects of IoT. To the best of our knowledge, this article is the first
    that covers the studies specifically targeting multimedia communication in IoT
    in the context of the above-mentioned requirements. A. Contributions of This Survey
    Article In summary, this work aims to make the following contributions: To provide
    a detailed survey of various M-IoT network architectures. To survey the various
    M-IoT applications i.e., traffic monitoring, habitat monitoring, surveillance
    for public safety, industrial monitoring, and health monitoring. To discuss the
    design for M-IoT communication by summarizing performance metrics for M-IoT architectures.
    To survey the M-IoT computing paradigm comprising multimedia data compression,
    event processing, fog/edge computing, cloud computing, and Software-Defined Networks
    (SDNs) for data computing. To discuss various routing protocols in the context
    of multimedia data delivery in M-IoT. To provide a survey on different physical
    MAC (PHY-MAC) protocols for M-IoT. To provide open issues, challenges, and future
    research directions involving M-IoT. B. Comparison of Related Survey Articles
    Alvi et al. in [4] delineate the concept of M-IoT. The article is classified into
    two categories: M-IoT vision and, M-IoT applications and use cases. In the first
    category, authors have presented the vision of M-IoT and proposed four-layer multi-agent-based
    M-IoT architecture. Requirements and open issues in each layer are also discussed
    in this section. Moreover, IoT has been analyzed in-depth in the context of multimedia
    data. The authors have also discussed several video encoding and compressing techniques.
    The second section outlines the various multimedia applications and uses cases
    concerning M-IoT. However, this article does not cover a detailed survey on M-IoT
    specifically. An in-depth discussion on various enabling technologies, i.e., MAC
    protocols and network layer protocols, is missing. Discussion on future machine-type-communication
    and integration with 5th generation (5G) cellular communication is not found.
    Furthermore, various QoS and QoE depending factors and Information-Centric Network
    (ICN) approach regarding M-IoT are not discussed. Multimedia computation technologies
    are not found in this article. The discussion on M-IoT in the context of architecture,
    enabling technologies, MAC and routing protocols is not found in the recent survey
    articles on IoT [2], [11], [12]. The existing survey on energy-efficient M-IoT
    is presented in [13]. This study explains the working of each layer of the traditional
    IoT architecture; however, the intrinsic nature of multimedia data is not considered
    in any aspect. Different routing protocols are discussed in [14]–[18]. A detailed
    survey on multimedia routing in wireless sensor networks is presented in [17],
    [19]. However, these articles present a brief overview of multimedia routing and
    the comparison of various routing standards. It merely discusses the issues and
    challenges of current multimedia data requirements. Current M-IoT takes not only
    QoS but QoE into consideration that is dependent not only on network parameters
    but user’s hardware capabilities itself. MAC protocols and efficient resource
    allocation standards are presented in [20]–[23]. BlueVoice has been evaluated
    for multimedia services in real-time IoT devices in [24]. QoS is analysed in [25]–[29],
    while QoE is studied in [30]–[35]. The concept of Quality of Information (QoI)
    and ICN using a distributed algorithm for multimedia data collection is proposed
    in [36]. Kaaradi et al. [30] have presented the concept of Quality of Things (QoT)
    for M-IoT. However, it lacks QoS objectives. The rest of this article discusses
    the introduction of the virtual layer for virtual object representation and cross-layer
    communication. Cross-layer design related to M-IoT is presented in [33], [37],
    [38]. Thiyagarajan et al. [39] have proposed a secure video transmission energy-aware
    encryption scheme for M-IoT. Using Dictionary Learning (DL) and Approximate Message
    Passing (AMP). A compressed sensing technique is proposed for M-IoT in [40]. Various
    video encoding schemes and multimedia sensing are outlined in [41], [42]. Performance
    comparison of Advance Video Codings (AVC) H.265 and H.264 is presented in [43].
    A detailed survey on multimedia big data computation is presented in [44]. Salman
    et al. in [45] present a survey on IoT from the perspective of Fog and SDN technologies.
    Articles [46]–[48], present review on multimedia in road traffic management and
    biometric security. However, all these studies do not include a survey on multimedia
    communication in any form. Existing challenges, issues, and proposed work from
    the perspective of M-IoT are not presented in any of the articles. Comparison:
    From the word comprehensive, this article provides an in-depth overview of M-IoT.
    This article specifies the limitations of IoT architecture and user requirements
    of multimedia data in order to revise IoT architecture. This enables us to cover
    a review of various IoT architectures supporting wireless multimedia communication.
    Computation is the key feature required for M-IoT. Limitations of cloud computing
    in exhausting the bandwidth and energy-constrained networks are identified. Advantages
    of Fog/Edge computation to assist cloud computing are presented. SDNs are moving
    the IoT architecture towards network virtualization. SDNs in the perspective of
    M-IoT is detailed in this article. This article also discusses the use of Machine
    Learning (ML) as an important aspect for feature extraction from multimedia data
    which extracts meaningful information from unstructured multimedia data. In addition,
    this paper presents various event processing mechanisms to reduce network overhead
    and latency. QoS and QoE metrics are well defined and evaluated in this article
    by comparing it with existing work. Routing and PHY-MAC protocols are well surveyed
    in the literature. However, contemporary literature lacks the consideration of
    multimedia data nature and requirements. This article presents a comprehensive
    overview of multimedia applications and uses cases. This article only includes
    research work that specifically considers multimedia (audio, video, image, visual)
    data in IoT. To the best of our knowledge, this article is the first to present
    a comprehensive survey on M-IoT. A comparison of this article in the context of
    M-IoT with other survey articles is presented in Table 2. TABLE 2 The Comparison
    of Comprehensive Survey on M-IoT C. Article Structure The remainder of the paper
    is organized as follows: Section II presents an overview of IoT architecture and
    a comparison of different architectures of multimedia communication in IoT. Diverse
    applications of M-IoT are discussed in Section III. Section IV summarizes the
    performance metrics, design requirements and existing work to maintain quality
    in M-IoT. Section V presents the M-IoT computing paradigm, including multimedia
    coding, event processing, cloud, Fog/Edge computing, and computing using SDNs.
    Section VI covers various routing protocols for M-IoT, while PHY-MAC protocols
    are discussed in Section VII. Section VIII discovers the open issues, challenges,
    and future research directions for multimedia communication in IoT. Finally, section
    IX concludes the article. Table 3 accords the list of acronyms used throughout
    this article. Fig. 2 shows the classification of this article. TABLE 3 The List
    of Acronyms and Corresponding Definitions FIGURE 2. Taxonomy of this article.
    Show All SECTION II. IoT and Multimedia IoT Architecture A. IOT Architecture “Anything,
    anytime, anywhere, any media” has become the axiom for IoT communication. Kevin
    Ashton first coined the term IoT in 1999 [49]. The concept of the M2M has gained
    momentum after the development of the first RFID. RFID uses an electromagnetic
    field that automatically detects and wirelessly tracks the object. RFID is a vital
    component of the IoT since it links millions and billions of physical objects
    with the cyber world [50]. Currently RFID is used in various IoT applications
    such as supply chain management, gestural detection [51], E-health [52], mobile-based
    payments [53], and intelligent restaurants [54]. Diverse IoT applications and
    devices from various manufacturers create heterogeneity in the network, which
    increases the challenges to achieve a unified and interoperable standard. Thus
    to speak and understand various languages, numerous architectures are proposed.
    However, no one has converged to a standardized architecture. Cloud computing
    layer-based architecture is proposed in [12]. The motivation and requirement of
    middleware based IoT architecture are presented in [55]. The integrated architecture
    of short-range micro IoT (e.g., IEEE 802.15.4 and IEEE 802.11 standards) and macro
    Sub-GHz technologies is proposed in [56]. Hu et al. [57] proposed the concept
    of the Software-Defined Device (SDD) layer-based IoT architecture. Security and
    cognitive layer-based IoT architecture for enhancing efficiency, scalability,
    security, and privacy is presented in [58]. The article [59] proposes an energy-efficient
    IoT architecture based on cloud computing, sensor sleep intervals, and QoI. Fig.
    3 shows the IoT architectures proposed in the literature. FIGURE 3. (a) Basic
    three elements of IoT: power-constrained hardware sensors or devices to sense
    and acquire the data, a middleware to process, analyze, and transmit the desired
    data, and application which visualizes the processed data and results. The existing
    proposed IoT architectures. (b) Middle-ware based [55], (c) Software-defined-device
    based [57], (d) Cloud-based [12], (e) Traditional three-layer IoT architecture
    [60]. Show All The traditional IoT comprises three fundamental elements: mostly
    power-constrained hardware devices to sense and acquire the data, a middleware
    to process, analyze, and transmit the desired data, and application which visualizes
    the processed data and results. These three fundamental elements are depicted
    in Fig. 3(a), and it forms the basis of IoT architecture: 1) things layer, 2)
    network layer, and 3) application layer [60]. 1) Things Layer It is the bottom
    layer in IoT architecture, also known as the perception layer, device layer, or
    sensor layer [61]. This layer is composed of a sensing hardware, scalar or multimedia
    sensors, and actuators, depending upon the services required by the application.
    Sensing devices have uplink data transmission mode while actuators have downlink
    data functionality. Access devices have the competency to operate in both uplink
    and downlink data transmission mode [57]. The main objective of this layer is
    to interconnect things in the IoT network. These devices sense, acquire and pre-process
    data from the physical world either locally or send the data to the centralized
    servers through gateways using Local Area Network or Wireless Personal Area Network
    (LAN/WPAN) via short-range low power enabling technologies like Zigbee, Bluetooth
    Low Energy (BLE), Ethernet, IEEE 802.15.4, etc. 2) Network Layer It is the middle
    layer in IoT architecture, also known as the transmission layer [62]. Virtually
    it is divided into two sub-layers: the access network and the core network. The
    main functionality of the network layer is to process the received data from the
    things layer. Therefore, it determines the energy-efficient optimum route to transmit
    the data to the IoT servers, devices and applications via the Internet using one
    of the communication networks such as WiFi, Ethernet, 3G, Long-Term Evolution
    (LTE), 5G or satellite network [63]. The access network layer is responsible for
    interconnecting various devices and applications through interfaces or gateways
    among Heterogeneous Networks (HetNet) using various communication protocols. The
    core network is responsible for determining the optimum route. Currently, the
    network layer should also support both Internet Protocol version 4 (IPv4) and
    IPv6 networks considering the requirements of cross-domain interoperability in
    heterogeneous IoT networks. Furthermore, to optimize the IoT uplink transmission,
    devices (e.g., smartphones and vehicles) are also exploited as sink nodes for
    an end to end communication, such as Device-to-Device (D2D) communication [64].
    Various data link layer and network layer protocols are presented in section VI
    and section VII. 3) Application Layer It is the top layer in IoT architecture,
    also known as the business layer [11]. Based on the functionality of the layer,
    it is virtually subdivided into two layers, i.e., service sublayer and application
    sublayer [65]. The service sublayer provides information management, data mining,
    data analytics, and decision-making services. The application sub-layer needs
    to provide the required services to end-user or machines. The application layer
    primarily analyzes the required services of IoT application and transforms the
    physical world data into the expressions of cyber world demands. Constrained Application
    Protocol (CoAP) is proposed by IEEE 802.15.4 standard [66] to improve data packets
    delivery and to reduce overheads. The messaging layer and request/response layer
    are two defined layers in CoAP. Other proposed IoT application layer protocols
    are Data Distribution Service (DDS), Advanced Message Queue Protocol (AMQP), and
    Extensible Messaging and Presence Protocol (XMPP) [11]. B. M-IoT Architectures
    The characteristics of IoT make it possible to support multimedia applications.
    However, it poses enormous challenges as multimedia applications are bandwidth-hungry
    and delay-sensitive. Radio and computational resources are preciously scarce for
    IoT devices. The rapid surge of multimedia data in IoT leads to vast amorphous
    data. Researchers have proposed different M-IoT architectures to efficiently analyze,
    process, and utilize the resources with more reliability. Novel M-IoT architectures
    are presented in this section. Fig. 4 and Table 4 summarizes existing M-IoT architectures.
    TABLE 4 M-IoT Proposed Architectures FIGURE 4. The existing proposed M-IoT network
    architectures: multi-agent-based M-IoT architecture [4], agent-based M-IoT architecture
    [67], AI-based SDNs for multimedia traffic management architecture [68], Fog-Cloud
    hybrid M-IoT architecture [69], and Big data layered M-IoT architecture [70].
    Show All 1) Multi-Agent Based M-IoT Architecture Based on the bulky and unstructured
    nature of the multimedia content, researchers in [4] propose a multi-agent cloud
    computing-based architecture for multimedia communication in IoT. The authors
    have outlined multiple open issues in M-IoT over different communication layers.
    The presented architecture is separated into four main parts; Multimedia sensing,
    reporting and addressability, multimedia aware cloud, and multi-agent systems.
    Multimedia sensing is responsible for pre-transmission processing, which includes
    transformation, quantization, estimation, and compression techniques to reduce
    the bandwidth requirements. In addition, authors have suggested equipping the
    network with energy harvesting capabilities to balance the tradeoff between feasible
    compressions and the energy-constrained M-IoT devices. The report and addressability
    comprise the abilities of the link-layer enabling technologies, i.e., IPv6 over
    Low-Power Wireless Personal Area Networks (6LoWPAN) based IPv6 Routing Protocol
    for Low-Power and Lossy Networks (RPL), green communication, transport, and application
    layer. The multimedia-aware cloud performs four main jobs that are: Multimedia-aware
    middleware is responsible for understanding various requirements/services of the
    end-users and adapts itself to aggregate, process, learn, filter, and deliver
    the services. The device should be uniquely identified to globally access and
    control remote multimedia devices based on several techniques, i.e., Internet
    Protocol (IP), Domain Name System (DNS), Uniform Resource Identifier (URI), and
    Object Name Sevices (ONS). Naming the multimedia content to manage huge multimedia
    data using Digital objects Identifiers (DOI), Digital Item Identification (DII),
    or Digital Item Declaration (DID). Data storage and processing are responsible
    for offering massive storage with the scalability, accessibility, and security.
    Along with stored multimedia, data should be categorized and indexed according
    to the end-users requirement. Multimedia content access requires security and
    privacy policies. Content-Delivery-Network (CDN) is proposed to process multimedia
    content in a distributed manner to overcome resource constraints. The multi-agent
    cloud performs data mining and data analysis, service composition, and content
    sharing. Authors have defined agents as autonomous software working independently
    to achieve objectives subject to design constraints. Kaeri et al. [67] further
    enhance the multi-agent M-IoT architecture to make it more practical by proposing
    and implementing the five-layer architecture. The proposed architecture includes
    a novel concept of modules based channel that comprises multimedia device communication,
    M-IoT services, resources, and a resource connector layer. Service execution agents
    and applications layer holds the upper position in the proposed architecture.
    Various multimedia devices and communication stack form the things layer. Multimedia
    data stream to or from the devices forms M-IoT service of the resource layer.
    Cloud resource is a special type that performs asynchronous communication. Edge
    nodes operate on synchronous communication for real-time processing. Resource
    connector exchanges messages to or from M-IoT service and resource layer with
    service execution agents layer which serves modules according to application requirement.
    It also provides Application Programming Interfaces (APIs) for applications. The
    authors have conducted experiments by implementing their proposed architecture
    in the remote collaboration support system for video conferencing [67]. 2) AI-Based
    Software-Defined M-IoT Architecture The robust increase in multimedia traffic
    necessitates an efficient network traffic management system. Rego et al. [68]
    propose an intelligent network management system for the IoT video surveillance
    system based on SDN and Artificial Intelligence (AI). The AI module is integrated
    into SDN to guarantee the QoS and QoE based on delay, loss rate, and jitter. The
    authors define two main functionalities for the AI module, i.e., data classification
    and resource estimation. The SDN controller governs SDN. After the SDN controller
    receives the data from IoT Network Heads (NHs), the SDN controller sends a request
    to the AI module to classify the data. Multimedia data is classified as critical
    traffic. The article also highlights the preprocessing standards to prioritizes
    the data set by classifying it as critical and label it in increasing order with
    1 being non-critical traffic and 5 being very critical traffic. Various Machine
    Learning (ML) approaches are compared to train AI traffic classification module
    to achieve the best performance that is a Support Vector Machine (SVM), Neural
    Network (NN), and statistic method (Kernel). Bayes statistic model is used for
    network resource estimation based on traffic priority, route traffic, bandwidth
    variation, buffer management, nodes sleeping duration in the network, and activate
    backup nodes. Open Flow architecture is used to communicate between the SDN controller
    and NHs. The authors also propose a customized message protocol for communication
    between the SDN controller and the AI module, and NH and IoT nodes. Experiments
    are conducted using emulator Mininet, and several results are presented. Results
    depict 77% accuracy of the AI module. 3) Fog-Cloud Hybrid M-IoT Architecture Rahman
    et al. [69] propose a context-aware fog-cloud hybrid based framework that integrates
    spatio-temporal multimedia data from IoT mobile and stationary nodes for the massive
    ad-hoc crowd. In the article, a three-tier architecture: mobile client tier, fog
    node tier, and remote cloud tier, is presented. The authors aim to optimize energy
    resource utilization and reduce end-to-end delay for the massive crowd in the
    smart city. The mobile client tier includes service consumers. Fog nodes tier
    comprises smartphones and other IoT fog nodes distributed in the city to assist
    in real-time processing of spatio-temporal collective or individual queries. Cloud
    tier is formed of IP based massive big data architecture to analytical compute,
    store, and process offline queries. BLE, WiFi Direct, 5G, or D2D spectrum can
    be used for communication within the fog tier. Cloud comprises of four different
    platforms that are the crowdsensing service, social network service, mobile or
    stationary IoT service, and crowdsourcing service. Smartphone acting as a context
    manager and fog node, provides storage, computation, and communication-based on
    an individual’s historical context. Thus, it decreases a large amount of payload
    to the backend cloud. The eventual storage and complex analytical computation
    can be pushed to the cloud. User context requirements are defined according to
    their subscribed IoT services. Moreover, semantics is added to the system using
    the 3A model which assimilates the data from Body Sensor Network (BSN), crowdsourcing,
    social networks and IoT devices to a unified, generic context by the smartphone’s
    context manager to deduce elevated semantics overlay. A query can be responded
    by one or all four platforms. To find a dust-free path, dust sensors deployed
    in the city can provide real-time data, crowdsourcing delivers the query response,
    human or mobile IoT sensors provides the dust level. The response to the query
    can be made available on social network services. Crowdsensing provides congestion
    and weather-related statistics. The article presents a practical implementation
    of the proposed framework and development of smartphone application considering
    Hajj pilgrims as a massive ad-hoc crowd. 4) Big Data Layered M-IoT Architecture
    Authors in [70] proposed a novel concept of six-layered M-IoT architecture based
    on big data aggregation, computation, and extraction of multimedia content. Instead
    of word media authors have considered modal, which refers to the way the data
    is interpreted to convey meaning. Moreover, they have listed three main problems
    associated with multimodal big data computation that is to compute the huge amount
    of data, to detect and extract meaningful information and the current limitation
    of big data processing platforms for multimedia. The six layers proposed in M-IoT
    architecture are: Identification: Devices are first identified based on their
    object ID that is Electronic Product Codes (EPC) and Ubiquitous Codes (uCodes).
    Objects are further discriminately identified based on IPv4 or IPv6. An efficient
    identification technique based on the 6LoWPAN compression mechanism over IPv6
    is presented in [71]. Physical Object: This layer represents the data aggregated
    from scalar or multimedia objects based on their modality and passes on the data
    to the central unit for further processing. Communication: It has the same functionality
    of link, network, and transport layer as in traditional IoT architecture. Middleware:
    It is defined to provide software level support for functional services that is
    resource discovery, data management, and non-functional services, which include
    reliability, scalability, and security. Multimodal computation: It is responsible
    for providing hardware components for computation and Real-Time Operating Systems
    (RTOS). Authors have proposed a sub-layer for big data analytics, which includes
    a centralized data unit, multimodal data aggregation unit, multimodal divide and
    conquers computation unit, and fusion and decision-making unit. These units are
    specifically designed to aggregate, analyze, process, and extract the desired
    features from the big multimodal data. Application layer: It provides the required
    services through a set of standardizing protocols. Moreover, the article presents
    a unique and efficient technique that is Divide and Conquers Principal Component
    Analysis (DC-PCA) to reduce the dimensions, subdivides the data, process the subdivided
    data in parallel fashion, and fuse the final parallel processed data to extract
    the features. Thus making the required decision for services and applications.
    The practical implementation of the proposed DC-PCA for face recognition application
    using Yale and ORL databases is presented. The authors efficiently presented the
    functionality of each layer. 5) Security Based Architecture Zhou and Chao [72]
    devised Mediaware Traffic Security Architecture (MTSA) for M-IoT based on four
    main components. These components are key management which comprises service control,
    user control, flow control scalable, and nonscalable schemes [73]. Batch rekeying
    accommodates multiple multimedia applications based on periodic batch keying,
    periodic batch leave keying, and periodic batch join rekeying [74]. Authentication
    is achieved by group authentication, source authentication, and individual sender
    authentication employing access control list, ability certificates, and mutual
    authentication methods [75]. Watermarking is used to identify the origin of multimedia
    content, trace illegal distribution, and block unauthorized access by embedding
    a unique watermark into multimedia content [76]. The proposed framework exploits
    visual secrecy measures to provide generic multimedia security solutions that
    degrade comparatively to the number of shares in possession of an attacker. MTSA
    inherits content-awareness characteristics from media-aware based middleware security
    architecture for multimedia services [75]. C. Summary and Insights This section
    defines IoT and elaborates each layer of traditional IoT architecture. It also
    covers various architectures and the design requirements for M-IoT. Multimedia
    communication in IoT needs flexible and interoperable architecture to support
    HetNET and different multimedia applications with various application requirements.
    Multiagent, fog-cloud hybrid, big data, and multimedia traffic security architectures
    have been investigated in detail. However, quality-aware architectures and M-IoT
    computation are presented in the latter section of the article. The existing work
    on M-IoT are mostly focussed on application-dependent requirements, and it does
    not take into the consideration of standardizing M-IoT architecture. Standardized
    M-IoT architecture is in need to support multimedia content in various IoT applications.
    The use of multi-agent base ML algorithms can effectively improve the learning
    and understanding of an individual’s multimedia demands in M-IoT architecture.
    This section is summarized in Table 4. SECTION III. Applications of M-IoT Multimedia
    objects equipped with Internet connectivity and interaction with other objects
    without human intervention leads toward the vast opportunities for the betterment
    of humankind in daily life. Since multimedia data is rich in information. Features
    like face recognition, motion detection, license plate identification, driver
    drowsiness indication, patient state, crowd detection, path hole, and obstacle
    detection, retina scanning for authorization and crime detection can be extracted
    employing various data aggregation, analytics and extraction tools. A heterogeneous
    network of multimedia objects, ubiquitous data transmission, and cloud-based multimedia
    content analytics paved the path for smart cities. In this section, we have classified
    numerous M-IoT applications based on different roles in the smart city. Table
    5 classifies and summarizes the applications of M-IoT. TABLE 5 Applications of
    Wireless Multimedia Communication in IoT A. Road Management System 1) Traffic
    Monitoring Efficient traffic monitoring and control is one of the major issues
    in the smart city. To handle this problem, there are different solutions based
    on infra-red detectors, magnetic loops, and microwave radars. These conventional
    techniques incur huge installation, maintenance costs, and lack of accuracy. The
    researcher put forward M-IoT based techniques to effectively detect and identify
    the volume of traffic and predict the reason for a traffic jam. Fig. 5 conceptualize
    the M-IoT to enhance the road management system. Authors in [77] presented computer
    vision-based ontology-driven context-aware M-IoT architecture to estimate the
    traffic by tracking the number of vehicles present on the road in real-time from
    CCTV camera video and segregate moving vehicles from stationary vehicles. Based
    on the density of stationary traffic that occupies the road is compared to a threshold
    value. Multimedia Web Ontology Language (MOWL) has been adopted, which utilizes
    time-varying Dynamic Bayesian Networks (DBN) for comparison and predicts the cause
    of traffic congestion. Automatic alerts can be triggered by road traffic authorities
    to avoid a traffic jam. Raspberry Pi and Pi camera-based IoT architecture are
    presented in [46] for traffic surveillance and road accidents. The authors used
    a Gaussian Mixture Model (GMM) with canny edge detection on VIRAT and MIT traffic
    data set to evaluate their proposal. The article also presents several surveyed
    efficient methods, i.e., hidden Markov and neural network, Lucas-Kanade, and K-means
    clustering techniques for accurate accident detection and vehicle tracking. FIGURE
    5. The use case of M-IoT for road management systems that includes accident detection
    and prevention system ([46], [82]), traffic estimation and congestion prevention
    systems [77], lane and path hole detection ([81], [83]), trespassing detection
    [91], automatic emergency detection and alerts generation systems [86], and traffic
    signal monitoring system ([78], [90]). Show All George et al. [78] proposed an
    Adaptive Nero Fuzzy Inference System (ANFIS) and image processing based technique
    using M-IoT for the better traffic light management and monitoring system. Camera
    images are obtained and analyzed on a ThinkSpeak based cloud server. Based on
    the analysis, control actions are given to traffic lights. Machine vision blob
    analysis technique is used to detect and locate the vehicle. Due to poor illumination
    conditions during night, the Otsu image processing technique is used. Low Power
    Wide Area Network (LoPWAN) and Long Range (LoRa) receiver and transmitters are
    adapted to propose IoT smart traffic monitoring and control architecture in [79].
    A comparative survey on the M-IoT based traffic management system is presented
    in [80]. 2) Path Detection, Lane Detection, and Accident Reporting Autonomous
    or Unmanned Ground Vehicles (UGV) are the key element in the development of a
    smart city. Lane detection is considered a vital feature to avoid a collision
    in UGVs. Image-Based obstacle detection and path planning are discussed in [81],
    which includes the conversion of video into fixed-rate image frames. Frames are
    then analyzed using image processing techniques, i.e., edge extraction and thresholding.
    A cloud-based M-IoT system is proposed for accident prevention in [82]. HoneyBee
    Optimization (HBO) based IoT road monitoring system is proposed in [83] to detect
    humps and pothole to prevent accidents. A driving algorithm for path planning
    is proposed for autonomous vehicles exploiting potential field methods and lane
    detection in [84]. Data is acquired using CCD cameras, differential GPS, 2-dimensional
    laser scanner, and digital compass. The analysis is performed using the proposed
    algorithm for lane detection. CDN and MPEG Dynamic Adaptive Streaming over HTTP
    (DASH) are used for a real-time vehicle monitoring system in [85]. Ni et al. [86]
    present a novel lifesaving concept for the individuals left behind in the vehicle.
    The article incorporates life recognition, environmental monitoring, and alarming
    subsystem. Vehicle-to-Vehicle (V2V) communication in M-IoT based on Direct Short-Range
    Communication (DSRC) for Intelligent Transport System (ITS) is proposed in [87].
    Several benefits of using the multimedia Internet of Vehicle Things (IoVT) for
    a traffic management system are identified in [88]. Android-based IoT vehicle
    monitoring system accessing various vehicle parameters and driver behavior analysis
    using a Controller Area Network (CAN) is presented in [89]. 3) Traffic Lights
    Management An efficient, cost-effective traffic and street light control mechanism
    based on M-IoT is outlined in [90] for smart cities. The solar panel-based streetlights
    with Direct Current (DC) power supply as a backup along with Light Dependent Resistor
    (LDR) is used to control the intensity of the light when no vehicle is present
    in the street. Traffic bollards are used to avoid an accident during red and yellow
    lights. Cameras are deployed for the surveillance systems. Latif et al. [91] proposed
    the smart city model having intelligent traffic monitoring and guidance system.
    The proposed model incorporates multimedia data for authentication, verification,
    registration, authorization, shortest path identification, to high light the congested
    areas. Public places like schools, colleges, hospitals, hotels, petrol pumps,
    and banks are considered as objects and are identified by specific IDs. Cameras
    are used to monitor the flow of traffic. The shortest path is determined based
    on time or distance. Vienna Development Method-Specification Language (VDM-SL)
    is opted-in this article for modeling purposes. 4) Authentication and Crime Detection
    IP Multimedia System (IMS) based M2M metropolitan platform for traffic management
    to restrict vehicles entering the prohibited area is detailed in [92]. Authors
    in [93], proposed a Deep Neural Network (DNN) based autonomous Taxi model for
    a smart city. Authors in [94] presented a novel concept of M-IoT based crime detection
    in a smart city by analyzing human emotions and CCTV videos. After detection and
    identification of crime, it is stored in the database and visualized using a Geographic
    Information System (GIS). As the smart city is the set of heterogeneous devices
    and networks, various network architecture supporting heterogeneity, e.g., Information-Driven
    Architecture (IDRA), participatory sensing in building the smart city is high
    lightened in [95]. Automatic toll tax payments are one of the essential features
    in a smart city. Beforehand payments based on source and destination location,
    and authentication based on license plate reading as JavaScript Object Notation
    (JSON) data are described in [96]. A detailed survey on M-IoT based road traffic
    surveillance and accident detection is presented in [46]. B. Habitat Monitoring
    1) Security and Surveillance The revolutionary IoT, transforming millions of lives
    by providing ease in almost every aspect of daily routine, could turn into the
    worst enemy. For example, hackers can hack to intercept every document you print
    and redirect it to an isolated site. They could have control of your smart TV
    to bug your home. The smart metering system could be hacked to control the appliances
    of the ventilation system of your home. A traffic light management system could
    be controlled to achieve specific tasks. Variation in the pacemaker of your heart
    could be made to kill. The autonomous vehicles could be hacked to control the
    braking system for your car. These issues lead to serious threats. Traditional
    use of passwords was the authentication system until now. However, the researcher
    has proposed various IoT security and surveillance system based on multimedia
    data, i.e., retina scanning, biometric scanning, voice recognition, and video
    surveillance systems to minimize security loopholes. Enthusiastic researchers
    have further extended the usage of M-IoT to gain maximum advantage in various
    fields. The following are M-IoT authentications, surveillance, and monitoring
    application. Fig. 6 shows the M-IoT application of security and surveillance for
    habitat monitoring. FIGURE 6. The use case of M-IoT applications for security
    and surveillance in a smart city. Existing work in security using multimedia data
    mostly includes fingerprint biometrics ([97]–[99]), voice bio-metrics ([101],
    [102]), retina and iris scanning ([103], [107]), and face recognition [105]. Multimedia
    data in IoT is widely used in surveillance systems ([108]–[124]). Show All a:
    Bio-Metric Authentication Al-alem et al. [97] presented the sketch map leading
    towards the Internet of Biometric Things (IoBT) using various multimedia devices.
    Authors have outlined various steps for efficient biometric identification, i.e.,
    image acquisition, segmentation, pre-processing, and feature extraction. Moreover,
    the article presents insights about different fingerprint acquisition devices,
    i.e., optical sensors, capacitive sensors, thermal, artificial fingerprints generation,
    ultrasonic, and digital cameras. Several fingerprint databases are also plotted.
    The smart objects in Industrial-IoT (IIoT) share information on open channels
    over the Internet that makes confidential industrial plants vulnerable to an eavesdropper.
    Das et al. [98] presented the cloud-based Biometric-Privacy Preserving User Authentication
    (BP2UA) technique. The security analysis of the proposed model is conducted using
    the Oracle-based Real-or-Random (RoR) model. Telecare Medical Information System
    (TMIS) has been introduced for critical patients to communicate with doctors.
    An un-registered adversary, i.e., attackers can find the loop opportunity to mislead
    the patient to achieve specific goals. An efficient, secure smart card based on
    biometric and password double authentication procedures for remote authorization
    is proposed in [99]. H. Hamidi, in [100] presented a secure biometrics-based technique
    for Health IoT (H-IoT). b: Voice Bio-Metrics With the growing deployment of smart
    homes and smart banking applications, i.e., voice to control everything, and authentication
    by voice recognition, provide attackers with an easy loophole which is one of
    the vital security challenges ahead. Voice biometrics are proposed by several
    researchers stretching up to the verification level of the security system. Voiceprint
    verification system based on DL exploiting SVM-Neural Network (SVM-NN) and Mel-Frequency
    Cepstral Coefficients (MFCC), and feature extraction technique to increase the
    security for M-IoT systems is proposed in [101]. In this work, the LibriSpeech
    dataset is utilized for training. Meng et al. [102] present a novel system based
    on a voice liveness detection system that utilizes wireless signals from IoT devices
    and received vocal samples for verification of Voice Control User Interfaces (VUI)
    decreasing spoofing attacks. The authors named their technique as WiVo. The feasibility
    and effectiveness of the proposed system are evaluated on the Samsung SmartThings
    testbed. The article also listed several attacks on VUI. A comprehensive survey
    on biometric-based IoT security issues, challenges, and techniques are presented
    in [47], [48]. c: Retina Authentication The researcher further enhances the security
    level of IoT using multimedia communication by proposing various techniques to
    implement retina scanning and iris recognition. Pjatkin et al. [103] proposed
    a probabilistic iris recognition approach using the UPOL database to overcome
    the PCA technique. HSI and Y C b C r color spaces are used to generate the Probability
    Density Function (PDF). The KLD tool is used to extract colored eye iris information.
    Ocular Recognition (OR) for a secure IoT application has been proposed in the
    literature. Different OR techniques have been investigated in [104]. An algorithm
    based on the fusion of iris and retinal scanning is proposed for user authentication
    in Apple and Andriod devices. Retina based face recognition authentication system
    is presented in [105]. In this article, retina modeling is improved by accurate
    truncation adaption, illumination classification, and lighting estimation. Yale
    B database is utilized to validate their model. Ocular maladies damage the vascular
    patterns and create abnormalities in the retina, which hinders the accurate recognition
    for authentication. Researchers in [106], proposed an efficient vascular recognition
    technique to overcome the effects caused by lesions and to extract region-based
    features from retina images. Gabor Wavelet is utilized for noise reduction and
    pre-processing, followed by segmentation. Blood vessel validation is performed
    to eliminate false detection by a 5-D feature extraction algorithm and classification
    based on SVM. The database is formed by 5-D extracted features. Finally, authentication
    is performed with the created database. Zhang et al. [107] proposed an improved
    Iris localization authentication method. The authors modeled the system by first
    evaluating the quality of the image taken according to the image intensity, clarity,
    and integrity. The clarity of the image is evaluated by using a block-variance
    method, and integrity is defined on the location of the pupil, i.e., the pupil
    must be in the center. The algorithm works by estimating the range of center,
    radius of the pupil, and pupil region extraction, thus reducing the delay in iris
    recognition. d: Surveillance for Public Safety With the increasing deployment
    of IoT in our daily life and decline in the implementation costs, video surveillance
    systems became a key requirement for the smart city to ensure public safety for
    crime detection, home security system, industrial surveillance, and other localization-related
    features. The immobility of the PC based surveillance system encourages the researcher
    to propose IoT based security systems. Multimedia communication over IoT enables
    us to achieve this objective. Basri et al. in [108] proposed IoT residential surveillance
    system. The proposed scheme is an Android-based application and hardware which
    includes Raspberry Pi, Pi camera, PIR sensor, and ultrasonic sensors to alert
    the owner of a house with an intruder. PIR sensor detects the suspicious movement
    within the specified range, and the image taken by Pi camera is stored in the
    memory card. An email or alert message is sent to the owner by Raspberry Pi. To
    detect emergency and generate alerts for the older person at home, an Android
    application is designed and implemented based on the Real-Time Stream Protocol
    (RTSP) and Real-time Transport Protocol (RTP) [109]. The video is captured, processed,
    and encoded using H.264 at the server end. Client-end includes smartphones, tablets,
    or PC, can access live streaming using RTSP and video is decoded using FFMPEG.
    Security is further enhanced for the elderly by face detection feature using OpenCV
    library for intrusion detection, and critical screenshots are saved for emergency
    alerts. A natural language processing interface combined with ontologies and image
    analysis based video surveillance approach is proposed in [110] for content-based
    retrieval of visual data. The proposal aims to achieve passenger safety in the
    public transport system. Four ontologies are utilized, i.e., DAML time, properties,
    object, and event. PCA and SVM are used for face detection and gender classification.
    Sphinx is used for audio mapping with semantics formed by ontology vocabularies.
    Infants baby monitoring system for the detection of sudden infant death syndrome
    (SIDS) is presented in [111]. A video camera exploiting the Eulerian motion magnification
    technique developed by MIT to monitor and detect infant chest motion during breathing
    is proposed. When an emergency is identified, an alert message is sent to a parent’s
    smartphone via Twilio, which is a cloud-based communication platform [111]. Video
    summarization to reduce the search time from big multimedia data generated by
    the surveillance system and content image-based retrieval techniques for smart
    surveillance is detailed in [112]. Aggregated Channel Feature (ACF) extraction
    and bounding box approach for moving objects are used, and the cost is determined
    if any critical situation is observed. Image with a high-cost box is summarized
    and utilized for video retrieval on search, which reduces the time, memory, and
    computation requirements of the system. Lin et al. [113] proposed a multi-view
    video summarization method to address the high bandwidth transmission requirement
    for the Internet of Video Things (IoVT). The proposed scheme is based on the K-Nearest
    Neighbour (KNN) model. The performance evaluation is measured by making a comparison
    with the GMM based summarization model based on precision metrics, i.e., removal
    of redundant data, and the security of critical information. An online multi-view
    summarization algorithm and RPi based distributed video summarization sensor node
    is developed in [114] and [115]. Al-Saleh et al. [116] presented a secure framework
    for Mobile Video Surveillance Systems (MVSS) by considering a key management system
    to secure channels between all the entities, i.e., camera, Mobile Edge Computing
    (MEC), MEC to MEC, and MEC to cloud. An optimized spectrum utilization scheme
    for video streaming in environment monitoring by automatic Transport Block Size
    (TBS) index selection using narrow-band Beyond 4G (B4G) is proposed in [117].
    Video-based Indoor Positioning System (VIPS) estimating the precise face detection
    of each individual with centimeter grade accuracy is presented in [118]. The prototype
    comprises two units, i.e., an Indoor Positioning System (IPS) and Mobile Handled
    Unit (MHU). IPS is responsible for capturing the frame of individuals approaching
    an area, the face is detected for all individuals and mapped to the area location,
    after which the positioning information is broadcasted to MHU which compares the
    individual information in its database with the received information. Cen et al.
    [119] proposed an efficient video compression and encoding/decoding technique
    for wireless multiview video streaming applications in IoT to enhance the energy
    efficiency of the system. The researcher in [120] presents the concept of distributed
    edge computing to minimize the video processing load at the cloud for real-time
    wireless multiview surveillance systems. Authors name this approach as Vigil,
    a camera with Edge Computing Node (ECN), which priorities the video frames from
    multi-camera deployed in the same region for multiview and intelligently schedule
    them for efficient resource utilization. It also provides a user input interface
    for a specific query. Slicing and parallel processing approaches to efficiently
    handle the bulky nature of IoVT are proposed in [121]. sTune architecture is followed
    in this approach, in which a metadata manager manages several cloud storage endpoints.
    The processing unit is composed of a master node and several slave nodes. The
    master node is capable of retrieving data from sTune and assigns the slave nodes
    to process the sliced video data in parallel. After processing master nodes stores
    the processed data back to the cloud. CPU and memory usage are considered as performance
    metrics to evaluate the performance. A multimedia application requesting the same
    content from M-IoT is delivered separately over the core network that increases
    the overhead. To cope with this issue, Silva and Neto [122] propose SCORPIO, an
    SDN control plane to provide multimedia multipart transport services to duplicate
    the multimedia packets at the edge of the network and map them with the applications
    of common interest in the data plane path. The performance metrics to evaluate
    the proposed methodology are throughput, jitter, and packet dropping ratio. Quality
    of Computing (QoC) is introduced in [123] to determine the occupancy of the network.
    The article presents an SDN based network selection approach to maintain QoC in
    HetNet. The proposed approach selects between the licensed band (LTE) or unlicensed
    (WiFi) for real-time services. The data aggregated at the sensor is transmitted
    to the edge processor over upstream links, i.e., LTE and WiFi. The Edge processor
    evaluates the received packets according to the data path and computational goals,
    and feedback is sent on a reverse path. Kougianos et al. [124] proposed a novel
    concept of using quadrotors for IoT real-time automatic tracking applications.
    C. Multimedia IoT in Industrial Applications 1) Smart Industry IIoT is the main
    component of the smart industry, enhancing product manufacturing, and optimizing
    the industrial process. Multimedia characteristics further enhance the outcome
    of the industrial process, as shown in Fig. 7a. The steel industry is known as
    the backbone of any nation. The steel industry modernizes civilization by playing
    a lead role in technology development. Steel manufacturing is performed at high
    temperature. Therefore track identification is challenging under such circumstances.
    Automatic depth-based vision feature extraction and track identification in steel
    billet to maintain the quality of steel products in a smart industry by M-IoT
    is proposed in [125]. Online images are taken once steel billets are manufactured.
    Features are extracted using Local Binary Pattern (LBP) and stored in a database
    with identification codes. The framework for 3D surface inspection of steel billets
    is presented in [126]. 3D scanning is performed using a camera by continuously
    capturing multiple images, and green-line lasers are utilized to extract the depth
    information of steel billets to inspect the object from various angles in the
    smart industry. FIGURE 7. The use case of M-IoT in industrial and agricultural
    applications. (a) Multimedia data flow in industrial IoT for inspection of steel
    manufacturing ([125], [126]), combustion quality maitenance [128], and industrial
    meter reading [129]. (b) Agricultural application of M-IoT for crop monitoring
    for production control ([134]–[139]). Show All Condition Monitoring (CM) system
    based on M-IoT is defined in [127]. It detects defective machines to prevent production
    outage and reduce the operational cost in the oil-gas petroleum industry. Thermal
    and gas turbine power plants are the biggest assets of the nation. Flame color
    video recording and images are analyzed to optimize air to fuel ratio that ensures
    combustion quality. Sujatha et al. [128] proposed Fishers Linear Discriminant
    (FLD) analysis technique for dimension reduction and classification. An Artificial
    Neural Network (ANN) based on Back-Propagation Algorithm (BPA) and Ant Colony
    Optimization (ACO) for feature extraction from flame images and videos are utilized
    to maintain the combustion quality. An automatic industrial meter reading device
    based on online Optical Character Recognition (OCR) is designed in [129]. After
    extracting readings of various industrial meters from images, the device logged
    the readings to the cloud. At the cloud, data is processed and made centrally
    available to authorized users on PC, smartphones, and laptops. The proposed smart
    device improves time utilization by reducing human intervention. Solar-powered
    grid estimation employing sky camera based on Energy Harvesting Wireless Sensor
    Networks (EHWSN) is presented in [130]. Authors in this article maximize the transmission
    quality of sky camera images and minimize the energy consumption of multimedia
    data transmission by determining the best forward relay path. 2) Smart Museum
    Preservation of culture is essential for our future generation to establish and
    strengthen their identity. The Museum industry plays a critical role in preserving
    cultural heritage and displaying knowledge about it. It is the primary source
    of promoting tourism and improves economics statistics. Smart Museum is the need
    for a smart environment to inspire tourists from all over the world. A smart device
    is proposed in [131] to gather localization information of the visitor using BLE.
    It automatically provides the information related to art in front of it using
    image processing and stores it to the cloud to be accessible on smart devices.
    Foreground detection and background subtraction are utilized in the proposed work
    for extraction and image processing. To manage the huge historical data and enhance
    the guiding system for tourist in a smart Museum, M-IoT beacon devices based on
    Raspberry Pi for content delivery operating on BLE is proposed in [132]. The researcher
    further takes M-IoT benefits by implementing computer vision-based image recognition
    transport robots for an automated warehouse in [133]. Neural network-based image
    classification is performed using the Orange Pi hardware platform. CvCanny library
    is utilized in this work for object edge detection to track the path inside the
    warehouse facility. 3) Smart Agriculture Agriculture is another important industrial
    sector. Researchers are trying to revolutionize the agriculture sector to increase
    its productivity by incorporating M-IoT (See Fig. 7b). Nisha and Megala [134]
    present automatic irrigation and an infected area monitoring system using a wireless
    camera in the crop field to aid farmers. Zigbee transceiver is deployed to incorporate
    low power Zigbee over IEEE 802.15.4 protocol for communication and managing sensors
    data. K-means clustering machine algorithm is used for the detection of disease,
    color determination, and pest detection. Agricultural production framework to
    monitor and predicts the future harvest of crops to maintain balance in supply
    and demand is proposed in [135]. The software-based visual general user interface
    is implemented, and live streaming of the field crop is obtained by deploying
    a wireless camera. Dynamic data analysis for crop growth management system using
    IoT is proposed in [136]. The dynamic system equips the farmer with the historically
    analyzed data on a smartphone while moving in the field by communicating with
    the nearest deployed sensor node. An efficient low power MAC-based WSN working
    in a dynamic duty cycle scheme is presented in work to resolve the congestion
    condition. The system is evaluated in the context of packet delivery ratio, end-to-end
    delay, and duty cycles. Authors in [137] present a detailed study of various IoT
    agricultural crop monitoring systems. Android-based food recognition application
    to automatically recommend a cooking recipe is presented in [138]. The proposed
    work employs Speeded-Up Robust Features (SURF) with the Hessian detector to extract
    144 64-dimension features, Bag-of-Features (BoF) for feature representation technique
    and SVM as a classifier. The proposed scheme gives 84% of the recognition rate.
    Witjaksono et al. in [139] exploits IoT based application for images recognition
    to determine the freshness of the food. The application also discriminates halal
    meat from non-halal meat for Muslims. D. Health Monitoring Multimedia data provides
    the medium to communicate, monitor, and cooperate with various aspects of daily
    life at numerous levels of granularity across various applications, which in terms
    of health is known as personal health media. Incorporating personal health media
    in one device to measure everything using IoT is the features of the future health
    system, as shown in Fig. 8. For this purpose, highly elaborative personal health
    data features are required. Boll et al. [140] presented a logical device layer-based
    architecture for mapping multimedia signals from various devices to the smallest
    elaborative unit named as primary health feature. Mapping is also performed to
    fuse multiple features and deploy advanced analytics to gain minor health details.
    FIGURE 8. The use case of M-IoT for Health. The existing work of M-IoT for smart
    health includes remotely personal health monitoring ([140]–[142]), robotic ambulance
    [144], X-ray for robotic surgery ([145], [146]), biomedical training for surgeons
    [147] and ocular diseases detection using smartphones [148], [149]. All these
    applications could be integrated using cloud service to be available for online
    and offline access. Show All Zafra et al. [141] addressed the issue of coexistence
    wearable devices for e-health with traditional three-layered IoT architecture
    and proposed a pervasive layered architecture to integrate M2M communication between
    e-health wearable and IoT devices. Shah et al. [142] highlight the challenges
    in analyzing big data generated from remote health monitoring and decision making
    by comparison with the patient’s history. The authors also provided details of
    various QoS driven Cloud of Things (CoT) based data processing for remote health
    applications. Rehman et al. [143] proposed 5G small cell network deployment in
    an ambulance for efficient uplink medical video streaming to enhance the medical
    QoS (m-QoS). Ultrasound video is considered as uplink traffic. Medical QoS performance
    is analyzed on the basis of throughput, delay, and Packet Loss Ratio (PLR). Results
    depict that implementing small cell networks augments the performance of the system.
    However, improvements are still required for deploying remote medical health systems
    as packets drop in critical medical condition is not tolerable. Sudden cardiac
    arrest is a heart condition in which heart stops due to lack of oxygen leading
    to death if immediate Automated External Defibrillator (AED) is not given. AED
    is a small device for untrained or minimal trained personnel to use it until the
    first aid arrives. Samani and Zhu [144] designed an intelligent robotic ambulance
    named AmbuBot to provide AED to save a life. AmbuBot is equipped with a GSM module
    for remote connectivity and high-resolution cameras for Lane Keeping System (LKS)
    to track lanes and prevent accidents. The system can be further extended for multiple
    conditions, body sensors, and multiple robots for collaborative work. Robot-Assisted
    Fracture Surgery (RAFS) is revolutionizing the medical health care by reducing
    infection risk during surgery and perfectly manipulate each bone fragment into
    the perfect position. The coordination system is in need between the detected
    bone track and an external robotic tool to exact position the broken bone. Automatic
    tool detection for surgery assistance based on computer vision X-ray images is
    proposed in [145]. Block detection, geometric model matching, and principal component
    analysis are utilized to achieve a 91% success rate. The robotic arm can extend
    the perfection provided by 3D positioning. Smartphone controlled Raspberry Pi
    based robotic arm is designed to assist the doctor in surgery [146]. The platform
    offers built-in compatibility of WiFi, camera and other sensors. Surgical skills
    and effectiveness directly affect the patient’s health. To minimize the harm to
    the patient, surgeons should be highly trained with subjective skills. To overcome
    this problem, research scientists, along with the medical Doctors in [147] have
    designed a biomedical IoT data extraction technique to train surgeons and provide
    real-time feedback on their skills efficiently. The proposed biomedical trainer
    architecture comprises virtual images, medical images, patients data, and journal
    data. The performance of the surgeon is evaluated by capturing the surgeon’s technique,
    visualizing the data, and comparison with the benchmark. Multimedia data features
    in IoT further benefits the field of medical health by retinal cataract detection
    technique for remote area patients. To achieve this, authors in [148] proposed
    a design to implement a microscopic lens over a low-cost smartphone camera and
    real-time detection by FeedForward Neural Network (FFNN) trained the algorithm.
    Yin et al. [149] enhance the system to detect multiple ocular diseases. The proposed
    automatic architecture includes retinal images of data acquisition using a fundus
    camera. Cloud platform stores patient history, process, analyze and extract features
    of stored images. The reports are generated after analysis, and corresponding
    ophthalmologists are referred. The proposed methodology aims to reduce the workload
    on medical specialists and save time. E. Summary and Insights This section covers
    the wireless multimedia delay-sensitive applications supported by IoT. Feature
    extraction from audio, video, and images are studied in detail for different applications
    in security surveillance, traffic, health, and industry monitoring. Various proposed
    methods for biometric authentication to enhance security systems are highlighted.
    Multimedia data in optimizing the performance of the industrial process is also
    detailed in this section. The existing M-IoT applications are more focused on
    feature extraction, mapping, and analysis of multimedia data. However, mobility
    has not been considered in the M-IoT network for the successful transmission of
    the delay-sensitive real-time application. Table 5 classifies the existing work
    on M-IoT applications and summarizes this section. SECTION IV. Performance Metrics
    for M-IoT As compared to traditional IoT, multimedia services are gaining admiration
    in IoT. Multimedia services are delay-sensitive and require efficient network
    models to maintain quality. The bulky nature of multimedia data increases the
    challenges to satisfy the network end-user. User-centric and network-centric metrics
    can assess quality. QoS can be determined by network-centric metrics, while user-centric
    metrics estimate QoE. QoE symbolizes the user perspective of QoS, i.e., measurement
    of the overall performance of service or network to evaluate delay-sensitive traffic.
    QoE is further influenced by two factors, i.e., objective and subjective factors.
    The subjective QoE is measured from experience evaluated by humans, which is problematic
    to measure. The objective QoE data includes network-related manageable and quantifiable
    parameters. Multimedia content over IoT can be evaluated through subjective QoE
    metrics such as Mean Opinion Score (MOS), Degradation Means Opinion Score (DMOS),
    and user satisfaction [150]. MOS is quantified by rating a user’s experience in
    the range from 1 to 5, where 5 represents the best experience and 1 as bad. Each
    MOS rating corresponds to a solo M-IoT service/session/application required by
    one or set of users and delivered by only one multimedia application. In DMOS,
    users are asked to quantify the degradation of the services as 1 being very annoying
    to 5 as degradation is inaudible. User engagement or satisfaction method can be
    adopted only when the user interacts with the application, i.e., video playtime,
    or several likes, and views. In the case of M2M communication, where the recipient
    of the application is a machine, the performance is evaluated by QoS. QoE and
    QoS perspective related to M-IoT architectures and optimization metrics are studied
    and detailed. Fig. 9 shows classification of QoS and QoE metrics to evaluate network
    and application quality. The elucidation of each study concerning QoE and QoS
    has been presented in the following subsections (See Table 6). TABLE 6 Performance
    Metrics for M-IoT Frameworks FIGURE 9. The classification of performance metrics
    for M-IoT network. The existing work on quality can be studied based on the objective-based
    QoS metrics or subjective-based QoE metrics. Show All A. Quality of Experience
    (QoE) Aware Architectures According to Qualinet White Paper [151], QoE is defined
    as “QoE is the degree of delight or annoyance of the user of an application or
    service. It results from the fulfillment of his or her expectations concerning
    the utility and enjoyment of the application or service in the light of the user’s
    personality and current state.” International telecommunication union (ITU) defines
    QoE in ITU-T Rec. P.10 [152] as follows: “The overall acceptability of an application
    or service, as perceived subjectively by the end-user.” Subjective and objective
    QoE data of the M-IoT network is mostly acquired and evaluated separately. The
    fusion of the subjective QoE data, i.e., user’s experience rating with the objective
    QoE data, i.e., bandwidth allocation, route selection, etc., is important to optimize
    the system. Huang et al. in [31] proposed a novel NN based self-learning self-updating
    framework to fuse QoE subjective and objective metrics named as QoEDF. MOS is
    adopted in this framework to quantify user experiences per service. Various factors
    affecting QoE has been presented in the article. Bandwidth allocation, jitter,
    and best route selection are considered as objective metrics. Two-layered NN based
    framework is presented to map the subjective MOS value with objective metrics.
    The optimization problem is formulated to optimize QoE by first selecting the
    best route and then assigning the required bandwidth for the selected route. Floris
    and Atzori in [153] and [154] proposed virtual layered based QoE-aware architecture.
    The term Quality of Data (QoD) is introduced to evaluate the quality or precision
    of acquired data by M-IoT devices, and QoS parameters are considered as influencing
    factors for QoD. QoE-aware framework for smart surveillance and vehicle monitoring
    system has been presented. The authors adopted MOS for numerically measuring QoE.
    Karaadi et al. [155] defined the term QoE and QoS in the rapport of M2H, H2H,
    H2H, and M2M. In the case of humans as the recipient of the multimedia services,
    the performance of the service is evaluated as QoE, otherwise, when a receiver
    is a machine, then the concept of QoT is utilized. QoT is defined as the acceptable
    quality to satisfy or complete a service session successfully. The bandwidth utilization
    is optimized by considering the minimum bandwidth at an acceptable level to meet
    the minimum requirement of an application. Results depict that the requirement
    for QoE is greater than QoT. The system can be further enhanced by utilizing ML
    approach to allocate minimum bandwidth as required to maintain QoT. Ikeda et al.
    [35] proposed M-IoT framework to evaluate QoE based on physical metrics and metaphysical
    metrics. The metaphysical metric is proposed to understand the user’s quality
    and service requirement, which varies with applications and model them with available
    physical metrics to achieve desired QoE. However, this work lacks subjective experiments
    and qualitative modeling. SDN and Network Function Virtualization (NFV) based
    QoE optimization for adaptive video streaming applications is proposed in [156].
    Video streaming comprises four main tasks, i.e., caching, encoding, forwarding,
    and playing back. Node selection for best-path selection is defined as the objective
    function subject to the constrained node in terms of resources. The proposed model
    is evaluated on Mininet a network emulator and OpenDaylight as an SDN controller.
    Performance evaluation of the model is studied based on end-to-end delay, packet
    loss, and user’s QoE. He and Wang [157] studied the effect of interference between
    Non-Orthogonal Multiple Access (NOMA) UE’s on QoE at the consumer end. Authors
    utilize the user satisfaction method, i.e., several clicks or playtime to quantify
    QoE and formulated Cournot competition Oligopoly game problem to optimize power
    allocation among NOMA UE’s to upload the acquired real-time video surveillance
    data to the BS with minimum interference and maintain QoE. Statistical learning,
    prediction, and automatic network resource management mechanism to optimize multimedia
    QoE has been presented in [158]. By statistical monitoring, the QoE is predicted,
    computed and managed by evaluating objective network metrics, i.e., jitter, packet
    loss rate, frame rate, frame resolution, data rate, codec, and data volume. MOS
    has been utilized for QoE. The mobile node frequently switching network has been
    tested for the proposed model. Ahmad et al. [159] presented a multi-dimensional
    passive QoE monitoring approach at the user terminal based on quality degradation,
    where the probes at UE becomes online when quality is degraded below a specific
    threshold. The analyzed data at UE will be sent to the service provider to take
    critical actions to overcome the degradation. The proposed system could be improved
    by the implementation of cloud-based QoE analysis and monitoring. Wang W. and
    Wang Q. in [32] introduce a novel concept of Smart Media Pricing (SMP) by implementing
    Price as a Resource (PaaR) instead of smart data pricing. The authors have proposed
    to price the end-user according to its required QoE as the criticality of a self-driving
    car is higher to ensure the QoE due to high data rate requirement for precision
    than the telepresence of a user in which bandwidth requirements are low. Premium
    quality content should be priced higher than an economy class user. B. Quality
    of Service (QoS) Aware Architecture The quality of telecommunication services
    is defined by ITU in recommendation ITU-T E.800 [160] as: “Totality of characteristics
    of a telecommunications service that bear on its ability to satisfy stated and
    implied needs of the user of the service.” Microsoft defines network QoS in [161]
    technical white paper as: “Network QoS refers to the ability of the network to
    handle this traffic such that it meets the service needs of certain applications.”
    A framework to assess the quality of stereoscopic images for 3D product modeling
    in M-IoT has been presented in [162]. The authors proposed a blind image Deep
    Belief Network (DBN) based on natural science feature extraction and Support Vector
    Regression (SVR) for training. More effective machine and Deep Learning (DL) algorithms
    could be adopted to reduce the image distortions. Bellavista et al. in [163] proposed
    an SDN controller based Fibre optics-Wireless (FiWi) and edge M-IoT hybrid network
    architecture to optimize QoS in HetNet. Resource allocation, i.e., bandwidth,
    is considered as QoS optimization metrics. FiWi and Edge M-IoT hybrid network
    enhance the performance by communicating via the SDN controller. Reserved and
    excess bandwidth are offered by FiWi network to edge network in case of spontaneous
    network addition at consumer end via SDN heads. SDN based HetNets integration
    offers better network management. Statistical QoS metrics analysis of HetNets
    gateway is studied in [164] for betterment in M-IoT network designing. PLR, throughput,
    and delay are considered as QoS data. Results show that delay is the same for
    all types of devices. However, PLR and throughput affect more on low data rate
    gateways as compared to high data rate gateways. Aazam et al. [34] proposed a
    fog resource estimation and utilization to improve QoS based on service Relinquish
    Rate (RR) and previous Net Promoter Score (NPS). Resources are managed according
    to past Service Level Agreement (SLA) or disagreements. Fog computation enhances
    the performance of the system model by equipping the devices to estimate and utilize
    resources more efficiently. Quality-aware Universal Communication Framework (UCF)
    to handle mobile connectivity and reduce signaling overheads repeatedly between
    end devices for M2M communication has been presented in [165]. Network QoS parameters
    have been analyzed in [166] to evaluate to satisfy QoE for IoVT at various network
    conditions. QoS-aware framework for the Narrow-Band Internet of Things (NB-IoT)
    network by utilizing a Partial Observable Markov Decision Process (POMDP) to optimize
    energy consumption is outlined in [167]. To conserve energy, Poison distribution
    in POMDP is used to estimate traffic arrival rates and adopt dynamic network configuration
    changes according to future traffic prediction. The proposed model conserves power
    for BS and UE. Implementation of various optimization problems and ML algorithms
    to predict traffic arrival can further improve the system. Web Real-Time Communication
    (WebRTC) for video conferencing in connection with cloud computation has been
    studied in [168]. The proposed model analyzes QoS parameters in comparison with
    WebRTC in connection with local networks. Traffic load and the computational delay
    has been considered as QoS metrics for analysis. Elhammouti et al. [169] form
    a game theory problem named satisfaction equilibrium with an objective function
    to optimize energy instead of maximizing QoS. The authors have highlighted key
    motivation for optimizing energy subject to achieve satisfactory QoS constraint.
    Several applications related to multimedia have specific data rate requirements,
    therefore maximizing the QoS above that level will waste the energy. The energy
    management can be further enhanced by allocating power based on the intrinsic
    requirement of the application. C. Summary and Insight In this section, work related
    to the quality of the M-IoT network in terms of network performance has been discussed
    in detail. Quality of network is further evaluated in terms of a subjective measure
    of user experience, which is QoE and performance of network parameters, i.e.,
    QoS. Various QoE-aware and QoS-aware frameworks have been discussed. Issues and
    further enhancements in these works are highlighted. The Key Performance Indicators
    (KPIs) of communication are network metrics. Due to the scarcity of the network’s
    bandwidth, bandwidth utilization is one of the major KPI. As multimedia data consume
    a huge amount of bandwidth therefore researchers are considering exploiting un-utilized
    wideband available in Terahertz (THz) band i.e., 30–300 GHz that can loosen the
    strict limitations on bandwidth utilization. However, several issues related to
    human exposure index due to high penetration power, antenna designing, resource
    allocation, physical and MAC designing are open for research. Studies related
    to QoS and QoE are highlighted in Table 6. SECTION V. M-IoT Computing Paradigm
    A significant increase in multimedia big data generated from IoT devices, this
    volume increases with diminishing size and mobile nature of IoT devices. The amount
    of data generated is expected to be 600 Zettabytes (ZB) annually by 2020 [170].
    One of the particular multimedia IoT data generated online is audio, video, images,
    and graphics [171]. The characteristics of multimedia data are specified as huge
    volume, structured and unstructured data, velocity, unpredictability (frequently
    changing), and accuracy [172]. The current IoT frameworks to analyze and process
    scalar data are unsuitable for multimedia data in IoT. Multimedia data in IoT
    poses challenges including storage and sharing, real-time computation, processing
    and provision, energy optimization, resource allocation, feature extraction from
    unstructured multimedia data, addressing and routing, QoS and QoE preservation,
    delay sensitivity, data reduction, compression and encryption, security and privacy
    [171]. Previously we have discussed M-IoT architectures, use cases, QoS, and QoE
    optimization techniques. In this section, various computation, processing, compression
    techniques have been discussed. Fig. 10 shows the classification of multimedia
    computing in IoT. Routing and resource allocation MAC approaches are present in
    the later sections. Four main phases of multimedia data computation are shown
    in Fig. 11. A detailed survey on multimedia big data computing in IoT is presented
    by Kumari et al. [44]. The authors have discussed in detail the difference between
    big data and big multimedia data. This section has been specifically subdivided
    into multimedia data compression and event processing, fog/edge frameworks for
    M-IoT computation, cloud computation for M-IoT and SDNs for M-IoT computing. Table
    7 classifies and summarizes the existing work related to multimedia data computing
    in IoT. TABLE 7 Multimedia Computing Paradigm in M-IoT FIGURE 10. Classification
    of M-IoT computing. The existing work on multimedia computing can be studied based
    on compression and encoding, event detection and processing, cloud computing,
    fog/edge computing, and SDNs for computing. Show All FIGURE 11. Multimedia data
    computing phases. Data is first efficiently acquired, compressed, and transmitted
    to computing unit for feature classification and extraction, and then the decision
    is made on classified data. Show All A. Multimedia Coding and Compression In conventional
    multimedia data encoding techniques, data is compressed once and decoded whenever
    played. M-IoT devices are more concerned with uploading the data in uplink transmission,
    which poses challenges on computationally powered constrained M-IoT devices. Traditionally
    video encoding/compression is achieved by utilizing spatial and temporal redundancies.
    The techniques for multimedia encoding are known as High-Efficiency Video Coding
    (HEVC) jointly developed by ITU-T and International Organization for Standardization
    (ISO). The current standard jointly designed in 2013 is H.265, which shows efficient
    performance as compared to H.264 developed in 2003 [173]. The major features of
    H.265 include maximum block size of 64×64 , adaptive block sub splitting and prediction,
    and up to thirty-five intra-frame prediction directions. Google developed VP9
    and DAALA is designed by Mozilla Corporation, both compete with H.264 [174]. Comparative
    analysis of H.264, H.265, VP9, and DAALA has been presented in [43]. Results depict
    that H.265 outperforms other encoding techniques. Liu et al. [175] devised a computation
    complexity reduction transcoder solution for real-time video communication. After
    mapping the relationship among H.264/AAVC decoding information, the Coding Unit
    (CU), and the Prediction Unit (PU) decision process, the proposed model exploits
    SVM to classify either to select PU decision mode or CU depth decision process.
    The objective of the algorithm is to optimize the interframe prediction process
    of the HEVC re-encoder. Energy consumption can be significantly minimized by applying
    compression techniques to avoid energy transmission costs. Santos et al. [176]
    proposed a truncation based compression technique named ScaleRelativeMax based
    on Energy Packing Efficiency (EPC) for sensitive biomedical applications. For
    a biomedical application, the reconstruction of the signal without losses is of
    great importance. The impact of different truncation strategies on the Compression
    Ratio (CR) has been discussed in detail and compared with the proposed strategy.
    Results illustrate that the proposed technique offers linear reconstruction growth
    with comparable CR to other techniques. Compressed Sensing (CS) uses sparse signal
    structures to diminish the size of the transmitted or stored data. Multimedia
    data is sparse in structure. CS is used for multimedia data acquisition and reconstruction.
    Li et al. [40] exploit DL and AMP for improving IoT multimedia data reconstruction
    quality and minimize bandwidth utilization. Performance comparison of the DL-AMP
    technique with EM-GM-GAMP, Gauss-AMP, fast-BM3D-AMP, and other proposed CS techniques
    in the literature validates the proposed framework is suitable for multimedia.
    A Joint full reference Quality Assessment Metric (JQAM) based on the Human Visual
    System (HVS) by considering binocular perception and image properties is projected
    in [177]. The proposed technique efficiently measures the image pixel, contrast,
    and structural distortion by considering the luminance masking of the image to
    access the quality of the image. Hu et al. in [178] proposed a joint compression
    and transmission technique to optimize energy usage based on the canonical Lyapunov
    optimization scheme for power-constrained multisensor wearable devices. M-IoT
    devices are energy and resource-constrained. M-IoT devices are required to be
    computationally efficient as most of the devices are battery operated. An efficient
    task allocation strategy to maintain the QoS is required to assign the task to
    process in parallel dynamically. Wei et al. [179] proposed a real-time approximate
    task computation allocation strategy for MultiProcessor System on Chips (MPSoC)
    to increase the number of executions in a hybrid energy environment. In a hybrid
    renewable energy system, the power supply is unpredictable. Authors designed a
    dynamic task scheduler to adapt real-time varying conditions in fluctuating energy
    availability. Khernane et al. [180] discussed the tradeoff between video data
    coding and quality at the user end while optimizing the energy for the maximum
    life expectancy of the network. An entirely distributed algorithm is presented
    to balance the power utilized to encode the video and video encoding rate. The
    authors considered the dynamic nature of link capacity. The transmission errors
    are minimized by incorporating retransmissions based on the two-state Markov chain.
    However, in this work, spectrum efficiency is not taken into account, which is
    the key requirement for multimedia data transmission. A detailed survey on M2M
    communication is highlighting the issue and challenges in distributed video cameras
    in [181]. Various video coding techniques, power consumption analysis, and energy
    harvesting approaches is detailed in this article. Aljawarneh et al. [182] devised
    a Graphics Processing Unit (GPU) encryption system based on Feistel Encryption
    Scheme (FES) and Advanced Encryption Standard (AES) to secure medical multimedia
    data. The multimedia data is divided into equal-sized blocks, which are subdivided
    into plain text and keys. Each key and plain text is then encrypted separately
    using FES and AES, respectively. The genetic algorithm integrates separately encrypted
    keys and plain text to secure the data from vulnerability. The system utilizes
    the GPU to process graphics efficiently and provides parallel processing to execute
    maximum tasks to increase system throughput. B. Event Processing The M-IoT encompasses
    myriad applications in every field which varies in data capacities, features,
    nature of outputs, and encoding formats. An increasing number of devices and applications
    transits the nature of multimedia traffic more towards unstructured events. Generic
    event detection and query processing framework is in need to process structured
    and unstructured multimedia events. Aslam and Curry [183] proposed a Multimedia
    Stream Processing Engine (MSPE) as a middleware with an operator to analysis unstructured
    events in multimedia data and DNN processor to extract and match the features.
    Publish/subscribe mechanism is adapted in which multimedia devices send captured
    events to the middleware and subscribers can access the desired events by relevant
    classifiers from middleware by DNN based matchers. Optimization models are adapted
    to analyze and process a user’s query to achieve optimized throughput and accuracy
    to serve the query. The integration of diverse image analysis techniques could
    enhance the genericity of the framework. Angsuchotmetee et al. in [184] offered
    Multimedia Semantic Sensor Network Ontology (MSSN-Onto) to detect various events
    in a HetNet to provide syntactic and semantic interoperability. A multimedia application
    that involves more than one user requires syntactic and semantic interoperability
    to understand different data encoding techniques and content-aware modeling. The
    proposed framework constitutes MSSN indexer, application manager, and event processing
    engine to process and index the data stream concerning their feature levels, and
    serving the queries of the users from the stored, indexed data. Xu et al. proposed
    an attention-in-attention (AIA) network in [185] for multievent recognition and
    representing the salient features of visual modality and semantic modality exploiting
    Convolutional Neural Network (CNN) for visual features extraction. AIA comprises
    Encoder Attention Modules (EAM) and Fusion Attention Module (FAM) for desired
    features matching and fuses multi-dimensional features into a single-dimensional
    feature. The authors employed a Recurrent Neural Network (RNN) based Long Short-Term
    Memory (LSTM) unit on decoding fused data into multi-events labels. Multiple AIA
    modules can enhance event recognition and representations of multimedia video
    streaming. Saha et al. [186] presented a context-aware Block-based Motion Estimation
    (BME) approach to enhance multimedia compression. The author uses the pixel distortion
    ratio to characterize the motion into a Large Diamond Search Pattern (LDSP) or
    Small Diamond Search Pattern (SDSP). The proposed scheme intends to reduce the
    computation time significantly. Parallel processing incorporating GPU and directional
    motion estimation can further augment the performance. Thiyagarajan et al. [39]
    devised energy-aware selective encryption for the high motion video frame. The
    detection of high motion is performed by the texture energy level of the frame
    which is classified by the DC coefficient in Discrete Cosine Transform (DCT) and
    the motion vector which expresses descriptive information of video magnitude and
    phase angle. The high value of the motion vector indicates high motion activity
    and vice versa. For securing multimedia data and conserving energy in M-IoT, all
    syntax elements of high motion frames are encrypted. However, in low energy frames,
    alternate syntax elements are encrypted. C. Cloud Computing for M-IoT The miniature
    IoT devices and bulky nature of multimedia data necessitate excessively large
    and time-sensitive computation resources. Cloud computing offers computing resources
    in a centralized manner instead of localized computing to augment energy conservation,
    QoS and improves the life expectancy of the M-IoT network. Computing pioneer ‘John
    McCarthy’ speculated cloud computing in 1961 as ‘ computation may someday be organized
    as a public utility’ [187], which raises the question, what exactly cloud computing
    refers to. National Institute of Standards and Technology (NIST) defined cloud
    computing in [188] as: “Cloud computing is a model for enabling convenient, on-demand
    network access to a shared pool of configurable computing resources (e.g., networks,
    servers, storage, applications, and services) that can be rapidly provisioned
    and released with minimal management effort or service provider interaction.”
    Cloud computing encompasses five essential elements [189]: 1) On-demand self-service:
    user with urgent requirement of CPU, storage, and software can avail the resources
    without human intervention. 2) Broad network access: the user required computation
    resources are available over the Internet for heterogeneous platforms. 3) Resource
    pooling: similar resources are organized in pools exploiting virtualization to
    serve multiple users. 4) Rapid elasticity: the consumer resource requirements
    vary according to the network condition and application regardless of having any
    knowledge about cloud computation capacity. Therefore cloud servers are flexible
    to address every user. 5) Measured services: The cloud server monitors the resource
    usage of each user through metering capabilities. In addition to these elements,
    the cloud services are categories as; Software as a Service (SaaS): accessing
    application from cloud, Platform as a Service (PaaS): providing application development
    platform as a service, Infrastructure as a Service (IaaS): providing hardware
    infrastructure i.e., storage, processing servers and network as a service [187]
    as depicted in Fig. 12. The cloud services are deployed in four models; private
    cloud, community cloud, public cloud, and hybrid cloud [189]. In this section
    varied proposed cloud computing schemes for M-IoT have been enlisted. A comprehensive
    study on the integration of cloud computing and IoT has been presented in [190].
    FIGURE 12. Cloud computing services for M-IoT. Cloud services are categorized
    as the platform as a service (PaaS), infrastructure as a service (IaaS), and software
    as a service (SaaS). Cloud services can be studied for M2M and M2H communication.
    Cloud services require a secure and safe connection between device and cloud.
    Show All 1) Multimedia Cloud Computing in IoT The ubiquity of audio processing
    and cameras even in low-end devices increases the audio and visual recognition
    applications. However, due to small size IoT devices, multimedia data processing
    requires additional computational services that are readily available. To cope
    with this issue, the researcher has put forward several remote cloud computing
    scheme for multimedia processing. Renna et al. in [191] presented a framework
    to provide the optimal balance between energy consumption to process the query
    and the cost incurred for cloud computing by incorporating resource consumption
    according to the volume of query which either lies in the idle state or active
    state. Ubiquitous and heterogeneous data generated from the surveillance system
    is transmitted to a centralized processing unit over limited bandwidth incur high
    latency. Ali et al. [192], [193] proposed a cloudlet based, lightweight distributed
    computing framework for IoT video surveillance systems to minimize network latency.
    The cloudlet system brings cloud computation resources closer to the IoT network
    to compute critical and sensitive data in real-time. In this article, face recognition
    is considered as a use case to validate the framework. Cloudlet exists between
    surveillance cameras and the public cloud. Image/video captured by the camera
    is sent to the cloudlet for face recognition and feature extraction, which is
    transmitted to the public cloud for matching and identification purposes. Cloudlet
    is a device with significant storage, CPU, and GPU. Preprocessing the captured
    data before transmitting to the public cloud significantly reduces the network
    latency. DNN based face detection ‘OpenFace’ in real-time video stream and face
    denaturing named ‘RTFace’ technique for privacy and safety has been presented
    in [194]. The proposed algorithm is implemented on cloudlets for speedy and efficient
    face detection and denaturing. Crowdsensing is an important aspect of smart cities
    which provides ease in multimedia data aggregation by exploiting multimedia sensor
    of public mobile phone, wearable devices, and tablets. The acquired data is wirelessly
    transmitted to the cloud in real-time due to the limited storage capacity of the
    devices. Hong et al. [195] addressed three problems in cloud-based video crowdsensing:
    1) optimal transcoding, 2) the optimal data transfer protocol and meta-data selection
    to upload a video over WiFi, 3) camera parameters which require complete video
    lookup. The authors presented three algorithms: Adaptive Transcoding Algorithm
    (ATA) based heuristic algorithm for video representation without quality compromise.
    Protocol Selection Algorithm (PSA) to dynamically select transmission protocol
    by comparing average throughput normalized value achieved from FDT and UDT. Cloud
    Database Algorithm (CDA) based on Field-of-View (FoV) approach to manage videos
    in the cloud database. Authors in [196] devised an analytical framework to serve
    the cloud access request from the access network, core, or edge network by maintaining
    an optimal number of replicas to improve resource utilization. Cloud computing
    for event detection in a video stream and probabilistic future event prediction
    is detailed in [197]. Authors proposed a dynamic programming based framework to
    efficiently allocate bandwidth resources from limited uplink bandwidth based on
    future event predictions to transmit only meaningful information. The results
    show 80% event detection with 97% QoS satisfaction, utilizing 10% of essential
    bandwidth. Wang et al. [198] devised multimedia sensing as a service (MSaaS),
    an energy-efficient framework work to upload multimedia data by prioritizing it
    first and then optimally allocate network resources. The authors exploit the quad-tree
    decomposition algorithm to segregate regular and premium blocks. In this article,
    the truncation based resource allocation optimization problem is formulated. A
    unified resource allocation metric is considered based on Automatic Repeat Request
    (ARQ), channel coding for Forwarding Error Correction (FEC), data rate, transmission
    power and packet length subject to energy-constrained quality optimization. D.
    Fog/Edge Computing For decades cloud computing served as pay-as-you-go, managing
    and providing alternative solutions for data centers and enterprises by providing
    remote storage units, processing units, networks, servers and applications to
    serve multiple customers [199]. Cloud computing flows a centralized processing
    infrastructure which is usually located far from users or IoT proximity. However,
    cloud computing upsurges network overheads by transmitting the aggregated data
    from sensors to the centralized processing cloud and then acquiring back the analyzed
    data over bandwidth, latency, and energy-constrained network. M-IoT network requires
    a model that can handle high velocity, volume, and variety of data with minimum
    latency, conserve bandwidth, reliability, globally secure and chooses the best
    processing unit in the least possible time. In 2012, Cisco introduced and defined
    fog computing as [200]: “The fog extends the cloud closer to the things that produce
    and act on IoT data.” Fog computing is the virtualized platform that offers computation,
    storage units and routing devices between User Equipment (UE) and traditional
    cloud, located at the edge of the network, reducing the response time of the system
    [201]. The fog-cloud hybrid computing architecture process the data in the following
    pattern. Critical time-sensitive and real-time data are processed on the fog node,
    while less critical data that can tolerate minute delay is processed and stored
    on fog gateway node for a few hours. The regular periodic data that is not delay-sensitive
    is sent to the cloud to be processed and stored for offline access [200]. Stojmenovic
    et al. [202] outlined a detailed overview of fog computation applications and
    challenges. The term edge computing also refers to the notion of providing computation
    at the edge of the network. The edge computing is defined as network processing
    and resources progressing between data origin and cloud unit [203]. Detailed edge
    computing architecture and issues are presented in [203]. The smartphone act as
    an edge between the user and the cloud. The processing unit is placed within the
    proximity of data producers to increase energy efficiency, response time, and
    bandwidth allocation optimization. Fog computing is referred to as edge computing.
    However, the difference lies in the location of the computing unit is placed.
    Fog computing is employed at the Local Area Network (LAN) or the gateways of the
    network, whereas edge computing is embedded within the end or edge device, as
    shown in Fig. 13. Linthicum et al. describe edge computing as the concept, while
    fog computing as a protocol to implement edge computing [204]. The authors also
    highlighted the limitations of both the architectures in data computing. Various
    fog and edge computing frameworks, vision, and challenges in the M-IoT network
    are studied and presented in the subsection. FIGURE 13. Fog/Edge computing in
    M-IoT. Fog/Edge devices reduce network overhead and latency by preprocessing the
    acquired multimedia data at Fog/Edge nodes. Fog/Edge devices can be a smartphone,
    network hubs, gateways, routers, and servers. Show All 1) Fog Computing in M-IoT
    Extending the computing closer to the edge or access network raises several issues
    and challenges. Determining and classifying critical multimedia data is necessary
    for load balancing on fog node and the cloud for optimal efficiency. Excessive
    workload on fog node increases the power consumption, causing efficiency degradation.
    Deng et al. [205] formulated a primal problem for maximizing power conservation
    in fog-cloud hybrid systems. Four layered fog-cloud frameworks have been proposed.
    Moreover, the authors decompose the problem into three subproblems by specifying
    the tradeoff between latency and power consumption. The problem is subject to
    various constraints: 1) delay at fog node, 2) Wide Area Network (WAN) communication
    system between fog and cloud server, 3) bandwidth and network overheads at the
    cloud server. Simulation results show that the proposed framework improves latency
    and power consumption for delay-sensitive traffic. Chen et al. [206] devised a
    fog-based video surveillance system to monitor a speedy road traffic system in
    urban areas using a drone camera. The authors proposed a tracking algorithm that
    extracts and transmits image frames of interest to fog node to meet minimum computation
    and delay requirements. The tracking algorithm utilizes Bayes estimation and probabilistic
    Monte Carlo simulations. Yousefpour et al. in [207] presented a fog-cloud hybrid
    generic framework to minimize the service latency by sharing the load among fog
    nodes. The framework considers the queue length and the type of service requested,
    as the different application requires different service time. The Fog layer offers
    collaborative architecture to process a request exploiting the concept of load
    sharing by offloading the service request to neighbor fog nodes. Authors also
    put forward an approach to find the best fog node to process the request in minimum
    time by using a centralized fog node for maintaining a reachability table to offload
    the request to the node which offers minimum service delay. Minimum service delay
    and propagation delay are measured using a recursive analytical process. Simulation
    results depict the proposed model outperforms No Fog Processing (NFP). Ni et al.
    [208] put forward a fog computation resource allocation strategy based on Priced
    Timed Petri Nets (PTPNs) that considers price and time cost of task completion.
    The proposed scheme utilizes a dynamic recursive algorithm for fog resource allocation.
    The authors also presented a probabilistic model to predict the time cost of task
    completion. The framework provides a novel scheme for users to select the resource
    pool that fulfills their requirements. The innovation can still be improved by
    implementing the ML technique to train the system by mapping the nature of services
    with required fog resource and service time. Yang in [209] discussed fog architectures
    for data stream processing in four different applications: 1) IoT stream analytics,
    2) real-time crowdsourcing, 3) network control, 4) event processing. The author
    investigates various issues and challenges in applications focused on real-time
    monitoring and crowdsourcing. The main objective of this architecture is to incorporate
    fog computation in the M-IoT network that augments the network throughput, latency,
    fairness, stability, and reliability. 2) Edge Computing in M-IoT Communication
    between M-IoT devices, edge devices, and cloud incur additional delay if the tasks
    are not properly scheduled. Xu et al. [210] introduced the concept of optimizing
    in-memory processing to reduce the delay and latency of the network. Three-tier
    architecture is proposed to formulate closed-loop feedback scheduling and prioritization
    model to integrate memories of all the edge devices to balance workload allocation.
    Results depict improvement in latencies for M-IoT systems and rational workload
    allocation. Genetics a geo-distributed real-time stream processing for the dynamic
    edge-cloud network is proposed in [211] to achieve low latency by exploiting minimum
    bandwidth allocation and task sharing. A distributed Complex Event Processing
    engine (CEP) for a fully distributed edge IoT network is presented in [212]. CEP
    utilizes both events based and stream-based approaches. The authors proposed a
    heuristic assignment model for task distribution for a balanced workload between
    edge devices and cloud. Results show 6.6 times less data volume flow as compared
    to a centralized framework. Li et al. [213] proposed CNN based deep leaning optimization
    problem to maximize the number of tasks for edge devices subject to limited bandwidth
    and system capacity. The authors aim to reduce the network traffic and overheads
    from M-IoT devices to the cloud. The system is designed for online and offline
    video processing, as video processing is the integration of computer vision and
    image processing. Sharma and Wang [214] devised a collaborative edge-cloud framework.
    The framework utilizes the historic cloud computing data to aid edge computation
    to analyze live data for maintaining QoS. The authors also highlighted the issues,
    challenges, and limitations of both edge and cloud computing. Furthermore, the
    motivation for a collaborative edge-cloud framework is also outlined. Long et
    al. in [215] proposed an edge M-IoT framework to process video on edge devices
    to improve the accuracy of human detection in surveillance systems. The proposed
    framework utilizes D2D communication to transmit the divided and compressed video
    frames to nearby edge nodes that form cooperative groups to process the video
    frames transmitted to them in multicast or unicast fashion. The authors deduced
    that human detection accuracy is positively correlated with the video coding rate
    and formulates an optimization problem to maximize the average video coding rate
    subject to deadline and group formulation constraint. Group formulation problem
    is solved by considering it as Winner Determination Problem (WDP), which states
    that the video chunks are allocated to the group of edge nodes which maximizes
    the overall utility. Simulation results validate that the proposed work outperforms
    no cooperation and an arbitrary model. Elias et al. [216] devised Where’s The
    Bear (WTB), an image processing technique for edge computing based on NN to recognize
    animals in wildlife monitoring systems. The objectives of WTB are to conserve
    bandwidth and improve accuracy. WTB exploits Google TensorFlow for image recognition
    and classification, and OpenCV for analysis. Results show that implementing image
    recognition at the edge of the network where the images are acquired reduces latency
    and conserves bandwidth. E. Software-Defined Networks Several devices are responsible
    for handling network in IoT, such as, routers, switches, and embedded devices.
    These devices are equipped with integrated circuits, that are pre-programmed to
    execute predetermined tasks. Such devices are not reconfigurable with dynamic
    changes in the network to support real-time multitasking. The expected 50 billion
    connected devices could generate 600 ZB annually by 2020 [170]. Transmitting such
    a huge amount of data to the cloud for analysis and processing may lead to developing
    network congestion, which can cause latency and bandwidth issues affecting overall
    QoS and QoE. To cope with this problem, most of the technology giants like Cisco
    and IBM offered to process the data closer to the network’s edge to achieve high
    data rates and low latency. However, edge processing may incur high energy consumption.
    To deal with issues mentioned above a flexible, scalable, reprogrammable, and
    reconfigurable M-IoT architecture is in need to manage multimedia traffic flow
    and data computation to optimize energy consumption and performance. SDN is an
    emerging network technology that offers flexible, interoperable, reconfigurable,
    and reprogrammable network architecture to satisfy dynamic changes in the network.
    SDN compromises network management [217], network virtualization [218], network
    accessibility [219], resource utilization [220], energy management [221], security
    and privacy [222] by segregating network control from hardware devices [223].
    The main objective of the SDN is to decouple the control plane from the data plane
    to rationalize the network. This network device now acts as a Forwarding Device
    (FD), that forwards a sequence of packets from source to destination by regulatory
    policies [224]. The control plane in SDN is a centralized unit while the data
    plane works in a distributed manner. The Telecommunication Management Network
    (TMN) architecture comprises three planes: management, data, and control plane.
    Management plane forms the maintenance and operations unit of the network, i.e.,
    human operators and software that monitors the status, configure and update the
    network. The data plan performs data transmission by following the flow decisions
    of the controller in the control plane. This plane constitutes all the FDs such
    as routers, switches, firewalls, and embedded circuits. The control plane is a
    centralized controller to configure and reprogram the network, for instance, network
    path, routing protocols, network policies according to the application requirements
    [225]. The SDN comprises two Application Programming Interfaces (APIs), i.e.,
    northbound API that is responsible for providing communication between application
    plane and controller, whereas southbound API supports communication between the
    controller and network devices as shown in Fig. 14. This section presents studies
    and proposed schemes associated with multimedia data computation by employing
    SDN. FIGURE 14. The architecture of Software-Defined Networks (SDNs) for multimedia
    computing. SDNs offers scalability, flexibility, reconfigurability, and re-programmability
    for efficient network management. SDNs separates data planes from the control
    plane and provide four APIs. Show All 1) Multimedia Computing in SDN SDNs are
    not specifically introduced for data computing. However, managing the network
    proficiently by SDNs could reduce the computing complexity to yield low latency
    and fewer overheads. Kaur et al. in [226] devised SDN as a middleware in edge-cloud
    hybrid architectures to improve the energy efficiency of the stream processing.
    The framework provides the classification of data flow into batch processing and
    stream processing. Batch processing is more focussed on network service bandwidth
    while stream processing comprehends real-time applications that are latency-sensitive.
    Upon the classification of workflow, network control logic are configured and
    implemented. The authors have formulated multi-objective optimization problems
    for each control logic, which exploits the Tchebycheff decomposition algorithm
    to solve the problems to minimize energy consumption by efficient routing path
    selection and scheduling. Results show that incorporating dynamic network changes
    according to the classified workflow enhances the energy efficiency meeting SLA.
    Salman et al. [227] proposed Software-Defined Mobile Edge Computing (SD-MEC) architecture
    to reduce latency and bandwidth by combining the features of both SDN and edge
    computing. The proposed framework offers scalability by managing the distributed
    edge network with SDN controllers to incorporate network changes and developing
    new services. Wang et al. [228] presented SDN-based-Publish/Subscribe (SDNPS)
    unified framework to serve multiple IoT applications. The presented framework
    aims to reduce the latency and throughput of the network with publishers that
    publish the generated data and offer services tagged with specific event topics
    to SDN. The subscribers that require specific event services receive their desired
    services from SDN based middleware without interaction with the publisher. SDNPS
    leads to a unified, interoperable framework. Baktir et al. [229] detailed the
    limitations and challenges of cloud-edge computing with increasing data traffic
    and proposed a vision of SDN based network management strategy to decrease the
    complexity of cloud-edge architectures. Authors have highlighted several use cases,
    including multimedia data computation in IoT for face detection and revealed the
    benefits of incorporating SDNs to add scalability and reliability in the network.
    A comprehensive survey and future research direction on SDN and fog computing
    is presented by Salman et al. [45]. F. Summary and Insights In this section, the
    limitations of underlying M-IoT architectures for multimedia communication has
    been discussed. Various multimedia encoding and compression techniques to reduce
    the complexity of multimedia data transmission in IoT has been detailed in [43],
    [173]–[182]. Detection, extraction, and event processing of meaningful information
    from multimedia data has been studied in [39], [183]–[186] for efficient network
    resource utilization. The vision of cloud computing and various studies to analysis
    and process multimedia data over the Internet through remote access is present
    in [187]–[198]. Increasing network overheads and the latency due to cloud computing
    has been discussed, the concept of fog\edge computing to minimize network latency
    for real-time applications is discussed in [205]–[216]. The notion of SDNs to
    enhance the scalability and interoperability to support heterogeneous M-IoT devices
    has been explained. Various studies related to SDN based fog\edge-cloud computing
    to reduce computing latency and overheads have been presented in [31], [32], [34],
    [35], [45], [46], [46]–[170]. SDNs, not only provides reconfigurability but also
    offers a more scalable and interoperable architecture. A tabular summarization
    of this section can be seen in Table 7. SECTION VI. Routing Protocols for Multimedia
    in IoT Multimedia data exhibits stringent requirements according to diverse characteristics
    in terms of volume, variety, velocity, and value, especially for efficient bandwidth
    utilization and reliability. The deviation from Moore’s law, multimedia devices
    are now becoming smaller in size, with a decrease in cost and memory to support
    mobility [3]. The current standards and protocols, as shown in Fig. 15, consume
    a significant amount of bandwidth and energy to ensure reliability. These communication
    protocols are not optimized for low power multimedia communication. The current
    standardization activities are not focussed on multimedia communication over IoT.
    ITU defines traffic routing of mobile services in ITU-T Recommendation E.170 [230]
    as: “establishing a successful connection between two exchanges or the selection
    of path between source and sink node in the network.” An intelligent routing protocol
    is in need to select an efficient route for multimedia content transmission over
    bandwidth and memory-constrained wireless IoT network. FIGURE 15. Standards and
    protocols of three layered IoT framework [2]. Show All The scarcity of IPv4 urges
    the recommendation of IPv6 for smart IoT objects. 6LoWPAN is an IP based technology
    for Low-power and Lossy Networks (LLNs) to bridge the gap between low-power devices
    and the IP world [231]. 6LoWPAN compresses IPv6 headers and fragmentation of large
    packets to make IPv6 suitable for resource-constrained devices [232]. International
    Engineering Task Force (IETF) proposed an IPv6 Routing Protocol for LLNs (RPL)
    [233], [234]. RPL is now widely adopted as a promising standard with increasing
    popularity because it offers flexibility and interoperability by adopting different
    network topologies. RPL exploits key network metrics such as throughput, node
    energy, latency, hop count, and link reliability. RPL supports Point-to-Point
    (P2P), Point-to-MultiPoint (P2MP) and MultiPoint-to-Point (MP2P) communication
    paradigm. Kim et al. [18] provided a detailed picture of the research that has
    investigated RPL. The authors presented the distribution of research carried out
    on RPL in the context of the geographical region, operating systems, hardware
    platforms, and network metrics. A plethora of work and survey studies of the IoT
    communication protocols mentioned in Fig. 16 are present in the literature [11],
    [3], [235], [236]. In this section, we have extensively studied routing of multimedia
    content, i.e., audio, image, and video in IoT to meet the stringent requirements
    of multimedia communication in IoT while maintaining QoS and QoE with efficient
    bandwidth and energy utilization. Fig. 16 shows the classification of the existing
    works on multimedia routing in IoT. Cross-layer communication protocol for multimedia
    data routing in IoT has been discussed. Routing protocols for multimedia data
    streaming in a multicast or unicast manner to provide the required QoS has been
    extensively studied. Table 8 tabulates the performance summary and comparison
    of studies on multimedia data routing in IoT. TABLE 8 The Existing Work on M-IoT
    in Context of Multimedia Data Routing FIGURE 16. Existing work on routing protocol
    for M-IoT is classified on their capability to transmit multimedia data in single-hop
    or multi-hop or multicast manner or on the basis of QoS requirements. Show All
    A. Multimedia Data Routing in M-IoT The recent studies on routing protocols for
    M-IoT discuss the transmission of data in varied perspectives, i.e., the transmission
    of audio, image, and video streaming in the context of energy, workload balance,
    fault tolerance and delay in time [17], [237]. 1) Energy-Aware Routing Xu et al.
    [36] proposed EQRoute, an energy-aware, and QoI-aware routing algorithm. The EQRoute
    is a distributed algorithm, designed for ubiquitous multimedia transmission based
    on the information value of data and capacity of the mobile user concerning it’s
    moving speed. In the proposed model, a mobile user constructs the data collection
    tree, based on its capacity and moving speed. The route is selected based on information
    gain, which is calculated in the context of communication cost and information
    value. The aim of the proposed work to maximize information gain and reduce energy
    consumption. Energy harvesting has shifted the design paradigm from energy-aware
    to Energy-Harvesting-Aware (EHA). Nguyen et al. [238] devised the EHA Routing
    Algorithm (EHARA) based on the energy-backoff process and energy prediction process
    that defines cost metrics to select the best route. A hybrid energy harvesting
    sources are considered in the proposed work, i.e., solar panels, moving vehicle-based,
    and RF-based. The energy prediction process utilizes a Kalman filter approach
    that considers previous time step and current statistics to determine an improved
    estimation of current energy arrivals from different sources. The energy backoff
    process is proposed to extend the network lifetime by putting the nodes with minimum
    energy to sleep that are unable to perform operations until the energy level is
    recovered. The node with the highest energy level and minimum cost link based
    on Dijkstra’s shortest path is selected to route the data. Carbon Dioxide (C O
    2 ) emission is one of the vital factors affecting the network or node lifetime
    in green communication. Alvi et al. [15] proposed green-RPL routing for M-IoT
    to route the multimedia data by selecting the parent node operating on green energy
    that consumes minimum energy and delays to the sink. The objective of the green-RPL
    is to minimize carbon footprint subject to path delay, path energy, residual energy,
    and idle time. Trinh et al. in [239] presented SPIDER, a sustainable policy-based
    intelligence-driven edge routing algorithm based on MEC to detect geographical
    obstacles using DL to aid the routing engine to efficiently offload the data and
    route the priority data in an emergency for energy conservation. The proposed
    work presents a facial recognition use case in a disaster scenario. 2) Load Balancing
    Packet loss due to heavy traffic and power depletion are two main reasons for
    network congestion. Taghizadeh et al. in [240] address these problems by proposing
    Context-aware and Load balancing RPL (CLPRL). The proposed work offers Context-Aware
    Objective Function (CAOF) and Context-Aware Routing metric (CARF) to improve RPL.
    CAOF ranks the nodes for the selection of a parent node based on the residual
    power level of the node and the Expected Transmission Count (ETX). After ranking,
    CARF takes the buffer queue utilization, node rank and network traffic dynamicity
    index that indicates the utilization of link in the past, to compute the route
    during heavy traffic conditions. The authors ensure the load balancing by considering
    the number of children node with a parent from the list of candidate parent nodes
    for parent selection. It helps in load balancing even if a node is eligible to
    be a parent node, but a large number of children node can create loops and network
    congestion. 3) Fault-Tolerant The miniature multimedia sensors are equipped with
    limited battery power. The exhaustion of the battery leads to network failure.
    Lin et al. [241] proposed a fault-tolerant routing for Cluster Head based (CH)
    HetNets. The proposed scheme addresses three problems that are the pre-verifying
    the fault-tolerant capability, distributing the load and optimizing the fault-tolerant
    cost. These problems are dealt with by the sink node with a virtual CH approach
    that estimates all the traffic in the network and verifies the sustainability
    of IoT application. Virtual CH combines all the energy resources of non-failure
    CHs, estimates the size of sensed data to be transmitted and verify the capability
    of tolerance offered by non-failure CHs in the network. After which an optimal
    fault-tolerant route is determined from the flow-bipartite graph that represents
    all the possible routes between faulty and non-faulty CHs. 4) Delay-Aware Multimedia
    data poses delay-sensitive characteristics. Dropping priority and meaningful multimedia
    data packets decrease the reliability of the application. Li et al. in [242] proposed
    mobile sensing vehicles for multimedia data collection to optimize delay and delivery
    ratio (DDSV). Mobile vehicles equipped with IoT devices are exploited to deliver
    data to and from multimedia IoT devices to data centers. The proposed work addresses
    three problems in the context of multimedia data packets that are data collection
    impartiality, delivery ratio, and delay. DDSV proposes priority assignment based-upon
    distance from the data center to overcome data collection impartiality. The vehicle
    with a high probability to pass through a data center is given high priority to
    deliver high priority data packets, which will augment delivery ratio and reduces
    delay in return. Performance is evaluated in the context of delivery ratio and
    average delay for data collection. 5) Mobility Mobility is one of the key requirements
    of rapidly evolving multimedia IoT applications. However, the majority of research
    has ignored mobility. Jeong et al. in [243] proposed MAPLE, a routing architecture
    based on mobility support Asymmetric Transmit Power (ATP) for LLNs. MAPLE utilizes
    a single high power periodic beacon in the downlink from the gateway to create
    a Received Signal Strength Indicator (RSSI) gradient field network. Any low power
    node can route the data for uplink transmission in a multi-hop manner using the
    RSSI gradient values of neighboring nodes. High RSSI value indicates high proximity
    to the gateway. Each high power beacon updates the RSSI gradient metric for uplink
    routing, which addresses the mobility problem, improves reliability and reduces
    the overheads in the network. MAPLE also reduces energy consumption because of
    single high power downlink transmission using ATP architecture. B. QoS Aware Routing
    QoS-aware frameworks to route wireless multimedia data in IoT network for bandwidth-hungry
    and delay-sensitive applications have been taken into consideration. The definition
    and requirements of the QoS-aware framework have been discussed in the earlier
    section. Below is the description of some of the QoS-aware routing protocols to
    support multimedia communication in IoT. 1) Cluster-Based QoS-Aware Routing Amjad
    et al. in [244] proposed centralized energy-efficient QoS-aware and Heterogeneously
    Clustered Routing (QHCR) for delay-sensitive real-time applications. The network
    area is divided into different energy levels, and Cost Values ( C v) that are
    determined based on distance from the Base Station (BS), initial energy levels,
    number of nodes, and weights. The cluster head is elected on it’s C v. The shortest
    path to the destination is selected based on path metric that is the combination
    of the initial energy of node, ETX, and inverse ETX, cost value of cluster head
    and minimum loss with QoS as a constraint. The proposed model offers intra-cluster
    multipath communication for the nodes that are at a significant distance from
    BS. Real-time multimedia and non-real-time data are transmitted over separate
    paths to reduce end-to-end delay and conserve energy. Filho and Amazonas [245]
    devised a QoS-aware routing protocol to eliminate the need for a routing table.
    The proposed scheme is based on a Trellis Coded Network (TCNet) utilizing a Mealy
    Machine (MM) or Finite State Machine (FSM). QoS is maintained using MultiProtocol
    Label Switching (MPLS). 2) SDN Based QoS-Aware Routing Bahnasse et al. in [246]
    devised QoS-aware SDN based smart and dynamic model to allocate bandwidth (Smart
    Alloc) for MPLS Traffic Engineering DiffServ Aware (DS-TE) network. The proposed
    architecture translates the QoS requirements of an application into commands that
    indicates bandwidth and priority requirements. The SLA of each application is
    detected in terms of delay, loss rate, jitter, HTTP load time, and TCP session
    delay, and threshold values are set. Smart-alloc adaptively allocates the bandwidth
    according to the status of SLA. Sway, an SDN based QoS-aware routing protocol
    for delay-sensitive and loss-sensitive application, is presented in [247]. Sway
    exploits Yen’s K-shortest path algorithm to compute traffic-aware (delay-sensitive
    or loss-sensitive) best routing path while considering QoS requirements for each
    packet. Multi-constrained QoS metrics are considered that are the delay, packet
    loss probability, and bandwidth. Integer linear programming is utilized to solve
    a multi-constrained QoS-aware route. 3) Distributed QoS-Aware Routing Shih et
    al. [248] devised a meta routing protocol for QoS-aware architectures to select
    the optimum path between gateways of HetNets. Gateways are registered in the network
    by broadcasting messages comprising the information of all the network interfaces.
    Nodes in each network update their table with the addresses of reachable network
    gateways and interfaces. The optimum path is selected by measuring QoS metrics
    of each gateway link that is timeliness and reliability. When the QoS requirement
    is not satisfied, the meta-router will transmit data on multiple paths to achieve
    maximum QoS. C. Cross-Layer Protocols for Multimedia Routing Rani et al. [37]
    proposed a cross-layer protocol to minimize energy consumption and response time.
    The authors formulated a multi-objective optimization problem to minimize the
    end-to-end packet error rate, time, and energy. These parameters are interlinked
    and dependant on cross-layer parameters such as path loss, modulation scheme,
    BER, transmission power, ARQ, duty cycling, and network routing protocol. The
    optimization of these parameters requires cross-layer communication and coordination.
    Authors exploit the Minimum Energy consumption Chain-Based Cluster Coordination
    Algorithm (ME-CBCCP) presented in [249], which finds the shortest path not only
    at the local cluster level but also takes the intercluster path into consideration.
    Bennis et al. [33] devised Efficient Queuing Multimedia (EQM), a cross-layer communication
    protocol for transmitting multimedia data over wireless networks. A carrier sense
    aware disjoint multipath routing protocol is presented to transmit high priority
    independent video frames by reserving 2-hops neighbor nodes for video frames.
    The routing layer coordinates with the MAC layer to be aware of priority video
    data. An enqueuing and dequeuing approach is presented to process high priority
    multimedia data first and scalar data at the last of the queue. The proposed work
    aims to reduce waiting for the time and energy consumption of wireless networks.
    Rosario et al. [250] proposed LinGO, QoE aware link quality and geographical beaconless
    opportunistic routing protocol for video transmission in IoT. Forwarding node
    selection and routing path are determined according to cross-layer parameters
    that are: 1) link quality indicator classified by packet reception ratio, 2) progress
    which is the Euclidian distance between forwarding node to the destination, 3)
    energy of the forwarding node. The proposed model increases the reliability by
    adding redundancy packets for high priority video packets which improve QoE. Devi
    et al. [38] proposed an agent-based cross-layer protocol for optimal path selection
    and reducing end-to-end delay to transmit important multimedia data with minimum
    latency. The proposed model exploits the agents to transmit the data when the
    channel consumes more time than a threshold time. Hassan et al. [251] presented
    a cross-layer framework to ensure QoS satisfaction. A channel access mechanism
    based on queuing model M/M/1 is formulated for the duty cycle to handle the packets
    of real-time applications. The impact of multi-hop communication is analyzed using
    PHY-MAC parameters that are transmission power, hop distance, path loss, and packet
    error ratio (PER) for adaptive switching between end-to-end transmission or hop-by-hop
    transmission scheme. D. Multicast and Hop-Count Based Routing Routing protocols
    for multimedia bandwidth-hungry and real-time applications of M-IoT have been
    designed based on multicast and hop-count metric [252]. A detailed survey on multipath
    routing protocols of M-IoT to ensure QoS parameters has been presented in [19].
    Below-mentioned are few studies in the context of multicast and multi-hop routing
    protocols of M-IoT. 1) Multicast Routing Multimedia real-time critical applications
    require the network to guarantee multiple QoS metrics that are maximum throughput,
    minimum delay, and minimum PLR. Multimedia communication requires multicast routing
    with minimum end-to-end latency for delay-sensitive health applications. A Fast
    Multiconstrained Multicast Routing Algorithm (FAMOUS) is proposed in [14]. The
    proposed routing scheme is based on Shortest Path Algorithm (SPT) and Minimum
    Steiner Tree (MST) algorithm. Authors exploit entropy-based weight aggregation
    to reduce multicriteria decision problems into a single criterion problem. The
    objective of FAMOUS is to determine the shortest path and optimal multicast tree
    from source to destination for better accuracy and speed. Aswale and Ghorpade
    in [253] presented Energy and ETX Aware Multipath Geographic Routing (EEMGR) protocol.
    ETX is a link quality metric that estimates the number of transmissions required
    to deliver a packet from source to destination successfully. EEMGR exploits ETX,
    node remaining energy and distance between a node to sink to determine the optimal
    path for reliable and energy-efficient multimedia routing. Performance comparison
    is made with the Two-Phase Geographic Greedy Forwarding (TPGF) algorithm. 2) Multi-Hop
    Routing The real-time multimedia applications demand a probability of zero percent
    delay violation. A cooperative relaying model incorporating Cognitive M2M Network
    (CM2MN) is proposed in [254] for effective end-to-end QoS. Probabilistic forwarding
    protocol (PFP) based on a network-aware routing algorithm for multi-hop routing
    is presented. Cooperative Quality Controller (CQC) is formulated to guarantee
    QoS requirements. The opportunistic relay selection as a routing extension is
    based on the M/M/1 queueing model with First-Come-First-Serve (FCFS) strategy.
    Chen et al. [255] presented Multipath Planning for the Single source (MPSS) and
    Multiple Sources (MPMS) for multimedia transmission in IoT. The proposed work
    is based on B-spline trajectories. MPSS comprises two units that are the calculation
    of the hop count module, which determines the number of hops required to satisfy
    QoS delay and energy-saving module that determines the minimum power required
    to deliver the data successfully. Utilizing spline trajectories, the source can
    determine the direction of next-hop by integrating parametric functions for geographical
    routing. The aim is to determine multiple paths that satisfy QoS with minimum
    energy consumption. The optimum path with the least energy consumption is selected.
    The performance of the system is evaluated based on end-to-end delay and energy
    consumption. Chen et al. in [256] devised a Trusted Connectivity Probability (TCP)
    based D2D relay selection model for routing data in a multi-hop manner. A ranking
    model is adapted to select the next-hop node with the highest rank. Rank is allotted
    based on Trust Probability (TP) that depends on the geographical distance between
    the current and next-hop nodes. An optimization problem is formed to select the
    optimal route with maximum TCP. The problem is solved with the help of the Dijkstra
    algorithm that determines the TCP value from a source node to all the nodes in
    the network. The model offers the D2D communication in both Channel State Information
    (CSI) aware and unknown condition to calculate the minimum power required to transmit
    between D2D device and BS. E. Summary and Insights In this section, routing protocols
    for M-IoT has been discussed. The existing research presents the routing protocols
    from the perspective of energy-awareness, load balancing, fault tolerance, mobility,
    delay awareness [257]. QoS–aware routing [258] for multimedia data is investigated
    and presented in [244]–[248]. Cross-layer protocols to improve routing strategies
    in terms of energy, delay, throughput, and reliability [259] have been presented
    in [37], [33], [249]–[251]. Challenges and issues in multicasting [260] and hop-count
    based routing schemes have been discussed in [252]–[256]. However, to support
    multimedia bandwidth-hungry and delay-sensitive applications, cross-layer and
    energy-aware protocols need to be explored in detail. The existing studies on
    multimedia routing protocols do not consider efficient bandwidth utilization and
    fault tolerance. Lightweight and energy efficient ML algorithms like reinforcement
    learning, Q-learning, Epsilon greedy are yet to be investigated for latency reduction
    and improve power conservation for multimedia routing in IoT. Table 8 presents
    a detailed overview of this section, classifying each study and highlighting it’s
    key features. SECTION VII. PHY-MAC Protocols for M-IoT The network protocol stack
    of the IoT architecture rests on the joint PHY-MAC layer as depicted in Fig. 16.
    The protocols under this layer, feature low power operations and guarantee a stringent
    QoS compliant performance. The discussion of the M-IoT applications in the preceding
    sections indicates a general guideline for the design of the PHY-MAC protocols.
    These guidelines include an ability to manage a dense, as well as a sparse network,
    with a small network overhead, over a wide range and with a low energy requirement
    [261]. The applicability of M-IoT in the wide range of applications like industrial
    monitoring, healthcare, security, and smart services in smart city applications
    implies that there are multiple QoS and QoE parameters for each application. Additionally,
    the heterogeneity of the devices in the network creates a set of challenges in
    terms of interoperability. That results in a need for application-oriented data
    transformations at the network gateway [262]. Therefore, the PHY-MAC layer for
    each application is designed to fulfill these QoS and QoE parameters. This section
    discusses the different MAC-PHY standards and protocols designed for specific
    applications. The major standard in use today is the IEEE 802.15.4 that covers
    the physical layer specifications for the global application. It forms the basis
    of the ZigBee standard that is usually used in the smart living IoT scenarios.
    Additionally, the IEEE 802.15.6 standard is defined for the healthcare scenarios.
    The other standards used for specific application cases are BLE, Long Range Wide
    Area Network (LoRaWAN), NB-IoT, and Near Field Communication (NFC). These provide
    the physical layer as well as MAC specifications for the M-IoT networks. The IEEE
    802.15.4 family of Low Rate Wireless Personal Area Networks (LR-WPANs) was first
    approved in 2003 [263]. Since then, several amendments have been made to the standard.
    There have been numerous region-specific amendments as well as application-specific
    amendments in the 2003 approved standard. The features of the PHY-MAC standards,
    along with the amendments, are tabulated in Table 9. This standard supports both,
    a star topology as well as a peer-to-peer topology. The MAC layer resides above
    the PHY layer in the OSI model and provides an interface between the PHY and the
    higher layers [263], [264]. The MAC specifications for the IEEE 802.15.4 (2003
    release) envisages the use of a Carrier Sense Multiple Access with Collison Avoidance
    (CSMA/CA) mechanism for Channel Access. The CSMA/CA supports the beaconed mode
    as well as the non-beaconed mode [265], [266]. The CSMA/CA mechanism for this
    standard and the IEEE 802.11 differs due to the absence of a request to send/clear
    to send (RTS/CTS) frame exchange in the IEEE 802.15.4 family. TABLE 9 Description
    of PHY-MAC Standards and Amendments Additionally, in the IEEE 802.15.4a-2007 amendment,
    the ALOHA is used for the channel access for the Ultra-Wide Band (UWB) [267].
    The 802.15.4 standard serves as the PHY-MAC standard for a large range of applications
    which requires a unique approach to each problem such as in industrial systems.
    Additional applications include multimedia surveillance, traffic management, advanced
    healthcare, and environmental monitoring [268]. Therefore, the focus of this section
    remains the IEEE 802.15.4 standard as most of the M-IoT scenarios are operated
    by this standard. The application-oriented PHY-MAC approaches are discussed under
    the following sub-headings. A. Existing Work on M-IoT Applications in the Context
    of PHY-MAC Protocols 1) Industrial Applications The IEEE 802.15.4 standard has
    been identified as a suitable technology for industrial applications owing to
    the features it offers in this domain such as support for a peer-to-peer topology
    and beaconing in the MAC protocol. The different beacon intervals for the IEEE
    802.15.4 superframes leads to a scheduling problem in the network. Toscano and
    Bello [269] present a solution for the scheduling problems in the multichannel
    networks. The key concept underlying the Multichannel Superframe Scheduling (MSS)
    algorithm is utilizing the maximum superframe duration to determine the length
    of the timeslice and to schedule all the superframes within the same timeslice
    on different channels [269]. The experimental results reveal the beacons are perfectly
    aligned, and through the tracking of the parents, the synchronization is maintained.
    This is not feasible in the time-division approach. Chen et al. [270] present
    a case for the use of IEEE 802.15.4 in the industrial scenario. The experimental
    evaluation of the standard is carried out in the OMNET++/INET framework that tests
    the large scale deployment of the nodes in an industrial setup. The node energy
    efficiency and the goodput support the argument for industrial applications. The
    Time Division Multiple Access (TDMA) approach is used with the Guaranteed Time
    Slot (GTS) that enhances reliability. The authors in [271] also propose a GTS
    based real-time messaging service in the industrial environment. Kim et al. in
    [272] allow a periodic synchronization of the node network clocks using Enhanced
    Beacons (EBs). The synchronization allows efficient scheduling in the proposed
    Time Slotted Channel Hopping (TISH) mode. The overall result is the reduction
    in energy consumption and traffic collisions compliant with industrial standards.
    2) Healthcare Applications Healthcare is one of the most important applications
    of M-IoT. The PHY-MAC layer for the healthcare applications is designed taking
    under consideration, the QoS parameters like low latency and high data integrity
    [273]. The IEEE 802.15.4 standard has been successfully used for healthcare applications.
    However, a new standard from IEEE 802.15.6 was approved in 2012 for wireless body
    area networks (WBANs). The IEEE 802.15.4 supports a large range for monitoring
    the complete health status of the user. One of the primary concerns with regards
    to the healthcare applications in the M-IoT scenario is prolonging the lifetime
    of the nodes. The nodes may be surgically implanted. Thus, it becomes imperative
    that the nodes have a large battery lifetime to prolong its use without causing
    inconvenience to the user. Fahmi et al. [274] provide a fuzzy logic-based sleep
    scheduling algorithm. This algorithm aims at optimizing the sleep schedule of
    the nodes and introducing an adaptive sleeping mechanism. The fuzzy logic uses
    an inference table that has a set of 81 rules to govern the sleeping times. The
    energy savings are significant, which are reflected in the experimental results.
    An intrinsic challenge faced by wireless networks is that of coexistence with
    multiple wireless networks. The WBAN based M-IoT networks also face a similar
    challenge, particularly in the IEEE 802.15.4 network. Deylami and Deylami [275]
    have presented an evaluation of the coexisting IEEE 802.15.4 based networks for
    health monitoring applications. The coexistence of multiple networks results in
    loss of data that may be critical, especially in the time divided slot approach
    and GTS based mechanisms. Therefore, a dynamic mechanism for resynchronizing the
    network clock according to the network coordinator is required. To evaluate the
    security of the network by analyzing the efficient usage of the bandwidth, authors
    in [276] foresee an exploitation attack on the contention period during the MAC
    layer operation. The mechanism to remedy the problem is required to enhance the
    reliability of the system, which is the paramount QoS parameter. This includes
    an intelligent backoff mechanism that offers a fair chance during the Contention
    Access Period (CAP). 3) Multimedia Content Streaming Including Surveillance The
    development of the advanced and cost-efficient Complementary Metal-Oxide Semiconductor
    (CMOS) sensors has led to the widespread growth of visual and audio content across
    many platforms. Its impact is profound in the IoT domain as well and has led to
    the development of the Wireless Multimedia Sensor Networks (WMSNs) [277]. These
    WMSNs have found their application in surveillance and telemedicine. The constraints
    these networks face are in terms of computing power, energy supply, and memory.
    Additionally, they struggle with limited channel bandwidth and variable capacity.
    Lin et al. [278] propose a system to mitigate the challenges of the limited network
    capabilities in the multimedia framework. This involves a dynamic scheme to adjust
    the beaconing interval and the superframe duration. This dynamic approach helps
    in the network synchronization and efficient scheduling, thus, resulting in enhanced
    transmission efficiency. The proposed method is effective for a dynamic data load,
    as well. Pham et al. [279] have presented an evaluation of the IEEE 802.15.4 standard
    for the image transmission applications real deployment scenarios. The evaluation
    is a representative of the Universal Asynchronous Receiver Transmitter (UART)
    and Serial Peripheral Interface (SPI) based boards for surveillance. The authors
    present a compression scheme for Joint Photographic Experts Group (JPEG) format
    image data as well as a block interleaving scheme that enhances the reconstructive
    accuracy after encoding the images. The authors identify the possible bottlenecks
    that induce higher latency. 4) Military Applications Mendes et al. [280] propose
    a cross-layer and cross standard methodology for an improved surveillance system
    in a military application. The proposed method involves support for the multimedia
    sensors as well as auxiliary sensors for improved enemy movement detection. The
    proposed method involves the superframe synchronization for improved transmission
    reliability by allowing cross-standard compatibility between the IEEE 802.15.4
    and IEEE 802.15.3 standard. The reliability is the key performance indicator for
    the applications. 5) Precision Agriculture The implications of M-IoT in the agricultural
    field are immense. The data rates for the various metrics that are sensed vary
    greatly amongst each other. Additionally, the priority of each data is different,
    so the channel access mechanism has to adapt accordingly. Kone et al. [281] propose
    a fine-tuned MAC layer for precision agricultural applications in the IEEE 802.15.4
    standard. Precision agriculture is closely monitored and controlled agricultural
    practice. The proposed method involves the selection of optimal values for the
    sampling frequency based on the recorded parameter. Additionally, the MAC parameters
    like the minimum value of the backoff exponent as well as the maximum number of
    backoffs. The proposed method demonstrates the increased sampling frequency for
    applications that require higher resolution, thus, improving the granularity.
    B. ZigBee Standard ZigBee is another standard that is used in the M-IoT scenario.
    It is particularly utilized in the consumer electronics sphere for home automation.
    However, the ZigBee and IEEE 802.15.4 can be used interoperably. Some applications
    with higher security requirements utilize ZigBee while coexisting with the IEEE
    802.15.4 standard. Han and Lim [282] explore such a scenario. The authors present
    a planned overview of automated systems for efficiently deploying smart living
    systems. C. IEEE 802.11 Standard Institute of Electrical and Electronics Engineers
    created the first standard for Wireless Local Area Network (WLAN). The standards
    in the IEEE 802.11 family are also known as Wi-Fi. These standards provide PHY
    and MAC protocols for M-IoT devices. The key characteristics of this standard
    can be seen in Table 9. From the day first, WLANs have been facing the challenge
    of efficient MAC layer resource allocation while accessing the channel [283].
    CSMA/CA is one of the popular collision avoidance mechanisms used by the MAC layer.
    In CSMA/CA, a randomized backoff mechanism is performed by the devices before
    accessing the channel resources. However, a blind exponential increase and reset
    of contention values in this backoff mechanism induce performance degradation.
    Ali et al. proposed solutions in [284]–[286] to tackle the blindness of currently
    implemented CSMA/CA. Their proposed channel observation-based mechanisms adaptively
    increase and decrease the contention parameters. Besides, ML-based techniques
    have been playing a vital role in the performance optimization of MAC layer resource
    allocation mechanisms [287]. Such ML-enabled techniques are also utilized for
    other low-power energy-constrained networks of IoT applications, such as smart
    healthcare systems [288]. In the context of M-IoT, an ML-enabled distributed channel
    access (MEDCA) mechanism is proposed in [289]. The proposed MEDCA mechanism utilizes
    Q learning algorithm to optimize the performance of channel access in multimedia-based
    WLANS (that is IEEE 802.11e). D. Narrow-Band IoT NB-IoT is one of the Low Power
    Wide Area (LPWA) technologies released by the 3rd Generation Partnership (3GPP).
    It is designed for heterogeneous IoT devices to achieve improved spectrum efficiency,
    extended, and in-depth coverage. The key feature of NB-IoT is that it can be directly
    deployed in the Global System for Mobile communication (GSM) or LTE spectrum [290].
    However, the NB-IoT device has to continuously monitor the data transmission channel
    for service announcements and updates that waste energy resources. Tsoukaneri
    et al. [291] present an NB-IoT communication approach that dynamically creates
    a group of devices that are subscribed to receive multimedia services in a multicast
    transmission. To enhance the coverage area, the repetition of control and data
    transmission signals has been considered. The Adaptive Coding and Modulation (ACM)
    scheme and repetition numbers are in need of link adaption for NB-IoT systems.
    However, traditional link adaption techniques without repetition numbers are not
    applicable to NB-IoT systems. Yu et al. [292] proposed an inner loop and outer
    loop link adaption that copes with block error ratio and coordination between
    ACM and repetition numbers. The direct communication link between user and BS
    usually does not satisfy QoS for transmitting vital data. Li et al. [64] exploit
    D2D communication as an opportunistic communication with improved link quality
    to upload critical data to BS. The proposed optimization aims to improve end-to-end
    delay and packet delivery ratio. NB-IoT is an emerging technology that yet needs
    to be explored in-depth for deployment. E. Bluetooth Low Energy BLE is also known
    as Bluetooth Smart was introduced in Bluetooth 4.0. BLE is a short-range PHY-MAC
    communication protocol for low power battery operated devices [293]. BLE is mostly
    used for scalar parametric monitoring applications. Multimedia communication using
    BLE has not been yet investigated in-depth in IoT, as BLE is only suitable for
    a small chunk of data. Gentili et al. [24] proposed BlueVoice, an application
    for voice communication over BLE. However, results in the proposed study have
    not been compared with other PHY-MAC protocols. F. Long Range Wide Area Network
    LoRaWAN developed by LoRa Alliance is another LPWA communication standard that
    provides PHY-MAC protocol for IoT applications. LoRaWAN utilizes LoRa modulation
    based on Chrip Spread Spectrum (CSS) and ALOHA medium access mechanism. To the
    best of our knowledge, no substantial work has been done in M-IoT exploiting LoRaWAN.
    G. Summary and Insights The PHY-MAC layer is responsible for the resource allocation
    and management of hardware and networking resources. The IEEE 802.15.4 standard
    is the most widely utilized standard for the M-IoT deployment. The various authors
    present solutions for improving reliability and reducing the delay by synchronizing
    the network clocks periodically. The MAC protocols are modified according to the
    application QoS. Various proposed work on PHY-MAC protocols mentioned in Table
    9 has been presented in this section. ML and DL based resource allocation and
    management techniques are yet to be explored for M-IoT applications. Security
    is another critical challenge in the wireless medium. Efficient authentication,
    authorization, and validation technique are required for critical M-IoT. Table
    10 classifies and summarizes this section. TABLE 10 Existing Work on PHY-MAC Protocols
    for M-IoT Applications SECTION VIII. Future Research Directions In spite of the
    plethora of research activities and incredible progress in recent years, M-IoT
    still possesses many open issues that are still waiting to be resolved. The main
    goal of M-IoT includes carrying out multimedia communication with maximum QoE
    in terms of packet delivery ratio, throughput, and extending network lifetime
    while minimizing energy expenditure and preventing connectivity degradation. These
    goals can be achieved by employing efficient data aggregation, interoperable and
    scalable architecture, efficient feature extraction, intelligent routing, and
    adaptive MAC protocols, and managing energy while maximizing computing. Additionally,
    there are restrictions on IoT devices to be miniscule with the capability of mobility
    and multiple communication interfaces. Therefore, there are extensive research
    issues that should further be explored in the field of M-IoT. Fig. 17 depicts
    the major areas that demand novel contributions and innovations. In this section,
    a wide range of research issues are delineated for future exploration. FIGURE
    17. Overview of the open issues, challenges, and future research directions for
    M-IoT systems. Show All A. Interoperable and Scalable Architecture M-IoT requires
    redefined efficient network architecture to offer scalability and interoperability
    for multiple multimedia heterogeneous devices while considering the spectrum scarcity
    and limited power resources. SDN based middleware is extensively studied with
    regard to software-defined IoT architectures [294], [295]. SDNs addresses the
    hardware and reconfigurability limitations of IoT devices [296]. Publish/subscribe
    is a communication mechanism for distributed IoT systems [297], [298]. In the
    publish/subscribe model, the user does not have to be in direct contact with the
    service provider. Software-defined publish/subscribe based agents for M-IoT architecture
    offers new opportunities to add scalability and interoperability in the network
    [299]. However, no dedicated work has been done to devise SDN based publish/subscribe
    M-IoT architecture. There is a need to explore SDNs in the context of standardizing
    M-IoT architecture. B. Feature Extraction Multimedia devices generate a huge amount
    of data that comprise structured and unstructured data. The processing of such
    amount of unstructured data over an energy-constrained network requires the transmission
    of only meaningful information. An Intelligent feature extraction mechanism is
    required to identify and classify multimedia data with minimum energy consumption
    [300], [301]. DL addresses the limitations of ML to process a huge amount of data
    [302]. DL offers proficient multimedia feature extraction models [303], [304].
    Extracting semantic from multimedia data could transform unstructured data into
    structured, indexed data for efficient processing [305]. Implementing DL over
    SDNs and adding semantics to multimedia data are yet to be explored for intelligent
    multimedia feature extractions. C. Data Prioritization Prioritizing multimedia
    data addresses a lot of issues related to energy [306], scheduling [307], video
    streaming [308], memory [309], improving PLR, enhancing QoS [310], security [311],
    and reduce network latency [312]. A large number of M-IoT applications mentioned
    in the previous sections are real-time delay-sensitive that require multimedia
    data prioritization. Multimedia applications require ubiquitous transmission for
    which AI-based data classification and priority optimization in M-IoT should be
    extensively studied concerning the requirements of the application. D. Event Processing
    Events are defined as real-world occurrences that reveal over space and time.
    A huge volume of event content is being captured in multimedia, of which YouTube
    videos, TV shows, and animations cover 60% of the Internet traffic [313]. The
    tremendous increase in real-life events captured in multimedia requires event
    analysis to associate metadata with events for efficient query processing. Event
    detection [314], feature representation [315], and adding semantics [316], is
    known as event mining [317]. An intelligent event mining in audio, videos, and
    images are required in M-IoT for efficient resource utilization to process the
    required service with minimum delay. E. Compression and Encoding/Decoding Techniques
    for M-IoT M-IoT necessitates compression techniques to become more vigorous with
    low complexity and to produce low bandwidth output while adhering to limited network
    and spectrum resources. Compression techniques are extensively studied in the
    context of multimedia transmission over wireless networks in [318], [319]. However,
    no enthusiastic work has been done on compression or encoding techniques for the
    transmission of multimedia data over the M-IoT network. There is a need to explore
    the coding methodologies related to multimedia services in M-IoT while considering
    the power and interface constraints. F. Computation Related Issues The difference
    between multimedia data and scalar data has been shown in Table 1. Processing
    and analysis of such high power consumption, and processing data requires efficient
    computing models for minimizing the network overheads and energy consumptions
    [320]. Multimedia processing is dependant on multiple factors, i.e., feature extraction,
    prioritization, network coding, compression, efficient routing, and MAC protocols.
    The limitation of cloud computing and compensation offered by Fog/Edge computing
    is detailed in the previous sections [321]. However, minimal work has been performed
    in SDNs as multimedia computing in IoT. Due to the diverse nature of multimedia
    applications, applications dependent software-defined computing architectures
    are required to offer interoperability in HetNets. To increase network throughput
    with minimum energy utilization, the intelligent transmission of only meaningful
    information to cloud and fog/edge is required for processing. G. QoE Related Research
    Direction User satisfaction of multimedia content in M-IoT is measured by exploiting
    QoE subjective metrics. Recent studies of QoE evaluation for M-IoT applications
    are conducted with primary QoE metrics that are packet loss, MOS, DMOS, and user
    satisfaction. Other QoE metrics such as buffering time, data rate, interruption
    time, and failure rate should also be used for evaluation of M-IoT (as discussed
    in [322]). Most of the work on M-IoT considers network performance metrics (QoS
    metrics) that are jitter, end-to-end delay, bit error rate, and frame loss. Both
    QoS and QoE metrics should be jointly evaluated to achieve better multimedia quality
    and network services [323]. H. Security and Privacy The transmission of bandwidth-hungry
    and delay-sensitive multimedia applications over the scares spectrum requires
    protection from eavesdroppers and threats. Confidential industrial and health
    multimedia data needs P2P, MP2P, and P2MP encryption. Very partial research has
    been conducted on securing multimedia transmission over the IoT network [324],
    [325]. There are several threats that compromise the user’s data and privacy [58].
    New approaches should be adopted to secure the network from any attack. Multimedia
    is content-based data [75]. However, content-aware secure transmission of multimedia
    data over M-IoT has not been studied. The authentic distribution of multimedia
    content is also required to verify legal copyrights. The miniature M-IoT devices
    are computational and energy-constrained. Thus, lightweight data cryptography
    is required for secure communication. AI offers to secure multimedia data at the
    cost of high power consumption due to complex algorithms, that are not feasible
    to implement on IoT devices [326], [327]. Fog/Edge enables IoT devices to perform
    computationally better and faster. Fog/Edge offers to implement blockchain-based
    secure and transparent systems [328], [329]. However, security issues related
    to multimedia data has not been explored in detail. I. Energy-Aware and Green
    Communication Energy is a scarce resource. Bandwidth and power-hungry multimedia
    applications require vast energy resources for their transmission. Thus, to transmit
    multimedia data over IoT, energy-aware and energy harvesting methods need to be
    explored. There are many energy harvesting solutions for harvesting energy from
    the environment. These solutions can assist in prolonging network life and promoting
    green communication [330]. SDNs provide a better softwarization and virtualization
    approach to manage hybrid energy resources in future communication networks [331].
    To the best of our knowledge, SDNs are not studied for energy harvesting approaches
    to transmit multimedia content over the IoT network. J. Routing and MAC Related
    Issues The routing and MAC layer protocols for M-IoT exploit QoS metrics to make
    their routing or medium access decisions. Cross-layer protocols provide multi-layer
    metrics for better decisions to select route and access medium for multimedia
    data in a wireless network [332], [333]. Cross-layer metrics evaluation for user
    satisfaction of multimedia data (QoE) has not been thoroughly explored [334].
    Selecting route and medium by evaluating cross-layer and mapping them with the
    user’s QoE will enhance the performance and lifetime of the M-IoT network. D2D
    communication provides an efficient routing and medium access extension for the
    delivery of multimedia content in a smart city [335]–[337]. Due to bandwidth scarcity
    and delay the urgency of multimedia data, D2D supports a proficient mechanism
    to reduce PLR, latency, and power consumption [338]. D2D communication as a routing
    and medium extension can be investigated for M-IoT. Lightweight ML algorithms
    like reinforcement learning do not consume a significant amount of energy. IoT
    devices equipped with these ML approaches for efficient route and medium selection.
    DL learning algorithms could be implemented on edge devices to extract multimedia
    features and map them with routing and MAC metrics to achieve better user’s QoE
    of multimedia content in IoT. To the best of our knowledge, no substantial amount
    of work has been proposed in this domain. K. Multimedia Applications and Smart
    City M-IoT applications support a wide variety of applications, assisting in building
    a smart city by providing varied networks and architectures [339], [340]. These
    applications contribute a major portion in the industry, agriculture, road management
    systems, and security (as discussed comprehensively in section III). However,
    work to secure and authenticate voice assistant systems has not been studied.
    The collaboration of these applications in the smart city requires integration
    in 5G. The integration of M-IoT has not been studied significantly. L. 5G and
    Beyond 5G The future 5G of wireless cellular communication is expected to lay
    the basis of an intelligent network for multimedia communication in smart cities.
    Massive Mulitple-Input-Multiple-Output (MIMO) systems for spectral efficiency
    [341], Non-Orthogonal Multiple Access (NOMA) for multimedia broadcast services
    [157], [342], micro and femtocells to increase cellular capacity, Ultra-Reliable
    Low-Latency Communication (URLLC) to achieve low latency for multimedia applications
    [343], [344], and NB-IoT for machine type communication are few solutions to achieve
    objectives of 5G [345]. However, a fully intelligent on-demand self-reconfigurable
    network to enhance many folds in the services and performance will be released
    in Beyond 5G (B5G). ML, DL, Quantum Computing (QC), and Quantum ML (QML) are considered
    as a core enabler of Sixth Generation (6G) or B5G [346]. Gigahertz (GHz) and Terahertz
    (THz) frequencies provide solutions to bandwidth scarcity and high date rates
    to deliver multimedia content [347]. All these areas are yet to investigate and
    explored for integrating M-IoT with 5G and 6G. M. Augmented and Virtual Reality
    in M-IoT Multimedia Augmented Reality (AR) and Virtual Reality (VR) in IoT will
    reveal many hidden and open the close doors for humanity [348]. 5G and B5G will
    enable user-friendly wireless AR and VR interfaces. AR and VR in M-IoT will revolutionize
    the health, industrial, and education sector [349]. It could be helpful for several
    patients suffering from immutable diseases, education and training, guidance and
    assistance, construction and architecture, and games. In brief, it could expedite
    the development of the smart city [350]. To achieve the development of a smart
    city, the requirements of end-user should be known, preferred, and satisfied by
    the interaction of end-user, telecommunication industry, content developers, and
    research scientists. N. Tactile Internet Certain real-time application areas of
    M-IoT such as robotic surgery, remote physical interaction, teleoperation, automation
    industry, and AR/VR require even minor tactile sensing information that occurs
    due to the interaction between the application and the environment [344]. IEEE
    recently launched activities to standardize tactile Internet (IEEE P1918.1) [351].
    The requirements of tactile information are ultra-low latency in milliseconds.
    URLLC seems to satisfy these requirements. There are a lot of research areas from
    the perspective of the tactile Internet that is yet to be studied in detail. Compression
    of tactile information, intelligent and scalable network traffic engineering for
    audio and video, and edge caching and computing for AR/VR has received very little
    attention [352]–[354]. Efficient routing and MAC protocols for tactile information
    are in need. O. Molecular Communication The ability to integrate all the five
    sensory features of humans that are olfactory (smell), gustatory (taste), tactile
    (touch), ocular (sight), and hearing (audio) in information and transmit is known
    as Human Bond Communication (HBC) [355]. In humans, the exchange of information
    is based on the synthesis, transformation, emission, propagation, and reception
    of molecules through biochemical and physical processes. In telecommunication
    engineering, this information exchange is classified as molecular communication
    [356]. With the emergence of NanoThings, molecular communication is the key research
    areas to revolutionize M-IoT [357]. SECTION IX. Conclusion The evolving Multimedia
    Internet-of-Things (M-IoT) has promoted several innovative applications, aiming
    to improve the quality of life by connecting numerous smart devices through emerging
    enabling technologies. Multimedia communication in IoT can support countless applications.
    The objective of this survey is to highlight the overview of M-IoT and the importance
    of M-IoT applications. The main issues while designing M-IoT architectures, protocols,
    and computing approaches are explored to provide stable IoT architecture to support
    maximum QoE. However, it is challenging to achieve because of constraints imposed
    by multimedia content, which distinguish it from traditional IoT. Various application-use
    cases were presented to illustrate how M-IoT can revolutionize the world. Various
    requirements and proposed solutions on Quality-of-Experience (QoE) for M-IoT on
    their subjective and objective-based metrics have been presented. Moreover, the
    relation between multimedia content, cloud computing, big data analytics, event
    processing, fog/edge computing, multimedia data coding, feature extraction, and
    SDNs have been discussed. Also, this article provides a comprehensive survey of
    various routing and Medium Access Control protocols (MAC) used for M-IoT. Finally,
    this article points out the open and potential research areas that need to be
    solved in future M-IoT systems. This article should deliver a sound basis for
    researchers to understand issues and challenges in M-IoT. Authors Figures References
    Citations Keywords Metrics More Like This Quality of Service (QoS) in Internet
    of Things 2018 3rd International Conference On Internet of Things: Smart Innovation
    and Usages (IoT-SIU) Published: 2018 A Fog Computing Framework for Quality of
    Service Optimisation in the Internet of Things (IoT) Ecosystem 2020 2nd International
    Multidisciplinary Information Technology and Engineering Conference (IMITEC) Published:
    2020 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details
    PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/8948470/08950450.pdf
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 'Multimedia Internet of Things: A Comprehensive Survey'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2020.3009298
  analysis: '>'
  authors:
  - Vippon Preet Kour
  - Sakshi Arora
  citation_count: 97
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account
    Personal Sign In Browse My Settings Help Institutional Sign In All Books Conferences
    Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals
    & Magazines >IEEE Access >Volume: 8 Recent Developments of the Internet of Things
    in Agriculture: A Survey Publisher: IEEE Cite This PDF Vippon Preet Kour; Sakshi
    Arora All Authors 98 Cites in Papers 12885 Full Text Views Open Access Comment(s)
    Under a Creative Commons License Abstract Document Sections I. Introduction II.
    Sources and Search Methods III. Introduction to the Internet of Things (IoT) Concepts
    and Theories IV. Related Work V. Findings Show Full Outline Authors Figures References
    Citations Keywords Metrics Abstract: A rise in the population has immensely increased
    the pressure on the agriculture sector. With the advent of technology, this decade
    is witnessing a shift from conventional approaches to the most advanced ones.
    The Internet of Things (IoT) has transformed both the quality and quantity of
    the agriculture sector. Hybridization of species along with the real-time monitoring
    of the farms paved a way for resource optimization. Scientists, research institutions,
    academicians, and most nations across the globe are moving towards the practice
    and execution of collaborative projects to explore the horizon of this field for
    serving mankind. The tech industry is racing to provide more optimal solutions.
    Inclusion of IoT, along with cloud computing, big data analytics, and wireless
    sensor networks can provide sufficient scope to predict, process, and analyze
    the situations and improve the activities in the real-time scenario. The concept
    of heterogeneity and interoperability of the devices by providing flexible, scalable,
    and durable methods, models are also opening new domains in this field. Therefore,
    this paper contributes towards the recent IoT technologies in the agriculture
    sector, along with the development of hardware and software systems. The public
    and private sector projects and startup''s started all over the globe to provide
    smart and sustainable solutions in precision agriculture are also discussed. The
    current scenario, applications, research potential, limitations, and future aspects
    are briefly discussed. Based on the concepts of IoT a precision farming framework
    is also proposed in this article. A graphical abstract for Recent developments
    of the Internet of Things in Agriculture: A Survey. Published in: IEEE Access
    ( Volume: 8) Page(s): 129924 - 129957 Date of Publication: 14 July 2020 Electronic
    ISSN: 2169-3536 DOI: 10.1109/ACCESS.2020.3009298 Publisher: IEEE CCBY - IEEE is
    not the copyright holder of this material. Please follow the instructions via
    https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and
    stipulations in the API documentation. SECTION I. Introduction The term ‘Agriculture’
    is inferred from the Latin words ‘Ager’ means ‘Land’ and ‘Culture’ means ‘Cultivation’.
    It is the milestone field of human civilization and is one of the benchmark areas.
    This field is the withstander of the economies of various nations. According to
    the Food and Agricultural Organization of the United Nations (FAO), more than
    60% of the human population depends on agriculture for survival and around 12%
    of the total land area is under agricultural production [1]. Predicted by FAO,
    the global population will reach the mark of 8 billion people by the year 2025
    and 9.6 billion by the end of 2050 (FAO, 2009) [2]. The interpretation of this
    data shows that to tackle this population growth, an estimated increase of 70%
    in food production must be achieved worldwide by 2050 [3]. Agriculture is also
    the second-largest greenhouse gas (GHG) emitter, because of fossil-based fertilizers,
    biomass, and machinery. In some of the developed and developing nations, the agriculture
    sector is the backbone of the economy. This field has a huge contribution in the
    growth of Gross Domestic Product (GDP) of developing countries, in particular,
    some of them are listed in TABLE 1. TABLE 1 Nations Having Agriculture as a Major
    Part of Their GDP [4] In India, 53% of the population is dependent on the agriculture
    sector for employment and 61.5 % of the Indian population is primarily dependent
    on the agriculture sector for its livelihood [5]. Focusing on the market size,
    India is the second-largest fruit producer in the world. Based on certain data
    and statistics, the farming income in India is expected to double by 2022. Eyeing
    this change, there is an intra-state cluster development of certain states in
    terms of the agriculture sector. The various stats and numbers representing the
    impact of agriculture in the overall economic development of India as compared
    to other fields has been shown in Fig. 1. FIGURE 1. Contributions of various sectors
    in the Indian economy [6]. Show All At present, the demand is more than the supply
    generated and this curve will illustrate more unstable results in the coming years,
    due to increase in demand with population rise. To maintain the demand-supply
    curve, there will be enormous stress on the agricultural sector. Global warming
    and changing climatic conditions are also important factors to be taken into consideration.
    From the past decades, due to the increase in demand and pressure on the overall
    structure of the field, this area is witnessing the slow but progressive shift
    from traditional approaches to the most advanced technology-driven methods. The
    use of traditional approaches and conventional methods, as well as the changes
    in the environment, lay stress on the agricultural sector. Some of the challenges
    for the agricultural sector are given as follows: The use of traditional techniques
    of farming hinders the optimization of both cost and time. Depletion of the topsoil
    due to floods and winds resulting in the deposition of the pollutants, sediments,
    nitrates, and phosphates, result in causing the eutrophication and the runoff
    of the soil. Planting the same crop after each harvest makes the soil redundant
    of the essential nutrients. Water scarcity due to the climatic changes lowers
    the level of groundwater for irrigation, thereby disturbing the water cycle. Global
    climate changes due to the destruction of the tropical forests and the other vegetative
    species in agriculture result in the elevation of the carbon dioxide and other
    greenhouse gas levels. Lack of expertise in proper recognition of the particular
    plant species. There is no proper method to detect the disease at early stages,
    such that precautionary measures could be taken to prevent it. Therefore, because
    of these factors, the need for the creation of modern methods and intensification
    of the agricultural practices to use water, soil, minerals, and other resources
    efficiently becomes obligatory. The nature of the technology and devices is changing
    i.e. it never settles for any less. A lot of research papers addressing the challenges
    of agriculture in the IoT domain have been put forth. Constant developments and
    everlasting expectations from the existing technologies paves a great way for
    motivating academicians and researchers to set and attain new standards. During
    recent years, there has been a paradigm shift in the study and application of
    domains like IoT, cloud computing, machine learning, and big data, etc. Therefore,
    from the trends of these data sets, a constant need is felt to revisit the current
    standings and capacities of the new age IoT concepts. The modern-day requirements
    and the counteractive substitutes in the field of agriculture and changes exactly
    to the expectations based on the concepts of IoT must be addressed. The contribution
    of IoT in the agriculture field and certain gaps in resource utilization motivated
    us to perform a study that addresses current issues and applications of IoT in
    agriculture. Agriculture is expected to get immensely fortified by the advancement
    of technology especially by the domain IoT. Precision agriculture is the new term
    appended to the agriculture filed, with all the procedures being followed, addressed,
    and simulated in a tech-driven manner. Incorporation of the internet has started
    to revolutionize this field by associating devices together, now being identified
    as the Internet of Things. Coined in 1999 by a British visionary “Kevin Ashton”,
    Internet of Things is a consortium of devices connected [7]. The devices are associated
    with internet via Wireless Sensor Networks (WSN), Radio-frequency Identification
    (RIFD), Near Field Communication (NFC), Long Term Evolution (LTE), and other devices
    and communication technologies. This association helps the devices and the other
    objects transfer the information gathered to destined places all over the network.
    Precision agriculture, therefore, aims to optimize and improve agricultural processes
    to ensure optimum production with reliable, fast, and distributed dimensions thus
    providing growers a detailed overview of the ongoing scenarios in the cultivation
    stretches. This practice is followed to reduce energy consumption. The major areas
    where IoT can leave an everlasting impression are climate monitoring [8], data
    analytics [9], early disease detection [10], crop counting [11], smart irrigation
    [12], etc. With the spread of a network of devices, a communication channel can
    be established between the farmers, fields, and experts. By developing IoT based
    models, the field conditions can be monitored remotely on regular time intervals
    without any human intervention and after analyzing the data favorable and efficient
    decisions can be taken accordingly. This will help to ensure both field and market
    safety and security to the farmer. Also, with early monitoring of crops, disease
    detection can be done and thus preventive measures can be taken to save the crop
    beforehand. For producers it will also help in the analysis of consumer demands.
    Whether the product will be able to meet market expectations, thus creating an
    intelligent decision driven farming. An analysis of different existing articles
    addressing the research and development of precision agriculture is presented
    in TABLE 2. TABLE 2 Alaysis of Various Papers in the Field of Precison Agricuture
    for the Current Study In this article based on research gaps and findings obtained
    from articles analyzed below, a systematic survey is done. Therefore in this study,
    the most prominent problems of the agriculture sector, and solutions provided
    by modern systems are addressed and discussed in detail. The major contributions
    of this study are as follows: A comprehensive survey of the architectural, conceptual,
    and implementation details of IoT models adopted for Precision Agriculture has
    been carried out. Various IoT hardware platforms and other associated devices
    like sensors, accumulators, etc. along with their role in agriculture have been
    discussed in brief. Various IoT OS supported for Precision Agriculture have been
    discussed. The significance and key differences of MIoT in agriculture have been
    discussed along with related studies. Studies limited to a specific domain has
    been merged together for clear mapping of the domain. Sensors and their role in
    agriculture is discussed. Various projects/ start-up’s started all over the globe
    for tacking agricultural problems and providing intelligent and sustainable solutions
    to farmers have also been discussed. Functional concepts like limitations, improvements,
    future works and applications are discussed separately. The rest of the paper
    has been organized as in Section 2 various search and source methods used for
    the selections of relevant articles has been introduced, in Section 3 to get into
    the deep insight of the various concepts, theories, and devices related to the
    implementation of Internet of Things has been discussed, followed by Section 4
    which gives the various related studies concerning different applications of Internet
    of Things in Agriculture, findings like challenges, limitations, improvements,
    future work, etc. with a short description of our proposed work has been given
    in Section 5, and finally, at last, the article ends with a conclusion. Table
    3 gives the detailed nomenclature used throughout this article. TABLE 3 Nomenclature
    SECTION II. Sources and Search Methods The research methodology consists of going
    through articles based on the contribution of IoT and its related technologies
    for the advancement and development of the agriculture filed. For designing the
    overall structure of this article, the data and selected studies are chosen strictly
    based on a time frame. Most of the articles taken for study are sorted from 2015
    to 2020. This time frame is chosen to visualize and understand the current impact
    of IoT in the field. In TABLE 4, a summary of the resources from where the papers
    have been selected is presented. TABLE 4 Summary of the E-Reserves for Obtaining
    the Related Research Articles Given the objective of this article, research has
    been conducted thoroughly by examining the existing literature work related to
    the subject. For developing a firm foundation, the articles containing the origin
    of IoT, alongside current standings, recent trends, and technologies, were considered
    for a study concerning their contributions to the field of agriculture. By reviewing
    the existing literature, a sustainable framework has been developed to overcome
    the existing challenges in the field. The keywords mainly used to identify the
    literature included Precision Agriculture, Agriculture, Plant Monitoring, Internet
    of Things, Smart Agriculture, Smart Farming, Irrigation, Plant Pathology, Wireless
    Sensor Networks, etc. The eight-year trends of the different terminologies and
    their search significance over the years have been extracted from Google and are
    presented in Fig. 2 and Fig. 3. FIGURE 2. Worldwide distribution of IoT of the
    past eight years [19]. Show All FIGURE 3. Precision Agriculture distribution worldwide
    of the past eight years [19]. Show All From the figures, it can be seen that the
    frequency of search or usage of these two terms is somewhat stable over the past
    eight years. An average, 80% of people talk and search about these topics for
    study and other related purposes, thus establishing the growing interest worldwide
    in this area. So for a better understanding, in the next section, the various
    terminologies related to the Internet of things concepts and devise have been
    discussed. SECTION III. Introduction to the Internet of Things (IoT) Concepts
    and Theories Inspired from the technology of the internet to connect the whole
    world, the Internet of Things constitutes of things possessing unique identities
    and are connected to the internet. A cosmos of sensors, actuators, appliances,
    and other devices connected with each over the internet, results in making the
    Internet of Things (IoT). The scope of IoT is not just limited to only connecting
    things but to allow them to communicate and exchange data. Based on the Electronic
    Devices and Network Annex-IEA-4E (EDNA), by 2020 the number of connected devices
    will rise to 50 billion, thus resulting in the generation of high revenue. IoT
    works in a layered manner depending upon the problem it is addressing. Therefore,
    it can be define that IoT possesses a layered architecture [20]. All these layers
    combined are called the IoT functional blocks. Apart from the functional blocks,
    various communication models that aid the smooth working of an IoT model are a
    request-response model, publish-subscribe, push-pull, and exclusive pair [20].
    Fig. 4 represents the reference architecture of IoT in agriculture and includes
    the following layers: device/physical layer, network layer, middleware layer,
    service layer, analytics layer, and end-user layer. The layered architecture includes
    all the hardware devices, facilities, equipment, internet, communication technologies,
    protocols, and data analytic algorithms. How the layers work along with each other
    is described below: Perception Layer: Also called physical or the device layer,
    this layer lies at the bottom of the architecture and constitutes of sensors,
    actuators, microcontrollers, gateways, routers, switches, hubs, etc. The main
    role of this layer is, how efficiently the sensing devices and the other equipment’s
    can work together to gather data. The microcontroller device acts as a controller
    as it performs all the networking ifunctionalities. The microcontroller also acts
    as a network regulating body as it regulates the networks, such that the sensors
    and other devices can collect data. The main aim of this layer is to capture data
    and transfer it to the other layer i.e., the higher abstraction layers. In terms
    of agriculture, the devices in the physical layer gather, soil, water, pH value,
    humidity, leaf wetness, and other data parameters. Also, the topology in which
    the devices are placed plays a major role in power consumption and efficient data
    collection in this layer. Network Layer: It comprises of internet and other communication
    technologies. The main aim of this layer is, how to achieve better communication
    in the platform. In terms of agriculture, the design of this layer plays an important
    role in a framework due to the selection of suitable communication technologies
    relevant to field size or the test bed size. LTE, CDMA, GSM, Wi-Fi, ZigBee, LoRa,
    NFC, UWB Bluetooth, and RIFD are some of the communication technologies used for
    agriculture purposes. ZigBee, LoRa, and NFC are the most used communication technologies
    employed depending upon the problem and the area to be addressed in the agro domain.
    NFC and Bluetooth are the most suitable for the greenhouses. Various protocols
    like HTTP, WWW, and SMTP serve for efficient communication in the agricultural
    scenarios. Middleware Layer: This layer in IoT architecture is accountable for
    device management, context awareness, interoperability, portability, and security-related
    responsibilities. In terms of agriculture scenarios, HYDRA, SMEPP act as best
    middleware due to their context-aware functionalities. Service Layer: Dealing
    with agricultural problems, cloud-assisted service layer in IoT layered architecture
    plays a prominent role in providing cloud storage and Software-as-a-Service (SaaS).
    To facilitate the function of sensing, actuation, and other activities, this layer
    focuses on some main areas or domains such as monitoring, detection, control,
    decision making, recognition, etc. The service layer offers services like device
    monitoring, control, discovery, and data publishing services. Analytics Layer:
    The layer is responsible for the processing and analysis of data. This layer works
    as a consortium of two steps- 1) Data ingestion, is the step that performs storage,
    cleansing, and streaming of data and the 2) Data analytics, which performs data
    reporting, mining, and learning. In the analytics layer various machine learning
    tools, data analytic algorithms are employed to give early predictive decisions
    for measuring the crop yield, crop growth, disease detection, etc. These decisions
    can enhance farm monitoring capacity. The predictive decisions can help in the
    design of better decision support systems. End-User Layer: Being the topmost layer
    of the model, it serves the consumer or the user. To provide the interface to
    the users to control and monitor their model, this layer allows them to view the
    system status, analyze or process the data. In agro models, the farmer is the
    end-user. This layer provides a user-friendly experience and platform to the farmers.
    The services or applications in this layer are designed based on the behavioral
    study and pattern analysis of the user. Various intelligent approaches and data
    analytic studies are employed to understand the behavior of the users, as they
    come with different needs and offer a lot of diversity. Social media, Cloud computing,
    Mobile messaging are the platforms used to provide services to users, experts,
    and industries. Through this layer, the whole IoT based platform can be monitored,
    controlled, and run. The services generated from this layer are mostly the link
    between the user and the systems/platforms. FIGURE 4. A layered ecosystem/architecture
    of Agro-IoT. Show All A. Multimedia Internet of Things (MIoT) in Agriculture Based
    on the working, nature of deployment, and the subject IoT concepts are used to
    address, traditional IoT is differentiated into various forms such as IoMT, MIoT,
    IIoT, etc. Without the inclusion of these concepts, IoT systems cannot successfully
    realize the concept of ubiquitous computing. In these paradigms, the interaction
    and cooperation between the heterogeneous devices is facilitated. Due to the increase
    in the number, diversity of devices and data with time, these concepts have become
    more functional and prominent to develop models and techniques for coming challenges
    and reflect the possibilities enabled in them. All these concepts have the same
    main character of availability, intelligence, and devices but they only differ
    in their due course of action i.e., their general usage. Being an allied branch
    or extension of IoT, MIoT, include smart objects that are usually resource-constrained,
    in terms of memory, energy, and processing power. Due to the progressive reduction
    in size and cost of production of these devices, MIoT models are expected to be
    developed and deployed on a large scale. Generally, the sensors of these models
    are usually designed to be battery operated or solar power operated. Due to the
    large data sensing and analysis, these devices require high computational power.
    Mostly, the multimedia data includes audio, video, and image data, which possess
    unstructured features and is difficult to transmit and analyze on a computationally
    scarce network and low bandwidth conditions. Multimedia data shows different behavior
    compared to the scalar data due to its computational complexity and network topology
    bottlenecks to the Quality of Service (QoS). A lot of work has been done in IoT
    and its allied fields to realize the concept of heterogeneous, low-level data
    transmission, and communication. In agricultural frameworks, the data is mostly
    in the visual form e.g., pest images, plant disease images, field images, etc.
    The characteristic difference in scalar and multimedia data is shown in Fig. 5.
    FIGURE 5. Key characteristic differences between IoT and MIoT data [25]. Show
    All Depending upon the various parameters there are key differences between IoT
    and MIoT and they are discussed as: The IoT systems work mostly on non-heterogeneous
    devices while the MIoT functions well in case of heterogeneity. IoT data is mostly
    scalar, however, MIoT considers the multimedia data. Traditional IoT networks
    does not take into consideration the concept QoS while transmission and communication
    whereas in case of MIoT, QoS and QoE play a major role as the prime parameters.
    IoT can function well over low bandwidth channels whereas MIoT networks are in
    demand of high bandwidth due to bulky data. Node operation is predefined in IoT
    whereas in MIoT the node operation is adaptive in nature. Various authors have
    worked on the implementation of concepts of MIoT for agriculture. Zhang et al.
    [21], worked on the concept of preserving the concept of data confidentiality
    while realizing the challenge of low-cost data acquisition. A measurement matrix
    under the control of chaos and random subsampling is employed to capture the ruptured
    image signals. Then these sampled sub-images are assembled to form a big master
    image and then encrypted based on android transform and single value diffusion.
    Correlation, histogram, keyspace, robustness, real-time, and entropy analysis
    are performed to understand and realize the concept of low-level transmission.
    Rani et al. [22], worked on the concept of bridging the gap between the scalar
    and multimedia data, and for this, they developed an IoMT cross-layer protocol.
    This protocol considered cross-communication between the physical, data link,
    and routing layers. The main objective of this work was to achieve energy-efficient
    communication with less computational time complexity. An optimal mathematical
    model was developed to study the cross-layer behavior in all the three layers,
    therefore selecting the efficient one. A comparative study was conducted on two
    parameters like delay and distance. Usman et al. [23], proposed a multilayer framework
    based on multilevel edge computing architecture to manage, and preserve the privacy
    of end devices from external attacks. Authors mainly focused on the three major
    challenges i.e., node management, privacy-preserving, and network protection.
    The proposed architecture is divided into three layers with the first layer comprising
    of underlying network partitioned into multiple clusters to manage end-devices
    and Level-One Edge Devices (LOEDs). In the second layer, the LOEDs apply an efficient
    aggregation technique to reduce the volumes of generated data and preserve the
    privacy of end-devices. Local differential privacy-based technique is applied
    to protect the privacy of sensitive information in aggregated data. In the last
    layer, the mobile sinks are registered with a level-two edge device via a handshaking
    mechanism to protect the underlying network from external threats. Floris and
    Atzori [24], addressed the issue of evaluation of Quality of Experience (QoE)
    for IoT applications where mostly multimedia data is involved. For designing a
    layered architecture, authors first tried to analyze the QoE parameters or factors
    with applications in the relevant scenarios. Then a layered multimedia IoT architecture
    was proposed for QoE analysis by combing each of the analytic and contributing
    factors. Zikria et al. [25], presented a brief overview of the MIoT along with
    its challenges, solutions and future opportunities. The authors discussed the
    data differences between the traditional IoT and MIoT, along with the role of
    communication technologies. The demand for realizing the dream of MIoT and its
    bottlenecks were also discussed. The challenge of data collection and its impact
    over the network traffic is also discussed along with the methodologies developed
    to solve it. Nauman et al. [26], presented a comprehensive survey on the multimedia
    internet of things. Authors discussed the existing role of MIoT in concern with
    various fields like medical, agriculture, automation, and industry, etc. The importance
    of QoE and QoS for multimedia transmission over IoT channels is also discussed.
    A better need for routing and Physical-Medium Access Control (PHY-MAC) protocols
    for M-IoT was also discussed. A potential discussion on open research issues related
    to multimedia communication in IoT was presented. Alsamhi et al. [27], presented
    a survey on the role of green IoT in greener and smart cities. The authors focused
    on how the environment pollution can be controlled along with other parameters
    for making living more sustainable and green with the aid of IoT concepts. AlSkaif
    et al. [28], presented a survey on the energy efficiency of MAC protocols in low
    data rate wireless multimedia sensors. The conflicting goals of WMSN were also
    discussed. Role and challenges of multimedia data were also discussed. A focused
    analysis was performed on network parameter constraints and what techniques are
    employed to solve them. A comparison of the energy consumption of MAC protocols
    in four selected application scenarios related to smart cities and environment
    monitoring was also presented. Libo et al. [29], worked on how with the use of
    multimedia data in the form of images can be employed to detect the plant diseases.
    Rape diseases were studied as a case study. Authors also discussed the challenges
    and bottlenecks faced for the transfer of multimedia data over low bandwidth channels.
    With machine intelligence, authors also proposed a diagnostic procedure via which
    the data can be transferred over wireless multimedia sensors networks. Psannis
    et al. [30], proposed a technique for the transfer of advanced media-based smart
    big data via intelligent systems. Authors in their work addressed the problem
    of the rapid rise of devices and heterogeneity. An encoding algorithm with HVEC
    standard for performance evaluation was proposed to transfer the data intelligently.
    B. Hardware Platforms for IoT The hardware platform for IoT comprises a set of
    compatible hardware capable of running certain software. The main components of
    a hardware platform are machine language, sensors, wireless devices, programs,
    and processors, protocols, etc. The processor in a hardware platform determines
    how much fast a framework can work. To design certain new methodologies in IoT,
    various hardware platforms supported are elaborated as: 1) Raspberry Pi It is
    a series of single-board computers developed in the UK by Raspberry foundation.
    There are various families of raspberry i.e., Raspberry Pi 1, Raspberry Pi 2,
    Raspberry Pi 3, Raspberry Pi Zero, Raspberry Pi 4. All these families have different
    models. The Broadcom processor is used in most of the boards. It acts more like
    a computer system and can do multitasking [31]. 2) Arduino Uno Developed by Arduino.cc,
    it is a microcontroller board and is based on the ATMega32 processor. Arduino
    Uno possessing a USB port is a very valuable addition to the family of microcontrollers.
    Various versions of Arduino like Arduino Uno, Arduino Due, Arduino Leonardo, and
    Arduino Mega are present in the market. Out of these the most common versions
    are Arduino Uno and Arduino Mega [32]. 3) Node MCU It is an open-source IoT platform.
    It generally refers to firmware rather than the development kits. It is a low-cost
    open-source kit/module developed for the ESP8266 Wi-Fi chip. It is developed in
    the Arduino IDE environment [33]. 4) Beaglebone Developed by Texas Instruments,
    it is a low-cost open-source single-board computer. Its size measures 75 by 75
    mm and possesses all the functionality of a basic computer. It requires 2W of
    power or a 5V separate power and can work smoothly without any cooling or sinks
    [34], [35]. 5) Banana Pi It is a low-cost credit-card-sized single-board computer
    developed by a Chinese company Shenzhen SINOVOIP Co. Ltd. The hardware design
    is hugely influenced by Raspberry Pi. It is compatible with Raspberry Pi boards
    as well. It can be developed both on Android and Linux [36]. The various hardware
    platforms of IoT with their functional specifications are given in TABLE 5. TABLE
    5 Hardware Platforms of IoT and Their Specifications C. IoT Operating System (IoT
    OS) for Agriculture IoT operating system (IoT OS) is an operating system designed
    to perform within the constraints particular to Internet of Things devices. IoT
    OS are designed and developed in such a way that it can function under the restrictions
    of memory, size, power and processing capability. The main aim of IoT OS is to
    enable successful data transfer over the network via internet. The IoT OS for
    a particular framework is not chosen at random. Certain parameters such as footprint,
    scalability, portability, modularity, connectivity, and reliability are taken
    into consideration. As per the requirement of agriculture, a huge number of devices
    are connected having different features and also the devices have to withstand
    the different environments, the OS then to be chosen must be scalable, cost-efficient,
    and reliable. Various studies have been put forward for the role of IoT OS in
    network management and overall communication. Javed et al. [37], provided a detailed
    reviewed comparison of the operating systems designed for IoT devices based on
    their architecture, scheduling methods, networking technologies, programming models,
    power, and memory management methods, along with other features required for IoT
    OS applications. Musaddiq et al. [38], studied the role of small IoTOS in powering
    the scarce network devices. Authors also put light on the energy consumption of
    these devices. A detailed discussion on IoT devices and resource management is
    provided and some state of art IoT OSs such as Contiki, TinyOS, and FreeRTOS are
    also investigated. Baccelli et al. [39], a comprehensive review of RIOT is provided.
    The key components highlighted in this study are the kernel, hardware abstraction,
    software modularity for various configurations. The authors also discussed the
    operational aspects like system boot-up, timers, power management, and networking
    along with the relevant APIs. Zikria et al. [40], proposed a study for the management,
    challenges, and opportunities of IoT OS in managing IoT systems. The authors discussed
    the issue of interoperability, protocol functionalities to support heterogeneous
    deployment scenarios. Supported hardware and future research trends are also discussed.
    Ain et al. [41], proposed an efficient and flexible decision-making system for
    maintaining user thermal comfort with the help of intelligent sensors. Fuzzy based
    approach along with RIOT OS was developed to tackle the problem of fluctuation
    and adjustment. Results show that the proposed approach can perform 28% better
    than the existing approaches in terms of energy efficiency. Stergiou et al. [42],
    studied the transfer of metadata in the IoT networks. Authors discussed the techniques
    and open tools such as CC analyzers and simulators which can provide intelligent
    metadata transfer over a network. The experimentation was performed on CloudSim
    and Cooja emulator of Contiki OS for the testing of a single network segment.
    From the experimentation, it was found that no duplicate packet transfer occurred
    which is a good sign for multimedia data transmission. The various IoT OS with
    their functional specifications are presented in TABLE 6. TABLE 6 IoT OS Platforms
    in Agriculture and Their Specifications D. Sensors and Their Role in Agriculture
    Sensors are the devices, modules, machines or subsystems capable of detecting
    the changes or events in the environment. They also send signals back to the receiver
    end. Mostly the sensors are used with other electronics. A sensors sensitivity
    usually indicates how much change in sensor output occurs with respect to the
    change in the input quantity measurements. Most sensors possess the linear transfer
    function. The sensitivity of a sensor is defined as the ratio between the output
    signal and the measured property. The resolution of a sensor is the smallest change
    it can detect in the quantity it is measuring. In the area of agriculture, demand
    of technological solutions with high aim in rising production and quality is increasing
    day by day. Also the solutions are required which provide optimal analysis and
    sustainable methods for the field development with reduced cost and time. To sustain
    such challenges, sensor- based technologies have proven to be of much help to
    tackle the above issues and challenges. Precision agriculture is an emerging area
    where sensor based technologies are playing a major role. Since the sensors are
    a major data collection agents, they play a dynamic role in agriculture. Also,
    it is very difficult to collect the data from an agricultural field due to the
    undulating field conditions that keep on changing over time. Sensors are selected
    or designed according the problem to be addressed or needs identified by the farmers.
    Agriculturalists generally use sensors to sense the soil conditions, humidity,
    crop conditions, minerals, pH value, water levels, and sunlight, etc. The nature
    and the characteristics of the component which needs to be sensed also plays a
    major role in the development of a sensing device. With the development of technology,
    machinery and easy-to-use microcontroller platforms, the usage of sensors has
    expanded beyond the traditional fields of measurement i.e., temperature, pressure
    and flow. However, the analog sensors such as potentiometers and force sensing
    resistors are still widely in use. Pajares et al. [54], discussed the sensors
    in agriculture and forestry. In the article, various related works of the sensors
    performed by different authors in the same domain were presented. The role and
    importance of the component or substance which needs to be sensed was discussed
    along with their characteristics and specifications. The major areas focused by
    authors were soil analysis, seed growth, weed detection, forest stands and reflectance,
    machinery for effective treatments, microorganisms, pest control, seedling breeding,
    growing, state of health, positioning, navigation, safety, detection and classification.
    Zhu et al. [55], showed that LIDAR, IMU, and Encoder (x2) can be used for designing
    a prototype vehicle for the agricultural domain. The authors also discussed how
    these sensors can be used for the development and usage of that prototype in case
    of undulating surfaces and rough terrains. A complete review of the wireless sensors
    and the network applications used in agriculture is provided. The authors also
    addressed the importance of sensors in the field of agriculture. Along with the
    sensors, the communication technologies that support sensor communications are
    also mentioned by Rehman et al. [56]. The sensors used in the medical and agricultural
    fields have also been discussed. In the case of the agricultural field, the various
    conditions and circumstances affecting the data collection from sensors are addressed.
    The various types of sensors and their platforms used by different authors in
    their work are also included by Chokkareddy et al. [57]. Plageras et al. [58],
    used efficient IoT based sensor and big data analytics for secure collection of
    data and communication over a channel. In the study, smart housing or building
    was taken as case study, and the secure data collection with the sensors was performed
    and analyzed. The behavior of various sensors for data collection in different
    scenarios in terms of IoT and cloud computing was studied by Stergiou et al. [59].
    The secure communication among devices was also studied along with performance
    bottlenecks and challenges. The various sensors and their use in agriculture is
    discussed below: 1) Level Sensors They measure the substance of liquid in a cast.
    The cast can be any agricultural field, pond, water tank, etc. They measure data
    in two methodologies 1) Point level measurements: indicate only whether the constituent
    or level measured is above or below the sensing point or threshold. 2) Continuous
    measurements: specific range measurements and exact substance amount determination
    are performed by these sensors. In agricultural fields, the water level sensors,
    humidity sensors, and moisture sensors are used to measure the water content levels
    in a field. The point level sensors are used when the water content in the cast
    i.e., soil or testbed is very less i.e. in dry and arid areas, whereas the continuous
    level sensors are feasible for semi-arid locations. Some of the ultrasonic level
    sensors are also used in water treatment plants. Blank et al. [60], designed a
    low-level senor based fusion application for agricultural machinery design. 2)
    Temperature Sensor Temperature sensors measure the temperature of the environment
    or surroundings. They are of different types i.e. thermistors, thermocouples,
    resistance temperature detectors, infrared sensors, semiconductor sensors. In
    agriculture they measure the temperature variants in a field. Mahan et al. [61]
    designed an optimal temperature based field monitoring system by using a low-cost
    infrared sensor. 3) Proximity Sensors Detect the presence of nearby objects without
    any physical intervention. The sensor works by emitting an electromagnetic beam
    in the field and looks for any alterations in the signal. These are mainly employed
    in agricultural cattle grazing, counting of fruits, etc. Kim et al. [62] used
    a capacitive proximity sensor to optimize the harvest yield of fields. 4) Infrared
    Sensors Senses the changes in the environment by emitting infrared rays. They
    work in two approaches i.e., active and passive. An active IR sensor can both
    emit and detect the radiations and constitute a light-emitting diode and a receiver.
    The passive IR sensors can only detect the radiation and possess only a LED. In
    agriculture field infrared sensors can be employed to detect the presence of rodents
    in the orchards, count the number of plants or trees in the field, capturing satellite
    images of the field. Allred et al. [63], used IR sensor-based satellite imagery
    to map the findings and results of UAV to chart agricultural drainage systems.
    5) Touch Sensors Also known as tactile sensors, work on sensing the touch. They
    are low-cost sensors. In the agriculture field they can be used for the detection
    of intrusions in the field. Depending on the target and the range, there are different
    types of sensors, the same are discussed in Fig. 6 and TABLE 7 below: TABLE 7
    Sensors Based on Their Fields of Application FIGURE 6. Sensors and their types.
    Show All SECTION IV. Related Work The advancement and role of the Internet of
    Things in precision agriculture along with the related areas where research is
    being conducted are discussed in this section. Literature including various approaches,
    techniques, and methodologies presented by the number of authors has been divided
    into different sections. Various studies are performed and put forward by various
    academicians and authors concerning the evolution of agriculture relating to the
    incubation of the concepts of the Internet of Things. Kim et al. [64], reviewed
    different articles related to the induction of unmanned aerial vehicles in agriculture.
    The authors highlighted the recent trends, controls, perspectives, and platforms
    of UAV for agriculture. The study focused on what are the different platforms
    used for UAV and how those platforms can be designed. The hardware components
    related to the design of UAVs were also discussed. Sensor types compatible with
    platforms such as fixed-wing, helicopter, quadcopter, etc. were also discussed.
    A study on critical technologies for communication, modeling, and control was
    also presented. Various applications of UAVs in crop monitoring, spraying, and
    mapping, etc. were also presented. The authors concluded their study by providing
    the data on the latest technology trends and applications of UAVs in agriculture.
    Ayaz et al. [65], studied the latest trends and technologies in the field of agriculture.
    The potential sensors, IoT devices, communication techniques, used for soil, crop
    irrigation, insect, pest analysis were studied and discussed. Also, how this technology
    is redefining the agriculture system and boosting farmers to work, is portrayed.
    Authors studied the recent developments of IoT and how it is helping in providing
    the solutions while designing an IoT system for agriculture, what strategies and
    policies need to be considered. The advanced agricultural practices such as greenhouses,
    vertical farming, hydroponic farming, and phenotyping are also explained. All
    the crop stages and potential challenges are also discussed. Farooq et al. [66],
    presented many aspects of IoT in agriculture. Authors discussed all the recent
    technologies associated with IoT along with big data analytics for the development
    of precision agriculture systems. Various network topologies, architectures, layers,
    and protocols are also presented. In context to the development of a smart farm,
    all the major components and relevant technologies were discussed. Also, the regulations,
    standardizations, and policies used by several countries to standardize IoT methods
    for agriculture have been discussed. Elijah et al. [67], gave an overview of IoT
    and data analytics technologies and practices in agriculture. The authors divided
    their study into four sections i.e., communication technology, internet, data
    storage, technology. The authors also provided an analysis and data on how the
    aforementioned sections can be employed for dealing with the diminishing agricultural
    resources. The pros and cons of various technologies such as cloud computing,
    WSN, radio frequency identification, middleware systems, etc. to their application
    in the agriculture field are also discussed. Studies on how these technologies
    can be used to develop an IoT ecosystem, with technical and business scenarios
    were also presented. Misra et al. [68], discussed the concepts and role of IoT,
    AI and big data in the field of agriculture. In the review, focus was laid on
    green- house monitoring, disease detection, usage UAV machines and drones agriculture
    and supply chain modernization, social media in food industry, food quality assessment
    and modernization for food traceability. Thakur et al. [69], reviewed articles
    of repute in the context of the employability of WSN in agriculture. The authors
    highlighted the different communication technologies and WSN technologies adopted
    for precision agriculture. The authors also discussed various sensors and their
    role in agriculture. The influence of various techniques for designing the models
    is also discussed at length. Damos [70], presented a review on the pest control
    in precision agriculture. The author discussed the various computer-aided technologies
    employed for forecasting and designing decision support systems. The challenges
    and constraints of designing the decision support system were highlighted. The
    most available and published data present online in terms of pest management was
    also discussed. A differentiation between the documented and existing decision
    support systems was highlighted. The advancement and role of the internet of things
    in precision agriculture along with the related areas where research is being
    conducted are discussed in this section. Literature including various approaches,
    techniques, and methodologies presented by the number of authors has been divided
    into different sections and are discussed as follows: A. IoT in Farm Management
    Farm management refers to the construction and implementation of decisions for
    obtaining the maximum production and profit via organizational operation of decisions.
    This area is most benefitted by automation and the implementation of new technological
    methods. With farm management agricultural practices are made informative by evaluation
    and comparison with the other developed approaches and methods. Diedrichs et al.
    [71], with the aid of machine learning and IoT sensing devices, predicted the
    occurrence of frost events. Authors designed their system based on three layers
    i.e., a group of internet-enabled devices for water data collection. The authors
    augmented the data using the synthetic minority oversampling technique due to
    its capability of reducing the occurrence of errors with the ML approaches. The
    humidity and temperature sensors were employed to collect data from five meteorological
    stations of the Mendoza Province of Argentina. For each station, the existing
    sensor data spanning from a period 2001 to 2016 was taken as a reference to collect
    the daily data. The data was divided into two sets i.e., locally available is
    the config-local and the one available globally is the config-all. Bayesian Networks
    were employed along with SMOTE and recursive portioning, to train the system.
    Jawad et al. [72], designed a wireless power transfer technology based on a drone
    charging system for smart agriculture. The authors used the concepts of magnetic
    resonator coupling and sleep/active modes of charge transfer system for designing
    the model. Authors mainly focused on how to charge wirelessly the drones and other
    equipment employed in agricultural field monitoring. The magnetic resonant coupling
    technique was considered due to its capability of high power transfer and efficiency.
    In the experimentation, authors found that the FSC coil with 150 coil turns in
    the transmitter circuit and the MTC comprising of 60 coil turns in the receiver
    (i.e. drone) accomplish the maximum transfer power and efficiency. For finding
    the accurate efficiency, the model was tested based on different load, and how
    to load misalignment changes the model behavior was also noted. Drone flight time
    was also taken into consideration and was estimated based on the adopted battery
    capacity and payload of the drone. Tseng et al. [73], proposed an intelligent
    IoT based platform for farm management. The authors took the data based on different
    plants i.e., beans, spinach, celery via sensors, and used 3D normalization on
    that data to extract the optimal/useful data. The average and variance were moved
    to obtain user data without making any visible changes in the actual data. Farmer’s
    behavior was analyzed for the application of pesticides and fertilizers. For the
    platform development SIM5320E, IoT Development Board is used along with the BH1750
    illumination sensor and BME280 temperature and moisture sensor. Bacco et al. [74],
    designed a model based on air-ground UAV communications for smart farming. Authors
    empirically and analytically developed a real test-bed implementation of IEEE
    802.15.4 based communication between unmanned aerial vehicle and ground sensors.
    The focus was laid on how to transfer data between sensors and other devices present
    on the ground in an optimized manner to ensure fewer transmission losses. From
    the experimentation, and result analysis authors found the Gilbert-Elliot model
    to be suitable to approximate the packet loss in the link at low transmission
    speeds. The authors used approximately 80,000 datasets from the testbed. Ahmed
    et al. [75], based on the concepts of fog computing and Wi-Fi-based long-distance
    networks proposed a system for smart monitoring. In comparison to the existing
    traditional models, a scalable and flexible model was designed for monitoring
    and controlling agro farms in rural areas. Authors introduced a WiLD network and
    fog computing in the existing WSN-based solutions to cover long ranges with fewer
    delays. A cross-layer based MAC and routing solution for sensing and actuating
    were proposed to reduce the network latency. Throughput, coverage range, and network
    latency of the network structure were analyzed. Liu et al. [76], by hybridizing
    the concepts of IoT, cloud computing, and data mining proposed an integrated framework
    for the agricultural field. China was considered as the territory to design and
    devise mechanisms to enhance modern agriculture as compared to the conventional
    one. Quality, safety, management, and pollution are were taken into consideration
    while designing the model. NoSql database, DynamoDB, relational database Oracle,
    and file object storage Amazon S3, were employed to provide the hybrid data storage
    design. Bai et al. [77], due to the issue of frequently changing environmental
    conditions addressed the issue of estimation and control in the greenhouse. The
    authors studied how to collaboratively deploy WSNs and actuator schemes for agriculture.
    Sensor nodes were used to conduct a local estimation with Kalman filters to enhance
    the stability and transmission of data ensuring energy optimization. Using the
    concepts of collective clustering and mutual effect, the actuator node based scheme
    is designed for the improvement of estimation speed and conversion accuracy. Parameter
    optimization is achieved through fuzzy neural networks along with the PID control
    algorithm. Jinbo et al. [78], performed research on developing a platform for
    the monitoring of a field with agricultural modernization. A system named DEMO
    was proposed by using the SpringMVC framework, MyBatis, Spring Data DynamoDB Stored
    Procedure, Paho, and other related technologies grounded on the J2EE platform.
    Open-source elements such as raspberry, IoT gateway integrated with the ZigBee
    module were used for the development of the platform and were chosen due to their
    stable and cost-efficient properties. The proposed system is capable of massive
    data processing and analysis for agricultural monitoring. RESTful interface service
    system developed on a cloud platform, ExtJs client technology, and WeChat were
    applied to develop the Demo system of an application layer. Mukherjee et al. [79],
    worked on the challenges of a decentralized and heterogeneous UAV swarm deployment.
    The work is focused on how to design and deploy a UAV in resource-constrained,
    harsh, and challenging environments. Swarm edge due to its heterogeneous nature
    and unequal data generation within its member’s results in under-utilization of
    the available computational resources. To solve this issue, the authors proposed
    a Nash bargaining-based weighted intra edge processing offload scheme which can
    reduce the problem of heavy processing in some swarm members. The proposed method
    achieves better scalability and reduced processing delays. Chen et al. [80], developed
    an IoT based inexpensive platform named ‘AgriTalk’ for precision soil farming.
    Turmeric plant was considered for cultivation and experiments were conducted to
    enhance its growth and production. Authors employed AgriTalk in developing several
    other IoT based models for the fields of Mountain Bao in Taiwan. For the study
    authors grew turmeric in three fields. The proposed model is capable of addressing
    dynamic changes in the field conditions for plants grown via in-soil cultivation.
    Automated devices like sensors, actuators with desired farming intelligence were
    employed to design the model. Manual delays for automatic control and switching
    over long distances were also addressed. From experim-entation it was found that
    the curcumin concentration in turmeric leaves after six months was elevated to
    6685.6 μM as compared to 72.1 μM thus witnessing a fivefold increase. Lopez et
    al. [81], proposed a smart system for estimation of soil parameters using an autonomous
    wireless sensor network. Phosphorus content in the soil was measured. For power
    optimization and maintaining a balance between change rate phenomena of soil throughout
    the day for phosphorous estimation, authors developed a dynamic power management
    approach. DPM was tested on both the circuit level and the system level. ANN was
    used to find the significant correlations between the soil parameters such as
    electrical conductivity, phosphorous, temperature, and humidity. Also, energy
    harvesting with the help of IoT and cloud services is proposed. Chen and Yang
    [82], provided a detailed analysis of how efficiently the systems can be developed
    for agriculture based on the techniques of data visualization, clustering, etc.
    The authors studied the significance of various parameters in the same environment
    and effects. For the promotion of efficient development of agriculture, the authors
    proved that data visualization and cluster analysis pave a way for finding the
    key technologies to be applied in modern agriculture. For time and cost optimization,
    functions such as sensing, monitoring, identification, transmission, and feedback
    can be realized using IOT platforms and they can serve as an impetus for intelligent
    agriculture. To test and develop their methodology, authors took the agriculture
    situation in the Jhinsa river basin which lies in the upper reaches of the Yangtze
    River as a testbed. This area has become the most abundant area of biological
    communities in Eurasia. For the study, the authors collected precipitation and
    temperature data. Since data was large, k-means clustering is used to analyze
    the data. Leng et al. [83], presented a study for the application of IoT in agricultural
    products supply chain management. Authors discussed in length what to take into
    consideration, while designing a structural model for the supply chain management.
    RIFD technology was considered as the key constituent for designing the model.
    Pereira et al. [84], based on the concepts of IoT developed an instrument capable
    of performing environment monitoring in a poultry farm. The authors focused on
    designing a cost efficient prototype for the poultry monitoring which provides
    affordable benefits compared to the commercial products available in the market.
    DHT22 sensors were used to collect air pressure and temperature details and CPU
    such as Wemos Mini D1with chipset ESP-8266EXwith standard Wi-Fi 2.4 Ghz connectivity
    were used to calibrate the whole model. Singh et al. [85], developed a cloud based
    autonomic system for delivering agriculture as a service via web and mobile based
    applications. For data collection IoT and other devices were used for communication
    and coordination. Fuzzy logic was used to automatically analyze agriculture. An
    architecture named Agri-info was developed to provide user services. Kolipaka
    [86], proposed a predictive analysis using cross media references for precision
    farming. Authors focused on the usage of sensors and MEMS integrated IoT for precision
    farming. The crop growth parameters such as soil state, water, weed state, crop
    quality and seed quality were also discussed. ML and big data approaches were
    applied to perform predictive analysis and thus finding method to provide optimal
    solutions to farmers. Further based upon the certain characteristics we have tabularized
    the major findings in TABLE 8. TABLE 8 Summary of Developed Methods for Farm Management
    B. IoT in Irrigation Irrigation is the method of application of controlled water
    to the farming fields, at needed intervals. Irrigation has been a constant area
    where a lot of energy, money, and labor is invested in the case of farming. Detection
    and knowledge of water level can reduce the cost of production by half. For increasing
    crop yield, smart irrigation management is essential. Various optimized and precise
    methods have been developed by various academicians. Klein et al. [96], with the
    help of satellite images, worked on the implementation of closed-loop irrigation.
    The authors designed a real-time water requirement system, which can optimize
    water delivery for 140 cells located in four hectares of land. Vegetative indexes
    were calculated for analyzing the total water consumption and how via loops this
    facility can be automated. Through this study and experimentation it was found
    that with the integration of closed-loop strategy and advanced water analysis,
    the overall water consumption efficiency can be improved. Alahi et al. [97], extended
    research to design and develop a smart nitrate monitoring system for the monitoring
    nitrate content in the surface and groundwater. The authors proposed a portable
    sensing system with the help of a planar inter-digital sensor, associated electronics,
    instrumentation, and electrochemical impedance spectroscopy-based analysis. Through
    real-time monitoring and sending data directly to the IoT web server, the proposed
    system possesses the capacity to monitor the impact of industrial, urban, and
    agricultural activity on water content and quality. The system also ensures distributed
    monitoring. Daskalakis et al. [98], used leaf sensing technology instead of ground
    soil monitoring for knowing the plant water stress. The authors proposed a low
    cost and low power consumption leaf moisture sensing model by sensing the leaves
    with the new plant backscatter sensor node/tag. The developed tag collects the
    information from a leaf via analog and digital conversions and then the data is
    transferred via remote communication to a low-cost software-defined radio reader
    using monostatic backscatter architecture. The data collected from this node is
    then connected to the irrigation system. The proposed system is powered by a flexible
    solar panel. Jayalakshmi and Gomathi [99], proposed a sensor-cloud based precision
    agriculture for intelligent water management, to enhance crop production. For
    the model design, moisture and stress levels of different plant organs were considered
    along with the behavior vegetative and reproductive organs cell growth, and its
    effects on the water requirement were studied. The dimensionality reduction technique
    was employed to choose the optimal parameters. For the case study, the wheat plant
    was taken. The effect of soil temperature and water suction rate was studied in
    the case of the plant growth. The non-adsorbing testbed was prepared by exploding
    the sand grains at high temperatures. With the aid of WSN, it was monitored when
    the plant needs to be irrigated. Angelopoulos et al. [100], developed a small
    scale smart irrigation prototype for a strawberry greenhouse. The prototype possesses
    off the shelf hardware and software requirements and was tested on large farms
    having multiple crops to get a data gain. The reference architecture also targets
    edge data distribution. The model was tested in Greece and its performance was
    compared against the traditional existing strawberry greenhouse methods for irrigation.
    Compared to the cloud-based approaches, and their incompetence to handle network
    traffic, security challenges, and data sharing with the third party, this model
    is secure and reliable and can handle large datasets. Dominguez-Nino et al. [101],
    worked on how to integrate sensors for developing automated software tools to
    undertake the routine tasks and decision-making involved in scheduling irrigation.
    The authors also focused on the suitability of capacitance approach soil moisture
    sensors and how to automatically interpret them and providing feedback to the
    scheduling algorithm. The proposed approach was tested in the apple orchards located
    at the IRTA-Lleida Experimental Station in Mollerussa, Lleida, Spain. For the
    study, both the physiological and agronomic properties were taken into consideration
    while experimentation. Krishnan et al. [102], designed an automated irrigation
    method. The authors developed a fuzzy logic-based system for precision irrigation
    by using Global System for Mobile Communication (GSM) service to enable farmers
    to water the fields. Soil and temperature, humidity, and motor status parameters
    were monitored and taken for the study. For the efficiency evaluation of the system,
    a comparison was done between the proposed system, drip irrigation, and manual
    flooding. Harun et al. [103], designed an environment-friendly system named “Greenhouse
    Irrigation Management System” for precision irrigation in agriculture. Some critical
    environmental parameters such as soil moisture, pH, temperature, humidity are
    measured with the use of WSNs to make decisions. The sensors measure the data
    and based on certain threshold value result, the fields are irrigated. Olivo [104],
    focused on the problems associated with device growth and its effects on the control
    decisions. To address this issue, an architecture named “Rules Engine and Context
    Event Processor (RECEP)” is proposed for the dynamic processing of events originated
    in the context of IoT and PA. In this model the concept if optimization was used
    to optimize the resources to increase agricultural production. The experimental
    setup was set in a banana field located in Machala-Ecuador. The given model was
    designed for operating in low-cost infrastructures for both small and large producers.
    Marcelino et al. [105], based on the work and issues of small family farmers,
    proposed a low-cost system for control, monitoring, and automation of agricultural
    greenhouse. The proposed model was designed by prototyping Raspberry Pi and Arduino
    along with sensors. Temperature, humidity, and light sensors are used for the
    field data collection. The web human interface was developed for interaction between
    the system and the farmers. Koksal and Tekinerdogan [106], developed an automatic
    farm management information system capable of performing data acquisition, processing,
    monitoring, planning, and decision making and managing the farm fields. The authors
    tested their models on two case studies on smart farming in Turkey, one for smart
    wheat in Konya and other greenhouses in Antalya. The feature-driven domain analysis
    model is designed based on IoT reference architectures and data modeling approaches.
    The system was capable of performing all farming related functions, such as irrigation,
    crop monitoring, etc. Hate et al. [107], designed a vegetable traceability system
    with smart irrigation. The field parameters like soil moisture, humidity, water
    supply control, and temperature of particular farmland are monitored with sensors
    such as water level, humidity, soil moisture, and temperature sensors. With IoT,
    the cost is reduced and efficiency is improved. Agale and Gaikwad [108], focused
    on the problem of water reduction in farmlands. An IoT based automatic system
    is designed to collect, analyze, and monitor the real-time sensor data every 10
    seconds from soil and environment and provide irrigation solutions based on that.
    The parameters like temperature, humidity, soil moisture were considered for data
    collection. The proposed method achieved 92.24 % accuracy in water-saving strategy.
    Huan et al. [109], designed a system for monitoring of water in aquaculture ponds.
    To design the system authors used the concept of narrowband IoT (NB-IoT). The
    system used STM32L151C8 microcontroller, sensors and other devices for real time
    data collection and other services. The system was implemented and tested in ChangZhou,
    JiangSu Province, China and performed with low error rate. Vij et al. [110], developed
    a smart precision irrigation system based on the concepts of IoT and machine learning.
    The main aim of authors was to develop a computationally efficient and low cost
    system. Raspberry Pi and Arduino Mega 3 were used as microcontroller and other
    sensors were used to fabricate the system. Compared to the existing systems, the
    proposed system is computationally efficient. The various findings of this section
    have been tabularized in TABLE 9. TABLE 9 Summary of IoT Based Developed Methods
    for Irrigation C. IoT in Crop Monitoring Crop monitoring is the process or method
    of observing the farm fields and crops for enhancing productivity and reducing
    cost. This can be performed with satellites, drones, sensors, and other methods.
    Vegetative indexes of an area can also play a major role in crop monitoring by
    providing the data related to the exact area of land under cultivation etc. With
    crop monitoring the estimated time of harvest can be predicted. de Souza et al.
    [118], proposed an integrated framework with the combination of hardware, software,
    middleware, and other equipment to monitor the testbed. The authors also recorded
    the testing of each equipment in the seed test labs. An IoT based system was developed
    where soil sensors provided the relevant information/data for the growth of seeds.
    Testing was performed in the Official Seed Analysis Laboratory (OSTL) of the Brazilian
    Agricultural Research Corporation. Rekha et al. [119], developed a WSN based framework
    for sensing agricultural characteristics and then provide decisions to the farmers.
    Based on the data collected, the model will provide decisions for irrigation and
    crop monitoring. For the case study, India was taken into consideration due to
    its large farming area and population dependence on agriculture. Groundnut farming
    was studied in this work. Becker Reshef et al. [120], proposed a remote sensing
    analysis based crop monitoring system for strengthening agricultural decisions
    and improving crop security. The authors named this model as “GEOGLAM” model which
    ensures the decision support of all the necessary steps for crop security and
    analysis. Kamath et al. [121], proposed a wireless sensor-based model for monitoring
    the growth of weeds in paddy crop. The authors performed a study on how Raspberry
    Pi and WSN can be modeled for precision agriculture. Raspberry Pi based model
    was deployed to monitor crop along with the integration of Bluetooth 4.0 to send
    signals from visual sensors to the base station. A solar cell battery was used
    to provide power to the system. At the remote station, the images of the crops
    were processed to extract the background and foreground objects. Classification
    between weeds and paddy crop was performed with SVM. Rao and Sridhar [122], Developed
    an automatic irrigation system by prototyping Raspberry Pi and other IoT devices
    to enhance crop productivity. A cloud-based data collection system supported by
    sensors used for data collection is employed to collect the field data. The data
    collected is sent to the base station and based on that data, the decisions are
    made. Parameters like humidity, soil temperature, and sunlight availability are
    measured. Geng et al. [123], for greenhouse environment monitoring proposed a
    four-layer IoT based mobile system. To design the system, the authors proposed
    integration of both Raspberry Pi and Arduino chip in the design where the former
    serves as the data server and later as the master chip for a mobile system. Fabrication
    of all the sensors, actuators, and other devices was done on a single board, thereby
    reducing the device’s physical distances for better performance due to serial
    communication. A dedicated communication protocol with CYC was designed to reduce
    transmission errors and data loss. Shadrin et al. [124], designed an intelligent
    agriculture IoT equipment to monitor the crop. The authors designed the system
    using the test case of monitoring the seed germination. The proposed model was
    fabricated with the integration of low power embedding wireless sensor nodes with
    artificial intelligence. CNN was used to train the model along with the collection
    of data via sensor nodes of the different stages of germinated seeds. A 3D clustering
    analysis was used to analyze the relationship between environmental factors and
    farmer issues. Uddin et al. [125], focused on developing a system for monitoring
    crops from the stage of seed germination to harvest. For this authors proposed
    a resource optimized fast health crop monitoring system. Saudi Arabian agriculture
    was taken into consideration as a case study. IoT and drones were harnessed to
    make an efficient agricultural monitoring system. Data collection methods were
    used to collect data from heterogeneous devices arranged in localized clusters.
    The system was designed to withstand a harsh environment with agility and feasibility.
    Feng et al. [126], proposed a crop growth and nutrition diagnostic system based
    on hyperspectral remote sensing. Color canopies obtained from images captured
    with satellites, UAV, and remote sensing were used to determine the index of yield.
    To determine the color canopy of plants, the color correlation was employed. Cen
    et al. [127], discussed the usage of UAV with dual image frame cameras to estimate
    the aboveground biomass and panicle biomass of rice. The authors conducted their
    study at different growth stages of the crop. The field investigations were made
    on the variations in typical vegetation indices. The accuracy of the model was
    obtained with the extraction of RGB images at two different stages. Random forest
    was employed to obtain AGB as well as the PB. Khan and Kumar [128], proposed a
    framework for the monitoring the crop field. To make their study reliable, the
    authors monitored weather in real-time to get an idea of how to provide an ambient
    condition to farm. Production increase techniques are also proposed for precision
    farming. To overcome the problems of delay in information transfer from the field
    to the farmer, the context-based agricultural mobile sink is designed in WSN.
    Thus the mobile sink node introduction improves the overall efficiency and energy
    consumption of the model. Frontward communication area (FCA) based route selection
    is proposed to reduce energy consumption and delay. Min and Kuang [129], designed
    a system for monitoring the rice crop field. The analysis of the growth of rice
    and rice duck in real-time is done by obtaining the data via the Internet of Things.
    Authors comprehensively viewed the rice and rice duck plant species and the ambient
    farm conditions required for their growth. Qiulan et al. [130], estimated the
    production of carbon from the crop growth. The authors provided a framework for
    the estimation of organic carbon compounds in the farmland soil. The wheat plant
    was taken as a test case in this study. The model provided the real monitoring
    of the farm for carbon production with the aid of IoT and other devices. The real-time
    data was collected from the Yanzhou District of Jining City, Shandong Province,
    China. Harun et al. [131], proposed an improved crop monitoring system based on
    IoT concepts. Brassica Chinensis is the plant taken for study and was subjected
    to four different light treatments such as pulse treatment, continuous treatment,
    high intensity, and artificial control for enhancing the plant growth. The authors
    also analyzed parameters such as leaf count, height, dry weight, and chlorophyll
    a and b. An intelligent embedded system was developed to monitor and capture real-time
    data. Alonso et al. [132], designed an intelligent edge IoT based platform for
    precision livestock and crop monitoring in a dairy farming scenario. In their
    study, authors used the concepts of AI, blockchain technology, edge computing
    and IoT concepts for designing the platform. The architecture named Global Edge
    Computing Architecture (GCEA) was tried and tested in real time in a dairy farm.
    Castellanos et al. [133], proposed a narrowband IoT (NB-IoT) system for collection
    of soil parameters to monitor the potato crop health and growth. A UAV aided network
    is used to support the purpose. The architecture proposed accessed the real filed
    scenario of a potato filed near Bogota, Columbia. The main achievement of this
    work was the energy harnessing due to optimal topology applied for the deployment
    of sensors across the field and thus making the battery last for 82 hours for
    above ground sensors and 77 months for the deep buried sensors. Shafi et al. [134],
    presented a multimodal for crop health monitoring based on the concepts remote
    sensing, IoT and ML. Authors conducted their research in Pakistan. Sensors were
    deployed in fields to collect the real time data. Multispectral data from drones
    presented a NDVI and was used to analyze the crop based on its chlorophyll content.
    Variable length time series data captured from IoT devices and sensors were used
    to generate crop health maps. Deep neural networks were implemented for classification
    and provided the optimal classification. Some studies of the articles incorporating
    IoT in fields related to crop monitoring are presented in TABLE 10. TABLE 10 Summary
    of Developed Methods Crop Monitoring D. IoT in Disease Detection Diseases play
    a vital role in the economic and food crisis of a country. So to avoid this, disease
    detection is employed. This involves the detection of various diseases whether
    fungal, viral, bacterial, etc. from the stages of early to the post-harvest. Incubation
    of IoT has revolutionized the disease detection area in plant phenotyping resulting
    in major control resources available to avoid disease occurrence. Wang et al.
    [146], focused on addressing the problem of pests and insects. Authors proposed
    an IoT based model that can detect the early occurrence of the pests and diseases
    from visual references. Rough set theory algorithm and NN were used to model design.
    The proposed model was compared with existing models for accuracy and efficiency.
    Pandiyan et al. [147], applied the concepts of image segmentation and IoT, to
    develop a system/platform that can detect the diseases in plants. Authors proposed
    a novel platform having an Advanced Segmented Dimension Extraction (ASDE) with
    Heterogeneous Internet of Things procedural (HIoT) aspects, to detect the apple
    leaf diseases. A sign based plant disease identification model for real-time resembling
    of leaf diseases namely bacteria, fungi, micro-organisms, and viruses is presented.
    Three levels i.e. connectivity level, platform level, and service level were employed
    for performing data aggregation, transmission, and automatic identity identification.
    Leaf gestures were studied to identify the diseases in leaves. Zhao et al. [148],
    developed an automatic crop disease detection system capable of identifying and
    recognizing the leaves from a cluttered background. Combining IoT concepts and
    CNN, authors designed a novel approach named “Multi-Context Fusion Network (MCFN)”
    along with IoT deployments for crop diseased detection in wild. Kale and Sonavane
    [149], developed a smart and optimized smart fertilizing decision support system
    for smart farming. The authors addressed the problem of disproportion due to lack
    of judgment. Concepts of IoT and GA were used to design the system. An improved
    GA based multilevel parameter optimized feature selection algorithm for ELM classifier
    along with IoT was proposed in the designed system. The proposed system focuses
    on plant disease detection in a real-time environment. Khattab et al. [150], developed
    an IoT based cognitive automatic monitoring system for detecting the epidemic
    diseases in plants. By combining the concepts of artificial intelligence and prediction
    algorithms to develop the expert system, capable of predicting, analyzing, and
    decision making. A layered approach was used to design the model. Soil, leaf wetness,
    wind speed, and wind direction sensors were employed to gather the data. The model
    was tested on detection of the diseases like Late Blight, Early Blight, and Powdery
    Mildew in tomato and potato crops. Chen et al. [151], based on AI technologies
    and IoT, developed a system named “RiceTalk” for the detection of Blight diseases
    in the rice plant. AgriTalk model was used as a base model in this work to develop
    this system. Compared to AgriTalk, the authors used non-image IoT devices to design
    this model for disease detection. Devi et al. [152], proposed a simple and efficient
    IoT enabled solution for developing a system for automatic disease detection.
    Bunchy top of banana and Sigatoka diseases in the wild banana plant were detected
    and classified. Environmental parameters like soil moisture, temperature were
    measured with sensors and the IoT model was framed using the Raspberry PI hardware
    model. Data were classified using GLCM and RFC for disease detection. Kitpo and
    Inoue [153], developed an early disease detection system for rice crops disease
    detection. The drones based IoT architecture with real-time data collection capabilities
    was designed. For the mapping of drones on the fields, GPS sensors were used.
    The designed system is capable of displaying the analytical results and the position
    of the plant where the disease is present. Pawara et al. [154], studied the pomegranate
    diseases such as Bacterial Blight, Fruit Spot, Fruit Rot, and Leaf Spot. Developed
    a HMM and senor based model to early detect the disease and provide the solutions.
    Parameters like air temperature, leaf wetness, air humidity, and soil wetness
    were considered and studied for model design. For digital communication between
    field and farm GSM module was used. Truong et al. [155], real-time data monitoring
    capable system was designed with IoT and cloud storage for disease detection and
    recognition. The fungal diseases of rural crop fields with detected. Environmental
    data conditions such as humidity, temperature, wind speed, and rainfall were employed
    for designing decision support. A Support Vector Machine Regression (SVMr) model
    was used to classify the data. Jumat et al. [156], developed a cost-efficient
    and affordable smart farming prototype capable of detecting plant disease and
    proving decisions. For study and experimentation, Septoria plant disease was taken
    and studied for different stages right from outbreak to spread maturity. The system
    also possesses the web-enabled facilities for farmer support. Some studies of
    the articles incorporating IoT in fields related to disease detection are presented
    in TABLE 11. TABLE 11 Summary of IoT Based Developed Methods for Disease Detection
    SECTION V. Findings Several research articles related to the role and responses
    of the Internet of Things in agriculture have been studied. From the literature
    and studies, it can be seen that immense contribution has made by IoT in the field
    of agriculture starting from micro areas and moving over to macro environments.
    Internet of Things along with the concepts of cloud computing, cluster computing,
    wireless sensor networks and computer vision has revolutionized the field of monitoring,
    crop production, disease detection, and supply chain management. Since the domain
    of agriculture itself is a wide domain so considering the impact IoT has or can
    make on this field, the search was not restricted or limited to any area. The
    data acquisition for agriculture systems is a multidimensional approach. There
    are several fields in agriculture where IoT is applied e.g., crop monitoring,
    diseased detection, precision irrigation, supply chain, cattle grazing, and raising,
    etc. To design a precision approach, the target plays a very important role in
    data collection. From the existing studies it is found that mostly overall 90%
    of the data is self-acquired by the authors with the use of wireless sensors.
    This data included soil data, pH values, light, water, humidity, and images. In
    the case of crop disease detection, leaves were taken as the primary subject of
    study due to their ease of availability and quantity. Nearly 80% of the leaf data
    was self-acquired using digital cameras and web-enabled devices. However in some
    studies to validate their models, authors also used the existing standard ground
    truth databases available. Satellite imaging and remote sensing images were also
    taken to understand the demography and vegetative indexes of a region. UAV drones
    were the most used devices along with web-enabled digital cameras and mobile devices
    to capture the data in the form of images and also acted for providing real-time
    monitoring of device location in the fields. Certain issues and challenges are
    faced by the authors while capturing real-time images due to environmental and
    lighting conditions. To avoid these issues, laboratory-based testbeds such as
    greenhouses were developed and their data was acquired in a closed environment.
    From the literature, it is seen that, to develop the prototypes certain common
    parameters were taken for conducting the study irrespective of the problem to
    be addressed. Theses parameters included soil data, pH value, humidity level,
    moisture content, water content. After the analysis of the studies it was found
    that for any agricultural system to flourish all these parameters play a combined
    role. These parameters were most common for the problems addressing farm management,
    crop monitoring, and irrigation. However in certain other parameters like leaf
    wetness, salinity, disease severity, fertilizer ratio, plant height, CO2 content,
    mineral content, and conductivity were considered while addressing the specific
    problems like plant disease detection, smart irrigation, seedling germination,
    etc. These were the devices employed to collect the data. Depending upon the problem
    the authors addressed, different type of sensors were employed. For soil data
    collection, the contact method sensors such as hygrometers, or electrodes which
    penetrate the soil were used to collect soil information. While as in the case
    of the collection of soil information via tractors or vehicles non-contact soil
    sensors were employed. But for the studies it can be seen that contact method
    sensors are the most common devices used for soil data collection. In case of
    soil pH value and salinity electrochemical sensors are employed. In the case of
    soil nitrates, CO2, and fertilizer content, topsoil depth, biomass content, organic
    matter are measured. For water data collection, parameters like relative humidity,
    leakage of pipes, dissolved oxygen, nitrates, and other oxides were measured by
    the authors. To accomplish this various water sensors like ultrasonic sensors
    were employed to measure the water levels in the tanks, ponds, and farms. Temperature
    and humidity sensors were used to measure the temperature of water and humidity
    of soil for water content. In the case of plant leaves, the leaf wetness sensors
    were employed to understand the moisture content of the plants. Other than these
    sensors, neutron sensors, time travels sensors, and capacitance sensors are also
    employed by some authors for measuring the water levels. In the case of supply
    chain and cattle grazing, tags and biosensors were employed to gather the data.
    To develop the prototypes, the authors used the devices based on functional capabilities.
    From all the devices, Arduino and Raspberry Pi were the most desirable hardware
    platforms for the authors. Arduino was employed to tackle simple or sequential
    issues that do not require complex solutions. In the case of scenarios with complex
    environments, Raspberry Pi boards were employed due to their capability of addressing
    multiple problems at the same time. For functionalities that faced time issues,
    Raspberry Pi boards were employed. In the case of communication technologies,
    LoRa and ZigBee are the most commonly used communication technologies by the authors
    in the platform designs due to their capabilities of handling a multitude of solutions.
    Lora and ZigBee use GPS to enable and detect geo-locations. They are low cost
    and secure for data transmission. Other than these technologies, authors also
    made use of cloud and cluster computing to handle a large mass of data and provide
    on-spot solutions to the consumers. The authors performed the processing of data
    in different stages. At first preprocessing on data was performed to remove any
    kind of outliers or anomalies in the data. To remove the imperfect data, algorithms
    such as noise removal with Gaussian noise, salt and pepper noise, histogram equalization
    were commonly used for the preprocessing of image data. However in the case of
    numerical data missing value imputation, the banana dataset for noise reduction
    was employed. To obtain the optimal data from a given set of data, data reduction
    was performed. The data reduction approaches e.g., dimensionality reduction, attribute
    subset selection, numerosity reduction, etc. were employed by various authors.
    To make systems capable of taking decisions, several learning algorithms like
    GA, CNN, NN, SVM, PNN, GANs were used to train and test the models. From the literature,
    it is seen that most studies and experiments were performed in countries that
    have agricultural economies like the USA, China, India, Brazil, Australia, etc.
    Most of these countries are economically stable and first world countries. They
    have better infrastructure and service availability. Also only 20% of the studies
    were focused on real-time implementation of their prototypes which indicates that
    most of the experimentation was conducted in a closed environment. This pattern
    raises concerns on how these studies can be employed in real-time environments
    with low infrastructure and maintenance costs. The problem of power consumption
    was also addressed by some studies. However there were no comparisons and reasons
    given on how the dream of IoT can be made real for poor and self-financing farmers.
    Along with this, a few studies provided the cost estimation for the deployment
    of the models. In the Fig. 7, the percentage distribution and contribution of
    IoT in different fields of agriculture are shown. From the figure it can be seen
    that more extensive studies are conducted in the field of crop monitoring. FIGURE
    7. Percentage contribution of IoT in different fields of agriculture. Show All
    These studies and analysis put forth by different articles show that current/existing
    solutions have incorporated IoT to solve several challenges in the agricultural
    domain. With the incorporation of these technologies, a large number of challenges/factors
    for improvement have emerged. Along with the study of factors for improvement,
    future research directions, applications are also highlighted. The sections below
    explain the factors for improvement and the futuristic research directions. A.
    Challenges Despite the growth achieved by IoT over the past few decades, there
    still exist some conceptual, fundamental, and developmental issues. 1) Cost Designing
    a cost-optimized model is still a difficulty faced by many authors. Scientists
    are focusing on developing cost-efficient systems by reducing the hardware and
    software requirements in IoT deployments. Economic differences of countries make
    it difficult for farmers to deploy devices and technology. So, it is important
    to develop some economic models. 2) Standardization To fully utilize the technology
    for large range of applications, standardization of devices is essential. The
    present or current mechanisms do not confirm any standardization formats either
    for the data and process representation. Deprived of the cordial use of the semantic
    ontologies, machine-readable codes result in output differences due to misinterpretation
    and alterations from time to time. With standardization the interoperability issues
    of the devices, applications, systems and products can be solved. 3) Heterogeneity
    While designing a system, heterogeneous devices are used. Every device differs
    in processes and services requirements. In the case of agriculture, most models
    perform with heterogeneous devices, so it is important to create interaction between
    heterogeneous modules and communication technologies. Because of heterogeneity,
    the complexity of the network increases, and sometimes falsified results may appear.
    4) Accessibility For developing any farming decision support system based on IoT
    technology and other devices, the demand for availability of existing software
    and hardware to be present anywhere any time is a must thing. These problems need
    to be addressed to ensure the availability of services anywhere and anytime. Lack
    of availability of the required equipment can result in chaos and delay in the
    services. 5) Adaptability While designing a model, especially for precision farming,
    it is pertinent for the devices to be adaptable with the other devices and the
    surroundings. Since the environmental conditions keep varying and also sometimes
    due to certain communication or hardware issues certain devices are not adaptable
    with each other. 6) Energy Optimization Energy is the most emerging issue in IoT
    systems, WSNs, and other devices for their communication. Till now conventional
    sources of energy have been supporting the designing and working models. But due
    to an increase in devices, the consumption of conventional energy is not a reliable
    solution. Non-conventional sources of energy like solar, wind, water energy harvesting
    schemes should also be tested, but they haven’t been of much success and new methodologies
    should be developed to employ them for model development. 7) Compatibility To
    achieve the standards of fragmentation and scalability, the developed models or
    software should be flexible and should run on any machine. 8) Reliability For
    successful and smooth working, reliability is a major concern for IoT devices
    in terms of data transmission. The devices need to gather and transfer reliable
    data as based on the data received and interpreted, the decisions are made. Reliability
    is still a challenge due to system failures, node failures, battery issues, or
    other interventions. 9) Mobility Generally the systems or models developed are
    static. For smooth implementation of the framework, there should be mobility as
    most of the devices and applications are mobile. In mobile models, the issue of
    maintaining connectivity is still a difficult task. 10) Environmental Conditions
    In agriculture there are different landforms. So it becomes difficult to adapt
    to those changes, and this also jeopardizes data and services. This alters the
    accuracy of a system. 11) Real-Time Deployment Most of the studies put forward
    are not employed or tested in a real-time testbed. So before deploying a system
    or model, real-time analysis is a must, to avoid post-deployment losses. B. Improvements
    Since the growth of IoT is remarkable in the field of agriculture, certain improvements
    can be included in the growth and developmental state to make the systems and
    models more efficient, reliable, and business-oriented. 1) Warding Off the Performance
    Degradation Generally while developing systems, customer interaction or input
    is not taken. As the models serve a variety of customers from dynamic backgrounds,
    therefore their input must be taken while developing the models. This way the
    performance hazards and chaos that occurs on the filed can be avoided. 2) Sharing
    Rich Data Globally In almost all, the IoT based models designed for precision
    farming, the data sharing while integrating and mapping the system design should
    be encouraged. This can lead to the development of an interactive model globally.
    This feature can also help in understanding the topographic and demographic challenges
    of various regions on a global level. Thus the suitable solutions can be designed
    with those working in resource-constrained environments. 3) Moving Towards High-Speed
    Communication The communication domain itself is witnessing a progressive and
    dynamic shift. Since the IoT models are remotely located, so better communication
    is a prerequisite. Therefore it is important to consider high-speed communication
    strategies like 5G, for making the devices more reachable with lesser delays.
    4) Cost Analytic Studies for Model Design With the incumbent of IoT in agriculture,
    a variety of models are designed for addressing different domains such as irrigation,
    farm management, disease detection, and crop monitoring, etc. While designing
    the models various case studies are performed. As the development cost of models
    for these cases varies from country to country i.e., in first world countries
    there will be the different cost of devices and in second and third world countries
    it will be different. Therefore a model cost analysis will provide an idea of
    the purchasing power and investment a farmer from these varied economic regions
    can invest to develop a model. Also this can result in seeking or considering
    other cheaper and efficient ways to develop models. C. Future Research Directions
    With the advancement in the development of precision agriculture platforms with
    IoT and other technologies, the development of new applications or research areas
    is envisioned. After the study of the literature, certain potential concepts and
    futuristic research directions are listed and discussed below: Design of platforms
    in a user-friendly manner (from farmers’ perspective and ease of using) using
    Artificial Intelligence and other learning tools. Farmer’s perspective here means
    that an audit should be done well before designing the prototype. From this study
    a clear insight and differences between the requirements of the farmers and farming
    systems across the globe can be understood. To develop concepts and methodologies
    based on multidimensional aspects like science, expertise, experience, industry,
    etc. Energy harvesting or power optimization methodologies should be developed
    to reduce the cost of production, maintenance, and fault tolerance. It is evident
    that mostly the farms be it small or large, require power and energy for the working
    of devices. In most of the cases, the power to the devices is supplied from the
    main line or the power grid. But this is not a sustainable and efficient method.
    Thus in order to make farms self-reliant, the energy harvesting or power optimization
    approaches should be developed or incorporated while designing of the models.
    Induction of cloud sources for data gathering and processing in a reliable, systematic,
    and scientific manner. Develop systems that can withstand variable soil and environmental
    conditions. Since the agricultural environments are harsh and keep on changing
    with change in climatic conditions or seasons. So it is essential to develop systems
    which can be robust and sustainable to the changes in the external as well as
    internal factors. Development of user or farmer friendly apps for monitoring crop
    and plant health. Mostly farmers come different ethnic and linguistic backgrounds.
    So due to this their level of understanding and ways to perform agricultural tasks
    is also different. It is important to develop frameworks considering the native
    language of a region into consideration so the farmer and machine interaction
    can be improved. This will enhance enable the acceptance of precision farming
    methods easy as it can be seen some areas are reluctant to adopt due to this linguistic
    and understanding problems. Development of efficient sensor-based systems for
    high elevation areas. High elevation areas mostly have undulating surfaces and
    also in most of the countries, supply of power to these areas is still a dream.
    Form the literature, it can be seen that these areas have not been targeted for
    precision farming instead of being resource deficient. Therefore deployment and
    design of sensor based systems in these areas opens a scope in future of precision
    farming. Usage of previous and existential scientific data for the development
    of decision support systems in farming. Generally for designing the precision
    farming models, the primary data is considered. However for designing cost efficient
    and reliable models, the previous case studies and deployment models should be
    considered for the study. This means a collaborative model development methodology
    should be developed for understanding the nature of the work. To recognize various
    plant species using mixed data sets or heterogeneous data. Design of a portable
    and sustainable farming equipment control systems for large as well as small farms.
    Mostly from the study it can be seen that first world countries are welcoming
    in PA approaches while as in most third world and other nations, this concept
    is still in avoidance due to cost and shelf life of products and equipment’s.
    Development of reliable supply chain management methods for precision farming.
    D. Applications of IoT in Agriculture IoT has revolutionized the world of agriculture,
    and a manifold of application can be derivative of implementation of the Internet
    of Things in agriculture. These applications are a resultant of the architectural
    design chosen. These applications have been categorized and differentiated based
    on the subject they focus on and also the service they provide. The major sectional
    areas where IoT is applicable in agriculture are- observation, data collection
    and corroboration, governing, and management. Most of these fields work collaboratively,
    and all the applications involve at least two of these sections. All these sections
    are described below and TABLE 12 presents various IoT applications in agriculture.
    TABLE 12 Applications of IoT in Agriculture 1) Observation It is also called monitoring
    as the main aim of this section is to discern the working of various models, devices,
    applications, etc. With the incubation of the concept of IoT, it is the first
    and foremost stage to be smeared. In this phase, all the devices and equipment
    that are placed strategically are monitored for their work. Sensors, are the major
    deployment and data collection tools engaged in this phase for data collection
    of various field and non-field parameters. Monitoring the certain parameters,
    like soil salinity, pH value, volumetric water content by using various soil sensors
    and other essential parameters such leaf wetness sensors, color, humidity, etc.
    helps in the development of systems capable of performing following operations
    e.g., calculation of leaf area index, leaf health, leaf color, plant growth and
    aid in the development of automatic plant recognition systems. Other devices like
    water sensors aid in the monitoring of irrigation levels and requirements of the
    fields. Thus with such devices, smart irrigation scheduling systems are developed.
    Also with the gas sensors, remote monitoring devices such as UAV devices or images
    with hyperspectral reflectance properties, help in the estimation of biomass,
    nitrogen, carbon, and other essential gases content. This data can also be used
    to find the vegetative indexes of the filed or large demography. Heavy-duty vehicles
    such as thrashers, tractors, trucks etc., also need supervision and can use data
    analytics for farm management. Robots, autonomous vehicles, agricultural drones
    other equipment also need to be monitored remotely for better farm supervision.
    Livestock monitoring with the aid of IoT is also an important subject for precision
    farming. It includes cattle monitoring remotely using tags. Labour is also a major
    area of concern for precision farming. Since human intervention is generally prone
    to errors due to differences in understanding, decision making, and methodologies
    applied to solve a particular problem. Also the induction of human labor is cost-intensive.
    Therefore, with the application of IoT, human interference can be minimized and
    a network can be set up for monitoring thus reducing the errors and cost. 2) Data
    Collection and Corroboration Data is the main constituent of precision farming.
    It acts as both base and catalyst in the whole process. With IoT, a large number
    of data is collected in varying forms and formats. Sensors, cameras, and various
    other nodes aid in the collection of data. In precision agriculture, based on
    the nature of the problem, the IoT network can be designed and formulated to collect
    different types of data. After the data is collected, the corroboration also called
    documentation of the data is very important for better understanding. Corroboration
    is a natural application of collected data, but certain additions of different
    samples such as manual or machine integration are also seen. Data once collected
    needs to be refined and understood, labeled, and thus documented in a certain
    format. Documentation or corroboration of data helps in formulating statistical
    analysis and developing the decision support systems. Remote sensing charts and
    other crop assessing tools can be employed to understand the total crop yield
    of a particular region. Crop management can also be optimized using corroborating
    data. A yearly or term analysis can be performed on this data to improve precision
    farming. Food chain supply management can use the predictive analysis of this
    data for optimizing and designing new efficient strategies. The major areas where
    its application is seen are yield mapping for fertilization planning, field planning,
    agro-food traceability, site-specific measurements based on soil and water analysis,
    and remote vehicle monitoring for supply chains, etc. 3) Foretelling Also called
    forecasting is one of the major attributes or applications for decision making
    that is brought in agriculture with the introduction of IoT. With the IoT devices
    and network, real-time data analysis along with the comparison to the previously
    available datasets helps in the forecasting of the upcoming events in much advance.
    With this foretelling, various decision support systems can be designed capable
    of taking optimal and real time-decisions. It can also act as a preventive measure
    mechanism for avoiding or dealing with various upcoming unprecedented situations.
    With monitoring, data collection, and corroboration, foretelling can help in early
    disease detection, pest growth, weeding, drought, smart irrigation, and harvesting.
    Artificial intelligence can be employed for designing these learning systems.
    With IoT, a predictive analysis could be made way earlier than the harvest period
    for assessing crop production and consumption. Pre and post-harvest crop monitoring
    along with behavioral sciences and market analysis can also be employed to help
    site-specific farming and production increase in precision agriculture in the
    context of IoT. 4) Governing and Management It is an outcome of the monitoring
    device. Governing helps in controlling the whole system. Foretelling also plays
    a major role in governing. With IoT, it is important to govern the farm. Thresholds
    play a major role in designing a controlling strategy. Controlling is a major
    addendum of IoT in agriculture. Applications of controlling can be easily seen
    in site-specific management, working of smart irrigation models, plant growth
    monitoring models, and early crop analysis models and also in supply chain and
    smart vehicular navigation, interaction, optimization, and logistics control of
    farms. With governing, all the new strategies, formulae, practices and methods
    employed to solve the problems occurring on daily basis in farms can be monitored.
    These strategies can then be compared and analysed with the previous existential
    strategies. Therefore a knowledge base can be maintained. From the data analysis
    of that knowledge base, the best or the optimal strategies that can be employed
    to design or mould the system can be fetched. Various case studies can be performed
    to gather and test such information. From this the redundant techniques can be
    withdrawn and robust ones can be prioritised. With these methodologies and experiments,
    the management can be made more flexible, scalable and reliable. Also governing
    and management can be employed to find the best suited solutions. Due to the growth
    in agriculture sector, various public and private sector projects and startups
    are being started in various countries across the world. All these projects use
    artificial intelligence and IoT concepts to provide support and solutions to the
    growing industry of agriculture. All these projects or startups are explained
    in the TABLE 13. TABLE 13 IoT Based Public and Private Sector Projects/Startups
    for Precision Agriculture E. Our Proposed Work Inspired by the contribution of
    IoT in the field of agriculture, we proposed an architecture for precision farming.
    The layout of the architecture to be designed is proposed and shown in Fig. 8.
    The structure proposed for precision farming in case of farm management will constitute
    of different layers. The first layer would be the sensing layer, in which different
    types of sensors like soil, humidity, water, light, proximity, and conductive
    sensors will be deployed in the region of experimentation. All data from the sensors
    will be sent to the base station. The second layer is the network layer, which
    consists of gateways, internet, and other devices. This layer manages the traffic
    of the whole architecture. This layer collects data from the sensing layer and
    transfers it to the decision layer and the application layer. The third layer
    is the decision layer, which processes the data, manipulates it, and generates
    alerts or actions. The next layer is the application layer, which constitutes
    the firmware and the users. It receives all the inputs from other layers and the
    outputs are made visible to users. It also manages how the whole architecture
    will work or look. FIGURE 8. Proposed layered architecture for Precision Agriculture.
    Show All Our proposed architecture aims to observe and monitor the farm in real-time.
    Optimize the resource utilization, early detection of the diseases, and identification
    of the plant species, optimize irrigation facilities, and make definite use of
    pesticides and other manures. Monitor the growth of plants in each stage and take
    the necessary actions for the betterment of plants. The model to be designed will
    take into consideration the earning and investment of the small scale farmer.
    A scalable and cost efficient model will be designed by considering the reusability
    and recycling of the materials used. From the literature, it is found that the
    issue of interoperability and robustness is still not achieved. So, while designing
    the model these issues will be prioritized. Also, power supply and power consumption
    is a bottleneck for each model. So, from the literature it is found that energy
    harnessing approaches can be used to address this issue. In the proposed model,
    main focus will be on incorporating the concepts of energy harnessing approaches
    like solar energy and wind flow energy for power optimization. Harnessing solar
    energy for regions which have different season’s e.g., Kashmir, which has four
    seasons like spring, summer, autumn and winter throughout the year. So for these
    regions depending only on solar energy will be a bottle neck. Therefore, in the
    proposed work, a hybrid approach based on consumption of both wind and solar energy
    for reducing power consumption will be proposed. Some of the major findings of
    the proposed work will be: A scalable and cost efficient model will be designed
    by considering the reusability and recycling of materials used. The issues of
    interoperability and robustness issues of heterogeneous devices will be targeted.
    Power supply and power consumption being the bottleneck of each model will be
    targeted. To tackle such issues, energy conservation and energy harnessing approaches
    like solar and wind energy will be used. Harnessing solar energy for regions which
    have different season’s e.g., Kashmir, which has four seasons like spring, summer,
    autumn and winter throughout the year. So for these regions depending only on
    solar energy will be a bottle neck. Therefore in the proposed work, a hybrid approach
    based on consumption of both wind and solar energy for reducing power consumption
    will be proposed. Small scale farmers will be targeted for the development of
    sustainable and robust model. SECTION VI. Conclusion The Internet is revolutionizing
    our world. Communication via connective devices has become the countenance of
    survival. Agriculture is growing from precision farming to micro-farming. IoT
    has added more potential to communication by enabling the communication between
    humans and objects along with the environmental aspects. Seeking the vision of
    omnipresence i.e., anytime, anything, anywhere, everywhere, IoT should be considered
    a core for the development of new architectural concepts. Resource scarcity is
    a must address issue in precision agriculture and models should be developed to
    optimize resource utilization. Inclusion of monitoring in food supply chains,
    farms, greenhouses equipped with tags, WSN, etc. at each stage in the growth of
    the product/plant, making automatic reasoning via intelligent analysis and responses
    is moving towards much safer, secure, and trustworthy systems. In the article,
    firstly the agriculture sector along with its challenges and economic importance
    is presented. The domain of IoT along with the communication technologies and
    goals, protocols, architectures are studied and put forward. The various IoT OS,
    their specifications and features with respect to agriculture are discussed. An
    analytic study of various articles in the field of agriculture is presented, highlighting
    their most focused sections and gaps or areas not addressed. The sensors based
    on their field of application are also discussed. A systematic review of different
    articles focusing especially on crop monitoring, irrigation, disease detection,
    and farm management is offered. The articles considered for study range from the
    time frame of the year 2015 to 2020. From the studies, certain issues are put
    forward that demand research and experimentation in the future. Various existing
    public and private sector platforms or start-ups which work for precision farming
    are also presented and discussed with their specifications and applications. Making
    precision farming a base, a layout of an IoT based architecture is proposed. The
    communication technologies and the hardware platforms of IoT are also discussed.
    The applications of IoT in agriculture are also discussed. The issues, challenges,
    and future research directions are also highlighted. As a whole, the in-depth
    description of various aspects of IoT for agriculture has been discussed and how
    these studies should be catered in a way to create efficient and smart agricultural
    scenarios. Authors Figures References Citations Keywords Metrics More Like This
    Internet of Things and Wireless Sensor Networks for Smart Agriculture Applications:
    A Survey IEEE Access Published: 2023 Weighted Connected Vertex Cover Based Energy-Efficient
    Link Monitoring for Wireless Sensor Networks Towards Secure Internet of Things
    IEEE Access Published: 2021 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/8948470/09139962.pdf
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 'Recent Developments of the Internet of Things in Agriculture: A Survey'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/app12031607
  analysis: '>'
  authors:
  - Pierfrancesco Bellini
  - Paolo Nesi
  - Gianni Pantaleo
  citation_count: 120
  full_citation: '>'
  full_text: ">\n\x01\x02\x03\x01\x04\x05\x06\a\b\x01\n\x01\x02\x03\x04\x05\x06\a\n\
    Citation: Bellini, P.; Nesi, P.; Pantaleo,\nG. IoT-Enabled Smart Cities: A\nReview\
    \ of Concepts, Frameworks\nand Key Technologies. Appl. Sci.\n2022, 12, 1607. https://doi.org/\n\
    10.3390/app12031607\nAcademic Editor: Luis Javier\nGarcía Villalba\nReceived:\
    \ 20 December 2021\nAccepted: 27 January 2022\nPublished: 3 February 2022\nPublisher’s\
    \ Note: MDPI stays neutral\nwith regard to jurisdictional claims in\npublished\
    \ maps and institutional afﬁl-\niations.\nCopyright:\n© 2022 by the authors.\n\
    Licensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed\n\
    under\nthe\nterms\nand\nconditions of the Creative Commons\nAttribution (CC BY)\
    \ license (https://\ncreativecommons.org/licenses/by/\n4.0/).\napplied  \nsciences\n\
    Review\nIoT-Enabled Smart Cities: A Review of Concepts, Frameworks\nand Key Technologies\n\
    Pierfrancesco Bellini\n, Paolo Nesi *\nand Gianni Pantaleo\nDistributed Systems\
    \ and Internet Technology Lab (DISIT), University of Florence, 50139 Florence,\
    \ Italy;\npierfrancesco.bellini@uniﬁ.it (P.B.); gianni.pantaleo@uniﬁ.it (G.P.)\n\
    * Correspondence: paolo.nesi@uniﬁ.it\nAbstract: In recent years, smart cities\
    \ have been signiﬁcantly developed and have greatly expanded\ntheir potential.\
    \ In fact, novel advancements to the Internet of things (IoT) have paved the way\
    \ for\nnew possibilities, representing a set of key enabling technologies for\
    \ smart cities and allowing the\nproduction and automation of innovative services\
    \ and advanced applications for the different city\nstakeholders. This paper presents\
    \ a review of the research literature on IoT-enabled smart cities, with\nthe aim\
    \ of highlighting the main trends and open challenges of adopting IoT technologies\
    \ for the\ndevelopment of sustainable and efﬁcient smart cities. This work ﬁrst\
    \ provides a survey on the key\ntechnologies proposed in the literature for the\
    \ implementation of IoT frameworks, and then a review\nof the main smart city\
    \ approaches and frameworks, based on classiﬁcation into eight domains, which\n\
    extends the traditional six domain classiﬁcation that is typically adopted in\
    \ most of the related works.\nKeywords: smart cities; internet of things; big\
    \ data\n1. Introduction\nThe increasing development and dissemination of Internet\
    \ of things (IoT) and Internet\nof everything (IoE) technologies represent an\
    \ important enabler in the current smart cities\nlandscape, leading the smart\
    \ city paradigm to the big data scale. In fact, as noted in [1], a\ntechnical\
    \ report by Ericson estimated that 29 billion devices would be connected by 2022.\n\
    According to the report presented by Statista Research in 2019, it has been estimated\
    \ that\nthe total number of connected IoT devices worldwide will increase to about\
    \ 75 billion by\n2025 [2], creating a potential IoT economic impact that could\
    \ reach USD 11 trillion per\nyear by 2025 [3]. These numbers are revealing that\
    \ IoT is going to be one of the highest\nvalue disruptive technologies, opening\
    \ new frontiers, possibilities and challenges in the\nproduction of smart services\
    \ and applications. The importance of IoT is more and more\nclosely connected\
    \ to the evolution of smart cities, for which IoT represents one of the key\n\
    drivers for smarter innovation and sustainable development. Smart cities are complex\
    \ socio-\ntechnical infrastructures, composed of human actors (different stakeholders\
    \ and users, such\nas citizens, city operators, administrative institutions, public\
    \ and private companies, etc.)\nand digital devices (e.g.: city sensors and actuators\
    \ exploited in many domains, such as\nmobility and transportation, environment,\
    \ energy, healthcare, governance, industry 4.0 etc.;\nsmart home and smart buildings\
    \ devices; and personal devices, such as smartphones).\nThis complexity is reﬂected\
    \ in the large variety of heterogeneous approaches, contexts,\napplication domains\
    \ and technological solutions that have been proposed in the literature\nfor the\
    \ realization and management of smart cities. The main goal of implementing and\n\
    integrating IoT solutions is to allow smart cities to advance further, providing\
    \ new capabili-\nties and features while signiﬁcantly reducing human intervention\
    \ [4]. In addition, it is also\nimportant to focus on the social challenges addressed\
    \ and the societal beneﬁts achieved by\nthe adoption of these technologies, for\
    \ instance assessing how they can contribute to the\nSustainable Development Goals\
    \ (SDGs) developed by United Nations within the context\nAppl. Sci. 2022, 12,\
    \ 1607. https://doi.org/10.3390/app12031607\nhttps://www.mdpi.com/journal/applsci\n\
    Appl. Sci. 2022, 12, 1607\n2 of 21\nof the 2030 Agenda [5]. Some of the main technical\
    \ challenges for modern IoT-enabled\nsmart cities are represented by the requirements\
    \ of supporting a multitude of different data\nproviders, dealing with many different\
    \ protocols and data formats, as well as ensuring\ninteroperability and scalability\
    \ and supporting the sharing of components. This is crucial\nin order to avoid\
    \ the implementation of redundant solutions for data ingestion, storage\nand analysis,\
    \ thus lowering operative costs and enhancing the city’s sustainability. The\n\
    motivation and contributions of the present paper are the following:\n1.\nProvide\
    \ an updated and comprehensive (although not exhaustive) overview of re-\nsearch\
    \ literature about smart city domains, solutions and frameworks, as well as about\n\
    key IoT technologies and applications integrated in smart city components.\n2.\n\
    Provide insights into recent trends, open technical and social challenges (also\
    \ assessing\nthe contribution of IoT–smart city technologies and domains toward\
    \ the SDGs) and\nfuture directions to be addressed in the implementation of IoT\
    \ in smart cities.\nIn this paper, an effort has been made to integrate IoT and\
    \ smart city solutions follow-\ning a classiﬁcation approach that focuses on the\
    \ identiﬁcation of eight applicable domains:\ngovernance; living and infrastructures;\
    \ mobility and transportation; economy; industry\nand production; energy; environment;\
    \ and healthcare. The rest of the paper is organized\nas follows. In Section 2,\
    \ a review of the main technologies employed in IoT frameworks\nis presented.\
    \ Section 3 provides a survey focused on IoT-enabled smart city domains\nand components.\
    \ Section 4 illustrates some recent trends and open challenges, and also\nassesses\
    \ the societal challenges involved and investigates potential future directions\
    \ for\nIoT-powered smart cities. Section 5 is left for the conclusions.\n2. IoT\
    \ Technologies and Architecture\nThe Internet of things has introduced an important\
    \ paradigm innovation in the com-\nmunication among digital devices, as well as\
    \ in the way that they connect with the physical\nenvironment [1] and interact\
    \ with human users. IoT architectures integrate and unify all\nsteps of data sensing/actuating\
    \ from/to devices, transmitting/receiving messages, data\nstorage, processing,\
    \ analysis and ﬁnal exploitation through the use of cloud, fog and edge\ncomputation,\
    \ services and applications. Many different technologies are involved in the\n\
    development of IoT frameworks. However, general functional architectures have\
    \ been\nproposed in the literature that are based on a simpliﬁed version of the\
    \ Open Systems\nInterconnection (OSI) model, but with different approaches. Some\
    \ works [1,6] deﬁne a\ntypical IoT framework composed of three layers (from the\
    \ lowest physical level to the\nhigher levels of abstraction): the perception/sensing\
    \ layer; the network layer; and the\napplication layer. In other works [7–12]\
    \ the former approach is expanded into ﬁve layers of\narchitecture, including:\
    \ the perception/sensing layer; the transportation/network layer;\nthe middleware/processing\
    \ layer; the application layer; and the business layer. In Figure 1,\nthe three-layer\
    \ and ﬁve-layer IoT architectures are depicted.\nAppl. Sci. 2022, 12, x FOR PEER\
    \ REVIEW \n3 of 22 \n \n \nFigure 1. The most common IoT architectures (three-layer\
    \ and five-layer) retrieved from the litera-\nture. \nDifferent computing paradigms\
    \ are defined depending on which level of the stack is \nbeing considered, from\
    \ bottom to top: edge computing; fog computing; and cloud com-\nputing [13]. In\
    \ the following, a description of the different layers is provided in terms of\
    \ \nthe functionalities and involved technologies. The five-layer architecture\
    \ was considered \nFigure 1. The most common IoT architectures (three-layer and\
    \ ﬁve-layer) retrieved from the literature.\nAppl. Sci. 2022, 12, 1607\n3 of 21\n\
    Different computing paradigms are deﬁned depending on which level of the stack\n\
    is being considered, from bottom to top: edge computing; fog computing; and cloud\n\
    computing [13]. In the following, a description of the different layers is provided\
    \ in terms\nof the functionalities and involved technologies. The ﬁve-layer architecture\
    \ was considered\nsince it can be viewed as a more detailed version of the three-layer\
    \ architecture.\n2.1. Perception/Sensing Layer\nThe perception or sensing layer\
    \ is related to the physical level that is made up of\ndevices, such as sensors\
    \ and actuators, which interact among themselves and with the\nphysical world\
    \ by sending and receiving data, exploiting wireless networks [8]. In this\ncontext,\
    \ sensors, actuators and mobile device technologies are involved. There is a wide\n\
    range of commercial devices that measure many kinds of physical quantities and\
    \ vari-\nables, i.e., sensors for measuring temperature, humidity, pressure, distance\
    \ and geospatial\ncoordinates, speed, acceleration, voltage, weight, pollutant\
    \ particles, luminance level, bio-\nmetrical signals, etc. Actuators are employed\
    \ to control/move other devices or systems\nphysically or virtually, and they\
    \ are typically classiﬁed into electrical, pneumatic and hy-\ndraulic categories\
    \ [14]. Several software tools and solutions are used to deploy low-level\nIoT\
    \ applications. Those described in the following are based on visual programming\
    \ lan-\nguages (VPLs): NetLab is an open source environment for developing embedded\
    \ systems;\nArdublock is an open source visual block programming tool for Arduino\
    \ systems; and\nScratch is a visual programming tool, developed at MIT, for IoT\
    \ code generation and\ncommunication with Arduino-based IoT products [15].\n2.2.\
    \ Transportation/Network Layer\nThe transportation or network layer provides the\
    \ function of data routing and trans-\nmission. Network gateways/brokers can be\
    \ used as mediators for integrating different\nIoT nodes, allowing them to transmit\
    \ and receive data to and from different sensors for\nM2M connectivity. Regarding\
    \ data transmission, different technologies and protocols\nare used. Proximity\
    \ communication protocols include Bluetooth, radio-frequency iden-\ntiﬁcation\
    \ (RFID) tag technology and near-ﬁeld communication (NFC). Larger coverage\nnetworks\
    \ exploit wireless technologies, such as Wi-Fi, Zigbee, long range wide-area net-\n\
    work (LoRaWAN), Sigfox and 5G.\nBluetooth and Bluetooth Low Energy [16] are low-power\
    \ wireless communication\ntechnologies designed for personal area networks (PANs),\
    \ which are suitable for low-\nbandwidth data transmission among mobile devices\
    \ over a short range of up to 10 m. They\nare usually employed in smart contexts\
    \ for connecting personal devices.\nRFID exploits radio frequencies for data communication\
    \ and is usually used to\nuniquely identify objects, people, vehicles, etc. Communication\
    \ is established between\na reader device and a tag device, which can be passive\
    \ or active. NFC [17] is similar to\nRFID, but it has an even shorter range for\
    \ communication (up to few centimeters). Unlike\nRFID, NFC does not implement\
    \ a reader/tag hierarchy and can be used for two-way\ncommunication. It is typically\
    \ used for mobile payments and access control operations.\nWi-Fi is based on the\
    \ IEEE 802.11 standard and uses wireless frequencies (operating\nat 2.4, 5 and\
    \ 60 GHz bands) to provide high-speed internet connectivity (from 1 Mb/s to\n\
    6.75 Gb/s) within a limited distance (up to 100 m) [18]. It is designed for wireless\
    \ local area\nnetworks (WLAN).\nWiMAX (Worldwide Interoperability for Microwave\
    \ Access) is based on the IEEE\n802.16 standard, operating at 2–66 GHz bands and\
    \ providing data rates from 1.5 Mb/s to\n1 Gb/s [18]. It can support broadband\
    \ wireless access for up to 50 km for ﬁxed stations and\nbetween 5–15 km for mobile\
    \ stations [19].\nZigbee is based on the IEEE 802.15.4 standard. It is a low-power\
    \ and low cost protocol\nfor wireless sensor networks (WSNs). It usually supports\
    \ star, tree and mesh network\ntopologies. The Zigbee protocol operates at 2.4\
    \ GHz and provides a data rate of about\n250 kbit/s [20]. The data transmission\
    \ range is similar to that of Wi-Fi (from 10 to 100 m).\nAppl. Sci. 2022, 12,\
    \ 1607\n4 of 21\nLoRaWAN is a low-power wide-area network (LPWAN) that is capable\
    \ of transmit-\nting over long ranges (about 10 km) and also supports multitenancy\
    \ and multi-domain\nnetworks [14]. It consists of several gateways that can be\
    \ added when the network size\nincreases and a higher capacity is required.\n\
    Narrowband IoT (NB-IoT) is an LPWAN protocol that operates on LTE licensed\nfrequency\
    \ bands, with a data rate of about 200 Kb/s [3]. The bandwidth of NB-IoT is about\n\
    180 KHz, and this protocol allows the connection of the order of hundreds of thousands\
    \ of\ndevices [21]. The NB-IoT technology also optimizes energy consumption, providing\
    \ power\ncontrol and power saving modalities [22].\nLTE-M is another LPWAN protocol,\
    \ operating at a 1.4 MHz bandwidth [23]. It was\nintroduced with the aim of supporting\
    \ a massive number of devices, providing 10 year bat-\ntery life support [24]\
    \ and supporting data rates of up to 1 Mbit/s, which is enough to satisfy\nthe\
    \ higher data rate requirements for devices such as video cameras and wearables\
    \ [25].\nThe features supported in LTE-M include handover management, extended\
    \ discontinuous\nreception and the suspension/resumption of radio resource control\
    \ connection.\nZ-Wave is a low-power protocol typically used in wireless home\
    \ area networks,\noperating at 868 MHz and 900 MHz frequencies [7]. Z-Wave devices\
    \ cannot directly\nconnect to the Internet or other mobile devices. Therefore,\
    \ the Z-Wave network is based on\nthe use of a controller, which acts as a gateway,\
    \ in order to manage all connected devices\nand allow them to interact with other\
    \ mobile devices via the Internet or local networks [26].\nSigfox is a narrowband\
    \ communication system for transmitting data over long ranges\n(up to 40 km [27]).\
    \ Although it employs narrowband signals, Sigfox can be suitable for\nmany kinds\
    \ of applications, such as geolocation services and control messages.\nFinally,\
    \ 5G is the ﬁfth generation of cellular networks. It is a very low-latency (less\n\
    than 1 ms) and high-bandwidth (10 Gb/s) protocol [28], making it a strong enabler\
    \ for\nsmart cities and allowing the interconnectivity of a large number of IoT\
    \ devices, as well as\nbeing suitable for real-time processing.\nThe last part\
    \ of the network layer stack is in charge of suitably formatting data for\ntheir\
    \ presentation. The client/server architecture, represented by the subscription\
    \ mecha-\nnism between IoT devices and brokers, presents different modalities\
    \ for sending/receiving\nmessages/data, i.e., push and pull. Typically, pull protocols\
    \ are REST call, web services,\nFTP and HTTP/HTTPS. On the other hand, the most\
    \ common push protocols to receive\ndata via data-driven subscriptions are: WebSocket\
    \ (WS), Constrained Application Proto-\ncol (CoAP), Message Queue Telemetry Transport\
    \ (MQTT), Advanced Message Queuing\nProtocol (AMQP) and FIWARE NGSI and NGSI-V2\
    \ [29]. Furthermore, in order to allow\ndata exchange among multiple devices and\
    \ applications, distributed publish–subscribe\nmessaging systems should be supported\
    \ (such as Apache Kafka, RabbitMQ, Orion Broker\nof FIWARE) for handling multiple\
    \ data streams in an efﬁcient and scalable way [13]. In this\ncontext, in order\
    \ to increase fault tolerance when handling data that should not be lost in\n\
    case of failure, the data persistence of queues is an important feature (e.g.,\
    \ Apache Kafka).\n2.3. Middleware/Processing Layer\nThe middleware or processing\
    \ layer can serve many different functionalities. For\ninstance, it can act as\
    \ a data aggregator module, since data may be collected from hetero-\ngeneous\
    \ devices with different protocols that may not have been originally designed\
    \ to\ncommunicate and interact with each other. Therefore, the middleware layer\
    \ has to enable\ninteroperability among connected devices, performing the necessary\
    \ programming and/or\nmodel abstractions. Interoperability should be ensured at\
    \ different levels:\n•\nTechnical level [30], in order to efﬁciently achieve and\
    \ ensure end-to-end connectivity\namong devices, gateways, brokers, servers, etc.;\n\
    •\nSyntactical level, for managing the variety of protocols and formats;\n•\n\
    Semantic level, for exploiting Semantic Web technologies, such as XML, RDF, OWL\n\
    Ontology and linked data (LD), to achieve unambiguous data representation and\
    \ data\nsemantic enrichment, thus improving the expressiveness level of the system\
    \ [31].\nAppl. Sci. 2022, 12, 1607\n5 of 21\nIoT middleware is also typically\
    \ devoted to providing scalability and reliability, allow-\ning the system to\
    \ handle a growing number of IoT connections and communication loads at\nthe big\
    \ data scale as well as supplying stable and fault-tolerant services. Moreover,\
    \ in order\nto enable data processing over IoT, database-level data persistence\
    \ is needed to integrate\nthe data coming with different protocols in a shared\
    \ model, and this is performed in the\nmiddleware layer. Therefore, middleware\
    \ includes the different data storage modalities\nand eventually covers other\
    \ functionalities, such as context identiﬁcation, information\nextraction and\
    \ the reconciliation of collected data. For example, FIWARE provides different\n\
    generic enablers (Cygnus, QuantumLeap, STH-Comet) to store data coming from the\
    \ Orion\nContext Broker.\n2.4. Application Layer\nThe application layer provides\
    \ the output formats, applications and services requested\nby the ﬁnal users.\
    \ Usually, works in the literature that are based on the three-layer IoT\narchitecture\
    \ include the messaging protocols management in this layer, as described in the\n\
    network layer at the end of Section 2.2.\nThe growing dissemination of IoT devices\
    \ and systems has led to the increasing\nadoption of event-driven applications\
    \ (exploiting push protocols). This is a signiﬁcant\nparadigm shift from the older\
    \ generation of smart city applications that relied on vertical\napplications\
    \ and were often based on extract, transform, load/extract, load, transform\n\
    (ETL/ELT) processes and languages, which usually only support pull protocols.\
    \ On the\nother hand, different frameworks and ecosystems are used to design and\
    \ implement event-\ndriven IoT application, for example VPL tools [32]. One of\
    \ the most used is Node-RED,\nwhich is based on the Node.js engine and allows\
    \ the creation of application ﬂows in a\ngraphic environment through the composition\
    \ of visual nodes or blocks [33].\n2.5. Business Layer\nThe business layer was\
    \ introduced to classify all operations and front-end tools that\nconsume data\
    \ from the application layer for producing advanced big data analytics and\nvisualization\
    \ services, with the goal of building business models, supporting decision-\n\
    making processes and performing simulations and what-if analysis. This can be\
    \ achieved\nby implementing, for instance, predictive models based on machine\
    \ learning, deep learn-\ning and artiﬁcial intelligence (AI) techniques [34],\
    \ as well as advanced and interactive\nvisual analysis tools [35]. Moreover, the\
    \ business layer includes all operations performed\nby system administrators,\
    \ which are needed to assess, control and maintain the overall\nfunctionality\
    \ of the platform/framework.\nIoT security aspects deserve a separate and speciﬁc\
    \ discussion. In fact, security\nrequirements and related issues have to be addressed\
    \ along the full IoT stack, including\nall functional architecture layers, from\
    \ the authentication of personal devices with IoT\nbrokers and ensuring secure\
    \ communication and secure encrypted storage for private data\nto the authentication\
    \ mechanisms for accessing and using IoT applications, data analytics\nand data\
    \ visualization tools. All of these requirements have to follow and cope with\
    \ strict\nregulations, such as the General Data Protection Regulation (GDPR) standard\
    \ [36].\n3. Review of IoT-Enabled Smart City Components and Solutions\nThere is\
    \ a wide range of research literature regarding IoT application in smart city\n\
    contexts. A search of the Web of Science (WoS) database for papers containing\
    \ the key-\nwords “smart city” OR “smart cities” AND “IoT” OR “Internet of things”\
    \ in their topic\n(i.e., the union of the “title”, “abstract” and “keywords” search\
    \ ﬁelds) resulted in a total\nof 5285 articles, published from 2010 to 2021, which\
    \ is a very large number of resources to\nbe extensively and systematically reviewed,\
    \ or even to be ﬁltered in a supervised way to\nselect and consider the most relevant\
    \ papers. In order to provide an overview of the grow-\ning interest around these\
    \ topics, the temporal evolution of the above-mentioned papers\n(grouped by year\
    \ of publication) is reported in Figure 2. It is to be noted that the apparent\n\
    Appl. Sci. 2022, 12, 1607\n6 of 21\ndecrease in the number of published papers\
    \ over the last year (depicted with a dotted line\nin Figure 2) may be due to\
    \ the fact that the count for 2021 was incomplete (since the search\nwas performed\
    \ in October 2021).\ncontexts. A search of the Web of Science (WoS) database for\
    \ papers containing the key\nwords “smart city” OR “smart cities” AND “IoT” OR\
    \ “Internet of things” in their topic \n(i.e., the union of the “title”, “abstract”\
    \ and “keywords” search fields) resulted in a total \nof 5285 articles, published\
    \ from 2010 to 2021, which is a very large number of resources to \nbe extensively\
    \ and systematically reviewed, or even to be filtered in a supervised way to \n\
    select and consider the most relevant papers. In order to provide an overview\
    \ of the grow-\ning interest around these topics, the temporal evolution of the\
    \ above-mentioned papers \n(grouped by year of publication) is reported in Figure\
    \ 2. It is to be noted that the apparent \ndecrease in the number of published\
    \ papers over the last year (depicted with a dotted line \nin Figure 2) may be\
    \ due to the fact that the count for 2021 was incomplete (since the search \n\
    was performed in October 2021). \n \nFigure 2. The temporal evolution of research\
    \ papers related to IoT-enabled smart cities, as retrieved \nfrom the WoS database\
    \ (collected in October 2021). \n \nOn the other hand, many different approaches\
    \ have been proposed in the literature \nfor classifying smart city frameworks\
    \ and solutions in a variety of application domains. \nFor this reason, we focused\
    \ on reviews and surveys as a starting point for our study. \nTherefore, the literature\
    \ research was conducted adopting the following criteria: \n1. \nThe WoS database\
    \ was used for searching for reviews and survey articles containing \nthe keywords\
    \ “smart city” OR “smart cities” AND “IoT” OR “Internet of things” in \nat least\
    \ one of the following fields: title; abstract; and paper keywords. Subsequently,\
    \ \na supervised overview and filter was performed in order to assure that each\
    \ paper \ntopic actually fit the subject of this review; \nFigure 2. The temporal\
    \ evolution of research papers related to IoT-enabled smart cities, as retrieved\n\
    from the WoS database (collected in October 2021).\nOn the other hand, many different\
    \ approaches have been proposed in the literature for\nclassifying smart city\
    \ frameworks and solutions in a variety of application domains. For\nthis reason,\
    \ we focused on reviews and surveys as a starting point for our study. Therefore,\n\
    the literature research was conducted adopting the following criteria:\n1.\nThe\
    \ WoS database was used for searching for reviews and survey articles containing\n\
    the keywords “smart city” OR “smart cities” AND “IoT” OR “Internet of things”\
    \ in at\nleast one of the following ﬁelds: title; abstract; and paper keywords.\
    \ Subsequently,\na supervised overview and ﬁlter was performed in order to assure\
    \ that each paper\ntopic actually ﬁt the subject of this review;\n2.\nRecent literature\
    \ was the main object of the present review, i.e., papers published from\n2018\
    \ to the present (2021) were selected from the initial search;\n3.\nPapers from\
    \ Q1 and Q2 journals (as ranked in the SCImago index) were given priority\nover\
    \ those from Q3 and Q4.\nFollowing these criteria, a total of 52 surveys and reviews\
    \ on IoT-enabled smart cities\nwere considered as the baseline for the survey\
    \ presented in this paper. It is to be noted\nthat most of the 52 surveys reviewed\
    \ often aimed to review one or some speciﬁc IoT–smart\ncity domains and use cases\
    \ without providing a more general or comprehensive overview,\nwhich is one of\
    \ the aims of this paper. In addition, in our opinion, the few general surveys\n\
    that were retrieved lacked in addressing the relationships between each smart\
    \ city domain\n(with related sub-domains and scenarios) with the related IoT technologies\
    \ that have been\nemployed in each speciﬁc context.\nIn order to describe the\
    \ wide landscape that we found by reviewing the selected\nliterature in the most\
    \ comprehensive way, the following eight domains were identiﬁed\n(as depicted\
    \ in Figure 3), which are typically used to classify smart city components and\n\
    application areas: governance; living and infrastructures; mobility and transportation;\n\
    economy; industry and production; energy; environment; and healthcare. This approach\n\
    extends the six-domain classiﬁcation presented in [1,37]. The classiﬁcation proposed\
    \ in this\npaper is not meant to be exhaustive and, in some cases, these domains\
    \ may not necessarily\nbe orthogonal as they may overlap in several contexts and\
    \ applications.\nAppl. Sci. 2022, 12, 1607\n7 of 21\nerature in the most comprehensive\
    \ way, the following eight domains were identified (as \ndepicted in Figure 3),\
    \ which are typically used to classify smart city components and ap-\nplication\
    \ areas: governance; living and infrastructures; mobility and transportation;\
    \ econ-\nomy; industry and production; energy; environment; and healthcare. This\
    \ approach ex-\ntends the six-domain classification presented in [1,37]. The classification\
    \ proposed in this \npaper is not meant to be exhaustive and, in some cases, these\
    \ domains may not necessarily \nbe orthogonal as they may overlap in several contexts\
    \ and applications. \n \nFigure 3. The classification of smart city domains with\
    \ related components and application areas. \nIn the next subsections, each of\
    \ the above identified smart city domains is discussed \nin terms of general scenarios,\
    \ features and services provided, the IoT technologies em-\nployed, the frameworks\
    \ or solutions adopted and real-world case studies of smart cities \nimplementing\
    \ solutions for that specific domain. \n3.1. Smart Governance \nSmart governance\
    \ deals with the adoption of ICT into city governance practices in \norder to\
    \ improve the decision-making process and speed up bureaucratic and adminis-\n\
    trative procedures through a smarter collaboration among different stakeholders\
    \ and so-\ncial actors [38], including public administrations, city officers,\
    \ private companies and cit-\nizens. This can be successfully accomplished by\
    \ providing innovative city services, dedi-\ncated channels and network integration\
    \ for citizens. For instance, citizens can be engaged \nin participating with\
    \ city governance activities and decisional processes through ICT-\nbased tools\
    \ and social media [39] as evidence of the mobile crowdsourcing paradigm [40],\
    \ \nFigure 3. The classiﬁcation of smart city domains with related components\
    \ and application areas.\nIn the next subsections, each of the above identiﬁed\
    \ smart city domains is discussed\nin terms of general scenarios, features and\
    \ services provided, the IoT technologies em-\nployed, the frameworks or solutions\
    \ adopted and real-world case studies of smart cities\nimplementing solutions\
    \ for that speciﬁc domain.\n3.1. Smart Governance\nSmart governance deals with\
    \ the adoption of ICT into city governance practices in\norder to improve the\
    \ decision-making process and speed up bureaucratic and administra-\ntive procedures\
    \ through a smarter collaboration among different stakeholders and social\nactors\
    \ [38], including public administrations, city ofﬁcers, private companies and\
    \ citizens.\nThis can be successfully accomplished by providing innovative city\
    \ services, dedicated\nchannels and network integration for citizens. For instance,\
    \ citizens can be engaged in par-\nticipating with city governance activities\
    \ and decisional processes through ICT-based tools\nand social media [39] as evidence\
    \ of the mobile crowdsourcing paradigm [40], according to\nwhich citizens can\
    \ act as “users as sensors” with their smartphones and mobile devices,\nparticipating\
    \ as individuals and in groups in the acquisition process of data of interest\
    \ for\nsmart communities.\nIoT technologies are transforming traditional city\
    \ governance transactions and pro-\ncesses into smart government resources on\
    \ the basis of the different participating ac-\ntors, i.e., government-to-citizen\
    \ (G2C), government-to-business (G2B) and government-to-\ngovernment (G2G) [41,42]:\n\
    •\nGovernment-to-citizen (G2C) refers to the set of software solutions (typically\
    \ web\nand mobile based) that support the relationships between public administrations\
    \ and\ncitizens, such as public administration web portals and/or mobile applications\
    \ and\nsocial media channels employed for communication and interaction between\
    \ local\ngovernments and citizens. In addition, IoT technologies, such as RFID\
    \ and biometric\nsensors, are widely and increasingly adopted in electronic ID\
    \ cards and mobile devices\nfor identity recognition, electronic authentication\
    \ and signature, according to different\ngovernmental standards, such as the European\
    \ Community’s electronic IDentiﬁcation,\nAuthentication and trust Services (eIDAS)\
    \ [43]. These features are typically required\nto access services that are provided\
    \ by public administrations and consult citizens’ per-\nsonal data related to\
    \ public services, etc., thus simplifying a lot of the communication\nand interaction\
    \ between governmental authorities and citizens;\n•\nGovernment-to-business (G2B)\
    \ regards the interactions between public administra-\ntions and businesses companies.\
    \ In this model, e-procurement solutions are adopted,\ni.e., digital tools (mainly\
    \ via the web), through which local governments publish ten-\nAppl. Sci. 2022,\
    \ 12, 1607\n8 of 21\nders, projects, competitions, facilities for the purchase/sale\
    \ of goods and other general\nservices for and from private companies. IoT technologies\
    \ are widely adopted in G2B\nactivities, facilitating and enhancing the relationship\
    \ between local governments and\ncompanies that provide public and private services\
    \ to citizens. For instance, trans-\nportation companies use location-based sensors\
    \ (usually exploiting GPS technology)\nand services, sharing them with local administrations\
    \ and allowing the easier and\nmore efﬁcient urban planning for mobility and transportation\
    \ [44]. In addition, it\nincludes similar aspects involved in many other domains\
    \ that provide public and\nfundamental services, such as waste management, water,\
    \ energy, etc. To this end,\nthe use of cloud computing is generally adopted to\
    \ store and share data and results\namong the different stakeholders (city operators,\
    \ companies and citizens);\n•\nGovernment-to-government (G2G) is related to the\
    \ software solutions that aim to\nimprove communications between the different\
    \ public administration entities and\ngroups, thereby speeding up all processes\
    \ that require the interaction of these actors.\nThis implies the use of IoT technologies\
    \ for data collection, storage and sharing, which\nexploits, for instance, cloud\
    \ computing and web/mobile-based services. A report of\nthe European JRC also\
    \ observed that governments may beneﬁt from the combination\nof various data sources\
    \ (e.g., from IoT and the web) with suitable analytical techniques\n(including\
    \ AI-based techniques) to better identify and design speciﬁc administrative\n\
    policies [45].\nIn Barcelona, ICT has represented a key driver for the evolution\
    \ of the city model,\nbased on ﬂexible and efﬁcient e-government initiatives and\
    \ services that aim to make\nthe city more innovative, inclusive and self-sufﬁcient\
    \ [46]. In the early 2000s, the city of\nBarcelona started implementing the 22@Barcelona\
    \ Project to enhance the technological,\nsocio-economical and sustainable impact\
    \ of the region in order to improve citizens’ quality\nof life (QoL) [47]. In\
    \ Amsterdam, a consortium consisting of the municipalities, research\ncenters\
    \ and private companies of the metropolitan area developed and launched the\n\
    Amsterdam Smart City Platform (ASCP) in 2014: an online board where the aforementioned\n\
    stakeholders can discuss urban issues, propose solutions and foster city innovation\
    \ [48]. The\nlocal government in Rio de Janeiro has promoted city data sharing\
    \ initiatives, hosting them\nin the so-called Intelligent Operations Centre (IOC)\
    \ premises with the aim of increasing\nthe efﬁciency of city services [49]. Moreover,\
    \ the Rio Agora social platform has been\nimplemented to allow citizens to propose\
    \ and discuss public policies with municipal\nauthorities [3]. Singapore has adopted\
    \ several smart governance projects through the\nSmart Nation and Digital Governance\
    \ Group (SNDGG) [50], including a digital identity\nsystem for Singapore residents\
    \ that allows them to perform easier transactions with public\nadministration\
    \ and the Core Operations Development and eXchange (CODEX), which\nis a digital\
    \ platform delivering smart services to citizens. In Toronto, the Sidewalk Labs\n\
    smart city project was proposed. The project promotes data sharing standards and\
    \ data\ngovernance models to proﬁtably exploit the data gathered from citizens\
    \ [51] through the\nurban data trust model. This allows for the collection, management\
    \ and aggregation of\nurban non-personal data, de-identiﬁed data and personal\
    \ information (according to data\nprivacy regulations and laws) and then extracts\
    \ value from them [52]. Songdo in South\nKorea is considered one of most advanced\
    \ large-scale greenﬁeld-based smart city projects\nin the world [53]. In fact,\
    \ Songdo is deﬁned as a ubiquitous U-city, in which data are\ncontinuously collected\
    \ through a capillary network of sensors and equipment. Data are\nshared and interconnected\
    \ with information from public institutions, such as the Incheon\nCity Trafﬁc\
    \ Information Center, the Korean Meteorological Administration, the Institute\n\
    of Health and Environment, Police Agency, etc. Data are analyzed by the U-Integrated\n\
    Operation Center and provided to citizens through media broadcasts and control\
    \ servers\nin order to help them to ﬁnd the necessary information [54].\nAppl.\
    \ Sci. 2022, 12, 1607\n9 of 21\n3.2. Smart Living and Infrastructures\nThe smart\
    \ living domain includes all components related to developing smarter city\ninfrastructures\
    \ (e.g., smart homes, smart buildings, etc.) as well the management and\nimprovement\
    \ of public services, such as cultural activities, tourism and education, which\n\
    are involved in enhancing the general quality of life of citizens:\n•\nSmart Buildings:\
    \ IoT allows the rapidly growing implementation of many kinds of\nfacilities for\
    \ smart buildings, for instance, air conditioning management, rainwater\ndrainage,\
    \ security systems for managing authenticated access to buildings, video\nsurveillance\
    \ and human activity monitoring [55], alerts for events such as ﬁres and gas\n\
    leaks, tools for monitoring the structural integrity of buildings [56], etc. Many\
    \ different\nIoT technologies are involved in the living and infrastructures domain,\
    \ depending on\nthe speciﬁc use case or scenario. As for smart buildings, IoT\
    \ integration with Building\nInformation Modeling (BIM) tools provides a high-ﬁdelity\
    \ representation of buildings\nand spatial properties as a set of virtual assets\
    \ [57], i.e., a digital twin of the building;\n•\nSmart Homes: In these environments,\
    \ different kinds of sensors, actuators and per-\nsonal devices are connected\
    \ through wireless networks and are often powered by\nhuman–machine interfaces\
    \ that are based on artiﬁcial intelligence to provide smart\nand automated services\
    \ for the users, with the goal of assisting them in daily tasks,\nsuch as lighting\
    \ control, surveillance, managing home appliances and home resources,\nenergy\
    \ consumption, etc. [58]. In addition, smart home applications can be useful to\n\
    detect and track the actions of the house’s residents in order to monitor their\
    \ health\nconditions [12], thereby especially helping the elderly and disabled\
    \ people. Several\nkinds of sensors are applied to smart home and indoor sensing\
    \ contexts. For in-\nstance, microelectromechanical systems (MEMS) are employed\
    \ for the detection of gas\nleaks [59]. Devices based on triboelectric nanogenerators\
    \ (TENG) are used for smart\nwindows [60] and smart indoor lighting systems [61].\
    \ Video cameras and Closed-\ncircuit television (CCTV) systems are used for smart\
    \ surveillance. Digital humidity\nand temperature (DHT) sensors are largely adopted\
    \ in ﬁre alerting systems [62]. The\nmost recent generation of domestic appliances\
    \ and entertainment devices is often\npowered by AI and assistive services, so\
    \ that they can interact while interconnected\nthrough wireless networks (the\
    \ most used network communication protocols are\nBluetooth, Zigbee, infrared and\
    \ Wi-Fi [63]), thus providing users with a better, more\nefﬁcient and enjoyable\
    \ home life and experience;\n•\nSmart Living Services: IoT devices have a large\
    \ application in a variety of areas and\nactivities that contribute toward improving\
    \ the general quality of life for smart citizens.\nCultural activities, for instance,\
    \ smart tourism management, are taking advantage of\nexploiting mobile applications,\
    \ GIS-aware and location-based services, multimedia\nstreams, virtual and augmented\
    \ reality and social media to manage and offer a better\nexperience for tourism\
    \ stakeholders [64]. Examples of these applications include\ntourist experience\
    \ enhancement, destination competitiveness and sustainability im-\nprovement by\
    \ tracking users’ ﬂows and behaviors [65]. Education is experiencing an\nincreasing\
    \ decentralization process with the inclusion of ICT and IoT elements, and\nthis\
    \ allows the production of new education services that can enhance interaction\
    \ in\nremote and real-world learning activities [66].\nNumerous smart living and\
    \ infrastructures applications can be found in real-world\ncases. In [67], it\
    \ is reported that 840 million units of smart home products were supplied in\n\
    China in 2019. Los Angeles has implemented smart strategies for tourism management.\n\
    Tourist trafﬁc is measured through sensors embedded in the pavements and this\
    \ informa-\ntion is used to adjust site visitor lights [68]. In Dubai, tourists\
    \ can discover places of interest\nand events by exploiting NFC tags from their\
    \ personal devices. There are many dedi-\ncated mobile apps that take advantage\
    \ of cloud computing and allow visitors to connect\nseamlessly, without the need\
    \ to download the app [69].\nAppl. Sci. 2022, 12, 1607\n10 of 21\n3.3. Smart Mobility\
    \ and Transportation\nThe smart mobility and transportation concept implies the\
    \ shift from traditional\ntransportation systems to Mobility-as-a-Service (MaaS),\
    \ where a smart IoT infrastructure\nconnects different actors (citizens, public\
    \ administrations, private companies) and entities\n(vehicles, personal devices,\
    \ city sensors, actuators, etc.) [70]. IoT and intelligent transporta-\ntion systems\
    \ (ITSs) [71] allow the provision of smart applications and services to manage,\n\
    for instance, private and public trafﬁc ﬂows, dynamic trafﬁc routing, smart parking,\
    \ vehicle\nsharing and sustainable mobility, connected driving, etc. Intelligent\
    \ trafﬁc solutions often\nrely on the application of predictive models for early\
    \ warnings, accident prevention and\nreal-time trafﬁc congestion management.\n\
    In this context, many IoT network technologies have been proposed and used. City\n\
    sensors and actuators (e.g., for the management of trafﬁc lights, digital signage,\
    \ road\nbarriers, etc.), location-based GPS services and mobile-to-mobile communication\
    \ are the\nbasis for the implementation of vehicle-to-vehicle communication (V2V)\
    \ and vehicle-to-\ninfrastructure communication (V2I). Additionally, 5G networks\
    \ and LTE-based systems\nhave been employed for vehicle-to-everything (V2X) services\
    \ [72]. Vehicular ad hoc net-\nworks (VANETs) [73] have been designed to handle\
    \ a large number of nodes (including\nvehicles, roadside units (RSU) and on-board\
    \ units (OBU) [74]) and present a good adapt-\nability to the frequent topology\
    \ changes and the data exchange rate [75]. The adoption of\nITSs is at the basis\
    \ of smart parking and car sharing [76] services. The most disseminated\ndevices\
    \ are RFID tags, infrared and ultrasonic sensors, smartphone-based sensors, video\n\
    cameras for smart parking [77] and on-board diagnostic systems (OBD tools) [78].\n\
    In Berlin, the smart mobility service Jelbi was introduced in 2019, based on a\
    \ mobile\napplication that is connected to all services provided locally (e.g.,\
    \ car-sharing companies\nsuch as MILES and DB Flinkster and e-vehicle hire companies\
    \ such as TIER), to foster the\npassage toward a more sustainable mobility [79].\
    \ In Florence, the Snap4City platform has\nbeen developed in the context of the\
    \ Sii-Mobility project for sustainable mobility, providing\na ﬂexible IoT smart\
    \ city platform and several applications to manage heterogeneous and\ncomplex\
    \ urban mobility scenarios by integrating city sensors/actuators and IoT/IoE [34].\n\
    Atlanta has powered its transportation infrastructure with many smart technologies.\
    \ For\ninstance, a system of adaptive trafﬁc signals that adjust to trafﬁc conditions\
    \ in real time\nare installed on the North Avenue Smart Corridor (a critical longitudinal\
    \ communication\nroadway) [3]. London has a cycle rental system, currently offering\
    \ more than 11,500 bikes\nand over 750 docking stations. As for car-sharing solutions,\
    \ London has six active operators\nin the city, covering the whole Greater London\
    \ area [80]. In addition, London’s public\ntransportation system provides the\
    \ use of Oyster cards, which are smart electronic cards\nthat exploit RFID technology\
    \ and can be used for paying and buying electronic tickets for\npublic transportation,\
    \ thereby reducing queues and eventually tracking users’ ﬂows. In\nSantander,\
    \ smart mobility services are applied to the management of public transportation,\n\
    outdoor parking management and trafﬁc routing [81]. The city of Bilbao has enhanced\
    \ the\nsustainability of local mobility by deploying a network of e-bikes with\
    \ 40 pick-up points\nand e-buses that are supported by mobile applications: GeoBilbao\
    \ (reporting real-time\ninformation about parking and trafﬁc status) and iBilbobus\
    \ (information about bus stops\nand schedules) [66]. In Seoul, the Gangnam ubiquitous\
    \ district has a centralized control\nframework, including the Transport Operation\
    \ and Information Service (TOPIS) app and\nthe “Owl Bus”, which is an innovative\
    \ bus service performing analytics on the big data\nthat is collected on-board\
    \ [82].\n3.4. Smart Economy\nA smart economy is based on the innovative interconnection\
    \ of local and global mar-\nkets through ICT, providing e-business and e-commerce\
    \ services to increase productivity\nand delivery [83]. In addition, the concept\
    \ of a sharing economy is also included in this\ndomain, where individuals or\
    \ private companies offer services exploiting their own assets\nas well as through\
    \ peer-to-peer marketplaces. There are also peer-to-peer labor services,\nAppl.\
    \ Sci. 2022, 12, 1607\n11 of 21\nin which citizens and stakeholders offer their\
    \ work and experience for speciﬁc tasks [84].\nArtiﬁcial intelligence and machine\
    \ learning techniques have been implemented for building\npredictive models and\
    \ improving recommendation systems for e-commerce and retail shop-\nping [85].\
    \ The use of NFC and wireless sensor technologies has facilitated payment and\n\
    transaction processes. In Shenzen, the use of mobiles and smartphones in daily\
    \ transactions\nand information access is making cash and bankcards obsolete [86].\n\
    3.5. Smart Industry and Production\nSmart industry and industry 4.0 deﬁne a transformation\
    \ process in which IoT tech-\nnologies, cyber-physical systems (CPS), M2M communication\
    \ systems and cloud-based\nmanufacturing [87] allow an innovative and less human-dependent\
    \ productive environ-\nment [88]. Regarding the automation of goods supply chains,\
    \ they can be easily tracked\nfrom the manufacturing process to ﬁnal distribution\
    \ using sensor technologies, such as\nRFID and NFC. Real-time information can\
    \ be collected and analyzed for shipment tracking,\nas well as for the assessment\
    \ of the quality and usability of products [14]. The smart indus-\ntry and production\
    \ domain includes all ﬁelds in which ICT leads to the automatization\nof the productive\
    \ workﬂow, therefore also includes smart agriculture and farming, which\naddresses\
    \ the challenge of sustainable food production. Smart agriculture systems often\n\
    employ IoT devices to improve irrigation efﬁciency [89] and AI solutions are often\
    \ deployed\nin IoT for agriculture, e.g., for crop monitoring, disease detection\
    \ and data-driven crop\nsupply management [7].\nDublin Airport has employed smart\
    \ industry 4.0 solutions to replace its baggage-\nhandling systems in Terminal\
    \ 2 [90]. In Shenzen, a smart industrial complex includes a\nseries of smart factories\
    \ that share technologies and provide efﬁcient services (exploiting\nan ultra-high-speed\
    \ Internet connection, next-generation wireless network, free Wi-Fi\ninfrastructures\
    \ and IoT devices connected via a common cloud platform) [3].\n3.6. Smart Energy\n\
    Smart energy systems involve the intelligent integration of decentralized renewable\n\
    and sustainable energy sources and their efﬁcient distribution [91] and aim to\
    \ optimize\npower consumption [92]. Smart grids take advantage of ICT and IoT\
    \ technologies for\nthe better management of power generation and distribution,\
    \ exploiting, for instance,\nprediction models (developed from collected consumption\
    \ data) and often ensuring the\nself-healing of the energy network supply [93].\
    \ Smart grids help energy load balancing\non the basis of usage and availability.\
    \ In this way, it is possible to switch automatically to\nalternative sources\
    \ of energy, as well as predicting future energy demand and estimating\nthe power\
    \ availability and price [14].\nNew generations of smart energy IoT devices have\
    \ been designed for alternative\nenergy harvesting, such as triboelectric nanogenerators\
    \ (TENG) and electrostatic energy\nharvesters (EEH) [59]. A multiplicity of IoT\
    \ sensors is involved in the smart energy context,\nsuch as light dependent resistors\
    \ (LDRs), sensors for measuring light luminosity [94] and\nthe consumption of\
    \ solar radiation and electricity [95].\nNice, France, has made efforts to improve\
    \ smart energy management by scheduling\nelectricity consumption in residential\
    \ and business locations. The smart grid in Nice\nwas created through a smart\
    \ solar neighborhood in city areas by supplying and storing\ndistributed electricity\
    \ [58]. The city of Padova has performed several initiatives in intelligent\n\
    energy management, such as a smart lighting system in which each smart light device\
    \ is\ngeolocated in the city and is powered by photometer sensors that monitor\
    \ the intensity\nof the light emitted by the lamps and check that the correct\
    \ operation of the bulbs is\nperformed [96]. Atlanta has implemented a smart neighborhood\
    \ project to reduce the\nHome Energy Rating System (HERS) score. Energy optimization\
    \ platforms manage home\nappliances, switching to solar power and batteries if\
    \ available [3]. In Helsinki, smart grids\nhelp to reduce energy usage by 15%\
    \ [97]. The Masdar City project aimed to be one of\nthe most efﬁcient and environment-friendly\
    \ systems in the UAE by exploiting renewable\nAppl. Sci. 2022, 12, 1607\n12 of\
    \ 21\nenergy technologies. The city has planned a solar power array and rooftop\
    \ solar panels that\ncan provide more than 10 MW. This, combined with wind energy\
    \ harvesting technologies,\ncan supply energy for a target population of about\
    \ 40,000 citizens [98].\n3.7. Smart Environment\nThe smart environment domain\
    \ includes environmental data collection, monitoring\nand analysis for pollution\
    \ reduction, water quality and supply monitoring and weather\nand climate events\
    \ management [67]. In this regard, air quality monitoring is a crucial\nfactor\
    \ for tracking levels of air pollutants (e.g., NOx, O3, CO2, N2O, PM10, PM2.5,\
    \ etc.),\nwhich represent a serious issue for human health (caused by transportation,\
    \ heating and\nindustrial emissions). Smart waste management is also included\
    \ in this area since it has\nnumerous impacts on the environment. Control policies\
    \ for waste production are handled\nwith smart waste bins that are installed with\
    \ sensors and are capable of providing the\nreal-time analysis of the capacity\
    \ that is currently available [92].\nAs for smart water, sensing devices that\
    \ are devoted to the assessment of water\nquantity and quality typically measure\
    \ parameters such as pH, conductivity, turbidity, total\ndissolved solids, etc.\
    \ [99]. Electromagnetic and ultrasonic sensors are employed to measure\nthe pressure\
    \ for water consumption rate analysis [100]. The application of WSNs for water\n\
    quantity and quality monitoring systems has opened up a new generation of smart\
    \ water\nmonitoring systems, providing a more advanced context awareness and near\
    \ real-time\ninteraction [101].\nSmart environment applications and services are\
    \ typically based on ambient and\nchemical sensors, which are used to measure\
    \ physical quantities expressing environmental\nparameters and conditions, such\
    \ as temperature, humidity, pressure [7] and different kinds\nof pollutants. Smart\
    \ sensing and visualization technologies (satellites, LiDAR) are applied\nto greenhouse\
    \ gas emissions (GHG) and land usage [99]. Location-based services and GIS\ndata\
    \ are also employed.\nIn Singapore, solid waste is managed by the Integrated Waste\
    \ Management Facility\n(IWMF), which includes innovative IoT technology that allows\
    \ for an increase in the process\nefﬁciency and a reduction in GHG emissions [102].\
    \ In Amsterdam, the Green City Watch is\na geo-spatial AI platform that monitors\
    \ urban green infrastructures in near real time using\nAI algorithms and satellite\
    \ images [103]. In Stockholm, solar-powered smart waste bins are\ninstalled, which\
    \ automatically report when they are fully charged and also perform waste\npackaging\
    \ [66]. The Busan smart city, South Korea, employs smart water management\nsystems\
    \ in the whole urban water cycle [3]. In the context of the European TRAFAIR\n\
    project, six European cities (Florence, Pisa, Livorno and Modena in Italy and\
    \ Santiago de\nCompostela and Zaragoza in Spain) have adopted the Snap4City platform\
    \ for monitoring\nurban air quality (using sensors that collect data in the six\
    \ cities) and providing urban air\nquality predictions using simulation models\
    \ [104].\n3.8. Smart Healthcare\nIoT technologies and ubiquitous computing have\
    \ been widely applied to mobile\nhealthcare for remote monitoring, telemedicine\
    \ and telenursing, adverse drugs reactions,\ncommunity healthcare, etc., and these\
    \ aspects are even more relevant in this recent period\nof the COVID-19 pandemic.\
    \ Remote patient monitoring (RPM) can be performed through\nthe use of wearable\
    \ or implanted devices (e.g., cardiac devices, airﬂow monitors, blood glu-\ncometers,\
    \ etc.) that are connected in the cloud using WSN technologies [20]. This has\
    \ led to\nthe development of body sensor networks (BSNs) or wireless body area\
    \ networks (WBANs),\nin which the integration of multiple heterogeneous data sources\
    \ allows the acquisition of\nthe biometric and physiological data of the patients\
    \ for IoT healthcare applications [105].\nSmart hospitals also rely on IoT technologies\
    \ to provide services for medical staff and pa-\ntients (the identiﬁcation and\
    \ monitoring of patients in hospitals and the smart management\nof medical instruments\
    \ supporting decision-making processes in hospitals) [106]. All of\nthese application\
    \ ﬁelds and the related requirements impose well-deﬁned standards, such\nAppl.\
    \ Sci. 2022, 12, 1607\n13 of 21\nas Health Level Seven (HL7), PACS-DICOM in biomedical\
    \ image processing [107], etc.\nRecent advances propose the use of AI techniques\
    \ to deﬁne innovative applications, e.g.,\nmachine learning prognostics and the\
    \ measurement of biometric parameters or symptoms\nfrom multimedia (using mobile\
    \ videos or voice messages, through deep learning- and\nspeech recognition-based\
    \ methods) [108] and disease prediction and prevention [109].\nSingapore has developed\
    \ the HealthHub platform, which integrates personal health\nrecord management\
    \ and the clinical data of patients and citizens [3]. In Stockholm, the\nNew Karolinska\
    \ Solna Hospital integrated smart energy and BIM technologies to provide\nuser-focused\
    \ services (for patients, visitors and medical staff) [110]. The hospital of Hefei,\n\
    China, is one of the ﬁrst of China’s smart hospitals [111] where all aspects of\
    \ the patients\nare managed via IoT and connected healthcare, also providing smart\
    \ building services\nand sustainable energy management. The Helsinki University\
    \ Hospital has implemented\na real-time locating system (RTLS) to collect and\
    \ share anonymized location data about\non-site movements for proximity tracing\
    \ during the COVID-19 pandemic. Moreover, cloud\nservices are provided to enable\
    \ doctors and nurses to remotely interact with COVID-19\npatients [112].\nTo conclude\
    \ the review, Table 1 presents an integrated summary of the smart city\ndomains\
    \ that were presented in this section, in terms of supported services and features,\n\
    real-world case studies and the IoT technologies employed.\nTable 1. A summary\
    \ of smart city domains: services and features, IoT technologies employed and\n\
    real-world cases.\nSmart City Domains\nServices, Applications\nand Features\n\
    IoT and Sensing\nTechnologies Involved\nReal-World Cases\nSmart Governance\n-\n\
    e-government\n-\nCitizens’ participation\n-\nCollaborative and shared\ndecision-making\
    \ policies\n-\nWeb- and mobile-based\napplications for G2C, G2B and\nG2G [41,42]\n\
    -\nBarcelona [46,47]\n-\nAmsterdam [48]\n-\nRio de Janeiro [3,49]\n-\nSingapore\
    \ [50]\n-\nToronto [51,52]\n-\nSongdo [53,54]\nSmart Living\nand Infrastructure\n\
    -\nSmart buildings\n-\nSmart homes\n-\nSmart tourism\n-\nSmart education\n-\n\
    BIM models [57]\n-\nIndoor/outdoor sensors and\nWSN technologies [59,62]\n-\n\
    Web and mobile apps,\nlocation-aware services, virtual\nand augmented reality\
    \ and social\nmedia [64]\n-\nE-learning systems and\ndecentralized education [66]\n\
    -\nLos Angeles [68]\n-\nDubai [69]\nSmart Mobility and\nTransportation\n-\nTrafﬁc\
    \ management\n-\nDynamic routing\n-\nSmart parking\n-\nVehicle sharing\n-\nSustainable\
    \ mobility\n-\nCity sensors and actuators,\npersonal devices\n-\nIoT and intelligent\n\
    transportation\nsystems (ITSs) [71]\n-\nVehicle-to-vehicle\ncommunication (V2V),\n\
    vehicle-to-infrastructure\ncommunication (V2I)\n-\nVANETs [73]\n-\nOn-board diagnostic\
    \ (OBD)\ntools [78]\n-\nBerlin [79]\n-\nFlorence [3]\n-\nAtlanta [3]\n-\nLondon\
    \ [80]\n-\nSantander [81]\n-\nBilbao [66]\n-\nSeoul [82]\nSmart Economy\n-\ne-business\n\
    -\ne-commerce\n-\nPeer-to-peer marketplaces\n-\nPeer-to-peer labor services\n\
    -\nAI solutions for web/mobile\nrecommendation systems [85]\n-\nShenzen [86]\n\
    Appl. Sci. 2022, 12, 1607\n14 of 21\nTable 1. Cont.\nSmart City Domains\nServices,\
    \ Applications\nand Features\nIoT and Sensing\nTechnologies Involved\nReal-World\
    \ Cases\nSmart Industry\nand Production\n-\nIndustry 4.0\n-\nSmart manufacturing\n\
    -\nPredictive maintenance\n-\nSmart agriculture\nand farming\n-\nCyber-physical\
    \ systems (CPS)\n-\nCloud-based manufacturing [87]\n-\nDublin [90]\n-\nShenzen\
    \ [3]\nSmart Energy\n-\nEnergy management\n-\nSustainable energy\nharvesting\n\
    -\nSmart lighting\n-\nSmart grids\n-\nTriboelectric nanogenerators\n(TENG) and\
    \ electrostatic energy\nharvesters (EEH) [59]\n-\nLight luminosity sensors [94]\n\
    -\nEnergy consumption measuring\ndevices [95]\n-\nNice [58]\n-\nPadova [96]\n\
    -\nAtlanta [3]\n-\nHelsinki [97]\n-\nMasdar City [98]\nSmart Environment\n-\n\
    Air quality monitoring\n-\nWeather monitoring\n-\nSmart waste management\n-\n\
    Smart water\n-\nAmbient sensors [7]\n-\nBig data from satellite, LiDAR\nand GIS\
    \ data [99]\n-\nSingapore [102]\n-\nAmsterdam [103]\n-\nStockholm [66]\n-\nBusan\
    \ [3]\n-\nFlorence, Pisa, Livorno\nand Modena, Santiago de\nCompostela and\nZaragoza\
    \ [104]\nSmart Healthcare\n-\nTelemedicine\n-\nRemote patient monitoring\n(RPM)\
    \ and healthcare\ntracking\n-\nSmart hospitals\n-\ne-health records\nmanagement\n\
    -\nDisease prediction and\nprevention\n-\nWearable or implanted devices\nfor remote\
    \ patient monitoring\n(RPM) [20]\n-\nBody sensor networks (BSNs)\nand wireless\
    \ body area networks\n(WBANs) [105]\n-\nStandards for information\nmanagement\
    \ (HL7,\nPACS-DICOM, etc.) [107]\n-\nSingapore [3]\n-\nStockholm [110]\n-\nHefei\
    \ [11]\n-\nHelsinki [112]\n4. Discussion on Recent Trends, Open Challenges and\
    \ Future Directions\nIoT smart city technologies and applications are spreading\
    \ rapidly, and this is reported\nin more and more real-world cases. However, on\
    \ the basis of the analysis and review\nperformed in the previous sections, this\
    \ integration process is not complete since it is still\nfacing some open challenges,\
    \ which may be resolved in future developments.\nFor instance, there are interoperability\
    \ problems due to the presence of many different\nIoT protocols, formats and frameworks\
    \ [3,29,92,105,113], and this aspect is enhanced\nby the fact that many smart\
    \ city applications have been initially developed as vertical\nsilos applications\
    \ [3,18] with each of them using its own solutions for data ingestion,\nstorage\
    \ and exploitation. Resolving the interoperability issues could bring economic\n\
    beneﬁts. In fact, achieving a higher level of interoperability among devices,\
    \ applications\nand services involves the reduction in costs for producing completely\
    \ new and different\ndeployments of the solutions [113], thereby allowing backward\
    \ compatibility through\nthe exploitation of older systems as well as an incremental\
    \ deployment and integration.\nOn the other hand, the development of the IoT/IoE\
    \ paradigm has led to the adoption\nof event-driven and push protocols [32], which\
    \ has paved the way not only to sense the\ncity but also to act through actuators\
    \ and to create event-driven applications. However,\nmost of the solutions proposed\
    \ in the literature still focus on limited domains, addressing\nspeciﬁc problems\
    \ with little or no software reuse [3]. In order to handle the high variety\n\
    of IoT devices and applications, the paradigm of microservice-oriented architecture\
    \ is\nincreasingly adopted in recent IoT-based solutions for smart cities [13,29,32,109].\
    \ This\nenhances the scalability and availability of IoT frameworks and simpliﬁes\
    \ the complexity\nof the traditional service-oriented architectures (SOA) [32].\
    \ For IoT-based solutions, the\nachievement of a higher scalability represents\
    \ the possibility to efﬁciently collect and\nprocess increasingly larger amounts\
    \ of data, which often leads to a higher accuracy in\ndata analysis and often\
    \ enables real-time or near real-time processing [114]. These aspects\nAppl. Sci.\
    \ 2022, 12, 1607\n15 of 21\nimply important social involvement, for instance,\
    \ in security and resilience, since they\nallow the building of more resilient\
    \ tools that are able to perform real-time analysis and\nsimulations, e.g., those\
    \ used by local public authorities for early warnings and alerts in\ncritical\
    \ events, such as disaster management [99] and resilience planning. Moreover,\
    \ many\nIoT solutions are still oriented toward traditional programming environments,\
    \ while the\nmost recent trends show an advancement in the exploitation of visual\
    \ paradigm languages\n(VPL) [15,32], including Node-RED, for implementing workﬂows\
    \ for IoT applications.\nThe adoption of microservice-oriented architectures leads\
    \ toward the overcoming of\nthe monolithic platform approach [3] since the microservice\
    \ paradigm allows the reuse of\nsoftware components and blocks. Moreover, microservice\
    \ architectures are open to exten-\nsions and they can also exploit external services\
    \ more easily (when necessary for delegating\npart of the computation as well\
    \ as accessing additional services or applications) [29]. For\ninstance, they\
    \ can be easily adapted to support almost all kinds of IoT and communication\n\
    protocols and also support data-driven and event-driven push modalities. This\
    \ is moving\nin the direction of the implementation of smarter frameworks for\
    \ business intelligence and\ndata analytics, as well as more interactive visual\
    \ analysis tools [32]. This deeper level of\nintegration and complexity of IoT-enabled\
    \ smart city platforms should bring advancements\nin performing real-time simulations,\
    \ what-if analysis and supporting decision-making\nprocesses, which is the basis\
    \ of the production of smarter and more efﬁcient services and\napplications for\
    \ all involved stakeholders.\nFurthermore, IoT-enabled smart city platforms are\
    \ evolving toward cross-organization\nand multitenancy IoT platforms and applications.\
    \ This allows the development of large\ninfrastructures that can support multiple\
    \ organizations, enhance scalability and reduce the\ninfrastructures’ costs since\
    \ they are shared between multiple operators [36]. This aspect\nis closely connected\
    \ with the reuse of components in smart city frameworks and tries to\nharmonize\
    \ and overcome the efforts needed in building custom-made platforms for each\n\
    city or each speciﬁc context, which is economically inefﬁcient [3]. Other potential\
    \ future di-\nrections include the introduction and dissemination of novel network\
    \ technologies, such as\n5G [28,59,72,102]. Technological advances in networks\
    \ and device solutions are important.\nIn fact, the adoption of the most recent\
    \ network technologies, such as 5G, combined with\nhigher efﬁciency in building\
    \ techniques and technologies following the paradigm of net\nzero energy infrastructure\
    \ can lead to building solutions that are aiming for net zero carbon\nemissions\
    \ [102]. Furthermore, the introduction of innovative computing paradigms, such\n\
    as the introduction and integration of deep learning and AI solutions [109,115],\
    \ semantic\ntechnologies and natural language processing (NLP) would improve the\
    \ interaction level\nbetween smart devices and all smart city actors, as well\
    \ as enabling the production of\nsmarter services for a better quality of life.\n\
    Finally, in order to also discuss the societal challenges addressed by IoT and\
    \ smart city\ntechnologies, we focused on assessing each application area and\
    \ domain, as discussed in\nSection 3, in terms of their contribution to the SDGs.\
    \ To this end, we will brieﬂy introduce\nthe 17 indicators representing the SDGs:\
    \ (1) no poverty; (2) zero hunger; (3) good health\nand well-being; (4) quality\
    \ education; (5) gender equality; (6) clean water and sanitation;\n(7) affordable\
    \ and clean energy; (8) decent work and economic growth; (9) industry, innova-\n\
    tion and infrastructure; (10) reduced inequalities; (11) sustainable cities and\
    \ communities;\n(12) responsible consumption and production; (13) climate action;\
    \ (14) life below water;\n(15) life on land; (16) peace, justice and strong institutions;\
    \ and (17) partnerships for the\ngoals. On the basis of our ﬁndings while reviewing\
    \ the literature, relevant contributions\nand relations among the presented IoT–smart\
    \ city application areas and the following SDGs\nwere retrieved:\n•\nZero Hunger:\
    \ Smart agriculture [7] solutions contribute to improving efﬁciency in ac-\ncessing\
    \ fundamental resources, such as food, and also allow precision agriculture [89];\n\
    •\nGood Health and Well-being: Smart healthcare solutions [106,108] contribute\
    \ to im-\nproving efﬁciency in healthcare services that are provided in hospitals\
    \ and medical\nstructures, as well as at home. Big data collection and analysis\
    \ in healthcare contexts\nAppl. Sci. 2022, 12, 1607\n16 of 21\ncan be useful for\
    \ monitoring critical cases, conditions and events [109], especially in\nthe period\
    \ of COVID-19 pandemic;\n•\nQuality Education: Smart education solutions contribute\
    \ to creating innovative educa-\ntion services, as well as to enhancing the interaction\
    \ between remote and real-world\nlearning activities [66];\n•\nClean Water and\
    \ Sanitation: Smart water solutions [100] are employed to monitor\nthe quantity\
    \ and quality of water distribution and aim to minimize consumption and\nmanage\
    \ wastewater treatments [101]. This represents an important step in the proper\n\
    design and maintenance of quality water systems;\n•\nAffordable and Clean Energy:\
    \ Smart energy solutions and energy grids [3,58,93,96,97]\ncontribute to a more\
    \ efﬁcient energy distribution and usage [92], helping to minimize\npower consumption\
    \ and consider innovative sustainable energy sources [91];\n•\nDecent Work and\
    \ Economic Growth: Smart governance solutions [3,38,39,46–54]\ncontribute to economic\
    \ growth [38] since they are expected to provoke a strong push\nin the direction\
    \ of smart and digital public administrations [39]. Moreover, smart\neconomy solutions\
    \ [83,84] can also contribute to allowing citizens, companies and\nsmart city\
    \ stakeholders to follow the market for smart applications and data economy,\n\
    rethinking the ﬂexibility of jobs and labors [84] and, thus, redeﬁning the economic\n\
    value associated with them;\n•\nIndustry, Innovation and Infrastructure: Smart\
    \ industry solutions [3,14,33,90] are\nestablishing new and relevant digital infrastructures\
    \ for sustainable industrial produc-\ntion [88] and data economy;\n•\nSustainable\
    \ Cities and Communities: Several IoT-enabled smart city components\ncontribute\
    \ to improving the sustainability of smart city communities. For instance,\nsmart\
    \ mobility solutions [3,66,79–82] are aiming to establish near-to-zero emissions\n\
    and reduced trafﬁc ﬂows and to also enhance the adoption of smart transportation\n\
    and IoT paradigms. These aspects will bring relevant inﬂuences and improvements\n\
    for the quality of life in smart cities [92];\n•\nClimate Action: Smart environment\
    \ technologies [3,66,102,103] that are focused on\nmonitoring air quality and\
    \ pollutant levels [99,104] contribute to analyzing and con-\ntrolling air quality\
    \ and fossil combustion, as well as their environmental impact in\nterms of CO2,\
    \ NO, NO2, etc. (which are the main effects of fossil combustion);\n•\nPeace,\
    \ Justice and Strong Institutions: Smart governance solutions [3,38,39,46–54]\n\
    contribute to providing institutions with data-driven decision-making processes\
    \ [39],\nwhich makes citizens’ participation more inclusive and deliberative,\
    \ thus creating a\nconsensus for the public good and enhancing equality and social\
    \ justice [38].\n5. Conclusions\nIn this paper, a review of the recent research\
    \ literature on IoT-enabled smart cities\nframework was performed. The rationale\
    \ behind this study was the requirement to un-\nderstand and classify the most\
    \ recent trends in the adoption of IoT technologies as a key\ndriver for the efﬁcient\
    \ and sustainable development of smart cities. The purpose was also\nto highlight\
    \ the main open challenges that need to be addressed and resolved in the future.\n\
    The review was conducted both for key IoT technologies, which were analyzed following\n\
    an architectural perspective, and for smart city approaches and frameworks, which\
    \ were\nbased on classiﬁcation into eight domains describing the main application\
    \ areas. From this\nanalysis, it emerged that in recent years, the integration\
    \ of IoT solutions and smart city\nframeworks is achieving increasingly higher\
    \ levels of complexity and wider application\nranges, which go beyond the past\
    \ generation of vertical silo applications that were based\non speciﬁc domains.\
    \ In fact, the necessity to overcome vertical silos (i.e., where data are\ncollected\
    \ and “siloed” in a unique system and closed to the rest of IoT [114]) has provoked\n\
    several initiatives. For instance, the EU developed speciﬁc initiatives and IoT\
    \ programs,\nsuch as the open API standard Open Messaging Interface (O-MI) and\
    \ Open Data Format\n(O-DF) [116]. This produces new added-value across multiple\
    \ platforms, providing the\nAppl. Sci. 2022, 12, 1607\n17 of 21\npossibility to\
    \ share protocols, data and results and allowing the better and more efﬁcient\n\
    cooperation between all involved actors and stakeholders (users, software and\
    \ network\nproviders, institutions, companies, etc.) [114]. To this end, the new\
    \ generation of smart\napplications will manage and optimize more complex sets\
    \ of heterogeneous information,\ndata, systems, sensors, devices, etc. However,\
    \ this process is still not complete since it\nhas to cope with several open technical\
    \ and social challenges (regarding the efforts to\nharmonize the many different\
    \ standards for IoT formats and protocols, interoperability\nand scalability issues\
    \ and the achievement of sustainability goals) in order to move toward\nmicroservice-oriented\
    \ architectures, event-driven/data-driven applications and more sus-\ntainable\
    \ solutions. Finally, another important driver could be represented by all involved\n\
    stakeholders and actors, who are raising their awareness and becoming more actively\n\
    engaged in the smart city environment, not only as service consumers but also\
    \ as the\nproducers of valuable contents and information.\nAuthor Contributions:\
    \ Conceptualization and methodology, P.B., G.P. and P.N.; research and investi-\n\
    gation, P.B., G.P. and P.N.; writing—original draft preparation, P.B., G.P. and\
    \ P.N.; writing—review\nand editing, G.P.; funding acquisition, P.N. All authors\
    \ have read and agreed to the published version\nof the manuscript.\nFunding:\
    \ The solution has been partially funded by the HERIT-DATA Interreg project.\n\
    Acknowledgments: The authors would like to thank the HERIT-DATA Interreg project.\
    \ Snap4City (https:\n//www.snap4city.org) is an open technology and research by\
    \ DISIT Lab, University of Florence, Italy.\nConﬂicts of Interest: The authors\
    \ declare no conﬂict of interest.\nReferences\n1.\nEjaz, W.; Anpalagan, A. Internet\
    \ of Things for Smart Cities: Technologies, Big Data and Security; Springer: Berlin/Heidelberg,\n\
    Germany, 2019. [CrossRef]\n2.\nFizza, K.; Banerjee, A.; Mitra, K.; Jayaraman,\
    \ P.P.; Ranjan, R.; Patel, P.; Georgakopoulos, D. QoE in IoT: A vision, survey\
    \ and future\ndirections. Discov. Internet Things 2021, 1, 4. [CrossRef]\n3.\n\
    Bauer, M.; Sanchez, L.; Song, J.S. IoT-enabled smart cities: Evolution and outlook.\
    \ Sensors 2021, 21, 4511. [CrossRef] [PubMed]\n4.\nJanani, R.P.; Renuka, K.; Aruna,\
    \ A.; Lakshmi Narayanan, K. IoT in smart cities: A contemporary survey. Glob.\
    \ Transit. Proc. 2021,\n2, 187–193. [CrossRef]\n5.\nUN-GGMI Report, Resolution\
    \ Adopted by the General Assembly on 6 July 2017. 2017. Available online: https://ggim.un.org/\n\
    documents/a_res_71_313.pdf (accessed on 17 January 2022).\n6.\nHassan, R.J.; Zeebaree,\
    \ S.R.M.; Ameen, S.Y.; Kak, S.F.; Sadeeq, M.A.M.; Ageed, Z.S.; Al-Zebari, A.;\
    \ Salih, A.A. State of Art Survey\nFor IoT effects on smart city, technology:\
    \ Challenges, opportunities, and solutions. Asian J. Res. Comput. Sci. 2021, 8,\
    \ 32–48.\n[CrossRef]\n7.\nSyed, A.S.; Sierra-Sosa, D.; Kumar, A.; Elmaghraby,\
    \ A. IoT in smart cities: A survey of technologies, practices and challenges.\n\
    Smart Cities 2021, 4, 24. [CrossRef]\n8.\nPukkasenung, P.; Lilakiatsakun, W. Improved\
    \ generic layer model for IoT architecture. J. Inf. Sci. Technol. 2021, 11, 18–29.\n\
    [CrossRef]\n9.\nSaid, O.; Masud, M. Towards Internet of Things: Survey and future\
    \ vision. Int. J. Comput. Netw. 2013, 5, 1–17.\n10.\nZhong, C.-L.; Zhu, Z.; Huang,\
    \ R.-G. Study on the IoT architecture and gateway technology. In Proceedings of\
    \ the 14th International\nSymposium on Distributed Computing and Applications\
    \ for Business Engineering and Science, Guiyang, China, 18–24 August\n2015. [CrossRef]\n\
    11.\nBurhan, M.; Rehman, R.A.; Khan, B.; Kim, B.S. IoT elements, layered architectures\
    \ and security issues: A comprehensive survey.\nSensors 2018, 18, 2796. [CrossRef]\n\
    12.\nMarques, G.; Garcia, N.; Pombo, N. A survey on IoT: Architectures, elements,\
    \ applications, QoS, platforms and security concepts.\nIn Advances in Mobile Cloud\
    \ Computing and Big Data in the 5G Era; Springer: Cham, Switzerland, 2017; pp.\
    \ 115–130. [CrossRef]\n13.\nBadidi, E.; Mahrez, Z.; Sabir, E. Fog computing for\
    \ smart cities’ big data management and analytics: A review. Future Internet\n\
    2020, 12, 190. [CrossRef]\n14.\nSethi, P.; Sarangi, S.R. Internet of Things: Architectures,\
    \ protocols, and applications. J. Electr. Comput. Eng. 2017, 2017, 9324035.\n\
    [CrossRef]\n15.\nRay, P.P. A survey on visual programming languages in Internet\
    \ of Things. Sci. Program. 2017, 2017, 1231430. [CrossRef]\n16.\nGomez, C.; Oller,\
    \ J.; Paradells, J. Overview and evaluation of Bluetooth low energy: An emerging\
    \ low-power wireless technology.\nSensors 2012, 12, 11734–11753. [CrossRef]\n\
    Appl. Sci. 2022, 12, 1607\n18 of 21\n17.\nAlvear, O.; Calafate, C.T.; Cano, J.C.;\
    \ Manzoni, P. Crowdsensing in smart cities: Overview, platforms, and environment\
    \ sensing\nissues. Sensors 2018, 18, 460. [CrossRef] [PubMed]\n18.\nRay, P.P.\
    \ A survey on Internet of Things architectures. J. King Saud Univ.–Comput. Inf.\
    \ Sci. 2018, 30, 291–319. [CrossRef]\n19.\nAhmed, S. Performance analysis of Mobile\
    \ WiMAX Technology. In Proceedings of the International Conference on Computing\n\
    for Sustainable Global Development (INDIACom), New Delhi, India, 5–7 March 2014;\
    \ pp. 959–961. [CrossRef]\n20.\nGhazal, T.M.; Hasan, M.K.; Alshurideh, M.T.; Alzoubi,\
    \ H.M.; Ahmad, M.; Akbar, S.S.; Al Kurdi, B.; Akour, I.A. IoT for smart cities:\n\
    Machine learning approaches in smart healthcare—A review. Future Internet 2021,\
    \ 13, 218. [CrossRef]\n21.\nLi, Y.; Cheng, X.; Cao, Y.; Wang, D.; Yang, L. Smart\
    \ choice for the smart grid: Narrowband Internet of Things (NB-IoT). IEEE\nInternet\
    \ Things J. 2018, 5, 1505–1515. [CrossRef]\n22.\nYang, D.; Huang, X.; Huang, J.;\
    \ Chang, X.; Xing, G.; Yang, Y. A ﬁrst look at energy consumption of NB-IoT in\
    \ the wild: Tools and\nlarge-scale measurement. IEEE/ACM Trans. Netw. 2021, 29,\
    \ 2616–2631. [CrossRef]\n23.\nEl Fawal, A.H.; Mansour, A.; Najem, M.; Le Roy,\
    \ F.; Le Jeune, D. LTE-M adaptive eNodeB for emergency scenarios. In Proceedings\
    \ of\nthe International Conference on Information and Communication Technology\
    \ Convergence (ICTC), Jeju, Korea, 18–20 October 2017;\npp. 536–541. [CrossRef]\n\
    24.\nRatasuk, R.; Mangalvedhe, N.; Bhatoolaul, D.; Ghosh, A. LTE-M evolution towards\
    \ 5G massive MTC. In Proceedings of the IEEE\nGlobecom Workshops (GC Wkshps),\
    \ Singapore, 4–8 December 2017; pp. 1–6. [CrossRef]\n25.\nBeale, M.; Uchiyama,\
    \ H.; Clifton, J.C. IoT evolution: What’s next? IEEE Wirel. Commun. 2021, 28,\
    \ 5–7. [CrossRef]\n26.\nLinh, P.M.; Kim, T. A study of the Z-Wave Protocol: Implementing\
    \ your own smart home gateway. In Proceedings of the\n3rd International Conference\
    \ on Computer and Communication Systems (ICCCS), Nagoya, Japan, 27–30 April 2018.\
    \ [CrossRef]\n27.\nMekki, K.; Bajic, E.; Chaxel, F.; Meyer, M. A comparative study\
    \ of LPWAN technologies for large-scale IoT deployment. ICT\nExpress 2019, 5,\
    \ 1–7. [CrossRef]\n28.\nRao, S.K.; Prasad, R. Impact of 5G technologies on smart\
    \ city implementation. Wirel. Pers. Commun. 2018, 100, 161–176. [CrossRef]\n29.\n\
    Badii, C.; Bellini, P.; Cenni, D.; Marazzini, M.; Nesi, P.; Pantaleo, G.; Paolucci,\
    \ M.; Soderi, M.; Zaza, I.; Belay, E.G.; et al. Snap4City:\nA scalable IOT/IOE\
    \ platform for developing smart city applications. In Proceedings of the 2018\
    \ IEEE SmartWorld, Ubiquitous\nIntelligence & Computing, Advanced & Trusted Computing,\
    \ Scalable, Computing & Communications, Cloud & Big Data\nComputing, Internet\
    \ of People and Smart City Innovations, Guangzhou, China, 8–12 October 2018. [CrossRef]\n\
    30.\nHazra, A.; Adhikari, M.; Amgoth, T.; Srirama, S.N. A comprehensive survey\
    \ on interoperability for IioT: Taxonomy, standards,\nand future directions. ACM\
    \ Comput. Surv. 2021, 55, 1–35. [CrossRef]\n31.\nZhang, J.; Ma, M.; Wang, P.;\
    \ Sun, X.D. Middleware for the Internet of Things: A survey on requirements, enabling\
    \ technologies,\nand solutions. J. Syst. Archit. 2021, 117, 102098. [CrossRef]\n\
    32.\nBadii, C.; Bellini, P.; Difino, A.; Nesi, P.; Pantaleo, G.; Paolucci, M.\
    \ MicroServices Suite for smart city applications. Sensors 2019, 19, 4798.\n[CrossRef]\n\
    33.\nBadii, C.; Bellini, P.; Cenni, D.; Mitolo, N.; Nesi, P.; Pantaleo, G.; Soderi,\
    \ M. Industry 4.0 synoptics controlled by IoT applications in\nNode-RED. In Proceedings\
    \ of the IEEE International Conferences on Internet of Things (iThings), Rhodes,\
    \ Greece, 2–6 November\n2020. [CrossRef]\n34.\nCollini, E.; Nesi, P.; Pantaleo,\
    \ G. Deep learning for short-term prediction of available bikes on bike-sharing\
    \ stations. IEEE Access\n2021, 9, 124337–124347. [CrossRef]\n35.\nBellini, P.;\
    \ Bugli, F.; Nesi, P.; Pantaleo, G.; Paolucci, M.; Zaza, I. Data ﬂow management\
    \ and visual analytic for big data smart\ncity/IOT. In Proceedings of the 2019\
    \ IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing,\n\
    Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People\
    \ and Smart City Innovation, Leicester,\nUK, 19–23 August 2019. [CrossRef]\n36.\n\
    Badii, C.; Bellini, P.; Diﬁno, A.; Nesi, P. Smart city IoT platform respecting\
    \ GDPR privacy and security aspects. IEEE Access 2020,\n8, 23601–23623. [CrossRef]\n\
    37.\nMardacany, E. Smart cities characteristics: Importance of buit environments\
    \ components. In Proceedings of the IET Conference\non Future Intelligent Cities,\
    \ London, UK, 4–5 December 2014. [CrossRef]\n38.\nDemirel, D. How the smart governance\
    \ model shapes cities? Cases from Europe. J. Enterprising Communities 2021. [CrossRef]\n\
    39.\nChun, S.A.; Adam, N.R.; Noveck, B. Smart governance in the context of smart\
    \ cities: A literature review. Inf. Polity 2018, 3,\n143–162. [CrossRef]\n40.\n\
    Shahrour, I.; Xie, X. Role of Internet of Things (IoT) and crowdsourcing in smart\
    \ city projects. Smart Cities 2021, 4, 68. [CrossRef]\n41.\nPapadopoulou, P.;\
    \ Kolomvatsos, K.; Hadjiefthymiades, S. Internet of Things in E-Government: Applications\
    \ and challenges. Int.\nJ. Artif. Intell. Mach. Learn. 2020, 10, 99–118. [CrossRef]\n\
    42.\nCoardos, D.; Tirziu, E.; Gheorge-Moisii, M. A general framework based on\
    \ IoT technology for smart governance. In Proceedings\nof the 2019 IE (Informatics\
    \ in Economy) International Conference, Bucharest, Romania, 30–31 May 2019. [CrossRef]\n\
    43.\nSzádeczky, T. Enhanced functionality brings new privacy and security issues—An\
    \ analysis of eI. Masaryk. Univ. J. Law Technol.\n2018, 12, 3–28. [CrossRef]\n\
    44.\nBadii, C.; Bellini, P.; Diﬁno, A.; Nesi, P. Sii-mobility: An IoT/IoE architecture\
    \ to enhance smart city mobility and transportation\nservices. Sensors 2018, 19,\
    \ 1. [CrossRef] [PubMed]\nAppl. Sci. 2022, 12, 1607\n19 of 21\n45.\nBarcevicius,\
    \ E.; Cibaite, G.; Codagnone, G.; Gineikyte, V.; Klimaviciute, L.; Liva, G.; Matulevic,\
    \ L.; Misuraca, G.; Vanini, I.\nExploring Digital Government transformation in\
    \ the EU; Publications Ofﬁce of the European Union: Luxembourg, 2019; JRC118857.\n\
    [CrossRef]\n46.\nGascó-Hernandez, M. Building a smart city: Lessons from Barcelona.\
    \ Commun. ACM 2018, 61, 50–57. [CrossRef]\n47.\nBakici, T.; Almirall, E.; Wareham,\
    \ J. A smart city initiative: The case of Barcelona. J. Knowl. Econ. 2013, 4,\
    \ 135–148. [CrossRef]\n48.\nNesti, G. Deﬁning and assessing the transformational\
    \ nature of smart city governance: Insights from four European cases. Int.\nRev.\
    \ Adm. Sci. 2020, 86, 20–37. [CrossRef]\n49.\nGaffney, C.; Robertson, C. Smarter\
    \ than smart: Rio de Janeiro’s ﬂawed emergence as a smart city. J. Urban Technol.\
    \ 2018, 25, 47–64.\n[CrossRef]\n50.\nChang, F.; Das, D. Smart nation Singapore:\
    \ Developing policies for a citizen-oriented smart city initiative. In Developing\
    \ National\nUrban Policies: Ways Forward to Green and Smart Cities; Springer:\
    \ Berlin/Heidelberg, Germany, 2020; pp. 425–440. [CrossRef]\n51.\nArtyushina,\
    \ A. Is civic data governance the key to democratic smart cities? The role of\
    \ the urban data trust in Sidewalk Toronto.\nTelemat. Inform. 2020, 5, 101456.\
    \ [CrossRef]\n52.\nAustin, L.M.; Lie, D. Data trusts and the governance of smart\
    \ environments: Lessons from the failure of Sidewalk Labs. Surveill.\nSoc. 2021,\
    \ 19, 255–261. [CrossRef]\n53.\nYigitcanlar, T.; Han, H.; Kamruzzaman, M.; Ioppolo,\
    \ G.; Sabatini-Marques, J. The making of smart cities: Are Songdo, Masdar,\nAmsterdam,\
    \ San Francisco and Brisbane the best we could build? Land Use Policy 2019, 88,\
    \ 104187. [CrossRef]\n54.\nLee, S.K.; Kwon, H.R.; Cho, H.; Kim, J.; Lee, D. International\
    \ Case Studies of Smart Cities: Songdo, Republic of Korea, IDB Report.\n2016.\
    \ Available online: https//publications.iadb.org/publications/english/document/International-Case-Studies-of-Smart-\n\
    Cities-Songdo-Republic-of-Korea.pdf (accessed on 17 January 2022).\n55.\nShi,\
    \ Q.; Zhang, Z.; He, T. Deep learning enabled smart mats as a scalable ﬂoor monitoring\
    \ system. Nat. Commun. 2020, 11, 4609.\n[CrossRef]\n56.\nLombardi, M.; Pascale,\
    \ F.; Santaniello, D. Internet of Things: A general overview between architectures,\
    \ protocols and applications.\nInformation 2021, 12, 87. [CrossRef]\n57.\nTang,\
    \ S.; Shelden, D.R.; Eastman, C.M.; Pishdad-Bozorghi, P.; Gao, X. A review of\
    \ building information modeling (BIM) and the\ninternet of things (IoT) devices\
    \ integration: Present status and future trends. Autom. Constr. 2019, 10, 127–139.\
    \ [CrossRef]\n58.\nSilva, B.N.; Khan, M.; Han, K. Towards sustainable smart cities:\
    \ A review of trends, architectures, components, and open\nchallenges in smart\
    \ cities. Sustain. Cities Soc. 2018, 38, 697–713. [CrossRef]\n59.\nLiu, L.; Guo,\
    \ X.; Lee, C. Promoting smart cities into the 5G era with multi-ﬁeld Internet\
    \ of Things (IoT) applications powered with\nadvanced mechanical energy harvesters.\
    \ Nano Energy 2021, 88, 106304. [CrossRef]\n60.\nWang, J.; Meng, C.; Wang, C.T.;\
    \ Liu, C.H.; Chang, C.; Li, C. A fully self-powered, ultra-stable cholesteric\
    \ smart window triggered\nby instantaneous mechanical stimuli. Nano Energy 2021,\
    \ 85, 105976. [CrossRef]\n61.\nQiu, C.; Wu, F.; Lee, C.; Yuce, M.R. Self-powered\
    \ control interface based on Gray code with hybrid triboelectric and photovoltaics\n\
    energy harvesting for IoT smart home and access control applications. Nano Energy\
    \ 2020, 70, 104456. [CrossRef]\n62.\nFadhil, J.A.; Omar, O.A.; Sarhan, Q.I. A\
    \ survey on the applications of smart home systems. In Proceedings of the 2020\
    \ International\nConference on Computer Science and Software Engineering (CSASE),\
    \ Duhok, Iraq, 16–18 April 2020. [CrossRef]\n63.\nLiao, L.D.; Wang, Y.; Tsao,\
    \ Y.-C.; Wang, I.-J.; Jhang, D.-F.; Chu, T.-S.; Tsao, C.-H.; Tsai, C.-N.; Chuang,\
    \ C.-C.; Ger, T.-R.; et al.\nDesign and validation of a multifunctional android-based\
    \ smart home control and monitoring system. IEEE Access 2019, 7,\n163313–163322.\
    \ [CrossRef]\n64.\nYe, B.H.; Ye, H.; Law, R. Systematic review of smart tourism\
    \ research. Sustainability 2020, 12, 3401. [CrossRef]\n65.\nBellini, P.; Cenni,\
    \ D.; Nesi, P.; Paoli, I. Wi-Fi based city users’ behaviour analysis for smart\
    \ city. J. Vis. Lang. Comput. 2017, 42,\n31–45. [CrossRef]\n66.\nSanchez-Corcuera,\
    \ R.; Nuñez-Marcos, A.; Sesma-Solance, J. Smart cities survey: Technologies, application\
    \ domains and challenges\nfor the cities of the future. Int. J. Distrib. Sens.\
    \ Netw. 2019, 15. [CrossRef]\n67.\nDu, J. Application analysis of IoT technology\
    \ in smart cities. In Proceedings of the 2nd International Conference on E-Commerce\n\
    and Internet Technology (ECIT), Hangzhou, China, 5–7 March 2021. [CrossRef]\n\
    68.\nAlam, T. Cloud-based IoT applications and their roles in smart cities. Smart\
    \ Cities 2021, 4, 64. [CrossRef]\n69.\nKhan, M.S.; Woo, M.; Nam, K.; Chathoth,\
    \ P.K. Smart city and smart tourism: A case of Dubai. Sustainability 2017, 9,\
    \ 2279.\n[CrossRef]\n70.\nPaiva, S.; Ahad, M.A.; Tripathi, G.S.; Feroz, N.; Casalino,\
    \ G. Enabling technologies for urban smart mobility: Recent trends,\nopportunities\
    \ and challenges. Sensors 2021, 21, 2143. [CrossRef]\n71.\nBiyik, C.; Abareshi,\
    \ A.; Paz, A.; Ruiz, R.A.; Battarra, R.; Rogers, C.D.F.; Lizarraga, C. Smart mobility\
    \ adoption: A review of the\nliterature. J. Open Innov. Technol. Mark. Complex.\
    \ 2021, 7, 146. [CrossRef]\n72.\nChen, S.; Hu, J.; Shi, Y.; Peng, Y.; Fang, J.;\
    \ Zhao, R.; Zhao, L. Vehicle-to-everything (v2x) services supported by LTE-based\
    \ systems\nand 5G. IEEE Commun. Stand. Mag. 2017, 1, 70–76. [CrossRef]\n73.\n\
    Abdelgadir, M.; Saeed, R.A.; Babiker, A. Mobility routing model for vehicular\
    \ ad-hoc networks (VANETs). Veh. Commun. 2017, 9,\n154–161. [CrossRef]\n74.\n\
    De Souza, A.M.; Brennand, C.A.; Yokoyama, R.S.; Donato, E.A.; Madeira, E.R.; Villas,\
    \ L.A. Trafﬁc management systems: A\nclassiﬁcation, review, challenges, and future\
    \ perspectives. Int. J. Distrib. Sens. Netw. 2017, 13. [CrossRef]\nAppl. Sci.\
    \ 2022, 12, 1607\n20 of 21\n75.\nUsha, B.A.; Sangeetha, K.N.; Suchit, T.E.; Shyam,\
    \ A.; Suryanarayanan, A. Comprehensive review of smart cities using IoT. In\n\
    Proceedings of the 8th International Conference on Reliability, Infocom Technologies\
    \ and Optimization (Trends and Future\nDirections) (ICRITO), Noida, India, 4–5\
    \ June 2020. [CrossRef]\n76.\nGolbabei, F.; Yigitcanlar, T.; Bunker, J. The role\
    \ of shared autonomous vehicle systems in delivering smart urban mobility: A\n\
    systematic review of the literature. Int. J. Sustain. Transp. 2021, 15, 731–748.\
    \ [CrossRef]\n77.\nBarriga, J.J.; Sulca, J.; Leon, J.L.; Ulloa, A.; Portero, D.;\
    \ Andrade, R.; Yoo, S.G. Smart parking: A Literature review from the\ntechnological\
    \ perspective. Appl. Sci. 2019, 9, 4569. [CrossRef]\n78.\nMogro, A.E.; Huertas,\
    \ J.I. Assessment of the effect of using air conditioning on the vehicle’s real\
    \ fuel consumption. Int. J. Interact.\nDes. Manuf. 2021, 15, 271–285. [CrossRef]\n\
    79.\nCepeliauskaite, G.; Keppner, B.; Simkute, Z.; Stasiskiene, Z.; Leuser, L.;\
    \ Kalnina, I.; Kotovica, N.; Andins, J.; Muiste, M. Smart-\nmobility services\
    \ for climate mitigation in urban areas: Case studies of Baltic countries and\
    \ Germany. Sustainability 2021, 13, 4127.\n[CrossRef]\n80.\nMoscholidou, I.; Pangbourne,\
    \ K. A preliminary assessment of regulatory efforts to steer smart mobility in\
    \ London and Seattle.\nTransp. Policy 2020, 98, 170–177. [CrossRef]\n81.\nSanchez,\
    \ L.; Muñoz, L.; Galache, J.A.; Sotres, P.; Santana, J.R.; Gutiérrez, V.; Ramdhany,\
    \ R.; Gluhak, A.; Krco, S.; Theodoridis, E.;\net al. SmartSantander: IoT experimentation\
    \ over a smart city testbed. Comput. Netw. 2014, 61, 217–238. [CrossRef]\n82.\n\
    Anthopoulous, L. Smart utopia VS smart reality: Learning by experience from 10\
    \ smart city cases. Cities 2017, 63, 128–148.\n[CrossRef]\n83.\nKezai, P.K.; Fischer,\
    \ S.; Lados, M. Smart economy and startup enterprises in the Visegrád Countries—A\
    \ comparative analysis\nbased on the Crunchbase Database. Smart Cities 2020, 3,\
    \ 70. [CrossRef]\n84.\nKumar, T.M.V. Smart Economy in Smart Cities: International\
    \ Collaborative Research: Ottawa, St.Louis, Stuttgart, Bologna, Cape Town,\nNairobi,\
    \ Dakar, Lagos, New Delhi, Varanasi, Vijayawada, Kozhikode, Hong Kong; Springer:\
    \ Berlin/Heidelberg, Germany, 2017.\n[CrossRef]\n85.\nBellini, P.; Nesi, P.; Palesi,\
    \ A.L.I.; Pantaleo, G. Fashion retail recommendation system by multiple clustering.\
    \ In Proceedings of the\n27th International DMS Conference on Visualization and\
    \ Visual Languages (DMSVIVA 2021), Pittsburgh, PA, USA, 29–30 June 2021.\n[CrossRef]\n\
    86.\nHu, R. The state of smart cities in China: The case of Shenzhen. Energies\
    \ 2019, 12, 4375. [CrossRef]\n87.\nLiu, Y.Y.; Hung, M.H.; Lin, Y.C.; Chen, C.C.;\
    \ Gao, W.L.; Cheng, F.T. A Cloud-based pluggable manufacturing service scheme\
    \ for\nsmart factory. In Proceedings of the 14th IEEE International Conference\
    \ on Automation Science and Engineering (CASE), Munich,\nGermany, 20–24 August\
    \ 2018. [CrossRef]\n88.\nOztemel, E.; Gursev, S. Literature review of Industry\
    \ 4.0 and related technologies. J. Intell. Manuf. 2020, 31, 127–182. [CrossRef]\n\
    89.\nLopes, S.F.; Pereira, R.M.; Lopes, S.O.; Coutinho, M.; Malheiro, A.; Fonte,\
    \ V. Yet a smarter irrigation system. Lect. Notes Inst.\nComput. Sci. Soc. Inform.\
    \ Telecommun. Eng. LNICST 2020, 323, 337–346. [CrossRef]\n90.\nSix Real World\
    \ Examples of Digital Transformation. Available online: https://www.smartindustry.com/blog/smart-industry-\n\
    connect/six-real-world-examples-of-digital-transformation/ (accessed on 17 January\
    \ 2022).\n91.\nAkin-Ponnle, A.E.; Carvalho, N.B. energy harvesting mechanisms\
    \ in a smart city—A review. Smart Cities 2021, 4, 25. [CrossRef]\n92.\nBelli,\
    \ L.; Cilfone, A.; Davoli, L.; Ferrari, G.; Adorni, P.; Di Nocera, F.; Dall’Olio,\
    \ A.; Pellegrini, C.; Mordacci, M.; Bertolotti, E.\nIoT-enabled smart sustainable\
    \ cities: Challenges and approaches. Smart Cities 2020, 3, 52. [CrossRef]\n93.\n\
    Shirazi, E.; Jadid, S. Autonomous self-healing in smart distribution grids using\
    \ multi agent systems. IEEE Trans. Ind. Inform. 2019,\n15, 6291–6301. [CrossRef]\n\
    94.\nDe Paz, J.F.; Bajo, J.; Rodriguez, S.; Villarrubia, G.; Corchado, J.M. Intelligent\
    \ system for lighting control in smart cities. Inf. Sci.\n2016, 372, 241–255.\
    \ [CrossRef]\n95.\nKumar, A.; Singh, A.; Mahanta, P.; Mukhopadhyay, C. Sensing\
    \ technologies for monitoring intelligent buildings: A review. IEEE\nSens. J.\
    \ 2018, 18, 4847–4860. [CrossRef]\n96.\nZanella, A.; Bui, N.; Castellani, A.;\
    \ Vangelista, N.; Zorzi, M. Internet of Things for smart cities. IEEE Internet\
    \ Things J. 2014, 1,\n22–32. [CrossRef]\n97.\nOkai, E.; Feng, X.; Sant, P. Smart\
    \ cities survey. In Proceedings of the IEEE 20th International Conference on High\
    \ Performance\nComputing and Communications and IEEE 16th International Conference\
    \ on Smart City, Exeter, UK, 28–30 June 2018. [CrossRef]\n98.\nSankaran, V.; Chopra,\
    \ A. Creating global sustainable smart cities (a case study of Masdar City). J.\
    \ Phys. Conf. Ser. 2020, 1706,\n012141. [CrossRef]\n99.\nRamirez-Moreno, M.A.;\
    \ Keshtkar, S.; Padilla-Reyes, D.A.; Ramos-Lopez, E.; García-Martinez, M.; Hernandez-Luna,\
    \ M.C.; Mogro,\nA.E.; Mahlknecht, J.; Huertas, J.; Peimbert-Garcia, R.E. Sensors\
    \ for sustainable smart cities: A review. Appl. Sci. 2021, 11, 8198.\n[CrossRef]\n\
    100. Quadar, N.; Chehri, A.; Jeon, G.; Ahmad, A. Smart water distribution system\
    \ based on IoT networks, a critical review. In Human\nCentred Intelligent Systems;\
    \ Springer: Berlin/Heidelberg, Germany, 2020; pp. 293–303. [CrossRef]\n101. Martinez,\
    \ R.; Vela, N.; El Aatik, A.; Murray, E.; Roche, P.; Navarro, J.M. On the use\
    \ of an IoT integrated system for water quality\nmonitoring and management in\
    \ wastewater treatment plants. Water 2020, 12, 1096. [CrossRef]\n102. Huseien,\
    \ G.F.; Shah, K.W. Potential applications of 5G network technology for climate\
    \ change control: A scoping review of\nSingapore. Sustainability 2021, 13, 9720.\
    \ [CrossRef]\nAppl. Sci. 2022, 12, 1607\n21 of 21\n103. Nitoslawski, S.A.; Galle,\
    \ N.J.; Van Den Bosch, C.K.; Steenberg, J.W.N. Smarter ecosystems for smarter\
    \ cities? A review of trends,\ntechnologies, and turning points for smart urban\
    \ forestry. Sustain. Cities Soc. 2019, 51, 101770. [CrossRef]\n104. Po, L.; Rollo,\
    \ F.; Viqueira, J.R.R.; Lado, R.T.; Bigi, A.; Lopez, J.C.; Paolucci, M.; Nesi,\
    \ P. TRAFAIR: Understanding trafﬁc ﬂow\nto improve air quality. In Proceedings\
    \ of the The 1st IEEE African Workshop on Smart Sustainable Cities and Communities\n\
    (IEEE ASC2 2019), In Conjunction with the 5th IEEE International Smart Cities\
    \ Conference, ISC2. 2019, Casablanca, Morocco,\n14–17 October 2019. [CrossRef]\n\
    105. Asghari, P.; Rahmani, A.M.; Javadi, H.S. Internet of Things applications:\
    \ A systematic review. Comput. Netw. 2019, 148, 241–261.\n[CrossRef]\n106. Tian,\
    \ S.; Yang, W.; Le Grange, J.M.; Wang, P.; Huang, W.; Ye, Z. Smart healthcare:\
    \ Making medical care more intelligent. Glob.\nHealth J. 2019, 3, 62–65. [CrossRef]\n\
    107. Haak, D.; Page, C.E.; Deserno, T.M. A survey of DICOM viewer software to\
    \ integrate clinical research and medical imaging.\nJ. Digit. Imaging 2016, 29,\
    \ 206–215. [CrossRef]\n108. Umair, M.; Cheema, M.A.; Cheema, O.; Li, H.; Lu, H.\
    \ Impact of COVID-19 on IoT adoption in healthcare, smart homes, smart\nbuildings,\
    \ smart cities, transportation and industrial IoT. Sensors 2021, 21, 3838. [CrossRef]\
    \ [PubMed]\n109. Atitallah, S.B.; Driss, M.; Boulila, W.; Ghezala, H.B. Leveraging\
    \ Deep Learning and IoT big data analytics to support the smart\ncities development:\
    \ Review and future directions. Comput. Sci. Rev. 2020, 38, 100303. [CrossRef]\n\
    110. Apanaviciene, R.; Urbonas, R.; Fokaides, P.A. Smart building integration\
    \ into a smart city: Comparative study of real estate\ndevelopment. Sustainability\
    \ 2020, 12, 9376. [CrossRef]\n111. BOE Hefei Digital Hospital. Available online:\
    \ https://www.wsp.com/en-CN/projects/boe-hefei-digital-hospital (accessed on\n\
    17 January 2022).\n112. How Smart Hospitals Can Improve Healthcare. Available\
    \ online: https://stlpartners.com/digital_health/how-smart-hospitals-\ncan-improve-healthcare/\
    \ (accessed on 17 January 2022).\n113. Geetanjali, V.; Subramanian, I.; Kannan,\
    \ G.; Prathiba, S.B.; Raja, G. IoTexpert: Interconnection, interoperability and\
    \ integration\nof IoT platforms. In Proceedings of the 2019 11th International\
    \ Conference on Advanced Computing (IcoAC), Chennai, India,\n18–20 December 2019;\
    \ pp. 212–219. [CrossRef]\n114. Kubler, S.; Robert, J.; Hefnawy, A.; Främling,\
    \ K.; Cheriﬁ, C.; Bouras, A. Open IoT ecosystem for sporting event management.\
    \ IEEE\nAccess 2017, 5, 7064–7079. [CrossRef]\n115. Bhattacharya, S.; Somayaji,\
    \ S.R.K.; Gadekallu, T.R.; Alazab, M.; Maddikunta, P.K.R. A review on deep learning\
    \ for future smart\ncities. Internet Technol. Lett. 2020, 5, e187. [CrossRef]\n\
    116. Robert, J.; Kubler, S.; Traon, Y.L.; Främling, K. O-MI/O-DF standards as\
    \ interoperability enablers for Industrial Internet: A\nperformance analysis.\
    \ In Proceedings of the 42nd Annual Conference of the IEEE Industrial Electronics\
    \ Society (IECON), Florence,\nItaly, 23–26 October 2016; pp. 4908–4915. [CrossRef]\n"
  inline_citation: '>'
  journal: Applied sciences (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/2076-3417/12/3/1607/pdf?version=1643877067
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'IoT-Enabled Smart Cities: A Review of Concepts, Frameworks and Key Technologies'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/rs13214387
  analysis: '>'
  authors:
  - Jia Liu
  - Jianjian Xiang
  - Yongjun Jin
  - Renhua Liu
  - Jining Yan
  - Lizhe Wang
  citation_count: 55
  full_citation: '>'
  full_text: ">\nremote sensing  \nReview\nBoost Precision Agriculture with Unmanned\
    \ Aerial Vehicle\nRemote Sensing and Edge Intelligence: A Survey\nJia Liu *, Jianjian\
    \ Xiang, Yongjun Jin, Renhua Liu, Jining Yan and Lizhe Wang\n\x01\x02\x03\x01\x04\
    \x05\x06\a\b\x01\n\x01\x02\x03\x04\x05\x06\a\nCitation: Liu, J.; Xiang, J.; Jin,\
    \ Y.; Liu,\nR.; Yan, J.; Wang, L. Boost Precision\nAgriculture with Unmanned Aerial\n\
    Vehicle Remote Sensing and Edge\nIntelligence: A Survey. Remote Sens.\n2021, 13,\
    \ 4387. https://doi.org/\n10.3390/rs13214387\nAcademic Editors: Prem Prakash\n\
    Jayaraman and Abdul M. Mouazen\nReceived: 28 August 2021\nAccepted: 25 October\
    \ 2021\nPublished: 30 October 2021\nPublisher’s Note: MDPI stays neutral\nwith\
    \ regard to jurisdictional claims in\npublished maps and institutional afﬁl-\n\
    iations.\nCopyright: © 2021 by the authors.\nLicensee MDPI, Basel, Switzerland.\n\
    This article is an open access article\ndistributed\nunder\nthe\nterms\nand\n\
    conditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n\
    4.0/).\nSchool of Computer Science, China University of Geosciences, Wuhan 430078,\
    \ China;\nxiangjianjian@cug.edu.cn (J.X.); jinyongjun@cug.edu.cn (Y.J.); liurenhua@cug.edu.cn\
    \ (R.L.);\nyanjn@cug.edu.cn (J.Y.); lizhe.wang@foxmail.com (L.W.)\n* Correspondence:\
    \ liujia@cug.edu.cn\nAbstract: In recent years unmanned aerial vehicles (UAVs)\
    \ have emerged as a popular and cost-\neffective technology to capture high spatial\
    \ and temporal resolution remote sensing (RS) images for a\nwide range of precision\
    \ agriculture applications, which can help reduce costs and environmental\nimpacts\
    \ by providing detailed agricultural information to optimize ﬁeld practices. Furthermore,\n\
    deep learning (DL) has been successfully applied in agricultural applications\
    \ such as weed detection,\ncrop pest and disease detection, etc. as an intelligent\
    \ tool. However, most DL-based methods place\nhigh computation, memory and network\
    \ demands on resources. Cloud computing can increase\nprocessing efﬁciency with\
    \ high scalability and low cost, but results in high latency and great pressure\n\
    on the network bandwidth. The emerging of edge intelligence, although still in\
    \ the early stages,\nprovides a promising solution for artiﬁcial intelligence\
    \ (AI) applications on intelligent edge devices\nat the edge of the network close\
    \ to data sources. These devices are with built-in processors enabling\nonboard\
    \ analytics or AI (e.g., UAVs and Internet of Things gateways). Therefore, in\
    \ this paper,\na comprehensive survey on the latest developments of precision\
    \ agriculture with UAV RS and\nedge intelligence is conducted for the ﬁrst time.\
    \ The major insights observed are as follows: (a) in\nterms of UAV systems, small\
    \ or light, ﬁxed-wing or industrial rotor-wing UAVs are widely used in\nprecision\
    \ agriculture; (b) sensors on UAVs can provide multi-source datasets, and there\
    \ are only a\nfew public UAV dataset for intelligent precision agriculture, mainly\
    \ from RGB sensors and a few\nfrom multispectral and hyperspectral sensors; (c)\
    \ DL-based UAV RS methods can be categorized\ninto classiﬁcation, object detection\
    \ and segmentation tasks, and convolutional neural network and\nrecurrent neural\
    \ network are the mostly common used network architectures; (d) cloud computing\
    \ is\na common solution to UAV RS data processing, while edge computing brings\
    \ the computing close to\ndata sources; (e) edge intelligence is the convergence\
    \ of artiﬁcial intelligence and edge computing,\nin which model compression especially\
    \ parameter pruning and quantization is the most important\nand widely used technique\
    \ at present, and typical edge resources include central processing units,\ngraphics\
    \ processing units and ﬁeld programmable gate arrays.\nKeywords: precision agriculture;\
    \ remote sensing; unmanned aerial vehicles; deep learning; high\nperformance;\
    \ mobile devices; edge intelligence; model compression\n1. Introduction\nAgriculture\
    \ is the foundation of society and national economies, and one of the most\nimportant\
    \ industries in China. Acquiring timely and reliable agriculture information such\n\
    as crop growth and yields is crucial to the establishment of related policies\
    \ and plans for\nfood security, poverty reduction and sustainable development.\
    \ In recent years precision\nagriculture (PA) has developed rapidly, which refers\
    \ to a management strategy that gathers,\nprocesses and analyzes temporal, spatial\
    \ and individual data in agricultural production.\nThis data is combined with\
    \ other information to support management decisions with\nestimated variability\
    \ for improved resource use efﬁciency, productivity, quality, proﬁtability\nRemote\
    \ Sens. 2021, 13, 4387. https://doi.org/10.3390/rs13214387\nhttps://www.mdpi.com/journal/remotesensing\n\
    Remote Sens. 2021, 13, 4387\n2 of 31\nand sustainability of agricultural production\
    \ according to the International Society of\nPrecision Agriculture (ISPA) [1,2].\
    \ It can help to reduce costs and environmental impacts\nby providing farmers\
    \ with detailed spatial information to optimize ﬁeld practices [3,4].\nThe traditional\
    \ way to get the prerequisite knowledge for PA depends on labor-\nintensive and\
    \ subjective investigation, which consumes a large amount of human time and\n\
    ﬁnancial resources. Since remote sensing (RS) allows for a high frequency of information\n\
    gathering without making physical contact at a low cost [5], it has been widely\
    \ used\nas a powerful tool for rapid, accurate and dynamic agriculture applications\
    \ [6,7]. RS\ndata are mainly collected by three kinds of platforms, i.e., spaceborne,\
    \ airborne, and\nground-based [5]. Spaceborne includes satellite RS and can provide\
    \ large-scale spatial\ncoverage, but can suffer from ﬁxed and long revisit periods\
    \ and cloud occlusion, limiting\nits application for ﬁne-scale PA [8,9]. Additionally,\
    \ relatively low spatial and temporal\nresolution and high equipment costs become\
    \ critical bottlenecks [10]. Ground-based remote\nsensors (onboard vehicles, ships,\
    \ ﬁxed or movable elevated platforms) are suitable for\nsmall scale monitoring.\
    \ In comparison, airborne platforms can collect data with high\nspatial resolution\
    \ and ﬂexibility in terms of ﬂight conﬁgurations such as observation\nangles,\
    \ ﬂight routes [7]. An unmanned aerial vehicle (UAV) is a powered, aerial vehicle\n\
    without any human operator, which can ﬂy autonomously or be controlled remotely\
    \ with\nvarious payloads [11]. Due to their advantages in terms of ﬂexible data\
    \ acquisition and\nhigh spatial resolution [12], UAVs are quickly evolving and\
    \ provide a powerful technical\napproach for many applications in PA, for example,\
    \ crop state mapping [13,14], crop\nyield prediction [15,16], diseases detection\
    \ [17,18], weed management [19,20] rapidly\nand nondestructively.\nCompared with\
    \ traditional mechanism-based methods, machine learning (ML) meth-\nods have long\
    \ been applied in a variety of agriculture applications to discover patterns\n\
    and correlations due to their capability to address linear and non-linear issues\
    \ from\nlarge numbers of inputs [7,21]. For example, Su et al. [22] proposed a\
    \ support vector\nmachine-based crop model for large-scale simulation of rice\
    \ production in China, and\nEveringham et al. [23] utilize a random forest model\
    \ to predict sugarcane yield with sim-\nulated and observed variables as inputs.\
    \ An ML pipeline typically consists of feature\nextraction and a classiﬁcation\
    \ or regression module for prediction, and its performance\nheavily relies on\
    \ the handcrafted feature extraction techniques [24,25]. In the past years,\n\
    with the development of computing and storage capability, deep learning (DL),\
    \ which\nis composed of “deep” layers to learn the representation of data with\
    \ multiple levels of\nabstraction and discovers intricate structure in large datasets\
    \ by using the backpropagation\nalgorithm [26], has improved the state-of-the-art\
    \ in a variety of tasks. This includes com-\nputer vision, natural language processing,\
    \ speech recognition etc. In the RS community,\neven for typical PA applications\
    \ with UAV data (e.g., weed detection [27], crops and plants\ncounting [28], land\
    \ cover and crop type classiﬁcation [29]), DL has emerged as an intelligent\n\
    and robust tool [30].\nDL has achieved success with high accuracy for PA, for\
    \ instance, the DL model in [27]\nprovides much better weed detection results\
    \ than ML methods in the bean ﬁeld with a\nperformance gain greater than 20%,\
    \ and more PA applications boosted by DL have shown\nsimilar promising superiority.\
    \ However, the successful implementation of DL comes at\nthe cost of high computational,\
    \ memory and network requirements at both the training\nand inference stages [31].\
    \ For example, the VGG-16, an early classic convolutional neural\nnetwork (CNN)\
    \ used for classiﬁcation contains around 140 million parameters, consumes\nover\
    \ 500MB of memory and has 15 billion ﬂoating point of operations (FLOPs) [32].\
    \ It is\nchallenging to deploy deep neural network models in scenarios onboard\
    \ mobile airborne\nand spaceborne platforms with limited computation, storage,\
    \ power consumption, and\nbandwidth resources [33]. To meet the computational\
    \ requirements of DL, a common way\nis to utilize cloud computing, where data\
    \ are moved from the data sources located at the\nnetwork edge such as smartphones\
    \ and internet-of-things (IoT) sensors to the cloud [31].\nHowever, the cloud-computing\
    \ mode might put great pressure on network bandwidth\nRemote Sens. 2021, 13, 4387\n\
    3 of 31\nand cause signiﬁcant latency when moving massive data across the wide\
    \ area network\n(WAN) [34]. Besides the above, privacy leakage is also a major\
    \ concern [35]. The emerging\nof edge computing fulﬁlls the above-mentioned issues.\n\
    According to the Edge Computing Consortium (ECC), edge computing is a distributed\n\
    open platform at the network edge, close to the things or data sources, and integrating\
    \ the\ncapabilities of networks, storage and applications [36]. In this new computing\
    \ paradigm,\ndata does not need to be sent to a Cloud or other remote centralized\
    \ or distributed systems\nfor further processing. The combination of edge computing\
    \ and artiﬁcial intelligence (AI)\nyields edge intelligence, the next stage of\
    \ edge computing. It aims to use AI technology to\nempower the edge. Edge is a\
    \ relative concept, which refers to any resource, storage, and\nnetwork resource\
    \ from the data source to the cloud-computing center. The resources on\nthis path\
    \ can be regarded as a continuous system. Currently, there is no formal deﬁnition\n\
    of edge intelligence internationally. Most organizations refer to edge intelligence\
    \ as the\nparadigm of running AI algorithms locally on an end device, with data\
    \ created on the\ndevice [34]. It enables the deployment of AI algorithms on intelligent\
    \ edge devices with\nbuilt-in processors for onboard analytics or AI (e.g., UAVs,\
    \ sensors and IoT gateways)\nthat are closer to the data sources [34,37]. However,\
    \ more researchers consider that edge\nintelligence should not be restricted to\
    \ running AI models on edge devices or servers. A\nbroader deﬁnition divides edge\
    \ intelligence into AI for edge (intelligence-enabled edge\ncomputing) and AI\
    \ on edge. The former tries to provide optimal solutions to key problems\nin edge\
    \ computing with AI technologies, while the latter focuses on the way to carry\
    \ out\nthe entire process of building AI models, i.e., model training and inference,\
    \ on the edge [38].\nZhou et al. further present a deﬁnition of six levels to\
    \ fully exploit the available data\nand resources across end devices, edge nodes,\
    \ and cloud datacenters, thus optimizing the\nperformance of training and inferencing\
    \ an AI model [34].\nThere already exist many reviews for agriculture with UAVs\
    \ [2,8,9,39–41] and\nDL [24,42–44]. However, the research and practice of edge\
    \ intelligence are still in an\nearly stage, and to the best of our knowledge,\
    \ there is a literature gap to review the ad-\nvances combining edge intelligence\
    \ and UAV RS in the PA area. Therefore, in this paper we\nattempt to provide an\
    \ in-depth and comprehensive survey on the latest development of PA\nwith UAV\
    \ RS and edge intelligence. The main contributions of this paper are as follows:\n\
    1. The most relevant DL techniques and their latest implementations in PA are\n\
    reviewed in detail. Speciﬁcally, this paper gives a comprehensive publicly available\
    \ UAV-\nbased RS datasets for intelligent agriculture, which attempts to facilitate\
    \ the validation of\nDL-based methods for the community.\n2. The cloud computing\
    \ and edge computing paradigms for the UAV RS in PA are\ndiscussed in this paper.\n\
    3. The relevant edge intelligence techniques are thoroughly reviewed and analyzed\n\
    for UAV RS in PA for the ﬁrst time to the best of our knowledge. Particularly,\
    \ this paper\ngives a compilation of the UAV intelligent edge devices and the\
    \ latest development of edge\ninference with model compression in detail.\nThe\
    \ remainder of this paper is structured as follows. Section 2 presents the application\n\
    of UAV RS technology in PA, including the relevant fundamentals of UAV systems,\
    \ RS\nsensors and typical applications in PA. Section 3 gives the DL methods and\
    \ publicly\navailable datasets used in PA. Section 4 emphatically analyzes the\
    \ edge intelligence for\nUAV RS in PA, including the cloud and edge computing\
    \ paradigms, basic concepts and\nmajor components of edge intelligence, network\
    \ model design and edge resources. Future\ndirections are given in Section 5 and\
    \ conclusions are drawn in Section 6.\nRemote Sens. 2021, 13, 4387\n4 of 31\n\
    2. UAV Remote Sensing in Precision Agriculture\n2.1. UAV Systems and Sensors for\
    \ Precision Agriculture\nUAV systems differ in size, weight, load, power, endurance\
    \ time, purpose etc., and\nthere are many kinds of taxonomic approaches. According\
    \ to the Civil Aviation Adminis-\ntration of China, UAVs mainly serve for military\
    \ and civilian ﬁelds. Agriculture belongs\nto the latter. In terms of the operational\
    \ risk, mainly including the metrics of size, the\nweight of UAVs and the ability\
    \ to carry payloads when performing missions, civilian UAVs\ncan be divided into\
    \ mini UAV, light UAV, small UAV, medium UAV, and large UAV [45].\nTheir major\
    \ characteristics are listed in Table 1. In addition, according to the aerodynamic\n\
    features, UAVs are usually classiﬁed into ﬁxed-wing, rotary-wing, ﬂapping-wing\
    \ and\nhybrid UAVs shown in Table 2 [9,46,47]. For ﬁxed-wing UAVs, the main wing\
    \ surface that\ngenerates lift is ﬁxed relative to the fuselage, and the power\
    \ device generates the forward\nforce. Rotary-wing UAVs possess power devices\
    \ and rotor blades that are rotating relative\nto the fuselage for generating\
    \ lift during ﬂight, and further mainly include unmanned\nhelicopters and multi-rotor\
    \ UAVs, for instance, tricopters, quadcopters, hexacopters and\noctocopters, which\
    \ can take off, land and hover vertically. Flapping-wing UAVs obtain\nlift and\
    \ power by ﬂapping wings up and down like birds and insects, and are suitable\
    \ for\nsmall, light and mini UAVs. The hybrid layout UAVs consists of a combination\
    \ of basic\nlayout types, mainly including tilt-rotor UAVs and rotor/ﬁxed UAVs.\
    \ Figure 1 shows the\nexamples of typical UAVs.\nTable 1. Categories and characteristics\
    \ of UAVs according to operational risks [45].\nCategory\nMajor Metrics\nmini\
    \ UAV\nempty weight < 0.25 kg, ﬂight altitude ≤ 50 m, max speed ≤ 40 km/h\nlight\
    \ UAV\nempty weight ≤ 4 kg, max take-off weight ≤ 7 kg, max speed ≤ 100 km/h\n\
    small UAV\nempty weight ≤ 15 kg, or max take-off weight ≤ 25 kg\nmedium UAV\n\
    empty weight > 15 kg, 25 kg < max take-off weight ≤ 150 kg\nlarge UAV\nmax take-off\
    \ weight > 150 kg\nTable 2. Categories and characteristics of UAVs according to\
    \ aerodynamic features [9,46,47].\nCategory\nAdvantages\nDrawbacks\nﬁxed wing\n\
    long range and endurance, large load, fast\nﬂight speed\nhigh requirements for\
    \ take-off and\nlanding, poor mobility, no\nhovering capability\nrotary wing\n\
    unmanned helicopter\nlong range, large load, hovering capability, low\nrequirement\
    \ for lifting and landing\nslow speed, difﬁculty in operating,\nhigh maintenance\
    \ cost\nmulti-rotor UAVs\nsmall in size, ﬂexible, hovering capability, almost\n\
    no requirement for lifting and landing\nshort range and endurance, slow\nspeed,\
    \ small load\nﬂapping-wing\nﬂexible, small in size\nslow speed, single drive mode\n\
    hybrid\nﬂexibility in vertical take-off and landing, fast\nspeed, long range\n\
    complex structure, high\nmaintenance cost\nIn the agriculture RS ﬁeld concerned\
    \ in this paper, UAVs used are less than 116 kg\nin general, and most belong to\
    \ the “small” (≤15 kg) or “light” (≤7 kg) categories, and\nﬂy lower than 1 km,\
    \ i.e., at a low altitude of 100 to 1000 m or ultra-low altitude of 1 to\n100\
    \ m [9,45]. On the other hand, ﬂapping-wing UAVs and hybrid UAVs are not often\n\
    used; ﬁxed-wing UAVs and industrial rotor-wing UAVs are the mainstream currently.\n\
    Speciﬁcally, since multi-rotor UAVs are more cost-effective than the other types,\
    \ and are\ngenerally more stable than unmanned helicopters during ﬂight, they\
    \ are the most widely\nused in the PA ﬁeld [8].\nBesides, UAVs can be equipped\
    \ with a variety of payloads for different purposes.\nTo capture agriculture information,\
    \ UAVs used in PA are generally with remote sensors\nRemote Sens. 2021, 13, 4387\n\
    5 of 31\nincluding RGB imaging, multispectral and hyperspectral imaging sensors,\
    \ thermal infrared\nsensors, light detection and ranging (LiDAR), and synthetic\
    \ aperture radar (SAR) [9,48,49].\nTheir major characteristics and applications\
    \ in PA are summarized in Table 3.\nRemote Sens. 2021, 13, x FOR PEER REVIEW \n\
    5 of 35\n \n \n \n(a) \n(b) \n \n \n(c) \n(d) \nFigure 1. Examples of typical\
    \ UAVs: (a) A fixed-wing UAV “AgEagle RX60” from AgEagle (https://ageagle.com/agricul-\n\
    ture/#); (b) An unmanned helicopter “Shuixing No.1” from Hanhe (http://www.hanhe-aviation.com/products2.html);\
    \ (c) \nA flapping-wing UAV from the Drone Bird Company “AVES Series” (https://www.thedronebird.com/aves/);\
    \ (d) A hybrid \nUAV “Linglong” from Northwestern Polytechnical University (https://wurenji.nwpu.edu.cn/cpyf/cpjj1/xzjyfj_ll_.htm).\
    \ \nIn the agriculture RS field concerned in this paper, UAVs used are less than\
    \ 116 kg\nin general, and most belong to the “small” ( ≤ 15 kg) or “light” ( ≤\
    \ 7 kg) categories, and fly\nlower than 1 km, i.e., at a low altitude of 100 to\
    \ 1000 m or ultra-low altitude of 1 to 100 m\n[9,45]. On the other hand, flapping-wing\
    \ UAVs and hybrid UAVs are not often used;\nfixed-wing UAVs and industrial rotor-wing\
    \ UAVs are the mainstream currently. Specifi-\ncally, since multi-rotor UAVs are\
    \ more cost-effective than the other types, and are gener-\nally more stable than\
    \ unmanned helicopters during flight, they are the most widely used\nin the PA\
    \ field [8]. \nBesides, UAVs can be equipped with a variety of payloads for different\
    \ purposes. To\ncapture agriculture information, UAVs used in PA are generally\
    \ with remote sensors in-\ncluding RGB imaging, multispectral and hyperspectral\
    \ imaging sensors, thermal infrared\nsensors, light detection and ranging (LiDAR),\
    \ and synthetic aperture radar (SAR)\n[9,48,49]. Their major characteristics and\
    \ applications in PA are summarized in Table 3. \nTable 3. The major characteristics\
    \ and applications of sensors mounted on UAVs in PA. \nSensors \nMajor Characteristics\
    \ \nTypical Applications \nRGB imaging \nobtain images in visible spectrum, with\
    \ \nadvantages of high-resolution, light-\nweight, low-cost, easy-to-use \ncrop\
    \ recognition, plants defects and \ngreenness monitoring [8,49–51] \nMultispectral\
    \ imager \nhigh spatial resolution at centimeter-\nlevel RS data with multiple\
    \ bands from \nvisible to near infrared \nleaf area index (LAI) estimation [52],\
    \ \ncrop diseases and weeds monitoring \nand mapping [18,53], nutrient defi-\n\
    ciency diagnosis [54] \nHyperspectral imager \nprovide a large continuous narrow\
    \ \nwavebands covering from ultraviolet \nto longwave infrared spectra \ncrop\
    \ species classification with similar \nspectral features [55], soil moisture\
    \ \ncontent monitoring [56], crop yield es-\ntimation [57] \nThermal \nsensors\
    \ \nuse the information at the emitted radi-\nation in the thermal infrared range\
    \ of \nelectromagnetic spectrum [58], and \nprovide measurements of energy \n\
    monitoring of water stress, crop dis-\neases and plant phenotyping, estima-\n\
    tion of crop yield [2], support decision \nFigure 1.\nExamples of typical UAVs:\n\
    (a) A ﬁxed-wing UAV “AgEagle RX60” from AgEa-\ngle (https://ageagle.com/agriculture/#\
    \ (accessed on 17 October 2021)); (b) An unmanned heli-\ncopter “Shuixing No.1”\
    \ from Hanhe (http://www.hanhe-aviation.com/products2.html (accessed\non 17 October\
    \ 2021)); (c) A ﬂapping-wing UAV from the Drone Bird Company “AVES Series” (https:\n\
    //www.thedronebird.com/aves/ (accessed on 17 October 2021)); (d) A hybrid UAV\
    \ “Linglong” from\nNorthwestern Polytechnical University (https://wurenji.nwpu.edu.cn/cpyf/cpjj1/xzjyfj_ll_.htm\n\
    (accessed on 17 October 2021)).\nTable 3. The major characteristics and applications\
    \ of sensors mounted on UAVs in PA.\nSensors\nMajor Characteristics\nTypical Applications\n\
    RGB imaging\nobtain images in visible spectrum, with advantages\nof high-resolution,\
    \ lightweight, low-cost, easy-to-use\ncrop recognition, plants defects and greenness\n\
    monitoring [8,49–51]\nMultispectral imager\nhigh spatial resolution at centimeter-level\
    \ RS data\nwith multiple bands from visible to near infrared\nleaf area index\
    \ (LAI) estimation [52], crop\ndiseases and weeds monitoring and\nmapping [18,53],\
    \ nutrient deﬁciency\ndiagnosis [54]\nHyperspectral imager\nprovide a large continuous\
    \ narrow wavebands\ncovering from ultraviolet to longwave\ninfrared spectra\n\
    crop species classiﬁcation with similar spectral\nfeatures [55], soil moisture\
    \ content\nmonitoring [56], crop yield estimation [57]\nThermal sensors\nuse the\
    \ information at the emitted radiation in the\nthermal infrared range of electromagnetic\n\
    spectrum [58], and provide measurements of energy\nﬂuxes and temperatures from\
    \ the earth’s surface [59]\nmonitoring of water stress, crop diseases and\nplant\
    \ phenotyping, estimation of crop yield [2],\nsupport decision making for irrigation\n\
    scheduling and harvesting operations [60]\nLiDAR\nuse laser as a radiation source,\
    \ and works at the\nwavelength of infrared to ultraviolet spectrum\ngenerally,\
    \ with advantages of narrow beams, wide\nspeed measurement ranges, and strong\
    \ resistance to\nelectromagnetic and clutter interference [61]\ndetect individual\
    \ crops [13], measure canopy\nstructure and height [62], predict biomass and\n\
    leaf nitrogen content [63]\nSAR\nprovide high-resolution, multi-polarization,\n\
    multi-frequency images in all weather and all day\ncrop identiﬁcation and land\
    \ cover mapping [64],\ncrop and cropland parameter extraction such as\nsoil salt\
    \ and moisture [65], crop yield\nestimation [66]\nRemote Sens. 2021, 13, 4387\n\
    6 of 31\n2.2. Application of UAV Remote Sensing in Precision Agriculture\nThe\
    \ major objectives of PA are to increase crop yields, improve product quality,\
    \ make\nefﬁcient use of agrochemical products, save energy and protect the physical\
    \ environment\nagainst pollution [47]. With the advantages of cost-effective,\
    \ high-resolution imagery [67],\nUAVs have now been commonly used in the PA area,\
    \ mainly for monitoring [12,68–70]\nand spraying [71–73]. For the former, different\
    \ sensors onboard UAVs capture RS data,\nwhich are utilized to identify speciﬁc\
    \ spatial features and time variant information of crop\ncharacteristics; for\
    \ the latter, UAV systems are used to spray accurate amounts of pesticides\nand\
    \ fertilizers, thus to mitigate possible diseases and pests and increase crop\
    \ yields and\nproduct quality [47]. RS provides an effective tool for UAV-based\
    \ PA monitoring, and the\nmost common related applications are as follows.\n•\n\
    Weed detection and mapping: As weeds have been responsible for most agricultural\n\
    yield losses, the utilization of herbicides is important in the growth of crops,\
    \ but the\nunreasonable use will cause a series of environmental problems. To\
    \ fulﬁll precision\nweed management [19,74], UAV RS can help to accurately locate\
    \ weed areas, analyze\nweed types and weed density etc., thus using herbicides\
    \ at ﬁxed points quantitatively\nor applying improved and targeted mechanical\
    \ soil tillage [27]. Weeds detection\nand mapping tries to ﬁnd/map the locations\
    \ of weeds in the obtained UAV RS im-\nages, and is achieved generally based on\
    \ the different spatial distribution [27,75],\nshape [76], spectral signatures\
    \ [53,77–79], or their combinations [80] of weeds com-\npared to normal crops.\
    \ Accordingly, the most important sensors as UAV payload\nare mainly RGB sensors\
    \ [27,76,77,80], multispectral sensors [53,78] and hyperspectral\nsensors [79]\
    \ ADDIN.\n•\nCrop pest and disease detection: Field crops are subjected to the\
    \ attack of various\npests and diseases at stages from sowing to harvest, which\
    \ affects the yield and quality\nof crops and become one of the main limits to\
    \ agricultural production in China. As\nthe main part of pest and disease management,\
    \ early detection of pests and diseases\nfrom UAV RS images allows efﬁcient application\
    \ of pesticides and an early response\nto the production costs and environmental\
    \ impact. Crop pest and disease detection\ntries to locate the possible pest or\
    \ disease infected areas on leaves from observed UAV\nRS images, and the detection\
    \ basis is mainly their spectral difference [81]. To obtain\nmore details of pests\
    \ and diseases on leaves, UAVs are usually with low ﬂight height\nfor observations\
    \ with high spatial or spectral resolution [82–84]. Commonly mounted\nsensors\
    \ are RGB sensors [83,85–87], multispectral sensors [88], infrared sensors [89]\n\
    and hyperspectral sensors [82,84].\n•\nCrop growth monitoring: RS can be used\
    \ to monitor group and individual characteris-\ntics of crop growth, e.g., crop\
    \ seedling condition, growth status and changes. Crop\ngrowth information monitoring\
    \ is fundamental for regulating crop growth, diagnosing\ncrop nutrient deﬁciencies,\
    \ analyzing and predicting crop yield etc., and can provide\ndecision-making basis\
    \ for agricultural policy formulation and food trade. Crop growth\nmonitoring\
    \ is to build a multitemporal crop model to allow for comparison of differ-\n\
    ent phenological stages [90], and UAV provides a good platform for obtaining crop\n\
    information [91]. The crop growth is generally quantiﬁed by several indices, such\n\
    as LAI, leaf dry weight, leaf nitrogen accumulation, etc., in which multiple spectral\n\
    bands are usually needed. As a relatively more comprehensive task, sensors onboard\n\
    UAVs are usually multispectral/hyperspectral ones [91,92] or the combination of\
    \ RGB\nand infrared [93] or LiDAR [63].\n•\nCrop yield estimation: Accurate yield\
    \ estimates are essential for predicting the volume\nof stock needed and organizing\
    \ harvesting operations. RS information can be used as\ninput variables or parameters\
    \ to directly or indirectly reﬂect the inﬂuencing factors in\nthe process of crop\
    \ growth and yield formation, alone or in combination with other\ninformation\
    \ for crop yield estimation. It tries to estimate the crop yield by observing\n\
    the morphological characteristics of crops in a non-destructive way [16]. Similar\
    \ to the\ntask of crop growth monitoring, crop yield estimation also relies on\
    \ multiple spectral\nRemote Sens. 2021, 13, 4387\n7 of 31\nbands for better and\
    \ richer information. Therefore, UAVs are usually equipped with\nmultimodal sensors,\
    \ for example, hyperspectral/multispectral [15,16,94–97], thermal\ninfrared [95],\
    \ and combination with RGB [15,16,94–97] or SAR [66].\n•\nCrop type classiﬁcation:\
    \ Crop type maps are one of the most essential inputs for\nagriculture tasks such\
    \ as crop yield estimation, and accurate crop type identiﬁcation\nis important\
    \ for subsidy control, biodiversity monitoring, soil protection, sustainable\n\
    application of fertilizer etc. There exist practices to explore the discrimination\
    \ of\ndifferent crop types from RS images in complex and heterogeneous environments.\n\
    Crop type classiﬁcation task tries to discriminate different types of crop into\
    \ a map\nbased on the information captured by RS data, and is similar to land\
    \ cover/land\nuse classiﬁcation [98]. According to the demands of different tasks,\
    \ it can be imple-\nmented from different spatial scales. For larger scale classiﬁcation,\
    \ SAR sensors are\nused [64,99,100], and for smaller scale, RGB images from UAVs\
    \ can be utilized [101],\nor with SAR data fused [102].\n3. Deep Learning in Precision\
    \ Agriculture with UAV Remote Sensing\n3.1. Deep Learning Methods in Precision\
    \ Agriculture\nDL is a subset of artiﬁcial neural network (ANN) methods in machine\
    \ learning. DL\nconsists of several connected layers of neurons with activations\
    \ like ANNs, but with\nmore hidden layers and deeper and more complex combinations,\
    \ which is responsible for\nobtaining better learning patterns than a common ANN.\
    \ The concept of DL is proposed in\n2006 by Hinton et al. [103] in which key issues\
    \ for deep ANN training are solved. With\nthe advance of computational capacity\
    \ of computer hardware and the availability of large\namounts of labeled samples,\
    \ the massive training and inference of DL become possible and\nefﬁcient, which\
    \ makes DL outperform traditional ML methods in a variety of applications.\nIn\
    \ the last decade, DL methods have gained increasingly more attention, and become\
    \ the\nde facto mainstream of ML. More fundamental details of DL models such as\
    \ the activation\nfunctions, loss functions, optimizers, basic structures are\
    \ referred to [26].\nAccording to the data type processed and the type of network\
    \ architectures, different\ntypes of DL models are designed and representative\
    \ ones are CNN, recurrent neural\nnetwork (RNN), and generative adversarial network\
    \ (GAN) etc. These three types of\nnetwork architectures are the most widely used\
    \ in agriculture applications, especially for\nthe UAV RS. CNNs are designed to\
    \ deal with grid-like data, such as images, and it is\ntherefore very suitable\
    \ for supervised image processing and computer vision applications.\nIt is usually\
    \ composed of three distinct hierarchical structures, such as convolutional layers,\n\
    pooling layers, and fully connected layers. Typical CNN architectures are AlexNet\
    \ [104],\nGoogleNet [105], and ResNet [106] etc. RNNs, as supervised models, have\
    \ also been\napplied to deal with time-series data via modeling time-related features.\
    \ One typical RNN\narchitecture is long short-term memory with its basic unit\
    \ remembering information from\narbitrary time intervals. Another network architecture\
    \ that is popular and successful in\nrecent years is GAN [107]. A GAN model consists\
    \ of two sub-networks, one is generative\nnetwork and the other is discriminative\
    \ network. Its main idea comes from Zero-Sum\nGame, in which the generative network\
    \ tries to generate samples as vivid as possible and\nthe discriminative network\
    \ tries to discriminate the fake ones and real ones. GANs have\nalso been applied\
    \ to image-to-image translation [108,109], sample augmentation [110,111]\nin the\
    \ ﬁeld of RS.\nIn UAV RS scenarios, most applications utilize images captured\
    \ by cameras as their\ndata inputs, i.e., they are computer vision related tasks.\
    \ In this way, UAV RS tasks in\nPA that uses DL methods (mainly CNN) can be divided\
    \ into three typical and principal\ncomputer vision tasks: classiﬁcation, detection\
    \ and segmentation [112].\n•\nClassiﬁcation tries to predict the presence/absence\
    \ of at least one object of a particular\nobject class in the image, and DL algorithms\
    \ are required to provide a real-valued con-\nﬁdence of the object’s presence.\
    \ Classiﬁcation methods are mainly used to recognize\ncrop diseases [86,113,114],\
    \ weed type [27,115,116], or crop type [117,118].\nRemote Sens. 2021, 13, 4387\n\
    8 of 31\n•\nDetection tasks try to predict the bounding box of each object of\
    \ a particular object\nclass in the image with associated conﬁdence, i.e., answer\
    \ the question “where are\nthe instances in the image, if any?” It means that\
    \ the extracted object information is\nrelatively more precise. Typical applications\
    \ are ﬁnding the crops with pests [119]\nor other diseases [120], locating the\
    \ weeds in the images [121,122], counting the crop\nnumber for yield estimation\
    \ [123–125] or disaster evaluation [126], etc.\n•\nSegmentation is a task that\
    \ predicts the object label (for semantic segmentation) or\ninstance label (for\
    \ instance segmentation) of each pixel in the test image, which can be\nviewed\
    \ as a more precise classiﬁcation for each pixel. It can not only locate objects,\
    \ but\nalso obtain their pixels at a ﬁner-grained level. Therefore, segmentation\
    \ methods are\nusually used to accurately locate features of interest in images.\
    \ Semantic segmentation\ncan help locate crop leaf diseases [127,128], generating\
    \ weed maps [76,78,129], or\nassessing crop growth [130,131] and yields [132],\
    \ while instance segmentation can\ndetect crop and weed plants [133,134], or conduct\
    \ crop seed phenotyping [135] at a\nﬁner level.\nOverall, the three principal\
    \ kinds of computer vision techniques have played a crucial\nrole in UAV-based\
    \ RS for PA and support various typical applications as mentioned in\nSection\
    \ 2.2, mainly including crop pest and disease detection, weed detection and mapping,\n\
    crop growth monitoring and yield estimation, crop type classiﬁcation etc. Table\
    \ 4 shows a\ncompilation of typical examples in PA using DL methods.\n3.2. Dataset\
    \ for Intelligent Precision Agriculture\nThe sensors integrated with a UAV depend\
    \ on the purpose, size, weight, power\nconsumption etc. A number of reviews discuss\
    \ the sensors on UAVs in the PA ﬁeld, and\nto the best of our knowledge, only\
    \ Zhang et al. [158] listed some datasets in agricultural\ndense scenes, but whether\
    \ these datasets can be publicly available are not indicated. Hence,\nin this\
    \ paper we give a compilation of publicly available UAV dataset with labels for\
    \ the\nPA applications together with their descriptions including the platform,\
    \ data type, major\napplications and links in Table 5, which attempt to facilitate\
    \ the development, testing and\ncomparison of relevant DL methods. We also summarized\
    \ the available datasets with\nlabels for related tasks from sensors onboard satellites,\
    \ which may be used to obtain a\npre-trained model.\nRemote Sens. 2021, 13, 4387\n\
    9 of 31\nTable 4. DL-based methods for typical UAV RS applications in PA.\nArea\n\
    Task\nSpeciﬁc Application\nType\nModel\nReference\nCrop pest and disease\ndetection\n\
    Classiﬁcation\nSoybean leaf diseases recognition\nCNN\nInception, VGG19, Xception,\
    \ Resnet-50\n[86]\nClassifying fusarium wilt of radish\nCNN\nVGG-A\n[113]\nDetection\
    \ of helminthosporium leaf blotch disease\nCNN\nCustomize CNN\n[114]\nObject\n\
    detection\nDetection for pine wilt disease\nCNN\nYOLOv4\n[120]\nIdentiﬁcation\
    \ of fruit tree pests\nCNN\nYOLOv3-tiny\n[119]\nRecognition of spraying area\n\
    CNN\nCustomize CNN\n[136]\nSemantic\nsegmentation\nQuantitative phenotyping of\
    \ northern leaf blight\nCNN\nMask R-CNN\n[127]\nVine disease detection\nCNN\n\
    VddNet\n[128]\nField weed density evaluation\nCNN\nModiﬁed U-Net\n[129]\nWeed\
    \ detection and\nmapping\nClassiﬁcation\nMapping of weed species in winter wheat\
    \ crops\nCNN\nModiﬁed Resnet18\n[115]\nWeed detection in line crops\nCNN\nResnet18\n\
    [27]\nMid-to late-season weed detection\nCNN\nMobilenetV2\n[122]\nWeed classiﬁcation\n\
    CNN\nResnet50\n[116]\nDetecting rumex obtusifolius weed plants\nCNN\nAlexNet\n\
    [121]\nObject\ndetection\nMid-to late-season weed detection\nCNN\nSSD, Faster\
    \ R-CNN\n[122]\nSemantic\nsegmentation\nLarge-scale semantic weed mapping\nCNN\n\
    Modiﬁed SegNet\n[78]\nWeed mapping\nCNN\nFCN\n[76]\nReal-time weed mapping\nCNN\n\
    FCN\n[137]\nIdentiﬁcation and grading of maize drought\nCNN\nModiﬁed U-Net\n[138]\n\
    Crop growth\nmonitoring and crop\nyield estimation\nClassiﬁcation\nYield assessment\
    \ of paddy ﬁelds\nCNN\nInception\n[139]\nRice grain yield estimation at the ripening\
    \ stage\nCNN\nAlexNet\n[16]\nIdentiﬁcation of citrus trees\nCNN\nCustomize CNN\n\
    [134]\nCount plants and detect plantation-rows\nCNN\nVGG19\n[140]\nCounting and\
    \ geolocation citrus-trees\nCNN\nVGG16\n[141]\nObject\ndetection\nStrawberry yield\
    \ prediction\nCNN\nFaster R-CNN\n[124]\nYield estimation of citrus fruits\nCNN,\
    \ RNN\nFaster R-CNN\n[123]\nGrowing status observation for oil palm trees\nCNN\n\
    Faster R-CNN\n[142]\nPlant identiﬁcation and counting\nCNN\nFaster R-CNN, YOLO\n\
    [143]\nCrop detection for early-season maize stand count\nCNN\nMask Scoring RCNN\n\
    [144]\nSemantic\nsegmentation\nPredict single boll weight of cotton\nCNN\nFCN\n\
    [132]\nSegmenting purple rapeseed leaves for nitrogen\nstress detection\nCNN\n\
    U-Net\n[131]\nCounting of in situ rice seedlings\nCNN\nModiﬁed vgg16 + customize\n\
    segmentation network\n[145]\nRemote Sens. 2021, 13, 4387\n10 of 31\nTable 4. Cont.\n\
    Area\nTask\nSpeciﬁc Application\nType\nModel\nReference\nCrop type\nclassiﬁcation\n\
    Classiﬁcation\nAutomatic classiﬁcation of trees\nCNN\nGoogLeNet\n[117]\nIdentifying\
    \ heterogeneous crops\nCRF\nSCRF\n[118]\nRice seedling detection\nCNN\nVGG16\n\
    [146]\nObject\ndetection\nAugmenting bale detection\nCNN, GAN\nCycleGAN, Modiﬁed\
    \ YOLOv3\n[147]\nPhenotyping in citrus\nCNN\nYOLOv3\n[148]\nDetection of banana\
    \ plants\nCNN\nCustomize CNN\n[149]\nAutomatic tobacco plant detection\nCNN\n\
    Customize CNN\n[150]\nDetection of maize tassels\nCNN\nTassel region proposals\
    \ based on\nmorphological processing + VGG16\n[151]\nDetection of maize tassels\n\
    CNN\nFaster R-CNN\n[152]\nFrost management in apple orchard\nCNN\nYOLOv4\n[153]\n\
    Semantic\nsegmentation\nSoil and crop segmentation\nCNN\nCustomize CNN\n[154]\n\
    Vegetable mapping\nRNN\nAttention-based RNN\n[155]\nCrop classiﬁcation\nCNN\n\
    SegNet\n[156]\nSemantic segmentation of citrus orchard\nCNN\nFCN, U-Net, SegNet,\
    \ DDCN,\nDeepLabV3+\n[130]\nUAV scouting for rice lodging assessment\nCNN\nEDANet\n\
    [157]\nTable 5. A compilation of publicly available datasets with labels for PA\
    \ applications.\nSource\nDataset\nPlatform\nData Types\nApplications\nDataset\
    \ Links\nUAV\nWHU-HI [159]\nDJI Matrice 600 Pro &\nLeica Aibot X6 V1\nhyperspectral\n\
    Accurate crop classiﬁcation and\nhyperspectral image classiﬁcation\nhttp://rsidea.whu.edu.cn/resource_WHUHi_\n\
    sharing.htm (accessed on 17 October 2021)\nRiceSeedlingDataset [146]\nDJI Phantom\
    \ 4 Pro & DJI\nZenmuse X7\nRGB\nRice object detection, rice\nseedling classiﬁcation\n\
    https:\n//github.com/aipal-nchu/RiceSeedlingDataset\n(accessed on 17 October 2021)\n\
    Purple rapeseed leaves\ndataset [131]\nMatrice 600\nRGB\nSegmentation of purple\
    \ rapeseed leaf\nhttps://ﬁgshare.com/s/e7471d81a1e35d5ab0d1\n(accessed on 17 October\
    \ 2021)\nStewart_NLBimages_2019 [127]\nDJI Matrice 600 s\nRGB\nNorthern Corn Leaf\
    \ Blight detection\nhttps://datacommons.cyverse.org/browse/iplant/\nhome/shared/GoreLab/dataFromPubs/Stewart_\n\
    NLBimages_2019 (accessed on 17 October 2021)\nField images of maize annotated\n\
    with disease symptoms [160]\nDJI Matrice 600 s\nRGB\nCorn disease detection\n\
    https://osf.io/p67rz/ (accessed on 17 October 2021)\nRemote Sens. 2021, 13, 4387\n\
    11 of 31\nTable 5. Cont.\nSource\nDataset\nPlatform\nData Types\nApplications\n\
    Dataset Links\nRSC [145]\nDJI S1000\nRGB\nRice counting\nhttps:\n//github.com/JintaoWU/RiceSeedingCounting\n\
    (accessed on 17 October 2021)\nweedMao [78]\nDJI Inspire2\nmultispectral\nWeed\
    \ mapping\nhttps://github.com/viariasv/weedMap/tree/86bf4\n4d3ecde5470f662ff53693fadc542354343\
    \ (accessed on\n17 October 2021)\noilPalmUav [142]\nSkywalker X8\nRGB\nOil palm\
    \ growth status monitoring\nhttps://github.com/rs-dl/MOPAD (accessed on\n17 October\
    \ 2021)\nSpaceborne or\nairborne platform\nHRSCD [161]\nairplane\nRGB\nLand cover\
    \ mapping, land cover\nchange monitoring\nhttps://ieee-dataport.org/open-access/hrscd-high-\n\
    resolution-semantic-change-detection-dataset\n(accessed on 17 October 2021)\n\
    CSIF [162]\nTERRA & AQUA\nmultispectral\nCalculation of chlorophyll\nﬂuorescence\
    \ parameters\nhttps:\n//ﬁgshare.com/articles/dataset/CSIF/6387494\n(accessed on\
    \ 17 October 2021)\nLEM+ dataset [163]\nSentinel-2\nmultispectral\nCrop classiﬁcation\n\
    https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7\n701344/ (accessed on 17 October\
    \ 2021)\nEYES IN THE SKIES [164]\nIKONOS\nmultispectral\nDrug crop identiﬁcation\n\
    https://ieee-dataport.org/documents/eyes-skies-\ndata-driven-fusion-approach-identifying-drug-\n\
    crops-remote-sensing-images (accessed on\n17 October 2021)\nBreizhCrops [165]\n\
    Sentinel-2\nmultispectral\nCrop classiﬁcation\nhttps://github.com/dl4sits/BreizhCrops\
    \ (accessed on\n17 October 2021)\nSemantic Segmentation of Crop\nType in Ghana\
    \ [166]\nSentinel-2 & PlanetScope\nmultispectral & SAR\n& RGB\nSemantic segmentation\
    \ of\ncrop classiﬁcation\nhttp://registry.mlhub.earth/10.34911/rdnt.ry138p/\n\
    (accessed on 17 October 2021)\nSemantic Segmentation of Crop\nType in South Sudan\
    \ [167]\nSentinel-2 & PlanetScope\nmultispectral & SAR\n& RGB\nSemantic segmentation\
    \ of\ncrop classiﬁcation\nhttp://registry.mlhub.earth/10.34911/rdnt.v6kx6n/\n\
    (accessed on 17 October 2021)\nAgriculturalField-Seg [168]\nairplane\nRGB\nCropland\
    \ segmentation\nhttps://www.aic.uniovi.es/bremeseiro/\nagriculturalﬁeld-seg/ (accessed\
    \ on 17 October 2021)\nEarthExplorer [169]\nSentinel-2 &\nlandsat-8 etc.\nRGB\
    \ &multispectral\n&Lidar\nCentral pivot irrigation system\nidentiﬁcation, paddy\
    \ ﬁeld segmentation,\ncrop classiﬁcation\nhttps://earthexplorer.usgs.gov/ (accessed\
    \ on\n17 October 2021)\nCopernicus Open Access\nHub [170]\nsentinel-1 & sentinel-2\n\
    & sentinel-3\nSAR & multispectral\nNitrate and sediment concentration\nestimation,\
    \ paddy ﬁeld segmentation,\nearly crop classiﬁcation etc.\nhttps://scihub.copernicus.eu/dhus/#/home\n\
    (accessed on 17 October 2021)\nTimeSen2Crop [171]\nSentinel-2\nmultispectral\n\
    Crop classiﬁcation\nhttps://rslab.disi.unitn.it/timesen2crop/ (accessed\non 17\
    \ October 2021)\nRemote Sens. 2021, 13, 4387\n12 of 31\n4. Edge Intelligence for\
    \ UAV RS in Precision Agriculture\n4.1. Cloud and Edge Computing for UAVs\n4.1.1.\
    \ Cloud Computing Paradigm for UAVs\nCloud computing is a computing paradigm that\
    \ provides end-users with infras-\ntructure, platforms, software and other on-demand\
    \ shared services through integrating\nlarge-scale and scalable computing, storage,\
    \ data, applications and other distributed com-\nputing resources over an Internet\
    \ connection [172,173]. The main characteristic of cloud\ncomputing is the change\
    \ in the way resources are used. End-users normally run applica-\ntions on their\
    \ end-devices while the core service and processing are performed on cloud\nservers.\
    \ At the same time, end-users do not need to master the corresponding technology\n\
    or operation skills for device maintenance, but only focus on the required services.\
    \ It\nimproves service quality while reducing operation and maintenance costs.\
    \ The key services\nthat cloud computing offers include infrastructure as a service\
    \ (IAAS), platform as a service\n(PAAS) and software as a service (SAAS) [174].\
    \ The cloud-computing paradigm provides\nthe major following advantages:\n•\n\
    The number of servers in the cloud is huge, providing users with powerful computing\n\
    and storage resources for massive UAV RS data processing.\n•\nCloud computing\
    \ supports users to obtain services at any location from various\nterminals such\
    \ as a laptop or a phone through virtualization.\n•\nCloud computing is a distributed\
    \ computing architecture, and issues such as single-\npoint errors are inevitable.\
    \ The fault-tolerant mechanisms such as copy strategies\nensure high reliability\
    \ for various processing and analysis services.\n•\nCloud centers can dynamically\
    \ allocate or release resources according to the needs of\nspeciﬁc users, and\
    \ can meet the dynamic scale growth requirements of applications\nand users. It\
    \ beneﬁts from the scalability of cloud computing.\nThere exist researches to\
    \ construct cloud-based systems for UAV RS. Jeong et al. [175]\nproposes a UAV\
    \ control system that performs real-time image processing in a cloud system\n\
    and controls a UAV according to these computed results, wherein the UAV contains\
    \ the\nminimal essential control function and shares data with the cloud server\
    \ via WiFi. In [176],\na cloud-based environment for generating yield estimation\
    \ maps from apple orchards is\npresented using UAV images. The DL model for apple\
    \ detection is trained and veriﬁed\nofﬂine in the cloud service of Google Colab,\
    \ along with the aid of GIS tools. Similarly,\nAmpatzidis et al. [143] developed\
    \ a cloud and AI based application, i.e., Agroview to accu-\nrately and rapidly\
    \ process, analyze and visualize data collected from UAVs. Agroview uses\nthe\
    \ Amazon Web Service (AWS) that provides highly reliable and scalable infrastructure\
    \ for\ndeploying cloud-based applications, a main application control machine\
    \ as user interface,\none instance for central processing units (CPU) intensive\
    \ usage like data stitching, and one\ninstance for graphics processing units (GPU)\
    \ intensive usage like tree detection algorithm.\nCurrent cloud-based applications\
    \ generally follow the pipeline as shown in Figure 2a.\nAccording to the pattern\
    \ of cloud computing, it suffers from the following disadvan-\ntages [177]. (a)\
    \ With the growing quantity of data generated at the edge, the speed of\ndata\
    \ transportation through network is becoming the bottleneck for the cloud-computing\n\
    paradigm. (b) The number of sensors at the edge of the network is increasing dramatically\n\
    and data produced will be enormous, making conventional cloud computing not efﬁcient\n\
    enough to handle all these data. (c) In the cloud-computing paradigm, the end-devices\n\
    at the edge usually play as a data consumer. The change from data consumer to\
    \ data\nproducer/consumer requires more function placement at the edge.\nRemote\
    \ Sens. 2021, 13, 4387\n13 of 31\n \nvantages [177]. (a) With the growing quantity\
    \ of data generated at the edge, the speed of \ndata transportation through network\
    \ is becoming the bottleneck for the cloud-computing \nparadigm. (b) The number\
    \ of sensors at the edge of the network is increasing dramatically \nand data\
    \ produced will be enormous, making conventional cloud computing not efficient\
    \ \nenough to handle all these data. (c) In the cloud-computing paradigm, the\
    \ end-devices at \nthe edge usually play as a data consumer. The change from data\
    \ consumer to data pro-\nducer/consumer requires more function placement at the\
    \ edge. \n \n(a) \ne Sens. 2021, 13, x FOR PEER REVIEW \n14 of 35 \n \n(b) \n\
    Figure 2. Cloud computing paradigm and edge computing paradigm for UAV RS. \n\
    4.1.2. Edge Computing Paradigm for UAVs \nEdge computing fulfills the above-mentioned\
    \ disadvantages by bringing the compu-\nting and storage resources to the edge\
    \ of the network, which is close to mobile devices or \nsensors [177]. In the\
    \ edge computing paradigm, the edge can perform computing offload-\ning, data\
    \ storage, caching and processing, as well as distribute request and delivery\
    \ ser-\nvice from cloud to end-users. In recent years, edge computing has attracted\
    \ tremendous \nattention for its low latency, mobility, proximity to the end-users\
    \ and location awareness, \ncompared to the cloud computing paradigm [137,172,178]\
    \ as shown in Figure 2 (b). Com-\npared with cloud computing, edge computing has\
    \ the following characteristics: \n• \nWith the rapid development of IoT, devices\
    \ around the world generate massive data, \nbut only a few are critical and most\
    \ are temporary, which do not require long-term \nstorage. A large amount of temporary\
    \ data are processed at the edge of the network, \nthereby reducing the pressure\
    \ on network bandwidth and data centers. \n• \nAlthough cloud computing can provide\
    \ services for mobile devices to make up for \ntheir lack of computing, storage,\
    \ power resources, the network transmission speed is \nlimited by the development\
    \ of communication technology, and there are issues such \nas unstable links and\
    \ routing in a complex network environment. These factors can \ncause high latency,\
    \ excessive jitter and slow data transmission speed, thus reducing \nthe response\
    \ of cloud services. Edge computing provides services near users, which \ncan\
    \ enhance the responsiveness of services. \n• \nEdge computing provides infrastructures\
    \ for the storage and use of critical data and \nimproves data security. \nFor\
    \ UAV-based RS applications in PA, edge computing is ideal for online tasks that\
    \ \nrequire the above promising features. There are ways to avoid massive data\
    \ from trans-\nferring to the cloud. The first one is to implement a UAV on-board\
    \ real-time processing \nplatform and delivery only the key information to the\
    \ network, and the other one is to \ndeploy a local ground station for UAV information\
    \ processing. \nAs the computing and storage resources are quite limited, the\
    \ optimization of com-\nputing workflow and algorithms are therefore required.\
    \ For example, Li et al. [120] devel-\noped an airborne edge computing system\
    \ for pine wilt disease detection of coniferous \nforests. The images captured\
    \ by an onboard camera are directly passed to the edge com-\nputing module in\
    \ which the lightweight YOLO model is implemented due to the limited \nprocessing\
    \ and storage resources. Similarly, Deng et al. [137] used a lightweight segmen-\n\
    tation model for real-time weed mapping on a NIVIDA Jetson TX board. Camargo et\
    \ al. \n[115] specially optimized ResNet model and changed it from 32-bit to 16-bit\
    \ to reduce \ncomputing on an NVIDIA Jetson AGX Xavier embedded system. Many researchers\
    \ \n[179,180] also exploited the acceleration of traditional image processing\
    \ algorithms for \nvarious RS data types on UAV platforms\nFigure 2. Cloud computing\
    \ paradigm and edge computing paradigm for UAV RS. (a) Cloud computing paradigm;\
    \ (b) Edge\ncomputing paradigm.\n4.1.2. Edge Computing Paradigm for UAVs\nEdge\
    \ computing fulﬁlls the above-mentioned disadvantages by bringing the com-\nputing\
    \ and storage resources to the edge of the network, which is close to mobile devices\n\
    or sensors [177]. In the edge computing paradigm, the edge can perform computing\
    \ of-\nﬂoading, data storage, caching and processing, as well as distribute request\
    \ and delivery\nservice from cloud to end-users. In recent years, edge computing\
    \ has attracted tremendous\nattention for its low latency, mobility, proximity\
    \ to the end-users and location aware-\nness, compared to the cloud computing\
    \ paradigm [137,172,178] as shown in Figure 2b.\nCompared with cloud computing,\
    \ edge computing has the following characteristics:\n•\nWith the rapid development\
    \ of IoT, devices around the world generate massive data,\nbut only a few are\
    \ critical and most are temporary, which do not require long-term\nstorage. A\
    \ large amount of temporary data are processed at the edge of the network,\nthereby\
    \ reducing the pressure on network bandwidth and data centers.\n•\nAlthough cloud\
    \ computing can provide services for mobile devices to make up for\ntheir lack\
    \ of computing, storage, power resources, the network transmission speed is\n\
    limited by the development of communication technology, and there are issues such\n\
    as unstable links and routing in a complex network environment. These factors\
    \ can\ncause high latency, excessive jitter and slow data transmission speed,\
    \ thus reducing\nthe response of cloud services. Edge computing provides services\
    \ near users, which\ncan enhance the responsiveness of services.\n•\nEdge computing\
    \ provides infrastructures for the storage and use of critical data and\nimproves\
    \ data security.\nFor UAV-based RS applications in PA, edge computing is ideal\
    \ for online tasks that\nrequire the above promising features. There are ways\
    \ to avoid massive data from trans-\nferring to the cloud. The ﬁrst one is to\
    \ implement a UAV on-board real-time processing\nplatform and delivery only the\
    \ key information to the network, and the other one is to\ndeploy a local ground\
    \ station for UAV information processing.\nAs the computing and storage resources\
    \ are quite limited, the optimization of comput-\ning workﬂow and algorithms are\
    \ therefore required. For example, Li et al. [120] developed\nan airborne edge\
    \ computing system for pine wilt disease detection of coniferous forests.\nThe\
    \ images captured by an onboard camera are directly passed to the edge computing\
    \ mod-\nule in which the lightweight YOLO model is implemented due to the limited\
    \ processing\nand storage resources. Similarly, Deng et al. [137] used a lightweight\
    \ segmentation model\nRemote Sens. 2021, 13, 4387\n14 of 31\nfor real-time weed\
    \ mapping on a NIVIDA Jetson TX board. Camargo et al. [115] specially\noptimized\
    \ ResNet model and changed it from 32-bit to 16-bit to reduce computing on an\n\
    NVIDIA Jetson AGX Xavier embedded system. Many researchers [179,180] also exploited\n\
    the acceleration of traditional image processing algorithms for various RS data\
    \ types on\nUAV platforms.\n4.2. Edge Intelligence: Convergence of AI and Edge\
    \ Computing\nArtiﬁcial intelligence methods are computationally and storage intensive.\
    \ Although it\ncan achieve excellent performance in most applications, it also\
    \ places high computing and\nstorage demands on resources, making it challenge\
    \ for real applications. The emerging of\nedge computing solves the above key\
    \ problems in artiﬁcial intelligence applications on\nedge devices. The combination\
    \ of edge computing and artiﬁcial intelligence yields edge\nintelligence [38].\
    \ Currently, there is no formal deﬁnition for edge intelligence internationally.\n\
    Edge intelligence is regarded as the paradigm of running AI algorithms locally\
    \ on an\nintelligent edge device [34]. Researchers also try to give a broader\
    \ deﬁnition, which\nmainly includes AI for edge and AI on edge. The former part\
    \ solves the problems in\nedge computing with AI, while the latter is the common\
    \ deﬁnition [34] and the focus of\nthis paper. In edge intelligence applications,\
    \ edge devices can reduce the amount of data\ntransferred to the central cloud\
    \ and greatly save bandwidth resources. Meanwhile, running\nDL models at edge\
    \ devices has lower computing consumption, higher performance, and\ncan avoid\
    \ possible privacy risks.\nIn the scope of this review, the combination of intelligent\
    \ UAV RS and edge computing\nresults in more effective PA applications. To obtain\
    \ better performance, DL models tend\nto be designed deeper and more complex,\
    \ which inevitably causes delays. Limited by\nprocessing and storage resources,\
    \ these complex DL models can hardly be directly applied\nto UAVs. Much work needs\
    \ to be fulﬁlled before implementing on the resources-limited\nUAV edge platforms\
    \ for efﬁcient PA applications. According to existing work, the major\ncomponents\
    \ of edge intelligence include: (a) edge caching, a distributed data system\n\
    near end users to collect and store the data produced by edge devices and surrounding\n\
    environments, and also the data received from the Internet; (b) edge training,\
    \ a distributed\nlearning procedure that learns the optimal models with the training\
    \ set cached at the edge;\n(c) edge inference, which infers the testing instance\
    \ on edge devices and servers using a\ntrained model or algorithm; and d) edge\
    \ ofﬂoading, a distributed computing paradigm\nthat offers computing service for\
    \ edge caching, edge training and edge inference [181]. As\nfor UAV RS in PA,\
    \ the existing studies mainly focus on edge training and edge inference,\nespecially\
    \ the inference onboard UAVs. On the other hand, for an edge intelligence system\n\
    and industrial ecosystem, algorithms and computing resources are the key elements.\
    \ As a\nresult, we discuss the relevant developments from the perspectives of\
    \ model design and\nedge resources for the edge intelligence in PA with UAV RS\
    \ in Sections 4.3 and 4.4.\n4.3. Lightweight Network Model Design\nTo obtain higher\
    \ classification, detection or segmentation accuracy, the deep CNN models\nare\
    \ designed with deeper, wider and more complex architectures, which inevitably\
    \ leads\nto computation-intensive and storage-intensive algorithms on computing\
    \ devices. When it\ncomes to edge devices, especially UAVs, their limited computing,\
    \ storage, power consumption\nand bandwidth resources can hardly meet the requirements\
    \ of intelligent applications.\nResearch has found that the structure of deep\
    \ neural networks is redundant. Based\non this property, the compression of deep\
    \ neural networks will therefore greatly ease the\nburden of inference and accelerate\
    \ computing to accommodate the usage on UAV platforms.\nIn recent years, researchers\
    \ have made great efforts to compress and accelerate deep neural\nnetwork models\
    \ from the aspects of algorithm optimization, hardware implementation\nand co-design\
    \ [182]. The work in [183] by Han et al. is widely considered to be the ﬁrst\n\
    to systematically carry out deep model compression. Its main work includes pruning\n\
    network connections to keep the more important ones only, quantitating model parameters\n\
    Remote Sens. 2021, 13, 4387\n15 of 31\nto reduce the model volume and improve\
    \ the efﬁciency, and further compressing the\nmodel through Huffman Coding. Through\
    \ model compression, it is conducive to reducing\ncomputing, memory and power\
    \ consumption, which makes it easier to be deployed to the\nUAV systems.\nThe\
    \ mainstream deep model compression methods can be divided into the following\n\
    categories: (1) lightweight convolution design, (2) parameter pruning, (3) low-rank\
    \ factor-\nization, (4) parameter quantization, and (5) knowledge distillation.\
    \ Each tries to compress\nthe model from different aspects, and they are always\
    \ used with the combination. Table 6\nshows a compilation of lightweight inference\
    \ applications onboard UAVs for PA. As shown\nin Table 6, the research of the\
    \ edge inference of UAV RS in the PA ﬁeld is in the starting\nstage yet, and there\
    \ are only a few attempts at general model quantization and pruning\nmethods.\
    \ Hence, we describe the categories and the corresponding development in details,\n\
    taking more domains in addition to agriculture for edge inference onboard UAVs\
    \ into\nconsideration below.\nTable 6. A compilation of lightweight inference\
    \ applications onboard UAVs for PA.\nApplications\nTask\nModel Compression\nTechniques\n\
    Performance\nBenchmark Platforms\nReferences\nTree species\nclassiﬁcation\nClassiﬁcation\n\
    Design a compact\nCNN\nmodel architecture\nAverage classiﬁcation\naccuracy of\
    \ 92%, and\nmodel size reduced from\n25 million trainable\nparameters to 2,982,484\n\
    12 Intel(R) Xeon(R) CPU\nE5–1650 v4 units each\nwith 3.60 GHz and four\nGeForce\
    \ GTX TITAN X\ngraphics cards\n[184]\nClassiﬁcation\nof weed and\ncrop plants\n\
    Classiﬁcation\nParameter\nquantization of\nResNet-18 from FP32\nto FP16 and\n\
    optimization to avoid\nredundant\ncomputations in\noverlapping\nimage patches\n\
    The overall accuracy of\n94% on the test data, and\nthe prediction pipeline\n\
    reached a performance\nof 2.2 frames per second\n(FPS) from 1.3 FPS\nNVIDIA Jetson\n\
    AGX Xavier\n[115]\nPlant seedling\nclassiﬁcation\nClassiﬁcation\nModel pruning\
    \ and\nquantization to\nLeNet5, VGG16,\nand AlexNet\nCompress the size of\nmodels\
    \ by a factor of 38\nand to reduce the FLOPs\nof VGG16 by a factor of\n99 without\
    \ considerable\nloss of accuracy\nunknown\n[185]\nTree crown\ndelineation\nSemantic\n\
    segmentation\n8-bit quantization is\nperformed on an\nalready-trained ﬂoat\nTensorFlow\
    \ model and\napplied during\nTensorFlow Lite\nconversion facilitating\nthe execution\
    \ of the\ntrained U-Net\nThe quantized model is\n0.1 times the size of the\noriginal\
    \ model; the most\nefﬁcient inference\nprocedure is achieved\nwith 28ms with\n\
    quantized-TPU model\nexecuted on Coral Edge\nGoogle Coral Edge\nTPU Board\n[186]\n\
    Weed detection\nSemantic\nsegmentation\nParameter\nquantization, apply\nFP32 for\
    \ training and\nuse FP16 for inference\nAn accuracy of 80.9% on\nthe testing samples\
    \ and\nits inference speed was\n4.5 FPS on a NVIDIA\nJetson TX2 module\nNVIDIA\
    \ Jetson TX2\n[137]\nRemote Sens. 2021, 13, 4387\n16 of 31\n4.3.1. Lightweight\
    \ Convolution Design\nLightweight convolution design refers to the compact design\
    \ of convolutional ﬁlters.\nThe convolutional ﬁlter is actually used for translation\
    \ invariant feature extraction, and\nmakes up the majority of CNN operations.\
    \ Therefore, lightweight convolution design has\nbeen a hot research direction\
    \ in DL.\nIt tries to replace the original heavy convolutional ﬁlters with compact\
    \ ones. Speciﬁ-\ncally, it transforms the convolutional ﬁlter with large size\
    \ into several smaller-sized ones\nand concatenates their results to achieve equivalent\
    \ convolution results, as smaller-sized\nﬁlters calculate much faster. Typical\
    \ designs are SqueezeNet [187], MobileNet [188], and\nShufﬂeNet [189]. SqueezeNet\
    \ designs a ﬁre module composed of a squeeze layer with\n1×1 ﬁlters to reduce\
    \ the input channels, and an expanding layer with a mix of 1×1 and\n3×3 ﬁlters.\
    \ MobileNet adopts the idea of depthwise separable convolutions to reduce\nthe\
    \ volume of parameters and computations, in which depthwise convolutions are used\n\
    for feature extraction and pointwise convolutions are deployed to build feature\
    \ via lin-\near combinations of input channels. ShufﬂeNet designs with group convolution\
    \ and\nchannel shufﬂe to reduce parameters, and can obtain similar results compared\
    \ with the\noriginal convolutions.\nIn [190], a DL ﬁre recognition algorithm is\
    \ proposed for embedded intelligent forest\nﬁre monitoring using UAVs. It is based\
    \ on the lightweight MobileNet V3 to reduce\nthe complexity of the conventional\
    \ YOLOv4 network architecture. With regards to the\nmodel parameters, a decline\
    \ of 63.91% from 63.94 million to 23.08 million is obtained.\nEgli et al. [184]\
    \ designs a computationally lightweight CNN with a sequential model design\nwith\
    \ four consecutive convolution/pooling layers for tree species classiﬁcation that\
    \ uses\nhigh-resolution RGB images from automated UAV observations, which outperforms\
    \ several\ndifferent architectures on the available data set. Similarly, in order\
    \ to accommodate the\nreal-time performance on UAVs, Hua et al. [191] designs\
    \ a lightweight E-Mobile Net as the\nbackbone network of feature extraction for\
    \ real-time tracking.\n4.3.2. Parameter Pruning\nIn deep models, not all parameters\
    \ contribute to the outstanding discriminative\nperformance, thus many of them\
    \ can be removed from the network while having the least\neffect on the accuracy\
    \ of the trained models. Based on the principle, parameter pruning\ntries to prune\
    \ out the redundant non-informative parameters from convolutional layers\nand\
    \ fully connected layers for less computational operations and memory consumption.\n\
    There are several ways of pruning with different granularity. Some unimportant\n\
    weight connection can be pruned out with certain threshold [192]. Similarly, individual\n\
    redundant neurons, along with their input and output connections, can be pruned\
    \ [193].\nFurthermore, the ﬁlters composed of neurons can also be removed according\
    \ to their\nimportance which is indicated by L1 or L2 norm [194]. With the coarsest\
    \ granularity, layers\nthat are least informative can also be pruned, as shown\
    \ in [185]. As for connection-level\nand neuron-level pruning, they introduce\
    \ unstructured sparse connections in the network,\nwhich will also affect the\
    \ computational efﬁciency. On the contrary, ﬁlter-level and layer-\nlevel pruning\
    \ does not interfere with the normal forward computing, which can therefore\n\
    compress the model and accelerate the model inference. Worth noting that pruning\
    \ is\nalways accompanied with model ﬁne-tuning.\nWang et al. [190] eliminated\
    \ the redundant channels through channel-level sparsity-\ninduced regularization,\
    \ and achieved a signiﬁcant drop of model parameter number and\ninference time\
    \ by over 95% and 75% but with comparable accuracy, thus making it suitable\n\
    for real-time ﬁre monitoring on UAV platforms. [185] adopts two ways of pruning,\
    \ with one-\nshot pruning to achieve the desired compression ratio in a single\
    \ step and iterative pruning\nto gradually remove connections until obtaining\
    \ the targeted compression ratio. The model\nis retrained to readapt the parameters\
    \ after pruning iterations to recover the accuracy\ndrop. Aiming at secure edge\
    \ computing for agricultural object detection application,\nRemote Sens. 2021,\
    \ 13, 4387\n17 of 31\nFan et al. [195] use layer pruning and ﬁlter pruning together\
    \ to achieve a smaller structure\nand maximize real-time performance.\n4.3.3.\
    \ Low-rank Factorization\nLow-rank factorization tries to factorize a large weight\
    \ matrix or tensor into several\nsmaller dimension matrices or tensors. It can\
    \ be applied to both convolutional layer\nand fully-connected layer. When convolutional\
    \ ﬁlters are factorized, it will make the\ninference process faster, and when\
    \ applied to denser fully-connected layers, it will remove\nredundancy and reduce\
    \ the storage requirements.\nLebedev et al. [196] explore the low-rank factorization\
    \ of deep network through\ntensor decomposition and discriminative ﬁne-tuning.\
    \ Based on CP-decomposition, they\ndecompose the original convolutional layer\
    \ into a sequence of four layers with smaller\nﬁlters, thus reducing the computations.\
    \ Similarly, famous factorization methods like Tucker\ndecomposition [197], and\
    \ singular value decomposition [198,199] are also widely applied\nwith low-rank\
    \ constraints in the model training process to reduce the number of parameters\n\
    and speed-up the network.\nTo meet the severe constraints of typical embedded\
    \ systems in the applications for grape\nleaf disease detection, a low-rank CNN\
    \ architecture LR-Net based on Tensor decomposition\nis developed in [200] for\
    \ both convolutional layer and fully-connected layer, and the obvious\nperformance\
    \ gain is obtained compared with other lightweight network architectures.\n4.3.4.\
    \ Parameter Quantization\nThe intention of parameter quantization is to reduce\
    \ the volume of the trained model\nduring storage and transmission. Generally,\
    \ weights in deep models are stored as 32-bit\nﬂoating-point numbers. If their\
    \ number of bits is reduced, it will lead to the reduction of\noperations and\
    \ model sizes.\nIn recent years, low-bit quantization is becoming popular for\
    \ deep model compression\nand acceleration. There are two types of quantization,\
    \ one is parameter sharing for the\ntrained model, and the other is the low-bit\
    \ representation for model training. Parameter\nsharing designs a function that\
    \ maps various weight parameters to the same value. In [201],\na new network architecture\
    \ HashedNets is designed, in which the weight parameters are\nrandomly mapped\
    \ to hash bucket through hash function and every parameter shares the\nsame weight\
    \ value. [202] develops an approximation that quantizes the gradients to 8-bit\n\
    for GPU cluster parallelism. Further, [203] proposes incremental network quantization\n\
    method that lossless quantizes parameters to low 5-bit. The challenging binary\
    \ neural\nnetwork [137] is also in the spot of researches.\nTo develop a lightweight\
    \ network architecture for weed mapping tasks onboard\nUAVs, [137] conducted optimization\
    \ and precision calibration during the inference process.\nThe precision was reduced\
    \ from 32-bit to 16-bit. Similarly, Camargo et al. [115] shifted\ntheir ResNet-18\
    \ model from 32-bit to 16-bit and observed speed performance decline on\nNVIDIA\
    \ Jetson AGX Xavier. To be able to execute deep models efﬁciently in embedded\n\
    platforms, Blekos et al. [186] perform quantization on the trained U-Net model\
    \ to 8-bit\nintegers with acceptable losses.\n4.3.5. Knowledge Distillation\n\
    The main objective of knowledge distillation is to train a student network from\
    \ the\nteacher network while maintaining its generalization capability [204].\
    \ The student network\nis lighter, i.e., having a smaller model size and less\
    \ computation, but with the same or\ncomparable performance as the larger network.\n\
    Great efforts have been done to improve the supervision of student network by\n\
    different knowledge transferred. Romero et al. [205] proposed a FitNets model\
    \ which\nteaches the student network to imitate the hints from both middle layers\
    \ and output layer\nof the teach network. Instead of hard labels that are used,\
    \ the work in [206] utilizes soft\nlabels as the representation from teacher network.\
    \ Kim et al. [207] proposed a paraphrasing\nRemote Sens. 2021, 13, 4387\n18 of\
    \ 31\nbased knowledge transfer method which uses convolution operations to paraphrase\
    \ the\nteacher model knowledge and translate it to a student model. From the point\
    \ of teacher\nnetworks, student networks can also learn knowledge from multiple\
    \ teachers [208].\nIn the ﬁeld of UAV based deep model inference, knowledge distillation\
    \ is a promising\ndirection. In [209], YOLO + MobileNet model acts as the teacher\
    \ network, while the pruned\nmodel functions as the student network, and knowledge\
    \ distillation algorithm is used to\nimprove the detection accuracy of the pruned\
    \ model. Qiu et al. [210] propose to distill\nknowledge to a lighter distilled\
    \ network through soft labels from trained teacher network\nMobileNet. Similar\
    \ applications using knowledge distillation for model compression can\nbe found\
    \ in [211,212].\n4.4. Edge Resources for UAV RS\nThe key idea of edge computing\
    \ is that computing should be closer to the data sources\nand users. It can avoid\
    \ massive data transfer to the cloud and process data near the places\nwhere things\
    \ and people produce or consume data, thus reducing the latency, pressure on\n\
    network bandwidth and demand for computing and storage resources. Edge is a relative\n\
    concept to the network core. It refers to any resource, storage, and network resource\
    \ from\nthe data source to the cloud-computing center. The resources on this path\
    \ (from the data\nsources to cloud centers) can be regarded as a continuous system.\
    \ Generally, the resources\nat the edge mainly include user terminals such as\
    \ mobile phones and personal computers,\ninfrastructure such as WiFi access points,\
    \ cellular network base stations and routers, and\nembedded devices such as cameras\
    \ and set-top boxes. These numerous resources around\nusers are independent of\
    \ each other, which are called edge nodes. In this paper, we focus\non the scope\
    \ of AI on edge among the edge intelligence, which is to run AI models on\nintelligent\
    \ edge devices. Such devices have built-in processors with onboard analytics\n\
    or AI capabilities, mainly including sensors, UAVs, autonomous cars, etc. Rather\
    \ than\nuploading, processing and storing data to a cloud, intelligent edge devices\
    \ offer the ability\nto process certain amounts of data directly, while reducing\
    \ latency, bandwidth requirement,\ncost, privacy threats, etc.\nFor the scenario\
    \ of edge computing for UAV RS in PA, applications can be deployed\non the UAV\
    \ intelligent edge devices with embedded computing platforms or edge servers.\n\
    Here in this paper we mainly discuss the former. To accelerate the processing\
    \ of complex\nDL models, a few types of onboard hardware accelerators are mainly\
    \ included in UAV\nsolutions currently.\nThe following list the popular examples,\
    \ which are divided into the general-purpose\nCPU based solutions, GPU solutions\
    \ and ﬁeld programmable gate arrays (FPGA) solutions.\nVery few studies also use\
    \ microcontroller unit (MCU) [213] and vision processing unit\n(VPU) [214] for\
    \ UAV image recognition and monitoring.\n•\nGeneral-purpose CPU based solutions:\
    \ Multi-core CPUs are latency-oriented archi-\ntectures, which have more computational\
    \ power per core, but less number of cores,\nand are more suitable for task-level\
    \ parallelism [215,216]. As for the general-purpose\nsoftware-programmable platforms,\
    \ Raspberry Pi has been widely adopted as ready-\nto-use solutions for a variety\
    \ of UAV applications due to their weight, size and low\npower consumption.\n\
    •\nGPU solutions: GPUs have been designed as throughput-oriented architectures,\
    \ and\nown less powerful cores than that of CPUs but have hundreds or thousands\
    \ of cores\nand signiﬁcantly larger memory bandwidth, which make GPUs suitable\
    \ for data-level\nparallelism [215]. In recent years, the embedded GPUs especially\
    \ from NVIDIA, for\nexample, the Jetson boards, standing out among the other manufacturers\
    \ have been\nwidely used to provide ﬂexible solutions compared with FPGAs.\n•\n\
    FPGA solutions: The advent of FPGA-based embedded platforms allows combin-\ning\
    \ high-level management capabilities of processors and ﬂexible operations of pro-\n\
    grammable hardware [217]. With the advantages of: a) relatively smaller size and\n\
    weight compared with clusters, multi-core and many-core processors, b) signiﬁcantly\n\
    Remote Sens. 2021, 13, 4387\n19 of 31\nlower power consumption compared with GPUs,\
    \ and c) reprogrammed ability during\nthe ﬂight different from application-speciﬁc\
    \ integrated circuit (ASIC), FPGA-based\nplatforms such as the Xilinx Zynq-7000\
    \ family provide plenty of solutions for real-time\nprocessing onboard UAVs [218].\n\
    Table 7 gives a compilation of edge computing platforms onboard UAVs for typical\n\
    RS applications with speciﬁc platform vendor, model, conﬁgurations and applications.\n\
    Table 7. A compilation of computing platforms onboard UAVs for typical RS applications.\n\
    Major\nComputing\nComponent\nVendor\nModel\nSpeciﬁcation\nApplications\nReference\n\
    CPU\nAICSHTER\nARK-1100\nCPU: Intel Celeron J1900\nMemory: 8 GB LPDDR3\nThermal\
    \ design power: 10 W\nWeight: 2.0 kg\nDetection and spatial\nlocalization\nof\
    \ insulators\n[219]\nIntel\nEdison\nCPU: Intel Atom Dual Core\n500 MHz processor\n\
    Memory: 1 GB DDR3\nStorage: 4 GB\nWeight: 16 g\nIdentiﬁcation of\nfaulty areas\
    \ in\nthe plantation\n[180]\nAtom\nprocessor board\nCPU: 2× ARM7 micro processor\n\
    Memory: 1 GB RAM\nWeight: 90 g\nObject tracking\n[220]\nHardkernel\nOdroid XU4\n\
    CPU: Samsung Exynos5422\nCortex™-A15 2Ghz and Cortex™-A7\nOcta core processor\n\
    GPU: Mali-T628 MP6\nMemory: 2 GB LPDDR3 RAM\nCooperative\nUAV tracking\n[221]\n\
    Texas\nInstruments\nBeagleBone Black\nCPU: ARM Cortex-A8\nMemory: 512 MB DDR3\n\
    Storage: 4-GB 8-bit eMMC\nSensor data fusion\n[222]\nRaspberry Pi\nFoundation\n\
    Raspberry Pi\nModel B\nCPU: ARM (ARM1176JZF-S)\nGPU: Broadcom VideoCore IV @\n\
    250 MHz\nMemory: 512 MB\nMoving objects\ndetection\nand location\n[223]\nRaspberry\
    \ Pi\nModel B+\nCPU: ARM (ARM1176JZF-S)\nGPU: Broadcom VideoCore IV @\n250 MHz\n\
    Memory: 512 MB\nObject detection and\nrange measurement\n[224]\nRaspberry Pi 2\n\
    Model B\nCPU:4× Cortex-A7900 MHz\nGPU: Broadcom VideoCore IV @\n250 MHz\nMemory:\
    \ 1 GB\nObject detection, air\nquality data\ncollection and\ntransmission,\npedestrian\
    \ detection,\nobject detection and\ntracking\n[225–228]\nRaspberry Pi 3\nModel\
    \ B\nCPU: 4× Cortex-A531.2 GHz\nGPU: Broadcom VideoCore IV @\n250 MHz\nMemory:\
    \ 1 GB\nSoybean weed\ndetection,\nagrochemical\nspraying, face\ndetection, human\n\
    detection, land\nuse classiﬁcation\n[116,229–232]\nRaspberry Pi 3\nModel B+\n\
    CPU: 4× Cortex-A531.4 GHz\nGPU: Broadcom VideoCore IV @\n400 MHz/300 MHz\nMemory:\
    \ 1 GB\nFace recognition and\nobject detection\n[233]\nRaspberry Pi 4\nModel B\n\
    CPU: 4× Cortex-A721.5 GHz\nGPU: Broadcom VideoCore VI @\n500 MHz\nMemory: 4 GB\n\
    Fault location for\ntransmission line\n[234]\nRemote Sens. 2021, 13, 4387\n20\
    \ of 31\nTable 7. Cont.\nMajor\nComputing\nComponent\nVendor\nModel\nSpeciﬁcation\n\
    Applications\nReference\nGPU\nNVIDIA\nTegra K1\nCPU: quad-core, 4-Plus-1™ ARM®\n\
    GPU: low-power NVIDIA\nKepler™-based GeForce®\ngraphics processor\nMemory: 2 GB\
    \ DDR3L RAM\nStorage:16 GB eMMC 4.51\nMax power: about 15 W\nWeight: less than\
    \ 200 g\nObject tracking and\nautomatic landing\n[235]\nJetson TK1\nCPU: NVIDIA\
    \ 4 Plus 1 quad core\nARM Cortex A15 CPU\nGPU: NVIDIA Kepler GK20 with 192\nSM3.2\
    \ CUDA cores\nMemory: 2 GB\nStorage: 16 GB eMMC 4.51\nVegetation\nindex estimation\n\
    [179]\nJeston TX1\nCPU: Quad-core ARM® Cortex®-A57\nMPCore Processor\nGPU: NVIDIA\
    \ Maxwell™ GPU with\n256 NVIDIA® CUDA® Cores\nMemory: 4 GB LPDDR4\nStorage: 16\
    \ GB eMMC 5.1\nObject detection\n[236]\nJeston TX2\nCPU: Dual-Core NVIDIA Denver\
    \ 2\n64-Bit CPU and Quad-Core Arm®\nCortex®-A57 MPCore processor\nGPU: 256-core\
    \ NVIDIA Pascal™ GPU\nMemory: 8 GB 128-bit LPDDR4\nStorage: 32 GB eMMC 5.1\nCoarse-grained\n\
    detection of pine\nwood nematode\ndisease, object\ndetection, pipeline\nsafety\
    \ excavator\ninspection, weed\ndetection,\npest detection\n[119,120,137,237,238]\n\
    Jetson Nano\nCPU: Quad-Core Arm® Cortex®-A57\nMPCore processor\nGPU: 128-core\
    \ NVIDIA\nMaxwell™ GPU\nMemory: 4 GB 64-bit LPDDR4\nStorage: 16 GB eMMC 5.1\n\
    Real-time\ncompression of\nhyperspectral data\n[239]\nJetson Xavier NX\nCPU: 6-core\
    \ NVIDIA Carmel\nArm®v8.2 64-bit CPU\nGPU: 384-core NVIDIA Volta™ GPU\nwith 48\
    \ Tensor Cores\nMemory: 8 GB 128-bit LPDDR4x\nStorage: 16 GB eMMC 5.1\nReal-time\
    \ vehicle\ndetection and speed\nmonitoring, real-time\ncompression of\nhyperspectral\
    \ data\n[239,240]\nJetson\nAGX Xavier\nCPU: 8-core NVIDIA Carmel\nArm®v8.2 64-bit\
    \ CPU\nGPU: 512-core NVIDIA Volta™ GPU\nwith 64 Tensor Cores\nMemory: 32 GB 256-bit\
    \ LPDDR4x\nStorage: 32 GB eMMC 5.1\nWeed and crop\nclassiﬁcation\n[115]\nFPGA\n\
    Terasic\nAltera DE2i-150\nCPU: Intel® Atom N2600\nFPGA: Altera Cyclone IV FPGA\n\
    Memory: 2 GB DDR3\nstorage: 64 GB SSD\nIdentiﬁcation of\nfaulty areas in\nthe\
    \ plantation\n[180]\nMaxeler\nMAX4\nacceleration card\nFPGA: Intel Altera Stratix-V\
    \ FPGA\nMemory: 48 GB DDR3\nonboard tmemory\nTree crown detection\n[218]\nIntel\n\
    DE1-SoC\nCPU: dual-core ARM\nCortex™-A9 processor\nFPGA: Cyclone V SoC\n5CSEMA5F31C6\n\
    Memory: 4450 Kbits\nembedded memory\nWeed classiﬁcation\n[241]\nXilinx\nZynq-7000\n\
    CPU: single-core ARM\nCortex™-A9 processor\nFPGA: Artix-7 based\nprogrammable\
    \ logic\nUAV hyperspectral\ndata compression\n[242]\nRemote Sens. 2021, 13, 4387\n\
    21 of 31\n5. Future Directions\nDespite the great progress of DL and UAV RS techniques\
    \ in the PA ﬁeld, the research\nand practice of edge intelligence, especially\
    \ in PA is still in an early stage. In addition to\ncommon challenges in PA, UAV\
    \ RS and edge intelligence, here we list a few speciﬁc issues\nthat need to be\
    \ addressed within the scope of this paper.\n•\nLightweight intelligent model\
    \ design in PA for edge inference. As mentioned in\nSection 4, most DL-based models\
    \ for UAV RS data processing and analytics in PA\nare highly resources intensive.\
    \ Hardware with powerful computing capability is\nimportant to support the training\
    \ and inference of these large AI models. Currently,\nthere are just a few studies\
    \ towards applying common parameter pruning and quanti-\nzation methods in PA\
    \ with UAV RS. The metrics of size and efﬁciency can be further\nimproved by considering\
    \ the data and algorithm characteristics and exploiting other\nsophisticated model\
    \ compression techniques such as knowledge distillation and a com-\nbination of\
    \ multiple compression methods [183]. In addition, instead of using existing\n\
    AI models, the neural architecture search (NAS) technique [243] can be utilized\
    \ to de-\nrive models tailored to the hardware resource constraints on the performance\
    \ metrics,\ne.g., latency and energy efﬁciency considering the underlying edge\
    \ devices [34].\n•\nTransfer learning and incremental learning for intelligent\
    \ PA models on UAV edge\ndevices. The performance of many DL models heavily relies\
    \ on the quantity and\nquality of datasets. However, it is difﬁcult or expensive\
    \ to collect a large amount\nof data with labels. Therefore, edge devices can\
    \ exploit transfer learning to learn a\ncompetitive model, in which a pre-trained\
    \ model with a large-scale dataset is further\nﬁne-tuned according to the domain-speciﬁc\
    \ data [244,245]. Secondly, edge devices\nsuch as UAVs may collect data with different\
    \ distributions or even data belonging to\nan unknown class compared with the\
    \ original training data during ﬂight. The model\non the edge devices can be updated\
    \ by incremental learning to give better prediction\nperformance [246].\n•\nCollaboration\
    \ of RS cloud centers, ground control stations and UAV edge devices. To\nbridge\
    \ the gap between the low computing and storage capabilities of edge devices\n\
    and the high resource requirements of DL training, the collaborative computing\n\
    between the end, the edge and the cloud is a possible solution. It has become\
    \ the trend\nfor edge intelligence architectures and application scenes. A good\
    \ cloud-edge-end\ncollaboration architecture should take into account the characteristics\
    \ of heterogeneous\ndevices, asynchronous communication and diverse computing\
    \ and storage resources,\nthus achieving collaborative model training and inference\
    \ [247]. In the conventional\nmode, the model training is often performed in the\
    \ cloud, and the trained model is\ndeployed on edge devices. This mode is simple,\
    \ but cannot fully utilize resources. For\nthe case of edge intelligence for UAV\
    \ RS in PA, decentralized edge devices and data\ncenters can cooperate with each\
    \ other to train or improve a model by using federated\nlearning [248].\n6. Conclusions\n\
    This paper gives a systematic and comprehensive overview of the latest development\n\
    of PA promoted by UAV RS and edge intelligence techniques. We ﬁrst introduce the\n\
    application of UAV RS in PA, including the fundamentals of various types of UAV\
    \ systems\nand sensors and typical applications to give a preliminary picture.\
    \ The latest development\nof DL methods and public datasets in PA with UAV RS\
    \ are then presented. Subsequently,\nwe give a thorough analysis of the development\
    \ of edge intelligence in PA with UAV RS,\nincluding the cloud computing and edge\
    \ computing paradigms, the basic concepts and\nmajor components (i.e., edge caching,\
    \ edge training, edge inference and edge ofﬂoading)\nof edge intelligence, the\
    \ developments from the perspectives of network model design and\nedge resources.\
    \ Finally, we present several issues that need to be further addressed.\nThrough\
    \ this survey, we provide preliminary insights into how PA beneﬁts from\nUAV RS\
    \ together with edge intelligence. In recent years, the small and light, ﬁxed-wing\
    \ or\nRemote Sens. 2021, 13, 4387\n22 of 31\nindustrial rotor-wing UAV systems\
    \ have been widely adopted in PA. Due to the advantages\nof easy-to-use, high\
    \ ﬂexibility, high resolution and being less affected by clouds during\nﬂight\
    \ at low altitudes, UAV RS has become a powerful manner to monitor agricultural\n\
    conditions. In addition, the integration of DL techniques in PA with UAV RS reached\n\
    higher accuracies compared with traditional analysis methods. These PA applications\
    \ have\nbeen transformed into computer vision tasks including classiﬁcation, object\
    \ detection and\nsegmentation, and CNN and RNN are the most widely adopted network\
    \ architectures.\nThere are also a few publicly available UAV datasets for intelligent\
    \ PA, mainly from RGB\nsensors and very few from multispectral and hyperspectral\
    \ sensors. These datasets can\nfacilitate the validation and comparison of DL\
    \ methods. However, deep models generally\nbring higher computing, memory and\
    \ network requirements, hence cloud computing is a\ncommon solution to increase\
    \ efﬁciency with high scalability and low cost, but at the cost of\nhigh latency\
    \ and pressure on the network bandwidth. The emerging of edge computing\nbrings\
    \ the computing to the edge of the network close to the data sources. The AI and\
    \ edge\ncomputing further yield edge intelligence, providing a promising solution\
    \ for efﬁcient\nintelligent UAV RS applications. In terms of hardware, typical\
    \ computing solutions include\nCPUs, GPUs and FPGAs. From the perspectives of\
    \ algorithm, lightweight model design\nderiving from model compression techniques\
    \ especially model pruning and quantization\nis one of the most signiﬁcant and\
    \ widely used technique. The PA supported by advanced\nUAV RS and edge intelligence\
    \ techniques offers the capabilities to increase productivity\nand efﬁciency while\
    \ reducing costs.\nThe research and practice of edge intelligence, especially\
    \ in PA with UAV RS is still in\nan early stage. In the future, in addition to\
    \ the general challenges of PA, UAV RS and edge\nintelligence, there are issues\
    \ within the scope of this paper that need to be addressed. These\ndirections\
    \ can include designing and implementing lightweight models for PA with UAV\n\
    RS on edge devices, realizing transfer learning and incremental learning for intelligent\n\
    PA models on UAV edge devices, and efﬁcient collaboration of RS cloud centers,\
    \ ground\ncontrol stations and UAV edge devices.\nAuthor Contributions: Conceptualization,\
    \ J.L., J.X. and J.Y.; literature investigation and analysis,\nJ.L., Y.J. and\
    \ J.X.; writing—original draft preparation, J.L., J.X., R.L. and J.Y.; writing—review\
    \ and\nediting, J.L., J.Y. and L.W; visualization, J.L., Y.J. and J.X.; supervision,\
    \ J.L. and L.W. All authors have\nread and agreed to the published version of\
    \ the manuscript.\nFunding: This research was funded in part by the National Natural\
    \ Science Foundation of China\nunder Grant No. 41901376 and No. 42172333, and\
    \ in part by the Fundamental Research Funds for\nthe Central Universities, China\
    \ University of Geosciences (Wuhan).\nData Availability Statement: Data sharing\
    \ is not applicable.\nConﬂicts of Interest: The authors declare no conﬂict of\
    \ interest.\nReferences\n1.\nISPA. Precision Ag Deﬁnition. Available online: https://www.ispag.org/about/deﬁnition\
    \ (accessed on 17 October 2021).\n2.\nMessina, G.; Modica, G. Applications of\
    \ UAV Thermal Imagery in Precision Agriculture: State of the Art and Future Research\n\
    Outlook. Remote Sens. 2020, 12, 1491. [CrossRef]\n3.\nSchimmelpfennig, D. Farm\
    \ proﬁts and adoption of precision agriculture; U.S. Department of Agriculture,\
    \ Economic Research Service:\nWashington, DA, USA, 2016.\n4.\nMaes, W.H.; Steppe,\
    \ K. Perspectives for Remote Sensing with Unmanned Aerial Vehicles in Precision\
    \ Agriculture. Trends Plant Sci.\n2019, 24, 152–164. [CrossRef]\n5.\nLillesand,\
    \ T.; Kiefer, R.W.; Chipman, J. Remote Sensing and Image Interpretation; John\
    \ Wiley & Sons: Hoboken, NJ, USA, 2015.\n6.\nMulla, D.J. Twenty ﬁve years of remote\
    \ sensing in precision agriculture: Key advances and remaining knowledge gaps.\n\
    Biosyst. Eng. 2013, 114, 358–371. [CrossRef]\n7.\nEskandari, R.; Mahdianpari,\
    \ M.; Mohammadimanesh, F.; Salehi, B.; Brisco, B.; Homayouni, S. Meta-Analysis\
    \ of Unmanned Aerial\nVehicle (UAV) Imagery for Agro-Environmental Monitoring\
    \ Using Machine Learning and Statistical Models. Remote Sens. 2020,\n12, 3511.\
    \ [CrossRef]\n8.\nTsouros, D.C.; Bibi, S.; Sarigiannidis, P.G. A Review on UAV-Based\
    \ Applications for Precision Agriculture. Information 2019,\n10, 349. [CrossRef]\n\
    Remote Sens. 2021, 13, 4387\n23 of 31\n9.\nZhang, H.; Wang, L.; Tian, T.; Yin,\
    \ J. A Review of Unmanned Aerial Vehicle Low-Altitude Remote Sensing (UAV-LARS)\
    \ Use in\nAgricultural Monitoring in China. Remote Sens. 2021, 13, 1221. [CrossRef]\n\
    10.\nJang, G.; Kim, J.; Yu, J.-K.; Kim, H.-J.; Kim, Y.; Kim, D.-W.; Kim, K.-H.;\
    \ Lee, C.W.; Chung, Y.S. Review: Cost-Effective Unmanned\nAerial Vehicle (UAV)\
    \ Platform for Field Plant Breeding Application. Remote Sens. 2020, 12, 998. [CrossRef]\n\
    11.\nUS Department of Defense. Unmanned Aerial Vehicle. Available online: https://www.thefreedictionary.com/Unmanned+\n\
    Aerial+Vehicle (accessed on 19 October 2021).\n12.\nDeng, L.; Mao, Z.; Li, X.;\
    \ Hu, Z.; Duan, F.; Yan, Y. UAV-based multispectral remote sensing for precision\
    \ agriculture: A comparison\nbetween different cameras. ISPRS J. Photogramm. Remote\
    \ Sens. 2018, 146, 124–136. [CrossRef]\n13.\nChristiansen, M.P.; Laursen, M.S.;\
    \ Jørgensen, R.N.; Skovsen, S.; Gislum, R. Designing and Testing a UAV Mapping\
    \ System for\nAgricultural Field Surveying. Sensors 2017, 17, 2703. [CrossRef]\n\
    14.\nPopescu, D.; Stoican, F.; Stamatescu, G.; Ichim, L.; Dragana, C. Advanced\
    \ UAV–WSN System for Intelligent Monitoring in\nPrecision Agriculture. Sensors\
    \ 2020, 20, 817. [CrossRef] [PubMed]\n15.\nZhou, X.; Zheng, H.; Xu, X.; He, J.;\
    \ Ge, X.; Yao, X.; Cheng, T.; Zhu, Y.; Cao, W.; Tian, Y. Predicting grain yield\
    \ in rice using\nmulti-temporal vegetation indices from UAV-based multispectral\
    \ and digital imagery. ISPRS J. Photogramm. Remote Sens. 2017,\n130, 246–255.\
    \ [CrossRef]\n16.\nYang, Q.; Shi, L.; Han, J.; Zha, Y.; Zhu, P. Deep convolutional\
    \ neural networks for rice grain yield estimation at the ripening stage\nusing\
    \ UAV-based remotely sensed images. Field Crops Res. 2019, 235, 142–153. [CrossRef]\n\
    17.\nSu, J.; Liu, C.; Coombes, M.; Hu, X.; Wang, C.; Xu, X.; Li, Q.; Guo, L.;\
    \ Chen, W.-H. Wheat yellow rust monitoring by learning from\nmultispectral UAV\
    \ aerial imagery. Comput. Electron. Agric. 2018, 155, 157–166. [CrossRef]\n18.\n\
    Guo, A.; Huang, W.; Dong, Y.; Ye, H.; Ma, H.; Liu, B.; Wu, W.; Ren, Y.; Ruan,\
    \ C.; Geng, Y. Wheat Yellow Rust Detection Using\nUAV-Based Hyperspectral Technology.\
    \ Remote Sens. 2021, 13, 123. [CrossRef]\n19.\nBajwa, A.; Mahajan, G.; Chauhan,\
    \ B. Nonconventional Weed Management Strategies for Modern Agriculture. Weed Sci.\
    \ 2015,\n63, 723–747. [CrossRef]\n20.\nHuang, Y.; Reddy, K.N.; Fletcher, R.S.;\
    \ Pennington, D. UAV Low-Altitude Remote Sensing for Precision Weed Management.\n\
    Weed Technol. 2018, 32, 2–6. [CrossRef]\n21.\nVan Klompenburg, T.; Kassahun, A.;\
    \ Catal, C. Crop yield prediction using machine learning: A systematic literature\
    \ review.\nComput. Electron. Agric. 2020, 177, 105709. [CrossRef]\n22.\nSu, Y.-X.;\
    \ Xu, H.; Yan, L.-J. Support vector machine-based open crop model (SBOCM): Case\
    \ of rice production in China. Saudi J.\nBiol. Sci. 2017, 24, 537–547. [CrossRef]\n\
    23.\nEveringham, Y.; Sexton, J.; Skocaj, D.; Inman-Bamber, G. Accurate prediction\
    \ of sugarcane yield using a random forest algorithm.\nAgron. Sustain. Dev. 2016,\
    \ 36, 27. [CrossRef]\n24.\nChandra, A.L.; Desai, S.V.; Guo, W.; Balasubramanian,\
    \ V.N. Computer vision with deep learning for plant phenotyping in\nagriculture:\
    \ A survey. arXiv Prepr. 2020, arXiv:2006.11391.\n25.\nZhou, L.; Zhang, C.; Liu,\
    \ F.; Qiu, Z.; He, Y. Application of Deep Learning in Food: A Review. Compr. Rev.\
    \ Food Sci. Food Saf. 2019,\n18, 1793–1811. [CrossRef]\n26.\nLeCun, Y.; Bengio,\
    \ Y.; Hinton, G. Deep learning. Nature 2015, 521, 436–444. [CrossRef] [PubMed]\n\
    27.\nBah, M.D.; Haﬁane, A.; Canals, R. Deep Learning with Unsupervised Data Labeling\
    \ for Weed Detection in Line Crops in UAV\nImages. Remote Sens. 2018, 10, 1690.\
    \ [CrossRef]\n28.\nKitano, B.T.; Mendes, C.C.T.; Geus, A.R.; Oliveira, H.C.; Souza,\
    \ J.R. Corn plant counting using deep learning and UAV images.\nIEEE Geosci. Remote.\
    \ Sens. Lett. 2019, 1–5. [CrossRef]\n29.\nNowakowski, A.; Mrziglod, J.; Spiller,\
    \ D.; Bonifacio, R.; Ferrari, I.; Mathieu, P.P.; Garcia-Herranz, M.; Kim, D.-H.\
    \ Crop type\nmapping by using transfer learning. Int. J. Appl. Earth Obs. Geoinf.\
    \ 2021, 98, 102313. [CrossRef]\n30.\nMa, L.; Liu, Y.; Zhang, X.; Ye, Y.; Yin,\
    \ G.; Johnarson, B.A. Deep learning in remote sensing applications: A meta-analysis\
    \ and\nreview. ISPRS J. Photogramm. Remote Sens. 2019, 152, 166–177. [CrossRef]\n\
    31.\nChen, J.; Ran, X. Deep Learning with Edge Computing: A Review. Proc. IEEE\
    \ 2019, 107, 1655–1674. [CrossRef]\n32.\nSimonyan, K.; Zisserman, A. Very Deep\
    \ Convolutional Networks for Large-Scale Image Recognition. In Proceedings of\
    \ the\nInternational Conference on Learning Representations, San Diego, CA, USA,\
    \ 7–9 May 2015.\n33.\nLiu, J.; Liu, R.; Ren, K.; Li, X.; Xiang, J.; Qiu, S. High-Performance\
    \ Object Detection for Optical Remote Sensing Images\nwith Lightweight Convolutional\
    \ Neural Networks. In Proceedings of the 2020 IEEE 22nd International Conference\
    \ on High\nPerformance Computing and Communications; IEEE 18th International Conference\
    \ on Smart City; IEEE 6th International\nConference on Data Science and Systems\
    \ (HPCC/SmartCity/DSS), Yanuca Island, Cuvu, Fiji, 14–16 December 2020; pp. 585–592.\n\
    34.\nZhou, Z.; Chen, X.; Li, E.; Zeng, L.; Luo, K.; Zhang, J. Edge Intelligence:\
    \ Paving the Last Mile of Artiﬁcial Intelligence with Edge\nComputing. Proc. IEEE\
    \ 2019, 107, 1738–1762. [CrossRef]\n35.\nPu, Q.; Ananthanarayanan, G.; Bodik,\
    \ P.; Kandula, S.; Akella, A.; Bahl, P.; Stoica, I. Low latency geo-distributed\
    \ data analytics.\nACM SIGCOMM Comp. Com. Rev. 2015, 45, 421–434. [CrossRef]\n\
    36.\nSittón-Candanedo, I.; Alonso, R.S.; Rodríguez-González, S.; Coria, J.A.G.;\
    \ De La Prieta, F. Edge Computing Architectures in Industry\n4.0: A General Survey\
    \ and Comparison. International Workshop on Soft Computing Models in Industrial\
    \ and Environmental Applications;\nSpringer: Berlin/Heidelberg, Germany, 2019;\
    \ pp. 121–131.\nRemote Sens. 2021, 13, 4387\n24 of 31\n37.\nPlastiras, G.; Terzi,\
    \ M.; Kyrkou, C.; Theocharidcs, T. Edge intelligence: Challenges and opportunities\
    \ of near-sensor machine learn-\ning applications. In Proceedings of the 2018\
    \ IEEE 29th International Conference on Application-Speciﬁc Systems, Architectures\n\
    and Processors (ASAP), Milano, Italy, 10–12 July 2018; pp. 1–7.\n38.\nDeng, S.;\
    \ Zhao, H.; Fang, W.; Yin, J.; Dustdar, S.; Zomaya, A.Y. Edge Intelligence: The\
    \ Conﬂuence of Edge Computing and\nArtiﬁcial Intelligence. IEEE Internet Things\
    \ J. 2020, 7, 7457–7469. [CrossRef]\n39.\nBoursianis, A.D.; Papadopoulou, M.S.;\
    \ Diamantoulakis, P.; Liopa-Tsakalidi, A.; Barouchas, P.; Salahas, G.; Karagiannidis,\
    \ G.;\nWan, S.; Goudos, S.K. Internet of Things (IoT) and Agricultural Unmanned\
    \ Aerial Vehicles (UAVs) in smart farming: A compre-\nhensive review. Internet\
    \ Things 2020, 100187, in press. [CrossRef]\n40.\nKim, J.; Kim, S.; Ju, C.; Son,\
    \ H.I. Unmanned Aerial Vehicles in Agriculture: A Review of Perspective of Platform,\
    \ Control, and\nApplications. IEEE Access 2019, 7, 105100–105115. [CrossRef]\n\
    41.\nMogili, U.R.; Deepak, B.B.V.L. Review on Application of Drone Systems in\
    \ Precision Agriculture. Procedia Comput. Sci. 2018,\n133, 502–509. [CrossRef]\n\
    42.\nKamilaris, A.; Prenafeta-Boldú, F.X. A review of the use of convolutional\
    \ neural networks in agriculture. J. Agric. Sci. 2018,\n156, 312–322. [CrossRef]\n\
    43.\nKamilaris, A.; Prenafeta-Boldú, F.X. Deep learning in agriculture: A survey.\
    \ Comput. Electron. Agric. 2018, 147, 70–90. [CrossRef]\n44.\nSantos, L.; Santos,\
    \ F.N.; Oliveira, P.M.; Shinde, P. Deep Learning Applications in Agriculture:\
    \ A Short Review. Iberian Robotics\nConference; Springer: Berlin/Heidelberg, Germany,\
    \ 2019; pp. 139–151.\n45.\nCivil Aviation Administration of China. Interim Regulations\
    \ on Flight Management of Unmanned Aerial Vehicles. 2018; Vol-\nume 2021. Available\
    \ online: http://www.caac.gov.cn/HDJL/YJZJ/201801/t20180126_48853.html (accessed\
    \ on 17 October 2021).\n46.\nPark, M.; Lee, S.; Lee, S. Dynamic topology reconstruction\
    \ protocol for uav swarm networking. Symmetry 2020, 12, 1111.\n[CrossRef]\n47.\n\
    Radoglou-Grammatikis, P.; Sarigiannidis, P.; Lagkas, T.; Moscholios, I. A compilation\
    \ of UAV applications for precision agriculture.\nComput. Netw. 2020, 172, 107148.\
    \ [CrossRef]\n48.\nHayat, S.; Yanmaz, E.; Muzaffar, R. Survey on Unmanned Aerial\
    \ Vehicle Networks for Civil Applications: A Communications\nViewpoint. IEEE Commun.\
    \ Surv. Tutor. 2016, 18, 2624–2661. [CrossRef]\n49.\nXie, C.; Yang, C. A review\
    \ on plant high-throughput phenotyping traits using UAV-based sensors. Comput.\
    \ Electron. Agric. 2020,\n178, 105731. [CrossRef]\n50.\nDelavarpour, N.; Koparan,\
    \ C.; Nowatzki, J.; Bajwa, S.; Sun, X. A Technical Study on UAV Characteristics\
    \ for Precision Agriculture\nApplications and Associated Practical Challenges.\
    \ Remote Sens. 2021, 13, 1204. [CrossRef]\n51.\nTsouros, D.C.; Triantafyllou,\
    \ A.; Bibi, S.; Sarigannidis, P.G. Data acquisition and analysis methods in UAV-based\
    \ applications for\nPrecision Agriculture. In Proceedings of the 2019 15th International\
    \ Conference on Distributed Computing in Sensor Systems\n(DCOSS), Santorini Island,\
    \ Greece, 29–31 May 2019; pp. 377–384.\n52.\nTahir, M.N.; Lan, Y.; Zhang, Y.;\
    \ Wang, Y.; Nawaz, F.; Shah, M.A.A.; Gulzar, A.; Qureshi, W.S.; Naqvi, S.M.; Naqvi,\
    \ S.Z.A. Real time\nestimation of leaf area index and groundnut yield using multispectral\
    \ UAV. Int. J. Precis. Agric. Aviat. 2020, 3.\n53.\nStroppiana, D.; Villa, P.;\
    \ Sona, G.; Ronchetti, G.; Candiani, G.; Pepe, M.; Busetto, L.; Migliazzi, M.;\
    \ Boschetti, M. Early season\nweed mapping in rice crops using multi-spectral\
    \ UAV data. Int. J. Remote Sens. 2018, 39, 5432–5452. [CrossRef]\n54.\nWang, H.;\
    \ Mortensen, A.K.; Mao, P.; Boelt, B.; Gislum, R. Estimating the nitrogen nutrition\
    \ index in grass seed crops using a\nUAV-mounted multispectral camera. Int. J.\
    \ Remote Sens. 2019, 40, 2467–2482. [CrossRef]\n55.\nIshida, T.; Kurihara, J.;\
    \ Viray, F.A.; Namuco, S.B.; Paringit, E.C.; Perez, G.J.; Takahashi, Y.; Marciano,\
    \ J.J., Jr. A novel approach for\nvegetation classiﬁcation using UAV-based hyperspectral\
    \ imaging. Comput. Electron. Agric. 2018, 144, 80–85. [CrossRef]\n56.\nGe, X.;\
    \ Wang, J.; Ding, J.; Cao, X.; Zhang, Z.; Liu, J.; Li, X. Combining UAV-based\
    \ hyperspectral imagery and machine learning\nalgorithms for soil moisture content\
    \ monitoring. PeerJ 2019, 7, e6926. [CrossRef] [PubMed]\n57.\nZhao, X.; Yang,\
    \ G.; Liu, J.; Zhang, X.; Xu, B.; Wang, Y.; Zhao, C.; Gai, J. Estimation of soybean\
    \ breeding yield based on optimization\nof spatial scale of UAV hyperspectral\
    \ image. Trans. Chin. Soc. Agric. Eng. 2017, 33, 110–116.\n58.\nPrakash, A. Thermal\
    \ remote sensing: Concepts, issues and applications. Int. Arch. Photogramm. Remote\
    \ Sens. 2000, 33, 239–243.\n59.\nWeng, Q. Thermal infrared remote sensing for\
    \ urban climate and environmental studies: Methods, applications, and trends.\n\
    ISPRS J. Photogramm. Remote Sens. 2009, 64, 335–344. [CrossRef]\n60.\nKhanal,\
    \ S.; Fulton, J.; Shearer, S. An overview of current and potential applications\
    \ of thermal remote sensing in precision\nagriculture. Comput. Electron. Agric.\
    \ 2017, 139, 22–32. [CrossRef]\n61.\nDong, P.; Chen, Q. LiDAR Remote Sensing and\
    \ Applications; CRC Press: Boca Raton, FL, USA, 2017.\n62.\nZhou, L.; Gu, X.;\
    \ Cheng, S.; Yang, G.; Shu, M.; Sun, Q. Analysis of plant height changes of lodged\
    \ maize using UAV-LiDAR data.\nAgriculture 2020, 10, 146. [CrossRef]\n63.\nShendryk,\
    \ Y.; Sofonia, J.; Garrard, R.; Rist, Y.; Skocaj, D.; Thorburn, P. Fine-scale\
    \ prediction of biomass and leaf nitrogen content in\nsugarcane using UAV LiDAR\
    \ and multispectral imaging. Int. J. Appl. Earth Obs. Geoinf. 2020, 92, 102177.\
    \ [CrossRef]\n64.\nNdikumana, E.; Minh, D.H.T.; Baghdadi, N.; Courault, D.; Hossard,\
    \ L. Deep Recurrent Neural Network for Agricultural\nClassiﬁcation using multitemporal\
    \ SAR Sentinel-1 for Camargue, France. Remote Sens. 2018, 10, 1217. [CrossRef]\n\
    65.\nLyalin, K.S.; Biryuk, A.A.; Sheremet, A.Y.; Tsvetkov, V.K.; Prikhodko, D.V.\
    \ UAV synthetic aperture radar system for control\nof vegetation and soil moisture.\
    \ In Proceedings of the 2018 IEEE Conference of Russian Young Researchers in Electrical\
    \ and\nElectronic Engineering (EIConRus), St. Petersburg and Moscow, Russia, 29\
    \ January–1 February 2018; pp. 1673–1675.\nRemote Sens. 2021, 13, 4387\n25 of\
    \ 31\n66.\nLiu, C.-A.; Chen, Z.-X.; Shao, Y.; Chen, J.-S.; Hasi, T.; Pan, H.-Z.\
    \ Research advances of SAR remote sensing for agriculture\napplications: A review.\
    \ J. Integr. Agric. 2019, 18, 506–525. [CrossRef]\n67.\nPádua, L.; Vanko, J.;\
    \ Hruška, J.; Adão, T.; Sousa, J.J.; Peres, E.; Morais, R. UAS, sensors, and data\
    \ processing in agroforestry: A\nreview towards practical applications. Int. J.\
    \ Remote Sens. 2017, 38, 2349–2391. [CrossRef]\n68.\nAllred, B.; Eash, N.; Freeland,\
    \ R.; Martinez, L.; Wishart, D. Effective and efﬁcient agricultural drainage pipe\
    \ mapping with UAS\nthermal infrared imagery: A case study. Agric. Water Manag.\
    \ 2018, 197, 132–137. [CrossRef]\n69.\nSantesteban, L.G.; Di Gennaro, S.F.; Herrero-Langreo,\
    \ A.; Miranda, C.; Royo, J.; Matese, A. High-resolution UAV-based thermal\nimaging\
    \ to estimate the instantaneous and seasonal variability of plant water status\
    \ within a vineyard. Agric. Water Manag. 2017,\n183, 49–59. [CrossRef]\n70.\n\
    Xue, J.; Su, B. Signiﬁcant Remote Sensing Vegetation Indices: A Review of Developments\
    \ and Applications. J. Sensors 2017,\n2017, 1–17. [CrossRef]\n71.\nDai, B.; He,\
    \ Y.; Gu, F.; Yang, L.; Han, J.; Xu, W. A vision-based autonomous aerial spray\
    \ system for precision agriculture. In\nProceedings of the 2017 IEEE International\
    \ Conference on Robotics and Biomimetics (ROBIO), Macau, China, 5–8 December 2017;\n\
    pp. 507–513.\n72.\nFaiçal, B.S.; Freitas, H.; Gomes, P.H.; Mano, L.; Pessin, G.;\
    \ de Carvalho, A.; Krishnamachari, B.; Ueyama, J. An adaptive approach\nfor UAV-based\
    \ pesticide spraying in dynamic environments. Comput. Electron. Agric. 2017, 138,\
    \ 210–223. [CrossRef]\n73.\nFaiçal, B.S.; Pessin, G.; Filho, G.P.R.; Carvalho,\
    \ A.C.P.L.F.; Gomes, P.H.; Ueyama, J. Fine-Tuning of UAV Control Rules for Spraying\n\
    Pesticides on Crop Fields: An Approach for Dynamic Environments. Int. J. Artif.\
    \ Intell. Tools 2016, 25, 1660003. [CrossRef]\n74.\nEsposito, M.; Crimaldi, M.;\
    \ Cirillo, V.; Sarghini, F.; Maggio, A. Drone and sensor technology for sustainable\
    \ weed management: A\nreview. Chem. Biol. Technol. Agric. 2021, 8, 18. [CrossRef]\n\
    75.\nBah, M.D.; Dericquebourg, E.; Haﬁane, A.; Canals, R. Deep Learning based\
    \ Classiﬁcation System for Identifying Weeds using High-\nResolution UAV Imagery.\
    \ Science and Information Conference; Springer: Berlin/Heidelberg, Germany, 2018;\
    \ pp. 176–187.\n76.\nHuang, H.; Deng, J.; Lan, Y.; Yang, A.; Deng, X.; Zhang,\
    \ L. A fully convolutional network for weed mapping of unmanned aerial\nvehicle\
    \ (UAV) imagery. PLoS ONE 2018, 13, e0196302. [CrossRef]\n77.\nOlsen, A.; Konovalov,\
    \ D.A.; Philippa, B.; Ridd, P.; Wood, J.C.; Johns, J.; Banks, W.; Girgenti, B.;\
    \ Kenny, O.; Whinney, J.; et al.\nDeepWeeds: A Multiclass Weed Species Image Dataset\
    \ for Deep Learning. Sci. Rep. UK 2019, 9, 1–12. [CrossRef]\n78.\nSa, I.; Popovi´c,\
    \ M.; Khanna, R.; Chen, Z.; Lottes, P.; Liebisch, F.; Nieto, J.; Stachniss, C.;\
    \ Walter, A.; Siegwart, R. WeedMap: A\nLarge-Scale Semantic Weed Mapping Framework\
    \ Using Aerial Multispectral Imaging and Deep Neural Network for Precision\nFarming.\
    \ Remote Sens. 2018, 10, 1423. [CrossRef]\n79.\nScherrer, B.; Sheppard, J.; Jha,\
    \ P.; Shaw, J.A. Hyperspectral imaging and neural networks to classify herbicide-resistant\
    \ weeds. J.\nAppl. Remote Sens. 2019, 13, 044516. [CrossRef]\n80.\nHuang, H.;\
    \ Lan, Y.; Yang, A.; Zhang, Y.; Wen, S.; Deng, J. Deep learning versus Object-based\
    \ Image Analysis (OBIA) in weed\nmapping of UAV imagery. Int. J. Remote Sens.\
    \ 2020, 41, 3446–3479. [CrossRef]\n81.\nHasan, R.I.; Yusuf, S.M.; Alzubaidi, L.\
    \ Review of the State of the Art of Deep Learning for Plant Diseases: A Broad\
    \ Analysis and\nDiscussion. Plants 2020, 9, 1302. [CrossRef] [PubMed]\n82.\nAbdulridha,\
    \ J.; Batuman, O.; Ampatzidis, Y. UAV-Based Remote Sensing Technique to Detect\
    \ Citrus Canker Disease Utilizing\nHyperspectral Imaging and Machine Learning.\
    \ Remote Sens. 2019, 11, 1373. [CrossRef]\n83.\nTetila, E.C.; Machado, B.B.; Astolﬁ,\
    \ G.; Belete, N.A.D.S.; Amorim, W.P.; Roel, A.R.; Pistori, H. Detection and classiﬁcation\
    \ of\nsoybean pests using deep learning with UAV images. Comput. Electron. Agric.\
    \ 2020, 179, 105836. [CrossRef]\n84.\nZhang, X.; Han, L.; Dong, Y.; Shi, Y.; Huang,\
    \ W.; Han, L.; González-Moreno, P.; Ma, H.; Ye, H.; Sobeih, T. A Deep Learning-Based\n\
    Approach for Automated Yellow Rust Disease Detection from High-Resolution Hyperspectral\
    \ UAV Images. Remote Sens. 2019,\n11, 1554. [CrossRef]\n85.\nHu, G.; Yin, C.;\
    \ Wan, M.; Zhang, Y.; Fang, Y. Recognition of diseased Pinus trees in UAV images\
    \ using deep learning and AdaBoost\nclassiﬁer. Biosyst. Eng. 2020, 194, 138–151.\
    \ [CrossRef]\n86.\nTetila, E.C.; Machado, B.B.; Menezes, G.K.; Oliveira, A.D.S.;\
    \ Alvarez, M.; Amorim, W.P.; Belete, N.A.D.S.; Da Silva, G.G.; Pistori, H.\nAutomatic\
    \ Recognition of Soybean Leaf Diseases Using UAV Images and Deep Convolutional\
    \ Neural Networks. IEEE Geosci.\nRemote Sens. Lett. 2019, 17, 903–907. [CrossRef]\n\
    87.\nWiesner-Hanks, T.; Wu, H.; Stewart, E.; DeChant, C.; Kaczmar, N.; Lipson,\
    \ H.; Gore, M.A.; Nelson, R.J. Millimeter-Level Plant\nDisease Detection from\
    \ Aerial Photographs via Deep Learning and Crowdsourced Data. Front. Plant Sci.\
    \ 2019, 10, 1550. [CrossRef]\n88.\nAlbetis, J.; Jacquin, A.; Goulard, M.; Poilvé,\
    \ H.; Rousseau, J.; Clenet, H.; Dedieu, G.; Duthoit, S. On the Potentiality of\
    \ UAV\nMultispectral Imagery to Detect Flavescence dorée and Grapevine Trunk Diseases.\
    \ Remote Sens. 2018, 11, 23. [CrossRef]\n89.\nKerkech, M.; Haﬁane, A.; Canals,\
    \ R. Vine disease detection in UAV multispectral images using optimized image\
    \ registration and\ndeep learning segmentation approach. Comput. Electron. Agric.\
    \ 2020, 174, 105446. [CrossRef]\n90.\nBendig, J.; Willkomm, M.; Tilly, N.; Gnyp,\
    \ M.L.; Bennertz, S.; Qiang, C.; Miao, Y.; Lenz-Wiedemann, V.I.S.; Bareth, G.\
    \ Very high\nresolution crop surface models (CSMs) from UAV-based stereo images\
    \ for rice growth monitoring In Northeast China. Int. Arch.\nPhotogramm. Remote\
    \ Sens. Spat. Inf. Sci. 2013, 40, 45–50. [CrossRef]\n91.\nNi, J.; Yao, L.; Zhang,\
    \ J.; Cao, W.; Zhu, Y.; Tai, X. Development of an Unmanned Aerial Vehicle-Borne\
    \ Crop-Growth Monitoring\nSystem. Sensors 2017, 17, 502. [CrossRef]\nRemote Sens.\
    \ 2021, 13, 4387\n26 of 31\n92.\nFu, Z.; Jiang, J.; Gao, Y.; Krienke, B.; Wang,\
    \ M.; Zhong, K.; Cao, Q.; Tian, Y.; Zhu, Y.; Cao, W.; et al. Wheat Growth Monitoring\
    \ and\nYield Estimation based on Multi-Rotor Unmanned Aerial Vehicle. Remote Sens.\
    \ 2020, 12, 508. [CrossRef]\n93.\nZhao, J.; Zhang, X.; Gao, C.; Qiu, X.; Tian,\
    \ Y.; Zhu, Y.; Cao, W. Rapid Mosaicking of Unmanned Aerial Vehicle (UAV) Images\
    \ for\nCrop Growth Monitoring Using the SIFT Algorithm. Remote Sens. 2019, 11,\
    \ 1226. [CrossRef]\n94.\nLi, B.; Xu, X.; Zhang, L.; Han, J.; Bian, C.; Li, G.;\
    \ Liu, J.; Jin, L. Above-ground biomass estimation and yield prediction in potato\
    \ by\nusing UAV-based RGB and hyperspectral imaging. ISPRS J. Photogramm. Remote\
    \ Sens. 2020, 162, 161–172. [CrossRef]\n95.\nMaimaitijiang, M.; Sagan, V.; Sidike,\
    \ P.; Hartling, S.; Esposito, F.; Fritschi, F.B. Soybean yield prediction from\
    \ UAV using\nmultimodal data fusion and deep learning. Remote Sens. Environ. 2020,\
    \ 237, 111599. [CrossRef]\n96.\nNebiker, S.; Lack, N.; Abächerli, M.; Läderach,\
    \ S. Light-weight multispectral UAV sensors and their capabilities for predicting\n\
    grain yield and detecting plant diseases. Int. Arch. Photogramm. Remote Sens.\
    \ Spat. Inf. Sci. 2016, 41.\n97.\nStroppiana, D.; Migliazzi, M.; Chiarabini, V.;\
    \ Crema, A.; Musanti, M.; Franchino, C.; Villa, P. Rice yield estimation using\n\
    multispectral data from UAV: A preliminary experiment in northern Italy. In Proceedings\
    \ of the 2015 IEEE International\nGeoscience and Remote Sensing Symposium (IGARSS),\
    \ Milan, Italy, 26–31 July 2015; pp. 4467–4664.\n98.\nKussul, N.; Lavreniuk, M.;\
    \ Skakun, S.; Shelestov, A. Deep Learning Classiﬁcation of Land Cover and Crop\
    \ Types Using Remote\nSensing Data. IEEE Geosci. Remote Sens. Lett. 2017, 14,\
    \ 778–782. [CrossRef]\n99.\nTeimouri, N.; Dyrmann, M.; Jørgensen, R.N. A Novel\
    \ Spatio-Temporal FCN-LSTM Network for Recognizing Various Crop Types\nUsing Multi-Temporal\
    \ Radar Images. Remote Sens. 2019, 11, 990. [CrossRef]\n100. Wang, S.; Di Tommaso,\
    \ S.; Faulkner, J.; Friedel, T.; Kennepohl, A.; Strey, R.; Lobell, D. Mapping\
    \ Crop Types in Southeast India\nwith Smartphone Crowdsourcing and Deep Learning.\
    \ Remote Sens. 2020, 12, 2957. [CrossRef]\n101. Rebetez, J.; Satizábal, H.F.;\
    \ Mota, M.; Noll, D.; Büchi, L.; Wendling, M.; Cannelle, B.; Perez-Uribe, A.;\
    \ Burgos, S. Augmenting a\nConvolutional Neural Network with Local Histograms-A\
    \ Case Study in Crop Classiﬁcation from High-Resolution UAV Imagery; ESANN:\n\
    Bruges, Belgium, 2016.\n102. Zhao, L.; Shi, Y.; Liu, B.; Hovis, C.; Duan, Y.;\
    \ Shi, Z. Finer Classiﬁcation of Crops by Fusing UAV Images and Sentinel-2A Data.\n\
    Remote Sens. 2019, 11, 3012. [CrossRef]\n103. Hinton, G.E.; Salakhutdinov, R.R.\
    \ Reducing the Dimensionality of Data with Neural Networks. Science 2006, 313,\
    \ 504–507.\n[CrossRef]\n104. Krizhevsky, A.; Sutskever, I.; Hinton, G.E. ImageNet\
    \ classiﬁcation with deep convolutional neural networks. Adv. Neural Inf.\nProcess.\
    \ Syst. 2012, 25, 1097–1105. [CrossRef]\n105. Szegedy, C.; Liu, W.; Jia, Y.; Sermanet,\
    \ P.; Reed, S.; Anguelov, D.; Erhan, D.; Vanhoucke, V.; Rabinovich, A. Going deeper\n\
    with convolutions. In Proceedings of the IEEE Conference on Computer Vision and\
    \ Pattern Recognition, Boston, MA, USA,\n7–12 June 2015; pp. 1–9.\n106. He, K.;\
    \ Zhang, X.; Ren, S.; Sun, J. Deep Residual Learning for Image Recognition. In\
    \ Proceedings of the 2016 IEEE Conference on\nComputer Vision and Pattern Recognition\
    \ (CVPR), Las Vegas, NV, USA, 27–30 June 2016; pp. 770–778.\n107. Goodfellow,\
    \ I.; Pouget-Abadie, J.; Mirza, M.; Xu, B.; Warde-Farley, D.; Ozair, S.; Courville,\
    \ A.; Bengio, Y. Generative adversarial\nnets. Adv. Neural Inf. Process. Syst.\
    \ 2014, 27.\n108. Reyes, M.F.; Auer, S.; Merkle, N.M.; Henry, C.; Schmitt, M.\
    \ SAR-to-Optical Image Translation Based on Conditional Generative\nAdversarial\
    \ Networks - Optimization, Opportunities and Limits. Remote Sens. 2019, 11, 2067.\
    \ [CrossRef]\n109. Wang, X.; Yan, H.; Huo, C.; Yu, J.; Pant, C. Enhancing Pix2Pix\
    \ for Remote Sensing Image Classiﬁcation. In Proceedings of the\nInternational\
    \ Conference on Pattern Recognition, Beijing, China, 20–24 August 2018; pp. 2332–2336.\n\
    110. Lv, N.; Ma, H.; Chen, C.; Pei, Q.; Zhou, Y.; Xiao, F.; Li, J. Remote Sensing\
    \ Data Augmentation Through Adversarial Training. Int.\nGeosci. Remote Sens. Symp.\
    \ 2020, 2511–2514.\n111. Ren, C.X.; Ziemann, A.; Theiler, J.; Durieux, A.M.S.\
    \ Deep snow: Synthesizing remote sensing imagery with generative adversarial\n\
    nets. In Proceedings of the 2020 Algorithms, Technologies, and Applications for\
    \ Multispectral and Hyperspectral Imagery XXVI,\nOnline only, 19 May 2020; pp.\
    \ 196–205. [CrossRef]\n112. Everingham, M.; Eslami, S.M.A.; Van Gool, L.; Williams,\
    \ C.K.I.; Winn, J.; Zisserman, A. The Pascal Visual Object Classes Challenge:\n\
    A Retrospective. Int. J. Comput. Vis. 2015, 111, 98–136. [CrossRef]\n113. Ha,\
    \ J.G.; Moon, H.; Kwak, J.T.; Hassan, S.I.; Dang, M.; Lee, O.N.; Park, H.Y. Deep\
    \ convolutional neural network for classifying\nFusarium wilt of radish from unmanned\
    \ aerial vehicles. J. Appl. Remote Sens. 2017, 11. [CrossRef]\n114. Huang, H.;\
    \ Deng, J.; Lan, Y.; Yang, A.; Zhang, L.; Wen, S.; Zhang, H.; Zhang, Y.; Deng,\
    \ Y. Detection of Helminthosporium Leaf\nBlotch Disease Based on UAV Imagery.\
    \ Appl. Sci. 2019, 9, 558. [CrossRef]\n115. De Camargo, T.; Schirrmann, M.; Landwehr,\
    \ N.; Dammer, K.-H.; Pﬂanz, M. Optimized Deep Learning Model as a Basis for Fast\n\
    UAV Mapping of Weed Species in Winter Wheat Crops. Remote Sens. 2021, 13, 1704.\
    \ [CrossRef]\n116. Ukaegbu, U.; Tartibu, L.; Okwu, M.; Olayode, I. Development\
    \ of a Light-Weight Unmanned Aerial Vehicle for Precision\nAgriculture. Sensors\
    \ 2021, 21, 4417. [CrossRef]\n117. Onishi, M.; Ise, T. Automatic classiﬁcation\
    \ of trees using a UAV onboard camera and deep learning. arXiv Prepr. 2018,\n\
    arXiv:1804.10390.\n118. Zhao, J.; Zhong, Y.; Hu, X.; Wei, L.; Zhang, L. A robust\
    \ spectral-spatial approach to identifying heterogeneous crops using remote\n\
    sensing imagery with high spectral and spatial resolutions. Remote Sens. Environ.\
    \ 2020, 239, 111605. [CrossRef]\nRemote Sens. 2021, 13, 4387\n27 of 31\n119. Chen,\
    \ C.-J.; Huang, Y.-Y.; Li, Y.-S.; Chen, Y.-C.; Chang, C.-Y.; Huang, Y.-M. Identiﬁcation\
    \ of Fruit Tree Pests with Deep Learning\non Embedded Drone to Achieve Accurate\
    \ Pesticide Spraying. IEEE Access 2021, 9, 21986–21997. [CrossRef]\n120. Li, F.;\
    \ Liu, Z.; Shen, W.; Wang, Y.; Wang, Y.; Ge, C.; Sun, F.; Lan, P. A Remote Sensing\
    \ and Airborne Edge-Computing Based\nDetection System for Pine Wilt Disease. IEEE\
    \ Access 2021, 9, 66346–66360. [CrossRef]\n121. Valente, J.; Doldersum, M.; Roers,\
    \ C.; Kooistra, L. Detecting rumex obtusifolius weed plants in grasslands from\
    \ UAV RGB imagery\nusing deep learning. ISPRS Ann. Photogramm. Remote Sens. Spat.\
    \ Inf. Sci. 2019, 4, 179–185. [CrossRef]\n122. Veeranampalayam Sivakumar, A.N.;\
    \ Li, J.; Scott, S.; Psota, E.; Jhala, A.J.; Luck, J.D.; Shi, Y. Comparison of\
    \ object detection\nand patch-based classiﬁcation deep learning models on mid-to\
    \ late-season weed detection in UAV imagery. Remote Sens. 2020,\n12, 2136. [CrossRef]\n\
    123. Apolo-Apolo, O.; Martínez-Guanter, J.; Egea, G.; Raja, P.; Pérez-Ruiz, M.\
    \ Deep learning techniques for estimation of the yield and\nsize of citrus fruits\
    \ using a UAV. Eur. J. Agron. 2020, 115, 126030. [CrossRef]\n124. Chen, Y.; Lee,\
    \ W.S.; Gan, H.; Peres, N.; Fraisse, C.; Zhang, Y.; He, Y. Strawberry Yield Prediction\
    \ Based on a Deep Neural Network\nUsing High-Resolution Aerial Orthoimages. Remote\
    \ Sens. 2019, 11, 1584. [CrossRef]\n125. Csillik, O.; Cherbini, J.; Johnson, R.;\
    \ Lyons, A.; Kelly, M. Identiﬁcation of Citrus Trees from Unmanned Aerial Vehicle\
    \ Imagery\nUsing Convolutional Neural Networks. Drones 2018, 2, 39. [CrossRef]\n\
    126. Zhang, Z.; Flores, P.; Igathinathane, C.; Naik, D.L.; Kiran, R.; Ransom,\
    \ J.K. Wheat Lodging Detection from UAS Imagery Using\nMachine Learning Algorithms.\
    \ Remote Sens. 2020, 12, 1838. [CrossRef]\n127. Stewart, E.L.; Wiesner-Hanks,\
    \ T.; Kaczmar, N.; DeChant, C.; Wu, H.; Lipson, H.; Nelson, R.J.; Gore, M.A. Quantitative\
    \ Phenotyping\nof Northern Leaf Blight in UAV Images Using Deep Learning. Remote\
    \ Sens. 2019, 11, 2209. [CrossRef]\n128. Kerkech, M.; Haﬁane, A.; Canals, R. VddNet:\
    \ Vine Disease Detection Network Based on Multispectral Images and Depth Map.\n\
    Remote Sens. 2020, 12, 3305. [CrossRef]\n129. Zou, K.; Chen, X.; Zhang, F.; Zhou,\
    \ H.; Zhang, C. A Field Weed Density Evaluation Method Based on UAV Imaging and\
    \ Modiﬁed\nU-Net. Remote Sens. 2021, 13, 310. [CrossRef]\n130. Osco, L.P.; Nogueira,\
    \ K.; Ramos, A.P.M.; Pinheiro, M.M.F.; Furuya, D.E.G.; Gonçalves, W.N.; Jorge,\
    \ L.A.D.C.; Junior, J.M.;\ndos Santos, J.A. Semantic segmentation of citrus-orchard\
    \ using deep neural networks and multispectral UAV-based imagery.\nPrecis. Agric.\
    \ 2021, 22, 1–18. [CrossRef]\n131. Zhang, J.; Xie, T.; Yang, C.; Song, H.; Jiang,\
    \ Z.; Zhou, G.; Zhang, D.; Feng, H.; Xie, J. Segmenting Purple Rapeseed Leaves\
    \ in the\nField from UAV RGB Imagery Using Deep Learning as an Auxiliary Means\
    \ for Nitrogen Stress Detection. Remote Sens. 2020,\n12, 1403. [CrossRef]\n132.\
    \ Xu, W.; Yang, W.; Chen, S.; Wu, C.; Chen, P.; Lan, Y. Establishing a model to\
    \ predict the single boll weight of cotton in northern\nXinjiang by using high\
    \ resolution UAV remote sensing data. Comput. Electron. Agric. 2020, 179, 105762.\
    \ [CrossRef]\n133. Champ, J.; Mora-Fallas, A.; Goëau, H.; Mata-Montero, E.; Bonnet,\
    \ P.; Joly, A. Instance segmentation for the ﬁne detection of crop\nand weed plants\
    \ by precision agricultural robots. Appl. Plant Sci. 2020, 8, e11373. [CrossRef]\
    \ [PubMed]\n134. Mora-Fallas, A.; Goëau, H.; Joly, A.; Bonnet, P.; Mata-Montero,\
    \ E. Instance segmentation for automated weeds and crops detection\nin farmlands.\
    \ A ﬁrst approach to Acoustic Characterization of Costa Rican Children’s Speech.\
    \ 2020. Available online: https:\n//www.academia.edu/44819282/A_ﬁrst_approach_to_Acoustic_Characterization_of_Costa_Rican_Children_s_Speech\
    \ (accessed\non 17 October 2021).\n135. Toda, Y.; Okura, F.; Ito, J.; Okada, S.;\
    \ Kinoshita, T.; Tsuji, H.; Saisho, D. Training instance segmentation neural network\
    \ with\nsynthetic datasets for crop seed phenotyping. Commun. Biol. 2020, 3, 173.\
    \ [CrossRef]\n136. Khan, S.; Tufail, M.; Khan, M.T.; Khan, Z.A.; Iqbal, J.; Wasim,\
    \ A. Real-time recognition of spraying area for UAV sprayers using a\ndeep learning\
    \ approach. PLoS ONE 2021, 16, e0249436. [CrossRef]\n137. Deng, J.; Zhong, Z.;\
    \ Huang, H.; Lan, Y.; Han, Y.; Zhang, Y. Lightweight Semantic Segmentation Network\
    \ for Real-Time Weed\nMapping Using Unmanned Aerial Vehicles. Appl. Sci. 2020,\
    \ 10, 7132. [CrossRef]\n138. Liu, C.; Li, H.; Su, A.; Chen, S.; Li, W. Identiﬁcation\
    \ and Grading of Maize Drought on RGB Images of UAV Based on Improved\nU-Net.\
    \ IEEE Geosci. Remote Sens. Lett. 2020, 18, 198–202. [CrossRef]\n139. Tri, N.C.;\
    \ Duong, H.N.; Van Hoai, T.; Van Hoa, T.; Nguyen, V.H.; Toan, N.T.; Snasel, V.\
    \ A novel approach based on deep learning\ntechniques and UAVs to yield assessment\
    \ of paddy ﬁelds. In Proceedings of the 2017 9th International Conference on Knowledge\n\
    and Systems Engineering (KSE), Hue, Vietnam, 19–21 October 2017; pp. 257–262.\n\
    140. Osco, L.P.; Arruda, M.D.S.D.; Gonçalves, D.N.; Dias, A.; Batistoti, J.; de\
    \ Souza, M.; Gomes, F.D.G.; Ramos, A.P.M.; Jorge, L.A.D.C.;\nLiesenberg, V.; et\
    \ al. A CNN approach to simultaneously count plants and detect plantation-rows\
    \ from UAV imagery. ISPRS J.\nPhotogramm. Remote Sens. 2021, 174, 1–17. [CrossRef]\n\
    141. Osco, L.P.; Arruda, M.D.S.D.; Junior, J.M.; da Silva, N.B.; Ramos, A.P.M.;\
    \ Moryia, A.S.; Imai, N.N.; Pereira, D.R.; Creste, J.E.;\nMatsubara, E.; et al.\
    \ A convolutional neural network approach for counting and geolocating citrus-trees\
    \ in UAV multispectral\nimagery. ISPRS J. Photogramm. Remote Sens. 2020, 160,\
    \ 97–106. [CrossRef]\n142. Zheng, J.; Fu, H.; Li, W.; Wu, W.; Yu, L.; Yuan, S.;\
    \ Tao, W.Y.W.; Pang, T.K.; Kanniah, K.D. Growing status observation for oil palm\n\
    trees using Unmanned Aerial Vehicle (UAV) images. ISPRS J. Photogramm. Remote\
    \ Sens. 2021, 173, 95–121. [CrossRef]\n143. Ampatzidis, Y.; Partel, V.; Costa,\
    \ L. Agroview: Cloud-based application to process, analyze and visualize UAV-collected\
    \ data for\nprecision agriculture applications utilizing artiﬁcial intelligence.\
    \ Comput. Electron. Agric. 2020, 174, 105457. [CrossRef]\nRemote Sens. 2021, 13,\
    \ 4387\n28 of 31\n144. Pang, Y.; Shi, Y.; Gao, S.; Jiang, F.; Veeranampalayam-Sivakumar,\
    \ A.-N.; Thompson, L.; Luck, J.; Liu, C. Improved crop row\ndetection with deep\
    \ neural network for early-season maize stand count in UAV imagery. Comput. Electron.\
    \ Agric. 2020, 178, 105766.\n[CrossRef]\n145. Wu, J.; Yang, G.; Yang, X.; Xu,\
    \ B.; Han, L.; Zhu, Y. Automatic Counting of in situ Rice Seedlings from UAV Images\
    \ Based on a\nDeep Fully Convolutional Neural Network. Remote Sens. 2019, 11,\
    \ 691. [CrossRef]\n146. Yang, M.-D.; Tseng, H.-H.; Hsu, Y.-C.; Yang, C.-Y.; Lai,\
    \ M.-H.; Wu, D.-H. A UAV Open Dataset of Rice Paddies for Deep Learning\nPractice.\
    \ Remote Sens. 2021, 13, 1358. [CrossRef]\n147. Zhao, W.; Yamada, W.; Li, T.;\
    \ Digman, M.; Runge, T. Augmenting Crop Detection for Precision Agriculture with\
    \ Deep Visual\nTransfer Learning—A Case Study of Bale Detection. Remote Sens.\
    \ 2020, 13, 23. [CrossRef]\n148. Ampatzidis, Y.; Partel, V. UAV-Based High Throughput\
    \ Phenotyping in Citrus Utilizing Multispectral Imaging and Artiﬁcial\nIntelligence.\
    \ Remote Sens. 2019, 11, 410. [CrossRef]\n149. Aeberli, A.; Johansen, K.; Robson,\
    \ A.; Lamb, D.; Phinn, S. Detection of Banana Plants Using Multi-Temporal Multispectral\
    \ UAV\nImagery. Remote Sens. 2021, 13, 2123. [CrossRef]\n150. Fan, Z.; Lu, J.;\
    \ Gong, M.; Xie, H.; Goodman, E.D. Automatic Tobacco Plant Detection in UAV Images\
    \ via Deep Neural Networks.\nIEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 2018,\
    \ 11, 876–887. [CrossRef]\n151. Zan, X.; Zhang, X.; Xing, Z.; Liu, W.; Zhang,\
    \ X.; Su, W.; Liu, Z.; Zhao, Y.; Li, S. Automatic Detection of Maize Tassels from\
    \ UAV\nImages by Combining Random Forest Classiﬁer and VGG16. Remote Sens. 2020,\
    \ 12, 3049. [CrossRef]\n152. Liu, Y.; Cen, C.; Che, Y.; Ke, R.; Ma, Y.; Ma, Y.\
    \ Detection of Maize Tassels from UAV RGB Imagery with Faster R-CNN. Remote Sens.\n\
    2020, 12, 338. [CrossRef]\n153. Yuan, W.; Choi, D. UAV-Based Heating Requirement\
    \ Determination for Frost Management in Apple Orchard. Remote Sens. 2021,\n13,\
    \ 273. [CrossRef]\n154. Dyson, J.; Mancini, A.; Frontoni, E.; Zingaretti, P. Deep\
    \ Learning for Soil and Crop Segmentation from Remotely Sensed Data.\nRemote Sens.\
    \ 2019, 11, 1859. [CrossRef]\n155. Feng, Q.; Yang, J.; Liu, Y.; Ou, C.; Zhu, D.;\
    \ Niu, B.; Liu, J.; Li, B. Multi-Temporal Unmanned Aerial Vehicle Remote Sensing\
    \ for\nVegetable Mapping Using an Attention-Based Recurrent Convolutional Neural\
    \ Network. Remote Sens. 2020, 12, 1668. [CrossRef]\n156. Der Yang, M.; Tseng,\
    \ H.H.; Hsu, Y.C.; Tseng, W.C. Real-time Crop Classiﬁcation Using Edge Computing\
    \ and Deep Learning.\nIn Proceedings of the 2020 IEEE 17th Annual Consumer Communications\
    \ & Networking Conference, Las Vegas, NV, USA,\n10–13 January 2020; pp. 1–4.\n\
    157. Yang, M.-D.; Boubin, J.G.; Tsai, H.P.; Tseng, H.-H.; Hsu, Y.-C.; Stewart,\
    \ C.C. Adaptive autonomous UAV scouting for rice lodging\nassessment using edge\
    \ computing with deep learning EDANet. Comput. Electron. Agric. 2020, 179, 105817.\
    \ [CrossRef]\n158. Zhang, Q.; Liu, Y.; Gong, C.; Chen, Y.; Yu, H. Applications\
    \ of Deep Learning for Dense Scenes Analysis in Agriculture: A Review.\nSensors\
    \ 2020, 20, 1520. [CrossRef] [PubMed]\n159. Zhong, Y.; Hu, X.; Luo, C.; Wang,\
    \ X.; Zhao, J.; Zhang, L. WHU-Hi: UAV-borne hyperspdectral with high spatial resolution\
    \ (H2)\nbenchmark datasets and classiﬁer for precise crop identiﬁcation based\
    \ on deep convolutional neural network with CRF. Remote\nSens. Environ. 2020,\
    \ 250, 112012. [CrossRef]\n160. Wiesner-Hanks, T.; Stewart, E.L.; Kaczmar, N.;\
    \ DeChant, C.; Wu, H.; Nelson, R.J.; Lipson, H.; Gore, M.A. Image set for deep\n\
    learning: Field images of maize annotated with disease symptoms. BMC Res. Notes\
    \ 2018, 11, 440. [CrossRef] [PubMed]\n161. Daudt, R.C.; Le Saux, B.; Boulch, A.;\
    \ Gousseau, Y. Multitask learning for large-scale semantic change detection. Comput.\
    \ Vis.\nImage Underst. 2019, 187, 102783. [CrossRef]\n162. Zhang, Y. CSIF. ﬁgshare.\
    \ Dataset. 2018.\n163. Oldoni, L.V.; Sanches, I.D.; Picoli, M.C.A.; Covre, R.M.;\
    \ Fronza, J.G. LEM+ dataset: For agricultural remote sensing applications.\nData\
    \ Brief 2020, 33, 106553. [CrossRef] [PubMed]\n164. Ferreira, A.; Felipussi, S.C.;\
    \ Pires, R.; Avila, S.; Santos, G.; Lambert, J.; Huang, J.; Rocha, A. Eyes in\
    \ the Skies: A Data-Driven\nFusion Approach to Identifying Drug Crops from Remote\
    \ Sensing Images. IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 2019,\n12, 4773–4786.\
    \ [CrossRef]\n165. Rußwurm, M.; Pelletier, C.; Zollner, M.; Lefèvre, S.; Körner,\
    \ M. BreizhCrops: A time series dataset for crop type mapping.\narXiv Prepr. 2019,\
    \ arXiv:1905.11893. [CrossRef]\n166. Rustowicz, R.; Cheong, R.; Wang, L.; Ermon,\
    \ S.; Burke, M.; Lobell, D. Semantic Segmentation of Crop Type in Ghana Dataset.\n\
    Available online: https://doi.org/10.34911/rdnt.ry138p (accessed on 17 October\
    \ 2021). [CrossRef]\n167. Rustowicz, R.; Cheong, R.; Wang, L.; Ermon, S.; Burke,\
    \ M.; Lobell, D. Semantic Segmentation of Crop Type in South Sudan\nDataset. Available\
    \ online: https://doi.org/10.34911/rdnt.v6kx6n (accessed on 17 October 2021).\
    \ [CrossRef]\n168. Torre, M.; Remeseiro, B.; Radeva, P.; Martinez, F. DeepNEM:\
    \ Deep Network Energy-Minimization for Agricultural Field\nSegmentation. IEEE\
    \ J. Sel. Top. Appl. Earth Obs. Remote Sens. 2020, 13, 726–737. [CrossRef]\n169.\
    \ United States Geological Survey. EarthExplorer. Available online: https://earthexplorer.usgs.gov/\
    \ (accessed on 17 October 2021).\n170. European Space Agency. Copernicus Open\
    \ Access Hub. Available online: https://scihub.copernicus.eu/dhus/#/home (accessed\n\
    on 17 October 2021).\n171. Weikmann, G.; Paris, C.; Bruzzone, L. TimeSen2Crop:\
    \ A Million Labeled Samples Dataset of Sentinel 2 Image Time Series for\nCrop-Type\
    \ Classiﬁcation. IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 2021, 14, 4699–4708.\
    \ [CrossRef]\nRemote Sens. 2021, 13, 4387\n29 of 31\n172. Khan, W.Z.; Ahmed, E.;\
    \ Hakak, S.; Yaqoob, I.; Ahmed, A. Edge computing: A survey. Future Gener. Comput.\
    \ Syst. 2019,\n97, 219–235. [CrossRef]\n173. Liu, J.; Xue, Y.; Ren, K.; Song,\
    \ J.; Windmill, C.; Merritt, P. High-Performance Time-Series Quantitative Retrieval\
    \ from Satellite\nImages on a GPU Cluster. IEEE J. Sel. Top. Appl. Earth Obs.\
    \ Remote Sens. 2019, 12, 2810–2821. [CrossRef]\n174. Hakak, S.; A Latif, S.; Amin,\
    \ G. A Review on Mobile Cloud Computing and Issues in it. Int. J. Comput. Appl.\
    \ 2013, 75, 1–4.\n[CrossRef]\n175. Jeong, H.-J.; Choi, J.D.; Ha, Y.-G. Vision\
    \ Based Displacement Detection for Stabilized UAV Control on Cloud Server. Mob.\
    \ Inf. Syst.\n2016, 2016, 1–11. [CrossRef]\n176. Apolo-Apolo, O.E.; Pérez-Ruiz,\
    \ M.; Guanter, J.M.; Valente, J. A Cloud-Based Environment for Generating Yield\
    \ Estimation Maps\nfrom Apple Orchards Using UAV Imagery and a Deep Learning Technique.\
    \ Front. Plant Sci. 2020, 11, 1086. [CrossRef]\n177. Shi, W.; Cao, J.; Zhang,\
    \ Q.; Li, Y.; Xu, L. Edge Computing: Vision and Challenges. IEEE Internet Things\
    \ J. 2016, 3, 637–646.\n[CrossRef]\n178. Ahmed, E.; Akhunzada, A.; Whaiduzzaman,\
    \ M.; Gani, A.; Ab Hamid, S.H.; Buyya, R. Network-centric performance analysis\
    \ of\nruntime application migration in mobile cloud computing. Simul. Model. Pr.\
    \ Theory 2015, 50, 42–56. [CrossRef]\n179. Horstrand, P.; Guerra, R.; Rodriguez,\
    \ A.; Diaz, M.; Lopez, S.; Lopez, J.F. A UAV Platform Based on a Hyperspectral\
    \ Sensor for\nImage Capturing and On-Board Processing. IEEE Access 2019, 7, 66919–66938.\
    \ [CrossRef]\n180. Da Silva, J.F.; Brito, A.V.; De Lima, J.A.G.; De Moura, H.N.\
    \ An embedded system for aerial image processing from unmanned\naerial vehicles.\
    \ In Proceedings of the 2015 Brazilian Symposium on Computing Systems Engineering\
    \ (SBESC), Foz do Iguacu,\nBrazil, 3–6 November 2015; pp. 154–157.\n181. Xu, D.;\
    \ Li, T.; Li, Y.; Su, X.; Tarkoma, S.; Jiang, T.; Crowcroft, J.; Hui, P. Edge\
    \ Intelligence: Architectures, Challenges, and\nApplications. arXiv Prepr. 2020,\
    \ arXiv:2003.12172.\n182. Sze, V.; Chen, Y.-H.; Yang, T.-J.; Emer, J.S. Efﬁcient\
    \ Processing of Deep Neural Networks: A Tutorial and Survey. Proc. IEEE 2017,\n\
    105, 2295–2329. [CrossRef]\n183. Han, S.; Mao, H.; Dally, W.J. Deep Compression:\
    \ Compressing Deep Neural Networks with Pruning, Trained Quantization\nand Huffman\
    \ Coding. In Proceedings of the International Conference on Learning Representations,\
    \ San Juan, Puerto Rico,\n2–4 May 2016.\n184. Egli, S.; Höpke, M. CNN-Based Tree\
    \ Species Classiﬁcation Using High Resolution RGB Image Data from Automated UAV\n\
    Observations. Remote Sens. 2020, 12, 3892. [CrossRef]\n185. Fountsop, A.N.; Fendji,\
    \ J.L.E.K.; Atemkeng, M. Deep Learning Models Compression for Agricultural Plants.\
    \ Appl. Sci. 2020,\n10, 6866. [CrossRef]\n186. Blekos, K.; Nousias, S.; Lalos,\
    \ A.S. Efﬁcient automated U-Net based tree crown delineation using UAV multi-spectral\
    \ imagery\non embedded devices. In Proceedings of the 2020 IEEE 18th International\
    \ Conference on Industrial Informatics (INDIN),\nWarwick, UK, 20–23 July 2020;\
    \ Volume 1, pp. 541–546.\n187. Iandola, F.N.; Han, S.; Moskewicz, M.W.; Ashraf,\
    \ K.; Dally, W.J.; Keutzer, K. SqueezeNet: AlexNet-level accuracy with 50x fewer\n\
    parameters and <0.5 MB model size. arXiv Prepr. 2016, arXiv:1602.07360.\n188.\
    \ Sandler, M.; Howard, A.; Zhu, M.; Zhmoginov, A.; Chen, L. MobileNetV2: Inverted\
    \ Residuals and Linear Bottlenecks. In\nProceedings of the 2018 IEEE Conference\
    \ on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18–23 June\
    \ 2018;\npp. 4510–4520.\n189. Ma, N.; Zhang, X.; Zheng, H.; Sun, J. ShufﬂeNet\
    \ V2: Practical Guidelines for Efﬁcient CNN Architecture Design. In Proceedings\n\
    of the European Conference on Computer Vision, Salt Lake City, UT, USA, 18–23\
    \ June 2018; pp. 122–138.\n190. Wang, S.; Zhao, J.; Ta, N.; Zhao, X.; Xiao, M.;\
    \ Wei, H. A real-time deep learning forest ﬁre monitoring algorithm based on an\n\
    improved Pruned + KD model. J. Real-Time Image Process. 2021, 1–11. [CrossRef]\n\
    191. Hua, X.; Wang, X.; Rui, T.; Shao, F.; Wang, D. Light-weight UAV object tracking\
    \ network based on strategy gradient and attention\nmechanism. Knowledge-Based\
    \ Syst. 2021, 224, 107071. [CrossRef]\n192. Han, S.; Pool, J.; Tran, J.; Dally,\
    \ W.J. Learning both weights and connections for efﬁcient neural networks. Neural\
    \ Inf. Process. Syst.\n2015, 28, 1135–1143.\n193. Srinivas, S.; Babu, R.V. Data-free\
    \ Parameter Pruning for Deep Neural Networks. In Proceedings of the British Machine\
    \ Vision\nConference 2015 (BMVC), Swansea, UK, 7–10 September 2015. [CrossRef]\n\
    194. Li, H.; Kadav, A.; Durdanovic, I.; Samet, H.; Graf, H.P. Pruning Filters\
    \ for Efﬁcient ConvNets. In Proceedings of the International\nConference on Learning\
    \ Representations, San Juan, Puerto Rico, 2–4 May 2016.\n195. Fan, W.; Xu, Z.;\
    \ Liu, H.; Zongwei, Z. Machine Learning Agricultural Application Based on the\
    \ Secure Edge Computing Platform.\nIn Proceedings of the International Conference\
    \ on Machine Learning, Online. 13–18 July 2020; pp. 206–220.\n196. Lebedev, V.;\
    \ Ganin, Y.; Rakhuba, M.; Oseledets, I.; Lempitsky, V. Speeding-up Convolutional\
    \ Neural Networks Using Fine-\ntuned CP-Decomposition. In Proceedings of the International\
    \ Conference on Learning Representations, San Diego, CA, USA,\n7–9 May 2015.\n\
    197. Kim, Y.; Park, E.; Yoo, S.; Choi, T.; Yang, L.; Shin, D. Compression of deep\
    \ convolutional neural networks for fast and low power\nmobile applications. arXiv\
    \ Prepr. 2015, arXiv:1511.06530.\n198. Jaderberg, M.; Vedaldi, A.; Zisserman,\
    \ A. Speeding up Convolutional Neural Networks with Low Rank Expansions. In\n\
    Proceedings of the British Machine Vision Conference, Nottingham, UK, 1–5 September\
    \ 2014.\nRemote Sens. 2021, 13, 4387\n30 of 31\n199. Zhang, X.; Zou, J.; He, K.;\
    \ Sun, J. Accelerating Very Deep Convolutional Networks for Classiﬁcation and\
    \ Detection. IEEE Trans.\nPattern Anal. Mach. Intell. 2016, 38, 1943–1955. [CrossRef]\
    \ [PubMed]\n200. Falaschetti, L.; Manoni, L.; Rivera, R.C.F.; Pau, D.; Romanazzi,\
    \ G.; Silvestroni, O.; Tomaselli, V.; Turchetti, C. A Low-Cost,\nLow-Power and\
    \ Real-Time Image Detector for Grape Leaf Esca Disease Based on a Compressed CNN.\
    \ IEEE J. Emerg. Sel. Top.\nCircuits Syst. 2021, 11, 468–481. [CrossRef]\n201.\
    \ Chen, W.; Wilson, J.; Tyree, S.; Weinberger, K.; Chen, Y. Compressing Neural\
    \ Networks with the Hashing Trick. Int. Conf.\nMach. Learn. 2015, 3, 2285–2294.\n\
    202. Dettmers, T. 8-Bit Approximations for Parallelism in Deep Learning. In Proceedings\
    \ of the International Conference on Learning\nRepresentations, San Juan, Puerto\
    \ Rico, 2–4 May 2016.\n203. Zhou, A.; Yao, A.; Guo, Y.; Xu, L.; Chen, Y. Incremental\
    \ Network Quantization: Towards Lossless CNNs with Low-precision\nWeights. In\
    \ Proceedings of the International Conference on Learning Representations, Toulon,\
    \ France, 24–26 April 2017.\n204. Choudhary, T.; Mishra, V.; Goswami, A.; Sarangapani,\
    \ J. A comprehensive survey on model compression and acceleration. Artif.\nIntell.\
    \ Rev. 2020, 53, 5113–5155. [CrossRef]\n205. Romero, A.; Ballas, N.; Kahou, S.E.;\
    \ Chassang, A.; Gatta, C.; Bengio, Y. FitNets: Hints for Thin Deep Nets. In Proceedings\
    \ of the\nInternational Conference on Learning Representations, San Diego, CA,\
    \ USA, 7–9 May 2015.\n206. Korattikara, A.; Rathod, V.; Murphy, K.; Welling, M.\
    \ Bayesian dark knowledge. Neural Inf. Process. Syst. 2015, 28, 3438–3446.\n207.\
    \ Kim, J.; Park, S.; Kwak, N. Paraphrasing Complex Network: Network Compression\
    \ via Factor Transfer. Neural Inf. Process. Syst.\n2018, 31, 2760–2769.\n208.\
    \ Gou, J.; Yu, B.; Maybank, S.J.; Tao, D. Knowledge Distillation: A Survey. Int.\
    \ J. Comput. Vis. 2021, 129, 1789–1819. [CrossRef]\n209. La Rosa, L.E.C.; Oliveira,\
    \ D.A.B.; Zortea, M.; Gemignani, B.H.; Feitosa, R.Q. Learning Geometric Features\
    \ for Improving the\nAutomatic Detection of Citrus Plantation Rows in UAV Images.\
    \ IEEE Geosci. Remote Sens. Lett. 2020, 1–5. [CrossRef]\n210. Qiu, W.; Ye, J.;\
    \ Hu, L.; Yang, J.; Li, Q.; Mo, J.; Yi, W. Distilled-MobileNet Model of Convolutional\
    \ Neural Network Simpliﬁed\nStructure for Plant Disease Recognition. Smart Agric.\
    \ 2021, 3, 109.\n211. Ding, M.; Li, N.; Song, Z.; Zhang, R.; Zhang, X.; Zhou,\
    \ H. A Lightweight Action Recognition Method for Unmanned-Aerial-Vehicle\nVideo.\
    \ In Proceedings of the 2020 IEEE 3rd International Conference on Electronics\
    \ and Communication Engineering (ICECE),\nXi’an, China, 14–16 December 2020; pp.\
    \ 181–185.\n212. Dong, J.; Ota, K.; Dong, M. Real-Time Survivor Detection in UAV\
    \ Thermal Imagery Based on Deep Learning. In Proceedings\nof the 2020 16th International\
    \ Conference on Mobility, Sensing and Networking (MSN), Tokyo, Japan, 17–19 December\
    \ 2020;\npp. 352–359.\n213. Sherstjuk, V.; Zharikova, M.; Sokol, I. Forest ﬁre\
    \ monitoring system based on UAV team, remote sensing, and image processing.\n\
    In Proceedings of the 2018 IEEE Second International Conference on Data Stream\
    \ Mining & Processing (DSMP), Lviv, Ukraine,\n21–25 August 2018; pp. 590–594.\n\
    214. Sandino, J.; Vanegas, F.; Maire, F.; Caccetta, P.; Sanderson, C.; Gonzalez,\
    \ F. UAV Framework for Autonomous Onboard Navigation\nand People/Object Detection\
    \ in Cluttered Indoor Environments. Remote Sens. 2020, 12, 3386. [CrossRef]\n\
    215. Jaiswal, D.; Kumar, P. Real-time implementation of moving object detection\
    \ in UAV videos using GPUs. J. Real-Time Image Process.\n2020, 17, 1301–1317.\
    \ [CrossRef]\n216. Saifullah, A.; Agrawal, K.; Lu, C.; Gill, C. Multi-Core Real-Time\
    \ Scheduling for Generalized Parallel Task Models. Real-Time Syst.\n2013, 49,\
    \ 404–435. [CrossRef]\n217. Madroñal, D.; Palumbo, F.; Capotondi, A.; Marongiu,\
    \ A. Unmanned Vehicles in Smart Farming: A Survey and a Glance at Future\nHorizons.\
    \ In Proceedings of the 2021 Drone Systems Engineering (DroneSE) and Rapid Simulation\
    \ and Performance Evaluation:\nMethods and Tools Proceedings (RAPIDO’21), Budapest,\
    \ Hungary, 18–20 January 2021; pp. 1–8.\n218. Li, W.; He, C.; Fu, H.; Zheng, J.;\
    \ Dong, R.; Xia, M.; Yu, L.; Luk, W. A Real-Time Tree Crown Detection Approach\
    \ for Large-Scale\nRemote Sensing Images on FPGAs. Remote Sens. 2019, 11, 1025.\
    \ [CrossRef]\n219. Ma, Y.; Li, Q.; Chu, L.; Zhou, Y.; Xu, C. Real-Time Detection\
    \ and Spatial Localization of Insulators for UAV Inspection Based on\nBinocular\
    \ Stereo Vision. Remote Sens. 2021, 13, 230. [CrossRef]\n220. Rodríguez-Canosa,\
    \ G.R.; Thomas, S.; Del Cerro, J.; Barrientos, A.; MacDonald, B. A Real-Time Method\
    \ to Detect and Track\nMoving Objects (DATMO) from Unmanned Aerial Vehicles (UAVs)\
    \ Using a Single Camera. Remote Sens. 2012, 4, 1090–1111.\n[CrossRef]\n221. Opromolla,\
    \ R.; Fasano, G.; Accardo, D. A Vision-Based Approach to UAV Detection and Tracking\
    \ in Cooperative Applications.\nSensors 2018, 18, 3391. [CrossRef]\n222. Li, B.;\
    \ Zhu, Y.; Wang, Z.; Li, C.; Peng, Z.-R.; Ge, L. Use of Multi-Rotor Unmanned Aerial\
    \ Vehicles for Radioactive Source Search.\nRemote Sens. 2018, 10, 728. [CrossRef]\n\
    223. Rebouças, R.A.; Da Cruz Eller, Q.; Habermann, M.; Shiguemori, E.H. Embedded\
    \ system for visual odometry and localization\nof moving objects in images acquired\
    \ by unmanned aerial vehicles. In Proceedings of the 2013 III Brazilian Symposium\
    \ on\nComputing Systems Engineering, Rio De Janeiro, Brazil, 4–8 December 2013;\
    \ pp. 35–40.\n224. Kizar, S.N.; Satyanarayana, G. Object detection and location\
    \ estimation using SVS for UAVs. In Proceedings of the International\nConference\
    \ on Automatic Control and Dynamic Optimization Techniques, Pune, India, 9–10\
    \ September 2016; pp. 920–924.\n225. Abughalieh, K.M.; Sababha, B.H.; Rawashdeh,\
    \ N.A. A video-based object detection and tracking system for weight sensitive\n\
    UAVs. Multimedia Tools Appl. 2019, 78, 9149–9167. [CrossRef]\nRemote Sens. 2021,\
    \ 13, 4387\n31 of 31\n226. Choi, H.; Geeves, M.; Alsalam, B.; Gonzalez, F. Open\
    \ source computer-vision based guidance system for UAVs on-board decision\nmaking.\
    \ In Proceedings of the 2016 IEEE aerospace conference, Big Sky, MO, USA, 5–12\
    \ March 2016; pp. 1–5.\n227. De Oliveira, D.C.; Wehrmeister, M.A. Using Deep Learning\
    \ and Low-Cost RGB and Thermal Cameras to Detect Pedestrians in\nAerial Images\
    \ Captured by Multirotor UAV. Sensors 2018, 18, 2244. [CrossRef]\n228. Kersnovski,\
    \ T.; Gonzalez, F.; Morton, K. A UAV system for autonomous target detection and\
    \ gas sensing. In Proceedings of the\n2017 IEEE aerospace conference, Big Sky,\
    \ MO, USA, 4–11 March 2017; pp. 1–12.\n229. Basso, M.; Stocchero, D.; Henriques,\
    \ R.V.B.; Vian, A.L.; Bredemeier, C.; Konzen, A.A.; De Freitas, E.P. Proposal\
    \ for an Embedded\nSystem Architecture Using a GNDVI Algorithm to Support UAV-Based\
    \ Agrochemical Spraying. Sensors 2019, 19, 5397. [CrossRef]\n230. Daryanavard,\
    \ H.; Hariﬁ, A. Implementing face detection system on uav using raspberry pi platform.\
    \ In Proceedings of the\nIranian Conference on Electrical Engineering, Mashhad,\
    \ Iran, 8–10 May 2018; pp. 1720–1723.\n231. Safadinho, D.; Ramos, J.; Ribeiro,\
    \ R.; Filipe, V.; Barroso, J.; Pereira, A. UAV Landing Using Computer Vision Techniques\
    \ for\nHuman Detection. Sensors 2020, 20, 613. [CrossRef]\n232. Natesan, S.; Armenakis,\
    \ C.; Benari, G.; Lee, R. Use of UAV-Borne Spectrometer for Land Cover Classiﬁcation.\
    \ Drones 2018, 2, 16.\n[CrossRef]\n233. Benhadhria, S.; Mansouri, M.; Benkhlifa,\
    \ A.; Gharbi, I.; Jlili, N. VAGADRONE: Intelligent and Fully Automatic Drone Based\
    \ on\nRaspberry Pi and Android. Appl. Sci. 2021, 11, 3153. [CrossRef]\n234. Ayoub,\
    \ N.; Schneider-Kamp, P. Real-Time On-Board Deep Learning Fault Detection for\
    \ Autonomous UAV Inspections. Electronics\n2021, 10, 1091. [CrossRef]\n235. Xu,\
    \ L.; Luo, H. Towards autonomous tracking and landing on moving target. In Proceedings\
    \ of the 2016 IEEE International\nConference on Real-time Computing and Robotics\
    \ (RCAR), Angkor Wat, Cambodia, 6–9 June 2016; pp. 620–628.\n236. Genc, H.; Zu,\
    \ Y.; Chin, T.-W.; Halpern, M.; Reddi, V.J. Flying IoT: Toward Low-Power Vision\
    \ in the Sky. IEEE Micro 2017, 37, 40–51.\n[CrossRef]\n237. Meng, L.; Peng, Z.;\
    \ Zhou, J.; Zhang, J.; Lu, Z.; Baumann, A.; Du, Y. Real-Time Detection of Ground\
    \ Objects Based on Unmanned\nAerial Vehicle Remote Sensing with Deep Learning:\
    \ Application in Excavator Detection for Pipeline Safety. Remote Sens. 2020,\n\
    12, 182. [CrossRef]\n238. Tijtgat, N.; Van Ranst, W.; Goedeme, T.; Volckaert,\
    \ B.; De Turck, F. Embedded real-time object detection for a UAV warning\nsystem.\
    \ In Proceedings of the IEEE International Conference on Computer Vision Workshops,\
    \ Venice, Italy, 22–29 October 2017;\npp. 2110–2118.\n239. Melián, J.; Jiménez,\
    \ A.; Díaz, M.; Morales, A.; Horstrand, P.; Guerra, R.; López, S.; López, J. Real-Time\
    \ Hyperspectral Data\nTransmission for UAV-Based Acquisition Platforms. Remote\
    \ Sens. 2021, 13, 850. [CrossRef]\n240. Balamuralidhar, N.; Tilon, S.; Nex, F.\
    \ MultEYE: Monitoring System for Real-Time Vehicle Detection, Tracking and Speed\n\
    Estimation from UAV Imagery on Edge-Computing Platforms. Remote Sens. 2021, 13,\
    \ 573. [CrossRef]\n241. Lammie, C.; Olsen, A.; Carrick, T.; Azghadi, M.R. Low-Power\
    \ and High-Speed Deep FPGA Inference Engines for Weed\nClassiﬁcation at the Edge.\
    \ IEEE Access 2019, 7, 51171–51184. [CrossRef]\n242. Caba, J.; Díaz, M.; Barba,\
    \ J.; Guerra, R.; López, J. FPGA-Based On-Board Hyperspectral Imaging Compression:\
    \ Benchmarking\nPerformance and Energy Efﬁciency against GPU Implementations.\
    \ Remote Sens. 2020, 12, 3741. [CrossRef]\n243. Zoph, B.; Le, Q.V. Neural architecture\
    \ search with reinforcement learning. arXiv Prepr. 2016, arXiv:1611.01578.\n244.\
    \ Liu, D.; Kong, H.; Luo, X.; Liu, W.; Subramaniam, R. Bringing AI to Edge: From\
    \ Deep Learning’s Perspective. arXiv Prepr. 2020,\narXiv:2011.14808.\n245. Pan,\
    \ S.J.; Yang, Q. A Survey on Transfer Learning. IEEE Trans. Knowl. Data Eng. 2009,\
    \ 22, 1345–1359. [CrossRef]\n246. Xiao, T.; Zhang, J.; Yang, K.; Peng, Y.; Zhang,\
    \ Z. Error-driven incremental learning in deep convolutional neural network for\n\
    large-scale image classiﬁcation. In Proceedings of the 22nd ACM international\
    \ conference on Multimedia, Orlando, FL, USA,\n3–7 November 2014; pp. 177–186.\n\
    247. Kai, C.; Zhou, H.; Yi, Y.; Huang, W. Collaborative Cloud-Edge-End Task Ofﬂoading\
    \ in Mobile-Edge Computing Networks With\nLimited Communication Capability. IEEE\
    \ Trans. Cogn. Commun. Netw. 2020, 7, 624–634. [CrossRef]\n248. Bonawitz, K.;\
    \ Eichner, H.; Grieskamp, W.; Huba, D.; Ingerman, A.; Ivanov, V.; Kiddon, C.;\
    \ Koneˇcný, J.; Mazzocchi, S.;\nMcMahan, H.B. Towards federated learning at scale:\
    \ System design. arXiv Prepr. 2019, arXiv:1902.01046.\n"
  inline_citation: '>'
  journal: Remote sensing (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/2072-4292/13/21/4387/pdf?version=1635752510
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: 'Boost Precision Agriculture with Unmanned Aerial Vehicle Remote Sensing
    and Edge Intelligence: A Survey'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/s19153287
  analysis: '>'
  authors:
  - Paula Fraga‐Lamas
  - Mikel Celaya-Echarri
  - Peio López-Iturri
  - Luis Castedo
  - Leyre Azpilicueta
  - Erik Aguirre
  - Manuel Suárez-Albela
  - Francisco Falcone
  - Tiago M. Fernández‐Caramés
  citation_count: 49
  full_citation: '>'
  full_text: '>

    Web Store Add shortcut Name URL Customize Chrome'
  inline_citation: '>'
  journal: Sensors (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/1424-8220/19/15/3287/pdf?version=1564127748
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: Design and Experimental Validation of a LoRaWAN Fog Computing Based Architecture
    for IoT Enabled Smart Campus Applications
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2020.2967777
  analysis: '>'
  authors:
  - Kaya Kuru
  - Darren Ansell
  citation_count: 45
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account
    Personal Sign In Personal Sign In * Required *Email Address *Password Forgot Password?
    Sign In Don''t have a Personal Account? Create an IEEE Account now. Create Account
    Learn more about personalization features. IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/8948470/08963653.pdf
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 'TCitySmartF: A Comprehensive Systematic Framework for Transforming Cities
    Into Smart Cities'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1007/s11370-022-00452-4
  analysis: '>'
  authors:
  - Syed Agha Hassnain Mohsan
  - Nawaf Qasem Hamood Othman
  - Yanlong Li
  - Mohammed H. Alsharif
  - Muhammad Asghar Khan
  citation_count: 35
  full_citation: '>'
  full_text: '>

    Intelligent Service Robotics (2023) 16:109–137

    https://doi.org/10.1007/s11370-022-00452-4

    REVIEW ARTICLE

    Unmanned aerial vehicles (UAVs): practical aspects, applications, open

    challenges, security issues, and future trends

    Syed Agha Hassnain Mohsan1

    · Nawaf Qasem Hamood Othman2 · Yanlong Li1,3 · Mohammed H. Alsharif4 ·

    Muhammad Asghar Khan5

    Received: 8 February 2022 / Accepted: 21 December 2022 / Published online: 16
    January 2023

    © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part
    of Springer Nature 2023

    Abstract

    Recently, unmanned aerial vehicles (UAVs) or drones have emerged as a ubiquitous
    and integral part of our society. They appear

    in great diversity in a multiplicity of applications for economic, commercial,
    leisure, military and academic purposes. The

    drone industry has seen a sharp uptake in the last decade as a model to manufacture
    and deliver convergence, offering synergy

    by incorporating multiple technologies. It is due to technological trends and
    rapid advancements in control, miniaturization,

    and computerization, which culminate in secure, lightweight, robust, more-accessible
    and cost-efﬁcient UAVs. UAVs support

    implicit particularities including access to disaster-stricken zones, swift mobility,
    airborne missions and payload features.

    Despite these appealing beneﬁts, UAVs face limitations in operability due to several
    critical concerns in terms of ﬂight

    autonomy, path planning, battery endurance, ﬂight time and limited payload carrying
    capability, as intuitively it is not

    recommended to load heavy objects such as batteries. As a result, the primary
    goal of this research is to provide insights

    into the potentials of UAVs, as well as their characteristics and functionality
    issues. This study provides a comprehensive

    review of UAVs, types, swarms, classiﬁcations, charging methods and regulations.
    Moreover, application scenarios, potential

    challenges and security issues are also examined. Finally, future research directions
    are identiﬁed to further hone the research

    work. We believe these insights will serve as guidelines and motivations for relevant
    researchers.

    Keywords UAVs · Path planning · Batteries · Charging · Swarms · Applications

    1 Introduction

    Unmanned aerial vehicles (UAVs), also known as drones, are

    being widely used and have gained signiﬁcant attention in

    the last decade. Most of the studies report multirotors due to

    B Syed Agha Hassnain Mohsan

    Hassnainagha@zju.edu.cn

    1

    Optical Communications Laboratory, Ocean College,

    Zhejiang University, Zheda Road 1, Zhoushan 316021,

    Zhejiang, China

    2

    School of Telecommunications Engineering, Xidian

    University, Xi’an, China

    3

    Ministry of Education Key Laboratory of Cognitive Radio

    and Information Processing, Guilin University of Electronic

    Technology, Guilin 541004, China

    4

    Department of Electrical Engineering, College of Electronics

    and Information Engineering, Sejong University, Seoul

    05006, Korea

    5

    Department of Electrical Engineering, Hamdard Institute of

    Engineering & Technology, Islamabad 44000, Pakistan

    their simplicity in control mechanisms and high-precision in

    positioning. Other types of UAVs are also reported, but their

    numbers are comparably low. There are several limitations to

    the practical implementation of UAVs in different application

    scenarios. The main critical limitation among UAVs is ﬂight

    endurance, which is limited due to the limited power supply

    provided by batteries. This issue can be mitigated through

    the design of different types of batteries using hybrid systems

    or internal combustion engines. Another promising solution

    is a docking station, which can recharge or swap batteries,

    store and even perform communication tasks with UAVs [1].

    Docking stations can solve the battery endurance issue and

    put UAVs one step ahead in autonomous systems.

    At present, UAVs are being used in multiple military,

    industrial and commercial applications [2], as shown in

    Fig. 1. In the military, UAVs offer navigation, secure com-

    munication and reconnaissance. Furthermore, they are being

    used in mobile edge computing, cellular communication,

    package delivery, smart healthcare, intelligent transportation

    systems, video surveillance missions, precision agriculture,

    123

    110

    Intelligent Service Robotics (2023) 16:109–137

    Fig. 1 Commercial, industrial and military applications of UAVs

    power-line inspection, remote sensing, search and rescue,

    and performing relief operations in disaster environments

    [3]. UAVs have the capability to access remote or dangerous

    areas, facilitate environmental monitoring and capture high-

    resolution imagery [4]. These ﬂying objects are helpful in

    monitoring as they bridge the constraints in limited-access,

    dynamic, harsh and complex environments. Furthermore,

    they reduce the labor and time required to survey, inspect

    and sample on ground, provide collision avoidance and quick

    convergencetoreachtargets,andoffermoretimeforintended

    managerial operations. However, there are multiple criti-

    cal limits on the design, deployment and performance of

    UAVs. Some of them have limited ﬂight time, limited auton-

    omy, less mobility and limited battery endurance. Harsh

    weather conditions and environments also impose limitations

    of UAV performance. Limited mission time is due to low

    battery endurance, harsh atmospheric conditions and sensor

    accuracy challenges. Several promising solutions are pre-

    sented in the literature to mitigate these challenges, including

    high-quality devices such as manufacturing materials and

    motors, UAV geometry, wings and batteries. Some studies

    also address optimization strategies to look for shortest tra-

    jectory for UAV ﬂight to reach the target destination [5].

    1.1 Scope and contributions

    This review is devoted to UAV technology and will help read-

    ers understand ongoing research and development activities.

    Our goal is to support readers in getting an overview of UAV

    types, swarms, conﬁgurations, standardizations and charging

    techniques, etc. We provide a comprehensive review of UAV

    Fig. 2 Organization of this paper

    challenges and security issues. We also provide realistic rec-

    ommendations and solutions to overcome these challenges.

    We carry out our extensive analysis to empower the use of

    UAVs in several application scenarios. In the end, we discuss

    future research directions to further hone the research work

    dedicated to this promising technology.

    1.2 Organization of the paper

    We have structured this study as follows: Sect. 2 reviews

    the research contributions on UAVs, types, classiﬁcations,

    payload, ﬂight time, swarms and standardizations. Section 3

    presents UAV battery charging techniques. Section 4 brieﬂy

    discusses the UAV application areas. We examine open

    challenges in Sect. 5, while security issues and mitigating

    solutions are addressed in Sect. 6. We also present future

    research directions in Sect. 7. Finally, this paper is concluded

    in Sect. 8. The organization of this review can be seen in

    Fig. 2.

    123

    Intelligent Service Robotics (2023) 16:109–137

    111

    Fig. 3 Architecture of UAV system

    2 Unmanned aerial vehicles (UAVs)

    UAVs refer to controlled aerial vehicles, which perform

    several missions without human assistance. They can be

    remotely operated through different electronic gadgets such

    as microprocessors and sensors [6]. UAVs can perform oper-

    ations autonomously in such areas where human intervention

    is dangerous [7]. Figure 3 presents a general architecture of

    UAVs where they utilize communication links to establish

    connectivity with satellite or ground control system (GCS)

    such as a laptop or smart phone. A human operator is needed

    to operate and control the UAV remotely. In literature, several

    works have been presented to address different features of

    UAVs. For instance, Zhang et al. [8] have focused on mobile

    charging features for drones to enhance their battery life.

    Aldhaher et al. [9] the use of a wirelessly powered receiver

    in order to decrease the weight of UAVs. Several wireless

    charging techniques have been suggested in [10] to increase

    the UAV’s ﬂight time. Raciti et al. [11] reported a charg-

    ing system empowered by a wireless power transfer (WPT)

    system. This study also highlights misalignment losses and

    associated mitigation solutions. Rohan et al. [12], proposed

    an intelligent drone charging system empowered by WPT.

    Shin et al. [13] addressed charge scheduling for multi-drones

    networks based on deep learning algorithms. In Table 1, we

    have summarized different surveys and reviews reporting on

    multiple aspects of UAVs.

    2.1 Classification of UAVs

    UAVs come in a variety of specs, equipment, sizes, ranges,

    and forms. Different types of UAVs can be found in the

    literature: ﬁxed-wing, single rotor, ﬁxed-wing hybrid, and

    multirotor [31]. Fixed-wing UAVs contain a main body,

    wings, propeller and motor. These UAVs need special train-

    ing to control and they remain useless for aerial surveillance.

    A ﬁxed-wing UAV is depicted in Fig. 4a [32]. These

    unmanned aerial vehicles are often used for aerial mapping

    and power line inspection. Such UAVs are not capable of

    hovering or forward ﬂight. Figure 4b depicts a hybrid ﬁxed-

    wing UAV [33]. Figure 4c depicts a single-rotor UAV [34].

    However, single-rotor UAVs are costly to produce and need

    skill training. These unmanned aerial vehicles are mechani-

    cally difﬁcult and susceptible to obstacles such as vibrations.

    Furthermore, multirotor UAVs are the most affordable and

    simple to build. These unmanned aerial vehicles are often

    employed for image and video surveillance. Quadcopters are

    the most often utilized UAVs, as seen in Fig. 4d. Quadcopters

    have gained popularity for their vertical landing, or quick

    maneuverability, low cost, and compact size. We have illus-

    trated basic UAV types in Table 2. While Table 3 provides

    a comparison of different UAVs considering various charac-

    teristics.

    2.2 UAV swarms

    Figure 5 depicts the classiﬁcation of UAV swarms as partly

    and completely autonomous. This categorization is also

    divided into single and multi-layered swarms. Each drone in

    the swarm provides real-time data recording and processing

    capabilities. While core processing takes place in the base

    station (BS) or in the clouds. UAV swarms with sophis-

    ticated monitoring mechanisms can cover a zone reliably

    and quickly by deploying several parallel-operating drones.

    Numerous studies have been reported on the usefulness of

    UAV swarms. Such as [35] analyzes swarms of drones to

    solve the charging process of many drones at the same time.

    It employs UAV swarms for smart power management. When

    considering the mission accomplishment of swarms of UAVs

    such as quadcopters, UAV ﬂight coordination and hovering

    endurance become critical. Furthermore, the communication

    efﬁciency of the quadcopter swarm is critical for a success-

    ful operation. The authors devised a multi-robot coordination

    123

    112

    Intelligent Service Robotics (2023) 16:109–137

    Table 1 Surveys of UAVs issues and challenges

    References

    Year

    Research focus

    [14]

    2015

    This articles focuses on several collision avoidance strategies discussed in literature.
    These strategies include sensing,

    tracking and collision avoidance. Authors comprehensive discussed the features,
    pros and cons of these strategies

    [15]

    2016

    This study surveys articles published between 2000 and 2015 on civil applications
    of UAVs. Authors addressed

    communication and networking aspects including safety, coverage, privacy, scalability
    and adaptability

    [16]

    2017

    This article focuses on open-source ﬂight controllers for research purpose. It
    addresses both software and hardware

    controllers and several other components for UAVs

    [17]

    2018

    This work is dedicated to UAV cellular communication in order to ﬁll the gap between
    3GPP regulations status quo and

    further research

    [18]

    2019

    This study is devoted to UAV deployment in cellular networks. It also addresses
    regulations, testbed initiatives,

    challenges, security issues and possible solutions for UAV-assisted cellular communications

    [19]

    2019

    This study comprehensively surveys UAV applications, beneﬁts, potential challenges,
    major tradeoffs, and mathematical

    tools

    [20]

    2019

    This study addresses UAVs for 5G/B5G wireless communication. It discusses potential
    challenges, research issues and

    future research directions

    [21]

    2019

    This study outlines the incorporation of UAVs in mm wave communication. It sheds
    some light on research challenges,

    cutting-edge solutions and possible future research directions

    [22]

    2020

    This study focuses on UAV applications, challenges, regulations, and future research
    aspects. Speciﬁcally, it highlights

    issues regarding trajectory, energy harvesting, security, interference and collision
    avoidance

    [23]

    2020

    This work addresses Software-Deﬁned Network (SDN) and Network Function Virtualization
    (NFV) technologies.

    Furthermore, it provides an insightful discussion on UAV classiﬁcations, use cases
    and challenges. It presents high-level

    insights into open research problems and future research directions

    [24]

    2020

    This study is focused on UAVs for three different perspectives including swarms,
    sensors and communications

    [25]

    2020

    This study focuses on several application scenarios of multi-UAV systems. Additionally,
    it highlights nomenclature

    taxonomy, architecture, current trends and potential challenges

    [26]

    2021

    This article comprehensively surveys green UAV communications, energy consumption
    models, applications, common

    trends and research challenges

    [27]

    2021

    This article focuses on UAV prototype, experimental demonstration, channel models
    and energy consumption models.

    Moreover, it also outlines various future research directions for UAVs

    [28]

    2021

    This work is based on deep learning tools to detect vehicles using UAV aerial
    images. It addresses optimization methods,

    reduction of computation overhead and accuracy enhancement. This work provides
    guidelines for researchers in

    artiﬁcial intelligence and trafﬁc surveillance domains

    [29]

    2022

    This study focuses on optimization algorithms e.g., Chicken Swarm Optimization
    Clustering, bee optimization algorithm,

    and genetic algorithm which are the gateway to better reliability, performance
    and accuracy. It also addresses protocols,

    routing schemes and associated challenges

    [30]

    2022

    This study surveys various task assignment algorithms in the context of main ideas,
    beneﬁts, drawbacks and operational

    features. These algorithms are compared on the basis of performance factors and
    characteristics. This study also

    discusses challenges, open issues, and possible future research directions

    This Study

    The key objective of this study is to survey academic contributions pertinent
    to UAV types, classiﬁcations,

    standardizations, swarms and charging methods. We brieﬂy discuss UAV characteristics
    such as payload, altitude,

    range, speed, and ﬂight time. Moreover, application scenarios, potential challenges
    and security issues are also

    examined. Finally, future research directions are identiﬁed to further hones the
    research work. We believe these insights

    will serve as guidelines and motivations for relevant researcher fraternity

    Fig. 4 a Fixed-wing, b ﬁxed wing hybrid, c single rotor, and d multirotor UAV

    123

    Intelligent Service Robotics (2023) 16:109–137

    113

    Table 2 Different types of UAVs

    UAV type

    US$ price

    Applications

    Advantages

    Drawbacks

    Fixed wing

    $20–150 k

    Structural inspection, area survey

    Large area coverage, long

    endurance, high speed

    Launching, landing,

    high price

    Rotary wing

    (helicopter)

    $20–150 k

    Supply drops, inspection

    Hovering, large payload

    High price

    Rotary wing

    (multicopter)

    $3–50 k

    Photography, ﬁlmography,

    inspection

    Hovering, availability, low price

    Short ﬂight time, small

    payload

    strategy in [36] to address the challenges of real-time syn-

    chronization of UAV swarms across a broad area network.

    Other investigations have looked at swarms of UAVs in the

    context of surveillance. [37], for example, describes quad-

    copter swarms for object location and tracking operations.

    Similarly, Leonard et al. [38] suggested tracking and detec-

    tion algorithms for a quadcopter swarm-based monitoring

    program.

    2.3 Developments in Navigation of UAVs

    Navigation has a strong impact on UAV ﬂight control. Sev-

    eral navigation technologies, such as Droppler, integrated,

    geometric, satellite and inertial navigation, perform multiple

    Fig. 5 Classiﬁcation of swarms

    Table 3 Characteristics of different UAVs

    Characteristics

    Fixed wing

    Rotary wing

    Hybrid

    Energy

    efﬁciency

    High

    Low

    High

    Flight system

    Complicated

    Simple

    Complicated

    Landing

    Conventional

    Vertical

    Vertical

    Autonomy

    No

    Yes

    Yes

    Hovering

    No

    Yes

    Yes

    Power supply

    Battery, fuel

    Battery

    Battery, fuel

    Endurance

    60–3000 m

    6–180 m

    180–480 m

    Payload

    1000 kg

    50 kg

    10 kg

    Weight

    0.1–400,000 kg

    0.01–100 kg

    1.5–65 kg

    functions. The key navigation systems for UAVs are high-

    altitude, long-endurance navigation systems and tactical or

    mediumrangenavigationsystems.Wecanevaluatethedevel-

    opment in navigation as follows:

    High-performance navigation with data fusion: it plays a key

    role to determine the ﬂight status to guarantee the normal

    UAV ﬂight.

    New inertial navigation system: it simpliﬁes the volume and

    weight and takes less energy to reﬁne the ﬂight pliability.

    Intelligent navigation system ability: information technology

    is used to enhance the UAV technology, along with updating

    the navigation system.

    2.4 Formation control design

    Motion control employee’s communication architecture

    needed for ﬂow of information. Formation control strategies

    are as follows:

    Leader–follower strategy: the main advantages of this tech-

    nology are that it can be accomplished easily and simply.

    Owing to the leader dependency, it confronts single-point

    failures. The limitations of this strategy could be addressed

    by assigning virtual and multi-leaders.

    Behavior-based strategy: the key beneﬁt of this strategy is

    that it is greatly adaptable to even some unknown environ-

    ments. However, it requires to be modeled mathematically

    which creates problems in analyzing stability of the system.

    Virtual structure strategy: this strategy considers rigid struc-

    tures for intended geometry or shape of the set of UAVs. The

    method fails to detect the faulty information in a UAV. The

    method also calls for a strong capability for computation.

    2.5 UAV characteristics

    2.5.1 Speed and ﬂight time

    Small-sized UAVs mostly ﬂy at a speed of 15 m/s or below.

    On the other hand, large-sized UAVs can travel at higher

    123

    114

    Intelligent Service Robotics (2023) 16:109–137

    Table 4 Payload capability of different UAVs

    References

    UAV types

    Payload

    Applications

    [40]

    Fixed wing

    56 kg

    To detect atmospheric

    trace gases, observing

    natural hazards such as

    volcanoes

    [41]

    Fixed wing

    40 kg

    Analysis of atmospheric

    gases, to measure water

    vapors, methane and

    carbon dioxide

    [42]

    Helicopter

    5 kg

    Mapping of greenhouse

    gas concentrations

    [43]

    UAV

    3.5 kg

    To monitor atmospheric

    CO2 concentration

    [44]

    Helicopter

    3 kg

    Measurement of volcanic

    gases such as CO2 and

    SO2

    speeds up to 100 m/s. Whenever any UAV is following any

    intended path to improve its energy or spectral efﬁciency, its

    speed should be taken into account at multiple turning points

    and locations along this path. In [38], authors have addressed

    this trade-off between UAV speed and turning agility.

    Similarly, ﬂight time indicates to the maximum time for

    which the UAV can ﬂy until the batteries are drained out. It

    is of paramount signiﬁcance along with cost. UAV weight,

    size and atmospheric conditions such as rain or wind have

    strong impact on battery endurance of UAVs which is closely

    associated to ﬂight time. GPS and autopilot systems also play

    a crucial role in ﬂight time. Small size UAVs can ﬂy up to

    20–30 min, while large size UAVs can ﬂy up to several hours.

    2.5.2 Payload

    The lifting capability of a UAV to carry any weight is referred

    to as payload. Lifting capacity ranges from a few grams

    to several hundred kilos. Greater payloads allow for more

    accessories to be carried at the expense of shorter ﬂying

    times, greater power capacity, and wider dimensions. Sensors

    and video cameras are common payloads for reconnaissance,

    surveillance, and commercial purposes. Cellular user equip-

    ment (UEs), such as tablets, mobile phones, and tablets

    weighing less than one kilogram, may also be carried by

    UAVs [39]. UAVs with high payloads are thought to have

    shorter ﬂight duration. However, if a UAV has a larger sur-

    face area along with occupying more motors; it has the ability

    to store more power, which increases ﬂying time. As a result,

    the payload’s quality might let it move faster while maintain-

    ing the same precision and resolution. In Table 4, we have

    illustrated payload capability of different UAVs.

    2.5.3 Sensing equipment

    Radiation detection has already been discussed in ground

    penetrating radar, and hyper-spectral cameras to Synthetic-

    Aperture Radar. The author identiﬁes highly sensitive light

    sensors in the ﬁeld of precision agriculture:

    Fluorescence excitation

    Infrared spectrum imaging, and

    Visible spectrum imaging

    The particular sensing arrays are highly precise but the

    specialized equipment is highly expensive with limited ver-

    satility. Table 5 presents an overview of some sensing devices

    in UAVs. While Table 6 provides comparison of different

    imaging and ranging sensors considering various parame-

    ters.

    2.5.4 Software

    UAVs are signiﬁcantly capable of playing roles in data pro-

    cessing tasks and problem solving. Several algorithms are

    used for optimization, autonomy and path planning. These

    tools can minimize human assistance and the infrastructure

    required for various tasks, such as communication. It is chal-

    lenging to ﬁgure out suitable off-the-shelf software, which

    requires time and resources. However, researchers are on the

    way to developing novel methods and algorithms to address a

    variety of such problems. A geometric correction algorithm

    can be employed to decrease image distortion. Image pro-

    cessing algorithms are used for remote sensing or to process

    images captured from UAV cameras. Similarly, an ofﬂine

    path planning tool can be employed for UAV- swarm aided

    persistent surveillance methods and a self-adapting multi-

    featured evolution approach offering trajectory planning for

    UAVs.

    The software installed in UAVs has been validated as an

    essential factor in value creation. This concept has paral-

    leled the expansion of industries and companies devoted to

    software development. Among these companies are Sky-

    works Aerial System (USA), SkyWards (USA), RedBird

    (France), PIX4D (Switzerland), MapBox (USA), DroneDe-

    ploy (USA), Dedrone (Germany), and Airware (USA). Most

    of these countries are from European countries and USA,

    outlining the emerging industry of this transformative tech-

    nology. Some of these companies focus on processing and

    analysis through captured images through UAVs, using their

    results to various industries such as construction, surveying,

    agriculture and mining, etc. While others operate as ﬂy-

    ing simulators (Redbird) and developers of UAV detection

    (Dedrone).

    123

    Intelligent Service Robotics (2023) 16:109–137

    115

    Table 5 UAV onboard sensors

    References

    Sensors

    Applications

    Advantages

    Drawbacks

    [45]

    Thermal infrared sensors

    Islands and hazardous area

    tracking

    Easy deployment, small

    size, low power, applicable

    in dark conditions

    Impressionable to distance

    and interference, low

    accuracy, sunlight

    interference, indoor or

    evening use only

    Hydrothermal studies, urban

    heat monitoring

    Detection, including forest

    ﬁres

    Volcanoes

    [46]

    Hyperspectral sensors

    Assessment

    Accurate analyses and

    classiﬁcation of the image,

    better capability to see the

    unseen, no prior

    knowledge of the sample

    required

    Hyperspectral cost and

    complexity, big data

    storage capacity is

    required

    Detection, including disaster

    damage

    Agriculture and vegetation

    disease

    Biophysical, physiological,

    or biochemical parameter

    estimation

    [47]

    Light detection and ranging

    (LiDAR)

    Building information

    High resolution and

    accuracy, feasible for

    spatial classiﬁcation, good

    performance for near-ﬁeld

    obstacle tracking

    Impact of vehicle mobility,

    affected by atmospheric

    conditions, calibration

    errors, sensor noise

    Mapping cultural heritage

    Absorption

    Estimation of forest carbon

    Vegetation canopy analysis

    [48]

    GPS

    Timing, mapping, tracking,

    navigation, localization

    Efﬁcient power

    consumption, low

    acquisition cost, small size

    Receiver clock errors,

    orbital errors, delays,

    susceptible magnetic

    environment

    Table 6 Classiﬁcation of UAV

    sensing devices

    Sensors

    Cost

    Weight

    Spectral resolution

    Spatial resolution

    LiDAR

    High

    High

    Low

    Very high

    Thermal infrared

    Average

    Average

    Low

    Average

    Near infrared (NIR)

    Low

    Low

    Low

    Very high

    Hyperspectral

    High

    Average

    High

    High

    Multispectral

    Average

    Average

    Average

    High

    Visible RGB

    Low

    Low

    Low

    Very high

    2.5.5 Range and altitude

    The range of a UAV relates to the area it can be operated

    remotely from. Small drones have a range of a few meters,

    whereas bigger drones have a range of hundreds of kilome-

    ters. In contrast, altitude points to the maximum height at

    which a drone may ﬂy. Aerial platforms are usually split into

    two groups based on their altitude.

    Low-altitudeplatforms(LAPs):LAPsaretypicallyusedto

    facilitate cellular connectivity since they are quick to deploy

    and inexpensive. LAPs also provide a line-of-sight route,

    which can boost communication performance greatly [49].

    High-altitude platforms (HAPs): high-altitude platforms

    (HAPs), including balloons, are also employed for cellular

    communication. When compared to LAPs, HAPs provide

    more coverage. The implementation of HAPs is complex,

    and they are mostly used to facilitate Internet connectivity.

    Table 7 shows the various kinds of UAVs based on their

    altitude. Table 8 provides a comparison of several types of

    UAVs. Figures 6a–d depict several UAV programs in various

    countries.

    2.5.6 Controllers of UAVs

    Controllers are responsible for executing speciﬁc tasks for

    UAVs. They are deﬁned as a series of actions that can affect

    UAVs and the physical world. The controllers vary accord-

    ing to the UAV type such as ﬂapping wing, single rotor,

    123

    116

    Intelligent Service Robotics (2023) 16:109–137

    Table 7 UAV categorization on

    altitude [50]

    Category

    Endurance

    (h)

    Flight alt.

    (m)

    Range

    (km)

    Mass (kg)

    High-altitude long endurance

    (HALE)

    24–48

    20,000

    > 2000

    2500–5000

    Low altitude long endurance

    (LALE)

    > 24

    3000

    > 500

    15–25

    Medium altitude long endurance

    (MALE)

    24–48

    3000

    > 500

    1000–1500

    Low altitude deep penetration

    (LADP)

    0.5–1

    50–9000

    > 250

    250–2500

    Table 8 Feature-based

    comparison of UAVs

    UAV type

    Altitude (km)

    Avg. control range (km)

    Avg. airspeed

    (m/s)

    Fixed-wing-multirotor hybrid UAVs

    (Jump 20 [52])

    4

    500–1000

    30

    Single rotor (Alpha 800 [53])

    3

    30

    15.2

    Multirotor UAVs (DJI Agras MG-1P

    [54])

    2

    3–5

    7

    Fixed-wing UAVs (AgEagle RX60 [55])

    0.125

    2

    18.8

    Fig. 6 Different examples of UAVs on altitude a LADP, b LALE, c MALE, and d HALE
    [51]

    multirotor and ﬁxed-wing. These UAVs are designed for

    certain operations and face different aerodynamics. UAV

    control encompasses an extensive range of technologies and

    treatments. For some certain operations, the control may

    contain the macro- executions (such as formation control

    and path planning) and the micro ﬂight control decisions

    of the actuators according to the provided commands. Due

    to the dynamic behavior of UAV conﬁgurations, the design

    and development of UAV control must follow an appropri-

    ate mechanism. As a result of the external disturbances, the

    operability of the ﬂight control system is critical to follow-

    ing the stable response. The key objective of the controller

    is to reduce the error between the estimated and desired

    states, which can be altitude, velocity, or position of the UAV

    operating under varying atmospheric conditions. Next, we

    discussed the ﬂight controller for UAVs in detail.

    2.5.7 Flight controllers

    Flight controllers are commonly known as autopilot systems,

    are the main elements of UAVs. They are generally designed

    to ensure autonomous ﬂight control, such as mission plan-

    ning, ﬂight waypoint generation and attitude stabilization. To

    efﬁciently realize these operations, ﬂight controllers require

    software or hardware assistance concurrently. The latter

    mostly consists of power control modules, communication

    entities, GPS modules, onboard sensors, inertial measure-

    ment units and onboard computers, and the former mainly

    contains signal processing algorithms, attitude control, path

    planning and task allocation.

    The ﬂight controller is based on three major components.

    The ﬁrst one is named "kernel control law," which is respon-

    siblefor theasymptoticstabilityof theUAV’s mobilitywithin

    123

    Intelligent Service Robotics (2023) 16:109–137

    117

    Table 9 Comparison of UAV

    ﬂight controllers

    Flight

    controller

    Open-source

    Operating

    system

    Supported UAVs

    Control modes

    Trinity

    No

    –

    Multirotor

    Manual, assistant,

    auto

    NAVIO2

    Yes

    Linux

    Helicopter, ﬁxed-wing,

    multirotor

    Manual, assistant,

    auto

    DJI A2

    No

    –

    Multirotor

    Manual, assistant,

    auto

    OcPoC

    Yes

    Linux

    Helicopter, ﬁxed-wing,

    multirotor

    Manual, assistant,

    auto

    PIXHAWK

    Yes

    Nuttx

    Helicopter, ﬁxed-wing,

    multirotor

    Manual, assistant,

    auto

    the air. The second component is called the command gen-

    erator, which is used to generate references for the kernel

    control. The last part is the ﬂight schedule, which is respon-

    sible for generating a group of ﬂight arrangements to realize

    the desired mission. Flight control of a UAV can be achieved

    by controlling the altitude in order to maintain the UAV at the

    desired height and controlling the orientation and velocity to

    follow speciﬁc trajectories. Different linear and non-linear

    controllers are used for UAVs. The linear controllers include

    H¥, LRQ, PD, and PID, and non-linear controllers include

    NDI, gain-scheduling, fuzzy logic control, nested saturation,

    sliding mode, and backstepping. The linear controllers are as

    follows:

    • The H¥ Loop-Forming technique, which integrates con-

    ventional loop forming control with robust control, pro-

    vides high robustness than other techniques. However, it

    is not feasible for large-scale UAV control.

    • A linear quadratic regulator (LQR) controller is an opti-

    mal controller which operates in dynamic systems with

    quadratic costs. It is regarded robust concerning technique

    uncertainty with a viable stability margin to error. How-

    ever, it is not feasible always as it needs the full state of

    the system.

    • A proportional–integral–derivative (PID) controller is the

    most commonly used controller in UAVs. They are very

    popular due to their ease of use. However, they also impose

    limitation in optimality and robustness.

    Nonlinear controllers are required to tackle with coupling

    components and non-linearity of UAV state variables. Non-

    linear controllers are as follows:

    • Robust Control Algorithms are utilized to realize the

    effective behavior of the controller within an acceptable

    disturbance ratio. It can measure the performance changes

    with respect to the changing system parameters. It is fea-

    sible approach as it needs only the information about the

    limit in uncertainty.

    • The Backstepping Controller is a recursive design pro-

    cess which divides the controller task into various steps

    to ensure gradual stability in each sub-system. It can

    tackle external uncertainty and utilize less computational

    resources.

    • The Sliding Mode Controller (SMC) follows Lyapunov

    stability principles to force system state trajectory through

    a discontinuous control signal. It is inherently robust to any

    changes in parametric uncertainty, external disturbances

    and modeling errors. It is very feasible to analyze the sec-

    ond order dynamic systems. Table 9 provides a comparison

    of different ﬂight controller.

    2.6 UAV standardizationsp

    2.6.1 UAVs 3GPP standardization

    In this technological era, UAVs have gotten a lot of atten-

    tion in the line-of-sight (LoS) and non-line-of-sight (NLoS)

    environments [56]. The third generation partnership group

    (3GPP) completed numerous investigations in 2017 and pro-

    duced Release-15 to recognize long-term evolution (LTE)-

    powered UAVs. The key objective of this research was

    to concentrate on UAV trafﬁc demands, channel modeling

    methodologies for air-to-ground dissemination views, reuse

    of existing cellular networks to facilitate LTE support, UAV

    communication, and innovations necessary to incorporate

    LTE into UAVs. The 3GPP’s goals also include determin-

    ing which trafﬁc categories require current cellular networks

    to accommodate UAVs ﬂying more than 300 m above the

    ground. Table 10 highlights the following UAV commu-

    nication needs: (i) synchronization and radio control; (ii)

    command and control; and (iii) application data [18].

    123

    118

    Intelligent Service Robotics (2023) 16:109–137

    Table 10 UAV communication requirements [18]

    Data type

    Data rate

    Critical

    Downlink

    Radio control

    (PDCCH)

    N/A

    Yes

    Synchronization

    (SSS/PSS)

    Yes

    Command and

    Control (C&C)

    60–100 kbps

    Yes

    Uplink

    Command and

    Control (C&C)

    60–100 kbps

    Yes

    Application data

    Up to 50 Mbps

    No

    2.6.2 UAVs standardization outside the 3GPP

    Aside from 3GPP standardization, numerous additional reg-

    ulatory bodies have speciﬁed distinct UAV requirements to

    assure effective, consistent, and standardized communica-

    tion.

    • The Institute of Electrical and Electronics Engineers

    (IEEE) established the Drones Working Group (DWG)

    in 2015. The primary goal of this group was to create a

    taxonomy for consumer drones in order to emphasize pri-

    vacy and security issues. In order to do this, the DWG

    creates techniques, systems, speciﬁcations, testing, and

    evaluations for consumer drones to protect the privacy

    and security of the public and their properties. Similarly,

    the IEEE Conformity Assessment Program (ICAP) and

    OM/AerCom SC are collaboratively designing a confor-

    mity assessment program such that UAV approaches can

    show conformance with IEEE standardizations. The IEEE

    drone application certiﬁcate program is also introduced

    which is comprised of industry stakeholders, that will

    support regulators, system integrators, solution providers,

    manufacturers, users and other potential beneﬁciaries. It

    also includes the academic community and test laborite

    to demonstrate to buyers that UAV systems or products

    conform to IEEE standardizations.

    • The European Telecommunications Standards Institute

    (ETSI) investigates UAV operations, use cases, and knowl-

    edge of the to-be-built Internet Protocol (IP) suite frame-

    work, as well as the spectrum rules required to accom-

    modate UAVs in current LTE networks [57]. ETSI has

    also developed European standards under EC regulation

    requests to ensure the extensive use of services such as

    Data Link Services (DLS), Advanced Surface Movement

    Guidance and Control along with Airport Collaborative

    Decision Making procedure. Furthermore, Radio Equip-

    ment Directive has been developed to employ on UAVs

    operating in conformity with the spectrum management.

    ETSI can also be utilized to show compliance with certain

    aspects of the directive.

    • The International Telecommunication Union (ITU-T)

    made work item (WI) Y.UAV.arch so that unmanned aerial

    vehicles (UAVs) and unmanned aerial vehicle controllers

    (UAVs) can have a stable and functional architecture over

    IMT-2020 networks [58]. IMT-2020 is employed for UAV

    communication. As UAVs need simultaneous applications

    with different aspects, thus a new kind of user terminal

    to IMT-2020 is needed. Likewise, the novel communica-

    tion network IMT-2020 is designed for ground coverage

    of UAVs. A group of functionalities is required to ﬁll the

    gap for interoperability between IMT-202 networks and

    UAVs in order to improve the quality of UAV operations

    and implement the feature of civilian UAV operations in

    IMT-2020. This recommendation supports an operational

    architecture for UAV operators through IMT-2020 net-

    works and functionalities deﬁned in the physical layer,

    application layer, and application support layer.

    • Federal aviation authority (FAA) is responsible for civil

    aircraft operations in national airspace (NAS) in the USA.

    It aims to provide operational and regulatory framework

    for unmanned trafﬁc management (UTM). It interacts

    with UTM for data or information exchange. In March

    2020, FAA released an updated UTM concept in order to

    deﬁne the technical and operational requirements for UTM

    ecosystem to ensure the operations of unmanned airspace

    systems in all existing airspaces. FAA has also set a limit

    of weight less than 55 pounds to include as small UAS. In

    general, FAA divides the existing airspace in six classes A

    to G. G refers to uncontrolled while class A-G is for con-

    trolled airspace. It means class G will not be monitored by

    air trafﬁc control will be overseen by ATC entities. Accord-

    ing to FAA rules, UTM operation can be performed till

    400ft above ground. In case of uncontrolled airspace, the

    remote pilots are exempted to get approval from authorized

    training center (ATC) authorities. However, while entering

    into controlled airspace, they must inform ATC about their

    intent. Moreover, the UAV operator should guarantee that

    the foreseen UTM operations are compliant with the cer-

    tain rules, e.g., e-registration of both operator and UAV

    and must satisfy safety requirements including communi-

    cation abilities and drone airworthiness [59].

    • European Aviation Safety Agency (EASA) has also

    implemented regulations to operate UAVs. The EASA

    concepts are based on a regulatory framework consid-

    ering operation-centric and proportional strategy which

    addresses conditions and the way of the operation rather

    than just focusing on UAV parameters. These actions

    are guided and accompanied by the European Roadmap

    to integrate civil remotely-piloted aircraft into the Euro-

    pean Aviation System. The document identiﬁed several

    levels of integration and harmonization. It also contains

    123

    Intelligent Service Robotics (2023) 16:109–137

    119

    Fig. 7 Classiﬁcation of UAV docking stations [1]

    three annexes with a clear strategy to implement and

    improve regulations, foreseeable research initiatives and

    societal impacts on UAV services. The major difference

    between proposed concepts is the application of three

    EASA drone categories such as OPEN, SPECIFIC and

    CERTIFIED [59]. Thus, UAV operations performed under

    both SPECIFIC and CERTIFIED must be authorized by

    the national aviation authorization (NAA). This authoriza-

    tionwillallowUAVoperationswithhighrisklevelssuchas

    ﬂying over populated area. Consequently, speciﬁc system

    capabilities and operational requirements must be satisﬁed

    by the operator to perform these operations.

    2.7 UAV docking station: preliminary description

    Docking stations are multipurpose to facilitate safe landing,

    recharge,ortakeoff,payloadanddatatransfer.Somedocking

    systems are capable of storing UAVs safely, protecting them

    from harsh environmental conditions. Docking stations can

    be categorized regarding [1]:

    • Mobility

    • Charging method

    • Automatic battery exchange

    • Positioning

    • Drone storage

    • Package delivery

    • Landing type

    • Landing platform type

    Docking station comprises multiple subsystems, for

    example, power supply, a landing platform, battery recharg-

    ing setup, drone storage system and many more. Docking

    stations should satisfy speciﬁc criteria to meet their goals.

    The classiﬁcation of UAV docking stations is illustrated in

    Fig. 7. We have summarized some commercially available

    docking stations in Table 11. In next section, we will com-

    prehensively discuss the UAV charging techniques.

    Table 11 Commercially available docking stations

    Docking station

    Set up

    Features

    Dronehug [60]

    Drone, docking

    station, and AI

    approach

    Autonomous

    docking station

    with storage

    system. Uses AI

    software for

    inspection

    Hive [61]

    Docking station

    Modular in

    construction to ﬁt

    various drones

    Skycharge

    Skyport [62]

    Docking station

    DJI Mavic and

    Parrot ANAFI

    Support

    Percepto [63]

    Drone and docking

    station

    Autonomous drone

    solution. 4 K

    Camera

    Nightingale

    security [64]

    Drone, docking

    station, and AI

    approach

    Autonomous threat

    response (patrol,

    threat response,

    manual, AI

    intrusion

    detection)

    Fig. 8 Statistics of WPT and Drones market growth [68]

    3 UAV battery charging

    One major issue in UAV performance is limited battery

    capacity. It is not suggested to increase battery weight or size

    as ultimately it will enhance payload which is another crucial

    issue. Charging can be obtained through wired or wireless

    power transfer (WPT) system [65] as discussed below:

    3.1 Wireless power tranfer (WPT)

    According to an analysis [66], the estimated revenue of WPT

    is around $2000 million till 2020. Figure 8 provides the esti-

    mated growth market for WPT and drones till 2025. It is

    envisaged that total sales with a Compound Annual Growth

    Rate (CARG) of 13.8% by 2025 will hit $43 billion [67]. This

    extensive growth is due to several applications in electronic

    123

    120

    Intelligent Service Robotics (2023) 16:109–137

    Table 12 Studies on charge scheduling of UAVs

    References

    Year

    Research focus

    [9]

    2017

    This study presents an overview of technologies which empower UAV-based ultra-light-weight
    WPT systems which

    can withstand the changes in the air-gap geometry

    [10]

    2018

    This article addresses WPT techniques for UAV mission duration enhancement along
    with practical demonstration of

    reliable and feasible techniques to charge UAVs through power lines

    [12]

    2018

    This study proposes an advanced battery charging system for UAVs based on resonance
    inductive coupling. The system

    is based on a UAV charging station with a receiver and multiple power transmitters

    [59]

    2018

    This study addresses the design and optimization of WPT system for UAVs enabled
    by magnetic resonance coupling.

    Authors have addresses imperfect landing and misalignment factors as well. The
    key contribution of this work is the

    compactness and lightness of WPT system components

    [71]

    2018

    This study introduces a novel tightly coupled three phase magnetic ﬁeld charger
    for a UAV operating at 60 kHz. It can

    fully remove the integer multiples and third harmonics in output voltage. Authors
    also proposed the conduction angel

    control in order to reduce the selective electromagnetic interference

    [13]

    2019

    This study focuses on auction-based strategy for controlling the charge schedule
    in multi-UAVs scenario. This this

    study, time slots were auctioned through a bidding method. The major issue is
    this process was the lack of prior

    information about the number of UAVs participating in the auction

    [72]

    2019

    This study is based on magnetic resonance coupling scheme as it offers several
    beneﬁts such as unaffected by harsh

    weather, good tolerance to misalignment, charging multiple devices simultaneously
    and high transfer efﬁciency

    [73]

    2019

    This study proposes a parallel transfer coil matrix design to enhance the performance
    of WPT under misalignment. The

    numerical and experimental results validate that phase difference between transceiver
    coils can be featured as the

    factor to indicate the change in magnetic ﬁeld

    [74]

    2020

    This study introduces a deep learning approach to handle the challenge that multi-UAVs
    can cooperatively and

    efﬁciently collect data from sensors while charging

    [75]

    2020

    This article reports a reliable and secure energy trading among UAVs and charging
    stations. This study permits UAVs to

    purchase energy from the charging station by providing tokens. Authors presented
    a game-theoretic model to decide

    the energy buying strategy for UAVs

    [76]

    2021

    This study is based on blockchain technology and deep reinforcement learning to
    develop an auction-empowered

    mechanism to schedule charging for UAVs while improving auction performance and
    maintaining secure transactions

    [77]

    2022

    This study proposes an aerial refueling technique by arranging UAVs into mission-UAV
    and charging-UAV to support

    charging along with uninterrupted UAV mission. In this proposed method, mission-UAV
    can be recharged through

    charging-UAV while operating in a perpetual manner

    [78]

    2022

    In this study, authors leverage a multi-agent deep reinforcement learning (MADRL)
    technique for the optimization of

    energy transfer between UAVs and ﬂying energy sources (FESs). In order to achieve
    high reliability. Authors used

    directional energy transfer to charge both UAVs FESs through energy beam-forming
    and laser beaming technologies,

    respectively

    industry with multiple advantages in terms of autonomy,

    reliability, convenience, security and safety. All these advan-

    tages can be obtained using various WPT techniques. One

    key beneﬁt of using WPT techniques is the operability in

    those environments where wired medium power transfer is

    impossible or dangerous. WPT techniques are organized as

    radiative electromagnetic (EM) and non-EM techniques. In

    non-EM, power is transferred through optical or acoustic

    sources. In EM techniques; resonance coupling, magnetic

    coupling, inductive coupling and capacitive coupling are

    used. At present, these WPT technologies are commercially

    used for several applications such as implantable medical

    devices, smart phones and UAVs etc.

    WPT techniques offer reliable and efﬁcient power trans-

    mission for UAVs. However, WPT techniques for charging

    UAVs must consider critical limitations under payload, inter-

    ference, harsh weather conditions and misalignment. Among

    these critical factors, misalignment is a dominant challenge

    as UAVs mostly suffer from landing accuracy issues. UAV-

    empowered WPT techniques must be lightweight. These

    techniques should ensure efﬁcient charging and high pre-

    cision landing along with tolerance to misalignment factor.

    Several research works have been carried out for UAV charg-

    ing through different WPT techniques [69, 70]. We have

    summarized some of these studies addressing UAV-based

    WPT systems in Table 12.

    3.1.1 Photovoltaic (PV) cell-based UAV charging

    The PV cells are used to charge batteries by using sun-

    light and they can signiﬁcantly enhance the ﬂight time of

    UAVs. In the presence of sunlight, the PV cells provide the

    required power to UAVs. However, in the absence of sunlight,

    the required power is delivered through batteries. Several

    123

    Intelligent Service Robotics (2023) 16:109–137

    121

    Fig. 9 PV-powered hovering favors small aircraft [84]

    research studies have been reported on solar-powered UAVs

    [79, 80]. According to Fazelpour et al. [79], various parame-

    ters play a major role in solar-powered energy transfer such as

    type of PV cell, position, orientation, geometry, temperature

    intensity, weather conditions and angle of incidence of sun.

    However, this technique is critically limited in the absence of

    sunlight. Atmospheric conditions such as clouds, fog, rain,

    temperature, humidity can substantially reduce the UAV’s

    efﬁciency and reliability. Thus, it is suggested to investigate

    alternative solutions to continue the UAV mission under such

    scenarios.ControllingPVcellpositionbasedonincidentsun-

    light, increasing PV cell size or UAV batteries, and carrying

    additional power supplies are some of these strategies.

    Currently, different types of PV cells are available to

    ensure high-efﬁciency and cost-effectiveness. Some studies

    have focused on mono-crystalline silicon PV cells as they

    support high ﬂexibility and easy integration with UAV wings

    [81]. Research fraternity is still looking for novel designs

    and energy management strategies with enhanced efﬁciency,

    high availability and reliability. There is a need to focus on

    researchactivitiesinmaterialperspectiveaslow-efﬁciencyof

    these PV cells is a major limit [82]. In [83], authors proposed

    optimization approach for solar-powered UAV trajectory in

    order to attain high solar radiation at low usage of mechan-

    ical energy. In [84], authors reported that solar power may

    be beneﬁcial for small size aircraft. They plotted a graph as

    shown in Fig. 9 considering PV cell size, drone size and mass

    for a continuous hovering ﬂight. To plot this graph, authors

    assumed 30% efﬁcient cells, 1/3 sunlight and drones capa-

    ble of sensor-autonomous hovering. Table 13 shows the PV

    cell size required for persistent solar-powered hovering for

    different UAVs.

    Solar-powered UAVs have gained signiﬁcant attention in

    both academia and industrial sectors. Several research and

    industrial activities have been initiated on solar-powered

    UAVs. Figure 10 shows solar-powered drones projects by

    technology giants e.g., Google and Facebook. Google started

    using these UAVs to provide internet access in remote areas.

    Table 13 PV cell size required for continuous solar-powered hovering

    for different UAVs

    Aircraft

    Power (W)

    Mass (g)

    PV size

    (m)

    Roboﬂy-expanded [85]

    0.22

    0.5

    0.05

    Nano-hummingbird [86]

    3.27

    17.5

    0.18

    Crazyﬂie 2.0 [87]

    8.88

    30

    0.30

    Parrot ANAFI [88]

    47.95

    320

    0.69

    AscTec Hummingbird [89]

    116.55

    750

    1.08

    AscTec Fireﬂy [90]

    251.03

    1600

    1.58

    Aerialtronics Zenith [91]

    666

    6650

    2.58

    At present, such UAVs are being used for forest ﬁre ﬁght-

    ing, internet coverage, high-altitude communication, border

    monitoring, and power-line inspection.

    3.1.2 Charging with laser beaming

    Laser power transfer (LPT) is another promising charging

    technique, which is commonly used in space and military

    missions [93]. In this charging method, laser diodes of dif-

    ferent wavelengths are used to deliver power to PV cells

    integrated on UAVs. These PV cells harvest energy from

    laser beams to charge batteries or deliver the required power

    to UAVs. This charging technique is mostly used for ﬁxed

    wing and rotary wing UAVs. Laser power transfer is consid-

    ered a promising approach to ensure unlimited endurance.

    It can deliver high energy to support various energy-hungry

    remote operations of UAVs [94]. Several studies have been

    reported on LPT techniques [95, 96]. In [96], the authors

    introduced a controller design mechanism considering laser

    PV module to adjust the power conversion of LPT system.

    In another reported work [97], the authors discussed results

    pertaining to voltage, current and efﬁciency considering a

    LPT system. Furthermore, author in [98] carried out anal-

    ysis of wavelength and temperature output of PV cells in

    a laser-based charging system. In [99], authors discussed

    UAV-based missions for longer durations considering dif-

    ferent techniques. Authors discussed laser charging based

    on low-power laser source and precise energy consumption

    for UAV along with investigating its dynamics in a mission

    environment. In another reported study [100], authors inves-

    tigatedthejointproblemoftrajectoryandpoweroptimization

    in a rotary-wing UAV-empowered mobile relaying network.

    In order to support sustainable and convenient energy sup-

    ply, they considered wireless charging of UAV through a

    power beacon and properly realized through a laser charg-

    ing system. Apart from different advantages of LPT systems,

    there are several critical issues such as mobility, blockage and

    limited performance on long-distance ﬂight. Moreover, this

    123

    122

    Intelligent Service Robotics (2023) 16:109–137

    Fig. 10 Solar-powered drones

    a Google’s project, b Facebook’s

    project [92]

    Fig. 11 LPT system to charge multi-UAVs

    system is not feasible in airports and military areas where

    laser beam usage can be harmful. In Fig. 11, we present a

    LPT system to charge multi-UAVs.

    4 UAV application areas

    The ongoing activities on UAV deployment have created a

    new breed of promising applications to carry out autonomous

    missions. This section highlights several prominent applica-

    tion areas of UAVs.

    4.1 Disaster management

    UAVs can visit disaster regions that are unsafe for manned

    action in the event of a man-made or environmental catastro-

    phe, such as terrorist strikes, tsunamis, and ﬂooding. Power,

    telecommunications infrastructure, water utilities, and trans-

    portation are all vulnerable to these calamities. UAVs can

    assist in the collection of data, the need for quick answers,

    and the navigation of debris. UAVs equipped with sensors,

    radars, and high-resolution cameras can aid rescue teams in

    identifying damage, launching urgent recovery efforts, and

    dispatching supplies including ﬁrst-aid manned helicopters

    and medical kits. UAVs can aid with catastrophe assess-

    ment, disaster alarms, and discovering preventative measures

    in real-time. A swarm of drones equipped with ﬁreﬁghting

    equipment can watch, analyze, and track any region in the

    event of a wildﬁre without jeopardizing human life. As a

    result, UAVs may help with real-time surveillance of a vast

    region without jeopardizing the safety and security of anyone

    involved. Unmanned aerial vehicles (UAVs) can help to ﬁnd

    people and animals in danger so they can be saved.

    4.2 Remote sensing

    Drone technology is increasingly being applied by amateurs

    to collect high-resolution imaging data of isolated places,

    such as mountaintops, coastlines, and islands. The usage

    of UAVs serves as a link between aerial, ground-based and

    space-borne remotely sensed data. UAVs’ cost-effectiveness

    and ultralight features enable spatial and temporal resolu-

    tion observation. Disease diagnosis, water quality inspection,

    famine monitoring, gas and oil yield estimations, conser-

    vation of natural resources, geological calamity survey,

    topographicalsurvey,woodlandmapping,hydrologicalmod-

    eling, and crop management are all possible applications of

    UAV remotely sensed. Poor water quality because of wastew-

    ater discharge and nutrient pollution is a critical concern in

    some marine and coastal environments. Particularly, nutri-

    ent ﬂow from agricultural, urban, and industrial activities

    can cause harmful algal blooms (HABs), ultimately produc-

    ing the harmful toxins. Some research labs in Virginia and

    Florida, USA are focusing on the use of UAVs to early trace

    and detect HABs through hyperspectral sensors. However,

    there are several challenges which must be tackled to make

    this technology practical for coastal monitoring activities.

    Moreover, this technique is also being utilized in archae-

    ological and cartography for crowd-sourced mapping and

    the generation of 3D atmospheric maps. Drones may deliver

    123

    Intelligent Service Robotics (2023) 16:109–137

    123

    current data at low cost, allowing land planners to avoid

    depending on obsolete mapping sources.

    4.3 Search and rescue (SAR)

    Unmanned aerial vehicles (UAVs) are considered critical in

    areas like disaster risk management, rescue missions, and

    public security. UAVs may save a lot of time and resources by

    providing real-time imaging data of desired sites. Resulting

    that, the SAR group is able to detect and pinpoint precisely

    where aid is necessary. Drones, for example, can be used to

    follow lost mountaineers on any trip or to defend humans

    in any isolated forest or desert. Drones may therefore aid in

    the tracking of unlucky victims as well as any difﬁcult ter-

    rain or harsh weather conditions. Drones can deliver critical

    medical equipment before an emergency or physician arrives.

    Drones containing food supplies and medical supplies such

    as vaccines, medical kits and life-saving jackets can be

    sent to disaster-stricken communities and isolated locations.

    Drones, for example, can deliver clothing, water, and other

    essentials to stranded people in difﬁcult regions before res-

    cue workers arrive. This technology can help speed up SAR

    efforts in disasters such as mission personnel, avalanches,

    forest ﬁres, and deadly gas penetration.

    4.4 Infrastructure and construction inspection

    UAVs have made as-built maps, project monitoring, and

    surveys more efﬁcient, simple, and quick. Tracking the devel-

    opment of the building project from start to ﬁnish ensures that

    the work on the site is of high quality. It may deliver reports to

    prospective stakeholders that include pictures, video, and 3D

    mapping. Infrastructure and construction inspection appli-

    cations can beneﬁt greatly from this approach. UAVs are

    gaining high popularity for evaluating the global system for

    mobile communication (GSM) towers, keeping an eye on

    gas pipelines, inspecting power cables, and keeping an eye

    on building projects [101].

    4.5 Precision agriculture

    UAVs could be installed in smart agriculture to obtain spe-

    ciﬁc information through ground sensors (quality of water,

    soilcomposition,humidity,andsoon),spraypesticides,diag-

    nose illness, schedule irrigation, detect weeds, and monitor

    and manage crops. The applicability of UAVs in precision

    agriculture is a cost-effective and time-saving strategy that

    can improve agricultural systems’ revenue, performance, and

    agricultural production. Furthermore, UAVs aid in insect

    damage, weed monitoring, chemical spraying, and farm man-

    agement, resulting in higher crop yields to handle these

    difﬁculties quickly. UAVs combined with remote sensing

    have the potential to revolutionize smart farming. It offers

    Fig. 12 UAV assistance on highway

    temporal, geographical, and spectral resolution, as well

    as multi-angular observation and comprehensive vegetation

    height data. By undertaking sophisticated aerial mapping,

    UAVs can have a huge inﬂuence on the agricultural system.

    UAVs outﬁtted with the necessary cameras and sensors can

    analyze crop health status, including leaf area, foreign pollu-

    tants, chlorophyll content, and temperatures [102]. WH Maes

    et al. evaluated the advancement of remote sensing through

    drones in growth vigor evaluation, nutritional status, disease

    and weed identiﬁcation, and drought stress [103]. With more

    UAV photos, digital image methods will be able to study

    plant diseases and other things in the future.

    4.6 Real-time monitoring of road traffic

    The integration of UAVs with road trafﬁc monitoring (RTM)

    systems has piqued the curiosity of many. UAVs can accom-

    plish 100% automation of the transportation industry in RTM

    [104]. Rescue squads, roadway surveyors, trafﬁc cops, and

    ﬁeld support personnel will all be automated. Reliable and

    intelligent UAVs can support with the automation of these

    parts. UAVs have emerged as a new viable instrument for

    gathering data on highway trafﬁc situations. As compared

    to traditional monitoring systems e.g., surveillance cameras,

    ultrasonic sensors, and circuit analyzers, low-cost UAVs, or

    drones, can inspect large sections of road [101]. Local police

    can use drones to gain a clear picture of road accidents or

    to conduct a large security crackdown on illegal activities

    along the highway, including car theft. Some of the other

    implications include vehicle recognition; raids on suspect

    cars; pursuing hijackers and armed robbers, or anybody who

    breaches trafﬁc regulations. It may also be used to monitor

    driving and incidents in vehicles and probably prevent traf-

    ﬁc bottlenecks and overcrowding [105]. Figure 12 depicts an

    overview of UAV service on the roadway.

    Likewise, UAVs may be used to monitor road conditions,

    such as detecting fractures and providing early warning to

    avert trafﬁc accidents and reduce damage. At present, road

    123

    124

    Intelligent Service Robotics (2023) 16:109–137

    inspection and monitoring are carried out using human vehi-

    cles, and the level of automation must be increased. The

    combination of road inspection technologies with UAVs has

    the potential to drastically minimize road damage. UAVs can

    take pictures of road cracks and use target detection algo-

    rithms to ﬁgure out what they are.

    4.7 UAVs for automated forest restoration

    One more developing study area is the use of UAVs for

    controlled forest restoration (AFR). UAVs could be used to

    aid in the accomplishment of re-vegetation activities e.g.,

    site infrastructure, site inspection, restoration plan, seedling

    supply, site maintenance (germinating and weeding, for

    example), and bio-diversity survey after restoring interven-

    tions [106]. Existing technology, such as GPS and image

    sensors, assists UAVs in performing speciﬁc tasks, such as

    fundamental pre-restoration site inspections and monitoring

    various aspects of biodiversity revival. UAVs could evaluate

    any alterations in temperature, forest functions, and eco-

    logical composition, hence assisting in the surveillance of

    replanting [107]. High-resolution cameras mounted on UAVs

    can give useful data on natural forests to aid in forest restora-

    tion initiatives. Because of their simplicity of data acquisition

    and mobility, UAV cameras with suitable resolution can aid

    in the characterization and study of forest landscapes. Like-

    wise, optical sensors mounted on UAVs are being used to

    obtain geometric properties of forests, such as vegetation

    cover, diameter, and length [108]. UAVs can also be used for

    remote sensing, which is a reliable and effective way to mon-

    itor forests that is different from the way it has been done in

    the past.

    4.8 UAVs for monitoring of overhead power lines

    Power line fault detection and avoidance are critical for the

    reliability and quality of generation capacity. Traditional

    procedures have several disadvantages, including expensive

    costs, inconvenient deployment, and dangerous dangers. As

    a result, researchers are interested in UAV-based power line

    distribution and inspection, as illustrated in Fig. 13. The

    safety of a power transmission system is sometimes referred

    to as power line inspection. The use of a digital camera

    installed on UAV to photograph power line corridors is a

    practical way to perform inspection duties [109]. UAVs can

    also be installed to look for broken bolts, rust or corrosion,

    and lightning strikes on electrical pylons. Short-circuiting

    issue of electricity lines is most commonly caused by severe

    weather, bushﬁres, and tree falls. Authors of a recent research

    [110]examinedtheuseofUAVstodetectandmonitordefects

    in overhead transmission lines. To ﬁnd defects, both climb-

    ing robots and ﬂying UAVs can be utilized. These inspection

    tasks may be carried out by UAVs at a cheaper cost than

    Fig. 13 Inspection of power lines through UAV

    helicopters and with a lower risk than traditional foot patrol.

    Fixed-wing UAVs, which can ﬂy at high altitude and speed

    than other types of UAVs, are most commonly used for rough

    inspection. Multirotor UAVs, on the other hand, obtain pho-

    tographs in the air at a closer distance from the objects by

    hovering. Because of their excellent 3D mobility, multirotor

    UAVs are ideal. Despite these advantages, autonomous mis-

    sion planning and piloting of a multirotor UAV in a limited

    or complicated area is difﬁcult. Advanced data collection,

    exchange, and processing tools for cooperative UAV net-

    works should be researched in the future to provide reliable,

    efﬁcient, and speedier inspections.

    4.9 UAVs for monitoring and assessing plant stress

    UAVs have become an integral element of data collection

    in multiple applications. The use of UAVs in agriculture is

    highly suitable in multiple scenarios. Currently, the use of

    UAVs is steadily expanding to monitor and assess crops,

    forests and orchards. They play a major role to manage

    plant stress such as pests, nutrition deﬁciencies, disease and

    waterqualityandquantity.Severalstudieshavebeenreported

    on plant height assessment, canopy cover estimation, veg-

    etation classiﬁcation, biomass estimation, yield prediction

    and stress detection [111]. Every domain has certain aspects

    which must be kept into account to address the impact of

    UAV-enabled services. Among these domains, plant stress

    detection and quantiﬁcation has received high attention.

    Several UAV-based approached are being used to assess

    plant stress. However, there are several shortcomings which

    prevent their usage at a high-scale. For instance, the tech-

    niques based on thermal imagery are limited by negative

    123

    Intelligent Service Robotics (2023) 16:109–137

    125

    impact from various factors including stomatal conductance

    patterns, canopy architecture, shadows and soil background.

    Similarly, methods based on hyperspectral and multispectral

    images suffer from spatial resolutions, angel of capture, illu-

    mination and canopy structure. Moreover, UAV-based red,

    green, and blue (RGB) images are only feasible in clear visi-

    bility scenarios. Although image-based techniques are useful

    for pesticide applications, irrigation practices, disease pre-

    diction and prevention and weather information, but they are

    not feasible yet, regardless of the deployment techniques and

    sensing devices. There is a need to develop sophisticated ML

    and computer vision techniques along with novel sensors for

    UAVs to overcome aforementioned limitations. At the same

    time, research fraternity should perform more experiments

    to study plant physiology and impact of various stresses on

    biological process. It will be an excellent opportunity to con-

    tribute in this domain and ﬁnd viable solutions.

    4.10 UAVs for space exploration

    There is an emerging trend to utilize UAVs for planetary

    exploration from last few years. UAVs offer tremendous

    potentials to carry our space missions such as study about

    moon surface and atmosphere. Although several planetary

    exploration techniques are available to perform these mis-

    sions including rovers, landers, orbiters, ﬂying balloons,

    ﬂying spacecraft, probes and telescopes [112]. However,

    thesetechniquesarerestrictedbyresolution,limitedinforma-

    tion and versatility. Therefore, UAVs have recently got focus

    due to several beneﬁts in such missions. Several government

    bodies and space agencies including National Aeronautics

    and Space Administration (NASA) has started using UAVs

    to other solar bodies. Researchers have focused on solar

    exploration works through autonomous, semi-autonomous

    and UAVs. According to Sharma et al. [112], UAVs have

    good chances to ﬂy in the atmosphere of Mars. It is due to

    the potential features of hovering, VTOL and low-speed for-

    ward ﬂight. In particular, UAVs offer a wide coverage area

    as compared to exiting orbiters and rovers. As gravity is less

    at Mars surface and it has low density, so UAV can achieve

    an optimal height of 380 m. However, some challenges still

    exist in terms of efﬁciency and cost. Thus, there is a need to

    developcompatiblepropulsionsystem, suitableaerodynamic

    design, and optimal ﬂight trajectories.

    4.11 Aquaculture farm monitoring

    and management

    UAVs have the ability to monitor ﬁsh farms in aquaculture,

    particularly on offshore sites. The mobility and affordability

    of UAVs ensures accessibility to remote areas. The automa-

    tion and mechanization to monitor farms through UAVs,

    sensors and artiﬁcial intelligence (AI) approaches will sup-

    port farmers to gather information about farms and interact

    efﬁciently. Moreover, due to the extensive advancements in

    aquaculture industry, UAVs can be used to achieve target

    results and effectively monitor the expanding farm sites.

    UAVs can signiﬁcantly reduce cost and labors in the aqua-

    culture industry, thus providing stability in ﬁsh form through

    minimizing farm deaths. In aquaculture, UAVs can be used to

    capture real-time images on underwater species, observing

    ﬁsh behavior, remote sensing, site surveillance, ﬁsh feeding

    management, and for assessment of the species [113].

    UAVs offer enormous beneﬁts for monitoring offshore

    kelp aquaculture farms. Giant kelps are effective aquaculture

    crops which needs regular monitoring in order to achieve

    maximum production, and optimizing biomass and nutri-

    tional content. For this purpose, a small UAV carrying a

    lightweight optical sensor can be used to monitor these

    farms. It can estimate the tissue nitrogen quantity, density

    and canopy area based on space and time scales, which plays

    signiﬁcant role to observe any changes in kelps. UAVs with

    integrated sensors such as hyperspectral, multispectral and

    RGB cameras can be used to provide a natural image of kelp

    forest canopy. Similarly, UAVs can be used to observe and

    characterize the mobility of the pellets. Through collected

    information, farmers can attain feeding optimization.

    4.12 UAVs in emergency medical services

    UAVs have shown great potential in smart cities worldwide.

    Smart cities have smart healthcare system based on teleme-

    try, implantable medical equipments, and medical drones

    to quickly deliver ﬁrst-aid supplies. Currently, UAVs have

    proven their stature to tackle with COVID-19 pandemic in

    different countries. However, it is worth noting that the lead-

    ing organization to tackle with COVID-19 is the national

    EMS institution along with several parties such as EMS

    personnel, nurses, and medical doctors. In addition, several

    policymakersareconsideringdifferentpreventivemeasureto

    ﬁght against COVID-19 including wearing surgical masks,

    avoiding facial-touching, regular hand-washing, city lock-

    down, high risk area avoidance, social gathering avoidance

    and implementing health codes [114]. Policy makers should

    consider the balance between economy and public safety

    before introducing any new measures. Currently, UAVs are

    being used to perform various tasks to prevent COVID-19

    such as:

    • Transport of patients

    • Public announcements

    • Crowd surveillance

    • Spraying disinfection

    • Mass screening

    • Crown aerial monitoring

    123

    126

    Intelligent Service Robotics (2023) 16:109–137

    Fig. 14 Role of UAVs in COVID-19 pandemic

    • Delivering vaccines and other medical supplies

    A very common application of UAVs is to supervise or

    monitor any speciﬁc area. UAV-integrated cameras can assist

    in real-time surveillance. Thermal cameras can be imple-

    mented to trace febrile patients. It helps to quickly implement

    isolation rules in any certain area in order to reduce the risk

    of further disease spread. Similarly, on-board loudspeaker

    can help to deliver ofﬁcial policies and give appropriate

    instructions in any community [115]. UAVs can help to

    deliver daily life items, ensuring reduction in mass contact at

    crowded markets or other public places. Furthermore, UAVs

    can support in transportation tasks such as medicament sup-

    ply deliver and COVID test sampling collecting, ultimately

    reducing the risk of contact with infectious person and virus

    spread. UAVs can also play their role in nucleic acid testing,

    collecting samples and delivering reports. They can also be

    used to spray disinfection in order to mitigate the viability

    of the virus on the surface. In 2020, UAVs have been used

    during the COVID-19 crises to deliver medical supplies in

    USA, China, Chile etc. Recently, Zipline, working collabo-

    ratively with Novant-Health, has been providing COVID-19

    vaccines in North Carolina, USA. UAVs have been used to

    provide personal protective equipment to frontline staff ﬁght-

    ing against this pandemic. Different applications of UAVs to

    cope with COVID-19 are presented in Fig. 14.

    4.13 UAVs for maritime communication

    and surveillance

    Aerial platform include the use of high-altitude platform

    Stations (HAPS), ﬂying up to 20 km from the ground and

    UAVs ﬂying at a few hundred meters above the sea surface

    [116]. Some UAVs can be installed and remotely operated

    from small boats, while larger systems rely on onshore

    architectures to launch and operate. This technology is com-

    plementary to surface and underwater vehicles since it can

    be easily controlled in the air at some distance and altitude,

    and thus communicate at a different speed and position. In

    maritime networks, UAVs can assist to forward the data from

    ground station to mobile vessel even in the absence of LoS

    path. In addition, UAVs can relay data from IoT sensors

    located in ocean and relay data from/to USVs. The main lim-

    itation in the operation of UAVs is limited battery capacity

    and payload. This limitation can be relieved through a teth-

    ered UAVs connected with a power supply. However, it can

    pose another issue of limited mobility. There is a need to ﬁnd

    optimal path to collect data from the sensor nodes in maritime

    environment. Some recent works have been reported on teth-

    ered UAVs ﬁxed on buoys [117]. Tethered UAVs can hover at

    a limited range above the water surface with limited mobility

    and coverage. Also, optical ﬁbers can be connected with teth-

    ered UAVs to ensure high transmission rates. However, HAPs

    are more suitable as they offer extended coverage. Moreover,

    HAPs can carry large antennas, removing less weight limi-

    tations and offering autonomy up to several months.

    Due to enormous beneﬁts of UAVs in maritime commu-

    nication, UAV-to-ship wireless channels must be developed.

    Furthermore, efﬁcient system testing must be conducted for

    the promising UAV-to-ship networks. In maritime environ-

    ments, UAV communication faces different channel char-

    acteristics, including temperature of troposphere above the

    ocean, pressure, waveguide impact due to humidity, signal

    attenuation due to climate change and seawater irregular

    ﬂuctuations. In contrast to terrestrial UAV-to-ground chan-

    nels, the scatterers effect on UAV-to-Ship is uneven due

    to irregular sea waves. Similarly, waveguide propagation is

    another essential factor in UAV-to-ship channels, which ulti-

    mate introduces different channel characteristics. In order

    to ensure sophisticated UAV communication in such mar-

    itime environments, the related channel modeling is an open

    research area for future contributions. In US, both the coastal

    guard and Navy have deployed a group of small UAVs to

    assist manned assets, supporting in many aspects to sup-

    port law enforcement, surveillance and military missions in

    marine and coastal environments. Moreover, two US-based

    systems ScanEagle and MQ-4C Triton are being used for

    naval missions. The former is deployed with radar as well

    as infrared (IR) and electro-optical (EO) sensors, making

    is capable to perform persistent maritime surveillance mis-

    sions. It has the ability to identify ships through installed AIR

    receivers.

    4.14 Flying cars and eVTOLs

    Rapidly expanding high infrastructure costs, land space lim-

    itations and urban population put a critical challenge for the

    123

    Intelligent Service Robotics (2023) 16:109–137

    127

    future ground-based transportation systems. Flying cars, no

    more conﬁned to the realm of ﬁction, are a remarkable step

    in transportation industry. Flying cars and eVTOL (elec-

    tric vertical take-off and landing) aircraft is envisaged to

    revolutionize the future transportation system, which can

    substantially minimize greenhouse gas emissions and car-

    bon footprint of personal vehicles as well as travel time.

    Currently, over 250 companies have started initiatives on

    eVTOLs and ﬂying cars, and few vehicles will pave their way

    to commercial market soon [118]. From last few decades,

    there has been a notable expansion in the use of personal

    vehicles worldwide, causing trafﬁc congestion, a rapid cli-

    mate change, and enhanced commuting duration, particularly

    in metropolitan areas. In this regard, eVTOLs and ﬂying cars

    are expected to be the future of smart transportation system

    as they will support reduced emission and trafﬁc congestion

    along with improving security. These disruptive technologies

    will have diverse requirements based on their application sce-

    nario. For example, personal vehicles should be economical,

    lightweight, and should contain fewer parking spaces, while

    piloted taxi services are envisaged to have range and speed

    according to their Rural Air Mobility (RAM) and Urban Air

    Mobility (UAM) missions.

    Flying car manufacturers are ﬁnding innovative designs

    to shrink the vehicle size through detachable propellers or

    retractable wings for different tasks such as drive mode or

    garage parking. Several ﬂight mechanisms and wing conﬁg-

    uration are being proposed for the eVTOLs and ﬂying cars to

    ensure forward ﬂight for the cruise and vertical lift for both

    take-off and landing. At present, mostly available ﬂying cars

    have hybrid energy supply system or only gasoline and do not

    have VTOL capabilities. However, ensuring a complete elec-

    tric ﬂying car is yet to be explored. In a recent study [118],

    authors discussed fully electric powertrain design with dual

    energy sources, such as hybrid fuel cells and batteries, to sup-

    portextendedrange.Moreover,authorsalsodiscussedtheuse

    of a single propeller for both ﬂight and drive modes in order

    to aid VTOL capability. Despite these technical advance-

    ments, initiating widespread deployment of ﬂying cars will

    impose an immense standardization challenges and sustain-

    ability implications [119]. Despite these challenges, several

    companies have started innovative strategies to introduce

    these smart ﬂying vehicles in future. With expanding features

    supporting timesaving, environment, and economic poten-

    tials, it’s time for regulatory bodies to make the life-changing

    leap to seed the architecture development for personal urban

    airspace utility. With these advancements in aviation regu-

    lations as well as processing and sensor technologies, we

    can expect a transition toward futuristic smart and automatic

    transportation systems.

    Fig. 15 Limitations of current stage of UAV usage

    5 Open challenges

    UAVs are prone to several critical challenges and limitations,

    which require future investigations. Some limitations in UAV

    usage are presented in Fig. 15 while potential challenges

    related to UAVs are as follow:

    • One of the critical challenge is to ensure the security of

    sensitive data such as position, location etc., from drones

    or UAVs. As there is no encryption on UAV, so there is

    risk to be hijacked. Hacking and cyber liability are critical

    issues of using UAVs. In military operations, UAVs are

    vulnerable to potential threats of data leakage. Hackers

    may usurp complete control of UAV to steal data, invasion

    of privacy and any illegal activity such as for smuggling.

    • Despite the extensive emergence of UAVs, there is a dire

    need to devise standardizations from regulatory bodies for

    the operations of UAVs in geographic area of different

    countries. A major hindrance in the widespread use of

    UAVs is the ambiguity or lack of signiﬁcant standards and

    regulations for UAV operations, allowed airspace, allowed

    weight and size, allowed height, privacy or secrecy consid-

    erations, safety requirements and characteristics. A lack in

    heterogeneity of government rules for the implementation

    of UAVs can be observed. UAVs can affect the navigation

    of commercial airplanes. So countries should implement

    regulations and rules for proper operations of UAVs. For

    instance, in the US, the FAA is responsible to issue cer-

    tiﬁcates and air trafﬁc regulations for UAVs. Similarly,

    international collaboration or coordination can also assist

    to introduce global rules, as different countries have dif-

    ferent regulations and standards. For example, at present,

    there are three different regions, such as (a) region 1 con-

    tains Africa, Europe and some part of Middle East, (b)

    region 2 contains US, and (c) region 3 is based on Asia

    and the Paciﬁc, operating at different frequency ranges

    for UAV operations. In short, several concerns are asso-

    ciated to UAV regulations, such as poorly documented

    123

    128

    Intelligent Service Robotics (2023) 16:109–137

    legal processes and delay in ﬂight approvals limiting the

    widespread use, availability and ﬂexibility of this technol-

    ogy. In this regard, a viable approach can be AI algorithms

    for standard compliance, which supports risk mitigation,

    enhanced security of conﬁdential data, and quick response

    to new standardization requirements. In this way, we can

    see AI-empowered UAVs authorized for domestic use in

    various countries, meeting the operational regulations of

    each certain geographic location.

    • Smooth and successful operation of UAVs can be per-

    formed using wireless sensors. For instance, smart trafﬁc

    control system can be attained by monitoring and surveil-

    lance from wireless sensors.

    • Limited transmission range, processing capability and

    slower speed are also some major concerns in UAVs which

    need more research contributions and investigations to

    mature this technology.

    • Due to UAV path constraints and battery limitations,

    resource allocation has become a crucial concern. It is

    noticed in three aspects: UAV hovering, local computing

    and task ofﬂoading. Thus, designing accurate path plan-

    ning can consequently compromise the operational cost

    and calculated performance. Efﬁcient resource allocation

    can improve fairness, task completion time reduction, cost

    reduction, power consumption reduction and computa-

    tional efﬁciency maximization.

    • The speed of some UAVs is slower than cars and other

    vehicles on highway. A possible solution to overcome this

    issue is to allow UAVs to travel at high altitudes by regula-

    tory bodies. In this way, UAVs can get broad ﬁeld-of-view

    which can overcome the limitation of speed.

    • The high speed of some UAVs is also a critical issue. UAVs

    ﬂying on speed between 35–70 Kmph should involve

    obstacle avoidance feature to prevent from any possible

    collision [120].

    • Another hurdle for UAV operation performance is power

    limitation, energy consumption or limited battery life.

    Usually UAVs are battery-powered and suffer from short

    battery life, generally below 1 h. UAV batteries are

    consumed for image analysis, data processing, wireless

    communication and UAV hovering. Usually UAVs need

    to travel over large areas and need to return multiple times

    to charging stations. In SAR operations, UAVs ﬂy for

    longer time periods over disaster stricken areas. Due to

    these limitations, a decision should be taken weather UAVs

    carry out image or data analysis in real-time or not. One

    possiblesolutionistoformswarmsofdronesthroughcoor-

    dination algorithms which can overcome the limitation of

    single drone in terms of energy efﬁciency [101]. Other

    interesting approaches are to investigate novel designs for

    recharging stations and efﬁcient WPT methods such as

    laser power transfer (LPT). In [121], energy-aware instal-

    lation of UAVs with low power and lossy networks (LLT)

    technique is proposed to overcome these issues.

    • Complete autonomous and safe operation of swarms of

    drones is critically important as its prone to human error,

    machine error and obstacles collisions. Thus, there is a

    need to swarm intelligence algorithms to avoid collisions.

    Cooperative formation control algorithms have been pro-

    posed to avoid collisions for the multi-UAVs [122]. These

    algorithms can fuse data from different deployed sources

    such as LIDARs, RADARs, gyroscopes, accelerometers,

    digital cameras, weather and location sensors.

    • There are several issues in using UAVs for infrastructure

    and construction monitoring such as limited processing

    capability, short ﬂight time and limited energy. There

    is a research gap in multiple UAVs cooperation for

    infrastructure and construction inspection. Multiple UAVs

    cooperation can ensure speedy project completion, high

    error tolerance and broad inspection scope.

    • Another key challenge is limited payload capability of

    lightweight UAVs. It limits the ability of UAVs to carry

    on-board load such as digital, stereo vision and thermal

    cameras, multiple sensors such as temperature, GPS and

    gat detection etc. UAVs are required to carry sensors like

    laser scanner, ultrasonic, RADAR and LADAR which are

    heavy [120].

    • Some cameras used in UAVs are very expensive and low

    resolution.Forexample,mostofthethermalcamerasareof

    resolution from 640 pixels by 480 pixels and price ranges

    from 2000 to 5000$. In addition, thermal aerial imag-

    ing suffers from several factors including emitted/reﬂected

    thermal radiations, shooting distance and atmospheric

    moisture.

    • In case of adverse weather conditions such as storm, rain

    and wind, UAV’s deployment for different applications

    such as precision agriculture is difﬁcult due to unwanted

    deviations in predetermined trajectories. Weather con-

    ditions also affect operation time, path elevation, UAV

    altitude and ﬂight direction. In natural disaster conditions

    e.g., typhoons, hurricanes or Tsunamis, atmospheric con-

    dition tends to be a cardinal challenge for UAV missions.

    In these detrimental conditions, UAVs cannot hover and

    cannot take accurate readings or data and cannot oper-

    ate in extreme conditions. Therefore, researchers should

    address the speciﬁcations and UAV capabilities to with-

    stand these adverse weather conditions and can complete

    weather-sensitive missions efﬁciently and safely. Speciﬁ-

    cally, wind speed should be taken into account for smooth

    UAV operations and it should be involved in UAV’s strate-

    gic mission plan and deployment phase.

    • There should be proper insurance liability due to damages

    caused by UAVs. Several media reports describe soft tis-

    sue injuries, eye loss and severe lacerations due to UAV

    123

    Intelligent Service Robotics (2023) 16:109–137

    129

    accidents. In addition to property damages and injuries due

    to UAV crash, UAV also cause accident with aircrafts, lia-

    bility doe damaged goods and dropped cargo. Liability for

    UAV use also contains an enormous threat to individual

    privacy.

    • Another major concern of privacy arises with the use

    of UAVs. UAVs are incorporated with cameras or other

    equipment which can capture photos or record videos;

    which may result in violation of individual’s privacy. To

    tackle this problem in USA, Center of Democracy and

    Technology (CDT) informed Federal Aviation Adminis-

    tration (FAA) to develop speciﬁc regulations to preserve

    privacy. For this purpose, Privacy by Design (PbD) was

    introduced which supports compensations for privacy vio-

    lations [123]. PbD regulations notably restrict the privacy

    intrusion. Moreover, consistent UAVs ﬂights can damage

    the market value of some companies by revealing their

    trade strategic plans and secrets.

    6 Security issues

    In this section, we have discussed different cyber security

    issues on UAVs such as:

    • UAVs mostly suffer from Hijacking, denial-of-service

    (DoS) and distributed DoS attacks because of the unavail-

    ability of appropriate DoS/DDoS resistant strategies. Sig-

    nal spooﬁng trough hijacking can harm the behavior of

    some UAVs. GPS Signal spooﬁng attacks occur due to

    inlaying or injecting wrong information from the GPS

    channels by the miscreant as illustrated in Fig. 16. In

    hijacking, full control of UAV can be stolen by the through

    inserting extra commands. Similarly, session hijacking can

    severely damage communication links of UAVs. More-

    over, DoS attacks impose severe availability challenges as

    attacker can cause network congestion by sending multi-

    ple requests. DoS attacks occur due to overﬂow data in

    communication links to cause interruptions, putting extra

    load on processing units and by depleting the batteries. In

    DDos, the attacker overwhelms the UAV by sending traf-

    ﬁc from several sources to introduce unreachability issues.

    These attacks can be mitigated by sensing, tracing signal

    distortion and high authentication.

    • Current countermeasure algorithms are available for single

    UAV networks. Thus, there is a need to develop or modify

    existing algorithms for multi-UAVs.

    • According to Shakhatreh et al. [101], existing simulation

    test beds are not complete mature. Similarly, available

    emulators for security analysis are only suitable for spe-

    ciﬁc software and hardware designs. Thus, there is a need

    to develop customized simulators and tools.

    Fig. 16 GPS spooﬁng attack

    • Existing security analyses neglect the software and hard-

    ware differences for different types of UAVs. In contrast,

    some attacks only occur in particular software or hardware

    design. In contrast, security measures are suitable for any

    speciﬁc UAV and cannot be implemented to different UAV

    systems. Thus, there is a need to design uniﬁed security

    measure which can be implemented to all UAVs.

    • Among various security threats, GCS threats are very

    harmful as sensitive data can be leaked through software

    tools and malicious operating commands. A compromised

    GCS receives erroneous commands from attacker. These

    attacks usually occur due to viruses, key loggers and mal-

    wares. Mitigative solutions such as GCS authentications

    are needed to secure UAV data to be leaked to unautho-

    rized processes, entities and users. Figure 17 illustrates

    some GCS attacks.

    • In some scenarios, attacker can misguide UAVs by sending

    some erroneous warning texts. It can cause network trafﬁc

    jams. The attacker can masquerade as a legitimate user to

    give false information, wrong commands or corrupt data

    to substantially degrade UAV performance. These attacks

    occur due to the unavailability of authentication strategies

    as any adversary can pretend like a legitimate user to cause

    interference in the network.

    • In some cases, the attackers can steal the UAV path plan-

    ning information or monitor UAV trajectories for any

    illegal activity by using this data. These threats can lever-

    age the attacker UAV around the legitimate UAV.

    • Eavesdropping is another major concern which occurs due

    to the absence of preventive strategies like data encryption.

    In such scenario, the adversary can access the legitimate

    UAV’s data. Non-repudiation can be used to strengthen the

    123

    130

    Intelligent Service Robotics (2023) 16:109–137

    Fig. 17 Ground control station (GCS) attacks, motivated by Mansﬁeld

    et al. [126]

    security measures [124]. In such case, speciﬁc information

    is needed for any conﬁrmation to prevent from security

    breaches.

    • Another important factor is the integrity of UAV mission

    which relates with data accuracy and transfer without any

    interference. If integrity protection strategies are absent,

    the data becomes invalid as attacker can damage the orig-

    inal data.

    • In some scenarios, UAV hardware components do not

    respond accurately and change their target behavior [125].

    Such kinds of attacks are performed to cause UAV mission

    failure or steal conﬁdential data.

    • Another critical attack is ﬂight control computer attack

    which can change mission instructions or parameters to

    interrupt UAV ﬂight control. On-board software or hard-

    ware tools can be used to protect from such attacks. It may

    contain warning generation, controller estimation or real-

    time monitoring in order to respond immediately against

    any possible risk.

    • In some cases, the attacker misguides UAV to stop follow-

    ing any intended trajectory through intended tampering

    on onboard navigational devices. Due to these attacks, the

    UAVs cannot provide accurate position and location to the

    control system.

    • It is highly critical to develop advanced mechanisms to

    combat ever evolving security risks against UAV com-

    munication, infrastructure and reliability. Major security

    concern related to delivery-based UAVs is hijacking,

    where attacker can steal or damage its load. In case of

    multimedia-, entertainment- or commercial-based UAVs,

    disruption its transmission can severely impact the whole

    Table 14 Security issues in ML-based UAV networks

    Reference

    Security aspect

    ML solution

    [128]

    Protection against

    trespassing UAVs

    SVM-based ML

    [129]

    Guaranteeing privacy,

    integrity, and

    conﬁdentiality of UAV

    compressed video

    streams

    CNN-based detection

    [130]

    UAV pilot identiﬁcation

    Classiﬁcation based on

    LD, QD, SVM, KNN,

    or R and F

    [131]

    Real-time mapping

    Genetic algorithm-based

    [132]

    Interception of

    malicious UAVs

    Q-learning

    [133]

    Eavesdropping detection

    One-class SVM and

    K-means

    [134]

    GPS spooﬁng protection

    ANN-supervised

    learning

    [135]

    Jamming, spooﬁng, and

    eavesdropping

    mitigation

    RL

    [136]

    Interference and

    jamming mitigation

    PHC-based learning

    [137]

    Eavesdropping

    mitigation

    Q-learning

    network performance. In such scenario, UAV authenti-

    cation is required, which can cause excessive delays. To

    cope with different security challenges, ML algorithms are

    proposed. ML-enabled physical layer security adopted to

    reduce the impact of malicious UAVs [127]. Furthermore,

    anti-jamming strategies can be implemented to enhance

    physical layer security (PLS) performance against poten-

    tial jammers. In Table 14, we have summarized security

    issues in ML-based UAV networks.

    7 Future research directions

    In this section, we present several future research directions

    for further contributions on UAV research as follows:

    Even though AI schemes including machine learning

    strategies and neural networks have been used in UAVs,

    but deep learning and reinforcement learning strategies

    are yet to be implemented fully [138–143]. It is due to

    limited power constraints and processing utilities. Hence,

    researchers should ﬁnd deep-learning-based novel strate-

    gies for UAVs, particularly for SAR mission [144]. These

    schemes can support contextual decisions and learning on the

    basis of trajectory information. The gathered information can

    123

    Intelligent Service Robotics (2023) 16:109–137

    131

    Fig. 18 AI/ML-based solutions

    for UAV communication

    be utilized to ensure efﬁcient autonomous piloting of UAVs.

    As UAVs suffer from both storage and energy limitations,

    thus, lightweight and portable ML, DL, and RL approaches

    can be adopted to tackle these limitations. AI/ML-based solu-

    tion can be implemented in a wide variety of scenarios for

    UAV communication as shown in Fig. 18.

    • Novel strategies for UAV energy harvesting and novel

    material for UAV batteries must be investigated to achieve

    extended missions [145]. Researchers should ﬁnd new

    lightweight and efﬁcient batteries to support enhance ﬂight

    time for UAVs. Future studies must address efﬁcient power

    control and energy consumption mechanism for UAVs.

    • Researchers should focus on ﬁnding power-efﬁcient algo-

    rithms to process UAV’s data e.g., aerial imaging, video

    and sensing data in real-time. In [146], authors proposed a

    convolutional neural network method to assist avalanches

    searchandrescueoperationthroughUAVcapturedimages.

    Similarly, algorithms for UAVs swarms, swarms opti-

    mization [147, 148], coordination, collision avoidance and

    UAVs trajectory plans are also needed.

    • It is envisaged that with the further development of UAVs

    with efﬁcient standardizations, privacy rules, image pro-

    cessing algorithms, low-cost sensors, enhanced ﬂight time

    and larger payload, there is a need to integrate UAVs in

    diverse applications such as ﬁeld crop phenotyping [149].

    • Imaging processing techniques for UAVs face several

    critical issues such as varying image orientation, higher

    overlaps, variable scales and varying altitudes. Research

    fraternity should address these challenges in future inves-

    tigations.

    • There is a need to propose efﬁcient and real-time trans-

    mission lines inspection methods through UAVs, such as

    data analysis tools, cooperative platforms, robust tracking

    [150] and detection means, vision-based inspection and

    UAV low altitude photogrammetry approaches.

    • Researchers should focus on the implementation of new

    sensing devices, special cameras, multi decision making

    algorithms,multispectralimagery,coexistenceofedge/fog

    computing [151, 152] or remote sensing and positioning

    mechanism to support efﬁcient detection of soil, mapping

    crop status and other farming characteristics [153].

    • There is a need to propose more strategies for sensing,

    guidance, navigation and localization. Any problem in

    these techniques can cause failure in accuracy and timely

    delivery of parcels. Thus, researchers should investigate

    low-cost, efﬁcient sensing devices and localization sys-

    tems.

    • Further research contributions should be made toward

    using UAVs in resilient public safety networks. Future

    studies should address public safety communications, pub-

    lic health in disaster scenario, blockchain integration in

    UAVs to enhance health monitoring systems. In a recent

    study [154], authors addressed public safety network using

    UAVs.

    • Researchers should ﬁnd adaptive control [155–160] and

    cooperative algorithms for multi-UAVs system. In current

    era,thousandsofUAVsintheairformanetworktoperform

    various tasks such as drones light show, QR code genera-

    tion and company’s logo design in air for promotion. There

    is aneedtoﬁndrobust coordinationmechanisms tosupport

    such applications.

    • More research works should be carried out to assess

    adverse weather effects on UAV robustness to ensure suc-

    cessful mission implementation.

    • Data ﬁltering techniques should be embedded in UAVs to

    prevent from redundant data, limit duplicate, illegal access

    and false locations. UAV can be integrated with emerg-

    ing intelligent reﬂecting surfaces (IRS) to enhance PLS

    of IRS-assisted UAV system in different scenarios while

    maintaining computational intricacy and system perfor-

    mance [161].

    • In future, UAVs may be recharged through different types

    of energy resources such as fuel cell, solar cell and bat-

    teries to prolong ﬂight time and endurance in persistent

    missions [162–164]. Considering hybrid power supply

    feature, it will important to effectively control UAV’s

    charging characteristics. In addition, UAVs can ofﬂoad

    123

    132

    Intelligent Service Robotics (2023) 16:109–137

    trafﬁc and computation tasks to nearby ground vehicles

    in order to save power consumption. Thus, collaborative

    scheduling of hybrid power supply, communication and

    computation is an interesting research topic for further

    contributions.

    • UAV-empowered aerial caching can be adopted to achieve

    enhanced data throughput in IoT applications. In this con-

    text, size of caching contents, users mutual distances and

    optimizations of UAVs are the primary concerns to ensure

    feasibility.

    • There is a need to implement security algorithms such as

    blockchain in UAVs swarms, means putting more com-

    putation ability and storage capacity on UAVs. However,

    it can reduce UAV ﬂight time and cause latency. Hence,

    further investigates are required to implement the secu-

    rity algorithms taking the resource-constrained nature of

    drones into account.

    • Cooperative path planning is highly signiﬁcant for intel-

    ligent rendezvous generation and energy reduction for

    UAVs. Due to geographic limitations and highly dynamic

    network topology, smartly monitoring UAV’s ﬂight in a

    collision-free and real-time manner has become a crucial

    issue. To overcome such issues for distributed and intel-

    ligent routing scheduling, deep reinforcement algorithms

    can be used through efﬁcient transfer learning and accel-

    erating the learning speed.

    • Present studies on UAVs mainly rely on trusted hard-

    ware or a third party integration, whose malfunction can

    severely damage the system. Therefore, there is a need

    to propose trust-free mechanisms to avoid illegal activity

    and develop trust for UAVs in an untrusted environment.

    In this regard, blockchain technology is a viable approach

    to ensure security. However, a major hurdle is to develop

    robust and lightweight blockchain system to withstand net-

    work fragmentation due to UAV’s constrained resources

    and high mobility. Moreover, it can cause complex incor-

    poration problem and requires rigorous testing. Thus, a

    highly devoted architecture integrating features of both

    UAVs and blockchain technology is needed.

    • Existing blockchain-assisted UAV applications need a per-

    missioned or private blockchain networks. These networks

    are critically vulnerable to threats in case of multi-UAVs

    networks. Moreover, due to increasing number of poten-

    tial attacks such as game-theory-based attacks, machine

    learning (ML), and quantum-based attacks, it is essential

    to secure blockchain. Thus, research efforts are needed

    to make private blockchain networks safer, secure and

    immutable.

    • NewsetofregulationsandpoliciesforUAVsmustbeintro-

    duced and implemented to ensure efﬁcient, reliable, secure

    and safe operations of the vehicles. Developing new stan-

    dardizations is one of the major concerns as UAVs must

    be interoperable with the current technologies. In order

    to manage EM spectrum and its bandwidth, it is critically

    essential for UAVs not to be operating in the congested

    bandwidth and frequency spectrum. It is also crucial to

    keep the knowledge of published regulatory agreements by

    NATO for UAVs. This regulation deﬁnes the standard data

    protocols and message formats. It also enables a standard

    interface between ground coalitions and UAVs. Addi-

    tionally, it indicates the coalition-shared database which

    permits data sharing between smart sources. In the US, the

    Federal Aviation Administration (FAA) provides certiﬁ-

    cation for remote piloting, even for commercial operators.

    Commercial UAVs should follow the rules set by the FAA

    for reliable operations. For example, commercial UAVs

    must have a weight of 55 pounds and their operational

    range must be below 400 feet above the ground in case

    of uncontrolled airspace as indicated by Class G. On the

    other hand, certain authorizations and permissions must be

    attained to ﬂy in controlled airspace as indicated by Class

    C, D and E [165]. UAVs which will be utilized for public

    operations must have a certiﬁcate issued from the FAA,

    operating body must comply with all regulations, rules,

    laws and federal of each speciﬁc area, city, province, state

    and country.

    8 Conclusion

    AsUAVshavegainedsigniﬁcantresearchattention,moreand

    more patents and scientiﬁc articles are being published. The

    rapidly expanding research and development of UAVs is a

    consequence of these innovations. Furthermore, the demand

    for high mobility, more autonomy and bigger range of UAVs

    resulted in the design of novel systems for battery swap-

    ping, docking stations and precision landing. The application

    of these is already being used for ﬁre detection and pre-

    vention, disaster monitoring, precision agriculture, wireless

    communication, remote sensing, power-line monitoring, and

    highway trafﬁc control etc. In this regard, we comprehen-

    sively review ongoing developments of UAVs, accomplished

    by both academia and industrial sectors. We review aca-

    demic contributions pertinent to UAV types, classiﬁcations,

    standardizations, swarms and charging methods. Further-

    more, this study outlines the rapidly expanding interest of

    researchers, state authorities and business bodies to further

    harness and utilize the complete features of this promis-

    ing technology. We brieﬂy discuss UAV characteristics such

    as payload, altitude, range, speed, and ﬂight time. More-

    over, application scenarios, potential challenges and security

    issues are also examined. Finally, future research directions

    are identiﬁed to further hone the research work.

    123

    Intelligent Service Robotics (2023) 16:109–137

    133

    Acknowledgements This work is supported by the National Natural

    Science Foundation of China under grant 62261009, Ministry of Edu-

    cation Key Laboratory of Cognitive Radio and Information Processing

    (CRKL200106)

    Declarations

    Conﬂict of interest The authors declare no conﬂict of interest.

    References

    1. Grlj CG, Krznar N, Pranji´c M (2022) A decade of UAV docking

    stations: a brief overview of mobile and ﬁxed landing platforms.

    Drones 6(1):17

    2. Rovira-Sugranes A, Razi A, Afghah F, Chakareski J (2022) A

    review of AI-enabled routing protocols for UAV networks: trends,

    challenges, and future outlook. Ad Hoc Netw 130:102790

    3. Noor F, Khan MA, Al-Zahrani A, Ullah I, Al-Dhlan KA (2020) A

    review on communications perspective of ﬂying ad-hoc networks:

    key enabling wireless technologies, applications, challenges and

    open research topics. Drones 4(4):65

    4. Dronova I, Kislik C, Dinh Z, Kelly M (2021) A review of

    unoccupied aerial vehicle use in wetland applications: emerging

    opportunities in approach, technology, and data. Drones 5(2):45

    5. Kim J, Kim S, Jeong J, Kim H, Park JS, Kim T (2018) CBDN:

    cloud-based drone navigation for efﬁcient battery charging in

    drone networks. IEEE Trans Intell Transp Syst 20(11):4174–4191

    6. Nourmohammadi A, Jafari M, Zander TO (2018) A survey on

    unmanned aerial vehicle remote control using brain–computer

    interface. IEEE Trans Hum-Mach Syst 48(4):337–348

    7. Kanellakis C, Nikolakopoulos G (2017) Survey on computer

    vision for UAVs: current developments and trends. J Intell Rob

    Syst 87(1):141–168

    8. Zhang S, Qian Z, Wu J, Kong F, Lu S (2016) Optimizing itinerary

    selection and charging association for mobile chargers. IEEE

    Trans Mob Comput 16(10):2833–2846

    9. Aldhaher S, Mitcheson PD, Arteaga JM, Kkelis G, Yates DC

    (2017) Light-weight wireless power transfer for mid-air charg-

    ing of drones. In: 2017 11th European conference on antennas

    and propagation (EUCAP). IEEE, pp 336–340

    10. Lu M, Bagheri M, James AP, Phung T (2018) Wireless charging

    techniques for UAVs: a review, reconceptualization, and exten-

    sion. IEEE Access 6:29865–29884

    11. Raciti A, Rizzo SA, Susinni G (2018) Drone charging stations

    over the buildings based on a wireless power transfer system. In:

    2018 IEEE/IAS 54th industrial and commercial power systems

    technical conference (I&CPS). IEEE, pp 1–6

    12. Rohan A, Rabah M, Talha M, Kim SH (2018) Development

    of intelligent drone battery charging system based on wireless

    power transmission using hill climbing algorithm. Appl Syst

    Innov 1(4):44

    13. Shin M, Kim J, Levorato M (2019) Auction-based charging

    scheduling with deep learning framework for multi-drone net-

    works. IEEE Trans Veh Technol 68(5):4235–4248

    14. Pham H, Smolka SA, Stoller SD, Phan D, Yang J (2015) A survey

    on unmanned aerial vehicle collision avoidance systems. arXiv

    preprint arXiv:1508.07723

    15. Hayat S, Yanmaz E, Muzaffar R (2016) Survey on unmanned

    aerial vehicle networks for civil applications: a communications

    viewpoint. IEEE Commun Surv Tutor 18(4):2624–2661

    16. Ebeid E, Skriver M, Jin J (2017) A survey on open-source ﬂight

    control platforms of unmanned aerial vehicle. In: 2017 euromicro

    conference on digital system design (DSD). IEEE, pp 396–402

    17. Geraci G, Garcia-Rodriguez A, Giordano LG, López-Pérez D,

    Björnson E (2018) Understanding UAV cellular communica-

    tions: from existing networks to massive MIMO. IEEE Access

    6:67853–67865

    18. Fotouhi A, Qiang H, Ding M, Hassan M, Giordano LG, Garcia-

    Rodriguez A, Yuan J (2019) Survey on UAV cellular com-

    munications: practical aspects, standardization advancements,

    regulation, and security challenges. IEEE Commun Surv Tutor

    21(4):3417–3442

    19. Mozaffari M, Saad W, Bennis M, Nam YH, Debbah M (2019) A

    tutorial on UAVs for wireless networks: applications, challenges,

    and open problems. IEEE Commun Surv Tutor 21(3):2334–2360

    20. Li B, Fei Z, Zhang Y (2018) UAV communications for 5G and

    beyond: recent advances and future trends. IEEE Internet Things

    J 6(2):2241–2263

    21. Zhang L, Zhao H, Hou S, Zhao Z, Xu H, Wu X et al (2019) A

    survey on 5G millimeter wave communications for UAV-assisted

    wireless networks. IEEE Access 7:117460–117504

    22. Ullah Z, Al-Turjman F, Mostarda L (2020) Cognition in UAV-

    aided5Gandbeyondcommunications:asurvey.IEEETransCogn

    Commun Netw 6(3):872–891

    23. Oubbati OS, Atiquzzaman M, Ahanger TA, Ibrahim A (2020)

    Softwarization of UAV networks: a survey of applications and

    future trends. IEEE Access 8:98073–98125

    24. Zhi Y, Fu Z, Sun X, Yu J (2020) Security and privacy issues of

    UAV: a survey. Mob Netw Appl 25(1):95–101

    25. Skorobogatov G, Barrado C, Salamí E (2020) Multiple UAV sys-

    tems: a survey. Unmanned Syst 8(02):149–169

    26. Jiang X, Sheng M, Zhao N, Xing C, Lu W, Wang X (2021) Green

    UAV communications for 6G: a survey. Chin J Aeronaut

    27. Song Q, Zeng Y, Xu J, Jin S (2021) A survey of prototype

    and experiment for UAV communications. Sci China Inf Sci

    64(4):1–21

    28. Srivastava S, Narayan S, Mittal S (2021) A survey of deep learning

    techniques for vehicle detection from UAV images. J Syst Arch

    117:102152

    29. Haider SK, Nauman A, Jamshed MA, Jiang A, Batool S, Kim SW

    (2022) Internet of drones: routing algorithms. Tech Chall Math

    10(9):1488

    30. Poudel S, Moh S (2022) Task assignment algorithms for

    unmanned aerial vehicle networks: a comprehensive survey. Veh

    Commun 100469

    31. Tahir A, Böling J, Haghbayan MH, Toivonen HT, Plosila J (2019)

    Swarms of unmanned aerial vehicles—a survey. J Ind Inf Integr

    16:100106

    32. Mairaj A, Baba AI, Javaid AY (2019) Application speciﬁc drone

    simulators: recent advances and challenges. Simul Model Pract

    Theory 94:100–117

    33. kalpa Gunarathna J, Munasinghe R (2018) Development of a

    quad-rotor ﬁxed-wing hybrid unmanned aerial vehicle. In: 2018

    Moratuwa engineering research conference (MERCon). IEEE, pp

    72–77

    34. Sheng WEN, Jie HAN, Yubin LAN, Xuanchun YIN, Yuhua LU

    (2018) Inﬂuence of wing tip vortex on drift of single rotor plant

    protection unmanned aerial vehicle. Nongye Jixie Xuebao/Trans

    Chin Soc Agric Mach 49(8)

    35. Lee D, Zhou J, Lin WT (2015) Autonomous battery swap-

    ping system for quadcopter. In: 2015 international conference on

    unmanned aircraft systems (ICUAS). IEEE, pp 118–124

    36. de Souza BJO, Endler M (2015) Coordinating movement within

    swarms of UAVs through mobile networks. In: 2015 IEEE inter-

    national conference on pervasive computing and communication

    workshops (PerCom Workshops). IEEE, pp 154–159

    37. Pestana J, Sanchez-Lopez JL, de la Puente P, Carrio A, Campoy

    P (2014) A vision-based quadrotor swarm for the participation

    in the 2013 international micro air vehicle competition. In: 2014

    123

    134

    Intelligent Service Robotics (2023) 16:109–137

    international conference on unmanned aircraft systems (ICUAS).

    IEEE, pp 617–622

    38. Fotouhi A, Ding M, Hassan M (2017) Understanding autonomous

    drone maneuverability for internet of things applications. In: 2017

    IEEE18thinternationalsymposiumonaworldofwireless,mobile

    and multimedia networks (WoWMoM). IEEE, pp 1–6

    39. Al-Hourani A, Gomez K (2017) Modeling cellular-to-UAV path-

    loss for suburban environments. IEEE Wirel Commun Lett

    7(1):82–85

    40. Saggiani G, Persiani F, Ceruti A, Tortora P, Troiani E, Giuletti F,

    et al. (2007) A UAV system for observing volcanoes and natural

    hazards. In: AGU fall meeting abstracts, vol 2007, pp GC11B-05

    41. Berman ES, Fladeland M, Liem J, Kolyer R, Gupta M (2012)

    Greenhouse gas analyzer for measurements of carbon dioxide,

    methane, and water vapor aboard an unmanned aerial vehicle.

    Sens Actuators, B Chem 169:128–135

    42. Khan A, Schaefer D, Tao L, Miller DJ, Sun K, Zondlo MA et al

    (2012) Low power greenhouse gas sensors for unmanned aerial

    vehicles. Remote Sens 4(5):1355–1368

    43. Watai T, Machida T, Ishizaki N, Inoue G (2006) A lightweight

    observation system for atmospheric carbon dioxide concentra-

    tion using a small unmanned aerial vehicle. J Atmos Ocean Tech

    23(5):700–710

    44. McGonigle AJS, Aiuppa A, Giudice G, Tamburello G, Hodson

    AJ, Gurrieri S (2008) Unmanned aerial vehicle measurements of

    volcanic carbon dioxide ﬂuxes. Geophys Res Lett 35(6)

    45. Hill AC, Laugier EJ, Casana J (2020) Archaeological remote

    sensing using multi-temporal, drone-acquired thermal and Near

    Infrared (NIR) Imagery: a case study at the Enﬁeld Shaker Village.

    New Hamps Remote Sens 12(4):690

    46. Miyoshi GT, Arruda MDS, Osco LP, Marcato Junior J, Gonçalves

    DN,ImaiNNetal(2020)Anoveldeeplearningmethodtoidentify

    single tree species in UAV-based hyperspectral images. Remote

    Sens 12(8):1294

    47. Lin YC, Cheng YT, Zhou T, Ravi R, Hasheminasab SM, Flatt

    JE et al (2019) Evaluation of UAV LiDAR for mapping coastal

    environments. Remote Sens 11(24):2893

    48. Liu Z, Zhang Y, Yu X, Yuan C (2016) Unmanned surface vehicles:

    an overview of developments and challenges. Annu Rev Control

    41:71–93

    49. Ding M, Wang P, López-Pérez D, Mao G, Lin Z (2015) Perfor-

    mance impact of LoS and NLoS transmissions in dense cellular

    networks. IEEE Trans Wirel Commun 15(3):2365–2380

    50. Hempe D (2006) Unmanned aircraft systems in the United States.

    In: US/Europe international safety conference

    51. EASA UAS Workshop [Online]. https://www.easa.europa.eu/

    sites/default/ﬁles/dfu/ws_prod-g-doc-Events-2008-February-1-

    Overview-of-the-UAV-Industry-(UVS).pdf

    52. ArcturusUAV.

    Jump

    20

    [Online].

    https://arcturus-uav.com/

    product/jump-20

    53. AlphaUnmmanedSystems. Alpha 800 UAV Helicopter [Online].

    https://alphaunmannedsystems.com/alpha-800-uav/

    54. DJI. DJI Agras MG-1P Series [Online]. https://www.dji.com/mg-

    1p/infor#specs

    55. AgEagle Aeriel Systems Inc. AgEagle RX-60 Taking Agriculture

    Intelligence to the Next Level [Online]. https://docs.wixstatic.

    com/ugd/89e3c5_e3de865b41b644fbb68adea13706723c.pdf?

    index=true

    56. Technical Speciﬁcation Group Radio Access Network (2017)

    Study on Enhanced LTE Support for Aerial Vehicles (Release

    15), 3GPP Standard TS 36.777

    57. Use cases and spectrum considerations for UAS (unmanned air-

    craft systems) (2018). ETSI, Sophia Antipolis, France, Rep. 103

    373

    58. Functional architecture for unmanned aerial vehicles and

    unmanned aerial vehicle controllers using IMT-2020 networks

    (2017). ITU-T, Geneva

    59. Lieb J, Volkert A (2020) Unmanned aircraft systems trafﬁc man-

    agement: a comparsion on the FAA UTM and the European

    CORUS ConOps based on U-space. In: 2020 AIAA/IEEE 39th

    digital avionics systems conference (DASC). IEEE, pp 1–6

    60. Dronehub. Autonomous drones-in-a-Box. https://dronehub.ai

    61. HIVE. Autonomous Drone Port. https://hive.aero

    62. Skycharge. SKYPORT DP5 drone box hangar. https://www.

    skycharge.de/drone-box-hangar

    63. Percepto. Percepto Base. https://percepto.co/air-mobile/

    64. Security, N. https://www.nightingalesecurity.com/specs-faqs/

    65. Campi T, Cruciani S, Feliziani M (2018) Wireless power transfer

    technology applied to an autonomous electric UAV with a small

    secondary coil. Energies 11(2):352

    66. Wireless power transmission: patent landscape analysis [Online].

    https://www.wipo.int/edocs/plrdocs/en/lexinnova_plr_wireless_

    power.pdf

    67. AirMed&Rescue [Online]. https://www.airmedandrescue.com

    68. Drone Market Report (2024) Drone Ind. Insights UG, Germany

    69. Xu J, Zeng Y, Zhang R (2018) UAV-enabled wireless power

    transfer: trajectory design and energy optimization. IEEE Trans

    Wireless Commun 17(8):5092–5106

    70. Hu Y, Yuan X, Jie Xu, Schmeink A (2019) Optimal 1D trajectory

    design for UAV-enabled multiuser wireless power transfer. IEEE

    Trans Commun 67(8):5674–5688

    71. Song C, Kim H, Kim Y, Kim D, Jeong S, Cho Y et al (2018) EMI

    reduction methods in wireless power transfer system for drone

    electrical charger using tightly coupled three-phase resonant mag-

    netic ﬁeld. IEEE Trans Ind Electron 65(9):6839–6849

    72. Jawad AM, Jawad HM, Nordin R, Gharghan SK, Abdullah NF,

    Abu-Alshaeer MJ (2019) Wireless power transfer with magnetic

    resonator coupling and sleep/active strategy for a drone charging

    station in smart agriculture. IEEE Access 7:139839–139851

    73. Li J, Yin F, Wang L, Cui B, Yang D (2019) Electromagnetic

    induction position sensor applied to anti-misalignment wireless

    charging for UAVs. IEEE Sens J 20(1):515–524

    74. Liu CH, Piao C, Tang J (2020) Energy-efﬁcient UAV crowd-

    sensing with multiple charging stations by deep learning. In:

    IEEE INFOCOM 2020-IEEE conference on computer commu-

    nications. IEEE, pp 199–208

    75. Hassija V, Chamola V, Krishna DNG, Guizani M (2020) A

    distributed framework for energy trading between UAVs and

    charging stations for critical applications. IEEE Trans Veh Tech-

    nol 69(5):5391–5402

    76. Qin C, Li P, Liu J, Liu J (2021) Blockchain-enabled charging

    scheduling for unmanned vehicles in smart cities. J Internet Tech-

    nol 22(2):327–337

    77. Zhu K, Yang J, Zhang Y, Nie J, Lim WYB, Zhang H, Xiong Z

    (2022) Aerial refueling: scheduling wireless energy charging for

    UAV enabled data collection. IEEE Trans Green Commun Netw

    78. Oubbati OS, Lakas A, Guizani M (2022) Multi-agent deep rein-

    forcement learning for wireless-powered UAV networks. IEEE

    Internet Things J

    79. Fazelpour F, Vafaeipour M, Rahbari O, Shirmohammadi R (2013)

    Considerable parameters of using PV cells for solar-powered air-

    crafts. Renew Sustain Energy Rev 22:81–91

    80. Wo´zniak W, Jessa M (2021) Selection of solar powered unmanned

    aerial vehicles for a long range data acquisition chain. Sensors

    21(8):2772

    81. ThipyopasC,SripawadkulV,WarinN(2019)Designanddevelop-

    ment of a small solar-powered UAV for environmental monitoring

    application. In: 2019 IEEE Eurasia conference on IOT, commu-

    nication and engineering (ECICE). IEEE, pp 316–319

    123

    Intelligent Service Robotics (2023) 16:109–137

    135

    82. Wu J, Wang H, Huang Y, Su Z, Zhang M (2018) Energy man-

    agement strategy for solar-powered UAV long-endurance target

    tracking. IEEE Trans Aerosp Electron Syst 55(4):1878–1891

    83. Gao XZ, Hou ZX, Guo Z, Chen XQ (2015) Reviews of methods to

    extract and store energy for solar-powered aircraft. Renew Sustain

    Energy Rev 44:96–108

    84. Elkunchwar N, Chandrasekaran S, Iyer V, Fuller SB (2021)

    Toward battery-free ﬂight: duty cycled recharging of small drones.

    In: 2021 IEEE/RSJ international conference on intelligent robots

    and systems (IROS). IEEE, pp 5234–5241

    85. Dhingra D, Chukewad YM, Fuller SB (2020) A device for rapid,

    automated trimming of insect-sized ﬂying robots. IEEE Robot

    Autom Lett 5(2):1373–1380

    86. Keennon M, Klingebiel K, Won H (2012) Development of the

    nano hummingbird: a tailless ﬂapping wing micro air vehicle. In:

    50th AIAA aerospace sciences meeting including the new hori-

    zons forum and aerospace exposition, p 588

    87. Förster J (2015) System identiﬁcation of the Crazyﬂie 2.0 nano

    quadrocopter. Bachelor’s thesis, ETH Zurich

    88. SAS PD (2018) Parrot anaﬁ specsheet

    89. Technologies A (2015) Ascending technologies hummingbird

    90. Technologies A (2015) Payload options & accessories

    91. Systems ACUA (2017) Aerialtronics altura zenith specsheet

    92. Solar Tribune (online). https://solartribune.com/solar-powered-

    drones/

    93. Achtelik, M. C., Stumpf, J., Gurdan, D., & Doth, K. M. (2011,

    September). Design of a ﬂexible high performance quadcopter

    platform breaking the MAV endurance record with laser power

    beaming. In: 2011 IEEE/RSJ international conference on intelli-

    gent robots and systems. IEEE, pp 5166–5172

    94. Ouyang J, Che Y, Xu J, Wu K (2018) Throughput maximiza-

    tion for laser-powered UAV wireless communication systems. In:

    2018 IEEE international conference on communications work-

    shops (ICC workshops). IEEE, pp 1–6

    95. Chen Q, Zhang D, Zhu D, Shi Q, Gu J, Ai Y (2015) Design and

    experiment for realization of laser wireless power transmission

    for small unmanned aerial vehicles. In: AOPC 2015: advances in

    laser technology and applications, vol 9671. International Society

    for Optics and Photonics, p 96710N

    96. Lee S, Lim N, Choi W, Lee Y, Baek J, Park J (2020) Study on

    battery charging converter for MPPT control of laser wireless

    power transmission system. Electronics 9(10):1745

    97. Kim Y, Shin HB, Lee WH, Jung SH, Kim CZ, Kim H et al (2019)

    1080 nm InGaAs laser power converters grown by MOCVD using

    InAlGaAs metamorphic buffer layers. Sol Energy Mater Sol Cells

    200:109984

    98. Zhang Q, Fang W, Liu Q, Wu J, Xia P, Yang L (2018) Distributed

    laser charging: a wireless power transfer approach. IEEE Internet

    Things J 5(5):3853–3864

    99. Jaafar

    W,

    Yanikomeroglu

    H

    (2020)

    Dynamics

    of

    laser-

    charged UAVs: a battery perspective. IEEE Internet Things J

    8(13):10573–10582

    100. Zhao MM, Shi Q, Zhao MJ (2020) Efﬁciency maximization for

    UAV-enabled mobile relaying systems with laser charging. IEEE

    Trans Wirel Commun 19(5):3257–3272

    101. Shakhatreh H, Sawalmeh AH, Al-Fuqaha A, Dou Z, Almaita E,

    Khalil I et al (2019) Unmanned aerial vehicles (UAVs): a survey

    on civil applications and key research challenges. IEEE Access

    7:48572–48634

    102. Reinecke M, Prinsloo T (2017) The inﬂuence of drone monitoring

    on crop health and harvest size. In: 2017 1st international con-

    ference on next generation computing applications (NextComp).

    IEEE, pp 5–10

    103. Maes WH, Steppe K (2019) Perspectives for remote sensing with

    unmanned aerial vehicles in precision agriculture. Trends Plant

    Sci 24(2):152–164

    104. Menouar H, Guvenc I, Akkaya K, Uluagac AS, Kadri A, Tuncer

    A (2017) UAV-enabled intelligent transportation systems for the

    smart city: applications and challenges. IEEE Commun Mag

    55(3):22–28

    105. Elloumi M, Dhaou R, Escrig B, Idoudi H, Saidane LA (2018)

    Monitoring road trafﬁc with a UAV-based system. In: 2018 IEEE

    wireless communications and networking conference (WCNC).

    IEEE, pp 1–6

    106. Tiansawat P, Elliott S (2020) Unmanned aerial vehicles for auto-

    mated forest restoration

    107. De Almeida DRA, Broadbent EN, Ferreira MP, Meli P, Zambrano

    AMA, Gorgens EB et al (2021) Monitoring restored tropical forest

    diversity and structure through UAV-borne hyperspectral and lidar

    fusion. Remote Sens Environ 264:112582

    108. Moura MM, de Oliveira LES, Sanquetta CR, Bastos A, Mohan

    M, Corte APD (2021) Towards Amazon forest restoration: auto-

    matic detection of species from UAV imagery. Remote Sens

    13(13):2627

    109. Zhang Y, Yuan X, Li W, Chen S (2017) Automatic power line

    inspection using UAV images. Remote Sens 9(8):824

    110. Foudeh HA, Luk PCK, Whidborne JF (2021) An advanced

    unmanned aerial vehicle (UAV) approach via learning-based con-

    trol for overhead power line monitoring: a comprehensive review.

    IEEE Access

    111. Barbedo JGA (2019) A review on the use of unmanned aerial

    vehicles and imaging sensors for monitoring and assessing plant

    stresses. Drones 3(2):40

    112. Sharma M, Gupta A, Gupta SK, Alsamhi SH, Shvetsov AV (2021)

    Survey on unmanned aerial vehicle for Mars exploration: deploy-

    ment use case. Drones 6(1):4

    113. Ubina NA, Cheng SC (2022) A review of unmanned system tech-

    nologies with its application to aquaculture farm monitoring and

    management. Drones 6(1):12

    114. Pulsiri N, Vatananan-Thesenvitz R (2021) Drones in emergency

    medical services: a systematic literature review with bibliometric

    analysis. Int J Innov Technol Manag 18(04):2097001

    115. Mohsan SAH, Khan MA, Alsharif MH, Elhaty IA, Jahid A (2022)

    Role of drone technology helping in alleviating the COVID-19

    pandemic. Micromachines 13(10):1593

    116. Alqurashi FS, Trichili A, Saeed N, Ooi BS, Alouini MS (2022)

    Maritime communications: a survey on enabling technologies,

    opportunities, and challenges. arXiv preprint arXiv:2204.12824

    117. Kourani A, Daher N (2021) Marine locomotion: a tethered UAV-

    Buoy system with surge velocity control. Robot Auton Syst

    145:103858

    118. Swaminathan N, Reddy SRP, Rajashekara K, Haran KS (2022)

    Flying cars and eVTOLs-technology advancements, powertrain

    architectures and design. IEEE Trans Transp Electr

    119. Kasliwal A, Furbush NJ, Gawron JH, McBride JR, Wallington

    TJ, De Kleine RD et al (2019) Role of ﬂying cars in sustainable

    mobility. Nat Commun 10(1):1–9

    120. Grifﬁths S, Saunders J, Curtis A, Barber B, McLain T, Beard

    R (2007) Obstacle and terrain avoidance for miniature aerial

    vehicles. In: Advances in unmanned aerial vehicles. Springer,

    Dordrecht, pp 213–244

    121. Winter T, Thubert P, Brandt A, Hui JW, Kelsey R, Levis P et al

    (2012) RPL: IPv6 routing protocol for low-power and lossy net-

    works. RFC 6550:1–157

    122. KurikiY,NamerikawaT(2014)Consensus-basedcooperativefor-

    mation control with collision avoidance for a multi-UAV system.

    In: 2014 American control conference. IEEE, pp 2077–2082

    123. Vattapparamban E, Güvenç I, Yurekli AI, Akkaya K, Ulua˘gaç

    S (2016) Drones for smart cities: issues in cybersecurity, privacy,

    and public safety. In: 2016 international wireless communications

    and mobile computing conference (IWCMC). IEEE, pp 216–221

    123

    136

    Intelligent Service Robotics (2023) 16:109–137

    124. He D, Chan S, Guizani M (2016) Communication security of

    unmanned aerial vehicles. IEEE Wirel Commun 24(4):134–139

    125. Birnbaum Z, Dolgikh A, Skormin V, O’Brien E, Muller D, Strac-

    quodaine C (2015) Unmanned aerial vehicle security using behav-

    ioral proﬁling. In: 2015 international conference on unmanned

    aircraft systems (ICUAS). IEEE, pp 1310–1319

    126. Mansﬁeld K, Eveleigh T, Holzer TH, Sarkani S (2013) Unmanned

    aerial vehicle smart device ground control station cyber security

    threat model In: 2013 IEEE international conference on technolo-

    gies for homeland security (HST). IEEE, pp 722–728

    127. Bithas PS, Michailidis ET, Nomikos N, Vouyioukas D, Kanatas

    AG (2019) A survey on machine-learning techniques for UAV-

    based communications. Sensors 19(23):5170

    128. Yue X, Liu Y, Wang J, Song H, Cao H (2018) Software deﬁned

    radio and wireless acoustic networking for amateur drone surveil-

    lance. IEEE Commun Mag 56(4):90–97

    129. Liao Q, Fischer T, Gao J, Hafeez F, Oechsner C, Knode J (2018)

    A secure end-to-end cloud computing solution for emergency

    management with UAVs. In: 2018 IEEE global communications

    conference (GLOBECOM). IEEE, pp 1–7

    130. Shoufan A, Al-Angari HM, Sheikh MFA, Damiani E (2018)

    Drone pilot identiﬁcation by classifying radio-control signals.

    IEEE Trans Inf Forens Secur 13(10):2439–2447

    131. Zohdi T (2020) The Game of Drones: rapid agent-based machine-

    learning models for multi-UAV path planning. Comput Mech

    65(1):217–228

    132. Min M, Xiao L, Xu D, Huang L, Peng M (2018) Learning-based

    defense against malicious unmanned aerial vehicles. In: 2018

    IEEE 87th vehicular technology conference (VTC Spring). IEEE,

    pp 1–5

    133. Hoang TM, Nguyen NM, Duong TQ (2019) Detection of eaves-

    dropping attack in UAV-aided wireless systems: unsupervised

    learning with one-class SVM and k-means clustering. IEEE Wirel

    Commun Lett 9(2):139–142

    134. Manesh MR, Kenney J, Hu WC, Devabhaktuni VK, Kaabouch

    N (2019) Detection of GPS spooﬁng attacks on unmanned aerial

    systems. In: 2019 16th IEEE annual consumer communications

    and networking conference (CCNC). IEEE, pp 1–6

    135. Xiao L, Xie C, Min M, Zhuang W (2017) User-centric view of

    unmanned aerial vehicle transmission against smart attacks. IEEE

    Trans Veh Technol 67(4):3420–3430

    136. XiaoL,LuX,XuD,TangY,WangL,ZhuangW(2018)UAVrelay

    in VANETs against smart jamming with reinforcement learning.

    IEEE Trans Veh Technol 67(5):4087–4097

    137. Li C, Xu Y, Xia J, Zhao J (2018) Protecting secure communication

    under UAV smart attack with imperfect channel estimation. IEEE

    Access 6:76395–76401

    138. Lv Z, Li Y, Feng H, Lv H (2021) Deep learning for security

    in digital twins of cooperative intelligent transportation sys-

    tems. IEEE Trans Intell Transp Syst. https://doi.org/10.1109/

    TITS.2021.3113779

    139. Liu F, Zhang G, Lu J (2020) Multi-source heterogeneous unsuper-

    vised domain adaptation via fuzzy-relation neural networks. IEEE

    Trans Fuzzy Syst. https://doi.org/10.1109/TFUZZ.2020.3018191

    140. Zhang L, Zheng H, Cai G, Zhang Z, Wang X, et al. (2022) Power-

    frequency oscillation suppression algorithm for AC microgrid

    withmultiplevirtualsynchronousgeneratorsbasedonfuzzyinfer-

    ence system. IET Renew Power Gener. https://doi.org/10.1049/

    rpg2.12461

    141. Zhang L, Gao T, Cai G, Hai KL (2022) Research on electric vehi-

    cle charging safety warning model based on back propagation

    neural network optimized by improved gray wolf algorithm. J

    Energy Storage. https://doi.org/10.1016/j.est.2022.104092

    142. Wu X, Zheng W, Chen X, Zhao Y, Yu T et al (2021) Improving

    high-impact bug report prediction with combination of interac-

    tive machine learning and active learning. Inf Softw Technol

    133:106530. https://doi.org/10.1016/j.infsof.2021.106530

    143. Chen P, Pei J, Lu W, Li M (2022) A deep reinforcement learning

    based method for real-time path planning and dynamic obstacle

    avoidance. Neurocomputing (Amsterdam) 497:64–75. https://doi.

    org/10.1016/j.neucom.2022.05.006

    144. Carrio A, Sampedro C, Rodriguez-Ramos A, Campoy P (2017) A

    review of deep learning methods and applications for unmanned

    aerial vehicles. J Sensors 2017

    145. Vergouw B, Nagel H, Bondt G, Custers B (2016) Drone tech-

    nology: types, payloads, applications, frequency spectrum issues

    and future developments. In: The future of drone use. TMC Asser

    Press, The Hague, pp 21–45

    146. Bejiga MB, Zeggada A, Noufﬁdj A, Melgani F (2017) A convo-

    lutional neural network approach for assisting avalanche search

    and rescue operations with UAV imagery. Remote Sens 9(2):100

    147. Cao B, Gu Y, Lv Z, Yang S, Zhao, J., et al. (2021) RFID reader

    anticollision based on distributed parallel particle swarm opti-

    mization. IEEE Internet Things J 8(5):3099–3107. https://doi.org/

    10.1109/JIOT.2020.3033473

    148. Hu Y, Qing JX, Liu ZH, Conrad ZJ, Cao JN et al (2021) Hov-

    ering efﬁciency optimization of the ducted propeller with weight

    penalty taken into account. Aerosp Sci Technol. https://doi.org/

    10.1016/j.ast.2021.106937

    149. YangG,LiuJ,ZhaoC,LiZ,HuangY,YuHetal(2017)Unmanned

    aerial vehicle remote sensing for ﬁeld-based crop phenotyping:

    current status and perspectives. Front Plant Sci 8:1111

    150. Yan J, Jiao H, Pu W, Shi C, Dai, J., et al. (2022) Radar sen-

    sor network resource allocation for fused target tracking: a brief

    review. Inf Fus 86–87:104–115. https://doi.org/10.1016/j.inffus.

    2022.06.009

    151. Cao B, Fan S, Zhao J, Tian S, Zheng Z, Yan Y, et al. (2021) Large-

    scale many-objective deployment optimization of edge servers.

    IEEE Trans Intell Transp Syst 22(6):3841–3849. https://doi.org/

    10.1109/TITS.2021.3059455

    152. Cao B, Sun Z, Zhang J, Gu Y (2021) Resource allocation in

    5G IoV architecture based on SDN and Fog-cloud computing.

    IEEE Trans Intell Transp Syst 22(6):3832–3840. https://doi.org/

    10.1109/TITS.2020.3048844

    153. Mogili UR, Deepak BBVL (2018) Review on application of

    drone systems in precision agriculture. Procedia Comput Sci

    133:502–509

    154. Wan S, Lu J, Fan P, Letaief KB (2017) To smart city: public safety

    network design for emergency. IEEE Access 6:1451–1460

    155. Cao B, Zhang W, Wang X, Zhao J, Gu Y et al (2021) A memetic

    algorithm based on two_Arch2 for multi-depot heterogeneous-

    vehicle capacitated arc routing problem. Swarm Evolut Comput

    63:100864. https://doi.org/10.1016/j.swevo.2021.100864

    156. Li D, Ge SS, Lee TH (2021) Simultaneous-arrival-to-origin con-

    vergence: sliding-mode control through the norm-normalized sign

    function. IEEE Trans Autom Control. https://doi.org/10.1109/

    TAC.2021.3069816

    157. Li D, Yu H, Tee KP, Wu Y, Ge SS et al (2021) On time-

    synchronized stability and control. IEEE Trans Syst Man Cybern-

    Syst. https://doi.org/10.1109/TSMC.2021.3050183

    158. Wang J, Tian J, Zhang X, Yang B, Liu S, Yin L, et al. (2022)

    Control of time delay force feedback teleoperation system with

    ﬁnite time convergence. Front Neurorobot. https://doi.org/10.

    3389/fnbot.2022.877069

    159. Gong X, Wang L, Mou Y, Wang H, Wei X, Zheng W, et al.

    (2022) Improved four-channel PBTDPA control strategy using

    force feedback bilateral teleoperation system. Int J Control

    20(3):1002–1017. https://doi.org/10.1007/s12555-021-0096-y

    123

    Intelligent Service Robotics (2023) 16:109–137

    137

    160. Lu S, Ban Y, Zhang X, Yang B, Liu S, Yin L, Zheng W (2022)

    Adaptive control of time delay teleoperation system with uncer-

    tain dynamics. Front Neurorobot 16:928863. https://doi.org/10.

    3389/fnbot.2022.928863

    161. Mohsan SAH, Khan MA, Alsharif MH, Uthansakul P, Solyman

    AA (2022) Intelligent reﬂecting surfaces assisted UAV commu-

    nications for massive networks: current trends, challenges, and

    research directions. Sensors 22(14):5278

    162. Mohsan SAH, Khan MA, Noor F, Ullah I, Alsharif MH (2022)

    Towards the unmanned aerial vehicles (UAVs): a comprehensive

    review. Drones 6(6):147

    163. Mohsan SAH, Othman NQH, Khan MA, Amjad H, ˙Zywiołek J

    (2022) A comprehensive review of micro UAV charging tech-

    niques. Micromachines 13(6):977

    164. Khan MA, Kumar N, Mohsan SAH, Khan WU, Nasralla MM,

    Alsharif MH, et al. (2022) Swarm of UAVs for network manage-

    ment in 6G: a technical review. IEEE Trans Netw Serv Manag

    165. Regulation&Policies[Online].https://www.faa.gov/regulations_

    policies

    Publisher’s Note Springer Nature remains neutral with regard to juris-

    dictional claims in published maps and institutional afﬁliations.

    Springer Nature or its licensor (e.g. a society or other partner) holds

    exclusive rights to this article under a publishing agreement with the

    author(s) or other rightsholder(s); author self-archiving of the accepted

    manuscript version of this article is solely governed by the terms of such

    publishing agreement and applicable law.

    123

    '
  inline_citation: '>'
  journal: Intelligent service robotics (Print)
  limitations: '>'
  pdf_link: https://link.springer.com/content/pdf/10.1007/s11370-022-00452-4.pdf
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'Unmanned aerial vehicles (UAVs): practical aspects, applications, open challenges,
    security issues, and future trends'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.34133/icomputing.0006
  analysis: '>'
  authors:
  - Shiqiang Zhu
  - Tong Yu
  - Tao Xu
  - Hongyang Chen
  - Schahram Dustdar
  - Sylvain Gigan
  - Deniz Gündüz
  - Ekram Hossain
  - Yaochu Jin
  - Feng Huei Lin
  - Bo Liu
  - Zhiguo Wan
  - Ji Zhang
  - Zhifeng Zhao
  - Wentao Zhu
  - Zuoning Chen
  - T.S. Durrani
  - Huaimin Wang
  - Jiangxing Wu
  - Tong‐Yi Zhang
  - Yunhe Pan
  citation_count: 25
  full_citation: '>'
  full_text: '>

    Web Store Add shortcut Name URL Customize Chrome'
  inline_citation: '>'
  journal: Intelligent computing
  limitations: '>'
  pdf_link: https://spj.science.org/doi/pdf/10.34133/icomputing.0006?download=true
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'Intelligent Computing: The Latest Advances, Challenges, and Future'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/ojcs.2021.3085846
  analysis: '>'
  authors:
  - Somali Chaterji
  - Nathan D. DeLay
  - John Evans
  - Nathan S. Mosier
  - Bernard A. Engel
  - Dennis R. Buckmaster
  - Michael R. Ladisch
  - Ranveer Chandra
  citation_count: 13
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account
    Personal Sign In Personal Sign In * Required *Email Address *Password Forgot Password?
    Sign In Don''t have a Personal Account? Create an IEEE Account now. Create Account
    Learn more about personalization features. IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE open journal of the Computer Society
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/8782664/9349230/09444818.pdf
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: 'Lattice: A Vision for Machine Learning, Data Engineering, and Policy Considerations
    for Digital Agriculture at Scale'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/s23083876
  analysis: '>'
  authors:
  - M D. Torres Pons
  - Estuardo Valenzuela
  - Brandon Rodríguez
  - Juan Arturo Nolazco-Flores
  - Carolina Del-Valle-Soto
  citation_count: 19
  full_citation: '>'
  full_text: ">\nCitation: Pons, M.; Valenzuela, E.;\nRodríguez, B.; Nolazco-Flores,\
    \ J.A.;\nDel-Valle-Soto, C. Utilization of 5G\nTechnologies in IoT Applications:\n\
    Current Limitations by Interference\nand Network Optimization\nDifﬁculties—A Review.\
    \ Sensors 2023,\n23, 3876. https://doi.org/10.3390/\ns23083876\nAcademic Editor:\
    \ Tommaso\nPecorella\nReceived: 15 March 2023\nRevised: 29 March 2023\nAccepted:\
    \ 3 April 2023\nPublished: 11 April 2023\nCopyright:\n© 2023 by the authors.\n\
    Licensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed\n\
    under\nthe\nterms\nand\nconditions of the Creative Commons\nAttribution (CC BY)\
    \ license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nsensors\nArticle\n\
    Utilization of 5G Technologies in IoT Applications:\nCurrent Limitations by Interference\
    \ and Network\nOptimization Difﬁculties—A Review\nMario Pons 1, Estuardo Valenzuela\
    \ 1, Brandon Rodríguez 1, Juan Arturo Nolazco-Flores 2\nand Carolina Del-Valle-Soto\
    \ 3,*\n1\nFacultad de Ingeniería, Universidad del Istmo, Km 19.2 Carretera a Fraijanes,\
    \ Fraijanes 01062, Guatemala;\npons171118@unis.edu.gt (M.P.); valenzuela181135@unis.edu.gt\
    \ (E.V.); rodriguez181048@unis.edu.gt (B.R.)\n2\nSchool of Engineering and Science,\
    \ Tecnológico de Monterrey, Av. Eugenio Garza Sada 2501,\nMonterrey 64849, NL,\
    \ Mexico; jnolazco@tec.mx\n3\nFacultad de Ingeniería, Universidad Panamericana,\
    \ Álvaro del Portillo 49, Zapopan 45010, JA, Mexico\n*\nCorrespondence: cvalle@up.edu.mx;\
    \ Tel.: +52-33-1368-2200\nAbstract: 5G (ﬁfth-generation technology) technologies\
    \ are becoming more mainstream thanks to\ngreat efforts from telecommunication\
    \ companies, research facilities, and governments. This tech-\nnology is often\
    \ associated with the Internet of Things to improve the quality of life for citizens\
    \ by\nautomating and gathering data recollection processes. This paper presents\
    \ the 5G and IoT technolo-\ngies, explaining common architectures, typical IoT\
    \ implementations, and recurring problems. This\nwork also presents a detailed\
    \ and explained overview of interference in general wireless applica-\ntions,\
    \ interference unique to 5G and IoT, and possible optimization techniques to overcome\
    \ these\nchallenges. This manuscript highlights the importance of addressing interference\
    \ and optimizing\nnetwork performance in 5G networks to ensure reliable and efﬁcient\
    \ connectivity for IoT devices,\nwhich is essential for adequately functioning\
    \ business processes. This insight can be helpful for\nbusinesses that rely on\
    \ these technologies to improve their productivity, reduce downtime, and\nenhance\
    \ customer satisfaction. We also highlight the potential of the convergence of\
    \ networks and\nservices in increasing the availability and speed of access to\
    \ the internet, enabling a range of new and\ninnovative applications and services.\n\
    Keywords: 5G technologies; interference; wireless network optimization; internet\
    \ of things\n1. Introduction\nThe COVID-19 pandemic shifted the general public’s\
    \ attention to digital solutions\nand brought immense demand to the telecommunications\
    \ market. The convergence of 5G\ntechnology and the Internet of Things (IoT) [1]\
    \ is the next natural step for two advanced\ntechnologies developed to make the\
    \ lives of their users more accessible, more comfortable,\nand more productive\
    \ [2]. One of the most standard technologies to be brought into the\nmainstream\
    \ area is 5G, which will allow for new business opportunities by being comple-\n\
    mented with Industry 4.0, IoT devices, and Smart Cities and improve overall connectivity\n\
    around the globe [3]. The Internet of Things is an ecosystem of increasing complexity:\
    \ a\nuniverse of connected things capable of capturing critical data and carrying\
    \ out advanced\nanalysis using cloud-based functionalities to extract valuable\
    \ information. This technology\nposes a great opportunity for a multitude of actors\
    \ in all sectors of activity [4]. Many\ncompanies are organizing to focus on IoT\
    \ and connectivity when developing their products\nand services of the future.\n\
    Deployment costs, range, interference, and capabilities of Internet of Things\
    \ devices\nare all factors in identifying the right primary or complementary connectivity\
    \ option for\nan IoT deployment. Wi-Fi 6 or Zigbee is adequate for some elements\
    \ of smart building\nSensors 2023, 23, 3876. https://doi.org/10.3390/s23083876\n\
    https://www.mdpi.com/journal/sensors\nSensors 2023, 23, 3876\n2 of 41\ncontrols\
    \ but useless for highly mobile wide-area use [5]. Additionally, endpoints such\
    \ as\nBluetooth, Zigbee, RFID, or Wi-Fi can be signiﬁcantly more cost effective\
    \ in scenarios where\n5G may be available but has not yet reached a signiﬁcant\
    \ market scale to do competitive\nendpoints or network services [6]. Technical\
    \ studies [7] show that 5G and other services can\ncoexist in speciﬁc frequency\
    \ bands. The technical conditions must be adequately adapted\nand not excessively\
    \ restrictive; otherwise, there is a risk of affecting the costs, coverage,\n\
    and quality of operation of 5G services.\nThere is great interest in the new applications\
    \ of mobile technology merging 5G and\nthe Internet of Things technologies. In\
    \ the design of new applications or technological\naccessories using 5G and the\
    \ Internet of Things, compliance with the permitted exposure\nlimits are contemplated.\
    \ International exposure guidelines have been developed due to\nextensive research\
    \ carried out over many decades. All the analyses carried out by indepen-\ndent\
    \ public health authorities, expert groups, and the World Health Organization\
    \ (WHO)\nagree that these guidelines guarantee protection for all people against\
    \ any health danger [8].\nAs with all technological generations, 5G dramatically\
    \ improves energy efﬁciency depart-\nment and speed rates. However, this technology\
    \ has recently been in the public eye for its\nimplementation challenges.\nIoT\
    \ technologies are now being widely used in the consumer-grade market, primarily\n\
    targeted toward home automation and security. This rise in consumer adoption has\
    \ led to\nproposals to incorporate IoT devices to bring these types of improvements\
    \ to a metropolitan\nscale [9]. These improvements are speculated to improve security\
    \ and automation tasks\nand tackle long-lasting difﬁculties such as trafﬁc control,\
    \ waste management, and so on.\nHowever, IoT does not depend solely on the electronics\
    \ being deployed and installed;\nthey rely on efﬁcient and resilient transmission\
    \ technology being used. The convergence\nof networks and services is an essential\
    \ aspect of the modern internet. The internet has\nevolved from a simple means\
    \ of communication to a complex and multifaceted ecosystem\nthat is integrated\
    \ into nearly every aspect of our daily lives. The advent of 5G technology\nhas\
    \ further pushed the convergence of networks and services, providing users with\
    \ faster\nand more reliable internet connections, enabling a range of new and\
    \ innovative applications\nand services [10].\nOne of the most signiﬁcant ways\
    \ that the convergence of networks and services\nimpacts internet services is\
    \ by increasing the availability and speed of access to the internet.\n5G technology\
    \ offers faster speeds and greater bandwidth, allowing users to access high-\n\
    quality video, audio, and other media content in real-time [11]. This means that\
    \ internet\nservice providers can offer a range of new services and applications\
    \ that were previously\nimpossible, such as virtual and augmented reality experiences\
    \ and immersive gaming.\nCellular connectivity will enable key IoT goals to be\
    \ achieved, in particular, reduced\ndevice complexity and cost and increased coverage\
    \ to support challenging and remote\napplications, deployment ﬂexibility, high\
    \ capacity, and long battery life. 3GPP wireless\ntechnologies offer compelling\
    \ technology advantages that will continue to increase the\ncapacity of Long Term\
    \ Evolution (LTE) infrastructure to address the vast IoT market in\nthe long term,\
    \ and 5G will add to the IoT landscape soon. In Releases 14, 15, and beyond\n\
    of the 3GPP (Third-Generation Partnership Project), the standards solve all commercial\n\
    bottlenecks to facilitate the vision of 5G and the huge IoT Market [12]. This\
    \ can lead\nto the explosion of billions of devices and sensors that show digital\
    \ representations of\nour real world powered by low-cost devices, long battery\
    \ life, ubiquitous coverage, and\ninnovative business applications. 5G promises\
    \ that it will be possible to achieve critical\nIoT applications, which require\
    \ real-time dynamic process control and automation in\nvarious ﬁelds, such as\
    \ vehicle-to-vehicle (V2V), vehicle-to-infrastructure (V2I), high-speed\nmotion,\
    \ and trafﬁc control. Critical parameters to enable the required performance are\n\
    sub-millisecond network latency and ultra-high reliability. Both are intrinsic\
    \ components of\nthe 3GPP work to deﬁne the new radio interface for 5G [13]. The\
    \ 5G network architecture\nis being designed to address both IoT scenarios.\n\
    Sensors 2023, 23, 3876\n3 of 41\nThe success of the IoT services on 5G networks\
    \ depends on the ability of these networks\nto manage interference effectively.\
    \ Interference can occur when different IoT devices operate\nin the same area,\
    \ and their signals overlap, causing lower throughput, higher latency, and\ndecreased\
    \ reliability [14]. This is a signiﬁcant challenge for 5G networks and IoT services,\
    \ as\nthey are designed to support a vast number of devices and applications,\
    \ each with unique\nconnectivity and latency requirements.\nFigure 1 shows the\
    \ comparison between 5G and IoT, which is a topic of interest\nin the technology\
    \ world. To implement 5G, there are speciﬁc requirements, including\ninfrastructure\
    \ and specialized hardware, while the evolution of wireless networks has led to\n\
    faster and more reliable data transfer rates. The evolution of IoT has enabled\
    \ the creation of\nlow-power, low-cost devices that can be connected to the internet.\
    \ Wireless communication\ntechnologies such as Bluetooth, Wi-Fi, ZigBee, and LoRa\
    \ are suitable for different types of\nIoT applications, and cloud-based solutions\
    \ are used to store and process vast amounts\nof data generated by IoT devices.\
    \ 5G applications include autonomous vehicles, remote\nsurgery, and virtual and\
    \ augmented reality, and these require high bandwidth, low latency,\nand reliable\
    \ connectivity. However, there are challenges associated with 5G networks,\nsuch\
    \ as interference and network optimization difﬁculties. The coexistence of 5G\
    \ networks\nand IoT applications is a concern, and optimization challenges in\
    \ 5G networks need to be\naddressed to enable efﬁcient and effective implementation.\n\
    Figure 1. Summary of conceptual schemes that addresses the present work.\nMotivation\n\
    The motivation of this work is to compile the impact of interference on the leading\
    \ 5G\ntechnologies that will inﬂuence the communications of IoT devices.\nIoT\
    \ services are used in various industries, including healthcare, manufacturing,\n\
    and transportation, where reliable and efﬁcient connectivity is essential for\
    \ the proper\nfunctioning of IoT devices and the smooth operation of business\
    \ processes. If interference\nand network performance issues are not addressed,\
    \ businesses may experience reduced\nproductivity, increased downtime, and decreased\
    \ customer satisfaction. Consequently,\naddressing the interference and optimization\
    \ of 5G networks in IoT services is essential to\nensure reliable and efﬁcient\
    \ connectivity for IoT devices and allow businesses to take full\nadvantage of\
    \ the beneﬁts of 5G networks and IoT services. For this reason, the motivation\n\
    of this work is to review the state of the art of the work to address the interference\
    \ and\noptimization of 5G technologies in IoT services.\nInterference and optimization\
    \ of 5G networks in IoT services is important to ensure\nreliable and efﬁcient\
    \ connectivity for IoT devices, which is essential for the proper func-\nSensors\
    \ 2023, 23, 3876\n4 of 41\ntioning of business processes. By implementing interference\
    \ management techniques and\noptimizing network performance, businesses can take\
    \ full advantage of the beneﬁts of 5G\nnetworks and IoT services.\nThe main contribution\
    \ of this review is to present the idea that the convergence\nof 5G networks and\
    \ IoT services represents a technological revolution that promises to\nchange\
    \ how we interact with the world around us. However, this union has its challenges,\n\
    and only by overcoming them can we unlock the full potential of these groundbreaking\n\
    technologies. By bridging the gap between 5G and IoT, we pave the way for a new\
    \ era\nof innovation: every device is connected, and every experience is seamless.\
    \ This work\ndescribes the main challenges between 5G networks and IoT services\
    \ and highlights the\nneed for seamless integration of these technologies to achieve\
    \ their full potential. This\npaper reinforces the idea that IoT technologies\
    \ power 5G services, and their compatibility\nis crucial for offering high-speed\
    \ and low-latency services to consumers. Furthermore, it\nunderscores that interference\
    \ is one of the biggest problems facing manufacturers, and they\nmust consider\
    \ it to offer compatible and reliable services. Ultimately, this article guides\n\
    the industry to ensure that 5G and IoT technologies work together seamlessly,\
    \ opening up\nendless possibilities for innovation and progress.\nFigure 2 describes\
    \ how the IoT and 5G technology can work together to enable a range\nof applications\
    \ in different ﬁelds. In the ﬁrst application, smart cities, IoT devices can\n\
    be used to collect real-time data on trafﬁc patterns, air quality, and energy\
    \ usage. These\ndata can be used to optimize city operations and improve quality\
    \ of life. 5G networks\ncan support these applications by providing the necessary\
    \ bandwidth and low latency.\nIn industrial automation, IoT devices can be used\
    \ to monitor and control manufacturing\nprocesses and equipment in real time.\
    \ This can help to improve efﬁciency and reduce\ndowntime. 5G networks can provide\
    \ the necessary bandwidth, reliability, and low latency\nto support these applications.\
    \ In healthcare, IoT devices can be used for remote patient\nmonitoring and real-time\
    \ communication between healthcare providers. This can help\nto improve patient\
    \ outcomes and reduce healthcare costs. 5G networks can provide\nthe necessary\
    \ bandwidth, low latency, and reliability to support these applications. In\n\
    transportation, IoT devices can provide real-time data on trafﬁc patterns and\
    \ vehicle\nperformance, which can be used to optimize trafﬁc ﬂow and improve safety.\
    \ 5G networks\ncan support these applications by providing the necessary bandwidth,\
    \ low latency, and\nreliability. In agriculture, IoT devices can be used to monitor\
    \ crops and livestock in real-time,\nwhich can help to optimize production and\
    \ reduce waste. 5G networks can support these\napplications by providing the necessary\
    \ bandwidth, reliability, and low latency. In retail,\nIoT devices can be used\
    \ to collect real-time data on customer behavior and inventory levels,\nwhich\
    \ can be used to optimize store operations and improve the customer experience.\
    \ 5G\nnetworks can provide the necessary bandwidth, reliability, and low latency\
    \ to support\nthese applications. Overall, the text shows how IoT and 5G technology\
    \ can work together\nto enable a range of applications in different ﬁelds. By\
    \ providing the necessary bandwidth,\nlow latency, and reliability, 5G networks\
    \ can support real-time data collection and analysis,\nwhich can help to improve\
    \ efﬁciency, reduce costs, and enhance the quality of life in\nvarious sectors.\n\
    Sensors 2023, 23, 3876\n5 of 41\n5G\nHealthcare\n5G will enable remote patient\
    \ \nmonitoring to happen at scale when \ncompared to other connectivity \nsolutions\
    \ through the promise of:\n-Greater reliability and security of the \nservice.\n\
    -Increased capacity for number of \nconnected           devices per square \n\
    kilometre.\n-Mobility versus in-home connectivity \nsolutions such as Wi-Fi.\n\
    Agriculture\nSmart farming may play a key role in food \ncrop production. Leveraging\
    \ a combination \nof 5G, edge computing and artiﬁcial \nintelligence that allows\
    \ for connectivity at a \nhigher speed with lower latency.\nCompanies are developing\
    \ \nsmart farming systems that \ncan beneﬁt from 5G. 5G will \nalso make farming\
    \ more \nprecise, using customized \ndata for farm management \njust like water,\
    \ pesticide use, \nand waste.\n5G is building transformative \npossibilities for\
    \ business. \nCreating powerful customer \nexperiences and effective \ninventory\
    \ tracking, high speeds \nand large data volumes that 5G \ncan support.\nHow products\
    \ are \nmanufactured \nThe evolution of the technology \nin the world of robotics\
    \ and \nwarehouse transportation \ndepends now on 5G and IoT will \nbe key to\
    \ enhancing and \nenabling advances in \nmanufacturing. \nIndustrial \nautomatation\n\
    5G technology has a number \nof features which will \npositively impact digital\
    \ \nexperiences and smart \ncities.\nBy using sensors, wearables and e-\nhealth\
    \ devices, patient attributes can be \ncollected and analysed without the need\
    \ \nfor patients to travel to primary care \nfacilities and have a face to face\
    \ \nappointment with a medical \nprofessional.\nRetail\n5G will empower \nan omnichannel\
    \ \nretail revolution to \nengage shoppers, \nincrease sales, \nand reduce \n\
    operating costs\n5G brakes on the \ndevelopment of the Internet \nof Things, which\
    \ will be \nable to explote the potential \nnot only in the home \nenvironment\
    \ but also in \nindustrial plants, in public \nbuildings or on the streets.\n\
    Smart cities\nOrganizational \nstructures. Since the \ncity as an entity \nseeks\
    \ innovation, it \nneeds data and \nanalysis tools to \nachieve it.\nhow can this\
    \ beneﬁt you?\nDeliver the best-performing 5G services anywhere.\nAchieve superior\
    \ RAN performance with a \nsuperior transport network.\nEstablish technology leadership\
    \ in new markets \nas you deliver on a whole new set of 5G use \ncases.\nService\
    \ providers will need high-performing 5G \nTransport solutions that are easy to\
    \ build, scale, \nand service. Transport solutions are designed to \nefﬁciently\
    \ meet all needs, getting 5G technology’s \nhelp will give us the best potential\
    \ to evolve with \nthe best performance.\n smart farming \ncould become a \ngame\
    \ changer as \nwe face a \ncrossroads in \nresources and \nproduction.\nIn addition\
    \ to a higher speed \nto upload and download \ndata, it ensures very short \n\
    latency times and the ability \nto connect multiple devices \nat the same time.\n\
    Transportation\nFigure 2. 5G applications impacted by IoT devices.\n2. Related\
    \ Work\nThe radio signal characteristics of new wireless applications are similar\
    \ to those of\nexisting mobile technologies [5]. This is where the interest of\
    \ this work lies in considering in\ndetail the impact and types of interference\
    \ of 5G technologies that coexist with IoT devices.\nThe new applications use\
    \ similar transmit powers and operate in the same frequency ranges.\nTo mitigate\
    \ interference, we can synchronize or coordinate all networks or implement\nlarge\
    \ guard bands that waste valuable spectrum [15]. In practice, close cooperation\
    \ is\nrequired between all operators in each frequency band, and not all usage\
    \ modes and\nall types of 5G deployments can likely be supported simultaneously.\
    \ Regulators need\nto consider these technical issues and their implications when\
    \ deciding how to arrange\nfrequencies in these bands.\nVarious interference management\
    \ techniques, such as power control, channel allo-\ncation, and beamforming, can\
    \ be implemented to ensure that IoT devices on the same\nnetwork do not interfere\
    \ with each other. However, these techniques can be complicated\nand may require\
    \ signiﬁcant changes to the network infrastructure [16]. Additionally, new\ninterference\
    \ management techniques may be required as IoT devices continue to evolve\nand\
    \ become more sophisticated.\nAnother signiﬁcant challenge in managing interference\
    \ in 5G networks is the diversity\nof devices and applications that use these\
    \ networks. IoT services can be used in various\nindustries, including healthcare,\
    \ manufacturing, and transportation, each with unique\nconnectivity and latency\
    \ requirements [17]. For instance, in healthcare, IoT devices, such as\nSensors\
    \ 2023, 23, 3876\n6 of 41\nwearable monitors and remote patient monitoring systems,\
    \ require low latency and reliable\nconnectivity to provide accurate data and\
    \ alerts. In contrast, IoT devices used in industrial\nautomation require high\
    \ bandwidth and low latency to operate effectively [18]. Therefore,\nmanaging\
    \ interference in 5G networks requires a comprehensive approach that considers\n\
    the diverse connectivity and latency requirements of different IoT devices and\
    \ applications.\nAnother important challenge is the potential for external interference;\
    \ while interfer-\nence management techniques can ensure that IoT devices on the\
    \ same network do not\ninterfere with each other, external interference can occur\
    \ when IoT devices operate in areas\nwith other wireless devices, such as Wi-Fi\
    \ routers, Bluetooth devices, and other cellular\nnetworks. This can lead to signal\
    \ degradation, reduced throughput, and decreased reliabil-\nity of the network\
    \ [19]. As a result, it is essential to consider external interference when\n\
    designing and implementing 5G networks for IoT services, and to use techniques\
    \ such as\nfrequency coordination and spectrum sharing to manage external interference\
    \ effectively.\nTo provide better insights for the 5G interference topic, we follow\
    \ the structure detailed\nin Figure 3.\nFigure 3. 5G and IoT technologies’ impact\
    \ scheme.\nThe impact of 5G network interference on IoT services is an active\
    \ research area. Sev-\neral studies have investigated the effects of interference\
    \ on the performance of IoT devices\nand applications. One recent study by Chandra\
    \ et al. analyzed the impact of interference\non the reliability of 5G networks\
    \ for IoT services [20]. The study found that interference\ncan signiﬁcantly reduce\
    \ the reliability of 5G networks for IoT services, especially in dense\ndeployments\
    \ where multiple devices operate in the same area. The study recommended\nusing\
    \ advanced interference management techniques such as dynamic channel allocation\n\
    and power control to mitigate interference effects and improve network reliability.\n\
    Another recent study by Azari et al. [21] investigated the impact of interference\
    \ on\nthe performance of 5G networks for IoT applications. The study found that\
    \ interference\ncan cause signiﬁcant degradation of network performance, especially\
    \ for applications\nthat require low latency and high bandwidth. The study recommended\
    \ using adaptive\nbeamforming and dynamic channel allocation to reduce interference\
    \ and improve the\nperformance of 5G networks for IoT applications. Additionally,\
    \ the study highlighted\nthe need for more research into interference management\
    \ techniques that can effectively\nmitigate the impact of interference on 5G networks\
    \ for IoT services.\nSeveral research studies have also investigated the impact\
    \ of interference on the\nenergy consumption of IoT devices connected to 5G networks.\
    \ One recent study by\nSensors 2023, 23, 3876\n7 of 41\nAl-Turjman et al. [22]\
    \ found that interference can cause IoT devices to consume more energy\nto maintain\
    \ connectivity, leading to reduced battery life and increased maintenance costs.\n\
    The study recommended the use of interference management techniques, such as energy-\n\
    efﬁcient channel allocation and scheduling to reduce interference and improve\
    \ the energy\nefﬁciency of IoT devices on 5G networks. The study concluded that\
    \ effective interference\nmanagement techniques are crucial for ensuring the sustainability\
    \ and economic viability\nof IoT services on 5G networks.\nAnother critical area\
    \ of research related to 5G network interference in IoT services is\nthe security\
    \ and privacy implications of interference management techniques. Interference\n\
    management techniques, such as beamforming and channel allocation, require the\
    \ ex-\nchange of information between IoT devices and the network, which can potentially\
    \ expose\nsensitive information to eavesdroppers and attackers. A recent study\
    \ by Hasan et al. [23]\ninvestigated the security and privacy risks associated\
    \ with beamforming and proposed a\nsecure beamforming scheme that uses encryption\
    \ and authentication to protect sensitive\ninformation. The study concluded that\
    \ the security and privacy implications of interference\nmanagement techniques\
    \ must be carefully considered when designing 5G networks for\nIoT services. Effective\
    \ security and privacy measures can help mitigate the risks associated\nwith interference\
    \ management techniques and ensure the integrity and conﬁdentiality of\nIoT data\
    \ on 5G networks.\nOverall, the current state of the art and related work on the\
    \ impact of 5G network\ninterference on IoT services highlight the importance\
    \ of effective interference management\ntechniques to ensure the reliability and\
    \ performance of 5G networks for IoT applications.\nThe studies recommend the\
    \ use of advanced interference management techniques, such as\ndynamic channel\
    \ allocation, power control, adaptive beamforming, and spectrum sharing,\nto mitigate\
    \ the effects of interference and improve network performance. However, more\n\
    research is needed to develop new and more effective interference management techniques\n\
    that can address the unique challenges of 5G networks and IoT services.\nTable\
    \ 1 presents a comparison of IoT services based on the impact of 5G network\n\
    interference on their performance. It describes six parameters as follows:\n1.\n\
    IoT Service: This parameters lists the various IoT services that are considered\
    \ in the\ncomparison.\n2.\nReliability: This metric represents the reliability\
    \ of 5G networks when used to support\nthe respective IoT service. Reliability\
    \ is a measure of the ability of the network to\nprovide consistent and dependable\
    \ service. The values in this column range from low\nto high.\n3.\nMultiple devices\
    \ operate: This metric indicates whether the IoT service can operate\nwith multiple\
    \ devices. This is an important factor to consider since many IoT services\ninvolve\
    \ the connection of multiple devices, and the network needs to support the\nsimultaneous\
    \ communication of these devices.\n4.\nLatency: This parameter measures the amount\
    \ of delay or lag time in transmitting data\nbetween the IoT devices and the network.\
    \ Latency is an important metric to consider\nfor real-time IoT services, such\
    \ as connected vehicles and healthcare monitoring. The\nvalues in this column\
    \ range from low to ultra-low.\n5.\nInterference management techniques: This parameter\
    \ lists the various techniques that\ncan be used to manage interference in the\
    \ network. Interference management is crucial\nto maintain high performance in\
    \ the presence of other devices and networks that\nmay use the same frequency\
    \ bands. The techniques listed in this column include dy-\nnamic frequency selection,\
    \ channel hopping, beamforming, coordinated multi-point\ntransmission, dynamic\
    \ power control, interference avoidance, MIMO (multiple-input,\nmultiple-output)\
    \ [24], cognitive radio, massive MIMO, and interference alignment.\n6.\nEnergy\
    \ consumption: This metric indicates the amount of energy consumed by the\nIoT\
    \ devices and the network. Energy consumption is an important consideration for\n\
    IoT services, especially for those that operate in remote locations or rely on\
    \ battery-\npowered devices. The values in this column range from low to high.\n\
    Sensors 2023, 23, 3876\n8 of 41\nTable 1 compares ten IoT services, including\
    \ smart home automation, smart agricul-\nture, industrial IoT, connected vehicles,\
    \ healthcare monitoring, smart cities, environmental\nmonitoring, smart grid management,\
    \ augmented reality, and drones. For each IoT service,\nthe table lists the parameters\
    \ in each column relevant to the impact of 5G network interfer-\nence on its performance.\
    \ Note that the values in the table are just examples and should be\nreplaced\
    \ with appropriate data from relevant papers. The table provides a helpful overview\n\
    of how different IoT services may be impacted by 5G network interference and what\
    \ factors\nare essential to consider when evaluating the performance of these\
    \ services in the presence\nof interference.\nTable 1. Impact of 5G network interference\
    \ on IoT services\nIoT Service\nReliability\nMultiple\nDevices\nLatency\nInterference\n\
    Management\nEnergy\nConsumption\nSmart home\nautomation [7]\nHigh\nYes\nLow\n\
    Dynamic frequency\nselection\nLow\nSmart agriculture [25]\nMedium\nYes\nMedium\n\
    Channel hopping\nHigh\nIndustrial IoT [26]\nHigh\nYes\nLow\nBeamforming\nMedium\n\
    Connected vehicles [27]\nHigh\nYes\nUltra-low\nCoordinated\nmulti-point\ntransmission\n\
    High\nHealthcare\nmonitoring [28]\nHigh\nYes\nLow\nDynamic power\ncontrol\nLow\n\
    Smart cities [29]\nHigh\nYes\nLow\nInterference\navoidance\nHigh\nEnvironmental\n\
    monitoring [30]\nMedium\nYes\nLow\nMIMO\nLow\nSmart grid\nmanagement [31]\nHigh\n\
    Yes\nLow\nCognitive radio\nHigh\nAugmented reality [32]\nHigh\nNo\nUltra-low\n\
    Massive MIMO\nHigh\nDrones [33]\nHigh\nYes\nUltra-low\nInterference\nalignment\n\
    Medium\n3. Materials and Methods\n4G networks are based on LTE technology, which\
    \ uses a frequency spectrum of around\n700 MHz to 2600 MHz. These frequencies\
    \ are divided into different bands that are used for\ndifferent purposes, such\
    \ as voice and data communication. 4G networks use a combination\nof Frequency\
    \ Division Duplex (FDD) and Time Division Duplex (TDD) techniques to\ntransmit\
    \ and receive data. FDD uses separate frequencies for transmitting and receiving\n\
    data, while TDD uses the same frequency for both.\nOn the other hand, IoT devices\
    \ use a variety of technologies and protocols to com-\nmunicate with each other\
    \ and with the internet. These devices can operate on different\nfrequency bands,\
    \ such as 2.4 GHz, 5 GHz, and sub-GHz bands. Some IoT devices use the\nunlicensed\
    \ spectrum, which means they can operate on any frequency without needing a\n\
    license, while others use the licensed spectrum, which requires a license from\
    \ the relevant\nregulatory body.\nOne of the main issues with 4G services and\
    \ networks is that they can cause inter-\nference with IoT devices, especially\
    \ those operating on the same frequency bands. This\ninterference can cause communication\
    \ problems and even lead to data loss or corruption.\nTo mitigate this interference,\
    \ different methods can be used, such as frequency hopping,\nspread-spectrum techniques,\
    \ and power control.\nSensors 2023, 23, 3876\n9 of 41\nFigure 4 summarizes this\
    \ section, where the main concepts related to the impact of\n5G networks on IoT\
    \ services are observed. We analyze the implementation, the evolution,\nand the\
    \ types of wireless technologies that inﬂuence current services, the leading 5G\n\
    technologies and problems, and the coexistence of next-generation networks. We\
    \ frame\ninterference as the heart of the study of problems in this type of network.\n\
    Figure 4. Materials and Methods for 5G and IoT services.\n3.1. 5G Implementation\
    \ Requirements\n5G is an emerging technology in the telecommunications area. Enabling\
    \ high-speed\nconnections, offering lower latencies, and ensuring highly scalable\
    \ connectivity between mul-\ntiple devices [34], every industry worldwide eagerly\
    \ waits for mainstream implementation.\n5G allows for several technologies related\
    \ to massive machine-to-machine communi-\ncations, or IoT, to improve and offer\
    \ high-speed connectivity between devices, primarily\nallowing automation in the\
    \ manufacturing and construction industries. However, IoT has\nseen massive consumer\
    \ implementation in homes, malls, and parks, which means this\ntechnology has\
    \ several use cases for ordinary daily consumers.\nOn the technical side of 5G,\
    \ it works on a higher spectrum range when compared to\ntraditional wireless technologies.\
    \ Ranging from 24 to 100 GHz, it provides low-latency\ncommunication and high\
    \ throughput rates but suffers from adverse conditions caused\nby its high-frequency\
    \ nature [35]. 5G also operates on two frequency bands: Sub 6 GHz\nand mmWave\
    \ (millimeter wave). While mmWave offers faster data transfer rates, it has\n\
    limited coverage and is easily obstructed. On the other hand, the Sub 6 GHz band,\
    \ which\nincludes frequencies below 6 GHz, offers wider coverage and can penetrate\
    \ obstacles such\nas buildings and walls [36]. This means that 5G can actually\
    \ work in the Sub 6 GHz band,\nproviding a more reliable and accessible network\
    \ for users. This is particularly important\nfor rural and suburban areas where\
    \ building penetration is critical, and for indoor usage\nwhere higher frequency\
    \ bands may not be able to reach. Therefore, despite the hype around\nmmWave,\
    \ the Sub 6 GHz band remains a vital part of the 5G network, providing a strong\n\
    foundation for the future of wireless technology.\nTo counteract the limitations,\
    \ 5G has been complemented with new technologies. The\nmost common ones are beamforming,\
    \ massive MIMO, small cell, mmWave, and network\nslicing, and new proposals arise\
    \ everyday to try and get the most out of this generation.\nSensors 2023, 23,\
    \ 3876\n10 of 41\nEven though 5G is far from being implemented worldwide, several\
    \ service providers\nhave been publicly working and sharing their advances related\
    \ to this technology. Some\nfamous names from the IT world are Ericsson, Verizon,\
    \ Nokia, AT&T, T-Mobile, Samsung,\nand Qualcomm. However, undoubtedly, most big\
    \ telecommunications companies are\nworking on projects related to the new generation\
    \ of wireless technologies.\nResearch groups have been focused on the 5G mobile\
    \ network ecosystem, with institu-\ntions such as METIS (Mobile and wireless communications\
    \ Enablers for Twenty-twenty\n(2020) Information Society), 5G PPP (5G Infrastructure\
    \ Public Private Partnership), and\nNYU New York University Wireless, conducting\
    \ impactful research related to MIMO\ntransmissions, millimeter waves, and frameworks\
    \ in the 5G ecosystem [37].\n5G networks offer several features that are essential\
    \ for the Internet of Things (IoT)\nservices, as Figure 5 shows. 5G provides increased\
    \ bandwidth and lower latency, allowing\nIoT devices to transmit data quickly\
    \ and efﬁciently for real-time communication and\nresponse. 5G enables massive\
    \ machine-type communication (mMTC), which allows a\nlarge number of IoT devices\
    \ to connect to the network simultaneously. Ultra-reliable and\nlow-latency communication\
    \ (URLLC) is also provided, ensuring quick and reliable data\ntransmission suitable\
    \ for mission-critical IoT services. Network slicing is another feature of\n5G\
    \ networks, which creates dedicated virtual networks for IoT devices to provide\
    \ better\nnetwork performance and security.\nFigure 5. 5G features that are essential\
    \ for the Internet of Things services.\nBefore the implementation of 5G networks,\
    \ organizations such as IEEE needed to\ncope with challenges about the implementation\
    \ of 5G. One of these challenges is about the\ndata rate key dimensions, since\
    \ the demand of technology services are increasing in the\npast years. 5G should\
    \ be a solution in order to satisfy all this demand and provide a great\nQuality\
    \ of Service (QoS) [38].\nAnother factor to consider is the latency, which is\
    \ responsible for the delay in incoming\nand outgoing packages on a link, as streaming\
    \ services such as online games [39], metaverse,\nand more demand a low latency\
    \ in order to provide better services.\nSensors 2023, 23, 3876\n11 of 41\nIn modern\
    \ society, most products use electrical power, including, for example, electric\n\
    cars such as Tesla. In other words, we are surrounded by electronic devices, and\
    \ it is\nessential to focus on developing friendly devices to avoid consuming\
    \ too much electricity.\nSome important points about 5G energy consumption need\
    \ to be mentioned. First, energy\nefﬁciency depends on the trafﬁc in the network.\
    \ According to the article “Energy-efﬁcient\n5G for a greener future” [40], when\
    \ the trafﬁc load is low, a base station can save 98.75% of\npower, but if the\
    \ trafﬁc load is high, the power consumption may increase.\nFigure 6 describes\
    \ the requirements for 5G. This generation is the latest generation\nof cellular\
    \ networks that is designed to offer signiﬁcant improvements in performance,\n\
    capacity, and ﬂexibility compared to previous generations. To achieve these improvements,\n\
    5G networks utilize several key technologies. One of these technologies is millimeter\n\
    wave (mmWave) frequencies, which are higher frequency bands that can provide higher\n\
    bandwidth and faster data rates. However, these frequencies have short wavelengths\n\
    and require line-of-sight communication between the transmitter and receiver.\
    \ Another\ntechnology used in 5G networks is massive MIMO (multiple input, multiple\
    \ output)\ntechnology, which uses a large number of antennas to increase the number\
    \ of spatial\nstreams and improve the efﬁciency of the wireless channel. This\
    \ can help to increase the\ndata transfer rates and overall network capacity.\
    \ Beamforming is also a key technology used\nin 5G networks, as it uses advanced\
    \ techniques to focus the radio signal towards a speciﬁc\ndevice, increasing the\
    \ signal strength and reducing interference. This technology is crucial\nfor providing\
    \ reliable and high-speed connectivity in a dense and dynamic environment.\nNetwork\
    \ slicing is another feature of 5G networks that allows for the creation of dedicated\n\
    virtual networks to meet the speciﬁc requirements of different applications. This\
    \ means that\ndevices can allocated their own network resources and services,\
    \ providing better network\nperformance and security. Edge computing is also used\
    \ in 5G networks, which provides real-\ntime processing and analysis of data at\
    \ the edge of the network. This can help to reduce the\nlatency and improve the\
    \ performance of time-sensitive applications, such as autonomous\nvehicles and\
    \ virtual reality. Low latency is another feature of 5G networks that is important\n\
    for applications that require real-time communication and response, such as autonomous\n\
    vehicles and remote surgery. 5G networks aim to achieve a latency of less than\
    \ 1 millisecond.\nHigh reliability is also a critical feature of 5G networks,\
    \ with features such as network slicing\nand redundant network paths, ensuring\
    \ that devices stay connected. This is essential for\nmission-critical applications\
    \ that require high availability and low downtime. 5G networks\nsupport full duplex\
    \ communication, which allows for simultaneous transmission and\nreception of\
    \ data. This technology can help to improve the efﬁciency and capacity of the\n\
    network, enabling higher data transfer rates and reducing latency.\nBased on the\
    \ requirements above, the following are the 5G network deployment\nrequirements:\n\
    •\nMillimeter wave (mmWave) frequencies for higher bandwidth and faster data rates.\n\
    •\nMassive MIMO (multiple input, multiple output) technology for increasing spatial\n\
    streams and improving the wireless channel’s efﬁciency.\n•\nBeamforming to focus\
    \ the radio signal towards a speciﬁc device, increasing signal\nstrength and reducing\
    \ interference.\n•\nNetwork slicing for creating dedicated virtual networks to\
    \ meet the speciﬁc require-\nments of different applications, improving network\
    \ performance and security.\n•\nEdge computing for real-time processing and analysis\
    \ of data at the edge of the net-\nwork, reducing latency and improving the performance\
    \ of time-sensitive applications.\n•\nLow latency for real-time communication\
    \ and response, aiming to achieve a latency of\nless than 1 millisecond.\n•\n\
    High reliability for mission-critical applications, ensuring high availability\
    \ and low\ndowntime.\n•\nFull duplex communication for simultaneous transmission\
    \ and reception of data,\nimproving efﬁciency, capacity, and reducing latency.\n\
    Sensors 2023, 23, 3876\n12 of 41\nThe combination of these technologies in 5G\
    \ networks can enable a wide range of\napplications, from IoT services to high-bandwidth\
    \ applications, such as virtual reality and\naugmented reality. 5G networks aim\
    \ to provide the necessary performance metrics to\nsupport these applications,\
    \ enabling the growth of the IoT ecosystem and a new era of\nconnectivity.\nFigure\
    \ 6. 5G implementation requirements.\n3.2. Evolution of Wireless Networks\nWireless\
    \ networks [41] have an important role in our society, because they allow us to\n\
    keep connected in a network without cables, being the bridge to create useful\
    \ tools. For\ninstance, 3GPP provides basic data services such as voice and messaging\
    \ capabilities, with\n4G we can make video calls, and use IP services, and with\
    \ 5G we can get more beneﬁts,\nsuch as low latency, more bandwidth, and other\
    \ interesting features [42].\n3.3. Evolution of IoT\nThe evolution of the internet\
    \ allowed remote connections between machines, and\nthe protocol standardization\
    \ used to transmit the information, such as TCP/IP, enabled\nresearchers to take\
    \ advantage of the internet and allowed to creation of new protocols and\nways\
    \ to transmit the data [43]. Since then, new technologies has arrived in our lives,\
    \ which\nis the case of IoT. In the last few years, new technologies and protocols\
    \ arose to connect\nand transmit data between IoT devices and networks, each providing\
    \ speciﬁc features\nto perform the applications. In the following statements,\
    \ we mention some protocols to\ncommunicate data. Each protocol can provide better\
    \ communication depending on the\napplication. For example, LoRaWAN is used in\
    \ long-range communication, allowing to\ntransmit of data through large distances\
    \ even with obstacles between the link and using\nlow power consumption. Zigbee\
    \ is a protocol commonly used in smart homes, avoiding\ninferences by routers,\
    \ electronic devices, and so on.\nSensors 2023, 23, 3876\n13 of 41\nThe evolution\
    \ of IoT technologies is having a signiﬁcant impact on 5G networks. As\nmore and\
    \ more devices are connected to the internet, there is a growing need for faster,\n\
    more reliable connectivity. This is where 5G networks come in, providing higher\
    \ speeds,\nlower latency, and greater capacity than previous wireless technologies.\
    \ The proliferation\nof IoT devices also creates new opportunities for 5G, as\
    \ the technology is able to support the\nmassive amounts of data generated by\
    \ these devices. However, this also poses challenges\nfor 5G networks, such as\
    \ the need to handle large amounts of trafﬁc from a variety of\ndevices with different\
    \ requirements. As a result, the evolution of IoT technologies is\ndriving innovation\
    \ in 5G networks, as providers look for ways to meet the demands of this\ngrowing\
    \ ecosystem.\nThe implementation of 5G networks is expected to have a signiﬁcant\
    \ impact on the\nevolution of IoT services. One of the most signiﬁcant changes\
    \ is the increase in the speed\nof data transfer. 5G networks have much faster\
    \ data transfer speeds, lower latency, and\nhigher capacity than previous generations\
    \ of mobile networks [44]. This means that IoT\ndevices can transmit and receive\
    \ data much more quickly, which enables more real-time\ndata processing and analysis.\
    \ The improved responsiveness of IoT services will open up\nopportunities for\
    \ new applications that require near-instantaneous data processing, such\nas remote\
    \ surgery, autonomous vehicles, and industrial automation.\nAnother important\
    \ change brought about by the implementation of 5G networks is\nthe increased\
    \ scalability of IoT services. 5G networks have a higher device density, which\n\
    means that they can support a greater number of IoT devices per unit area. This\
    \ will help\nto increase the scalability of IoT services and allow for the deployment\
    \ of more complex\nand sophisticated IoT solutions.\nFurthermore, 5G networks\
    \ are expected to improve the reliability of IoT services. 5G\nnetworks have more\
    \ robust error correction capabilities and redundancy features, which\ncan increase\
    \ the reliability of IoT services. This is particularly important for mission-critical\n\
    applications, such as remote monitoring of infrastructure or medical devices [45].\
    \ Improved\nreliability will also be beneﬁcial in industries that require highly\
    \ reliable communication\nnetworks, such as manufacturing and energy.\nThe enhanced\
    \ security features of 5G networks will also impact the evolution of IoT\nservices.\
    \ 5G networks offer improved security features, such as network slicing, which\n\
    allows for the creation of isolated virtual networks for different IoT applications.\
    \ This can\nhelp to prevent unauthorized access and ensure the security and privacy\
    \ of IoT data. With\nthe increasing number of IoT devices, the importance of security\
    \ and privacy is critical and\n5G networks can provide a more secure environment\
    \ for the data transmitted.\n5G networks will help to reduce the power consumption\
    \ of IoT devices. 5G networks\nare designed to be more energy efﬁcient than previous\
    \ generations of mobile networks [46].\nThis can help to reduce the power consumption\
    \ of IoT devices, prolonging their battery life\nand reducing their environmental\
    \ impact. This is particularly important for IoT devices\nthat are difﬁcult or\
    \ expensive to replace or recharge, such as sensors deployed in remote\nor inaccessible\
    \ locations. Figure 7 describes the main features related to 5G networks and\n\
    IoT services. The performance metrics associated with energy consumption are mentioned\n\
    here too.\nSensors 2023, 23, 3876\n14 of 41\nFigure 7. Deﬁning 5G and features\
    \ that are essential for the Internet of Things services.\n3.4. Wireless Communication\
    \ Technologies for IoT and Cloud-Based Solutions\nThis section covers various\
    \ wireless communication protocols used in IoT devices,\nincluding Wi-Fi AdHoc,\
    \ Zigbee, Z-Wave, LoRaWAN, and SigFox. It also touches on the\nuse of cloud computing\
    \ for IoT applications, such as data storage, analytics, and remote\ndevice management.\
    \ This section could provide a comprehensive overview of wireless\ncommunication\
    \ technologies used in IoT devices and their integration with cloud-based\nsolutions.\n\
    1.\nWi-Fi AdHoc: With the standard of IEEE 802.11, Wi-Fi technology turned into\
    \ the\nﬁrst technology to create devices connected to the network. Allowing to\
    \ create news\narchitectures such as Wi-Fi AdHoc is a decentralized type of wireless\
    \ network because\neach node participates in routing by forwarding data to other\
    \ nodes [47]. These nodes\ncan be IoT devices and are very helpful in applications\
    \ where it is needed to have\nmany devices connected.\n2.\nZigbee: The most popular\
    \ industry wireless mesh networking standard for connecting\nsensors, instrumentation,\
    \ and control systems. Zigbee implements communication in\na personal wireless\
    \ area network, providing low power consumption and interoper-\nating multi-vendor,\
    \ commonly used in home automation, low-power consumption\nsensors, HVAC (Heating,\
    \ Ventilation, and Air Conditioning) control, etc. [48].\n3.\nZ-Wave: A wireless\
    \ protocol evolved by Zensys and conﬁrmed by the Z-Wave Alliance\nfor automation\
    \ apparatuses for home and commercial environments. This protocol\nallows transmitting\
    \ short messages with minimum noise and uses a Mesh network\nconﬁguration [49].\n\
    4.\nLoRaWAN: A low-power, wide-area networking protocol designed to connect battery\n\
    wirelessly operated ‘things’ to the internet in regional, national, or global\
    \ networks. It\ntargets IoT requirements, such as bi-directional communication,\
    \ end-to-end security,\nmobility, and localization services. According to work\
    \ cited in [50], LoRa has the most\nfeatures in terms of IoT, such as low power\
    \ consumption, long-range communication,\netc. Furthermore, the paper tested communication\
    \ in urban and forest areas, showing\nthat LoRaWAN can transmit data up to 2.1\
    \ km in urban areas.\nSensors 2023, 23, 3876\n15 of 41\n5.\nSigFox: SigFox is\
    \ a network operator dedicated to the Internet of Things. The SigFox\nnetwork\
    \ uses the ultra-narrow band, allowing devices to communicate with low\npower\
    \ on a wide area [51].\n6.\nCloud Computing: Cloud computing is a term used to\
    \ describe both a platform and a\ntype of application. One of the essential features\
    \ of cloud computing is the capability\nto assign dynamic resources to the network,\
    \ being an important key to providing\nscalable solutions and avoiding high costs.\
    \ The interference plays an important\nrole when connecting devices since the\
    \ signal quality decrease, which means the\nmodulation decreases and the bits\
    \ per error increases. That is a problem if we are\ntrying to offer large bandwidths\
    \ and low latency in each data transmission [52]. We\nmust consider different\
    \ factors to provide a great QoS, like the weather, buildings,\nhardware, software\
    \ resources, etc. In the IoT context, the buildings and distances\ncreate the\
    \ main interferences. For that reason, technologies such as Zigbee, SigFox,\n\
    LoRaWAN, and Z-wave play a vital role in connecting devices.\n7.\nWiGig: WiGig,\
    \ also known as 802.11ay, is a wireless communication technology that\noperates\
    \ on the 60 GHz frequency band [53]. It was developed as an extension of the\n\
    Wi-Fi standard to provide high-speed, short-range wireless communication, primarily\n\
    for applications that require high bandwidth, such as virtual reality, high-deﬁnition\n\
    video streaming, and gaming. WiGig supports multi-gigabit data transfer rates,\
    \ with\ntheoretical speeds of up to 176 Gbps, which is much faster than the previous\
    \ Wi-\nFi standards [54]. It achieves this speed through the use of wider bandwidth\
    \ and\nadvanced modulation techniques, such as Quadrature Amplitude Modulation\
    \ (QAM)\nand Orthogonal Frequency Division Multiplexing (OFDM). Another notable\
    \ feature\nof WiGig is its low latency, making it ideal for applications that\
    \ require real-time\ndata transfer, such as gaming and virtual reality [55]. It\
    \ also supports multiple-input,\nmultiple-output technology, which enables multiple\
    \ antennas to transmit and receive\ndata simultaneously, improving the overall\
    \ performance and efﬁciency of the network.\nIn the context of 5G networks, WiGig\
    \ can be used as a complementary technology\nto provide high-speed local area\
    \ network (LAN) connections for mobile devices and\nIoT devices. The 60 GHz frequency\
    \ band has a limited range, but it can support high\ndata rates over short distances,\
    \ making it suitable for applications, such as augmented\nand virtual reality\
    \ (AR/VR), wireless HD video streaming, and cloud gaming [56]. In\naddition, WiGig\
    \ can be used as a backhaul technology for small cells in 5G networks,\nenabling\
    \ high-speed data transfers between small cells and the core network. This\ncan\
    \ help improve the performance and capacity of 5G networks, especially in densely\n\
    populated urban areas where there is high demand for data services. Regarding\
    \ IoT\nservices, WiGig can enable high-speed local area connections between IoT\
    \ devices,\nallowing them to share data quickly and efﬁciently. This can be especially\
    \ useful for\napplications, such as smart homes, where multiple IoT devices need\
    \ to communicate\nwith each other in real time.\n3.5. 5G Applications\n5G beneﬁts\
    \ are not utilized solely by the most prominent IT corporations world-\nwide.\
    \ In the modern era, we have found several exciting applications where 5G’s high\n\
    speeds, excellent reliability, and energy efﬁciency come into play and provide\
    \ a better\nuser experience.\n•\nEntertainment services: Video-on-demand services\
    \ are currently one of the most\nutilized services on the internet. These services\
    \ demand high-speed connections, and\nwith rising trends to utilize higher resolution\
    \ devices, 5G plays a vital role in providing\noptimal user experience so that\
    \ they can consume their content without interruption.\n•\nGeneral mobile networks:\
    \ Due to the COVID-19 pandemic in recent years, teleworking\nhas seen an immense\
    \ rise in all sectors globally. This means workers must be able\nto respond to\
    \ video or voice calls at any given time, requiring improved downlink\nand uplink\
    \ speeds. These requirements, complemented with the higher reliability\nSensors\
    \ 2023, 23, 3876\n16 of 41\naspects of 5G, mean that this implementation will\
    \ improve communications in any\ngiven context, especially for work-related tasks.\n\
    •\nInternet of Things: IoT is one of the trendiest topics around the electronics\
    \ ecosys-\ntem, due to its nature to provide automation to simple or very complex\
    \ topics. Even\nthough most IoT devices currently utilize 3G or 4G-LTE technologies\
    \ due to their low\nrequirements for data connectivity, a new generation of IoT\
    \ devices requires higher\nthroughput rates. These requirements are on the limits\
    \ of the current generation of\nwireless technologies, which makes 5G an interesting\
    \ contestant to solve these require-\nments. The most popular IoT applications\
    \ today involve Smart Homes, industries,\nor farming, which generally require\
    \ low amounts of wireless capabilities because\nthe devices have low microprocessing\
    \ power due to the nature of the technology\nitself. However, new trends, such\
    \ as Smart Cities or IoV (Internet of Vehicles), require\nmuch greater throughput\
    \ to function correctly and offer an optimal user experience.\nThese types of\
    \ solutions require capabilities that are only offered by 5G. IoT data\nare visioned\
    \ to increase in data provided per area by 1000 times [57] which means\nIoT applications\
    \ will be part of our everyday lives. The current data are provided\nmainly by\
    \ sensors, but more complex devices will mean that data will be gathered\nfrom\
    \ additional sources. This exponential growth in data consumption will also need\n\
    to be stored in scalable data storages, and this is where cloud computing comes\
    \ in.\nSome of the most famous architectural trends of IoT devices follow three\
    \ principles:\nHardware: All sensor nodes that gather data, their communication\
    \ methods, and the\nhardware interface with the user.\nMiddleware: The layer in\
    \ charge of storing and analyzing the data and monitoring\nthe devices.\nPresentation\
    \ layer: Commonly called the front end, this presents visualization tools\nbetter\
    \ to understand our devices’ current state and behavior.\n5G technologies can\
    \ impact the hardware and middleware layer. As the technology is\nmore energy\
    \ efﬁcient, the devices do not need massive antennas, which can lead to\nincreased\
    \ consumption. At the middleware layer, as devices can communicate more\ndata\
    \ in a given period, this layer will beneﬁt from extra data to improve any statistical\n\
    or machine learning model.\n3.6. 5G Technologies\nThe purpose of this section\
    \ is to describe some of the most popular technologies\nimplemented with 5G.\n\
    Figure 8 shows characteristics and technical speciﬁcations of 5G. 5G networks\
    \ offer\nseveral key characteristics and technical speciﬁcations that make them\
    \ ideal for a wide range\nof applications. 5G provides signiﬁcantly increased\
    \ bandwidth, enabling faster data transfer\nrates for high-speed applications,\
    \ such as virtual and augmented reality. It also offers lower\nlatency, making\
    \ it suitable for real-time communication and response applications, such\nas\
    \ autonomous vehicles and remote surgery. 5G is highly reliable, with features\
    \ such\nas network slicing and redundant network paths, ensuring devices stay\
    \ connected. 5G\nenables massive machine-type communication (mMTC) and ultra-reliable\
    \ and low-latency\ncommunication (URLLC), making it suitable for mission-critical\
    \ applications, such as\nindustrial automation. Additionally, 5G offers network\
    \ slicing, beamforming, and uses\nmillimeter wave (mmWave) frequencies for even\
    \ higher bandwidth and faster data rates.\nOverall, 5G networks offer signiﬁcant\
    \ improvements in bandwidth, latency, reliability, and\nﬂexibility, making them\
    \ well-suited for a wide range of applications.\nSensors 2023, 23, 3876\n17 of\
    \ 41\nFigure 8. Characteristics and technical speciﬁcations of 5G networks.\n\
    1.\nMassive MIMO: This technology is responsible for sending and receiving multiple\n\
    signals simultaneously, utilizing the same radio channel. While other technologies,\n\
    such as Wi-Fi or 4G-LTE, have utilized this technology, massive MIMO performs\
    \ best\nwhen paired with 5G technologies. This technology uses extra antennas\
    \ to move\nenergy into smaller regions of space, which means spectral efﬁciency\
    \ and coverage\nare improved [58].\n2.\nNOMA: Non-Orthogonal Multiple Access:\
    \ A radio access technology that plays a vital\nrole in 5G applications [59].\
    \ This technology offers several beneﬁts, such as low latency\nand massive high-speed\
    \ connectivity. Code domain NOMA is commonly paired with\nmMIMO, drastically improving\
    \ spectral efﬁciency [60]. Power domain NOMA is\ncommonly utilized with MIMO,\
    \ beamforming, and even cooperative communications,\nbeing one of the most ﬂexible\
    \ technologies utilized in 5G implementations.\n3.\nMillimeter Wave: This technology\
    \ uses a frequency band between 30 GHz and\n300 GHz and derives its name from\
    \ the 1 to 10 mm waves utilized by the tech-\nnology. Utilized commonly in radar\
    \ applications, this technology is being paired with\n5G to improve spectrum bandwidth\
    \ and increase spectrum utilizations. The main\nbeneﬁt of pairing this technology\
    \ with 5G is the spectrum freedom linked to mmWave.\nStandard technologies, such\
    \ as GPS, 4G, and satellite connections, utilize the 1 GHz\nto 6 GHz spectrum,\
    \ which is becoming very crowded [61]. Because mmWave is new\nand has a massive\
    \ spectral range, 5G provides an improved user experience through\nthis combination.\n\
    4.\nMachine Learning Techniques: Supervised and unsupervised models are being\
    \ im-\nplemented in 5G technologies to improve overall network capacities, predict\
    \ energy\nconsumption, and optimize tracking technologies such as beamforming.\
    \ In the su-\npervised category, some 5G networks utilize Linear Regression Algorithms\
    \ to predict\nthe scheduling of nodes [62]. Other supervised models utilize Deep\
    \ Neural Networks\nto predict beamforming vectors. Then, unsupervised learning\
    \ models are used to\nimprove handover selection and reduce interruption of services,\
    \ as well as they can\nreduce latency by clustering fog nodes.\n5.\nUnmanned Aerial\
    \ Vehicles (UAV): Being the most innovative proposal, current 5G\nresearchers\
    \ are utilizing UAVs to improve network coverage. These UAVs will assist\nthe\
    \ terrestrial network by serving as beacons. The high altitude of these planes\
    \ could\nsolve many interference problems and even replace entirely terrestrial\
    \ cellular net-\nworks [63]. UAVs, commonly known as drones, have become increasingly\
    \ popular for\nboth commercial and personal use. With the advent of 5G networks\
    \ and IoT, UAVs\ncan now be equipped with a wide range of sensors and devices\
    \ that can transmit\nreal-time data to ground stations for analysis and decision\
    \ making [64]. There are\nseveral potential implementations of UAVs in the context\
    \ of 5G and IoT. One such\nimplementation is in the area of precision agriculture.\
    \ UAVs can be used to gather data\non crop growth, soil conditions, and other\
    \ factors that affect agricultural production.\nThese data can be transmitted\
    \ in real time to a ground station for analysis and used\nSensors 2023, 23, 3876\n\
    18 of 41\nto optimize planting, fertilization, and irrigation schedules [65].\
    \ 5G networks and\nIoT sensors can provide the necessary bandwidth and low latency\
    \ for this type of\napplication. Another potential application of UAVs in the\
    \ context of 5G and IoT is\nin industrial inspection and maintenance. UAVs equipped\
    \ with cameras and other\nsensors can be used to inspect and monitor equipment\
    \ and infrastructure such as\npower lines and wind turbines. Real-time data transmission\
    \ via 5G networks can\nenable remote monitoring and control of these systems,\
    \ improving their reliability\nand reducing maintenance costs [66]. UAVs can also\
    \ be used for emergency response\nand disaster management. In the event of a natural\
    \ disaster, such as a hurricane or\nearthquake, UAVs can be deployed to assess\
    \ damage and provide real-time informa-\ntion to ﬁrst responders. The data collected\
    \ can be transmitted via 5G networks to\nemergency management centers for analysis\
    \ and decision making. UAVs can be used\nfor surveillance and security purposes.\
    \ In public safety applications, UAVs can be\nused to monitor crowd movements\
    \ and gather intelligence on potential threats. In\nprivate security applications,\
    \ UAVs can be used to patrol and monitor facilities for\nintruders or other security\
    \ threats. The combination of UAVs with 5G networks and\nIoT sensors can enable\
    \ a wide range of applications in various industries. With the\npotential to improve\
    \ efﬁciency, reduce costs, and enhance safety, it is likely that we\nwill see\
    \ an increase in the adoption of UAVs in the coming years.\n3.7. 5G Problems\n\
    5G offers excellent improvements over last-generation mobile communication tech-\n\
    nologies. However, many problems related to technological complications, security\
    \ and\nprivacy implications, and even social implications have been discovered.\n\
    Technical complications are related primarily to interference. 5G as a technology\
    \ has\ncomplications related to interference, being as sensible as being dramatically\
    \ affected by\nmild rain in urbanized areas [67]. Even though the technologies\
    \ mentioned previously\nhelp mitigate these problems, 5G still needs to be ready\
    \ to be used on a massive scale.\nTests performed in several countries utilizing\
    \ small cells show the need for more extensive\narchitectures to offer full coverage\
    \ and optimal user experience [68]. This means costly\narchitectures will lead\
    \ providers to focus mainly on urban areas, leaving rural areas unat-\ntended.\
    \ This leads to the following obstacles, which are ethical and social implications.\n\
    One of the main advantages of 5G is the ability to offer improved connections\
    \ to people\nin poor conditions. However, right now, it is only used as a marketing\
    \ stunt because 5G\narchitectures are considerably expensive and cannot offer\
    \ coverage in rural areas. As 5G\nequipment and technology become more widely\
    \ adopted in the following years, we expect\nbig strides in this department.\n\
    Another ethical and social implication is IoV technologies enabled by 5G. As we\
    \ see\nmore autonomous driving cars, and 5G will enable more precise driving for\
    \ these cars, as\nwell as broad adoption of them, we are encountering huge moral\
    \ dilemmas in cases where\ncar accidents are caused by autonomous vehicles. Security\
    \ implications arise from the trend\nof connecting vehicles to the internet, which\
    \ means people can be kidnapped remotely by\ntheir car if hackers gain control\
    \ of their vehicle via the web.\nThe main problems mentioned and explained above\
    \ are listed below:\n•\nTechnical complications related to interference, including\
    \ sensitivity to mild rain in\nurban areas.\n•\nNeed for extensive and costly\
    \ architectures to offer full coverage and optimal user\nexperience, which may\
    \ lead providers to focus mainly on urban areas, leaving rural\nareas unattended.\n\
    •\nEthical and social implications related to the inability to offer improved\
    \ connections\nto people in poor conditions due to the high cost of 5G architectures\
    \ and the lack of\ncoverage in rural areas.\n•\nSecurity implications arising\
    \ from the trend of connecting vehicles to the internet,\nwhich could result in\
    \ remote kidnappings by hackers.\nSensors 2023, 23, 3876\n19 of 41\nTable 2 compares\
    \ the problems presented by 5G and IoT services across several key\nareas, namely\
    \ security, latency, interference, cost, and compatibility. In terms of security,\n\
    5G networks are vulnerable to a range of threats, such as DDoS attacks, identity\
    \ theft, and\nman-in-the-middle attacks, while IoT devices can suffer from security\
    \ breaches due to weak\nencryption, passwords, and outdated ﬁrmware. Regarding\
    \ latency, 5G networks have lower\nlatency, which can be a problem for certain\
    \ IoT applications that require real-time response,\nwhile IoT services may suffer\
    \ from latency due to network congestion, distance from the\nserver, and the number\
    \ of devices connected to the network. Interference is another factor\nthat can\
    \ affect both 5G and IoT services, with both being susceptible to interference\
    \ from\nother wireless devices and environmental factors. Cost is also a concern,\
    \ as the high cost of\n5G infrastructure and services may limit its usefulness\
    \ for many IoT applications, while IoT\nservices may also be expensive to deploy\
    \ and maintain, particularly if they require high\nbandwidth or specialized hardware.\
    \ Finally, compatibility is a potential issue for both 5G\nand IoT services, with\
    \ some IoT devices not being compatible with 5G networks, and IoT\nservices limited\
    \ by compatibility issues with proprietary hardware or software.\nTable 2. Comparison\
    \ of problems presented by 5G and IoT services\nProblem\n5G\nIoT Services\nSecurity\n\
    5G networks are vulnerable to various security threats,\nsuch as DDoS attacks,\
    \ identity theft, and\nman-in-the-middle attacks.\nIoT devices are susceptible\
    \ to security breaches\ndue to poor encryption, weak passwords, and\noutdated\
    \ ﬁrmware.\nLatency\n5G networks have lower latency, which can be a\nproblem for\
    \ certain IoT applications that require\nreal-time response.\nIoT services may\
    \ suffer from latency due to\nnetwork congestion, distance from the server, and\n\
    the number of devices connected to the network.\nInterference\n5G networks can\
    \ experience interference from other\nwireless devices, which can disrupt the\
    \ transmission of\ndata.\nIoT services may also suffer from interference due\n\
    to environmental factors, such as obstacles and\ninterference from other wireless\
    \ devices.\nCost\nThe cost of 5G infrastructure and services may be\nprohibitively\
    \ high for many IoT applications,\nparticularly those that require large-scale\
    \ deployment.\nIoT services may also be expensive to deploy and\nmaintain, particularly\
    \ if they require high\nbandwidth or specialized hardware.\nCompatibility\nSome\
    \ IoT devices may not be compatible with 5G\nnetworks, which can limit their usefulness\
    \ in certain\napplications.\nIoT services may also be limited by compatibility\n\
    issues, particularly if they rely on proprietary\nhardware or software.\n3.8.\
    \ Coexistence of 5G Networks and IoT Applications\nThe coexistence of 5G networks\
    \ and IoT applications has the potential to revolu-\ntionize several industries\
    \ by providing ultra-reliable and low-latency communication,\nmassive machine-type\
    \ communications, and network slicing for multiple services and\napplications\
    \ [18]. One novel idea is the use of 5G networks for industrial automation and\n\
    autonomous vehicles, where ultra-reliable and low-latency communication is critical\
    \ for\nensuring the safety and reliability of the system. Another innovative application\
    \ is the use\nof 5G networks for vehicle-to-everything communication, where autonomous\
    \ vehicles can\nexchange information with other vehicles and infrastructure to\
    \ improve trafﬁc management\nand safety [69]. The use of 5G networks for smart\
    \ cities and agriculture can also be highly\nbeneﬁcial, as it can enable massive\
    \ machine-type communication to support a large number\nof IoT devices, such as\
    \ sensors and actuators, and facilitate data collection, analysis, and\ndecision\
    \ making. Additionally, the use of network slicing can enable multiple services\
    \ and\napplications to coexist on the same infrastructure while maintaining their\
    \ unique require-\nments for security, reliability, and latency. However, the\
    \ coexistence of 5G networks and IoT\napplications also presents several challenges,\
    \ such as security, interference, compatibility,\nand cost [35]. For example,\
    \ security is critical for protecting IoT devices and networks from\ncyber attacks,\
    \ while interference from other wireless devices and environmental factors can\n\
    affect both 5G and IoT services. Moreover, compatibility issues can arise when\
    \ IoT devices\nSensors 2023, 23, 3876\n20 of 41\nare not compatible with 5G networks,\
    \ and the high cost of deploying and maintaining 5G\ninfrastructure and IoT services\
    \ can limit their widespread adoption. Overall, the coexis-\ntence of 5G networks\
    \ and IoT applications presents both opportunities and challenges and\nrequires\
    \ careful consideration of their technical requirements, security, and compatibility\
    \ to\nrealize their full potential.\nTable 3 provides a summary of the coexistence\
    \ of various 5G services and networks\nwith IoT applications. It highlights the\
    \ wireless technology, algorithms used, and coex-\nistence of services with 4G\
    \ and Wi-Fi. The table includes several 5G services, such as\n5G NR, 5G-V2X, 5G\
    \ mMTC, 5G-UHD, 5G-IoT, 5G-eMBB, 5G-URLLC, 5G-mIoT, 5G-gNB,\nand 5G-Slicing, and\
    \ describes their potential applications and system description. The 5G\nservices\
    \ offer different beneﬁts and are designed for speciﬁc applications, such as ultra-\n\
    reliable and low-latency communications for industrial automation, vehicle-to-everything\n\
    communications for trafﬁc management and safety, massive machine-type communications\n\
    for smart cities and agriculture, ultra-high-deﬁnition video communications and\
    \ virtual re-\nality, Internet of Things communications for smart homes and wearables,\
    \ enhanced mobile\nbroadband for high-speed data transfer and streaming, ultra-reliable\
    \ and low-latency com-\nmunications for mission-critical applications, massive\
    \ IoT communications for smart cities\nand agriculture, gigabit-class communications\
    \ for high-speed data transfer and streaming,\nand network slicing for multiple\
    \ services and applications. The table provides a useful\noverview of the coexistence\
    \ of 5G and IoT services and can be helpful in understanding the\npotential beneﬁts\
    \ and challenges of deploying these technologies together.\nTable 3. Coexistence\
    \ of 5G services and networks and Internet of things applications\nService\nWireless\n\
    Technology\nAlgorithms\nUsed\nCoexistence of Services\nApplications and System\
    \ Description\n5G NR [70]\nNR-U\nNOMA\nCoexisting with 4G\nand Wi-Fi\nUltra-reliable\
    \ and low-latency\ncommunications for industrial automation and\nautonomous vehicles\n\
    5G-V2X [71]\nPC5\nOFDMA\nCoexisting with 4G\nand Wi-Fi\nVehicle-to-everything\
    \ communications for trafﬁc\nmanagement and safety\n5G mMTC [72]\nNR-MTC\nNOMA\n\
    Coexisting with 4G\nand Wi-Fi\nMassive machine-type communications for\nsmart\
    \ cities and agriculture\n5G-UHD [73]\nNR-U\nOFDMA\nCoexisting with 4G\nand Wi-Fi\n\
    Ultra-high-deﬁnition video communications and\nvirtual reality\n5G-IoT [74]\n\
    NR-MTC\nNOMA\nCoexisting with 4G\nand Wi-Fi\nInternet of things communications\
    \ for smart\nhomes and wearables\n5G-eMBB [75]\nNR-eMBB\nOFDMA\nCoexisting with\
    \ 4G\nand Wi-Fi\nEnhanced mobile broadband for high-speed data\ntransfer and streaming\n\
    5G-URLLC [76]\nNR-URLLC\nNOMA\nCoexisting with 4G\nand Wi-Fi\nUltra-reliable and\
    \ low-latency communications\nfor mission-critical applications\n5G-mIoT [77]\n\
    NR-mIoT\nNOMA\nCoexisting with 4G\nand Wi-Fi\nMassive IoT communications for smart\
    \ cities\nand agriculture\n5G-gNB [78]\nNR-gNB\nOFDMA\nCoexisting with 4G\nand\
    \ Wi-Fi\nGigabit-class communications for high-speed\ndata transfer and streaming\n\
    5G-Slicing [79]\nNR-Slicing\nNOMA\nCoexisting with 4G\nand Wi-Fi\nNetwork slicing\
    \ for multiple services\nand applications\n3.9. Interference and Network Optimization\
    \ Difﬁculties\nNowadays, with the development of new technologies, networks face\
    \ different chal-\nlenges. Issues such as coverage, latency, availability, and\
    \ accessibility, among others, appear.\nMoreover, taking into account a more profound\
    \ or more centralized point to the character-\nistics of the network, issues such\
    \ as latency, interference, spectrum use according to the\ntechnology being used,\
    \ and others appear.\nSensors 2023, 23, 3876\n21 of 41\nInterference in 5G networks\
    \ can occur due to a variety of factors such as environmental\nconditions, radio\
    \ frequency congestion, and the deployment of too many access points\nin a limited\
    \ area. These issues can cause signal loss or degradation, resulting in poor\n\
    network performance and reduced data transfer rates. Interference in 5G networks\
    \ can\nhave a signiﬁcant impact on IoT devices that rely on a stable and reliable\
    \ connection to\noperate effectively.\nIoT devices are designed to transmit small\
    \ amounts of data over long periods, often\nusing low power and low bandwidth\
    \ networks. The interference in 5G networks can cause\ndelays or interruptions\
    \ in the transmission of data between IoT devices and the cloud-based\nsystems\
    \ they rely on. These disruptions can impact critical functions, such as real-time\n\
    monitoring of environmental conditions, trafﬁc management, and energy consumption.\
    \ In\naddition, interference in 5G networks can result in increased latency, which\
    \ can make it\ndifﬁcult for IoT devices to communicate with each other in a timely\
    \ manner.\nAnother critical aspect of interference in 5G networks is the potential\
    \ for security\nbreaches. As the number of connected devices increases, the risk\
    \ of cyber attacks also\ngrows. Interference in 5G networks can make it easier\
    \ for hackers to gain unauthorized\naccess to IoT devices and the data they transmit.\
    \ This can have serious consequences,\nparticularly for devices that are used\
    \ in critical infrastructure, such as healthcare systems,\npower grids, and transportation\
    \ networks.\nTo mitigate the impact of interference in 5G networks on IoT devices,\
    \ it is essential to\nensure that the network is properly conﬁgured and managed.\
    \ This includes deploying ac-\ncess points strategically to minimize congestion,\
    \ using directional antennas to focus signals\nand reduce interference, and implementing\
    \ security measures to prevent unauthorized\naccess. In addition, new technologies\
    \ such as edge computing and network slicing can help\nto reduce latency and improve\
    \ the reliability of IoT device communication.\nTable 4 outlines some of the main\
    \ types of interference that can impact 5G networks\nand the IoT. Interference\
    \ can occur due to a variety of factors, such as noise, multipath,\nco-channel\
    \ interference, interference from other devices or wireless networks, and jamming.\n\
    One of the key aspects of network performance that interference can affect is\
    \ coverage.\nInterference can reduce the coverage of a wireless network by increasing\
    \ the signal-to-\nnoise ratio (SNR) threshold required for reliable communication.\
    \ When there is noise,\nmultipath, or interference from other wireless networks\
    \ present, signals may not reach as\nfar or penetrate as deeply into buildings,\
    \ resulting in reduced overall coverage. Another\naspect that can be affected\
    \ by interference is latency. Interference can increase latency by\nintroducing\
    \ delays in signal transmission or reception. For instance, multipath interference\n\
    can cause signals to arrive at a receiver at slightly different times, leading\
    \ to signal distortion\nand increased latency. This delay can be particularly\
    \ problematic for real-time applications,\nsuch as gaming or video conferencing.\
    \ Interference can also impact the availability of a\nwireless network. When there\
    \ is co-channel interference or interference from other devices,\nit can cause\
    \ collisions or channel saturation, leading to reduced availability. This can\
    \ result\nin packet loss or connection drops, making it difﬁcult for users to\
    \ access the network and\nresulting in a poor user experience. Access to a wireless\
    \ network can also be affected by\ninterference. Interference can make it harder\
    \ for devices to connect to a network, leading\nto connection failures or reduced\
    \ bandwidth. This can be particularly problematic in\nareas with high device density,\
    \ such as urban environments. Interference can also affect\nmodulation and coding.\
    \ When there is interference present, the quality of the signal can\ndegrade,\
    \ making it more difﬁcult for the receiver to demodulate and decode the signal.\n\
    This can result in errors and reduce the overall throughput of the network.\n\
    Sensors 2023, 23, 3876\n22 of 41\nTable 4. Types of interference that impact 5G\
    \ networks and IoT\nInterference Type\nCoverage\nLatency\nAvailability\nAccess\n\
    Modulation\nCoding\nNoise\nReduced\nIncreased\nReduced\nReduced\nReduced\nReduced\n\
    Multipath\nReduced\nIncreased\nReduced\nReduced\nReduced\nReduced\nInter-cell\
    \ Interference\nReduced\nIncreased\nReduced\nReduced\nReduced\nReduced\nCo-channel\
    \ Interference\nReduced\nIncreased\nReduced\nReduced\nReduced\nReduced\nInterference\
    \ from other devices\nReduced\nIncreased\nReduced\nReduced\nReduced\nReduced\n\
    Jamming\nReduced\nIncreased\nReduced\nReduced\nReduced\nReduced\nInterference\
    \ from other wireless networks\nReduced\nIncreased\nReduced\nReduced\nReduced\n\
    Reduced\n3.9.1. Interference\nOne of the issues highlighted by the development\
    \ of 5G is interference. It should be\nremembered that interference, by deﬁnition,\
    \ is when two electromagnetic waves overlap.\nThis overlapping causes communication\
    \ failures from where the wave is sent to where it is\nreceived. There are two\
    \ types of interference: constructive and destructive. Constructive\ninterference\
    \ occurs when the waves overlap or collide in phase, and this causes the resulting\n\
    wave to have a greater amplitude. Furthermore, destructive interference is when\
    \ there is\nan out-of-phase overlap, where the resultant of this wave will be\
    \ of lower amplitude [80].\nSome networks may be more susceptible to interference\
    \ depending on the type of wave\nthey handle, i.e., the frequency used in the\
    \ electromagnetic spectrum. RF can give this\ninterference, whereas in 5G networks,\
    \ millimeter bands and below 6 GHz bands are used.\nIn addition, it must be taken\
    \ into account that these interferences will continue to grow\nwith the development\
    \ of technology.\nFigure 9 covers various types of interference in wireless communication\
    \ systems in\n5G. Adjacent channel interference occurs when adjacent frequencies\
    \ or channels overlap\ndue to imperfections in ﬁlters or non-linearity in ampliﬁers.\
    \ Inter-cell interference happens\nwhen two users from neighboring cells try to\
    \ use the same frequency band simultaneously\ndue to resource limitation within\
    \ the network. Intra-channel and inter-channel interference\noccur due to physical\
    \ proximity of devices and low power within the macro-cell network,\nrespectively.\
    \ Inter-symbol interference results from signal distortion due to phase or\namplitude\
    \ dispersion in the channel. Inter-carrier occurs due to frequency offsets between\n\
    sub-carriers. Inter-numerology interference arises due to non-orthogonality in\
    \ the system,\ncausing difﬁculties for symbol alignment. Cross-link interference\
    \ occurs when signals\nare transmitted to neighboring cells in different directions\
    \ simultaneously. Inter-beam\ninterference happens due to the use of multi-beam\
    \ antenna systems, causing interference\nfrom adjacent beams. Multi-user interference\
    \ happens when several users try to transmit\ntheir information requests at the\
    \ same time, and MU-MIMO is used to increase the capacity\nand performance of\
    \ wireless broadcasting systems.\nWe must consider that with the evolution of\
    \ higher data rates, we are looking for\nthe implementation in a frequency spectrum\
    \ that is becoming more saturated daily. The\ndevelopment in these frequencies\
    \ makes the operator reuse the same frequencies for\nneighboring cells to save\
    \ spectrum. This development causes high interference between\ncells [81]. In\
    \ addition to these, other interferences also occur within the networks. The\n\
    classiﬁcation of these interferences is as follows:\n•\nAdjacent channel interference:\
    \ Adjacent channel interference is a problem that occurs\nin many devices and\
    \ many frequency ranges. This occurs when an adjacent frequency\nor the adjacent\
    \ channel of the one used by our device overlaps. This problem occurs\nin 5G,\
    \ as in other mobile technologies. This type of interference is mainly caused,\
    \ as\nstated in [82], by an imperfection in the ﬁlters, where they cannot ﬁlter\
    \ the desired\nsignal correctly. These imperfections result in nearby frequencies\
    \ passing into the\npassband. In turn, this occurs because the ampliﬁers are not\
    \ linear.\n•\nIntra-cell and inter-cell interference: Inter-cell interference\
    \ is one of the most signiﬁ-\ncant causes of network performance degradation.\
    \ This occurs when two users from\nneighboring cells attempt to use the same frequency\
    \ band simultaneously. This occurs,\nSensors 2023, 23, 3876\n23 of 41\nas said\
    \ in [83], because of resource limitation within the network, due to the frequency\n\
    reuse factor. In the same way, inter-cell interference is identiﬁed when a Base\
    \ Station\nconnects directly in the close range of another BS, and that is when\
    \ there is a simulta-\nneous transmission in that reuse. A distortion appears\
    \ by the interference that gives\nthe user and other equipment in the same cell.\n\
    •\nIntra-Channel and Inter-Channel interference: Inter-channel interference usually\
    \ oc-\ncurs when there is a low power within the macro-cell network. Then, when\
    \ communi-\ncating, the information is forwarded to the nearest base station.\
    \ When the transmission\nis made, it is completed through fast switching and restricts\
    \ delays and propagation\nlosses. However, this produces intra-channel interference\
    \ that affects the valuable\nsignal. On the other hand, inter-channel interference\
    \ occurs due to the physical prox-\nimity of the devices when two separate frequency\
    \ bands cause interference with each\nother. As these devices operate in close\
    \ range, the transmitter of a high-power signal\ninterferes with the receiver\
    \ of a weak signal. It is important to emphasize that 5G IoT\nnetworks or devices\
    \ with channels in the MHz range are susceptible to this type of\ninterference\
    \ due to the proximity and number of nearby devices. One way to mitigate\nthis\
    \ type of interference is through spatial modulation via MIMO [84].\n•\nInter-Symbol\
    \ Interference: Inter-symbol interference occurs when one or more symbols\ninterfere\
    \ with other symbols. It is caused by phase or amplitude dispersion in the\nchannel,\
    \ resulting in signal distortion. This can be seen in OFDMA, where multipath\n\
    propagation occurs. One study [85] exposed how this type of interference can be\n\
    an excellent challenge for network systems and should be sought to improve the\n\
    efﬁciency of the bandwidth while seeking alternatives in the modulation. This\
    \ is in\norder to counteract this type of interference.\n•\nInter-numerology interference:\
    \ Multiple numerology is a model to provide ﬂexibility\nfor devices in different\
    \ services. For these numerologies, 15, 30, 60, 120, and 240 kHz\nchannels are\
    \ used. They aim to improve performance and signiﬁcant bandwidth.\nAs stated in\
    \ [86], the authors introduce a non-orthogonality in the system, causing\ndifﬁculties\
    \ for symbol alignment in the time domain. When sampling at the same\nfrequency,\
    \ numerology tends to align differently, making synchronization within the\nframe\
    \ difﬁcult. This is known as interference between numerologies.\n•\nCross-Link\
    \ Interference: This interference occurs when signals are transmitted to\nneighboring\
    \ cells in different directions simultaneously, either in time frequency or\n\
    arbitrarily overlapping resources. As mentioned in [87], there are different types\
    \ of\ninterference and different ways in which it occurs. For example, the Base\
    \ Station\nreceives interference from user equipment devices in adjacent cells,\
    \ or a downlink\nuser equipment receives interference from a second database.\n\
    •\nInter Beam Interference: With the high demand for technological services, the\
    \ aim\nhas been to improve spectral efﬁciency and network performance. In trade-offs\
    \ for\nnetworks such as 5G, where the quality and capacity must be high, the solution\
    \ of\nincorporating a multi-beam antenna system such as mMIMO was sought, as explored\n\
    in detail in [88]. This technique identiﬁes the best route to providing optimal\
    \ perfor-\nmance to a user. This approach helps compensate for transmission attenuation\
    \ losses,\nespecially in millimeter-wave communication. In this case, the base\
    \ station generates\nmultiple narrow beams of mainly RF energy in all directions\
    \ of the coverage area. This\ncauses a spatial division of multiple beams, introducing\
    \ interference. Adjacent beams\ncause this interference from the same cell or\
    \ a neighboring cell.\n•\nMulti-user Interference: Multi-user interference is\
    \ due to the industry’s quest for\nhigher data rates in applications and the dramatic\
    \ increase in subscribers to wireless\ncommunications [89]. The techniques used\
    \ for this type of technology are given by MU-\nMIMO, a 5G generation technique\
    \ that helps increase the capacity and performance of\nwireless broadcasting systems.\
    \ Multi-user interference occurs when several users try\nto transmit their information\
    \ requests at the same time.\nSensors 2023, 23, 3876\n24 of 41\nFigure 9. Main\
    \ concepts of interference in 5G.\n3.9.2. Interference in 5G\nThe different classiﬁcations\
    \ of interference have been explored. Now it is sought\nas part of the state of\
    \ the art to understand interference within 5G. The enrichment of\ninterference\
    \ in technologies such as Hetnets, IoT, D2D, Relay Node, and New Radio 5G\nwill\
    \ be sought.\n•\nInterference in Hetnets: Hetnets are 5G heterogeneous networks.\
    \ They aim to pro-\nvide wireless coverage for mobile subscribers and indoor and\
    \ outdoor applications.\nHetnets are multi-tier network systems that deploy small\
    \ cells in populated areas.\nThese cells are characterized by having a short range\
    \ and low power consumption.\nThis network comprises access points, which allow\
    \ high density, improvements in\nnetwork ﬂexibility, and so on [90]. Due to the\
    \ infrastructure and locations for deploy-\ning this type of network, they are\
    \ prone to different types of interference, such as\nintra-cell, inter-cell, and\
    \ adjacency channels. This type of problem is due to its poor\nsystematization\
    \ and organization in its network design. There are types of interference\nwithin\
    \ heterogeneous networks due to their infrastructure or grouping depending\non\
    \ the need to be met. The ﬁrst interference that appears is Co-tier interference.\
    \ This\ntype of interference appears mostly in femtocells, where there is much\
    \ demand for\nhigher data rates. This environment allows coverage, such as low-power\
    \ radio access\npoints, giving various services at home [91]. This type of interference\
    \ is observed\nwhen multiple users reside in the same network tier, where transmission\
    \ occurs over\nadjacent cells within the femtocell. Similar to co-tier, cross-tier\
    \ interference can appear.\nThe difference is that the co-tier is the inter-cell\
    \ interference, and the cross-tier is the\ninterference between the femtocell\
    \ and macro-cells, considering that the femtocell is\ninside the macro-cell [92].\
    \ Last but not least, in [93], channel control interference says\nthat one of\
    \ the most critical factors for channel control is the physical control format\n\
    indicator channel. This channel carries scheduling and synchronization information\n\
    for the uplink and downlink link data channels. As the transport is by physical\
    \ means,\nthis will induce interference.\n•\nInterference in D2D: With the introduction\
    \ of 5G, the best wireless systems have\nconstantly sought a solution that allows\
    \ the best quality of communication. Device-\nto-device networks are one of the\
    \ candidates to be the future of 5G networks. Direct\ncontact between two mobiles\
    \ increases efﬁciency in the spectrum. However, it always\nbrings some challenges,\
    \ in this case dealing with interference. As discussed in the\ndescription of\
    \ Hetnets above, these use a high connectivity capacity thanks to their\nSensors\
    \ 2023, 23, 3876\n25 of 41\nstructure with macro-cell and femtocell. They allow\
    \ good performance [94]. With\nthe introduction of D2D, a cellular network is\
    \ sought that signiﬁcantly improves\nspectral efﬁciency and performance. However,\
    \ some challenges are the need for more\nsecurity that this type of technology\
    \ presents and interference. On the interference\nside, they appear related to\
    \ inter-cell interference. Furthermore, intra-cell may be\nrelated to adjacent\
    \ frequency. Furthermore, we must remember that there are types\nof interference\
    \ typical of D2D nodes, D2D-to-CU interference, and inter-D2D node\ninterference,\
    \ among others.\n•\nInterference in IoT and Smart Cities: We cannot limit our\
    \ minds to just one application\nwhen discussing the Internet of things. However,\
    \ everything from D2D devices and\nV2X to smart homes or buildings is part of\
    \ it. The conception of IoT with 5G has\nevolved in large and small ecosystems.\
    \ IoT in some applications is used over the\nunlicensed ISM band, which is used\
    \ for various physical devices to properly leverage\nthe spectrum to adhere to\
    \ the conditions and regulations of short radio communication.\nThe Internet of\
    \ Things has been seen as the other great leap in the evolution of the\nInternet.\
    \ With this in mind, developing smart cities will help create a more sustainable\n\
    and cost-efﬁcient ecosystem [95]. The combination of technologies such as 5G,\
    \ IoT,\nand others will enable big data, offering complex services to the community,\
    \ adding\nmembers in smart cities, and ensuring compatibility. However, it should\
    \ be noted\nthat interference must be characterized. When talking about smart\
    \ cities using Wi-Fi\nbecause of the use of the millimeter band, physical obstacles\
    \ such as walls are things\nto keep in mind, in addition to channel overlapping\
    \ and inter-carrier interference [96].\n3.9.3. Optimization Challenges in 5G Networks\n\
    5G is presented as a developed environment with an ecosystem where the boundaries\n\
    are complete cities. 5G technologies promise high-speed and low-latency data transmission\n\
    using the millimeter band. Although this frequency band allows these advantages,\
    \ it only\nallows short distances. By allowing such short distances, problems\
    \ such as interference\nbecome apparent. The optimization of this type of network\
    \ should always be used to\nget the best out of it. In 5G, techniques such as\
    \ MIMO and beamforming are used to\nreduce interference or signal degradation\
    \ [90]. It should be noted that optimizations for\n5G networks include different\
    \ architectures that are part of this type of network. These\narchitectures can\
    \ be divided into non-standalone and standalone.\nOptimizing these architectures,\
    \ depending on their niche, can be proﬁtable, as the\ncommunication varies. Communication\
    \ can be more accessible or restricted depending\non the architecture. At the\
    \ same time, different modulations can be obtained to enhance\ndata transmission,\
    \ transmission speed, and latency. In the same way, with 5G, most of the\narchitectures\
    \ allow the incorporation of MIMO. Thanks to beamforming management, it is\npossible\
    \ to optimize the use of frequencies for transmission so that some technologies\
    \ can\nsend information in the mmWaves range.\nFrom interference in the case of\
    \ NR, other interferences negatively affect the data\ntransmission in this architecture\
    \ due to the nature of this architecture. These are inter-\ncarrier interference\
    \ and phase interference. This is because it uses the mmWave frequency\nrange.\
    \ In turn, another interference that damages NR is numerology interference [97].\n\
    The evolution of mobile networks from 3G to 4G and now to 5G has signiﬁcantly\n\
    impacted the services and Internet of Things devices. Each new generation has\
    \ provided\nfaster data transfer speeds, increased bandwidth, and improved reliability,\
    \ enabling the\nemergence of new services and applications that were previously\
    \ not possible on mobile\ndevices. As 5G networks become more widely adopted,\
    \ they will continue to unlock new\nopportunities for innovation, transforming\
    \ the way we interact with our devices and the\nworld around us.\nTable 5 shows\
    \ the impact of each mobile generation starting with 3G and explains the\nimpact\
    \ in an IoT context.\nSensors 2023, 23, 3876\n26 of 41\nTable 5. Mobile generations\
    \ and IoT.\nYear\nTechnology\nImpact in IoT\n2000\n3G allows devices to\nconnect\
    \ to the internet since\n3G enables mobile and\nwireless internet\nconnections.\n\
    With internet connections, electronic\ndevices start transmitting data through\n\
    the internet, the ﬁrst step to developing\nIoT devices.\n2008\n4G enables cloud\n\
    computing technology and\ntransmits information with\nthe IP protocol. In addition,\n\
    4G increased the bandwidth\nof each transmission.\nThe data transmission through\
    \ IP protocol\nenables an easy communication method with\nelectronic devices.\
    \ The cloud enables a way to\ndevelop more affordable solutions.\nFurthermore,\
    \ the internet connection cost\ndecreases because 4G delivers a cheap way to\n\
    transmit data as IP protocols manage the data\nmore efﬁciently. This generation\
    \ is the most\nimportant in an IoT context because the\nindustry has all the resources\
    \ to connect\ndevices to the cloud.\n2019\nWith 5G, an essential\nfeature is the\
    \ beam width,\nan important key in the IoT\ncontext.\nIf we have more bandwidth,\
    \ we can provide\nbetter solutions, such as real-time monitoring\nsystems. In\
    \ our society, these solutions are\nvital if we want to automate processes. For\n\
    this reason, 5G plays an essential role in the\nIoT context because the industry\
    \ is trying to\nautomate all its processes.\nNew technologies and recent research\
    \ about wireless communication have created\nnew ways to transmit and receive\
    \ data. With the evolution of technology such as 5G, new\nfeatures arrived to\
    \ provide/perform the ways to send and receive data. IoT has shown\nmore beneﬁts,\
    \ helping with other technologies such as machine learning, cloud computing,\n\
    and others. Since the data can be processed, each device forms a swarm intelligence\
    \ that\nallows automatization and avoids wasting resources in the industry.\n\
    Another factor in analyzing is the interference with the channels, since our houses,\n\
    ofﬁces, and even natural places have electronic devices that typically use the\
    \ 2.4 GHz band,\nwhich causes interference in this band. Therefore, 5G incorporates\
    \ new bands to avoid\nthe interference caused by this massive consumption of 2.4\
    \ GHz. We need to compare\nthe features of 3G, 4G, and 5G to understand why 5G\
    \ is an essential key in smart cities.\nThe main technical characteristics of\
    \ these three generations of technologies can be seen in\nTable 6.\nTable 6. Important\
    \ Features in 3G, 4G, and 5G.\n``````````\nFeature\nGeneration\n3G\n4G\n5G\nStandard\n\
    WCDMA, CDMA2000\nOFDMA, MC-CDMA\nCDMA, BDMA\nData rate\n2 Mbps\n2 Mbps–1 Gbps\n\
    1 Gbps and higher\nFrequency\n1.8–2.5 GHz\n2–8 GHz\n3–300 GHz\nCore type network\n\
    Packet network\nAll IP network\nIP network and 5G-NI\nTable 7 presents the expectations\
    \ for the use of 5G technology in the IoT. The ﬁrst\nfeature mentioned is bandwidth.\
    \ Bandwidth refers to the amount of data that can be\ntransmitted over a network\
    \ or a communication channel in a given amount of time. In\nthe context of 5G,\
    \ higher bandwidth means that more data can be transmitted over the\nairwaves\
    \ in a shorter period of time, which can result in faster and more reliable 5G\n\
    Sensors 2023, 23, 3876\n27 of 41\ntransmissions. Another feature highlighted is\
    \ artiﬁcial intelligence, which can analyze\nall the data generated by the IoT\
    \ devices to take accurate decisions. With the use of AI,\nIoT devices can identify\
    \ patterns, make predictions, and take actions based on the data\ngathered. This\
    \ feature is essential to support IoT applications that require real-time decision\n\
    making, such as smart cities and intelligent transportation systems. The third\
    \ feature is\nreal-time monitoring and management, which means the capability\
    \ to monitor and manage\nelectronic devices. This feature allows IoT devices to\
    \ be monitored and managed from a\ncentral location, which can be very useful\
    \ for large-scale applications, such as industrial\nautomation or smart grid management.\
    \ Swarm intelligence is another feature mentioned,\nwhich means that each IoT\
    \ device can be a node and work with other nodes to create a\nswarm intelligence.\
    \ This feature enables IoT devices to work collaboratively and efﬁciently,\nproviding\
    \ better performance and reliability in complex applications. Quality of service\n\
    (QoS) is also listed as a signiﬁcant feature that 5G can provide in IoT connections.\
    \ With\n5G, IoT devices can experience better connectivity, lower latency, and\
    \ higher throughput,\nwhich can improve the overall QoS and performance of IoT\
    \ applications. In the context\nof IoT connections, QoS refers to the ability\
    \ of the network to provide reliable and high-\nperformance connectivity to IoT\
    \ devices. 5G is a promising technology for IoT connections,\nas it can provide\
    \ several features that can improve the overall QoS and performance of IoT\napplications.\
    \ 5G is designed to provide a signiﬁcantly improved QoS compared to previous\n\
    generations of mobile networks. This is achieved through a combination of advanced\n\
    technologies and features that are built into the 5G standard. One of the key\
    \ features of\n5G that can contribute to a better QoS is the use of advanced radio\
    \ access technologies.\nThese technologies, such as massive MIMO and beamforming,\
    \ allow for more efﬁcient\nuse of the radio spectrum and better signal quality.\
    \ This means that 5G can provide better\nconnectivity and signal strength, which\
    \ can improve the reliability and availability of the\nnetwork. Another important\
    \ feature of 5G that can contribute to a better QoS is the use of\nnetwork slicing.\
    \ Network slicing allows the network to be divided into multiple virtual\nnetworks,\
    \ each tailored to speciﬁc use cases and requirements. This means that different\n\
    applications and services can be given different levels of priority, bandwidth,\
    \ and latency\nrequirements, depending on their needs. This can improve the QoS\
    \ for each individual\napplication and user. In addition, 5G can provide lower\
    \ latency, higher throughput, and\nbetter support for massive IoT deployments,\
    \ all of which can contribute to a better QoS.\nLower latency means that there\
    \ is less delay between the transmission of data and its\nreception, which can\
    \ enable real-time communication and faster response times. Higher\nthroughput\
    \ means that more data can be transmitted over the network in a given time,\n\
    which can improve the performance of applications that require high-bandwidth\
    \ data\ntransfer. Finally, better support for massive IoT deployments means that\
    \ the network can\nhandle a large number of connected devices and data trafﬁc,\
    \ without compromising the\nQoS for individual devices or applications.\nLow latency\
    \ is another feature that 5G can offer, reducing the delay between data\ntransmission\
    \ and reception. This feature is particularly important for applications that\n\
    require immediate decision making, such as autonomous vehicles or remote surgery.\
    \ Cloud\ncomputing is mentioned as a feature that 5G can provide in IoT connections.\
    \ With 5G, IoT\ndevices can connect to the cloud more efﬁciently, and each device\
    \ can use all the resources\nof the cloud, such as storage and processing power.\
    \ This feature can signiﬁcantly improve\nthe performance and scalability of IoT\
    \ applications, especially those that require large\namounts of data processing\
    \ and storage.\nLow latency is particularly important for applications that require\
    \ immediate decision\nmaking, such as autonomous vehicles or remote surgery. With\
    \ 5G, the latency can be\nreduced to as low as one millisecond, which can enable\
    \ real-time communication and\nfaster response times. Furthermore, 5G can provide\
    \ higher throughput, which refers to\nthe amount of data that can be transmitted\
    \ over a network in a given time. With higher\nthroughput, IoT devices can transmit\
    \ and receive larger amounts of data, which can\nimprove the performance of IoT\
    \ applications that require high-bandwidth data transfer,\nSensors 2023, 23, 3876\n\
    28 of 41\nsuch as video streaming or real-time sensor data. Cloud computing is\
    \ another feature\nthat 5G can offer for IoT connections. With 5G, IoT devices\
    \ can connect to the cloud more\nefﬁciently, and each device can use all the resources\
    \ of the cloud, such as storage and\nprocessing power. This feature can signiﬁcantly\
    \ improve the performance and scalability of\nIoT applications, especially those\
    \ that require large amounts of data processing and storage.\nTable 7. Expectation\
    \ for 5G in IoT.\nFeature\nDescription\nBandwidth\nMore bandwidth to supply applications\
    \ with\nhigh speed.\nAI\nArtiﬁcial intelligence can analyze all the data\ngenerated\
    \ by the IoT devices to take accurate\ndecisions.\nReal-time monitoring and\n\
    management\nThe capability to monitor and manage electronic\ndevices remotely.\n\
    Swarm intelligence\nEach IoT device can be a node, and working with\nother nodes,\
    \ can work as a swarm intelligence.\nQoS\n5G can provide a better QoS in IoT connections.\n\
    Low Latency\n5G reduces the latency, which means that the IoT\ndevices can take\
    \ immediate decisions.\nCloud computing\n5G can provide better connections to\
    \ the cloud,\nwhich means each IoT device can use all the\nresources of the cloud.\n\
    Since smart cities use IoT devices to provide a solution in our daily routine,\
    \ 5G is\nessential in providing a more stable, scalable, and accurate solution,\
    \ with help from other\ntechnologies, such as cloud computing, machine learning,\
    \ and so on. In other words, 5G is\nkey in smart cities because this generation\
    \ optimizes how to transmit and receive data and\nperforms the way to obtain data.\
    \ Based on these data, electronic devices can make accurate\ndecisions after processing.\n\
    Table 8 was divided into parts, in which the ﬁrst part deals exclusively with\
    \ the\ndescription and impact on 5G, and the second part describes cases and ways\
    \ to prevent\nthis interference.\nTable 8. Technologies for the elderly\nInterference\n\
    Description\n5G Impact\nAdjacent Channel\nInterference\nThis occurs when the frequency\
    \ channel of\nour device is overlapped.\nIf we do not have good bandpass ﬁlters,\
    \ there\nwill be interference from nearby frequencies. In\n5G devices, this can\
    \ have a signiﬁcant impact.\nIntra-cell and\ninter-cell\ninterference\nInter-cell\
    \ interference occurs when two\nusers in neighboring cells attempt to use\nthe\
    \ same frequency simultaneously.\nIntra-cell interference occurs when there is\n\
    a simultaneous short-range transmission\nby two BSs, with distortion from the\
    \ user\nand the other equipment in the same cell.\nThis type of interference can\
    \ severely damage 5G\nnetworks because for bases or architectures\nwhere there\
    \ are micro- or macro-cells, the power\nof neighboring signals in both uplink\
    \ and\ndownlink transmission by multiple users can\ninterfere with each other\
    \ [98].\nSensors 2023, 23, 3876\n29 of 41\nTable 8. Cont.\nInterference\nDescription\n\
    5G Impact\nIntra-Channel and\nInter-Channel\ninterference\nIntra-channel interference\
    \ occurs when\nthere is little power within the macro\nnetwork cell.\nInter-channel\
    \ interference occurs due to the\nproximity of devices when two separate\nfrequencies\
    \ cause interference. As they operate\nat short range, the transmitter of a high-power\n\
    signal causes interference; interference can also\nbe due to the exploration of\
    \ hetnets with OFDM.\nThere are ICI reduction solutions with reverse\nfrequency\
    \ allocation (RFA) employed, which is a\nproactive interference.\nInter-Symbol\n\
    interference\nThis type of interference occurs when one\nor more symbols interfere\
    \ with other\nsymbols.\nIt is caused by phase or amplitude dispersion of\nthe\
    \ channel, which results in signal distortion.\nThis can be clearly seen in OFDMA,\
    \ which\ncauses multipath propagation and impacts\nbandwidth efﬁciency.\nInter-Numerology\n\
    interference\nOccurs when using the numerology system\nfor greater ﬂexibility\
    \ and does not allow\nthe alignment in the time domain to be\nperfect. These misalignments\
    \ or\nimperfections are known as\ninter-numerology interference.\nIn the search\
    \ for higher performance and\nsigniﬁcant bandwidth, using numerology, can\ncause\
    \ interference by having networks with\nmany devices sending signiﬁcant amounts\
    \ of\ninformation, which makes this type of\ninterference more pronounced, affecting\
    \ the\nnetwork’s performance.\nCross-Link\nInterference\nThis type of interference\
    \ occurs when a\ntransmission is made to a neighboring cell\nin different directions\
    \ simultaneously,\neither by arbitrarily overlapping resources\nor by time frequency.\n\
    Cross-link interference can affect 5G networks\ndue to the amount of BS required,\
    \ since incorrect\nhopping can cause performance failures.\nInter-Beam\ninterference\
    \ [99]\nThis occurs when using MIMO technology,\nas this type of array sends RF\
    \ energy in all\ndirections, with the spatial division of the\nmultiple beams\
    \ causing interference.\nAdjacent beams cause this either by the\nsame cell or\
    \ by neighboring cells.\nIt causes interference in applications where\nMIMO antenna\
    \ technology is introduced due to\nthe same usage. When looking for better spectral\n\
    efﬁciency and improvements in network\nperformance, interference from adjacent\
    \ beams\nwithin the same cell or multiple MIMO arrays\nmay negatively inﬂuence\
    \ their neighbors.\nMulti-User\ninterference [100]\nThis occurs when, in MU-MIMO,\
    \ multiple\nusers try to transmit information\nsimultaneously.\nConsidering that\
    \ in 5G, performance and\ninformation forwarding improvements are\nsought, when\
    \ switching to MU-MIMO,\nuncoordinated cells encounter more signiﬁcant\nproblems\
    \ during user management.\nAdjacent Channel\nInterference\nThis occurs when the\
    \ frequency channel of\nthe device is overlapped.\nIf we do not have good bandpass\
    \ ﬁlters, there\nwill be interference from nearby frequencies. In\n5G devices,\
    \ this can have a signiﬁcant impact.\nIt is pertinent to consider how this type\
    \ of interference can affect or impact 5G networks\ntoday, since it must be kept\
    \ in mind with the explosive development of technology. In turn,\nthis can affect\
    \ different 5G architectures, since the main objectives of these networks are\
    \ to\nimprove things such as latency, throughput, transmission speeds, etc.\n\
    Table 9 provides an overview of different types of interference that can occur\
    \ in 5G net-\nworks and their potential impacts on network performance. Adjacent\
    \ Channel Interference\noccurs when the frequency channel of our device is overlapped\
    \ with nearby frequencies,\nleading to interference. Intra-cell and inter-cell\
    \ interference occurs when multiple users\nSensors 2023, 23, 3876\n30 of 41\n\
    in neighboring cells attempt to use the same frequency simultaneously or when\
    \ there is a\nsimultaneous short-range transmission by two base stations in the\
    \ same cell. This type of\ninterference can severely damage 5G networks, particularly\
    \ in architectures where there\nare micro- or macro-cells. Intra-channel and inter-channel\
    \ interference occurs when there\nis little power within the macro network cell,\
    \ though inter-channel interference can also\noccur due to the proximity of devices\
    \ operating at different frequencies. Inter-Symbol inter-\nference occurs when\
    \ one or more symbols interfere with other symbols, resulting in signal\ndistortion\
    \ due to phase or amplitude dispersion of the channel. Inter-Carrier interference\n\
    occurs when the signal is lost due to an offset between the subcarriers, leading\
    \ to large-scale\nor small-scale fading and variations in the received signal.\
    \ Inter-Numerology interference\noccurs when using the numerology system for greater\
    \ ﬂexibility, leading to misalignments\nor imperfections known as inter-numerology\
    \ interference. Cross-Link Interference occurs\nwhen a transmission is made to\
    \ a neighboring cell in different directions simultaneously,\nleading to performance\
    \ failures. Inter-Beam interference occurs when using MIMO tech-\nnology, with\
    \ the spatial division of the multiple beams causing interference from adjacent\n\
    beams either by the same cell or by neighboring cells. Finally, Multi-User interference\n\
    occurs when multiple users try to transmit information simultaneously, leading\
    \ to problems\nduring user management in uncoordinated cells.\nTable 9. Interference\
    \ and its impact on 5G networks.\nInterference Type\nDescription\nImpact on 5G\n\
    Networks (✓yes,\n× is no\nAdjacent Channel\nFrequency channel overlap\n✓\nIntra-cell\
    \ and inter-cell\nSimultaneous transmission in\nneighboring cells\n×\nIntra-Channel\
    \ and\ninter-Channel\nLow power in the macro\nnetwork cell\n✓\nInter-Symbol\n\
    Interference between symbols\n×\nInter-Carrier\nSignal loss due to subcarrier\
    \ offset\n×\nInter-Numerology\nMisalignments in the\nnumerology system\n×\nCross-Link\n\
    Overlapping transmissions to\nneighboring cells\n×\nInter-Beam\nInterference from\
    \ adjacent beams\nin MIMO\n×\nMulti-User\nSimultaneous transmission from\nmultiple\
    \ users\n×\n4. Results and Discussions\nIn recent years, the deployment of 5G\
    \ networks has gained signiﬁcant attention due\nto its potential to revolutionize\
    \ the communication industry. One of the areas where 5G\nnetworks are expected\
    \ to have a substantial impact is the IoT services. This literature\nreview article\
    \ aims to provide an in-depth analysis of the impact of 5G networks on IoT\nservices,\
    \ speciﬁcally examining the issue of interference in this type of network and\
    \ its\nrelated technologies.\nAs a result of new technologies in mobile communications,\
    \ 5G can provide a solution\nin a smart city context. Each IoT device can consume\
    \ a reduced bandwidth, but the problem\narises when the number of IoT devices\
    \ increases. For this reason, it is essential to provide\nhigh beam width for\
    \ better communication between IoT devices.\nSensors 2023, 23, 3876\n31 of 41\n\
    The emergence of 5G networks and Internet of Things services has brought about\n\
    a new era of connectivity and transformation to various industries. With the increasing\n\
    number of connected devices, there is a need for a network that can handle the\
    \ massive\ndata transfer, low latency, and high-speed communication required by\
    \ IoT devices. The\nconvergence of 5G networks and IoT services is expected to\
    \ revolutionize the way devices\ncommunicate with each other and the internet.\
    \ In this section, we will critically discuss the\nrelated impact of network and\
    \ service convergence between 5G networks and IoT services.\nOne of the main beneﬁts\
    \ of the convergence of 5G networks and IoT services is the\nability to support\
    \ massive machine-to-machine communication. The integration of 5G\nnetworks with\
    \ IoT devices creates a seamless connection, allowing devices to communicate\n\
    with each other and the internet at high speeds and low latency. This has signiﬁcant\n\
    implications for industries such as healthcare, transportation, and manufacturing,\
    \ where\nlarge volumes of data need to be transmitted in real time to enable efﬁcient\
    \ operations. For\ninstance, connected cars, trains, and airplanes can communicate\
    \ with each other and other\nconnected devices in real time, leading to improved\
    \ safety and efﬁciency.\nAnother impact of the convergence of 5G networks and\
    \ IoT services is the creation\nof new business models and revenue streams. With\
    \ the increased speed and capacity of\n5G networks, service providers can offer\
    \ new IoT services such as smart homes, smart\ncities, and smart factories. This\
    \ creates an opportunity for service providers to develop new\nbusiness models\
    \ and revenue streams, such as selling data insights, providing managed\nservices,\
    \ and offering customized solutions. For example, telecom operators can offer\n\
    IoT connectivity as a service, which provides businesses with a cost-effective\
    \ and scalable\nmethod to connect and manage their IoT devices.\nHowever, the\
    \ convergence of 5G networks and IoT services also presents some chal-\nlenges\
    \ that need to be addressed. One of the challenges is the issue of security and\
    \ privacy.\nAs the number of connected devices grows, the potential for cyberattacks\
    \ and data breaches\nalso increases. Therefore, service providers and device manufacturers\
    \ need to work to-\ngether to ensure that IoT devices are secure and comply with\
    \ data protection regulations.\nAdditionally, the convergence of 5G networks and\
    \ IoT services requires signiﬁcant invest-\nments in infrastructure and technology.\
    \ Service providers need to deploy a massive number\nof 5G base stations to enable\
    \ reliable and consistent connectivity for IoT devices.\nThe convergence of 5G\
    \ networks and IoT services has the potential to revolutionize the\nway devices\
    \ communicate with each other and the internet. It has signiﬁcant implications\n\
    for industries such as healthcare, transportation, and manufacturing, creating\
    \ new business\nmodels and revenue streams. However, it also presents challenges\
    \ such as security and\nprivacy concerns and the need for signiﬁcant investments\
    \ in infrastructure and technology.\nTherefore, service providers and device manufacturers\
    \ need to work together to address\nthese challenges and ensure that the convergence\
    \ of 5G networks and IoT services leads to\na safer, more efﬁcient, and connected\
    \ world.\nTable 10 discusses the potential positive and negative impacts of integrating\
    \ 5G\ntechnologies with IoT solutions. The table is divided into three columns,\
    \ including Category,\nContext, and Explanation.\nThe ﬁrst category mentioned\
    \ in the table is Positive, which includes three different\ncontexts. The ﬁrst\
    \ context is Cost Optimization, which refers to the potential cost savings\nassociated\
    \ with integrating 5G technologies with IoT solutions. With the help of data\n\
    gathered by devices, businesses and organizations can optimize their processes,\
    \ leading to\nmore cost-effective solutions. Additionally, data-driven decision\
    \ making allows private\nor public entities to make better decisions. For instance,\
    \ a city can use IoT solutions to\noptimize trafﬁc ﬂow, leading to reduced fuel\
    \ consumption and fewer trafﬁc jams.\nThe second context mentioned in the Positive\
    \ category is Improving QoS, which refers\nto the potential improvement in the\
    \ quality of life for citizens. By providing relevant\ninformation and real-time\
    \ control over public infrastructure, cities can positively impact\ncitizens’\
    \ lives. For example, using IoT solutions, a city can improve security by monitoring\n\
    Sensors 2023, 23, 3876\n32 of 41\npublic spaces and providing real-time alerts\
    \ in case of emergencies. Additionally, cities can\ncreate new economic development\
    \ opportunities fueled by the digitalization era.\nThe third context mentioned\
    \ in the Positive category is Reducing climate change. By\nimplementing IoT solutions\
    \ with 5G technologies, businesses can have closer control over\nindustrial processes\
    \ and real-time analytics regarding relevant environmental properties.\nThis can\
    \ be the next step in becoming a more environmentally friendly society.\nMoving\
    \ onto the Negative category, the table mentions two different contexts. The\n\
    ﬁrst context is Digital Non-Inclusion, which refers to the potential negative\
    \ impact of IoT\nsolutions on regions with less access to technological services,\
    \ while 5G and IoT efforts\ncan improve the quality of life of those cities that\
    \ can afford it, they currently do not offer\ncost-effective solutions for regions\
    \ with less access to technological services.\nThe second context mentioned in\
    \ the Negative category is privacy compromises.\nHaving real-time information\
    \ on assets, people, and any living or non-living organism\nin a region can seriously\
    \ threaten privacy violations. Political or social movements can\nnegatively use\
    \ sensible data related to citizens to perform any action.\nTable 10. Explanation\
    \ of the positive or negative impact in 5G and IoT.\nCategory\nContext\nExplanation\n\
    Positive\nCost\nOptimization\nIntegrating 5G technologies with IoT solutions will\n\
    allow for more cost-effective solutions when 5G\ntechnologies reach the mainstream\
    \ market. Optimizing\nprocesses with the data gathered by the devices will\nallow\
    \ for data-driven decision making, allowing\nprivate or public entities to make\
    \ better decisions.\nPositive\nImproving\nQoS\nBy providing relevant information\
    \ and real-time\ncontrol over public infrastructure, citizens will be\npositively\
    \ impacted by reduced trafﬁc, improved\nsecurity, and new economic development\n\
    opportunities fueled by the digitalization era.\nPositive\nReducing\nclimate change\n\
    Having closer control over industrial processes and\nreal-time analytics regarding\
    \ relevant environmental\nproperties, implementing IoT solutions with 5G\ntechnologies\
    \ can be the next step in becoming a more\nenvironmentally friendly society.\n\
    Negative\nDigital\nNon-Inclusion\nWhile 5G and IoT efforts can improve the quality\
    \ of\nlife of those cities that can afford it, they currently do\nnot offer cost-effective\
    \ solutions for regions with less\naccess to technological services.\nNegative\n\
    Privacy\ncompromises\nHaving real-time information on assets, people, and\nany\
    \ living or non-living organism in a region can\nseriously threaten privacy violations.\
    \ Political or social\nmovements can negatively use sensible data related to\n\
    citizens to perform any action.\nFigure 10 discusses the main challenges on 5G\
    \ networks. One of the main challenges\nof 5G networks related to interference,\
    \ IoT devices, and network optimization is the high\ndemand for wireless connectivity\
    \ and data transmission. With the increasing number of\nIoT devices and the exponential\
    \ growth of data usage, 5G networks must be optimized\nto handle the massive amount\
    \ of data transmission while minimizing interference. The\ndeployment of small\
    \ cells and heterogeneous networks is one strategy to increase net-\nwork capacity\
    \ and reduce interference. However, the complexity of network planning,\ndeployment,\
    \ and management increases with the deployment of small cells, which requires\n\
    sophisticated optimization techniques. Additionally, the development of 5G IoT\
    \ devices\nSensors 2023, 23, 3876\n33 of 41\nwith limited power and processing\
    \ capabilities also presents a challenge. The design of\nlow-power wireless communication\
    \ protocols and efﬁcient resource allocation techniques\nis necessary to optimize\
    \ the performance of IoT devices in 5G networks. 5G networks’\nchallenges related\
    \ to interference, IoT devices, and network optimization require advanced\nsolutions\
    \ and innovative technologies to ensure high-quality wireless connectivity and\n\
    meet the demands of the growing digital ecosystem.\nFigure 10. Challenges of 5G\
    \ networks.\nTable 11 is a representation of the future research challenges in\
    \ 5G that are directly\nrelated to IoT services. It is a ﬁve-column table with\
    \ the following labels for each column:\nFeatures, Advantages, Research Challenges,\
    \ Key Requirements, and Interoperability. The\nFeatures column lists the main\
    \ features that are relevant for IoT services in 5G. In this table,\nthe features\
    \ are IoT Services, Edge Computing, 5G Radio Access, and Network Slicing. The\n\
    Advantages column lists the advantages that 5G can provide to IoT services, for\
    \ example,\nenabling new use cases, reducing latency, providing high data rates,\
    \ and providing cus-\ntomizable networks. The Research Challenges column lists\
    \ the key research challenges that\nneed to be addressed in order to fully realize\
    \ the potential of 5G for IoT services, for exam-\nple, network slicing, security,\
    \ scalability, resource allocation, and spectrum management.\nThe Key Requirements\
    \ column lists the key technical requirements that need to be met in\norder to\
    \ address the research challenges, for example, low latency, high reliability,\
    \ energy\nefﬁciency, and service level agreements. The Interoperability column\
    \ lists the key interoper-\nability issues that need to be addressed in order\
    \ to ensure that different 5G networks and\nIoT devices can work together seamlessly,\
    \ for example, standardization, integration with\nexisting systems, compatibility\
    \ with different technologies, and interoperability between\nnetwork slices.\n\
    Interference can have a signiﬁcant impact on 5G networks, particularly in the\
    \ context\nof Internet of Things (IoT) devices. The large number of IoT devices\
    \ that will be connected\nto 5G networks will inevitably lead to increased interference,\
    \ which can result in degraded\nnetwork performance and poor user experience.\n\
    One of the critical responses to interference in 5G networks is to employ advanced\n\
    signal processing techniques to mitigate the effects of interference. For example,\
    \ beam-\nforming and advanced receiver algorithms can help to reduce interference\
    \ on 5G networks.\nAdditionally, the use of multi-antenna systems and smart antennas\
    \ can improve the quality\nof the received signal and reduce interference.\nAnother\
    \ critical response is to implement interference management protocols that\nenable\
    \ the efﬁcient use of available radio resources. These protocols can help to coordinate\n\
    the use of different channels, reduce interference between neighboring cells,\
    \ and optimize\nthe use of spectrum resources.\nFor instance, the use of small\
    \ cell networks can help to reduce interference by reduc-\ning the distance between\
    \ the transmitter and receiver. In addition, the use of frequency\nSensors 2023,\
    \ 23, 3876\n34 of 41\nreuse techniques, such as fractional frequency reuse, can\
    \ help to mitigate the impact of\ninterference in multi-cell networks.\nTable\
    \ 11. Future research challenges in 5G related to IoT services.\nFeatures\nAdvantages\n\
    Research\nChallenges\nKey Requirements\nInteroperability\nIoT\nServices\nEnables\
    \ new\nuse cases\nNetwork slicing\nLow latency\nStandardization\nSecurity\nHigh\
    \ reliability\nIntegration with existing systems\nScalability\nMassive machine-type\n\
    communication\nCompatibility with different\ntechnologies\nEdge\nComputing\nReduced\n\
    latency\nResource allocation\nEnergy efﬁciency\nInteroperability with\ncloud services\n\
    Edge intelligence\nResource management\nSecurity\nEdge analytics\nQoS management\n\
    Integration with network slicing\n5G Radio\nAccess\nHigh data rates\nSpectrum\n\
    management\nLow power consumption\nCompatibility with legacy systems\nMulti-connectivity\n\
    Interference management\nNetwork densiﬁcation\nmmWave\ncommunications\nCoverage\n\
    Integration with edge computing\nNetwork\nSlicing\nCustomizable\nnetworks\nOrchestration\n\
    Service level agreements\nInteroperability between slices\nResource allocation\n\
    Isolation\nScalability\nQoS management\nSecurity\nIntegration with existing networks\n\
    Table 12 summarizes the future research challenges in 5G for IoT services. The\
    \ ﬁrst\nitem, Issues, describes the main challenges faced in the implementation\
    \ of 5G for IoT\nservices. The ﬁve issues identiﬁed in the table are Interference,\
    \ Security, Energy Efﬁciency,\nScalability, and Latency. The item Methodologies\
    \ presents the proposed techniques or\nmethods to address the identiﬁed issues.\
    \ For example, DSA and Cooperative Sensing are\nproposed to address the Interference\
    \ issue. Similarly, Authentication and Encryption are\nproposed to address the\
    \ Security issue. The table provides a list of techniques for each of\nthe identiﬁed\
    \ issues. The item Advantages describes the potential beneﬁts of using the\nproposed\
    \ methodologies. For instance, the use of DSA and Cooperative Sensing can lead\n\
    to better spectrum utilization and increased reliability. Similarly, using authentication\
    \ and\nencryption can provide secure communication and protect against attacks.\
    \ The item Limi-\ntations/Future Work describes the challenges or limitations\
    \ of the proposed methodologies\nand highlights the areas that need further research.\
    \ For example, the table highlights\nthe need for developing efﬁcient and scalable\
    \ DSA and cooperative sensing algorithms\nto address the Interference issue. Similarly,\
    \ developing lightweight and energy-efﬁcient\nsecurity mechanisms is identiﬁed\
    \ as future work to address the Security issue.\nTable 13 includes several types\
    \ of interference that affect 5G networks and IoT ser-\nvices. These include atmospheric\
    \ absorption, free space path loss, reﬂection, refraction,\ndiffraction, scattering,\
    \ rain fade, multipath fading, co-channel interference, adjacent chan-\nnel interference,\
    \ and interference from other radios and IoT devices. The table provides\ntechnical\
    \ details about the frequency range, bandwidth, power level, and impact of each\n\
    interference type.\n•\nInterference: The type of interference that affects 5G\
    \ networks and IoT services.\n•\nFrequency: The frequency range in which the interference\
    \ occurs.\n•\nBandwidth: The bandwidth of the interference.\n•\nPower: The power\
    \ level of the interference.\n•\nImpact: The effect of the interference on 5G\
    \ networks and IoT services.\nSensors 2023, 23, 3876\n35 of 41\nTable 12. Future\
    \ research challenges in 5G for IoT services.\nIssues\nMethodologies\nAdvantages\n\
    Limitations/Future Work\nInterference\nDynamic Spectrum\nAccess, cooperative\n\
    Sensing\nBetter spectrum\nutilization,\nincreased reliability\nDeveloping efﬁcient\
    \ and\nscalable DSA (Dynamic\nSpectrum Access) and\ncooperative sensing\nalgorithms\n\
    Security\nAuthentication,\nencryption\nSecure\ncommunication,\nprotecting against\n\
    attacks\nDeveloping lightweight\nand energy-efﬁcient\nsecurity mechanisms\nEnergy\n\
    Efﬁciency\nPower\nmanagement,\nresource allocation\nLonger battery life,\nimproved\
    \ system\ncapacity\nDeveloping\nenergy-efﬁcient\nalgorithms for resource\nallocation\
    \ and power\nmanagement\nScalability\nNetwork slicing,\nvirtualization\nBetter\
    \ resource\nutilization,\nimproved service\nquality\nDeveloping efﬁcient\nnetwork\
    \ slicing and\nvirtualization techniques\nfor massive IoT\ndeployments\nLatency\n\
    Edge computing,\nnetwork\narchitecture\nReduced\ncommunication\ndelay, improved\n\
    application\nperformance\nDeveloping low-latency\nedge computing and\nnetwork\
    \ architecture for\nIoT services\nTable 13. Interference characteristics in 5G\
    \ networks and IoT services.\nInterference\nFrequency\nBandwidth\nPower\nImpact\n\
    Reference\nAtmospheric Absorption\n24–40 GHz\nNarrowband\nLow\nAttenuation\n[101]\n\
    Free Space Path Loss\nAll\nAll\nLow\nAttenuation\n[102]\nReﬂection\nAll\nAll\n\
    Low\nMultipath Fading\n[103]\nRefraction\nAll\nAll\nLow\nPath Bending\n[104]\n\
    Diffraction\nAll\nAll\nLow\nPath Bending\n[105]\nScattering\nAll\nAll\nLow\nMultipath\
    \ Fading\n[106]\nRain Fade\n10–100 GHz\nWideband\nHigh\nAttenuation\n[107]\nMultipath\
    \ Fading\nAll\nAll\nLow\nIntersymbol Interference\n[108]\nCo-Channel Interference\n\
    All\nAll\nHigh\nReduced Signal Quality\n[109]\nAdjacent Channel\nInterference\n\
    All\nAll\nHigh\nReduced Signal Quality\n[110]\nInterference from\nOther Radios\n\
    All\nAll\nHigh\nReduced Signal Quality\n[111]\nInterference from Other\nIoT Devices\n\
    All\nAll\nLow\nReduced Signal Quality\n[112]\nSensors 2023, 23, 3876\n36 of 41\n\
    5. Conclusions\nThe convergence of 5G technology and the Internet of Things is\
    \ an essential step\ntowards achieving new business opportunities and improving\
    \ connectivity worldwide.\nThe ecosystem of IoT devices is complex, and choosing\
    \ the right primary or complementary\nconnectivity option depends on factors such\
    \ as deployment costs, range, interference,\nand capabilities. Technical studies\
    \ have shown that 5G and other services can coexist in\nspeciﬁc frequency bands,\
    \ provided that the technical conditions are adequately adapted.\nCompliance with\
    \ the permitted exposure limits is also essential when designing new\napplications\
    \ or technological accessories using 5G and IoT.\nThe convergence of networks\
    \ and services, driven by 5G technology, is transforming\nthe internet into a\
    \ complex and multifaceted ecosystem integrated into nearly every aspect\nof our\
    \ daily lives. The availability and speed of access to the internet are increasing,\n\
    allowing users to access high-quality media content in real-time and internet\
    \ service\nproviders to offer a range of new services and applications. Cellular\
    \ connectivity will\nenable the achievement of key IoT goals, such as reducing\
    \ device complexity and cost,\nincreasing coverage to support remote applications,\
    \ and providing deployment ﬂexibility,\nhigh capacity, and long battery life.\n\
    Businesses can beneﬁt greatly from the optimization of network performance in\
    \ 5G\nnetworks, which is essential for adequately functioning business processes,\
    \ improving\nproductivity, reducing downtime, and enhancing customer satisfaction.\
    \ The potential of the\nconvergence of networks and services in increasing the\
    \ availability and speed of access to\nthe internet enables a range of new and\
    \ innovative applications and services, transforming\nthe way we live and work.\n\
    Managing interference in 5G networks is a signiﬁcant challenge in ensuring the\
    \ reli-\nability and performance of IoT services. Effective interference management\
    \ techniques,\ndiverse connectivity and latency requirements of IoT devices and\
    \ applications, and external\ninterference are signiﬁcant issues that must be\
    \ addressed to ensure that 5G networks can\nsupport the massive number of devices\
    \ and applications that rely on them.\n5G has a lot of features necessary for\
    \ smart cities. However, it can be improved by\ncombining it with protocols such\
    \ as LoRaWAN, which provides low-range communication,\nZ-Wave, Zigbee, and SigFox\
    \ for house IoT devices. 5G with IoT technologies combine\nall this to provide\
    \ a more complex solution, taking care of the attenuation of the signal,\nsecurity\
    \ protocols, bandwidth, QoS, and more.\nAuthor Contributions: M.P. reviewed, interpreted\
    \ and drafted the comparison results and some\ntables. E.V. was involved on the\
    \ formal analysis and the manuscript. B.R. made the ﬁgures and their\ncomparison\
    \ and performed the formal analysis. J.A.N.-F. directed some formal concepts and\
    \ review\nthe manuscript. C.D.-V.-S. developed the analysis, supervised the research\
    \ methodology and the\napproach of this work, prepared the scenario and analyzed\
    \ the results. All authors have read and\nagreed to the published version of the\
    \ manuscript.\nFunding: This research received no external funding.\nInstitutional\
    \ Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\n\
    Data Availability Statement: Not applicable.\nConﬂicts of Interest: The authors\
    \ declare no conﬂict of interest.\nReferences\n1.\nLin, Z.; Lin, M.; De Cola,\
    \ T.; Wang, J.B.; Zhu, W.P.; Cheng, J. Supporting IoT with rate-splitting multiple\
    \ access in satellite and\naerial-integrated networks. IEEE Internet Things J.\
    \ 2021, 8, 11123–11134. [CrossRef]\n2.\nShao, D.; Mwangakala, H.; Ishengoma, F.;\
    \ Mongi, H.; Mambile, C.; Chali, F. Sustenance of the digital transformations\
    \ induced\nby the COVID-19 pandemic response: Lessons from Tanzanian public sector.\
    \ Glob. Knowl. Mem. Commun. 2022, ahead-of-print.\n[CrossRef]\nSensors 2023, 23,\
    \ 3876\n37 of 41\n3.\nMinoli, D.; Occhiogrosso, B. Practical aspects for the integration\
    \ of 5G networks and IoT applications in smart cities environments.\nWirel. Commun.\
    \ Mob. Comput. 2019, 2019, 5710834. [CrossRef]\n4.\nVermesan, O.; Friess, P. Internet\
    \ of Things: Converging Technologies for Smart Environments and Integrated Ecosystems;\
    \ River Publishers:\nLjubljana, Slovenia, 2013.\n5.\nGhosh, A.; Maeder, A.; Baker,\
    \ M.; Chandramouli, D. 5G evolution: A view on 5G cellular technology beyond 3GPP\
    \ release 15.\nIEEE Access 2019, 7, 127639–127651. [CrossRef]\n6.\nMontori, F.;\
    \ Bedogni, L.; Di Felice, M.; Bononi, L. Machine-to-machine wireless communication\
    \ technologies for the Internet of\nThings: Taxonomy, comparison and open issues.\
    \ Pervasive Mob. Comput. 2018, 50, 56–81. [CrossRef]\n7.\nMuteba, K.; Djouani,\
    \ K.; Olwal, T. 5G NB-IoT: Design, Considerations, Solutions and Challenges. Procedia\
    \ Comput. Sci. 2022,\n198, 86–93. [CrossRef]\n8.\nHardell, L.; Carlberg, M. [Comment]\
    \ Health risks from radiofrequency radiation, including 5G, should be assessed\
    \ by experts\nwith no conﬂicts of interest. Oncol. Lett. 2020, 20, 15. [CrossRef]\n\
    9.\nMumtaz, S.; Alsohaily, A.; Pang, Z.; Rayes, A.; Tsang, K.F.; Rodriguez, J.\
    \ Massive Internet of Things for industrial applications:\nAddressing wireless\
    \ IIoT connectivity challenges and ecosystem fragmentation.\nIEEE Ind. Electron.\
    \ Mag. 2017, 11, 28–33.\n[CrossRef]\n10.\nMarkakis, E.K.; Karras, K.; Sideris,\
    \ A.; Alexiou, G.; Pallis, E. Computing, caching, and communication at the edge:\
    \ The cornerstone\nfor building a versatile 5G ecosystem. IEEE Commun. Mag. 2017,\
    \ 55, 152–157. [CrossRef]\n11.\nChettri, L.; Bera, R. A comprehensive survey on\
    \ Internet of Things (IoT) toward 5G wireless systems. IEEE Internet Things J.\
    \ 2019,\n7, 16–32. [CrossRef]\n12.\nChaudhari, B.S.; Zennaro, M.; Borkar, S. LPWAN\
    \ technologies: Emerging application characteristics, requirements, and design\n\
    considerations. Future Internet 2020, 12, 46. [CrossRef]\n13.\nHwang, S.H.; Liu,\
    \ S.Z. Survey on 3GPP low power wide area technologies and its application. In\
    \ Proceedings of the 2019 IEEE\nVTS Asia Paciﬁc Wireless Communications Symposium\
    \ (APWCS), Singapore, 28–30 August 2019; IEEE: Piscataway, NJ, USA,\n2019; pp.\
    \ 1–5.\n14.\nSahoo, B.P.; Chou, C.C.; Weng, C.W.; Wei, H.Y. Enabling millimeter-wave\
    \ 5G networks for massive IoT applications: A closer\nlook at the issues impacting\
    \ millimeter-waves in consumer devices under the 5G framework. IEEE Consum. Electron.\
    \ Mag. 2018,\n8, 49–54. [CrossRef]\n15.\nYang, L.; Zhao, B.Y.; Zheng, H. The spaces\
    \ between us: Setting and maintaining boundaries in wireless spectrum access.\
    \ In\nProceedings of the Sixteenth Annual International Conference on Mobile Computing\
    \ and Networking, Chicago, IL, USA, 20–24\nSeptember 2010; pp. 37–48.\n16.\nQamar,\
    \ F.; Hindia, M.N.; Dimyati, K.; Noordin, K.A.; Amiri, I.S. Interference management\
    \ issues for the future 5G network: A\nreview. Telecommun. Syst. 2019, 71, 627–643.\
    \ [CrossRef]\n17.\nAttaran, M. The impact of 5G on the evolution of intelligent\
    \ automation and industry digitization. J. Ambient. Intell. Humaniz.\nComput.\
    \ 2021, 1–17. [CrossRef]\n18.\nSiddiqi, M.A.; Yu, H.; Joung, J. 5G ultra-reliable\
    \ low-latency communication implementation challenges and operational issues\n\
    with IoT devices. Electronics 2019, 8, 981. [CrossRef]\n19.\nFerro, E.; Potorti,\
    \ F. Bluetooth and Wi-Fi wireless protocols: A survey and a comparison. IEEE Wirel.\
    \ Commun. 2005, 12, 12–26.\n[CrossRef]\n20.\nChandra, S.; Arya, R.; Verma, A.K.\
    \ Reliability and age of information analysis of 5G IoT for intelligent communication.\
    \ Comput.\nElectr. Eng. 2022, 101, 108053. [CrossRef]\n21.\nAzari, A.; Masoudi,\
    \ M. Interference management for coexisting Internet of Things networks over unlicensed\
    \ spectrum. Ad Hoc\nNetw. 2021, 120, 102539. [CrossRef]\n22.\nAl-Turjman, F. 5G-enabled\
    \ devices and smart-spaces in social-IoT: An overview. Future Gener. Comput. Syst.\
    \ 2019, 92, 732–744.\n[CrossRef]\n23.\nHasan, M.K.; Ghazal, T.M.; Saeed, R.A.;\
    \ Pandey, B.; Gohel, H.; Eshmawi, A.; Abdel-Khalek, S.; Alkhassawneh, H.M. A review\
    \ on\nsecurity threats, vulnerabilities, and counter measures of 5G enabled Internet-of-Medical-Things.\
    \ IET Commun. 2022, 16, 421–432.\n[CrossRef]\n24.\nLin, Z.; Lin, M.; Champagne,\
    \ B.; Zhu, W.P.; Al-Dhahir, N. Secrecy-energy efﬁcient hybrid beamforming for\
    \ satellite-terrestrial\nintegrated networks. IEEE Trans. Commun. 2021, 69, 6345–6360.\
    \ [CrossRef]\n25.\nTang, Y.; Dananjayan, S.; Hou, C.; Guo, Q.; Luo, S.; He, Y.\
    \ A survey on the 5G network and its impact on agriculture: Challenges\nand opportunities.\
    \ Comput. Electron. Agric. 2021, 180, 105895. [CrossRef]\n26.\nMahmood, A.; Beltramelli,\
    \ L.; Abedin, S.F.; Zeb, S.; Mowla, N.I.; Hassan, S.A.; Sisinni, E.; Gidlund,\
    \ M. Industrial IoT in\n5G-and-beyond networks: Vision, architecture, and design\
    \ trends. IEEE Trans. Ind. Inform. 2021, 18, 4122–4137. [CrossRef]\n27.\nStorck,\
    \ C.R.; Duarte-Figueiredo, F. A survey of 5G technology evolution, standards,\
    \ and infrastructure associated with vehicle-to-\neverything communications by\
    \ internet of vehicles. IEEE Access 2020, 8, 117593–117614. [CrossRef]\n28.\n\
    Liu, E.; Efﬁok, E.; Hitchcock, J. Survey on health care applications in 5G networks.\
    \ IET Commun. 2020, 14, 1073–1080. [CrossRef]\n29.\nOgbodo, E.U.; Abu-Mahfouz,\
    \ A.M.; Kurien, A.M. Enabling LPWANs for Coexistence and Diverse IoT Applications\
    \ in Smart\nCities Using Lightweight Heterogenous Multihomed Network Model. J.\
    \ Sens. Actuator Netw. 2022, 11, 87. [CrossRef]\nSensors 2023, 23, 3876\n38 of\
    \ 41\n30.\nIvanova, D.; Markova, E.; Moltchanov, D.; Pirmagomedov, R.; Koucheryavy,\
    \ Y.; Samouylov, K. Performance of priority-based\ntrafﬁc coexistence strategies\
    \ in 5G mmWave industrial deployments. IEEE Access 2022, 10, 9241–9256. [CrossRef]\n\
    31.\nAhmad, A.; Rehmani, M.H.; Tembine, H.; Mohammed, O.A.; Jamalipour, A. IEEE\
    \ Access Special Section Editorial: Optimization\nfor emerging wireless networks:\
    \ IoT, 5G, and smart grid communication networks. IEEE Access 2017, 5, 2096–2100.\
    \ [CrossRef]\n32.\nBairagi, A.K.; Munir, M.S.; Alsenwi, M.; Tran, N.H.; Alshamrani,\
    \ S.S.; Masud, M.; Han, Z.; Hong, C.S. Coexistence mechanism\nbetween eMBB and\
    \ uRLLC in 5G wireless networks. IEEE Trans. Commun. 2020, 69, 1736–1749. [CrossRef]\n\
    33.\nShen, H.; Ye, Q.; Zhuang, W.; Shi, W.; Bai, G.; Yang, G. Drone-small-cell-assisted\
    \ resource slicing for 5G uplink radio access\nnetworks. IEEE Trans. Veh. Technol.\
    \ 2021, 70, 7071–7086. [CrossRef]\n34.\nPainuly, S.; Sharma, S.; Matta, P. Future\
    \ trends and challenges in next generation smart application of 5G-IoT. In Proceedings\
    \ of\nthe 2021 5th International Conference on Computing Methodologies and Communication\
    \ (ICCMC), Erode, India, 8–10 April\n2021; IEEE: Piscataway, NJ, USA, 2021; pp.\
    \ 354–357.\n35.\nGupta, N.; Sharma, S.; Juneja, P.K.; Garg, U. Sdnfv 5g-iot: A\
    \ framework for the next generation 5g enabled iot. In Proceedings of\nthe 2020\
    \ International Conference on Advances in Computing, Communication & Materials\
    \ (ICACCM), Dehradun, India, 21–22\nAugust 2020; IEEE: Piscataway, NJ, USA, 2020;\
    \ pp. 289–294.\n36.\nIslam, S.; Zada, M.; Yoo, H. Low-pass ﬁlter based integrated\
    \ 5G smartphone antenna for sub-6- GHz and mm-wave bands. IEEE\nTrans. Antennas\
    \ Propag. 2021, 69, 5424–5436. [CrossRef]\n37.\nMitra, R.N.; Agrawal, D.P. 5G\
    \ mobile technology: A survey. ICT Express 2015, 1, 132–137. [CrossRef]\n38.\n\
    Ahad, A.; Tahir, M.; Yau, K.L.A. 5G-based smart healthcare network: Architecture,\
    \ taxonomy, challenges and future research\ndirections. IEEE Access 2019, 7, 100747–100762.\
    \ [CrossRef]\n39.\nAndrewsetal, J. Whatwill5Gbe? IEEE J. Sel. Areas Commun. 2014,\
    \ 32, 1065–1082.\n40.\nHan, S.; Bian, S. Energy-efﬁcient 5G for a greener future.\
    \ Nat. Electron. 2020, 3, 182–184.\n41.\nLin, Z.; Niu, H.; An, K.; Wang, Y.; Zheng,\
    \ G.; Chatzinotas, S.; Hu, Y. Refracting RIS-aided hybrid satellite-terrestrial\
    \ relay\nnetworks: Joint beamforming design and optimization. IEEE Trans. Aerosp.\
    \ Electron. Syst. 2022, 58, 3717–3724. [CrossRef]\n42.\nShim, J.P.; Varshney,\
    \ U.; Dekleva, S.; Knoerzer, G. Mobile and wireless networks: Services, evolution\
    \ and issues. Int. J. Mob.\nCommun. 2006, 4, 405–417. [CrossRef]\n43.\nCano, J.C.;\
    \ Berrios, V.; Garcia, B.; Toh, C.K. Evolution of IoT: An industry perspective.\
    \ IEEE Internet Things Mag. 2018, 1, 12–17.\n[CrossRef]\n44.\nJovovi´c, I.; Forenbacher,\
    \ I.; Periša, M. Massive machine-type communications: An overview and perspectives\
    \ towards 5G. In\nProceedings of the 3rd International Virtual Research Conference\
    \ in Technical Disciplines, Zilina, Slovakia, 19–23 October 2015;\nVolume 3.\n\
    45.\nVaezi, M.; Azari, A.; Khosravirad, S.R.; Shirvanimoghaddam, M.; Azari, M.M.;\
    \ Chasaki, D.; Popovski, P. Cellular, wide-area, and\nnon-terrestrial IoT: A survey\
    \ on 5G advances and the road toward 6G. IEEE Commun. Surv. Tutor. 2022, 24, 1117–1174.\
    \ [CrossRef]\n46.\nTao, J.; Umair, M.; Ali, M.; Zhou, J. The impact of Internet\
    \ of Things supported by emerging 5G in power systems: A review.\nCSEE J. Power\
    \ Energy Syst. 2019, 6, 344–352.\n47.\nStudent, V.; Dhir, R. A study of ad hoc\
    \ network: A review. Int. J. 2013, 3, 135–138.\n48.\nTomar, A. Introduction to\
    \ ZigBee technology. Glob. Technol. Cent. 2011, 1, 1–24.\n49.\nYassein, M.B.;\
    \ Mardini, W.; Khalil, A. Smart homes automation using Z-wave protocol. In Proceedings\
    \ of the 2016 International\nConference on Engineering & MIS (ICEMIS), Agadir,\
    \ Morocco, 22–24 September 2016, IEEE: Piscataway, NJ, USA, 2016; pp. 1–6.\n50.\n\
    Villarim, M.R.; de Luna, J.V.H.; de Farias Medeiros, D.; Pereira, R.I.S.; de Souza,\
    \ C.P.; Baiocchi, O.; da Cunha Martins, F.C. An\nevaluation of LoRa communication\
    \ range in urban and forest areas: A case study in brazil and portugal. In Proceedings\
    \ of the\n2019 IEEE 10th Annual Information Technology, Electronics and Mobile\
    \ Communication Conference (IEMCON), Vancouver, BC,\nCanada, 17–19 October 2019;\
    \ IEEE: Piscataway, NJ, USA, 2019; pp. 0827–0832.\n51.\nAbdulmalek, S.; Nasir,\
    \ A.; Jabbar, W.A.; Almuhaya, M.A.; Bairagi, A.K.; Khan, M.A.M.; Kee, S.H. IoT-Based\
    \ Healthcare-Monitoring\nSystem towards Improving Quality of Life: A Review. Healthcare\
    \ 2022, 10, 1993. [CrossRef] [PubMed]\n52.\nZhang, Q.; Cheng, L.; Boutaba, R.\
    \ Cloud computing: State-of-the-art and research challenges. J. Internet Serv.\
    \ Appl. 2010, 1, 7–18.\n[CrossRef]\n53.\nHansen, C.J. WiGiG: Multi-gigabit wireless\
    \ communications in the 60 GHz band. IEEE Wirel. Commun. 2011, 18, 6–7. [CrossRef]\n\
    54.\nMohamed, E.M. WiGig access point selection using non-contextual and contextual\
    \ multi-armed bandit in indoor environment. J.\nAmbient. Intell. Humaniz. Comput.\
    \ 2022, 1–16. [CrossRef]\n55.\nPham, D.A.; Park, E.; Lee, H.L.; Lim, S. High gain\
    \ and wideband metasurfaced magnetoelectric antenna for WiGig applications.\n\
    IEEE Trans. Antennas Propag. 2020, 69, 1140–1145. [CrossRef]\n56.\nKim, S.; Yun,\
    \ J.H. Motion-aware interplay between wigig and wiﬁ for wireless virtual reality.\
    \ Sensors 2020, 20, 6782. [CrossRef]\n57.\nZhang, W.; Zhang, Z.; Chao, H.C. Cooperative\
    \ fog computing for dealing with big data in the internet of vehicles: Architecture\n\
    and hierarchical resource management. IEEE Commun. Mag. 2017, 55, 60–67. [CrossRef]\n\
    58.\nDahlman, E.; Parkvall, S.; Skold, J. 4G, LTE-Advanced Pro and the Road to\
    \ 5G; Academic Press: Cambridge, MA, USA, 2016.\n59.\nLin, Z.; Lin, M.; Wang,\
    \ J.B.; De Cola, T.; Wang, J. Joint beamforming and power allocation for satellite-terrestrial\
    \ integrated\nnetworks with non-orthogonal multiple access. IEEE J. Sel. Top.\
    \ Signal Process. 2019, 13, 657–670. [CrossRef]\n60.\nMa, Z.; Xiao, M.; Xiao,\
    \ Y.; Pang, Z.; Poor, H.V.; Vucetic, B. High-reliability and low-latency wireless\
    \ communication for internet of\nthings: Challenges, fundamentals, and enabling\
    \ technologies. IEEE Internet Things J. 2019, 6, 7946–7970. [CrossRef]\nSensors\
    \ 2023, 23, 3876\n39 of 41\n61.\nRappaport, T.S.; Sun, S.; Mayzus, R.; Zhao, H.;\
    \ Azar, Y.; Wang, K.; Wong, G.N.; Schulz, J.K.; Samimi, M.; Gutierrez, F. Millimeter\n\
    wave mobile communications for 5G cellular: It will work! IEEE Access 2013, 1,\
    \ 335–349. [CrossRef]\n62.\nDangi, R.; Lalwani, P.; Choudhary, G.; You, I.; Pau,\
    \ G. Study and investigation on 5G technology: A systematic review. Sensors\n\
    2022, 22, 26. [CrossRef]\n63.\nHuang, H.; Savkin, A.V. A method for optimized\
    \ deployment of unmanned aerial vehicles for maximum coverage and minimum\ninterference\
    \ in cellular networks. IEEE Trans. Ind. Inform. 2018, 15, 2638–2647. [CrossRef]\n\
    64.\nLuppicini, R.; So, A. A technoethical review of commercial drone use in the\
    \ context of governance, ethics, and privacy. Technol.\nSoc. 2016, 46, 109–119.\
    \ [CrossRef]\n65.\nVergouw, B.; Nagel, H.; Bondt, G.; Custers, B. Drone technology:\
    \ Types, payloads, applications, frequency spectrum issues and\nfuture developments.\
    \ In The Future of Drone Use: Opportunities and Threats from Ethical and Legal\
    \ Perspectives; T.M.C. Asser Press:\nThe Hague, The Netherlands, 2016; pp. 21–45.\n\
    66.\nKatta, S.S.; Nandyala, S.; Viegas, E.K.; AlMahmoud, A. Benchmarking Audio-based\
    \ Deep Learning Models for Detection and\nIdentiﬁcation of Unmanned Aerial Vehicles.\
    \ In Proceedings of the 2022 Workshop on Benchmarking Cyber-Physical Systems and\n\
    Internet of Things (CPS-IoTBench), Milan, Italy, 3–6 May 2022; IEEE: Piscataway,\
    \ NJ, USA, 2022; pp. 7–11.\n67.\nBorralho, R.; Mohamed, A.; Quddus, A.U.; Vieira,\
    \ P.; Tafazolli, R. A survey on coverage enhancement in cellular networks:\nChallenges\
    \ and solutions for future deployments. IEEE Commun. Surv. Tutor. 2021, 23, 1302–1341.\
    \ [CrossRef]\n68.\nAlsharif, M.H.; Nordin, R. Evolution towards ﬁfth generation\
    \ (5G) wireless networks: Current trends and challenges in the\ndeployment of\
    \ millimetre wave, massive MIMO, and small cells. Telecommun. Syst. 2017, 64,\
    \ 617–637. [CrossRef]\n69.\nBoban, M.; Kousaridas, A.; Manolakis, K.; Eichinger,\
    \ J.; Xu, W. Connected roads of the future: Use cases, requirements, and\ndesign\
    \ considerations for vehicle-to-everything communications. IEEE Veh. Technol.\
    \ Mag. 2018, 13, 110–123. [CrossRef]\n70.\nGarcia, M.H.C.; Molina-Galan, A.; Boban,\
    \ M.; Gozalvez, J.; Coll-Perales, B.; ¸Sahin, T.; Kousaridas, A. A tutorial on\
    \ 5G NR V2X\ncommunications. IEEE Commun. Surv. Tutor 2021, 23, 1972–2026. [CrossRef]\n\
    71.\nAlalewi, A.; Dayoub, I.; Cherkaoui, S. On 5G-V2X use cases and enabling technologies:\
    \ A comprehensive survey. IEEE Access\n2021, 9, 107710–107737. [CrossRef]\n72.\n\
    Bockelmann, C.; Pratas, N.K.; Wunder, G.; Saur, S.; Navarro, M.; Gregoratti, D.;\
    \ Vivier, G.; De Carvalho, E.; Ji, Y.; Stefanovi´c,\nˇC.; et al.\nTowards massive\
    \ connectivity support for scalable mMTC communications in 5G networks.\nIEEE\
    \ Access 2018,\n6, 28969–28992. [CrossRef]\n73.\nSalva-Garcia, P.; Alcaraz-Calero,\
    \ J.M.; Alaez, R.M.; Chirivella-Perez, E.; Nightingale, J.; Wang, Q. 5G-UHD: Design,\
    \ prototyping\nand empirical evaluation of adaptive Ultra-High-Deﬁnition video\
    \ streaming based on scalable H. 265 in virtualised 5G networks.\nComput. Commun.\
    \ 2018, 118, 171–184. [CrossRef]\n74.\nRahimi, H.; Zibaeenejad, A.; Safavi, A.A.\
    \ A novel IoT architecture based on 5G-IoT and next generation technologies.\n\
    In\nProceedings of the 2018 IEEE 9th annual information technology, electronics\
    \ and mobile communication conference (IEMCON),\nVancouver, BC, Canada, 1–3 November\
    \ 2018; IEEE: Piscataway, NJ, USA, 2018; pp. 81–88.\n75.\nHunukumbure, M.; Tsoukaneri,\
    \ G. Cost analysis for drone based 5G eMBB provision to emergency services. In\
    \ Proceedings of\nthe 2019 IEEE Globecom Workshops (GC Wkshps), Waikoloa, HI,\
    \ USA, 9–13 December 2019; IEEE: Piscataway, NJ, USA, 2019;\npp. 1–5.\n76.\nLi,\
    \ Z.; Uusitalo, M.A.; Shariatmadari, H.; Singh, B. 5G URLLC: Design challenges\
    \ and system concepts. In Proceedings of the\n2018 15th international symposium\
    \ on wireless communication systems (ISWCS), Lisbon, Portugal, 28–31 August 2018;\
    \ IEEE:\nPiscataway, NJ, USA, 2018; pp. 1–6.\n77.\nTrivisonno, R.; Condoluci,\
    \ M.; An, X.; Mahmoodi, T. mIoT slice for 5G systems: Design and performance evaluation.\
    \ Sensors\n2018, 18, 635. [CrossRef] [PubMed]\n78.\nMarchese, M.; Moheddine, A.;\
    \ Patrone, F. IoT and UAV integration in 5G hybrid terrestrial-satellite networks.\
    \ Sensors 2019,\n19, 3704. [CrossRef] [PubMed]\n79.\nChekired, D.A.; Togou, M.A.;\
    \ Khoukhi, L.; Ksentini, A. 5G-slicing-enabled scalable SDN core network: Toward\
    \ an ultra-low\nlatency of autonomous driving service. IEEE J. Sel. Areas Commun.\
    \ 2019, 37, 1769–1782. [CrossRef]\n80.\nBodinier, Q.; Bader, F.; Palicot, J. On\
    \ spectral coexistence of CP-OFDM and FB-MC waveforms in 5G networks. IEEE Access\
    \ 2017,\n5, 13883–13900. [CrossRef]\n81.\nBiglieri, E.; Goldsmith, A.J.; Greenstein,\
    \ L.J.; Poor, H.V.; Mandayam, N.B. Principles of Cognitive Radio; Cambridge University\n\
    Press: Cambridge, UK, 2013.\n82.\nZubow, A.; Sombrutzki, R. Adjacent channel interference\
    \ in IEEE 802.11 n. In Proceedings of the 2012 IEEE Wireless Communica-\ntions\
    \ and Networking Conference (WCNC), Paris, France, 1–4 April 2012; IEEE: Piscataway,\
    \ NJ, USA, 2012; pp. 1163–1168.\n83.\nYu, Y.; Dutkiewicz, E.; Huang, X.; Mueck,\
    \ M.; Fang, G. Performance analysis of soft frequency reuse for inter-cell interference\n\
    coordination in LTE networks. In Proceedings of the 2010 10th International Symposium\
    \ on Communications and Information\nTechnologies, Tokyo, Japan, 26–29 October\
    \ 2010; IEEE: Piscataway, NJ, USA, 2010; pp. 504–509.\n84.\nBoukalov, A.O.; Haggman,\
    \ S.G. System aspects of smart-antenna technology in cellular wireless communications-an\
    \ overview.\nIEEE Trans. Microw. Theory Tech. 2000, 48, 919–929. [CrossRef]\n\
    85.\nBahai, A.R.; Saltzberg, B.R.; Ergen, M. Multi-Carrier Digital Communications:\
    \ Theory and Applications of OFDM; Springer Science &\nBusiness Media: Berlin/Heidelberg,\
    \ Germany, 2004.\nSensors 2023, 23, 3876\n40 of 41\n86.\nZambianco, M.; Verticale,\
    \ G. Interference minimization in 5G physical-layer network slicing.\nIEEE Trans.\
    \ Commun. 2020,\n68, 4554–4564. [CrossRef]\n87.\nSeiﬁ, N.; Zhang, J.; Heath, R.W.;\
    \ Svensson, T.; Coldrey, M. Coordinated 3D beamforming for interference management\
    \ in cellular\nnetworks. IEEE Trans. Wirel. Commun. 2014, 13, 5396–5410. [CrossRef]\n\
    88.\nDe Gaudenzi, R.; Angeletti, P.; Petrolati, D.; Re, E. Future technologies\
    \ for very high throughput satellite systems. Int. J. Satell.\nCommun. Netw. 2020,\
    \ 38, 141–161. [CrossRef]\n89.\nHanzo, L.; Yang, L.L.; Kuan, E.; Yen, K. Single-and\
    \ Multi-Carrier DS-CDMA: Multi-User Detection, Space-Time Spreading, Synchroni-\n\
    sation, Standards and Networking; John Wiley & Sons: Hoboken, NJ, USA, 2003.\n\
    90.\nAgiwal, M.; Roy, A.; Saxena, N. Next generation 5G wireless networks: A comprehensive\
    \ survey. IEEE Commun. Surv. Tutor.\n2016, 18, 1617–1655. [CrossRef]\n91.\nOmar,\
    \ T.; Ketseoglou, T.; Naffaa, I. A novel self-healing model using precoding &\
    \ big-data based approach for 5G networks.\nPervasive Mob. Comput. 2021, 73, 101365.\n\
    92.\nShaddad, R.Q.; Al-Barakani, W.G.; Al-Hakimi, A.R.; Ahmed, S.A.; Ahmed, M.Y.\
    \ Mobility Management for Small Cells in 5G\nUltra-Dense Wireless Network. In\
    \ Proceedings of the 2022 2nd International Conference on Emerging Smart Technologies\
    \ and\nApplications (eSmarTA), Ibb, Yemen, 25–26 October 2022; IEEE: Piscataway,\
    \ NJ, USA, 2022; pp. 1–6.\n93.\nStanze, O.; Weber, A. Heterogeneous networks with\
    \ LTE-Advanced technologies. Bell Labs Tech. J. 2013, 18, 41–58. [CrossRef]\n\
    94.\nQiao, J.; Shen, X.S.; Mark, J.W.; Shen, Q.; He, Y.; Lei, L. Enabling device-to-device\
    \ communications in millimeter-wave 5G cellular\nnetworks. IEEE Commun. Mag. 2015,\
    \ 53, 209–215. [CrossRef]\n95.\nLynggaard, P. Using neural networks to reduce\
    \ sensor cluster interferences and power consumption in smart cities. Int. J.\
    \ Sens.\nNetw. 2020, 32, 25–33. [CrossRef]\n96.\nLiu, Y.; Zeng, Q.; Zhao, Y.;\
    \ Wu, K.; Hao, Y. Novel channel-hopping pattern-based wireless IoT networks in\
    \ smart cities for\nreducing multi-access interference and jamming attacks. EURASIP\
    \ J. Wirel. Commun. Netw. 2021, 2021, 152. [CrossRef]\n97.\nPérez-Neira, A.I.;\
    \ Caus, M.; Zakaria, R.; Le Ruyet, D.; Koﬁdis, E.; Haardt, M.; Mestre, X.; Cheng,\
    \ Y. MIMO signal processing in\noffset-QAM based ﬁlter bank multicarrier systems.\
    \ IEEE Trans. Signal Process. 2016, 64, 5733–5762. [CrossRef]\n98.\nZhang, X.;\
    \ Haenggi, M. A stochastic geometry analysis of inter-cell interference coordination\
    \ and intra-cell diversity. IEEE Trans.\nWirel. Commun. 2014, 13, 6655–6669. [CrossRef]\n\
    99.\nElsayed, M.; Shimotakahara, K.; Erol-Kantarci, M. Machine learning-based\
    \ inter-beam inter-cell interference mitigation in\nmmWave. In Proceedings of\
    \ the ICC 2020–2020 IEEE International Conference on Communications (ICC), Dublin,\
    \ Ireland, 7–11\nJune 2020; IEEE: Piscataway, NJ, USA, 2020; pp. 1–6.\n100. Hu,\
    \ B.; Beaulieu, N.C. Accurate performance evaluation of time-hopping and direct-sequence\
    \ UWB systems in multi-user\ninterference. IEEE Trans. Commun. 2005, 53, 1053–1062.\
    \ [CrossRef]\n101. Moongilan, D. 5G wireless communications (60 GHz band) for\
    \ smart grid—An EMC perspective. In Proceedings of the 2016\nIEEE International\
    \ Symposium on Electromagnetic Compatibility (EMC), Ottawa, ON, Canada, 25–29\
    \ July 2016; IEEE: Piscataway,\nNJ, USA, 2016; pp. 689–694.\n102. Sun, S.; MacCartney,\
    \ G.R.; Rappaport, T.S. Millimeter-wave distance-dependent large-scale propagation\
    \ measurements and\npath loss models for outdoor and indoor 5G systems. In Proceedings\
    \ of the 2016 10th European Conference on Antennas and\nPropagation (EuCAP), Davos,\
    \ Switzerland, 10–15 April 2016; IEEE: Piscataway, NJ, USA, 2016; pp. 1–5.\n103.\
    \ Schulpen, R.; Bronckers, L.; Smolders, A.; Johannsen, U. 5G millimeter-wave\
    \ NLOS coverage using specular building reﬂections.\nIn Proceedings of the 2020\
    \ 14th European Conference on Antennas and Propagation (EuCAP), Copenhagen, Denmark,\
    \ 15–20\nMarch 2020; IEEE: Piscataway, NJ, USA, 2020; pp. 1–5.\n104. Morais, D.H.;\
    \ Morais. 5G and beyond Wireless Transport Technologies; Springer: Berlin/Heidelberg,\
    \ Germany, 2021.\n105. Deng, S.; MacCartney, G.R.; Rappaport, T.S. Indoor and\
    \ outdoor 5G diffraction measurements and models at 10, 20, and 26 GHz.\nIn Proceedings\
    \ of the 2016 IEEE Global Communications Conference (GLOBECOM), Washington, DC,\
    \ USA, 4–8 December 2016;\nIEEE: Piscataway, NJ, USA, 2016; pp. 1–7.\n106. Chun,\
    \ Y.J.; Cotton, S.L.; Dhillon, H.S.; Lopez-Martinez, F.J.; Paris, J.F.; Yoo, S.K.\
    \ A Comprehensive Analysis of 5G Heterogeneous\nCellular Systems Operating Over\
    \ κ–µ Shadowed Fading Channels. IEEE Trans. Wirel. Commun. 2017, 16, 6995–7010.\
    \ [CrossRef]\n107. Samad, M.A.; Diba, F.D.; Choi, D.Y. A survey of rain fade models\
    \ for earth–space telecommunication links—Taxonomy, methods,\nand comparative\
    \ study. Remote Sens. 2021, 13, 1965. [CrossRef]\n108. Mahmud, M.H.; Hossain,\
    \ M.M.; Khan, A.A.; Ahmed, S.; Mahmud, M.A.; Islam, M.H. Performance analysis\
    \ of OFDM, W-OFDM\nand F-OFDM under Rayleigh fading channel for 5G wireless communication.\
    \ In Proceedings of the 2020 3rd International\nConference on Intelligent Sustainable\
    \ Systems (ICISS), Thoothukudi, India, 3–5 December 2020; IEEE: Piscataway, NJ,\
    \ USA, 2020;\npp. 1172–1177.\n109. Dey, P.; Masal, A.; Kaimalettu, S.; Milleth,\
    \ J.K.; Ramamurthi, B. Reference signal design to mitigate co-channel interference\
    \ in 5G\nOFDM systems with multiple numerologies. Phys. Commun. 2022, 53, 101653.\
    \ [CrossRef]\n110. Wu, T.Y.; Chang, T. Interference reduction by millimeter wave\
    \ technology for 5G-based green communications. IEEE Access 2016,\n4, 10228–10234.\
    \ [CrossRef]\nSensors 2023, 23, 3876\n41 of 41\n111. Soret, B.; De Domenico, A.;\
    \ Bazzi, S.; Mahmood, N.H.; Pedersen, K.I. Interference coordination for 5G new\
    \ radio. IEEE Wirel.\nCommun. 2017, 25, 131–137. [CrossRef]\n112. Qamar, F.; Hindia,\
    \ M.N.; Dimyati, K.; Noordin, K.A.; Majed, M.B.; Abd Rahman, T.; Amiri, I.S. Investigation\
    \ of future 5G-IoT\nmillimeter-wave network performance at 38 GHz for urban microcell\
    \ outdoor environment. Electronics 2019, 8, 495. [CrossRef]\nDisclaimer/Publisher’s\
    \ Note: The statements, opinions and data contained in all publications are solely\
    \ those of the individual\nauthor(s) and contributor(s) and not of MDPI and/or\
    \ the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury\
    \ to\npeople or property resulting from any ideas, methods, instructions or products\
    \ referred to in the content.\n"
  inline_citation: '>'
  journal: Sensors (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/1424-8220/23/8/3876/pdf?version=1681180014
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'Utilization of 5G Technologies in IoT Applications: Current Limitations
    by Interference and Network Optimization Difficulties—A Review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1007/s10311-023-01617-y
  analysis: '>'
  authors:
  - Lin Chen
  - Zhonghao Chen
  - Yubing Zhang
  - Yunfei Liu
  - Ahmed I. Osman
  - Mohamed Farghali
  - Jianmin Hua
  - Ahmed S. Al‐Fatesh
  - Ikko Ihara
  - David Rooney
  - Pow‐Seng Yap
  citation_count: 23
  full_citation: '>'
  full_text: ">\nVol.:(0123456789)\n1 3\nEnvironmental Chemistry Letters (2023) 21:2525–2557\
    \ \nhttps://doi.org/10.1007/s10311-023-01617-y\nREVIEW ARTICLE\nArtificial intelligence‑based\
    \ solutions for climate change: a review\nLin Chen1,2 · Zhonghao Chen3 · Yubing Zhang3 ·\
    \ Yunfei Liu3 · Ahmed I. Osman4  · Mohamed Farghali5,6 · \nJianmin Hua1,2 · Ahmed Al‑Fatesh7 ·\
    \ Ikko Ihara5 · David W. Rooney4 · Pow‑Seng Yap3\nReceived: 15 May 2023 / Accepted:\
    \ 25 May 2023 / Published online: 13 June 2023 \n© The Author(s) 2023\nAbstract\n\
    Climate change is a major threat already causing system damage to urban and natural\
    \ systems, and inducing global eco‑\nnomic losses of over $500 billion. These\
    \ issues may be partly solved by artificial intelligence because artificial intelligence\
    \ \nintegrates internet resources to make prompt suggestions based on accurate\
    \ climate change predictions. Here we review \nrecent research and applications\
    \ of artificial intelligence in mitigating the adverse effects of climate change,\
    \ with a focus on \nenergy efficiency, carbon sequestration and storage, weather\
    \ and renewable energy forecasting, grid management, building \ndesign, transportation,\
    \ precision agriculture, industrial processes, reducing deforestation, and resilient\
    \ cities. We found that \nenhancing energy efficiency can significantly contribute\
    \ to reducing the impact of climate change. Smart manufacturing can \nreduce energy\
    \ consumption, waste, and carbon emissions by 30–50% and, in particular, can reduce\
    \ energy consumption in \nbuildings by 30–50%. About 70% of the global natural\
    \ gas industry utilizes artificial intelligence technologies to enhance the \n\
    accuracy and reliability of weather forecasts. Combining smart grids with artificial\
    \ intelligence can optimize the efficiency \nof power systems, thereby reducing\
    \ electricity bills by 10–20%. Intelligent transportation systems can reduce carbon\
    \ dioxide \nemissions by approximately 60%. Moreover, the management of natural\
    \ resources and the design of resilient cities through \nthe application of artificial\
    \ intelligence can further promote sustainability.\nKeywords Artificial intelligence ·\
    \ Climate change · Energy efficiency · Sustainability · Resource management\n\
    \ * Ahmed I. Osman \n \naosmanahmed01@qub.ac.uk\n * Mohamed Farghali \n \nmohamed.farghali@aun.edu.eg\n\
    \ * Jianmin Hua \n \nhuajianmin@cqu.edu.cn\n * Pow‑Seng Yap \n \nPowSeng.Yap@xjtlu.edu.cn\n\
    \ \nLin Chen \n \nchnlinchen@gmail.com\n \nZhonghao Chen \n \nzhonghaochen98@163.com\n\
    \ \nYubing Zhang \n \nzhangyubing2000@163.com\n \nYunfei Liu \n \nyunfeiliu1230@gmail.com\n\
    1 \nSchool of Civil Engineering, Chongqing University, \nChongqing 400045, China\n\
    2 \nKey Laboratory of New Technology for Construction \nof Cities in Mountain\
    \ Area, Ministry of Education, \nChongqing University, Chongqing 400045, China\n\
    3 \nDepartment of Civil Engineering, Xi’an Jiaotong‑Liverpool \nUniversity, Suzhou 215123,\
    \ China\n4 \nSchool of Chemistry and Chemical Engineering, Queen’s \nUniversity\
    \ Belfast, David Keir Building, Stranmillis Road, \nBelfast BT9 5AG, Northern Ireland, UK\n\
    5 \nDepartment of Agricultural Engineering \nand Socio‑Economics, Kobe University,\
    \ Kobe 657‑8501, \nJapan\n6 \nDepartment of Animal and Poultry Hygiene \nand Environmental\
    \ Sanitation, Faculty of Veterinary \nMedicine, Assiut University, Assiut 71526,\
    \ Egypt\n7 \nChemical Engineering Department, College of Engineering, \nKing Saud\
    \ University, P.O. Box 800, Riyadh 11421, \nSaudi Arabia\n2526\n \nEnvironmental\
    \ Chemistry Letters (2023) 21:2525–2557\n1 3\nIntroduction\nThe carbon dioxide\
    \ emissions caused by industrial pro‑\nduction are leading to climate change,\
    \ which is currently \none of humanity’s most severe climate problems. Sea level\
    \ \nrise, the increasing frequency of natural disasters, the \nreduction of crop\
    \ production capacity, and the loss of bio‑\ndiversity are closely related to\
    \ climate change (Shivanna \n2022). The widespread use of fossil fuels in manufactur‑\n\
    ing processes is primarily responsible for the extensive \ncarbon dioxide emissions\
    \ (Yue and Gao 2018). Therefore, \nimproving energy efficiency, developing green\
    \ energy, and \nconserving energy are essential to address climate change. \n\
    The transition from a society based on fossil fuels to one \nbased on electricity\
    \ can positively affect ecological protec‑\ntion (Fang et al. 2023; Farghali et al.\
    \ 2022).\nArtificial intelligence can achieve automated discov‑\nery, distribution,\
    \ and transmission operations through \ndeep neural networks, significantly reducing\
    \ energy con‑\nsumption (Farghali et al. 2023). As the severity of cli‑\nmate\
    \ change issues continues to increase, artificial intelli‑\ngence is often touted\
    \ as a potential solution for addressing \nthe challenges of climate change. Artificial\
    \ intelligence \ntechnology has the potential to seamlessly integrate the \nexpanding\
    \ opportunities offered by the internet of things \n(IoT) and renewable energy\
    \ within the energy industry. \nIt can play a crucial role in energy supply, optimizing\
    \ \ndecision‑making processes, and autonomous software \ncontrol, thus serving\
    \ as a significant driving force in the \nenergy sector. In addition, artificial\
    \ intelligence has also \nplayed an indispensable role in solar radiation modeling,\
    \ \nsimulation and optimization of renewable energy systems, \nurban power load\
    \ forecasting, and urban building heat load \nforecasting (Al‑Othman et al. 2022;\
    \ Jha et al. 2017; Khos‑\nravi et al. 2018; Lyu and Liu 2021; Wang and Srinivasan\
    \ \n2017). Artificial intelligence can aid in mitigating climate \nchange in multiple\
    \ ways, such as improving the prediction \nof extreme weather events (McGovern\
    \ et al. 2017), con‑\nstructing energy‑efficient and green intelligent buildings\
    \ \nthat collect and sense data while predicting thermal com‑\nfort (Ngarambe\
    \ et al. 2020; Yan et al. 2021), establishing \nnutrient cycling and crop productivity\
    \ models to reduce \nfertilizer usage (Elahi et al. 2019b; Zhang et al. 2021),\
    \ \nimplementing sustainable forest management practices \nthat are efficient\
    \ and precise to decrease deforestation (Liu \net al. 2021), providing smart waste\
    \ management systems \n(Fang et al. 2023), and developing resilient cities (Allam\
    \ \nand Dhunny 2019).\nCurrently, the review of artificial intelligence and cli‑\n\
    mate change primarily focuses on the technical aspects \nof artificial intelligence,\
    \ omitting a perspective on how \nartificial intelligence can be applied in various\
    \ fields that \nare impacted by climate change. As illustrated in Fig. 1, \nthis\
    \ review divides the impact of climate change on \nhuman social production and\
    \ life into eight sections, each \nof which investigates the use of artificial\
    \ intelligence in \nresource management, green energy efficiency, and sus‑\ntainable\
    \ development. Furthermore, the future of artificial \nintelligence’s sustainable\
    \ development in the context of \nclimate change was investigated. In short, artificial\
    \ intel‑\nligence has the potential to transform how we respond \nto climate change\
    \ mitigation by providing new tools and \ninsights to assist us in achieving a\
    \ more sustainable future.\nUsing artificial intelligence in energy \nefficiency,\
    \ carbon sequestration, \nand storage\nEnergy efficiency\nIn contemporary society,\
    \ energy concerns have emerged as \none of the major global issues. As the global\
    \ economy stead‑\nily expands and the population continues to burgeon, there \n\
    has been an exponential surge in energy demand (Chen et al. \n2022b; Osman et al.\
    \ 2022; Yang et al. 2023). Concurrently, \nthe judicious utilization of energy\
    \ and the attainment of sus‑\ntainable development has posed an increasingly momentous\
    \ \nchallenge (Chen et al. 2023a). In order to meet the mounting \nenergy demand\
    \ and curb deleterious environmental impact, \nefficacious measures must be implemented\
    \ to enhance \nenergy efficiency and abate energy wastage (Cai et al. 2019; \n\
    Nižetić et al. 2019). Artificial intelligence technology has \nprogressively emerged\
    \ as a new technological tool in the \nenergy sector, offering novel prospects\
    \ and challenges for \nameliorating energy efficiency and realizing sustainable\
    \ \ndevelopment (Baysan et al. 2019; Farghali et al. 2023).\nIn the energy sector,\
    \ the implementation of artificial intel‑\nligence can heighten the efficiency\
    \ of energy utilization by \npredicting energy demand, optimizing energy production\
    \ \nand consumption, and realizing intelligent control, thus \ncurtailing energy\
    \ costs, lessening environmental pollution, \nand fostering sustainable development\
    \ (Khalilpourazari \net al. 2021; Lee and Yoo 2021). As a result, the relation‑\n\
    ship between artificial intelligence and energy efficiency has \nemerged as a\
    \ highly discussed topic in the research com‑\nmunity, garnering the interest\
    \ of numerous scholars and \ncorporations alike (Ahmad et al. 2021; Kumari et al.\
    \ 2020). \nMoreover, it is contended that judiciously applying artificial \nintelligence\
    \ technology can result in a tangible enhancement \nof energy efficiency, foster\
    \ sustainable development, and \npave the way for a more promising future for\
    \ human society. \nAccordingly, Table 1 presents an analysis of the utilization\
    \ \nof artificial intelligence technology in augmenting energy \n2527\nEnvironmental\
    \ Chemistry Letters (2023) 21:2525–2557 \n1 3\nefficiency, outlining the present\
    \ status and efficacy of its \ndeployment in the energy sector.\nArtificial intelligence\
    \ has recently revolutionized the \nenergy sector, which has emerged as a revolutionary\
    \ tech‑\nnological tool offering novel opportunities and challenges \nfor enhancing\
    \ energy efficiency and accomplishing sus‑\ntainable development (Ahmed et al.\
    \ 2022a; Farghali et al. \n2023; Yang et al. 2022). A thorough examination outlined\
    \ \nin Table 1 has revealed that artificial intelligence has \nbeen proficiently\
    \ employed in various domains of energy \nefficiency, such as fault detection\
    \ and diagnosis, thermal \ncomfort prediction and control, demand response, and\
    \ \nenergy storage optimization. The application of artificial \nintelligence\
    \ in these domains has demonstrated promising \nresults in augmenting energy efficiency,\
    \ reducing energy \nwaste, and fostering sustainable development (Chopra \net al.\
    \ 2022; Fang et al. 2023). However, implementing \nartificial intelligence in\
    \ energy efficiency is an ongoing \nprocess. Its effectiveness is heavily contingent\
    \ upon the \naccuracy of input data and the proper selection of artificial \n\
    intelligence algorithms (Arumugam et al. 2022; Ouadah \net al. 2022).\nFig. 1\
    \  Utilization of artificial intelligence in reducing the impact of \nclimate\
    \ change. This figure outlines various artificial intelligence \napplications\
    \ in energy efficiency, including carbon sequencing, stor‑\nage, and renewable\
    \ energy forecasting. Furthermore, artificial intel‑\nligence optimizes transportation\
    \ systems, precision agriculture, and \nnatural resource management. The technology\
    \ is also employed in \nenergy‑efficient building design and retrofitting, weather\
    \ forecasting, \nand industrial process optimization. Consideration is given to\
    \ the dis‑\ncourse surrounding the implementation of sustainable and resilient\
    \ \nurban centers and their potential implications in the upcoming era. \nThe\
    \ discussion focuses on implementing sustainable and resilient \nurban development\n\
    2528\n \nEnvironmental Chemistry Letters (2023) 21:2525–2557\n1 3\nTable 1  Utilization\
    \ of artificial intelligence technologies to improve energy efficiency at present\n\
    Research project description\nCountry\nApplication area\nCurrent status Effectiveness\n\
    Critical findings\nReferences\nThe convergence of the internet \nof things and\
    \ artificial intel‑\nligence facilitates energy \nefficiency\nItaly\nEnergy management\
    \ systems\nWidely used\nHighly effective The investigation exhibits the \nadvantageous\
    \ potential of the \ninternet of things (IoT) para‑\ndigms and machine learning\
    \ \ntechniques in pursuing self‑\nsufficient energy efficiency. \nHowever, it\
    \ is noteworthy \nthat the outcomes pertain to \ncomparably uncomplicated set‑\n\
    tings, and further exploration is \nessential for energy‑intensive \noperations,\
    \ sizable offices, and \nother vast infrastructures\nTomazzoli et al. (2020)\n\
    The development of artificial \nintelligence in smart buildings \nhas progressed\
    \ to enhance \nenergy efficiency\nJapan\nEnergy management systems\nWidely used\n\
    Highly effective The paper explores using arti‑\nficial intelligence technology\
    \ \nto optimize building energy \nsystems and minimize energy \nconsumption. Nevertheless,\
    \ \nthere is a need to enhance the \nrobustness, precision, and \ndependability\
    \ of the judi‑\ncious deployment of artificial \nintelligence systems in smart\
    \ \nbuildings\nFarzaneh et al. (2021)\nUsing artificial intelligence to \nassist\
    \ with predicting main‑\ntenance needs for renewable \nenergy systems\nUK\nPredictive\
    \ maintenance\nEmerging\nEffective\nThis study highlights the effi‑\ncacy of artificial\
    \ intelligence \ntechniques in the predictive \nmaintenance of renewable \nenergy\
    \ systems and suggests \nthat further experimentation in \ndiverse operational\
    \ modes is \nwarranted for improvement\nShin et al. (2021)\nArtificial intelligence‑driven\
    \ \nmethods for detecting and \ndiagnosing faults in building \nenergy systems\n\
    China\nFault detection and diagnosis\nEmerging\nEffective\nThis research thoroughly\
    \ \nexamines fault detection and \ndiagnosis techniques for build‑\ning energy\
    \ systems that rely on \nartificial intelligence. However, \nfurther investigation\
    \ is still \nneeded into these systems' \nefficacy, efficiency, scalability, \n\
    and dependability in real‑world \nscenarios\nZhao et al. (2019)\n2529\nEnvironmental\
    \ Chemistry Letters (2023) 21:2525–2557 \n1 3\nThe table examines research conducted\
    \ in various nations on the role of technologies driven by artificial intelligence\
    \ in enhancing energy efficiency. According to the data in the table, artificial\
    \ \nintelligence has been utilized effectively in various ways to improve energy\
    \ efficiency. This includes fault detection and diagnosis, thermal comfort prediction\
    \ and control, demand response, and \nenergy storage optimization. The table also\
    \ illustrates the barriers to adopting artificial intelligence technologies in\
    \ the energy sector\nTable 1  (continued)\nResearch project description\nCountry\n\
    Application area\nCurrent status Effectiveness\nCritical findings\nReferences\n\
    The convergence of artificial \nintelligence and building \nenergy efficiency\n\
    China\nBuilding automation and control Emerging\nEffective\nThe present study\
    \ explores using \nartificial intelligence‑based \ntechnology to enhance building\
    \ \nenergy efficiency. Artificial \nintelligence constitutes a \npractical approach\
    \ toward \nachieving zero energy in build‑\nings, and further research in \nthis\
    \ domain is imperative\nYan et al. (2021)\nThe employment of artificial \nintelligence\
    \ techniques in fore‑\ncasting indoor thermal comfort \nin buildings\nSouth Korea\n\
    Occupancy and comfort control\nEmerging\nEffective\nThe present study demonstrates\
    \ \nthe potential effectiveness of \nartificial intelligence‑based \ntechnology\
    \ in regulating ther‑\nmal comfort in buildings, but \nits economic viability\
    \ warrants \nfurther investigation\nNgarambe et al. (2020)\nThe application of\
    \ artificial intel‑\nligence in the economic evalu‑\nation of energy efficiency\
    \ and \nrenewable energy technologies\nIndia\nRenewable energy integration\nEmerging\n\
    Promising\nThe study introduces an effective \nevaluation model based on arti‑\n\
    ficial intelligence that can be \nutilized for predicting energy \nefficiency\
    \ and conservation. \nThe proposed model exhibits \na significant energy efficiency\
    \ \nrate of around 97.32%\nChen et al. (2021)\nA system for residential demand\
    \ \nresponse that utilizes artificial \nintelligence technology is \ndiscussed\
    \ in this study\nSpain\nDemand response\nEmerging\nPromising\nThe study highlights\
    \ the poten‑\ntial of artificial intelligence‑\nbased demand response \nsystems\
    \ in residential buildings \nbut suggests further investigat‑\ning its applicability\
    \ in other \nbuilding types\nEsnaola‑Gonzalez et al. (2021)\nArtificial intelligence\
    \ is used \nto anticipate, enhance, and \nmanage thermal energy storage \nsystems\n\
    United Arab Emirates Energy storage management\nEmerging\nPromising\nAccording\
    \ to research, using \nartificial intelligence methods \nin thermal energy storage\
    \ \nsystems is an ongoing process. \nHowever, the accuracy of \nartificial intelligence\
    \ largely \ndepends on the quality of input \ndata, which remains a major \nlimitation\n\
    Olabi et al. (2023)\n2530\n \nEnvironmental Chemistry Letters (2023) 21:2525–2557\n\
    1 3\nAccording to the findings presented in Table 1, research \nconducted in Italy\
    \ and Japan suggests that using artificial \nintelligence technologies in energy\
    \ management systems has \nbeen widespread and has resulted in favorable outcomes.\
    \ \nSimilarly, the research conducted in the UK suggests that \nwhile the use\
    \ of artificial intelligence in predictive main‑\ntenance is still in its early\
    \ stages, it has demonstrated good \neffectiveness. Moreover, in other countries,\
    \ such as China \nand India, artificial intelligence is used for fault detection\
    \ \nand diagnosis and in integrating renewable energy and \ndemand response. Overall,\
    \ the analysis presented in Table 1 \nsuggests that most of the applications of\
    \ artificial intelli‑\ngence in various aspects of energy efficiency are still\
    \ in their \nnascent stages, and their effectiveness needs further inves‑\ntigation.\
    \ Thus, there is a need to conduct further research to \nassess the efficacy of\
    \ these applications.\nSome scholars contend that the exorbitant cost of artificial\
    \ \nintelligence technology is a major obstacle to its application \nin energy\
    \ efficiency (Enholm et al. 2022; Yang 2022; Zhao \net al. 2022). This is because\
    \ the creation and implementation \nof artificial intelligence‑based systems necessitate\
    \ signifi‑\ncant investment, which may exceed the financial capacity of \nspecific\
    \ organizations (Ahmed et al. 2022b). Additionally, \nthe scarcity of data and\
    \ proficient experts in artificial intel‑\nligence presents a significant challenge\
    \ to its widespread \nimplementation in energy efficiency (Chai et al. 2022).\
    \ \nNonetheless, despite these obstacles, it is expected that the \nutilization\
    \ of artificial intelligence technologies in energy \nefficiency will increase,\
    \ driven by the burgeoning need to \nreduce energy consumption, mitigate environmental\
    \ impact, \nand achieve sustainable development.\nThis section thoroughly examines\
    \ using artificial intelli‑\ngence‑based technologies to enhance energy efficiency.\
    \ The \nfindings demonstrate that artificial intelligence is a powerful \ntool\
    \ that enhances energy efficiency and promotes sustain‑\nable development. Artificial\
    \ intelligence has demonstrated \nefficacy in numerous areas, although its potential\
    \ requires \nfurther evaluation. The scarcity of expertise and financial \nconstraints\
    \ hinder its widespread adoption. Nonetheless, the \nfuture holds promise for\
    \ increased utilization of artificial \nintelligence in energy efficiency.\nCarbon\
    \ sequestration and storage\nCarbon sequestration and storage are pivotal elements\
    \ of cli‑\nmate change mitigation strategies (Liu et al. 2022b; Osman \net al.\
    \ 2022; Yang et al. 2022, 2023). The application of arti‑\nficial intelligence\
    \ in this field can significantly augment the \nefficiency and effectiveness of\
    \ these processes (Cheong et al. \n2022; Kaack et al. 2022). Artificial intelligence‑based\
    \ tech‑\nnologies can be harnessed to discern appropriate geological \nformations\
    \ for carbon storage and prognosticate the behavior \nof carbon dioxide after\
    \ it is introduced into storage sites \n(Abdalla et al. 2021). Furthermore, artificial\
    \ intelligence can \noptimize the injection procedure and monitor storage sites\
    \ \nto ensure carbon dioxide is securely trapped underground \n(Li et al. 2021).\
    \ Artificial intelligence can also expedite the \ndevelopment of novel and ingenious\
    \ carbon sequestration \napproaches, such as mineral carbonation, which converts\
    \ \ncarbon dioxide into stable minerals (Ding et al. 2022).\nIn summary, incorporating\
    \ artificial intelligence in carbon \nsequestration and storage can promote climate\
    \ objectives \nand sustainable development. Figure 2 depicts the sequential \n\
    phases of incorporating artificial intelligence technology in \ncarbon sequestration\
    \ and storage and its capacity to facilitate \nthe realization of climate goals\
    \ and sustainable development. \nBy leveraging artificial intelligence, it is\
    \ feasible to reduce \ngreenhouse gas emissions and alleviate the impacts of cli‑\n\
    mate change, expediting the attainment of carbon neutrality.\nIn recent years,\
    \ the utilization of artificial intelligence in \ncarbon sequestration and storage\
    \ has increased significantly \n(Qerimi and Sergi 2022). As depicted in Fig. 2,\
    \ artificial \nintelligence has the potential to enhance the efficiency and \n\
    efficacy of these processes by identifying appropriate geo‑\nlogical formations\
    \ for carbon storage (Jin et al. 2022), pre‑\ndicting the behavior of carbon dioxide\
    \ once it is introduced \ninto the storage sites (Chinh Nguyen et al. 2022), optimiz‑\n\
    ing the injection process (Elsheikh et al. 2022), monitoring \nstorage sites (Kishor\
    \ and Chakraborty 2022), and devising \nnew and innovative carbon sequestration\
    \ methods (Gupta \nand Li 2022). Moreover, artificial intelligence can aid in\
    \ \naccomplishing sustainability objectives and achieving car‑\nbon neutrality\
    \ by reducing greenhouse gas emissions and \nmitigating climate change (Jahanger\
    \ et al. 2023; Sahil et al. \n2023). Therefore, one of the advantages of artificial\
    \ intel‑\nligence technology in carbon sequestration and storage is its \ncapacity\
    \ to analyze vast amounts of geological and engineer‑\ning data to locate appropriate\
    \ storage sites and optimize the \ninjection process (Yao et al. 2023). Additionally,\
    \ artificial \nintelligence can anticipate the behavior of carbon dioxide \nin\
    \ storage sites and monitor the site to ensure the permanent \ntrapping of the\
    \ gas underground (Kushwaha et al. 2023). \nAnother strength is its ability to\
    \ develop new and innovative \ncarbon storage methods, such as driving the development\
    \ of \npromising materials for sustainable carbon dioxide manage‑\nment (Zhang\
    \ et al. 2022).\nIntegrating artificial intelligence in carbon sequestration \n\
    and storage encounters various impediments (Hasan et al. \n2022). Among them,\
    \ the financial expenses required for \nimplementation (Heo et al. 2022) and a\
    \ lack of expertise \nin the field (Ahmad et al. 2022) pose significant obstacles.\
    \ \nMoreover, ethical and regulatory concerns may arise in \nmonitoring and managing\
    \ carbon storage sites through the \nuse of artificial intelligence (Swennenhuis\
    \ et al. 2022), and \ncareful attention must be given to ensure that the technology\
    \ \ndoes not cause any detrimental environmental impacts or \n2531\nEnvironmental\
    \ Chemistry Letters (2023) 21:2525–2557 \n1 3\nunintended consequences (Delanoë\
    \ et al. 2023). However, \nas technology advances and becomes more accessible\
    \ in the \nfuture (Liu et al. 2022c), the usage of artificial intelligence in\
    \ \ncarbon sequestration and storage is anticipated to increase. \nTherefore,\
    \ ensuring that artificial intelligence technology \nis implemented ethically\
    \ and responsibly is crucial, aim‑\ning to achieve sustainability goals and carbon\
    \ neutrality. \nMoreover, further research and development must address \nthe\
    \ challenges of using artificial intelligence in carbon \nsequestration and storage\
    \ and capitalize on the technology's \npotential benefits.\nTo sum up, integrating\
    \ artificial intelligence in carbon \nsequestration and storage can significantly\
    \ augment the effi‑\ncacy and potency of these processes, facilitate the attain‑\n\
    ment of climate objectives, and promote sustainable growth. \nThis technology\
    \ can be employed to discern appropriate \nFig. 2  Carbon sequestration and storage\
    \ utilizing artificial intelli‑\ngence. Five distinct phases are depicted in the\
    \ figure above for incor‑\nporating artificial intelligence into carbon sequestration\
    \ and storage. \nIt also highlights artificial intelligence's critical role in\
    \ achieving cli‑\nmate goals and promoting sustainable development. The illustration\
    \ \ndepicts the use of artificial intelligence in the analysis of geological \n\
    data to identify suitable formations for carbon storage and in predict‑\ning the\
    \ behavior of carbon dioxide upon injection at storage sites. In \naddition, it\
    \ demonstrates how artificial intelligence can improve the \nefficiency of the\
    \ injection process to maximize carbon storage while \nensuring the security of\
    \ underground carbon dioxide sequestration \nthrough site monitoring. Moreover,\
    \ artificial intelligence can acceler‑\nate the development of pioneering carbon\
    \ storage techniques\n2532\n \nEnvironmental Chemistry Letters (2023) 21:2525–2557\n\
    1 3\ngeological formations for carbon storage, anticipate the \nbehavior of carbon\
    \ dioxide, optimize the injection process, \noversee storage sites, and generate\
    \ fresh and inventive car‑\nbon sequestration techniques. Nevertheless, the applica‑\n\
    tion of artificial intelligence in this realm also encounters \nobstacles such\
    \ as financial expenditure, dearth of expertise, \nethical and regulatory quandaries,\
    \ and plausible adverse \nenvironmental effects.\nUsing artificial intelligence\
    \ in weather \nforecasting\nSevere weather occurrences such as tornadoes, hail,\
    \ and \nthunderstorms can cause significant damage to infrastructure \nand human\
    \ settlements, resulting in financial losses and pos‑\ning a severe threat to\
    \ public safety. Improved observational \nand calculation techniques have contributed\
    \ to a reduced risk \nof loss of life and damage from the effects of climate change.\
    \ \nDespite a scientific consensus on the fundamental aspects of \nclimate change,\
    \ accurately predicting results remains chal‑\nlenging due to the intricate nature\
    \ of earth system models \nand the inherent uncertainty surrounding climate change\
    \ \n(Bonan and Doney 2018). Artificial intelligence’s data pro‑\ncessing and collection\
    \ capabilities significantly improve \nthe gap between digital model predictions\
    \ and real situa‑\ntions, achieving more accurate predictions of future results\
    \ \n(McGovern et al. 2017).\nThe large amount of data provided by observation\
    \ sat‑\nellites and the complexity of climate models have made \nartificial intelligence\
    \ increasingly crucial in weather fore‑\ncasting. Artificial intelligence is widely\
    \ used to search for \nall information and discover new climate models, thereby\
    \ \nreducing prediction bias and improving accuracy (Jones \n2017). Gradually\
    \ more professionals are paying attention to \nthe potential of artificial intelligence\
    \ in weather forecasting. \nHsiang et al. (2017) predicted the effects of climate\
    \ change \non the economy in the USA using data from six economic \nsectors on\
    \ short‑term weather changes. Introducing artifi‑\ncial intelligence will better\
    \ assist relevant departments in \nmodeling data and predicting the effects of\
    \ weather change \non the economy. In short, combining artificial intelligence\
    \ \nand numerical climate simulation data can effectively fill \nthe data gaps\
    \ in observations, reducing uncertainty and bias \nin climate prediction (Kadow\
    \ et al. 2020). Table 2 demon‑\nstrates the application of artificial intelligence\
    \ in weather \nforecasting.\nMore precise meteorological models can be created\
    \ by \nanalyzing many historical and present weather data using \nmachine learning\
    \ algorithms. These models can help predict \nseveral climatic characteristics,\
    \ such as temperature, pre‑\ncipitation, and wind speed. By contrasting three\
    \ models—\ndeep neural network, time convolution neural network, and \nshort‑term\
    \ memory neural network—with support vector \nmachine, random model, and empirical\
    \ equation, Chen et al. \n(2020b) calculated daily evapotranspiration in the Northeast\
    \ \nChina Plain of China. Zhang et al. (2019a) found that distrib‑\nuted lagged\
    \ nonlinear models outperform cross‑correlation \nfunctions in predicting variable\
    \ selection and determining \nlag effects. In contrast, machine learning methods\
    \ predict \nstandardized precipitation evapotranspiration indices more \naccurately\
    \ than nonlinear models using artificial neural \nnetworks.\nThe impact of solar\
    \ activity on climate change, particu‑\nlarly concerning droughts and floods,\
    \ is significant. To \nimprove solar activity's early detection and warning capa‑\n\
    bilities, researchers such as Jiang et al. (2023) have turned \nto artificial\
    \ intelligence. Specifically, they have employed \nthree‑dimensional recognition\
    \ techniques to identify mete‑\norological and ecological drought events, followed\
    \ by the \nextraction of propagating drought events using spatiotempo‑\nral overlap\
    \ rules. Machine learning models and the C‑vine \ncopula are combined to compute\
    \ the propagation prob‑\nability. Artificial intelligence‑based solar energy forecast\
    \ \nmodels were the subject of classification research by Wang \net al. (2020).\
    \ Pham et al. (2020) gathered the highest tem‑\nperature, lowest temperature,\
    \ wind speed, relative humidity, \nsolar radiation, and other meteorological characteristics.\
    \ The \nfuzzy reasoning system based on an adaptive network fore‑\ncasts rainfall\
    \ using support vector machines, artificial neural \nnetworks, and particle swarm\
    \ optimization.\nThe use of artificial intelligence contributes to reduc‑\ning\
    \ forecast uncertainty and speeding up prediction execu‑\ntion. Artificial intelligence\
    \ can detect geographic variables \ncomplex for humans, establishing more accurate\
    \ climate \nmodels. Mostajabi et al. (2019) used station‑level air pres‑\nsure,\
    \ temperature, relative humidity, and temperature to \nconstruct a machine learning\
    \ model to forecast the occur‑\nrence of lightning. Convolutional neural networks\
    \ were used \nby Duan et al. (2021) to propose a data‑driven model that \nreconstructs\
    \ radar reflectivity using deep learning and RR \nusing Himawari‑8 radiation data.\
    \ Deep learning is used by \nPullman et al. (2019) to identify infrared brightness\
    \ tempera‑\nture and other hail‑related parameters for hail detection. In a \n\
    study published in 2021, Adikari et al. (2021) compared the \npredictive abilities\
    \ of wavelet decomposition function, con‑\nvolutional neural network, short‑term\
    \ memory network, and \nadaptive neuro‑fuzzy inference system in flood and drought.\n\
    Satellites can obtain massive amounts of land resource \ninformation at different\
    \ periods through artificial intelli‑\ngence to compare these data can improve\
    \ the efficiency of \nspatial land planning and enhance the rationality and feasi‑\n\
    bility of planning schemes. López Santos et al. (2019) stud‑\nied the critical\
    \ variables of artificial neural case studies in \nsustainable land management.\
    \ They found through random \nabstraction of orchards that the yield of orchards\
    \ depends \n2533\nEnvironmental Chemistry Letters (2023) 21:2525–2557 \n1 3\n\
    Table 2  Weather forecasting incorporating artificial intelligence\nUsing artificial\
    \ intelligence, meteorological models can be developed for temperature fluctuations,\
    \ drought, hail, and typhoons. Predicting and \nforewarning extreme weather conditions\
    \ can aid in establishing adaptation and mitigation procedures to reduce the resulting\
    \ damage. The appli‑\ncation of artificial intelligence reduces the execution\
    \ time of predictions and the uncertainty associated with them. As more data is\
    \ analyzed, the \naccuracy of artificial intelligence in weather forecasting will\
    \ increase\nRegional scope\nParticular year Data time\nPrediction content\nMethod\n\
    References\nThe whole world\n2019\n1901–2016 Average temperature\nUsing deep neural\
    \ networks for top‑\ndown climate prediction\nIse and Oba (2019)\nThe whole world\n\
    2019\n1984–2017 El niño‑southern oscillation Establishing a statistical prediction\
    \ \nmodel using deep learning methods \nto predict el niño‑southern oscillation\
    \ \nwith a lead time exceeding one and a \nhalf years\nHam et al. (2019)\nThe\
    \ whole world\n2020\n2010–2019 Tropical instability wave\nUsing a data‑driven\
    \ model based \non deep learning to predict the \nspatiotemporal changes in sea\
    \ level \ntemperature related to unstable tropi‑\ncal waves\nZheng et al. (2020)\n\
    Malaysia,\nTerengganu\n2021\n1985–2019 Rainfall\nconstructing and contrasting\
    \ regression \nmodels using neural networks, deci‑\nsion trees, Bayesian linear\
    \ models, \nand decision forests to predict rainfall\nRidwan et al. (2021)\nSeoul,\
    \ South Korea 2018\n1994–2015 Torrential rain\nUse machine learning with prediction\
    \ \nperformance higher than the regres‑\nsion model to open the function \nof\
    \ predicting rainstorm damage in \nadvance\nChoi et al. (2018)\nShaanxi, China\n\
    2020\n1961–2016 Drought\nCompare the cross‑correlation function \nwith the distributed\
    \ lag nonlinear \nmodel to determine the optimum \nprediction variable and the\
    \ lag \nperiod. Create a distributed lag \nnonlinear model, an artificial neural\
    \ \nnetwork model, and machine learning \nsoftware to estimate the standardized\
    \ \nwater evaporation index\nZhang et al. (2019a)\nSwitzerland\n2019\n2006–2017\
    \ Lightning\nA four‑parameter model was created \nbased on four frequently used\
    \ surface \nmeteorological variables—station‑\nlevel air pressure, temperature,\
    \ rela‑\ntive humidity, and wind speed. Use \ndata validation from the lightning\
    \ \nlocation system to confirm the gener‑\nated alert\nMostajabi et al. (2019)\n\
    Taiwan, China\n2020\n1965–2019 Typhoon\nDigitize the path of typhoons before \n\
    and after landfall using artificial \nintelligence methods and combine \nit with\
    \ hydrological and geographic \nfeatures for prediction\nChang et al. (2020)\n\
    Poland\n2019\n2008–2017 Hail\nBuilding a machine learning model \ndriven by radar\
    \ reflectivity, remote \nsensing data, and environmental vari‑\nables to predict\
    \ hail\nCzernecki et al. (2019)\nShaanxi, China\n2023\n1982–2020 Drought\nEmploying\
    \ three‑dimensional identifi‑\ncation approaches to recognize bio‑\nlogical and\
    \ meteorological drought \nevents, extracting the propagating \ndrought events\
    \ based on certain spati‑\notemporal overlap rules, and comput‑\ning the propagation\
    \ probability by \nfusing machine learning models and \nC‑vine copula\nJiang et al.\
    \ (2023); \nPham et al. (2020)\n2534\n \nEnvironmental Chemistry Letters (2023)\
    \ 21:2525–2557\n1 3\non the physical planting conditions, the ability to utilize\
    \ cli‑\nmate, and the level of understanding of crops of fruit farm‑\ners. Using\
    \ the cellular automata model of an artificial neural \nnetwork, Saputra and Lee\
    \ (2019) selected the height, slope, \naspect, distance, and soil type as parameters\
    \ to simulate and \npredict the change in land use and land cover in Sumatra.\n\
    Artificial intelligence is more intelligent and automated in \nland classification,\
    \ allowing for global zoning and decision‑\nmaking. Besides, artificial intelligence\
    \ has improved soil \nfunctionality and land use sustainability. AlDousari et al.\
    \ \n(2022) employed support vector machines and artificial \nneural networks to\
    \ assess and forecast changes in Kuwait’s \nland usage and cover. Combining a\
    \ linear regression tech‑\nnique and an artificial neural network, Ebrahimi et al.\
    \ (2019) \nassessed various subsurface soil parameters from diverse \nland use\
    \ efficiencies and projected soil respiration using \ndetailed soil data. Nguyen\
    \ et al. (2021) investigated a tech‑\nnique for openly accessing existing data\
    \ and Sentinel‑2 sat‑\nellite photos through machine learning algorithms. Then\
    \ \nthey utilized land use maps to examine how changes in land \nuse affect sustainable\
    \ development using local and global \nindicators.\nIn summary, weather forecasting\
    \ is a data issue. The accu‑\nracy of artificial intelligence in weather forecasting\
    \ will con‑\ntinue to improve as the amount of analyzed data increases. \nThe\
    \ increase in accuracy and timeliness of weather forecast‑\ning can help reduce\
    \ the occurrence of weather disasters and \nimprove land use efficiency.\nPotential\
    \ of artificial intelligence‑assisted \nrenewable energy forecasting and grid\
    \ \nmanagement\nThe expansion of the global population and economy has \nled to\
    \ an increase in energy use. Although with techno‑\nlogical advances and energy\
    \ efficiency legislation, the effi‑\nciency of energy end‑use services has gradually\
    \ increased. \nHowever, this improvement is not always enough to offset \nincreased\
    \ demand for energy services, such as commodity \nproduction and consumption.\
    \ Farghali et al. (2023) men‑\ntioned that global energy‑related carbon emissions\
    \ reached \nalarming levels in 2021 and rebounded to the second‑highest \nannual\
    \ growth rate in history. Chatterjee and Dethlefs (2022) \napplied that traditional\
    \ energy sources affected the environ‑\nment, leading to difficulties such as\
    \ acid rain, greenhouse \neffects, and ozone depletion. Sustainable green energy,\
    \ such \nas wind and solar, can replace traditional energy to reduce \ncarbon\
    \ emissions. As a result, the share of renewable energy \nin global power generation\
    \ jumped from 27% in 2019 to \n29% in 2020. Renewable energy generation grow by\
    \ more \nthan 8% in 2021, the fastest year‑on‑year increase since the \n1970s.\
    \ Solar and wind contribute two‑thirds of the growth \nin renewable energy. Hannan\
    \ et al. (2021) found that overall \nrenewable energy production should increase\
    \ the share of \nrenewable energy in electricity generation structures to a \n\
    record 30% in 2021.\nThere are many challenges to renewable energy produc‑\ntion,\
    \ such as land and human resource waste due to inap‑\npropriate site selection,\
    \ security risks due to poor layout, \nand the intermittent impact of renewable\
    \ energy production \non the grid. Intermittent production is the primary issue\
    \ of \nrenewable energy. The time and extent of electricity gen‑\nerated by commonly\
    \ used renewable sources are not con‑\ntrolled. The power generated by tradition\
    \ can be manually \nadjusted by the power required for the load, while the output\
    \ \npower of green energy is uncontrollable. The power gener‑\nated by renewable\
    \ energy sources usually depends on solar \nradiation, wind, and other factors.\
    \ Alassery et al. (2022) \napplied the difference between the output power of\
    \ green \nenergy and the power required for the load can lead to power \noutages\
    \ or excessive energy output, resulting in a waste of \nenergy.\nArtificial intelligence\
    \ can help promote the broader adop‑\ntion of renewable energy worldwide. Artificial\
    \ intelligence is \na powerful tool for solving the complexity of global energy\
    \ \ntransformation, improving system efficiency, and reducing \ncosts. Bahaloo\
    \ et al. (2022) mentioned that the digitization \nof oil and gas was well documented,\
    \ with almost all energy \nmajors adopting artificial intelligence, machine learning,\
    \ and \nother innovative technologies to improve operations. Arti‑\nficial intelligence\
    \ can also be used in wind, solar, and other \ngreen energy projects to increase\
    \ efficiency through greater \nautomation. Liu et al. (2022c) applied that as\
    \ energy compa‑\nnies looked to digitize operations to a greater extent, artifi‑\n\
    cial intelligence play a leading role in energy transformation \nin the future.\
    \ Because solar and wind have high randomness, \nlow predictability, and intermittent\
    \ characteristics, using \nintelligent technology for renewable energy scheduling,\
    \ \nmanagement, and optimization can stabilize the grid power \nand ensure the\
    \ grid supply security, as shown in Fig. 3.\nIn the early planning phase, artificial\
    \ intelligence can bet‑\nter generate renewable energy locally by planning and\
    \ siting. \nArtificial intelligence uses geographic information systems \nto select\
    \ suitable places to produce renewable energy. Arti‑\nficial intelligence determines\
    \ the most convenient address \nbased on a comprehensive topography analysis,\
    \ climate, land \nuse, and other factors. In site selection, there is no need\
    \ for \nrenewable energy leaders to visit the local area. Artificial \nintelligence\
    \ can assist investors in determining the risk level \nof new green energy projects,\
    \ predicting the energy produc‑\ntion of various renewable energy sources under\
    \ different \nconditions, and anticipating energy demand in different loca‑\n\
    tions at different times of the day through neural modeling \nanalysis. An et al.\
    \ (2023) demonstrated the use of artificial \nintelligence in determining the\
    \ optimal location for a solar \n2535\nEnvironmental Chemistry Letters (2023)\
    \ 21:2525–2557 \n1 3\nfarm based on the time and intensity of the sun, assisting\
    \ \noperators in site layout planning, and controlling solar panels \nto rotate\
    \ toward the sun throughout the day for maximum \nsunlight capture when generating\
    \ electricity through solar \nenergy.\nArtificial intelligence minimizes operational\
    \ costs by \nidentifying faults at an early stage. Shin et al. (2021) applied\
    \ \nthat the impact of a failure in the renewable energy indus‑\ntry may be disproportionate\
    \ compared to other machinery \nindustries. For example, when a wind power plant's\
    \ main \ncomponents are damaged late, significant elements must \nbe manufactured\
    \ and transported. High requirements for \ncustomization and complicated installation\
    \ will make the \nwind turbine shut down for several months, so in addition \n\
    to maintenance costs, there will be a considerable loss of \nrevenue. Bode et al.\
    \ (2020) mentioned that artificial intel‑\nligence‑assisted methods had attracted\
    \ attention. Artificial \nintelligence uses neural network learning methods to\
    \ input \nhistorical and real‑time data into artificial intelligence \nmodels\
    \ for comparison. Heo et al. (2022) mentioned that \nif data is abnormal, artificial\
    \ intelligence will provide diag‑\nnostic advice to the human inspector to help\
    \ the artificial \nintelligence make the final decision. This help is expected\
    \ to \nlead to better predictive maintenance by overcoming several \nlimitations\
    \ of manual inspection, such as the fatigue and \nvariability of inspectors.\n\
    Artificial intelligence’s prediction and management of \npower characteristics\
    \ can often be divided into power gen‑\neration and demand forecasting. Bendaoud\
    \ et al. (2022) \nstated that when people need power generation forecasting, \n\
    artificial intelligence is often used to combine multiple mete‑\norological models\
    \ to improve the accuracy of sustainable \nenergy forecasts. For example, the\
    \ Thomas Institute, in con‑\njunction with the National Renewable Energy Laboratory\
    \ of \nthe USA, has developed a model that includes a variety of \nweather parameters\
    \ and imports a large amount of historical \ndata for artificial intelligence\
    \ learning. Boza and Evgeniou \n(2021) compared with a meteorological model with\
    \ only one \nparameter, the prediction accuracy of solar energy is more \nthan\
    \ 30% higher. The UK's national grid power system oper‑\nators also use artificial\
    \ intelligence to improve renewable \ngeneration forecasts. The carrier provides\
    \ a system based \non about 80 input variables and improved solar forecasting\
    \ \nby 33%. Wind power can also create models for learning \nFig. 3  Technology's\
    \ role in managing renewable energy sources and \nthe power grid using artificial\
    \ intelligence. This figure shows how \nartificial intelligence connects the power\
    \ grid, renewable energy col‑\nlectors, and power distribution cabinets used by\
    \ residents. The figure \nshows that artificial intelligence can timely adjust\
    \ and control each \npart’s input and output power by controlling the smart meter.\
    \ This \nfigure illustrates how artificial intelligence is used in today's energy\
    \ \nnetworks. In addition, this figure shows how artificial intelligence \ncan\
    \ better ensure normal electricity use by using smart meters to take \ninformation\
    \ to control the charging and discharging of electrical stor‑\nage devices\n2536\n\
    \ \nEnvironmental Chemistry Letters (2023) 21:2525–2557\n1 3\nthe information\
    \ used in weather forecasting. This model \nincreases the value of wind power\
    \ and reduces the risk and \nloss of machines from storms through intelligent\
    \ regulation.\nAs with power generation forecasting, demand forecasting \nis essential\
    \ to balance the grid. Wang et al. (2019) mentioned \nthat the global deployment\
    \ of smart meters has significantly \nincreased available data related to power\
    \ consumption, pro‑\nviding a database for artificial intelligence to build predictive\
    \ \nmodels. Artificial intelligence makes an overall linear and \nnonlinear energy\
    \ demand prediction model through artificial \nneural networks. General linear\
    \ models are more effective \nthan nonlinear energy demand forecasting models\
    \ for large, \ngeographically divided environments. Saxena et al. (2019) \nmentioned\
    \ that nonlinear energy demand forecasting models \nperform better in smart cities,\
    \ especially in complex environ‑\nments with increasingly small geographic/market‑scale\
    \ fore‑\ncasts. In the study, the nonlinear energy demand prediction \nmodel accurately\
    \ predicted 40 days of 57 peak load days at a \nuniversity in the USA, with predictions\
    \ of up to one percent \naccuracy, and estimated that a university in the USA\
    \ could \nsave about 80,000 dollars over a 1‑year test period. It also \ndemonstrates\
    \ the potential of artificial intelligence to deliver \neconomic benefits in demand\
    \ forecasting.\nGuo et al. (2023) analyzed that grid frequencies play a \ncentral\
    \ role in grid control because they reflect the power \ngeneration and demand\
    \ balance. The excess power supply \ncan increase frequencies, while shortages\
    \ lead to lower fre‑\nquencies. Large frequency deviations correspond to large\
    \ \npower imbalances, threatening system stability and lead‑\ning to large‑scale\
    \ power outages. Artificial intelligence \nsystem significantly affects the temporary\
    \ problem of the \nintelligent grid, combined with information, digitization,\
    \ \ninnovative operation mechanism, operation mode, and real‑\nizing practical\
    \ analysis. Nawaz et al. (2021) mentioned that \nartificial intelligence relies\
    \ on the analogy and learning of \nmany training samples to form the knowledge\
    \ of grid stabil‑\nity evaluation to make online discrimination of grid safety\
    \ \nlevel. People analyzed the complex mechanism of the power \nsystem involves\
    \ many factors affecting electromagnetic and \nelectromechanical transient processes,\
    \ reaching hundreds \nof nodes in the test system alone. Artificial intelligence\
    \ \nhas advantages over traditional machine learning in solv‑\ning complex problems\
    \ with multiple factors and unknown \nmechanisms.\nKruse et al. (2021) stated\
    \ that artificial intelligence helps \npeople generate renewable energy and reduce\
    \ carbon emis‑\nsions, but it still has significant challenges as a new tech‑\n\
    nology. To efficiently manage new sample data that is con‑\nstantly generated\
    \ in the power system’s operation, strengthen \nthe power system's stability analysis\
    \ based on artificial \nintelligence. There is a need for timely disaggregation\
    \ of \nthe latest data. It takes much time and can cause learning \nto lag behind\
    \ data updates. Artificial intelligence requires \nmore historical data than traditional\
    \ time domain simulation \nand reverse trajectory techniques. Xu and Yin (2015)\
    \ built \na learning model that selects/extracts critical features in the \ngrid,\
    \ reduces spatial input dimensions, eliminates redundant \ncomponents, and improves\
    \ predictive efficiency.\nIn conclusion, artificial intelligence's potential for\
    \ renew‑\nable energy has been proved, and artificial intelligence helps \npeople\
    \ to locate renewable energy sources and prevent facili‑\nties from failing. Because\
    \ of the uncontrollability of renew‑\nable energy production, too much electricity\
    \ will be wasted, \nand too little electricity will affect people's regular use.\
    \ Arti‑\nficial intelligence coordinates grids by predicting renewable \nenergy\
    \ production to reduce energy waste. The initiative of \nartificial intelligence\
    \ to help power grid operators has been \nrecognized in many regions and has created\
    \ some resource \nbenefits.\nFeasibility of artificial intelligence \nin energy‑efficient\
    \ building design \nand retrofitting\nIntegrating artificial intelligence in building\
    \ energy‑efficient \ndesign and retrofitting is a rapidly developing field with\
    \ tre‑\nmendous promise for reducing energy consumption and car‑\nbon emissions\
    \ in the built environment (Moraliyage et al. \n2022; Tian et al. 2021). By leveraging\
    \ the power of advanced \nalgorithms, artificial intelligence can analyze copious\
    \ \namounts of data, including energy usage patterns, building \noccupancy, weather\
    \ conditions, and other relevant factors \nthat impact building energy consumption\
    \ (Kim et al. 2020). \nSubsequently, this analysis can inform the development\
    \ of \npredictive models that optimize building performance by \nadjusting heating\
    \ and cooling systems, lighting, and other \nbuilding systems, thereby minimizing\
    \ energy waste (Chen \net al. 2023b; Dong et al. 2021). Furthermore, artificial\
    \ intel‑\nligence can also be utilized to design new buildings that \nare inherently\
    \ more energy‑efficient by leveraging advanced \nmodeling and simulation tools\
    \ (Baduge et al. 2022). By opti‑\nmizing building orientation, window placement,\
    \ insulation, \nand other design elements, architects and engineers can cre‑\n\
    ate energy‑efficient and comfortable buildings for occupants \n(Debrah et al.\
    \ 2022).\nIn addition to optimizing new buildings, artificial intel‑\nligence\
    \ can be leveraged to retrofit existing buildings and \nimprove their energy efficiency\
    \ (Konhäuser et al. 2022). \nArtificial intelligence‑powered retrofitting involves\
    \ ana‑\nlyzing building data and identifying areas where energy \nefficiency can\
    \ be improved, such as upgrading insulation, \ninstalling efficient lighting,\
    \ or replacing outdated heat‑\ning, ventilation, and air conditioning systems\
    \ (Chan et al. \n2022). Therefore, artificial intelligence‑powered energy‑\nefficient\
    \ building design and retrofitting have the potential \n2537\nEnvironmental Chemistry\
    \ Letters (2023) 21:2525–2557 \n1 3\nto significantly reduce energy consumption\
    \ and carbon emis‑\nsions in the built environment. Although there are challenges\
    \ \nto implementing these technologies, such as the need for \naccurate data and\
    \ the cost of implementing new systems, the \nbenefits are evident, making this\
    \ a promising area for future \nresearch and development.\nThe integration of\
    \ artificial intelligence in energy‑effi‑\ncient building design and retrofitting\
    \ has the potential to \nrevolutionize the construction and operation of buildings,\
    \ \nleading to substantial reductions in energy consumption and \ngreenhouse gas\
    \ emissions (Zhang et al. 2023). By analyz‑\ning data on occupancy, weather conditions,\
    \ and other fac‑\ntors, buildings can be optimized to minimize energy waste \n\
    while ensuring occupant comfort, resulting in significant \ncost savings for building\
    \ owners and operators and a more \nsustainable built environment. Figure 4 demonstrates\
    \ how \nartificial intelligence can be utilized to analyze massive \namounts of\
    \ data and optimize various aspects of buildings, \nincluding heating, ventilation,\
    \ air conditioning, lighting \ncontrol, building envelope optimization, renewable\
    \ energy \nintegration, energy modeling, and predictive maintenance. \nFor instance,\
    \ artificial intelligence algorithms can adjust \nheating, ventilation, air conditioning,\
    \ and lighting systems \nto reduce energy waste based on data analysis of occupancy\
    \ \nrates and weather conditions (Chen et al. 2022a). Addition‑\nally, artificial\
    \ intelligence technology can assist in designing \nbuilding maintenance structures\
    \ by analyzing data on build‑\ning orientation and weather conditions, among other\
    \ factors \n(Huseien and Shah 2022). Artificial intelligence technology \ncan\
    \ also aid in integrating renewable energy sources into \nbuildings to reduce\
    \ reliance on non‑renewable resources (Al‑\nOthman et al. 2022). Moreover, by\
    \ detecting maintenance \nFig. 4  Designing and retrofitting energy‑efficient\
    \ buildings utiliz‑\ning artificial intelligence technology. The illustration\
    \ shows the use \nof artificial intelligence technologies to increase the efficiency\
    \ of \nheating, ventilation, and air conditioning systems, regulate lighting,\
    \ \noptimize building envelopes, incorporate renewable energy sources, \nsimulate\
    \ energy consumption, and predict maintenance needs within \nbuildings. The figure\
    \ also effectively illustrates the potential for arti‑\nficial intelligence technology\
    \ to offer pragmatic optimization solu‑\ntions by analyzing building data, reducing\
    \ energy consumption, and \nimproving occupant comfort. In addition, the figure \
    \ illustrates the \npotential for artificial intelligence technology to predict\
    \ building sys‑\ntem maintenance requirements\n2538\n \nEnvironmental Chemistry\
    \ Letters (2023) 21:2525–2557\n1 3\nneeds before the building's operational systems\
    \ fail, artificial \nintelligence technology can prevent downtime and ensure \n\
    the continuous operation of buildings (Javaid et al. 2022).\nMoreover, studies\
    \ indicate that utilizing artificial intel‑\nligence in energy‑efficient building\
    \ design and retrofitting \noffers many advantages, including rapidly and precisely\
    \ ana‑\nlyzing vast quantities of data (Ma et al. 2023). This enables \nartificial\
    \ intelligence algorithms to identify energy optimi‑\nzation opportunities that\
    \ might elude human analysts. For \ninstance, artificial intelligence can pinpoint\
    \ energy usage \npatterns imperceptible to the human eye, enabling building \n\
    operators to make modifications that can result in significant \nenergy savings\
    \ (Mhlanga 2023). In addition, artificial intel‑\nligence's capacity to generate\
    \ more accurate energy models \nof buildings can inform decisions regarding design\
    \ and ret‑\nrofitting (Saheb et al. 2022). Another benefit of incorporat‑\ning\
    \ artificial intelligence in energy‑efficient building design \nand retrofitting\
    \ is the ability to continuously monitor and \nadjust building systems in real\
    \ time (Felius et al. 2020). This \ncan result in enhanced energy performance\
    \ over the build‑\ning's lifespan. Artificial intelligence algorithms can tweak\
    \ \nbuilding systems to adapt to occupancy patterns, weather \nconditions, and\
    \ other factors. It also allows for predictive \nmaintenance of building systems,\
    \ mitigating downtime and \npreventing energy waste caused by poorly functioning\
    \ sys‑\ntems (Lee et al. 2019).\nTo conclude, the section mentioned above highlights\
    \ that \nusing artificial intelligence‑powered energy‑efficient build‑\ning design\
    \ and retrofitting presents a tremendous opportu‑\nnity for mitigating energy\
    \ consumption and carbon emis‑\nsions in the built environment. Using artificial\
    \ intelligence \nalgorithms to optimize building systems and design, build‑\n\
    ings can be more energy‑efficient while ensuring occupants' \ncomfort. The continued\
    \ research and development in this \ndomain are expected to give rise to novel\
    \ and pioneering \napplications, further amplifying the potential for energy con‑\n\
    servation and sustainability in the built environment.\nRole of artificial intelligence\
    \ in optimizing \ntransportation systems for reducing \ngreenhouse gas emissions\n\
    The transport sector contributes to greenhouse gas emis‑\nsions, constituting\
    \ almost one‑third of worldwide emissions \n(Solaymani 2019). As the globe confronts\
    \ climate change \nchallenges, decreasing transportation emissions has become\
    \ \na top priority (Li and Yu 2019). Using artificial intelligence \nto enhance\
    \ transportation systems and diminish carbon \nfootprint presents a promising\
    \ solution (Fatemidokht et al. \n2021). Artificial intelligence can revamp transportation\
    \ sys‑\ntems by refining routes, managing fleets, developing self‑\ngoverning\
    \ vehicles, optimizing public transit, and regulating \ndemand (Abduljabbar et al.\
    \ 2019). Using extensive data on \ntraffic patterns, passenger demand, and weather\
    \ conditions, \nartificial intelligence algorithms can identify opportunities\
    \ \nto curtail emissions and augment efficiency in transporta‑\ntion systems.\
    \ This can result in substantial cost savings, as \nwell as a decline in greenhouse\
    \ gas emissions and a more \nsustainable transportation sector. Hence, Fig. 5\
    \ displays the \nvarious ways in which artificial intelligence can be employed\
    \ \nto optimize transportation systems and decrease their carbon \nfootprint,\
    \ along with the potential benefits and challenges of \nimplementing these solutions.\n\
    Artificial intelligence technology is extensively utilized \nin transport systems.\
    \ As per Fig. 5, artificial intelligence can \nbe applied to refine transportation\
    \ routes based on various \nfactors, such as traffic patterns, road conditions,\
    \ and weather \n(Chavhan et al. 2020). This can lead to reduced travel times,\
    \ \nimproved fuel efficiency, and reduced emissions. Further‑\nmore, artificial\
    \ intelligence can also be employed to manage \nvehicle fleets more efficiently,\
    \ which includes optimizing \nmaintenance schedules and fueling (Alexandru et al.\
    \ 2022). \nUsing predictive analytics to anticipate maintenance needs \nand plan\
    \ refueling stops, transportation systems can mini‑\nmize downtime and lessen\
    \ fuel consumption. Developing \nself‑governing vehicles presents the potential\
    \ to significantly \nreduce emissions by refining fuel efficiency and decreasing\
    \ \ntraffic congestion (Tyagi and Aswathy 2021). Artificial intel‑\nligence algorithms\
    \ can be utilized to control autonomous \nvehicles, refining their performance\
    \ and decreasing energy \nconsumption.\nFurthermore, artificial intelligence can\
    \ also be utilized \nto refine public transit systems, which includes scheduling\
    \ \nand route planning (Nikitas et al. 2020). By utilizing data on \npassenger\
    \ demand and traffic patterns, transit systems can \nrefine efficiency and reduce\
    \ emissions by diminishing empty \nbuses or trains and optimizing routes. Ultimately,\
    \ artificial \nintelligence can also be utilized in public transit systems, \n\
    including incentivizing users to transition to lower‑emission \nmodes of transportation,\
    \ such as public transit or electric \nvehicles (Olayode et al. 2020). Using data\
    \ on user behav‑\nior and preferences, transportation systems can promote the\
    \ \nadoption of more sustainable transportation modes.\nDespite the potential\
    \ benefits of artificial intelligence \ntechnologies in optimizing transport systems\
    \ to reduce car‑\nbon emissions and advance early carbon neutrality in the \n\
    transport industry, some challenges are still associated with \nthese technologies.\
    \ The utilization of artificial intelligence \ntechnologies in transportation\
    \ systems hinges on the aggre‑\ngation and interpretation of vast amounts of data,\
    \ includ‑\ning personal data about users. Ensuring the confidentiality \nand security\
    \ of this data is crucial to establish trust in these \nsystems and forestall\
    \ any potential misuse or exploitation. \nMoreover, implementing artificial intelligence\
    \ technologies \nnecessitates considerable investment in infrastructure and \n\
    2539\nEnvironmental Chemistry Letters (2023) 21:2525–2557 \n1 3\ntechnology, including\
    \ sensors, cameras, and data processing \ncapabilities. This can present a significant\
    \ obstacle, primar‑\nily for smaller transportation systems or those in developing\
    \ \ncountries (Abduljabbar et al. 2019).\nFurthermore, with the growing prevalence\
    \ of artificial \nintelligence technologies in transportation systems, a press‑\n\
    ing need arises for clear and effective governance and regu‑\nlation to ensure\
    \ ethical and responsible use. This involves \naddressing critical issues such\
    \ as determining liability for \naccidents involving autonomous vehicles and mitigating\
    \ the \nexacerbation of existing inequalities or biases. Additionally, \nthe potential\
    \ for autonomous vehicles and other artificial \nintelligence‑powered transportation\
    \ technologies to displace \nmany workers in trucking and delivery must be acknowl‑\n\
    edged. A just transition for affected workers should be a top \npriority. Finally,\
    \ the acceptance and adoption of artificial \nintelligence‑powered transportation\
    \ technologies hinge on \nvarious factors, including cultural attitudes, user\
    \ preferences, \nand trust in these systems. Thus, developing these technolo‑\n\
    gies should be user‑centric and involve consistent consulta‑\ntion with users\
    \ to ensure their success (Hahn et al. 2021).\nThis section elaborates on how\
    \ artificial intelligence \nalgorithms can be utilized to enhance transportation\
    \ sys‑\ntems, such as optimizing transportation routes, managing \nvehicle fleets,\
    \ controlling autonomous vehicles, optimizing \npublic transit systems, and managing\
    \ the demand for trans‑\nportation services. Nonetheless, implementing these tech‑\n\
    nologies necessitates substantial investment in infrastructure \nand technology\
    \ and clear governance and regulation while \nensuring data privacy and security.\
    \ Tackling these critical \nissues ensures that artificial intelligence‑powered\
    \ transpor‑\ntation technologies are developed and deployed responsibly \nand\
    \ ethically.\nUsing artificial intelligence for precision \nagriculture to reduce\
    \ fertilizer and chemical \nuse emissions\nAs demand for food production steadily\
    \ expands, chemical \ntreatments (pesticides) are widely used to increase crop\
    \ \nmarket penetration, thus significantly impacting pollina‑\ntors and the earth's\
    \ environment. Precision farming uses \ncutting‑edge sensors for predictive analytics\
    \ to gather \nreal‑time information on soil, crop maturity, air quality, \nweather,\
    \ equipment and labor prices, and availability to \nincrease agricultural yields\
    \ and improve decision‑making \n(Raj et al. 2021). Precision agriculture aims\
    \ to increase \nagricultural output and minimize environmental effects \n(Das\
    \ et al. 2018). It is making modern agriculture more \nprofitable and sustainable\
    \ by applying artificial intelli‑\ngence (Ampatzidis et al. 2020; Wei et al. 2020).\
    \ Preci‑\nsion agriculture benefits from artificial intelligence, which \nidentifies\
    \ pests, detect diseases, predicts yields, and plans \nfertilizer and pesticide\
    \ use. The technology enables mod‑\nels incorporating data inputs to measure farm\
    \ organization \nand directly impact efficiency, resulting in improved out‑\n\
    comes (Bacco et al. 2018; Reddy et al. 2020). Advances \nFig. 5  Importance of\
    \ artificial intelligence in reducing greenhouse \ngas emissions by optimizing\
    \ transportation systems. The illustra‑\ntion depicts the application of artificial\
    \ intelligence technology to \nimprove transportation systems and reduce carbon\
    \ emissions. The \nstatement emphasizes the potential for artificial intelligence\
    \ to opti‑\nmize transportation routes based on various factors. Furthermore,\
    \ it \ndemonstrates the capability of artificial intelligence to improve fleet\
    \ \nmanagement efficiency. In addition, the diagram depicts the potential \napplication\
    \ of artificial intelligence to the regulation of autonomous \nvehicles. Ultimately,\
    \ the diagram demonstrates that artificial intelli‑\ngence can potentially optimize\
    \ public transportation systems and con‑\ntrol transportation service demand.\
    \  CO2 refers to carbon dioxide\n2540\n \nEnvironmental Chemistry Letters (2023)\
    \ 21:2525–2557\n1 3\nin computer vision, machine learning, and deep learning \n\
    technologies may be used to identify crop illnesses from \nvarious current crop\
    \ diseases accurately, quickly, and more \nswiftly. Robotics and artificial intelligence\
    \ are developing \ncognitive capacities similar to those of humans, increasing\
    \ \nproductivity and enhancing and amplifying human poten‑\ntial (Barile et al.\
    \ 2019).\nHerbicides or other chemical residues are left on plant \nproducts due\
    \ to chemical spray transfer, often when the \nwind blows tiny droplets of spray\
    \ solution to nearby crops \nor fields (Creech et al. 2015). The use of unneeded\
    \ herbi‑\ncide applications to redundant regions can result from preci‑\nsion\
    \ spraying technology, which can drastically reduce the \nquantity of herbicide\
    \ required. Applying herbicides where \nweeds are present might lessen the environmental\
    \ impact \nwhile lowering the risk of expense, crop damage, and exces‑\nsive chemical\
    \ residues (Balafoutis et al. 2017). Applications \nfor agricultural remote sensing\
    \ are increasingly using deep \nlearning and convolutional neural networks (Kussul\
    \ et al. \n2017). According to Swaminathan et al. (2023), robots that \nmonitor\
    \ and spray weeds using computer vision and artifi‑\ncial intelligence might eliminate\
    \ 80% of the chemicals now \nsprayed on crops and lower the price of herbicides\
    \ by 90%. \nA fertilizer application model is used in precision fertiliza‑\ntion\
    \ to calculate the necessary fertilizer input and apply ferti‑\nlizer using a\
    \ variable rate applicator after checking the soil’s \nnutrient levels and segmenting\
    \ the field into a grid (Elbeltagi \net al. 2022). Precision fertilizer application\
    \ can minimize \nfertilizer use, increase crop yields, balance soil nutrients,\
    \ \nand reduce atmospheric emissions. Table 3 demonstrates the \nuse of artificial\
    \ intelligence technology to improve the use of \nfertilizers and pesticides in\
    \ precision agriculture.\nUsing genome analysis and editing techniques, precision\
    \ \nagriculture and artificial intelligence technologies may gen‑\nerate successful\
    \ crops that are fit for the land and maximize \nplant production (Joseph et al.\
    \ 2021). Lessening the effect of \nchemicals on the soil will help minimize the\
    \ usage of chemi‑\ncal fertilizers in agriculture and make farming more ecologi‑\n\
    cally friendly. In Hafizabad and Sheikhupura districts, Elahi \net al. (2019a)\
    \ estimated target values of agrochemicals used \non rice farms by maintaining\
    \ rice yields at current levels and \nfound that 52.6% of pesticide and 43.6%\
    \ of pure nitrogen \nfertilizer inputs could be reduced to have a favorable and\
    \ \nsignificant impact. Putra et al. (2020) modeled the amount \nof nutrient data\
    \ stored and released by fertilizer application \nto simulate the availability\
    \ and loss of oil palm nutrients so \nthat the nutrient balance can be effectively\
    \ determined to \nbe maintained by fertilizer application to a specific site.\
    \ Du \net al. (2021) developed a water and fertilizer control system \nbased on\
    \ soil conductivity thresholds to improve the utiliza‑\ntion of water and fertilizer\
    \ for cotton cultivation from soil \nconductivity and moisture content, resulting\
    \ in a 10.89% \nreduction.\nChen et al. (2020a) enhanced image recognition of\
    \ pests \nby using the “You Only Look Once” neural algorithm and \nacquired images\
    \ using an uncrewed aerial vehicle with a \n90% recognition rate. High‑resolution\
    \ pest images are \nacquired by stabilized flight unmanned aerial vehicles to\
    \ \nsolve the disturbance of leaves by propeller wind. Enhance \nthe speed of\
    \ picture identification to locate pests and dis‑\neases more effectively and\
    \ use fewer pesticides on farms. \nThe smart sprayer is a piece of technology\
    \ that combines \nweed recognition, a mapping system, and a unique rapid and \n\
    precise spraying mechanism. It also uses a newly created \nalgorithm to generate\
    \ visual maps. Partel et al. (2019) used \nan embedded graphics processing unit\
    \ in a smart sprayer \nfor precision weed control of artificial and amaranth weeds\
    \ \nwith 59–71% accuracy, which can significantly reduce pes‑\nticide costs, crop\
    \ damage, and the risk of excessive herbi‑\ncide residues, and potentially reduce\
    \ environmental impacts. \nFacchinetti et al. (2021) used a “Rover” sprayer vehicle\
    \ to \naccurately detect color differences between salad and ground \nand reduce\
    \ pesticide spraying by 55%. The  I2PDM system \nis composed of an intelligent\
    \ integrated pest management \nwireless sensor network that collects images, pest\
    \ num‑\nbers, and species through sensor nodes and stores them in \na database\
    \ for analysis, thus generating models that can be \nvisually translated into\
    \ numerical information (Rustia et al. \n2020). The technique was applied to a\
    \ tomato field, and the \npesticide dose was reduced from 235 to 204 L/time (16%),\
    \ \nindicating that insecticide spraying effectively reduced pests \n(Rustia et al.\
    \ 2022).\nIn conclusion, artificial intelligence provides systems that \nare proved\
    \ to be scalable, stable, and accurate to provide \nreal‑time data for precision\
    \ agriculture. Artificial intelli‑\ngence‑supported precision agriculture eliminates\
    \ random‑\nness, provides precise and required amounts of fertilizers \nand pesticides,\
    \ and can increase food productivity by utiliz‑\ning the limited available arable\
    \ land for farming.\nUse of artificial intelligence in optimizing \nindustrial\
    \ processes for more \nenergy‑efficient and lower‑emission \noperations\nIn recent\
    \ years, various companies have also recognized the \nidea of energy conservation\
    \ and emission reduction effi‑\nciency by developing a green energy strategy.\
    \ In the pro‑\ncess of energy transformation, many industrial enterprises \nare\
    \ in the process of developing many challenges. However, \nthe use of artificial\
    \ intelligence can provide new ideas for \nthe transformation of these companies.\
    \ Lei et al. (2023) \nmentioned that traditional enterprises had used many excel‑\n\
    lent management methods, such as comprehensive quality \nmanagement, ISO 9000\
    \ quality management system, and \n2541\nEnvironmental Chemistry Letters (2023)\
    \ 21:2525–2557 \n1 3\nTable 3  Artificial intelligence interventions to improve\
    \ fertilizer and chemical use in precision agriculture\nUsing algorithms, artificial\
    \ intelligence accurately calculates and sprays chemicals on pests and fertilizer\
    \ application points. Combining artificial intelligence with fertilizers and pesticides\
    \ can \nincrease their efficiency, thereby reducing the amount of fertilizers\
    \ and chemicals used in agriculture. In addition, artificial intelligence is expected\
    \ to reduce the environmental impact of agricul‑\ntural chemicals and fertilizers\n\
    Agricultural products\nArtificial intelligence\nDescriptions\nImpact\nReferences\n\
    Paddy in Sheikhu‑\npura and Gujran‑\nwala districts\nArtificial neural networks\n\
    Evaluated the actual usage of agrochemicals\nReduce pesticides: 52.6%; nitrogen\
    \ fertilizer: \n43.6%\nElahi et al. (2019a)\nLongan\nYou Only Look Once, the neural\
    \ network \nalgorithm\nMarking of pests to predict the distribution \nlocation\
    \ and occurrence time of pests and \ndiseases\nPest identification rate of 90%\n\
    Chen et al. (2020a)\nArtificial weeds\nEmbedded graphics processing unit (NVIDIA\
    \ \nGTX 1070 Ti) smart sprayer\nMapped weeds, developed sensor fusion algo‑\n\
    rithms to remove noise and improve weed \nlocalization accuracy\n71% overall accuracy\
    \ rate\nPartel et al. (2019)\nAmaranthus weed\nGraphics processing unit (NVIDIA\
    \ Jetson \nTX2) smart sprayer\n59% overall accuracy rate\nSalad\n“Rover” sprayer\
    \ car\nColor detection and segmentation algorithms \nto find plants; high‑pressure\
    \ variable speed \nspraying of pesticides\n55% reduction in pesticide spraying\n\
    Facchinetti et al. (2021)\nTomato\nIntelligent and integrated pest and disease\
    \ \nmanagement (Intelligent  I2PDM) programs; \nconvolutional neural networks\n\
    Cascade deep learning classification algorithm \ndetects and identifies pests\
    \ on sticky paper \ntraps for image classification\nPesticide doses were reduced\
    \ by about 16%\nRustia et al. (2022)\nOil palm (Elaeis \nguineensis Jacq) in \n\
    Indonesia\nAndroid fertilizer application\nStock and flow diagrams calculation\
    \ solution \ndevelopment\nSimulation of nutrient availability and loss \nduring\
    \ oil palm care or cultivation\nPutra et al. (2020)\nCotton\nEfficient water and\
    \ fertilizer control system for \ncotton with wireless sensor network\nWireless\
    \ sensor network data collection trans‑\nmits data to the decision support system,\
    \ \nconsidering soil conductivity and moisture \ncontent\n10.89% reduction in\
    \ fertilizer application (0.76 \nto 0.87 tons of chemical fertilizer)\nDu et al.\
    \ (2021)\n2542\n \nEnvironmental Chemistry Letters (2023) 21:2525–2557\n1 3\n\
    management excellence model. These management methods \nare usually analyzed from\
    \ a macro perspective. Integrating \nartificial intelligence into traditional\
    \ industries facilitates a \ndigital transformation that allows for micro‑level\
    \ monitoring \nof industrial processes. Artificial intelligence can optimize \n\
    energy usage and reduce emissions by analyzing data and \nfeedback mechanisms,\
    \ leading to greater energy conserva‑\ntion and efficiency. This section will\
    \ analyze the application \nof artificial intelligence in industrial processes.\n\
    Artificial intelligence optimizing industrial \nprocesses preconstruction\nArtificial\
    \ intelligence optimizes preindustrial process design \nby managing product design\
    \ and industrial process layout. \nNeural networks are computational algorithms\
    \ that simulate \nhuman brain analysis and processing of information through \n\
    artificial intelligence. Artificial intelligence can use neural \nnetwork learning\
    \ to create process plans using geometric \ndata, decision logic, and algorithms.\
    \ It incorporates manu‑\nfacturing process plans for new goods based on part forms,\
    \ \nmaterials, and other factors. The system's primary input is a \ndescription\
    \ of the geometry. Leo Kumar (2017) mentioned \nthat designers could quickly get\
    \ input from it, which closely \ncoordinates with product modeling activities.\
    \ Artificial intel‑\nligence can increase the space usage of the model by opti‑\n\
    mizing the model, thus saving more material‑saving prod‑\nucts, increasing industrial\
    \ process efficiency, and reducing \nemissions from the point of view of the product's\
    \ use of \nmaterials. Artificial intelligence optimizes industrial process \n\
    layouts to save energy and reduce scrap rates. Manufactur‑\ning has seen success\
    \ with machine learning, automation and \nrobotics, machine vision, data mining,\
    \ big data, and expert \nsystems. Sarker (2022) stated that artificial intelligence\
    \ tech‑\nnology could understand the operation of each process step \nto identify\
    \ the problem, timely adjustment, and optimization. \nThe same artificial intelligence\
    \ can help planners determine \nthe allocation of human resources earlier so that\
    \ projects can \nproceed earlier.\nIn conclusion, artificial intelligence optimizes\
    \ the upfront \nlayout of industrial processes with a more rational product \n\
    design and a more appropriate division of labor. Artificial \nintelligence saves\
    \ energy by providing granular data to help \npeople make more rational decisions\
    \ in the early design \nstages.\nOptimizing mid‑stage industrial process \nconstruction\
    \ with artificial intelligence\nThe most important aid of artificial intelligence\
    \ in industrial \nprocesses is to monitor control and detect equipment losses\
    \ \nin advance. Collecting data using hardware sensors to moni‑\ntor industrial\
    \ production processes is traditional. However, \nthere are some challenges in\
    \ the use of hardware sensors. \nFor example, temperature, humidity in different\
    \ working \nenvironments, cumbersome personalization requirements, \nslow measurement\
    \ data transfer, and higher cost of hard‑\nware sensors all impact measurement\
    \ results. Perera et al. \n(2023) applied traditionally. This issue has been resolved\
    \ by \napplying straightforward fixes like removing data points with \nmissing\
    \ values or substituting them with the average values \nof the variables they\
    \ influence. However, these technologies \nare not regarded as the ideal answer\
    \ due to the possibility \nof affecting model performance. Xie et al. (2020) reported\
    \ \nautoencoder is a deep neural network that can extract rel‑\nevant information\
    \ features and reconstruct data in several \nsets. Suppose the potential variable\
    \ is a random variable, \nand its probabilistic variant is called a variational\
    \ autoen‑\ncoder by building a new soft sensor framework. Data loss \ndue to sensor\
    \ failure in industrial processes can also work \nwell with neural network learning.\
    \ The most recent artificial \nintelligence‑based algorithms allow soft sensors\
    \ to increase \ncomputational efficiency and forecast accuracy by resolving \n\
    the drawbacks of conventional modeling methods compared \nto classical statistics\
    \ and machine learning‑based models. \nThis model enables better monitoring and\
    \ control of the \nprocess, lowering pollutants and material and energy waste.\
    \ \nPerera et al. (2023) mentioned that industrial processes use \nsoft sensors\
    \ to monitor operations. However, they typically \nhave the following four issues:\
    \ missing data from tiny data‑\nsets, dimensionality reduction, process adaptation,\
    \ and fea‑\nture extraction from time and space. Specialists from various \nfields\
    \ use artificial intelligence to solve the issues in Table 4.\nArtificial intelligence\
    \ also controls various catalysts in \nindustrial processes and associated toxic\
    \ gas emissions. Sun \net al. (2019a) mentioned that refineries could continuously\
    \ \nmonitor and keep emissions under the required limits thanks \nto using soft\
    \ sensors, which directly impact environmental \nsustainability. Fernandez de\
    \ Canete et al. (2021) reported \nthat soft sensors could be created for the pulp\
    \ and paper \nsector to detect levels of bleached wastewater containing \nhazardous\
    \ chemicals. The pulp and paper sector uses soft \nsensors to anticipate chemical\
    \ oxygen demand for financial \ngain and material efficiency, enabling influential\
    \ paper wash‑\ning with fewer chemicals.\nArtificial intelligence helps industrial\
    \ processes perform \ncomplex operations. The assembly industry is the process\
    \ \nby which mechanical parts or components are connected \naccording to the technical\
    \ requirements of the design, com‑\nbining mechanical parts or components into\
    \ machines. \nThe assembly industry can effectively reduce some links \nin industrial\
    \ processes and speed up the use of raw materi‑\nals by using assembly‑style preconditioners\
    \ that can effec‑\ntively reduce manual errors. Cohen et al. (2019) stated \n\
    that precomponent production requires significant data \nanalysis. In modeling,\
    \ if component data problems produce \n2543\nEnvironmental Chemistry Letters (2023)\
    \ 21:2525–2557 \n1 3\nTable 4  Common sensor problems and their solutions This\
    \ table details the most common issues with soft sensors and the corresponding\
    \ solutions\nThe following table outlines soft sensor‑related issues, their causes,\
    \ and corresponding solutions. Developing neural network models increases the\
    \ availability of complementary soft sensors. \nThrough the development of empirical\
    \ models, the team of experts expedites the processing of data collected by soft\
    \ sensors. By reducing their conditions, artificial intelligence can also facili‑\n\
    tate using soft sensors in various working environments\nProblem\nProblem cause\n\
    Solution\nReferences\nMissing data from small datasets\nFrequent hardware sensor\
    \ failures\nA sequence neural network model that can handle short \ndata sets\
    \ could be proposed. The model's encoder makes \npredictions and processes the\
    \ variable's dynamics. In terms \nof prediction accuracy, this prediction method\
    \ outperforms \nconventional artificial neural networks\nChou et al. (2020)\n\
    Categorize lost data as lightweight, medium, or heavy and \ndelete the corresponding\
    \ levels. Use average interpolation \nto supplement the missing data and apply\
    \ neural network \nlearning\nXie et al. (2020)\nDimensionality reduction\nRedundant\
    \ variables that result from dimensionality reduction \nmay unnecessarily increase\
    \ the complexity of the soft sensor \nmodel. The performance of soft sensors may\
    \ thus suffer as a \nresult of this\nExtract features from the previous layer\
    \ and then build a \nmodel to restore data using this information, ensuring that\
    \ \ninformation can be passed between different levels to better \nstore data\n\
    Yuan et al. (2020)\nThe model divides the data into subsets and then determines\
    \ \nthe subset's variables, maximizing the data set's responsive‑\nness\nHikosaka\
    \ et al. (2020)\nAdapting to varying process conditions\nThe machine's performance\
    \ changes due to process operating \nconditions, weather, or seasonal changes.\
    \ The related perfor‑\nmance of the machine changes and the relevant parameters\
    \ \nare affected\nTraining adaptive soft sensors update historical data sets to\
    \ \npredict data at an early stage of change after cumulative \ntraining\nSun\
    \ et al. (2020)\nUse special metrics to work with data samples and select the\
    \ \nmost relevant data from the historical data set to model。\nZheng et al. (2021)\n\
    Extracting temporal and spatial features Industrial processes have a strong temporal\
    \ dependence. Tra‑\nditional static models are unable to derive from process data\
    \ \nrelevant dynamic information\nThe network contains time and spatial attention\
    \ modules that \nextract time and space features from the data. Then use the \n\
    spacetime fusion module to merge the extracted features. \nThe data obtained by\
    \ this feature can fit highly with dynamic \ndata\nWu et al. (2021)\n2544\n \n\
    Environmental Chemistry Letters (2023) 21:2525–2557\n1 3\nwaste, reducing the\
    \ enterprise’s productivity can also cause \nresource waste. Cioffi et al. (2020)\
    \ mentioned that one is for \nintelligent manufacturing. This fully integrated\
    \ collaborative \nproduction system reacts in real time to changing condi‑\ntions\
    \ in the factory, supply network, and customer needs. \nThe other solution is\
    \ lean manufacturing, which aims to \nreduce costs while maximizing efficiency.\
    \ A transforma‑\ntional “cyber‑physical production system” converts data \nfrom\
    \ connected systems into predetermined and required \noperations for elastic performance.\
    \ The use of digital twin \ntechnologies supports the product lifecycle. Both\
    \ techniques \nmay guarantee the preconditioners' precision, enhancing effi‑\n\
    ciency and lowering emissions.\nTo summarize, in the middle of an industrial process,\
    \ arti‑\nficial intelligence assists soft sensors in monitoring pipeline \ndata.\
    \ Although there are some problems with soft sensors, \nartificial intelligence\
    \ minimizes the impact of problems in \nsoft sensors by building models. More\
    \ accurate data can help \npeople control the use of chemicals and reduce emissions.\n\
    Artificial intelligence optimizes industry processes \nin the late stage\nArtificial\
    \ intelligence optimization for the later stages of \nindustrial processes is\
    \ mainly optimized for the process. \nAfter some time in industrial processes,\
    \ managers use arti‑\nficial intelligence to address inappropriate and inefficient\
    \ \nresource allocation. Dwivedi et al. (2021) reported that arti‑\nficial intelligence\
    \ improves efficiency by combining manage‑\nment methods. For example, the combination\
    \ of artificial \nintelligence and lean production, through which each pro‑\n\
    duction link calculates the efficiency of the link and then \nreduces the waste\
    \ of related raw materials due to idle, can \nalso help the management of the\
    \ enterprise to optimize the \nproduction line. The primary use of artificial\
    \ intelligence \nhere is as a tool for data analysis and, thus, for interpret‑\n\
    ing or evaluating results to improve energy and resource \nmanagement.\nFlexible\
    \ manufacturing on mature production lines can \nbenefit from using artificial\
    \ intelligence. Resilient manu‑\nfacturing involves adapting to sudden changes\
    \ in the pro‑\nduction process to ensure continuous production activities. \n\
    As needed, intelligent optimization and field conditions are \nutilized to modify\
    \ the control system. Additionally, artificial \nintelligence can upload information\
    \ from related devices to \nthe cloud, allowing for remote manipulation of production\
    \ \nprocesses even when relevant managers are not present on‑\nsite. This feature\
    \ enhances the agility and resilience of the \nproduction process. Oruganti et al.\
    \ (2023) mentioned that \nthis model helps the assembly line in industrial processes\
    \ \ncope with accidents while reducing pressure on managers.\nIn this section,\
    \ artificial intelligence can optimize con‑\nvection lines in mature industrial\
    \ processes, reducing risks \nand scrap rates. It can also provide information\
    \ support for \nindustrial processes by uploading relevant pipeline informa‑\n\
    tion to mobile devices, enabling remote access to essential \ndata.\nIn summary,\
    \ artificial intelligence improves product \ndesign through data modeling and\
    \ enhances the monitoring \nof industrial processes through soft sensors, thereby\
    \ reduc‑\ning scrap rates. Additionally, in mature industrial systems, \nartificial\
    \ intelligence can optimize assembly lines, increase \nproductivity by eliminating\
    \ unnecessary processing steps, \nassist managers in flexible production, and\
    \ reduce the burden \non managers. Ultimately, artificial intelligence helps reduce\
    \ \nthe impact of labor on industrial processes and improves \noverall efficiency.\n\
    Artificial intelligence for natural resource \nmanagement: reducing deforestation\
    \ \nand emissions\nIn recent years, the difficulties and potentials regarding\
    \ natu‑\nral resource management (especially land, water, and forests) \nhave\
    \ been a hot topic of exploration worldwide. Humans are \nlosing valuable ecosystem\
    \ services and critical habitats that \nsustain biodiversity through the loss\
    \ of forests, so artificial \nintelligence models are thought to reduce the risk\
    \ of natural \nresource loss (Buchanan et al. 2008; Newman et al. 2014). \nIn\
    \ order to forecast incremental deforestation and deforesta‑\ntion rates in the\
    \ Amazon rainforest, Dominguez et al. (2022) \nemployed a dense neural network\
    \ to model spatially static \ndata and an extended short‑term memory network to\
    \ model \ntemporal data on deforestation. The rate of future forest loss \nis\
    \ estimated by comparing the prediction results and per‑\nforming retraining to\
    \ update the model with new data so that \naction can be taken in advance. The\
    \ freely available dataset \ngenerated reasonable deforestation risk maps using\
    \ all tech‑\nniques in the Mexico and Madagascar study areas. Mayfield \net al.\
    \ (2017) had more consistent predictive performance \nthrough Gaussian processes.\
    \ However, they could not use \nthe model to predict the amount or total area\
    \ of deforestation \nand risk factors and could only determine whether deforesta‑\n\
    tion risk exists. In addition, the weightless neural network \narchitecture created\
    \ by the field‑programmable gate array in \nconjunction with an unmanned aerial\
    \ vehicle for deforesta‑\ntion monitoring and visual navigation assessment in\
    \ green \nrural regions is shown to provide a greater level of process‑\ning of\
    \ visuals (Torres et al. 2020). Tien Bui et al. (2017) \nmodeled forest fires\
    \ by particle swarm optimization neuro‑\nfuzzy, which can determine the optimal\
    \ values of parameters \nand reasonably predict the causes of forest fires generated\
    \ in \nVietnam, random forest, and support vector machine. Tien \nBui et al. (2016)\
    \ developed fire sensitivity maps effective for \nplanning and management of forest\
    \ fires.\n2545\nEnvironmental Chemistry Letters (2023) 21:2525–2557 \n1 3\nIn\
    \ order to manage the environmental restoration of ter‑\nrestrial ecosystems by\
    \ creating a biological retreat configura‑\ntion for the Changsha–Zhuzhou–Xiangtan\
    \ urban area, Yin \net al. (2021) suggested an artificial intelligence‑assisted\
    \ \nintelligent planning framework. Its identification of envi‑\nronmental components\
    \ in existing biodefense zones supports \nthe effectiveness of machine learning\
    \ in green resource pre‑\ndiction, demonstrating that retreat configurations help\
    \ bet‑\nter understand urban growth's impact on environmentally \nrelevant processes.\
    \ The basis for ecological berm vegetation \nscreening and backpropagation is\
    \ soil moisture susceptible \nto climatic change and vegetation growth conditions.\
    \ Liu \net al. (2022a) suggested a neural network regression model \noptimized\
    \ by a genetic algorithm for roads in the Zhejiang \nprovince to modify the system's\
    \ greater processing power \nand address the problems with local minima. Controlling\
    \ \nor managing land pollution through prediction, clustering, \ndata‑centric\
    \ analysis, and soil quality evaluation requires \nartificial intelligence and\
    \ machine learning (Gautam et al. \n2023).\nManaging varied and complex urban\
    \ water resources \nrequires using current technological platforms owing to \n\
    increased water demand brought on by climate change, \nurbanization, and population\
    \ expansion (Mrówczyńska et al. \n2019). A more simplified procedure to increase\
    \ water effi‑\nciency is adaptive intelligent dynamic water resource plan‑\nning,\
    \ which uses a subset of artificial intelligence technology \nto maintain the\
    \ water environment in metropolitan settings \n(Xiang et al. 2021). Liu et al.\
    \ (2019) added dynamic iner‑\ntia weights to the moth flame algorithm in the projection\
    \ \ntracking water quality evaluation model with higher stability \nand reliability,\
    \ improving the regional water environment \nevaluation accuracy. Afzaal et al.\
    \ (2020) used recurrent \nneural networks and long‑ and short‑term memory to solve\
    \ \nthe problem of dynamic inputs of climate change in Prince \nEdward Island,\
    \ Canada. In order to complement crop water \nneeds, accurate calculation of reference\
    \ evapotranspiration \nmay give helpful data for water management and sustainable\
    \ \nagriculture. It can also provide immediate feedback on water \ndeficiency\
    \ in potatoes. Also, artificial neural networks can \nbe used to predict and evaluate\
    \ leachate infiltration from \nlandfills into groundwater, Bagheri et al. (2017)\
    \ analyzed the \ncost of leachate concentration at different depths by build‑\n\
    ing a fuzzy logic model of leachate infiltration into ground‑\nwater in Kurdistan\
    \ province for more accurate determina‑\ntion of molybdenum, sodium and chemical\
    \ oxygen demand \n(R2 = 0.99998).\nThe socioeconomic, environmental, and ecological\
    \ activi‑\nties that take place in urban areas, as well as the lives of the \n\
    populations that inhabit them, are significantly influenced by \nurban land use\
    \ planning. By using aerial imaging analysis \nto pinpoint physical surface materials\
    \ or human land use, \nthese investigations may be carried out at a considerable\
    \ \ncost and time savings. Geospatial data and environmental \ninformation may\
    \ be captured using remote sensing imaging \ntechnology for ground observation.\
    \ Deep learning models \ncan be used to categorize land cover or land use, and\
    \ they \ncan also be trained with high accuracy to classify differ‑\nent types\
    \ of habitations (Alem and Kumar 2022). Using an \nintelligent planning support\
    \ system based on a multiagent \nsystem and applying Bayesian learning methods\
    \ in Zanjan, \nnorthwest Iran, it is possible to perform automated urban \nland\
    \ use planning consultations (Ghavami et al. 2017). In \naddition, convolutional\
    \ neural networks that can perform \nmany image classification tasks have higher\
    \ performance for \nland cover/land classification than support vector machines,\
    \ \nrandom forests, and k‑nearest neighbors (Carranza‑García \net al. 2019).\n\
    In summary, artificial intelligence plays a crucial role \nin natural resource\
    \ management, as shown in Fig. 6. This \nincludes forest resource management,\
    \ ecosystem restora‑\ntion, water resource management, and land use planning.\
    \ \nArtificial intelligence facilitates the management of natural \nresource use,\
    \ rationalizes the allocation of natural resources, \nand reduces unnecessary\
    \ waste.\nUsing artificial intelligence in developing \nsustainable and resilient\
    \ cities\nAs a refuge for modern people, cities inhabit over half of \nthe world's\
    \ population, providing convenience for human \nmodernization while consuming\
    \ a large amount of energy. \nGreenhouse gases emitted by cities account for three‑quar‑\n\
    ters of the total emissions, making them the core strategy \nfor mitigating global\
    \ climate change. The impacts of climate \nchange on towns and the relationship\
    \ between it and sustain‑\nable urban development are complex (Mi et al. 2019).\
    \ With \nthe gradual severity of climate issues, cities face increasing \nuncertainties\
    \ and unknown risks. In addition to the urgent \nneed to solve issues like energy\
    \ shortages, air pollution, \nand waste management, people are becoming increasingly\
    \ \ninterested in how “resilient” communities are at handling \ncalamities (Zhu\
    \ et al. 2019). Resilient cities are a new urban \ngovernance concept that has\
    \ emerged after intelligent cities \nto improve the city's ability to withstand\
    \ disasters and self‑\nrecover in emergencies. Zhu et al. (2020b) explored the\
    \ con‑\nnections and differences between smart and resilient cities.\nArtificial\
    \ intelligence can be applied to various aspects of \nwaste management, such as\
    \ waste‑to‑energy, waste sorting, \nwaste generation models, plastic pyrolysis,\
    \ logistics, dis‑\nposal, and resource recovery. It can also help reduce illegal\
    \ \ndumping and improve public health. By implementing arti‑\nficial intelligence\
    \ in waste logistics, transportation distance \ncan be reduced by up to 36.8%,\
    \ cost savings by up to 13.35%, \nand time savings by up to 28.22%. Artificial\
    \ intelligence can \n2546\n \nEnvironmental Chemistry Letters (2023) 21:2525–2557\n\
    1 3\naccurately identify and sort waste with 72.8–99.95% accu‑\nracy (Fang et al.\
    \ 2023). Combining artificial intelligence \nwith chemical analysis can improve\
    \ waste pyrolysis, carbon \nemission estimation, and energy conversion. This technol‑\n\
    ogy can also increase efficiency and reduce costs in waste \nmanagement systems\
    \ for smart cities (Fang et al. 2023).\nSince 1973 Holling introduced the concept\
    \ of resilience \ninto ecosystem research, and the connotation of resilience \n\
    has greatly enriched and expanded. Rapidly developing cities \nare easily affected\
    \ by natural disasters such as floods, earth‑\nquakes, and hurricanes. Besides,\
    \ terrorist attacks and sudden \nviruses also cause cities to face massive crises.\
    \ As urban \nvulnerability increases (Szewrański et al. 2018), Building \nresilient\
    \ cities is receiving increasing academic attention. \nArtificial intelligence\
    \ is not a panacea for addressing climate \nissues. However, as an efficient and\
    \ reliable framework, it \ncan help humans plan and establish sustainable livelihoods,\
    \ \nenhancing the resilience of cities. Table 5 demonstrates the \napplication\
    \ of artificial intelligence in building sustainable \nand resilient cities.\n\
    The increase in climate uncertainty poses enormous \nchallenges to urban water\
    \ resource management. Artificial \nintelligence's rational planning and constraints\
    \ on water \nresource applications make cities safer, more resilient, and \nmore\
    \ sustainable. By streamlining the information transfor‑\nmation process with\
    \ artificial intelligence modeling, Xiang \net al. (2021) presented an adaptive\
    \ intelligent dynamic water \nresource planning to sustain metropolitan regions'\
    \ water \nenvironment and increase water resource usage. Pluchinotta \net al.\
    \ (2021) used the system dynamics model to explore \ndifferent sustainable urban\
    \ water resources management \npolicies in Ebbsfleet garden city. They created\
    \ a novel tech‑\nnique that uses a coupled dynamic artificial neural network \n\
    architecture, a Bayesian framework, and a genetic algorithm \nto predict irrigation\
    \ water use over the short term with little \ninformation. Additionally, Maurya\
    \ et al. (2020) proposed \na framework based on the comprehensive management of\
    \ \nurban water resources and stress state response for urban \nwater resource\
    \ planning and management.\nBy enhancing its whole ecological environment, a city\
    \ \ncan become more resilient. Artificial intelligence can be \nused to build\
    \ a detailed, multidimensional, multiscale, and \nresilient city. Yin et al. (2021)\
    \ created a novel technique \nthat uses a coupled dynamic artificial neural network\
    \ archi‑\ntecture, a Bayesian framework, and a genetic algorithm to \npredict\
    \ irrigation water use over the short term with little \ninformation. The ecological\
    \ sources are categorized, the \nenvironmental channel and strategy points are\
    \ established, \nFig. 6  Applications of artificial intelligence in natural resource\
    \ man‑\nagement. Artificial intelligence can monitor forests, reduce deforesta‑\n\
    tion, and assist decision‑makers in issuing early fire warnings. Using \nartificial\
    \ intelligence to manage intelligent ecosystem restoration and \nadapt to climate\
    \ change can reduce ecosystem pollution and imple‑\nment effective conservation\
    \ measures. Artificial intelligence is neces‑\nsary for the effective management\
    \ of urban water resources. Remote \nsensing and geographic information systems\
    \ technologies improve \nurban land use and planning\n2547\nEnvironmental Chemistry\
    \ Letters (2023) 21:2525–2557 \n1 3\nand planning is provided for urban growth\
    \ and ecological \nrestoration of the terrestrial ecosystem. To better under‑\n\
    stand how urbanization has impacted Beijing, Tianjin, \nand Hebei’s urban ecosystem,\
    \ Kang et al. (2018) created \na framework combining ecosystem services and health.\
    \ \nUsing probabilistic risk assessment, Liu et al. (2023) esti‑\nmated the likely\
    \ risk of a flood occurring in urban areas \nand assessed the effect of future\
    \ climate change on urban \nflood risk. To recognize the complexity of the urban\
    \ eco‑\nsystem's health in the future, Yue et al. (2023) developed \nTable 5 \
    \ Utilization of artificial intelligence in resilient city buildings\nWater resource\
    \ management, urban ecological management, air quality testing, and disaster monitoring\
    \ are crucial elements in constructing \nresilient cities. By employing big data\
    \ and deep learning technologies, artificial intelligence can analyze and predict\
    \ real‑time data, optimizing \nurban operations and resource utilization and enhancing\
    \ urban resilience\nResearch contents\nParticular year Research area\nResearch\
    \ method\nReferences\nWater resources management 2020\nMelbourne, Australia\n\
    An example of a method that examines \nhybrid crow search techniques and \nartificial\
    \ neural networks by combining \na discrete wavelet transform with an \nadaptive\
    \ neural fuzzy inference system\nZubaidi et al. (2020)\nWater resources management\
    \ 2021\nEbbsfleet, Britain\nExplore sustainable solutions for urban \nwater resource\
    \ management through \nsystem dynamics models\nPluchinotta et al. (2021)\nWater\
    \ resources management 2018\nBembézar,\nSpain\nUsing the integration of a dynamic\
    \ \nartificial neural network architecture, \na Bayesian framework, and a genetic\
    \ \nalgorithm, the irrigation water demand \nwith restricted data availability\
    \ was \nexamined\nGonzález Perea et al. (2019)\nUrban heat island\n2019\nNingbo,\
    \ China\nThe impact of the urban morphology \nindex on the land surface temperature\
    \ at \nthree observation scales is distinguished \nusing ordinary least squares\
    \ regression \nand random forest regression\nSun et al. (2019b)\nAir quality\n\
    2021\nTehran, Iran\nOne can compare and forecast the daily \nconcentration of\
    \ nitrogen dioxide in \nthe atmosphere using multiple linear \nregression and\
    \ a multilayer perceptron \nneural network\nShams et al. (2021)\nDisaster resilience\n\
    2018\nShenzhen, China\nSupport vector machines and the Delphi \nanalytic hierarchy\
    \ process assessed \nstreets' physical and social resilience\nZhang et al. (2019b)\n\
    Urban heat island\n2020\nHangzhou, China\nTo investigate the effect of urbanization\
    \ \nand landscape design on habitat quality, \na complete assessment framework\
    \ of \nenvironmental services and trade‑offs \nwas built using ordinary least\
    \ squares \nand a regionally weighted regression \nmodel\nZhu et al. (2020a)\n\
    Urban heat island\n2021\nPearl river delta, China Propose a Malmquist Luenberger\
    \ model \nfor measuring green total factor produc‑\ntivity based on relaxation\
    \ measurement\nLi and Chen (2021)\nAir quality\n2018\nTaiwan, China\nA shallow\
    \ multioutput short‑ and long‑\nterm neural memory network model is \nproposed,\
    \ which combines small batch \ngradient descent, dropout neurons, and \nL2 regularization\
    \ to conduct regional \nmultistep advance air quality prediction\nZhou et al.\
    \ (2019)\nAir quality\n2018\nAthens, Greece\nFive air contaminants’ results were\
    \ com‑\npared using multiple linear regression, \nartificial neural networks,\
    \ and a set of \ncorrelation, difference statistical meas‑\nurements, and residual\
    \ distribution\nAlimissis et al. (2018)\n2548\n \nEnvironmental Chemistry Letters\
    \ (2023) 21:2525–2557\n1 3\na hybrid technique. The urban ecosystem's condition\
    \ was \nidentified using an ecological model to thoroughly assess \necosystem\
    \ health.\nThe internet of things is also essential in improving the \nefficiency\
    \ of resilient urban transportation. Cities' many \ncomponents are now connected\
    \ thanks to the use of artificial \nintelligence in the internet of things, which\
    \ has cultivated \nthe city's capacity for adaptability and helped it grow into\
    \ an \norganism of interconnected things. In order to properly man‑\nage resources\
    \ and optimize energy consumption, artificial \nintelligence can process vast\
    \ amounts of data provided by \nthe internet of things. This can create an intelligent\
    \ network \nthat connects everything on the physical Earth (Ullah et al. \n2020).\
    \ Zhang et al. (2021) proposed a new method to assign \neach network layer reasoning\
    \ calculation to the equipment \nof the multilayer internet of things system.\
    \ Moreover, they \ndesigned a dynamic programming algorithm to balance the \n\
    corresponding time of calculation and transmission cost \nminimization. Lv et al.\
    \ (2021) develop a brand‑new net‑\nwork information physics system, a machine\
    \ learning‑based \nassessment framework, and an online sorting algorithm to \n\
    enable real‑time online analysis and evaluation. In order to \nimprove the network\
    \ architecture of smart cities, blockchain \nand artificial intelligence are integrated\
    \ into the internet of \nthings network (Singh et al. 2020).\nIn addition to harming\
    \ human health, air pollution \nimpedes sustainable ecological growth. To build\
    \ a resilient \ncity, air quality must be tested and managed. Almalawi et al.\
    \ \n(2022) used linear regression, support vector regression, \nand gradient enhancement\
    \ decision trees to build a one‑step \nmodel and analyze the air quality index\
    \ using sensors. Fur‑\nthermore, Catalano and Galatioto (2017) designed a new\
    \ \nmodel. They compared it with a specific background statisti‑\ncal model, focusing\
    \ on testing the air quality in Manchester \nand enhancing the prediction of traffic‑related\
    \ air pollution. \nMihăiţă et al. (2019) utilized mobile and fixed air quality\
    \ \ndetection equipment, combined with machine learning meth‑\nods, to gather\
    \ data and model the information using decision \ntrees and neural networks. Their\
    \ findings suggest that noise \nand humidity are the primary factors influencing\
    \ predictions \nof nitrogen dioxide concentration at mobile collection sites.\
    \ \nTo compare the results of air pollution in the five schools \nutilizing correlation,\
    \ different statistical metrics, and resid‑\nual distribution, Alimissis et al.\
    \ (2018) used artificial neural \nnetworks and multiple linear regression. They\
    \ found that \nartificial neural networks have computational advantages \nwhen\
    \ the density of air quality networks is limited.\nIn summary, artificial intelligence\
    \ technologies are cru‑\ncial in promoting urban resilience and sustainable develop‑\n\
    ment. With big data and deep learning techniques, artificial \nintelligence can\
    \ offer real‑time data, analysis, and predic‑\ntions, optimizing urban operations\
    \ and resource manage‑\nment. This, in turn, enhances urban resilience to disasters\
    \ \nand improves the overall happiness and quality of life for \nurban residents.\n\
    Perspective\nNumerous industries are swiftly integrating disruptive tech‑\nnologies\
    \ such as artificial intelligence (Shao et al. 2022). \nHowever, the exponential\
    \ expansion of computational and \nenergy demands associated with many modern\
    \ machine \nlearning technologies and systems can result in substan‑\ntial carbon\
    \ emissions (Hanifa et al. 2023). Machine learn‑\ning models can establish different\
    \ orders of magnitude and \nhierarchies among diverse models, facilitating a thorough\
    \ \nand more accurate assessment of carbon dioxide quantifica‑\ntion and the environmental\
    \ efficiency of industrial activi‑\nties. Developing and defining a clear, robust,\
    \ and general \nmethod to calculate the energy consumption of artificial \nintelligence\
    \ models can reduce the carbon footprint (Hen‑\nderson et al. 2020). Cloud for\
    \ data storage, hardware for \ncomputing, and hardware providers are essential\
    \ for energy \nconsumption evaluation of artificial intelligence algorithms, \n\
    thus advancing the evaluation criteria, including precision, \naccuracy, or recall\
    \ for the calculation of energy consump‑\ntion of the project. Also, to automate\
    \ system control and \nenhance the automation of grid intelligence, appropriate\
    \ \nfunctioning of renewable energy‑producing equipment is \nrequired (Ghadami\
    \ et al. 2021; Zahraee et al. 2016). Pro‑\nmote new smart infrastructure that\
    \ uses less energy and poli‑\ncies that support the sustainable advancement of\
    \ artificial \nintelligence to lessen grid instability. Energy segmentation \n\
    can assist artificial intelligence ecosystems or systems of \nsystems by supporting\
    \ organized data management, data \nmining capabilities, and machine learning\
    \ techniques, per‑\nmitting artificial intelligence‑enabled smart grids (Ashfaq\
    \ \net al. 2022). Moreover, a sizable initial investment will be \nneeded to restructure\
    \ and modernize the electric system’s \ndata management systems, enabling the\
    \ deployment of data‑\nintensive solutions to address privacy and cyberattack\
    \ issues. \nUtility companies will need time and money to develop the \nnecessary\
    \ degree of “data ready” to successfully implement \nartificial intelligence solutions.\
    \ The data layer is the support \nlayer for future investments.\nTransportation\
    \ infrastructure combined with the internet \nof things technology to collect\
    \ and process real‑time data \nin the field to effectively alleviate traffic congestion.\
    \ Intel‑\nligent monitoring of urban surface and underground space \nanomalies\
    \ based on digital twin for urban construction and \noperation management (Wu\
    \ et al. 2022). A city informa‑\ntion model creates a three‑dimensional city space\
    \ model, \nachieves all‑encompassing three‑dimensional visualization \nmanagement\
    \ of urban traffic planning, construction, and \noperation, supports urban traffic\
    \ simulation, analysis, and \n2549\nEnvironmental Chemistry Letters (2023) 21:2525–2557\
    \ \n1 3\nverification, and achieves intelligent supervision of urban \ntransportation.\
    \ Using long‑range, ZigBee, wireless fidelity, \n5G, and emerging narrow‑band\
    \ internet of things commu‑\nnication technologies, ample opportunity exists to\
    \ create \ncost‑effective, autonomous, energy‑efficient, and easy‑\nto‑use internet\
    \ of things (IoT)‑based agriculture solutions \nwith robust architecture and low\
    \ maintenance (Cicioğlu \nand Çalhan 2021). A potential strategy is to employ\
    \ crop \nsimulation models in conjunction with remote sensing for \ncrop phenotype\
    \ data, and using artificial intelligence models \nto integrate phenotypic and\
    \ genotypic data at the plot level \ncan further help address complex challenges\
    \ in agriculture \n(Khaki and Wang 2019; Ma et al. 2018). Artificial intel‑\n\
    ligence can drive positive change in cities and societies and \ncontribute to\
    \ achieving multiple sustainable development \ngoals (Vinuesa et al. 2020). However,\
    \ it is also essential \nto advance the implementation of appropriate policies\
    \ and \nregulations to reduce the damage caused by artificial intel‑\nligence\
    \ to the most vulnerable urban and social groups and \nnature. In conclusion,\
    \ the algorithmic computation of artifi‑\ncial intelligence improves efficiency\
    \ gains for future practi‑\ncal applications and makes timely, rational, and optimized\
    \ \ndecisions. The adoption of the internet of things and tel‑\necommunication\
    \ technologies facilitates the advancement \nof social transportation systems\
    \ and agricultural systems, \nthus conforming to the process of sustainable urbanization.\n\
    Conclusion\nAs the global economy and population have expanded, \nenergy demand\
    \ has increased exponentially. Traditional pat‑\nterns of energy production have\
    \ proved to be detrimental to \nthe environment, with excessive emissions of harmful\
    \ gases \ncausing global warming and extreme weather events such as \ntornadoes,\
    \ hail, and thunderstorms causing severe damage to \nhuman habitats and posing\
    \ a serious threat to human life and \nproperty. Artificial intelligence technology\
    \ is emerging as \na new tool in the energy sector, offering a promising direc‑\n\
    tion for combating climate change to address these issues \nand mitigate their\
    \ adverse environmental effects. Artificial \nintelligence contributes to climate\
    \ change mitigation in the \nenergy sector by predicting energy demand and enhancing\
    \ \nenergy efficiency to reduce environmental pollution. Numer‑\nous nations use\
    \ artificial intelligence to improve energy effi‑\nciency and reduce energy waste.\n\
    In addition, artificial intelligence has improved weather \nprediction technology,\
    \ enabling more accurate weather fore‑\ncasting and modeling to better prepare\
    \ for and respond to \nextreme weather events via early warning systems. Artificial\
    \ \nintelligence enables a deeper comprehension of natural fac‑\ntors such as\
    \ climate and geography, thereby facilitating the \nselection of optimal sites\
    \ for renewable energy. It can predict \nrenewable energy production, adjust grid\
    \ output, and guar‑\nantee a continuous electricity supply. Moreover, artificial\
    \ \nintelligence can optimize residential architecture by deter‑\nmining optimal\
    \ house orientation and window placement, \nthereby reducing energy consumption\
    \ and enhancing living \nconditions. Addressing traffic emissions is also essential,\
    \ and \nartificial intelligence can enhance bus systems by utilizing \nlarge data\
    \ samples to develop neural networks that optimize \nroutes, vehicle rounds, and\
    \ passenger traffic.\nArtificial intelligence is essential to reduce the environ‑\n\
    mental impact of agrochemical use. Precision agriculture \nemploys artificial\
    \ intelligence to collect and analyze environ‑\nmental data related to crop growth,\
    \ enabling farmers to make \ninformed decisions, reduce chemical use, and increase\
    \ yield. \nIn the industrial sector, traditional hardware sensors cannot \nprovide\
    \ relevant information to decision‑makers. Artificial \nintelligence enables decision‑makers\
    \ to optimize industrial \nprocesses by analyzing data, developing models, and\
    \ com‑\npleting missing information from hardware sensors to con‑\nserve energy\
    \ and reduce emissions. People’s understanding \nof nature is enhanced by artificial\
    \ intelligence, allowing for \nmore accurate predictions of future deforestation\
    \ and tree \nloss, which can assist governments in protecting the envi‑\nronment\
    \ and promoting sustainable energy. By calculating \nrelevant data to ensure residents'\
    \ safety, artificial intelligence \ncan also aid in developing sustainable and\
    \ resilient cities \nby minimizing damage caused by extreme weather events. \n\
    In addition, artificial intelligence significantly mitigates cli‑\nmate change\
    \ by increasing energy efficiency and providing \ndecision‑makers with accurate\
    \ data.\nAcknowledgements Dr Ahmed I. Osman and Prof. David W. Rooney \nwish to\
    \ acknowledge the support of The Bryden Centre project (Project \nID VA5048),\
    \ which was awarded by The European Union’s INTER‑\nREG VA Programme, managed\
    \ by the Special EU Programmes Body \n(SEUPB), with match funding provided by\
    \ the Department for the \nEconomy in Northern Ireland and the Department of Business,\
    \ Enter‑\nprise and Innovation in the Republic of Ireland.\nFunding The authors\
    \ have not disclosed any funding.\nDeclarations \nConflict of interest The authors\
    \ declare no conflict of interest.\nOpen Access  This article is licensed under\
    \ a Creative Commons Attri‑\nbution 4.0 International License, which permits use,\
    \ sharing, adapta‑\ntion, distribution and reproduction in any medium or format,\
    \ as long \nas you give appropriate credit to the original author(s) and the source,\
    \ \nprovide a link to the Creative Commons licence, and indicate if changes \n\
    were made. The images or other third party material in this article are \nincluded\
    \ in the article's Creative Commons licence, unless indicated \notherwise in a\
    \ credit line to the material. If material is not included in \nthe article's\
    \ Creative Commons licence and your intended use is not \npermitted by statutory\
    \ regulation or exceeds the permitted use, you will \nneed to obtain permission\
    \ directly from the copyright holder. To view a \ncopy of this licence, visit\
    \ http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\n2550\n \nEnvironmental\
    \ Chemistry Letters (2023) 21:2525–2557\n1 3\nReferences\nAbdalla AN, Nazir MS,\
    \ Tao H, Cao S, Ji R, Jiang M, Yao L (2021) \nIntegration of energy storage system\
    \ and renewable energy \nsources based on artificial intelligence: an overview.\
    \ J Energy \nStor 40:102811. https:// doi. org/ 10. 1016/j. est. 2021. 102811\n\
    Abduljabbar R, Dia H, Liyanage S, Bagloee SA (2019) Applications \nof artificial\
    \ intelligence in transport: an overview. Sustainability \n11:189. https:// doi.\
    \ org/ 10. 3390/ su110 10189\nAdikari KE, Shrestha S, Ratnayake DT, Budhathoki\
    \ A, Mohanasund‑\naram S, Dailey MN (2021) Evaluation of artificial intelligence\
    \ \nmodels for flood and drought forecasting in arid and tropical \nregions. Environ\
    \ Model Softw 144:105136. https:// doi. org/ 10. \n1016/j. envso ft. 2021. 105136\n\
    Afzaal H, Farooque AA, Abbas F, Acharya B, Esau T (2020) Compu‑\ntation of evapotranspiration\
    \ with artificial intelligence for pre‑\ncision water resource management. Appl\
    \ Sci 10:1621. https:// \ndoi. org/ 10. 3390/ app10 051621\nAhmad T, Zhang D,\
    \ Huang C, Zhang H, Dai N, Song Y, Chen H \n(2021) Artificial intelligence in\
    \ sustainable energy indus‑\ntry: status Quo, challenges and opportunities. J\
    \ Clean Prod \n289:125834. https:// doi. org/ 10. 1016/j. jclep ro. 2021. 125834\n\
    Ahmad T, Zhu H, Zhang D, Tariq R, Bassam A, Ullah F, AlGhamdi \nAS, Alshamrani\
    \ SS (2022) Energetics systems and artificial \nintelligence: applications of\
    \ industry 4.0. Energy Rep 8:334–\n361. https:// doi. org/ 10. 1016/j. egyr. 2021.\
    \ 11. 256\nAhmed QW, Garg S, Rai A, Ramachandran M, Jhanjhi NZ, Masud \nM, Baz\
    \ M (2022a) AI‑based resource allocation techniques in \nwireless sensor internet\
    \ of things networks in energy efficiency \nwith data optimization. Electronics\
    \ 11:2071. https:// doi. org/ 10. \n3390/ elect ronic s1113 2071\nAhmed S, Alshater\
    \ MM, Ammari AE, Hammami H (2022b) Artifi‑\ncial intelligence and machine learning\
    \ in finance: a bibliomet‑\nric review. Res Int Bus Financ 61:101646. https://\
    \ doi. org/ 10. \n1016/j. ribaf. 2022. 101646\nAlassery F, Alzahrani A, Khan AI,\
    \ Irshad K, Islam S (2022) An \nartificial intelligence‑based solar radiation\
    \ prophesy model for \ngreen energy utilization in energy management system. Sustain\
    \ \nEnergy Technol Assess 52:102060. https:// doi. org/ 10. 1016/j. \nseta. 2022.\
    \ 102060\nAlDousari AE, Kafy AA, Saha M, Fattah MA, Almulhim AI, Faisal \nA‑A,\
    \ Al Rakib A, Jahir DMA, Rahaman ZA, Bakshi A, Shah‑\nrier M, Rahman MM (2022)\
    \ Modelling the impacts of land use/\nland cover changing pattern on urban thermal\
    \ characteristics \nin Kuwait. Sustain Cities Soc 86:104107. https:// doi. org/\
    \ 10. \n1016/j. scs. 2022. 104107\nAlem A, Kumar S (2022) Transfer learning models\
    \ for land cover \nand land use classification in remote sensing image. Appl Artif\
    \ \nIntell 36:2014192. https:// doi. org/ 10. 1080/ 08839 514. 2021. \n20141 92\n\
    Alexandru M, Dragoș C, Bălă‑Constantin Z (2022) Digital Twin for \nautomated guided\
    \ vehicles fleet management. Proc Comput Sci \n199:1363–1369. https:// doi. org/\
    \ 10. 1016/j. procs. 2022. 01. 172\nAlimissis A, Philippopoulos K, Tzanis CG,\
    \ Deligiorgi D (2018) Spatial \nestimation of urban air pollution with the use\
    \ of artificial neural \nnetwork models. Atmos Environ 191:205–213. https:// doi.\
    \ org/ \n10. 1016/j. atmos env. 2018. 07. 058\nAllam Z, Dhunny ZA (2019) On big\
    \ data, artificial intelligence and \nsmart cities. Cities 89:80–91. https://\
    \ doi. org/ 10. 1016/j. cities. \n2019. 01. 032\nAlmalawi A, Alsolami F, Khan\
    \ AI, Alkhathlan A, Fahad A, Irshad K, \nQaiyum S, Alfakeeh AS (2022) An IoT based\
    \ system for magnify \nair pollution monitoring and prognosis using hybrid artificial\
    \ \nintelligence technique. Environ Res 206:112576. https:// doi. org/ \n10. 1016/j.\
    \ envres. 2021. 112576\nAl‑Othman A, Tawalbeh M, Martis R, Dhou S, Orhan M, Qasim\
    \ M, \nGhani Olabi A (2022) Artificial intelligence and numerical mod‑\nels in\
    \ hybrid renewable energy systems with fuel cells: advances \nand prospects. Energy\
    \ Convers Manag 253:115154. https:// doi. \norg/ 10. 1016/j. encon man. 2021.\
    \ 115154\nAmpatzidis Y, Partel V, Costa L (2020) Agroview: cloud‑based appli‑\n\
    cation to process, analyze and visualize UAV‑collected data for \nprecision agriculture\
    \ applications utilizing artificial intelligence. \nComput Electron Agric 174:105457.\
    \ https:// doi. org/ 10. 1016/j. \ncompag. 2020. 105457\nAn Y, Chen T, Shi L,\
    \ Heng CK, Fan J (2023) Solar energy potential \nusing GIS‑based urban residential\
    \ environmental data: a case \nstudy of Shenzhen, China. Sustain Cities Soc 93:104547.\
    \ https:// \ndoi. org/ 10. 1016/j. scs. 2023. 104547\nArumugam K, Swathi Y, Sanchez\
    \ DT, Mustafa M, Phoemchalard C, \nPhasinam K, Okoronkwo E (2022) Towards applicability\
    \ of \nmachine learning techniques in agriculture and energy sector. \nMater Today:\
    \ Proc 51:2260–2263. https:// doi. org/ 10. 1016/j. \nmatpr. 2021. 11. 394\nAshfaq\
    \ A, Kamran M, Rehman F, Sarfaraz N, Ilyas HU, Riaz HH \n(2022) Role of Artificial\
    \ intelligence in renewable energy and \nits scope in future. 2022 5th International\
    \ Conference on Energy \nConservation and Efficiency (ICECE) 1–6. https:// doi.\
    \ org/ 10. \n1109/ ICECE 54634. 2022. 97589 57\nBacco M, Berton A, Ferro E, Gennaro\
    \ C, Gotta A, Matteoli S, Paon‑\nessa F, Ruggeri M, Virone G, Zanella A (2018)\
    \ Smart farming: \nopportunities, challenges and technology enablers. 2018 IoT\
    \ Vert \nTop Summit Agric Tuscany (IOT Tuscany). 1–6. https:// doi. org/ \n10.\
    \ 1109/ IOT‑ TUSCA NY. 2018. 83730 43\nBaduge SK, Thilakarathna S, Perera JS,\
    \ Arashpour M, Sharafi P, Teo‑\ndosio B, Shringi A, Mendis P (2022) Artificial\
    \ intelligence and \nsmart vision for building and construction 4.0: machine and\
    \ deep \nlearning methods and applications. Autom Constr 141:104440. \nhttps://\
    \ doi. org/ 10. 1016/j. autcon. 2022. 104440\nBagheri M, Bazvand A, Ehteshami\
    \ M (2017) Application of artificial \nintelligence for the management of landfill\
    \ leachate penetration \ninto groundwater, and assessment of its environmental\
    \ impacts. J \nClean Prod 149:784–796. https:// doi. org/ 10. 1016/j. jclep ro.\
    \ 2017. \n02. 157\nBahaloo S, Mehrizadeh M, Najafi‑Marghmaleki A (2022) Review\
    \ of \napplication of artificial intelligence techniques in petroleum oper‑\n\
    ations. Petrol Res. https:// doi. org/ 10. 1016/j. ptlrs. 2022. 07. 002\nBalafoutis\
    \ A, Beck B, Fountas S, Vangeyte J, Wal TV, Soto I, Gómez‑\nBarbero M, Barnes\
    \ A, Eory V (2017) Precision agriculture tech‑\nnologies positively contributing\
    \ to GHG emissions mitigation. \nFarm Prod Econ Sustain 9:1339. https:// doi.\
    \ org/ 10. 3390/ su908 \n1339\nBarile S, Piciocchi P, Bassano C, Spohrer J, Pietronudo\
    \ MC (2019) \nRe‑defining the role of artificial intelligence (AI) in wiser service\
    \ \nsystems. Adv Artif Intell Softw Syst Eng. 787:159–170. https:// \ndoi. org/\
    \ 10. 1007/ 978‑3‑ 319‑ 94229‑2_ 16\nBaysan S, Kabadurmus O, Cevikcan E, Satoglu\
    \ SI, Durmusoglu MB \n(2019) A simulation‑based methodology for the analysis of\
    \ the \neffect of lean tools on energy efficiency: an application in power \n\
    distribution industry. J Clean Prod 211:895–908. https:// doi. org/ \n10. 1016/j.\
    \ jclep ro. 2018. 11. 217\nBendaoud NMM, Farah N, Ben Ahmed S (2022) Applying\
    \ load profiles \npropagation to machine learning based electrical energy forecast‑\n\
    ing. Electr Power Syst Res 203:107635. https:// doi. org/ 10. 1016/j. \nepsr.\
    \ 2021. 107635\nBode G, Thul S, Baranski M, Müller D (2020) Real‑world application\
    \ \nof machine‑learning‑based fault detection trained with experi‑\nmental data.\
    \ Energy 198:117323. https:// doi. org/ 10. 1016/j. \nenergy. 2020. 117323\n2551\n\
    Environmental Chemistry Letters (2023) 21:2525–2557 \n1 3\nBonan GB, Doney SC\
    \ (2018) Climate, ecosystems, and planetary \nfutures: the challenge to predict\
    \ life in Earth system models. \nScience 359:eaam8328. https:// doi. org/ 10.\
    \ 1126/ scien ce. aam83 28\nBoza P, Evgeniou T (2021) Artificial intelligence\
    \ to support the inte‑\ngration of variable renewable energy sources to the power\
    \ sys‑\ntem. Appl Energy 290:116754. https:// doi. org/ 10. 1016/j. apene \nrgy.\
    \ 2021. 116754\nBuchanan GM, Butchart SHM, Dutson G, Pilgrim JD, Steininger MK,\
    \ \nBishop KD, Mayaux P (2008) Using remote sensing to inform \nconservation status\
    \ assessment: estimates of recent deforestation \nrates on New Britain and the\
    \ impacts upon endemic birds. Biol \nCons 141:56–66. https:// doi. org/ 10. 1016/j.\
    \ biocon. 2007. 08. 023\nCai W, Lai K‑h, Liu C, Wei F, Ma M, Jia S, Jiang Z, Lv\
    \ L (2019) Pro‑\nmoting sustainability of manufacturing industry through the lean\
    \ \nenergy‑saving and emission‑reduction strategy. Sci Total Environ \n665:23–32.\
    \ https:// doi. org/ 10. 1016/j. scito tenv. 2019. 02. 069\nCarranza‑García M,\
    \ García‑Gutiérrez J, Riquelme JC (2019) A \nframework for evaluating land use\
    \ and land cover classification \nusing convolutional neural networks. Rem Sens\
    \ 11:274. https:// \ndoi. org/ 10. 3390/ rs110 30274\nCatalano M, Galatioto F\
    \ (2017) Enhanced transport‑related air pol‑\nlution prediction through a novel\
    \ metamodel approach. Transp \nRes Part D: Transp Environ 55:262–276. https://\
    \ doi. org/ 10. \n1016/j. trd. 2017. 07. 009\nChai SY, Hayat A, Flaherty GT (2022)\
    \ Integrating artificial intel‑\nligence into haematology training and practice:\
    \ opportunities, \nthreats and proposed solutions. Br J Haematol 198:807–811.\
    \ \nhttps:// doi. org/ 10. 1111/ bjh. 18343\nChan KC, Wong VTT, Yow AKF, Yuen\
    \ PL, Chao CYH (2022) \nDevelopment and performance evaluation of a chiller plant\
    \ \npredictive operational control strategy by artificial intelligence. \nEnergy\
    \ Build 262:112017. https:// doi. org/ 10. 1016/j. enbui ld. \n2022. 112017\n\
    Chang L‑C, Chang F‑J, Yang S‑N, Tsai F‑H, Chang T‑H, Herricks \nEE (2020) Self‑organizing\
    \ maps of typhoon tracks allow \nfor flood forecasts up to two days in advance.\
    \ Nat Commun \n11:1983. https:// doi. org/ 10. 1038/ s41467‑ 020‑ 15734‑7\nChatterjee\
    \ J, Dethlefs N (2022) Facilitating a smoother transition \nto renewable energy\
    \ with artificial intelligence. Patterns \n3:100528. https:// doi. org/ 10. 1016/j.\
    \ patter. 2022. 100528\nChavhan S, Gupta D, Chandana BN, Khanna A, Rodrigues JJPC\
    \ \n(2020) IoT‑based context‑aware intelligent public transport \nsystem in a\
    \ metropolitan area. IEEE Internet Things J 7:6023–\n6034. https:// doi. org/\
    \ 10. 1109/ JIOT. 2019. 29551 02\nChen CJ, Huang YY, Li YS, Chang CY, Huang YM\
    \ (2020a) An \nAIoT based smart agricultural system for pests detection. IEEE\
    \ \nAccess 8:180750–180761. https:// doi. org/ 10. 1109/ ACCESS. \n2020. 30248\
    \ 91\nChen Z, Zhu Z, Jiang H, Sun S (2020b) Estimating daily refer‑\nence evapotranspiration\
    \ based on limited meteorological data \nusing deep learning and classical machine\
    \ learning methods. \nJ Hydrol 591:125286. https:// doi. org/ 10. 1016/j. jhydr\
    \ ol. 2020. \n125286\nChen C, Hu Y, Karuppiah M, Kumar PM (2021) Artificial intelligence\
    \ \non economic evaluation of energy efficiency and renewable \nenergy technologies.\
    \ Sustain Energy Technol Assess 47:101358. \nhttps:// doi. org/ 10. 1016/j. seta.\
    \ 2021. 101358\nChen K, Zhu X, Anduv B, Jin X, Du Z (2022a) Digital twins model\
    \ \nand its updating method for heating, ventilation and air condi‑\ntioning system\
    \ using broad learning system algorithm. Energy \n251:124040. https:// doi. org/\
    \ 10. 1016/j. energy. 2022. 124040\nChen L, Msigwa G, Yang M, Osman AI, Fawzy\
    \ S, Rooney DW, Yap \nP‑S (2022b) Strategies to achieve a carbon neutral society:\
    \ a \nreview. Environ Chem Lett 20:2277–2310. https:// doi. org/ 10. \n1007/ s10311‑\
    \ 022‑ 01435‑8\nChen L, Huang L, Hua J, Chen Z, Wei L, Osman AI, Fawzy S, Rooney\
    \ \nDW, Dong L, Yap P‑S (2023a) Green construction for low‑carbon \ncities: a\
    \ review. Environ Chem Lett 21:1627–1657. https:// doi. \norg/ 10. 1007/ s10311‑\
    \ 022‑ 01544‑4\nChen X, Cao B, Pouramini S (2023b) Energy cost and consumption\
    \ \nreduction of an office building by Chaotic Satin Bowerbird opti‑\nmization\
    \ algorithm with model predictive control and artificial \nneural network: a case\
    \ study. Energy 270:126874. https:// doi. org/ \n10. 1016/j. energy. 2023. 126874\n\
    Cheong S‑M, Sankaran K, Bastani H (2022) Artificial intelligence \nfor climate\
    \ change adaptation. Wiley Interdiscip Rev: Data Min \nKnowl Discov 12:e1459.\
    \ https:// doi. org/ 10. 1002/ widm. 1459\nChinh Nguyen H, Alamray F, Kamal M,\
    \ Diana T, Mohamed A, Algarni \nM, Su C‑H (2022) Computational prediction of drug\
    \ solubility \nin supercritical carbon dioxide: thermodynamic and artificial \n\
    intelligence modeling. J Mol Liq 354:118888. https:// doi. org/ \n10. 1016/j.\
    \ molliq. 2022. 118888\nChoi C, Kim J, Kim J, Kim D, Bae Y, Kim HS (2018) Development\
    \ \nof heavy rain damage prediction model using machine learning \nbased on big\
    \ data. Adv Meteorol 2018:5024930. https:// doi. org/ \n10. 1155/ 2018/ 50249\
    \ 30\nChopra R, Magazzino C, Shah MI, Sharma GD, Rao A, Shahzad U \n(2022) The\
    \ role of renewable energy and natural resources for \nsustainable agriculture\
    \ in ASEAN countries: do carbon emis‑\nsions and deforestation affect agriculture\
    \ productivity? Resour \nPolicy 76:102578. https:// doi. org/ 10. 1016/j. resou\
    \ rpol. 2022. \n102578\nChou CH, Wu H, Kang JL, Wong DSH, Yao Y, Chuang YC, Jang\
    \ SS, \nOu JDY (2020) Physically consistent soft‑sensor development \nusing sequence‑to‑sequence\
    \ neural networks. IEEE Trans Industr \nInf 16:2829–2838. https:// doi. org/ 10.\
    \ 1109/ TII. 2019. 29524 29\nCicioğlu M, Çalhan A (2021) Smart agriculture with\
    \ internet of things \nin cornfields. Comput Electr Eng 90:106982. https:// doi.\
    \ org/ 10. \n1016/j. compe leceng. 2021. 106982\nCioffi R, Travaglioni M, Piscitelli\
    \ G, Petrillo A, De Felice F (2020) \nArtificial intelligence and machine learning\
    \ applications in \nsmart production: progress, trends, and directions. Sustainabil‑\n\
    ity 12:492. https:// doi. org/ 10. 3390/ su120 20492\nCohen Y, Faccio M, Pilati\
    \ F, Yao X (2019) Design and management of \ndigital manufacturing and assembly\
    \ systems in the industry 4.0 \nera. Int J Adv Manuf Technol 105:3565–3577. https://\
    \ doi. org/ 10. \n1007/ s00170‑ 019‑ 04595‑0\nCreech CF, Henry RS, Werle R, Sandell\
    \ LD, Hewitt AJ, Kruger GR \n(2015) Performance of postemergence herbicides applied\
    \ at dif‑\nferent carrier volume rates. Weed Technol 29:611–624. https:// \ndoi.\
    \ org/ 10. 1614/ WT‑D‑ 14‑ 00101.1\nCzernecki B, Taszarek M, Marosz M, Półrolniczak\
    \ M, Kolendowicz L, \nWyszogrodzki A, Szturc J (2019) Application of machine learn‑\n\
    ing to large hail prediction: the importance of radar reflectivity, \nlightning\
    \ occurrence and convective parameters derived from \nERA5. Atmos Res 227:249–262.\
    \ https:// doi. org/ 10. 1016/j. atmos \nres. 2019. 05. 010\nDas U, Pathak P,\
    \ Meena M, Mallikarjun N (2018) Precision farming a \npromising technology in\
    \ horticulture: a review. Int J Pure Appl \nBiosci 6:1596–1606. https:// doi.\
    \ org/ 10. 18782/ 2320‑ 7051. 3088\nDebrah C, Chan APC, Darko A (2022) Artificial\
    \ intelligence in green \nbuilding. Autom Constr 137:104192. https:// doi. org/\
    \ 10. 1016/j. \nautcon. 2022. 104192\nDelanoë P, Tchuente D, Colin G (2023) Method\
    \ and evaluations of \nthe effective gain of artificial intelligence models for\
    \ reducing \n CO2 emissions. J Environ Manag 331:117261. https:// doi. org/ \n\
    10. 1016/j. jenvm an. 2023. 117261\nDing Z, Chen Z, Liu J, Evrendilek F, He Y,\
    \ Xie W (2022) Co‑com‑\nbustion, life‑cycle circularity, and artificial intelligence‑based\
    \ \nmulti‑objective optimization of two plastics and textile dyeing \n2552\n \n\
    Environmental Chemistry Letters (2023) 21:2525–2557\n1 3\nsludge. J Hazard Mater\
    \ 426:128069. https:// doi. org/ 10. 1016/j. \njhazm at. 2021. 128069\nDominguez\
    \ D, del Villar LD, Pantoja O, González‑Rodríguez M \n(2022) Forecasting amazon\
    \ rain‑forest deforestation using a \nhybrid machine learning model. Sustainability\
    \ 14:691. https:// \ndoi. org/ 10. 3390/ su140 20691\nDong Z, Liu J, Liu B, Li\
    \ K, Li X (2021) Hourly energy consump‑\ntion prediction of an office building\
    \ based on ensemble learning \nand energy consumption pattern classification.\
    \ Energy Build \n241:110929. https:// doi. org/ 10. 1016/j. enbui ld. 2021. 110929\n\
    Du C, Zhang L, Ma X, Lou X, Shan Y, Li H, Zhou R (2021) A cotton \nhigh‑efficiency\
    \ water‑fertilizer control system using wireless sen‑\nsor network for precision\
    \ agriculture. Processes 9:1693. https:// \ndoi. org/ 10. 3390/ pr910 1693\nDuan\
    \ M, Xia J, Yan Z, Han L, Zhang L, Xia H, Yu S (2021) Recon‑\nstruction of the\
    \ radar reflectivity of convective storms based on \ndeep learning and himawari‑8\
    \ observations. Rem Sens 13:3330. \nhttps:// doi. org/ 10. 3390/ rs131 63330\n\
    Dwivedi YK, Hughes L, Ismagilova E, Aarts G, Coombs C, Crick \nT, Duan Y, Dwivedi\
    \ R, Edwards J, Eirug A, Galanos V, Ilavar‑\nasan PV, Janssen M, Jones P, Kar\
    \ AK, Kizgin H, Kronemann \nB, Lal B, Lucini B, Medaglia R, Le Meunier‑FitzHugh\
    \ K, Le \nMeunier‑FitzHugh LC, Misra S, Mogaji E, Sharma SK, Singh \nJB, Raghavan\
    \ V, Raman R, Rana NP, Samothrakis S, Spencer J, \nTamilmani K, Tubadji A, Walton\
    \ P, Williams MD (2021) Artifi‑\ncial Intelligence (AI): multidisciplinary perspectives\
    \ on emerging \nchallenges, opportunities, and agenda for research, practice and\
    \ \npolicy. Int J Inf Manag 57:101994. https:// doi. org/ 10. 1016/j. ijinf \n\
    omgt. 2019. 08. 002\nEbrahimi M, Sarikhani MR, Safari Sinegani AA, Ahmadi A, Keesstra\
    \ \nS (2019) Estimating the soil respiration under different land uses \nusing\
    \ artificial neural network and linear regression models. \nCATENA 174:371–382.\
    \ https:// doi. org/ 10. 1016/j. catena. 2018. \n11. 035\nElahi E, Weijun C, Zhang\
    \ H, Abid M (2019a) Use of artificial neu‑\nral networks to rescue agrochemical‑based\
    \ health hazards: a \nresource optimisation method for cleaner crop production.\
    \ J \nClean Prod 238:117900. https:// doi. org/ 10. 1016/j. jclep ro. 2019. \n\
    117900\nElahi E, Weijun C, Zhang H, Nazeer M (2019b) Agricultural intensifi‑\n\
    cation and damages to human health in relation to agrochemicals: \napplication\
    \ of artificial intelligence. Land Use Policy 83:461–\n474. https:// doi. org/\
    \ 10. 1016/j. landu sepol. 2019. 02. 023\nElbeltagi A, Kushwaha NL, Srivastava\
    \ A, Zoof AT (2022) Chapter 5: \nartificial intelligent‑based water and soil management.\
    \ Deep \nLearning for Sustainable Agriculture 2022:129–142. https:// doi. \norg/\
    \ 10. 1016/ B978‑0‑ 323‑ 85214‑2. 00008‑2\nElsheikh AH, Abd Elaziz M, Vendan A\
    \ (2022) Modeling ultrasonic \nwelding of polymers using an optimized artificial\
    \ intelligence \nmodel using a gradient‑based optimizer. Weld World 66:27–44.\
    \ \nhttps:// doi. org/ 10. 1007/ s40194‑ 021‑ 01197‑x\nEnholm IM, Papagiannidis\
    \ E, Mikalef P, Krogstie J (2022) Artificial \nintelligence and business value:\
    \ a literature review. Inf Syst Front \n24:1709–1734. https:// doi. org/ 10. 1007/\
    \ s10796‑ 021‑ 10186‑w\nEsnaola‑Gonzalez I, Jelić M, Pujić D, Diez FJ, Tomašević\
    \ N (2021) An \nAI‑powered system for residential demand response. Electronics\
    \ \n10:693. https:// doi. org/ 10. 3390/ elect ronic s1006 0693\nFacchinetti D,\
    \ Santoro S, Galli LE, Fontana G, Fedeli L, Parisi S, \nBonacchi LB, Šušnjar S,\
    \ Salvai F, Coppola G, Matteucci \nM, Pessina D (2021) Reduction of pesticide\
    \ use in fresh‑\ncut salad production through artificial intelligence. Appl \n\
    Sci 11:1992. https:// doi. org/ 10. 3390/ app11 051992\nFang B, Yu J, Chen Z,\
    \ Osman AI, Farghali M, Ihara I, Hamza EH, \nRooney DW, Yap P‑S (2023) Artificial\
    \ intelligence for waste \nmanagement in smart cities: a review. Environ Chem\
    \ Lett. https:// \ndoi. org/ 10. 1007/ s10311‑ 023‑ 01604‑3\nFarghali M, Osman\
    \ AI, Umetsu K, Rooney DW (2022) Integration \nof biogas systems into a carbon\
    \ zero and hydrogen economy: \na review. Environ Chem Lett 20:2853–2927. https://\
    \ doi. org/ 10. \n1007/ s10311‑ 022‑ 01468‑z\nFarghali M, Osman AI, Mohamed IMA,\
    \ Chen Z, Chen L, Ihara I, Yap \nP‑S, Rooney DW (2023) Strategies to save energy\
    \ in the context \nof the energy crisis: a review. Environ Chem Lett. https://\
    \ doi. org/ \n10. 1007/ s10311‑ 023‑ 01591‑5\nFarzaneh H, Malehmirchegini L, Bejan\
    \ A, Afolabi T, Mulumba A, \nDaka PP (2021) Artificial Intelligence evolution\
    \ in smart build‑\nings for energy. Effic Appl Sci 11:763. https:// doi. org/\
    \ 10. 3390/ \napp11 020763\nFatemidokht H, Rafsanjani MK, Gupta BB, Hsu CH (2021)\
    \ Efficient \nand secure routing protocol based on artificial intelligence \n\
    algorithms With UAV‑assisted for vehicular Ad hoc networks \nin intelligent transportation\
    \ systems. IEEE Trans Intell Transp \nSyst 22:4757–4769. https:// doi. org/ 10.\
    \ 1109/ TITS. 2020. 30417 46\nFelius LC, Dessen F, Hrynyszyn BD (2020) Retrofitting\
    \ towards \nenergy‑efficient homes in European cold climates: a \nreview. Energ\
    \ Effi 13:101–125. https:// doi. org/ 10. 1007/ \ns12053‑ 019‑ 09834‑7\nFernandez\
    \ de Canete J, del Saz‑Orozco P, Gómez‑de‑Gabriel J, \nBaratti R, Ruano A, Rivas‑Blanco\
    \ I (2021) Control and soft \nsensing strategies for a wastewater treatment plant\
    \ using a \nneuro‑genetic approach. Comput Chem Eng 144:107146. \nhttps:// doi.\
    \ org/ 10. 1016/j. compc hemeng. 2020. 107146\nGautam K, Sharma P, Dwivedi S,\
    \ Singh A, Gaur VK, Varjani S, \nSrivastava JK, Pandey A, Chang J‑S, Ngo HH (2023)\
    \ A review \non control and abatement of soil pollution by heavy metals: \nemphasis\
    \ on artificial intelligence in recovery of contaminated \nsoil. Environ Res 225:115592.\
    \ https:// doi. org/ 10. 1016/j. envres. \n2023. 115592\nGhadami N, Gheibi M,\
    \ Kian Z, Faramarz MG, Naghedi R, Eftekhari \nM, Fathollahi‑Fard AM, Dulebenets\
    \ MA, Tian G (2021) Imple‑\nmentation of solar energy in smart cities using an\
    \ integration \nof artificial neural network, photovoltaic system and classical\
    \ \nDelphi methods. Sustain Cities Soc 74:103149. https:// doi. org/ \n10. 1016/j.\
    \ scs. 2021. 103149\nGhavami SM, Taleai M, Arentze T (2017) An intelligent spatial\
    \ land \nuse planning support system using socially rational agents. Int J \n\
    Geogr Inf Sci 31:1022–1041. https:// doi. org/ 10. 1080/ 13658 816. \n2016. 12633\
    \ 06\nGonzález Perea R, Camacho Poyato E, Montesinos P, Rodríguez Díaz \nJA (2019)\
    \ Optimisation of water demand forecasting by artificial \nintelligence with short\
    \ data sets. Biosys Eng 177:59–66. https:// \ndoi. org/ 10. 1016/j. biosy stems\
    \ eng. 2018. 03. 011\nGuo W, Qureshi NMF, Jarwar MA, Kim J, Shin DR (2023) AI‑oriented\
    \ \nsmart power system transient stability: the rationality, applica‑\ntions,\
    \ challenges and future opportunities. Sustain Energy \nTechnol Assess 56:102990.\
    \ https:// doi. org/ 10. 1016/j. seta. 2022. \n102990\nGupta S, Li L (2022) The\
    \ Potential of machine learning for enhancing \n CO2 sequestration, storage, transportation,\
    \ and utilization‑based \nprocesses: a brief perspective. JOM 74:414–428. https://\
    \ doi. org/ \n10. 1007/ s11837‑ 021‑ 05079‑x\nHahn D, Munir A, Behzadan V (2021)\
    \ Security and privacy issues in \nintelligent transportation systems: classification\
    \ and challenges. \nIEEE Intell Transp Syst Mag 13:181–196. https:// doi. org/\
    \ 10. \n1109/ MITS. 2019. 28989 73\nHam Y‑G, Kim J‑H, Luo J‑J (2019) Deep learning\
    \ for multi‑year \nENSO forecasts. Nature 573:568–572. https:// doi. org/ 10.\
    \ 1038/ \ns41586‑ 019‑ 1559‑7\nHanifa M, Agarwal R, Sharma U, Thapliyal PC, Singh\
    \ LP (2023) A \nreview on  CO2 capture and sequestration in the construction \n\
    industry: emerging approaches and commercialised technologies. \n2553\nEnvironmental\
    \ Chemistry Letters (2023) 21:2525–2557 \n1 3\nJ Co2 Util 67:102292. https://\
    \ doi. org/ 10. 1016/j. jcou. 2022. \n102292\nHannan MA, Al‑Shetwi AQ, Ker PJ,\
    \ Begum RA, Mansor M, Rah‑\nman SA, Dong ZY, Tiong SK, Mahlia TMI, Muttaqi KM\
    \ (2021) \nImpact of renewable energy utilization and artificial intelligence\
    \ \nin achieving sustainable development goals. Energy Rep 7:5359–\n5373. https://\
    \ doi. org/ 10. 1016/j. egyr. 2021. 08. 172\nHasan MMF, Zantye MS, Kazi M‑K (2022)\
    \ Challenges and opportuni‑\nties in carbon capture, utilization and storage:\
    \ a process systems \nengineering perspective. Comput Chem Eng 166:107925. https://\
    \ \ndoi. org/ 10. 1016/j. compc hemeng. 2022. 107925\nHenderson P, Hu J, Romoff\
    \ J, Brunskill E, Jurafsky D, Pineau J (2020) \nTowards the systematic reporting\
    \ of the energy and carbon foot‑\nprints of machine learning. J Mach Learn Res\
    \ 21:10039–10081. \nhttps:// doi. org/ 10. 5555/ 34557 16. 34559 64\nHeo S, Ko\
    \ J, Kim S, Jeong C, Hwangbo S, Yoo C (2022) Explainable \nAI‑driven net‑zero\
    \ carbon roadmap for petrochemical industry \nconsidering stochastic scenarios\
    \ of remotely sensed offshore \nwind energy. J Clean Prod 379:134793. https://\
    \ doi. org/ 10. 1016/j. \njclep ro. 2022. 134793\nHikosaka T, Aoshima S, Miyao\
    \ T, Funatsu K (2020) Soft sensor \nmodeling for identifying significant process\
    \ variables with time \ndelays. Ind Eng Chem Res 59:12156–12163. https:// doi.\
    \ org/ 10. \n1021/ acs. iecr. 0c016 55\nHsiang S, Kopp R, Jina A, Rising J, Delgado\
    \ M, Mohan S, Rasmussen \nDJ, Muir‑Wood R, Wilson P, Oppenheimer M, Larsen K,\
    \ Houser \nT (2017) Estimating economic damage from climate change in \nthe United\
    \ States. Science 356:1362–1369. https:// doi. org/ 10. \n1126/ scien ce. aal43\
    \ 69\nHuseien GF, Shah KW (2022) A review on 5G technology for smart \nenergy\
    \ management and smart buildings in Singapore. Energy AI \n7:100116. https://\
    \ doi. org/ 10. 1016/j. egyai. 2021. 100116\nIse T, Oba Y (2019) Forecasting climatic\
    \ trends using neural networks: \nan experimental study using global historical\
    \ data. Front Robot \nAI 6:32. https:// doi. org/ 10. 3389/ frobt. 2019. 00032\n\
    Jahanger A, Ozturk I, Chukwuma Onwe J, Joseph TE, Razib Hossain M \n(2023) Do\
    \ technology and renewable energy contribute to energy \nefficiency and carbon\
    \ neutrality? Evidence from top ten manu‑\nfacturing countries. Sustain Energy\
    \ Technol Assess 56:103084. \nhttps:// doi. org/ 10. 1016/j. seta. 2023. 103084\n\
    Javaid M, Haleem A, Singh RP, Suman R (2022) Artificial intelligence \napplications\
    \ for industry 4.0: a literature‑based study. J Ind Integr \nManag 7:83–111. https://\
    \ doi. org/ 10. 1142/ s2424 86222 13000 40\nJha SK, Bilalovic J, Jha A, Patel\
    \ N, Zhang H (2017) Renewable energy: \npresent research and future scope of artificial\
    \ intelligence. Renew \nSustain Energy Rev 77:297–317. https:// doi. org/ 10.\
    \ 1016/j. rser. \n2017. 04. 018\nJiang T, Su X, Zhang G, Zhang T, Wu H (2023)\
    \ Estimating propagation \nprobability from meteorological to ecological droughts\
    \ using a \nhybrid machine learning copula method. Hydrol Earth Syst Sci \n27:559–576.\
    \ https:// doi. org/ 10. 5194/ hess‑ 27‑ 559‑ 2023\nJin W, Atkinson TA, Doughty\
    \ C, Neupane G, Spycher N, McLing TL, \nDobson PF, Smith R, Podgorney R (2022)\
    \ Machine‑learning‑\nassisted high‑temperature reservoir thermal energy storage\
    \ opti‑\nmization. Renew Energy 197:384–397. https:// doi. org/ 10. 1016/j. \n\
    renene. 2022. 07. 118\nJones N (2017) How machine learning could help to improve\
    \ climate \nforecasts. Nature 548:379. https:// doi. org/ 10. 1038/ 54837 9a\n\
    Joseph A, Chandra J, Siddharthan S (2021) Genome analysis for preci‑\nsion agriculture\
    \ using artificial intelligence: a survey. Data Sci \nSecur 132:221–226. https://\
    \ doi. org/ 10. 1007/ 978‑ 981‑ 15‑ 5309‑7_ \n23\nKaack LH, Donti PL, Strubell\
    \ E, Kamiya G, Creutzig F, Rolnick D \n(2022) Aligning artificial intelligence\
    \ with climate change \nmitigation. Nat Clim Chang 12:518–527. https:// doi. org/\
    \ 10. 1038/ \ns41558‑ 022‑ 01377‑7\nKadow C, Hall DM, Ulbrich U (2020) Artificial\
    \ intelligence recon‑\nstructs missing climate information. Nat Geosci 13:408–413.\
    \ \nhttps:// doi. org/ 10. 1038/ s41561‑ 020‑ 0582‑5\nKang P, Chen W, Hou Y, Li\
    \ Y (2018) Linking ecosystem services and \necosystem health to ecological risk\
    \ assessment: a case study of \nthe Beijing‑Tianjin‑Hebei urban agglomeration.\
    \ Sci Total Envi‑\nron 636:1442–1454. https:// doi. org/ 10. 1016/j. scito tenv.\
    \ 2018. 04. \n427\nKhaki S, Wang L (2019) Crop yield prediction using deep neural\
    \ net‑\nworks. Front Plant Sci 10:621. https:// doi. org/ 10. 3389/ fpls. 2019.\
    \ \n00621\nKhalilpourazari S, Khalilpourazary S, Özyüksel Çiftçioğlu A, Weber\
    \ \nG‑W (2021) Designing energy‑efficient high‑precision multi‑pass \nturning\
    \ processes via robust optimization and artificial intelli‑\ngence. J Intell Manuf\
    \ 32:1621–1647. https:// doi. org/ 10. 1007/ \ns10845‑ 020‑ 01648‑0\nKhosravi\
    \ A, Nunes RO, Assad MEH, Machado L (2018) Comparison \nof artificial intelligence\
    \ methods in estimation of daily global \nsolar radiation. J Clean Prod 194:342–358.\
    \ https:// doi. org/ 10. \n1016/j. jclep ro. 2018. 05. 147\nKim MK, Kim Y‑S, Srebric\
    \ J (2020) Predictions of electricity con‑\nsumption in a campus building using\
    \ occupant rates and weather \nelements with sensitivity analysis: artificial\
    \ neural network ver‑\nsus linear regression. Sustain Cities Soc 62:102385. https://\
    \ doi. \norg/ 10. 1016/j. scs. 2020. 102385\nKishor A, Chakraborty C (2022) Artificial\
    \ intelligence and inter‑\nnet of things based healthcare 4.0 monitoring system.\
    \ Wire‑\nless Pers Commun 127:1615–1631. https:// doi. org/ 10. 1007/ \ns11277‑\
    \ 021‑ 08708‑5\nKonhäuser K, Wenninger S, Werner T, Wiethe C (2022) Leveraging\
    \ \nadvanced ensemble models to increase building energy perfor‑\nmance prediction\
    \ accuracy in the residential building sector. \nEnergy Build 269:112242. https://\
    \ doi. org/ 10. 1016/j. enbui ld. \n2022. 112242\nKruse J, Schäfer B, Witthaut\
    \ D (2021) Revealing drivers and risks for \npower grid frequency stability with\
    \ explainable artificial intel‑\nligence. Patterns 2:100365. https:// doi. org/\
    \ 10. 1016/j. patter. 2021. \n100365\nKumari A, Gupta R, Tanwar S, Kumar N (2020)\
    \ Blockchain and AI \namalgamation for energy cloud management: challenges, solu‑\n\
    tions, and future directions. J Parallel Distrib Comput 143:148–\n166. https://\
    \ doi. org/ 10. 1016/j. jpdc. 2020. 05. 004\nKushwaha OS, Uthayakumar H, Kumaresan\
    \ K (2023) Modeling of car‑\nbon dioxide fixation by microalgae using hybrid artificial\
    \ intel‑\nligence (AI) and fuzzy logic (FL) methods and optimization by \ngenetic\
    \ algorithm (GA). Environ Sci Pollut Res 30:24927–24948. \nhttps:// doi. org/\
    \ 10. 1007/ s11356‑ 022‑ 19683‑0\nKussul N, Lavreniuk M, Skakun S, Shelestov A\
    \ (2017) Deep learning \nclassification of land cover and crop types using remote\
    \ sensing \ndata. IEEE Geosci Rem Sens Lett 14:778–782. https:// doi. org/ \n\
    10. 1109/ LGRS. 2017. 26811 28\nLee J, Yoo HJ (2021) An overview of energy‑efficient\
    \ hardware accel‑\nerators for on‑device deep‑neural‑network training. IEEE Open\
    \ \nJ Solid‑State Circuits Soc 1:115–128. https:// doi. org/ 10. 1109/ \nOJSSCS.\
    \ 2021. 31195 54\nLee WJ, Wu H, Yun H, Kim H, Jun MBG, Sutherland JW (2019) \n\
    Predictive maintenance of machine tool systems using artificial \nintelligence\
    \ techniques applied to machine condition data. Proc \nCIRP 80:506–511. https://\
    \ doi. org/ 10. 1016/j. procir. 2018. 12. 019\nLei Y, Liang Z, Ruan P (2023) Evaluation\
    \ on the impact of digital \ntransformation on the economic resilience of the\
    \ energy industry \nin the context of artificial intelligence. Energy Rep 9:785–792.\
    \ \nhttps:// doi. org/ 10. 1016/j. egyr. 2022. 12. 019\n2554\n \nEnvironmental\
    \ Chemistry Letters (2023) 21:2525–2557\n1 3\nLeokumar SP (2017) State of the\
    \ art‑intense review on artificial intel‑\nligence systems application in process\
    \ planning and manufactur‑\ning. Eng Appl Artif Intell 65:294–329. https:// doi.\
    \ org/ 10. 1016/j. \nengap pai. 2017. 08. 005\nLi Y, Chen Y (2021) Development\
    \ of an SBM‑ML model for the \nmeasurement of green total factor productivity:\
    \ the case of pearl \nriver delta urban agglomeration. Renew Sustain Energy Rev\
    \ \n145:111131. https:// doi. org/ 10. 1016/j. rser. 2021. 111131\nLi X, Yu B\
    \ (2019) Peaking  CO2 emissions for China’s urban passenger \ntransport sector.\
    \ Energy Policy 133:110913. https:// doi. org/ 10. \n1016/j. enpol. 2019. 110913\n\
    Li Y, Jia M, Han X, Bai X‑S (2021) Towards a comprehensive optimi‑\nzation of\
    \ engine efficiency and emissions by coupling artificial \nneural network (ANN)\
    \ with genetic algorithm (GA). Energy \n225:120331. https:// doi. org/ 10. 1016/j.\
    \ energy. 2021. 120331\nLiu D, Zhang G, Li H, Fu Q, Li M, Faiz MA, Ali S, Li T,\
    \ Imran Khan \nM (2019) Projection pursuit evaluation model of a regional sur‑\n\
    face water environment based on an ameliorative moth‑flame \noptimization algorithm.\
    \ Ecol Indic 107:105674. https:// doi. org/ \n10. 1016/j. ecoli nd. 2019. 105674\n\
    Liu T, Sun Y, Wang C, Zhang Y, Qiu Z, Gong W, Lei S, Tong X, \nDuan X (2021) Unmanned\
    \ aerial vehicle and artificial intelli‑\ngence revolutionizing efficient and\
    \ precision sustainable forest \nmanagement. J Clean Prod 311:127546. https://\
    \ doi. org/ 10. 1016/j. \njclep ro. 2021. 127546\nLiu D, Liu C, Tang Y, Gong C\
    \ (2022a) A GA‑BP neural network \nregression model for predicting soil moisture\
    \ in slope ecologi‑\ncal protection. Sustainability 14:1386. https:// doi. org/\
    \ 10. 3390/ \nsu140 31386\nLiu T, Chen L, Yang M, Sandanayake M, Miao P, Shi Y,\
    \ Yap P‑S \n(2022b) Sustainability considerations of green buildings: a \ndetailed\
    \ overview on current advancements and future consid‑\nerations. Sustainability\
    \ 14:14393. https:// doi. org/ 10. 3390/ su142 \n114393\nLiu Z, Sun Y, Xing C,\
    \ Liu J, He Y, Zhou Y, Zhang G (2022c) Artifi‑\ncial intelligence powered large‑scale\
    \ renewable integrations in \nmulti‑energy systems for carbon neutrality transition:\
    \ challenges \nand future perspectives. Energy AI 10:100195. https:// doi. org/\
    \ 10. \n1016/j. egyai. 2022. 100195\nLiu W, Feng Q, Engel BA, Yu T, Zhang X, Qian\
    \ Y (2023) A probabil‑\nistic assessment of urban flood risk and impacts of future\
    \ climate \nchange. J Hydrol 618:129267. https:// doi. org/ 10. 1016/j. jhydr\
    \ ol. \n2023. 129267\nLópez Santos A, Torres González JA, Meraz Jiménez ADJ, Sosa\
    \ \nRamírez J, Peña Uribe GDJ, Valdivia Martínez O, García Marín \nMÁ, González\
    \ Barrios JL, Hernández Salgado JR, Arreola Ávila \nJG (2019) Assessing the culture\
    \ of fruit farmers from Calvillo, \nAguascalientes, Mexico with an artificial\
    \ neural network: an \napproximation of sustainable land management. Environ Sci\
    \ \nPolicy 92:311–322. https:// doi. org/ 10. 1016/j. envsci. 2018. 11. 015\n\
    Lv Z, Han Y, Singh AK, Manogaran G, Lv H (2021) Trustworthiness \nin industrial\
    \ IoT systems based on artificial intelligence. IEEE \nTrans Industr Inf 17:1496–1504.\
    \ https:// doi. org/ 10. 1109/ TII. \n2020. 29947 47\nLyu W, Liu J (2021) Artificial\
    \ intelligence and emerging digital tech‑\nnologies in the energy sector. Appl\
    \ Energy 303:117615. https:// \ndoi. org/ 10. 1016/j. apene rgy. 2021. 117615\n\
    Ma W, Qiu Z, Song J, Li J, Cheng Q, Zhai J, Ma C (2018) A deep \nconvolutional\
    \ neural network approach for predicting phenotypes \nfrom genotypes. Planta 248:1307–1318.\
    \ https:// doi. org/ 10. 1007/ \ns00425‑ 018‑ 2976‑9\nMa D, Li X, Lin B, Zhu Y,\
    \ Yue S (2023) A dynamic intelligent building \nretrofit decision‑making model\
    \ in response to climate change. \nEnergy Build 284:112832. https:// doi. org/\
    \ 10. 1016/j. enbui ld. \n2023. 112832\nMaurya SP, Singh PK, Ohri A, Singh R (2020)\
    \ Identification of indi‑\ncators for sustainable urban water development planning.\
    \ Ecol \nIndic 108:105691. https:// doi. org/ 10. 1016/j. ecoli nd. 2019. 105691\n\
    Mayfield H, Smith C, Gallagher M, Hockings M (2017) Use of freely \navailable\
    \ datasets and machine learning methods in predicting \ndeforestation. Environ\
    \ Model Softw 87:17–28. https:// doi. org/ \n10. 1016/j. envso ft. 2016. 10. 006\n\
    McGovern A, Elmore KL, Gagne DJ, Haupt SE, Karstens CD, Lager‑\nquist R, Smith\
    \ T, Williams JK (2017) Using artificial intelligence \nto improve real‑time decision‑making\
    \ for high‑impact weather. \nBull Am Meteor Soc 98:2073–2090. https:// doi. org/\
    \ 10. 1175/ \nBAMS‑D‑ 16‑ 0123.1\nMhlanga D (2023) Artificial intelligence and\
    \ machine learning for \nenergy consumption and production in emerging markets:\
    \ a \nreview. Energies 16:745. https:// doi. org/ 10. 3390/ en160 20745\nMi Z,\
    \ Guan D, Liu Z, Liu J, Viguié V, Fromer N, Wang Y (2019) Cit‑\nies: the core\
    \ of climate change mitigation. J Clean Prod 207:582–\n589. https:// doi. org/\
    \ 10. 1016/j. jclep ro. 2018. 10. 034\nMihăiţă AS, Dupont L, Chery O, Camargo\
    \ M, Cai C (2019) Evaluating \nair quality by combining stationary, smart mobile\
    \ pollution mon‑\nitoring and data‑driven modelling. J Clean Prod 221:398–418.\
    \ \nhttps:// doi. org/ 10. 1016/j. jclep ro. 2019. 02. 179\nMoraliyage H, Dahanayake\
    \ S, De Silva D, Mills N, Rathnayaka P, \nNguyen S, Alahakoon D, Jennings A (2022)\
    \ A robust artificial \nintelligence approach with explainability for measurement\
    \ and \nverification of energy efficient infrastructure for net zero carbon \n\
    emissions. Sensors 22:9503. https:// doi. org/ 10. 3390/ s2223 9503\nMostajabi\
    \ A, Finney DL, Rubinstein M, Rachidi F (2019) Nowcasting \nlightning occurrence\
    \ from commonly available meteorological \nparameters using machine learning techniques.\
    \ npj Clim Atmos \nSci 2:41. https:// doi. org/ 10. 1038/ s41612‑ 019‑ 0098‑0\n\
    Mrówczyńska M, Sztubecka M, Skiba M, Bazan‑Krzywoszańska A, \nBejga P (2019) The\
    \ use of artificial intelligence as a tool support‑\ning sustainable development\
    \ local policy. Sustainability 11:4199. \nhttps:// doi. org/ 10. 3390/ su111 54199\n\
    Nawaz R, Akhtar R, Shahid MA, Qureshi IM, Mahmood MH (2021) \nMachine learning\
    \ based false data injection in smart grid. Int J \nElectr Power Energy Syst 130:106819.\
    \ https:// doi. org/ 10. 1016/j. \nijepes. 2021. 106819\nNewman ME, McLaren KP,\
    \ Wilson BS (2014) Assessing deforesta‑\ntion and fragmentation in a tropical\
    \ moist forest over 68 years; \nthe impact of roads and legal protection in the\
    \ Cockpit Coun‑\ntry, Jamaica. For Ecol Manage 315:138–152. https:// doi. org/\
    \ 10. \n1016/j. foreco. 2013. 12. 033\nNgarambe J, Yun GY, Santamouris M (2020)\
    \ The use of artificial \nintelligence (AI) methods in the prediction of thermal\
    \ comfort \nin buildings: energy implications of AI‑based thermal comfort \ncontrols.\
    \ Energy Build 211:109807. https:// doi. org/ 10. 1016/j. \nenbui ld. 2020. 109807\n\
    Nguyen HAT, Sophea T, Gheewala SH, Rattanakom R, Areerob T, \nPrueksakorn K (2021)\
    \ Integrating remote sensing and machine \nlearning into environmental monitoring\
    \ and assessment of land \nuse change. Sustain Prod Consum 27:1239–1254. https://\
    \ doi. org/ \n10. 1016/j. spc. 2021. 02. 025\nNikitas A, Michalakopoulou K, Njoya\
    \ ET, Karampatzakis D (2020) \nArtificial Intelligence, transport and the smart\
    \ city: definitions \nand dimensions of a new mobility era. Sustainability 12:2789.\
    \ \nhttps:// doi. org/ 10. 3390/ su120 72789\nNižetić S, Djilali N, Papadopoulos\
    \ A, Rodrigues JJPC (2019) Smart \ntechnologies for promotion of energy efficiency,\
    \ utilization of \nsustainable resources and waste management. J Clean Prod \n\
    231:565–591. https:// doi. org/ 10. 1016/j. jclep ro. 2019. 04. 397\nOlabi AG,\
    \ Abdelghafar AA, Maghrabie HM, Sayed ET, Rezk H, Radi \nMA, Obaideen K, Abdelkareem\
    \ MA (2023) Application of \nartificial intelligence for prediction, optimization,\
    \ and control \n2555\nEnvironmental Chemistry Letters (2023) 21:2525–2557 \n1\
    \ 3\nof thermal energy storage systems. Therm Sci Eng Progress \n39:101730. https://\
    \ doi. org/ 10. 1016/j. tsep. 2023. 101730\nOlayode OI, Tartibu LK, Okwu MO (2020)\
    \ Application of artificial \nintelligence in traffic control system of non‑autonomous\
    \ vehicles \nat signalized road intersection. Proc CIRP 91:194–200. https:// \n\
    doi. org/ 10. 1016/j. procir. 2020. 02. 167\nOruganti RK, Biji AP, Lanuyanger\
    \ T, Show PL, Sriariyanun M, Upad‑\nhyayula VKK, Gadhamshetty V, Bhattacharyya\
    \ D (2023) Artifi‑\ncial intelligence and machine learning tools for high‑performance\
    \ \nmicroalgal wastewater treatment and algal biorefinery: a critical \nreview.\
    \ Sci Total Environ 876:162797. https:// doi. org/ 10. 1016/j. \nscito tenv. 2023.\
    \ 162797\nOsman AI, Chen L, Yang M, Msigwa G, Farghali M, Fawzy S, \nRooney DW,\
    \ Yap P‑S (2022) Cost, environmental impact, and \nresilience of renewable energy\
    \ under a changing climate: a \nreview. Environ Chem Lett 21:741–764. https://\
    \ doi. org/ 10. 1007/ \ns10311‑ 022‑ 01532‑8\nOuadah A, Zemmouchi‑Ghomari L, Salhi\
    \ N (2022) Selecting an appro‑\npriate supervised machine learning algorithm for\
    \ predictive \nmaintenance. Int J Adv Manuf Technol 119:4277–4301. https:// \n\
    doi. org/ 10. 1007/ s00170‑ 021‑ 08551‑9\nPartel V, Charan Kakarla S, Ampatzidis\
    \ Y (2019) Development and \nevaluation of a low‑cost and smart technology for\
    \ precision weed \nmanagement utilizing artificial intelligence. Comput Electron\
    \ \nAgric 157:339–350. https:// doi. org/ 10. 1016/j. compag. 2018. 12. \n048\n\
    Perera YS, Ratnaweera DAAC, Dasanayaka CH, Abeykoon C (2023) \nThe role of artificial\
    \ intelligence‑driven soft sensors in advanced \nsustainable process industries:\
    \ a critical review. Eng Appl Artif \nIntell 121:105988. https:// doi. org/ 10.\
    \ 1016/j. engap pai. 2023. \n105988\nPham BT, Le LM, Le T‑T, Bui K‑TT, Le VM,\
    \ Ly H‑B, Prakash I (2020) \nDevelopment of advanced artificial intelligence models\
    \ for daily \nrainfall prediction. Atmos Res 237:104845. https:// doi. org/ 10.\
    \ \n1016/j. atmos res. 2020. 104845\nPluchinotta I, Pagano A, Vilcan T, Ahilan\
    \ S, Kapetas L, Maskrey S, \nKrivtsov V, Thorne C, O’Donnell E (2021) A participatory\
    \ sys‑\ntem dynamics model to investigate sustainable urban water man‑\nagement\
    \ in Ebbsfleet Garden City. Sustain Cities Soc 67:102709. \nhttps:// doi. org/\
    \ 10. 1016/j. scs. 2021. 102709\nPullman M, Gurung I, Maskey M, Ramachandran R,\
    \ Christopher SA \n(2019) Applying deep learning to hail detection: a case study.\
    \ \nIEEE Trans Geosci Rem Sens 57:10218–10225. https:// doi. org/ \n10. 1109/\
    \ TGRS. 2019. 29319 44\nPutra DP, Bimantio MP, Sahfitra AA, Suparyanto T, Pardamean\
    \ B \n(2020) Simulation of availability and loss of nutrient elements in \nland\
    \ with android‑based fertilizing applications. In: 2020 inter‑\nnational conference\
    \ on information management and technology \n(ICIMTech), pp 312–317. https://\
    \ doi. org/ 10. 1109/ ICIMT ech50 \n083. 2020. 92112 68\nQerimi Q, Sergi BS (2022)\
    \ The case for global regulation of carbon \ncapture and storage and artificial\
    \ intelligence for climate change. \nInt J Greenh Gas Control 120:103757. https://\
    \ doi. org/ 10. 1016/j. \nijggc. 2022. 103757\nRaj EFI, Appadurai M, Athiappan\
    \ K (2021) Precision farming in \nmodern agriculture.  Smart Agriculture Automation\
    \ Using \nAdvanced Technologies 65:294–329. https:// doi. org/ 10. 1007/ \n978‑\
    \ 981‑ 16‑ 6124‑2_4\nReddy KSP, Roopa YM, L.N KR, Nandan NS (2020) IoT based smart\
    \ \nagriculture using machine learning. In: 2020 Second interna‑\ntional conference\
    \ on inventive research in computing applications \n(ICIRCA), pp 130–134. https://\
    \ doi. org/ 10. 1109/ ICIRC A48905. \n2020. 91833 73\nRidwan WM, Sapitang M, Aziz\
    \ A, Kushiar KF, Ahmed AN, El‑Shafie \nA (2021) Rainfall forecasting model using\
    \ machine learning \nmethods: case study Terengganu, Malaysia. Ain Shams Eng J\
    \ \n12:1651–1663. https:// doi. org/ 10. 1016/j. asej. 2020. 09. 011\nRustia DJA,\
    \ Lin CE, Chung J‑Y, Zhuang Y‑J, Hsu J‑C, Lin T‑T (2020) \nApplication of an image\
    \ and environmental sensor network for \nautomated greenhouse insect pest monitoring.\
    \ J Asia‑Pacific \nEntomol 23:17–28. https:// doi. org/ 10. 1016/j. aspen. 2019.\
    \ 11. 006\nRustia DJA, Chiu L‑Y, Lu C‑Y, Wu Y‑F, Chen S‑K, Chung J‑Y, Hsu \nJ‑C,\
    \ Lin T‑T (2022) Towards intelligent and integrated pest man‑\nagement through\
    \ an AIoT‑based monitoring system. Pest Manag \nSci 78:4288–4302. https:// doi.\
    \ org/ 10. 1002/ ps. 7048\nSaheb T, Dehghani M, Saheb T (2022) Artificial intelligence\
    \ for sus‑\ntainable energy: a contextual topic modeling and content analy‑\n\
    sis. Sustain Comput: Inform Syst 35:100699. https:// doi. org/ 10. \n1016/j. suscom.\
    \ 2022. 100699\nSahil K, Mehta P, Kumar Bhardwaj S, Dhaliwal LK (2023) Chapter 20:\
    \ \ndevelopment of mitigation strategies for the climate change using \nartificial\
    \ intelligence to attain sustainability. Visualization Tech‑\nniques for Climate\
    \ Change with Machine Learning and Artificial \nIntelligence 2023:421–448.  https://\
    \ doi. org/ 10. 1016/ B978‑0‑ 323‑ \n99714‑0. 00021‑2\nSaputra MH, Lee HS (2019)\
    \ Prediction of Land use and land cover \nchanges for North Sumatra, Indonesia,\
    \ using an artificial‑neural‑\nnetwork‑based cellular automaton. Sustainability\
    \ 11:11. https:// \ndoi. org/ 10. 3390/ su111 13024\nSarker IH (2022) AI‑based\
    \ modeling: techniques, applications and \nresearch issues towards automation,\
    \ intelligent and smart \nsystems. SN Comput Sci 3:158. https:// doi. org/ 10.\
    \ 1007/ \ns42979‑ 022‑ 01043‑x\nSaxena H, Aponte O, McConky KT (2019) A hybrid\
    \ machine learn‑\ning model for forecasting a billing period’s peak electric load\
    \ \ndays. Int J Forecast 35:1288–1303. https:// doi. org/ 10. 1016/j. \nijfor\
    \ ecast. 2019. 03. 025\nShams SR, Jahani A, Kalantary S, Moeinaddini M, Khorasani\
    \ N \n(2021) Artificial intelligence accuracy assessment in  NO2 con‑\ncentration\
    \ forecasting of metropolises air. Sci Rep 11:1805. \nhttps:// doi. org/ 10. 1038/\
    \ s41598‑ 021‑ 81455‑6\nShao Z, Zhao R, Yuan S, Ding M, Wang Y (2022) Tracing\
    \ the evo‑\nlution of AI in the past decade and forecasting the emerging \ntrends.\
    \ Exp Syst Appl 209:118221. https:// doi. org/ 10. 1016/j. \neswa. 2022. 118221\n\
    Shin W, Han J, Rhee W (2021) AI‑assistance for predictive main‑\ntenance of renewable\
    \ energy systems. Energy 221:119775. \nhttps:// doi. org/ 10. 1016/j. energy.\
    \ 2021. 119775\nShivanna KR (2022) Climate change and its impact on biodiversity\
    \ \nand human welfare. Proc Indian Natl Sci Acad 88:160–171. \nhttps:// doi. org/\
    \ 10. 1007/ s43538‑ 022‑ 00073‑6\nSingh S, Sharma PK, Yoon B, Shojafar M, Cho\
    \ GH, Ra I‑H (2020) \nConvergence of blockchain and artificial intelligence in\
    \ IoT \nnetwork for the sustainable smart city. Sustain Cities Soc \n63:102364.\
    \ https:// doi. org/ 10. 1016/j. scs. 2020. 102364\nSolaymani S (2019)  CO2 emissions\
    \ patterns in 7 top carbon emitter \neconomies: the case of transport sector.\
    \ Energy 168:989–1001. \nhttps:// doi. org/ 10. 1016/j. energy. 2018. 11. 145\n\
    Sun K, Wu X, Xue J, Ma F (2019a) Development of a new multi‑\nlayer perceptron\
    \ based soft sensor for  SO2 emissions in power \nplant. J Process Control 84:182–191.\
    \ https:// doi. org/ 10. 1016/j. \njproc ont. 2019. 10. 007\nSun Y, Gao C, Li\
    \ J, Wang R, Liu J (2019b) Quantifying the effects \nof urban form on land surface\
    \ temperature in subtropi‑\ncal high‑density urban areas using machine learning.\
    \ Rem \nSens 11:959. https:// doi. org/ 10. 3390/ rs110 80959\nSun Y‑M, Han X,\
    \ Zhang D‑X, Sun Q‑Y, Chen X‑G, Yao M‑P, Huang \nS‑Y, Ma D‑S, Zhou B (2020) Study\
    \ on online soft sensor \nmethod of total sugar content in chlorotetracycline\
    \ fermen‑\ntation tank. Open Chem 18:31–38. https:// doi. org/ 10. 1515/ \nchem‑\
    \ 2020‑ 0004\n2556\n \nEnvironmental Chemistry Letters (2023) 21:2525–2557\n1\
    \ 3\nSwaminathan B, Palani S, Vairavasundaram S, Kotecha K, Kumar V \n(2023) IoT‑driven\
    \ artificial intelligence technique for fertilizer \nrecommendation model. IEEE\
    \ Consum Electron Mag 12:109–\n117. https:// doi. org/ 10. 1109/ MCE. 2022. 31513\
    \ 25\nSwennenhuis F, de Gooyert V, de Coninck H (2022) Towards a \n CO2‑neutral\
    \ steel industry: justice aspects of  CO2 capture and \nstorage, biomass‑ and\
    \ green hydrogen‑based emission reductions. \nEnergy Res Soc Sci 88:102598. https://\
    \ doi. org/ 10. 1016/j. erss. \n2022. 102598\nSzewrański S, Świąder M, Kazak JK,\
    \ Tokarczyk‑Dorociak K, van Hoof \nJ (2018) Socio‑environmental vulnerability\
    \ mapping for environ‑\nmental and flood resilience assessment: the case of ageing\
    \ and \npoverty in the City of Wrocław, Poland. Integr Environ Assess \nManag\
    \ 14:592–597. https:// doi. org/ 10. 1002/ ieam. 4077\nTian Z, Shi X, Hong S‑M\
    \ (2021) Exploring data‑driven building \nenergy‑efficient design of envelopes\
    \ based on their quantified \nimpacts. J Build Eng 42:103018. https:// doi. org/\
    \ 10. 1016/j. jobe. \n2021. 103018\nTien Bui D, Pham BT, Nguyen QP, Hoang N‑D\
    \ (2016) Spatial predic‑\ntion of rainfall‑induced shallow landslides using hybrid\
    \ integra‑\ntion approach of least‑squares support vector machines and dif‑\n\
    ferential evolution optimization: a case study in central Vietnam. \nInt J Dig\
    \ Earth 9:1077–1097. https:// doi. org/ 10. 1080/ 17538 947. \n2016. 11695 61\n\
    Tien Bui D, Bui Q‑T, Nguyen Q‑P, Pradhan B, Nampak H, Trinh PT \n(2017) A hybrid\
    \ artificial intelligence approach using GIS‑based \nneural‑fuzzy inference system\
    \ and particle swarm optimization \nfor forest fire susceptibility modeling at\
    \ a tropical area. Agric \nFor Meteorol 233:32–44. https:// doi. org/ 10. 1016/j.\
    \ agrfo rmet. \n2016. 11. 002\nTomazzoli C, Scannapieco S, Cristani M (2020) Internet\
    \ of Things \nand artificial intelligence enable energy efficiency. J Ambient\
    \ \nIntell Humaniz Comput 14:4933–4954. https:// doi. org/ 10. 1007/ \ns12652‑\
    \ 020‑ 02151‑3\nTorres VAMF, Jaimes BRA, Ribeiro ES, Braga MT, Shiguemori EH,\
    \ \nVelho HFC, Torres LCB, Braga AP (2020) Combined weightless \nneural network\
    \ FPGA architecture for deforestation surveillance \nand visual navigation of\
    \ UAVs. Eng Appl Artif Intell 87:103227. \nhttps:// doi. org/ 10. 1016/j. engap\
    \ pai. 2019. 08. 021\nTyagi AK, Aswathy SU (2021) Autonomous intelligent vehicles\
    \ (AIV): \nresearch statements, open issues, challenges and road for future. \n\
    Int J Intell Netw 2:83–102. https:// doi. org/ 10. 1016/j. ijin. 2021. \n07. 002\n\
    Ullah Z, Al‑Turjman F, Mostarda L, Gagliardi R (2020) Applications \nof artificial\
    \ intelligence and machine learning in smart cities. \nComput Commun 154:313–323.\
    \ https:// doi. org/ 10. 1016/j. com‑\ncom. 2020. 02. 069\nVinuesa R, Azizpour\
    \ H, Leite I, Balaam M, Dignum V, Domisch S, \nFelländer A, Langhans SD, Tegmark\
    \ M, Fuso Nerini F (2020) \nThe role of artificial intelligence in achieving the\
    \ sustainable \ndevelopment goals. Nat Commun 11:233. https:// doi. org/ 10. \n\
    1038/ s41467‑ 019‑ 14108‑y\nWang Z, Srinivasan RS (2017) A review of artificial\
    \ intelligence based \nbuilding energy use prediction: contrasting the capabilities\
    \ of \nsingle and ensemble prediction models. Renew Sustain Energy \nRev 75:796–808.\
    \ https:// doi. org/ 10. 1016/j. rser. 2016. 10. 079\nWang Y, Chen Q, Hong T,\
    \ Kang C (2019) Review of smart meter data \nanalytics: applications, methodologies,\
    \ and challenges. IEEE \nTrans Smart Grid 10:3125–3148. https:// doi. org/ 10.\
    \ 1109/ TSG. \n2018. 28181 67\nWang H, Liu Y, Zhou B, Li C, Cao G, Voropai N,\
    \ Barakhtenko E \n(2020) Taxonomy research of artificial intelligence for deter‑\n\
    ministic solar power forecasting. Energy Convers Manag \n214:112909. https://\
    \ doi. org/ 10. 1016/j. encon man. 2020. 112909\nWei MCF, Maldaner LF, Ottoni\
    \ PMN, Molin JP (2020) Carrot yield \nmapping: a precision agriculture approach\
    \ based on machine \nlearning. AI 1:229–241. https:// doi. org/ 10. 3390/ ai102\
    \ 0015\nWu H, Han Y, Jin J, Geng Z (2021) Novel deep learning based on data \n\
    fusion integrating correlation analysis for soft sensor modeling. \nInd Eng Chem\
    \ Res 60:10001–10010. https:// doi. org/ 10. 1021/ acs. \niecr. 1c011 31\nWu J,\
    \ Wang X, Dang Y, Lv Z (2022) Digital twins and artificial intelli‑\ngence in\
    \ transportation infrastructure: classification, application, \nand future research\
    \ directions. Comput Electr Eng 101:107983. \nhttps:// doi. org/ 10. 1016/j. compe\
    \ leceng. 2022. 107983\nXiang X, Li Q, Khan S, Khalaf OI (2021) Urban water resource\
    \ man‑\nagement for sustainable environment planning using artificial \nintelligence\
    \ techniques. Environ Impact Assess Rev 86:106515. \nhttps:// doi. org/ 10. 1016/j.\
    \ eiar. 2020. 106515\nXie R, Jan NM, Hao K, Chen L, Huang B (2020) supervised\
    \ vari‑\national autoencoders for soft sensor modeling with missing data. \nIEEE\
    \ Trans Industr Inf 16:2820–2828. https:// doi. org/ 10. 1109/ \nTII. 2019. 29516\
    \ 22\nXu Y, Yin W (2015) Block stochastic gradient iteration for convex and \n\
    nonconvex optimization. SIAM J Optim 25:1686–1716. https:// \ndoi. org/ 10. 1137/\
    \ 14098 3938\nYan B, Hao F, Meng X (2021) When artificial intelligence meets build‑\n\
    ing energy efficiency, a review focusing on zero energy build‑\ning. Artif Intell\
    \ Rev 54:2193–2220. https:// doi. org/ 10. 1007/ \ns10462‑ 020‑ 09902‑w\nYang\
    \ C‑H (2022) How artificial intelligence technology affects pro‑\nductivity and\
    \ employment: firm‑level evidence from Taiwan. Res \nPolicy 51:104536. https://\
    \ doi. org/ 10. 1016/j. respol. 2022. 104536\nYang M, Chen L, Msigwa G, Tang KHD,\
    \ Yap P‑S (2022) Implica‑\ntions of COVID‑19 on global environmental pollution\
    \ and car‑\nbon emissions with strategies for sustainability in the COVID‑19 \n\
    era. Sci Total Environ 809:151657. https:// doi. org/ 10. 1016/j. scito \ntenv.\
    \ 2021. 151657\nYang M, Chen L, Wang J, Msigwa G, Osman AI, Fawzy S, Rooney \n\
    DW, Yap P‑S (2023) Circular economy strategies for combating \nclimate change\
    \ and other environmental issues. Environ Chem \nLett 21:55–80. https:// doi.\
    \ org/ 10. 1007/ s10311‑ 022‑ 01499‑6\nYao P, Yu Z, Zhang Y, Xu T (2023) Application\
    \ of machine learn‑\ning in carbon capture and storage: an in‑depth insight from\
    \ the \nperspective of geoscience. Fuel 333:126296. https:// doi. org/ 10. \n\
    1016/j. fuel. 2022. 126296\nYin X, Li J, Kadry SN, Sanz‑Prieto I (2021) Artificial\
    \ intelligence \nassisted intelligent planning framework for environmental res‑\n\
    toration of terrestrial ecosystems. Environ Impact Assess Rev \n86:106493. https://\
    \ doi. org/ 10. 1016/j. eiar. 2020. 106493\nYuan X, Wang Y, Yang C, Gui W (2020)\
    \ Stacked isomorphic autoen‑\ncoder based soft analyzer and its application to\
    \ sulfur recovery \nunit. Inf Sci 534:72–84. https:// doi. org/ 10. 1016/j. ins.\
    \ 2020. 03. 018\nYue X‑L, Gao Q‑X (2018) Contributions of natural systems and\
    \ human \nactivity to greenhouse gas emissions. Adv Clim Chang Res \n9:243–252.\
    \ https:// doi. org/ 10. 1016/j. accre. 2018. 12. 003\nYue W, Yao Y, Su M, Rong\
    \ Q, Xu C (2023) Identifying distributions \nof urban ecosystem health based on\
    \ Latin‑hypercube sampling \nand multi‑criteria decision analysis framework. Ecol\
    \ Indic \n147:109957. https:// doi. org/ 10. 1016/j. ecoli nd. 2023. 109957\n\
    Zahraee SM, Khalaji Assadi M, Saidur R (2016) Application of arti‑\nficial intelligence\
    \ methods for hybrid energy system optimiza‑\ntion. Renew Sustain Energy Rev 66:617–630.\
    \ https:// doi. org/ 10. \n1016/j. rser. 2016. 08. 028\nZhang R, Chen Z‑Y, Xu\
    \ L‑J, Ou C‑Q (2019a) Meteorological drought \nforecasting based on a statistical\
    \ model with machine learn‑\ning techniques in Shaanxi province, China. Sci Total\
    \ Environ \n665:338–346. https:// doi. org/ 10. 1016/j. scito tenv. 2019. 01.\
    \ 431\n2557\nEnvironmental Chemistry Letters (2023) 21:2525–2557 \n1 3\nZhang\
    \ X, Song J, Peng J, Wu J (2019b) Landslides‑oriented urban \ndisaster resilience\
    \ assessment: a case study in ShenZhen, China. \nSci Total Environ 661:95–106.\
    \ https:// doi. org/ 10. 1016/j. scito \ntenv. 2018. 12. 074\nZhang P, Guo Z,\
    \ Ullah S, Melagraki G, Afantitis A, Lynch I (2021) \nNanotechnology and artificial\
    \ intelligence to enable sustainable \nand precision agriculture. Nat Plants 7:864–876.\
    \ https:// doi. org/ \n10. 1038/ s41477‑ 021‑ 00946‑6\nZhang Z, Zheng Y, Qian\
    \ L, Luo D, Dou H, Wen G, Yu A, Chen Z \n(2022) Emerging trends in sustainable\
    \  CO2‑management materi‑\nals. Adv Mater 34:2201547. https:// doi. org/ 10. 1002/\
    \ adma. 20220 \n1547\nZhang Y, Teoh BK, Wu M, Chen J, Zhang L (2023) Data‑driven\
    \ esti‑\nmation of building energy consumption and GHG emissions \nusing explainable\
    \ artificial intelligence. Energy 262:125468. \nhttps:// doi. org/ 10. 1016/j.\
    \ energy. 2022. 125468\nZhao Y, Li T, Zhang X, Zhang C (2019) Artificial intelligence‑based\
    \ \nfault detection and diagnosis methods for building energy sys‑\ntems: advantages,\
    \ challenges and the future. Renew Sustain \nEnergy Rev 109:85–101. https:// doi.\
    \ org/ 10. 1016/j. rser. 2019. 04. \n021\nZhao P, Gao Y, Sun X (2022) How does\
    \ artificial intelligence affect \ngreen economic growth? Evidence from China.\
    \ Sci Total Envi‑\nron 834:155306. https:// doi. org/ 10. 1016/j. scito tenv.\
    \ 2022. 155306\nZheng G, Li X, Zhang R‑H, Liu B (2020) Purely satellite data–driven\
    \ \ndeep learning forecast of complicated tropical instability waves. \nSci Adv\
    \ 6:1482. https:// doi. org/ 10. 1126/ sciadv. aba14 82\nZheng J, Shen F, Ye L\
    \ (2021) Improved mahalanobis distance based \nJITL‑LSTM soft sensor for multiphase\
    \ batch processes. IEEE \nAccess 9:72172–72182. https:// doi. org/ 10. 1109/ ACCESS.\
    \ 2021. \n30791 84\nZhou Y, Chang F‑J, Chang L‑C, Kao IF, Wang Y‑S (2019) Explore\
    \ a \ndeep learning multi‑output neural network for regional multi‑\nstep‑ahead\
    \ air quality forecasts. J Clean Prod 209:134–145. \nhttps:// doi. org/ 10. 1016/j.\
    \ jclep ro. 2018. 10. 243\nZhu S, Li D, Feng H (2019) Is smart city resilient?\
    \ Evidence from \nChina. Sustain Cities Soc 50:101636. https:// doi. org/ 10.\
    \ 1016/j. \nscs. 2019. 101636\nZhu C, Zhang X, Zhou M, He S, Gan M, Yang L, Wang\
    \ K (2020a) \nImpacts of urbanization and landscape pattern on habitat quality\
    \ \nusing OLS and GWR models in Hangzhou, China. Ecol Indic \n117:106654. https://\
    \ doi. org/ 10. 1016/j. ecoli nd. 2020. 106654\nZhu S, Li D, Feng H, Gu T, Hewage\
    \ K, Sadiq R (2020b) Smart city \nand resilient city: differences and connections.\
    \ Wires Data Min \nKnowl Discov 10:e1388. https:// doi. org/ 10. 1002/ widm. 1388\n\
    Zubaidi SL, Al‑Bugharbee H, Ortega‑Martorell S, Gharghan SK, Olier \nI, Hashim\
    \ KS, Al‑Bdairi NS, Kot P (2020) A novel methodol‑\nogy for prediction urban water\
    \ demand by wavelet denoising and \nadaptive neuro‑fuzzy inference system approach.\
    \ Water 12:1628. \nhttps:// doi. org/ 10. 3390/ w1206 1628\nPublisher's Note Springer\
    \ Nature remains neutral with regard to \njurisdictional claims in published maps\
    \ and institutional affiliations.\n"
  inline_citation: '>'
  journal: Environmental chemistry letters (Print)
  limitations: '>'
  pdf_link: https://link.springer.com/content/pdf/10.1007/s10311-023-01617-y.pdf
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'Artificial intelligence-based solutions for climate change: a review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/electronics12112490
  analysis: '>'
  authors:
  - Dimitris Kanellopoulos
  - V. Sharma
  - Theodor Panagiotakopoulos
  - Achilles Kameas
  citation_count: 6
  full_citation: '>'
  full_text: ">\nCitation: Kanellopoulos, D.; Sharma,\nV.K.; Panagiotakopoulos, T.;\
    \ Kameas,\nA. Networking Architectures and\nProtocols for IoT Applications in\n\
    Smart Cities: Recent Developments\nand Perspectives. Electronics 2023, 12,\n2490.\
    \ https://doi.org/10.3390/\nelectronics12112490\nAcademic Editors: Marek Pagáˇc,\n\
    Chuan Pham, Van Dung Nguyen,\nHuynh Kha Tu, Huu Khoa Tran and\nTran Anh Khoa\n\
    Received: 28 April 2023\nRevised: 28 May 2023\nAccepted: 29 May 2023\nPublished:\
    \ 31 May 2023\nCopyright:\n© 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\n\
    This article is an open access article\ndistributed\nunder\nthe\nterms\nand\n\
    conditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n\
    4.0/).\nelectronics\nReview\nNetworking Architectures and Protocols for IoT Applications\
    \ in\nSmart Cities: Recent Developments and Perspectives\nDimitris Kanellopoulos\
    \ 1,*\n, Varun Kumar Sharma 2, Theodor Panagiotakopoulos 3,4,*\nand Achilles Kameas\
    \ 3\n1\nDepartment of Mathematics, University of Patras, 26500 Patras, Greece\n\
    2\nDepartment of Computer Science and Engineering, The LNM Institute of Information\
    \ Technology,\nJaipur 302031, India; varunksharma.102119.cse@gmail.com\n3\nSchool\
    \ of Science and Technology, Hellenic Open University, 26335 Patras, Greece; kameas@eap.gr\n\
    4\nSchool of Business, University of Nicosia, 2417 Nicosia, Cyprus\n*\nCorrespondence:\
    \ d_kan2006@yahoo.gr (D.K.); panagiotakopoulos@eap.gr (T.P.)\nAbstract: Numerous\
    \ municipalities employ the smart city model in large cities to improve the quality\n\
    of life of their residents, utilize local resources efﬁciently, and save operating\
    \ expenses. This model\nincorporates many heterogeneous technologies such as Cyber-Physical\
    \ Systems (CPS), Wireless\nSensor Networks (WSNs), and Cloud Computing (ClCom).\
    \ However, effective networking and\ncommunication protocols are required to provide\
    \ the essential harmonization and control of the many\nsystem mechanisms to achieve\
    \ these crucial goals. The networking requirements and characteristics\nof smart\
    \ city applications (SCAs) are identiﬁed in this study, as well as the networking\
    \ protocols\nthat can be utilized to serve the diverse data trafﬁc ﬂows that are\
    \ required between the dissimilar\nmechanisms. Additionally, we show examples\
    \ of the networking designs of a few smart city systems,\nsuch as smart transport,\
    \ smart building, smart home, smart grid, smart water, pipeline monitoring,\n\
    and control systems.\nKeywords: smart city; IoT applications; networking architectures;\
    \ Cyber-Physical Systems (CPS);\nWireless Sensor Networks (WSNs)\n1. Introduction\n\
    Nowadays, several municipalities implement the smart city model [1] to improve\n\
    the quality of life for their citizens and the efﬁcient use of city resources.\
    \ Intelligent\nservices can decrease operational costs and resource expenditure\
    \ in smart cities. They can\nenhance performance and operations in a wide variety\
    \ of smart city applications (SCAs)\nincluding transportation, healthcare, energy,\
    \ education, and many more. Smart services are\nprovided by various cutting-edge\
    \ technologies supporting the smart city model. Examples\nof these technologies\
    \ include the internet of things (IoT), Wireless Sensor Networks (WSNs),\nCyber-Physical\
    \ Systems (CPS), Cloud Computing (ClCom), fog computing (FoC), big data\nanalytics,\
    \ and robots.\nIoT is the core technology used in smart cities, bringing plentiful\
    \ human life beneﬁts [2].\nIoT enables the integration of physical objects/smart\
    \ things into urban environments\nwhere innovative services are offered to support\
    \ every activity at any time and from any\nlocation [2]. Things are monitored\
    \ by IoT applications that make direct decisions for their\nefﬁcient management.\
    \ Moreover, things state their conditions, such as battery status and\nfault reporting\
    \ for prognostic maintenance. WSNs offer real-time monitoring of the state\nof\
    \ the infrastructure and resources in a smart city [3]. Wireless sensor devices\
    \ can also\nobtain physical environment information such as temperature. In a\
    \ CPS, the computation,\nnetworking, and physical processes are put together to\
    \ control and monitor the physical\nenvironment of a smart city [4]. In smart\
    \ cities, CPSs are employed to offer practical\nconnections between the virtual\
    \ and physical worlds. Applications for smart cities can\nbe sustained by the\
    \ ClCom paradigm that provides a scalable and affordable platform\nElectronics\
    \ 2023, 12, 2490. https://doi.org/10.3390/electronics12112490\nhttps://www.mdpi.com/journal/electronics\n\
    Electronics 2023, 12, 2490\n2 of 63\nfor computation and IoT data storage [5].\
    \ FogC offers reduced latency, greater mobility,\nlocation awareness, streaming,\
    \ and real-time response for SCAs [6]. Smart cities have\ndispersed vast numbers\
    \ of sensors, and thus large-scale data processing requires a complex\ninfrastructure.\
    \ Robotics in the cloud can be an effective computing tool for IoT applications\n\
    that require a lot of data processing [7]. To improve the services offered by\
    \ smart cities,\nbig data analytics is employed to generate intelligent and optimal\
    \ temporary and lasting\ndecisions [8].\nThe abovementioned technologies are used\
    \ to implement numerous smart city ser-\nvices [9,10]. For instance, intelligent\
    \ transportation services are applied to improve route\nplanning and avoid jamming\
    \ in city streets. These services can enhance vehicular safety\nand make possible\
    \ self-driving cars. Furthermore, parking services and smart trafﬁc light\ncontrols\
    \ are provided. Smart energy services [10] (e.g., intelligent energy management\n\
    and energy consumption prediction) are used to sustain smart grids and smart buildings.\n\
    These services can also offer improved utilization of renewable energy. Additional\
    \ smart\nservices are engaged in real-time monitoring of bridges, tunnels, water\
    \ networks, train and\nsubway rails, and gas and oil pipelines. Structural health\
    \ monitoring is also feasible using\nsmart services [11]. Last but not least,\
    \ there are smart services that focus on monitoring the\nenvironment, public safety,\
    \ and security of citizens [12].\nAll these smart city services necessitate a\
    \ reliable networking infrastructure to efﬁ-\nciently exchange messages between\
    \ the modules of a smart city system implementing a\nparticular smart service.\
    \ In particular, smart city services need a variety of networking and\ncommunication\
    \ technologies for their completion because they are proposed for dissim-\nilar\
    \ scales. For example, smart services for smart buildings must be implemented\
    \ based\non Zigbee (IEEE 802.15.4) or Bluetooth (IEEE 802.15.1) network protocols.\
    \ On the other\nhand, smart services for the smart grid must be mainly implemented\
    \ using the WiMAX\n(IEEE 802.16) network protocol. From another viewpoint, smart\
    \ city services can exploit\ndissimilar network and communication models and solutions.\n\
    Until now, the networking and communication components of smart city systems have\n\
    received little research attention. To the best of our knowledge, a comprehensive\
    \ survey\nof network architectures and protocols for IoT applications in smart\
    \ cities does not exist\nand is the goal of this study. The communication and\
    \ networking issues involved in smart\ncity systems are examined in this study.\
    \ This paper considers networking technologies,\ntopologies, and communication\
    \ requirements for such systems. It also examines if current\nnetwork protocols\
    \ are appropriate for certain smart city services. This paper surveys recent\n\
    developments in networking architectures to support SCAs. As this is an active\
    \ area, this\npaper is important to support new research in this ﬁeld. The paper\
    \ contributes as follows:\n1.\nIt presents network requirements of the major SCAs\
    \ including intelligent transporta-\ntion, smart buildings, pipeline monitoring\
    \ and control, smart water networks, smart\ngrids, and manufacturing control and\
    \ monitoring.\n2.\nIt reviews networking architectures used for the above applications\
    \ focusing mainly\non the protocols’ suitability.\nThe remainder of this paper\
    \ is structured as follows: Section 2 describes SCAs;\nSection 3 presents network\
    \ requirements and protocols used for important SCAs;\nSections 4 and 5 analyze\
    \ protocols and network architectures for smart grids, smart build-\nings, smart\
    \ water and pipeline network monitoring, and smart transportation; Section 6\n\
    summarizes the paper, while Section 7 provides open research directions; lastly,\
    \ Section 8\nconcludes the paper. Figure 1 provides the layout of the survey.\n\
    Electronics 2023, 12, 2490\n3 of 63\nElectronics 2023, 12, x FOR PEER REVIEW \n\
    3 of 65 \n \n \n \nFigure 1. The layout of the survey paper. \nSystematic Literature\
    \ Review \nArticle Selection Method: We provide a Systematic Literature Review\
    \ (SLR) meth-\nodology [13] with particular notice to studies related to networking\
    \ architectures or \nprotocols for IoT applications in smart cities. The SLR was\
    \ employed to systematically \nstudy networking architectures and protocols for\
    \ IoT applications in smart cities. We \nproposed a research question to cope\
    \ with the key issues of networking architectures and \nprotocols for IoT applications\
    \ in smart cities. \nQuestion Formalization: Key issues and challenges in the\
    \ field were identified. Such \nissues were network architectures for IoT, network\
    \ protocols for IoT, IoT applications for \nsmart cities, and smart city applications.\
    \ This study answers the next research question: \nRQ: What is the emphasis of\
    \ networking architectures or protocols for IoT applica-\ntions in smart cities?\
    \ \nThis question determines the number of studies focusing on network architectures\
    \ \nand protocols for IoT applications for smart cities that have been published\
    \ to date to \nemphasize its significance in smart cities. \nArticle Selection\
    \ Process: The article selection process is performed in three stages: \n1. \n\
    Automated keyword-based search; \n2. \nSelection of the article based on the title,\
    \ abstract, and quality of the publication; \nFigure 1. The layout of the survey\
    \ paper.\nSystematic Literature Review\nArticle Selection Method:\nWe provide\
    \ a Systematic Literature Review (SLR)\nmethodology [13] with particular notice\
    \ to studies related to networking architectures\nor protocols for IoT applications\
    \ in smart cities. The SLR was employed to systematically\nstudy networking architectures\
    \ and protocols for IoT applications in smart cities. We\nproposed a research\
    \ question to cope with the key issues of networking architectures and\nprotocols\
    \ for IoT applications in smart cities.\nQuestion Formalization: Key issues and\
    \ challenges in the ﬁeld were identiﬁed. Such\nissues were network architectures\
    \ for IoT, network protocols for IoT, IoT applications for\nsmart cities, and\
    \ smart city applications. This study answers the next research question:\nRQ:\
    \ What is the emphasis of networking architectures or protocols for IoT applications\n\
    in smart cities?\nThis question determines the number of studies focusing on network\
    \ architectures and\nprotocols for IoT applications for smart cities that have\
    \ been published to date to emphasize\nits signiﬁcance in smart cities.\nArticle\
    \ Selection Process: The article selection process is performed in three stages:\n\
    1.\nAutomated keyword-based search;\n2.\nSelection of the article based on the\
    \ title, abstract, and quality of the publication;\n3.\nElimination of inappropriate\
    \ articles.\nElectronics 2023, 12, 2490\n4 of 63\nIn the ﬁrst stage, the search\
    \ process is automatically performed using searching on\npopular academic databases\
    \ such as IEEE explorer, ACM, Wiley, Springer, Science Direct,\nSAGE, and Google\
    \ Scholar. The following search string was deﬁned by adding other\nspellings of\
    \ the main elements to ﬁnd relevant articles. The search string was as follows:\n\
    (“IoT” OR “Internet of Things”) AND (“network architecture” OR “network pro-\n\
    tocol” AND “smart cities” OR “smart rural” OR “smart village” OR “smart trafﬁc”\
    \ OR\n“smart transportation” OR “smart street lights” OR “smart energy” OR “smart\
    \ grid” OR\n“smart buildings” OR “smart home” OR “smart residence” OR “home automation”\
    \ OR\n“smart water” or “smart waste management” OR “smart healthcare” OR “smart\
    \ rural”\nAND “Cloud Computing” OR “edge computing” OR “software-deﬁned networking”\
    \ OR\n“Artiﬁcial Intelligence”).\nWe found 264 articles from journals, conference\
    \ proceedings, books, and patents.\nThese articles were published between 2013\
    \ and 2023. In the article selection based on the\nquality of the publisher stage,\
    \ the search string was constrained by searching for conference\npapers and journal\
    \ articles of IEEE, ACM, Sage, Wiley, Science Direct, and Springer, in\norder\
    \ to guarantee that only high-quality publications and articles were selected\
    \ for the\nreview. Consequently, 240 articles were selected.\nIn the third stage\
    \ of eliminating the inappropriate articles, a Quality Assessment\nChecklist (QAC)\
    \ based on [13] was developed, wherein those articles emerging from the\ninitial\
    \ search were reﬁned. After reading the abstracts, we eliminated the unrelated\
    \ articles.\nThe entire body of the remaining papers was checked, and those which\
    \ were not related to\nour concerned ﬁeld were also crossed out. After eliminating\
    \ inappropriate articles, only\n226 studies were identiﬁed.\n2. Smart City Applications\n\
    This section discusses the main SCAs used in diverse domains. To understand what\n\
    type of assistance is needed by the networking infrastructures offered for SCAs,\
    \ their\nadvantages and design problems were addressed.\nIn the energy sector,\
    \ SCAs are being used to increase the reliability, efﬁciency, and\nsustainability\
    \ of electric energy generation and distribution in smart grids [14]. A smart\
    \ grid\nis a new power grid system that automatically collects and reacts to available\
    \ information\nabout supplier and consumer behavior. Smart grids use CPS to supply\
    \ self-monitoring and\nsuperior control mechanisms for power generation and consumer\
    \ demand, improving grid\nreliability and efﬁciency. CPS systems are also used\
    \ to manage the process of producing\nrenewable energy from wind turbines [15].\n\
    Certain applications are utilized in smart buildings to monitor and manage energy\n\
    consumption [16]. CPS controls the equipment in the buildings, including the Heating,\n\
    Ventilation, and Air-Conditioning (HVAC) systems; appliances; and lighting systems.\n\
    Different kinds of sensor nodes, which keep track of the current state of the\
    \ environment\nand energy consumption, are typically included in smart building\
    \ systems. A centralized\nmonitoring and control system receives observations\
    \ and measurements from these sensors.\nBased on reported observations, current\
    \ operational circumstances, and environmental\nfactors, the control system employs\
    \ intelligent algorithms to manage the sub-systems\nemployed in the buildings\
    \ to optimize energy consumption.\nIntelligent transportation is another SCA that\
    \ has attracted a lot of interest in the\ntransportation sector. Applications\
    \ related to vehicle safety are among the most crucial\ntypes of such applications.\
    \ Vehicles can be equipped with a variety of safety features,\nsuch as blind spot\
    \ monitoring, emergency braking, collision avoidance systems, and lane\nchange\
    \ warning signs. To improve driving safety, these applications offer full or semi-\n\
    automatic operations. Real-time and reliability support in detection and response\
    \ are these\napplications’ most crucial characteristics. Applications for enhancing\
    \ vehicle safety must\nbe dependable and able to operate in real-time in all aspects\
    \ such as threat observations,\ndecision making, communication, and actions. However,\
    \ the software cannot handle\nhigh levels of incorporation across all the relevant\
    \ devices and guarantee real-time and\nElectronics 2023, 12, 2490\n5 of 63\ntrustworthy\
    \ replies. Furthermore, self-driving vehicles are regarded as crucial SCAs [17].\n\
    They combine all the aforementioned capabilities with vision and monitoring equipment\n\
    to provide the vehicle the ability to traverse the roads using sensed data and\
    \ intelligent\nsoftware that evaluates and reacts to these data in real-time.\
    \ Intelligent trafﬁc light controls,\nwhich incorporate device monitoring across\
    \ numerous locations to precisely forecast trafﬁc\npatterns, are another application\
    \ of intelligent transportation. The authors of [18] present\nan example of intelligent\
    \ trafﬁc lights.\nWater networks are maintained using smart city technology to\
    \ increase their intelli-\ngence, efﬁciency, dependability, and sustainability.\
    \ CPS systems are integrated into water\nnetworks to add smart characteristics\
    \ to the processes of water distribution [19]. Offering\nearly warning systems\
    \ to identify problems in water networks is one of these duties. For\ninstance,\
    \ it is simple to identify leaks and pipe bursts. Quick, temporary ﬁxes can be\n\
    implemented to prevent water wastage and future network threats or damage [20].\n\
    WSN-based monitoring of greenhouses is another SCA. Such monitoring provides\n\
    well-organized control for appropriate soil, climate, lighting, and water level\
    \ in green-\nhouses [21]. Other smart city systems are deployed in the industry\
    \ to automate, control,\nmonitor, and improve manufacturing procedures [22,23].\
    \ Finally, smart-healthcare systems\nbased on edge computing [24] are proposed\
    \ to monitor and examine the physical health of\nusers [25].\nFigure 2 shows some\
    \ important applications including smart trafﬁc surveillance\nand management,\
    \ smart healthcare, weather and air quality monitoring, smart waste\nmanagement,\
    \ smart street lighting, smart emergency response system, and smart home.\n \n\
    observations, decision making, communication, and actions. However, the software\
    \ \ncannot handle high levels of incorporation across all the relevant devices\
    \ and guarantee \nreal-time and trustworthy replies. Furthermore, self-driving\
    \ vehicles are regarded as \ncrucial SCAs [17]. They combine all the aforementioned\
    \ capabilities with vision and \nmonitoring equipment to provide the vehicle the\
    \ ability to traverse the roads using \nsensed data and intelligent software that\
    \ evaluates and reacts to these data in real-time. \nIntelligent traffic light\
    \ controls, which incorporate device monitoring across numerous \nlocations to\
    \ precisely forecast traffic patterns, are another application of intelligent\
    \ \ntransportation. The authors of [18] present an example of intelligent traffic\
    \ lights. \nWater networks are maintained using smart city technology to increase\
    \ their intel-\nligence, efficiency, dependability, and sustainability. CPS systems\
    \ are integrated into \nwater networks to add smart characteristics to the processes\
    \ of water distribution [19]. \nOffering early warning systems to identify problems\
    \ in water networks is one of these \nduties. For instance, it is simple to identify\
    \ leaks and pipe bursts. Quick, temporary fixes \ncan be implemented to prevent\
    \ water wastage and future network threats or damage \n[20]. \nWSN-based monitoring\
    \ of greenhouses is another SCA. Such monitoring provides \nwell-organized control\
    \ for appropriate soil, climate, lighting, and water level in green-\nhouses [21].\
    \ Other smart city systems are deployed in the industry to automate, control,\
    \ \nmonitor, and improve manufacturing procedures [22,23]. Finally, smart-healthcare\
    \ sys-\ntems based on edge computing [24] are proposed to monitor and examine\
    \ the physical \nhealth of users [25]. \nFigure 2 shows some important applications\
    \ including smart traffic surveillance and \nmanagement, smart healthcare, weather\
    \ and air quality monitoring, smart waste man-\nagement, smart street lighting,\
    \ smart emergency response system, and smart home. \n \nFigure 2. Facilitating\
    \ networking and communication amongst SCAs.\nElectronics 2023, 12, 2490\n6 of\
    \ 63\nAnalysis of Smart City Applications/Systems\nThis subsection analyses the\
    \ SCAs shown in Figure 2.\nSmart Trafﬁc Surveillance Systems: These systems are\
    \ based on centralized pro-\ncesses and may fail due to networking problems. Thus,\
    \ to automate such an innova-\ntive system, centralized and distributed methods\
    \ must be used to maintain local servers.\nJavaid et al. [26] suggested a smart\
    \ trafﬁc management system using a mixture of central-\nized and decentralized\
    \ processes to optimize the ﬂow of vehicles on roads and an algorithm\nto manage\
    \ a variety of trafﬁc conditions efﬁciently. In the context of smart cities, effec-\n\
    tive trafﬁc management implies that a decision-making model identiﬁes and quantiﬁes\n\
    trafﬁc congestion as well as predicts trafﬁc patterns. Afrin and Yodo [27] offered\
    \ a theoreti-\ncal analysis that takes into account such effective trafﬁc management.\
    \ Notably, existing\ndecision-making models are primarily devoted to urban and\
    \ highway trafﬁc management,\nnot considering the closed campuses and collector\
    \ roads scenarios. Sarrab et al. [28] iden-\ntiﬁed this weakness and proposed\
    \ an IoT-based system model that collects, processes,\nand stores real-time trafﬁc\
    \ data for such an unusual scenario. In an IoT-based trafﬁc man-\nagement system,\
    \ various challenges emerge. These challenges include security issues,\nextremely\
    \ sophisticated networking equipment, network overhead, required adjustments,\n\
    and speciﬁc information ﬁelds in the protocol header and structure, as well as\
    \ higher costs.\nSmart Healthcare Systems: For real-time monitoring of health\
    \ parameters, these sys-\ntems are progressively being associated with and connected\
    \ via the Internet to numerous\ntypes of available smart wearable sensing and\
    \ computing devices. These systems face\nseveral problems [29] that must be resolved.\
    \ A security/privacy perspective, inter-realm au-\nthentication, interoperability\
    \ issues, device-to-device informal communication, and collec-\ntion and management\
    \ of medical data are among the issues on this list. Alromaihi et al. [30]\naddressed\
    \ issues related to cyber-security while using IoT for such applications. They\n\
    sought to examine secure techniques’ deployment and implementation from the perspec-\n\
    tive of preventing and reducing cyber-attacks on IoT devices. Some crucial surveys\
    \ and\nreviews [31,32] on smart healthcare applications tackle the problem of\
    \ integrating IoT\nsystems with any healthcare application particularly.\nWeather\
    \ and Air Quality Monitoring Systems: These systems use environmental\nmonitoring\
    \ stations, which are extremely pricey to acquire and maintain. For example,\n\
    these stations require engineers with specialized skill sets and data analysts.\
    \ Therefore, it is\nimpractical to deploy such monitoring stations densely. Instead,\
    \ they are often deployed\nsparsely, which creates the problem of limited spatial\
    \ resolutions for useful measurements.\nLately, cheap monitoring sensors have\
    \ evolved in the market, signiﬁcantly assisting in\nreﬁning the granularity of\
    \ monitoring [33]. Highlighting the same problem, the authors [33]\nemphasized\
    \ the drawbacks of these inexpensive sensors (particularly with air quality\n\
    monitoring sensors). For instance, these sensors frequently struggle with the\
    \ issue of\ncross-compassions in the presence of multiple ambient pollutants.\
    \ Moreover, these sensors\nare extremely susceptible to unexpected variations\
    \ in humidity, temperature, and wind\ndirection, and as a result, their accuracy\
    \ deteriorates with time. A recalibration routine\nmight be a way to maintain\
    \ and enhance such accuracy. However, because it would take\na lot more time and\
    \ work, this technique is highly improbable and would not work for\nlarge-scale\
    \ deployments. In a weather monitoring system, the monitoring is highly complex\n\
    and involves three steps [34]:\n(1)\nObserving: It can be performed by monitoring\
    \ satellite imagery, precipitation reports,\nsurface data, and gathering data\
    \ from other nearby forecasters.\n(2)\nForecasting: It can be performed by forecasters\
    \ as short-term and long-term forecasting.\nShort-term forecasting is carried\
    \ out by evaluating the current weather conditions\nand projecting them over the\
    \ next few hours using knowledge of the mechanics\nof the weather. Long-term forecasting,\
    \ however, is possible through weather (nu-\nmerical) modeling and the projection\
    \ of such modeling using computer simulations.\nTo produce these simulations for\
    \ future forecasting, these modeling techniques use\nenvironmental data from satellite\
    \ photography, weather balloons, and surface ob-\nElectronics 2023, 12, 2490\n\
    7 of 63\nservations. Following completion of the forecasting, the forecasters\
    \ translate the\nproduced simulated expected output into a perceptible format\
    \ for non-specialists so\nthat they can respond appropriately.\n(3)\nCommunicating:\
    \ Finally, they communicate such output or forecasted information to\nappropriate\
    \ authorities.\nDespite the fact that all of these computer models are used to\
    \ forecast the weather, the\nsuccess of each one is largely inﬂuenced by three\
    \ different elements: (a) the quantity of\nprecise data; (b) the length of time\
    \ needed to analyze that data; and (c) the complexity of\ndynamic atmospheric\
    \ weather events. A large part of collecting accurate data for a region\nis the\
    \ placement of weather stations. They may occasionally be stationed distant from\
    \ rural\nareas in a city area. Because of this, they are unable to gather enough\
    \ information for desert,\nsea, or even rural areas to supply the computer models\
    \ used to predict weather conditions\naccurately. Forecasters also use satellite\
    \ data to combat this issue. However, because\nof cloud cover and signiﬁcant changes\
    \ in the amount of water vapor in the atmosphere,\nsatellite data accuracy can\
    \ occasionally be unreliable. Moreover, the topographic image and\nmap information\
    \ or surface/land features change substantially in a shorter area. Hence,\nit\
    \ further impacts temperature and precipitation values signiﬁcantly. This further\
    \ makes\nthings harder for a computer model to predict accurately. Hence, there\
    \ is a need to re-\nevaluate and re-modify such models’ mathematical equations\
    \ so that they can predict the\nchanges more accurately.\nSmart Waste Management\
    \ Systems: Automated smart waste management is crucial for\nthe following reasons:\
    \ (1) due to a lack of waste disposal infrastructure; (2) thin or delicate\nwaste\
    \ collection methods being required; (3) lack of effective waste logistics management;\n\
    (4) insufﬁcient use of cutting-edge trash treatment and recycling technologies;\
    \ and (5) lack\nof workers and specialists with the necessary technical and non-technical\
    \ skills to handle\ngarbage disposal and the associated infrastructures. Smart\
    \ waste management schemes\ninclude various steps such as (1) waste collection;\
    \ (2) differentiation of waste as per their\nbiological and physical properties;\
    \ (3) storage; (4) transportation of waste into garbage\ndisposal infrastructures/treatment\
    \ plants; and (5) waste treatment and disposal. Sosunova\nand Porras [35] identiﬁed\
    \ issues and challenges while collecting and analyzing data from\nsmart deployed\
    \ sensors on garbage bins. Their study investigated some operational issues\n\
    such as the management of waste vehicles and urban infrastructure and smartly\
    \ managing\nwaste vehicle routes.\nSmart Street Lighting Systems: This system\
    \ is a network-oriented solution that uses\nstreetlights ﬁtted with speciﬁc actuators\
    \ and sensors, implying a wide range of facilities\nand connectivity interfaces\
    \ [36]. The street lighting application (described in [37]) has a\nmechanism that\
    \ gathers or monitors environmental data and then evaluates street lighting\n\
    with the use of smart wireless nodes (ﬁtted out with numerous forms of sensors\
    \ and\nactuators). These smart nodes are mounted atop the towers that hold the\
    \ streetlights, and\nthey are connected to the Internet by way of a gateway device.\
    \ Zanella et al. [37] insist\nthat their system could assist in gathering environmental\
    \ parameters such as humidity, air\ntemperature, and CO level. Moreover, the authors\
    \ stated that optimizing street lighting\nefﬁciency is a paramount concern that\
    \ must be addressed. This monitoring system makes\nit possible to maximize efﬁciency\
    \ since it allows for the adjustment of streetlamp intensity\nin response to the\
    \ time of day, the presence of people, and the weather. Although this\nsystem\
    \ is simple and built on the IoT concept, it will inevitably contain crucial concerns\
    \ that\nrequire particular attention, such as complicated networking solutions\
    \ and communication\namong heterogeneous devices. However, selecting the right\
    \ light lamp is critical for a\npower-efﬁcient lighting mechanism. Their selection\
    \ is based on how effective they are in\nterms of power usage and lifespan. The\
    \ existing metropolitan system relies on Metal Halide\n(MH) or High-Pressure Sodium\
    \ (HPS) bulbs. Unlike LEDs, these bulbs are frequently seen\nas being inefﬁcient\
    \ in terms of power consumption and requiring signiﬁcant maintenance,\nwhich adds\
    \ signiﬁcantly to the cost. In addition, the system should be designed following\n\
    the advised design standards (it must adhere to the current standard CEN/TR 13201)\
    \ [36].\nElectronics 2023, 12, 2490\n8 of 63\nCurrently, there are three kinds\
    \ of control systems for smart lighting systems in use:\ncentralized, decentralized,\
    \ and hybrid. Nevertheless, these systems are susceptible to a\nvariety of security\
    \ assaults. Moreover, not much effort has been made into this problem\nthus far.\n\
    Smart Emergency Response Systems: Such a system ensures the safety and security\
    \ of\nits residents. It can be utilized for crime detection and prevention, dealing\
    \ with natural\ncalamities and accidents, and law enforcement [38]. Data collection\
    \ is ﬁrst and foremost\nimportant for the designing portion of these applications.\
    \ Depending on the gathered\nfacts, the development of intelligence (which aids\
    \ in making important decisions) and the\nability to respond swiftly and quickly\
    \ are the issues that require special attention. When\nit comes to gathering data,\
    \ we can make use of CCTV cameras and sophisticated trafﬁc\nsensors. A developer\
    \ can create and put into action a crucial learning scheme that will\nconduct\
    \ predictive analysis and gather intelligence on top of the data gathered. Therefore,\n\
    this kind of predictive analysis has the potential to gather signiﬁcant information\
    \ that\nwill help the relevant authorities (e.g., the ﬁre safety department, the\
    \ police department,\nand law enforcement agencies) take the proper security and\
    \ preventive measures. The\nconcept of widespread surveillance has important beneﬁts\
    \ for security and safety. However,\nkeeping track of such vast amounts of data\
    \ also prompts a lot of worries and issues for\ndesigners and developers, including\
    \ storage; the effectiveness of learning algorithms; and,\nmost importantly, the\
    \ question of whether it is morally right or acceptable to keep track\nof each\
    \ individual (a privacy issue). In addition, a very important point is whether\
    \ this\nkind of widespread surveillance is feasible, especially for nations such\
    \ as China and India,\nwhere a city’s population can exceed that of a whole nation.\
    \ Further, Gharaibeh et al. [38]\nclaimed that combining information transmission\
    \ technologies with well-implemented\ndata analytics models is necessary for quick\
    \ and swift collaboration. To save as many lives\nas possible during natural disasters,\
    \ it is imperative to gather, assess, and communicate\nvital information to the\
    \ relevant authorities. As a result, there is currently a lot of work\nbeing done\
    \ to enhance the performance of information exchange systems. Although this\n\
    system is based on the IoT concept and is relatively simple, it faces important\
    \ problems\nthat need consideration, such as complex networking solutions and\
    \ information sharing\nacross heterogeneous devices on time (time-sensitive application).\n\
    Smart Residence/Home Automation: A smart home has highly developed systems\nsuch\
    \ as a control system for devices or objects (such as fans, lights, music systems,\
    \ TVs,\nand other smart appliances), automated door openers, smart appliances\
    \ that may send\nusers remote status updates, smart refrigerators, and washing\
    \ machines. A user can control\nthe majority of smart home appliances remotely\
    \ with two recently produced gadgets:\nGoogle Home and Amazon Echo. In a smart\
    \ home, the end-user demands a high-speed\ninternet connection, so they can access\
    \ networking sites that control the home with HD live\nstreaming services. In\
    \ contrast, a smart healthcare application needs safe connections to\ncomputing\
    \ servers in the cloud for managing sensitive private information. Hence, data\n\
    management systems must address a crucial issue, namely, the necessity to concentrate\n\
    on data distribution based on various end-user categories rather than just recommending\n\
    distinct data distribution among various end-user groups [38]. The concept of\
    \ smart home\nautomation raises serious concerns about security and privacy risks.\
    \ A smart home includes\nsecurity monitoring systems with motion sensors, wirelessly\
    \ opening smart door locks,\ntelevisions, phones, and other smart appliances that\
    \ are highly outﬁtted with cameras and\nmicrophones. Although these gadgets improve\
    \ the system, little research has been done on\ntheir privacy and security features.\
    \ If we conduct a thorough analysis of these gadgets, we\nwill discover that their\
    \ manufacturers offer either very few or no security features at all.\nIndeed,\
    \ Fernandes et al. [39] provided their eye-opening views after carefully examining\n\
    Samsung’s SmartThings framework (programming) and their SmartApps market. They\n\
    argued that more than 50%—exactly 55%—of these smart applications are already\
    \ more\nprivileged by default and as a result, do not need to access unrelated\
    \ applications. As a\nresult, hackers can use them with ease. Apart from this,\
    \ according to a published document\nElectronics 2023, 12, 2490\n9 of 63\nby WikiLeaks\
    \ [40], the Central Intelligence Agency (CIA) has all the tools to access, control,\n\
    and hack these smart home applications anywhere in the world. Furthermore, criminal\n\
    entities and hackers could seize control of smart personal devices, capture delicate\
    \ private\ninformation, and exploit that information immorally typically through\
    \ user tracking and\nproﬁling. Additionally, a hacker may break into one of these\
    \ smart applications, grab vital\ninformation, and then use it to launch any kind\
    \ of attack. For instance, based on motion\nsensors, security camera feeds, and\
    \ power usage patterns, a burglar can determine where\nand when to break into\
    \ the house. By locating the authentication credentials of authorized\nparties,\
    \ they can compromise smart door locks [41]. Better security-aware hardware and\n\
    software (as well as the related common standards) must be developed to safeguard\
    \ against\nall these attempts so that high-tech appliances, sensors, actuators,\
    \ etc., are impervious to\nsuch security and privacy attacks.\nSmart Grid Networks:\
    \ The functionality of the traditional electricity grid is unidirec-\ntional (i.e.,\
    \ electricity is transmitted from electricity-producing sources to end-customers).\n\
    Electricity has been moving from power plants to users in a single direction thanks\
    \ to\nthe deployment of electricity grids. The existing grid system operates in\
    \ an open-loop\nfashion since there are not any adequate communication infrastructures\
    \ in the distribution\nsector. Moreover, the main distribution center has little\
    \ or no real-time knowledge of the\nsystem’s operating conditions and dynamically\
    \ changing load. There are also several tech-\nnical, economic, and environmental\
    \ problems with this conventional approach. Therefore,\nthis conventional system\
    \ must become dependable, manageable, and scalable, as well as\nﬂexible, secure,\
    \ and interoperable [42].\nThe smart grid is the next invention of the Electric\
    \ Power System (EPS) that incor-\nporates quicker, more secure, and reliable communication\
    \ networks [43]. Smart grids\nsupplement the conventional electricity grid by\
    \ incorporating renewable energy sources\nsuch as biomass, solar energy, and wind\
    \ energy. These energy sources are much cleaner\nand more ecologically friendly\
    \ than non-renewable energy sources such as fossil fuels.\nHowever, it is important\
    \ to identify the most suitable communication technology for the\nsmart grid’s\
    \ successful implementation and deployment. The smart grid’s overall commu-\n\
    nication style is unique compared with conventional network communication patterns.\
    \ The\ncommunication network architecture of the smart grid must be able to handle\
    \ information\nexchange between sensors, actuators, smart electronic devices,\
    \ and numerous smart meters\nin such a particular environment with little to no\
    \ human intervention. This type of com-\nmunication, called Device-to-Device (D2D)\
    \ communication, is autonomous and may be\ninitiated in response to an event or\
    \ at regular intervals. Notably, depending on how these\nsmart grid applications\
    \ were built, their QoS requirements and characteristics differ greatly\nin terms\
    \ of delay, burst size, and packet arrival rate. For example, the latency requirement\n\
    of a smart meter event and a substation event are quite different [44]. In intelligent\
    \ grid\nnetworks, the monitoring, managing, and controlling functions inside the\
    \ same network\npresent the issues of ﬂexible QoS differentiation. Moreover, applications\
    \ based on the smart\ngrid can be developed and implemented using the current\
    \ wireless and wired networking\ninfrastructure and technologies. For some devices,\
    \ such as smart meters, designing and\nstandardizing acceptable smart grid-based\
    \ protocols is a critical matter [45]. Furthermore,\nthese smart grid-based networks\
    \ are too dependent on intelligent sensors, actuators, and\nother devices. This\
    \ makes them extremely vulnerable to attacks by malicious users. These\nsmart\
    \ grids could be taken over by malevolent users or hackers, who could then obtain\n\
    unauthorized access to many smart meters and alter crucial data. Moreover, as\
    \ the existing\nelectricity system is insufﬁcient for establishing smart grid\
    \ systems, high-level adjustments\nto current power infrastructure scenarios are\
    \ required. Subsequently, these smart systems\nrequire high installation costs\
    \ because the installation requires a large number of smart\nmeters, sensors,\
    \ and actuators for sensing and data collection [46]. The efﬁcient operation of\n\
    such a smart grid system also necessitates a dependable, consistent, and error-free\
    \ network\nchannel. Therefore, it will be challenging for developers of such intelligent\
    \ applications.\nElectronics 2023, 12, 2490\n10 of 63\nMany surveys [42–45,47]\
    \ reviewed communication frameworks for smart grids, smart-\ngrid-based networking\
    \ technologies, trafﬁc management, and the requirements of numer-\nous smart grid\
    \ applications. Further, Kansal and Bose [48] presented their insights on\ntransmission\
    \ grid applications regarding their latency and bandwidth requirements.\n3. Network\
    \ Requirements for SCAs\nThis section considers several communication requirements\
    \ including reliability, delay\ntolerance, bandwidth, power consumption, security,\
    \ network type, heterogeneous network\nsupport, and mobility support. It also\
    \ studies the aptness of different network protocols for\ndissimilar SCAs.\nSmart\
    \ city services and applications need robust and dependable communication\nsupport\
    \ as well as an effective networking infrastructure, which will permit competent\n\
    message-sharing procedures among the components of the smart city systems [49].\
    \ Every\nsmart city system has an intricate networking architecture made up of\
    \ various networking\ncomponents. Therefore, smart city systems are innately required\
    \ to have a variety of net-\nworking requirements. To access the far-off destination,\
    \ which may be clouds, the network\ntrafﬁc from a broad variety of deployed diverse\
    \ applications uses a common networking\narchitecture and resources. These resources\
    \ may consist of switches, routers, communica-\ntion connections (links), and\
    \ other forms of network middle-boxes. The idea of accessing\nfaraway clouds or\
    \ far-off destinations or remotely distributed apps consequently brings\nup problems\
    \ with high packet loss probability, signiﬁcant delay, and constrained network\n\
    bandwidth. In addition, security is a serious issue that must be considered when\
    \ develop-\ning, implementing, and deploying intelligent applications for smart\
    \ cities. Otherwise, users\nwould be reluctant to approve the use of such applications\
    \ in the absence of adequate secu-\nrity safeguards. Such intelligent applications\
    \ need a high-speed networking environment\nwhere the quick reaction may be managed\
    \ with the support of the ability of a fast-processing\nspeed. Furthermore, a\
    \ variety of apps can be implemented in the context of a smart city,\nbased on\
    \ their usefulness and relevance to the users. These applications, however, have\n\
    different networking requirements, particularly in terms of response and security\
    \ [50]. For\nexample, the networking requirements of smart emergency response\
    \ systems are quite\ndifferent compared to other applications such as smart healthcare\
    \ systems. Emergency\nresponse smart systems must be exceedingly secure and quick\
    \ to react [50]. In contrast,\nsmart-healthcare-based systems or apps do not necessarily\
    \ need to be especially dynamic.\n−\nNetwork Protocols: Monitoring applications\
    \ for smart cities often use a dense network\nof heterogeneous sensor nodes, including\
    \ ﬁxed sensor nodes, mobile sensor nodes,\nand crowd sensing nodes. Long-Term\
    \ Evolution (LTE) [51], LTE for Machines (LTE-M),\nextended coverage GSM IoT,\
    \ and ﬁfth-generation (5G) technologies [52] are intriguing\noptions to support\
    \ such heterogeneous networks. First, the bulk of crowd-sensing\nnodes (smartphones)\
    \ is already supported by LTE communications. Consequently, no\nfurther wireless\
    \ communication devices are required. To save energy, LTE and 5G can\nbe utilized\
    \ on the sink nodes (also known as cluster heads) to allow the data gathered\n\
    by the sink nodes to be transmitted to the monitoring center via base stations\
    \ (the\nbackbone network), as opposed to multihop relaying.\n−\nZigbee [53], WiFi,\
    \ and Bluetooth can still be used for the traditional stationary nodes\nto communicate\
    \ within clusters. This layout has the advantage of allowing the sensor\nnode\
    \ clusters to be separated from one another while maintaining network connectiv-\n\
    ity. Additionally, the moderate number of nodes in each cluster makes maintenance\n\
    simpler. In addition to supporting larger networks, LTE and 5G technologies also\
    \ make\npossible sensor nodes with faster data rates, improving the performance\
    \ of real-time\nmonitoring [54]. Applications for crowd sensing, for instance,\
    \ can accommodate video\nstreams taken by cameras on smartphones or moving vehicles.\
    \ The fast data rates\nprovided by LTE and 5G can potentially be advantageous\
    \ for the sink nodes or clusters.\nThe use of vibration data (accelerometer readings)\
    \ in structural health monitoring\napplications of bridges, tunnels, or towers\
    \ is fairly common. The cluster heads will be\nElectronics 2023, 12, 2490\n11\
    \ of 63\nable to send the vibration data in this situation in real time. In conclusion,\
    \ practically\nall applications for smart city monitoring that demand a high data\
    \ throughput and\nminimal delay may be satisﬁed by LTE and 5G. Additionally, there\
    \ are some new\nsensor node standards, such as IEEE 802.11ah [55], LoRaWAN [56],\
    \ and Narrowband-\nIoT (NB-IoT) [57]. These narrowband protocols offer numerous\
    \ advantages: greater\ncoverage, improved scalability, reduced energy usage, and\
    \ increased device longevity.\nResearchers have tested these standards in more\
    \ than a few applications, including\nstreet lighting, energy metering, and home\
    \ automation, even though some are still\nbeing discussed and revised. The new\
    \ narrowband communication standards enable\nthe sensor nodes to run more sustainably,\
    \ which is beneﬁcial for applications that\naim for long-term monitoring. In addition\
    \ to these protocols and standards, the FogC\narchitecture [58] aids in monitoring\
    \ smart cities. In such an architecture, the mobile\nusers (the potential crowd-sensing\
    \ providers) and the cloud are connected via fog\nservers. These fog servers are\
    \ WiFi access points or cellular base stations. Mobile users\nare more inclined\
    \ to participate in sensing since they may upload their crowd-sensing\nmeasurements\
    \ to the fog server in just one hop, signiﬁcantly decreasing the cost and\nenergy\
    \ usage compared to cellular networks. As a result, such an architecture can give\n\
    us better sensing coverage. Using the measurements from the mobile users and the\n\
    WSNs, the fog servers can perform some basic regional estimation based on the\
    \ FogC\narchitecture, such as the nearby trafﬁc conditions. The service latency\
    \ and response\ntime are then decreased because mobile users can access such estimates\
    \ directly from\nthe fog servers rather than from a remote cloud through a backbone\
    \ network. Lastly,\nusing the appropriate networking protocols for each SCA is\
    \ crucial to getting the\nbest possible trade-off between delay, energy use, and\
    \ cost. The networks may be\nhierarchical so that diverse roles and functions\
    \ can be assigned at various layers to\nincrease the networks’ dependability and\
    \ cost-effectiveness. As a result, certain nodes\nmay be able to transmit data\
    \ utilizing various protocols.\n−\nBandwidth requirements: Many video applications\
    \ in smart cities require high band-\nwidth [59]. In these applications, sensors\
    \ capture video from the physical environment.\nMoreover, video transmission is\
    \ more bandwidth-hungry than the conventional scalar\ndata trafﬁc in IoT. Examples\
    \ of these applications are intelligent multimedia surveil-\nlance systems for\
    \ home monitoring, multimedia-based industrial monitoring systems,\ntrafﬁc monitoring\
    \ systems for road safety, and remote multimedia-based monitoring\nof an environmental\
    \ system.\n−\nDelay Tolerance: Some SCAs, such as smart transportation, only tolerate\
    \ a small\namount of end-to-end delay. For example, to prevent imminent danger\
    \ to the ve-\nhicle or potentially fatal crashes, the data that are being relayed\
    \ must arrive within\nmicroseconds. Therefore, the control systems must react\
    \ in time. However, other\napplications have a higher tolerance for delays [49].\
    \ Such applications rely on data\nmonitoring and information gathering for upcoming\
    \ analysis.\n−\nPower Consumption: Another crucial need for applications is power\
    \ consumption.\nSmart grid systems and other applications with local high-energy\
    \ sources can tolerate\nprotocols with higher energy expenditure levels [45].\
    \ Other applications have medium\npower needs and require energy sources with\
    \ limited capacities. One example of such\nan application is intelligent transportation.\
    \ Other applications demand protocols with\nlow or very low energy consumption\
    \ characteristics since they have limited energy\nresources. Unmanned aerial vehicles\
    \ (UAVs), smart water networks, and pipeline\nmonitoring for gas and oil are a\
    \ few examples of such uses.\n−\nReliability: The majority of applications have\
    \ medium reliability requirements. A\ntypical example of such applications is\
    \ smart water networks. Some other applications\nhave high-reliability necessities\
    \ such as intelligent transportation and smart grids [49].\n−\nSecurity: The majority\
    \ of applications need medium to high security. Applications\nsuch as production\
    \ control and monitoring, for instance, need medium security, whilst\nElectronics\
    \ 2023, 12, 2490\n12 of 63\nothers, such as smart grids, need high security because\
    \ of the sensitivity of the data\nand the importance of the operations carried\
    \ out [50].\n−\nHeterogeneity of network protocols: The majority of smart city\
    \ systems use network-\ning protocols that link the system’s parts together. Intelligent\
    \ transportation and smart\nbuildings are two examples of such systems. These\
    \ protocols must coexist in such\nsituations without conﬂicting with one another.\
    \ To ensure seamless and effective\noperation, it is also necessary to correctly\
    \ map the control information in the head-\ners at the various networking stack\
    \ tiers used by the many heterogeneous protocols\nand networks.\n−\nWired/wireless\
    \ connectivity: The majority of SCAs that include wireless connectivity\nare UAVs\
    \ and monitoring of gas and oil pipelines. Others, including intelligent\ntransportation\
    \ and smart buildings, use wired and wireless connectivity [50]. In\nthese situations,\
    \ wired networking may be used for communication within a speciﬁc\nphysical system\
    \ (such as within a UAV), while wireless communication may be used\nto link the\
    \ physical system to other such systems that are comparable to it or to the\n\
    backbone and infrastructure networks.\n−\nMobility: Some systems, such as the\
    \ smart grid, pipeline monitoring for gas and oil,\nand smart water networks,\
    \ have low to medium mobility [50]. Other systems, such\nas UAVs and intelligent\
    \ transportation, are quite mobile. Medium- to high-mobility\nsmart city systems\
    \ can be connected if the networking protocols are reliable and\nadaptable to\
    \ node mobility without using up a large amount of bandwidth on control\nmessages\
    \ and related processing to react to changes in the network architecture.\nTable\
    \ 1 presents a qualitative comparison of the requirements of some SCAs. Each\n\
    SCA has its own transmission range and is sustained by a heterogeneous network\
    \ with\nlow, medium, or high trafﬁc rates and supporting high or low mobility\
    \ of devices. Each\nSCA is based on different protocols and requires different\
    \ bandwidth and latency tolerance.\nIn each SCA, the number of devices involved\
    \ differs.\nTable 1. Networking aspects and qualitative comparison of SCA requirements.\n\
    Smart City Ser-\nvices/Applications\nSeemingly Fitted\nNetwork Proto-\ncol/Technology/Standard\n\
    Transmission\nRange (Meters)\nBandwidth\nRequirement\n(Minimum)\nLatency\nTolerance\n\
    Number of\nDevices\nNetwork\nMobility\nSupport\nTrafﬁc Rate\nSmart Trafﬁc\nSurveillance\n\
    Cellular, IEEE 802.11,\nIEEE 802.16, IEEE\n802.15.4\n≈1000\nM\nM\n≈1000\nHeterogeneous\n\
    H\nL\nSmart\nHealthcare\nSystem\nCellular, IEEE 802.11,\nIEEE 802.16, IEEE\n802.15.4,\n\
    IEEE 802.15.6, IEEE\n802.15.4j\n≈1000\nM\nM\n≈1000\nHeterogeneous\nL\nL\nWeather\
    \ and Air\nQuality\nMonitoring\nSystem\nCellular, IEEE 802.11,\nIEEE 802.16, IEEE\n\
    802.15.4\n≈1000\nL/M\nM\n≈1000\nHeterogeneous\nL\nL\nSmart Waste\nManagement\n\
    IEEE 802.11, IEEE\n802.16,\nIEEE 802.15.4\n≈100\nL/M\nH\n≈1000\nHeterogeneous\n\
    L\nL\nSmart Street\nLighting System\nIEEE 802.16\nIEEE 802.15.4\n≈10\nM\nH\n≈100\n\
    Heterogeneous\nL\nL\nSmart\nEmergency\nResponse System\nCellular, IEEE 802.16,\n\
    IEEE 802.15.4\n≈1000\nH\nL\n≈1000\nHeterogeneous\nH\nH\nSmart\nResidence/\nHome\n\
    Automation\nIEEE 802.15.4, IEEE\n802.15.1\n≈100\nM/H\nL\n≈10\nHeterogeneous\n\
    L\nM/H\nSmart Grid\nNetworks\nCellular, IEEE 802.16\n≈100\nL\nM/H\n≈100\nHeterogeneous\n\
    L\nM/H\nIEEE 802.11: WiFi; IEEE 802.16: WiMAX; IEEE 802.15.1: Bluetooth; IEEE\
    \ 802.15.4: Zigbee; IEEE 802.15.4j: Medical\nBody Area Network (M-BAN); IEEE 802.15.6:\
    \ Body Area Network (BAN); Cellular: CDMA, GSM, UMTS; L: low;\nM: medium; H: high.\n\
    Electronics 2023, 12, 2490\n13 of 63\n3.1. Additional Challenges\n−\nInteroperability:\
    \ Smart city systems are built on several heterogeneous networking\nprotocols\
    \ that use various media access control (MAC) mechanisms at the physi-\ncal and\
    \ data link layers. For the underlying technologies to be integrated seam-\nlessly,\
    \ these protocols must be interoperable [60]. In digital home networks, the IEEE\n\
    1905.1 protocol [61], which was created to offer a convergent interface between\
    \ physi-\ncal/data link layers and the network layer, is aimed to perform this\
    \ function. Future\nresearch should focus on the creation of similar protocols\
    \ to increase the support\nsystem for smart city systems.\n−\nScalability: A smart\
    \ city platform must manage many devices that are connected to\nthe city’s infrastructure.\
    \ Large amounts of city-related data, which are continuously\nproduced and consumed\
    \ by devices and client applications, must be stored and\nprocessed. The platform\
    \ must simultaneously be able to handle hundreds of requests\nfrom users and services\
    \ that rely on it. Thus, the scalability requirements change\ndepending on the\
    \ features of the city as well as the installed applications and services.\nRecently,\
    \ Del Esponte et al. [62] suggested InterSCity, a microservices-based, open-\n\
    source smart city platform that facilitates the collaborative development of large-scale\n\
    systems, apps, and services for smart cities.\n−\nLoad Balancing: To maximize\
    \ the usage of resources, load balancing assigns appro-\npriate resources (i.e.,\
    \ network resources, storage capacity, computational resources,\nand energy resources)\
    \ to user tasks. A large-scale IoT network performs better and\navoids overload\
    \ thanks to an effective load-balancing strategy [63]. Response time,\ncost, throughput,\
    \ performance, and resource usage are all improved in terms of\nQoS parameters.\n\
    −\nThe Cloud/Edge/FogC Paradigms: Cloud, Edge, and FogC facilitate the creation\
    \ of\nsmart city prototypes. These computing paradigms efﬁciently aid in the gathering,\n\
    upkeep, and analysis of city data to pinpoint crucial city-related events that\
    \ demand\nadvanced processing and response [64]. Nonetheless, some IoT applications/systems\n\
    for smart cities have strict processing and delay constraints. These real-time\
    \ applica-\ntions present the greatest obstacles to cloud-based services. Consequently,\
    \ FogC and\nEdge Computing have emerged as viable computing paradigms for designing,\
    \ imple-\nmenting, deploying, and controlling such systems/applications. These\
    \ paradigms\nbring computing resources closer to the IoT/device plane so that\
    \ the primary computa-\ntion can be done locally [65,66]. Each computing paradigm\
    \ offers particular assistance\nbased on the requirements of the application at\
    \ hand. For example, to support a cloud-\nbased SCA, ClCom offers centralized\
    \ storage and processing capacity. For certain\nSCAs, ClCom can offer scalable\
    \ processing power and data storage [5]. The features of\nClCom (e.g., powerful\
    \ processing, massive and scalable data storage, and cutting-edge\nsoftware services)\
    \ can be used to provide various support services for a variety of\nSCAs. ClCom\
    \ can be the primary control and management platform for SCAs. The\ncity’s ClCom\
    \ services can be used to connect various sensors and actuators for SCAs\nto gather,\
    \ process, store, and manage sensor data for various SCAs. Vast volumes\nof data\
    \ are gathered across a smart city, which can eventually become big data. The\n\
    sophisticated platforms required for storing and analyzing this massive amount\
    \ of\ndata to improve operations and planning can be provided by Cloud Computing.\
    \ To\neffectively support SCAs, the communication between city sensors and actuators\
    \ and\nClCom may involve various communication requirements. The network architectures\n\
    used in the smart city should meet these requirements. Smart applications require\n\
    the integration of sensors, actuators, and the cloud, and they can only function\
    \ well\nwith a robust network that offers good communication services linking\
    \ both sides.\nThe fact that cloud services are either provided at a single central\
    \ location or across\nnumerous distributed platforms in various locations is another\
    \ problem that occurs\nwhen adopting ClCom for a smart city. For many cloud applications,\
    \ the distributed\nClCom strategy can offer greater quality and dependability\
    \ support [67]. However,\nElectronics 2023, 12, 2490\n14 of 63\nit is frequently\
    \ necessary to establish effective communication channels between the\ndistributed\
    \ ClCom facilities that are present in various locations. The dependability\n\
    and efﬁciency of the networks linking all components on both sides present another\n\
    problem when using the cloud. There are issues with delays, dropped packets, and\n\
    unstable connections when the Internet is involved. To consider these challenges,\n\
    the SCA architecture must be carefully studied, as must the planning and control\
    \ of\nnetwork resources and communication models. However, some elements cannot\
    \ be\navoided, such as transmission delays. Ksentini et al. [68] investigated\
    \ the QoS require-\nments of many IoT/cloud-enabled applications in a FogC environment\
    \ to recognize\nQoS metrics. The authors introduced a QoS management model (QoS-Fog)\
    \ that is\ninspired by the work of the OpenFog consortium on the reference architecture\
    \ [69] for\na FogC system.\n3.2. Features and Challenges of Smart City Networks\n\
    A smart city network has the following features [70]:\n1.\nLarge Densities: A\
    \ smart city network has a very large density as thousands of smart\ndevices are\
    \ distributed in the area of a city.\n2.\nAbnormal Trafﬁc Patterns: Cascading\
    \ or synchronization among smart devices produces\nextremely bursty or correlated\
    \ trafﬁc patterns. These trafﬁc patterns differ from\nthe regular social-generated\
    \ trafﬁc patterns on which most existing schemes and\ntechnology used in our society\
    \ are based.\n3.\nDisorganized Network Topology: Unlike the widely used wireless\
    \ connectivity features,\nsmart city networks often adhere to a mesh network topology.\
    \ The problem arises\nwhen smart devices communicate across unreliable wireless\
    \ channels, where packet\nlosses caused by wireless channel special properties\
    \ are extremely common and even-\ntually have an impact on the functioning of\
    \ the smart city system. Therefore, it appears\nvery improbable that a single\
    \ high-throughput backbone can be deployable soon.\n4.\nHeterogeneity: SCAs use\
    \ a variety of technologies. In terms of power consumption,\nlatency, throughput,\
    \ and communication ranges, each of these technologies operates\nat a unique trade-off\
    \ threshold. The involved dissimilar technologies must coexist on\na single platform.\n\
    5.\nCoexistence of heterogeneous technologies: Communication technologies used\
    \ in smart\ncities are distributed over the same radio space. At the same time,\
    \ independent radio\ninfrastructures are connected through a variety of wireless\
    \ channels. Under such\ncircumstances, the SCA must handle interference issues\
    \ with competence.\n6.\nSecurity and Privacy: SCAs are extremely vulnerable to\
    \ several risks from malevolent\nusers. The majority of specialized smart sensors,\
    \ actuators, and other intelligent\ndevices are developed by designers without\
    \ considering security measures. Such\napplications may be highly vulnerable due\
    \ to hostile actors’ ease of access to these\ncutting-edge technologies and potential\
    \ threats to people’s security and privacy.\nThe main challenges for smart city\
    \ networks are as follows [70]:\n•\nLack of Standardization Solutions: The IEEE\
    \ 802.15.1 Bluetooth technologies for Personal\nArea Networks (PANs) and the IEEE\
    \ 802.11 groups for wireless LANs adopt the\nconcept of single-hop ad-hoc networking.\
    \ These standards permit direct communi-\ncation between two devices that are\
    \ in the transmission range of each other. At the\nsame time, the multi-hop ad-hoc\
    \ networking paradigm enables the communication\nbetween any two devices which\
    \ are not necessarily in their transmission range [71]. A\nproblem that researchers\
    \ must consider is how these intricate heterogeneous sets of\ndevices (i.e., actuators,\
    \ sensors, and other smart devices) can communicate uniformly\nwithout any standardization.\
    \ Global distributors and manufacturers must propose\nand accept standardized\
    \ network solutions that enable communication between di-\nverse devices on homogeneous\
    \ communication entities. The IEEE 802.15.4 standard\nis the dominant solution\
    \ that presents a sophisticated version of the Physical Layer.\nThis standard\
    \ deals with the trade-off between data rate, communication range, and\nElectronics\
    \ 2023, 12, 2490\n15 of 63\npower consumption. Several revisions or amendments\
    \ (i.e., IEEE 802.15.4g and IEEE\n802.15.4e) aimed at the SCA have just been released.\
    \ The IEEE 802.15.4g amendment\nallows for a redesigned physical layer, allowing\
    \ data rates and communication ranges\ncompatible with neighborhood mesh (wide)\
    \ networks. Then, it is followed by another\ncutting-edge modiﬁcation, known as\
    \ IEEE 802.15.4e, which modiﬁes and enhances\nthe method used by devices to access\
    \ wireless channels while also using time-slotted\nchannel hopping mode. This\
    \ hopping mode further delivers low-power consumption\nand improved dependability.\
    \ From another viewpoint, many researchers customized\nappropriate upper-layer\
    \ protocols (i.e., the Internet Layer). They made the necessary\nmodiﬁcations\
    \ there to make smart applications compatible with conventional infras-\ntructure.\
    \ Since the network of low-power smart devices is conﬁned, the researchers\ndeveloped\
    \ numerous adjustments to the Internet protocols to make them easily adapt-\n\
    able. For example, the most notable IETF projects are RPL [72] and 6LoWPAN [73],\n\
    which greatly aid in creating and adapting smart city scenarios.\n•\nInterference\
    \ problem: Sophisticated technologies that are spread across the same radio\n\
    space and independent radio infrastructures are linked via a range of wireless\
    \ channels.\nBecause of this, the smart application must handle interference problems\
    \ in such\nsituations. To share unlicensed bands, numerous networks must cooperate\
    \ and be\ncompatible with one another.\n•\nVertical handover (soft): Multiple\
    \ radios are used by the rapidly expanding number of\nsmart devices being developed.\
    \ These devices should be able to recognize and use the\nbest interface that is\
    \ currently available while balancing power usage and throughput.\n•\nD2D Communications:\
    \ In the IoT context, there are numerous D2D communication de-\nmands. Unfortunately,\
    \ conventional network gateways cannot handle such generated\nmessages from heterogeneous\
    \ devices.\n•\nShort Communicating Messages: Internet-based protocols support\
    \ and recommend\nacceptable performance for longer data packet scenarios. However,\
    \ smart devices\ncommunicate with one another using short messages (since most\
    \ of them are tiny\nand operate over low-powered battery devices). To this end,\
    \ short communicating\nmessages will positively impact network congestion detection\
    \ and avoidance policies\nand promote in-band aggregation.\n•\nLocal Network Trafﬁc\
    \ Pattern: Smartphones and D2D-speciﬁc devices frequently use the\nsame network\
    \ infrastructure. However, most cellular data networks are exclusively\nplanned,\
    \ implemented, deployed, and managed for smartphone usage. Fitting trafﬁc\nfrom\
    \ these heterogeneous devices onto a single platform is now the main challenge\n\
    that cellular data network providers face. It is difﬁcult to integrate the trafﬁc\
    \ from these\ntwo types of heterogeneous devices into the same network infrastructure\
    \ due to several\nintrinsic factors and the speciﬁed features of this traditional\
    \ network. Additionally,\nD2D devices use a more signiﬁcant proportion of scarce\
    \ resources than smartphones,\nunnecessarily creating a problem of unfairness\
    \ in the system [74]. Therefore, we\nmust ﬁrst comprehend D2D trafﬁc patterns\
    \ and how they differ from trafﬁc patterns\ngenerated by smartphones. Understanding\
    \ trafﬁc patterns can provide insights into\nmanaging and allocating shared network\
    \ resources more effectively and guarantee\nthe highest level of service quality\
    \ for both types of devices.\n•\nSecurity mechanisms: Denial of Service (DoS)\
    \ attacks are a remarkable threat to the\nsecurity of smart city networks and\
    \ must be identiﬁed. Some statistical methods\nhave been proposed to solve this\
    \ problem. Such a statistical method is presented\nin [75] that is based on feature\
    \ distance maps that enhance the statistical analysis\nprocess. Another security\
    \ mechanism is authentication, a process of identifying\nusers and devices in\
    \ a network and granting access to authorized persons and non-\nmanipulated devices.\
    \ Authentication is one method to mitigate attacks on the IoT\nsystems such as\
    \ the reply attack, the Man-in-the-Middle attack, the impersonation\nattack, and\
    \ the Sybil attack [76]. To realize end-to-end security, the nodes must be\nencrypted.\
    \ However, due to the heterogeneity of the IoT systems, some nodes might\nElectronics\
    \ 2023, 12, 2490\n16 of 63\nbe able to embed general-purpose microprocessors for\
    \ this task. In addition, low\nresources and constrained devices can only embed\
    \ application-speciﬁc integrated\ncircuits. Therefore, conventional cryptographic\
    \ primitives are not suitable for low-\nresource smart devices due to their low\
    \ computation power, limited battery life, small\nsize, small memory, and limited\
    \ power supply. As a result, lightweight cryptography\nmay be an efﬁcient encryption\
    \ for these devices. Trust management is another security\nmechanism that detects\
    \ and eliminates malicious nodes and provides secure access\ncontrol. Automated\
    \ and dynamic trust calculations are needed to validate the trust\nvalues of the\
    \ participating nodes in an IoT network. The majority of trust management\nschemes\
    \ focus on detecting malicious nodes; only a few trust-based access control\n\
    methods have been proposed. In fact, with scalability and the large number of\
    \ smart\nthings storing sensitive data, there is an urgent need for automated,\
    \ transparent, and\neasy access control management so that different nodes/users\
    \ can be granted different\nlevels of access. From another perspective, Blockchain\
    \ technology can be used to\ncreate secure virtual zones where things can identify\
    \ and trust each other [77]. Self-\norganization Blockchain Structures (BCS) can\
    \ also be planned to set up the relationship\nbetween Blockchain and IoT, as suggested\
    \ in [78].\n•\nAnomaly Detection in Sensor Systems: The type of data that ﬂow\
    \ through the IoT system\ncan vary to a great extent, in terms of either format,\
    \ shape (in time and space), and\nsemantics. Therefore, the process of separating\
    \ normal from abnormal sensed data is\nextremely demanding. In the context of\
    \ IoT applications, sensors are the real source\nof big data, which suggests that\
    \ anomaly detection at the edge could be a powerful\ntool to address the inevitable\
    \ data communication bottlenecks. Anomaly detection is\nconcerned with identifying\
    \ data patterns that deviate remarkably from the expected\nbehavior. This is critical\
    \ in the process of ﬁnding out important information about\nthe IoT system’s functioning,\
    \ detecting abnormalities that are often rare or difﬁcult\nto model or, otherwise,\
    \ to predict [79]. A timely identiﬁcation of anomalies is vital to\npreventing\
    \ IoT system failure.\n•\nAdvanced Techniques in Smart City Networks: Artiﬁcial\
    \ intelligence (AI), machine learn-\ning (ML), and deep reinforcement learning\
    \ (DRL) play a key role in the evolution of the\nsmart city sectors [80]. These\
    \ techniques are now being developed as solutions for com-\npletely automated\
    \ IoT applications. Using these techniques, the optimal analysis of\nthe big data\
    \ is performed to reach an optimal decision. Utilizing DRL/ML approaches\ncan\
    \ improve security; decrease energy consumption; reduce latency; and increase\n\
    precision and accuracy in surveillance, energy management, air quality prediction,\n\
    person detection, trafﬁc management, etc. For example, an intelligent transportation\n\
    system is highly based on ML- and DRL-based techniques to realize self-driving\
    \ vehi-\ncles and guarantee the security of connected vehicles. DRL techniques\
    \ are also used to\nprecisely monitor and estimate the real-time trafﬁc ﬂow data\
    \ in an urban environment.\nIn SGs, big data analytics and thus the aforementioned\
    \ techniques can enhance the\nsafety of power grids, decision-making of power-sharing,\
    \ management, and power\ngrid performance. In particular, SGs are making effective\
    \ use of smart meter big data\nfor different applications such as load assessment\
    \ and prediction, baseline estimation,\ndemand response, load clustering, and\
    \ malicious data deception attacks. In health\nintelligence, extensive use of\
    \ AI, ML, and DRL techniques is implemented due to\nhigh-performance IoT devices,\
    \ Cloud Computing, and an increase in data rates. These\ntechniques can play a\
    \ vital role in disease diagnosis, cure prediction, social media ana-\nlytics\
    \ for a particular disease, and medical imaging [81]. In cyber-security, the role\
    \ of\nAI-, ML-, and DRL-based techniques is also outstanding. These techniques\
    \ can be used\nfrom an advanced security perspective of IoT to confront security\
    \ threats. Notably, the\naccuracy and precision of the aforementioned techniques\
    \ can be further enhanced by\nincreasing the amount of training data to strengthen\
    \ their learning capabilities and\nhence the automated decision efﬁciencies [82].\n\
    Electronics 2023, 12, 2490\n17 of 63\n4. Protocols Used for SCAs\nFigure 3 shows\
    \ a proposed taxonomy of networking protocols and architectures for\nSCAs. It\
    \ also shows the challenges in IoT communications via TCP/IP.\nElectronics 2023,\
    \ 12, x FOR PEER REVIEW \n18 of 65 \n \n \ncreate a system that enables effective\
    \ communication between several indoor and out-\ndoor devices. Nevertheless, the\
    \ real-time implementation of IEEE 802.11ah may need to \nbe improved by the absence\
    \ of an appropriate interference mechanism. \n \nFigure 3. A taxonomy of technologies\
    \ facilitating communication and networking for smart cities \nwith IoT-enabled\
    \ application protocols and suggested networking architectures and protocols.\
    \ \nIEEE 802.15.1 (Bluetooth), IEEE 802.15.4 (Zigbee), IEEE 802.11 a/b/g/n, Cellular\
    \ \n3G/4G/5G/LTE/LTE-A, and IEEE 802.16 (WiMAX) are only a few examples of standards\
    \ \nand protocols that should be evaluated for their applicability for various\
    \ SCAs. Smart \nhome automation systems, smart buildings, and smart garbage systems\
    \ require \nshort-range communication capability and can utilize protocols (e.g.,\
    \ Bluetooth and \nZigbee) from the WPAN group. These protocols are distinguished\
    \ by a lower bandwidth \nrequirement, minimal power usage, and a shorter-range\
    \ communication infrastructure \nenvironment. In contrast, LAN groups such as\
    \ WiFi can be used for SCAs that require \nlonger-range communication. Such applications\
    \ are smart transportation management \nsystems. \nThe protocols from WAN groups,\
    \ such as Cellular and WiMAX, can be adopted by \napplications that need wide-range\
    \ communication, such as smart emergency response \nsystems, weather and air quality\
    \ monitoring systems, and smart grid systems. These \nfeatures designed in terms\
    \ of standards or protocols have enough capability that allows \nFigure 3. A taxonomy\
    \ of technologies facilitating communication and networking for smart cities\n\
    with IoT-enabled application protocols and suggested networking architectures\
    \ and protocols.\nSCAs involve numerous smart things that operate on low-powered\
    \ battery devices [83].\nNew connectivity solutions are being investigated in\
    \ light of the following question:\ndo the currently available methods, tools,\
    \ and techniques—especially those for wireless\nnetworks—allow for the reliable\
    \ handling of such a large number of smart devices?\nYaqoob et al. [84] provided\
    \ details on current connectivity solutions based on WPAN\ntechnologies such as\
    \ ZigBee, WiFi, Bluetooth, and others that offer low-power D2D com-\nmunication.\
    \ In these technologies, the throughput performance, the number of con-\nnected\
    \ devices, transmission ranges, etc., are severely constrained. Other technologies\n\
    (e.g., WiMAX, LTE, and LTE-A) involve signiﬁcant power consumption and are only\n\
    partially applicable to such settings. IEEE and 3GPP adapt their technologies\
    \ and commu-\nnication strategies to the rapidly expanding IoT-based modern communication\
    \ perspective.\nIEEE 802.11 (WiFi) was initially designed to maintain higher throughput\
    \ performance\nfor fewer stations distributed over a shorter distance in an interior\
    \ context. Due to the\nlimitations of its initial design, this standard does not\
    \ support IoT applications. Hence,\nElectronics 2023, 12, 2490\n18 of 63\nto enable\
    \ IEEE 802.11 adaptive in such circumstances, the community (IEEE 802.11ah\nTask\
    \ Group (TGah)) developed a new power-efﬁcient protocol [55]. They aim to create\
    \ a\nsystem that enables effective communication between several indoor and outdoor\
    \ devices.\nNevertheless, the real-time implementation of IEEE 802.11ah may need\
    \ to be improved by\nthe absence of an appropriate interference mechanism.\nIEEE\
    \ 802.15.1 (Bluetooth), IEEE 802.15.4 (Zigbee), IEEE 802.11 a/b/g/n, Cellular\n\
    3G/4G/5G/LTE/LTE-A, and IEEE 802.16 (WiMAX) are only a few examples of standards\n\
    and protocols that should be evaluated for their applicability for various SCAs.\
    \ Smart\nhome automation systems, smart buildings, and smart garbage systems require\
    \ short-\nrange communication capability and can utilize protocols (e.g., Bluetooth\
    \ and Zigbee) from\nthe WPAN group. These protocols are distinguished by a lower\
    \ bandwidth requirement,\nminimal power usage, and a shorter-range communication\
    \ infrastructure environment.\nIn contrast, LAN groups such as WiFi can be used\
    \ for SCAs that require longer-range\ncommunication. Such applications are smart\
    \ transportation management systems.\nThe protocols from WAN groups, such as Cellular\
    \ and WiMAX, can be adopted by\napplications that need wide-range communication,\
    \ such as smart emergency response\nsystems, weather and air quality monitoring\
    \ systems, and smart grid systems. These\nfeatures designed in terms of standards\
    \ or protocols have enough capability that allows for\nboth synchronous and asynchronous\
    \ data connections. The best-effort trafﬁc (which can\neffectively tolerate latency)\
    \ allows the asynchronous data connections feature to be linked\nwith smart city\
    \ services or applications. Meanwhile, exploring synchronous data connec-\ntions\
    \ is possible for those services or applications that generate trafﬁc mandating\
    \ strict\nQoS standards such as low latency and high accessible network capacity\
    \ [49]. Since IEEE\n802.15.4 (Zigbee) is a short-range (low bit rate) communication\
    \ protocol that often suggests\nhigher ﬂexibility for small devices running on\
    \ low power, such a protocol can signiﬁcantly\nincrease network lifetime. Moreover,\
    \ such a protocol encourages and indicates support\nfor applications and services\
    \ with relatively relaxed latency and throughput conditions in\nWPANs. The authors\
    \ of [85] utilized a WSN based on IEEE 802.15.4 and proposed an intelli-\ngent\
    \ system for lighting applications. The authors highlighted the beneﬁts of using\
    \ wireless\nemulsions: uncomplicatedness in the implementation and deployment,\
    \ relatively easier in\nexpanding a network, and ﬂexibility in the system due\
    \ to the use of wireless technology,\nwhich supports the usage of heterogeneous\
    \ devices in the same implemented and deployed\nstructure. Furthermore, they emphasized\
    \ the advantages of employing the same intelligent\ninfrastructure for a variety\
    \ of services, leading to more effective management, monitoring,\nand cost-effectiveness.\
    \ For example, by including speciﬁc smart metering devices such as\nwater or gas\
    \ meters, the smart network or infrastructure (that was initially established\
    \ to\ntarget smart lighting applications) can also be used for smart metering\
    \ applications.\n5G has just supplanted 4G with advanced access schemes called\
    \ BDMA and FBMC\nmultiple access, which was ﬁrst launched in 2015. In the case\
    \ of BDMA multiple access, an\northogonal beam is frequently used, meaning that\
    \ resources can be distributed in parallel to\neach mobile base station by dividing\
    \ the antenna beam in accordance with the position of\nthe mobile stations to\
    \ enable multiple accesses to the base stations. Successively, this helps\nin\
    \ improving the capacity of 5G networks [86]. Speciﬁcally, the idea of moving\
    \ towards\n5G is based on current technology advancements and particularly on\
    \ unique customer\nneeds. Nonetheless, it is typically presumed that implemented\
    \ 5G cellular networks should\naddress noteworthy complications that are not successfully\
    \ addressed by 4G, i.e., enhanced\nnetwork capacity and data rate, lower End-to-End\
    \ (E2E) latency, reduced cost, and con-\nsistent user QoE provisioning. In addition,\
    \ massive and rapid growth in the number of\nhighly developed connected devices\
    \ leads to a sharp increase in network trafﬁc and a\nwidening range of applications\
    \ with unique dynamic requirements and features. Gupta\nand Jha [86] studied numerous\
    \ facilitators, such as choice or use of spectrum, massive\nMIMO, trafﬁc and power\
    \ management policies, ofﬂoading (local), and self-conﬁguring and\norganizing\
    \ networks, which can address these challenges effectively. Real-time managing\n\
    and supervising in smart city scenarios will be conceivable these days thanks\
    \ to 5G. 5G\nElectronics 2023, 12, 2490\n19 of 63\nultimately targets some networking\
    \ possibilities, i.e., ultra-Reliable and Low-Latency Com-\nmunications (uRLLC),\
    \ enhanced Mobile Broadband (eMBB), and massive Machine Type\nCommunications (mMTC).\
    \ In a smart city context, eMBB controls data transfer between a\nvariety of networked\
    \ user end devices, edge devices, or cloud servers. Conversely, mMTC\naims to\
    \ manage huge connected, complex devices, such as wearables, actuators, and sen-\n\
    sors, through dense urban deployment. Finally, uRLLC takes responsibility for\
    \ managing\nhighly time-critical communication such as vehicular communication,\
    \ base stations, and\nedge devices communication [87]. Although 5G has completely\
    \ brought about a new\nrevolution in the ﬁeld of networking, numerous unknown\
    \ challenges still are possible in\nthese cases of communication when 5G is deployed\
    \ in the context of smart cities. One major\nproblem is power-efﬁcient communication,\
    \ especially when communicating low-powered\nbattery devices such as sensors and\
    \ other smart, complex wearables. Additionally, when\ntwo distinct technologies\
    \ (4G/5G) work together, there might be a problem. Speciﬁc device-\nlevel compatibility\
    \ problems might always persist when communication infrastructures\nmigrate to\
    \ next-generation platforms. Moreover, a big question arises, namely, how to\n\
    handle the widespread use of gadgets, particularly those in isolated or difﬁcult-to-reach\n\
    places, as well as the potential high costs associated with building and maintaining\
    \ 5G\nnetworks.\nTable 2 compares protocols used for smart cities, while Table\
    \ 3 evaluates standards\nutilizing features and characteristics.\nTable 2. Comparison\
    \ of protocols used for smart cities. Adapted and extended from [49,84,88].\n\
    Communication\nTechnology/Standard 1\nPhysical Layer Speciﬁcations\nData Link\
    \ Layer\nSpeciﬁcations 4\nData Rate 5\nCoverage Area 6\nOperating Frequency\n\
    Bands 2\nData Modulation and\nReceiver Sensitivity 3\nZigBee/IEEE 802.15.4\n2.4\
    \ GHz, 868 MHz–915\nMHz (DSSS)\nData Modulation: 16-ary orthogonal modulation\n\
    (2.4 GHz) and BPSK with DE (868 MHz–915 MHz).\nReceiver Sensitivity:\n−85 dBm\
    \ (2.4 GHz PHY)\n−92 dBm (868/915 MHz PHY)\nCSMA-CA, TDD\n(optional)\n250 Kbps\n\
    (2.4 GHz),\n20 Kbps\n(868 MHz), and\n40 Kbps\n(915 MHz)\n30–50 m\nBluetooth/\n\
    IEEE 802.15.1\n2.4 GHz, 2400\nMHz–2483.5 MHz\n(FHSS/FSK)\nData Modulation:\nGFSK\
    \ and PSK (for higher data rates)—π/4 DQPSK\nand 8 DPSK\nReceiver Sensitivity:\n\
    −70 dBm to −82 dBm (usually depends on the type of\nPHY use), say, Bluetooth LE\
    \ 125K (Coded) PHY can\nachieve −103 dBm\nTDD, M&S, FH\n1 Mbps\n1–100 m\nWiFi/IEEE\
    \ 802.11\n(Legacy) (a/b/g/n)\nConventional: 2.4 GHz\na: 5 GHz (OFDM),\nb: 2.4\
    \ GHz (DSSS),\ng: 2.4 GHz (DSSS,\nOFDM),\nn: 5 GHz (DSSS,\nOFDM)\nData Modulation:\n\
    Conventional: DI, DSSS, and FHSS, a: OFDM\nb: HR-DSSS, g: OFDM, DSSS, and CCK\n\
    n: OFDM using MIMO and CB\nReceiver Sensitivity:\nLegacy: 1 Mbps: −80 dBm, 2 Mbps:\
    \ −75 dBm\nb: 2 Mbps: −80 dBm, 11 Mbps: −76 dBM\ng: 6–54 Mbps: −82 dBm to −65\
    \ dBm\nn: 1–54 Mbps: −80 dBm to −65 dBm\nCSMA-CA\nConventional:\n1–2 Mbps\na:\
    \ 6–54 Mbps\n(VMT)\nb: 1–11 Mbps\n(VMT)\ng: 6–54 Mbps\n(VMT)\nn: 1–54 Mbps\n(VMT)\n\
    1–100 m\nWiMAX/IEEE 802.16\n2.5 GHz, 3.5 GHz,\n5.8 GHz\n(MIMO-OFDM)\nData Modulation:\n\
    OFDM using MIMO, AMC, AAS\nReceiver Sensitivity:\nQPSK (1/2): −80 dBm, QPSK (3/4):\
    \ −78 dBm\n16 QAM (1/2): −73 dBm, 16 QAM (3/4): −71 dBm\n64 QAM (2/3): −66 dBm,\
    \ 64 QAM (3/4): −65 dBm\nTDD, FDD\n75 Mbps\n1–5 Km (NLoS),\n10–50 km (LoS)\nLoRaWAN/LoRA\n\
    Alliance\n867–869 MHz (Europe)\n865–867 MHz (India)\nData Modulation:\nLoRA (CSSM)\n\
    Receiver Sensitivity:\n−137 dBm (SF = 12, BW = 125 KHz, NF = 6)\nPure ALOHA\n\
    with DCLs or PSA\n(LBT)\n250 bps–50 Kbps\n(Europe)\nNS (India)\n2–5 km\n3G (WCDMA\n\
    Technology) (BIS)\n1.92–1.98 GHz,\n2.11–2.17 GHz\n(licensed)\nData Modulation:\n\
    AM/PSK using QAM\nReceiver Sensitivity:\n−102 dBm\nCDMA\n384 Kbps\n(deployed)–\n\
    2 Mbps\n1–10 km\nGPRS\n900–1800 MHz\nData Modulation:\nGMSK\nReceiver Sensitivity:\n\
    −159 dBm\nTDMA, FDMA,\nand FH\nUp to 170 Kbps\n1–10 km\nZ-Wave/Z-Wave\nAlliance\n\
    900 MHz\nData Modulation:\nFSK/BFSK (for 9.6 Kbps and 40 Kbps)\nGFSK (for 100\
    \ Kbps) with BT = 0.6\nReceiver Sensitivity:\n−104 dBm\nCSMA-CA\n9.6 Kbps–100\
    \ Kbps\n100 m\nElectronics 2023, 12, 2490\n20 of 63\nTable 2. Cont.\nCommunication\n\
    Technology/Standard 1\nPhysical Layer Speciﬁcations\nData Link Layer\nSpeciﬁcations\
    \ 4\nData Rate 5\nCoverage Area 6\nOperating Frequency\nBands 2\nData Modulation\
    \ and\nReceiver Sensitivity 3\nLTE/3GPP\n2.5 GHz, 5 GHz,\n10 GHz (OFDM CP for\n\
    downlink, SC-FDMA\nCP for uplink)\nData Modulation:\nAMC, QPKS, 16QAM\nReceiver\
    \ Sensitivity:\n−103 dBm (LTE/A signal—5 MHz BW, QPSK, CR = 1/3,\nSNR = −1 dB,\
    \ NF of LTE/A-based receiver chain = 5 dB)\n−90.7 dBm (LTE/A signal—5 MHz BW,\
    \ 16QAM,\nCR = 2/3, SNR = 11.3 dB, NF of LTE/A-based receiver\nchain = 5 dB)\n\
    TDD, FDD\n75 Mbps (UL)\n300 Mbps (DL)\n30 km\nLTE-A/3GPP\n2.5 GHz, 5 GHz,\n10\
    \ GHz, 15 GHz,\n20 GHz (OFDM CP for\ndownlink, SC-FDMA\nCP for uplink)\n500 Mbps\
    \ (UL)\n1 Gbps (DL)\n30 km\n5G (New Radio (NR)\nAir Interface) (Single\nUniﬁed,\
    \ 4G + World\nWide Wireless Web\n(WWWW))\nFor 5G mmWave\naccess, an extensive\n\
    spectrum of bands\nbetween 13 and 86 GHz\nhas been recommended\nC-band (3300–4200\
    \ and\n4400–5000 MHz)\nData Modulation:\nUFMC, F-OFDM, and FBMC\n5G New Radio\
    \ (NR) Uplink Receiver Sensitivity:\nPRef = TN + 10log10(BW) + NF+ IM + SNR\n\
    At room temperature, the TN in a 50 system is\n−174 dBm/Hz. For Wide Area BS,\
    \ Medium Range BS,\nor Local Area BS, the base station NF is 5 dB, 10 dB, or\n\
    13 dB, respectively. IM = 2 dB. The SNR value is that at\nwhich 95% of the maximum\
    \ throughput is achieved.\nPRef = TN + 10log10(BW) + NF+ IM + SNR = −93 db,\n\
    (For NF = 5 dB, BW = 100 MHz, SNR = −1)\nTDD, FDD\n10–50 Gbps\nDepends on\nchanging\
    \ cell\nradius (1 km to\nseveral km’s)\n1: LoRaWAN: Long-Range Wide Area Network,\
    \ 3GPP: Third-Generation Partnership Project, WCDMA: Wideband\nCode Division Multiple\
    \ Access, BIS: Broadband Internet Service, GPRS: General Packet Radio Services,\
    \ LTE: Long-\nTerm Evolution, LTE-A: LTE-Advanced, 3GPP: Third-Generation Partnership\
    \ Project. 2: DSSS: Direct-Sequence\nSpread Spectrum, FHSS/FSK: FHSS: Frequency\
    \ Hopping Spread Spectrum/Frequency Shift Keying, OFDM:\nOrthogonal Frequency-Division\
    \ Multiplexing, MIMO-OFDM: Multiple-Input/Multiple-Output-OFDM, OFDM\nCP: OFDM\
    \ with Cyclic Preﬁx, SC-FDMA CP: Single Carrier-Frequency Division Multiple Access\
    \ with Cyclic Preﬁx.\n3: BPSK with DE: Bi-Phase Shift Keying with Differential\
    \ Encoding, GFSK: Gaussian Frequency Shift Keying,\nPSK: Phase Shift Keying, π/4\
    \ DQPSK: π/4 Phase Differential Quaternary PSK, 8 DPSK: 8-Phase Differential\n\
    PSK, DI: Diffuse Infrared, DSSS: Direct-Sequence Spread Spectrum, FHSS: Frequency\
    \ Hopping Spread Spectrum,\nHR-DSSS: High Rate-DSSS, CCK: Complementary Code Keying,\
    \ MIMO: Multiple-Input/Multiple-Output, CB:\nChannel Bonding, AMC: Adaptive Modulation\
    \ Coding, AAS: Adaptive Antenna System, QPSK: Quadrature PSK,\nQAM: Quadrature\
    \ Amplitude Modulation, CSSM: Chirp Spread Spectrum Modulation, SF: Spreading\
    \ Factor, BW:\nBandWidth, NF: Noise Figure, AM/PSK: Amplitude-Modulation PSK,\
    \ GMSK: Gaussian Minimum Shift-Keying,\nBFSK/FSK: Binary-Frequency Shift Keying,\
    \ BT: Bandwidth-Time product, SNR: Signal-to-Noise Ratio, CR: Code\nRate. 4: CSMA-CA:\
    \ Carrier Sense Multiple Access-Collision Avoidance, TDD: Time division duplexing,\
    \ M&S:\nMaster and Slave, FH: Frequency Hopping, FDD: Frequency Division Duplexing,\
    \ DCLs: Duty-Cycle Limitations,\nPSA (LBT): Polite Spectrum Access (Listen Before\
    \ Talk), TDMA: Time Division Multiple Access, FDMA: Frequency\nDivision Multiple\
    \ Access. 5: VMT: Varying Modulation Types, NS: Not Speciﬁed, UL: UpLink, DL:\
    \ DownLink.\n6: LoS: Line of Sight, NLoS: Non-LoS.\nTable 3. Evaluation of standards\
    \ utilizing their features.\nCommunication\nTechnology/Standard 1\nFeatures 2\n\
    Topology 3\nNetwork Category 4\nLimitations\nZigBee/IEEE 802.15.4\nIt allows short-range\
    \ transmissions. It requires lesser\nbandwidth and minimal power usage. It clears\
    \ channel\nassessment (for the case of CSMA). Dynamic selection of\noperating\
    \ channels for coexistence. Packet strength signal for\neffective forwarding and\
    \ location. It is designed and suited for\nPAN-based applications.\nMesh\nWPAN\n\
    Low data rate and short\ncoverage.\nBluetooth/IEEE 802.15.1\nIt creates dynamic\
    \ (ad-hoc) connections using radio waves. It\npresents low-cost, robust, low-power\
    \ solutions for P2P\ncommunication. It allows for short-range transmissions. It\
    \ is\nmainly designed and suited for PAN-based applications. It\nsuggests support\
    \ for IoT devices, via BLE (version), and\nconserves power by continually maintaining\
    \ devices in sleep\nmode until they are connected. It helps with quick device\n\
    pairing and reconnections, which improves device availability\nand operational\
    \ efﬁcacy.\nP2P\nWPAN\nShort coverage and less\nsecure.\nElectronics 2023, 12,\
    \ 2490\n21 of 63\nTable 3. Cont.\nCommunication\nTechnology/Standard 1\nFeatures\
    \ 2\nTopology 3\nNetwork Category 4\nLimitations\nWiFi/IEEE 802.11\n(Legacy) (a/b/g/n)\n\
    General features:\nIt can aid both in an infrastructure-mode and an ad-hoc\nmanner.\
    \ These standards are quickly utilized in temporary\nand permanent LAN installations\
    \ and deployments because of\ntheir ﬂexibility and performance. It supports network\n\
    management service and asynchronous communication. It\nsuggests time-constrained\
    \ delivery services and support for\nbroadcast and multicast services. Moreover,\
    \ it offers support\nfor long-range communication.\nSpeciﬁc features:\nIEEE 802.11a—works\
    \ on the 5 GHz band, has a lesser\ninterference level than other devices but has\
    \ higher\npropagation losses compared to the 2.4 GHz band.\nIEEE 802.11b—works\
    \ on the 2.4 GHz band. There may be\ninterference issues with those devices, which,\
    \ too, operate on\nthe 2.4 GHz band. However, it offers a higher capacity and\n\
    reachability than the 5 GHz spectrum to get through\nobstructions. It can also\
    \ provide support for the ARS\nmethod [79], which allows an IEEE 802.11b device\
    \ to\ndynamically switch from its theoretical maximum data rate\n(11 Mbps) to\
    \ lower data rates such as 5.5 Mbps, 2 Mbps, or\neven 1 Mbps if interference rises.\n\
    IEEE 802.11g—faster operating speed and generally has better\nsignal range, being\
    \ not easily obstructed. The IEEE\n802.11g-based devices used OFDM to carry higher\
    \ data rates\nwhile providing robustness against multipath fading/effects.\nHowever,\
    \ additional modulation techniques (as shown in\nTable 2) are also used to preserve\
    \ and manage compatibility.\nIEEE 802.11n—offers superior performance to its other\
    \ peer\nstandards by suggesting modiﬁcations in MIMO, OFDM,\npower saving, antenna\
    \ technology, and wider channel\nbandwidth. The IEEE 802.11n-based access point\
    \ can operate\nin Legacy, Mixed, and Greenﬁeld modes [89]. This standard\neffectively\
    \ exploits MIMO to take complete beneﬁt of the\navailable data rate.\nStar\nLAN\n\
    Short coverage,\ncomparatively higher\nsignal attenuation, less\nreliable and\
    \ stable\ncompared to wired\nconnections.\nWiMAX/IEEE 802.16\nIt was introduced\
    \ initially to overcome the disadvantages of\nmobile networks and WLANs. It supports\
    \ high data\ntransmission rates while allowing more coverage than\nWLANs. It provides\
    \ numerous QoS scheduling mechanisms\nsupporting heterogeneous trafﬁc, such as\
    \ VoIP, voice data\n(trafﬁc), video data/streams, and Internet trafﬁc. Moreover,\
    \ it\nhas speciﬁc features such as high-speed Internet; a\nlong-distance communication\
    \ facility; and support for security,\nmobility, and scalability.\nP2MP, Mesh\n\
    MAN\nNot widespread and\noperationally expensive.\nLoRaWAN/LoRA\nAlliance\nIt\
    \ provides long-range transmissions and offers robustness\nfrom interferences.\
    \ The PHY layer of this standard or protocol\nmodulates the signal in the SUB-GHz\
    \ ISM band. This\nspeciﬁcation aims to provide low-power WANs with\ncapabilities\
    \ speciﬁcally required to facilitate low-cost mobile\nsecure bidirectional communication.\
    \ Additionally, it deﬁnes\nthe idea of geolocation, which can be quickly applied\
    \ to enable\nGPS-free tracking applications.\nIt utilizes minimum amounts of power,\
    \ and hence IoT-based\nsensors and actuators can operate for a long time.\nAdditionally,\
    \ it manages less bandwidth utilization, making it\ntheir default choice for IoT-based\
    \ deployments.\nThe overall architecture (i.e., star) is relatively straightforward\n\
    since a LoRaWAN-based GW can be designed to manage\nnumerous end devices or nodes.\
    \ It also offers secure\ncommunication between the end device or node and the\n\
    application server using the AES-128 encryption standard.\nStar\nWAN\nShort coverage.\n\
    3G (WCDMA\nTechnology) (BIS)\nThis MNwT was initially engineered and designed\
    \ to transmit\nand receive multimedia trafﬁc with variable and high bit rates.\n\
    This standard (having a comparable spectrum everywhere it is\nused) enables seamless\
    \ worldwide networking. It utilizes the\npacket switching concept for data communication\
    \ and circuit\n(or optional packet) switching technique for voice\ncommunication.\
    \ It allows global roaming across a similar type\nof network (wireless) called\
    \ a cellular network at 384 Kbps or\neven higher (up to several Mbps).\n-\nWAN\n\
    Spectrum licensed cost,\nhuge power\nconsumption, and\ninsufﬁcient bandwidth to\n\
    handle growing user\ndemands.\nGPRS\nAs an enhancement over GSM, GPRS adds several\
    \ nodes\ncalled GSNs to support end-to-end packet-switched services in\nthe system.\
    \ It operates by aggregating several separate data\nchannels by the concept of\
    \ packetization. Moreover, it is a\nlow-cost technology that suggests a packet-based\
    \ radio service.\nIt offers the capabilities such as a high transfer rate,\nvolume-based\
    \ billing, shorter access time, improved radio\nresource utilization, and simpliﬁed\
    \ access to packet data\nnetworks [90].\n-\nWAN\nLow data rate.\nElectronics 2023,\
    \ 12, 2490\n22 of 63\nTable 3. Cont.\nCommunication\nTechnology/Standard 1\nFeatures\
    \ 2\nTopology 3\nNetwork Category 4\nLimitations\nZ-Wave/Z-Wave\nAlliance\nIt\
    \ allows for operation in the low-frequency range, hence\noffering better performance.\
    \ It supports low-power mesh\nnetworks and employs BFSK modulation. The lower\
    \ frequency\nwith longer wavelength allows Z-Wave devices to establish\nmore reliable\
    \ and faster connections since these parameters\nassist these devices in easily\
    \ penetrating objects and walls.\nSix layers of backward compatibility provide\
    \ version\ninteroperability. The interoperability facility among\nZ-Wave-based\
    \ smart or conventional devices assists in\nblending several applications at once,\
    \ such as HA, SA, and LA.\nStar, cluster,\nmesh\nWPAN\nDifﬁculty in mobility\n\
    management. Fewer\nsecurity features.\nLTE/3GPP\nIt is a 3GPP interface (radio)\
    \ based on UMTS/HSPA and\nGSM/EDGE networking technologies. It suggests\nimprovements\
    \ in data rate and capacity by employing new\nand modiﬁed modulation schemes.\
    \ Moreover, it offers support\nfor FDM and TDM techniques. It adopts an IP-based\
    \ network\nmodel that promises a seamless handoff of voice and data to\ncell towers\
    \ using an older technology.\nStar\nWAN\nHigh operational costs\nbecause extra\
    \ antennas\nare used at network base\nstations to transmit data.\nLTE-A/3GPP\n\
    Through modifying and proposing novel PHY layer\nspeciﬁcations or implementations\
    \ and reforming the CN,\nLTE-A offers much-improved performance over UMTS/HSPA\n\
    MNwTs. It can speed up to 3 Gbps download and 1.5 Gbps\nupload. Additionally,\
    \ it has various antenna systems that\nsimplify switching between cell regions,\
    \ as well as\ncutting-edge transmission techniques that pack more data per\nsecond\
    \ into each hertz of the spectrum and improve\nthroughput performance at the level\
    \ of cell boundaries.\nSubsequently, it leads to superior performance in terms\
    \ of\nconsistent connection and capacity (network) [89,91,92].\nP2P\nWAN\nThe\
    \ installation of towers\nto improve signals while\na smart device is in\nmotion\
    \ may result in\nsigniﬁcant costs.\nDevice compatibility is a\nconcern because\
    \ older\nmodels of devices that\ndo not support 4G LTE\ncannot connect to LTE\n\
    networks.\n5G (New Radio (NR) Air\nInterface) (Single Uniﬁed,\n4G + World Wide\n\
    Wireless Web (WWWW))\nThis technology addresses signiﬁcant challenges: a massive\n\
    and quick increase in highly sophisticated connected devices\ncontributes to a\
    \ sharp escalation in network trafﬁc and an\nexpanding variety of applications\
    \ with distinct dynamic\ndemands and features.\nSince LTE user equipment is not\
    \ required to be able to operate\non an NR carrier, NR is designed to be optimized\
    \ for\nperformance without taking backward compatibility into\naccount. Moreover,\
    \ NR can support operations in licensed\nspectrum bands from below 1 GHz to 52.6\
    \ GHz with a\nspectrum expansion facility.\nIn the case of mmWave frequencies,\
    \ excellent capacity and\nhigh data rates are possible. This technology’s ultra-lean\n\
    design seeks to decrease interference and improve system\npower efﬁciency by effectively\
    \ reducing always-on\ntransmissions [93,94].\nThis technology utilizes sophisticated\
    \ access procedures such\nas Beam Division and FBMC Multiple Access to adapt 4G\
    \ to\n5G networks. Beam Division Multiple Access (BDMA)\nschemes’ central design\
    \ principle is concurrently serving\nnumerous mobile users. This technique typically\
    \ uses an\northogonal beam, which suggests that resources can be\nallocated in\
    \ parallel to each mobile base station by separating\nthe antenna beam in accordance\
    \ with the position of the\nmobile stations to enable numerous accesses to the\
    \ base\nstations. This subsequently assists in improving the capacity\nof 5G networks\
    \ [79].\nE2E Network\nSlicing\nWAN\nIn the case of the NLoS\nstate, the effectiveness\
    \ of\nthis technology needs to\nbe thoroughly examined,\nparticularly when it\
    \ runs\nat high frequencies\nbecause wireless\nchannels’ basic nature is\ninconsistent\
    \ when the\nfrequency changes to\nhigher values. Due to\nhigher frequencies’\n\
    extreme vulnerability to\ninterference from\nobstructions, this\ndisadvantage\
    \ exists.\nSubsequently, this\nhampers the throughput\nperformance of\nunderlying\
    \ deployed\nLayer-4 protocols such as\nTCP and MPTCP.\n1: LoRaWAN: Long-Range\
    \ Wide Area Network; 3GPP: Third-Generation Partnership Project; WCDMA: Wideband\n\
    Code Division Multiple Access; BIS: Broadband Internet Service; GPRS: General\
    \ Packet Radio Services; LTE:\nLong-Term Evolution; LTE-A: LTE-Advanced; 3GPP:\
    \ Third-Generation Partnership Project. 2: CSMA: Carrier\nSense Multiple Access;\
    \ PAN: Personal Area Networks; P2P: Point-to-Point; BLE: Bluetooth Low Energy;\
    \ LANs:\nLocal Area Networks; ARS: Adaptive Rate Selection; OFDM: Orthogonal Frequency\
    \ Division Multiplexing;\nMIMO: Multiple-Input/Multiple-Output; WLANs: Wireless\
    \ LANs; VoIP: Voice over Internet Protocol; PHY:\nPHYsical; ISM: Industrial, Scientiﬁc,\
    \ and Medical; WANs: Wide Area Networks; GPS: Global Positioning System;\nGW:\
    \ GateWay; AES: Advanced Encryption Standard; MNwT: Mobile Network Technology;\
    \ GSM: Global System\nfor Mobile communication; GSNs: GPRS Support Nodes; HA:\
    \ Home Automation; SA: Security Automation;\nLA: Lighting Automation; UMTS: Universal\
    \ Mobile Telecommunications System; HSPA: High-Speed Packet\nAccess; FDM: Frequency\
    \ Division Multiplexing; TDM: Time Division Multiplexing; CN: Core Network. 3:\
    \ P2P:\nPoint-to-Point; P2MP: Point-to-MultiPoint; E2E: End-to-End. 4: WPAN: Wireless\
    \ Personal Area Network; LAN:\nLocal Area Network; WAN: Wide Area Network; MAN:\
    \ Metropolitan Area Network.\nElectronics 2023, 12, 2490\n23 of 63\n4.1. IEEE\
    \ 802.11 Standards\nTable 4 presents IEEE 802.11 standards and their features.\n\
    Table 4. IEEE 802.11 standards and their enhancements/features.\nStandards (Year\
    \ Released)\nEnhancement(s)/Feature(s) *\nTarget\nIEEE 802.11 (1997) (Original)\n\
    The standard and its amendments serve as the foundation for\nwireless network\
    \ products bearing the WiFi brand. This signiﬁes\ntwo raw data rates of 1 and\
    \ 2 Mbps that must be transferred via\nDSSS and FHSS at 2.4 GHz in the ISM band.\n\
    Wireless Standard (basic)\nIEEE 802.11b (1999)\nThis standard is intended to operate\
    \ in the 2.4 GHz spectrum;\nhowever, the level of interference issues is higher\
    \ when this\nstandard-based device tries to interoperate with many other\ndevices/standards\
    \ operating on the same band. It can attain a\ntheoretical data rate of 11 Mbps.\
    \ Nevertheless, dynamic\nadaptations can be applied to the transfer rate subject\
    \ to the current\ninterference level and signal power to minimize the error rate\
    \ (ARS\nPolicy). Depending on the channel conditions, the raw data rates\ncan\
    \ be adapted to 5.5 Mbps, 2 Mbps, and 1 Mbps. Additionally, it\nprovides somewhat\
    \ simpler deployment processes (e.g., upgrading\nthe current chipsets) as it demonstrates\
    \ backward compatibility\nwith the original standard due to the use of CDMA and\
    \ DSSS (same\nas the original standard) [89]. The coverage indoor and outdoor\n\
    ranges are 115 feet and 460 feet, respectively.\nWiFi-1\nIEEE 802.11a (1999)\n\
    Designed to operate on the 5 GHz spectrum and to have the least\namount of interference\
    \ compared to other devices. Depending on\nthe needs, the raw data rates can be\
    \ changed to 48 Mbps, 36 Mbps,\n24 Mbps, 18 Mbps, 12 Mbps, 9 Mbps, and 6 Mbps.\
    \ However, it can\nreach a theoretical transfer rate of 54 Mbps. The coverage\
    \ indoor\nand outdoor ranges are 115 feet and 391 feet, respectively [89].\nWiFi-2\n\
    IEEE 802.11g (2003)\nAllows for device compatibility with devices that operate\
    \ and\nfollow IEEE 802.16b standards. It can also attain a theoretical\ntransfer\
    \ rate of 54 Mbps. In real-time situations, it can achieve a\npractical data rate\
    \ of 24 Mbps. Nonetheless, when IEEE\n802.11b-based devices are introduced into\
    \ IEEE 802.11g networks,\nor when these heterogeneous compliant devices interoperate,\
    \ the\nrate decreases drastically to accommodate IEEE 802.11b-based\ntransmission\
    \ speeds every time that the compliant device tries to\ncommunicate [89]. The\
    \ coverage indoor and outdoor ranges are\n148 feet and 296 feet, respectively.\n\
    WiFi-3\nIEEE 802.11e (2005)\nIt speciﬁes a set of QoS augmentations for WLAN applications\n\
    through extensive amendments to the MAC sub-layer. It addressed\nQoS requirements\
    \ by emphasizing two-channel access schemes:\n(1) the contention-based EDCA scheme\
    \ and (2) the contention-free\nHCCA scheme. This standard, via EDCA, provides\
    \ trafﬁc\nprioritization support based on QoS classes (similar to\ndifferentiated\
    \ services). Conversely, this standard suggests\nparameterized QoS (similar to\
    \ integrated services) via HCCA. It\nalso speciﬁes enhancement over the conventional\
    \ IEEE 802.11\npower saver method (APSD) and reduces the signaling load [95].\
    \ It\nis designed to operate at frequencies ranging from 2.4 to\n2.4835 GHz or\
    \ from 5.75 to 5.850 GHz. This standard also speciﬁes\nthat a high transmission\
    \ rate may not be sufﬁcient to meet the QoS\nrequirements imposed by real-time\
    \ audio, voice, video, and\nlive-streaming applications. Following that, the provisions\
    \ of trafﬁc\nprioritization at the MAC sub-layer were insisted upon.\nQoS improvements\n\
    Electronics 2023, 12, 2490\n24 of 63\nTable 4. Cont.\nStandards (Year Released)\n\
    Enhancement(s)/Feature(s) *\nTarget\nIEEE 802.11n (2009)\nThis standard was suggested\
    \ while keeping the increased speed\nrequirement in mind. Later, it was able to\
    \ boost the attainable\nspeeds of WiFi networks beyond what was possible with\
    \ 802.11g.\nAchieving such high performance required several new features,\nincluding\
    \ a modiﬁed OFDM scheme, power-saving mechanisms,\nantenna technology, MIMO, and\
    \ wider channel bandwidth.\nNonetheless, backward compatibility in the standard\
    \ has been\nsigniﬁcantly affected (reduced) under exceptional scenarios.\nWhenever\
    \ or not an old standard compliance-based device attempts\nto communicate with\
    \ an IEEE 802.11g-based device in an 802.11g\nnetwork, the network’s operation,\
    \ performance, and other\ncapabilities suffer signiﬁcantly. These standard-based\
    \ APs can\noperate in Legacy mode (choosing one standard amongst\n802.11a/b/g),\
    \ Mixed mode (choose (out of 802.11a/b/g/n) and\noperate on heterogeneous conditions),\
    \ and Greenﬁeld mode\n(operate with a single (common) 802.11n altogether) [89].\
    \ It can\nreach a theoretical transfer rate of 600 Mbps. The coverage indoor\n\
    and outdoor ranges are 230 feet and 821 feet, respectively.\nWiFi-4\nIEEE 802.11ac\
    \ (2013)\nThis standard (called initially VHT) was suggested while keeping\nincreased\
    \ speed requirements in mind (likewise with other\nstandards). This standard was\
    \ later able to increase the achievable\nspeeds (up to 1 Gbps (minimum) to 7 Gbps\
    \ (maximum)) of WiFi\nnetworks beyond what 802.11n was capable of. The standard\n\
    enables the transmission of HD videos, online interactive games,\nlive-streaming,\
    \ and other demanding applications. It operates\nusing MU-MIMO technology, which\
    \ enables a single AP and its\nantenna to send data concurrently to several devices.\
    \ As a result,\nthis helps to increase airtime efﬁciency so that every associated\n\
    client—regardless of the 802.11 types it operates on—ﬁnally\nreceives the amount\
    \ of airtime it is supposed to receive, depending\non the technology used.\nWiFi-5\n\
    IEEE 802.11ah (2017)\nDesigned to operate on unlicensed spectrum below 1 GHz,\
    \ it can\nprovide signiﬁcantly more transmission coverage than traditional\n802.11\
    \ standards, which typically operate on 2.4 and 5 GHz bands.\nThis standard can\
    \ be employed in those scenarios where accessible\nbandwidth is comparatively\
    \ narrow. It can normally apply with\nWiFi (outdoor) for performing CTO, large-scale\
    \ WSNs (i.e., smart\ngrid), and extended-range hotspots. Supporting a reasonably\
    \ large\ntransmission range/coverage property aids in managing large-scale\nnetworks\
    \ where the number of devices may be much greater than\nwhat the conventional\
    \ 802.11 standard can support. It advises that\nchanges to the PHY and MAC layers\
    \ be made to provide important\nimprovements including energy-saving capabilities,\
    \ support for\naccommodating a high number of devices, reliable media access\n\
    techniques, and throughput performance improvement by using\nsmall frame formats\
    \ [96].\nExtended coverage, low-power\nWLAN\nIEEE 802.11ax (2021)\nThis standard\
    \ was proposed with the consideration of higher speed\nrequirements. Later, this\
    \ standard increased WiFi network\nachievable speeds above what was made possible\
    \ by earlier\nstandards. Speciﬁcally, it can offer support for a 10 Gbps data\
    \ rate,\nconsistency, and low power consumption. It operates using\nMU-MIMO and\
    \ MU-OFDMA multi-user technologies, which\nenables a single AP and its antenna\
    \ to send data concurrently to\nseveral end devices. Although the 802.11ac standard\
    \ is where\nMU-MIMO technology was ﬁrst introduced, 802.11ax now allows\nfor groups\
    \ of up to eight clients. In addition, this standard also\nsuggests several improvements\
    \ in spatial reusing policies and\npower-saver schemes [97].\nWiFi-6\n* ARS: Adaptive\
    \ Rate Selection, CDMA: Code Division Multiple Access; DSSS: Direct Sequence Spread\
    \ Spectrum;\nEDCA: Enhanced Distributed Channel Access; HCCA: HCF-Controlled Channel\
    \ Access; APSD: Automatic\nPower Save Delivery; APs: Access Points; MU-MIMO: Multi-User,\
    \ Multiple Input, Multiple Output; VHT: Very\nHigh Throughput; CTO: Cellular Trafﬁc\
    \ Ofﬂoading; MU-OFDMA: Multi-User Orthogonal Frequency Division\nMultiple Access.\n\
    Electronics 2023, 12, 2490\n25 of 63\n4.2. IEEE 802.15.1\nThe IEEE 802.15.1 (WPAN\
    \ protocol) uses the 2.4 GHz spectrum and a master/slave\ntime division duplex\
    \ mechanism that operates smoothly in the 10 to 100 m range with a\n1 Mbps data\
    \ rate. This technology uses modest data rates for short-range services designed\n\
    to use less power. Recent implementations of this technology include Bluetooth\
    \ and\nBluetooth Low Energy (BLE), offering IP connectivity to aid the IoT [98].\
    \ The deployment\nof services offered for tracking and localization devices is\
    \ typically suggested by BLE-based\ndevices, which are recognized as BLE beacons.\
    \ These beacons produce a signal that other\ncompatible devices can pick up between\
    \ 50 and 70 m away. Using such a beacon promises\ngreater indoor localization\
    \ accuracy than other technologies such as WiFi or GPS. They can\nbe used for\
    \ a wide range of services targeted toward information dissemination, the launch\n\
    of points of sale, user tracking, etc., thanks to this capability. Additionally,\
    \ to provide\nspeciﬁc services of interest, it is frequently required to combine\
    \ the BLE technology with\nother technologies such as WiFi [99]. Originally, the\
    \ aim of BLE technology (Bluetooth\nClassic Radio (BCR)) was to provide a continuous\
    \ wireless connection, i.e., BlueTooth\nBasic Rate/Enhanced Data Rate (BT BR/EDR).\
    \ It became the perfect option for the IoT\nsince it permits connectivity and\
    \ audio-streaming applications using brief bursts of long-\ndistance radio, which\
    \ lowers the battery consumption of mobile devices (because they need\nnot be\
    \ connected all the time). Using the idea of dual-mode chipsets and the new BLE\n\
    speciﬁcation, smartphones or regular phones can be linked to other heterogeneous\
    \ devices\n(such as headphones) in BR/EDR mode. Otherwise, they can be connected\
    \ to wearables\nin LE mode. A low-power radio called BCR, or BT BR/EDR, intends\
    \ to broadcast data\nacross 79 channels in the 2.4 GHz unlicensed frequency range.\
    \ Wireless audio streaming is\nprimarily made possible through BCR, which has\
    \ evolved into the industry-standard radio\nprotocol for in-car entertainment\
    \ systems, wireless speakers, and headphones. BLE aims to\ntransmit data over\
    \ 40 channels in the 2.4 GHz unlicensed frequency range. To facilitate the\ndeployment\
    \ of dependable and large-scale device networks, BLE seeks to provide support\n\
    for a wide range of communication methods, typically P2P; broadcast; and, most\
    \ notably,\nmesh [100]. This unique Bluetooth feature can be used to create distribution\
    \ and locating\nmaps utilizing ﬁngerprint templates for indoor device and user\
    \ localization. Due to BLE’s\ngreater susceptibility to abrupt fading and substantial\
    \ changes in received signal strength,\nit has been proven that using BLE is more\
    \ efﬁcient than using WiFi-based solutions [99,101].\nHowever, Bluetooth technology\
    \ has a problem with increasing power usage, particularly\nwhen its BR/EDR mode\
    \ is used in an IoT context. This is because this mode allows the\nmaster nodes\
    \ to continuously poll the slave nodes, even when there is no data transmission.\n\
    The researchers [102,103] already brought up this issue, addressed it, and offered\
    \ a variety\nof scheduling techniques for polling the slave nodes. Moreover, the\
    \ BR/EDR mode reveals\na lack of scalability that further restricts the performance\
    \ of the system.\n4.3. LoRA\nThe LoRa protocol was primarily used for WAN applications\
    \ and operated as a low-\ndata-rate, low-power technology on the sub-1 GHz spectrum\
    \ that could go up to 10 km.\nLoRa communicates on three classes of bandwidth:\
    \ 125, 250, and 500 KHz. Even while\nthis technology can function at the largest\
    \ bandwidth class, which further improves data\nrate, it still causes issues with\
    \ high power consumption, a shorter communication range,\nand an increase in the\
    \ likelihood of interference because it is free to operate in a wider\nfrequency\
    \ spectrum. This method is founded on the idea of spread spectrum modulation\n\
    and a CSSM variant with a spreading factor ranging from 7 to 12. The transmission\
    \ range\nwill expand as the spreading factor’s value rises, but the power consumption\
    \ will rise\nas well. The CSSM utilizes complete allocated bandwidth, thereby\
    \ making it resilient to\nchannel noise and multi-path fading, but it does not\
    \ differentiate the noise in the channel\nsuch as DSSS. In contrast to the FSK\
    \ modulation approach, which normally identiﬁes\nsignals that are 8 to 10 dB above\
    \ the noise ﬂoor, the CSSM feature enables this technology\nto sense, perceive,\
    \ and capture signals that are 19.5 dB below the noise ﬂoor [103]. Its\nElectronics\
    \ 2023, 12, 2490\n26 of 63\narchitecture uses a star network topology and includes\
    \ gateways and end nodes. In this\ndesign, end nodes are referred to as slaves\
    \ and run on battery-powered devices with\nlimited power, but gateways are thought\
    \ of as powerful machines that gather data from\nslave nodes. Furthermore, LoRaWAN\
    \ is a communication layer that operates on top of\nLoRA. LoRaWAN incorporates\
    \ the basic LoRa criteria and suggests improved adaptability\nand suitability\
    \ for low-power applications. This layer/technology has advantages over\ncellular\
    \ technologies, which are expected to be battery hungry by the concept. In practice,\n\
    LoRaWAN improved network features and functionalities by addressing the concept\
    \ of\na specialized server (network) and speciﬁcally deﬁning numerous device types\
    \ to meet\nthe needs of each specialized application. Managed communication, packet\
    \ ﬁltering, and\npacket scheduling are all made possible using specialized network\
    \ servers. LoRaWAN\nhas also facilitated bi-directional-employing adaptive transmission\
    \ power and rate, which\naids in optimizing network performance in terms of power\
    \ consumption and throughput.\nThis technology can be employed for a wide range\
    \ of applications, such as smart health\nnursing [104], trafﬁc monitoring [105],\
    \ agriculture monitoring [106], localization [107],\nand smart grid applications\
    \ [108]. In particular, this technology is useful for non-latency-\nsensitive\
    \ applications and those that call for extensive deployments. Haxhibeqiri et al.\
    \ [109]\nand Adelantado et al. [110] emphasized that LoRaWAN is feasible for smart\
    \ metering,\ntracking, and localization-based applications. At the same time,\
    \ it is not so feasible for\nreal-time monitoring and video surveillance.\n4.4.\
    \ WiMAX\nWiMAX can handle high capacity, i.e., a potential peak data rate of 60\
    \ Mbps for an\nentire downlink operation and a rate of 28 Mbps for an entirely\
    \ uplink operation, based on\nthe original IEEE 802.16 air interface standard\
    \ (2004) [111] and the IEEE 802.16e amend-\nment [112]. It can be done using two\
    \ antennas with a channel bandwidth of 10 MHz.\nAdditionally, it may provide support\
    \ for multimedia services with different trafﬁc charac-\nteristics and wide area\
    \ mobility with changing QoS needs. Additionally, it offers a variety\nof QoS\
    \ scheduling options for accommodating heterogeneous trafﬁc, such as Internet\
    \ data\ntrafﬁc, VoIP (Voice over IP), classic audio trafﬁc, and voice and video\
    \ streams [113].\nTable 5 shows the speciﬁed WiMAX standards and their operational\
    \ parameters [114].\nThis standard provides a communication channel between geographically\
    \ separated de-\nvices. As a result, the maximum achievable covered distance ranges\
    \ between 30 km and\n100 km. However, this technology has some drawbacks, such\
    \ as high installation costs\nand the possibility of complications and irregularities\
    \ when dealing with high-deﬁnition\nmultimedia trafﬁc.\nWireless network trafﬁc\
    \ has recently increased extraordinarily due to the rapid pro-\nliferation of\
    \ smart handheld devices, sensors, and actuators. These devices, along with\n\
    smart controllers, mobile users, and other smart services-based specialized devices,\
    \ are\nthe most common use cases for W-LANs in dense network environments. In\
    \ such a dense\nnetwork environment, interference is a critical issue that must\
    \ be addressed if satisfactory\nperformance and, thus, proﬁcient spatial frequency\
    \ reuse is required. Subsequently, the\nstandards IEEE 802.11 were designed and\
    \ implemented to support these requirements.\nNumerous international organizations,\
    \ including IEEE and 3GPP, adopted and improved\ntheir technologies in response\
    \ to changing needs and the emerging IoT market. For instance,\nthe original IEEE\
    \ 802.11 (WiFi) standard was designed to support and provide superior\nthroughput\
    \ performance to a small number of stations located close to each other, and as\
    \ a\nresult, this technology was not particularly useful for IoT systems. As a\
    \ result, to address\nthe challenges and requirements of IoT, the IEEE 802.11ah\
    \ Task Group (TG) was formed by\nthe IEEE 802.11 MAN/LAN Standards Committee to\
    \ redesign and extend the applicability\nof WiFi standards to IoT scenarios. They\
    \ focused on the critical issue of power-aware\nefﬁcient schemes and protocols\
    \ to extend the functionality and applicability of 802.11-based\nnetworks while\
    \ dealing with a variety of small power-constrained smart outdoor and\nindoor\
    \ devices [55,97].\nElectronics 2023, 12, 2490\n27 of 63\nTable 5. WiMAX standards\
    \ and their operational parameters.\nSpeciﬁc\nStandards\nIEEE 802.16\n(2001) 1\n\
    IEEE 802.16a (2003) 2\nIEEE 802.16b 3\nIEEE 802.16c\n(2002) 4\nIEEE 802.16d\n\
    (2004) 5 (Fixed)\nIEEE 802.16e\n(2005) 6\nIEEE 802.16m\n(PAI) 7\nOperating\nFrequency\n\
    Band\n10–66 GHz (LS\nRF Bands)\n2–11 GHz (LS/ULS RF\nBands) (WMANs)\n5–6 GHz (ULS\n\
    RF Bands)\n10–66 GHz\n2–11 GHz\n(LS/ULS RF\nBands)\n2–6 GHz (LS RF\nBands)\n450–3600\
    \ MHz\n(LS/ULS RF\nBands)\nData Rate (max)\n32–134 Mbps\n(28 MHz)\n75 Mbps max,\
    \ 20 MHz\nchannelization\n75 Mbps\n70 Mbps (20\nMHz)\n75 Mbps\n90 Mbps\n100 Mbps\
    \ (MA)\nand 1 Gbps (FA)\nCoverage Area\n(Max)\n10–50 Km\n45 km\n45 Km\n50 km\n\
    45 km\n100 km\n100 km\nPropagation\nmodel (Channel\nCondition)\nLoS only\nNLoS\n\
    NLoS\nLoS\nLoS/NloS\nNLoS\nNLoS\nChannel\nBandwidth\n20, 25, and 28\nMHz\nSelectable\
    \ between 1.25\nand 20 MHz\n10, 20 MHz (5\nMHz is optional)\n28 MHz\nSelectable\
    \ between 1.5 MHz and 20\nMHz\n5–20 MHz/RF\ncarrier,\nCA-supported\nfeature to\
    \ assist\nin attaining BW\nup to 100 MHz.\nMobility\nSupport\nFixed\nFixed\nFixed\n\
    Fixed\nFixed/nomadic\nPortable/mobile\nversion of\nWiMAX\nPortable/mobile\nversion\
    \ of\nWiMAX.\nTopology\n(MAC\nArchitecture)\nP2MP and Mesh\nAssistance\nMore extended\n\
    coverage than\nWLANs while\nsustaining high\ntransmission\nrates\nVoIP\nLicensed\
    \ exempt\napplications.\nQoS support.\nCreating\nproﬁles\n(systems) for\n10–66\
    \ GHz will\nhelp with\ncompatibility\nrequirements\nfor LoS\nbroadband\nwireless\
    \ access.\nTechnological\nﬁxes and minor\nmodiﬁcations\nto 802.16a\nstandard.\
    \ The\nETSI\nHiperMAN\nstandard was\nmatched with\nthis standard to\nenable\n\
    worldwide\nadoption.\nMobility\n(60–120 km/hr)\nfacility to\nWiMAX. Better\nadaptability\n\
    and improved\nQoS support.\nMany\nadditional\nservice classes.\nIncreases\nmobility\
    \ (350\nkm/hr), and\nguarantees\nsuperior QoS\nservices.\nModulation\nTechniques\n\
    Employed\nQPSK, 16-QAM,\n64-QAM\nBPSK, QPSK, 16-QAM,\n64-QAM\nBPSK, QPSK,\n16-QAM,\n\
    64-QAM\nQPSK, 16-QAM,\n64-QAM\nOFDM,\nOFDMA, QPSK,\n16-QAM,\n64-QAM\nOFDM,\nOFDMA,\
    \ QPSK,\n16-QAM,\n64-QAM,\n256-QAM,\nS-OFDMA\nOFDM,\nOFDMA, QPSK,\n16-QAM,\n64-QAM,\n\
    256-QAM,\nS-OFDMA\nAccess\nScheme/Protocol\nRequest/Grant\nSalient Features\n\
    Overcomes the\ndisadvantages\nof mobile\nnetworks and\nWLANs.\nDesigned to operate\
    \ in\nthe LS and ULS RF\nbands ranging from 2 to\n11 GHz (to make it\noperable\
    \ in low\nfrequency ranges). As a\nresult, gives WiMAX\nimplementations more\n\
    ﬂexibility while\nmaintaining data rate\nand transmission range.\nIncreases the\n\
    amount of\nspectrum the\ntechnology may\nuse in the 5–6\nGHz RF channels\nand\
    \ provides\nQoS support.\nMore speciﬁcs\nabout this\ntechnology\nwere\nstandardized,\n\
    which promotes\ninteroperability\nby encouraging\nmore consistent\nimplementa-\n\
    tion.\nComprises\nminor\nenhancements\nand ﬁxes to\n802.16a\nstandard. This\n\
    extension also\nmakes system\nproﬁles for the\n802.16a device\ncompliance\ntesting.\n\
    Designed to\nstandardize\ncommunication\nbetween\ncarriers’ mobile\ndevices and\n\
    ﬁxed base\nstation, instead\nof between base\nstations and\nstatic receivers.\n\
    Designed to\nincrease the\nmobility facility\n(typically more\nthan IEEE\n802.16e).\n\
    Moreover,\nenables the use\nof numerous\nadvanced\nantenna\nconceptions i.e.,\n\
    beamforming\nand MIMO.\n1: LS: Licensed Spectrum, RF: Radio Frequency, LoS: Line\
    \ of Sight, QPSK: Quadrature Phase Shift Keying,\nQAM: Quadrature Amplitude Modulation.\
    \ 2: LS: Licensed Spectrum, ULS: UnLicensed Spectrum, RF: Radio\nFrequency, WMANs:\
    \ Wireless MANs, NLoS: Non-Line of Sight, VoIP: Voice over IP, BPSK: Binary Phase-Shift\n\
    Keying, QPSK: Quadrature Phase Shift Keying, QAM: Quadrature Amplitude Modulation.\
    \ 3: ULS: UnLicensed\nSpectrum, RF: Radio Frequency, NLoS: Non-Line of Sight,\
    \ BPSK: Binary Phase-Shift Keying, QPSK: Quadrature\nPhase Shift Keying, QAM:\
    \ Quadrature Amplitude Modulation. 4: LoS: Line of Sight, QPSK: Quadrature Phase\n\
    Shift Keying, QAM: Quadrature Amplitude Modulation. 5: LS: Licensed Spectrum,\
    \ ULS: UnLicensed Spectrum,\nRF: Radio Frequency, LoS: Line of Sight, NLoS: Non-Line\
    \ of Sight, OFDM: Orthogonal Frequency Division\nMultiplexing, OFDMA: Orthogonal\
    \ Frequency Division Multiple Access, QPSK: Quadrature Phase Shift Keying,\nQAM:\
    \ Quadrature Amplitude Modulation. 6: LS: Licensed Spectrum, RF: Radio Frequency,\
    \ NLoS: Non-Line of\nSight, P2MP: Point-to-MultiPoint, OFDM: Orthogonal Frequency\
    \ Division Multiplexing, OFDMA: Orthogonal\nFrequency Division Multiple Access,\
    \ QPSK: Quadrature Phase Shift Keying, QAM: Quadrature Amplitude\nModulation,\
    \ S-OFDMA: Scalable Orthogonal Frequency Division Multiple Access. 7: PAI: Progressed\
    \ Air\nInterface, LS: Licensed Spectrum, ULS: UnLicensed Spectrum, RF: Radio Frequency,\
    \ MA: Mobile Applications,\nFA: Fixed Applications, NLoS: Non-Line of Sight, CA:\
    \ Carrier Aggregation, BW: BandWidth, P2MP: Point-to-\nMultiPoint, Orthogonal\
    \ Frequency Division Multiplexing, OFDMA: Orthogonal Frequency Division Multiple\n\
    Access, QPSK: Quadrature Phase Shift Keying, QAM: Quadrature Amplitude Modulation\
    \ S-OFDMA: Scalable\nOrthogonal Frequency Division Multiple Access.\nElectronics\
    \ 2023, 12, 2490\n28 of 63\n4.5. Challenges in IoT Communication Using the TCP/IP\
    \ Protocol Suite\nIn IoT, smart sensing motes, devices, and actuators share unique\
    \ features such as\nconstrained memory, power, and processing capabilities; the\
    \ need for facilitating real-time\nrequirements of smart applications; extremely\
    \ vulnerable radio environments; and little to\nno human involvement after deployment\
    \ [115]. By enabling communication amongst these\ndevices utilizing low-power-cost\
    \ technologies, a new infrastructure for deployed smart\nservices has been formed.\
    \ Researchers [116] argued that the TCP/IP protocol suite might\nprovide a solution\
    \ and be ﬂexible enough for a variety of evolving IoT communication\nscenarios.\
    \ Unfortunately, there were additional challenges that network administrators,\n\
    designers, and researchers had to overcome. Researchers were searching for the\
    \ best way\nto install IPv6-based sensor motes that can effectively/minimally\
    \ use the system’s limited\nresources (i.e., power and bandwidth). Because of\
    \ such power constraints, researchers\nhighlighted the requirements of low-power\
    \ Layer-2 technologies (i.e., BLE, IEEE 802.15.4)\nand low-power WiFi usage. In\
    \ contrast with traditional Ethernet links, these technologies\noperate with smaller\
    \ maximum transmission unit (MTU) sizes and slower transmission\nspeeds. IoT network\
    \ protocol designers faced a problem in adapting to and determining\nthe ideal\
    \ MTU size. Another obstacle is that IoT networks often are based solely on wireless\n\
    networks and thus they can only communicate using wireless mesh technologies.\
    \ This\nvulnerability brings extra challenges in front of TCP/IP architecture:\n\
    (1)\nThe current IP addressing model cannot assist mesh communication (since it\
    \ relies on\na multi-link subnet prototype) at all.\n(2)\nIn mesh communication,\
    \ the multicasting and broadcasting communication methods are\nquite expensive,\
    \ power-demanding, and prohibitive as the network nodes are extremely\npower constrained.\
    \ Moreover, unicasting is the only remaining alternative method.\n(3)\nUnicasting\
    \ is power intensive in and of itself because it may take many hops while\nforwarding\
    \ and may wake up an excessive number of nodes that are asleep. Notably,\nidle\
    \ nodes and hops can modify the radio state’s operation mode to save power. Ad-\n\
    ditionally, a large amount of power is used and saved by a node during transmission,\n\
    reception, overhearing, idle, and sleeping phases [117]. However, to ensure successful\n\
    delivery, we cannot just alter the operational modes. Instead, it requires effective\n\
    coordination and intricate synchronization [117,118].\n(4)\nThere is a high requirement\
    \ for scalable routing/forwarding schemes for IP communi-\ncation to take place\
    \ over mesh architectural systems.\n(5)\nFor many IoT applications requiring data\
    \ prioritizing and customized control, original\nTCP-suited features such as those\
    \ operational on ﬁxed MSS sizes (such as MTU sizes)\nthat further lead to silly\
    \ window syndrome or in-order byte-stream delivery to ensure\ndependability, are\
    \ unsuitable [119]. Nonetheless, the IETF started deﬁning standard\nInternet protocols\
    \ such as RPL [120] for such specialized environments to minimize\nprotocol overheads\
    \ that impair the computing ability and memory management of\nthese specialized\
    \ resource-constrained devices.\nWiFi-based infrastructure networks enable backhauling\
    \ support, which helps estab-\nlish and sustain seamless connectivity among smart\
    \ IoT devices. In smart home wireless\nnetworks, this form of connectivity can\
    \ be provided through TCP connections. The TCP/IP\nprotocol suite supports dependable\
    \ data delivery and congestion control strategies to main-\ntain network throughput\
    \ performance via TCP at Layer-4. TCP is a protocol that has been\nregularly modiﬁed\
    \ and improved over the years to effectively transport large amounts of\nbyte-stream\
    \ in-ordered data via resilient P2P connections with comparatively lower latency\n\
    needs. IoT services deal with atypical communication patterns, for which TCP/IP\
    \ protocol\nsuite-based protocols, such as TCP, are unable to handle such patterns\
    \ adequately [119].\nThere are severe problems that TCP faces when it deals with\
    \ an IoT application:\n(1)\nTCP connection establishment and termination (three-way\
    \ handshaking) incur signiﬁ-\ncant overhead in the system as most communication\
    \ in an IoT application includes\nthe transmission of brief segments and relatively\
    \ little data.\nElectronics 2023, 12, 2490\n29 of 63\n(2)\nTCP functionality needs\
    \ resilient P2P connections. It is impossible to sustain these con-\nnections\
    \ in an IoT network environment because smart sensors and other connected\ndevices\
    \ switch their mode of radio state from active to sleep phase persistently [119].\n\
    (3)\nSome IoT applications might need broadcast and multicast communication patterns,\n\
    and enabling such patterns via TCP will result in substantial network overhead\
    \ in the\nentire IoT system and high-power consumption.\n(4)\nSome IoT services\
    \ have very granular delay requirements, and any extra delay in\nthe form of connection\
    \ establishment or MSS creation (waiting for data to ﬁll the\nentire MSS) is completely\
    \ unacceptable for their performance. Thus, TCP is unable to\nprovide much support\
    \ for these IoT services.\n(5)\nIoT applications that rely on wireless communication\
    \ scenarios must deal with crit-\nical wireless channel characteristics such as\
    \ channel error, interference, and wire-\nless interface properties that result\
    \ in buffer-induced, channel-induced, link-layer\ncontention-induced, and collision-induced\
    \ packet losses. When TCP operates in such\na setting, its stringent in-order\
    \ delivery requirements and retransmission policies\n(i.e., fast retransmission)\
    \ may occasionally result in very serious system problems\nsuch as Head-of-Line\
    \ (HoL) or Receiver Buffer Blocking, which ultimately results in\na reduction\
    \ in throughput, delay, and power consumption performance [121–124].\nFurthermore,\
    \ wireless MAC methods that use MAC-level retransmissions may fur-\nther impair\
    \ TCP’s performance, if Layer-2 retransmission latency exceeds the TCP\nRetransmission\
    \ Time Out timer.\nSome standards, such as BACnet/IP [125], were proposed to implement\
    \ Layer-4\nfunctionalities at the Application Layer (AppL) itself and proposed\
    \ to utilize UDP as an\nunderlying Layer-4 protocol. Managing packet losses should\
    \ depend on an application’s\nrequirements, which may vary from application to\
    \ application. However, TCP and its\nupdated variants rely on the concept of data\
    \ delivery deferment and try to perform retrans-\nmissions from an already created\
    \ copy in the sender buffer. However, this is not the only\napproach to dealing\
    \ with packet losses in the network. Another method is for AppL to\naccept packet\
    \ delivery that is not completely ﬂawless and proceed with its current opera-\n\
    tions. This feature will be helpful in real-time audio and video distribution.\
    \ Additionally,\nretransmission is an additional option. However, AppL should\
    \ handle this retransmission\nrather than an underlying Layer-4 protocol such\
    \ as TCP. In terms of buffering the lost data\nbits, doing so enables the source\
    \ application to reconstruct them. Furthermore, in situations\nwhere real-time\
    \ services are severely constrained, the transmitting application may transmit\n\
    fresh data instead of retransmitting lost data to “repair” the effects of the\
    \ initial loss [126].\nClark and Tennenhouse [126] concluded these concepts and\
    \ subsequently introduced the\nconcept of Application Level Framing (ALF). Implementing\
    \ Layer-4 facilities at AppL itself\nbrings the idea of employing ALF into the\
    \ system. Hence, utilizing the notion of ALF,\na network can recognize individual\
    \ Application Data Units (ADUs), and subsequently\ncan offer support for ﬂexible\
    \ Layer-4 facilities, i.e., employing adaptive retransmission\nprocedures for\
    \ diverse forms of ADUs and disseminating data more effectively by using\nin-network\
    \ caching. Unluckily, the TCP/IP protocol suite forbids applications from adding\n\
    any application semantics into network-level packet structure. Therefore, it fails\
    \ to provide\nsupport for the ALF scheme [119].\n4.6. Compound TCP for IoT\nCompound\
    \ TCP [127] was initially designed to offer support for improved channel\nutilization\
    \ and fairness performances. It will play a signiﬁcant role in home networks with\n\
    WiFi-assisted smart and standard devices [115,128].\nPokhrel and Williamson [115]\
    \ studied the effectiveness of a compound TCP over an\nIoT scenario involving\
    \ sensors and other devices (i.e., smartphones, laptops, PC, and home\nappliances).\
    \ They analyzed and evaluated the scenario improving the performance of con-\n\
    nections made using the examined TCP variant across infrastructure WiFi networks\
    \ in the\npresence of signiﬁcant buffer-overﬂow-induced losses and severely degraded\
    \ transmission\nElectronics 2023, 12, 2490\n30 of 63\nchannel circumstances. The\
    \ authors also addressed the varying bandwidth requirements\nfor all IoT devices\
    \ as well as ubiquitous connectivity, ranging from traditional bandwidth-\nhungry\
    \ Internet devices to low-power gadgets. The authors of [129] demonstrated a\n\
    thorough evaluation of the steady-state performance of TCP via WiFi-assisted classical\n\
    devices considering the situations of high-buffer-overﬂow-induced losses and signiﬁcantly\n\
    deteriorated transmission channel conditions. The authors of [115,129] suggested\
    \ models\nthat aided in capturing the dynamics of congestion and ﬂow control of\
    \ several concurrently\nrunning competitive long-lived compound TCP connections.\
    \ In evaluating and developing\nthese models, they considered MAC-level retransmissions,\
    \ link-layer contention, channel\nfailures, and collision. The authors of [130]\
    \ utilized a transient model suggesting a new\nqueue management scheme to capture\
    \ the interactions of short-lived TCP ﬂows (the most\nworkable ﬂows in IoT scenarios)\
    \ over conventional trafﬁc patterns over WiFi networks.\nHowever, the performance\
    \ of TCP in WiFi networks is constrained, especially when using\na single shared\
    \ Access Points (APs). As a result, TCP might not be able to scale well and\n\
    provide superior performance in wide-area Industry 4.0 networks, especially when\
    \ wireless\nchannels are often reused by several APs [131].\n4.7. Viewpoints of\
    \ Network Layer Routing for IoT Systems\nThe network architectures for IoT are\
    \ heterogeneous and include WiFi, WSNs, Wireless\nMesh Networks (WMNs), Vehicular\
    \ Networks, and Mobile Communication Networks\n(MCNs) (5G/LTE/4G/3G) [132]. Due\
    \ to the large-scale production of intelligent sensing\ndevices, survivability\
    \ and self-organization of deployed functional networks are essential. A\nWSN\
    \ is deployed for a variety of smart agricultural, environmental, domestic, and\
    \ military\napplications. It is an ad-hoc network with no infrastructure, in which\
    \ the sensor nodes\ncommunicate over multi-hop routing. WSNs run on battery-powered,\
    \ low-power sensors\ncapable of sensing, collecting, processing, aggregating,\
    \ and regulating communication.\nNumerous WSN-based platforms, including MICA2,\
    \ TelosB, and MICAz MOTE, have\nbeen suggested. Therefore, some standards were\
    \ introduced to enable interaction and\nother compatibilities among these numerous\
    \ heterogeneous platforms. For example, the\nIEEE802.15.4 (Zigbee) standard creates\
    \ the WSNs backbone as part of the IoT. WSNs provide\ncritical functionalities\
    \ for developing IoT systems, allowing Low-Powered battery-operated\nEnd Devices\
    \ (LPEDs) with very minimal resources to attach to the Internet. A WSN can be\n\
    considered a special form of LoWPAN consisting of several equipped sensor nodes.\
    \ Due\nto the lack of IP communication infrastructure, interoperability must be\
    \ obtained from the\nviewpoint of WSN and the Internet. To address the interoperability\
    \ issue, various works\nsuggested a standardized arrangement that could enable\
    \ the usage of IP over LoWPAN.\nThe IEEE 802.15.4 standard allows for the interoperability\
    \ for Low power and Lossy\nNetworks (LLNs). The design tenet of this standard\
    \ outlines the physical and data link\nlayers of the network and offers a low-cost\
    \ framework for network operations. To link\nLPEDs to the Internet, 6LoWPAN may\
    \ be used as an adaptation layer to enable sensors\nto implement an IP stack and\
    \ become approachable by other conventional devices over\nthe Internet. This adaptability\
    \ layer also supports end-to-end connectivity, which enables\na variety of applications\
    \ and permits these LPEDs to implement routing and forwarding\nalgorithms at the\
    \ Internet layer. However, the current network layer routing policies cannot\n\
    be supported when the number of nodes grows. Therefore, the RPL protocol [72]\
    \ considers\nthe LLN situation [133]. Most of the nodes in LLNs are resource-constrained,\
    \ and they are\nconnected by some lossy links that only support low data rates.\
    \ These links are thought\nto be extremely unstable and have poor performance\
    \ in terms of packet delivery rates. In\nsuch specialized networks, the trafﬁc\
    \ patterns are often P2MP and MultiPoint-2-MultiPoint\n(MP2MP) rather than just\
    \ P2P [72]. These networks contain hundreds of smart devices.\nThis makes the\
    \ implementation of routing policies more difﬁcult than ever. In addition,\nnumerous\
    \ existing traditional ad-hoc wireless network routing methods, such as DSR and\n\
    AODV, cannot manage these unique situations and unforeseen circumstances. Designing\n\
    and implementing routing in ad-hoc networking settings has been more difﬁcult\
    \ due to the\nElectronics 2023, 12, 2490\n31 of 63\nmobility aspect and the resource\
    \ limitations at wireless nodes. Their forwarding policies’\ndesign principles\
    \ emphasize QoS elements including bandwidth usage and end-to-end\nlatency [134,135].\
    \ The forwarding rules frequently created and applied for WSNs situations\ntake\
    \ into account the increase in the network lifetime by effectively utilizing the\
    \ node\nenergy [117,136]. As these ad-hoc networks were designed to operate and\
    \ maintain solely\ninside their operational infrastructure, this was very feasible.\
    \ However, the interoperability\nof these ad-hoc networks is a major problem when\
    \ such networks are integrated with\nIoT networks. The ad-hoc network integration\
    \ with IoT needs novel routing policies\nthat support scalability and assure QoS,\
    \ fairness, and connectivity between two nodes\n(both in APs and ad-hoc networks)\
    \ with the least amount of power consumption. The\nstandard classical forwarding\
    \ strategies were intended to ensure QoS between a pair of\ndevices/nodes. In\
    \ the case of an IoT environment, the routing procedures should suggest\nenough\
    \ fairness so that each node can sufﬁciently get enough chances to communicate\
    \ with\nnearby APs. For such specialized scenarios, hierarchical routing solutions\
    \ are followed\nto decrease data redundancy and ensure data aggregation. Researchers\
    \ have often raised\nconcerns about the disadvantaged forwarding rules, which\
    \ lead to the consumption of\nexcess energy in networks while taking into account\
    \ mobile and static ad-hoc network\nscenarios. It consequently increases the likelihood\
    \ of frequent network disconnections,\nroute failures, and even network partitioning,\
    \ all contributing to the system’s signiﬁcant\nMAC-level and routing-level overhead\
    \ problems [134,135]. Hence, bearing in mind the\nhigh-power consumption problem,\
    \ many researchers presented numerous smart routing\nparadigms [118,134,135,137].\
    \ Still, many of these suggested schemes failed to achieve the\ndesired QoS.\n\
    Cross-layer design-based recommendations for power consumption and congestion\n\
    control are well-suited design proposals for comprehending the changes in wireless\
    \ channel\nattributes. Therefore, signiﬁcant work has been done in these areas.\
    \ These designs provide\nsupport for dynamically accessing and evaluating extremely\
    \ variable channel parameters\nat lower layers (MAC and PHY) for the Internet/Routing\
    \ and Transport layers to further\noptimize forwarding and congestion window adaptations\
    \ decisions [121,134,135,138–140].\nThe Received Signal Strength Indicator (RSSI)\
    \ indicates how well a device can hear a\nsignal from an AP or router. A network\
    \ layer forwarding policy can effectively utilize the\nRSSI (accessible through\
    \ lower layers dynamically) to assess link quality. AODV and DSR\nare examples\
    \ of the traditional ad-hoc routing protocols used in various smart forwarding\n\
    systems designed for IoT scenarios. The AOMDV IoT [141] and MLB [142] routing\
    \ mecha-\nnisms were suggested for the IoT scenarios and talked about node and\
    \ link disjoint paths\nwhile discovering routes. However, the proposed schemes\
    \ do not shed light and discuss\nanything related to performance issues when there\
    \ is a signiﬁcant level of interference in\nthe network because of trafﬁc running\
    \ parallel onto multiple paths. The abovementioned\ntechniques do not always perform\
    \ well in terms of throughput and end-to-end delay.\nRecently, the scheme [140]\
    \ considered different critical factors such as interference level,\nlink-layer\
    \ contentions, routing load, MAC load, and other performance issues related to\n\
    wireless scenarios. The authors of [140] insisted that multipath load distribution\
    \ policies’\nefﬁciency depends on the distribution (physical) of routes. Nevertheless,\
    \ different possible\ndisjoint routes—those lacking any common nodes or links—might\
    \ be able to interfere\nwith one another due to the radio signals’ predicted broadcasting\
    \ behavior in wireless\ncommunication. Consequently, such separate disconnected\
    \ pathways could be utilized to\nenhance the performance of the network as a whole\
    \ [138,140].\nWhen employing an IoT-based system, the end sensor nodes depend\
    \ on WSN-based\nnetworking connectivity to deliver sensed and collected data from\
    \ smart things to sink\nnodes. These nodes are commonly known as IoT GateWay nodes\
    \ (IoT-GW). To balance\nenergy usage and gather crucial sensor data, numerous\
    \ such static and mobile IoT-GWs\ncan be deployed in the system. In the whole\
    \ system, numerous WSNs, gathering numerous\ntypes of critical data, are connected\
    \ to the Internet [142,143]. Originally, Zigbee speciﬁed\nthree forms of devices:\
    \ Zigbee Coordinator, Zigbee Router, and Zigbee End Device, and\nElectronics 2023,\
    \ 12, 2490\n32 of 63\nthree forms of network topologies: tree, star, and mesh.\
    \ Moreover, the Zigbee stack\nembraces AODV to create paths dynamically. In the\
    \ case of star network topology, the\nReduced and Fully Functional Devices (i.e.,\
    \ RFDs and FFDs) can communicate with the\nPAN central coordinator only. They\
    \ are not capable of communicating with one another.\nHere, the PAN coordinator\
    \ may be powered by mains, while the RFDs and FFDs run on\nlow-powered limited\
    \ battery devices. Moreover, in the case of the mesh network topology,\nany device\
    \ can communicate to within-range devices at a point of time. Moreover, this\n\
    topology contains a PAN coordinator, which can communicate with other RFDs and\
    \ FFDs.\nFurthermore, this networking topology offers support for the usage of\
    \ the integrated\nforwarding scheme united with hierarchical/tree and AODV routing\
    \ procedures. Lastly,\nthe tree (cluster) network topology is a subset form of\
    \ mesh networking topology, consisting\nof RFDs and FFDs (which may act as coordinators).\
    \ However, the FFD count could be\nmore than the RFD count in the network. RFDs\
    \ may attach to tree (cluster) network\ntopology as the end nodes in the system.\
    \ The coordinator FFDs can offer synchronization\nfunctionalities to other connected\
    \ coordinators and devices. However, there will be a single\nPAN coordinator amongst\
    \ these coordinators [144].\n4.8. IoT Application Protocols\nEach IoT application\
    \ is based on IoT application layer protocols for data transfer.\nThese protocols\
    \ can be the following:\n•\nRepresentational State Transfer Hypertext Transfer\
    \ Protocol (REST HTTP): HTTP [145] is\nthe primary client/server protocol that\
    \ adopts the request/response model. HTPP has\nbeen related to the REST architecture\
    \ [146] to ease the interaction between dissimilar\nentities over web-based services.\
    \ The mixture of HTTP and REST enables IoT devices\nto make their status readily\
    \ available in terms of the standardized CRUD (create, read,\nupdate, delete)\
    \ functions [147]. The CRUD functions are mapped to the POST, GET,\nPUT, and DELETE\
    \ techniques of HTTP, correspondingly. In this fashion, we can build\na REST model\
    \ for dissimilar IoT devices [148].\n•\nConstrained Application Protocol (CoAP)\
    \ [149]: It is a lightweight RESTful protocol lately\nstandardized by the Internet\
    \ Engineering Task Force (IETF). CoAP is used by IoT\ndevices for IP-based, HTTP-like\
    \ interactions. It uses UDP with acknowledgment mes-\nsages to set up reliable\
    \ communication based on a request/response interaction. It has\nreduced complexity,\
    \ and thus it is suitable for resource-constrained IoT applications\nand machine-to-machine\
    \ (M2M) communication.\n•\nMessage Queuing Telemetry Transport (MQTT) [150] is\
    \ established for IoT messaging.\nAccording to MQTT design principles, network\
    \ bandwidth and device resource re-\nquirements should be kept to a minimum while\
    \ also aiming to assure dependability\nand some level of delivery assurance. Since\
    \ June 2016, MQTT has been recognized by\nISO as a standard (ISO/IEC 20922). The\
    \ protocol continues to progress by formalizing\npopular capability options and\
    \ adding new functionalities. The most recent version,\nMQTT v5.0, was released\
    \ in 2018. MQTT operates according to a publish/subscribe\nparadigm. Clients connect\
    \ to a centralized broker when using MQTT.\n•\nOpen Platform Communications Uniﬁed\
    \ Architecture (OPC UA) [151]: This interoper-\nability standard is used for the\
    \ secure and reliable exchange of data in the industrial\nautomation domain and\
    \ other industries. It is platform independent and ensures\nthe seamless ﬂow of\
    \ information among IoT devices from multiple vendors. It sup-\nports two different\
    \ communication methods: the Client/Server method as well as\nPublish/Subscribe\
    \ (e.g., over UDP or MQTT) to mainly meet different industry re-\nquirements from\
    \ the production systems to edge and cloud scenarios. Today, the main\nIoT vendors\
    \ including IBM, AWS, Google Cloud, Microsoft, and SIEMENS leverage\nsecure, standardized\
    \ information exchange in edge-to-cloud applications based on\nOPC UA.\n•\nExtensible\
    \ Messaging and Presence Protocol (XMPP) [152]: This extensible protocol is\n\
    based on text messages that use XML (Extensible Mark-up Language), through which\n\
    Electronics 2023, 12, 2490\n33 of 63\nit can implement both request/response and\
    \ publish/subscribe methods by using\nsuitable extensions. XMPP exchanges instant\
    \ messages between clients, and this\nhappens in real-time using a push mechanism\
    \ to avoid increasing unnecessary network\nloads. XMPP also determines the state\
    \ of an XMPP entity as online, ofﬂine, busy, etc.\n•\nAdvanced Message Queuing\
    \ Protocol (AMQP) [153]: An open standard for passing\nbusiness messages between\
    \ applications or organizations using TCP. It connects sys-\ntems, feeds business\
    \ processes with the information they need, and reliably transmits\nonward the\
    \ instructions that achieve their goals using the point/point and pub-\nlish/subscribe\
    \ interaction modes. AMQP was designed to achieve the main goals of\nmessage orientation;\
    \ queuing; routing; security; reliability; and interoperability.\n•\nData Distribution\
    \ Service (DDS) [154]: DDS was developed by the Open Management\nGroup (OMG).\
    \ DDS is a real-time M2M protocol that enables dependable, high-\nperformance,\
    \ interoperable, scalable data exchanges using a publish–subscribe pattern.\n\
    DDS provides low-latency data connectivity, high reliability, and scalability\
    \ in publish–\nsubscribe and request/response patterns over TCP and UDP. The needs\
    \ of various\nIoT applications requiring real-time data exchange can be addressed\
    \ using DDS. Such\napplications are air trafﬁc control, transportation systems,\
    \ autonomous vehicles, and\nsmart grid management.\nLastly, Glaroudis et al. [155]\
    \ provided a comparison among IoT application protocols\nin terms of well-accepted\
    \ key performance indicators and discussed their suitability in the\nframework\
    \ of smart farming.\n5. Networking Architectures and Protocols\n5.1. Generic Architectures\n\
    Zanella et al. [37] provided an in-depth analysis of an urban IoT’s enabling technolo-\n\
    gies, protocols, and architecture. They also demonstrated the implementation of\
    \ an IoT\nisland as a proof-of-concept in the Italian City of Padova. In the IoT,\
    \ two methods provide\ndata access to objects/things. The ﬁrst involves deploying\
    \ multi-hop mesh networks with\nshort-range communication among network nodes\
    \ using unlicensed frequency. The second\ninvolves using licensed frequency band\
    \ long-range cellular technologies (e.g., 2G/GSM).\nCentenaro et al. [156] presented\
    \ a hopeful alternative solution (i.e., a new type of wire-\nless connectivity)\
    \ called Low-Power Wide Area Networks (LPWANs). LPWAN is based\non a star topology\
    \ characterized by low-rate, long-range transmission technologies in\nthe unlicensed\
    \ sub-GHz frequency bands. The authors considered LPWAN to provide\nconnectivity\
    \ in the IoT scenario for a characteristic SCA. Furthermore, they discussed\n\
    the advantages of LPWAN over well-known methods regarding effectiveness, efﬁciency,\n\
    and architectural design. Leccese et al. [157] created a Raspberry-Pi Card-controlled\
    \ SCA\nthat uses a ZigBee Sensor Network and WiMAX to provide completely controlled\
    \ street\nlighting. Sanchez et al. [158] described SmartSantander, an IoT experimental\
    \ research\nfacility that was deployed in Santander City, Spain. SmartSantander\
    \ supports testing\nproposed protocols, services, and conﬁgurations in a realistic\
    \ setting at an appropriate\nscale. Machine-to-machine (M2M) communication is\
    \ a signiﬁcant part of IoT. Vilajosana\nand Dohler [159] reviewed currently used\
    \ smart city M2M technologies (i.e., sensors, data\nloggers, wireless modems,\
    \ and gateway). They considered one of the most famous deploy-\nment use cases,\
    \ i.e., smart parking. In any IoT environment for smart cities, a huge amount\n\
    of M2M communication requests occur. Unfortunately, conventional network gateways\n\
    cannot face this challenge. Huang et al. [160] presented an admission control\
    \ model for\nM2M communications. Their model differentiates all M2M requests into\
    \ delay-sensitive\nand delay-tolerant. Then, it aggregates all delay-tolerant\
    \ requests by routing them into\none low-priority queue, aiming to reduce the\
    \ number of requests from various devices\nto the access point in the IoT for\
    \ smart cities. Silva et al. [161] developed the bottom-up\narchitecture after\
    \ analyzing a variety of existing architectures. This architecture has four\n\
    layers: sensing, transmission, data management, and application. Each layer integrates\n\
    security modules to protect sensitive data. The sensing layer, located at the\
    \ bottom of the\nElectronics 2023, 12, 2490\n34 of 63\narchitecture, collects\
    \ data from physical devices. The transmission layer is located above\nthe sensing\
    \ layer. Several communication technologies are used to transmit data from the\n\
    transmission layer to the (upper) data management layer. The data management layer\n\
    performs data fusion, data analysis, data processing, and data storing. It stores\
    \ valuable\ninformation that various applications use at the application layer\
    \ to provide services.\nThe majority of the above works mainly focus on a single\
    \ characteristic, such as quality\nof service [162].\nMarques et al. [163] proposed\
    \ a generic, multilevel IoT-based smart cities infrastructure\nmanagement architecture\
    \ that allows the integration of physical objects, communication\ninfrastructure,\
    \ cloud platform, and IoT-based services in a pervasive way. This architecture\n\
    (Figure 4) is generic and includes four layers: (1) Physical Objects, (2) Communication,\n\
    (3) Cloud Platform, and (4) Services.\nElectronics 2023, 12, x FOR PEER REVIEW\
    \ \n35 of 65 \n \ndata management layer. The data management layer performs data\
    \ fusion, data analysis, \ndata processing, and data storing. It stores valuable\
    \ information that various applications \nuse at the application layer to provide\
    \ services. \nThe majority of the above works mainly focus on a single characteristic,\
    \ such as \nquality of service [162]. \nMarques et al. [163] proposed a generic,\
    \ multilevel IoT-based smart cities infra-\nstructure management architecture\
    \ that allows the integration of physical objects, com-\nmunication infrastructure,\
    \ cloud platform, and IoT-based services in a pervasive way. \nThis architecture\
    \ (Figure 4) is generic and includes four layers: (1) Physical Objects, (2) \n\
    Communication, (3) Cloud Platform, and (4) Services. \n \nFigure 4. Architecture\
    \ design. Adapted from [163]. \n1. \nThe Physical Objects Layer enables IoT sensors\
    \ to collect data that will feed the smart \ncity architecture with information\
    \ used to offer services. After the sensors collect \ndata, a Communication Device\
    \ is used to collect sensor data. A communication de-\nvice can implement different\
    \ technologies (e.g., RFID, Bluetooth, and Zigbee). Sen-\nsor data are processed\
    \ by a NodeMCU, which communicates with a Local Pro-\nFigure 4. Architecture design.\
    \ Adapted from [163].\n1.\nThe Physical Objects Layer enables IoT sensors to collect\
    \ data that will feed the smart\ncity architecture with information used to offer\
    \ services. After the sensors collect data,\na Communication Device is used to\
    \ collect sensor data. A communication device can\nimplement different technologies\
    \ (e.g., RFID, Bluetooth, and Zigbee). Sensor data\nElectronics 2023, 12, 2490\n\
    35 of 63\nare processed by a NodeMCU, which communicates with a Local Processing\
    \ unit\nresponsible for gathering information used by the application providing\
    \ a service.\nThe local processing unit brings elements of edge computing, as\
    \ it pushes part of the\ncomputation to edge nodes instead of relying on concentrating\
    \ all the computation in\na centralized remote server.\n2.\nThe Communication\
    \ Layer: The architecture supports a variety of network access\ntechnologies.\
    \ The communication layer supports the implementation of various\nwireless technologies.\
    \ The local processing unit located at the Physical Objects Layer\ndeﬁnes the\
    \ technology to be used and relays data to the communication layer using\nthe\
    \ interface of a network access point.\n3.\nThe Cloud Platform Layer provides\
    \ three services: processing, database queries, and\ndata storage. In the context\
    \ of providing services for smart cities, each of these services\ncan be dynamically\
    \ allocated to satisfy the needs of various applications. Notably,\nonly some\
    \ applications and service types require a cloud platform to operate correctly.\n\
    This layer is offered as part of the infrastructure provided, and its implementation\n\
    is optional.\n4.\nThe Services Layer implements four groups, which are called\
    \ classes of services:\n(I) Surveillance, (II) Transportation and Logistics, (III)\
    \ Infrastructure, and (IV) Tech-\nnology. In each class, different kinds of applications\
    \ can be implemented to deal with\nthe challenges of smart cities.\nThis architecture\
    \ is a generic solution, so the underlying layers are designed to offer\nsupport\
    \ to the applications. Therefore, it can be adapted to the speciﬁc implementa-\n\
    tion of a given service. To this end, the authors adapted their architecture to\
    \ a waste\nmanagement scenario.\nAnother multi-level smart city architecture [164]\
    \ was built on semantic web technolo-\ngies, and its design is mostly used in\
    \ smart city wireless sensor network applications. Data\ncollection, data processing,\
    \ integration and reasoning, and device control and alerts make\nup its four layers.\
    \ Using ontology, a data model, at the network’s edge, Gheisari et al. [165]\n\
    suggested a novel architecture for IoT devices in the smart city that protects\
    \ privacy.\nSaadeh et al. [166] proposed a four-layer architecture for mobile\
    \ object authentication in the\ncontext of IoT smart cities. Their architecture\
    \ is based on the applicability of a proposed hier-\narchical elliptic curve identity-based\
    \ signature authentication protocol. Naranjo et al. [167]\npresented a Fog-based\
    \ smart city network architecture called FogC Architecture Network\n(FOCAN). To\
    \ reduce latency and increase the efﬁciency of services among things with\nvarious\
    \ capabilities, FOCAN is a multi-tier framework in which the applications operating\n\
    on things collaborate to compute, route, and interact with one another through\
    \ the smart\ncity environment. One of FOCAN’s primary beneﬁts is that the IoT\
    \ device can deliver\nservices effectively and with less energy consumption.\n\
    5.2. SDN-IoT Architectures\nSoftware-deﬁned networking (SDN) [168] is an approach\
    \ to enable ﬂexible and efﬁ-\ncient network conﬁguration to enhance a network.\
    \ SDN can provide many advantages\nfor conﬁguring city networks to support different\
    \ applications. For example, SDN can\nimprove the QoS of city networks against\
    \ link failures [169] and meet smart city latency de-\nmands [170]. While some\
    \ efforts are investigating this approach for supporting SCAs, there\nis room\
    \ for developing more advanced management and networking mechanisms in SDN\nfor\
    \ efﬁcient, reliable, and secure network conﬁgurations in smart cities. Jazaeri\
    \ et al. [171]\nconsidered the advantages of integrating edge computing, SDN,\
    \ and IoT technologies and\nreviewed different frameworks and platforms.\nLiu\
    \ et al. [172] proposed an architecture that decouples urban sensing applications\n\
    from the physical infrastructure. In their architecture, centralized controllers\
    \ manage\nphysical devices and offer APIs for data acquisition, transmission,\
    \ and processing services\nto develop urban sensing applications. Bi et al. [173]\
    \ proposed a scalable SDN-enabled\narchitecture that integrates a variety of smart\
    \ city components and provides reliable and\nElectronics 2023, 12, 2490\n36 of\
    \ 63\ntimely scheduling for big data transfer to support smart city services.\
    \ They also studied\nthe time-constrained big data transfer scheduling (TBTS)\
    \ problem under this architecture\nand proposed a heuristic with an intelligent\
    \ scheme that can maximize the throughput and\nschedule the multi-ﬂow transfer\
    \ dynamically.\nIoT systems collect and process data vulnerable to availability,\
    \ integrity, and privacy\nthreats. Nguyen et al. [174] proposed a collaborative\
    \ and intelligent-network-based in-\ntrusion detection system (NIDS) architecture,\
    \ namely, SeArch, for SDN-based cloud IoT\nnetworks. SeArch is a security architecture\
    \ in which an arrangement of three layers of IDS\nnodes, i.e., Edge-IDS, Fog-IDS,\
    \ and Cloud-IDS, is introduced with an effective collaboration\namong nodes.\n\
    Blockchain is an innovative solution for increasing data integrity and privacy\
    \ in smart\ncities [175]. Sharma and Park [176] proposed a novel hybrid network\
    \ architecture for the\nsmart city by exploiting the strength of emerging SDN\
    \ and Blockchain technologies. To\nachieve efﬁciency and address the current limitations,\
    \ their architecture is divided into\ncore and edge networks. By designing a hybrid\
    \ architecture, their architecture inherits\nthe strength of centralized and distributed\
    \ network architectures. “PrivySharing” [177]\nis a Blockchain-based innovative\
    \ framework for privacy-preserving and secure IoT data\nsharing in a smart city\
    \ environment. This framework protects data privacy by segmenting\nthe blockchain\
    \ network into different channels, consisting of a limited number of approved\n\
    businesses and handling a certain category of data, such as health, smart auto,\
    \ smart\nenergy, or ﬁnancial information. Additionally, smart contracts contain\
    \ access control rules\nthat regulate who has access to the users’ data within\
    \ a channel. In addition, private\ndata gathering and encryption are used to further\
    \ isolate and safeguard the data within\na channel.\nIslam et al. [178] designed\
    \ a decentralized and distributed architecture for the IoT\necosystem that addresses\
    \ the existing challenges through the use of the technologies\nBlockchain, SDN,\
    \ and Network Function Virtualization (NFV). This energy-aware architec-\nture\
    \ confronts the problems of scalability, ﬂexibility, complexity, monitoring, managing,\n\
    and collecting IoT data and defends against cyber threats.\n5.3. Architectures\
    \ for Smart Grid\nThe automated and intelligent management of the next-generation\
    \ electric power\nsystems determines their effectiveness and efﬁciency. Smart\
    \ Grid (SG) is the name given to\nthe next generation of electricity systems,\
    \ which are anticipated to offer various beneﬁts\nover the current systems in\
    \ terms of digitization, ﬂexibility, intelligence, resilience, sustain-\nability,\
    \ and customization [179]. Smart transmission infrastructures use new technologies\n\
    to improve power quality. Smart control centers monitor and communicate with electric\n\
    devices remotely in real time, while smart substations self-consciously coordinate\
    \ their local\ndevices. The dispatch of electricity to end-users is implemented\
    \ by using the electrical and\ncommunication infrastructures that connect the\
    \ transmission and customer domains. The\ndistribution domain includes distribution\
    \ feeders and transformers to supply electricity.\nIt interacts with much different\
    \ equipment, such as distributed energy resources (DERs),\nplug-in electric vehicles\
    \ (PEVs), automatic metering infrastructure (AMI), and sensors with\ncommunication\
    \ capability. The distribution domain is responsible for delivering electricity\n\
    to energy consumers, user demands, and energy availability. To provide quality\
    \ electricity,\nthe stability of this domain is monitored and controlled.\nTypical\
    \ applications [44] of the smart grid communications network are automatic\nmeter\
    \ reading, demand response, PEVs, substation automation, and DERs/microgrid.\n\
    DERs are tiny energy production and/or storage devices linked to the distribution\
    \ system.\nDistributed generation (DG), distributed storage (DS), or a combination\
    \ of renewable\nand non-renewable sources are all possible sources for DER. Solar\
    \ panels, wind turbines,\ncombustion turbines, fuel cells, battery storage systems,\
    \ etc., are a few examples of DER.\nAn electric power system with one or more\
    \ DER units and loads is referred to as a microgrid.\nElectronics 2023, 12, 2490\n\
    37 of 63\nThe communication infrastructure in the smart grid supports the capabilities\
    \ of the\nsmart grid and complies with performance standards. This infrastructure\
    \ connects a huge\nnumber of electric devices and manages complex device communications.\
    \ As a result, it is\nbuilt in a hierarchical architecture with interconnected\
    \ individual sub-networks, and each\nsub-network is responsible for separate geographical\
    \ regions. The extremely dispersed\nsmaller area networks that support the power\
    \ systems at various locations are connected by\nWANs, which act as the communication’s\
    \ backbone. When the control centers are located a\ngreat distance from the substations\
    \ or the end-users, the real-time measurements made at\nthe electric devices are\
    \ transported to the control centers through the WANs, and in the\nopposite direction,\
    \ the WANs carry out the instruction communications from the control\ncenters\
    \ to the electric devices.\nThe authors of [43] present a communication architecture\
    \ in an SG. This architecture\nincludes (1) an energy smart house with electric\
    \ appliances connected to the smart grid,\n(2) a residential complex with AMI,\
    \ (3) a residential subdivision installed with solar panels,\n(4) a PEV charging\
    \ station, (5) a power substation, and (6) power transmission lines. In this\n\
    architecture, the Internet and ISPs serve as the backbone in connecting the distributed\
    \ sub-\nnetworks. Demertzis et al. [180] presented and categorized the communication\
    \ network\nstandards that have been established for smart grids and should be\
    \ considered in planning\nand implementing new infrastructures. Such standards\
    \ are IEC 61850 for substation\nautomation. This standard is based on open architecture\
    \ and incorporates sampling\nand timing synchronization speciﬁcations based on\
    \ IEEE 1588 in LANs and WANs [181].\nNotably, IEEE 1588 is the standard for a\
    \ precision clock synchronization protocol for\nnetworked measurement and control\
    \ systems [182].\nDue to the widespread use of renewable energy resources (RERs)\
    \ throughout the\npower grid, it is anticipated that electric power distribution\
    \ networks in smart grids would\nundergo signiﬁcant changes to accommodate the\
    \ nature of non-radial power ﬂow. For the\nmost part, the low-voltage distribution\
    \ networks where RERs (such as solar cells) may be\nattached are not monitored\
    \ by the majority of the present supervisory control and data ac-\nquisition (SCADA)\
    \ systems for power grids. For the goal of active monitoring and control,\nAbdrabou\
    \ [183] presented a multi-hop wireless network with a cellular frequency-reuse\n\
    structure that may supply the communication infrastructure to dense low-voltage\
    \ distribu-\ntion networks. A position-based QoS-aware routing protocol was also\
    \ presented as a useful\nmethod for prioritizing data transfer across the newly\
    \ introduced network architecture.\nHetGrid [184] is a unique overlay network\
    \ design with a speciﬁc QoS routing method\nfor power distribution grid applications.\
    \ It delivers QoS assurances across the network\nwhile taking into account three\
    \ factors: bandwidth, latency, and dependability. The authors\ncreated two components\
    \ to accomplish this:\n•\nA multipath routing mechanism that compensates critical\
    \ applications for their high-\nreliability requirements by using end-to-end physically\
    \ disjoint paths, and\n•\nAltruistic resource allocation with the QoS routing\
    \ mechanism that targets communi-\ncation with QoS guarantees for applications\
    \ with strict QoS requirements.\nThe ﬁndings in [184] show that the HetGrid overlay\
    \ network architecture enables ex-\ntremely effective, trustworthy, and QoS-aware\
    \ communication in heterogeneous networks.\nThe major characteristics that set\
    \ SG apart from the standard electrical power grid are\nthe ability to execute\
    \ two-way communication, demand-side management, and real-time\npricing. The present\
    \ SG systems have interoperability problems because they need to\nbe protocol\
    \ independent. Therefore, global communication network management and\nmonitoring\
    \ approaches have been proposed using SDN [185]. Thanks to SDN, network\nadministrators\
    \ may more efﬁciently manage their networks by separating the control plane\n\
    from the data plane. SDN has advanced in SG due to its reliance on communication\n\
    networks. SDN implementation in SG systems has the potential to increase efﬁciency\n\
    and resilience. SDN can assist the SG in integrating several SG standards and\
    \ protocols\nby virtue of its programmability, protocol independence, and granularity\
    \ capabilities to\ncope with varied communication systems. Rehmani et al. [185]\
    \ presented SDN-based\nElectronics 2023, 12, 2490\n38 of 63\nSGC architectures,\
    \ along with case studies. They discussed routing schemes for SDN-\nbased SGC\
    \ and provided a detailed survey of security and privacy schemes applied to\n\
    SDN-based SGC.\nAlam et al. [186] provided a detailed survey on smart grid communication\
    \ networks in\nterms of communication network requirements, architecture, technologies,\
    \ and applications.\nThey proposed a Cognitive Radio (CR)-based Communication\
    \ Network for Smart Grid.\nCR is a software-deﬁned radio (SDR) platform that can\
    \ quickly reconﬁgure its operating\nparameters, such as modulation/demodulation,\
    \ compression algorithm, and error coding\ntechniques, according to changing circumstances\
    \ and requirements, through cognition. In\nsuch an SDR platform, radio transceivers\
    \ can switch functions and operations on demand\nonly. Molokomme et al. [187]\
    \ reviewed architectures that aim to accomplish the various\nand strict QoS requirements\
    \ in SG communication systems.\nWireless communication networks have been motivated\
    \ to harvest energy from\nambient environments and run energy-efﬁciently for economic\
    \ and ecological beneﬁts\nthrough improvements in the smart power grid and the\
    \ advocacy of “green communica-\ntions”. Hu et al. [188] examined recent developments\
    \ in energy harvesting, redistribution,\ntrade, and planning for future wireless\
    \ networks integrating with smart grids. The authors\nconsidered the optimization\
    \ of various energy-harvesting wireless systems as well as tradi-\ntional models\
    \ of renewable energy-harvesting technologies. Moreover, they discussed how\n\
    to distribute redundant (unused) energy generated by cellular networks, plan for\
    \ energy\nunder dynamic pricing when smart grids are in place, and engage in two-way\
    \ energy\ntrading using smart grids.\nFrom a different viewpoint, including IoT\
    \ devices and providing connectivity, au-\ntomation, and monitoring for such devices\
    \ enables SG systems to sustain multiple network\noperations during the generation,\
    \ distribution, transmission, and expenditure of energy.\nNumerous IoT-aided SG\
    \ systems have been proposed in the literature. The survey [189] on\nIoT-aided\
    \ SG systems considers the systems’ current architectures, uses, and prototypes.\n\
    5.4. Architectures for Smart Buildings\nThere are various building applications\
    \ such as heating, cooling, load control, air\nquality, ventilation, lighting,\
    \ water management, and cooking gas management. A smart\nbuilding incorporates\
    \ the major building systems on a common network and functionality\nto provide\
    \ operational efﬁciency, ﬁre safety, and security. A smart building architecture\n\
    (SBA) manages several real-time domains, including automated temperature regulation,\n\
    air cleaning, HVAC systems, and humidity control (i.e., indoor environment regulation\n\
    and monitoring); smart lighting and controlling home appliances (energy management);\
    \ a\nsmart ﬁre detection system; and other building operations. A typical smart\
    \ building [190]\nhas security cameras, lighting sensors, an indoor air quality\
    \ system, a ﬁre alarm system, a\nwater management system, and an energy management\
    \ system. Moreover, it can detect\nintrusion and supports HVAC services.\nDiverse\
    \ SBAs include complex operational systems, sensing, and communication\ntechnologies.\
    \ Such architectures have converged into an IP-based architecture. This con-\n\
    vergence is occurring rapidly with the increased usage of IP-based smart devices\
    \ driven\nthrough IoT concerning conventional building management and smart buildings.\
    \ Tradi-\ntionally, numerous building systems utilized varied forms of networking\
    \ protocols and\ncabling systems. This variety makes the whole system more complex\
    \ and highly infeasible\nfrom both a deployment and a system administration standpoint\
    \ [191]. SBAs entail making\nplans for and assisting with the inclusion of operational\
    \ technologies that improve the\napplication’s, service’s, or provision’s operational\
    \ steps while also boosting the well-being\nof its users. Researchers, policymakers,\
    \ and implementers should pay attention to several\ncrucial issues, such as reliable\
    \ communication/connection procedures, power-efﬁcient\nmeasures, competent security\
    \ measures, efﬁcient sensors and actuators, and data analyt-\nics procedures.\
    \ Amalgamating new systems and technologies with conventional (base)\ntechnologies\
    \ to accomplish the revelation of SBAs, includes, but is not limited to, WSN\n\
    Electronics 2023, 12, 2490\n39 of 63\ndeployment; advanced power-aware trafﬁc\
    \ engineering policies; cloud, edge, and fog com-\nputing paradigms; big data\
    \ engineering and analytics; and human–computer interaction\nprocedures [192].\
    \ The rapid development of ICT technologies has enhanced the connect-\nedness\
    \ of intelligent sensing, actuators, and communication devices to real-time physical\n\
    entities. Recently, smart sensing mechanisms, actuators, and data harvesting technology\n\
    have boosted the area of SBAs proposals. However, choosing the best ICT technologies\
    \ for\na particular smart building domain poses signiﬁcant difﬁculties, including\
    \ heterogeneity\nof IoT devices and applications, workable networking protocols\
    \ and architectures, power\nefﬁciency, and QoS/QoE provisioning [190,193]. One\
    \ solution is the SDN paradigm, which\nmanages the network more efﬁciently than\
    \ a customary one. SDN also assists network\nservices, including storage, routing,\
    \ dynamic bandwidth management, and QoS. Hence,\nthese simpliﬁcations offer a\
    \ creative environment through the implementation of proper\nsoftware tools for\
    \ smart buildings. Network architecture and its implementation for in-\ntelligent\
    \ infrastructure is based on IoT relationships (between IoT in home automation\n\
    and applications) and can be established using smart home Cloud Computing based\
    \ on\nSDN. Recently, Younus et al. [190] proposed an SDN architecture that improves\
    \ critical SB\nparameters such as bandwidth efﬁciency, energy efﬁciency, latency,\
    \ security, and reliability.\nSilva et al. [194] presented a Web of Things (WoT)\
    \ SBA that is integrated with the repre-\nsentational state transfer (RESTful)\
    \ application programming interface (API). The RESTful\nAPI employs HTTP requests\
    \ (e.g., GET, PUT, POST, and DELETE) to access and use WoT\ndata. Regarding network\
    \ performance and smart building power management, the authors\nshowed how their\
    \ recommendation for smart city architecture improved performance.\nSmart sensing\
    \ devices and actuators permit collecting, monitoring, controlling, or\nmodifying\
    \ vital building parameters so that users receive the best QoS/QoE possible. These\n\
    functionalities depend on sensor integration competence and their properties.\
    \ These sys-\ntems comprise signal conditioning circuits, implanted algorithms,\
    \ power, and transceiver\nmodules [195]. Researchers developed such system-based\
    \ SBAs for assessing and regulat-\ning air quality, smart lighting systems, ﬁre\
    \ detection systems, power management, and\nother basic building operations.\n\
    An indoor-air-quality-based SBA considers sensing and actuator-based systems for\n\
    monitoring and regulating air quality parameters. An indoor environmental observing\n\
    system was initially suggested in [196] that observes polluting gases, temperature,\
    \ and\nrelative humidity. Other kinds of such systems have been proposed in [197,198].\
    \ Con-\nsidering smart indoor lighting systems, numerous solutions have been proposed\
    \ in the\nliterature. In SBAs, light sensors manage and track the lighting system\
    \ to satisfy the users’\nneeds. The authors of [199] shed light on power consumption\
    \ reduction via energy-efﬁcient\nsmart lighting systems. Today’s smart building\
    \ employs low-power usage LED-based\nlight sources that last longer than Compact\
    \ Fluorescent Lamps (CFLs) [200]. In reality, the\ndevelopment of control technologies,\
    \ heterogeneous networks, and embedded systems\nhas made it promising to create\
    \ smart innovative lighting systems that can effectively\naddress the problem\
    \ of energy conservation. Researchers have recently begun testing by\nintegrating\
    \ different power-saving techniques in a single illumination system for improved\n\
    energy efﬁciency while enhancing lighting performance without sacriﬁcing user\
    \ satisfac-\ntion. According to the authors of [201], using several cheap detectors,\
    \ as opposed to a\nsingle expensive sensor, would result in improved performance\
    \ and higher power savings.\nConsidering the same motivation, various authors\
    \ [202–204] have suggested similar types\nof smart lighting systems for several\
    \ room types, such as classrooms and ofﬁces. In [205],\nthe authors provide a\
    \ deep and profound study concerning smart lighting systems focusing\non power\
    \ savings procedures and connectivity alternatives as well as the integration\
    \ of\nvisible light communication technology [206].\nRecently, researchers focused\
    \ on two main goals, namely, occupants’ work perfor-\nmance and thermal comfort,\
    \ to propose effective SBAs. Hence, many Occupant-Oriented\nTechnologies (OOT)\
    \ have been put forth by academics who want to maximize thermal\ncomfort while\
    \ conserving energy. OOT-based systems offer a practical way to lessen the\nElectronics\
    \ 2023, 12, 2490\n40 of 63\ndrawbacks of the automatic control used today. In\
    \ practice, thermal comfort analysis is\nbased on parallel objective and subjective\
    \ evaluation. The objective evaluation comprises\nmonitoring, assessing, and recording\
    \ the status of environmental parameters through dedi-\ncated sensors and instruments\
    \ following standardized guidelines. Subjective evaluation\ninvolves monitoring,\
    \ assessing, and recording thermal preference, thermal sensation, and\nthermal\
    \ environment acceptance. Further thermal comfort sensor results as the cumulative\n\
    method to both above-mentioned analysis can be found in [193].\nGreen building\
    \ refers to SBAs with an ambient intelligence system that adjusts to\npredetermined\
    \ circumstances in real-world situations. In this situation, the system makes\n\
    full use of embedded sensors in an environment that can gather data and subsequently\n\
    allow the system to act in accordance with that data. The ambient intelligence\
    \ concept aims\nto conserve natural resources with limited and efﬁcient use of\
    \ them to offer comfort to the\noccupants. Through unconventional energy sources,\
    \ it also meets some of the conventional\nenergy requirements [207]. Many aspects\
    \ of SBAs, such as security, monitoring, and\npower efﬁciency, are the subject\
    \ of extensive study. However, one of the most important\nfunctions of an SB system\
    \ is to control the interior climate, which is typically done by\nHVAC systems\
    \ [208]. The performance of HVAC systems in the instance of commercial\nbuildings\
    \ for frequency regulations has been demonstrated by the authors of [209] for\
    \ this\ncontext. Their demonstrated numerical experiments suggest that 15% of\
    \ rated fan energy\ncan be employed for regulation use while having a minor effect\
    \ on a building’s indoor\ntemperature. The method of computational control for\
    \ passive and active sources was\nused in another scheme [210]. The authors emphasized\
    \ the problem that the ambient and\nactive sources of lighting, heating, ventilation,\
    \ cooling, and shading are not synchronized\nin buildings. Such a computational\
    \ control scheme is also suitable for reducing daily power\nusage. Similarly,\
    \ numerous methods [211–213] considering HVAC systems have been\nproposed with\
    \ respect to frequency regulation, predictive control, and smart controller.\n\
    An IoT-assisted HVAC smart system tracks environmental situations. It also notiﬁes\n\
    when measurements exceed thresholds and provides data on energy usage and consump-\n\
    tion. In addition, it can autonomously turn equipment intermittently at programmed\n\
    times. As individuals spend more time indoors (at home, work, or in other enclosed\
    \ spaces)\nthan outdoors, the air quality inside buildings should be improved\
    \ along with that of the\nexternal surroundings. This is the task of indoor Air\
    \ Quality Monitoring Systems (AQMS).\nThe basic parts of an AQMS (Figure 5) are\
    \ a sensor array, a processing/display unit, a signal\nconditioning circuit, a\
    \ small amount of external memory, and a communication module\nthat is typically\
    \ wireless. A sensor array is a group of specialized micro-sensors that can\n\
    detect certain airborne concentrations of gases such as NOX, SOX, CO2, CO, and\
    \ O3, as\nwell as some essential environmental parameters such as humidity and\
    \ temperature. These\nsensors are connected to a GUI unit that shows the values\
    \ of the real-time indoor air quality\nparameters and an external memory used\
    \ to store real-time data [214]. When deploying\nsuch systems, various communication\
    \ (wireless) modules, including WiFi, ZigBee, and\nLoRAWAN technologies, are considered.\n\
    Electronics 2023, 12, 2490\n41 of 63\nElectronics 2023, 12, x FOR PEER REVIEW\
    \ \n42 of 65 \n \n \nFigure 5. Air Quality Monitoring Sensor System. Adapted from\
    \ [215,216]. \nFigure 6 shows an SBA architecture [217]. The system of this architecture\
    \ collects \nvital information about the various air quality parameters, including\
    \ CO2, CO, particles \n(Particulate Matter PM10 and PM2.5), and some other crucial\
    \ parameters such as hu-\nmidity and temperature. By using gas sensor boards and\
    \ wasp motes, the authors created \na method for collecting and monitoring the\
    \ indoor atmosphere. For monitoring CO2 and \nCO parameters, they also used TGS\
    \ 4161 and TGS 2442 gas sensors. These sensors usually \nwork using the resistive\
    \ heating principle. The TGS 2442 sensor has excellent sensitivity \nto fluctuations\
    \ in CO gas concentration. This sensor’s internal resistance, or “IR”, is in-\n\
    versely proportionate to the amount of CO present. As the CO content rises, the\
    \ IR falls. \nWhile TGS 4161 also offers low power consumption and suggests better\
    \ performance in \ndetecting changes in CO2 gas concentration, the TGS4161 is\
    \ ideally suited for indoor air \ncontrol applications as it can measure 350–10,000\
    \ ppm carbon dioxide. The authors used \nthe DustTrak DRX, a specialized aerosol\
    \ laser photometer that simultaneously measures \nmass and size fraction, for\
    \ PM1 and PM2.5 monitoring purposes. To define and create an \ninterface to the\
    \ deployed sensor for wireless transmission of gathered aerosol data, this \n\
    photometer is connected to a base station device via LAN. The authors also set\
    \ up ZB \n(ENs) at each location that was taken into consideration, which sent\
    \ updates on the air \nquality and aerosols at regular periods to BS (ZBC) that\
    \ had already been set up. \nThis system assesses the indoor air quality to assess\
    \ the current state of the indoor \nenvironment while simultaneously providing\
    \ real-time inputs for HVAC system man-\nagement. The authors also designed a\
    \ toolkit that analyzes real-time air quality data and \ndisplays them through\
    \ meaningful representations to service the SBAs. Likewise, Lozano et \nal. [216]\
    \ proposed another IAQMS technique that considers a star topological architecture\
    \ \n[217]. The ZB (ENs) in this technique is based on the XBee and XBee pro-version\
    \ modules. \nNevertheless, the suggested scheme [216] considers a single pollutant\
    \ only, i.e., suggest-\nFigure 5. Air Quality Monitoring Sensor System. Adapted\
    \ from [215,216].\nFigure 5 shows a typical sensor system for an indoor environment\
    \ for air quality monitoring.\nFigure 6 shows an SBA architecture [217]. The system\
    \ of this architecture collects\nvital information about the various air quality\
    \ parameters, including CO2, CO, particles\n(Particulate Matter PM10 and PM2.5),\
    \ and some other crucial parameters such as humidity\nand temperature. By using\
    \ gas sensor boards and wasp motes, the authors created a\nmethod for collecting\
    \ and monitoring the indoor atmosphere. For monitoring CO2 and\nCO parameters,\
    \ they also used TGS 4161 and TGS 2442 gas sensors. These sensors usually\nwork\
    \ using the resistive heating principle. The TGS 2442 sensor has excellent sensitivity\n\
    to ﬂuctuations in CO gas concentration. This sensor’s internal resistance, or\
    \ “IR”, is\ninversely proportionate to the amount of CO present. As the CO content\
    \ rises, the IR falls.\nWhile TGS 4161 also offers low power consumption and suggests\
    \ better performance in\ndetecting changes in CO2 gas concentration, the TGS4161\
    \ is ideally suited for indoor air\ncontrol applications as it can measure 350–10,000\
    \ ppm carbon dioxide. The authors used\nthe DustTrak DRX, a specialized aerosol\
    \ laser photometer that simultaneously measures\nmass and size fraction, for PM1\
    \ and PM2.5 monitoring purposes. To deﬁne and create an\ninterface to the deployed\
    \ sensor for wireless transmission of gathered aerosol data, this\nphotometer\
    \ is connected to a base station device via LAN. The authors also set up ZB (ENs)\n\
    at each location that was taken into consideration, which sent updates on the\
    \ air quality\nand aerosols at regular periods to BS (ZBC) that had already been\
    \ set up.\nThis system assesses the indoor air quality to assess the current state\
    \ of the indoor en-\nvironment while simultaneously providing real-time inputs\
    \ for HVAC system management.\nThe authors also designed a toolkit that analyzes\
    \ real-time air quality data and displays\nthem through meaningful representations\
    \ to service the SBAs. Likewise, Lozano et al. [216]\nproposed another IAQMS technique\
    \ that considers a star topological architecture [217].\nThe ZB (ENs) in this\
    \ technique is based on the XBee and XBee pro-version modules. Never-\ntheless,\
    \ the suggested scheme [216] considers a single pollutant only, i.e., suggesting\
    \ using\nElectronics 2023, 12, 2490\n42 of 63\na GAC sensor. Conversely, the authors\
    \ of [215] further claimed that they considered seven\npollutants in their proposed\
    \ implementation.\nElectronics 2023, 12, x FOR PEER REVIEW \n43 of 65 \n \n \n\
    ing using a GAC sensor. Conversely, the authors of [215] further claimed that\
    \ they con-\nsidered seven pollutants in their proposed implementation. \n \n\
    Figure 6. IAQMS architecture. Adapted from [217,218]. \nIoE for Smart Building:\
    \ To achieve optimal functionality and energy-efficient per-\nformance, Kim et\
    \ al. [218] offered an overview of the design and implementation of en-\nergy-related\
    \ SB technologies, including energy management systems, renewable energy \napplications,\
    \ and current advanced smart technologies. Undoubtedly, the electricity sec-\n\
    tor of smart cities is impacted by the Internet of Energy (IoE), which aims to\
    \ increase en-\nergy efficiency, prevent energy waste, and enhance environmental\
    \ conditions by inte-\ngrating IoT technologies into distributed energy systems.\
    \ Two examples of IoE technol-\nogy are intelligent sensor use and the incorporation\
    \ of renewable energy sources. As a \nresult, the IoE is becoming a tool for legal\
    \ science to support the goals of a smart city. \nMetallidou et al. [219] discussed\
    \ the factors that prompted the European Union to create \nregulations to make\
    \ it easier to transition current towns into smart cities, starting with \nexisting\
    \ structures. To achieve energy efficiency, the authors suggested a smart building\
    \ \ntemplate that uses IoT technology to manage the performance of all technical\
    \ systems. In \naddition, they suggested an automated remote-control technique\
    \ supported by a cloud \ninterface to enhance the certification of existing buildings\
    \ for energy performance. This \ntechnology reduces time-consuming processes and\
    \ stores the energy performance of each \nbuilding on a cloud platform to make\
    \ decisions and put measures in place. A review of \ncurrent tactics in the field\
    \ of active building energy management systems (BEMS) was \noffered by Mariano-Hernández\
    \ et al. [220]. The authors reviewed articles on several \nBEMS management techniques\
    \ for residential and non-residential buildings, including \nModel Predictive\
    \ Control (MPC), Demand Side Management (DSM), Optimization, and \nFault Detection\
    \ and Diagnostics (FDD). MPC predicts building response to control re-\nquests,\
    \ while DSM is an agreement of actions to improve the energy system on the user\
    \ \nFigure 6. IAQMS architecture. Adapted from [217,218].\nIoE for Smart Building:\
    \ To achieve optimal functionality and energy-efﬁcient per-\nformance, Kim et\
    \ al. [218] offered an overview of the design and implementation of\nenergy-related\
    \ SB technologies, including energy management systems, renewable en-\nergy applications,\
    \ and current advanced smart technologies. Undoubtedly, the electricity\nsector\
    \ of smart cities is impacted by the Internet of Energy (IoE), which aims to increase\n\
    energy efﬁciency, prevent energy waste, and enhance environmental conditions by\
    \ inte-\ngrating IoT technologies into distributed energy systems. Two examples\
    \ of IoE technology\nare intelligent sensor use and the incorporation of renewable\
    \ energy sources. As a re-\nsult, the IoE is becoming a tool for legal science\
    \ to support the goals of a smart city.\nMetallidou et al. [219] discussed the\
    \ factors that prompted the European Union to create\nregulations to make it easier\
    \ to transition current towns into smart cities, starting with\nexisting structures.\
    \ To achieve energy efﬁciency, the authors suggested a smart building\ntemplate\
    \ that uses IoT technology to manage the performance of all technical systems.\
    \ In\naddition, they suggested an automated remote-control technique supported\
    \ by a cloud\ninterface to enhance the certiﬁcation of existing buildings for\
    \ energy performance. This\ntechnology reduces time-consuming processes and stores\
    \ the energy performance of each\nbuilding on a cloud platform to make decisions\
    \ and put measures in place. A review of\ncurrent tactics in the ﬁeld of active\
    \ building energy management systems (BEMS) was\noffered by Mariano-Hernández\
    \ et al. [220]. The authors reviewed articles on several BEMS\nmanagement techniques\
    \ for residential and non-residential buildings, including Model\nPredictive Control\
    \ (MPC), Demand Side Management (DSM), Optimization, and Fault\nDetection and\
    \ Diagnostics (FDD). MPC predicts building response to control requests,\nwhile\
    \ DSM is an agreement of actions to improve the energy system on the user side.\
    \ FDD\nis an automatic procedure of detecting and separating ﬂaws in BEMS to protect\
    \ a system\nfrom additional harm. Moudgil et al. [221] examined cutting-edge academic\
    \ and industrial\nElectronics 2023, 12, 2490\n43 of 63\nresearch to discover signiﬁcant\
    \ technological solutions that improve the integration of IoT\nin building infrastructure\
    \ (BI). Their review also identiﬁes key technical and non-technical\nproblems\
    \ that must be resolved through extensive research for BI to fully incorporate\
    \ IoT.\nThe authors contend that IoT in BI is still not operationally capable.\
    \ IoT and BI stakeholders\nmust make a concerted effort to give modern BI access\
    \ to a generic IoT framework with\ncognitive intelligence and context-aware computing\
    \ capabilities.\n5.5. Smart Water and Pipeline Network Monitoring\nRetroﬁtting\
    \ the traditional water distribution system with smart devices has some\nbeneﬁts,\
    \ including lower utility costs, lower consumer bills, and less water loss [222,223].\n\
    For example, smart water sensors can keep an eye on the pressure online and alert\
    \ utilities\nto pressure changes or large pressure losses in the water network,\
    \ allowing them to remotely\nadjust the pressure to save energy consumption [224].\
    \ Automation can be used for both\noperational procedures and components that\
    \ provide functionality. For instance, when a\nwater problem occurs during operation\
    \ or with the element itself, the smart components\ninform the system center and\
    \ then take action to avert a crash. The water utility can also\ndetermine a sensor’s\
    \ requirement for maintenance or replacement thanks to the automatic\nself-veriﬁcation\
    \ mechanism [225].\nIn [226], the authors suggest an IoT-based smart water grid\
    \ architecture that includes\ntechnical systems, functions, and a hierarchy framework.\
    \ Moreover, this smart water\nsystem (SWS) also comprises smart sensing mechanisms,\
    \ simulation procedures, diag-\nnostic techniques, disposal, warning, and control\
    \ mechanisms. Although an SWS incor-\nporates ofﬂine performance, real-time performance\
    \ is deﬁned by online procedures such\nas online data monitoring, online data\
    \ assimilation, online modeling, online charting,\nand online results output.\
    \ An SWS must have real-time functionality to implement the\nnecessary smart features\
    \ [227]. Researchers put a lot of effort [228] into developing wa-\nter systems\
    \ that operate intelligently. Real-time modeling, real-time sampling, real-time\n\
    controlling, etc., which seek to reduce the lag between system input and system\
    \ output,\nshould be added to the smart performance of SWS. It was discovered\
    \ that using SCADA\nwould considerably increase the data transfer efﬁciency [229].\
    \ A smart water architec-\nture [230] often includes ﬁve layers: (1) the physical\
    \ layer; (2) the sensing and control layer;\n(3) the communication layer; (4)\
    \ the data management layer; and (5) the data fusion layer.\nWithin the framework\
    \ of the GST4Water project, the authors of [230] presented a system\nthat allows\
    \ for receiving consumption data sent by a generic smart meter installed in a\n\
    user’s house and transferring them to a cloud platform. The consumption data are\
    \ saved\nand processed to characterize leakage at the district meter area and\
    \ the individual user level.\nMeanwhile, the processed data are returned to the\
    \ Water Utility and can be used for billing.\nOn the other hand, they provide\
    \ regular feedback to the user, thus gaining full awareness\nof their consumption\
    \ behavior. Panagiotakopoulos et al. [231] presented an IoT framework\nbased on\
    \ FIWARE that aims to realize a highly ﬂexible standards-based open-source soft-\n\
    ware solution for developing SWSs. They designed an architecture consisting of\
    \ various\nFIWARE software components and two dashboard applications. Amaxilatis\
    \ et al. [232]\nconsidered numerous intelligent infrastructure solutions regarding\
    \ conventional water\nmetering systems, which effectively facilitate uninterrupted\
    \ bi-directional (whenever re-\nquired) data exchange between water ﬂow devices,\
    \ metering equipment, and end-users.\nThe authors’ ultimate objective is to design,\
    \ implement, and deploy more sophisticated\ninfrastructure offering improved performance\
    \ in bigger smart city infrastructure. To limit\nthe amount of data that needs\
    \ to be shared between the various system layers, their ap-\nproach makes use\
    \ of the FogC paradigm to develop the infrastructure for the smart water\ngrid\
    \ model.\nThe Information and Communications Technology (ICT) Solutions for the\
    \ Efﬁcient\nWater Resources Management project was funded by the European Commission\
    \ under the\nauspices of the Seventh Framework Program (FP7). The goal of the\
    \ Smart Water project is\nto examine the role of ICT in monitoring and effectively\
    \ managing urban water systems,\nElectronics 2023, 12, 2490\n44 of 63\nwith a\
    \ focus on the deployment of sensors, communication technologies, and related\n\
    decision support systems in utility providers’ water networks to address issues\
    \ such as\nleakage management, demand management, asset management, and so forth.\
    \ Kulkarni\nand Farnham [233] focused on the issues surrounding wireless connectivity,\
    \ proposed\na framework for assessing potential solutions based on the total cost\
    \ of ownership, and\nhighlighted lessons learned from two European utilities’\
    \ Smart Water case studies.\nPipelines are used to transport water, gases, and\
    \ oil. Since they are frequently under-\nground, the humid atmosphere easily erodes\
    \ them, which may result in leaks. In addition,\nwater in the pipelines may get\
    \ contaminated by infectious agents or substances that are\nmistakenly or purposely\
    \ introduced into the system. As a result, maintaining pipeline\nnetworks is crucial\
    \ for maintaining public health and protecting the environment. The sen-\nsor\
    \ node deployment profoundly impacts the sensing performance indicators for pipeline\n\
    network monitoring, including coverage area, coverage population, and detection\
    \ time.\nThe sensor nodes should typically be positioned near the pipeline network’s\
    \ junctions [234].\nGiven the design of the pipeline network, the optimal sensor\
    \ node deployment challenges\nare therefore formulated as integer optimization\
    \ problems, where the integer variables\nrepresent the maximum amount of sensor\
    \ nodes that must be placed at each junction. The\ndeployment difﬁculties for\
    \ pipeline network monitoring are typically challenging to solve\nbecause of the\
    \ integer decision variables.\nPipeline network ﬂows are not predictable. As a\
    \ result, depending on the ﬂow pattern,\nthe sensing performance of a deployed\
    \ sensor node may vary. As a result, the ﬂow pattern\nis taken into account in\
    \ [235], which formulates a mix-integer optimization problem to\ndecide how to\
    \ deploy sensor nodes to reduce the projected population at risk of malicious\n\
    contamination. The authors solved the ensuing mix-integer optimization using a\
    \ branch\nand bound technique. Even though a strategy such as this can identify\
    \ the ideal answer,\nthe time complexity is typically signiﬁcant. This means that\
    \ large pipeline networks cannot\nbe used with the method. Similarly, the study\
    \ in [236] considers the various demand\npatterns of water ﬂows through pipes.\
    \ The authors used a genetic-based method to ﬁnd the\nbest deployment locations\
    \ to increase coverage under various monitoring station demand\npatterns. The\
    \ global optimum of these heuristic algorithms could take a while to reach.\n\
    The performance of the algorithms may also be impacted by their parameter choices.\n\
    Consequently, we do not advise using it for massive pipeline networks.\nSingapore’s\
    \ WaterWise@SG program aims to identify pipeline leaks and anticipate\nburst incidents\
    \ [237,238]. PipeNet has also been put to the test in Boston to ﬁnd pipeline\n\
    leaks, where three tiers of nodes are employed to quantify pH levels and pressure.\
    \ To\nreduce water waste, a system named IWCMSE [239] has been designed to track\
    \ water\nconsumption for businesses. A Steamﬂood and Waterﬂood Tracking System\
    \ [240] has been\ncreated to ﬁnd irregularities in pipeline systems, such as leaks\
    \ and bottlenecks. With the\naid of all these technologies, the investigators\
    \ had the opportunity to evaluate the efﬁciency\nof the monitoring algorithms.\
    \ However, these technologies rely on ﬁxed sensors, and we\nstill need to put\
    \ innovative testbed models and systems built around crowd sensing and\nmobile\
    \ WSN into place.\n5.6. Architectures for Smart Transportation\nThe Internet-of-Vehicles\
    \ (IoV, also known as V2X) aims to reduce trafﬁc congestion\nand accidents. It\
    \ also enables information exchange involving the vehicle and all entities\nthat\
    \ may have an impact on it. Vehicle networking and vehicle intelligence are the\
    \ two\ntechnologies that underpin IoV implementation. The three components that\
    \ compose\nvehicle networking are the onboard information service, VANET, and\
    \ mobile network.\nVANET stands for vehicle-to-vehicle short-range communication.\
    \ Providing remote loca-\ntion, remote diagnostics, navigation, and other information\
    \ services is referred to as an\nonboard information service. Every car can be\
    \ utilized as a potent mobile terminal thanks\nto mobile networks. Vehicle intelligence\
    \ is the use of cutting-edge technologies, including\nartiﬁcial intelligence (AI),\
    \ big data analytics, deep learning (DL), and cognitive computing\nElectronics\
    \ 2023, 12, 2490\n45 of 63\n(CogC), to facilitate information sharing among people\
    \ and vehicles, as well as between\nvehicles and the environment, infrastructure,\
    \ or other vehicles.\nVehicular networks consist of data-gathering sensors and\
    \ inter-vehicle communica-\ntion systems. Such networks require an open and ﬂexible\
    \ layered architecture to handle\ncharacteristics such as interoperability, scalability,\
    \ dependability, and modularity. Recently,\nthe research community proposed efﬁcient\
    \ vehicle network architectures. For example,\nthe Universal IoV (UIoV) architecture\
    \ [241] includes seven layers. Offering services and\nchoosing messaging protocols\
    \ are tasks that fall within the application layer. Data prepro-\ncessing, big\
    \ data processing, and intelligent transmission are all tasks that the multimedia\n\
    and big data layer is in charge of. For IoV systems, the cloud service layer’s\
    \ ClCom and\ncloud virtualization technologies offer hardware computing platforms,\
    \ infrastructure, and\nsoftware services. In the UIoV architecture, the communication\
    \ layer and the intra–inter\ndevices layer are merged to accomplish the connectivity\
    \ of many heterogeneous objects\nand networks. Notably, there is no intra–inter\
    \ devices layer in classical architecture. The\nUIoV system’s physical objects\
    \ layer gathers and transmits all the data to the intra–inter\ndevices layer for\
    \ additional processing. In the IoV, both vehicles and non-vehicle items are\n\
    identiﬁed using the Identiﬁcation Layer.\nLiu et al. [242] suggested another IoV\
    \ network architecture to increase the ﬂexibility of\napplication management while\
    \ enhancing the scalability and dependability of information\nservices. This architecture\
    \ has four layers in total, the data layer of which has a variety\nof nodes with\
    \ various wireless communication interfaces. Because the topology of IoV\nis frequently\
    \ changed, an immense quantity of data are frequently produced and trans-\nmitted\
    \ at the data layer. To safeguard the accurate semantics of the underlying resources,\n\
    the virtualization layer splits a few nodes into fog nodes and the network, computation,\n\
    communication, and storage resources in IoV. To execute applications such as road\
    \ safety\nmanagement and data sensing, the control layer’s SDN controller is responsible\
    \ for schedul-\ning the abstraction resources of the virtualization layer and\
    \ interacting with the application\nlayer. A difﬁcult topic in network architecture\
    \ design is dealing with diverse networks.\nInteroperability, scalability, dependability,\
    \ and adaptability are some of its network features.\nThe design seeks to increase\
    \ layer separation and network architecture’s total number of\nlayers. In addition\
    \ to being a service-oriented design, the IoV architecture should facilitate\n\
    the connectivity of cars with heterogeneous networks and other communication devices.\n\
    By introducing the CogC paradigm into autonomous driving systems, the learning\
    \ ability\nof autonomous vehicles can be effectively improved. Utilizing both\
    \ physical and network\ndata space, the Cognitive Internet of Vehicles (CIoV)\
    \ paradigm [243] improves network\nsecurity and transportation safety. CIoV enables\
    \ IoV to bear more accurate perceptive\nability through cognition in the intra-vehicle\
    \ network (driver, passengers, smart devices,\netc.), inter-vehicle network (adjacent\
    \ intelligent vehicles), and beyond-vehicle network\n(road environment, cellular\
    \ network, edge nodes, remote cloud, etc.). The CIoV architecture\nincludes a\
    \ cognitive data engine that can conduct cognition of user tasks by the use of\n\
    data collected, e.g., driving behavior model analysis, emotion analysis, and road\
    \ condition\ninvestigation. Five layers are present in the network architecture\
    \ of CIoV. The gathering\nand preprocessing of big data from several sources are\
    \ done by the sensing layer. As\nopposed to the previous communication layer (of\
    \ other architectures), the architecture’s\ncommunication layer uses a cloud/edge\
    \ hybrid structure to accommodate various applica-\ntion schedules. The data cognition\
    \ engine at the cognition layer processes and interprets\nheterogeneous data streams\
    \ (machine learning (ML), DL, data mining, etc.) using a variety\nof cognitive\
    \ analysis approaches. The control layer’s resource awareness engine is in\ncharge\
    \ of allocating and scheduling network resources with the aid of technologies\
    \ such\nas NFV, SDN, network slicing, and self-organized networking (SON). There\
    \ are primar-\nily two categories in the application layer (i.e., usual application\
    \ services and intelligent\ntransportation applications).\nEfﬁcient message authentication\
    \ and integrity are required to guarantee vehicle pri-\nvacy and safeguard vehicular\
    \ communications. To protect V2V and V2I communications\nElectronics 2023, 12,\
    \ 2490\n46 of 63\nin the context of the VANET against a broad range of cyber threats,\
    \ Karim [244] provided\na cryptography-based routing solution. This solution includes\
    \ a data encryption and de-\ncryption mechanism based on attributes and identity\
    \ that has the lowest computational\noverhead while keeping the optimum level\
    \ of security. Contreras-Castillo et al. [245]\nsuggested a seven-layer network\
    \ architecture. The user interface layer, which controls infor-\nmation exchange\
    \ between the user and the vehicle, is the top layer. Utilizing roadside units\n\
    (RSUs) and onboard sensors, the data collecting layer gathers data. The pre-processing\n\
    and ﬁltering layer eliminates the unnecessary information from the gathered data\
    \ before\nsending the remaining information to the communication layer for transmission.\
    \ Making\nchoices and managing network service providers are the responsibilities\
    \ of control and\nmanagement. Large volumes of data must be processed by the processing\
    \ layer to create\nthe pertinent data needed for various applications. To stop\
    \ assaults, the security layer\ndirectly manages each of the layers above. A unique\
    \ network architecture with enhanced\nthroughput, reduced latency, higher security,\
    \ and widespread connectivity was recently\nproposed by Ji et al. [246]. This\
    \ architecture consists of four layers:\n1.\nSecurity authentication layer: The\
    \ RSUs on the road may monitor trafﬁc environment\ndata in real-time after setting\
    \ several sensors, surveillance footage, and radar. This\nlayer determines the\
    \ legality of the car and RSU that are requesting to join the network.\nPerhaps\
    \ an illegal vehicle or an RSU that has been installed unlawfully will attempt\n\
    to steal or alter the information of a real vehicle.\n2.\nData acquisition layer:\
    \ This layer collects and categorizes many types of data from\nvarious networks.\
    \ To ensure that the data can be sent to the edge layer securely, it\ndigitizes\
    \ the data.\n3.\nEdge layer: Edge devices produce several data streams. As a result,\
    \ processing and\nanalyzing data in one go using ClCom will result in signiﬁcant\
    \ delays. As a result, we\nmust process data more closely related to the data\
    \ source. The edge node, a physical\ndevice situated closest to the data source,\
    \ is used by the edge layer to carry out basic\nprocessing and analysis on the\
    \ acquired local data. It releases data analysis ﬁndings\nfor nearby trafﬁc incidents\
    \ and current road conditions in real-time, then creates a\nlocal decision-making\
    \ plan, carrying out various ClCom jobs and boosting the cloud\ndata center’s\
    \ computing power.\n4.\nCloud Platform Layer: The cloud data center analyses the\
    \ information it has collected\nabout global trafﬁc in this tier, develops a plan,\
    \ and rationally distributes trafﬁc\nresources. This layer, having the ability\
    \ to implement connection management, data\nmanagement, aided autonomous driving,\
    \ intelligent navigation, path planning, and\ninformation security, is the “smart\
    \ brain” of the IoV.\nA blockchain-based vehicle network architecture (Block-VN)\
    \ for the smart city was\npresented in [247]. Building innovative distributed\
    \ transport management systems is made\npossible by the robust and secure Block-VN\
    \ architecture. The authors considered how the\nnetwork of vehicles evolves with\
    \ paradigms focused on networking and vehicular informa-\ntion. To handle real-time\
    \ transportation data, Jan et al. [248] created a model for assessing\ntransportation\
    \ data using Spark and Hadoop. This model/system is separated into four\nlayers:\
    \ data collection and acquisition, network, data processing, and application.\
    \ Each\nlayer is built to process and manage data in a structured manner. On the\
    \ data processing\nlayer, Hadoop and Spark are used to test the data. By utilizing\
    \ the suggested event and\ndecision mechanism based on Named Data Networking [249],\
    \ the data are made available\nto a smart community member. The suggested approach\
    \ was examined using transporta-\ntion datasets from some reliable sources. The\
    \ outcomes demonstrate data processing and\nreal-time distribution to citizens\
    \ in the shortest amount of time. Spark with the Hadoop\nenvironment produces\
    \ ﬁndings that are quite accurate. From another viewpoint, Social\nIoV (SIoV)\
    \ are a breed of socially aware ephemeral networks [250], where vehicular nodes\n\
    share/exchange information with different entities and are thus forth comparable\
    \ with\ntraditional social networks. Kerrache et al. [251] proposed a trust-aware\
    \ communication\nElectronics 2023, 12, 2490\n47 of 63\narchitecture for social\
    \ IoV (TACASHI), which offers a trust-aware social in-vehicle and\ninter-vehicle\
    \ communication architecture for SIoVs.\n5.7. Architectures for Smart Rural Areas/Smart\
    \ Villages\nThe smart village paradigm digitizes various aspects of rural activities\
    \ using IoT\ntechnologies. In the countryside, a variety of activities are carried\
    \ out, including smart\nagriculture, waste management, irrigation management,\
    \ livestock management, smart\nenergy, smart healthcare, and smart education.\
    \ A smart village or smart rural area can\nenable real-time data analytics and\
    \ automate decision-making for local villagers regard-\ning healthcare, agriculture,\
    \ environment, transportation, and energy. It differs from a\nsmart city as there\
    \ are key differences (e.g., low cost, infrastructure, and sustainability)\nbetween\
    \ urban and rural environments [252]. To realize the smart village goal, The Euro-\n\
    pean Commission (2017) [253] launched an action plan, in which it proposed to\
    \ interfere\nICTs in villages. Cambra-Fierro and Pérez [254] addressed the meaning\
    \ of “smart” in\nrural contexts as well as its link with sustainability. The European\
    \ Commission-funded\nSmart Rural 21 initiative [255], which has the ultimate goal\
    \ of encouraging and motivat-\ning communities to create and execute smart village\
    \ methods and tactics throughout\nEurope as a tool for rural development, serving\
    \ as the authors’ primary source. IEEE\nSmart Village [256] also supports the\
    \ world’s energy-impoverished communities by pro-\nviding a complete solution\
    \ combining renewable energy, community-based education, and\nentrepreneurial\
    \ opportunities.\nMalik et al. [257] discussed the implementation details of smart\
    \ villages with different\ntechnologies. They concluded that digitization is only\
    \ possible if a reliable and robust net-\nwork and communication infrastructure\
    \ are installed in the village environment. Shrestha\nand Drozdenko [258] proposed\
    \ a Smart Rural framework to mitigate the effects of climate\nchange using IoT\
    \ and the Cloud, building a prototype on the Louisiana Tech University\ncampus.\
    \ Their framework is an energy-efﬁcient monitoring system for observing the envi-\n\
    ronmental conditions that affect agricultural production and human health. It\
    \ consists of\nthe following subsystems: Wireless Sensor Nodes, Fog Server, Cloud\
    \ Services, and a Web\nDashboard. The dashboard converts raw sensor data into\
    \ meaningful information from\nwhich public ofﬁcials and residents can adapt to\
    \ or frustrate the effects of climate change.\nMonzon Baeza and Alvarez Marban\
    \ [259] proposed a ﬂexible and scalable Smart Rural\nsystem for gathering and\
    \ processing IoT data from remote rural areas with no traditional\ncommunication\
    \ coverage as a handicap. The authors offered an architecture structured in\n\
    separate segments using IoT, 5G, Cloud, and High-Altitude Platform Station (HAPS).\
    \ Their\nproposal is applied to the rural environment to thus cover all the needs\
    \ of the system in the\ncollection of IoT data from these remote rural areas,\
    \ its coverage by space vehicles, and its\nprocessing and storage through 5G terrestrial\
    \ networks and cloud services. Their proposal\nincludes the deployment of IoT\
    \ sensors and the development of Amazon Web Services.\nConversely, the part of\
    \ the space segment, considered by HAPS, has been simulated for\ndifferent space\
    \ channels. This method provides a complete and automated smart rural\nsystem\
    \ that allows access to these IoT data from remote rural areas through the Internet.\
    \ To\nprovide secure services close to end-devices, Aljuhani et al. [260] explored\
    \ the integration\nof a Distributed Fog Computing (DFC) network architecture with\
    \ IoT in improving security\nand privacy solutions for villagers and consumer\
    \ electronic (CE) devices. As a case study,\nthe authors designed and evaluated\
    \ the performance of an Intrusion Detection System (IDS)\nin a DFC-based smart\
    \ village environment. Moreover, they discussed open security issues\nand challenges\
    \ regarding Fog-to-Things enabled smart villages. Rohan et al. [261] proposed\n\
    a collaborative edge-computing architecture considering the resource constraints\
    \ in a smart\nvillage. The authors illustrated the concept of collaborative edge\
    \ computing as applicable\nto reduce cost and better manage the existing infrastructural\
    \ facilities. Collaboration occurs\nbetween the multiple IoT edge devices (e.g.,\
    \ the edge data centers or edge routers) for data\nprocessing and storage. For\
    \ example, in times of high computational load demand, one\nvillage’s edge devices\
    \ can collaborate with another village’s edge devices.\nElectronics 2023, 12,\
    \ 2490\n48 of 63\n6. Summary\n•\nVarious SCAs have different network requirements\
    \ such as bandwidth, delay toler-\nance, power consumption, reliability, wireless\
    \ connectivity, mobility, security, and\nprivacy. Therefore, they need different\
    \ protocols at the OSI-RM layers. The network\narchitectures for IoT are heterogeneous\
    \ and include various network technologies such\nas WiFi, WSNs, Mesh Wireless\
    \ Networks (WMNs), Vehicular Networks, and Mobile\nCommunication Networks (MCNs)\
    \ (5G/LTE/4G/3G). The standards adopted in these\narchitectures must allow interoperability,\
    \ while cross-layer design-based recommen-\ndations for power consumption and\
    \ congestion control are well-suited proposals.\n•\nState-of-the-art generic network\
    \ architectures for smart cities adopt the SDN paradigm\nand are based on FogC\
    \ to reduce latency and increase the efficiency of provided services.\n•\nFog\
    \ and ClCom will be used in smart grid communication system architecture in the\n\
    future to fulﬁll QoS needs. Such architecture will additionally feature communication\n\
    methods that can lessen QoS issues like latency, security, and spectrum efﬁciency.\
    \ The\nCR technology will be an indispensable part of this architecture as this\
    \ technology can\nquickly reconﬁgure the operating parameters of the SG communication\
    \ system to the\nchanging requirements through cognition.\n•\nBy extracting usable\
    \ data from both the physical and network data space, it is possible\nto increase\
    \ network security and transportation safety in IoVs. Future IoV architectures\n\
    will become cognitive. These architectures will include cognitive data engines\
    \ that\nwill conduct cognition of user tasks by the use of data collected, e.g.,\
    \ driving behavior\nmodel analysis, emotion analysis, and road condition investigation.\n\
    •\nThe networking performance of SDN is better than the customary networking of\
    \ smart\nbuildings (SB). However, as Younus et al. [190] state, it also has been\
    \ facing some\nchallenges such as network management in terms of maintenance,\
    \ east–west interface,\nsouthbound interface, trafﬁc management, energy, ML-based\
    \ SDN networking for SB,\nand the network resources issue of SB SDN-based networking.\n\
    7. Open Research Issues\n−Network slicing management is required: IoT services\
    \ such as smart transportation and\nsmart energy have diversiﬁed requirements.\
    \ To accommodate diverse IoT services, the\nnetwork slicing paradigm is suggested\
    \ because it enables multiple independent logical\nnetworks running on the same\
    \ physical network infrastructure. Wu et al. [9] presented\nan architecture for\
    \ intelligent network slicing management for the Industrial IoT (IIoT)\nfocusing\
    \ on three IIoT services (smart transportation, smart energy, and smart factory).\
    \ The\nauthors also provided a comprehensive survey on intelligent network slicing\
    \ management\nin this ﬁeld.\n−NFV Implementation in the SDN-IoT Environment: The\
    \ ETSI Industry Speciﬁcation\nGroup proposed NFV to virtualize the network functions\
    \ that were before performed\nby some proprietary dedicated. NFV allows for the\
    \ ﬂexible provisioning of software-\nbased network functionalities on top of an\
    \ appropriately shared physical infrastructure by\nseparating the network functions\
    \ from the underlying hardware appliances [262]. Utilizing\ninexpensive commodity\
    \ servers, it solves the issue of operating costs associated with\nadministering\
    \ and controlling this closed and proprietary equipment. When SDN is\nused in\
    \ conjunction with NFV (the software-deﬁned NFV architecture), it can overcome\n\
    the difﬁculties associated with intelligent service orchestration and dynamic\
    \ resource\nmanagement [263]. SDN can dynamically establish a virtual service\
    \ environment through\nNFV. As a result, the need for specialized hardware and\
    \ labor-intensive effort to fulﬁll\na new service request is avoided. In conjunction\
    \ with the use of SDN, NFV also allows\nreal-time and dynamic function provisioning\
    \ along with ﬂexible trafﬁc forwarding. The\nSDN-IoT network may be improved and\
    \ secured with NVF. It enables the software-based\ndeployment of network devices\
    \ as virtualized components. Throughput is increased\nbecause of NFV integration\
    \ in the SDN-IoT network, which enhances network performance.\nTo this end, Sinh\
    \ et al. [264] proposed a practical model for hosting IoT services and building\n\
    Electronics 2023, 12, 2490\n49 of 63\nSDN controller applications to show that\
    \ SDN/NFV can effectively apply to IoT services.\nRecently, Mukherjee et al. [265]\
    \ proposed an SDN-based distributed IoT network with NFV\nimplementation for smart\
    \ cities.\n−Cognitive IoT network architecture for smart cities: CR technology\
    \ can address the\nbandwidth needs of IoT applications [266]. IoT devices can\
    \ be enabled with cognitive\nfunctionalities, including spectrum sensing, dynamic\
    \ spectrum accessing, circumstantial\nperceiving, and self-learning. Many SCAs\
    \ and services can be based on CR technology\nbecause it can do dynamic sensing\
    \ and cognition of the surrounding environment. For\nexample, in smart grid applications,\
    \ cognitive IoT can achieve the objective of enabling\nusers to know their energy\
    \ consumption at any time and anywhere [267]. In smart home ap-\nplications, cognitive-radio-equipped\
    \ sensors can handle potential heterogeneous network\ninterference [268]. At the\
    \ same time, cognitive IoT can help with smoother real-time moni-\ntoring over\
    \ longer distances in the healthcare industry without worrying about spectrum\n\
    availability [269]. The complete utilization of cognitive radio technology in\
    \ IoT demands\nextensive research in spectrum optimization, standardization, hardware\
    \ design, privacy\nprotection, heterogeneous network fusion, scalability and ﬂexibility\
    \ problems, etc. [270].\nFor this reason, many CIoT-based smart city network architectures\
    \ must be proposed to\nsolve such problems. In this regard, Park et al. [271]\
    \ suggested a CIoT-based smart city\nnetwork architecture that outlines how data\
    \ collected from SCAs may be analyzed using\nthe CogC paradigm and manage the\
    \ scalability and ﬂexibility challenges.\n−Challenges in IoT communication through\
    \ TCP/IP suite: Unfortunately, many Access\nPoints (APs) can utilize identical\
    \ WiFi channels in overlapping regions, leading to interfer-\nence problems that\
    \ can signiﬁcantly impair TCP performance over WiFi [272]. Now, many\nAPs can\
    \ provide support for wireless access to numerous users in a WiFi network with\n\
    the DownLink multi-user MIMO (DL MU-MIMO) functionality. DL MU-MIMO is a PHY\n\
    layer technology (included with IEEE 802.11ac standard [273]) that increases the\
    \ capacity\nof WLANs by simultaneously broadcasting data streams to several stations.\
    \ As a result, it\nis possible to achieve greater data rates that are equal to\
    \ the number of antennas on APs.\nThus, several stations are served at once. Pokhrel\
    \ and Singh [131] stressed the employment\nof CR and Federated Learning (FL) methods\
    \ with many APs to improve the Compound\nTCP’s performance in wide-area Industry\
    \ 4.0 WiFi networks. An FL method can accelerate\nthe learning processes of the\
    \ transport protocols such as Compound TCP. In FL, training\ndata are dispersed\
    \ across a large number of clients, each having unreliable and compar-\natively\
    \ slow network connections, with the aim of developing a high-quality centralized\n\
    model. The authors of [131] insisted on using these specialized strategies to\
    \ coordinate\nnumerous APs with regard to losses caused by unique wireless channel\
    \ characteristics and\nWiFi downloading and uploading dynamics. Through the use\
    \ of FL and CR approaches in\ndual AP settings, it is now possible to improve\
    \ the Layer-4 performances of TCP versions.\nAnother study [274] assumed TCP Cubic\
    \ [275] as the Layer-4 protocol and considered the\nFL approach for IoVs. The\
    \ authors of [276] developed a framework for exploiting the FL\ntechnique, which\
    \ enhances the efﬁciency and privacy protection for the case of IoVs.\n−Digital\
    \ Twins for Smart Processes: A virtual depiction of resources, personnel, proce-\n\
    dures, systems, devices, and locations is referred to as a digital twin. Digital\
    \ twin technology\ncan be used to duplicate a variety of objects, including humans,\
    \ IoT devices, aircraft en-\ngines, and vehicles. A digital twin of the original\
    \ vehicle is created, for instance, when\nan automobile business creates a virtual\
    \ representation or digital duplicate (copy) of a car\nmodel. If a manufacturer\
    \ creates a virtual representation of its manufacturing process, the\nreplicated\
    \ process is a digital twin of the physical process. A digital twin is a proﬁle\
    \ of\nthe actual process or physical object’s past and present state. In this\
    \ virtual graphic, the\ndynamics and features of an IoT device’s life and operation\
    \ are depicted. The digital twin\ncan offer the location, state, and/or status\
    \ of physical assets in real-time due to continual\nlearning and advancements.\
    \ This fusion of the real and digital worlds enables organizations\nto monitor\
    \ systems, set strategies, and anticipate problems before they occur. Digital\
    \ twins\nare created using digital twin technology, which integrates network infrastructure\
    \ graphs,\nElectronics 2023, 12, 2490\n50 of 63\nAI, software analytics, and the\
    \ IoT. Through digital twins, the idea of the smart city is\ndemonstrated. This\
    \ technology can efﬁciently administer the city, from urban planning to\nthe optimization\
    \ of land use. Digital twins make it possible to simulate plans before putting\n\
    them into action in the real world, revealing issues before they materialize.\
    \ If a digital twin\nis in place, government organizations can only fully assess\
    \ what might be achieved with\nthe data to better citizens’ lives, offer economic\
    \ opportunity, and establish a more cohesive\ncommunity. Although the idea is\
    \ currently novel, it is expected to catch on in the next few\nyears [277].\n\
    −The 6G Network for Futuristic Smart Cities: A futuristic smart city is a dense\
    \ and\nAI-centric city because massive device connectivity with vast data trafﬁc\
    \ is estimated in\nthe future. In such cities, the concept of IoT will be converted\
    \ to the concept of Internet of\nEverything (IoE). Networks of futuristic smart\
    \ cities should have a huge bandwidth, low\nlatency, and AI integration. Such\
    \ networks should also provide ubiquity, high QoS, and\non-demand content for\
    \ thousands of interconnected devices. The 6G network [278] is the\nproblem-solving\
    \ network of futuristic cities, with huge bandwidth and low latency. It is\nunder\
    \ development for wireless communications technologies supporting cellular data\n\
    networks. Like its predecessors, 6G networks will probably be broadband cellular\
    \ networks,\nin which the service area is divided into small geographical areas\
    \ (cells). It is expected that\n6G will be supported by existing 5G infrastructures\
    \ such as SDN, NFV, and network slicing,\ntogether with new infrastructure. The\
    \ network requirements of 6G are as follows [278]:\n(1) ultra-fast data rates\
    \ as high as 1 Tbps; (2) ultra-low latency of less than 1 ms; (3) increased\n\
    mobility and coverage; (4) ﬂexible and efﬁcient connection of trillion level objects;\
    \ (5) peak\nspectral efﬁciency of 60 b/s/Hz; (6) very high system reliability;\
    \ and (7) improved network\nsecurity [279]. However, the main problem of 6G is\
    \ that transmitting at a higher frequency\nspectrum is prone to high path loss,\
    \ making the distance for transmission limited [280].\nThe expected 6G of the\
    \ radio access network is based on terahertz (THz) waves with the\ncapability\
    \ of carrying up to one terabit per second (Tbps). THz waves have the capability\
    \ of\ncarrying a large amount of data, but these waves have numerous drawbacks,\
    \ such as short-\nrange and atmospheric attenuation. Hence, these drawbacks can\
    \ introduce complications\nand hinder the performance of the 6G network. Therefore,\
    \ such complications of THz waves\nmust be considered, and efﬁcient AI-centric\
    \ multilayer physical network architectures of 6G\nmust be proposed for futuristic\
    \ smart cities. Farooq et al. [280] considered the expectations\nfrom a network\
    \ of futuristic smart cities and the problems of THz waves and proposed\na conceptual\
    \ terrestrial network (TN) architecture for 6G. The nested Bee Hive [280] is a\n\
    scalable multilayer architecture designed to meet the needs of futuristic smart\
    \ cities. It\nprovides an on-ground cloud network that helps smart devices to\
    \ run AI applications\npartially on their own and the rest on the cloud. Furthermore,\
    \ the distributed and edge\ncomputing-oriented infrastructure of Bee Hive provides\
    \ security and reduces trafﬁc load on\nthe upper layer of the network. Undoubtedly,\
    \ pervasive AI is the main enabling technology\nin 6G, while some forms of AI\
    \ are realized as part of 5G. Many successful examples of\nusing AI on wireless\
    \ communications have been proposed, from physical layer designs\n(e.g., channel\
    \ estimation and precoding), to network resource allocation (e.g., trafﬁc control\n\
    and cache storage management), to security and authentication, to dynamic cell\
    \ and\ntopology formation and management, to fault prediction and detection, etc.\
    \ However,\nDL-based solutions require high computational complexity, which might\
    \ not ﬁt in current\nmobile phones [281]. Apart from the complexity, Artiﬁcial\
    \ Neural Network (ANN)-based\nRL algorithms must be carefully designed to decrease\
    \ the computational resources required\non these devices [282]. Quantum communication\
    \ [283] offers a promising approach to\navoiding the challenge of limited computational\
    \ resources and energy efﬁciency. Applying\nArtiﬁcial Neural Networks in IoT also\
    \ comes with the trade-off challenge between accuracy\nand computational/energy\
    \ requirements [282]. Tariq et al. [284] studied some of the above\nissues and\
    \ envisioned 6G to facilitate futuristic smart cities with pervasive autonomous\n\
    systems. Apart from pervasive AI, Imoize et al. [285] discussed other important\
    \ enabling\ntechnologies of 6G and their challenges. These enabling technologies\
    \ are as follows:\nElectronics 2023, 12, 2490\n51 of 63\n•\nReconﬁgurable Intelligent\
    \ Surfaces (RISs) [286] that reﬂect signals and help in places\nwhere maintaining\
    \ Line of Sight (LoS) is difﬁcult. RISs will be mainly deployed on\ndoors, windows,\
    \ and buildings.\n•\nCell-Free Massive MIMO: The massive MIMO technology is introduced\
    \ in 5G with\na more dense network of access points (APs), and this is further\
    \ developed in 6G\nto include a network with no cells (cell-free) [287]. Cell-Free\
    \ Massive MIMO im-\nproves spectral efﬁciency in communication networks, but there\
    \ are some health risks\nassociated with such a dense network of APs.\n•\nCubeSat\
    \ communication or the Internet of Space Things [288]. A CubeSat (or U-class\n\
    spacecraft) is a miniaturized spacecraft with sizes that are multiples of U, up\
    \ to 6U,\nand U being 10 × 10 × 10 cm cubic units.\n•\nUAVs/satellite communication.\n\
    •\nTerahertz communication and Optical Wireless Technology [289].\n•\nBlockchain\
    \ technology [290] and quantum communication [283].\nThe development of futuristic\
    \ smart cities keeps up with the development of energy-\nefﬁcient 6G communication.\
    \ Kamruzzaman [291] presented the key trends in the IoT for\nenergy-efﬁcient 6G\
    \ wireless communication in smart cities. He argues that the application\nof IoT\
    \ devices to 6G in smart cities will provide a 100 Gbps data rate, <0.1 ms latency\
    \ rate,\nup to 1000 km/h mobility rate, 100 bps/Hz spectral efﬁciency, and 1000\
    \ GHz frequency.\nThis will resolve the issues of energy inefﬁciency and other\
    \ concerns in conventional\ncommunication networks. Moreover, the use of energy-efﬁcient\
    \ 6G in smart cities via IoT\ndevices probably will solve various problems that\
    \ are encountered by existing smart city\nsystems. In futuristic smart cities,\
    \ residents will use the innovative 6G brain–computer\ninterface (BCI) technology\
    \ [292] for a multi-sense experience. BCI is based on the signals\nand information\
    \ that monitor and control machines using sensible wearable headsets and\ndevices.\
    \ It uses human consciousness more than external sources for better interaction.\n\
    As humans have ﬁve senses (sight, hearing, touch, smell, and taste), BCI comprises\
    \ ﬁve\ndatasets, comprising features of human senses that are used for human interaction\
    \ with the\nmachine [292].\n8. Conclusions\nUtilizing resources efficiently, reducing\
    \ operating expenses, and enhancing city\ndwellers’ quality of life are the objectives\
    \ of the smart city paradigm. This goal is ob-\ntained by combining various technologies\
    \ including IoT, WSNs, CPS, ClCom, FoC, big\ndata analytics, and robots. For this\
    \ model, the effective networking and communication\nbetween the many components\
    \ required to enable various SCAs are crucial for achieving its\nobjectives. The\
    \ ever-increasing need for networking leads to many elastic and manageable\nplatforms\
    \ for various SCAs including smart grid, smart buildings, smart home, smart water,\n\
    and smart transportation systems. The networking needs of the key SCAs were examined\n\
    in this research, and the appropriate protocols that can be applied at different\
    \ system\nlevels have been identiﬁed. Additionally, we provided examples of networking\
    \ protocols\nand smart grid, intelligent building, smart residence, and smart\
    \ transportation system\narchitectures. We concentrated on key criteria for a\
    \ variety of networking designs, such as\nenergy savings, routing, security, dependability,\
    \ mobility, and support for heterogeneous\nnetworks. In addition, we presented\
    \ open research issues.\nThis survey can assist researchers to recognize research\
    \ gaps/problems working in the\nnetworking architectures for smart cities, and\
    \ it provides an overview of available protocols\nand architectures for SCAs.\n\
    Author Contributions: Conceptualization, D.K.; methodology, D.K. and V.K.S.; analysis\
    \ and investi-\ngation, D.K. and V.K.S.; draft preparation, D.K., V.K.S. and T.P.;\
    \ supervision, A.K. All authors have\nread and agreed to the published version\
    \ of the manuscript.\nElectronics 2023, 12, 2490\n52 of 63\nFunding: This research\
    \ work was supported by the research project CRISIS, “Competences for Resilient\n\
    Smart Cities’ Staff” (Project No.: 2021-1-EL01-KA220-HED-000032257, Erasmus+ KA2—Partnerships\
    \ for\nCooperation).\nData Availability Statement: Not applicable.\nConﬂicts of\
    \ Interest: The authors declare no conﬂict of interest.\nAbbreviations\nThe following\
    \ abbreviations are used in this manuscript:\nAMI\nAutomatic Metering Infrastructure\n\
    AMQP\nAdvanced Message Queuing Protocol\nAODV\nAd-Hoc On-Demand Distance Vector\n\
    API\nApplication Programming Interface\nAQMS\nIndoor Air Quality Monitoring System\n\
    BLE\nBluetooth Low Energy\nClCom\nCloud Computing\nCoAP\nConstrained Application\
    \ Protocol\nCPS\nCyber-Physical System\nCR\nCognitive Radio\nDDS\nData Distribution\
    \ Service\nDERs\nDistributed Energy Resources\nDL\nDeep Learning\nD2D\nDevice-to-Device\
    \ communication\nEPS\nElectric Power System\nETSI\nEuropean Telecommunications\
    \ Standards Institute\nFoC\nFog Computing\nHTTP\nHypertext Transfer Protocol\n\
    HVAC\nHeating, Ventilating, and Air-Conditioning\nIEEE\nInstitute of Electrical\
    \ and Electronics Engineers\nIETF\nInternet Engineering Task Force\nIoT\nInternet\
    \ of Things\nIoV\nInternet of Vehicles\nIPv6\nInternet Protocol version 6\nISP\n\
    Internet Service Provider\nLAN\nLocal Area Network\nLoRA\nLong Range (a spread\
    \ spectrum modulation technique)\nLPWAN\nLow-Power Wide Area Network\nLTE\nLong-Term\
    \ Evolution\nMAC\nMedium Access Control\nMLB\nMultipath Load-Balancing (routing)\n\
    MQTT\nMessage Queuing Telemetry Transport\nM2M\nMachine-to-Machine\nNFV\nNetwork\
    \ Function Virtualization\nOSI-RM\nOpen Systems Interconnection−Reference Model\n\
    PAN\nPersonal Area Network\nPEVs\nPlug-in Electric Vehicles\nPHY\nPhysical layer\n\
    QoE\nQuality of Experience\nQoS\nQuality of Service\nREST\nRepresentational State\
    \ Transfer protocol\nRFID\nRadio-Frequency Identiﬁcation\nRPL\nRouting Protocol\
    \ for Low-Power and Lossy Networks\nSBA\nSmart Building Architecture\nSCA\nSmart\
    \ City Application\nSCADA\nSupervisory Control and Data Acquisition (system)\n\
    SDN\nSoftware Deﬁned Networking\nSG\nSmart Grid\nElectronics 2023, 12, 2490\n\
    53 of 63\nSWS\nSmart Water System\nTCP\nTransmission Control Protocol\nUAV\nUnmanned\
    \ Aerial Vehicle\nUDP\nUser Datagram Protocol\nVANET\nVehicular Ad-hoc Network\n\
    WAN\nWide Area Network\nWSN\nWireless Sensor Network\nXML\nExtensible Mark-up\
    \ Language\nXMPP\nExtensible Messaging and Presence Protocol\n5G\nFifth Generation\n\
    6G\nSixth Generation\n6LoWPAN\nIPv6 over Low-Power Wireless Personal Area Network\n\
    References\n1.\nAchmad, K.A.; Nugroho, L.E.; Djunaedi, A. Smart city model: A\
    \ literature review. In Proceedings of the 2018 10th International\nConference\
    \ on Information Technology and Electrical Engineering (ICITEE), Bali, Indonesia,\
    \ 24–26 July 2018; pp. 488–493.\n[CrossRef]\n2.\nAl-Fuqaha, A.; Guizani, M.; Mohammadi,\
    \ M.; Aledhari, M.; Ayyash, M. Internet of things: A survey on enabling technologies,\n\
    protocols, and applications. IEEE Commun. Surv. Tutor. 2015, 17, 2347–2376. [CrossRef]\n\
    3.\nKhalifeh, A.; Darabkh, K.A.; Khasawneh, A.M.; Alqaisieh, I.; Salameh, M.;\
    \ AlAbdala, A.; Alrubaye, S.; Alassaf, A.; Al-HajAli, S.;\nAl-Wardat, R.; et al.\
    \ Wireless sensor n etworks for smart cities: Network design, implementation and\
    \ performance evaluation.\nElectronics 2021, 10, 218. [CrossRef]\n4.\nPuliaﬁto,\
    \ A.; Tricomi, G.; Zafeiropoulos, A.; Papavassiliou, S. Smart cities of the future\
    \ as cyber physical systems: Challenges and\nenabling technologies. Sensors 2021,\
    \ 21, 3349. [CrossRef] [PubMed]\n5.\nAlam, T. Cloud-based IoT applications and\
    \ their roles in smart cities. Smart Cities 2021, 4, 1196–1219. [CrossRef]\n6.\n\
    Hu, P.; Dhelim, S.; Ning, H.; Qiu, T. Survey on fog computing: Architecture, key\
    \ technologies, applications and open issues.\nJ. Netw. Comput. Appl. 2017, 98,\
    \ 27–42. [CrossRef]\n7.\nBeigi, N.K.; Partov, B.; Farokhi, S. Real-time cloud\
    \ robotics in practical smart city applications. In Proceedings of the 2017 IEEE\n\
    28th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications\
    \ (PIMRC), Montreal, QC, Canada,\n8–13 October 2017; pp. 1–5. [CrossRef]\n8.\n\
    Osman, A.M.S. A novel big data analytics framework for smart cities. Future Gener.\
    \ Comput. Syst. 2019, 91, 620–633. [CrossRef]\n9.\nWu, Y.; Dai, H.N.; Wang, H.;\
    \ Xiong, Z.; Guo, S. A survey of intelligent network slicing management for industrial\
    \ IoT: Integrated\napproaches for smart transportation, smart energy, and smart\
    \ factory. IEEE Commun. Surv. Tutor. 2022, 24, 1175–1211. [CrossRef]\n10.\nMarinakis,\
    \ V.; Doukas, H.; Tsapelas, J.; Mouzakitis, S.; Sicilia, Á.; Madrazo, L.; Sgouridis,\
    \ S. From big data to smart energy services:\nAn application for intelligent energy\
    \ management. Future Gener. Comput. Syst. 2020, 110, 572–586. [CrossRef]\n11.\n\
    Sony, S.; Laventure, S.; Sadhu, A. A literature review of next-generation smart\
    \ sensing technology in structural health monitoring.\nStruct. Control Health\
    \ Monit. 2019, 26, e2321. [CrossRef]\n12.\nLacinák, M.; Ristvej, J. Smart city,\
    \ safety and security. Procedia Eng. 2017, 192, 522–527. [CrossRef]\n13.\nKitchenham,\
    \ B. Procedures for Performing Systematic Reviews; Technical Report TR/SE-0401;\
    \ Keele University: Keele, UK, 2004.\nAvailable online: https://www.inf.ufsc.br/~aldo.vw/kitchenham.pdf\
    \ (accessed on 10 February 2023).\n14.\nButt, O.M.; Zulqarnain, M.; Butt, T.M.\
    \ Recent advancement in smart grid technology: Future prospects in the electrical\
    \ power\nnetwork. Ain Shams Eng. J. 2021, 12, 687–695. [CrossRef]\n15.\nJha, A.V.;\
    \ Appasani, B.; Ghazali, A.N.; Pattanayak, P.; Gurjar, D.S.; Kabalci, E.; Mohanta,\
    \ D.K. Smart grid cyber-physical systems:\nCommunication technologies, standards\
    \ and challenges. Wirel. Netw. 2021, 27, 2595–2613. [CrossRef]\n16.\nSchmidt,\
    \ M.; Åhlund, C. Smart buildings as Cyber-Physical Systems: Data-driven predictive\
    \ control strategies for energy\nefﬁciency. Renew. Sustain. Energy Rev. 2018,\
    \ 90, 742–756. [CrossRef]\n17.\nYurtsever, E.; Lambert, J.; Carballo, A.; Takeda,\
    \ K. A survey of autonomous driving: Common practices and emerging technologies.\n\
    IEEE Access 2020, 8, 58443–58469. [CrossRef]\n18.\nMao, T.; Mihăită, A.S.; Chen,\
    \ F.; Vu, H.L. Boosted genetic algorithm using machine learning for trafﬁc control\
    \ optimization. IEEE\nTrans. Intell. Transp. Syst. 2022, 23, 7112–7141. [CrossRef]\n\
    19.\nWang, Z.; Song, H.; Watkins, D.W.; Ong, K.G.; Xue, P.; Yang, Q.; Shi, X.\
    \ Cyber-physical systems for water sustainability: Challenges\nand opportunities.\
    \ IEEE Commun. Mag. 2015, 53, 216–222. [CrossRef]\n20.\nJan, F.; Min-Allah, N.;\
    \ Dü¸stegör, D. IoT based smart water quality monitoring: Recent techniques, trends\
    \ and challenges for\ndomestic applications. Water 2021, 13, 1729. [CrossRef]\n\
    21.\nKochhar, A.; Kumar, N. Wireless sensor networks for greenhouses: An end-to-end\
    \ review.\nComput.\nElectron.\nAgric.\n2019, 163, 104877. [CrossRef]\n22.\nCheng,\
    \ L.; Wang, T.; Hong, X.; Wang, Z.; Wang, J.; Liu, J. A study on the architecture\
    \ of manufacturing internet of things. Int. J.\nModel. Identif. Control 2015,\
    \ 23, 8–23. [CrossRef]\nElectronics 2023, 12, 2490\n54 of 63\n23.\nDafﬂon, B.;\
    \ Moalla, N.; Ouzrout, Y. The challenges, approaches, and used techniques of CPS\
    \ for manufacturing in Industry 4.0: A\nliterature review. Int. J. Adv. Manuf.\
    \ Technol. 2021, 113, 2395–2412. [CrossRef]\n24.\nSatyanarayanan, M. The emergence\
    \ of edge computing. Computer 2017, 50, 30–39. [CrossRef]\n25.\nChen, M.; Li,\
    \ W.; Hao, Y.; Qian, Y.; Humar, I. Edge cognitive computing based smart healthcare\
    \ system. Future Gener. Comput.\nSyst. 2018, 86, 403–411. [CrossRef]\n26.\nJavaid,\
    \ S.; Suﬁan, A.; Pervaiz, S.; Tanveer, M. Smart trafﬁc management system using\
    \ Internet of Things. In Proceedings of the\n2018 20th International Conference\
    \ on Advanced Communication Technology (ICACT), Chuncheon, Republic of Korea,\
    \ 11–14\nFebruary 2018; pp. 393–398. [CrossRef]\n27.\nAfrin, T.; Yodo, N. A survey\
    \ of road trafﬁc congestion measures towards a sustainable and resilient transportation\
    \ system.\nSustainability 2020, 12, 4660. [CrossRef]\n28.\nSarrab, M.; Pulparambil,\
    \ S.; Awadalla, M. Development of an IoT based real-time trafﬁc monitoring system\
    \ for city governance.\nGlob. Transit. 2020, 2, 230–245. [CrossRef]\n29.\nZeadally,\
    \ S.; Siddiqui, F.; Baig, Z.; Ibrahim, A. Smart healthcare: Challenges and potential\
    \ solutions using internet of things (IoT)\nand big data analytics. PSU Res. Rev.\
    \ 2020, 4, 149–168. [CrossRef]\n30.\nAlromaihi, S.; Elmedany, W.; Balakrishna,\
    \ C. Cyber security challenges of deploying IoT in smart cities for healthcare\
    \ applications.\nIn Proceedings of the 6th International Conference on Future\
    \ Internet of Things and Cloud Workshops (FiCloudW), Barcelona,\nSpain, 6–8 August\
    \ 2018; pp. 140–145. [CrossRef]\n31.\nBaker, S.B.; Xiang, W.; Atkinson, I. Internet\
    \ of things for smart healthcare: Technologies, challenges, and opportunities.\
    \ IEEE\nAccess 2017, 5, 26521–26544. [CrossRef]\n32.\nQadri, Y.A.; Nauman, A.;\
    \ Zikria, Y.B.; Vasilakos, A.V.; Kim, S.W. The future of healthcare internet of\
    \ things: A survey of emerging\ntechnologies. IEEE Commun. Surv. Tutor. 2020,\
    \ 22, 1121–1167. [CrossRef]\n33.\nConcas, F.; Mineraud, J.; Lagerspetz, E.; Varjonen,\
    \ S.; Liu, X.; Puolamäki, K.; Nurmi, P.; Tarkoma, S. Low-cost outdoor air quality\n\
    monitoring and sensor calibration: A survey and critical analysis. ACM Trans.\
    \ Sens. Netw. 2021, 17, 1–44. [CrossRef]\n34.\nBloomer, M. The Challenges and\
    \ Complexities of Weather Forecasting. Available online: https://www.weather.gov/car/\n\
    weatherforecasting (accessed on 10 January 2023).\n35.\nSosunova, I.; Porras,\
    \ J. IoT-enabled smart waste management systems for smart cities: A systematic\
    \ review. IEEE Access 2022, 10,\n73326–73363. [CrossRef]\n36.\nOmar, A.; AlMaeeni,\
    \ S.; Attia, H.; Takruri, M.; Altunaiji, A.; Sanduleanu, M.; Shubair, R.; Ashhab,\
    \ M.S.; Al Ali, M.; Al Hebsi, G.\nSmart city: Recent advances in intelligent street\
    \ lighting systems based on IoT. J. Sens. 2022, 2022, 5249187. [CrossRef]\n37.\n\
    Zanella, A.; Bui, N.; Castellani, A.; Vangelista, L.; Zorzi, M. Internet of things\
    \ for smart cities. IEEE Internet Things J. 2014, 1, 22–32.\n[CrossRef]\n38.\n\
    Gharaibeh, A.; Salahuddin, M.A.; Hussini, S.J.; Khreishah, A.; Khalil, I.; Guizani,\
    \ M.; Al-Fuqaha, A. Smart cities: A survey on data\nmanagement, security, and\
    \ enabling technologies. IEEE Commun. Surv. Tutor. 2017, 19, 2456–2501. [CrossRef]\n\
    39.\nFernandes, E.; Jung, J.; Prakash, A. Security analysis of emerging smart\
    \ home applications. In Proceedings of the 2016 IEEE\nSymposium on Security and\
    \ Privacy, San Jose, CA, USA, 22–26 May 2016; pp. 636–654. [CrossRef]\n40.\nVault7-Home.\
    \ Available online: https://wikileaks.org/ciav7p1/index.html (accessed on 10 January\
    \ 2023).\n41.\nEl-Hajj, M.; Fadlallah, A.; Chamoun, M.; Serhrouchni, A. A survey\
    \ of internet of things (IoT) authentication schemes. Sensors\n2019, 19, 1141.\
    \ [CrossRef] [PubMed]\n42.\nBari, A.; Jiang, J.; Saad, W.; Jaekel, A. Challenges\
    \ in the smart grid applications: An overview. Int. J. Distrib. Sens. Netw.\n\
    2014, 10, 974682. [CrossRef]\n43.\nWang, W.; Xu, Y.; Khanna, M. A survey on the\
    \ communication architectures in smart grid. Comput. Netw. 2011, 55, 3604–3629.\n\
    [CrossRef]\n44.\nKhan, R.H.; Khan, J.Y. A comprehensive review of the application\
    \ characteristics and trafﬁc requirements of a smart grid\ncommunications network.\
    \ Comput. Netw. 2013, 57, 825–845. [CrossRef]\n45.\nKuzlu, M.; Pipattanasomporn,\
    \ M.; Rahman, S. Communication network requirements for major smart grid applications\
    \ in HAN,\nNAN and WAN. Comput. Netw. 2014, 67, 74–88. [CrossRef]\n46.\nAbdullah,\
    \ A.A.; Hassan, T.M. Smart grid (SG) properties and challenges: An overview. Discov.\
    \ Energy 2022, 2, 8. [CrossRef]\n47.\nGao, J.; Xiao, Y.; Liu, J.; Liang, W.; Chen,\
    \ C.P. A survey of communication/networking in smart grids. Future Gener. Comput.\
    \ Syst.\n2012, 28, 391–404. [CrossRef]\n48.\nKansal, P.; Bose, A. Bandwidth and\
    \ latency requirements for smart transmission grid applications. IEEE Trans. Smart\
    \ Grid 2012, 3,\n1344–1352. [CrossRef]\n49.\nJawhar, I.; Mohamed, N.; Al-Jaroodi,\
    \ J. Networking architectures and protocols for smart city systems. J. Internet\
    \ Serv. Appl. 2018,\n9, 26. [CrossRef]\n50.\nShoaib, N.; Shamsi, J.A. Understanding\
    \ network requirements for smart city applications: Challenges and solutions.\
    \ IT Prof. 2019,\n21, 33–40. [CrossRef]\n51.\nSesia, S.; Touﬁk, I.; Baker, M.\
    \ LTE-the UMTS Long Term Evolution: From Theory to Practice; John Wiley & Sons:\
    \ Hoboken, NJ,\nUSA, 2011.\n52.\nChin, W.H.; Fan, Z.; Haines, R. Emerging technologies\
    \ and research challenges for 5G wireless networks. IEEE Wirel. Commun.\n2014,\
    \ 21, 106–112. [CrossRef]\nElectronics 2023, 12, 2490\n55 of 63\n53.\nRamya, C.M.;\
    \ Shanmugaraj, M.; Prabakaran, R. Study on ZigBee technology. In Proceedings of\
    \ the 3rd International Conference\non Electronics Computer Technology, Kanyakumari,\
    \ India, 8–10 April 2011; Volume 6, pp. 297–301. [CrossRef]\n54.\nAtat, R.; Liu,\
    \ L.; Chen, H.; Wu, J.; Li, H.; Yi, Y. Enabling cyber-physical communication in\
    \ 5G cellular networks: Challenges,\nspatial spectrum sensing, and cyber-security.\
    \ IET Cyber-Phys. Syst. Theory Appl. 2017, 2, 49–54. [CrossRef]\n55.\nKhorov,\
    \ E.; Lyakhov, A.; Krotov, A.; Guschin, A. A survey on IEEE 802.11ah: An enabling\
    \ networking technology for smart cities.\nComput. Commun. 2015, 58, 53–69. [CrossRef]\n\
    56.\nKim, D.Y.; Jung, M. Data transmission and network architecture in long range\
    \ low power sensor networks for IoT. Wirel. Pers.\nCommun. 2017, 93, 119–129.\
    \ [CrossRef]\n57.\nRatasuk, R.; Vejlgaard, B.; Mangalvedhe, N.; Ghosh, A. NB-IoT\
    \ system for M2M communication. In Proceedings of the 2016 IEEE\nWireless Communications\
    \ and Networking Conference, Doha, Qatar, 3–6 April 2016; pp. 1–5. [CrossRef]\n\
    58.\nPerera, C.; Qin, Y.; Estrella, J.C.; Reiff-Marganiec, S.; Vasilakos, A.V.\
    \ Fog computing for sustainable smart cities: A survey. ACM\nComput. Surv. 2017,\
    \ 50, 1–43. [CrossRef]\n59.\nAlvi, S.A.; Afzal, B.; Shah, G.A.; Atzori, L.; Mahmood,\
    \ W. Internet of multimedia things: Vision and challenges. Ad Hoc Netw.\n2015,\
    \ 33, 87–111. [CrossRef]\n60.\nAvelar, E.; Marques, L.; dos Passos, D.; Macedo,\
    \ R.; Dias, K.; Nogueira, M. Interoperability issues on heterogeneous wireless\n\
    communication for smart cities. Comput. Commun. 2015, 58, 4–15. [CrossRef]\n61.\n\
    Cohen, E.G.; Ho, D.; Mohanty, B.P.; Rajkotia, P.R.; Berger, L.T.; Schwager, A.;\
    \ Schneider, D.M. IEEE 1905.1: Convergent digital\nhome networking. In MIMO Power\
    \ Line Communications: Narrow and Broadband Standards, EMC, and Advanced Processing;\
    \ CRC:\nBoca Raton, FL, USA, 2014.\n62.\nDel Esposte, A.D.M.; Santana, E.F.; Kanashiro,\
    \ L.; Costa, F.M.; Braghetto, K.R.; Lago, N.; Kon, F. Design and evaluation of\
    \ a\nscalable smart city software platform with large-scale simulations. Future\
    \ Gener. Comput. Syst. 2019, 93, 427–441. [CrossRef]\n63.\nKanellopoulos, D.;\
    \ Sharma, V.K. Dynamic load balancing techniques in the IoT: A review. Symmetry\
    \ 2022, 14, 2554. [CrossRef]\n64.\nLiu, Q.; Gu, J.; Yang, J.; Li, Y.; Sha, D.;\
    \ Xu, M.; Shams, I.; Yu, M.; Yang, C. Cloud, edge, and mobile computing for smart\n\
    cities. In Urban Informatics; The Urban Book Series; Shi, W., Goodchild, M.F.,\
    \ Batty, M., Kwan, M.P., Zhang, A., Eds.; Springer:\nSingapore, 2021. [CrossRef]\n\
    65.\nda Silva, T.P.; Batista, T.; Lopes, F.; Neto, A.R.; Delicato, F.C.; Pires,\
    \ P.F.; da Rocha, A.R. Fog computing platforms for smart city\napplications-A\
    \ survey. ACM Trans. Internet Technol. 2022, 22, 1–32. [CrossRef]\n66.\nMouradian,\
    \ C.; Naboulsi, D.; Yangui, S.; Glitho, R.H.; Morrow, M.J.; Polakos, P.A. A comprehensive\
    \ survey on fog computing:\nState-of-the-art and research challenges. IEEE Commun.\
    \ Surv. Tutor. 2017, 20, 416–464. [CrossRef]\n67.\nCoady, Y.; Hohlfeld, O.; Kempf,\
    \ J.; McGeer, R.; Schmid, S. Distributed cloud computing: Applications, status\
    \ quo, and challenges.\nACM SIGCOMM Comput. Commun. Rev. 2015, 45, 38–43. [CrossRef]\n\
    68.\nKsentini, A.; Jebalia, M.; Tabbane, S. IoT/cloud-enabled smart services:\
    \ A review on QoS requirements in fog environment and a\nproposed approach based\
    \ on priority classiﬁcation technique. Int. J. Commun. Syst. 2021, 34, e4269.\
    \ [CrossRef]\n69.\nOpenFog Consortium Architecture Working Group. OpenFog Reference\
    \ Architecture for Fog Computing. 2017. Available online:\nhttps://www.iiconsortium.org/pdf/OpenFog_Reference_Architecture_2_09_17.pdf\
    \ (accessed on 10 January 2023).\n70.\nTheoleyre, F.; Watteyne, T.; Bianchi, G.;\
    \ Tuna, G.; Gungor, V.C.; Pang, A.C. Networking and communications for smart cities\n\
    special issue editorial. Comput. Commun. 2015, 58, 1–3. [CrossRef]\n71.\nConti,\
    \ M.; Giordano, S. Mobile ad hoc networking: Milestones, challenges, and new research\
    \ directions. IEEE Commun. Mag.\n2014, 52, 85–96. [CrossRef]\n72.\nWinter, T.;\
    \ Thubert, P.; Brandt, A.; Hui, J.; Kelsey, R.; Levis, P.; Pister, K.; Struik,\
    \ R.; Vasseur, J.P.; Alexander, R. RPL: IPv6 Routing\nProtocol for Low-Power and\
    \ Lossy Networks. RFC 6550. 2012. Available online: https://www.rfc-editor.org/rfc/rfc6550.html\n\
    (accessed on 1 February 2023).\n73.\nKushalnagar, N.; Montenegro, G.; Schumacher,\
    \ C. IPv6 over Low-Power Wireless Personal Area Networks (6LoWPANs):\nOverview,\
    \ Assumptions, Problem Statement, and Goals. RFC 4919. 2007. Available online:\
    \ https://www.rfc-editor.org/rfc/rfc4\n919 (accessed on 1 February 2023).\n74.\n\
    Soltanmohammadi, E.; Ghavami, K.; Naraghi-Pour, M. A survey of trafﬁc issues in\
    \ machine-to-machine communications over\nLTE. IEEE Internet Things J. 2016, 3,\
    \ 865–884. [CrossRef]\n75.\nVelliangiri, S.; NG, B.A.; Baik, N.K. Detection of\
    \ DoS attacks in smart city networks with feature distance maps: A statistical\n\
    approach. IEEE Internet Things J. 2023; Early Access. [CrossRef]\n76.\nHassan,\
    \ W.H. Current research on Internet of Things (IoT) security: A survey. Comput.\
    \ Netw. 2019, 148, 283–294. [CrossRef]\n77.\nHammi, M.T.; Hammi, B.; Bellot, P.;\
    \ Serhrouchni, A. Bubbles of Trust: A decentralized blockchain-based authentication\
    \ system\nfor IoT. Comput. Secur. 2018, 78, 126–142. [CrossRef]\n78.\nQu, C.;\
    \ Tao, M.; Zhang, J.; Hong, X.; Yuan, R. Blockchain based credibility veriﬁcation\
    \ method for IoT entities. Secur. Commun.\nNetw. 2018, 2018, 7817614. [CrossRef]\n\
    79.\nErhan, L.; Ndubuaku, M.; Di Mauro, M.; Song, W.; Chen, M.; Fortino, G.; Bagdasar,\
    \ O.; Liotta, A. Smart anomaly detection in\nsensor systems: A multi-perspective\
    \ review. Inf. Fusion 2021, 67, 64–79. [CrossRef]\n80.\nUllah, Z.; Al-Turjman,\
    \ F.; Mostarda, L.; Gagliardi, R. Applications of artiﬁcial intelligence and machine\
    \ learning in smart cities.\nComp. Commun. 2020, 154, 313–323. [CrossRef]\nElectronics\
    \ 2023, 12, 2490\n56 of 63\n81.\nAhmed, S.T.; Kumar, V.; Kim, J. AITel: eHealth\
    \ Augmented Intelligence based Telemedicine Resource Recommendation Frame-\nwork\
    \ for IoT devices in Smart cities. IEEE Internet Things J. 2023; Early Access.\
    \ [CrossRef]\n82.\nHeidari, A.; Navimipour, N.J.; Unal, M. Applications of ML/DL\
    \ in the management of smart cities and societies based on new\ntrends in information\
    \ technologies: A systematic literature review. Sustain. Cities Soc. 2022, 85,\
    \ 104089. [CrossRef]\n83.\nSyed, A.S.; Sierra-Sosa, D.; Kumar, A.; Elmaghraby,\
    \ A. IoT in smart cities: A survey of technologies, practices and challenges.\n\
    Smart Cities 2021, 4, 429–475. [CrossRef]\n84.\nYaqoob, I.; Hashem, I.A.T.; Mehmood,\
    \ Y.; Gani, A.; Mokhtar, S.; Guizani, S. Enabling communication technologies for\
    \ smart cities.\nIEEE Commun. Mag. 2017, 55, 112–120. [CrossRef]\n85.\nFernandes,\
    \ R.F.; Fonseca, C.C.; Brandão, D.; Ferrari, P.; Flammini, A.; Vezzoli, A. Flexible\
    \ Wireless Sensor Network for smart\nlighting applications. In Proceedings of\
    \ the 2014 IEEE International Instrumentation and Measurement Technology Conference\n\
    (I2MTC) Proceedings, Montevideo, Uruguay, 12–15 May 2014; pp. 434–439. [CrossRef]\n\
    86.\nGupta, A.; Jha, R.K. A survey of 5G network: Architecture and emerging technologies.\
    \ IEEE Access 2015, 3, 1206–1232. [CrossRef]\n87.\nYang, C.; Liang, P.; Fu, L.;\
    \ Cui, G.; Huang, F.; Teng, F.; Bangash, Y.A. Using 5G in smart cities: A systematic\
    \ mapping study. Intell.\nSyst. Appl. 2022, 14, 200065. [CrossRef]\n88.\nGungor,\
    \ V.C.; Sahin, D.; Kocak, T.; Ergut, S.; Buccella, C.; Cecati, C.; Hancke, G.P.\
    \ Smart grid technologies: Communication\ntechnologies and standards. IEEE Trans.\
    \ Ind. Inform. 2011, 7, 529–539. [CrossRef]\n89.\nGarcía-García, L.; Jiménez,\
    \ J.M.; Abdullah, M.T.A.; Lloret, J. Wireless technologies for IoT in smart cities.\
    \ Netw. Protoc. Algorithms\n2018, 10, 23–64. [CrossRef]\n90.\nBettstetter, C.;\
    \ Vogel, H.J.; Eberspacher, J. GSM phase 2+ general packet radio service GPRS:\
    \ Architecture, protocols, and air\ninterface. IEEE Commun. Surv. 1999, 2, 2–14.\
    \ [CrossRef]\n91.\nDahlman, E.; Parkvall, S.; Skold, J. 4G: LTE/LTE-Advanced for\
    \ Mobile Broadband; Academic Press: New York, NY, USA, 2013.\n92.\nJung, W.; Kwon,\
    \ Y. Differences between LTE and 3G service customers: Business and policy implications.\
    \ Telemat. Inform. 2015,\n32, 667–680. [CrossRef]\n93.\nRinaldi, F.; Raschella,\
    \ A.; Pizzi, S. 5G NR system design: A concise survey of key features and capabilities.\
    \ Wirel. Netw. 2021, 27,\n5173–5188. [CrossRef]\n94.\nZaidi, A.A.; Baldemair,\
    \ R.; Tullberg, H.; Bjorkegren, H.; Sundstrom, L.; Medbo, J.; Kilinc, C.; Da Silva,\
    \ I. Waveform and numerology\nto support 5G services and requirements. IEEE Commun.\
    \ Magaz. 2016, 54, 90–98. [CrossRef]\n95.\nPerez-Costa, X.; Camps-Mur, D. IEEE\
    \ 802.11 E QoS and power saving features overview and analysis of combined performance.\n\
    IEEE Wirel. Commun. 2010, 17, 88–96. [CrossRef]\n96.\nSun, W.; Choi, M.; Choi,\
    \ S. IEEE 802.11ah: A long range 802.11 WLAN at sub 1 GHz. J. ICT Stand. 2013,\
    \ 1, 83–108. [CrossRef]\n97.\nMozaffariahrar, E.; Theoleyre, F.; Menth, M. A survey\
    \ of Wi-Fi 6: Technologies, advances, and challenges. Future Internet 2022,\n\
    14, 293. [CrossRef]\n98.\nKhajenasiri, I.; Estebsari, A.; Verhelst, M.; Gielen,\
    \ G. A review on Internet of Things solutions for intelligent energy control in\n\
    buildings for smart city applications. Energy Procedia 2017, 111, 770–779. [CrossRef]\n\
    99.\nCerruela García, G.; Luque Ruiz, I.; Gómez-Nieto, M.Á. State of the art,\
    \ trends and future of bluetooth low energy, near ﬁeld\ncommunication and visible\
    \ light communication in the development of smart cities. Sensors 2016, 16, 1968.\
    \ [CrossRef]\n100. Bluetooth®Wireless Technology. Available online: https://www.bluetooth.com/learn-about-bluetooth/tech-overview/\
    \ (ac-\ncessed on 22 January 2023).\n101. Faragher, R.; Harle, R. Location ﬁngerprinting\
    \ with bluetooth low energy beacons. IEEE JSAC 2015, 33, 2418–2428. [CrossRef]\n\
    102. Miorandi, D.; Zanella, A.; Pierobon, G. Performance evaluation of Bluetooth\
    \ polling schemes: An analytical approach. Mob. Netw.\nAppl. 2004, 9, 6372. [CrossRef]\n\
    103. Nikoukar, A.; Raza, S.; Poole, A.; Güne¸s, M.; Dezfouli, B. Low-power wireless\
    \ for the internet of things: Standards and applications.\nIEEE Access 2018, 6,\
    \ 67893–67926. [CrossRef]\n104. Catherwood, P.A.; Steele, D.; Little, M.; Mccomb,\
    \ S.; McLaughlin, J. A community-based IoT personalized wireless healthcare\n\
    solution trial. IEEE J. Transl. Eng. Health Med. 2018, 6, 1–13. [CrossRef]\n105.\
    \ Sharma, V.; You, I.; Pau, G.; Collotta, M.; Lim, J.D.; Kim, J.N. LoRaWAN-based\
    \ energy-efﬁcient surveillance by drones for\nintelligent transportation systems.\
    \ Energies 2018, 11, 573. [CrossRef]\n106. Jawad, H.M.; Nordin, R.; Gharghan,\
    \ S.K.; Jawad, A.M.; Ismail, M. Energy-efﬁcient wireless sensor networks for precision\n\
    agriculture: A review. Sensors 2017, 17, 1781. [CrossRef] [PubMed]\n107. Podevijn,\
    \ N.; Plets, D.; Trogh, J.; Martens, L.; Suanet, P.; Hendrikse, K.; Joseph, W.\
    \ TDoA-based outdoor positioning with tracking\nalgorithm in a public LoRa network.\
    \ Wirel. Commun. Mob. Comput. 2018, 2018, 1864209. [CrossRef]\n108. de Castro\
    \ Tomé, M.; Nardelli, P.H.; Alves, H. Long-range low-power wireless networks and\
    \ sampling strategies in electricity\nmetering. IEEE Trans. Ind. Electron. 2018,\
    \ 66, 1629–1637. [CrossRef]\n109. Haxhibeqiri, J.; De Poorter, E.; Moerman, I.;\
    \ Hoebeke, J. A survey of LoRaWAN for IoT: From technology to application. Sensors\n\
    2018, 18, 3995. [CrossRef]\n110. Adelantado, F.; Vilajosana, X.; Tuset-Peiro,\
    \ P.; Martinez, B.; Melia-Segui, J.; Watteyne, T. Understanding the limits of\
    \ LoRaWAN.\nIEEE Commun. Mag. 2017, 55, 34–40. [CrossRef]\n111. IEEE Std. 802.16-2004;\
    \ IEEE Standard for Local and Metropolitan Area Networks. Part 16: Air Interface\
    \ for Fixed Broadband\nWireless Access Systems. IEEE: Piscataway, NJ, USA, 2004.\n\
    Electronics 2023, 12, 2490\n57 of 63\n112. IEEE Std. 802.16e-2005; IEEE Standard\
    \ for Local and Metropolitan Area Networks. Part 16: Air Interface for Fixed Broadband\n\
    Wireless Access Systems. IEEE: Piscataway, NJ, USA, 2006.\n113. Vu, H.L.; Chan,\
    \ S.; Andrew, L.L. Performance analysis of best-effort service in saturated IEEE\
    \ 802.16 networks. IEEE Trans. Veh.\nTechnol. 2009, 59, 460–472. [CrossRef]\n\
    114. Pareit, D.; Lannoo, B.; Moerman, I.; Demeester, P. The history of WiMAX:\
    \ A complete survey of the evolution in certiﬁcation and\nstandardization for\
    \ IEEE 802.16 and WiMAX. IEEE Commun. Surv. Tutor. 2011, 14, 1183–1211. [CrossRef]\n\
    115. Pokhrel, S.R.; Williamson, C. Modeling compound TCP over WiFi for IoT. IEEE/ACM\
    \ Trans. Netw. 2018, 26, 864–878. [CrossRef]\n116. Sheng, Z.; Yang, S.; Yu, Y.;\
    \ Vasilakos, A.V.; McCann, J.A.; Leung, K.K. A survey on the IETF protocol suite\
    \ for the internet of\nthings: Standards, challenges, and opportunities. IEEE\
    \ Wirel. Commun. 2013, 20, 91–98. [CrossRef]\n117. Sharma, V.K.; Shukla, S.S.P.;\
    \ Singh, V. A tailored Q-Learning for routing in wireless sensor networks. In\
    \ Proceedings of the 2012\n2nd IEEE International Conference on Parallel, Distributed\
    \ and Grid Computing, Solan, India, 6–8 December 2012; pp. 663–668.\n118. Kanellopoulos,\
    \ D.; Sharma, V.K. Survey on power-aware optimization solutions for MANETs. Electronics\
    \ 2020, 9, 1129. [CrossRef]\n119. Shang, W.; Yu, Y.; Droms, R.; Zhang, L. Challenges\
    \ in IoT Networking via TCP/IP Architecture. NDN Technical Report NDN-0038.\n\
    2016. Available online: http://named-data.net/techreports.html (accessed on 1\
    \ February 2023).\n120. Iova, O.; Picco, P.; Istomin, T.; Kiraly, C. RPL: The\
    \ routing standard for the internet of things... or is it? IEEE Commun. Mag. 2016,\n\
    54, 16–22. [CrossRef]\n121. Sharma, V.K.; Kumar, M. Adaptive congestion control\
    \ scheme in mobile ad-hoc networks. Peer-Peer Netw. Appl. 2017, 10, 633–657.\n\
    [CrossRef]\n122. Sharma, V.K.; Verma, L.P.; Kumar, M. CL-ADSP: Cross-Layer adaptive\
    \ data scheduling policy in mobile ad-hoc networks. Future\nGener. Comput. Syst.\
    \ 2019, 97, 530–563. [CrossRef]\n123. Verma, L.P.; Sharma, V.K.; Kumar, M.; Kanellopoulos,\
    \ D.; Mahanti, A. DB-CMT: A new concurrent Multi-path Stream Control\nTransport\
    \ Protocol. J. Netw. Syst. Manag. 2022, 30, 67. [CrossRef]\n124. Verma, L.P.;\
    \ Sharma, V.K.; Kumar, M.; Mahanti, A. An adaptive multi-path data transfer approach\
    \ for MP-TCP. Wirel. Netw. 2022,\n28, 2185–2212. [CrossRef]\n125. ANSI/ASHRAE\
    \ Standard 135-2004; BACnet: A Data Communication Protocol for Building Automation\
    \ and Control Networks,\nStandard 135-2004. American Society of Heating Refrigeration,\
    \ and Air-Conditioning Engineers Inc.: Atlanta, GA, USA, 2004.\n126. Clark, D.D.;\
    \ Tennenhouse, D.L. Architectural considerations for a new generation of protocols.\
    \ ACM SIGCOMM Comput. Commun.\nRev. 1990, 20, 200–208. [CrossRef]\n127. Tan, K.;\
    \ Song, J.; Zhang, Q.; Sridharan, M. A compound TCP approach for high-speed and\
    \ long distance networks. In Proceedings\nof the IEEE INFOCOM 2006. 25TH IEEE\
    \ International Conference on Computer Communications, Barcelona, Spain, 23–29\n\
    April 2006. [CrossRef]\n128. Verma, L.P.; Sharma, V.K.; Kumar, M.; Kanellopoulos,\
    \ D. A novel delay-based adaptive congestion control TCP variant. Comput.\nElectr.\
    \ Eng. 2022, 101, 108076. [CrossRef]\n129. Pokhrel, S.R.; Panda, M.; Vu, H.L.;\
    \ Mandjes, M. TCP performance over Wi-Fi: Joint impact of buffer and channel losses.\
    \ IEEE\nTrans. Mob. Comput. 2015, 15, 1279–1291. [CrossRef]\n130. Pokhrel, S.R.;\
    \ Vu, H.L.; Cricenti, A.L. Adaptive admission control for IoT applications in\
    \ home WiFi networks. IEEE Trans. Mob.\nComput. 2019, 19, 2731–2742. [CrossRef]\n\
    131. Pokhrel, S.R.; Singh, S. Compound TCP performance for industry 4.0 WiFi:\
    \ A cognitive federated learning approach. IEEE Trans.\nInd. Inform. 2020, 17,\
    \ 2143–2151. [CrossRef]\n132. Qiu, T.; Chen, N.; Li, K.; Atiquzzaman, M.; Zhao,\
    \ W. How can heterogeneous internet of things build our future: A survey. IEEE\n\
    Commun. Surv. Tutor. 2018, 20, 2011–2027. [CrossRef]\n133. Kharrufa, H.; Al-Kashoash,\
    \ H.A.; Kemp, A.H. RPL-based routing protocols in IoT applications: A review.\
    \ IEEE Sens. J. 2019, 19,\n5952–5967. [CrossRef]\n134. Sharma, V.K.; Verma, L.P.;\
    \ Kumar, M. A fuzzy-based adaptive energy efﬁcient load distribution scheme in\
    \ ad-hoc networks. Int. J.\nIntell. Syst. Appl. 2018, 12, 72. [CrossRef]\n135.\
    \ Sharma, V.K.; Kumar, M. Adaptive energy efﬁcient load distribution using fuzzy\
    \ approach. Adhoc Sens. Wirel. Netw. 2017, 39,\n123–166.\n136. Reina, D.G.; Toral,\
    \ S.L.; Barrero, F.; Bessis, N.; Asimakopoulou, E. The role of ad hoc networks\
    \ in the internet of things: A case\nscenario for smart environments. In Internet\
    \ of Things and Inter-Cooperative Computational Technologies for Collective Intelligence;\n\
    Springer: Berlin/Heidelberg, Germany, 2013; pp. 89–113. [CrossRef]\n137. Vazifehdan,\
    \ J.; Prasad, R.V.; Niemegeers, I. Energy-efﬁcient reliable routing considering\
    \ residual energy in wireless ad hoc\nnetworks. IEEE Trans. Mob. Comput. 2013,\
    \ 13, 434–447. [CrossRef]\n138. Sharma, V.K.; Kumar, M. Adaptive load distribution\
    \ approach based on congestion control scheme in ad-hoc networks. Int. J.\nElectron.\
    \ 2019, 106, 48–68. [CrossRef]\n139. Papandriopoulos, J.; Dey, S.; Evans, J. Optimal\
    \ and distributed protocols for cross-layer design of physical and transport layers\
    \ in\nMANETs. IEEE/ACM Trans. Netw. 2008, 16, 1392–1405. [CrossRef]\n140. Sharma,\
    \ V.K.; Verma, L.P.; Kumar, M.; Naha, R.K.; Mahanti, A. A-CAFDSP: An adaptive-congestion\
    \ aware Fibonacci sequence\nbased data scheduling policy. Comput. Commun. 2020,\
    \ 158, 141–165. [CrossRef]\nElectronics 2023, 12, 2490\n58 of 63\n141. Tian, Y.;\
    \ Hou, R. An improved AOMDV routing protocol for internet of things. In Proceedings\
    \ of the 2010 International Conference\non Computational Intelligence and Software\
    \ Engineering, Wuhan, China, 10–12 December 2010; pp. 1–4. [CrossRef]\n142. Tseng,\
    \ C.H. Multipath load balancing routing for Internet of things. J. Sens. 2016,\
    \ 2016, 4250746. [CrossRef]\n143. Pan, M.S.; Tseng, Y.C. ZigBee and their applications.\
    \ In Sensor Networks and Conﬁguration: Fundamentals, Standards, Platforms, and\n\
    Applications; Springer: Berlin/Heidelberg, Germany, 2007; pp. 349–368.\n144. Sun,\
    \ J.; Wang, Z.; Wang, H.; Zhang, X. Research on routing protocols based on ZigBee\
    \ network. In Proceedings of the Third\nInternational Conference on Intelligent\
    \ Information Hiding and Multimedia Signal Processing (IIH-MSP 2007), Kaohsiung,\n\
    Taiwan, 26–28 November 2007; Volume 1, pp. 639–642. [CrossRef]\n145. Fielding,\
    \ R.; Gettys, J.; Mogul, J.; Frystyk, H.; Masinter, L.; Leach, P.; Lee, B. Hypertext\
    \ Transfer Protocol—HTTP/1.1. 1999.\nAvailable online: https://www.w3.org/Protocols/rfc2616/rfc2616.html\
    \ (accessed on 2 February 2023).\n146. Webber, J.; Parastatidis, S.; Robinson,\
    \ I. REST in Practice: Hypermedia and Systems Architecture; O’Reilly Media, Inc.:\
    \ Sebastopol,\nCA, USA, 2010.\n147. Dizdarevic, J.; Caprio, F.; Jukan, A.; Masip-Bruin,\
    \ X. A survey of communication protocols for Internet-of-Things and related\n\
    challenges of fog and cloud computing integration. ACM Comput. Surv. 2019, 51,\
    \ 1–29. [CrossRef]\n148. Babovic, Z.B.; Protic, J.; Milutinovic, V. Web performance\
    \ evaluation for Internet of Things applications. IEEE Access 2016, 4,\n6974–6992.\
    \ [CrossRef]\n149. Bormann, C.; Castellani, A.P.; Shelby, Z. CoAP: An application\
    \ protocol for billions of tiny internet nodes. IEEE Internet Comput.\n2012, 16,\
    \ 62–67. [CrossRef]\n150. OASIS. Message Queuing Telemetry Transport. Available\
    \ online: http://mqtt.org (accessed on 10 February 2023).\n151. OPC Foundation.\
    \ OPC Uniﬁed Architecture Speciﬁcation. 2023. Available online: https://opcfoundation.org\
    \ (accessed on 10\nFebruary 2023).\n152. XMPP Standards Foundation. Extensible\
    \ Messaging and Presence Protocol. 2021. Available online: https://xmpp.org (accessed\n\
    on 10 February 2023).\n153. OASIS. OASIS Advanced Message Queuing Protocol (AMQP)\
    \ Version 1.0—OASIS Standard; OASIS: Burlington, MA, USA, 2012.\n154. Pardo-Castellote,\
    \ G.; Innovations, R.T.; Chairman, D.D.S. OMG Data Distribution Service: Real-time\
    \ publish/subscribe becomes\na standard. RTC Mag. 2005, 14, 1–3. Available online:\
    \ https://www.rti.com/hubfs/docs/reprint_rti.pdf (accessed on 10 February\n2023).\n\
    155. Glaroudis, D.; Iossiﬁdes, A.; Chatzimisios, P. Survey, comparison and research\
    \ challenges of IoT application protocols for smart\nfarming. Comput. Netw. 2020,\
    \ 168, 107037. [CrossRef]\n156. Centenaro, M.; Vangelista, L.; Zanella, A.; Zorzi,\
    \ M. Long-range communications in unlicensed bands: The rising stars in the IoT\n\
    and smart city scenarios. IEEE Wirel. Commun. 2016, 23, 60–67. [CrossRef]\n157.\
    \ Leccese, F.; Cagnetti, M.; Trinca, D. A smart city application: A fully controlled\
    \ street lighting isle based on Raspberry-Pi card, a\nZigBee sensor network and\
    \ WiMAX. Sensors 2014, 14, 24408–24424. [CrossRef]\n158. Sanchez, L.; Muñoz, L.;\
    \ Galache, J.A.; Sotres, P.; Santana, J.R.; Gutierrez, V.; Ramdhany, R.; Gluhak,\
    \ A.; Krco, S.;\nTheodoridis, E.; et al. SmartSantander: IoT experimentation over\
    \ a smart city testbed. Comput. Netw. 2014, 61, 217–238.\n[CrossRef]\n159. Vilajosana,\
    \ I.; Dohler, M. Machine-to-Machine (M2M) communications for smart cities. Mach.-Mach.\
    \ (M2M) Commun. 2015,\n355–373. [CrossRef]\n160. Huang, J.; Xing, C.C.; Shin,\
    \ S.Y.; Hou, F.; Hsu, C.H. Optimizing M2M communications and quality of services\
    \ in the IoT for\nsustainable smart cities. IEEE Trans. Sustain. Comput. 2017,\
    \ 3, 4–15. [CrossRef]\n161. Silva, B.N.; Khan, M.; Han, K. Towards sustainable\
    \ smart cities: A review of trends, architectures, components, and open\nchallenges\
    \ in smart cities. Sustain. Cities Soc. 2018, 38, 697–713. [CrossRef]\n162. Jin,\
    \ J.; Gubbi, J.; Luo, T.; Palaniswami, M. Network architecture and QoS issues\
    \ in the internet of things for a smart city. In\nProceedings of the 2012 International\
    \ Symposium on Communications and Information Technologies (ISCIT), Gold Coast,\n\
    Australia, 2–5 October 2012; pp. 956–961. [CrossRef]\n163. Marques, P.; Manfroi,\
    \ D.; Deitos, E.; Cegoni, J.; Castilhos, R.; Rochol, J.; Pignaton, E.; Kunst,\
    \ R. An IoT-based smart cities\ninfrastructure architecture applied to a waste\
    \ management scenario. Ad Hoc Netw. 2019, 87, 200–208. [CrossRef]\n164. Gaur,\
    \ A.; Scotney, B.; Parr, G.; McClean, S. Smart city architecture and its applications\
    \ based on IoT. Procedia Comput. Sci 2015, 52,\n1089–1094. [CrossRef]\n165. Gheisari,\
    \ M.; Pham, Q.V.; Alazab, M.; Zhang, X.; Fernández-Campusano, C.; Srivastava,\
    \ G. ECA: An edge computing architecture\nfor privacy-preserving in IoT-based\
    \ smart city. IEEE Access 2019, 7, 155779–155786. [CrossRef]\n166. Saadeh, M.;\
    \ Sleit, A.; Sabri, K.E.; Almobaideen, W. Hierarchical architecture and protocol\
    \ for mobile object authentication in the\ncontext of IoT smart cities. J. Netw.\
    \ Comput. Appl. 2018, 121, 1–19. [CrossRef]\n167. Naranjo, P.G.V.; Pooranian,\
    \ Z.; Shojafar, M.; Conti, M.; Buyya, R. FOCAN: A Fog-supported smart city network\
    \ architecture for\nmanagement of applications in the Internet of Everything environments.\
    \ J. Parallel Distrib. Comput. 2019, 132, 274–283. [CrossRef]\n168. Ortiz, S.\
    \ Software-Deﬁned Networking: On the verge of a breakthrough? Computer 2013, 46,\
    \ 10–12. [CrossRef]\n169. AlZoman, R.; Alenazi, M.J. Exploiting SDN to improve\
    \ QoS of smart city networks against link failures. In Proceedings of the\nSeventh\
    \ International Conference on Software Deﬁned Systems (SDS), Paris, France, 20–23\
    \ April 2020; pp. 100–106. [CrossRef]\nElectronics 2023, 12, 2490\n59 of 63\n\
    170. Holik, F. Meeting smart city latency demands with SDN. In Intelligent Information\
    \ and Database Systems: Recent Developments.\nACIIDS 2019. Studies in Computational\
    \ Intelligence; Huk, M., Maleszka, M., Szczerbicki, E., Eds.; Springer: Cham,\
    \ Switzerland,\nVolume 830. [CrossRef]\n171. Jazaeri, S.S.; Jabbehdari, S.; Asghari,\
    \ P.; Haj Seyyed Javadi, H. Edge computing in SDN-IoT networks: A systematic review\
    \ of\nissues, challenges and solutions. Clust. Comput. 2021, 24, 3187–3228. [CrossRef]\n\
    172. Liu, J.; Li, Y.; Chen, M.; Dong, W.; Jin, D. Software-deﬁned internet of\
    \ things for smart urban sensing. IEEE Commun. Mag. 2015,\n53, 55–63. [CrossRef]\n\
    173. Bi, Y.; Lin, C.; Zhou, H.; Yang, P.; Shen, X.; Zhao, H. Time-constrained\
    \ big data transfer for SDN-enabled smart city. IEEE Commun.\nMag. 2017, 55, 44–50.\
    \ [CrossRef]\n174. Nguyen, T.G.; Phan, T.V.; Nguyen, B.T.; So-In, C.; Baig, Z.A.;\
    \ Sanguanpong, S. Search: A collaborative and intelligent NIDs\narchitecture for\
    \ SDN-based cloud IoT networks. IEEE Access 2019, 7, 107678–107694. [CrossRef]\n\
    175. Bhushan, B.; Khamparia, A.; Sagayam, K.M.; Sharma, S.K.; Ahad, M.A.; Debnath,\
    \ N.C. Blockchain for smart cities: A review of\narchitectures, integration trends\
    \ and future research directions. Sustain. Cities Soc. 2020, 61, 102360. [CrossRef]\n\
    176. Sharma, P.K.; Park, J.H. Blockchain based hybrid network architecture for\
    \ the smart city. Future Gener. Comput. Syst. 2018, 86,\n650–655. [CrossRef]\n\
    177. Makhdoom, I.; Zhou, I.; Abolhasan, M.; Lipman, J.; Ni, W. PrivySharing: A\
    \ blockchain-based framework for privacy-preserving\nand secure data sharing in\
    \ smart cities. Comput. Secur. 2020, 88, 101653. [CrossRef]\n178. Islam, M.J.;\
    \ Rahman, A.; Kabir, S.; Karim, M.R.; Acharjee, U.K.; Nasir, M.K.; Band, S.S.;\
    \ Sookhak, M.; Wu, S. Blockchain-SDN-based\nenergy-aware and distributed secure\
    \ architecture for IoT in smart cities. IEEE Internet Things J. 2021, 9, 3850–3864.\
    \ [CrossRef]\n179. Tuballa, M.L.; Abundo, M.L. A review of the development of\
    \ Smart Grid technologies. Renew. Sustain. Energy Rev. 2016, 59,\n710–725. [CrossRef]\n\
    180. Demertzis, K.; Tsiknas, K.; Taketzis, D.; Skoutas, D.N.; Skianis, C.; Iliadis,\
    \ L.; Zoiros, K.E. Communication network standards for\nsmart grid infrastructures.\
    \ Network 2021, 1, 132–145. [CrossRef]\n181. Bosisio, A.; Berizzi, A.; Morotti,\
    \ A.; Pegoiani, A.; Greco, B.; Iannarelli, G. IEC 61850-based smart automation\
    \ system logic to\nimprove reliability indices in distribution networks. In Proceedings\
    \ of the 2019 IEEE 8th International Conference on Advanced\nPower System Automation\
    \ and Protection (APAP), Florence, Italy, 18–20 October 2019; pp. 1219–1222.\n\
    182. Girela-López, F.; López-Jiménez, J.; Jiménez-López, M.; Rodríguez, R.; Ros,\
    \ E.; Díaz, J. IEEE 1588 high accuracy default proﬁle:\nApplications and challenges.\
    \ IEEE Access 2020, 8, 45211–45220. [CrossRef]\n183. Abdrabou, A. A wireless communication\
    \ architecture for smart grid distribution networks. IEEE Syst. J. 2014, 10, 251–261.\n\
    [CrossRef]\n184. Demir, K.; Germanus, D.; Suri, N. Robust QoS-aware communication\
    \ in the smart distribution grid. Peer-Peer Netw. Appl. 2017,\n10, 193–207. [CrossRef]\n\
    185. Rehmani, M.H.; Davy, A.; Jennings, B.; Assi, C. Software deﬁned networks-based\
    \ smart grid communication: A comprehensive\nsurvey. IEEE Commun. Surv. Tutor.\
    \ 2019, 21, 2637–2670. [CrossRef]\n186. Alam, S.; Sohail, M.F.; Ghauri, S.A.;\
    \ Qureshi, I.M.; Aqdas, N. Cognitive radio based smart grid communication network.\
    \ Renew.\nSustain. Energy Rev. 2017, 72, 535–548. [CrossRef]\n187. Molokomme,\
    \ D.N.; Chabalala, C.S.; Bokoro, P.N. A review of cognitive radio smart grid communication\
    \ infrastructure systems.\nEnergies 2020, 13, 3245. [CrossRef]\n188. Hu, S.; Chen,\
    \ X.; Ni, W.; Wang, X.; Hossain, E. Modeling and analysis of energy harvesting\
    \ and smart grid-powered wireless\ncommunication networks: A contemporary survey.\
    \ IEEE Trans. Green Commun. Netw. 2020, 4, 461–496. [CrossRef]\n189. Saleem, Y.;\
    \ Crespi, N.; Rehmani, M.H.; Copeland, R. Internet of things-aided smart grid:\
    \ Technologies, architectures, applications,\nprototypes, and future research\
    \ directions. IEEE Access 2019, 7, 62962–63003. [CrossRef]\n190. Younus, M.U.;\
    \ ul Islam, S.; Ali, I.; Khan, S.; Khan, M.K. A survey on software deﬁned networking\
    \ enabled smart buildings:\nArchitecture, challenges and use cases. J. Netw. Comput.\
    \ Appl. 2019, 137, 62–77. [CrossRef]\n191. Minoli, D.; Sohraby, K.; Occhiogrosso,\
    \ B. IoT considerations, requirements, and architectures for smart buildings—Energy\n\
    optimization and next-generation building management systems. IEEE Internet Things\
    \ J. 2017, 4, 269–283. [CrossRef]\n192. Jia, M.; Komeily, A.; Wang, Y.; Srinivasan,\
    \ R.S. Adopting Internet of Things for the development of smart buildings: A review\
    \ of\nenabling technologies and applications. Autom. Constr. 2019, 101, 111–126.\
    \ [CrossRef]\n193. Kumar, A.; Singh, A.; Kumar, A.; Singh, M.K.; Mahanta, P.;\
    \ Mukhopadhyay, S.C. Sensing technologies for monitoring intelligent\nbuildings:\
    \ A review. IEEE Sens. J. 2018, 18, 4847–4860. [CrossRef]\n194. Silva, B.N.; Khan,\
    \ M.; Han, K. Integration of Big Data analytics embedded smart city architecture\
    \ with RESTful web of things for\nefﬁcient service provision and energy management.\
    \ Future Gener. Comput. Syst. 2020, 107, 975–987. [CrossRef]\n195. Kumar, A.;\
    \ Srivastava, V.; Singh, M.K.; Hancke, G.P. Current status of the IEEE 1451 standard-based\
    \ sensor applications. IEEE\nSens. J. 2014, 15, 2505–2513. [CrossRef]\n196. Kumar,\
    \ A.; Hancke, G.P. Energy efﬁcient environment monitoring system based on the\
    \ IEEE 802.15. 4 standard for low cost\nrequirements. IEEE Sens. J. 2014, 14,\
    \ 2557–2566. [CrossRef]\n197. du Plessis, R.; Kumar, A.; Hancke, G.P.; Silva,\
    \ B.J. A wireless system for indoor air quality monitoring. In Proceedings of\n\
    the IECON 2016—42nd Annual Conference of the IEEE Industrial Electronics Society,\
    \ Florence, Italy, 23–26 October 2016;\npp. 5409–5414.\nElectronics 2023, 12,\
    \ 2490\n60 of 63\n198. Kularatna, N.; Sudantha, B.H. An environmental air pollution\
    \ monitoring system based on the IEEE 1451 standard for low cost\nrequirements.\
    \ IEEE Sens. J. 2008, 8, 415–422. [CrossRef]\n199. Gagliardi, G.; Lupia, M.; Cario,\
    \ G.; Tedesco, F.; Cicchello Gaccio, F.; Lo Scudo, F.; Casavola, A. Advanced adaptive\
    \ street lighting\nsystems for smart cities. Smart Cities 2020, 3, 1495–1512.\
    \ [CrossRef]\n200. Warmerdam, K.; Pandharipande, A. Location data analytics in\
    \ wireless lighting systems. IEEE Sens. J. 2015, 16, 2683–2690.\n[CrossRef]\n\
    201. Tiller, D.K.; Guo, X.; Henze, G.P.; Waters, C.E. Validating the application\
    \ of occupancy sensor networks for lighting control. Light.\nRes. Technol. 2010,\
    \ 42, 399–414. [CrossRef]\n202. Byun, J.; Hong, I.; Lee, B.; Park, S. Intelligent\
    \ household LED lighting system considering energy efﬁciency and user satisfaction.\n\
    IEEE Trans. Consum. Electron. 2013, 59, 70–76. [CrossRef]\n203. Higuera, J.; Hertog,\
    \ W.; Perálvarez, M.; Polo, J.; Carreras, J. Smart lighting system ISO/IEC/IEEE\
    \ 21451 compatible. IEEE Sens. J.\n2015, 15, 2595–2602. [CrossRef]\n204. Tan,\
    \ Y.K.; Huynh, T.P.; Wang, Z. Smart personal sensor network control for energy\
    \ saving in DC grid powered LED lighting\nsystem. IEEE Trans. Smart Grid 2012,\
    \ 4, 669–676. [CrossRef]\n205. Chew, I.; Karunatilaka, D.; Tan, C.P.; Kalavally,\
    \ V. Smart lighting: The way forward? Reviewing the past to shape the future.\n\
    Energy Build. 2017, 149, 180–191. [CrossRef]\n206. Füchtenhans, M.; Grosse, E.H.;\
    \ Glock, C.H. Smart lighting systems: State-of-the-art and potential applications\
    \ in warehouse order\npicking. Int. J. Prod. Res. 2021, 59, 3817–3839. [CrossRef]\n\
    207. Kumar, A.; Hancke, G.P. An energy-efﬁcient smart comfort sensing system based\
    \ on the IEEE 1451 standard for green buildings.\nIEEE Sens. J. 2014, 14, 4245–4252.\
    \ [CrossRef]\n208. Kavalionak, H.; Carlini, E. An HVAC regulation architecture\
    \ for smart building based on weather forecast. In Proceedings of the\nEconomics\
    \ of Grids, Clouds, Systems, and Services: 15th International Conference, GECON\
    \ 2018, Pisa, Italy, 18–20 September\n2018; Proceedings 15. Springer International\
    \ Publishing: Berlin/Heidelberg, Germany, 2019; pp. 92–103.\n209. Hao, H.; Lin,\
    \ Y.; Kowli, A.S.; Barooah, P.; Meyn, S. Ancillary service to the grid through\
    \ control of fans in commercial building\nHVAC systems. IEEE Trans. Smart Grid\
    \ 2014, 5, 2066–2074. [CrossRef]\n210. Sun, B.; Luh, P.B.; Jia, Q.S.; Jiang, Z.;\
    \ Wang, F.; Song, C. Building energy management: Integrated control of active\
    \ and passive\nheating, cooling, lighting, shading, and ventilation systems. IEEE\
    \ Trans. Autom. Sci. Eng. 2012, 10, 588–602. [CrossRef]\n211. Lin, Y.; Barooah,\
    \ P.; Meyn, S.; Middelkoop, T. Experimental evaluation of frequency regulation\
    \ from commercial building HVAC\nsystems. IEEE Trans. Smart Grid 2015, 6, 776–783.\
    \ [CrossRef]\n212. Ma, Y.; Matuško, J.; Borrelli, F. Stochastic model predictive\
    \ control for building HVAC systems: Complexity and conservatism.\nIEEE Trans.\
    \ Control Syst. Technol. 2014, 23, 101–116. [CrossRef]\n213. Javed, A.; Larijani,\
    \ H.; Ahmadinia, A.; Emmanuel, R.; Mannion, M.; Gibson, D. Design and implementation\
    \ of a cloud enabled\nrandom neural network-based decentralized smart controller\
    \ with intelligent sensor nodes for HVAC. IEEE Internet Things J.\n2016, 4, 393–403.\
    \ [CrossRef]\n214. Kumar, A.; Kumar, A.; Singh, A. Energy efﬁcient and low cost\
    \ air quality sensor for smart buildings. In Proceedings of the\n2017 3rd International\
    \ Conference on Computational Intelligence & Communication Technology (CICT),\
    \ Ghaziabad, India, 9–10\nFebruary 2017; pp. 1–4.\n215. Kim, J.Y.; Chu, C.H.;\
    \ Shin, S.M. ISSAQ: An integrated sensing systems for real-time indoor air quality\
    \ monitoring. IEEE Sens. J.\n2014, 14, 4230–4244. [CrossRef]\n216. Lozano, J.;\
    \ Suárez, J.I.; Arroyo, P.; Ordiales, J.M.; Alvarez, F. Wireless sensor network\
    \ for indoor air quality monitoring. Chem.\nEng. Trans. 2012, 30, 231–235.\n217.\
    \ Bhattacharya, S.; Sridevi, S.; Pitchiah, R. Indoor air quality monitoring using\
    \ wireless sensor network. In Proceedings of the 2012\nSixth International Conference\
    \ on Sensing Technology (ICST), Kolkata, India, 18–21 December 2012; pp. 422–427.\n\
    218. Kim, D.; Yoon, Y.; Lee, J.; Mago, P.J.; Lee, K.; Cho, H. Design and implementation\
    \ of smart buildings: A review of current research\ntrend. Energies 2022, 15,\
    \ 4278. [CrossRef]\n219. Metallidou, C.K.; Psannis, K.E.; Egyptiadou, E.A. Energy\
    \ efﬁciency in smart buildings: IoT approaches. IEEE Access 2020, 8,\n63679–63699.\
    \ [CrossRef]\n220. Mariano-Hernández, D.; Hernández-Callejo, L.; Zorita-Lamadrid,\
    \ A.; Duque-Pérez, O.; García, F.S. A review of strategies for\nbuilding energy\
    \ management system: Model predictive control, demand side management, optimization,\
    \ and fault detect &\ndiagnosis. J. Build. Eng. 2021, 33, 101692. [CrossRef]\n\
    221. Moudgil, V.; Hewage, K.; Hussain, S.A.; Sadiq, R. Integration of IoT in building\
    \ energy infrastructure: A critical review on\nchallenges and solutions. Renew.\
    \ Sustain. Energy Rev. 2023, 174, 113121. [CrossRef]\n222. The Smart Water Networks\
    \ Forum What Is a Smart Water Network? Available online: https://swan-forum.com/smart-water-\n\
    network/ (accessed on 1 October 2022).\n223. Nguyen, K.A.; Stewart, R.A.; Zhang,\
    \ H.; Sahin, O.; Siriwardene, N. Re-engineering traditional urban water management\
    \ practices\nwith smart metering and informatics. Environ. Model. Softw. 2018,\
    \ 101, 256–267. [CrossRef]\n224. Chen, Y.; Han, D. Water quality monitoring in\
    \ smart city: A pilot project. Autom. Constr. 2018, 89, 307–316. [CrossRef]\n\
    225. Kamienski, C.; Soininen, J.P.; Taumberger, M.; Dantas, R.; Toscano, A.; Cinotti,\
    \ T.S.; Maia, R.F.; Neto, A.T. Smart water management\nplatform: IoT-based precision\
    \ irrigation for agriculture. Sensors 2019, 19, 276. [CrossRef]\nElectronics 2023,\
    \ 12, 2490\n61 of 63\n226. Ye, Y.; Liang, L.; Zhao, H.; Jiang, Y. The System Architecture\
    \ of Smart Water Grid for Water Security. Procedia Eng. 2016, 154,\n361–368. [CrossRef]\n\
    227. Alvisi, S.; Casellato, F.; Franchini, M.; Govoni, M.; Luciani, C.; Poltronieri,\
    \ F.; Riberto, G.; Stefanelli, C.; Tortonesi, M. Wireless\nmiddleware solutions\
    \ for smart water metering. Sensors 2019, 19, 1853. [CrossRef] [PubMed]\n228.\
    \ Li, J.; Yang, X.; Sitzenfrei, R. Rethinking the framework of smart water system:\
    \ A review. Water 2020, 12, 412. [CrossRef]\n229. Dong, X.; Lin, H.; Tan, R.;\
    \ Iyer, R.K.; Kalbarczyk, Z. Software-Deﬁned Networking for Smart Grid Resilience:\
    \ Opportunities and\nChallenges. In Proceedings of the CPSS 2015—1st ACM Workshop\
    \ on Cyber-Physical System Security, Part of ASIACCS 2015,\nDenver, CO, USA, 16\
    \ October 2015; pp. 61–68. [CrossRef]\n230. Luciani, C.; Casellato, F.; Alvisi,\
    \ S.; Franchini, M. From Water Consumption Smart Metering to Leakage Characterization\
    \ at\nDistrict and User Level: The GST4Water Project. Proceedings 2018, 2, 675.\
    \ [CrossRef]\n231. Panagiotakopoulos, T.; Vlachos, D.P.; Bakalakos, T.V.; Kanavos,\
    \ A.; Kameas, A. A FIWARE-based IoT framework for smart\nwater distribution management.\
    \ In Proceedings of the 12th International Conference on Information, Intelligence,\
    \ Systems &\nApplications (IISA), Chania Crete, Greece, 12–14 July 2021; pp. 1–6.\
    \ [CrossRef]\n232. Amaxilatis, D.; Chatzigiannakis, I.; Tselios, C.; Tsironis,\
    \ N.; Niakas, N.; Papadogeorgos, S. A smart water metering deployment\nbased on\
    \ the fog computing paradigm. Appl. Sci. 2020, 10, 1965. [CrossRef]\n233. Kulkarni,\
    \ P.; Farnham, T. Smart city wireless connectivity considerations and cost analysis:\
    \ Lessons learnt from smart water case\nstudies. IEEE Access 2016, 4, 660–672.\
    \ [CrossRef]\n234. Watson, J.P.; Greenberg, H.J.; Hart, W.E. A multiple-objective\
    \ analysis of sensor placement optimization in water networks. In\nCritical Transitions\
    \ in Water and Environmental Resources Management; American Society of Civil Engineers:\
    \ Reston, VA, USA, 2004;\npp. 1–10.\n235. Berry, J.W.; Fleischer, L.; Hart, W.E.;\
    \ Phillips, C.A.; Watson, J.P. Sensor placement in municipal water networks. J.\
    \ Water Resour.\nPlan. Manag. 2005, 131, 237–243. [CrossRef]\n236. Liu, S.; Liu,\
    \ W.; Chen, J.; Wang, Q. Optimal locations of monitoring stations in water distribution\
    \ systems under multiple demand\npatterns: A ﬂaw of demand coverage method and\
    \ modiﬁcation. Front. Environ. Sci. Eng. 2012, 6, 204–212. [CrossRef]\n237. Whittle,\
    \ A.J.; Girod, L.; Preis, A.; Allen, M.; Lim, H.B.; Iqbal, M.; Srirangarajan,\
    \ S.; Fu, C.; Wong, K.J.; Goldsmith, D. WATER-\nWISE@SG: A testbed for continuous\
    \ monitoring of the water distribution system in Singapore. In Water Distribution\
    \ Systems\nAnalysis; American Society of Civil Engineers: Reston, VA, USA, 2010;\
    \ pp. 1362–1378.\n238. Whittle, A.; Allen, M.; Preis, A.; Iqbal, M. Sensor networks\
    \ for monitoring and control of water distribution systems. In\nProceedings of\
    \ the 6th International Conference on Structural Health Monitoring of Intelligent\
    \ Infrastructure, Hong Kong, China,\n9–11 December 2013; pp. 9–11.\n239. Patil,\
    \ K.; Ghosh, A.; Das, D.; Vuppala, S.K. IWCMSE: Integrated water consumption monitoring\
    \ solution for enterprises. In\nProceedings of the ACM International Conference\
    \ on Interdisciplinary Advances in Applied Computing, Amritapuri, India,\n10–14\
    \ October 2014; pp. 1–8. [CrossRef]\n240. Yoon, S.; Ye, W.; Heidemann, J.; Littleﬁeld,\
    \ B.; Shahabi, C. SWATS: Wireless sensor networks for steamﬂood and waterﬂood\n\
    pipeline monitoring. IEEE Netw. 2011, 25, 50–56. [CrossRef]\n241. Ang, L.M.; Seng,\
    \ K.P.; Ijemaru, G.K.; Zungeru, A.M. Deployment of IoV for smart cities: Applications,\
    \ architecture, and challenges.\nIEEE Access 2018, 7, 6473–6492. [CrossRef]\n\
    242. Liu, K.; Xu, X.; Chen, M.; Liu, B.; Wu, L.; Lee, V.C. A hierarchical architecture\
    \ for the future internet of vehicles. IEEE Commun.\nMag. 2019, 57, 41–47. [CrossRef]\n\
    243. Chen, M.; Tian, Y.; Fortino, G.; Zhang, J.; Humar, I. Cognitive internet\
    \ of vehicles. Comput. Commun. 2018, 120, 58–70. [CrossRef]\n244. Karim, A. Development\
    \ of secure Internet of Vehicle Things (IoVT) for smart transportation system.\
    \ Comput. Electr. Eng. 2022,\n102, 108101. [CrossRef]\n245. Contreras-Castillo,\
    \ J.; Zeadally, S.; Guerrero-Ibañez, J.A. Internet of vehicles: Architecture,\
    \ protocols, and security. IEEE Internet\nThings J. 2017, 5, 3701–3709. [CrossRef]\n\
    246. Ji, B.; Zhang, X.; Mumtaz, S.; Han, C.; Li, C.; Wen, H.; Wang, D. Survey\
    \ on the internet of vehicles: Network architectures and\napplications. IEEE Commun.\
    \ Stand. Mag. 2020, 4, 34–41. [CrossRef]\n247. Sharma, P.K.; Moon, S.Y.; Park,\
    \ J.H. Block-VN: A distributed blockchain based vehicular network architecture\
    \ in smart city. J. Inf.\nProcess. Syst. 2017, 13, 184–195. [CrossRef]\n248. Jan,\
    \ B.; Farman, H.; Khan, M.; Talha, M.; Din, I.U. Designing a smart transportation\
    \ system: An internet of things and big data\napproach. IEEE Wirel. Commun. 2019,\
    \ 26, 73–79. [CrossRef]\n249. Saxena, D.; Raychoudhury, V.; Suri, N.; Becker,\
    \ C.; Cao, J. Named Data Networking: A survey. Comput. Sci. Rev. 2016, 19, 15–55.\n\
    [CrossRef]\n250. Kaiwartya, O.; Abdullah, A.H.; Cao, Y.; Altameem, A.; Prasad,\
    \ M.; Lin, C.T.; Liu, X. Internet of vehicles: Motivation, layered\narchitecture,\
    \ network model, challenges, and future aspects. IEEE Access 2016, 4, 5356–5373.\
    \ [CrossRef]\n251. Kerrache, C.A.; Lagraa, N.; Hussain, R.; Ahmed, S.H.; Benslimane,\
    \ A.; Calafate, C.T.; Cano, J.-C.; Vegni, A.M. TACASHI:\nTrust-aware communication\
    \ architecture for social internet of vehicles. IEEE Internet Things J. 2019,\
    \ 6, 5870–5877. [CrossRef]\n252. Anastasiou, E.; Manika, S.; Ragazou, K.; Katsios,\
    \ I. Territorial and human geography challenges: How can Smart villages support\n\
    rural development and population inclusion? Soc. Sci. 2021, 10, 193. [CrossRef]\n\
    253. Komorowski, Ł.; Stanny, M. Smart villages: Where can they happen? Land 2020,\
    \ 9, 151.\nElectronics 2023, 12, 2490\n62 of 63\n254. Cambra-Fierro, J.J.; Pérez,\
    \ L. (Re) thinking smart in rural contexts: A multi-country study. Growth Chang.\
    \ 2022, 53, 868–889.\n[CrossRef]\n255. European Network for Rural Development,\
    \ Smart Villages. Available online: https://enrd.ec.europa.eu/smart-and-competitive-\n\
    rural-areas/smart-villages_en (accessed on 10 June 2022).\n256. IEEE Smart Village.\
    \ Available online: http://ieee-smart-village.org/ (accessed on 10 June 2022).\n\
    257. Malik, P.K.; Singh, R.; Gehlot, A.; Akram, S.V.; Das, P.K. Village 4.0: Digitalization\
    \ of village with smart internet of things\ntechnologies. Comput. Ind. Eng. 2022,\
    \ 165, 107938. [CrossRef]\n258. Shrestha, S.; Drozdenko, B. Smart Rural Framework\
    \ using IoT devices and Cloud computing. In Proceedings of the 2019 IEEE\nGreen\
    \ Technologies Conference (GreenTech), Lafayette, LA, USA, 3–6 April 2019. [CrossRef]\n\
    259. Monzon Baeza, V.; Alvarez Marban, M. High Altitude Platform Stations Aided\
    \ Cloud-Computing Solution for Rural-Environment\nIoT Applications. Comput. Netw.\
    \ Commun. 2022, 1, 85–98.\n260. Aljuhani, A.; Kumar, P.; Kumar, R.; Jolfaei, A.;\
    \ Islam, A.N. Fog intelligence for secure smart villages: Architecture, and future\n\
    challenges. IEEE Consum. Electron. Mag. 2022, 8, 1–9. [CrossRef]\n261. Rohan,\
    \ R.; Pal, D.; Watanapa, B.; Funilkul, S. Emerging Paradigm of IoT Enabled Smart\
    \ Villages. In Proceedings of the 2022 IEEE\nInternational Conference on Consumer\
    \ Electronics (ICCE), Las Vegas, NV, USA, 7–9 January 2022.\n262. Han, B.; Gopalakrishnan,\
    \ V.; Ji, L.; Lee, S. Network function virtualization: Challenges and opportunities\
    \ for innovations. IEEE\nCommun. Mag. 2015, 53, 90–97. [CrossRef]\n263. Li, Y.;\
    \ Chen, M. Software-deﬁned network function virtualization: A survey. IEEE Access\
    \ 2015, 3, 2542–2553. [CrossRef]\n264. Sinh, D.; Le, L.V.; Lin, B.S.P.; Tung,\
    \ L.P. SDN/NFV—A new approach of deploying network infrastructure for IoT. In\
    \ Proceedings\nof the 2018 27th Wireless and Optical Communication Conference\
    \ (WOCC), Hualien, Taiwan, 30 April–1 May 2018; pp. 1–5.\n265. Mukherjee, B.K.;\
    \ Pappu, S.I.; Islam, M.; Acharjee, U.K. An SDN based distributed IoT network\
    \ with NFV implementation for\nsmart cities. In Proceedings of the International\
    \ Conference on Cyber Security and Computer Science, Dhaka, Bangladesh, 15–16\n\
    February 2020; Springer: Cham, Switzerland; pp. 539–552. [CrossRef]\n266. Khan,\
    \ A.A.; Rehmani, M.H.; Rachedi, A. Cognitive-radio-based Internet of Things: Applications,\
    \ architectures, spectrum related\nfunctionalities, and future research directions.\
    \ IEEE Wirel. Commun. 2017, 24, 17–25. [CrossRef]\n267. Pranaya, Y.C.; Himarish,\
    \ M.N.; Baig, M.N.; Ahmed, M.R. Cognitive architecture based smart grids for smart\
    \ cities. In Proceedings\nof the 3rd International Conference on Power Generation\
    \ Systems and Renewable Energy Technologies (PGSRET 2017), Johor\nBahru, Malaysia,\
    \ 4–6 April 2017; pp. 44–49. [CrossRef]\n268. Gai, K.; Xu, K.; Lu, Z.; Qiu, M.;\
    \ Zhu, L. Fusion of cognitive wireless networks and edge computing. IEEE Wirel.\
    \ Commun. 2019, 26,\n69–75. [CrossRef]\n269. Scrugli, M.A.; Loi, D.; Raffo, L.;\
    \ Meloni, P. A runtime-adaptive cognitive IoT node for healthcare monitoring.\
    \ In Proceedings of the\n16th ACM International Conference on Computing Frontiers\
    \ 2019, Alghero, Italy, 30 April–2 May 2019; pp. 350–357. [CrossRef]\n270. Li,\
    \ F.; Lam, K.Y.; Li, X.; Sheng, Z.; Hua, J.; Wang, L. Advances and emerging challenges\
    \ in cognitive internet-of-things. IEEE Trans.\nInd. Inform. 2019, 16, 5489–5496.\
    \ [CrossRef]\n271. Park, J.H.; Salim, M.M.; Jo, J.H.; Sicato, J.C.S.; Rathore,\
    \ S.; Park, J.H. CIoT-Net: A scalable cognitive IoT based smart city network\n\
    architecture. Hum.-Cent. Comput. Inf. Sci. 2019, 9, 29. [CrossRef]\n272. Nayak,\
    \ P.; Garetto, M.; Knightly, E.W. Multi-user downlink with single-user uplink\
    \ can starve TCP. In Proceedings of the IEEE\nINFOCOM 2017, Atlanta, GA, USA,\
    \ 1–4 May 2017; pp. 1–9. [CrossRef]\n273. Bejarano, O.; Knightly, E.W.; Park,\
    \ M. IEEE 802.11 ac: From channelization to multi-user MIMO. IEEE Commun. Mag.\
    \ 2013, 51,\n84–90. [CrossRef]\n274. Pokhrel, S.R.; Choi, J. Improving TCP performance\
    \ over WiFi for internet of vehicles: A federated learning approach. IEEE Trans.\n\
    Veh. Technol. 2020, 69, 6798–6802. [CrossRef]\n275. Rhee, I.; Xu, L.; Ha, S.;\
    \ Zimmermann, A.; Eggert, L.; Scheffenegger, R. CUBIC for Fast Long-Distance Networks\
    \ (No. Rfc8312).\n2018. Available online: https://www.rfc-editor.org/rfc/rfc8312\
    \ (accessed on 1 February 2023).\n276. Shahraki, A.; Taherkordi, A.; Haugen, Ø.;\
    \ Eliassen, F. A survey and future directions on clustering: From WSNs to IoT\
    \ and\nmodern networking paradigms. IEEE Trans. Netw. Serv. Manag. 2020, 18, 2242–2274.\
    \ [CrossRef]\n277. Mylonas, G.; Kalogeras, A.; Kalogeras, G.; Anagnostopoulos,\
    \ C.; Alexakos, C.; Munoz, L. Digital twins from smart manufacturing\nto smart\
    \ cities: A survey. IEEE Access 2021, 9, 143222–143249. [CrossRef]\n278. Akhtar,\
    \ M.W.; Hassan, S.A.; Ghaffar, R.; Jung, H.; Garg, S.; Hossain, M.S. The shift\
    \ to 6G communications: Vision and requirements.\nHum. Cent. Comput. Inf. Sci.\
    \ 2020, 10, 53. [CrossRef]\n279. Nguyen, V.L.; Lin, P.C.; Cheng, B.C.; Hwang,\
    \ R.H.; Lin, Y.D. Security and privacy for 6G: A survey on prospective technologies\n\
    and challenges. IEEE Commun. Surv. Tutor. 2021, 23, 2384–2428. [CrossRef]\n280.\
    \ Farooq, M.S.; Nadir, R.M.; Rustam, F.; Hur, S.; Park, Y.; Ashraf, I. Nested\
    \ Bee Hive: A conceptual multilayer architecture for 6G in\nfuturistic sustainable\
    \ smart cities. Sensors 2022, 22, 5950. [CrossRef] [PubMed]\n281. Huang, H.; Guo,\
    \ S.; Gui, G.; Yang, Z.; Zhang, J.; Sari, H.; Adachi, F. Deep learning for physical-layer\
    \ 5G wireless techniques:\nOpportunities, challenges and solutions. IEEE Wirel.\
    \ Commun. 2020, 27, 214–222. [CrossRef]\n282. Chen, M.; Challita, U.; Saad, W.;\
    \ Yin, C.; Debbah, M. Artiﬁcial Neural Networks-Based Machine Learning for Wireless\
    \ Networks:\nA Tutorial. IEEE Commun. Surv. Tutor. 2019, 21, 3039–3071. [CrossRef]\n\
    283. Manzalini, A. Quantum Communications in Future Networks and Services. Quantum\
    \ Rep. 2020, 2, 221–232. [CrossRef]\nElectronics 2023, 12, 2490\n63 of 63\n284.\
    \ Tariq, F.; Khandaker, M.R.A.; Wong, K.K.; Imran, M.A.; Bennis, M.; Debbah, M.\
    \ A speculative study on 6G. IEEE Wirel. Commun.\n2020, 27, 118–125. [CrossRef]\n\
    285. Imoize, A.L.; Adedeji, O.; Tandiya, N.; Shetty, S. 6G enabled smart infrastructure\
    \ for sustainable society: Opportunities, challenges,\nand research roadmap. Sensors\
    \ 2021, 21, 1709. [CrossRef] [PubMed]\n286. Basar, E.; Di Renzo, M.; De Rosny,\
    \ J.; Debbah, M.; Alouini, M.-S.; Zhang, R. Wireless communications through Reconﬁgurable\n\
    Intelligent Surfaces. IEEE Access 2019, 7, 116753–116773. [CrossRef]\n287. Hu,\
    \ S.; Rusek, F.; Edfors, O. Beyond Massive MIMO: The potential of data transmission\
    \ with large intelligent surfaces. IEEE Trans.\nSignal Process. 2018, 66, 2746–2758.\
    \ [CrossRef]\n288. Akyildiz, I.F.; Kak, I.A. The Internet of Space Things/Cubesats.\
    \ IEEE Netw. 2019, 33, 212–218. [CrossRef]\n289. Akyildiz, I.F.; Jornet, J.M.;\
    \ Han, C. Terahertz band: Next frontier for wireless communications. Phys. Commun.\
    \ 2014, 12, 16–32.\n[CrossRef]\n290. Kumari, A.; Gupta, R.; Tanwar, S. Amalgamation\
    \ of blockchain and IoT for smart cities underlying 6G communication:\nA comprehensive\
    \ review. Comput. Commun. 2021, 172, 102–118. [CrossRef]\n291. Kamruzzaman, M.M.\
    \ Key technologies, applications and trends of internet of things for energy-efﬁcient\
    \ 6G wireless communica-\ntion in smart cities. Energies 2022, 15, 5608. [CrossRef]\n\
    292. Kohli, V.; Tripathi, U.; Chamola, V.; Rout, B.K.; Kanhere, S.S. A review\
    \ on Virtual Reality and Augmented Reality use-cases of\nBrain Computer Interface\
    \ based applications for smart cities. Microprocess. Microsyst. 2022, 88, 104392.\
    \ [CrossRef]\nDisclaimer/Publisher’s Note: The statements, opinions and data contained\
    \ in all publications are solely those of the individual\nauthor(s) and contributor(s)\
    \ and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility\
    \ for any injury to\npeople or property resulting from any ideas, methods, instructions\
    \ or products referred to in the content.\n"
  inline_citation: '>'
  journal: Electronics (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/2079-9292/12/11/2490/pdf?version=1685597834
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'Networking Architectures and Protocols for IoT Applications in Smart Cities:
    Recent Developments and Perspectives'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/smartcities5010019
  analysis: '>'
  authors:
  - Nasim Nezamoddini
  - Amirhosein Gholami
  citation_count: 7
  full_citation: '>'
  full_text: ">\n\x01\x02\x03\x01\x04\x05\x06\a\b\x01\n\x01\x02\x03\x04\x05\x06\a\n\
    Citation: Nezamoddini, N.; Gholami,\nA. A Survey of Adaptive Multi-Agent\nNetworks\
    \ and Their Applications in\nSmart Cities. Smart Cities 2022, 5,\n318–347. https://doi.org/\n\
    10.3390/smartcities5010019\nAcademic Editor: Zhixiang Fang\nReceived: 11 January\
    \ 2022\nAccepted: 7 March 2022\nPublished: 9 March 2022\nPublisher’s Note: MDPI\
    \ stays neutral\nwith regard to jurisdictional claims in\npublished maps and institutional\
    \ afﬁl-\niations.\nCopyright:\n© 2022 by the authors.\nLicensee MDPI, Basel, Switzerland.\n\
    This article is an open access article\ndistributed\nunder\nthe\nterms\nand\n\
    conditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n\
    4.0/).\nsmart cities\nArticle\nA Survey of Adaptive Multi-Agent Networks and Their\n\
    Applications in Smart Cities\nNasim Nezamoddini 1,∗\nand Amirhosein Gholami 2\n\
    1\nIndustrial and Systems Engineering Department, Oakland University, Rochester,\
    \ MI 48309, USA\n2\nSystems Science and Industrial Engineering Department, Binghamton\
    \ University,\nBinghamton, NY 13902, USA; agholam1@binghamton.edu\n*\nCorrespondence:\
    \ nezamoddini@oakland.edu; Tel.: +1-(248)-370-2989\nAbstract: The world is moving\
    \ toward a new connected world in which millions of intelligent\nprocessing devices\
    \ communicate with each other to provide services in transportation, telecommu-\n\
    nication, and power grids in the future’s smart cities. Distributed computing\
    \ is considered one of\nthe efﬁcient platforms for processing and management of\
    \ massive amounts of data collected by\nsmart devices. This can be implemented\
    \ by utilizing multi-agent systems (MASs) with multiple\nautonomous computational\
    \ entities by memory and computation capabilities and the possibility\nof message-passing\
    \ between them. These systems provide a dynamic and self-adaptive platform\nfor\
    \ managing distributed large-scale systems, such as the Internet-of-Things (IoTs).\
    \ Despite, the\npotential applicability of MASs in smart cities, very few practical\
    \ systems have been deployed using\nagent-oriented systems. This research surveys\
    \ the existing techniques presented in the literature\nthat can be utilized for\
    \ implementing adaptive multi-agent networks in smart cities. The related\nliterature\
    \ is categorized based on the steps of designing and controlling these adaptive\
    \ systems.\nThese steps cover the techniques required to deﬁne, monitor, plan,\
    \ and evaluate the performance of\nan autonomous MAS. At the end, the challenges\
    \ and barriers for the utilization of these systems in\ncurrent smart cities,\
    \ and insights and directions for future research in this domain, are presented.\n\
    Keywords: MAS; adaptive systems; network systems; smart city; systems of systems\n\
    1. Introduction\nThe smart city is a new notion that has rapidly gained ground\
    \ in the agendas of city\nauthorities all over the world. An increasing population\
    \ concentration in urban areas and\nsubsequent arising challenges have highlighted\
    \ the need for intelligent ways to facilitate\ncitizen’s lives, deliver services,\
    \ and mitigate against disasters [1]. One of the solutions was to\nintroduce new\
    \ urban areas equipped with a city with an advanced metering infrastructure\n\
    and smart objects with ubiquitous sensing and embedded intelligence [2]. Each\
    \ one of the\nsmart objects collects the data from their environment, communicates\
    \ with other objects,\nprocess information, and in some cases, autonomously react\
    \ to dynamic internal and\nexternal changes [3]. Wireless sensor networks (WSN),\
    \ radio frequency identiﬁcation\n(RFID), near-ﬁeld communications (NFC) tags,\
    \ unique/universal/ubiquitous identiﬁers\n(UID), actuators, smartphones, and smart\
    \ appliances are examples of these smart devices.\nThe devices are connected through\
    \ a platform called the Internet-of-Things (IoTs) that\nallows technologies to\
    \ access and interchange data through wireless and sired internet\nnetworks [4].\n\
    Although adopting the IoTs opens new possibilities and opportunities to change\n\
    our society to a connected world, at the same time, it brings its own problems\
    \ and risks.\nIntegrating a diverse range of devices with different functionalities,\
    \ computation capa-\nbilities, and data streams is extremely challenging [5].\
    \ Scalability is another major issue\nfor controlling IoTs systems, considering\
    \ the highly dynamic and distributed nature of\nthese networked systems [6]. Each\
    \ of the sensing devices and other end users may join or\nSmart Cities 2022, 5,\
    \ 318–347. https://doi.org/10.3390/smartcities5010019\nhttps://www.mdpi.com/journal/smartcities\n\
    Smart Cities 2022, 5\n319\nleave the system or change their locations at any time,\
    \ and that makes the topology of the\nsystem uncertain and subject to unexpected\
    \ changes. The control mechanisms with ﬁxed\nconﬁgurations are not efﬁcient for\
    \ the heterogeneous and dynamic nature of IoTs systems.\nThe distributed nature\
    \ of the IoTs also makes it more vulnerable to possible cyber-attacks\nand failures.\
    \ Failures in part of the system, especially in a central leader, may cascade\
    \ to\nother connected nodes and eventually result in the collapse of the whole\
    \ system. These\nsystems need to be designed and controlled in a more robust and\
    \ resilient way, promoting\nthe efﬁciency of the system in delivering services\
    \ and achieving its predeﬁned targets\nand goals.\nThe distributed processing\
    \ and control of multi-agent systems (MAS) or agent-oriented\nprogramming (AOP)\
    \ are some of the main technological paradigms for the efﬁcient deploy-\nment\
    \ of smart devices and services in the smart city [7]. These techniques are considered\n\
    the best abstraction approaches for modeling the operations and functionalities\
    \ of IoTs\nsystems in all three layers of perception, network, and application\
    \ [8]. They also proved\ntheir effectiveness in supporting autonomous networks\
    \ of the objects in the IoTs with\nself-adaptive and self-organizing properties\
    \ [9]. There is a large number of instantaneous\ncommunications between devices\
    \ in the IoT. In MAS, each device is mapped to an agent\nwith a predeﬁned range\
    \ of features and capabilities. This mapping provides a suitable high-\nperformance\
    \ infrastructure for testing and implementing large-scale data acquisition and\n\
    offers a scalable platform for the distributed computing of the received data\
    \ [10]. Moreover,\nsimulating objects as smart-reactive agents enables the real-time\
    \ tuning of control parame-\nters in complex interconnected networks, such as\
    \ the IoT. The autonomous agents in the\nMAS can be programmed and function without\
    \ human intervention. They are also able to\ninteract with other agents and reﬂect\
    \ modular functionalities and coordination. The agents\nin the MAS also reﬂect\
    \ goal-oriented behavior, which is one of the main requirements for\nmanaging\
    \ connected devices in smart cities [11]. These advantages make them suitable\n\
    platforms for implementing different domains of a smart city, including mobility,\
    \ envi-\nronment, governance, energy, economy, health, technology, and education\
    \ [12]. Figure 1\nsummarizes some of the related literature for the application\
    \ of multi-agent systems in\ndifferent applications in a smart city.\nEducation\n\
    Pireva et al., \n2014 Samia et \nal., 2018\nAl-Tarabily et \nal., 2018\nHamal\
    \ et al., \n2021\nIlango et al., \n2021\nEnergy\nCoelho et al., \n2017\nShawon\
    \ et al., \n2019\nKhan et al., \n2021\nCosta et al., \n2022\nMerabet et al.\n\
    2014\nMobility\nChen et al., \n2009\nTorabi et al., \n2018\nCruz-Piris et al.,\
    \ \n2018\nFernández-\nIsabel et al., \n2020\nEconomy\nČech et al., \n2013\nCalvaresi\
    \ et al., \n2019\nBajo et al., 2017\nPapi et al., 2022\nMinarsch et al.\n2021\n\
    Health\nAlanezi, 2021\nZhang et al., \n2021\nMutlag et al., \n2021\nJemal et al.,\
    \ \n2015\nElghamrawy, \n2020\nTechnology\nAlexakos & \nKalogeras,  \n2015\nLom\
    \ & Přibyl, \n2017\nCiortea et al.,\n2018\nClemen et al.,\n2021\nEnvironment\n\
    Likotiko et al., \n2017\nKoc & Işık, \n2020\nChallenger et a., \n2021\nAlsamhi\
    \ et al., \n2021\nGovernance\nKumar, 2011\nIskhakov et al., \n2018\nPawlak et\
    \ al., \n2018\nFanitabasi, 2021\nAdaptive Multi-Agent Networks\nGovernance\nKumar,\
    \ 2011\nIskhakov et al., \n2018\nPawlak et al., \n2018\nFanitabasi, 2021\nSmart\
    \ City\nFigure 1. Multi-agent systems in smart city applications.\nSelf-adaptiveness\
    \ is one of the main requirements in designing pervasive interconnected\nsystems,\
    \ such as the IoTs and smart cities [13]. The cooperative nature of MAS-based\
    \ systems\nand their learning capabilities enable the designing of robust solutions\
    \ that can adapt their\nconﬁguration and operations when facing unexpected variations\
    \ and disruptions [14].\nTo achieve these abilities, it is necessary to learn\
    \ from previous events, such as abrupt\nenvironmental changes and internal misfunctions,\
    \ and adapt the controlling parameters\nand strategies continuously. The overview\
    \ of a self-adaptive system is presented in Figure 2.\nA self-adaptive MAS constantly\
    \ receives feedback from internal units and the external\nenvironment. The received\
    \ data is monitored and analyzed, and perceptions are fed into\nSmart Cities 2022,\
    \ 5\n320\nthe planning module to decide the next action and response of the system.\
    \ Control com-\nmands are deﬁned considering system’s main goal and the units’\
    \ roles and responsibilities\nin achieving the desired level. Then, actions are\
    \ sent back to the actuating units and\noutcomes are collected for updating the\
    \ next actions and eventually system evaluation\nand modiﬁcations.\nExisting survey\
    \ articles in the literature cover relatively narrow topics of multi-agent\nsystems\
    \ and fail to provide a broad understanding of these systems and their utilization\n\
    in IoTs platforms. Some researchers only focused on particular applications of\
    \ these sys-\ntems [8,15–18] , while others reviewed variations of a certain control\
    \ technique [19–21].\nSuccessful applications of MASs in real-world smart cities\
    \ require a more comprehensive\nsystematic perspective, integrating different\
    \ steps of system deﬁnition, monitoring, plan-\nning, and evaluation. This paper\
    \ enhances the previously published papers related to MAS\nsystems with a systematic\
    \ survey of the steps required to realize future IoTs platforms\nand smart cities.\
    \ Speciﬁcally, we focus on the techniques that enable MAS to perceive\nsystem\
    \ status and environment dynamics and react autonomously to overcome unexpected\n\
    changes and disruptions. The rest of the paper is organized as follows: In Section\
    \ 2, all\nfactors required for deﬁning MAS frameworks are reviewed. Correspondingly,\
    \ Section 3\ninvestigates the state of the art of the models that can be applied\
    \ for data monitoring,\nand the status measurement of these systems. The concepts\
    \ and techniques for planning\nand controlling MASs are listed in Section 4. The\
    \ common platforms for validating and\nevaluating these systems are presented\
    \ in Section 5. The last section provides insights to\nexisting gaps and open\
    \ issues that can be addressed by this research community to achieve\nfully operative\
    \ autonomous IoTs in future smart cities.\nDefine\nMonitor\nPlan  \nParameters\n\
    Perceptions\nEvents\nActions\nEvaluate  \nModifications\nOutcomes\nUpdates\nFeatures\n\
    Goals\nFigure 2. Overview of a self-adaptive MAS.\n2. Deﬁnition Frameworks\nThe\
    \ ﬁrst step for designing an adaptive multi-agent network is to deﬁne the key\n\
    features and requirements of the system. These systems can be identiﬁed based\
    \ on the\ncharacteristics of their entities, operations and actions, information\
    \ ﬂow, and the external\nenvironment that they operate in [8]. Summary of the\
    \ inﬂuencing factors in deﬁning MASs\nis presented in Figure 3.\nSmart Cities\
    \ 2022, 5\n321\nAdaptive Multi-Agent Networks\nEntity\nInformation\nEnvironment\n\
    Action\nNodes\nFeatures (learning level, reliability, ...)\nLinks\nBoundary\n\
    Constraints\nAdaptation Sources\nUncertainty\nObservability\nMessage Passing Platform\n\
    Sharing Level\nFailures\nPhysical paths\nInformation flow\nCloseness\nRoles (leaders,\
    \ followers, ... )\nDevices (actuators, sensors, ...)\nSupport Level\nCollective\n\
    Cooperative\nCollaborative\nCompetitive\nCoordinative\nParameters\nStructure\n\
    Context\nSettings\nResources\nRequirements\nFully Observable\nPartially Observable\n\
    Not Observable\nCentralized\nDistributed\nDecentralized\nDelays\nNoises\nData\
    \ Loss\nTiming\nContinuous\nDiscrete\nEvent Triggered\nFigure 3. Contributing\
    \ factors in deﬁning adaptive MASs.\n2.1. Entities\nA MAS system is a network\
    \ of multiple entities that may or may not interact with each\nother. In most\
    \ of the MAS literature, these systems are mapped into a graph G(v, ϵ) with a\n\
    non-empty set of nodes or agents v = {v1, ..., vN} and edges ϵ connecting these\
    \ agents [22].\nEntity deﬁnes the type of these agents and their communication\
    \ links that can be same\nor different in a MAS platform. Nodes in adaptive multi-agent\
    \ networks varied in their\nassigned devices, roles, features, and dynamics. They\
    \ can be deﬁned as agents reﬂecting\neither software or hardware devices. In the\
    \ IoTs platforms, a node can be a sensor to collect\nthe data, an actuator to\
    \ perform commands, or a combination of both [23]. Nodes are also\ndeﬁned based\
    \ on the role/roles that they play in the network. For example, the agents\nmay\
    \ play leader or follower roles in MASs. The leader is the main decision maker\
    \ in these\nsystems, and has access to the target settings [24]. Other agents\
    \ called “followers” just\nmimic and minimize their distances from the leader.\
    \ Some agents are listeners that can only\nobserve their relative position and\
    \ environment, while other speaker agents are able to\nproduce a communication\
    \ output with other nodes and agents [25]. In the literature, there\nare more\
    \ complex roles, such as meta-agents, that can perform high-level responsibilities,\n\
    such as reasoning for other special-purpose agents [26]. Nodes may also play the\
    \ role\nof external observer or resource, either collecting status data or feeding\
    \ other operating\nagents [27].\nIn real-world heterogeneous MASs, agents/nodes\
    \ also differ based on their features\nand settings, including accessibility,\
    \ energy usage, authority level, and learning and in-\nformation processing capabilities\
    \ [28]. Sometimes agents are identiﬁed based on their\nreliability and performance\
    \ quality in the system. Reliability is the degree of reliance that a\nsystem\
    \ can place on the agent and its information and services. For example, in swarm\
    \ op-\ntimization, agents are categorized and distinguished based on the quality\
    \ of their solutions\nin the previous iteration [29]. In the IoTs systems, some\
    \ agents and elements may be self-\ninterested, with a lack of a global perspective\
    \ of the system [30], and the potential to inject\nunreliable and misleading information\
    \ into the system, which needs extra considerations\nduring modeling and evaluation\
    \ states [31].\nThe agents also differ based on their dynamics and mathematical\
    \ descriptions, ex-\nplaining the movement and evolution of the agents over time\
    \ [32]. These changes are\nthe result of injecting a control input in the agent.\
    \ These dynamics can be expressed as\nlinear or nonlinear models [33]. In linear\
    \ models, we may be faced with a ﬁrst-order single\nintegrator that all agents\
    \ converge to constant values, or double-integrator differential\nequations, which\
    \ agents may converge to multiple ﬁnal states [34]. These models are\nspecial\
    \ forms of general linear models, where the agents are inﬂuenced with state and\
    \ input\nmatrix parameters. Nonlinear agent models also include Lagrangian systems,\
    \ unicycle\nSmart Cities 2022, 5\n322\nmodels, and the attitude dynamics of rigid\
    \ bodies [32]. In the majority of nonlinear models,\nit is assumed that agents’\
    \ nonlinear functions are either unknown or contain unknown\nparameters [35],\
    \ and this uncertainty needs to be addressed by either limiting conditions or\n\
    approximation techniques, such as fuzzy logic systems [36] and neural networks\
    \ [37]. Each\none of these models use different sets of equations to explain the\
    \ dynamics of individual\nagents. Depending on the number of agreement metrics,\
    \ agents’ dynamics can be also\ncategorized as ﬁrst-, second-, and higher-order\
    \ models [8].\nOther than individual nodes, edges and joint connections between\
    \ the agents play an\nimportant role in the controllability of MASs [38,39]. These\
    \ interactions enable cooperation\nbetween agents and reﬂect communication paths,\
    \ such as wires, plans, and routes in\nthe network. They are deﬁned to investigate\
    \ the physical entity ﬂow or information\nsharing between agents [40]. Agents\
    \ in MAS platforms exchange their local states and\ncontrol commands with other\
    \ neighboring nodes or inﬂuencing nodes. The communication\nplatform is shown\
    \ as an undirected graph in cases that both agents can communication\nwith each\
    \ other. In the cases that there is a one-way information ﬂow between agents,\n\
    directed graphs are used to reﬂect these interactions [41]. The links and their\
    \ weights can\nbe also applied to show the similarities and closeness of agent\
    \ pairs in the system.\n2.2. Actions\nMulti-agent systems can be also investigated\
    \ from an action standpoint and distin-\nguished based on their support level,\
    \ requirements, adaptation sources, timing, and con-\nstraints that they may face\
    \ during their operations. Actions or decisions can be deﬁned\nin terms of policies\
    \ that determine a set of actions or probabilities for selecting actions in\n\
    each state of the system [42]. These policies are either deterministic or stochastic\
    \ policies.\nIn deterministic policies, the optimal ﬁxed decisions are determined\
    \ for each state of the\nagent, while in stochastic policies, the probability\
    \ distribution of the actions is deﬁned.\nIn nonstationary systems, the decisions\
    \ vary with time as well [43].\nSupport level refers to the agents’ supports and\
    \ reactions versus other agents’ actions\nand decisions. For example, they may\
    \ follow the same or different goals. Minimizing\noperation errors, maintaining\
    \ a certain status, or maximizing system performance over\ntime are examples of\
    \ these objectives [44]. There are also cases in which agents follow\nmore than\
    \ one goal, which require more complex reward structures [43]. In systems that\n\
    agents have common goals, depending on on their awareness, they may fall into\
    \ one of\nthe collective or cooperative MASs [45]. In collective MASs such as\
    \ robot formations,\nthe agents have the same goal, but agents independently perform\
    \ their own tasks and\nexplore their possible contributions to accomplish the\
    \ system’s main goal [46]. Swarm\nintelligence is also an example of the collective\
    \ systems in which agents optimize the\nmain objective function, and agents’ actions\
    \ are guided by the partial information sharing\nof successful agents with other\
    \ exploring agents [47]. In cooperative MASs, agents are\naware of other agents\
    \ and share their local information to help them achieve their common\ngoals.\
    \ Consensus and rescue agents are two well-known examples of such systems [21].\n\
    In systems with nonidentical goals, we may experience negative or positive interactions\n\
    between agents. Negative interactions refer to the agents competing for shared\
    \ resources\nor agents with conﬂicting individual goals [48]. In systems with\
    \ positive interactions\nsuch as path planning, the agents only focus on their\
    \ own operations while minimizing\ninterference with other agents [40]. In collaborative\
    \ MASs such as machine learning\ntechniques, although agents have different goals,\
    \ they help other agents by sharing their\nexperience and knowledge from their\
    \ environment and rewarding system. There are also\nexamples of multi-agent systems\
    \ with combined positive cooperative intra-group and\nnegative competitive inter-group\
    \ interactions [49].\nIt should be noted that not all goals in real-world problems\
    \ are functional and some\nare deﬁned to meet certain requirements, such as reliability\
    \ and the system’s tracking\nerror [50]. It was shown that the individual contribution\
    \ of the agents on the global solution\ncan be quantiﬁed and speciﬁed by a control\
    \ mechanism [51]. Requirement constraints\nSmart Cities 2022, 5\n323\nusually\
    \ reﬂect the desired output deﬁned by the decision maker. Synchronization, tracking,\n\
    and estimation errors are examples of such constraints in the system [24,52].\
    \ Deadlines\nfor accomplishing tasks can be also considered another form of the\
    \ constraints for the\nMAS [53].\nActions are also categorized based on the source\
    \ of their adaptations. Adaptation\ntechniques are deﬁned in three main groups\
    \ of parameters, structure, and context [13].\nSimilarly in MASs, adaptations\
    \ are achieved by changing a system’s decisions and be-\nhaviors through parameters\
    \ and network structures. These parameters can be deﬁned at\nmacro-level as system\
    \ parameters or at micro-level in terms of agents’ actions and decisions.\nThe\
    \ environment or context can be also altered using the decisions of the actuator\
    \ agents in\nthe system. In some MASs such as formation and tracking controls,\
    \ the agents only focus\non their locating decisions [19]. In other applications\
    \ such as distributed computing, their\nparameter decisions may represent their\
    \ beliefs and estimations for certain variables and\nsystem settings [54]. Settings\
    \ for the level of resource or service that agents provide for\nother agents or\
    \ borrow from other agents are other examples of parameter settings [55].\nAdaptation\
    \ can be also achieved by changing the structure and topology of the system.\n\
    Underlying topology can be ﬁxed or switched over time because of unreliable transmis-\n\
    sion or limitations in the communication and sensing range of the agents. At the\
    \ same\ntime, new agents may join the system and start to create new connections\
    \ and change the\nneighborhood map of the previous agents. Sometimes communications\
    \ may fail due to\nlink failures between two agents [56].\nActions are also distinguished\
    \ based on their timing and sequences [57]. The dynamics\nof the MAS can be shown\
    \ for both continuous-time [58] and discrete-time systems [38].\nOther than time-based\
    \ control techniques, we may deﬁne event-triggered mechanisms\nthat reduce network\
    \ congestion. These techniques initiate and release control commands\nonly after\
    \ detecting triggering conditions deﬁned based on certain error thresholds [59].\n\
    Any sampling [60], transmission [61], estimation [62], or control [63] can be\
    \ modiﬁed to an\nevent-triggered mechanism.\nThe actions of MASs are subject to\
    \ the constraints in their settings, resources, and re-\nquirements [64,65]. In\
    \ an IoTs system in which agents represent devices in the system,\nthe constraints\
    \ can reﬂect settings, technical limitations, or working range of the devices\n\
    in the network [21]. For example, it is necessary to consider the sensing limitations\
    \ of the\nwireless sensor agents or computation capabilities of the agents in\
    \ distributed processing.\nIn practical applications, it is also necessary to\
    \ model boundaries for the operations and\ninputs of actuator agents. These limitations\
    \ can be modeled as input saturation constraints\nduring the MAS modeling phase\
    \ [66]. Communication constraints are caused by physical\nobstacles or artiﬁcial\
    \ settings [67]. They can inﬂuence both agents’ actions and system con-\ntexts\
    \ by limiting network congestion in the system [67]. For example, physical barriers\
    \ may\nlimit the movements and actions of the multi-robot systems and need to\
    \ be modeled as state\nconstraints of the agents [68]. Most of the real-world\
    \ multi-agent systems are also subject\nto constraints in resources, such as data\
    \ sampling, computation, memory, and processing\nresource availability. The energy\
    \ constraint of the individual agents is another constraint\naffecting the design\
    \ and control of the distributed MASs [69]. Bandwidth capacity is a\nconstraint\
    \ that affects the agents’ communications with each other and controller units\
    \ [70].\n2.3. Environment\nAgents interact and inﬂuence the environment during\
    \ their operation period. The en-\nvironment can be deﬁned based on its boundary,\
    \ uncertainty, and observability levels.\nThere is no exact deﬁnition for the\
    \ boundaries of the environment in MASs, but in most of\nthe literature, any external\
    \ surrounding condition of the agents is deﬁned as an environ-\nment [71]. Environment\
    \ boundaries mainly depend on MAS application and in general,\nthey include a\
    \ shared physical, communication, and social structure and space of the agents,\n\
    and resources and services deﬁning the constraints, interaction rules, and relations\
    \ between\nthem [72]. In fact, this abstraction is considered an external world\
    \ that provides a median\nSmart Cities 2022, 5\n324\nfor coordination, maintaining\
    \ the independence of the processes from the actions of the\noperating agents.\
    \ The environment boundaries are also deﬁned based on their interaction\nmediation\
    \ and resource and context management mechanisms [73]. Other external entities\n\
    interacting with agents or monitored by them are also considered part of the environment.\n\
    For example, targets in tracking problems or reference models are part of the\
    \ external envi-\nronment in these problems [74]. In multi-agent programming,\
    \ the environment is models\nbased on aspects such as the action model, agents’\
    \ perception model, a computational\nmodel for internal and external functionalities,\
    \ the data exchange model between agents\nand the environment, and agents’ distribution\
    \ model [71].\nIn most of the real-world MASs, especially in the IoTs domain,\
    \ agents operate in\nan uncertain environment. Therefore, it is necessary to investigate\
    \ the environment’s\nlevel of uncertainty and underlying hidden dynamics. The\
    \ systems may perform in a\ndeterministic environment [75] or be subject to a\
    \ variety of uncertainties that affect the\ncontrollability of the MAS [76]. Uncertainty\
    \ can be caused because of an unknown value\nfunction or constraint of the system\
    \ [44,77]. For example, the location of other agents\nin path planning [78] and\
    \ agents’ behaviors and parameter settings in a heterogeneous\ncontrol [79] can\
    \ be considered as a source of uncertainties in the environment of the agent.\n\
    Uncertainty in communications is another source that becomes critical in MAS networks,\n\
    such as multi-robot systems [80]. Unknown disturbances can be one of the uncertainty\n\
    sources in the MASs environment [81]. Sometimes uncertainty is a result of unmodeled\n\
    dynamics between agents and the environment [82]. The environment can be uncertain\n\
    in such a way that targets appear at random times [83]. Uncertainty may also originate\n\
    in one of the environment parameters [84]. Uncertainty in the environment can\
    \ be also\nreﬂected by injected noises in the system that affect the state of\
    \ the agents [85]. The main\nsource of the uncertainty arises from the operations\
    \ of the other agents that make the\nenvironment unpredictable. These dynamics\
    \ make the environment nonstationary due to\nthe simultaneous learning of the\
    \ agents for the best policies that change the overall state\nof the environment\
    \ constantly [86]. Uncertainty in the environment is usually modeled\nby stochasticity\
    \ in process equations, output/measurement equations, or communication\nchannels\
    \ between the agents [20].\nIn theory, the environment can be modeled on one of\
    \ the categories of the fully\nobservable, partially observable, or not observable\
    \ categories [87]. In fully observable\nsystems, agents are able to perceive complete\
    \ information about the state of the environment\nand its elements, such as resources\
    \ and other agents’ states [74]. Agents in a partially\nobservable environment,\
    \ such as a partially observable MDP (POMDP), are only able to\nlearn partial\
    \ information about the states and their probability distributions instead of\n\
    absolute values [88]. In these systems, the relations between actions and rewards\
    \ are not\nclear and need to be estimated [89]. In a more extreme case, the agents\
    \ may not be able to\nperceive anything about the environment and blindly act\
    \ on their tasks and responsibilities.\nVisibility plays an important role in\
    \ the controllability and efﬁciency of the MASs [90]. Most\nof the developed techniques\
    \ are based on an unrealistic assumption for the observability\nof the environment\
    \ and agents are always under constraints, forcing them to learn the\nabstractions\
    \ of the environment instead of the details. One of the main assumptions for the\n\
    observability of the environment for agents’ actions and their rewards and penalties\
    \ is that\nof the Markovian environment [91]. In this environment, the future\
    \ state of the agents is\ndetermined by their current states. In non-Markovian\
    \ environments, state dynamics are\nmore complex and there may be strong dependencies\
    \ on initial states or changes that are\nepisodic over time [92]. Observability\
    \ can be also limited by agents’ information received\nfrom other agents. For\
    \ example, they may not have access to the communication network\nall the time\
    \ and get disconnected for a period of time [90]. The agents may also have noisy\n\
    observations affecting their perceptions from the environment and other agents\
    \ [93].\nSmart Cities 2022, 5\n325\n2.4. Information Flow\nTo design an effective\
    \ MAS control mechanism, it is necessary to pay attention to\nthe information\
    \ ﬂow between agents that can be deﬁned in the forms of its message\npassing platform,\
    \ information sharing level, and communication failures over time [94].\nInformation\
    \ ﬂow in an adaptive multi-agent network is implemented either for collecting\n\
    agent status and outcomes and sending them to controllers or for delivering commands\n\
    from controllers to interacting agents.\nThe message passing platform reﬂects\
    \ the access level of the agents to high-level\ninformation about system status,\
    \ goals, and constraints. Three main platforms for infor-\nmation ﬂow between\
    \ agents and controllers include centralized, layers or decentralized,\nand distributed\
    \ frameworks (Figure 4). In a centralized approach, one agent has access\nto agent\
    \ information and decides for the whole system [95,96]. Scalability, vulnerability\n\
    to the controller agent failure, and a need for high communication resources for\
    \ agents\nare common problems for this approach. To overcome this issue, some\
    \ researchers used\nassumptions such as the parametric similarity of the agents\
    \ to approximate all policies in\nonly one unique policy [97]. After receiving\
    \ a common policy in this framework, agents\ncan locally explore their policies\
    \ to minimize their own losses. The common policy is\nupdated interactively using\
    \ the feedback received from the trajectories of all agents. These\ntechniques\
    \ are considered as hybrid forms with some levels of decentralized information\n\
    updates and ﬂow between agents. In decentralized or layered approaches, the system\
    \ is\ncontrolled by more than one controller in each layer or community [98].\
    \ This technique is\nconsidered more reliable than the previous technique, but\
    \ it requires a precise deﬁnition\nof the communication and cooperation rules\
    \ between the controllers. The distributed\nform is considered the most common\
    \ technique in controlling MASs, where each agent is\nresponsible for deciding\
    \ and coordinating with other agents to achieve the main goal of the\nsystem [99].\
    \ In this technique agents have full autonomy to select their own actions [100].\n\
    This technique is more robust and scalable. However, it is more challenging in\
    \ terms of\nﬁnding the best decision of the agents given their limitations in\
    \ exploration and information\naccess. None of these platforms are considered\
    \ a best option, and depending on the system\ngoals and resources, one speciﬁc\
    \ platform is chosen.\nCentralized\nDecentralized\nDistributed\nSensor\nActuator\n\
    Controller\nState Data\nCommands\nFigure 4. MAS information ﬂow platforms.\nIt\
    \ is also necessary to consider the knowledge and information sharing levels between\n\
    agents [101]. It was shown that the degree of information sharing directly affects\
    \ the learn-\ning process of the agents and system efﬁciency [102]. Some of the\
    \ agents have minimum\ninformation-sharing regarding expected rewards, agent conﬁguration,\
    \ or adaptation tac-\ntics [28]. Although in most of the existing literature it\
    \ is assumed that agents are only able\nto communicate with their neighboring\
    \ agents, some studies targeted other types of peer-\nto-peer communications between\
    \ agents, such as broadcasting or communications through\nmiddle agents [94].\
    \ The middleware can be a matchmaker that manages and matches the\nright information\
    \ to the right agent or a broker that ﬁlters or rewords the communicated\ninformation\
    \ and then distributes it to the related agents. The agents may also use a trace\n\
    manager that receives the data and sends it to the subscribed agents based on\
    \ their interests\nand registered requests. In the literature, more ﬂexible information\
    \ sharing was proposed,\nwhereby agents are able to compare and choose their own\
    \ communication platforms [103].\nSmart Cities 2022, 5\n326\nThey can also have\
    \ the authority to select their communication source from a list of multiple\n\
    signal sources [104]. On the other hand, targeted communications architecture\
    \ helps agents\nto choose the contents and receivers of their messages in cooperative,\
    \ competitive, or mixed\nenvironments [105].\nThese communication and information\
    \ dynamics are subject to failures and challenges,\nsuch as delays, data losses,\
    \ quantization errors, noises, unknown dynamics, fading channels,\nnodes-access\
    \ competition, and sampling intervals [60]. In communication latencies, state\n\
    information of the neighboring agents is received by delays due to limitations\
    \ on the\ncapacity of communication channels and network congestion [106]. In\
    \ some cases, delays\nare not ﬁxed and vary due to differences in the observability\
    \ of the state over time [107].\nThis is different from input delays that reﬂect\
    \ the processing and connecting times of the\nincoming data ﬂow in the MASs [108].\
    \ The other inﬂuencing factor is to consider data\nlosses in deﬁning MAS communications.\
    \ The packet dropout rate in the network is usually\nvariable and stochastic due\
    \ to ﬂuctuations in the power supply and the trafﬁc of the system,\nand they are\
    \ usually modeled by the Bernoulli process [109]. Information dynamics are also\n\
    designed based on missing information rates during communications and the usefulness\
    \ of\nthe collected information for their decision-making process [110]. Noises\
    \ in agents’ statuses\nand measurements are another challenge inﬂuencing the quality\
    \ of the information ﬂow\nin multi-agent networks [111]. Two major types of noises\
    \ are additive and multiplicative\nnoises. The noises caused by external sources\
    \ are modeled as additive-inﬂuencing nodes\nmeasurements. The multiplicative noises\
    \ are the results of missing information and a\nfailure in modeling the internal\
    \ dynamics of the system, and inﬂuence agents’ states. They\nare also modeled\
    \ as random noise with known probabilities and unknown non-random\nnoise with\
    \ bounded energy or bounded magnitude [62].\n3. Monitoring Paradigms\nTo survive\
    \ in dynamic environments, an adaptive multi-agent system requires the\nconstant\
    \ monitoring of its internal and external states. The data collected by distributed\n\
    sensing agents are processed to explore the environment, evaluate system performance,\n\
    and deﬁne the next optimal actions. The data analysis can be implemented in a\
    \ central\nprocessor or in distributed local processors. The centralized single\
    \ processing of the data\nwill be very challenging given the complex relations\
    \ between agents and the high levels\nof multicollinearity between variables [96].\
    \ Traditional data mining techniques for ﬂat\nvectorial data analysis are inefﬁcient\
    \ for handling large-scale data with inherent relational\ndependencies, weights,\
    \ edge directions, and heterogeneity between system elements [112].\nThe other\
    \ challenge for processing the data collected through MASs is resource limitation\n\
    for transmission, processing, and storing high-dimensional data streams collected\
    \ by the\nagents over time. In the literature, a wide range of techniques were\
    \ proposed for alleviating\nthe data collection burden, and event-triggered data\
    \ sampling is one of the most acceptable\napproaches [62]. Distributed processing,\
    \ data abstraction, and subgraph selection are\nother examples for reducing the\
    \ computation times of data processing in MASs [65]. Some\nresearchers also focused\
    \ on developing innovative techniques for analyzing distributed data\nstreams,\
    \ which are mainly categorized as spatio-temporal data analyzing techniques [113].\n\
    In these techniques, deep learning algorithms such as graph neural networks (GNN),\n\
    graph convolutional networks (GCN), graph autoencoders (GAE), graph recurrent\
    \ neural\nnetworks (GRNN), or graph reinforcement learning were widely applied\
    \ for processing the\ndata collected from interconnected system elements or agents\
    \ [114]. These approaches were\napplied for one of the data mining tasks, such\
    \ as dimension reduction and prediction, and\npattern mining, clustering, and\
    \ anomaly detection in large-scale networks, such as multi-\nagent systems. The\
    \ required analytics for these techniques can be implemented in agent\nor system\
    \ levels. In this survey, we focus on system-level techniques and omit reviewing\n\
    techniques in single-agent levels. This is mainly because most of the agent-level\
    \ techniques\nare implemented on traditional vectorial data and are not speciﬁed\
    \ for MAS platforms.\nSmart Cities 2022, 5\n327\n3.1. Dimension Reduction and\
    \ Filtering\nOne of the main requirements for MASs is a way to abstract the overall\
    \ data stream or\nﬁlter unnecessary information collected over time. This is very\
    \ important in distributed\nsystems such as the IoTs and can considerably reduce\
    \ the computation time of the main\nsystem. These techniques are also effective\
    \ for clustering and categorizing the system status\nor their quick comparison\
    \ with the target network.\nSome initial techniques for abstracting MASs and their\
    \ relations was the use of graph\ntheory and the eigenvectors of the network adjacency\
    \ matrix [115]. These techniques are\nnot sufﬁcient for complex systems with dynamic\
    \ multi-dimensional agents. To solve this\nproblem, encoding techniques such as\
    \ GAE were applied for encoding or decoding graphs\ninto vectors [114]. The encoding\
    \ techniques are called network-embedding mechanisms\nand may encode the topological\
    \ features of the nodes and their ﬁrst- and second-order\nproximity information\
    \ [116], agents’ attributes [117,118], MAS dynamics and evolution over\ntime [119],\
    \ and information diffusion or dynamic role evolutions [120]. Generative network\n\
    automata techniques are also applied for the simultaneous representation of the\
    \ state transi-\ntions and topology transformations of the network based on graph\
    \ rewriting concepts [121].\nOther deep neural techniques that can be applied\
    \ for MAS abstraction include long–short-\nterm memory (LSTM) recurrent neural\
    \ networks and variational autoencoders [122]. Some\nof these techniques can be\
    \ also utilized for modeling opponent agents based on the local\ninformation of\
    \ the main agents [123]. Some knowledge distillation techniques such as\npruning\
    \ and low-rank decomposition can be also applied for original multi-agent systems\n\
    to remove redundant information collected from distributed agents [124]. There\
    \ are other\nabstraction techniques in the literature that reduce the number of\
    \ local states by collaps-\ning data values. These techniques are mostly applied\
    \ for the veriﬁcation and testing of\nmulti-agent systems [125]. Traditional dimension-reduction\
    \ techniques such as principal\ncomponent analysis were also modiﬁed successfully\
    \ and applied for multi-agent networks,\nsuch as WSN [126]. The only drawback\
    \ of these techniques is their high computation time\nfor large-scale systems\
    \ and losing the neighborhood pattern of the agents. This can be\nsolved by relying\
    \ more on the structural roles of nodes and increasing the ﬂexibility of\nlearning\
    \ node representations [127]. Learning over a common communication grounding\n\
    through autoencoding was another solution to reduce computation time and increase\
    \ total\nsystem performance [128].\n3.2. Anomaly Detection\nThe remote access\
    \ of different devices and the distributed nature of computing in\nthe IoTs makes\
    \ it vulnerable to various attacks. Many different techniques were proposed\n\
    to identify anomalies in distributed platforms, such as MAS [129]. Anomalies are\
    \ states\nof the system that remarkably differ from normal system operations.\
    \ These techniques\ncan be applied for malicious interactions or attacks that\
    \ may delete or manipulate the\ndata related to the network structure and node\
    \ or link statuses [130]. Anomalies can be\nin three different levels, such as\
    \ point, contextual, or collective anomalies [114]. In point\nanomalies, irregularity\
    \ happens in one agent that can be observed without any reason.\nContext abnormalities\
    \ include a higher range of agent anomalies over time. For example,\ncommunication\
    \ patterns may change in part of the MAS. In collective anomalies, agents\nalone\
    \ may seem completely normal, but a collection of the data collected from agents\n\
    shows unusual patterns. The survey for the anomaly detection in the node, edge,\
    \ subgraph,\nand graph levels is reviewed in reference [131]. These anomalies\
    \ can emerge in structural,\nattributed, or dynamic temporal graphs. In node-level\
    \ anomaly detection, the agents\nthat are signiﬁcantly different from other agents\
    \ are identiﬁed. In the IoTs platform, that\ncan reﬂect abnormal users or a network\
    \ intruder that injects fake information into the\nsystem [132]. These nodes also\
    \ can represent agents with performances considerably\ndeviating from the rest\
    \ of the agents. In edge-level anomaly detection, unusual and\nunexpected connections\
    \ and relations between agents are identiﬁed [133]. Subgraph-level\nanomaly detection\
    \ focuses on multiple agents that collectively show anomalous behavior.\nSmart\
    \ Cities 2022, 5\n328\nIdentifying this group of agents will be very challenging\
    \ and usually bipartite graphs\nare utilized to identify dense blocks in these\
    \ networks [134]. Sometimes the anomalies\nare identiﬁed at a graph level and\
    \ in certain snapshots of the temporal system, using its\nunusual evolving patterns\
    \ and features. Deep neural networks such as LSTM were widely\napplied for this\
    \ purpose [135]. Multi-agent systems are introduced as an efﬁcient platform\n\
    for anomaly detection techniques for IoTs systems [129]. Other techniques such\
    \ as Kmean\nclustering proved their effectiveness for identifying unusual patterns\
    \ of collected data in\ndistributed networks [136].\n3.3. Predictive Models\n\
    Predictive models can be applied at either system or entity levels for predicting\n\
    certain features and characteristics over time [137]. For example, knowing and\
    \ predicting\nfuture topological changes, such as removing and adding agents and\
    \ new communications\npatterns, can have a substantial effect on designing control\
    \ protocols. Deep graph generative\nmodels are widely used for this purpose to\
    \ model a network structure without knowing its\nstructural information [138].\
    \ They may also utilize recurrent neural networks for predicting\nfuture connections\
    \ or edges in the graph based on node-ordering procedures [112]. There\nare other\
    \ techniques that utilize efﬁcient sampling strategies to extract patterns in\
    \ input\ndata and learn their dynamics to generate a predicted temporal network\
    \ [139]. Other than\nstructural patterns of the system, estimating future states\
    \ of other agents can help agents\nto optimize their own actions more efﬁciently.\
    \ It was proved that convolutional neural\nnetworks successfully captured the\
    \ spatio-temporal characteristics of the networked entities\nand predicted their\
    \ future features (nodes) and communications (edges) with neighboring\nagents\
    \ [140]. As an example, predicting the future trajectories of the agents is one\
    \ of the\ncommon problems in the literature, with a main application in robot\
    \ planning, autonomous\ndriving, and trafﬁc prediction [141]. These estimation\
    \ techniques are useful in missing\ndata treatment of IoTs systems as well [142].\
    \ The other application of predictive models\nis in the early detection of events\
    \ in event-triggered techniques or identifying hotspots\nwith an unusual density\
    \ of certain events [143]. Classiﬁcation techniques for a network\nof connected\
    \ agents can be applied for the performance monitoring of the system and\ninitiating\
    \ corrective actions if classiﬁed as an abnormal graph [144]. One of the common\n\
    platforms for this purpose is DeepSphere, which was applied to learn the evolving\
    \ patterns\nof a system over time and identify anomalous snapshots of the network\
    \ over time [145].\nThe distributed estimation of certain features of the system\
    \ or environment is another\nexample for system-level predictive models. These\
    \ techniques can either run at the same\ntime or need consensus in their two sampling\
    \ stages, and utilize a wide range of approaches,\nincluding the adaptive observer,\
    \ Kalman ﬁlter, Luenberger observer, Bayesian ﬁlter, belief\npropagation inference,\
    \ and the H∞ ﬁlter [146].\n3.4. Clustering\nMonitoring MAS dynamics can be also\
    \ targeted for clustering agents based on their\nperformance or hidden interestsThis\
    \ is mainly because grouping agents may help to iden-\ntify non-cooperative agents\
    \ or design more dedicated control frameworks for each group of\nthe agents [147].\
    \ Sometimes clustering is helpful when heterogeneous agents show different\ndynamics\
    \ in consensus, which requires more customized control protocols [148]. The simi-\n\
    larities between a group of agents or their trajectories can be measured by dynamic\
    \ corre-\nlations between agents [149] or using principal component analysis (PCA)\
    \ projects [150].\nClustering agents can be investigated by applying traditional\
    \ graph partitioning and com-\nmunity detection techniques, such as spectral clustering,\
    \ hierarchical clustering, Markov\nmodels, and modularity maximization methods\
    \ [151,152]. Deep learning is also considered\nan effective tool for community\
    \ detection in high-dimensional multi-label graph-structured\ndata [153]. This\
    \ problem was also investigated in dynamic time-varying graphs, with the\nevolution\
    \ of groups and their growth, contraction, merging, splitting, and birth and death\n\
    over time [154]. The results show that the emergence of these communities is independent\n\
    Smart Cities 2022, 5\n329\nof initial measurements and settings and mostly depends\
    \ on node dynamics, underlying\ninteraction graphs, and coupling strengths between\
    \ agents [155]. Cluster dynamics are also\ninvestigated in controlling a swarm\
    \ of agents in formation control and their aggregation,\nand splitting patterns\
    \ and other quantitative features, such as size and cluster distances\nfrom each\
    \ other [156]. Sometimes, clustering is a dynamic process in which agents with\n\
    similar behaviors ﬁnd each other and join together in the state space [157]. This\
    \ will be\nsimilar to the dynamics of the group consensus techniques presented\
    \ in the literature [158].\nOther similar variations were proposed for deﬁning\
    \ monitoring agents to optimize the\nprocess of automated clustering [159].\n\
    3.5. Pattern Recognition\nTo design more robust and resilient MASs, they should\
    \ be able to learn the behavior of\nother agents and environment dynamics to improve\
    \ their performance over time. Pattern\nmining is considered one of the main techniques\
    \ for knowledge discovery and identifying\ncausal structures and associations\
    \ [160]. For this purpose, graph pattern mining techniques\nare recognized as\
    \ suitable approaches for knowledge discovery in multi-agent network\nsystems.\
    \ The pattern mining techniques can focus either on structural patterns such as\n\
    frequent subgraphs, paths, cliques, and motifs, or the label evolution patterns\
    \ of dynamic\ngraphs with single or multiple attributes [161]. Knowledge discovery\
    \ on graphs can be also\napplied to ﬁnd periodic patterns that repeatedly are\
    \ observed in agents’ communications or\nstates [162]. Sometimes considering more\
    \ than one label in agents and their communications\nadds interesting ﬁndings\
    \ for the dynamic changes of the attributed multi-agent graph.\nAs an example,\
    \ mining-trend motifs help to identify a group of nodes or agents that show\n\
    similar increasing or decreasing trends over time [163]. More complex trends such\
    \ as\nrecurrent trends are identiﬁed in a set of nodes over a sequence of time\
    \ intervals using\nalgorithms, such as RPMiner [164]. The identiﬁed patterns in\
    \ attributes and states may\nentail changes in the network topological structures\
    \ and agnets communication, which are\nknown as triggering patterns [165]. It\
    \ was shown that in the pattern mining of multi-agent\nnetworks, relying on occurrence\
    \ frequency is sometimes misleading and new metrics such\nas sequence virtual\
    \ growth rate are necessary to identify highly correlated patterns with\na signiﬁcant\
    \ trend sequence in the graph [166]. Norm mining is another category that\ninvestigates\
    \ events triggering rewards and penalties and identiﬁes the norms in a varying\n\
    environment setting [167]. This will help agents to survive and adapt to their\
    \ environment\nwithout the deprivation of their resources and services.\n4. Development\
    \ Approaches\nMulti-agent systems are one of the main paradigms proposed for implementing\
    \ the\nIoTs. The ﬁrst step for developing these systems is to determine their\
    \ main platform and\ndeﬁne the features reviewed in Section 2. Then, appropriate\
    \ learning mechanisms are\nselected to empower their adaptiveness against a new\
    \ environments and possible changes\nin external and internal dynamics. At the\
    \ end, a suitable control mechanism is designed to\nguarantee achieving the main\
    \ goals of the system.\n4.1. Main Platform\nAdaptive multi-agent networks are\
    \ developed on the main platform, enabling informa-\ntion ﬂow, intelligent learning,\
    \ and the real-time decision making of the included agents and\nelements. This\
    \ abstraction framework for modeling the structural, behavioral, and social\n\
    models of the agents can be deﬁned using appropriate an AOP, which is a specialization\
    \ of\nobject-oriented programming [168]. These platforms initially were inspired\
    \ by adaptive\norganizational models and later more structured techniques (e.g.,\
    \ JADE) were proposed\nin the software engineering domain [169]. Rapid advances\
    \ in computation capabilities\noffered more customized models, such as O-MaSE,\
    \ that utilized three concepts of the meta-\nmodel, method fragments, and guidelines\
    \ based on method engineering concepts [170].\nThese platforms varied case by\
    \ case and targeted either a speciﬁc application domain, such\nSmart Cities 2022,\
    \ 5\n330\nas a microgrid [15], or ﬂexible general-purpose platforms [171]. Some\
    \ of the program-\nming languages applied for implementing agent-oriented platforms\
    \ include Java, C/C++,\nPython, AgentSpeak, NetLoGo, XML, and GAML [172]. The\
    \ majority of these platforms\nare designed by adding reasoning and cognitive\
    \ models, such as the procedural reasoning\nsystem (PRS) and/or belief–desire–intention\
    \ (BDI) models [173]. PRSs help reasoning about\nprocesses, enabling agents to\
    \ interact with the dynamic environment and use procedures\nfor selecting intentions.\
    \ These procedures are triggered when they can contribute to achieve\ncertain\
    \ goals. In a BDI model, which is the most common approach, the behavior of the\n\
    agent is deﬁned in terms of its beliefs, goals, and plans. In this model, the\
    \ interpreter is re-\nsponsible for updating these features based on the feedback\
    \ received from the environment\nand the managing agents’ intentions/or actions.\
    \ These models showed great success in\nintegrating AI as a pluggable component\
    \ [174] or in meta-level plans [175]. The multi-agent-\noriented programming (MAOP)\
    \ platforms such as JaCaMo have a structured approach\nbased on three concepts\
    \ of agent, environment, and organization dimensions [176]. They\nalso successfully\
    \ integrated with the IoTs to offer self-adaptive applications in human-\ncentric\
    \ environments [177]. Systems of systems is another efﬁcient methodology to develop\n\
    meta-models to manage MASs with different subsystems [178]. During the last decades,\n\
    tens of these approaches and updates for old versions were proposed. To choose\
    \ the best\noption from the long list of the proposed AOP techniques and platforms,\
    \ they can be com-\npared based on basic platform properties, usability and scalability,\
    \ stability and operating\nabilities, security management, and their applicability\
    \ in practice [172]. They also need to\nbe investigated and evaluated based on\
    \ their architectural debt and their long-term effects\non the health of a software\
    \ system [179]. The evaluation frameworks for agent-oriented\nmethodologies are\
    \ reviewed in reference [180]. Although various AOPs were proposed in\nthe literature,\
    \ they still suffer strong reasoning and decision modules for modeling costs,\n\
    preferences, time, resources, and durative actions, etc., [181]. As a result,\
    \ developers are\nstill reluctant to switch to these platforms and prefer to utilize\
    \ the current programming\nlanguage with small modiﬁcations of the main code [181].\n\
    4.2. Learning Mechanism\nOne of the main frameworks in adaptive multi-agent networks\
    \ is their learning mech-\nanism. Most of the recent learning frameworks are online,\
    \ helping the system to learn the\ndynamics of their environment and the best\
    \ responses to these changes. Various aspects\nsuch as knowledge-access level\
    \ and learning technique were investigated for grouping\nthe MAS learning literature\
    \ [182]. Agents may have full autonomy to learn and share\ntheir knowledge with\
    \ other agents [100] or may be restricted to only communicate and\nshare their\
    \ states with a central learner [183]. If learning is system-wise, one agent or\
    \ the\nmain ruler learns the policies for all agents in the system. In this case,\
    \ the learner has\nfull observability to discover the states of the involved agents\
    \ without a detailed focus\non the individual agent’s actions. In this learning\
    \ mechanism, information is collected\nfrom distributed agents and fed to the\
    \ central learner of the system. This helps to achieve\nhigh-level information\
    \ about system dynamics without getting trapped in the difﬁculties of\ncoordinating\
    \ information ﬂow between multiple learners. Centralized learning and train-\n\
    ing can be integrated with either a central decision maker or decentralized excitation\
    \ [184].\nIn the second category, the centralized learner learns the value function\
    \ using the criteria\nfor guiding distributed actors [185]. The centralized learning\
    \ mechanisms suffer from\nproblems such as the complexity of the state process\
    \ and learning process. They were also\ndeveloped based on some unrealistic assumptions,\
    \ such as consistent and complete access\nto all agents’ information. The other\
    \ challenge of centralized learning is its vulnerability\nagainst the failures\
    \ of the learner, a need for the high computation and memory resources\nin the\
    \ central learner, and scalability for large-scale systems with thousands of distributed\n\
    agents [186]. As a result of this learning, it may entail homogeneous team learning\
    \ with one\npolicy for all agents or heterogeneous learning with a unique behavior\
    \ for each individual\nagent [187]. Other variations of this platform to alleviate\
    \ the listed challenges are QMIX\nSmart Cities 2022, 5\n331\nwith mixed global\
    \ and local components [188]. Coordinated sampling by means of the\nmaximum-entropy\
    \ RL technique and policy distillation were other proposed solutions for\nimproving\
    \ centralized learning mechanisms [189]. There are also some hybrid techniques\n\
    that agents learn individually but then share in a centralized common knowledge\
    \ memory\nfor sorting and storing their knowledge [190]. In distributed learning\
    \ techniques, each\nagent is responsible for their own learning [191]. In these\
    \ learning frameworks, the agents\nhave limited observability and only explore\
    \ their surrounding environments and they are\nunable to learn the overall dynamics\
    \ of the systems in real-time. Most of these learning\ntechniques are integrated\
    \ with the decision-making process of the control mechanisms.\nThe role-based\
    \ learning technique is another trend in the literature in which the complex\n\
    tasks are decomposed into different roles. The RODE technique is one of the examples\n\
    for such learning that utilize agents clustering to discover roles and the required\
    \ learning\ngroups [90]. The learning and updating learned models can get initiated\
    \ based on certain\nevents or on discrete or continuous-time updates over the\
    \ system’s operation. Some of\nthe common learning techniques applied in the literature\
    \ include reinforcement learning,\nsupervised learning, deep learning, game theory,\
    \ probabilistic, swarm systems, applied\nlogic, evolutionary algorithms, or a\
    \ combination of some of them [192]. Since most of these\ntechniques were applied\
    \ for the simultaneous learning and control of the MASs, they are\nreviewed in\
    \ the next section. Some of the proposed techniques for learning are initiated\n\
    after receiving initial domain knowledge. In the literature, these techniques\
    \ are identiﬁed\nas transfer learning methods [182].\n4.3. Control Solutions\n\
    Control solutions can be investigated from aspects such as applications and techniques.\n\
    There are some literature that surveyed existing control techniques for multi-agent\
    \ sys-\ntems [193]. They focused on interaction limitations and categorized them\
    \ into sensing-based\ncontrol, event-based control, pinning-based control, resilient\
    \ control, and collaborative\ncontrol. This sections reviews the applications\
    \ and techniques of MASs control especially\nthose that can be applied in controlling\
    \ and managing smart cities.\n4.3.1. MASs Applications\nThe multi-agent systems\
    \ control is applied for a variety of domains including consen-\nsus and synchronization,\
    \ leader-following coordination, formation control, containment\nand surrounding\
    \ control, coverage, and distributed optimization and estimation [32,194].\nConsensus\
    \ and synchronization are the most common domains for the MAS literature.\nThe\
    \ main goal in this category is to reach an agreement in all agents and lead their\
    \ states\nto a common state or time-varying reference [21]. This is achieved by\
    \ monitoring and\ninformation exchanges between neighboring nodes. Therefore,\
    \ consensus highly depends\non the communication graphs between agents and their\
    \ information sharing levels [195].\nOne of the main features of a smart city\
    \ is consensus between smart service systems that\ninteract and coordinate decisions\
    \ in the system. For example, in a typical autonomous\ntransportation method,\
    \ multiple agents such as client agents, car agents, parking agents,\nroute agents,\
    \ and many other agents interact with each other while seeking the agreement\n\
    and balance of interests [196]. Other examples for the application of MAS consensus\
    \ are\npresented for smart parking that tests various negotiation strategies to\
    \ reach agreement\nbetween the involved agents [197]. Applications of consensus\
    \ in other platforms of a smart\ncity such as in block chains [198] and smart\
    \ grids [199], a smart factory [200], or other\nservices provided by multi-robot\
    \ rendezvous [201] are investigated in the literature. Con-\nsensus can be also\
    \ applied for distributed computing where different processors need to\nreach\
    \ the same estimation after iterative computations [21]. Leader–follower consensus\
    \ can\nbe considered as a special case of consensus in which the main goal is\
    \ to minimize tracking\nerror and state difference between leader and follower\
    \ agents [24]. Examples of leader–\nfollower control for smart city applications\
    \ are presented for IoTs-based digital twins [202]\nand irrigation management\
    \ systems [203]. This can be used in pinning control, in which\nSmart Cities 2022,\
    \ 5\n332\nthe leader reﬂects the desired trajectory of the system [41]. One of\
    \ the best applications\nof pinning control is to restore complex cyberphysical\
    \ networks in the smart city to their\ninitial states after mixed attack strategies\
    \ [204]. Group consensus is another variation in\nwhich agents with different\
    \ task distributions converge to multiple consensus values [205].\nApplications\
    \ of this consensus for capturing the supportability of applications on smart\n\
    city platforms and the IoTs [206], or recovery control with ideal structures [207],\
    \ are also\npresented in the literature.\nFormation control is another domain\
    \ for applying MASs [19]. In this category of\ncontrol framework, network evolution\
    \ is guided to reach and maintain a desired geo-\nmetric form by monitoring and\
    \ controlling their absolute or relative distance from other\nagents [208]. In\
    \ problems with monitoring agents’ positions, depending on their interac-\ntions\
    \ with other agents, they might follow displacement-based control [209] or distance-\n\
    based control mechanisms [210]. The relative position of neighboring agents is\
    \ measured\nwith respect to a global coordinate system in displacement-based control,\
    \ while the base\nis changed to the agent’s local coordinate system in distance-based\
    \ control systems [19].\nFlocking is a special case of formation control in which\
    \ the main goal is to keep all agents\nat an equal distance from their neighbors\
    \ [211]. Applications of formation control in smart\ncities are presented in the\
    \ literature for search and rescue, operations, intelligent highways,\nand mobile\
    \ sensor networks [212]. Flocking is another techniques that can be used to solve\n\
    robust problems in distributed environments [213]. In this technique, a large\
    \ number of\nagents organize into a coordinated motion using three simple rules\
    \ of cohesion, separation,\nand alignment [214]. One potential application for\
    \ this technique can be forming a setting\nin which each agent is equally distanced\
    \ from its neighbors [32]. This idea is applied to\npropose simple and scalable\
    \ protocols for the migration of virtual machines (VMs) in IoTs\ncloud platforms\
    \ [215].\nContainment control is similar to distributed average tracking with\
    \ multiple leaders.\nHowever, in this technique, the control protocol guides the\
    \ followers and their state de-\ncisions to the convex hull formed by the leaders\
    \ instead of leaders’ state averages [216].\nThis can be helpful in smart cities\
    \ when a failure or accident happens in certain areas.\nContainment control guides\
    \ multi-agents such as autonomous robots to secure and remove\nundesirable outcomes\
    \ while limiting their movements into other populated areas in the\ncity [217].\
    \ In the surrounding control problems, the main goal is to protect a set of sta-\n\
    tionary or moving agents from possible threats surrounding them using other controlled\n\
    agents [218]. One of the main applications for this technique is unmanned ground\
    \ vehi-\ncles or unmanned surface vessels [219]. There are very few applications\
    \ for containment\nand surrounding control in the literature and this area needs\
    \ further investigation to ﬁnd\nsuitable applications in future connected smart\
    \ cities [220].\nOne of the common goals in utilizing MASs is distributed optimization\
    \ [49]. These\ntechniques cover problems such as constrained, unconstrained, dynamic,\
    \ and time-varying\nmodels. The applications for this domain of MAS control in\
    \ smart cities are promising [221].\nExamples of such applications are presented\
    \ in energy [222,223], transportation [148,224],\nhealth care [225], and supply\
    \ chains [226,227]. Task allocations in cloud computing plat-\nforms are considered\
    \ as one of the main applications of distributed multi-agent optimization\nin\
    \ smart cities [220]. Distributed estimation can be also reformulated as a distributed\
    \ opti-\nmization problem in which the main goal is to reduce computation time\
    \ and estimation\nerror by splitting the task between multiple agents [228,229].\
    \ Some of the variations for this\ndomain include distributed parameter estimation\
    \ and distributed data regression using an\naverage consensus algorithm, and a\
    \ distributed Kalman ﬁltering algorithm [32]. One of the\nmain applications of\
    \ distributed estimation in smart cities is monitoring the environmental\nstate\
    \ using deployed sensors in the system [142]. The state estimation of wireless\
    \ power\ntransfer systems in IoTs applications [230], and crowd sensing [231],\
    \ are other examples of\ndistributed estimation in smart cities. Simulating real-world\
    \ systems can be also considered\none of the initial applications of multi-agent\
    \ systems [232].\nSmart Cities 2022, 5\n333\n4.3.2. Control Techniques\nIn the\
    \ literature, various techniques were applied for controlling multi-agent systems,\n\
    namely graph theory, game theory, control theory, and machine learning, which\
    \ are con-\nsidered the most commonly used techniques for this purpose [29,45].\
    \ There are also other\nalgorithms such as optimization and bio-inspired algorithms,\
    \ which were applied for the\ncollective behavior of these systems [233].\nGraph\
    \ theory was applied for deﬁning the structural controllability of multi-agent\n\
    systems [234]. One of the most frequently used techniques in this domain is to\
    \ use a graph\nLaplacian matrix to investigate MAS dynamics and convergence rates\
    \ [67]. In the literature,\nconsensus problems were also investigated using an\
    \ edge Laplacian matrix by deﬁning the\nedge state as a relative state difference\
    \ for the edges [235]. The graph Laplacian spectrum\nhas the second smallest and\
    \ largest eigenvalues and their ratios play an important role\nin MASs control\
    \ [236]. In recent literature, graph theory was mostly used for an initial\nanalysis\
    \ of the network dynamics, and other complementary approaches were applied\nto\
    \ reach consensus states [237]. Applications of graph theory are not limited to\
    \ using an\nLaplacian matrix and, in some cases, only adjacency and valency matrices\
    \ were applied to\ninvestigate the network dynamic and its synchronization [238].\n\
    Game theory is another popular technique for modeling the dynamics and decision\n\
    making of rationale collaborator agents in MASs [239]. In most of the distributed\
    \ games,\nthe main goal is to reach the Nash equilibrium while optimizing its\
    \ own performance\nmetric [240]. Markov games or stochastic games are examples\
    \ of the initial applications\nof sequential multi-agent games that can be solved\
    \ using dynamic programming (DP),\nQ-learning, or linear programming techniques\
    \ [45]. Uncertainties in an agent’s payoff and\nreward/utility can be also modeled\
    \ using Bayesian–Stackelberg games [241]. Evolutionary\ngames are other variations\
    \ of game theory techniques applied for modeling the collec-\ntive behavior of\
    \ the agents, with bounded rationality repeatedly looking for equilibrium\npoints\
    \ [242]. The majority of the MAS problems were solved using control theory and\n\
    its variations, such as adaptive control. For example, distributed model predictive\
    \ con-\ntrol is widely applied for modeling different types of dynamics, with\
    \ goals of regulation,\ntracking, or economic considerations in the system [64].\
    \ A survey for online learning\ncontrol mechanisms in multi-agent systems was\
    \ presented [194]. Neuro-adaptive optimal\ncontrol is considered one of the most\
    \ popular techniques in controlling complex MASs\nby solving an associated matrix\
    \ of equations, such as the coupled Riccati equations or\ncoupled Hamilton–Jacobi\
    \ equations [243]. In the literature, other traditional optimization\ntechniques\
    \ such as variational inequality [106], duality theory [244], and the alternating\n\
    direction method of multipliers (ADMM) [245] were applied for optimizing the operations\n\
    of multi-agent systems.\nReinforcement learning is one of the well-known semi-supervised\
    \ learning techniques\napplied in the simultaneous learning and control of adaptive\
    \ MASs [246]. The multi-\nagent reinforcement learning (MARL) technique is usually\
    \ applied for perceiving the\nenvironment based on partial information, such as\
    \ rewards and penalties received as\nfeedback from the previous actions and decisions\
    \ [86]. Other techniques developed based\non RL include Q-learning and policy\
    \ gradient techniques that try to learn the optimal policy\nof the agents. The\
    \ MARL techniques with networked agents are a special case of the MARL\nalgorithms,\
    \ in which agents can communicate with neighboring agents in a time-varying\n\
    communication topology [247]. These algorithms were developed for both cooperative\n\
    and non-cooperative settings. Using RL in MASs is very challenging because of\
    \ the joint\naction space and dynamics generated with multiple autonomous decision\
    \ makers that\nmake the environment nonstationary and difﬁcult to be perceived\
    \ [248]. Using an ensemble\nof the policies is another technique proposed for\
    \ designing control frameworks robust\nto environmental change and nonstationary\
    \ dynamics [249]. Reference [188] proposed\nQMIX, which exploits a linear decomposition\
    \ of the joint value function across agents\nwhile keeping the local and global\
    \ maximum value functions monotonically over standard\nQ-learning. The other challenge\
    \ is the high computation time for processing continuous\nSmart Cities 2022, 5\n\
    334\nstates and actions in MAS settings modeled by the Markov decision process,\
    \ Markov\ngame, or extensive form games [250]. In these settings, due to increasing\
    \ number of\nstate action pairs, it is very challenging to approximate value function\
    \ or optimal policy.\nOne of the main solutions for this problem is to apply deep\
    \ reinforcement learning(DRL)\nthat integrates deep neural networks in the learning\
    \ process of RL iterations [251]. Two\nwell-known variations of these techniques\
    \ include deep Q-learning [252] and the deep\ndeterministic policy gradient (DDPG),\
    \ which are designed based on actor–critic networks\nwith a replay buffer [253].\
    \ Policy gradient techniques such as DDPG perform better in\nMASs due to the independence\
    \ of approximation from system dynamics. Other challenges\nof using RL-based control\
    \ mechanisms in MASs include credit assignment problems that\nreﬂect a lack of\
    \ tracing agents’ actions and their inﬂuences on system outcomes [187]. This\n\
    problem may result in the emergence of lazy inactive agents not willing to contribute\
    \ to\nlearning system dynamics. One of the proposed platforms for addressing this\
    \ challenge is\ncounterfactual multi-agent (COMA) policy gradients using a counterfactual\
    \ baseline that\nkeeps other agents’ actions ﬁxed while marginalizing the actions\
    \ of the single agent [185].\nAn overview of the reviewed techniques is presented\
    \ in Figure 5.\nDomains\nConsensus & \nSynchronization\nLeader/Follower \nTracking\n\
    Formation Control\nContainment  & \nSurrounding\nCoverage Control\nDistributed\
    \ \nOptimization\nDistributed Estimation\nTechniques\nReinforcement Learning\n\
    MARL\nQMIX\nCOMA\nDRL\nDDPG\nGraph Theory\nControl Theory\nTraditional Optimization\
    \ \nADMM\nDuality Theory\nVariational Inequality\nGame Theory\nNeuro-Adaptive\n\
    Adaptive Control\nMPC\nDQN\nFigure 5. MAS control overview.\n5. Evaluation Metrics\n\
    The next step in implementing adaptive MASs is their evaluation and validation.\
    \ We\nfocus on two main factors for this topic that include the main performance\
    \ indicators\napplied for evaluating these systems and also existing test platforms\
    \ and datasets applied\nfor this purpose.\n5.1. Performance Indicators\nThe performance\
    \ of MASs is calculated based on various factors, such as convergence,\nstability,\
    \ optimality, robustness, security, and other practical indicators, such as the\
    \ quality\nof services, security, scalability, and bandwidth utilization [46].\
    \ The performance of MASs\ncan also be measured based on more practical statistical\
    \ and quantitative factors for outputs\nand resource utilization, such as throughput,\
    \ response time, the number of concurrent\nagents/tasks, computational time, and\
    \ communications overheads [254].\nSmart Cities 2022, 5\n335\nConvergence is applied\
    \ in many MASs techniques and is considered one of the main\nperformance criteria\
    \ of the algorithm. The Nash equilibrium is a point and setting that\nall agents\
    \ will prefer in which no agent can gain any more by changing only its own\ndecisions.\
    \ This point highly relies on its underlying assumptions, such as the rationality\n\
    and reasoning capabilities of the agents [255]. Since convergence is not practical\
    \ in real-\nworld problems, researchers presented ﬁnite time convergence rules\
    \ for controlling MASs.\nThe main drawback of these rules is their dependency\
    \ to initial states that makes them\ninfeasible for cases with unknown initial\
    \ states. Therefore, a ﬁxed time stability rule is\npresented that works well\
    \ with any arbitrary initial state of the agents. This type of analysis\nwas tested\
    \ for both time-triggered, and event-triggered systems and worked efﬁciently for\n\
    both categories of the problems. These assumptions are violated in the bounded\
    \ rationality\nand limitations of the mutual modeling of the agents. Moreover,\
    \ it was shown that many\nof the value-based MARL algorithms do not converge to\
    \ a stationary NE, and we may\nneed to deﬁne cyclic equilibrium instead of unique\
    \ states. To overcome this problem, some\nof the recent techniques used regret\
    \ concepts instead of NE, which measure performance\ncompared to the best static\
    \ strategy of the agents.\nStability is one of the main indicators in evaluating\
    \ the control mechanism of MASs.\nThis measure shows whether the proposed scheme\
    \ will deviate the convergence of the\nagents when facing future changes of the\
    \ state and output of the system and distribu-\ntions [256]. Lyapunov-based stability\
    \ is known as one of the primary methods for testing\nthe stability of MASs [257].\
    \ The Routh–Hurwitz stability criterion was also applied for\na stability analysis\
    \ of high-order consensus problems [258]. A system is also considered\nstable\
    \ if after disturbance its solution and state are bounded in a certain region.\
    \ It was\nproved that stability analysis for the cooperative control of heterogeneous\
    \ agents with\nnonlinear dynamics is more challenging and needs error compensation\
    \ controllers to elim-\ninate error dynamics for the equilibrium point [259].\
    \ Barbalat’s Lemma is an extension\nfor Lyapunov analysis that overcomes the limitations\
    \ of this technique in handling the\nstability of autonomous and time-varying\
    \ nonlinear systems [260]. One of the measures to\nevaluate the proposed control\
    \ mechanism is optimality, in which the solution is compared\nwith the optimal\
    \ solution of the centralized technique [64]. It is also important to quantify\n\
    the optimality gap or bounds that the solution deviates from in its equivalent\
    \ centralized\nproblem solution [261]. Most of the MAS problems involve a nonconvex\
    \ objective function\nwith the local optimum point. To improve the efﬁciency of\
    \ the search of the agents, some\nresearchers deﬁned conditions for the optimality\
    \ of the consensus protocols [262].\nRobustness is deﬁned to reﬂect the control\
    \ system’s capability in handling future exter-\nnal unknown perturbations [263].\
    \ Determining the robustness of MASs with a large number\nof nodes is an NP-hard\
    \ problem such that its calculations require more complex techniques,\nsuch as\
    \ machine learning and neural networks [264]. There are speciﬁc considerations\n\
    that can help to increase the robustness of these systems. For example, it was\
    \ shown that\nexisting feedback controls and responsibility declarations of the\
    \ agents are very impor-\ntant in system robustness [265]. The robustness of the\
    \ system can be investigated against\nperturbations of the coupling strengths\
    \ [266], communication delays [267], and agents’\ndynamics [268] by introducing\
    \ required formulations and protocols. These conditions for\nlarge open systems\
    \ with a heterogeneous group of agents and unpredictable dynamics\nwere investigated\
    \ in reference [269]. Increasing the number of agents and decreasing the\ncontribution\
    \ of each agent on overall dynamics was considered an inﬂuencing factor in the\n\
    robustness of the synchronization of heterogeneous MASs [270]. Communications\
    \ strength\nand the nominal magnitude of the edge weights were identiﬁed as other\
    \ important factors\nfor the robustness of consensus networks [271]. The security\
    \ of MASs and their control\nprotocols need to be investigated for evaluating\
    \ and adopting a suitable platform. The\nanalysis of security against the physical\
    \ faults and cyber-attacks of sensors and actuators,\nand surveys for recent advances,\
    \ were summarized in reference [272]. The surveyed tech-\nniques investigated\
    \ the security from the detection of the attack or fault and the techniques\n\
    Smart Cities 2022, 5\n336\nand protocols proposed for secure and fault-tolerant\
    \ control mechanisms. Another survey\ninvestigated the security from access control\
    \ and trust models standpoints [273].\n5.2. Test Datasets and Platforms\nThere\
    \ are multiple test platforms and datasets, which are mainly used for compar-\n\
    ing the efﬁciency of the proposed MASs control mechanisms. In machine learning,\
    \ one\nof the common platforms for testing MARL and other MAS techniques is MiniGrid\
    \ in\nOpenai-Gym [274]. The TRACILOGIS platform is utilized for dynamic resource\
    \ alloca-\ntion and scheduling [275]. There are also two- and multiple-player\
    \ games such as the\nMultiStep MNIST Game, FindGoal, RedBlueDoors, and StarCraft\
    \ II that can be used for\ntesting and comparing MAS techniques [90,128,276].\
    \ Other MAS control problems such as\nconsensus and containment control are tested\
    \ using simulation on small-scale numerical\nexperiments with predeﬁned equations\
    \ for system dynamics and state changes, and their\ninitial communication topologies\
    \ or Laplacian matrices [24]. There are also datasets such as\nGraphGT from various\
    \ domains for graph generation and transformation problems [277].\nThe SNAP data\
    \ set [278] and the co-authorship network Hepth, communication network\nAS, and\
    \ interaction user network Stov are other examples of graph data sets that can\
    \ be\nutilized for testing and evaluating multi-agent network monitoring platforms\
    \ [119].\n6. Conclusions\nThis research surveyed the techniques proposed for designing\
    \ and controlling adap-\ntive multi-agent networked systems. These systems provide\
    \ distributed frameworks for\nimplementing IoTs systems comprising smart nodes\
    \ and devices. Agents in these sys-\ntems reﬂect the required levels of reactivity,\
    \ autonomy, proactiveness, and social ability\nenabling the main system to resist\
    \ possible external disturbances and internal failures. This\nis considered as\
    \ one of the main requirements for smart cities. Future cities will no longer\n\
    be considered as a set of disconnected systems, and they will change to interconnected\n\
    networks with millions of smart agents. These agents and subsystems will constantly\n\
    sense, monitor, plan, and communicate with each other to provide more adaptive,\
    \ dynamic,\nefﬁcient, and reliable services for future citizens. To achieve this\
    \ goal, we require new\nperspectives, integrating existing advancements and variations\
    \ in deﬁning, monitoring,\nplanning, and evaluating multi-agent systems. This\
    \ research reviewed and summarized\nthe recent advances to meet these requirements\
    \ for the successful implementation of future\nsmart cities.\nMost of the proposed\
    \ MAS techniques in the literature were developed as separate\nmodules of the\
    \ system for either designing and planning or evaluating these systems. Few\n\
    researchers linked the proposed techniques to establish a solid integrated framework\
    \ that is\nable to simultaneously monitor, adapt, control, and evaluate its performance.\
    \ For example,\nbig-data analytics techniques are not fully linked to control\
    \ techniques and their potential\napplicability in reducing the computation steps\
    \ of these search platforms is not fully\ninvestigated in the literature. Integrating\
    \ more advanced state monitoring platforms such\nas clustering and pattern mining\
    \ on the collected agents’ data streams enables the designing\nof more customized\
    \ frameworks for the various communities of the agents. Investigating\nthe potential\
    \ advantages of state monitoring techniques in designing noise- and fault-\ntolerant\
    \ control mechanisms are other suggestions for future research in the MAS domain.\n\
    One of the other existing challenges that need to be addressed before using MASs\
    \ for\nsmart city platforms is heterogeneity of the involved agents in the network.\
    \ A smart city\nshould be able to efﬁciently control and monitor a wide range\
    \ of heterogeneous systems\nwith different entities, actions, and information\
    \ ﬂows. Most of the problems in the literature\nare simpliﬁed by deﬁning initial\
    \ assumptions on system structure, autonomy, and entity\ntypes and dynamics. More\
    \ investigations and research are required for evaluating the\nproposed control\
    \ mechanisms for heterogeneous systems, in which the agents not only\nhave nonidentical\
    \ deﬁnitions and duties but also differ in levels of uncertainty, disturbance,\n\
    and noise.\nSmart Cities 2022, 5\n337\nThe other missing aspect in the existing\
    \ literature is considering the high level of\nenvironment uncertainty for systems\
    \ exploring new platforms. The majority of the pro-\nposed techniques in this\
    \ domain suffer from high computation times for iterative search\nto estimate\
    \ system dynamics and best policy. Moreover, the recently presented MASs\ntechniques\
    \ in the machine learning domain neglected the power of information sharing\n\
    and communication between agents, and the techniques still rely on a central processor\
    \ for\nstoring, processing, and decision making. The reviewed literature highlighted\
    \ the need\nfor revising these approaches to make them suitable for future distributed\
    \ multi-agent\nsystems that are able to establish wireless communications with\
    \ other agents while explor-\ning solutions for emerging complex situations, such\
    \ as internal failure or cyber-attacks.\nThe control mechanisms can be also improved\
    \ by utilizing middle agents for the matching\nand abstracting of the signal-sharing\
    \ process to reduce the computation time and increase\ntheir convergence rates.\
    \ Most of the techniques were developed for static platforms and\ndid not include\
    \ potential changes in agents’ locations, communications, qualiﬁcations,\nand\
    \ reliability. Developing more general frameworks which are robust against episodic\n\
    dynamics with predictable cycles and trends is another great idea for empowering\
    \ adap-\ntive multi-agent networks. For the successful implementation of these\
    \ systems on the\ninternet of things, it is necessary to constantly evaluate the\
    \ systems and its changes to\nprevent potential security issues that infected\
    \ agents may cause. The control mechanisms\nneed to be designed in a more dynamic\
    \ platform that can immediately react to changes\nin agents’ availabilities, and\
    \ thereby trust change. Designing and deﬁning unique and\ngeneral performance\
    \ indicators and test frameworks can also provide a fair measurement\nfor comparing\
    \ existing techniques and determining their strengths and weaknesses in\ncontrolling\
    \ multi-agent networks with predeﬁned features and requirements.\nAuthor Contributions:\
    \ This paper represents a result of collegial teamwork. N.N. designed the\nresearch,\
    \ conducted the literature reviews, and prepared the original draft of the manuscript.\
    \ A.G.\nﬁnalized and transformed the manuscript to meet MDPI draft, and submitted\
    \ to the journal. All\nauthors have read and agreed to the published version of\
    \ the manuscript.\nFunding: This research received no external funding.\nInstitutional\
    \ Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\n\
    Data Availability Statement: Not applicable.\nAcknowledgments: The authors did\
    \ not receive support from any organization for the submit-\nted work.\nConﬂicts\
    \ of Interest: The authors declare that there is no conﬂict of interest.\nReferences\n\
    1.\nCocchia, A. Smart and digital city: A systematic literature review. In Smart\
    \ City; Springer: Cham, Switzerland, 2014; pp. 13–43.\n2.\nKim, T.; Ramos, C.;\
    \ Mohammed, S. Smart city and IoT. Future Gener. Comput. Syst. 2017, 76, 159–162.\
    \ [CrossRef]\n3.\nKhan, J.Y.; Yuce, M.R. Internet of Things (IoT): Systems and\
    \ Applications; CRC Press: Boca Raton, FL, USA, 2019.\n4.\nPark, E.; Del Pobil,\
    \ A.P.; Kwon, S.J. The role of Internet of Things (IoT) in smart cities: Technology\
    \ roadmap-oriented approaches.\nSustainability 2018, 10, 1388. [CrossRef]\n5.\n\
    Mukhopadhyay, S.C.; Suryadevara, N.K. Internet of things: Challenges and opportunities.\
    \ In Internet of Things; Springer:\nBerlin/Heidelberg, Germany, 2014; Volume 9,\
    \ pp. 1–17.\n6.\nIqbal, A.; Suryani, M.A.; Saleem, R.; Suryani, M.A. Internet\
    \ of things (IoT): On-going security challenges and risks. Int. J. Comput.\nSci.\
    \ Inf. Secur. 2016, 14, 671.\n7.\nRoscia, M.; Longo, M.; Lazaroiu, G.C. Smart\
    \ City by multi-agent systems. In Proceedings of the 2013 International Conference\
    \ on\nRenewable Energy Research and Applications (ICRERA), Madrid, Spain, 20–23\
    \ October 2013; pp. 371–376.\n8.\nDorri, A.; Kanhere, S.S.; Jurdak, R. Multi-agent\
    \ systems: A survey. IEEE Access 2018, 6, 28573–28593. [CrossRef]\n9.\ndo Nascimento,\
    \ N.M.; de Lucena, C.J.P. FIoT: An agent-based framework for self-adaptive and\
    \ self-organizing applications based\non the Internet of Things. Inf. Sci. 2017,\
    \ 378, 161–176. [CrossRef]\n10.\nForestiero, A. Multi-agent recommendation system\
    \ in Internet of Things. In Proceedings of the 2017 17th IEEE/ACM International\n\
    Symposium on Cluster, Cloud and Grid Computing (CCGRID), Madrid, Spain, 14–17\
    \ May 2017; pp. 772–775.\nSmart Cities 2022, 5\n338\n11.\nAseere, A.M. Multiagent\
    \ Systems Applied to Smart City. J. Eng. Appl. Sci. 2020, 7, 29–36.\n12.\nLongo,\
    \ M.; Roscia, M.; Lazaroiu, C. Innovating multi-agent systems applied to smart\
    \ city. Res. J. Appl. Sci. Eng. Technol. 2014, 7,\n4296–4302. [CrossRef]\n13.\n\
    Krupitzer, C.; Roth, F.M.; VanSyckel, S.; Schiele, G.; Becker, C. A survey on\
    \ engineering approaches for self-adaptive systems.\nPervasive Mob. Comput. 2015,\
    \ 17, 184–206. [CrossRef]\n14.\nBoes, J.; Migeon, F. Self-organizing multi-agent\
    \ systems for the control of complex systems. J. Syst. Softw. 2017, 134, 12–28.\n\
    [CrossRef]\n15.\nKantamneni, A.; Brown, L.E.; Parker, G.; Weaver, W.W. Survey\
    \ of multi-agent systems for microgrid control. Eng. Appl. Artif.\nIntell. 2015,\
    \ 45, 192–203. [CrossRef]\n16.\nKaviani, S. Multi-Agent Clinical Decision Support\
    \ Systems: A Survey. In Proceedings of the 1st Korea Artiﬁcial Intelligence\n\
    Conference, Jeju Island, Korea, 23–25 April 2020\n17.\nDominguez, R.; Cannella,\
    \ S. Insights on multi-agent systems applications for supply chain management.\
    \ Sustainability 2020,\n12, 1935. [CrossRef]\n18.\nGjikopulli, A.A.; Banerjee,\
    \ A. A survey on Multi-Agent Systems (MAS). Netw. Archit. Serv. 2020, 55–59.\n\
    19.\nOh, K.K.; Park, M.C.; Ahn, H.S. A survey of multi-agent formation control.\
    \ Automatica 2015, 53, 424–440. [CrossRef]\n20.\nMa, L.; Wang, Z.; Han, Q.L.;\
    \ Liu, Y. Consensus control of stochastic multi-agent systems: A survey. Sci.\
    \ China Inf. Sci. 2017,\n60, 120201. [CrossRef]\n21.\nLi, Y.; Tan, C. A survey\
    \ of the consensus for multi-agent systems. Syst. Sci. Control Eng. 2019, 7, 468–482.\
    \ [CrossRef]\n22.\nRahmani, A.; Ji, M.; Mesbahi, M.; Egerstedt, M. Controllability\
    \ of multi-agent systems from a graph-theoretic perspective. SIAM\nJ. Control\
    \ Optim. 2009, 48, 162–186. [CrossRef]\n23.\nDiaconescu, I.M.; Wagner, G. Modeling\
    \ and simulation of web-of-things systems as multi-agent systems. In German Conference\
    \ on\nMultiagent System Technologies; Springer: Cham, Switzerland, 2015; pp. 137–153.\n\
    24.\nLiang, H.; Liu, G.; Zhang, H.; Huang, T. Neural-Network-Based Event-Triggered\
    \ Adaptive Control of Nonafﬁne Nonlinear\nMultiagent Systems With Dynamic Uncertainties.\
    \ IEEE Trans. Neural Netw. Learn. Syst. 2021, 32, 2239–2250. [CrossRef]\n25.\n\
    Lowe, R.; Gupta, A.; Foerster, J.; Kiela, D.; Pineau, J. On the interaction between\
    \ supervision and self-play in emergent\ncommunication. arXiv 2020, arXiv:2002.01093.\n\
    26.\nFouad, H.; Moskowitz, I.S. Meta-Agents: Using Multi-Agent Networks to Manage\
    \ Dynamic Changes in the Internet of Things. In\nArtiﬁcial Intelligence for the\
    \ Internet of Everything; Elsevier: Cambridge, MA, USA, 2019; pp. 271–281.\n27.\n\
    Xu, X.; Chen, S.; Huang, W.; Gao, L. Leader-following consensus of discrete-time\
    \ multi-agent systems with observer-based\nprotocols. Neurocomputing 2013, 118,\
    \ 334–341. [CrossRef]\n28.\nD’Angelo, M.; Gerasimou, S.; Ghahremani, S.; Grohmann,\
    \ J.; Nunes, I.; Pournaras, E.; Tomforde, S. On learning in collective\nself-adaptive\
    \ systems: State of practice and a 3d framework. In Proceedings of the 2019 IEEE/ACM\
    \ 14th International Symposium\non Software Engineering for Adaptive and Self-Managing\
    \ Systems (SEAMS), Montreal, QC, Canada, 25 May 2019; pp. 13–24.\n29.\nZheng,\
    \ Y.; Wang, L. Consensus of heterogeneous multi-agent systems without velocity\
    \ measurements. Int. J. Control 2012,\n85, 906–914. [CrossRef]\n30.\nGottifredi,\
    \ S.; Tamargo, L.H.; García, A.J.; Simari, G.R. Arguing about informant credibility\
    \ in open multi-agent systems. Artif.\nIntell. 2018, 259, 91–109. [CrossRef]\n\
    31.\nKendrick, P.; Hussain, A.; Criado, N.; Randles, M. Multi-agent systems for\
    \ scalable internet of things security. In Proceedings\nof the Second International\
    \ Conference on Internet of things, Data and Cloud Computing, Cambridge, UK, 22–23\
    \ March 2017;\npp. 1–6.\n32.\nChen, F.; Ren, W. On the control of multi-agent\
    \ systems: A survey. Found. Trends® Syst. Control 2019, 6, 339–499. [CrossRef]\n\
    33.\nZuo, Z.; Zhang, J.; Wang, Y. Adaptive fault-tolerant tracking control for\
    \ linear and Lipschitz nonlinear multi-agent systems. IEEE\nTrans. Ind. Electron.\
    \ 2014, 62, 3923–3931. [CrossRef]\n34.\nAmirkhani, A.; Barshooi, A.H. Consensus\
    \ in multi-agent systems: A review. Artif. Intell. Rev. 2021, 2021, 1–39. [CrossRef]\n\
    35.\nJiang, C.; Du, H.; Zhu, W.; Yin, L.; Jin, X.; Wen, G. Synchronization of\
    \ nonlinear networked agents under event-triggered control.\nInf. Sci. 2018, 459,\
    \ 317–326. [CrossRef]\n36.\nZhang, L.; Chen, B.; Lin, C.; Shang, Y. Fuzzy adaptive\
    \ ﬁnite-time consensus tracking control for nonlinear multi-agent systems.\nInt.\
    \ J. Syst. Sci. 2021, 52, 1346–1358. [CrossRef]\n37.\nWang, Z.; Xue, H.; Pan,\
    \ Y.; Liang, H. Adaptive neural networks event-triggered fault-tolerant consensus\
    \ control for a class of\nnonlinear multi-agent systems. AIMS Math. 2020, 5, 2780–2800.\
    \ [CrossRef]\n38.\nGuan, Y.; Ji, Z.; Zhang, L.; Wang, L. Controllability of heterogeneous\
    \ multi-agent systems under directed and weighted topology.\nInt. J. Control 2016,\
    \ 89, 1009–1024. [CrossRef]\n39.\nRen, W.; Beard, R.W. Consensus seeking in multiagent\
    \ systems under dynamically changing interaction topologies. IEEE Trans.\nAutom.\
    \ Control 2005, 50, 655–661. [CrossRef]\n40.\nDesaraju, V.R.; How, J.P. Decentralized\
    \ path planning for multi-agent teams with complex constraints. Auton. Robot.\
    \ 2012,\n32, 385–403. [CrossRef]\n41.\nMovric, K.H.; Lewis, F.L. Cooperative optimal\
    \ control for multi-agent systems on directed graph topologies. IEEE Trans. Autom.\n\
    Control 2013, 59, 769–774. [CrossRef]\nSmart Cities 2022, 5\n339\n42.\nDe Nijs,\
    \ F. Resource-Constrained Multi-Agent Markov Decision Processes. Ph.D. Thesis,\
    \ Delft University of Technology, Delft,\nThe Netherlands, 2019.\n43.\nRadulescu,\
    \ R.; Mannion, P.; Roijers, D.M.; Nowé, A. Recent Advances in Multi-Objective\
    \ Multi-Agent Decision Making; Benelux\nAssociation for Artiﬁcial Intelligence:\
    \ Leiden, The Netherlands, 2020; pp. 392–394.\n44.\nLee, D.; Hu, J. Primal-dual\
    \ distributed temporal difference learning. arXiv 2018, arXiv:1805.07918.\n45.\n\
    Rizk, Y.; Awad, M.; Tunstel, E.W. Decision making in multiagent systems: A survey.\
    \ IEEE Trans. Cogn. Dev. Syst. 2018, 10, 514–529.\n[CrossRef]\n46.\nRossi, F.;\
    \ Bandyopadhyay, S.; Wolf, M.; Pavone, M. Review of multi-agent algorithms for\
    \ collective behavior: A structural\ntaxonomy. IFAC-PapersOnLine 2018, 51, 112–117.\
    \ [CrossRef]\n47.\nAydin, M.E. Coordinating metaheuristic agents with swarm intelligence.\
    \ J. Intell. Manuf. 2012, 23, 991–999. [CrossRef]\n48.\nZhu, L.; Xiang, Z. Aggregation\
    \ analysis for competitive multiagent systems with saddle points via switching\
    \ strategies. IEEE\nTrans. Neural Netw. Learn. Syst. 2017, 29, 2931–2943. [CrossRef]\n\
    49.\nYang, T.; Yi, X.; Wu, J.; Yuan, Y.; Wu, D.; Meng, Z.; Hong, Y.; Wang, H.;\
    \ Lin, Z.; Johansson, K.H. A survey of distributed\noptimization. Annu. Rev. Control\
    \ 2019, 47, 278–305. [CrossRef]\n50.\nXiao, W.; Cao, L.; Li, H.; Lu, R. Observer-based\
    \ adaptive consensus control for nonlinear multi-agent systems with time-delay.\n\
    Sci. China Inf. Sci. 2020, 63, 1–17. [CrossRef]\n51.\nBrown, R.; Rossi, F.; Solovey,\
    \ K.; Tsao, M.; Wolf, M.T.; Pavone, M. On Local Computation for Network-Structured\
    \ Convex\nOptimization in Multi-Agent Systems. IEEE Trans. Control Netw. Syst.\
    \ 2021, 8, 542–554. [CrossRef]\n52.\nShen, Q.; Shi, P.; Zhu, J.; Wang, S.; Shi,\
    \ Y. Neural Networks-Based Distributed Adaptive Control of Nonlinear Multiagent\
    \ Systems.\nIEEE Trans. Neural Netw. Learn. Syst. 2020, 31, 1010–1021. [CrossRef]\n\
    53.\nCalvaresi, D.; Cid, Y.D.; Marinoni, M.; Dragoni, A.F.; Najjar, A.; Schumacher,\
    \ M. Real-time multi-agent systems: Rationality,\nformal model, and empirical\
    \ results. Auton. Agents Multi-Agent Syst. 2021, 35, 12. [CrossRef]\n54.\nEriksson,\
    \ A.; Hansson, J. Distributed Optimisation in Multi-Agent Systems Through Deep\
    \ Reinforcement Learning; TRITA-EECS-EX:\nStockholm, Sweden, 2019.\n55.\nYu, H.;\
    \ Shen, Z.; Leung, C.; Miao, C.; Lesser, V.R. A survey of multi-agent trust management\
    \ systems. IEEE Access 2013, 1, 35–50.\n56.\nTariverdi, A.; Talebi, H.A.; Shaﬁee,\
    \ M. Fault-tolerant consensus of nonlinear multi-agent systems with directed link\
    \ failures,\ncommunication noise and actuator faults. Int. J. Control 2021, 94,\
    \ 60–74. [CrossRef]\n57.\nCalvaresi, D.; Marinoni, M.; Sturm, A.; Schumacher,\
    \ M.; Buttazzo, G. The challenge of real-time multi-agent systems for\nenabling\
    \ IoT and CPS. In Proceedings of the International Conference on Web Intelligence,\
    \ Leipzig, Germany, 23–26 August 2017;\npp. 356–364.\n58.\nCheng, L.; Hou, Z.G.;\
    \ Tan, M.; Lin, Y.; Zhang, W. Neural-network-based adaptive leader-following control\
    \ for multiagent systems\nwith uncertainties. IEEE Trans. Neural Netw. 2010, 21,\
    \ 1351–1358. [CrossRef] [PubMed]\n59.\nDing, L.; Han, Q.L.; Ge, X.; Zhang, X.M.\
    \ An overview of recent advances in event-triggered consensus of multiagent systems.\n\
    IEEE Trans. Cybern. 2017, 48, 1110–1123. [CrossRef]\n60.\nShen, B.; Wang, Z.;\
    \ Liu, X. A Stochastic Sampled-Data Approach to Distributed H∞ Filtering in Sensor\
    \ Networks. IEEE Trans.\nCircuits Syst. I Regul. Pap. 2011, 58, 2237–2246. [CrossRef]\n\
    61.\nHeemels, W.H.; Donkers, M.; Teel, A.R. Periodic event-triggered control for\
    \ linear systems. IEEE Trans. Autom. Control 2012,\n58, 847–861. [CrossRef]\n\
    62.\nGe, X.; Han, Q.L.; Ding, L.; Wang, Y.L.; Zhang, X.M. Dynamic event-triggered\
    \ distributed coordination control and its applications:\nA survey of trends and\
    \ techniques. IEEE Trans. Syst. Man Cybern. Syst. 2020, 50, 3112–3125. [CrossRef]\n\
    63.\nZhang, X.M.; Han, Q.L.; Zhang, B.L. An overview and deep investigation on\
    \ sampled-data-based event-triggered control and\nﬁltering for networked systems.\
    \ IEEE Trans. Ind. Inform. 2016, 13, 4–16. [CrossRef]\n64.\nNegenborn, R.; Maestre,\
    \ J. Distributed Model Predictive Control: An overview of features and research\
    \ opportunities. In\nProceedings of the 11th IEEE International Conference on\
    \ Networking, Sensing and Control, Miami, FL, USA, 7–9 April 2014.\n65.\nLiu,\
    \ P.; Xiao, F.; Wei, B.; Wang, A. Distributed constrained optimization problem\
    \ of heterogeneous linear multi-agent systems\nwith communication delays. Syst.\
    \ Control Lett. 2021, 155, 105002. [CrossRef]\n66.\nChen, Z.; Li, Z.; Chen, C.P.\
    \ Adaptive neural control of uncertain MIMO nonlinear systems with state and input\
    \ constraints. IEEE\nTrans. Neural Netw. Learn. Syst. 2016, 28, 1318–1330. [CrossRef]\
    \ [PubMed]\n67.\nWen, G.; Duan, Z.; Yu, W.; Chen, G. Consensus in multi-agent\
    \ systems with communication constraints. Int. J. Robust Nonlinear\nControl 2012,\
    \ 22, 170–182. [CrossRef]\n68.\nZhang, Y.; Liang, H.; Ma, H.; Zhou, Q.; Yu, Z.\
    \ Distributed adaptive consensus tracking control for nonlinear multi-agent systems\n\
    with state constraints. Appl. Math. Comput. 2018, 326, 16–32. [CrossRef]\n69.\n\
    Zhang, D.; Xu, Z.; Srinivasan, D.; Yu, L. Leader-follower consensus of multiagent\
    \ systems with energy constraints: A Markovian\nsystem approach. IEEE Trans. Syst.\
    \ Man Cybern. Syst. 2017, 47, 1727–1736. [CrossRef]\n70.\nMarcotte, R.J.; Wang,\
    \ X.; Mehta, D.; Olson, E. Optimizing multi-robot communication under bandwidth\
    \ constraints. Auton. Robot.\n2020, 44, 43–55. [CrossRef]\n71.\nRicci, A.; Piunti,\
    \ M.; Viroli, M. Environment programming in multi-agent systems: An artifact-based\
    \ perspective. Auton. Agents\nMulti-Agent Syst. 2011, 23, 158–192. [CrossRef]\n\
    Smart Cities 2022, 5\n340\n72.\nWeyns, D.; Omicini, A.; Odell, J. Environment\
    \ as a ﬁrst class abstraction in multiagent systems. Auton. Agents Multi-Agent\
    \ Syst.\n2007, 14, 5–30. [CrossRef]\n73.\nPlaton, E.; Mamei, M.; Sabouret, N.;\
    \ Honiden, S.; Parunak, H.V.D. Mechanisms for environments in multi-agent systems:\
    \ Survey\nand opportunities. Auton. Agents Multi-Agent Syst. 2007, 14, 31–47.\
    \ [CrossRef]\n74.\nJohansson, K.; Rosolia, U.; Ubellacker, W.; Singletary, A.;\
    \ Ames, A.D. Mixed Observable RRT: Multi-Agent Mission-Planning in\nPartially\
    \ Observable Environments. arXiv 2021, arXiv:2110.01002.\n75.\nBourne, R.A.; Excelente-Toledo,\
    \ C.B.; Jennings, N.R. Run-time selection of coordination mechanisms in multi-agent\
    \ systems. In\n14th European Conference on Artiﬁcial Intelligence (ECAI-2000);\
    \ IOS Press: Amsterdam, The Netherlands, 2000.\n76.\nChen, S.; Wang, M.; Li, Q.\
    \ Second-order consensus of hybrid multi-agent systems with unknown disturbances\
    \ via sliding mode\ncontrol. IEEE Access 2020, 8, 34973–34980. [CrossRef]\n77.\n\
    Hernandez-Leal, P.; Kartal, B.; Taylor, M.E. A survey and critique of multiagent\
    \ deep reinforcement learning. Auton. Agents\nMulti-Agent Syst. 2019, 33, 750–797.\
    \ [CrossRef]\n78.\nWagner, G.; Choset, H. Path planning for multiple agents under\
    \ uncertainty. In Proceedings of the Twenty-Seventh International\nConference\
    \ on Automated Planning and Scheduling, Pittsburgh, PA, USA, 18–23 June 2017.\n\
    79.\nLi, Z.; Duan, Z.; Xie, L.; Liu, X. Distributed robust control of linear multi-agent\
    \ systems with parameter uncertainties. Int. J.\nControl 2012, 85, 1039–1050.\
    \ [CrossRef]\n80.\nAmato, C. Decision-Making Under Uncertainty in Multi-Agent\
    \ and Multi-Robot Systems: Planning and Learning. In Proceedings\nof the IJCAI,\
    \ Stockholm, Sweden, 13–19 July 2018; pp. 5662–5666.\n81.\nPeng, Z.; Zhang, J.;\
    \ Hu, J.; Huang, R.; Ghosh, B.K. Optimal containment control of continuous-time\
    \ multi-agent systems with\nunknown disturbances using data-driven approach. Sci.\
    \ China Inf. Sci. 2020, 63, 209205. [CrossRef]\n82.\nHu, G. Robust consensus tracking\
    \ for an integrator-type multi-agent system with disturbances and unmodelled dynamics.\
    \ Int. J.\nControl 2011, 84, 1–8. [CrossRef]\n83.\nKhazaeni, Y.; Cassandras, C.G.\
    \ Event-driven cooperative receding horizon control for multi-agent systems in\
    \ uncertain environ-\nments. IEEE Trans. Control Netw. Syst. 2016, 5, 409–422.\
    \ [CrossRef]\n84.\nZuo, Z.; Wang, C.; Ding, Z. Robust consensus control of uncertain\
    \ multi-agent systems with input delay: A model reduction\nmethod. Int. J. Robust\
    \ Nonlinear Control 2017, 27, 1874–1894. [CrossRef]\n85.\nZhou, Z.; Xu, H. Mean\
    \ ﬁeld game and decentralized intelligent adaptive pursuit evasion strategy for\
    \ massive multi-agent system\nunder uncertain environment. In Proceedings of the\
    \ 2020 American Control Conference (ACC), Denver, CO, USA, 1–3 July 2020;\npp.\
    \ 5382–5387.\n86.\nBusoniu, L.; Babuska, R.; De Schutter, B. A comprehensive survey\
    \ of multiagent reinforcement learning. IEEE Trans. Syst. Man\nCybern. Part C\
    \ (Appl. Rev.) 2008, 38, 156–172. [CrossRef]\n87.\nKhan, N. Learning to Cooperate\
    \ Using Deep Reinforcement Learning in a Multi-Agent System. Ph.D. Thesis, University\
    \ of\nMinnesota, Minneapolis, MN, USA, 2020.\n88.\nOmidshaﬁei, S.; Pazis, J.;\
    \ Amato, C.; How, J.P.; Vian, J. Deep decentralized multi-task multi-agent reinforcement\
    \ learning under\npartial observability. In Proceedings of the International Conference\
    \ on Machine Learning, PMLR, Sydney, Australia, 6–11 August\n2017; pp. 2681–2690.\n\
    89.\nShang, W.; Li, Q.; Qin, Z.; Yu, Y.; Meng, Y.; Ye, J. Partially observable\
    \ environment estimation with uplift inference for\nreinforcement learning based\
    \ recommendation. Mach. Learn. 2021, 110, 2603–2640. [CrossRef]\n90.\nWang, R.E.;\
    \ Everett, M.; How, J.P. R-MADDPG for partially observable environments and limited\
    \ communication. arXiv 2020,\narXiv:2002.06684.\n91.\nLi, W.; Xie, L.; Zhang,\
    \ J.F. Containment control of leader-following multi-agent systems with Markovian\
    \ switching network\ntopologies and measurement noises. Automatica 2015, 51, 263–267.\
    \ [CrossRef]\n92.\nPerez, J.; Silander, T. Non-markovian control with gated end-to-end\
    \ memory policy networks. arXiv 2017, arXiv:1705.10993.\n93.\nMansour, A.M. Cooperative\
    \ Multi-Agent Vehicle-to-Vehicle Wireless Network in a Noisy Environment. Int.\
    \ J. Circuits, Syst.\nSignal Process. 2021, 15, 135–148. [CrossRef]\n94.\nBúrdalo,\
    \ L.; Terrasa, A.; Julián, V.; García-Fornes, A. The information ﬂow problem in\
    \ multi-agent systems. Eng. Appl. Artif. Intell.\n2018, 70, 130–141. [CrossRef]\n\
    95.\nBaki, B.; Bouzid, M.; Lig˛eza, A.; Mouaddib, A.I. A centralized planning\
    \ technique with temporal constraints and uncertainty for\nmulti-agent systems.\
    \ J. Exp. Theor. Artif. Intell. 2006, 18, 331–364. [CrossRef]\n96.\nGe, M.; Bangui,\
    \ H.; Buhnova, B. Big data for internet of things: A survey. Future Gener. Comput.\
    \ Syst. 2018, 87, 601–614. [CrossRef]\n97.\nKhan, A.; Zhang, C.; Lee, D.D.; Kumar,\
    \ V.; Ribeiro, A. Scalable centralized deep multi-agent reinforcement learning\
    \ via policy\ngradients. arXiv 2018, arXiv:1805.08776.\n98.\nHuang, D.; Jiang,\
    \ H.; Yu, Z.; Hu, C.; Fan, X. Cluster-delay consensus in MASs with layered intermittent\
    \ communication: A\nmulti-tracking approach. Nonlinear Dyn. 2019, 95, 1713–1730.\
    \ [CrossRef]\n99.\nGe, X.; Yang, F.; Han, Q.L. Distributed networked control systems:\
    \ A brief overview. Inf. Sci. 2017, 380, 117–131. [CrossRef]\n100. Sayed, A.H.\
    \ Adaptive networks. Proc. IEEE 2014, 102, 460–497. [CrossRef]\n101. Zhuge, H.\
    \ Knowledge ﬂow network planning and simulation. Decis. Support Syst. 2006, 42,\
    \ 571–592. [CrossRef]\nSmart Cities 2022, 5\n341\n102. Zhang, C.; Lesser, V.R.;\
    \ Abdallah, S. Self-organization for coordinating decentralized reinforcement\
    \ learning. In Proceedings of\nthe 9th International Conference on Autonomous\
    \ Agents and Multiagent Systems: IFAAMAS, Richland, SC, USA, 9–13 May 2010;\n\
    Volume 1, pp. 739–746.\n103. Althnian, A.; Agah, A. Evolutionary learning of goal-oriented\
    \ communication strategies in multi-agent systems. J. Autom. Mob.\nRobot. Intell.\
    \ Syst. 2015, 9, 52–64. [CrossRef]\n104. Zhang, T.; Zhu, Q. Informational design\
    \ of dynamic multi-agent system. arXiv 2021, arXiv:2105.03052.\n105. Das, A.;\
    \ Gervet, T.; Romoff, J.; Batra, D.; Parikh, D.; Rabbat, M.; Pineau, J. Tarmac:\
    \ Targeted multi-agent communication. In\nProceedings of the International Conference\
    \ on Machine Learning, PMLR, Long Beach, CA, USA, 9–15 June 2019; pp. 1538–1546.\n\
    106. Wang, D.; Wang, Z.; Chen, M.; Wang, W. Distributed optimization for multi-agent\
    \ systems with constraints set and communication\ntime-delay over a directed graph.\
    \ Inf. Sci. 2018, 438, 1–14. [CrossRef]\n107. Jiang, X.; Xia, G.; Feng, Z. Output\
    \ consensus of high-order linear multi-agent systems with time-varying delays.\
    \ IET Control\nTheory Appl. 2019, 13, 1084–1094. [CrossRef]\n108. Tan, X.; Cao,\
    \ J.; Li, X.; Alsaedi, A. Leader-following mean square consensus of stochastic\
    \ multi-agent systems with input delay\nvia event-triggered control. IET Control\
    \ Theory Appl. 2017, 12, 299–309. [CrossRef]\n109. Han, F.; Wei, G.; Ding, D.;\
    \ Song, Y. Local condition based consensus ﬁltering with stochastic nonlinearities\
    \ and multiple missing\nmeasurements. IEEE Trans. Autom. Control 2017, 62, 4784–4790.\
    \ [CrossRef]\n110. Cholvy, L.; da Costa Pereira, C. Usefulness of information\
    \ for goal achievement. In International Conference on Principles and\nPractice\
    \ of Multi-Agent Systems; Springer: Cham, Switzerland, 2019; pp. 123–137.\n111.\
    \ Djaidja, S.; Wu, Q.H.; Fang, H. Leader-following consensus of double-integrator\
    \ multi-agent systems with noisy measurements.\nInt. J. Control Autom. Syst. 2015,\
    \ 13, 17–24. [CrossRef]\n112. Bacciu, D.; Micheli, A.; Podda, M. Edge-based sequential\
    \ graph generation with recurrent neural networks. Neurocomputing 2020,\n416,\
    \ 177–189. [CrossRef]\n113. Atluri, G.; Karpatne, A.; Kumar, V. Spatio-temporal\
    \ data mining: A survey of problems and methods. ACM Comput. Surv.\n(CSUR) 2018,\
    \ 51, 1–41. [CrossRef]\n114. Wu, Z.; Pan, S.; Chen, F.; Long, G.; Zhang, C.; Philip,\
    \ S.Y. A comprehensive survey on graph neural networks. IEEE Trans. Neural\nNetw.\
    \ Learn. Syst. 2020, 32, 4–24. [CrossRef]\n115. Laurence, E.; Doyon, N.; Dubé,\
    \ L.J.; Desrosiers, P. Spectral dimension reduction of complex dynamical networks.\
    \ Phys. Rev. X\n2019, 9, 011042. [CrossRef]\n116. Wang, D.; Cui, P.; Zhu, W. Structural\
    \ deep network embedding.\nIn Proceedings of the 22nd ACM SIGKDD International\n\
    Conference on Knowledge Discovery and Data Mining, San Francisco, CA, USA, 13–17\
    \ August 2016; pp. 1225–1234.\n117. Kipf, T.N.; Welling, M. Variational graph\
    \ auto-encoders. arXiv 2016, arXiv:1611.07308.\n118. Hamilton, W.L.; Ying, R.;\
    \ Leskovec, J. Inductive representation learning on large graphs. In Proceedings\
    \ of the 31st International\nConference on Neural Information Processing Systems,\
    \ Long Beach, CA, USA, 4–9 December 2017; pp. 1025–1035.\n119. Mahdavi, S.; Khoshraftar,\
    \ S.; An, A. Dynamic joint variational graph autoencoders. arXiv 2019, arXiv:1910.01963.\n\
    120. Barros, C.D.; Mendonça, M.R.; Vieira, A.B.; Ziviani, A. A Survey on Embedding\
    \ Dynamic Graphs. arXiv 2021, arXiv:2101.01229.\n121. Sayama, H.; Laramee, C.\
    \ Generative network automata: A generalized framework for modeling adaptive network\
    \ dynamics\nusing graph rewritings. In Adaptive Networks; Springer: Heidelberg,\
    \ Germany, 2009; pp. 311–332.\n122. Taheri, A.; Gimpel, K.; Berger-Wolf, T. Learning\
    \ Graph Representations with Recurrent Neural Network Autoencoders; KDD Deep\n\
    Learning Day: London, UK, 2018.\n123. Papoudakis, G.; Albrecht, S.V.\nVariational\
    \ autoencoders for opponent modeling in multi-agent systems.\narXiv 2020,\narXiv:2001.10829.\n\
    124. Zhang, K.; Ying, H.; Dai, H.N.; Li, L.; Peng, Y.; Guo, K.; Yu, H. Compacting\
    \ Deep Neural Networks for Internet of Things:\nMethods and Applications. IEEE\
    \ Internet Things J. 2021, 8, 11935–11959. [CrossRef]\n125. Lomuscio, A.; Qu,\
    \ H.; Russo, F. Automatic data-abstraction in model checking multi-agent systems.\
    \ In International Workshop on\nModel Checking and Artiﬁcial Intelligence; Springer:\
    \ Heidelberg, Germany, 2010; pp. 52–68.\n126. Rassam, M.A.; Zainal, A.; Maarof,\
    \ M.A. An adaptive and efﬁcient dimension reduction model for multivariate wireless\
    \ sensor\nnetworks applications. Appl. Soft Comput. 2013, 13, 1978–1996. [CrossRef]\n\
    127. Grover, A.; Leskovec, J. node2vec: Scalable feature learning for networks.\
    \ In Proceedings of the 22nd ACM SIGKDD International\nConference on Knowledge\
    \ Discovery and Data Mining, San Francisco, CA, USA, 13–17 August 2016; pp. 855–864.\n\
    128. Lin, T.; Huh, J.; Stauffer, C.; Lim, S.N.; Isola, P. Learning to Ground Multi-Agent\
    \ Communication with Autoencoders.\nIn\nProceedings of the Advances in Neural\
    \ Information Processing Systems, Virtual, 6–14 December 2021; Volume 34.\n129.\
    \ García, N.M. Multi-agent system for anomaly detection in Industry 4.0 using\
    \ Machine Learning techniques. ADCAIJ Adv. Distrib.\nComput. Artif. Intell. J.\
    \ 2019, 8, 33–40.\n130. Tahsien, S.M. A Neural Network Guided Genetic Algorithm\
    \ for Flexible Flow Shop Scheduling Problem with Sequence Dependent\nSetup Time.\
    \ Ph.D. Thesis, The University of Guelph, Guelph, ON, Canada, 2020.\n131. Ma,\
    \ X.; Wu, J.; Xue, S.; Yang, J.; Sheng, Q.Z.; Xiong, H. A Comprehensive Survey\
    \ on Graph Anomaly Detection with Deep\nLearning. arXiv 2021, arXiv:2106.07178.\n\
    132. Ding, K.; Li, J.; Liu, H. Interactive anomaly detection on attributed networks.\
    \ In Proceedings of the Twelfth ACM International\nConference on Web Search and\
    \ Data Mining, Melbourne, VIC, Australia, 11–15 February 2019; pp. 357–365.\n\
    Smart Cities 2022, 5\n342\n133. Duan, D.; Tong, L.; Li, Y.; Lu, J.; Shi, L.; Zhang,\
    \ C. AANE: Anomaly Aware Network Embedding For Anomalous Link Detection.\nIn Proceedings\
    \ of the 2020 IEEE International Conference on Data Mining (ICDM), Sorrento, Italy,\
    \ 17–20 November 2020;\npp. 1002–1007.\n134. Zheng, M.; Zhou, C.; Wu, J.; Pan,\
    \ S.; Shi, J.; Guo, L. Fraudne: A joint embedding approach for fraud detection.\
    \ In Proceedings of\nthe 2018 International Joint Conference on Neural Networks\
    \ (IJCNN), Rio de Janeiro, Brazil, 8–13 July 2018; pp. 1–8.\n135. Ruff, L.; Vandermeulen,\
    \ R.; Goernitz, N.; Deecke, L.; Siddiqui, S.A.; Binder, A.; Müller, E.; Kloft,\
    \ M. Deep one-class classiﬁcation.\nIn Proceedings of the International Conference\
    \ on Machine Learning, PMLR, Stockholm, Sweden, 10–15 July 2018; pp. 4393–4402.\n\
    136. Louati, F.; Ktata, F.B. A deep learning-based multi-agent system for intrusion\
    \ detection. SN Appl. Sci. 2020, 2, 1–13. [CrossRef]\n137. Guo, X.; Zhao, L. A\
    \ systematic survey on deep generative models for graph generation. arXiv 2020,\
    \ arXiv:2007.06686.\n138. You, J.; Ying, R.; Ren, X.; Hamilton, W.; Leskovec,\
    \ J. Graphrnn: Generating realistic graphs with deep auto-regressive models. In\n\
    Proceedings of the International Conference on Machine Learning, PMLR, Stockholm,\
    \ Sweden, 10–15 July 2018; pp. 5708–5717.\n139. Zhou, D.; Zheng, L.; Han, J.;\
    \ He, J. A data-driven graph generative model for temporal interaction networks.\
    \ In Proceedings\nof the 26th ACM SIGKDD International Conference on Knowledge\
    \ Discovery & Data Mining, Virtual Event, CA, USA, 23–27\nAugust 2020; pp. 401–411.\n\
    140. Peng, H.; Wang, H.; Du, B.; Bhuiyan, M.Z.A.; Ma, H.; Liu, J.; Wang, L.; Yang,\
    \ Z.; Du, L.; Wang, S.; et al. Spatial temporal incidence\ndynamic graph neural\
    \ networks for trafﬁc ﬂow forecasting. Inf. Sci. 2020, 521, 277–290. [CrossRef]\n\
    141. Li, L.; Yao, J.; Wenliang, L.; He, T.; Xiao, T.; Yan, J.; Wipf, D.; Zhang,\
    \ Z. GRIN: Generative Relation and Intention Network for\nMulti-agent Trajectory\
    \ Prediction. In Proceedings of the Advances in Neural Information Processing\
    \ Systems, Virtual, 6–14\nDecember 2021; Volume 34.\n142. Guastella, D.; Camps,\
    \ V.; Gleizes, M.P. Multi-agent Systems for Estimating Missing Information in\
    \ Smart Cities.\nIn 11th\nInternational Conference on Agents and Artiﬁcial Intelligence-ICAART\
    \ 2019; SCITEPRESS-Science and Technology Springer: Prague,\nCzech Republic, 2019;\
    \ pp. 214–223.\n143. Feng, W.; Zhang, C.; Zhang, W.; Han, J.; Wang, J.; Aggarwal,\
    \ C.; Huang, J. STREAMCUBE: Hierarchical spatio-temporal hashtag\nclustering for\
    \ event exploration over the Twitter stream. In Proceedings of the 2015 IEEE 31st\
    \ International Conference on Data\nEngineering, Seoul, Korea, 13–17 April 2015;\
    \ pp. 1561–1572.\n144. Zhao, L.; Akoglu, L. On using classiﬁcation datasets to\
    \ evaluate graph outlier detection: Peculiar observations and new insights.\n\
    Big Data 2021, 2021, 69. [CrossRef] [PubMed]\n145. Teng, X.; Yan, M.; Ertugrul,\
    \ A.M.; Lin, Y.R. Deep into hypersphere: Robust and unsupervised anomaly discovery\
    \ in dynamic\nnetworks. In Proceedings of the Twenty-Seventh International Joint\
    \ Conference on Artiﬁcial Intelligence, Stockholm, Sweden,\n13–19 July 2018.\n\
    146. Ierardi, C.; Orihuela, L.; Jurado, I. Distributed estimation techniques for\
    \ cyber-physical systems: A systematic review. Sensors\n2019, 19, 4720. [CrossRef]\n\
    147. Jing, G.; Zheng, Y.; Wang, L. Flocking of multi-agent systems with multiple\
    \ groups. Int. J. Control 2014, 87, 2573–2582. [CrossRef]\n148. Chen, K.; Wang,\
    \ J.; Zhang, Y.; Lewis, F.L. Cluster consensus of heterogeneous linear multi-agent\
    \ systems. IET Control Theory Appl.\n2018, 12, 1533–1542. [CrossRef]\n149. Belghache,\
    \ E.; Georgé, J.P.; Gleizes, M.P. DREAM: Dynamic data relation extraction using\
    \ adaptive multi-agent systems.\nIn Proceedings of the 2017 Twelfth International\
    \ Conference on Digital Information Management (ICDIM), Fukuoka, Japan,\n12–14\
    \ September 2017; pp. 292–297.\n150. Li, W.; Yang, J.Y. Comparing networks from\
    \ a data analysis perspective. In International Conference on Complex Sciences;\
    \ Springer:\nHeidelberg, Germany, 2009; pp. 1907–1916.\n151. Kim, J.; Lee, J.G.\
    \ Community detection in multi-layer graphs: A survey. ACM SIGMOD Rec. 2015, 44,\
    \ 37–48. [CrossRef]\n152. Banka, A.A.; Naaz, R. Large Scale Graph Analytics for\
    \ Communities Using Graph Neural Networks. In International Conference\non Computational\
    \ Data and Social Networks; Springer: Cham, Switzerland, 2020; pp. 39–47.\n153.\
    \ Liu, F.; Xue, S.; Wu, J.; Zhou, C.; Hu, W.; Paris, C.; Nepal, S.; Yang, J.;\
    \ Yu, P.S. Deep learning for community detection: Progress,\nchallenges and opportunities.\
    \ arXiv 2020, arXiv:2005.08225.\n154. Cazabet, R.; Rossetti, G.; Amblard, F. Dynamic\
    \ Community Detection; Springer: New York, NY, USA, 2017.\n155. Rossetti, G.;\
    \ Cazabet, R. Community discovery in dynamic networks: A survey. ACM Comput. Surv.\
    \ (CSUR) 2018, 51, 1–37.\n[CrossRef]\n156. Chen, Z.; Liao, H.; Chu, T. Aggregation\
    \ and splitting in self-driven swarms. Phys. A Stat. Mech. Appl. 2012, 391, 3988–3994.\n\
    [CrossRef]\n157. Ogston, E.; Overeinder, B.; Van Steen, M.; Brazier, F. A method\
    \ for decentralized clustering in large multi-agent systems. In\nProceedings of\
    \ the Second International Joint Conference on Autonomous Agents and Multiagent\
    \ Systems, Melbourne, VIC,\nAustralia, 14–18 July 2003; pp. 789–796.\n158. Cai,\
    \ N.; Diao, C.; Khan, M.J. A novel clustering method based on quasi-consensus\
    \ motions of dynamical multiagent systems.\nComplexity 2017, 2017, 4978613. [CrossRef]\n\
    159. Kadar, M.; Muntean, M.V.; Csabai, T. A Multi-agent System with Self-optimization\
    \ for Automated Clustering (MASAC). In\nAgents and Multi-Agent Systems: Technologies\
    \ and Applications 2019; Springer: Singapore, 2019; pp. 117–128.\n160. Sequeira,\
    \ P.; Antunes, C. Real-time sensory pattern mining for autonomous agents. In International\
    \ Workshop on Agents and Data\nMining Interaction; Springer: Heidelberg, Germany,\
    \ 2010; pp. 71–83.\nSmart Cities 2022, 5\n343\n161. Fournier-Viger, P.; He, G.;\
    \ Cheng, C.; Li, J.; Zhou, M.; Lin, J.C.W.; Yun, U. A survey of pattern mining\
    \ in dynamic graphs. Wiley\nInterdiscip. Rev. Data Min. Knowl. Discov. 2020, 10,\
    \ e1372. [CrossRef]\n162. Halder, S.; Samiullah, M.; Lee, Y.K. Supergraph based\
    \ periodic pattern mining in dynamic social networks. Expert Syst. Appl.\n2017,\
    \ 72, 430–442. [CrossRef]\n163. Jin, R.; McCallen, S.; Almaas, E. Trend motif:\
    \ A graph mining approach for analysis of dynamic complex networks. In Proceedings\n\
    of the Seventh IEEE International Conference on Data Mining (ICDM 2007), Omaha,\
    \ NE, USA, 28–31 October 2007; pp. 541–546.\n164. Cheng, Z.; Flouvat, F.; Selmaoui-Folcher,\
    \ N. Mining recurrent patterns in a dynamic attributed graph. In Paciﬁc-Asia Conference\
    \ on\nKnowledge Discovery and Data Mining; Springer: Cham, Switzerland, 2017;\
    \ pp. 631–643.\n165. Kaytoue, M.; Pitarch, Y.; Plantevit, M.; Robardet, C. Triggering\
    \ patterns of topology changes in dynamic graphs. In Proceedings\nof the 2014\
    \ IEEE/ACM International Conference on Advances in Social Networks Analysis and\
    \ Mining (ASONAM 2014), Beijing,\nChina, 17–20 August 2014; pp. 158–165.\n166.\
    \ Fournier-Viger, P.; Cheng, C.; Cheng, Z.; Lin, J.C.W.; Selmaoui-Folcher, N.\
    \ Mining signiﬁcant trend sequences in dynamic\nattributed graphs. Knowl.-Based\
    \ Syst. 2019, 182, 104797. [CrossRef]\n167. Mahmoud, M.A.; Ahmad, M.S.; Mostafa,\
    \ S.A. Norm-based behavior regulating technique for multi-agent in complex adaptive\n\
    systems. IEEE Access 2019, 7, 126662–126678. [CrossRef]\n168. Venkatesan, D. A\
    \ Novel Agent-Based Enterprise Level System Development Technology. Ph.D. Thesis,\
    \ Anna University, Tamil\nNadu, India, 2018.\n169. Bellifemine, F.; Bergenti,\
    \ F.; Caire, G.; Poggi, A. JADE—A java agent development framework. In Multi-Agent\
    \ Programming;\nSpringer: Boston, MA, USA, 2005; pp. 125–147.\n170. DeLoach, S.A.;\
    \ Garcia-Ojeda, J.C. O-MaSE: A customisable approach to designing and building\
    \ complex, adaptive multi-agent\nsystems. Int. J. Agent-Oriented Softw. Eng. 2010,\
    \ 4, 244–280. [CrossRef]\n171. Cardoso, R.C.; Ferrando, A. A Review of Agent-Based\
    \ Programming for Multi-Agent Systems. Computers 2021, 10, 16. [CrossRef]\n172.\
    \ Kravari, K.; Bassiliades, N. A survey of agent platforms. J. Artif. Soc. Soc.\
    \ Simul. 2015, 18, 11. [CrossRef]\n173. Bordini, R.H.; El Fallah Seghrouchni,\
    \ A.; Hindriks, K.; Logan, B.; Ricci, A. Agent programming in the cognitive era.\
    \ Auton. Agents\nMulti-Agent Syst. 2020, 34, 37. [CrossRef]\n174. Costantini,\
    \ S. ACE: A ﬂexible environment for complex event processing in logical agents.\
    \ In International Workshop on Engineering\nMulti-Agent Systems; Springer: Cham,\
    \ Switzerland, 2015; pp. 70–91.\n175. Araujo, P.; Rodríguez, S.; Hilaire, V. A\
    \ metamodeling approach for the identiﬁcation of organizational smells in multi-agent\n\
    systems: Application to ASPECS. Artif. Intell. Rev. 2018, 49, 183–210. [CrossRef]\n\
    176. Boissier, O.; Bordini, R.H.; Hübner, J.F.; Ricci, A. Dimensions in programming\
    \ multi-agent systems. Knowl. Eng. Rev. 2019, 34, e2.\n[CrossRef]\n177. Rahimi,\
    \ H.; Trentin, I.F.; Ramparany, F.; Boissier, O. SMASH: A Semantic-enabled Multi-agent\
    \ Approach for Self-adaptation of\nHuman-centered IoT. arXiv 2021, arXiv:2105.14915.\n\
    178. Baek, Y.M.; Song, J.; Shin, Y.J.; Park, S.; Bae, D.H. A meta-model for representing\
    \ system-of-systems ontologies. In Proceedings of\nthe 2018 IEEE/ACM 6th International\
    \ Workshop on Software Engineering for Systems-of-Systems (SESoS), Gothenburg,\
    \ Sweden,\n29 May 2018; pp. 1–7.\n179. Pigazzini, I.; Briola, D.; Fontana, F.A.\
    \ Architectural Technical Debt of Multiagent Systems Development Platforms. In\
    \ Proceedings\nof the WOA 2021: Workshop “From Objects to Agents”, Bologna, Italy,\
    \ 1–3 September 2021.\n180. Jazayeri, A.; Bass, E.J. Agent-Oriented Methodologies\
    \ Evaluation Frameworks: A Review. Int. J. Softw. Eng. Knowl. Eng. 2020,\n30,\
    \ 1337–1370. [CrossRef]\n181. Logan, B. An agent programming manifesto. Int. J.\
    \ Agent-Oriented Softw. Eng. 2018, 6, 187–210. [CrossRef]\n182. Da Silva, F.L.;\
    \ Costa, A.H.R. A survey on transfer learning for multiagent reinforcement learning\
    \ systems. J. Artif. Intell. Res.\n2019, 64, 645–703. [CrossRef]\n183. Dusparic,\
    \ I.; Cahill, V. Autonomic multi-policy optimization in pervasive systems: Overview\
    \ and evaluation. ACM Trans. Auton.\nAdapt. Syst. (TAAS) 2012, 7, 1–25. [CrossRef]\n\
    184. Sharma, P.K.; Fernandez, R.; Zaroukian, E.; Dorothy, M.; Basak, A.; Asher,\
    \ D.E. Survey of recent multi-agent reinforcement\nlearning algorithms utilizing\
    \ centralized training. In Artiﬁcial Intelligence and Machine Learning for Multi-Domain\
    \ Operations\nApplications III; International Society for Optics and Photonics:\
    \ Orlando, FL, USA, 2021; Volume 11746, p. 117462K.\n185. Foerster, J.; Farquhar,\
    \ G.; Afouras, T.; Nardelli, N.; Whiteson, S. Counterfactual multi-agent policy\
    \ gradients. In Proceedings of\nthe AAAI Conference on Artiﬁcial Intelligence,\
    \ New Orleans, LA, USA, 2–7 February 2018; Volume 32.\n186. De Lemos, R.; Giese,\
    \ H.; Müller, H.A.; Shaw, M.; Andersson, J.; Litoiu, M.; Schmerl, B.; Tamura,\
    \ G.; Villegas, N.M.; Vogel, T.; et al.\nSoftware engineering for self-adaptive\
    \ systems: A second research roadmap. In Software Engineering for Self-Adaptive\
    \ Systems II;\nSpringer: Heidelberg, Germany, 2013; pp. 1–32.\n187. Panait, L.;\
    \ Luke, S. Cooperative multi-agent learning: The state of the art. Auton. Agents\
    \ Multi-Agent Syst. 2005, 11, 387–434.\n[CrossRef]\n188. Rashid, T.; Samvelyan,\
    \ M.; Schroeder, C.; Farquhar, G.; Foerster, J.; Whiteson, S. Qmix: Monotonic\
    \ value function factorisation\nfor deep multi-agent reinforcement learning. In\
    \ Proceedings of the International Conference on Machine Learning, PMLR,\nStockholm,\
    \ Sweden, 10–15 July 2018; pp. 4295–4304.\nSmart Cities 2022, 5\n344\n189. Chen,\
    \ G. A New Framework for Multi-Agent Reinforcement Learning–Centralized Training\
    \ and Exploration with Decentralized\nExecution via Policy Distillation. arXiv\
    \ 2019, arXiv:1910.09152.\n190. Pesce, E.; Montana, G. Improving coordination\
    \ in small-scale multi-agent deep reinforcement learning through memory-driven\n\
    communication. Mach. Learn. 2020, 109, 1727–1747. [CrossRef]\n191. Czarnowski,\
    \ I.; J˛edrzejowicz, P. An agent-based framework for distributed learning. Eng.\
    \ Appl. Artif. Intell. 2011, 24, 93–102.\n[CrossRef]\n192. D’Angelo, M. Engineering\
    \ Decentralized Learning in Self-Adaptive Systems. Ph.D. Thesis, Linnaeus University\
    \ Press, Vaxjo,\nSweden, 2021.\n193. Shi, P.; Yan, B. A survey on intelligent\
    \ control for multiagent systems. IEEE Trans. Syst. Man Cybern. Syst. 2020, 51,\
    \ 161–175.\n[CrossRef]\n194. Poveda, J.I.; Benosman, M.; Teel, A.R. Hybrid online\
    \ learning control in networked multiagent systems: A survey. Int. J. Adapt.\n\
    Control Signal Process. 2019, 33, 228–261. [CrossRef]\n195. Tahbaz-Salehi, A.;\
    \ Jadbabaie, A. A necessary and sufﬁcient condition for consensus over random\
    \ networks. IEEE Trans. Autom.\nControl 2008, 53, 791–795. [CrossRef]\n196. Svítek,\
    \ M.; Skobelev, P.; Kozhevnikov, S. Smart City 5.0 as an urban ecosystem of Smart\
    \ services. In International Workshop on\nService Orientation in Holonic and Multi-Agent\
    \ Manufacturing; Springer: Cham, Switzerland, 2019; pp. 426–438.\n197. Alves,\
    \ B.R.; Alves, G.V.; Borges, A.P.; Leitão, P. Experimentation of negotiation protocols\
    \ for consensus problems in smart parking\nsystems. In International Conference\
    \ on Industrial Applications of Holonic and Multi-Agent Systems; Springer: Cham,\
    \ Switzerland,\n2019; pp. 189–202.\n198. Yu, H.; Yang, Z.; Sinnott, R.O. Decentralized\
    \ big data auditing for smart city environments leveraging blockchain technology.\n\
    IEEE Access 2018, 7, 6288–6296. [CrossRef]\n199. Yang, S.; Tan, S.; Xu, J.X. Consensus\
    \ based approach for economic dispatch problem in a smart grid. IEEE Trans. Power\
    \ Syst. 2013,\n28, 4416–4426. [CrossRef]\n200. De Sousa, A.L.; De Oliveira, A.S.\
    \ Distributed MAS with Leaderless Consensus to Job-Shop Scheduler in a Virtual\
    \ Smart Factory\nwith Modular Conveyors. In Proceedings of the 2020 Latin American\
    \ Robotics Symposium (LARS), 2020 Brazilian Symposium\non Robotics (SBR) and 2020\
    \ Workshop on Robotics in Education (WRE), Natal, Brazil, 9–13 November 2020;\
    \ pp. 1–6.\n201. Cardona, G.A.; Calderon, J.M. Robot swarm navigation and victim\
    \ detection using rendezvous consensus in search and rescue\noperations. Appl.\
    \ Sci. 2019, 9, 1702. [CrossRef]\n202. Saad, A.; Faddel, S.; Youssef, T.; Mohammed,\
    \ O.A. On the implementation of IoT-based digital twin for networked microgrids\n\
    resiliency against cyber attacks. IEEE Trans. Smart Grid 2020, 11, 5138–5150.\
    \ [CrossRef]\n203. Lee, S.; Yang, Y.; Nayel, M.; Zhai, Y. Leader-follower irrigation\
    \ system management with Shapley value. In International Workshop\non Automation,\
    \ Control, and Communication Engineering (IWACCE 2021); SPIE: Beijing, China,\
    \ 2021; Volume 11929, pp. 8–14.\n204. Song, Z.; Liu, Y.; Tan, M. Robust pinning\
    \ synchronization of complex cyberphysical networks under mixed attack strategies.\
    \ Int.\nJ. Robust Nonlinear Control 2019, 29, 1265–1278. [CrossRef]\n205. Miao,\
    \ G.; Ma, Q. Group consensus of the ﬁrst-order multi-agent systems with nonlinear\
    \ input constraints. Neurocomputing 2015,\n161, 113–119. [CrossRef]\n206. Yamakami,\
    \ T. A dimensional framework to evaluate coverage of IoT services in city platform\
    \ as a service. In Proceedings of the\n2017 International Conference on Service\
    \ Systems and Service Management, Dalian, China, 16–18 June 2017; pp. 1–5.\n207.\
    \ Etemadyrad, N.; Li, Q.; Zhao, L. Deep Graph Spectral Evolution Networks for\
    \ Graph Topological Evolution. In Proceedings of\nthe AAAI Conference on Artiﬁcial\
    \ Intelligence, Vancouver, BC, Canada, 2–9 February 2021; Volume 35, pp. 7358–7366.\n\
    208. Ren, W.; Beard, R.W. Formation feedback control for multiple spacecraft via\
    \ virtual structures. IEE Proc. Control Theory Appl.\n2004, 151, 357–368. [CrossRef]\n\
    209. Cortés, J. Global and robust formation-shape stabilization of relative sensing\
    \ networks. Automatica 2009, 45, 2754–2762. [CrossRef]\n210. Krick, L.; Broucke,\
    \ M.E.; Francis, B.A. Stabilisation of inﬁnitesimally rigid formations of multi-robot\
    \ networks. Int. J. Control 2009,\n82, 423–439. [CrossRef]\n211. Olfati-Saber,\
    \ R.; Jalalkamali, P. Collaborative target tracking using distributed Kalman ﬁltering\
    \ on mobile sensor networks. In\nProceedings of the 2011 American Control Conference,\
    \ San Francisco, CA, USA, 29 June–1 July 2011; pp. 1100–1105.\n212. Wang, H.;\
    \ Shi, D.; Song, B.\nA dynamic role assignment formation control algorithm based\
    \ on hungarian method.\nIn\nProceedings of the 2018 IEEE SmartWorld, Ubiquitous\
    \ Intelligence & Computing, Advanced & Trusted Computing, Scal-\nable Computing\
    \ & Communications, Cloud & Big Data Computing, Internet of People and Smart City\
    \ Innovation (Smart-\nWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI), Guangzhou, China,\
    \ 8–12 October 2018; pp. 687–696.\n213. Barve, A.; Nene, M.J. Survey of Flocking\
    \ Algorithms in multi-agent Systems. Int. J. Comput. Sci. Issues (IJCSI) 2013,\
    \ 10, 110–117.\n214. Olfati-Saber, R. Flocking for multi-agent dynamic systems:\
    \ Algorithms and theory. IEEE Trans. Autom. Control 2006, 51, 401–420.\n[CrossRef]\n\
    215. Abdelwahab, S.; Hamdaoui, B. Flocking virtual machines in quest for responsive\
    \ iot cloud services. In Proceedings of the 2017\nIEEE International Conference\
    \ on Communications (ICC), Paris, France, 21–25 May 2017; pp. 1–6.\n216. Haghshenas,\
    \ H.; Badamchizadeh, M.A.; Baradarannia, M. Containment control of heterogeneous\
    \ linear multi-agent systems.\nAutomatica 2015, 54, 210–216. [CrossRef]\nSmart\
    \ Cities 2022, 5\n345\n217. Ji, M.; Ferrari-Trecate, G.; Egerstedt, M.; Buffa,\
    \ A. Containment control in mobile networks. IEEE Trans. Autom. Control 2008,\n\
    53, 1972–1975. [CrossRef]\n218. Xu, B.; Zhang, H.T.; Meng, H.; Hu, B.; Chen, D.;\
    \ Chen, G. Moving target surrounding control of linear multiagent systems with\n\
    input saturation. IEEE Trans. Syst. Man Cybern. Syst. 2020, 52, 1705–1715. [CrossRef]\n\
    219. Hu, B.B.; Zhang, H.T.; Liu, B.; Meng, H.; Chen, G. Distributed Surrounding\
    \ Control of Multiple Unmanned Surface Vessels With\nVarying Interconnection Topologies.\
    \ IEEE Trans. Control Syst. Technol. 2021, 30, 400–407. [CrossRef]\n220. Li, M.;\
    \ Wang, Z.; Li, K.; Liao, X.; Hone, K.; Liu, X. Task Allocation on Layered Multiagent\
    \ Systems: When Evolutionary\nMany-Objective Optimization Meets Deep Q-Learning.\
    \ IEEE Trans. Evol. Comput. 2021, 25, 842–855. [CrossRef]\n221. Amini, M.H.; Mohammadi,\
    \ J.; Kar, S. Promises of fully distributed optimization for iot-based smart city\
    \ infrastructures. In\nOptimization, Learning, and Control for Interdependent\
    \ Complex Networks; Springer: Cham, Switzerland, 2020; pp. 15–35.\n222. Raju,\
    \ L.; Sankar, S.; Milton, R. Distributed optimization of solar micro-grid using\
    \ multi agent reinforcement learning. Procedia\nComput. Sci. 2015, 46, 231–239.\
    \ [CrossRef]\n223. Mohamed, M.A.; Jin, T.; Su, W. Multi-agent energy management\
    \ of smart islands using primal-dual method of multipliers.\nEnergy 2020, 208,\
    \ 118306. [CrossRef]\n224. Olszewski, R.; Pałka, P.; Turek, A. Solving “Smart\
    \ City” Transport Problems by Designing Carpooling Gamiﬁcation Schemes with\n\
    Multi-Agent Systems: The Case of the So-Called “Mordor of Warsaw”. Sensors 2018,\
    \ 18, 141. [CrossRef]\n225. Euchi, J.; Zidi, S.; Laouamer, L. A new distributed\
    \ optimization approach for home healthcare routing and scheduling problem.\n\
    Decis. Sci. Lett. 2021, 10, 217–230. [CrossRef]\n226. Lin, F.r.; Kuo, H.c.; Lin,\
    \ S.m. The enhancement of solving the distributed constraint satisfaction problem\
    \ for cooperative supply\nchains using multi-agent systems. Decis. Support Syst.\
    \ 2008, 45, 795–810. [CrossRef]\n227. Hsieh, F.S. Dynamic conﬁguration and collaborative\
    \ scheduling in supply chains based on scalable multi-agent architecture. J.\n\
    Ind. Eng. Int. 2019, 15, 249–269. [CrossRef]\n228. Liu, Q.; Yang, S.; Wang, J.\
    \ A collective neurodynamic approach to distributed constrained optimization.\
    \ IEEE Trans. Neural Netw.\nLearn. Syst. 2016, 28, 1747–1758. [CrossRef]\n229.\
    \ Necoara, I.; Nedelcu, V.; Dumitrache, I. Parallel and distributed optimization\
    \ methods for estimation and control in networks. J.\nProcess Control 2011, 21,\
    \ 756–766. [CrossRef]\n230. Rana, M.M.; Abdelhadi, A.; Shireen, W. Monitoring\
    \ Operating Conditions of Wireless Power Transfer Systems Using Distributed\n\
    Estimation Process. In Proceedings of the 2021 IEEE International Conference on\
    \ Communications Workshops (ICC Workshops),\nMontreal, QC, Canada, 14–23 June\
    \ 2021; pp. 1–4.\n231. Guastella, D.A.; Campss, V.; Gleizes, M.P. A Cooperative\
    \ Multi-Agent System for Crowd Sensing Based Estimation in Smart\nCities. IEEE\
    \ Access 2020, 8, 183051–183070. [CrossRef]\n232. Tan, R.K.; Bora, ¸S. Exploiting\
    \ of Adaptive Multi Agent System Theory in Modeling and Simulation: A Survey.\
    \ J. Appl. Math.\nComput. (JAMC) 2018, 1, 21–26. [CrossRef]\n233. Rossi, F.; Bandyopadhyay,\
    \ S.; Wolf, M.T.; Pavone, M. Multi-Agent Algorithms for Collective Behavior: A\
    \ structural and\napplication-focused atlas. arXiv 2021, arXiv:2103.11067.\n234.\
    \ Chen, F.; Ren, W. Multi-Agent Control: A Graph-Theoretic Perspective. J. Syst.\
    \ Sci. Complex. 2021, 34, 1973–2002. [CrossRef]\n235. Zelazo, D.; Rahmani, A.;\
    \ Mesbahi, M. Agreement via the edge laplacian. In Proceedings of the 2007 46th\
    \ IEEE Conference on\nDecision and Control, New Orleans, LA, USA, 12–14 December\
    \ 2007; pp. 2309–2314.\n236. You, K.; Xie, L. Network topology and communication\
    \ data rate for consensusability of discrete-time multi-agent systems. IEEE\n\
    Trans. Autom. Control 2011, 56, 2262–2275. [CrossRef]\n237. Shi, C.X.; Yang, G.H.\
    \ Robust consensus control for a class of multi-agent systems via distributed\
    \ PID algorithm and weighted\nedge dynamics. Appl. Math. Comput. 2018, 316, 73–88.\
    \ [CrossRef]\n238. Wang, Q.; Wang, Y. Cluster synchronization of a class of multi-agent\
    \ systems with a bipartite graph topology. Sci. China Inf. Sci.\n2014, 57, 1–11.\
    \ [CrossRef]\n239. Shoham, Y.; Leyton-Brown, K. Multiagent Systems: Algorithmic,\
    \ Game-Theoretic, and Logical Foundations; Cambridge University\nPress: Cambridge,\
    \ UK, 2008.\n240. Zhu, M.; Martínez, S. Distributed coverage games for energy-aware\
    \ mobile sensor networks. SIAM J. Control Optim. 2013,\n51, 1–27. [CrossRef]\n\
    241. Sengupta, S.; Kambhampati, S. Multi-agent reinforcement learning in bayesian\
    \ stackelberg markov games for adaptive moving\ntarget defense. arXiv 2020, arXiv:2007.10457.\n\
    242. Sun, C.; Wang, X.; Liu, J. Evolutionary game theoretic approach for optimal\
    \ resource allocation in multi-agent systems. In\nProceedings of the 2017 Chinese\
    \ Automation Congress (CAC), Jinan, China, 20–22 October 2017; pp. 5588–5592.\n\
    243. Yan, B.; Shi, P.; Lim, C.C.; Shi, Z. Optimal robust formation control for\
    \ heterogeneous multi-agent systems based on reinforcement\nlearning. Int. J.\
    \ Robust Nonlinear Control 2021, 32, 2683–2704. [CrossRef]\n244. Wai, H.T.; Yang,\
    \ Z.; Wang, Z.; Hong, M. Multi-agent reinforcement learning via double averaging\
    \ primal-dual optimization.\narXiv 2018, arXiv:1806.00877.\n245. Jian, L.; Zhao,\
    \ Y.; Hu, J.; Li, P. Distributed inexact consensus-based ADMM method for multi-agent\
    \ unconstrained optimization\nproblem. IEEE Access 2019, 7, 79311–79319. [CrossRef]\n\
    246. Kapoor, S. Multi-agent reinforcement learning: A report on challenges and\
    \ approaches. arXiv 2018, arXiv:1807.09427.\nSmart Cities 2022, 5\n346\n247. Zhang,\
    \ K.; Yang, Z.; Ba¸sar, T. Decentralized multi-agent reinforcement learning with\
    \ networked agents: Recent advances. arXiv\n2019, arXiv:1912.03821.\n248. Papoudakis,\
    \ G.; Christianos, F.; Rahman, A.; Albrecht, S.V. Dealing with non-stationarity\
    \ in multi-agent deep reinforcement\nlearning. arXiv 2019, arXiv:1906.04737.\n\
    249. Lowe, R.; Wu, Y.; Tamar, A.; Harb, J.; Abbeel, P.; Mordatch, I. Multi-agent\
    \ actor-critic for mixed cooperative-competitive\nenvironments. arXiv 2017, arXiv:1706.02275.\n\
    250. Zhang, K.; Yang, Z.; Ba¸sar, T. Multi-agent reinforcement learning: A selective\
    \ overview of theories and algorithms. In Handbook of\nReinforcement Learning\
    \ and Control; Springer: Cham, Switzerland, 2021; pp. 321–384.\n251. Du, W.; Ding,\
    \ S. A survey on multi-agent deep reinforcement learning: From the perspective\
    \ of challenges and applications.\nArtif. Intell. Rev. 2021, 54, 3215–3238. [CrossRef]\n\
    252. Mnih, V.; Badia, A.P.; Mirza, M.; Graves, A.; Lillicrap, T.; Harley, T.;\
    \ Silver, D.; Kavukcuoglu, K. Asynchronous methods for\ndeep reinforcement learning.\
    \ In Proceedings of the International Conference on Machine Learning, PMLR, New\
    \ York, NY, USA,\n20–22 June 2016; pp. 1928–1937.\n253. Lillicrap, T.P.; Hunt,\
    \ J.J.; Pritzel, A.; Heess, N.; Erez, T.; Tassa, Y.; Silver, D.; Wierstra, D.\
    \ Continuous control with deep\nreinforcement learning. arXiv 2015, arXiv:1509.02971.\n\
    254. Lee, L.C.; Nwana, H.S.; Ndumu, D.T.; De Wilde, P. The stability, scalability\
    \ and performance of multi-agent systems. BT Technol.\nJ. 1998, 16, 94–103. [CrossRef]\n\
    255. Liu, J.; Zhang, Y.; Sun, C.; Yu, Y. Fixed-time consensus of multi-agent systems\
    \ with input delay and uncertain disturbances via\nevent-triggered control. Inf.\
    \ Sci. 2019, 480, 261–272. [CrossRef]\n256. Chli, M.; De Wilde, P.; Goossenaerts,\
    \ J.; Abramov, V.; Szirbik, N.; Correia, L.; Mariano, P.; Ribeiro, R. Stability\
    \ of multi-agent\nsystems. In Proceedings of the SMC’03 Conference Proceedings,\
    \ 2003 IEEE International Conference on Systems, Man and\nCybernetics. Conference\
    \ Theme-System Security and Assurance (Cat. No. 03CH37483), Washington, DC, USA,\
    \ 8 October 2003;\nVolume 1, pp. 551–556.\n257. Maadani, M.; Butcher, E.A. Consensus\
    \ stability in multi-agent systems with periodically switched communication topology\n\
    using Floquet theory. Trans. Inst. Meas. Control 2021, 43, 1239–1254. [CrossRef]\n\
    258. Miao, G.; Xu, S.; Zou, Y. Consentability for high-order multi-agent systems\
    \ under noise environment and time delays. J. Frankl.\nInst. 2013, 350, 244–257.\
    \ [CrossRef]\n259. Wang, B.; Fang, X.; Zhao, Y. Stability Analysis of Cooperative\
    \ Control for Heterogeneous Multi-agent Systems with Nonlinear\nDynamics. In Proceedings\
    \ of the 2019 IEEE International Conference on Industrial Technology (ICIT), Melbourne,\
    \ VIC, Australia,\n13–15 February 2019; pp. 1446–1453.\n260. Liu, Y.; Min, H.;\
    \ Wang, S.; Liu, Z.; Liao, S. Distributed consensus of a class of networked heterogeneous\
    \ multi-agent systems. J.\nFrankl. Inst. 2014, 351, 1700–1716. [CrossRef]\n261.\
    \ Sun, X.; Cassandras, C.G.; Meng, X. Exploiting submodularity to quantify near-optimality\
    \ in multi-agent coverage problems.\nAutomatica 2019, 100, 349–359. [CrossRef]\n\
    262. Katsuura, H.; Fujisaki, Y. Optimality of consensus protocols for multi-agent\
    \ systems with interaction. In Proceedings of the 2014\nIEEE International Symposium\
    \ on Intelligent Control (ISIC), Juan Les Pins, France, 8–10 October 2014; pp.\
    \ 282–285.\n263. Yang, X.; Wang, J.; Tan, Y. Robustness analysis of leader–follower\
    \ consensus for multi-agent systems characterized by double\nintegrators. Syst.\
    \ Control Lett. 2012, 61, 1103–1115. [CrossRef]\n264. Wang, G.; Xu, M.; Wu, Y.;\
    \ Zheng, N.; Xu, J.; Qiao, T. Using machine learning for determining network robustness\
    \ of multi-\nagent systems under attacks. In Paciﬁc Rim International Conference\
    \ on Artiﬁcial Intelligence; Springer: Cham, Switzerland, 2018;\npp. 491–498.\n\
    265. Baldoni, M.; Baroglio, C.; Micalizio, R. Fragility and Robustness in Multiagent\
    \ Systems. In International Workshop on Engineering\nMulti-Agent Systems; Springer:\
    \ Cham, Switzerland 2020; pp. 61–77.\n266. Tian, Y.P.; Liu, C.L. Robust consensus\
    \ of multi-agent systems with diverse input delays and asymmetric interconnection\n\
    perturbations. Automatica 2009, 45, 1347–1353. [CrossRef]\n267. Münz, U.; Papachristodoulou,\
    \ A.; Allgöwer, F. Delay robustness in consensus problems.\nAutomatica 2010, 46,\
    \ 1252–1265.\n[CrossRef]\n268. Trentelman, H.L.; Takaba, K.; Monshizadeh, N. Robust\
    \ synchronization of uncertain linear multi-agent systems. IEEE Trans.\nAutom.\
    \ Control 2013, 58, 1511–1523. [CrossRef]\n269. Minsky, N.H.; Murata, T. On manageability\
    \ and robustness of open multi-agent systems. In International Workshop on Software\n\
    Engineering for Large-Scale Multi-Agent Systems; Springer: Heidelberg, Germany,\
    \ 2003; pp. 189–206.\n270. Kim, J.; Yang, J.; Shim, H.; Kim, J.S. Robustness of\
    \ synchronization in heterogeneous multi-agent systems. In Proceedings of the\n\
    2013 European Control Conference (ECC), Zurich, Switzerland, 17–19 July 2013;\
    \ pp. 3821–3826.\n271. Zelazo, D.; Bürger, M. On the robustness of uncertain consensus\
    \ networks. IEEE Trans. Control Netw. Syst. 2015, 4, 170–178.\n[CrossRef]\n272.\
    \ Zhang, D.; Feng, G.; Shi, Y.; Srinivasan, D. Physical safety and cyber security\
    \ analysis of multi-agent systems: A survey of recent\nadvances. IEEE/CAA J. Autom.\
    \ Sin. 2021, 8, 319–333. [CrossRef]\n273. Jung, Y.; Kim, M.; Masoumzadeh, A.;\
    \ Joshi, J.B. A survey of security issue in multi-agent systems. Artif. Intell.\
    \ Rev. 2012,\n37, 239–260. [CrossRef]\nSmart Cities 2022, 5\n347\n274. Chevalier-Boisvert,\
    \ M.; Willems, L.; Pal, S. Minimalistic Gridworld Environment for OpenAI Gym.\
    \ 2018. Available online:\nhttps://github.com/maximecb/gym-minigrid (accessed\
    \ on 10 January 2022).\n275. Mezgebe, T.T.; Demesure, G.; El Haouzi, H.B.; Pannequin,\
    \ R.; Thomas, A. CoMM: A consensus algorithm for multi-agent-based\nmanufacturing\
    \ system to deal with perturbation. Int. J. Adv. Manuf. Technol. 2019, 105, 3911–3926.\
    \ [CrossRef]\n276. Foerster, J.N.; Assael, Y.M.; De Freitas, N.; Whiteson, S.\
    \ Learning to communicate with deep multi-agent reinforcement learning.\narXiv\
    \ 2016, arXiv:1605.06676.\n277. Du, Y.; Wang, S.; Guo, X.; Cao, H.; Hu, S.; Jiang,\
    \ J.; Varala, A.; Angirekula, A.; Zhao, L. GraphGT: Machine Learning Datasets\
    \ for\nGraph Generation and Transformation. In Proceedings of the Thirty-Fifth\
    \ Conference on Neural Information Processing Systems\nDatasets and Benchmarks\
    \ Track (Round 2), Virtual, 6–14 December 2021.\n278. Leskovec, J.; Krevl, A.\
    \ SNAP Datasets: Stanford Large Network Dataset Collection; SNAP: Santa Monica,\
    \ CA, USA, 2014.\n"
  inline_citation: '>'
  journal: Smart cities (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/2624-6511/5/1/19/pdf?version=1646988778
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: A Survey of Adaptive Multi-Agent Networks and Their Applications in Smart
    Cities
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1515/9783110628517
  analysis: '>'
  authors:
  - Nilanjan Dey
  - Gitanjali R. Shinde
  - Parikshit N. Mahalle
  - Henning Salling Olesen
  citation_count: 5
  full_citation: '>'
  full_text: '>

    Skip to content Authenticated with University of Nebraska - Lincoln What does
    this mean? $ USD € EUR - Euro £ GBP - Pound $ USD - Dollar EN 0 University of
    Nebras... SUBJECTS FOR AUTHORS SERVICES PUBLICATIONS ABOUT Open Access Published
    by De Gruyter 2019 The Internet of Everything Advances, Challenges and Applications
    Edited by: Nilanjan Dey , Gitanjali Shinde , Parikshit Mahalle and Henning Olesen
    Funded by: Knowledge Unlatched In the series De Gruyter Series on the Internet
    of Things https://doi.org/10.1515/9783110628517 Cite this Share this 6 OVERVIEW
    CONTENTS Overview About this book In the era before IoT, the world wide web, internet,
    web 2.0 and social media made people’s lives comfortable by providing web services
    and enabling access personal data irrespective of their location. Further, to
    save time and improve efficiency, there is a need for machine to machine communication,
    automation, smart computing and ubiquitous access to personal devices. This need
    gave birth to the phenomenon of Internet of Things (IoT) and further to the concept
    of Internet of Everything (IoE). This book aims to present different aspects of
    IoE, challenges faced by IoE and its applications, divided into 8 chapters. This
    multifaceted coverage of the various verticals and IoT layers is the main attraction
    of this book. Hot topic. Important application of AI. International authors. Most
    recent research. Author / Editor information Henning Olesen, Aalborg, Denmark
    Nilanjan Dey, Kolkatta, India P.N. Mahalle, Pune, India G.R. Shinde, Pune, India
    Topics Artificial Intelligence Computer Sciences Computer Sciences in Medicine
    and Life Sciences Human-Machine Interaction Life Sciences Life Sciences, other                     (Deutsch)
    Download book   Buy Hardcover $137.99 Please note that the hardcover edition is
    printed upon ordering, and will take 2 to 4 weeks to deliver. Language: English
    Publisher: De Gruyter Copyright year: 2019 Audience: academic and industrial researchers
    Pages Front matter: 8 Main content: 176 Illustrations Illustrations: 73 Coloured
    Illustrations: 21 Keywords: Signalvwerarbeitung; Kommunikationstechnik; Künstliche
    Intelligenz eBook Published: August 5, 2019 ISBN: 9783110628517 Hardcover Published:
    August 5, 2019 ISBN: 9783110625486 Subjects Architecture and Design Arts Asian
    and Pacific Studies Business and Economics Chemistry Classical and Ancient Near
    Eastern Studies Computer Sciences Cultural Studies Engineering General Interest
    Geosciences History Industrial Chemistry Islamic and Middle Eastern Studies Jewish
    Studies Law Library and Information Science, Book Studies Life Sciences Linguistics
    and Semiotics Literary Studies Materials Sciences Mathematics Medicine Music Pharmacy
    Philosophy Physics Social Sciences Sports and Recreation Theology and Religion
    Services For Journal Authors For Book Authors For Librarians Rights & Permissions
    Publications Publication types Open Access About Contact Career About De Gruyter
    Partnerships Press FAQs Social Facebook Instagram LinkedIn X / Twitter YouTube
    Winner of the OpenAthens Best Publisher UX Award 2022  Help/FAQ Privacy policy
    Cookie Policy Accessibility Terms & Conditions Legal Notice © Walter de Gruyter
    GmbH 2024 Consent to website analysis We use cookies and other technologies. Some
    of them are necessary for the website to function and are always set. Cookies
    for website analysis are not required and are set only with your consent. Some
    services for analysis process personal data in the USA. With your consent to use
    these services, you also consent to the processing of your data in the USA. Your
    consent is voluntary and can be revoked at any time. For more information, please
    see our Cookie Policy. Accept optional analytics cookies Reject non-essential
    cookies'
  inline_citation: '>'
  journal: De Gruyter eBooks
  limitations: '>'
  pdf_link: null
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: The Internet of Everything
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1007/978-3-319-29206-9
  analysis: '>'
  authors:
  - Rajendra Akerkar
  - Priti Srinivas Sajja
  citation_count: 14
  full_citation: '>'
  full_text: '>

    Your privacy, your choice We use essential cookies to make sure the site can function.
    We also use optional cookies for advertising, personalisation of content, usage
    analysis, and social media. By accepting optional cookies, you consent to the
    processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Textbook © 2016 Intelligent Techniques
    for Data Science Home Textbook Authors: Rajendra Akerkar , Priti Srinivas Sajja   Focuses
    on methods significantly beneficial in data science, and clearly describes them
    at an introductory level, with extensions to selected intermediate and advanced
    techniques Reinforces the machine learning principles with necessary demonstrations
    in the field of data science Integrates illustrations, cases and examples to support
    pedagogical exposition Equips readers with the necessary information to obtain
    hands-on experience of data science 26k Accesses 19 Citations 4 Altmetric Sections
    Table of contents About this book Keywords Authors and Affiliations About the
    authors Bibliographic Information Publish with us Table of contents (9 chapters)
    Search within book Search Access provided by University of Nebraska-Lincoln Front
    Matter Pages i-xvi PDF Introduction to Data Science Rajendra Akerkar, Priti Srinivas
    Sajja Pages 1-30 PDF Data Analytics Rajendra Akerkar, Priti Srinivas Sajja Pages
    31-52 PDF Basic Learning Algorithms Rajendra Akerkar, Priti Srinivas Sajja Pages
    53-93 PDF Fuzzy Logic Rajendra Akerkar, Priti Srinivas Sajja Pages 95-123 PDF
    Artificial Neural Network Rajendra Akerkar, Priti Srinivas Sajja Pages 125-155
    PDF Genetic Algorithms and Evolutionary Computing Rajendra Akerkar, Priti Srinivas
    Sajja Pages 157-184 PDF Other Metaheuristics and Classification Approaches Rajendra
    Akerkar, Priti Srinivas Sajja Pages 185-209 PDF Analytics and Big Data Rajendra
    Akerkar, Priti Srinivas Sajja Pages 211-236 PDF Data Science Using R Rajendra
    Akerkar, Priti Srinivas Sajja Pages 237-259 PDF Back Matter Pages 261-272 PDF
    Back to top About this book This textbook provides readers with the tools, techniques
    and cases required to excel with modern artificial intelligence methods. These
    embrace the family of neural networks, fuzzy systems and evolutionary computing
    in addition to other fields within machine learning, and will help in identifying,
    visualizing, classifying and analyzing data to support business decisions./p>
    The authors, discuss advantages and drawbacks of different approaches, and present
    a sound foundation for the reader to design and implement data analytic solutions
    for real‐world applications in an intelligent manner. Intelligent Techniques for
    Data Science also provides real-world cases of extracting value from data in various
    domains such as retail, health, aviation, telecommunication and tourism. Back
    to top Keywords Big Data Machine learning Data Analytics Data Science Intelligent
    algorithms Back to top Authors and Affiliations Western Norway Research Institute,
    Sogndal, Norway Rajendra Akerkar Department of Computer Science, Sardar Patel
    University, Vallabh Vidhyanagar, India Priti Srinivas Sajja Back to top About
    the authors Rajendra Akerkar is a professor of information technology at Western
    Norway Research Institute, Norway. He has 23 years of research and teaching experience
    in artificial intelligent systems, semantic technologies and big data science.
    His recent research focuses on real world use of big data, and social media analysis
    in a wide set of semantic dimensions. He has held senior positions in the key
    academic conference committees, journal boards and review committees in those
    fields and he has supervised Ph.D. and research M.Sc. projects in intelligent
    systems, web intelligence and data science.  He has managed 12 international ICT
    initiatives, and data-intensive research & development projects for more than
    17 years. Dr Priti Srinivas Sajja (b.1970) joined the faculty of the Department
    of Computer Science, Sardar Patel University, India in 1994 and is presently working
    as a Professor. She received her M.S. (1993) and Ph.D (2000) in Computer Science
    from the Sardar Patel University. Her research interests include knowledge-based
    systems, soft computing, multi-agent systems, and software engineering. She has
    152 publications in books, book chapters, journals, and in the proceedings of
    national and international conferences out of which five publications have won
    best research paper awards. She is co-author of ''Knowledge-Based Systems'' and
    ''Intelligent Technologies for Web Applications'' published in the USA. She is
    supervising work of a few doctoral research scholars while six candidates have
    completed their Ph.D research under her guidance. She was Principal Investigator
    of a major research project funded by UGC, India. She is serving as a member on
    the editorial board of many international science journals and served as a program
    committee member for various international conferences.     Back to top Bibliographic
    Information Book Title Intelligent Techniques for Data Science Authors Rajendra
    Akerkar, Priti Srinivas Sajja DOI https://doi.org/10.1007/978-3-319-29206-9 Publisher
    Springer Cham eBook Packages Computer Science, Computer Science (R0) Copyright
    Information Springer International Publishing Switzerland 2016 Hardcover ISBN
    978-3-319-29205-2 Published: 18 October 2016 Softcover ISBN 978-3-319-80514-6
    Published: 16 June 2018 eBook ISBN 978-3-319-29206-9 Published: 11 October 2016
    Edition Number 1 Number of Pages XVI, 272 Number of Illustrations 64 b/w illustrations,
    57 illustrations in colour Topics Data Mining and Knowledge Discovery, Artificial
    Intelligence, Knowledge Management Back to top Publish with us Policies and ethics
    Back to top Download book PDF Download book EPUB Buy it now Buying options Softcover
    Book USD 84.99 Hardcover Book USD 84.99 MyCopy Softcover USD 39.99 Tax calculation
    will be finalised at checkout Other ways to access Licence this eBook for your
    library Learn about institutional subscriptions Discover content Journals A-Z
    Books A-Z Publish with us Publish your research Open access publishing Products
    and services Our products Librarians Societies Partners and advertisers Our imprints
    Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage
    cookies Your US state privacy rights Accessibility statement Terms and conditions
    Privacy policy Help and support 129.93.161.219 Big Ten Academic Alliance (BTAA)
    (3000133814) - University of Nebraska-Lincoln (3000134173) © 2024 Springer Nature'
  inline_citation: '>'
  journal: Springer eBooks
  limitations: '>'
  pdf_link: null
  publication_year: 2016
  relevance_score1: 0
  relevance_score2: 0
  title: Intelligent Techniques for Data Science
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.36227/techrxiv.19642977.v1
  analysis: '>'
  authors:
  - Samir Patel
  - Shubham Vyas
  - Pallabi Saikia
  - Denish kalariya
  - naman parmar
  citation_count: 2
  full_citation: '>'
  full_text: '>

    LOG IN SIGN UP TechRxiv 9,172,904 views 4,235,710 downloads About TechRxiv TechRxiv
    (pronounced "tech archive") is an open, moderated preprint server for unpublished
    research in the areas of engineering, computer science, and related technology.
    https://www.techrxiv.org/ Public Documents 9174 Members by author by title by
    keyword Filter All Sort by Most Recent BIOENGINEERING 871 COMMUNICATION, NETWORKING
    AND BROADCAST TECHNOLOGIES 2284 COMPONENTS, CIRCUITS, DEVICES AND SYSTEMS 1068
    COMPUTING AND PROCESSING 3373 ENGINEERED MATERIALS, DIELECTRICS AND PLASMAS 248
    ENGINEERING PROFESSION 543 FIELDS, WAVES AND ELECTROMAGNETICS 853 GENERAL TOPICS
    FOR ENGINEERS 647 GEOSCIENCE 268 NUCLEAR ENGINEERING 70 PHOTONICS AND ELECTROOPTICS
    345 POWER, ENERGY AND INDUSTRY APPLICATIONS 1201 ROBOTICS AND CONTROL SYSTEMS
    879 TRANSPORTATION 387 AEROSPACE 265 SIGNAL PROCESSING AND ANALYSIS 1949 Terahertz
    Communications and Sensing for 6G and Beyond: A Comprehensive Review Wei Jiang
    and 14 more April 04, 2024 Next-generation cellular technologies, commonly referred
    to as the sixth generation (6G), are envisioned to support a higher system capacity,
    better performance, and network sensing capabilities. The terahertz (THz) band
    is one potential enabler to this end due to the large unused frequency bands and
    the high spatial resolution enabled by the short signal wavelength and large bandwidth.
    Different from earlier surveys, this paper presents a comprehensive treatment
    and technology survey on THz communications and sensing in terms of advantages,
    Rapid Feasibility Assessment of Energy Unit Integration in Distribution Networks
    Sicheng Gong and 2 more April 03, 2024 In contemporary heavy-load distribution
    networks, preceding feasibility assessment is imperative before incorporating
    additional energy units. However, the feasibility examination for massive combined
    operational scenarios of relevant units is computationally intensive with repetitive
    power flow calculations. To this end, this paper proposes a rapid assessment framework,
    the kernel of which is to learn from formerly examined scenarios, thus forming
    expansive feasible/infeasible regions to geometrically rule in/out subsequent
    scenarios. Without running the power flow computation in most scenarios, we accelerate
    the assessment process. Moreover, enlightened by heuristic hypersurface search,
    such prechecking efficiency can be further boosted. In a risk-averse manner, this
    framework can be conceptualized using the exact grid model. Especially, evidenced
    by testing on a 10.5kV distribution grid, the framework shows a significant assessment
    efficiency improvement and strict accuracy guarantee, where we observe at least
    76.13% assessment time reduction and zero accuracy loss in all testing cases.
    We anticipate this work to be a starting point for more sophisticated geometry-accelerating
    feasibility assessment methods. Improving Molecular De Novo Drug Design with Transformers
    Dhaval Soni and 7 more April 03, 2024 Drug design is undergoing a transformation
    as we challenge conventional methods by integrating state-of-the-art artificial
    intelligence with the intricate domain of molecular biology. At the heart of our
    endeavor lies a significant challenge: the scarcity of datasets containing active
    compounds for emerging target proteins. To confront this obstacle, we''re pioneering
    an innovative approach. We''re merging the advanced Generative Pre-trained Transformer
    (GPT) architecture with the nuanced capabilities of Long Short-Term Memory (LSTM)
    networks, with the aim of generating Simplified Molecular Input Line Entry System
    (SMILES) strings to unveil novel therapeutic pathways. Additionally, we''re employing
    a Bidirectional Encoder Representations from Transformers (BERT) pretraining strategy
    to enrich our model with comprehensive molecular data, including amino acid sequences
    and molecular SMILES datasets. Through meticulous fine-tuning on a meticulously
    curated protein-ligand complex dataset, we''re achieving precise conditional generation
    via autoregressive supervised learning. Our research introduces a groundbreaking
    method to assess molecular affinity, validated against established proteins, showcasing
    superior binding affinities compared to certain FDA-approved drugs in docking
    experiments. By pushing the boundaries of generative algorithms and establishing
    a robust framework for evaluating molecular affinity, we''re driving forward the
    field of de novo drug design, offering promising therapeutic avenues and enabling
    deeper exploration of the chemical landscape. Formalising a Gateway-based Blockchain
    Interoperability Solution with Event-B Guzmán Llambías and 2 more April 03, 2024
    A document by Guzman Llambias . Click on the document to view its contents. Magnetic
    Behavior of NO Fe-Si Sheets under Tensile and Compressive Stress Carlo Appino
    and 6 more April 03, 2024 The stress dependence of the magnetic properties of
    non-oriented Fe-Si steel sheets has been investigated by measurement and analysis
    of hysteresis loop, magnetization curve, and energy losses taken at different
    peak polarization values Jp (0.5 T – 1.5 T) between DC and f = 400 Hz. The salient
    feature of the material response to the stress lies in the monotonic deterioration
    of the soft magnetic properties, across the whole (Jp - f) domain, on passing
    from the maximum tensile stress (σ = +30 MPa) to the maximum compression (σ =
    -30 MPa). This is understood in terms of stress-induced redistribution of the
    domains between easy axes, making magnetic hardening by compression directly related
    to unfavorably directed domains and 90° domain-wallmediated magnetization transitions.
    The loss decomposition is carried out across the whole investigated frequency
    range, taking into account the skin effect at the highest frequencies. Quasi-static
    and dynamic losses follow a same trend with σ, both monotonically increasing on
    passing from the tensile to the compressive stress limits, according to the theoretically
    expected relationship existing between the hysteresis and the excess loss components.
    The latter is shown to identify the correlation regions where the magnetization
    is reversed of size comparable with the average grain size and loosely following
    the dependence of the loss figure on the applied stress. A bio-inspired hardware
    implementation of an analog spike-based hippocampus memory mo... Daniel Casanueva-Morato
    and 4 more April 03, 2024 The need for processing at the edge the increasing amount
    of data that is being produced by multitudes of sensors has led to the demand
    for mode power efficient computational systems, by exploring alternative computing
    paradigms and technologies. Neuromorphic engineering is a promising approach that
    can address this need by developing electronic systems that faithfully emulate
    the computational properties of animal brains. In particular, the hippocampus
    stands out as one of the most relevant brain region for implementing auto associative
    memories capable of learning large amounts of information quickly and recalling
    it efficiently. In this work, we present a computational spike-based memory model
    inspired by the hippocampus that takes advantage of the features of analog electronic
    circuits: energy efficiency, compactness, and real-time operation. This model
    can learn memories, recall them from a partial fragment and forget. It has been
    implemented as a Spiking Neural Networks directly on a mixed-signal neuromorphic
    chip. We describe the details of the hardware implementation and demonstrate its
    operation via a series of benchmark experiments, showing how this research prototype
    paves the way for the development of future robust and low-power mixed-signal
    neuromorphic processing systems. Exploratory Study of oneM2M-based Interoperability
    Architectures for IoT: A Smart Cit... VJS Pranavasri and 6 more April 03, 2024
    The advent of the Internet of Things (IoT) has ushered in transformative possibilities
    for smart cities, with the potential to revolutionize urban living through enhanced
    connectivity and data-driven decision-making. However, the effective realization
    of IoT in smart cities hinges upon the seamless interoperability of diverse devices
    and systems. To address this critical need, the oneM2M standards initiative has
    emerged as a foundational framework for IoT interoperability. In this research
    paper, we perform an exploratory analysis of three prominent open-source oneM2M
    based interoperability systems-Mobius, OM2M, and ACME. We leverage an existing
    large-scale system provided by our Smart City Living Lab deployed at IIIT Hyderabad,
    sprawling a 66-acre campus featuring over 370 nodes across eight verticals. We
    investigate the architectural characteristics of each solution, considering their
    strengths and limitations in facilitating IoT interoperability. Through this analysis,
    our paper aims to provide valuable insights for stakeholders seeking to implement
    IoT interoperability solutions in the context of smart cities. By evaluating the
    strengths and limitations of Mobius, OM2M, and ACME, we seek to offer guidance
    for selecting the most suitable solution. Our analysis reveals that the optimal
    framework choice depends on specific quality constraints: Mobius excels in performance,
    while ACME offers advantages in ease of setup for smaller-scale implementations.
    Comparing Concepts of Service Blocking Queues in Hardware-in-the-Loop Systems
    Tobias Konheiser and 3 more April 03, 2024 ZF is developing an autonomous driving
    system, which requires extensive testing of the developed devices and software
    on hardware-in-the-loop (HIL) systems. Therefore, a robust and high-performing
    HIL system is essential. The purpose of a HIL system is to replay recorded data
    to the device-undertest. Recordings are loaded, processed and streamed to the
    deviceunder-test with real-time requirements. This streaming chain includes processing
    nodes and queues. This requires careful management of queue configurations. An
    overflow in the queue will result in packet loss, while an underflow may violate
    the real-time constraint. This study aims to develop and evaluate concepts for
    service blocking queues. These concepts block or pause the incoming service to
    a queue when necessary to avoid queue overflows and associated data loss. However,
    an out-of-the-box solution is not available and different approaches affect the
    behaviour and performance of the system. Therefore, the developed concepts are
    evaluated against each other and against the existing system based on selected
    performance parameters in specific scenarios. The scenarios cover a wide range
    of situations, reflecting standard input data with varying numbers of parallel
    streams and bottleneck scenarios forcing queue overflows or blockages. The developed
    service blocking queue concepts eliminate data loss in all scenarios, but introduce
    overhead, resulting in reduced system performance. However, the service blocking
    queue concept using a modified token-bucket approach proved to be the best solution,
    as the elimination of data loss justifies the additional overhead. This concept
    is proposed for implementation and deployment on the HIL system. Generative AI-Based
    Text Generation Methods Using Pre-Trained GPT 2 Model Rohit Pandey and 7 more
    April 03, 2024 A text generation model is a machine learning model that uses neural
    networks, especially transformers architecture to generate contextually relevant
    text based on linguistic patterns learned from extensive corpora. The models are
    trained on a huge amount of textual data so that they can model and learn complex
    concepts of any language like its grammar, vocabulary, phrases, and styles. FlowDep
    - An efficient and optical-flow-based algorithm of obstacle detection for aut...
    Chen-Fu Yeh and 7 more April 03, 2024 Obstacle detection is crucial for the safety
    and efficiency of autonomous vehicles. For mini-vehicles such as palm-sized drones,
    it is a challenge to implement traditional methods like Lidar due to high costs
    and physical constraints. Vision-based deep learning approaches, while accurate,
    are too resource-intensive for the mini-vehicles. To address this issue, we introduce
    Flowdep, a novel optical-flow-based algorithm inspired by the low-resolution but
    efficient motion-detection mechanisms in insects. Flowdep combines optic flow
    and IMU (or positioning information) to estimate the depth of every image pixel.
    We also generate a variant of Flowdep using the artificial neural network (Flowdep-ANN).
    Our tests show that Flowdep and Flowdep-ANN are 5.8 to 114.7 times faster than
    the DNN networks we tested, while the accuracies of Flowdep and Flowdep-ANN are
    on par with these networks. We further tested Flowdep and Flowdep-ANN on a small
    autonomous vehicle with Raspberry Pi4 as the computing platform, and both models
    successfully performed real-time object detection. The present work demonstrates
    the potential of using optical flow as an efficient approach to estimate depth
    and detect obstacles in resource-constrained mini-vehicles. Misinformative Data
    Visualizations in the Sports Media Domain Drew Scott April 03, 2024 Sports are
    data-driven: individual performances are measured using statistics and teams leverage
    data analytics to outperform competition. Sports media-which is created by media
    outlets, teams, and individuals-engage its consumers by creating narratives about
    the sport, teams, and players. Due to the importance of data in the sports world,
    data visualizations are a pillar in the sports media landscape. These data visualizations,
    while appearing to accurately convey data to its consumers, can be misinformative;
    media creators often have incentives to present specific narratives which don''t
    always fit the data. This work contributes to an existing misinformative data
    visualization taxonomy. In doing so, it makes it easier to understand the techniques
    and design choices used to create misinformative visualizations in all domains,
    not only in sports media. A Survey of RFID Authentication Protocols Drew Scott
    April 03, 2024 "Radio frequency identification" (RFID) systems are ubiquitous
    in today''s world. In an RFID system, it is a desirable to attain mutual authentication
    between a reader and a tag before commencing application-level communications.
    This is because tags should not share secret information with unknown parties
    and readers need to defend against tag impersonation. Authentication protocols
    designed for communication between computers, however, are not appropriate for
    RFID systems because tags are extremely resource constrained (low energy, small
    memory, etc.). Thus, there have been many attempts to design secure and practical
    authentication protocols for RFID systems over the years since RFID systems became
    prevalent. This survey summarizes and compares these protocols. The Effect of
    Multipath in Distributed Arrays with Time Reversal Hassna Ouassal and 2 more April
    03, 2024 This article examines the effect of multipath channels on the performance
    of distributed arrays that employ time reversal. A model of the signal received
    from a distributed array is formulated, and a statistical analysis of the variation
    in signal power in the presence of phase noise and multipath is given. We present
    the impact these nonidealities have on received signal power, and we analyze the
    received power for three specific cases: continuous waveform, impulse waveform,
    and modulated rectangular pulse waveform in the presence of standard channel models.
    It is shown that for larger arrays in multipath channels, the change in power
    between coherent and incoherent states converges to the line-of-sight channel.
    It is further shown that in a line-of-sight channel time-reversal completely cancels
    unknown channel delays resulting in coherent signals from all nodes in a distributed
    array, while in a multipath channel only the main diagonal round-trip paths are
    coherent. Nevertheless, this additional benefit improves signal coherence in complex
    channels and can aide in distributed array synchronization using two-way time
    transfer. Disproof of Hodge Conjecture by Graph Theory Jihyeon Yoon April 02,
    2024 Hodge conjecture is turned out to be false in extension of graph theory based
    on its algebraic attribute. Hash3D: Training-free Acceleration for 3D Generation
    Xingyi Yang and 1 more April 02, 2024 The evolution of 3D generative modeling
    has been notably propelled by the adoption of 2D diffusion models. Despite this
    progress, the cumbersome optimization process per se presents a critical hurdle
    to efficiency. In this paper, we introduce Hash3D, a universal acceleration for
    3D generation without model training. Central to Hash3D is the insight that feature-map
    redundancy is prevalent in images rendered from camera positions and diffusion
    time-steps in close proximity. By effectively hashing and reusing these feature
    maps across neighboring timesteps and camera angles, Hash3D substantially prevents
    redundant calculations, thus accelerating the diffusion model''s inference in
    3D generation tasks. We achieve this through an adaptive grid-based hashing. Surprisingly,
    this feature-sharing mechanism not only speed up the generation but also enhances
    the smoothness and view consistency of the synthesized 3D objects. Our experiments
    covering 5 textto-3D and 3 image-to-3D models, demonstrate Hash3D''s versatility
    to speed up optimization, enhancing efficiency by 1.3 ∼ 4×. Additionally, Hash3D''s
    integration with 3D Gaussian splatting largely speeds up 3D model creation, reducing
    text-to-3D processing to about 10 minutes and image-to-3D conversion to roughly
    30 seconds. The code is provided in https://github.com/Adamdad/hash3D. Area and
    Power Efficient Implementation of Configurable Ring Oscillator PUF Enas Abulibdeh
    and 4 more April 02, 2024 Physically Unclonable Function (PUF) is an emerging
    hardware security primitive that provides a promising solution for lightweight
    security. PUFs can be used to generate a secret key that depends on the random
    manufacturing process variation of the device for lightweight authentication and
    device identification. This work proposes an optimized version of the Configurable
    Ring Oscillator (CRO) PUF that aims to reduce power consumption and area overhead.
    The proposed design eliminates the duplication of ROs, reduces the switching activity,
    and introduces the inter-stage delay as an additional source of randomness. The
    proposed PUF has been implemented in 22nm FDSOI technology using the Synopsys
    tools. A comprehensive security analysis has been acquired utilizing Challenge-Response
    Pairs collected from 8 chips. Results show an average of 49.42%, 38.25%, 9.95%,
    and 45.5% for uniformity, diffuseness, reliability, and uniqueness, respectively.
    Compared with the state-of-the-art, the proposed design achieves an area and power
    reduction of 75% and 65.1%, respectively. With the proposed PUF delivering 10
    32 CRPs, it is classified as a strong PUF. Additionally, the proposed design passes
    NIST tests and achieves an average prediction accuracy of 67.1% of machine learning
    modeling. A Hero Or A Killer? Overview Of Opportunities, Challenges, And Implications
    Of Text-T... Mijat Kustudic and 1 more April 02, 2024 SORA is a text-to-video
    model that can create videos based on simple user prompts. The model promises
    to revolutionize the way content is created. When SORA is released to the general
    public, it may transform a wide array of industries but also pose significant
    challenges and risks. This research aims to provide a comprehensive understanding
    of SORA''s opportunities, challenges, and implications. It explores its potential
    applications in film-making, education, gaming, advertising, accessibility, healthcare,
    and social media content creation. Additionally, it delves into its potential
    challenges and risks, including misinformation, privacy concerns, bias, regulatory
    complexities, and dependence on technology. This research provides important recommendations
    to promote responsible deployment of the AI model. Advancements and Challenges
    in Robot Grasping and Manipulation for Aspiring Researche... Claudio Zito April
    02, 2024 Robot grasping and manipulation represent pivotal aspects of robotics
    research with profound implications for the future of autonomous systems. This
    report delves into the intricacies of designing robotic hands, the hurdles in
    creating robust manipulation actions, and the advancements in the field that poised
    to catalyze a new era of autonomy. Drawing inspiration from science fiction''s
    portrayal of robotics, we bridge the conceptual gap between fiction and ongoing
    real-world technical research, aiming to provide a comprehensive overview for
    students interested in robotics. ← Previous 1 2 3 4 5 6 7 8 9 … 509 510 Next →
    TechRxiv | Powered by Authorea.com Home About Submission Guidelines FAQs Terms
    of Use Privacy Policy Contact Us'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: https://www.techrxiv.org/articles/preprint/A_Futuristic_Survey_on_Learning_Techniques_for_Internet_of_Things_IoT_Security_Developments_Applications_and_Challenges/19642977/1/files/34888401.pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'A Futuristic Survey on Learning Techniques for Internet of Things (IoT)
    Security : Developments, Applications, and Challenges'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/rs15164112
  analysis: '>'
  authors:
  - Bhargavi Janga
  - Gokul Prathin Asamani
  - Ziheng Sun
  - Nicoleta Cristea
  citation_count: 2
  full_citation: '>'
  full_text: ">\nCitation: Janga, B.; Asamani, G.P.;\nSun, Z.; Cristea, N. A Review\
    \ of\nPractical AI for Remote Sensing in\nEarth Sciences. Remote Sens. 2023, 15,\n\
    4112. https://doi.org/10.3390/\nrs15164112\nAcademic Editor: Lefei Zhang\nReceived:\
    \ 7 July 2023\nRevised: 14 August 2023\nAccepted: 15 August 2023\nPublished: 21\
    \ August 2023\nCopyright:\n© 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\n\
    This article is an open access article\ndistributed\nunder\nthe\nterms\nand\n\
    conditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n\
    4.0/).\nremote sensing  \nReview\nA Review of Practical AI for Remote Sensing\
    \ in Earth Sciences\nBhargavi Janga 1, Gokul Prathin Asamani 1, Ziheng Sun 1,*\n\
    and Nicoleta Cristea 2\n1\nCenter for Spatial Information Science and Systems,\
    \ College of Science, George Mason University, 4400\nUniversity Drive, MSN 6E1,\
    \ Fairfax, VA 22030, USA; bjanga@gmu.edu (B.J.); gasamani@gmu.edu (G.P.A.)\n2\n\
    Department of Civil and Environmental Engineering, University of Washington, Seattle,\
    \ WA 98195, USA;\ncristn@uw.edu\n*\nCorrespondence: zsun@gmu.edu; Tel.: +1-703-993-6124\n\
    Abstract: Integrating Artiﬁcial Intelligence (AI) techniques with remote sensing\
    \ holds great potential\nfor revolutionizing data analysis and applications in\
    \ many domains of Earth sciences. This review\npaper synthesizes the existing\
    \ literature on AI applications in remote sensing, consolidating and\nanalyzing\
    \ AI methodologies, outcomes, and limitations. The primary objectives are to identify\n\
    research gaps, assess the effectiveness of AI approaches in practice, and highlight\
    \ emerging trends and\nchallenges. We explore diverse applications of AI in remote\
    \ sensing, including image classiﬁcation,\nland cover mapping, object detection,\
    \ change detection, hyperspectral and radar data analysis, and\ndata fusion. We\
    \ present an overview of the remote sensing technologies, methods employed, and\n\
    relevant use cases. We further explore challenges associated with practical AI\
    \ in remote sensing,\nsuch as data quality and availability, model uncertainty\
    \ and interpretability, and integration with\ndomain expertise as well as potential\
    \ solutions, advancements, and future directions. We provide\na comprehensive\
    \ overview for researchers, practitioners, and decision makers, informing future\n\
    research and applications at the exciting intersection of AI and remote sensing.\n\
    Keywords: Artificial Intelligence; remote sensing technology; deep learning; LiDAR;\
    \ image classification;\nobject detection; change detection; data analysis\n1.\
    \ Introduction\nRemote sensing is a technology that enables data collection without\
    \ direct contact\nwith the subject, utilizing sensors to measure or detect various\
    \ types of energy, such as\nelectromagnetic radiation and acoustic signals, emitted,\
    \ reﬂected, or scattered by the object\nunder investigation [1]. Multiple sensors\
    \ and platforms have been developed for remote\nsensing. As sensors continue to\
    \ advance, the amount of remote sensing data generated\nhas reached staggering\
    \ proportions. For example, according to NASA’s Earth Science\nData Systems (ESDS),\
    \ the Earthdata Cloud held more than 59 petabytes (PB) of data as\nof September\
    \ 2021. ESDS estimates that this amount is expected to increase to more than\n\
    148 PB in 2023, 205 PB in 2024, and 250 PB in 2025 [2]. To effectively manage\
    \ this massive\nvolume of remote sensing data, preprocessing techniques, including\
    \ noise reduction and\nsensor calibration using a variety of algorithms and data\
    \ compression algorithms, are\nutilized to minimize the data size, while computer\
    \ systems with ample memory and\nparallel processing capabilities facilitate the\
    \ handling of these large datasets [3].\nWith the increasing data quality and\
    \ volume from remote sensing platforms, there\nis a need for computational platforms\
    \ and effective tools to handle and extract valuable\ninformation from remote\
    \ sensing datasets. AI tools can assist in managing large volumes of\nobservations,\
    \ modeling, analysis, and environmental forecasting, and have proven effective\n\
    for key tasks such as noise reduction [4], data fusion [5], object detection [6,7],\
    \ and many\nother important applications. As AI technologies develop, acquiring\
    \ and storing remote\nsensing data becomes increasingly important. The process\
    \ of obtaining this large volume\nof data entails using various sensors on different\
    \ platforms, such as Unmanned Aerial\nRemote Sens. 2023, 15, 4112. https://doi.org/10.3390/rs15164112\n\
    https://www.mdpi.com/journal/remotesensing\nRemote Sens. 2023, 15, 4112\n2 of\
    \ 34\nVehicles (UAVs) [8], unmanned ground vehicles (UGVs), aircraft, and satellites.\
    \ These\nsensors, including Global Positioning System (GPS), Inertial Measurement\
    \ Unit (IMU),\nLiDAR, and cameras, play an important role in capturing diverse\
    \ types of energy, such\nas electromagnetic radiation and acoustic signals, emitted,\
    \ reﬂected, or scattered by the\nobjects of interest. In remote sensing, fusing\
    \ data from multiple sensors, such as LiDAR,\nmultispectral or hyperspectral imaging,\
    \ and radar, facilitates comprehensive and detailed\nanalysis of the Earth’s surface,\
    \ atmosphere, and environment [9]. In advanced applications,\nAI-powered onboard\
    \ and ground processing systems take center stage, autonomously\nhandling critical\
    \ tasks like calibration, ﬁltering, ﬁlling, and scaling [10,11]. These algorithms\n\
    identify intricate patterns and detect anomalies, minimizing subjectivity and\
    \ bias in the\nanalysis process and empowering researchers to efﬁciently assimilate,\
    \ analyze, and interpret\nvast amounts of remote sensing data with unprecedented\
    \ speed and accuracy.\nA number of challenges related to AI approaches may limit\
    \ their practical applications.\nFor example, training AI algorithms, especially\
    \ deep learning models, requires signiﬁcant\ncomputational resources, making them\
    \ challenging to develop on resource-constrained\nshared devices. Many neural\
    \ network-based models are often considered black-box models,\nand understanding\
    \ the reasons behind AI predictions is difﬁcult but critical for gaining\ntrust\
    \ and ensuring effective decision making [12]. Creating labeled datasets for training\n\
    AI models in remote sensing can be labor-intensive and time consuming, especially\
    \ for\nﬁne-grained or multi-class tasks [13], and transferring AI models trained\
    \ on one dataset\nto perform well on different datasets can also require additional\
    \ resources. Incorporat-\ning domain-speciﬁc knowledge and expertise into AI models\
    \ is essential to ensure the\nrepresentation of relevant features and relationships\
    \ [14,15].\nTo successfully deploy an operational AI model, there are a few critical\
    \ steps to\nconsider. First, real-world applications usually need AI models to\
    \ scale efﬁciently to\nprocess large-scale remote sensing data in real time, with\
    \ minimal turnaround. Practical\nAI systems require collaborative platforms for\
    \ AI developers, domain experts, and remote\nsensing practitioners working together\
    \ to share knowledge, data, and best practices, with\npublic-facing applications\
    \ displaying user-friendly tools and interfaces that enable non-\nexperts to leverage\
    \ AI capabilities for remote sensing applications effectively. Uncertainty\nestimates\
    \ are also needed for decision-making processes, especially in accuracy-critical\n\
    applications like precision agriculture and environmental monitoring [16]. When\
    \ integrated\nwith social media and sensitive data, AI systems need to address\
    \ privacy concerns, ethical\nconsiderations, and compliance with local and international\
    \ regulations.\nThis review paper aims to comprehensively evaluate and synthesize\
    \ the existing\nliterature on the need to develop practical AI in remote sensing.\
    \ We aim to provide\nvaluable insights that inform future research and applications.\
    \ Key contributions of this\npaper include the following:\n1.\nOverview of successful\
    \ examples of practical AI in research and real-world applications;\n2.\nDiscussion\
    \ of research challenges and reality gaps in the practical integration of AI\n\
    with remote sensing;\n3.\nEmerging trends and advancements in practical AI techniques\
    \ for remote sensing;\n4.\nCommon challenges practical AI face in remote sensing,\
    \ such as data quality, avail-\nability of training data, interpretability, and\
    \ the requirement for domain expertise;\n5.\nPotential practical AI solutions\
    \ and ongoing or future real-world applications.\nWe adopted a structured approach\
    \ to organize this paper. First, we commence with a\nbackground, which is a signiﬁcant\
    \ section that provides crucial context on AI and remote\nsensing, emphasizing\
    \ key techniques. Subsequently, we explore various applications of\nAI in remote\
    \ sensing, presenting an overview of the methods employed and relevant use\ncases.\
    \ Additionally, we discuss the challenges related to AI integration in remote\
    \ sensing.\nFinally, we summarize futuristic AI applications that can potentially\
    \ transform various\nﬁelds beyond what we currently imagine.\nRemote Sens. 2023,\
    \ 15, 4112\n3 of 34\n2. Basics of AI and Remote Sensing\nThis section comprehensively\
    \ explores the fundamental concepts of remote sensing\nand discusses key AI techniques\
    \ in this ﬁeld. A systematic literature review was con-\nducted to achieve a comprehensive\
    \ understanding, encompassing reputable sources such\nas peer-reviewed publications,\
    \ conference papers, and technical reports. The selected litera-\nture was critically\
    \ analyzed, and key insights and ﬁndings were synthesized to provide\ncomprehensive\
    \ coverage of a broad spectrum of AI techniques in remote sensing.\n2.1. Brief\
    \ Recap of Remote Sensing Technologies\nUnderstanding the fundamental principles\
    \ of remote sensing is important for compre-\nhending its diverse techniques and\
    \ applications and integrating them with AI techniques.\nRemote sensing systems\
    \ are built to take advantage of the various parts of the electromag-\nnetic spectrum\
    \ (Figure 1) and atmospheric windows to observe different targets. Passive\nsensors\
    \ detect natural energy emitted or reﬂected by the Earth, such as optical sensors\
    \ that\ncapture sunlight reﬂection (Figure 2a), whereas active sensors emit energy\
    \ and measure the\nreﬂected or backscattered signals (Figure 2b). This wide range\
    \ of sensors enables remote\nsensing data to be acquired via satellites for global\
    \ coverage, aircraft for higher spatial\nresolution, and drones for small-scale\
    \ data collection [17].\n \ncases. Additionally, we discuss the challenges related\
    \ to AI integration in remote sensing. \nFinally, we summarize futuristic AI applications\
    \ that can potentially transform various \nfields beyond what we currently imagine.\
    \ \n2. Basics of AI and Remote Sensing \nThis section comprehensively explores\
    \ the fundamental concepts of remote sensing \nand discusses key AI techniques\
    \ in this field. A systematic literature review was con-\nducted to achieve a\
    \ comprehensive understanding, encompassing reputable sources such \nas peer-reviewed\
    \ publications, conference papers, and technical reports. The selected lit-\n\
    erature was critically analyzed, and key insights and findings were synthesized\
    \ to provide \ncomprehensive coverage of a broad spectrum of AI techniques in\
    \ remote sensing. \n2.1. Brief Recap of Remote Sensing Technologies \nUnderstanding\
    \ the fundamental principles of remote sensing is important for com-\nprehending\
    \ its diverse techniques and applications and integrating them with AI tech-\n\
    niques. Remote sensing systems are built to take advantage of the various parts\
    \ of the \nelectromagnetic spectrum (Figure 1) and atmospheric windows to observe\
    \ different tar-\ngets. Passive sensors detect natural energy emitted or reflected\
    \ by the Earth, such as opti-\ncal sensors that capture sunlight reflection (Figure\
    \ 2a), whereas active sensors emit energy \nand measure the reflected or backscattered\
    \ signals (Figure 2b). This wide range of sensors \nenables remote sensing data\
    \ to be acquired via satellites for global coverage, aircraft for \nhigher spatial\
    \ resolution, and drones for small-scale data collection [17]. \n \nFigure 1.\
    \ Simplified representation of the electromagnetic spectrum (adapted from \nhttps://crisp.nus.edu.sg/~research/tutorial/em.htm,\
    \ accessed on 30 July 2023). \nOnce remote sensing data is acquired, interpreting\
    \ images and digital data becomes \ncrucial in extracting meaningful information.\
    \ Digital image processing techniques include \nfiltering, image fusion, feature\
    \ extraction, and classification algorithms, enabling the ex-\ntraction of valuable\
    \ insights [18]. The following paragraphs describe the main remote \nsensing techniques,\
    \ while AI methods that assist with data processing are presented in \nSection\
    \ 2.2. \nFigure 1. Simpliﬁed representation of the electromagnetic spectrum (adapted\
    \ from https://crisp.nus.\nedu.sg/~research/tutorial/em.htm, accessed on 30 July\
    \ 2023).\nOnce remote sensing data is acquired, interpreting images and digital\
    \ data becomes\ncrucial in extracting meaningful information. Digital image processing\
    \ techniques include\nﬁltering, image fusion, feature extraction, and classiﬁcation\
    \ algorithms, enabling the extrac-\ntion of valuable insights [18]. The following\
    \ paragraphs describe the main remote sensing\ntechniques, while AI methods that\
    \ assist with data processing are presented in Section 2.2.\n2.1.1. Optical Remote\
    \ Sensing\nThis technique focuses on gathering and interpreting optical data,\
    \ primarily within\nthe visible and near-infrared sections of the electromagnetic\
    \ spectrum (Figure 1) [19]. As\nsunlight interacts with the Earth’s surface, materials\
    \ on the surface absorb and reﬂect\nspeciﬁc wavelengths of light. This interaction\
    \ creates unique spectral signatures that are\ncharacteristic of different surface\
    \ features [20]. The sensors, available in handheld, airborne,\nand spaceborne\
    \ modes, contain detectors that record light intensity across different wave-\n\
    lengths (Figure 3). The recorded data are transmitted to ground stations or processing\n\
    centers, where they are processed and transformed into images or spectral data.\n\
    Remote Sens. 2023, 15, 4112\n4 of 34\nRemote Sens. 2023, 15, 4112 \n4 of 37 \n\
    \ \n \n \nFigure 2. (a) Passive remote sensing: the sensor receives information.\
    \ (b) Active remote sensing: the \nsensor emits and receives information. \n2.1.1.\
    \ Optical Remote Sensing \nThis technique focuses on gathering and interpreting\
    \ optical data, primarily within \nthe visible and near-infrared sections of the\
    \ electromagnetic spectrum (Figure 1) [19]. As \nsunlight interacts with the Earth’s\
    \ surface, materials on the surface absorb and reflect spe-\ncific wavelengths\
    \ of light. This interaction creates unique spectral signatures that are char-\n\
    acteristic of different surface features [20]. The sensors, available in handheld,\
    \ airborne, \nand spaceborne modes, contain detectors that record light intensity\
    \ across different wave-\nlengths (Figure 3). The recorded data are transmitted\
    \ to ground stations or processing \ncenters, where they are processed and transformed\
    \ into images or spectral data. \nIn the context of optical remote sensing image\
    \ (RSI) object detection, the primary ob-\njective is to ascertain whether a given\
    \ aerial or satellite image contains pertinent objects \nand precisely determine\
    \ their locations [21]. To ensure image quality, several processing \nsteps are\
    \ undertaken. Preprocessing involves noise removal and contrast enhancement to\
    \ \nimprove clarity and interpretability, followed by feature extraction, where\
    \ relevant char-\nacteristics are identified and extracted from the images for\
    \ further analysis. The ultimate \nobjective is to classify objects within the\
    \ images and assess the accuracy of the results. This \nclassification process\
    \ allows for effective interpretation and understanding of the image \ninformation.\
    \ An accuracy assessment is also performed to verify the reliability and preci-\n\
    sion of the results. \nIn optical remote sensing, three primary modes are commonly\
    \ used as follows: \nhandheld, airborne, and spaceborne. Handheld sensors capture\
    \ spectral signatures of \nground objects, facilitating ground-truthing and small-scale\
    \ data collection. Airborne sen-\nsors mounted on airplanes or drones offer higher\
    \ spatial resolution and efficient coverage \nof larger areas, making them useful\
    \ for tasks such as land cover/land-use mapping [22], \ncrop health assessment,\
    \ and identification of ecological hotspots. Spaceborne sensors on \nFigure 2.\
    \ (a) Passive remote sensing: the sensor receives information. (b) Active remote\
    \ sensing: the\nsensor emits and receives information.\nRemote Sens. 2023, 15,\
    \ 4112 \n5 of 37 \n \nsatellites provide extensive coverage and repeated observations\
    \ over time, enabling the \nmapping of large areas, monitoring changes in land\
    \ use, tracking migratory patterns, and \nobserving atmospheric conditions. The\
    \ wealth of data collected by spaceborne sensors \ncontribute significantly to\
    \ various applications, including environmental monitoring, ur-\nban planning,\
    \ disaster management [23], and climate studies. \n \nFigure 3. The basic mechanism\
    \ of optical remote sensing: sensors record information received as a \nfunction\
    \ of wavelength and atmospheric conditions. \nVegetation indices, like the Normalized\
    \ Difference Vegetation Index (NDVI) [24], are \nderived from optical remote sensing\
    \ data by analyzing reflectance and absorption [25]. \nThey serve as early detectors\
    \ of nutrient deficiencies by studying light reflection changes \n[26]. For instance,\
    \ higher near-infrared reflection often means nitrogen shortage, whereas \nless\
    \ red light reflection could indicate phosphorus deficiency [27,28]. Monitoring\
    \ these \nindices over time offers predictive insights into vegetation growth\
    \ dynamics, which ex-\ntends to crop trends. AI analysis of historical data uncovers\
    \ vegetation responses to chang-\ning conditions and can inform fertilizer and\
    \ pesticide use by farmers, resulting in resource \nFigure 3. The basic mechanism\
    \ of optical remote sensing: sensors record information received as a\nfunction\
    \ of wavelength and atmospheric conditions.\nIn the context of optical remote\
    \ sensing image (RSI) object detection, the primary\nobjective is to ascertain\
    \ whether a given aerial or satellite image contains pertinent objects\nand precisely\
    \ determine their locations [21]. To ensure image quality, several processing\n\
    Remote Sens. 2023, 15, 4112\n5 of 34\nsteps are undertaken. Preprocessing involves\
    \ noise removal and contrast enhancement\nto improve clarity and interpretability,\
    \ followed by feature extraction, where relevant\ncharacteristics are identiﬁed\
    \ and extracted from the images for further analysis. The\nultimate objective\
    \ is to classify objects within the images and assess the accuracy of the\nresults.\
    \ This classiﬁcation process allows for effective interpretation and understanding\
    \ of\nthe image information. An accuracy assessment is also performed to verify\
    \ the reliability\nand precision of the results.\nIn optical remote sensing, three\
    \ primary modes are commonly used as follows: hand-\nheld, airborne, and spaceborne.\
    \ Handheld sensors capture spectral signatures of ground\nobjects, facilitating\
    \ ground-truthing and small-scale data collection. Airborne sensors\nmounted on\
    \ airplanes or drones offer higher spatial resolution and efﬁcient coverage of\n\
    larger areas, making them useful for tasks such as land cover/land-use mapping\
    \ [22],\ncrop health assessment, and identiﬁcation of ecological hotspots. Spaceborne\
    \ sensors on\nsatellites provide extensive coverage and repeated observations\
    \ over time, enabling the\nmapping of large areas, monitoring changes in land\
    \ use, tracking migratory patterns, and\nobserving atmospheric conditions. The\
    \ wealth of data collected by spaceborne sensors\ncontribute signiﬁcantly to various\
    \ applications, including environmental monitoring, urban\nplanning, disaster\
    \ management [23], and climate studies.\nVegetation indices, like the Normalized\
    \ Difference Vegetation Index (NDVI) [24], are\nderived from optical remote sensing\
    \ data by analyzing reﬂectance and absorption [25]. They\nserve as early detectors\
    \ of nutrient deﬁciencies by studying light reﬂection changes [26].\nFor instance,\
    \ higher near-infrared reﬂection often means nitrogen shortage, whereas less\n\
    red light reﬂection could indicate phosphorus deﬁciency [27,28]. Monitoring these\
    \ indices\nover time offers predictive insights into vegetation growth dynamics,\
    \ which extends to crop\ntrends. AI analysis of historical data uncovers vegetation\
    \ responses to changing conditions\nand can inform fertilizer and pesticide use\
    \ by farmers, resulting in resource savings, higher\nyields, and reduced chemical\
    \ reliance. AI-based methods also proved valuable for deriving\nsnow-covered areas\
    \ from sensors with radiometric information limited to visible and near-\ninfrared\
    \ bands [29,30], allowing for applications in environmental monitoring at m-scale\n\
    spatial resolution.\n2.1.2. Radar Remote Sensing\nThis technique operates in the\
    \ microwave region of the electromagnetic spectrum\n(Figure 1), involving the\
    \ transmission and reception of microwave waves [31]. A radar\nantenna emits pulses\
    \ of microwave radiation toward the Earth or space, capturing the\nechoes reﬂected\
    \ by the targets and containing data regarding the targets’ characteristics,\n\
    including distance, direction, shape, size, roughness, and dielectric properties\
    \ (Figure 4) [32].\nBy analyzing the time and intensity of the echo signals, radar\
    \ remote sensing can generate\nimages or maps of the targets with varying resolutions\
    \ and perspectives. It is widely used\nin mapping land surfaces, monitoring weather\
    \ patterns, studying ocean currents, and\ndetecting objects such as buildings\
    \ and vehicles [33].\nSynthetic Aperture Radar (SAR) produces high-resolution\
    \ surface images and is par-\nticularly valuable for large-scale forest cover\
    \ mapping because it can penetrate clouds and\nfoliage, enabling accurate mapping\
    \ even in challenging weather or limited visibility condi-\ntions [34]. The dual-polarization\
    \ technology employed by SAR allows for differentiation\nbetween different forest\
    \ canopy types and the underlying vegetation. When the radar\nsignal encounters\
    \ the forest canopy, it scatters, with a portion of the signal returning to the\n\
    radar instrument. This returned signal carries crucial information about forest\
    \ structure and\nbiomass. By incorporating dual-polarization radar, the accuracy\
    \ and comprehensiveness of\nforest mapping are enhanced, providing detailed insights\
    \ into both the forest structure and\nunderlying vegetation. The ability of SAR\
    \ to effectively distinguish between various forest\ncanopy types and the vegetation\
    \ beneath them is a signiﬁcant advantage. This capability\nenables SAR to generate\
    \ high-resolution data that can detect changes in forest cover with\nexceptional\
    \ precision [35].\nRemote Sens. 2023, 15, 4112\n6 of 34\nRemote Sens. 2023, 15,\
    \ 4112 \n6 of 37 \n \n \n \nFigure 4. Radar sensor: converts microwave signals\
    \ into electrical signals. \nSynthetic Aperture Radar (SAR) produces high-resolution\
    \ surface images and is par-\nticularly valuable for large-scale forest cover\
    \ mapping because it can penetrate clouds and \nfoliage, enabling accurate mapping\
    \ even in challenging weather or limited visibility con-\nditions [34]. The dual-polarization\
    \ technology employed by SAR allows for differentiation \nbetween different forest\
    \ canopy types and the underlying vegetation. When the radar sig-\nnal encounters\
    \ the forest canopy, it scatters, with a portion of the signal returning to the\
    \ \nradar instrument. This returned signal carries crucial information about forest\
    \ structure \nand biomass. By incorporating dual-polarization radar, the accuracy\
    \ and comprehensive-\nness of forest mapping are enhanced, providing detailed\
    \ insights into both the forest \nstructure and underlying vegetation. The ability\
    \ of SAR to effectively distinguish between \nvarious forest canopy types and\
    \ the vegetation beneath them is a significant advantage. \nThis capability enables\
    \ SAR to generate high-resolution data that can detect changes in \nforest cover\
    \ with exceptional precision [35]. \n2.1.3. LiDAR \nLiDAR operates by emitting\
    \ pulsed lasers that reach a target, and the time it takes for \nthe reflected\
    \ light to return to the sensor is precisely measured to calculate the distance\
    \ \nbetween the sensor and the object (Figure 5) [36]. For airborne surveys, the\
    \ distance trav-\neled is then converted to elevation, and multiple returns allow\
    \ for mapping forests and \ntree heights [37,38] Figure 5. LiDAR systems incorporate\
    \ GPS systems, which identify the \nlocations of the emitted light energy, and\
    \ an inertial measurement unit, IMU, which pro-\nvides the aircraft’s orientation\
    \ in the sky. \nFigure 4. Radar sensor: converts microwave signals into electrical\
    \ signals.\n2.1.3. LiDAR\nLiDAR operates by emitting pulsed lasers that reach\
    \ a target, and the time it takes for\nthe reﬂected light to return to the sensor\
    \ is precisely measured to calculate the distance\nbetween the sensor and the\
    \ object (Figure 5) [36]. For airborne surveys, the distance\ntraveled is then\
    \ converted to elevation, and multiple returns allow for mapping forests\nand\
    \ tree heights [37,38] Figure 5. LiDAR systems incorporate GPS systems, which\
    \ identify\nthe locations of the emitted light energy, and an inertial measurement\
    \ unit, IMU, which\nprovides the aircraft’s orientation in the sky.\nRemote Sens.\
    \ 2023, 15, 4112 \n7 of 37 \n \n \nFigure 5. LiDAR sensor: detects objects at\
    \ a distance D based on the speed of light, c, and the time \nbetween the light\
    \ being emitted and being detected. Multiple returns assist in mapping objects\
    \ with \ncomplex shapes. The yellow wave indicates multiple reflected returned\
    \ rays, while the red-to-black \ngradient ray and the adjacent black wave represent\
    \ the laser pulse. \nLiDAR systems record the reflected rays of light in the form\
    \ of a waveform or distri-\nbution in two different ways. In a Discrete Return\
    \ LiDAR System [39], the waveform curve \nis analyzed to identify individual peaks,\
    \ with individual points on the ground recorded \nat each peak location, whereas\
    \ a full waveform LiDAR System records the complete dis-\ntribution of the returned\
    \ light energy, and although data processing is more complex, it \nhas the potential\
    \ to capture a larger amount of information compared to discrete return \nLiDAR\
    \ systems. Whether collected as discrete points or entire waveforms, LiDAR data\
    \ \nare often available as a LiDAR point cloud, which represents a three-dimensional\
    \ collec-\ntion of points in space\nFigure 5. LiDAR sensor: detects objects at\
    \ a distance D based on the speed of light, c, and the time\nbetween the light\
    \ being emitted and being detected. Multiple returns assist in mapping objects\
    \ with\ncomplex shapes. The yellow wave indicates multiple reﬂected returned rays,\
    \ while the red-to-black\ngradient ray and the adjacent black wave represent the\
    \ laser pulse.\nLiDAR systems record the reﬂected rays of light in the form of\
    \ a waveform or distribu-\ntion in two different ways. In a Discrete Return LiDAR\
    \ System [39], the waveform curve\nis analyzed to identify individual peaks, with\
    \ individual points on the ground recorded\nat each peak location, whereas a full\
    \ waveform LiDAR System records the complete dis-\nRemote Sens. 2023, 15, 4112\n\
    7 of 34\ntribution of the returned light energy, and although data processing\
    \ is more complex, it\nhas the potential to capture a larger amount of information\
    \ compared to discrete return\nLiDAR systems. Whether collected as discrete points\
    \ or entire waveforms, LiDAR data are\noften available as a LiDAR point cloud,\
    \ which represents a three-dimensional collection of\npoints in space.\n2.1.4.\
    \ Thermal Remote Sensing\nThis technique is a passive remote sensing method that\
    \ measures the radiant ﬂux\nemitted by ground objects within speciﬁc wavelength\
    \ ranges, typically 3–5 µm and\n8–14 µm [40,41]. Thermal cameras, radiometers,\
    \ and other sensors are utilized to cap-\nture energy within the thermal infrared\
    \ range. The thermal detector can be either cryogenic\nor uncooled and converts\
    \ the data into electrical signals, which are then processed to\ngenerate thermal\
    \ images or temperature data of the target object or surface. By analyz-\ning\
    \ these thermal images and data, valuable information about the object’s emissivity,\n\
    reﬂectivity, and temperature can be obtained. Factors that can impact the accuracy\
    \ of TIR\nremote sensing data include atmospheric conditions, changes in solar\
    \ illumination, and\nvariations in target emissivity and radiance. To address\
    \ these uncertainties, TIR data often\nundergo calibration or correction processes\
    \ to ensure precise temperature measurement\nand analysis. Thermal remote sensing\
    \ can be employed in environmental monitoring and\nwildﬁre detection [42,43].\
    \ As an example, Figure 6 shows a temperature map derived from\nECOSTRESS data\
    \ collected during the historic Paciﬁc Northwest heatwave in 2021.\nRemote Sens.\
    \ 2023, 15, 4112 \n8 of 37 \n \n \nFigure 6. Land surface temperature sensed by\
    \ ECOSTRESS during the 2021 Pacific Northwest heat-\nwave. Image Courtesy: NASA,\
    \ https://earthobservatory.nasa.gov/images/148506/exceptional-heat-\nhits-pacific-northwest,\
    \ accessed on 3 August 2023. \n2.1.5. Multispectral and Hyperspectral Imaging\
    \ \nMulti-spectral cameras have the ability to detect a broader range of wavelengths\
    \ be-\nyond the visible spectrum, including infrared and ultraviolet (Figure 1).\
    \ It relies on spec-\ntral signature rather than spatial shape to detect and discriminate\
    \ among different mate-\nrials in a scene [44]. The camera captures a sequence\
    \ of images using different filters that \ntarget specific wavelengths or bands\
    \ of light in parallel, forming a comprehensive dataset \ncontaining information\
    \ from various spectral channels. The images then undergo a series \nof processing\
    \ steps, including normalization, calibration, alignment, registration, noise\
    \ re-\nduction, and enhancement. Hyper-spectral imaging (HSI) [45] is a more advanced\
    \ tech-\nnique that collects information across the electromagnetic spectrum with\
    \ very high spec-\ntral resolution from ground objects using hundreds of narrow\
    \ bands [46]. HSI data contain \nnumerous narrow spectral bands, creating a dataset\
    \ known as a hyper-spectral image \ncube containing spatial dimensions (x, y coordinates)\
    \ and spectral bands (wavelengths) \nand enabling detailed analysis of reflected\
    \ or emitted light at specific spectral intervals. \nHowever, the high-dimensional\
    \ and noisy nature of the data poses analysis challenges,\nFigure 6. Land surface\
    \ temperature sensed by ECOSTRESS during the 2021 Paciﬁc Northwest\nheatwave.\
    \ Image Courtesy: NASA, https://earthobservatory.nasa.gov/images/148506/exceptional-\n\
    heat-hits-paciﬁc-northwest, accessed on 3 August 2023.\n2.1.5. Multispectral and\
    \ Hyperspectral Imaging\nMulti-spectral cameras have the ability to detect a broader\
    \ range of wavelengths\nbeyond the visible spectrum, including infrared and ultraviolet\
    \ (Figure 1). It relies on\nspectral signature rather than spatial shape to detect\
    \ and discriminate among different\nmaterials in a scene [44]. The camera captures\
    \ a sequence of images using different ﬁlters\nthat target speciﬁc wavelengths\
    \ or bands of light in parallel, forming a comprehensive\ndataset containing information\
    \ from various spectral channels. The images then undergo\na series of processing\
    \ steps, including normalization, calibration, alignment, registration,\nnoise\
    \ reduction, and enhancement. Hyper-spectral imaging (HSI) [45] is a more advanced\n\
    technique that collects information across the electromagnetic spectrum with very\
    \ high\nRemote Sens. 2023, 15, 4112\n8 of 34\nspectral resolution from ground\
    \ objects using hundreds of narrow bands [46]. HSI data\ncontain numerous narrow\
    \ spectral bands, creating a dataset known as a hyper-spectral im-\nage cube containing\
    \ spatial dimensions (x, y coordinates) and spectral bands (wavelengths)\nand\
    \ enabling detailed analysis of reﬂected or emitted light at speciﬁc spectral\
    \ intervals.\nHowever, the high-dimensional and noisy nature of the data poses\
    \ analysis challenges,\nrequiring the application of algorithms that facilitate\
    \ denoising, classiﬁcation, detection,\nand other tasks. It should be noted that\
    \ there is no absolute threshold on the number of\nbands that distinguish between\
    \ multispectral and hyperspectral remote sensing [47].\nAbove all, data from multiple\
    \ sensors are combined to gain a deeper understanding of\nthe system investigated\
    \ [48,49]. Table 1 provides an overview of the pros and cons of each\nremote sensing\
    \ technique, with its advantages, limitations, and applications.\nTable 1. Summary\
    \ of various types of remote sensing techniques.\nTechnique\nAdvantages\nLimitations\n\
    Sample Applications\nOptical remote\nsensing\n- captures reﬂected solar radiation\
    \ and\nemitted thermal radiation for analysis\nwithin the visible and near-infrared\n\
    spectrum bands\n- provides various sensor types for the\ncollection of handheld,\
    \ airborne, and\nspace-borne data\n- offers extensive coverage and repeated\n\
    observations over time with spaceborne\nsensors\n- atmospheric conditions can\n\
    impact data accuracy,\nlimitations due to sun angles\nand shadows\n- night-time\
    \ data are not\navailable, and single snapshot\nacquisition\n- limited visibility\
    \ due to clouds\nwhich can hinder data\ncollection, inability to penetrate\nclouds\n\
    - cost and availability of\nhigh-resolution data\n- land-use mapping, crop\nhealth\
    \ assessment\n- Monitoring vegetation\n- Monitoring climate change\nRadar remote\n\
    sensing\n- operates in the microwave region,\nproviding valuable data on distance,\n\
    direction, shape, size, roughness, and\ndielectric properties of targets\n- enables\
    \ accurate mapping even in\nchallenging weather or limited visibility\nconditions\n\
    - utilizes dual-polarization technology for\nenhanced forest cover mapping\n-\
    \ data processing can be\ncomplex, especially for full\nwaveform LiDAR systems\n\
    - lack of spectral information\nand limited penetration through\nsome materials\n\
    - high sensitivity to surface\nroughness\n- mapping land surfaces and\nmonitoring\
    \ weather patterns\n- studying ocean currents\n- detecting buildings,\nvehicles,\
    \ and changes in\nforest cover\nLiDAR\n- provides precise distance and elevation\n\
    measurements of ground objects\n- high-resolution 3D data\n- penetration of vegetation\n\
    - day and night operation\n- multiple returns of one single laser pulse\nand reduced\
    \ atmospheric interference\n- data processing complexity,\nespecially for full\
    \ waveform\nLiDAR systems\n- accuracy dependent on\nelevation and angle\n- high\
    \ cost and availability\n- limited penetration through\nthick dense vegetation\n\
    - create accurate and\ndetailed 3D maps of trees,\nbuildings, pipelines, etc\n\
    Thermal remote\nsensing\n- measures radiant ﬂux emitted by\nground objects within\
    \ speciﬁc\nwavelength ranges\n- provides information on the emissivity,\nreﬂectivity,\
    \ and temperature of target\nobjects\n- atmospheric conditions,\nchanges in solar\
    \ illumination,\nand target variations can impact\ndata accuracy\n- agriculture\
    \ (e.g., ﬁre\ndetection, urban heat\nislands) and environmental\nmonitoring\n\
    Multispectral and\nhyperspectral\nimaging\n- captures a broad range of wavelengths,\n\
    including infrared and ultraviolet, for\ncomprehensive data collection\n- HSI\
    \ provides valuable insights into\nmaterial composition, structure, and\ncondition\n\
    - high-dimensional and noisy\ndata in HSI pose analysis\nchallenges\n- limited\
    \ spectral resolution in\nmultispectral imaging\n- recognition of vegetation\n\
    patterns such as greenness,\nvitality, and biomass\n- studying material\nproperties\
    \ (e.g., physical\nand chemical alterations\nRemote Sens. 2023, 15, 4112\n9 of\
    \ 34\n2.2. Key AI Techniques in Remote Sensing\n2.2.1. Conventional Machine Learning\
    \ in Remote Sensing\nThe remote sensing community has extensively utilized conventional\
    \ machine learn-\ning methods for various tasks such as classiﬁcation, object\
    \ detection, and geophysical\nparameter estimation. These methods have proven\
    \ effective in handling multi-temporal\nand multi-sensor remote sensing data,\
    \ providing valuable information for environmental\nmonitoring [14,50–53].\nEnsemble\
    \ decision-tree-derived classiﬁers are well-known algorithms for classifying\n\
    tasks with remote sensing data [54–56]. These algorithms include bagging [57],\
    \ boost-\ning [58,59], and random forest (RF) techniques [60]. The RF approach\
    \ was used in a variety\nof applications ranging from land cover classiﬁcation\
    \ [61–66] to data fusion [7,67] classiﬁca-\ntion tasks using hyperspectral data\
    \ [68,69]. Random forest involves bagging, creating an\nensemble of decision trees\
    \ by randomly selecting samples and features from the training\ndata. By combining\
    \ multiple decision trees, RF classiﬁers can provide robust predictions\nwhile\
    \ offering variable importance (VI) measurements and are often used in remote\
    \ sensing\napplications [70]. This feature selection method allows RF to effectively\
    \ rank and eliminate\nirrelevant features, reducing dimensionality and identifying\
    \ the most signiﬁcant remote\nsensing and geographic data that offer new insights\
    \ into the Earth system [49,71]. The\nselective feature choice in RF is particularly\
    \ beneﬁcial as it prevents overﬁtting, enhances\ngeneralization, and reduces computational\
    \ load and redundancy. Despite these advantages,\naccurately selecting discriminatory\
    \ variables from high-dimensional remote sensing data\nremains challenging [72],\
    \ and the selection of training data may inﬂuence the results [73].\nSimilar to\
    \ RF, boosting approaches such as the Extreme Gradient Boosting (XGBoost)\nmethod\
    \ also utilize decision trees as base learners but take the process further by\
    \ combin-\ning the strengths of individual trees in a boosting technique [74].\
    \ This iterative process\nsequentially creates decision trees, with each subsequent\
    \ tree focused on correcting the\nerrors of its predecessors. This approach helps\
    \ XGBoost achieve low bias and variance,\nultimately improving classiﬁcation.\
    \ An advantage of XGBoost in remote sensing data\nclassiﬁcation is its ability\
    \ to handle cases where different classes (e.g., algal bloom species)\nexhibit\
    \ similar spectral signatures but may have varying concentrations or distributions\
    \ [75].\nTo ensure optimal accuracy and prevent overﬁtting, XGBoost employs hyper-parameter\n\
    tuning techniques.\nAnother conventional technique is Support Vector Machines\
    \ (SVMs) that categorize\ndata by discovering high-dimensional hyperplanes that\
    \ effectively separate distinct classes,\nleading to improved data generalization\
    \ and better image classiﬁcation [76]. These ma-\nchines handle challenges like\
    \ non-linearity and dimensionality by utilizing the kernel trick,\nwhich involves\
    \ mapping input data into higher-dimensional spaces and relies on a subset of\n\
    training data, referred to as support vectors, to establish decision boundaries.\
    \ By leveraging\nkernel functions, SVMs transform input data, enabling the identiﬁcation\
    \ of hyperplanes in\nexpanded dimensions and effectively accommodating scenarios\
    \ in which original feature\nseparability is limited [77]. Notably, SVMs incorporate\
    \ a ﬂexible soft margin approach,\nallowing for a degree of misclassiﬁcation tolerance\
    \ [78].\n2.2.2. Deep Learning in Remote Sensing\nDeep learning, a subﬁeld of machine\
    \ learning, has emerged as a valuable tool in remote\nsensing, offering solutions\
    \ to unprecedented challenges and creating new opportunities in\nremote sensing\
    \ applications [53,79–81]. Deep learning utilizes hierarchical artiﬁcial neural\n\
    networks to identify patterns within data and extract valuable features from large\
    \ and\ncomplex datasets [82]. During training, the network adjusts weights and\
    \ biases through\na process known as backpropagation, enhancing its ability to\
    \ recognize patterns and\nrelationships as it processes more data. Deep learning\
    \ networks gradually transform the\ndata into representations suitable for speciﬁc\
    \ tasks such as image preprocessing, object\nrecognition, and pixel-based classiﬁcation\
    \ [83]. This section lists and brieﬂy introduces\nsome common deep learning algorithms.\n\
    Remote Sens. 2023, 15, 4112\n10 of 34\n1.\nDeep Convolutional Neural Networks\
    \ (DCNNs)\nDeep Convolutional Neural Networks, DCNNs, utilize a multi-layer architecture\n\
    effective for image recognition and classiﬁcation tasks [84,85]. The architecture\
    \ of DCNNs\nconsists of multiple layers, in which the initial layers, known as\
    \ convolutional layers, play\na fundamental role in detecting low-level features\
    \ within the input image (Figure 7). They\nachieve this by applying convolutional\
    \ ﬁlters, also called kernels, to the image. These ﬁlters\neffectively act as\
    \ feature detectors, focusing on edges, corners, and other basic patterns\nthat\
    \ characterize the image, helping identify simple shapes and textures in the scene.\n\
    A non-linear activation function, Rectiﬁed Linear Unit, ReLU [86], is applied\
    \ after each\nconvolutional operation to introduce non-linearity and enable the\
    \ learning of more intricate\npatterns. Following the convolutional layers, pooling\
    \ layers are utilized to reduce the\nspatial dimensions of the data while retaining\
    \ the essential information. Pooling achieves\nthis downsampling by aggregating\
    \ information from neighboring pixels and introducing\nthe ability to detect certain\
    \ features regardless of their spatial position within the image.\nThe convolution\
    \ and pooling process is typically repeated multiple times to allow the\nnetwork\
    \ to learn higher-level features and representations progressively. As the network\n\
    goes deeper into its layers, it can capture increasingly abstract and sophisticated\
    \ features\nessential for recognizing complex objects or patterns. The last fully\
    \ connected layer of\nthe DCNN generates probabilities associated with the different\
    \ classes of objects, with the\nsoftmax activation function ensuring that the\
    \ class probabilities sum up to one. This ﬁnal\nclassiﬁcation step enables the\
    \ network to recognize and categorize objects present in the\nremote sensing image\
    \ accurately [87].\n \nthrough a process known as backpropagation, enhancing its\
    \ ability to recognize patterns \nand relationships as it processes more data.\
    \ Deep learning networks gradually transform \nthe data into representations suitable\
    \ for specific tasks such as image preprocessing, ob-\nject recognition, and pixel-based\
    \ classification (Zhang et al., 2016). This section lists and \nbriefly introduces\
    \ some common deep learning algorithms. \n1. \nDeep Convolutional Neural Networks\
    \ (DCNNs) \nDeep Convolutional Neural Networks, DCNNs, utilize a multi-layer architecture\
    \ \neffective for image recognition and classification tasks (Traore et al., 2018;\
    \ Chen et al., \n2021a). The architecture of DCNNs consists of multiple layers,\
    \ in which the initial layers, \nknown as convolutional layers, play a fundamental\
    \ role in detecting low-level features \nwithin the input image (Figure 7). They\
    \ achieve this by applying convolutional filters, \nalso called kernels, to the\
    \ image. These filters effectively act as feature detectors, focus-\ning on edges,\
    \ corners, and other basic patterns that characterize the image, helping iden-\n\
    tify simple shapes and textures in the scene. A non-linear activation function,\
    \ Rectified \nLinear Unit, ReLU (Agarap et al., 2018), is applied after each convolutional\
    \ operation to \nintroduce non-linearity and enable the learning of more intricate\
    \ patterns. Following the \nconvolutional layers, pooling layers are utilized\
    \ to reduce the spatial dimensions of the \ndata while retaining the essential\
    \ information. Pooling achieves this downsampling by \naggregating information\
    \ from neighboring pixels and introducing the ability to detect \ncertain features\
    \ regardless of their spatial position within the image. The convolution \nand\
    \ pooling process is typically repeated multiple times to allow the network to\
    \ learn \nhigher-level features and representations progressively. As the network\
    \ goes deeper into \nits layers, it can capture increasingly abstract and sophisticated\
    \ features essential for \nrecognizing complex objects or patterns. The last fully\
    \ connected layer of the DCNN \ngenerates probabilities associated with the different\
    \ classes of objects, with the softmax \nactivation function ensuring that the\
    \ class probabilities sum up to one. This final classi-\nfication step enables\
    \ the network to recognize and categorize objects present in the re-\nmote sensing\
    \ image accurately (Aloysius et al., 2017). \n \nFigure 7. Illustration of a basic\
    \ DCCN architecture. \nThe convolution is calculated using the following equation:\
    \ \n[ , ]\n[\n,\n]\n[ , ]\nm\nn\ny i j\nx i\nm j\nn\nw m n\nb\n=\n+\n+\n⋅\n+\n\
    \n \nwhere \U0001D466[\U0001D456,\U0001D457] is the output feature map at position\
    \ (\U0001D456, \U0001D457), \U0001D465 is the input image, w is the fil-\nter,\
    \ b is the bias term, and m and n are the indices of the filter. \nAn activation\
    \ function can be defined as \nReLU(x) = max (0,x) \nsetting all negative values\
    \ to zero and leaving positive values unchanged. \nFigure 7. Illustration of a\
    \ basic DCCN architecture.\nThe convolution is calculated using the following\
    \ equation:\ny[i, j] = ∑\nm ∑\nn\nx[i + m, j + n] · w[m, n] + b\nwhere y[i,j]\
    \ is the output feature map at position (i, j), x is the input image, w is the\
    \ ﬁlter, b\nis the bias term, and m and n are the indices of the ﬁlter.\nAn activation\
    \ function can be deﬁned as\nReLU(x) = max (0,x)\nsetting all negative values\
    \ to zero and leaving positive values unchanged.\nIt is a simple activation function\
    \ that is computationally efﬁcient to compute and\nhelps alleviate the vanishing\
    \ gradient problem, which can occur during backpropagation in\nDCNN. It is worth\
    \ noting that ReLU is not without its limitations. One issue is the “dying\nReLU”\
    \ problem, where neurons can become “stuck” during training and become inactive,\n\
    resulting in zero activations that prevent learning. To address this, variants\
    \ like Leaky\nReLU [88] and Parametric ReLU [89] have been introduced. While Figure\
    \ 7 illustrates a\nbasic DCNN architecture as an example, recent years have seen\
    \ the evolution of more\nspecialized architectures for speciﬁc applications. Notably,\
    \ U-Net [90] and SegNet [91]\nRemote Sens. 2023, 15, 4112\n11 of 34\nare tailored\
    \ for semantic segmentation tasks in images. U-Net features a contracting\npath\
    \ with repeated 3 × 3 convolutions, ReLU activations, and 2 × 2 max pooling for\n\
    feature extraction, followed by an expansive path for upsampling and generating\
    \ detailed\nsegmentation masks. On a similar note, SegNet focuses on pixel-wise\
    \ image labeling. It\ncomprises an encoder network akin to VGG16’s convolutional\
    \ layers, a decoder network\nfor low-to-full resolution feature mapping, and a\
    \ pixel-wise classiﬁcation layer. Further,\nalong the timeline, AlexNet [92] ushered\
    \ in a new era for DCNNs with its multi-layered\narchitecture, employing convolution,\
    \ max pooling, and Local Response Normalization\n(LRN) to process image features.\
    \ VGG introduces depth with its 3 × 3 convolutional\nkernel, leading to VGG16\
    \ and VGG19 models known for their accuracy. The Inception\nnetwork, designed\
    \ by Google, utilizes diverse kernel sizes for capturing features at varying\n\
    scales, whereas DeepLab [93] harnesses DCNNs, atrous convolution, and CRFs for\
    \ precise\nsemantic segmentation, achieving high accuracy and efﬁciency.\n2.\n\
    Deep Residual Networks (ResNets)\nIn remote sensing, the need for deep neural\
    \ networks arises due to the complexity\nof high-dimensional and noisy data caused\
    \ by similar spectral characteristics of objects.\nHowever, neural networks are\
    \ trained using a back-propagation process that relies on\ngradient descent, which\
    \ decreases the loss function and ﬁnds the weights that minimize it.\nIf there\
    \ are too many layers, repeated multiplications will eventually reduce the gradient\n\
    until it “disappears”, and performance will plateau or deteriorate with each additional\n\
    layer [94]. To handle this issue, ResNets were introduced as a solution to this\
    \ “degradation\nproblem” in deep learning models [95,96].\nResNets introduce residual\
    \ blocks or “skip connections” or “shortcut connections”.\nThese skip connections\
    \ allow for the stacking of multiple identity mappings, which are\nessentially\
    \ convolutional layers that initially do nothing. By bypassing and reusing the\n\
    activations of the previous layer, the skip connections introduce a shortcut for\
    \ the gradients\nto ﬂow more directly during backpropagation. This helps to speed\
    \ up the initial training\nphase by compressing the network into fewer layers.\n\
    The core difference of residual learning is the residual block and skip connections\n\
    which are deﬁned as\ny = F(x) + x\nwhere F is the residual mapping (sequence of\
    \ convolutional layers), x is the input to\nthe block, and y is the output. Residual\
    \ blocks allow us to train much deeper neural\nnetworks bypassing one or more\
    \ layers in between. ‘Shortcut projection’, which is a\n1 × 1 convolutional layer,\
    \ denoted as P(x), is incorporated within the skip connection,\nallowing for dimension\
    \ adjustment and alignment of the feature maps. Shortcut projection\nis represented\
    \ as\ny = F(x) + P(x)\nwhere P represents the 1 × 1 convolutional layer used for\
    \ dimension adjustment. By\nensuring that the information passed between layers\
    \ is well-aligned and optimized, shortcut\nprojection contributes to faster training\
    \ convergence and more effective model learning.\nThe initial training enables\
    \ the model to establish a baseline data representation. Once this\ninitial training\
    \ is complete, all layers are expanded, and the remaining parts of the network,\n\
    known as the residual parts, are allowed to explore more of the feature space\
    \ of the input\nimage. Through these techniques, ResNets address the vanishing\
    \ gradient problem and\nfacilitate the training of much deeper models, which can\
    \ effectively capture and represent\nthe complex and subtle patterns present in\
    \ remote sensing imagery.\n3.\nYou Only Look Once (YOLO)\nAlgorithms for real-time\
    \ object detection and segmentation in remote sensing images\nrepresent signiﬁcant\
    \ advancement with applications in the identiﬁcation and classiﬁcation\nof multiple\
    \ objects within large datasets of images or video frames. The algorithm named\n\
    YOLO (You Only Look Once) has gained popularity for its ability to process the\
    \ entire\nRemote Sens. 2023, 15, 4112\n12 of 34\nimage simultaneously using a\
    \ Single Shot Detector and a CNN [97], initially leveraging the\nDarknet framework\
    \ [98]. Within YOLO, bounding boxes indicating the location, class, and\nconﬁdence\
    \ score of each detected object within the image are generated [99] (Figure 8).\
    \ The\nconﬁdence score produced by YOLO reﬂects both the likelihood of an object\
    \ being present\nin the bounding box and the accuracy of the box itself and is\
    \ used in the ﬁnal detection\nprocess. Overlapping bounding boxes can still occur.\
    \ To reﬁne the results and ensure only\nthe most accurate detections are retained,\
    \ YOLO incorporated Non-Maximum Suppression\n(NMS), a technique that eliminates\
    \ redundant bounding boxes by keeping only the one\nwith the highest conﬁdence\
    \ score. YOLOv2 [100] improves the speed and the type of object\ndetected, and\
    \ YOLOv3 enables the prediction of objects of different sizes [101–103].\nRemote\
    \ Sens. 2023, 15, 4112 \n13 of 37 \n \n \nclass, and confidence score of each\
    \ detected object within the image are generated [99] \n(Figure 8). The confidence\
    \ score produced by YOLO reflects both the likelihood of an ob-\nject being present\
    \ in the bounding box and the accuracy of the box itself and is used in the \n\
    final detection process. Overlapping bounding boxes can still occur. To refine\
    \ the results \nand ensure only the most accurate detections are retained, YOLO\
    \ incorporated Non-Max-\nimum Suppression (NMS), a technique that eliminates redundant\
    \ bounding boxes by \nkeeping only the one with the highest confidence score.\
    \ YOLOv2 [100] improves the speed \nand the type of object detected, and YOLOv3\
    \ enables the prediction of objects of different \nsizes [101–103]. \n \nFigure\
    \ 8. YOLO workflow: the output shows identified objects from the original image.\
    \ Darknet has \nbeen replaced in later versions of YOLO by other frameworks. \n\
    YOLO has further evolved through multiple versions, currently eight, with different\
    \ \nupdates, including changes in backbone architectures, the addition and then\
    \ removal of \nanchors, and the use of PyTorch and PaddlePaddle frameworks, with\
    \ the overall goal of \nbalancing speed and accuracy for real-time object detection\
    \ [104,105] \n4. \nFaster Region-Based CNN (R-CNN) \nFaster R-CNN is a two-step\
    \ approach for object detection in remote sensing [106] \nbased on two key modules:\
    \ the Region Proposal Network (RPN) and the Fast R-CNN \ndetector. The Fast R-CNN\
    \ module is an upgrade of the previous R-CNN approach allow-\ning simultaneous\
    \ processing of the entire image and region proposals in a single forward \npropagation\
    \ pass and also replacing the slower SVM-based classification with a softmax \n\
    layer, increasing the processing speed while also improving detection accuracy\
    \ [107]. The \nRPN uses predefined bounding boxes of various scales and aspect\
    \ ratios to determine ar-\neas of interest for the detector. The RPN operates\
    \ by sliding a small network over the \nconvolutional feature map, producing object\
    \ proposals with corresponding objectness \nscores that undergo further processing\
    \ through fully connected layers for box regression \nand box classification.\
    \ This allows the model to refine the positions of the proposed \nbounding boxes\
    \ and classify them accurately. \n5. \nSelf-Attention Methods \nIn remote sensing,\
    \ approaches such as Recurrent Neural Networks (RNNs) face chal-\nlenges related\
    \ to capturing complex contextual dependencies when analyzing longer se-\nquences\
    \ of images. RNNs are well-suited for sequential data analysis, yet they encounter\
    \ \ndifficulties in effectively capturing the nuanced relationships between distant\
    \ elements \nwithin extended sequences. This limitation can lead to a loss of\
    \ important contextual in-\nformation and hinder their performance on tasks involving\
    \ long-range dependencies. To \novercome this limitation, attention mechanisms\
    \ have been designed to allow access to all \nelements in a sequence at each time\
    \ step, facilitating a comprehensive understanding of \ndependencies and improving\
    \ the handling of longer sequences. \nThe transformer architecture [108], originally\
    \ developed for natural language pro-\ncessing, has played a key role in advancing\
    \ attention mechanisms by introducing self-\nattention as a standalone mechanism.\
    \ The model involves transforming feature maps into \nFigure 8. YOLO workﬂow:\
    \ the output shows identiﬁed objects from the original image. Darknet has\nbeen\
    \ replaced in later versions of YOLO by other frameworks.\nYOLO has further evolved\
    \ through multiple versions, currently eight, with different\nupdates, including\
    \ changes in backbone architectures, the addition and then removal of\nanchors,\
    \ and the use of PyTorch and PaddlePaddle frameworks, with the overall goal of\n\
    balancing speed and accuracy for real-time object detection [104,105]\n4.\nFaster\
    \ Region-Based CNN (R-CNN)\nFaster R-CNN is a two-step approach for object detection\
    \ in remote sensing [106]\nbased on two key modules: the Region Proposal Network\
    \ (RPN) and the Fast R-CNN\ndetector. The Fast R-CNN module is an upgrade of the\
    \ previous R-CNN approach allowing\nsimultaneous processing of the entire image\
    \ and region proposals in a single forward\npropagation pass and also replacing\
    \ the slower SVM-based classiﬁcation with a softmax\nlayer, increasing the processing\
    \ speed while also improving detection accuracy [107]. The\nRPN uses predeﬁned\
    \ bounding boxes of various scales and aspect ratios to determine\nareas of interest\
    \ for the detector. The RPN operates by sliding a small network over the\nconvolutional\
    \ feature map, producing object proposals with corresponding objectness\nscores\
    \ that undergo further processing through fully connected layers for box regression\n\
    and box classiﬁcation. This allows the model to reﬁne the positions of the proposed\n\
    bounding boxes and classify them accurately.\n5.\nSelf-Attention Methods\nIn remote\
    \ sensing, approaches such as Recurrent Neural Networks (RNNs) face\nchallenges\
    \ related to capturing complex contextual dependencies when analyzing longer\n\
    sequences of images. RNNs are well-suited for sequential data analysis, yet they\
    \ encounter\ndifﬁculties in effectively capturing the nuanced relationships between\
    \ distant elements\nwithin extended sequences. This limitation can lead to a loss\
    \ of important contextual\ninformation and hinder their performance on tasks involving\
    \ long-range dependencies. To\novercome this limitation, attention mechanisms\
    \ have been designed to allow access to all\nelements in a sequence at each time\
    \ step, facilitating a comprehensive understanding of\ndependencies and improving\
    \ the handling of longer sequences.\nThe transformer architecture [108], originally\
    \ developed for natural language process-\ning, has played a key role in advancing\
    \ attention mechanisms by introducing self-attention\nas a standalone mechanism.\
    \ The model involves transforming feature maps into sequences\nRemote Sens. 2023,\
    \ 15, 4112\n13 of 34\nof embeddings, which capture essential information from\
    \ the input data. This capability\nis particularly valuable in modeling spatial\
    \ and spectral dependencies in remote sensing\nimagery. By incorporating attention\
    \ mechanisms, transformers can effectively learn and\nleverage the contextual\
    \ and spatial relationships present in remote sensing data, making\nthem highly\
    \ suited for complex and high-dimensional data analysis [109].\nThe general formula\
    \ for attention is\nSelfAttention(X) = softmax(Q KT/dk)V\nwhere X is the input;\
    \ Q is the query matrix obtained by linearly transforming the input\nembeddings:\
    \ Q = XWQ; K is the key matrix obtained by linearly transforming the input\nembeddings:\
    \ K = XWK; V is the value matrix obtained by linearly transforming the input\n\
    embeddings: V = XWV; dK is the dimension of the key and query vectors; WQ, WV,\
    \ and\nWK are learnable weight matrices for linear transformations.\nBERT (Bidirectional\
    \ Encoder Representations from Transformers) is an example of a\ntransformer-based\
    \ model that has shown remarkable success in language representation\nlearning\
    \ tasks that captures bidirectional contextual information by considering both\
    \ the left\nand right context in all layers [110]. When applying BERT to remote\
    \ sensing data, a speciﬁc\napproach can be followed as described by [111] regarding\
    \ the hyperspectral imagery. The\nhyperspectral images (HSIs) are ﬂattened and\
    \ directly inputted into the BERT model for\nfeature extraction, allowing the\
    \ model to learn global dependencies among spectral bands.\nThe addition of a\
    \ multi-head self-attention (MHSA) mechanism accommodates diverse\npixel relationships\
    \ regardless of spatial distance, enabling the model to effectively capture\n\
    long-range dependencies and complex relationships within the hyperspectral data.\n\
    6.\nLong Short-Term Memory, LSTM\nLSTM, short for Long Short-Term Memory [112],\
    \ is a type of recurrent neural network\n(RNN) that is commonly used for sequence\
    \ modeling and time series analysis [113]. The\nLSTM design aims to address the\
    \ vanishing gradient problem in traditional RNNs, which\ncan make it challenging\
    \ to capture long-term dependencies in sequences [114]. LSTMs\nreceive an input\
    \ sequence, which could be a sequence of sensor readings, or any other\nsequential\
    \ data, with each element in the sequence representing a feature vector. At each\n\
    time step, the LSTM network activates a series of gates: input gate, forget gate,\
    \ and output\ngate, controlling the level of information allowed to enter, exit,\
    \ or be retained, with the\nuse of memory cell states and hidden states. The input\
    \ gate takes the current input and\nthe previous hidden state as inputs, and a\
    \ sigmoid activation function for these inputs\nproduces a value between 0 and\
    \ 1 for each element in the feature vector. A selection process\nis then applied,\
    \ with 1 being retention and 0 being elimination in the cell. A similar process\n\
    occurs in the forget gate that decides which elements of the memory cell should\
    \ be erased\nor forgotten. The memory cell is then updated based on the input\
    \ from the input and the\nforget gates, allowing the LSTM to retain important\
    \ information and discard irrelevant or\nredundant information. The output gate\
    \ takes the current input and the updated hidden\nstate from the previous time\
    \ step and, similarly, determines which elements of the cell\nshould be outputted.\
    \ The hidden state is updated based on the output from the output gate\nand the\
    \ updated memory cell, and the LSTM network can output a prediction based on\n\
    the updated hidden state. This prediction can be used for various tasks such as\
    \ sequence\nclassiﬁcation, sequence generation, or time series forecasting.\n\
    2.2.3. Other AI Methods in Remote Sensing\nThere is a growing interest in utilizing\
    \ generative adversarial networks, GANs [115],\nin remote sensing applications\
    \ [116,117]. GANs are neural networks excelling in handling\ncomplex, high-dimensional\
    \ data, even with limited or no annotated training data [118].\nGANs consist of\
    \ two networks, a generator and a discriminator, trained in compe-\ntition. The\
    \ generator produces fake images (forgeries) using random noise, which the\ndiscriminator\
    \ evaluates alongside real images (Figure 9). Both networks train simulta-\nRemote\
    \ Sens. 2023, 15, 4112\n14 of 34\nneously and compete against each other. The\
    \ generator learns from the discriminator’s\nfeedback, incorporating synthetic\
    \ and real images through backpropagation, leveraging the\ndiscriminator’s error\
    \ signal. This iterative cycle enhances the generator’s ability to produce\nhigher-quality,\
    \ more realistic images. The generator becomes proﬁcient at deceiving the\ndiscriminator\
    \ by reﬁning the forgeries through successive iterations and feeding them back\n\
    to the discriminator, completing the GAN training process [119].\nRemote Sens.\
    \ 2023, 15, 4112 \n15 of 37 \n \n \ndiscriminator evaluates alongside real images\
    \ (Figure 9). Both networks train simultane-\nously and compete against each other.\
    \ The generator learns from the discriminator’s feed-\nback, incorporating synthetic\
    \ and real images through backpropagation, leveraging the \ndiscriminator’s error\
    \ signal. This iterative cycle enhances the generator’s ability to pro-\nduce\
    \ higher-quality, more realistic images. The generator becomes proficient at deceiving\
    \ \nthe discriminator by refining the forgeries through successive iterations\
    \ and feeding them \nback to the discriminator, completing the GAN training process\
    \ [119]. \n \nFigure 9. Simplified GAN architecture. \nAdversarial training is\
    \ as follows: \n\U0001D45A\U0001D456\U0001D45B\U0001D43A\U0001D45A\U0001D44E\U0001D465\
    \U0001D437 \U0001D438\U0001D465~ \U0001D443\U0001D451\U0001D44E\U0001D461\U0001D44E\
    [\U0001D459\U0001D45C\U0001D454\U0001D437(\U0001D465)] + \U0001D438\U0001D465\
    ~ \U0001D443\U0001D467[\U0001D459\U0001D45C\U0001D454(1−\U0001D437(\U0001D43A\
    (\U0001D467)))] \n \nwhere G is the generator network, D is the discriminator\
    \ network, z is random noise, x is \na real sample, Pdata is true data distribution,\
    \ and Pz is the prior distribution of the random \nnoise vector. The generator\
    \ and discriminator compete to outperform each other in a min-\nmax game. \nGANs\
    \ have various applications in remote sensing, including image-to-image trans-\n\
    lation tasks like dehazing and removal of thin clouds. For this purpose, the CycleGAN\
    \ \n[79] and its variants can be used to accomplish cloud-removal tasks [120].\
    \ CycleGAN can \nbe trained on datasets with image pairs with clouds and no clouds,\
    \ with the goal of learn-\ning the mapping between the two sets of images. With\
    \ the trained CycleGAN, clouds can \nbe removed in new sets of images. CycleGAN\
    \ consists of two generators and two discrim-\ninators, with each generator handling\
    \ the forward and back translation between the image \ndomains, while each discriminator\
    \ distinguishes between real and synthetic images. Dur-\ning training, the generators\
    \ aim to maximize the probability of the discriminators making \nmistakes while\
    \ the discriminators strive to accomplish their tasks. Challenges related to \n\
    applying this method for cloud removal tasks include a high percentage of cloud\
    \ cover in \nthe image or complex cloud shapes not seen in training datasets.\
    \ \nTo enhance the resolution of low-resolution satellite images, the SRGAN (Super-Res-\n\
    olution Generative Adversarial Network) model can be utilized [121]. Built on\
    \ a ResNet, \nthe generator learns to map low-resolution images to high-resolution\
    \ counterparts. The \ndiscriminator’s task is to differentiate between generated\
    \ and real high-resolution images. \nDuring training, the generator seeks to deceive\
    \ the discriminator, while the discriminator \naims to classify the images correctly\
    \ [7]. \nFor image-to-image translation tasks and other tasks such as image sharpening,\
    \ clas-\nsification, and others, the Pix2Pix GAN model can also be used [122].\
    \ A series of other \nGAN-based algorithms, such as HRPGAN [123] and similar algorithms,\
    \ can also be used \nfor super-resolution, whereas MARTA GANs [124] can be used\
    \ for data augmentation, \nPSGAN for pan-sharpening [125], and ES-CCGAN [126]\
    \ and CLOUD-GAN [127] based \non CycleGAN for dehazing and cloud removal [118].\
    \ \nFigure 9. Simpliﬁed GAN architecture.\nAdversarial training is as follows:\n\
    minGmaxD Ex~Pdata[logD(x)] + Ex~Pz[log(1 − D(G(z)))]\nwhere G is the generator\
    \ network, D is the discriminator network, z is random noise, x is a\nreal sample,\
    \ Pdata is true data distribution, and Pz is the prior distribution of the random\n\
    noise vector. The generator and discriminator compete to outperform each other\
    \ in a\nmin-max game.\nGANs have various applications in remote sensing, including\
    \ image-to-image transla-\ntion tasks like dehazing and removal of thin clouds.\
    \ For this purpose, the CycleGAN [79]\nand its variants can be used to accomplish\
    \ cloud-removal tasks [120]. CycleGAN can be\ntrained on datasets with image pairs\
    \ with clouds and no clouds, with the goal of learning\nthe mapping between the\
    \ two sets of images. With the trained CycleGAN, clouds can be re-\nmoved in new\
    \ sets of images. CycleGAN consists of two generators and two discriminators,\n\
    with each generator handling the forward and back translation between the image\
    \ domains,\nwhile each discriminator distinguishes between real and synthetic\
    \ images. During training,\nthe generators aim to maximize the probability of\
    \ the discriminators making mistakes\nwhile the discriminators strive to accomplish\
    \ their tasks. Challenges related to applying\nthis method for cloud removal tasks\
    \ include a high percentage of cloud cover in the image\nor complex cloud shapes\
    \ not seen in training datasets.\nTo enhance the resolution of low-resolution\
    \ satellite images, the SRGAN (Super-\nResolution Generative Adversarial Network)\
    \ model can be utilized [121]. Built on a ResNet,\nthe generator learns to map\
    \ low-resolution images to high-resolution counterparts. The\ndiscriminator’s\
    \ task is to differentiate between generated and real high-resolution images.\n\
    During training, the generator seeks to deceive the discriminator, while the discriminator\n\
    aims to classify the images correctly [7].\nFor image-to-image translation tasks\
    \ and other tasks such as image sharpening, clas-\nsiﬁcation, and others, the\
    \ Pix2Pix GAN model can also be used [122]. A series of other\nGAN-based algorithms,\
    \ such as HRPGAN [123] and similar algorithms, can also be used\nfor super-resolution,\
    \ whereas MARTA GANs [124] can be used for data augmentation,\nPSGAN for pan-sharpening\
    \ [125], and ES-CCGAN [126] and CLOUD-GAN [127] based on\nCycleGAN for dehazing\
    \ and cloud removal [118].\nDeep Reinforcement Learning (DRL) offers advantages\
    \ in remote sensing, such as\nlearning from unlabeled data and improving decision-making\
    \ processes [128]. DRL com-\nbines reinforcement learning (RL) techniques with\
    \ deep neural networks to create a pow-\nRemote Sens. 2023, 15, 4112\n15 of 34\n\
    erful framework for solving complex problems. RL involves an agent interacting\
    \ with an\nenvironment to maximize cumulative rewards, while deep neural networks\
    \ approximate\noptimal policies. The agent observes the environment’s state, takes\
    \ an action, and receives\na reward based on the action. The agent updates its\
    \ policy using the reward signal and\ntransitions to a new state, aiming to maximize\
    \ cumulative reward over time. Deep neural\nnetworks serve as function approximators,\
    \ capturing complex relationships between states\nand actions and generalizing\
    \ to new situations [129].\nAn example of DRL in remote sensing is unsupervised\
    \ band selection in hyperspectral\nimage classiﬁcation [130], speciﬁcally using\
    \ a deep Q-network, DQN [131]. The currently\nselected bands represent the state\
    \ by formulating the problem as a Markov decision process,\nMDP [132], and adding\
    \ the next band is considered the action. The DQN learns a band-\nselection policy\
    \ by maximizing the reward signal based on classiﬁcation accuracy from the\nselected\
    \ bands. Training involves normalized spectral signatures and reward signals,\
    \ up-\ndating DQN weights with batches of these data. The learned policy is evaluated\
    \ on unseen\ndatasets to assess generalization and accuracy, demonstrating its\
    \ superiority over other\nmethods. Adjustments to DQN parameters, such as layer\
    \ count, neuron count, and learn-\ning rate, can further enhance accuracy and\
    \ consistency. This model is suitable for remote\nsensing image processing applications\
    \ that analyze large amounts of data, overcoming\nchallenges related to limited\
    \ labeled samples and redundant spectral information.\nEach technique offers unique\
    \ beneﬁts and is suited for speciﬁc tasks in remote sensing,\nenabling researchers\
    \ and practitioners to choose the most appropriate approach based on\ntheir data\
    \ and objectives. Table 2 provides an overview of the key AI techniques in remote\n\
    sensing, highlighting their advantages, limitations, and applications.\nTable\
    \ 2. AI models comparison table.\nTechnique\nAdvantages\nLimitations\nApplications\n\
    RF\n- effectively handles multi-temporal\nand multi-sensor remote sensing data\n\
    - provide variable importance\nmeasurements for feature selection\n- enhances\
    \ generalization and reduces\ncomputational load and redundancy\n- RF feature\
    \ selection prioritizes\ninformative variables by evaluating\ninterrelationships\
    \ and discriminating\nability in high-dimensional remote\nsensing data, leading\
    \ to more accurate\nclassiﬁcation results\n- can be sensitive to the choice of\n\
    hyper-parameters\n- does not guarantee that the selected\nfeatures will be the\
    \ best for all tasks\n- classiﬁcation of remote\nsensing data\n- object detection\
    \ in remote\nsensing\nXGBoost\n- the ability to handle cases where\ndifferent\
    \ classes exhibit similar spectral\nsignatures\n- effective differentiation of\
    \ classes with\nsubtle spectral differences, enhancing\nclassiﬁcation performance.\n\
    - utilization of hyper-parameter tuning\ntechniques to ensure optimal accuracy\n\
    and prevent overﬁtting\n- hyperparameter sensitivity\n- prone to overﬁtting\n\
    - slower than RF\n- the classiﬁcation of remote\nsensing data with high\naccuracy\
    \ and robustness\nDCNNs\n- efﬁciently handle intricate patterns\nand features\
    \ in remote sensing images\n- learn hierarchical representations of\nfeatures\
    \ from convolution and pooling\nlayers\n- enable accurate recognition of objects\n\
    through fully connected layers with\nsoftmax activation\n- training DCNNs can\
    \ be\ncomputationally expensive, especially\nfor large-scale datasets\n- may suffer\
    \ from vanishing gradients\nor overﬁtting if not properly\nregularized\n- remote\
    \ sensing image\nrecognition and\nclassiﬁcation\n- object detection tasks in\n\
    remote sensing using RPN\nRemote Sens. 2023, 15, 4112\n16 of 34\nTable 2. Cont.\n\
    Technique\nAdvantages\nLimitations\nApplications\nResNets\n- alleviate the degradation\
    \ problem in\ndeep learning models, allowing the\ntraining of much deeper networks\n\
    - handling complex high-dimensional\nand noisy data in remote sensing\n- implementing\
    \ very deep networks\nmay still require signiﬁcant\ncomputational resources\n\
    - image recognition object\ndetection\nYOLO\n- efﬁciently identify and classify\n\
    multiple objects in large datasets of\nimages or video frames\n- simultaneously\
    \ process the entire\nimage and region proposals\n- utilize NMS to remove overlapping\n\
    bounding boxes and improve precision\n- may struggle with the detection of\nsmall\
    \ objects in low-resolution images\n- requires careful anchor box design for\n\
    accurate bounding box predictions\n- real-time object detection\nand segmentation\
    \ in remote\nsensing images\nSelf Attention\nmethods\n- capture long-range dependencies\
    \ in\nsequences and handle spatial and\nspectral dependencies in remote\nsensing\
    \ data\n- provide access to all elements in a\nsequence, enabling a comprehensive\n\
    understanding of dependencies\n- transformer models can be\nmemory-intensive due\
    \ to their\nself-attention mechanism\n- properly tuning the number of\nattention\
    \ heads and layers is essential\nfor optimal performance\n- sequence modeling\
    \ and\nimage classiﬁcation in\nremote sensing data\n- time series analysis of\n\
    remote sensing data and\ncapture diverse pixel\nrelationships regardless of\n\
    spatial distance\nLSTM\n- effectively captures long-term\ndependencies in sequences\n\
    - overcomes the vanishing gradient\nproblem with gate mechanisms\n- training LSTMs\
    \ can be time\nconsuming, particularly for longer\nsequences\n- can struggle with\
    \ capturing very\nlong-term dependencies in sequences\n- may require careful tuning\
    \ of\nhyperparameters to prevent overﬁtting\n- sequence modeling and\ntime series\
    \ analysis in\nremote sensing data\nGANs\n- capable of handling complex,\nhigh-dimensional\
    \ data distributions\nwith limited or no annotated training\ndata\n- data augmentation\
    \ method enhances\nthe performance of data-reliant deep\nlearning models\n- training\
    \ GANs can be challenging and\nunstable, requiring careful\nhyper-parameter tuning\n\
    - generating high-quality, realistic\nimages may be difﬁcult in some cases\n-\
    \ may suffer from mode collapse, where\nthe generator produces limited\nvariations\
    \ in images\n- image-to-image translation\ntasks like converting\nsatellite images\
    \ with cloud\ncoverage into cloud-free\nversions using CycleGAN\n- enhancing the\
    \ resolution of\nlow-resolution satellite\nimages with SRGAN and\nsimilar approaches\n\
    - image-to-image translation,\ndata augmentation, and\npan-sharpening\nDRL\n-\
    \ learns from unlabeled data to improve\ndecision-making processes\n- combines\
    \ reinforcement learning (RL)\nwith deep neural networks for solving\ncomplex\
    \ problems\n- handles redundant spectral\ninformation\n- requires careful design\
    \ and tuning of\nreward functions to ensure the desired\nbehavior\n- training\
    \ deep neural networks in DRL\ncan be computationally expensive and\ntime consuming\n\
    - exploration vs. exploitation trade-off\nin RL can impact the learning process\n\
    and can be dependent on the sample\n- improving unsupervised\nband selection in\n\
    hyperspectral image\nclassiﬁcation using DRL\nwith DQN\n- image processing\napplications\
    \ that analyze\nlarge amounts of data\n3. Current Practical Applications of AI\
    \ in Remote Sensing\n3.1. Land Cover Mapping\nAI techniques have been widely used\
    \ in mapping tasks for assigning labels to indi-\nvidual image pixels and allowing\
    \ for the categorization based on different spectral and\nspatial features, providing\
    \ valuable information about the distribution and characteristics\nof land cover\
    \ types in a speciﬁc area [133–135] (Figure 10). As a practical example, the\n\
    Remote Sens. 2023, 15, 4112\n17 of 34\nEnvironmental Systems Research Institute\
    \ (Esri) has recently released a high-resolution\n(10 m) annual global land cover\
    \ map (2017–2022), which was created using a full CNN\nwith a U-Net architecture\
    \ developed using Impact Observatory [136]. To train this model, a\nmassive training\
    \ dataset of over ﬁve billion labeled image pixels was utilized, generously\n\
    provided by the National Geographic Society. The map-making process involved utilizing\n\
    the comprehensive coverage and high spatial resolution of the European Space Agency’s\n\
    (ESA) Sentinel-2 satellite imagery.\n \n3. Current Practical Applications of AI\
    \ in Remote Sensing \n3.1. Land Cover Mapping \nAI techniques have been widely\
    \ used in mapping tasks for assigning labels to indi-\nvidual image pixels and\
    \ allowing for the categorization based on different spectral and \nspatial features,\
    \ providing valuable information about the distribution and characteristics \n\
    of land cover types in a specific area [133–135] (Figure 10). As a practical example,\
    \ the \nEnvironmental Systems Research Institute (Esri) has recently released\
    \ a high-resolution \n(10 m) annual global land cover map (2017–2022), which was\
    \ created using a full CNN \nwith a U-Net architecture developed using Impact\
    \ Observatory [136]. To train this model, \na massive training dataset of over\
    \ five billion labeled image pixels was utilized, gener-\nously provided by the\
    \ National Geographic Society. The map-making process involved \nutilizing the\
    \ comprehensive coverage and high spatial resolution of the European Space \n\
    Agency’s (ESA) Sentinel-2 satellite imagery. \n \nFigure 10. Esri Land Cover Explorer\
    \ screenshot. \nCreating the map entailed running the AI model on an extensive\
    \ collection of approx-\nimately 400,000 Earth observations of Land Use/Land Cover,\
    \ LULC [137], of around 500 \nterabytes of cached imagery. The model incorporated\
    \ six Sentinel-2 surface reflectance \nbands and generated ten land cover classes,\
    \ including water, trees, grass, crops, and built \nareas. To achieve a comprehensive\
    \ depiction of land cover, the final map was created by \ncompositing the outputs\
    \ of the model applied to multiple dates of imagery throughout \nthe year, offering\
    \ a comprehensive depiction of land cover. The computation process re-\nquired\
    \ approximately 1.2 million core hours to handle the immense computational load,\
    \ \nwith Microsoft Azure Batch expediting the processing time, with up to 6400\
    \ cores running \nsimultaneously. \n3.2. Earth Surface Object Detection \nSpaceKnow’s\
    \ GEMSTONE (Global Economy Monitoring System Delivering Trans-\nparency and Online\
    \ Expertise) project aims to develop advanced ML algorithms that uti-\nlize satellite\
    \ data for monitoring global economic activity [138]. These algorithms combine\
    \ \nspectral unmixing and deep neural networks (DNNs) to detect [139] raw materials\
    \ and \nmanufactured structures, enabling comprehensive monitoring. Spectral unmixing\
    \ in-\nvolves analyzing the spectral properties of satellite imagery to identify\
    \ and differentiate \nspecific materials of interest, whereas DNNs classify and\
    \ distinguish these detected ma-\nterials, ensuring accurate and high-quality\
    \ results. These algorithms are deployed in \nFigure 10. Esri Land Cover Explorer\
    \ screenshot.\nCreating the map entailed running the AI model on an extensive\
    \ collection of ap-\nproximately 400,000 Earth observations of Land Use/Land Cover,\
    \ LULC [137], of around\n500 terabytes of cached imagery. The model incorporated\
    \ six Sentinel-2 surface reﬂectance\nbands and generated ten land cover classes,\
    \ including water, trees, grass, crops, and built\nareas. To achieve a comprehensive\
    \ depiction of land cover, the final map was created by com-\npositing the outputs\
    \ of the model applied to multiple dates of imagery throughout the year,\noffering\
    \ a comprehensive depiction of land cover. The computation process required approx-\n\
    imately 1.2 million core hours to handle the immense computational load, with\
    \ Microsoft\nAzure Batch expediting the processing time, with up to 6400 cores\
    \ running simultaneously.\n3.2. Earth Surface Object Detection\nSpaceKnow’s GEMSTONE\
    \ (Global Economy Monitoring System Delivering Trans-\nparency and Online Expertise)\
    \ project aims to develop advanced ML algorithms that utilize\nsatellite data\
    \ for monitoring global economic activity [138]. These algorithms combine\nspectral\
    \ unmixing and deep neural networks (DNNs) to detect [139] raw materials and\n\
    manufactured structures, enabling comprehensive monitoring. Spectral unmixing\
    \ involves\nanalyzing the spectral properties of satellite imagery to identify\
    \ and differentiate speciﬁc\nmaterials of interest, whereas DNNs classify and\
    \ distinguish these detected materials,\nensuring accurate and high-quality results.\
    \ These algorithms are deployed in carefully\nselected locations, and the analysis\
    \ outputs are aggregated into speciﬁc economic indices.\nUsers can access this\
    \ information via a user-friendly dashboard or an API (Application\nProgramming\
    \ Interface), allowing seamless integration into their organizations’ workﬂows.\n\
    The effectiveness of these algorithms has been demonstrated via case studies such\
    \ as the\nNagoya Port Analysis, in which various elements, such as oil tanks,\
    \ were detected and\ntracked [140] over time, providing valuable insights into\
    \ the port’s activity. A road algo-\nrithm successfully monitored the expansion\
    \ of the road network in Zayed City, Abu Dhabi,\nshowcasing its potential for\
    \ large-scale monitoring of urbanization and road development.\nRemote Sens. 2023,\
    \ 15, 4112\n18 of 34\n3.3. Multisource Data Fusion and Integration\nIntegrating\
    \ information from various remote sensing techniques can provide a com-\nprehensive\
    \ understanding of objects or phenomena. This process involves collecting data\n\
    from diverse sources, ensuring accurate data registration and co-registration,\
    \ integrating\ncorrelated measurements, and estimating desired object attributes\
    \ or identities [141]. For\ninstance, the European Space Agency (ESA) utilizes\
    \ AI and satellite data to tackle survey-\ning water pipe networks, detecting\
    \ leaks, and identifying new water sources. Access to\nclean drinking water and\
    \ reducing water pipe leaks are signiﬁcant concerns in regions\ndealing with water\
    \ scarcity, both in developing and developed nations. To handle this,\nESA has\
    \ developed a service catering to the needs of governments, water utilities, charities,\n\
    non-proﬁts, and NGOs operating in these areas. The service merges neural networks\
    \ with\nmulti-spectral and synthetic aperture radar satellite data, particularly\
    \ ESA Sentinel 1 and\n2 data. Neural networks recognize water’s spectral and backscatter\
    \ signatures, indicating\nmoisture. This enables comprehensive surveys to locate\
    \ underground water sources and\nidentify pipe network leaks. As a result, a detailed\
    \ map of Earth’s sub-surface water has\nbeen created, boasting a spatial resolution\
    \ of 10 square meters [142]. This map encompasses\nover 1.5 trillion [142] satellite\
    \ tiles and stores vast amounts of data. ESA has also launched\na free underground\
    \ water mapping service called SpaceWater.AI, with the support of Esri,\nNvidia,\
    \ and Amazon Web Services. Pilot users, such as the United Nations High Com-\n\
    missioner for Refugees (UNHCR) and WaterAid, are already beneﬁting from this service.\n\
    The accuracy of identifying underground water sources reaches a maximum peak of\
    \ up to\n98% [142], although it may vary based on geographic and environmental\
    \ conditions.\nAdditionally, ESA has also developed the Total Ecosystem Management\
    \ of the Inter-\nTidal Habitat (TEMITH) project [143], led by the University of\
    \ Southampton, to monitor\nSolent’s intertidal habitat on England’s south coast\
    \ using Earth Observation (EO) data.\nThis project focuses on two pressures: algal\
    \ mats and sediment disturbance. Gathering and\npreparing data involve multiple\
    \ steps. Satellite data from various sources, including in\nsitu datasets, are\
    \ used to select collection dates and locations. For feature detection, two\n\
    sensors are used as follows: Copernicus Sentinel-2 (10 m resolution) and the high-resolution\n\
    MAXAR (0.31 to 0.61 m). Imagery is captured within a 4 week timeframe, extending\
    \ to\n8 weeks if needed, preferably during low tide and cloud-free conditions.\
    \ Sediment distur-\nbance detection uses mapped polygon datasets for model training,\
    \ supplemented by drone\nimagery, aerial photography, and high-resolution satellite\
    \ imagery for additional labeling.\nThe labeling process considers scarring morphology\
    \ and context, selecting high-conﬁdence\npolygons for model training. Similarly,\
    \ mapped polygon datasets for algal mats, seagrass,\nand salt marsh detection\
    \ come from diverse sources, including the Environment Agency,\nHampshire and\
    \ Isle Wight Wildlife Trust, Natural England, and the Channel Coastal Obser-\n\
    vatory. Dataset selection is based on suitability and compatibility with available\
    \ satellite\nimagery, aiming for a match within two weeks of data collection.\
    \ Prioritizing Sentinel-2\nimagery known for cloud-free, low-tide images, enhances\
    \ feature visibility. The project\ntrains three ResU-Net models and six U-Net\
    \ CNN models. These models identify indicators\nlike nutrient enrichment, seagrass\
    \ presence, and salt marsh presence, targeting sediment\ndisturbance and algal\
    \ mats.\n3.4. Three-Dimensional and Invisible Object Extraction\nRemote sensing\
    \ data are the primary source for extracting valuable information about\nthe 3D\
    \ structures and spectral characteristics of objects [144]. Two key types of data\
    \ used\nin remote sensing are LiDAR data and hyperspectral data. LiDAR data provide\
    \ detailed\ninformation on object heights and shapes within a surveyed area, whereas\
    \ hyperspectral\ndata capture the electromagnetic spectrum reﬂected or emitted\
    \ by objects, allowing for the\nidentiﬁcation and analysis of different materials\
    \ based on their unique spectral characteris-\ntics. However, both data types\
    \ face challenges, such as spectral redundancy, low spatial\nresolution for hyperspectral\
    \ data, and the presence of high- and low-frequency information\nin LiDAR data.\n\
    Remote Sens. 2023, 15, 4112\n19 of 34\nStartups like Enview have introduced a\
    \ Web-based AI service speciﬁcally designed for\nLiDAR data analysis. By utilizing\
    \ CNNs, Enview enables the automated identiﬁcation of\nphysical objects within\
    \ 3D point clouds, including power lines, pipelines, buildings, trees,\nand vehicles.\
    \ This technology is particularly beneﬁcial for companies in the electricity and\n\
    natural gas distribution sector, streamlining object identiﬁcation through the\
    \ segmentation\nand classiﬁcation of LiDAR data. Enview’s AI technology has already\
    \ delivered signiﬁcant\ncost savings by automating power line inspection [145].\n\
    In the realm of HSI, Metaspectral, a Vancouver-based company, has developed an\n\
    AI platform that combines HSI and edge computing to revolutionize various industries.\n\
    The platform incorporates data compression techniques and deep neural networks\
    \ and\nsupports various neural architectures. By reducing data streams without\
    \ compromising\ninformation, the platform enables real time, pixel-by-pixel analysis\
    \ of hyperspectral data.\nMetaspectral’s AI platform ﬁnds applications in space\
    \ exploration, recycling, and agri-\nculture. The Canadian Space Agency utilizes\
    \ this technology to measure greenhouse gas\nlevels on Earth. In recycling, the\
    \ system accurately classiﬁes plastics by analyzing their\nchemical structures,\
    \ enhancing the recycling process. In agriculture, the early detection\nof diseases\
    \ is made possible by identifying speciﬁc spectral signatures associated with\n\
    plant diseases, allowing for timely interventions. Additionally, the platform\
    \ aids in climate\nchange mitigation efforts by detecting and analyzing wildﬁre\
    \ risks through hyperspectral\nanalysis, facilitating proactive measures like\
    \ controlled burns [146,147].\n4. Existing Challenges\nThis section will discuss\
    \ the challenges and limitations of AI in remote sensing [14],\nwith potential\
    \ solutions and advancements for overcoming these challenges.\n4.1. Data Availability\n\
    AI training data are often sourced from satellites, aerial sensors, or ground-based\n\
    instruments. However, these valuable data are not always readily accessible to\
    \ researchers,\nscientists, or organizations. Some datasets may be restricted\
    \ due to proprietary rights or\ncontrolled by government agencies, limiting their\
    \ availability for broader use. Additionally,\ncertain remote sensing datasets\
    \ have limited temporal coverage, making it challenging to\nassess interannual\
    \ and decadal variability [148,149]. Consequently, the limited access to\nremote\
    \ sensing data can impede the development and application of AI in this ﬁeld.\n\
    To effectively train AI models, a signiﬁcant amount of labeled data is required\
    \ to\nteach algorithms to recognize and interpret speciﬁc features and patterns\
    \ in remote sensing\ndata. However, creating labeled datasets can be a time-consuming\
    \ task that demands\nexpertise [150]. The availability of accurately labeled data\
    \ is essential to achieve reliable\nresults when training AI models. Real-time\
    \ or frequent updates of remote sensing data are\ncrucial for monitoring and analyzing\
    \ dynamic environmental conditions and changes [151].\nHowever, the availability\
    \ of such timely data can be limited, especially in certain regions\nor for speciﬁc\
    \ types of data. This limitation can undermine the effectiveness of AI appli-\n\
    cations in remote sensing, as models trained on outdated or infrequent data may\
    \ need\nto represent current conditions accurately. Overcoming the challenge of\
    \ data availability\nin remote sensing requires collaborative efforts to improve\
    \ data sharing and access [152].\nThe initiatives that promote open data policies,\
    \ data-sharing platforms, and partnerships\nbetween organizations can facilitate\
    \ greater availability of remote sensing data. Collaborat-\ning with space agencies,\
    \ government organizations, and private entities can also expand\naccess to the\
    \ necessary data for training and implementing AI models in remote sensing\napplications\
    \ [153].\n4.2. Training Optimization\nAchieving optimal performance of AI models\
    \ in remote sensing demands careful\nconsideration and a solid grasp of mathematics.\
    \ Selecting suitable loss functions is im-\nportant in guiding models toward improved\
    \ accuracy. For instance, cross-entropy loss\nRemote Sens. 2023, 15, 4112\n20\
    \ of 34\nis commonly employed for land cover classiﬁcation, whereas mean squared\
    \ error (MSE)\nloss is preferable for regression tasks [154]. Imbalanced datasets\
    \ can pose a signiﬁcant\nchallenge during model optimization when certain classes\
    \ are rare or underrepresented. In\nthese conditions, the model may exhibit bias\
    \ towards the majority class, resulting in poor\nperformance for the minority\
    \ classes [155]. Optimizing complex models in remote sensing\ncomes with its own\
    \ set of challenges. Deep learning models like CNNs or RNNs possess\nnumerous\
    \ parameters and demand substantial computational resources for training [156].\n\
    Algorithms such as stochastic gradient descent (SGD) and its variants, such as\
    \ Adam or\nRMSprop, are commonly employed for parameter updates [157]. Fine-tuning\
    \ the learning\nrate, selecting appropriate batch sizes, and determining convergence\
    \ criteria are critical\nsteps in optimizing complex models. Additionally, hardware\
    \ limitations can introduce\ntraining time and computational efﬁciency challenges.\n\
    4.3. Data Quality\nThe accuracy, reliability, and completeness of training data\
    \ directly inﬂuence the\nmodel’s performance and generalization capability [158].\
    \ Obtaining accurate and reliable\nground truth labels can be difﬁcult due to\
    \ limited ground-based observations, subjective\ninterpretations, or human errors\
    \ [159]. For instance, mislabeling land cover classes or\nconfusion between similar\
    \ classes can greatly affect the training and performance of mod-\nels in land\
    \ cover classiﬁcation. Different sources, sensors, or acquisition times result\
    \ in\nvariations in spatial resolution, spectral characteristics, or temporal\
    \ patterns [160]. These\ninconsistencies can introduce biases and complicate the\
    \ training process. In time series\nanalysis, inconsistent temporal sampling intervals\
    \ or missing observations can hinder the\nmodel’s ability to capture temporal\
    \ patterns accurately [161].\n4.4. Uncertainty\nUncertainty arises in remote sensing\
    \ data from various sources, including atmospheric\nconditions, sensor limitations,\
    \ data acquisition techniques, and natural variability, caused\nby factors like\
    \ clouds, haze, or aerosols, resulting in incomplete or distorted remote sensing\n\
    data [162]. Sensor characteristics and calibration also contribute to uncertainty\
    \ [163].\nAI models trained on static datasets may need adjustments to adapt to\
    \ these dynamic\nvariations and may not generalize well to different locations\
    \ or periods. Temporal and\nspatial variability of natural phenomena also will\
    \ further contribute to uncertainty in\nremote sensing-based AI models [164].\n\
    4.5. Model Interpretability\nInterpretability ensures the trustworthiness and\
    \ validation of AI model outputs [165]\nand becomes especially important in sensitive\
    \ applications like environmental monitor-\ning [166] or disaster response, where\
    \ transparency and accountability are crucial. However,\nAI models, particularly\
    \ complex deep learning models, often function as black boxes, mak-\ning it difﬁcult\
    \ to understand or explain their internal mechanisms and decision-making\nprocesses\
    \ [167]. Efforts are being made to address the interpretability of AI models in\n\
    remote sensing [168]. Techniques such as model explainability, feature importance\
    \ anal-\nysis, or visualization methods can help shed light on the reasoning behind\
    \ the model’s\npredictions [169].\n4.6. Diversity\nEvaluating and validating AI\
    \ models on diverse and independent datasets are critical\nsteps to assess their\
    \ generalization ability. To ensure consistent and reliable performance in\nreal-world\
    \ applications, it is essential to test the models across different geographic\
    \ regions,\nseasons, sensor types, and environmental conditions. However, one\
    \ of the main challenges\nlies in the availability of diverse and representative\
    \ training data [6]. Currently, various\ntechniques are employed to address the\
    \ data availability challenges. Data augmentation\ngenerates additional training\
    \ examples by applying transformations, such as rotation,\nRemote Sens. 2023,\
    \ 15, 4112\n21 of 34\nscaling, or noise addition, to the existing data [170].\
    \ This technique exposes the model to\nbroader variations, enhancing its ability\
    \ to generalize to unseen data. Another common\napproach is transfer learning,\
    \ where pre-trained models trained on large-scale datasets\nlike ImageNet serve\
    \ as a starting point [171]. By ﬁne-tuning these pre-trained models\non a smaller\
    \ remote sensing dataset, the models can leverage their acquired knowledge\nand\
    \ adapt it to the speciﬁc task. Ensemble methods also contribute to diversity\
    \ and\ngeneralization [172] by combining multiple individual models, each trained\
    \ with different\nalgorithms or variations of the training data.\nWhile progress\
    \ has been made in these areas, there are still unresolved aspects that\nresearchers\
    \ are actively working on. Ensuring that the training dataset is representative\
    \ of\nthe target population or the real-world distribution of data presents a\
    \ signiﬁcant challenge,\nand collecting a representative dataset that covers all\
    \ possible variations, particularly in re-\nmote sensing, where data can be scarce\
    \ or costly to obtain, is demanding [173]. Developing\neffective techniques to\
    \ adapt pre-trained models to remote sensing-speciﬁc features and\nvariations\
    \ remains an ongoing research area.\nRemote sensing applications often involve\
    \ detecting and analyzing rare or complex\nevents [174], such as natural disasters\
    \ or occurrences of rare species. AI models trained\non standard datasets may\
    \ have yet to encounter such events during training, posing\nchallenges in generalizing\
    \ these scenarios. Research efforts are focused on developing\ntechniques to handle\
    \ these rare events and improve the generalization capabilities of\nAI models.\
    \ For example, IBM and NASA have collaboratively introduced the largest\ngeospatial\
    \ AI foundation model, named watsonx.ai, in partnership with Hugging Face.\nThis\
    \ model utilizes NASA’s satellite data, speciﬁcally Harmonized Landsat Sentinel-2\n\
    (HLS) data, to revolutionize Earth observation and advance climate science. This\
    \ joint\ninitiative aims to democratize AI access, particularly in addressing\
    \ evolving environmental\nconditions. The geospatial model is accessible on Hugging\
    \ Face’s open-source platform,\nshowcasing its commitment to open AI and science.\
    \ It stands out as the ﬁrst open-source\nAI foundation model developed in collaboration\
    \ with NASA. This partnership emphasizes\nthe potential of open-source technologies\
    \ in deepening our understanding of Earth’s\nclimate and environment. The watsonx.ai\
    \ model excels in tasks such as ﬂood and burns\nscar mapping, demonstrating a\
    \ 15 percent enhancement over existing techniques. IBM’s\nexpertise in AI and\
    \ NASA’s Earth-satellite data contribute to the model’s accuracy and\neffectiveness.\
    \ The collaboration resonates with NASA’s Open Source Science Initiative and\n\
    IBM’s broader efforts in AI advancement. Moreover, this geospatial model holds\
    \ potential\nbeyond its current applications. It could be adapted for tasks such\
    \ as deforestation tracking,\ncrop yield prediction, and greenhouse gas monitoring.\
    \ IBM’s Environmental Intelligence\nSuite will soon feature a commercial version\
    \ of the model [175]. Another common issue\nis the perpetuation of biases and\
    \ inequities when AI models are trained on biased or\nunrepresentative data [56,176].\n\
    4.7. Integrity and Security\nBiases or inaccuracies in the training data can result\
    \ in biased or unreliable AI predic-\ntions, which can have consequences in real-world\
    \ applications [177]. To maintain integrity,\nit is essential to prioritize transparency,\
    \ fairness, and accountability throughout the AI\nmodel development and training\
    \ processes [178]. By adhering to these principles, the\nintegrity of the AI system\
    \ can be upheld, instilling trust in its outcomes and promoting\nethical practices.\
    \ As discussed above, maintaining integrity in remote sensing data involves\n\
    multiple aspects, including data quality, data integrity, and the prevention of\
    \ tampering or\nmanipulation [179]. Protecting data integrity entails safeguarding\
    \ the data from unautho-\nrized modiﬁcations, tampering, or cyberattacks. Remote\
    \ sensing data can be vulnerable to\nmalicious actions, such as data breaches\
    \ or unauthorized access [180]. One concern is the\npotential compromise of personal\
    \ privacy through detailed imagery capturing identiﬁable\nfeatures or activities.\
    \ To address this, robust encryption protocols [181] and secure commu-\nnication\
    \ channels should be implemented while transmitting remote sensing data [182].\n\
    Remote Sens. 2023, 15, 4112\n22 of 34\nAdditionally, secure storage systems, including\
    \ servers or cloud platforms equipped with\naccess controls and encryption mechanisms,\
    \ are essential for protecting the data from\nunauthorized access. Privacy regulations,\
    \ such as GDPR, impose strict data handling,\nstorage, and sharing requirements\
    \ [183].\n5. Ongoing and Future Practical AI Applications in Remote Sensing\n\
    This section explores ongoing and potential ideas that can advance practical AI\
    \ appli-\ncations. The workaround for these ideas may already be in progress,\
    \ and some may inspire\nfuture applications with transformative impacts on environmental\
    \ management.\n5.1. Wildﬁre Detection and Management\nThe application of AI in\
    \ wildﬁre management is increasing steadily [184], using\nadvanced algorithms\
    \ and remote sensing technologies to enable early detection and rapid\nresponse.\
    \ AI systems analyze data from satellites, drones [185], and sensors to track\n\
    wildﬁres in real time and predict ﬁre behavior accurately by considering historical\
    \ ﬁre data,\nweather patterns, and topographical information. This data-driven\
    \ approach enhances\nﬁreﬁghting efﬁciency and reduces the impact of wildﬁres on\
    \ communities and ecosystems.\nAI’s beneﬁt lies in its capacity to handle large-scale\
    \ data analysis [186] and pattern\nrecognition, identifying hidden correlations\
    \ in historical ﬁre data, weather, and other\nrelevant factors. AI-powered drones\
    \ equipped with thermal imaging cameras can swiftly\ndetect ﬁres, leading to quicker\
    \ response times and reduced costs. The Prometheus system\ndeveloped by ESA uses\
    \ AI and satellite data to predict wildﬁre behavior. Successful AI\nintegration\
    \ in wildﬁre management relies on a network of sensors collecting real-time\n\
    data on ﬁre occurrence, weather, and environment, fed into AI algorithms for analysis.\n\
    Advanced ML techniques, like deep learning and neural networks, train AI models\
    \ on\nvast datasets to enhance accuracy. To harness AI’s potential, investments\
    \ in infrastructure,\ncommunication networks, and technology are necessary. Though\
    \ initial costs may be\nsigniﬁcant, beneﬁts include reduced damages, improved\
    \ response times, and enhanced\nﬁreﬁghter safety. As AI systems become more sophisticated,\
    \ their seamless integration into\nwildﬁre management practices will drive automation\
    \ and efﬁciency.\n5.2. Illegal Logging and Deforestation Monitoring\nBy analyzing\
    \ satellite and drone imagery, AI can detect changes in forest cover, logging\n\
    patterns, and illegal encroachments. This information can be used to track deforestation\n\
    and identify areas that need protection. To revolutionize deforestation monitoring,\
    \ AI\nwith satellite imagery helps detect changes in forest cover and detect illegal\
    \ logging in\nreal time. The implementation involves effectively utilizing technologies\
    \ like the Google\nEarth Engine (GEE) [187] and employing advanced AI algorithms.\
    \ Satellite imagery data\nare collected from the different sources of remote sensing\
    \ technology on changes in forest\ncover, which are then subjected to data cleaning\
    \ and organization during the pre-processing\nstage of an AI model. The algorithms\
    \ are then applied to analyze the data and identify\npatterns in illegal logging\
    \ activities in a particular geographical area, which helps in\ndecision making,\
    \ ultimately leading to concrete actions against deforestation and holding\nillegal\
    \ loggers accountable. As AI technology advances, we anticipate developing even\n\
    more innovative and efﬁcient applications for protecting our forests [188,189].\
    \ A notable\nexample of this approach is Global Forest Watch (GFW), which utilizes\
    \ satellite imagery\nand advanced algorithms to monitor deforestation globally,\
    \ alerting governments, NGOs,\nand stakeholders.\n5.3. Coastal and Marine Ecosystem\
    \ Monitoring\nTo protect coastal and marine ecosystems, AI can detect changes\
    \ in coral reefs [190],\nidentify marine pollution, track marine species, and\
    \ support the sustainable management\nof coastal resources (Figure 11). One noteworthy\
    \ trend in marine research involves using\nimage recognition algorithms to analyze\
    \ photographs or videos of marine environments.\nRemote Sens. 2023, 15, 4112\n\
    23 of 34\nThese algorithms can identify organisms or objects of interest, making\
    \ them valuable\ntools for monitoring changes in animal populations and pinpointing\
    \ areas where human\nactivities are causing ecological damage. ML algorithms can\
    \ also analyze underwater\nsounds [191]. Understanding underwater soundscapes\
    \ can be complex, but speciﬁc sounds\ncan be recognized and distinguished from\
    \ background noise with ML. This capability\nallows researchers and managers to\
    \ monitor changes in ecosystem dynamics and gain\nvaluable insights into the evolution\
    \ of marine ecosystems [192]. In marine research [193],\ncomputer vision techniques\
    \ can be used to analyze high-deﬁnition (HD) digital camera\nphoto sequences captured\
    \ by ﬁxed underwater stations, Autonomous Underwater Vehicles\n(AUVs), and Remotely\
    \ Operated Vehicles (ROVs) across various oceanic regions. This\ntechnology facilitates\
    \ the identiﬁcation of areas with potential ﬁsh activity in their natural\nhabitat,\
    \ providing details such as the number of ﬁsh, species composition, and abundance\n\
    in different locations.\n \nand advanced algorithms to monitor deforestation globally,\
    \ alerting governments, NGOs, \nand stakeholders. \n5.3. Coastal and Marine Ecosystem\
    \ Monitoring \nTo protect coastal and marine ecosystems, AI can detect changes\
    \ in coral reefs [190], \nidentify marine pollution, track marine species, and\
    \ support the sustainable management \nof coastal resources (Figure 11). One noteworthy\
    \ trend in marine research involves using \nimage recognition algorithms to analyze\
    \ photographs or videos of marine environments. \nThese algorithms can identify\
    \ organisms or objects of interest, making them valuable tools \nfor monitoring\
    \ changes in animal populations and pinpointing areas where human activ-\nities\
    \ are causing ecological damage. ML algorithms can also analyze underwater sounds\
    \ \n[191]. Understanding underwater soundscapes can be complex, but specific sounds\
    \ can \nbe recognized and distinguished from background noise with ML. This capability\
    \ allows \nresearchers and managers to monitor changes in ecosystem dynamics and\
    \ gain valuable \ninsights into the evolution of marine ecosystems [192]. In marine\
    \ research [193], computer \nvision techniques can be used to analyze high-definition\
    \ (HD) digital camera photo se-\nquences captured by fixed underwater stations,\
    \ Autonomous Underwater Vehicles \n(AUVs), and Remotely Operated Vehicles (ROVs)\
    \ across various oceanic regions. This \ntechnology facilitates the identification\
    \ of areas with potential fish activity in their natural \nhabitat, providing\
    \ details such as the number of fish, species composition, and abundance \nin\
    \ different locations. \n \nFigure 11. AI with remote sensors for coastal and\
    \ marine ecosystem monitoring. \n \n \nFigure 11. AI with remote sensors for coastal\
    \ and marine ecosystem monitoring.\n5.4. Biodiversity Conservation and Habitat\
    \ Monitoring\nAdvanced image analysis techniques, such as object detection and\
    \ classiﬁcation, can\noffer valuable insights to identify and monitor habitats,\
    \ track species populations, and\nassess ecological connectivity, thereby enhancing\
    \ the accuracy and efﬁciency of biodiversity\nmonitoring [194]. AI helps improve\
    \ the conservation and sustainable use of biological\nand ecosystem values [195].\
    \ GEE, which integrates AI for geospatial data analysis, can be\nused to process\
    \ large amounts of satellite imagery and other remote sensing data [187].\nImagine\
    \ deploying AI-powered cameras that can automatically recognize and count species\n\
    in remote areas and generate real-time data on population trends and distribution.\
    \ This\ninformation becomes invaluable in guiding conservation efforts and assessing\
    \ the progress\nof restoration projects. Another trend is AI applications that\
    \ analyze extensive scientiﬁc\nliterature, news articles, and social media posts\
    \ [196] related to biodiversity and envi-\nronmental issues. By extracting relevant\
    \ information, identifying patterns, and detecting\ntrends, NLP algorithms enable\
    \ researchers and policymakers to stay updated on the latest\ndevelopments in\
    \ the ﬁeld.\nRemote Sens. 2023, 15, 4112\n24 of 34\n5.5. Airborne Disease Monitoring\
    \ and Forecasting\nThe future of using AI and remote sensing envisions a proactive\
    \ and data-driven\napproach to public health, and we might detect outbreaks early,\
    \ respond rapidly, and\nimplement targeted interventions [197]. By monitoring\
    \ various indicators, such as air\nquality [198], weather patterns, and population\
    \ density, AI can identify potential hotspots\nand areas at risk. Remote sensing\
    \ technologies equipped with AI-enabled sensors can\nprovide real-time surveillance\
    \ of disease-prone areas [199]. Drones, for example, can collect\ndata on air\
    \ quality [200], temperature, and humidity, whereas satellites can capture high-\n\
    resolution imagery. AI models trained on historical data, combined with remote\
    \ sensing\ninputs, can generate accurate disease forecasting models. By analyzing\
    \ factors such as\nenvironmental conditions, population movement, and social interactions,\
    \ these models can\npredict the future spread of airborne diseases, informing\
    \ public health agencies to prepare\nresources, implement preventive measures,\
    \ and allocate healthcare facilities in advance,\nminimizing the impact of outbreaks.\
    \ AI can also be used to detect and diagnose diseases\nearly [201].\nAI and remote\
    \ sensing can aid in risk assessment by analyzing various factors that\ncontribute\
    \ to disease transmission, including air pollution levels, urbanization patterns,\n\
    and human mobility. By understanding the risk factors associated with speciﬁc\
    \ areas\nor populations, public health authorities can develop targeted strategies\
    \ for prevention,\nallocate resources efﬁciently, and prioritize interventions\
    \ where they are most needed.\nAI-powered systems can also play a role in raising\
    \ public awareness and educating com-\nmunities about airborne diseases. Through\
    \ real-time data visualization, interactive maps,\nand user-friendly interfaces,\
    \ individuals can access information about disease prevalence,\npreventive measures,\
    \ and local resources.\n5.6. Precision Forestry\nThe combination of AI, LiDAR\
    \ [202], and hyperspectral imagery provides detailed in-\nformation on forest\
    \ structure, biomass, and species composition, promoting sustainable and\nefﬁcient\
    \ forestry management [203]. Advanced thermal imaging techniques detect subtle\n\
    temperature changes in trees as early indicators of pest infestation or disease\
    \ outbreaks, and\ntemperature variations can enable the detection of changes even\
    \ before visible symptoms\nappear. Additionally, non-invasive acoustic sensors\
    \ provide continuous monitoring and\nreal-time insights into tree health and growth\
    \ dynamics. By detecting anomalies such\nas wind-induced stress or structural\
    \ weaknesses, these sensors assist forest managers in\npromptly dealing with potential\
    \ issues [204].\nAdditionally, short-range remote sensing technology captures\
    \ data that aid in visu-\nalizing various artifacts on tree trunks, providing\
    \ valuable insights into their current and\nfuture health status [205]. For detecting\
    \ tassels in RGB imagery acquired by unmanned\naerial vehicles (UAVs), an algorithm,\
    \ YOLOv5-tassel, is used, and it has signiﬁcant poten-\ntial in precision agriculture\
    \ [206]. Incorporating AI algorithms signiﬁcantly increases the\nprobability of\
    \ identifying these artifacts. This technological integration enables accurate\n\
    measurement of tree characteristics and quality, whether the trees are standing\
    \ or lying,\nfacilitating an understanding of tree health and informed decision\
    \ making in forestry\nmanagement practices.\n5.7. Urban Heat Island Mitigation\n\
    For identifying heat patterns, vegetation cover [207], and surface materials,\
    \ AI can\nhelp urban planners optimize green infrastructure, develop heat mitigation\
    \ strategies, and\nimprove urban liveability. By integrating AI with satellite\
    \ remote sensing and urban sensor\nnetwork data, an integrated framework can provide\
    \ accurate predictions of the urban heat\nisland phenomenon [208], offering spatiotemporal\
    \ granularity. This predictive capability is\nvaluable for forecasting UHI (Figure\
    \ 12) at speciﬁc times, facilitating the development of\nmitigation strategies,\
    \ and formulating relevant policies to counteract its effects [209].\nRemote Sens.\
    \ 2023, 15, 4112\n25 of 34\n \nurban planners optimize green infrastructure, develop\
    \ heat mitigation strategies, and im-\nprove urban liveability. By integrating\
    \ AI with satellite remote sensing and urban sensor \nnetwork data, an integrated\
    \ framework can provide accurate predictions of the urban heat \nisland phenomenon\
    \ [208], offering spatiotemporal granularity. This predictive capability is \n\
    valuable for forecasting UHI (Figure 12) at specific times, facilitating the development\
    \ of \nmitigation strategies, and formulating relevant policies to counteract\
    \ its effects [209]. \n \nFigure 12. Urban heat island illustration. \nAI algorithms\
    \ can analyze various contributing factors, including land use type, ur-\nban\
    \ morphology, and anthropogenic heat emissions, which contribute to the formation\
    \ of \nheat islands. Leveraging this knowledge, geospatial and AI-based models\
    \ can predict the \nimpacts of different urban design and mitigation strategies\
    \ on local temperatures, inform-\ning urban planners and decision makers to make\
    \ informed choices and implement tai-\nlored strategies to combat urban heat islands\
    \ based on the unique characteristics [210]. \n5.8. Precision Water Management\
    \ \nIntegrating weather patterns and soil conditions with AI systems can yield\
    \ accurate \nirrigation recommendations, predict crop water stress, and facilitate\
    \ resource allocation, \nenhancing water use efficiency and conservation. In water\
    \ management applications, par-\nticularly in extracting water bodies from remote\
    \ sensing images, neural network architec-\ntures can be employed for semantic\
    \ segmentation [211–213]. Furthermore, AI algorithms \noffer promising opportunities\
    \ to develop digital image classification methods, specifically \nfor assessing\
    \ water usage in irrigation. These methods utilize multi-temporal image data \n\
    from remote sensing systems such as Landsat and Sentinel-2 to generate comprehensive\
    \ \ncrop maps encompassing various growing seasons. These emerging technologies\
    \ enable \ncost-effective and accurate mapping of irrigated crops, facilitating\
    \ effective water resource \nmanagement [214]. Moreover, Adaptive Intelligent\
    \ Dynamic Water Resource Planning \n(AIDWRP) could be employed to sustain the\
    \ urban areas’ water environment [215]. The \nutilization of Big Data and ML technologies\
    \ also holds the potential to impact many facets \nof environment and water management\
    \ [216]. \nFigure 12. Urban heat island illustration.\nAI algorithms can analyze\
    \ various contributing factors, including land use type, urban\nmorphology, and\
    \ anthropogenic heat emissions, which contribute to the formation of\nheat islands.\
    \ Leveraging this knowledge, geospatial and AI-based models can predict\nthe impacts\
    \ of different urban design and mitigation strategies on local temperatures,\n\
    informing urban planners and decision makers to make informed choices and implement\n\
    tailored strategies to combat urban heat islands based on the unique characteristics\
    \ [210].\n5.8. Precision Water Management\nIntegrating weather patterns and soil\
    \ conditions with AI systems can yield accurate\nirrigation recommendations, predict\
    \ crop water stress, and facilitate resource allocation,\nenhancing water use\
    \ efﬁciency and conservation. In water management applications,\nparticularly\
    \ in extracting water bodies from remote sensing images, neural network archi-\n\
    tectures can be employed for semantic segmentation [211–213]. Furthermore, AI\
    \ algorithms\noffer promising opportunities to develop digital image classiﬁcation\
    \ methods, speciﬁcally\nfor assessing water usage in irrigation. These methods\
    \ utilize multi-temporal image data\nfrom remote sensing systems such as Landsat\
    \ and Sentinel-2 to generate comprehensive\ncrop maps encompassing various growing\
    \ seasons. These emerging technologies enable\ncost-effective and accurate mapping\
    \ of irrigated crops, facilitating effective water resource\nmanagement [214].\
    \ Moreover, Adaptive Intelligent Dynamic Water Resource Planning\n(AIDWRP) could\
    \ be employed to sustain the urban areas’ water environment [215]. The\nutilization\
    \ of Big Data and ML technologies also holds the potential to impact many facets\n\
    of environment and water management [216].\n5.9. Disaster Resilience Planning\n\
    By assessing the exposure and susceptibility of critical infrastructure and communities,\n\
    AI-powered remote sensing can support the development of effective disaster response\n\
    plans, early warning systems, and resilient urban designs [217]. It guides individuals\n\
    during disasters, offering real-time evacuation information, shelter locations,\
    \ and critical\ndetails of the affected areas [218]. AI-enhanced remote sensing\
    \ services and products can\nenhance disaster preparedness awareness, assisting\
    \ emergency agencies in evacuations and\nresource deliveries. Urban Resilience.AI\
    \ Lab researchers use big data for AI models, crucial\nfor mitigation, preparedness,\
    \ and recovery (Urban Resilience.AI Lab). Predictive analytics\nanticipate evacuations\
    \ using seismic and weather data while combining satellite images,\nseismometers,\
    \ and social media veriﬁes disasters for faster responses (AI for Disaster\nResponse,\
    \ AIRD). AI evaluates the damage, allocates resources, and prioritizes recovery\n\
    efforts using satellite imagery [219]. Additionally, AI assesses pre-disaster\
    \ vulnerability,\nutilizing remote sensing data to identify high-risk areas [220].\
    \ These advancements enhance\ndisaster readiness, minimizing impacts on communities\
    \ [221].\n6. Conclusions\nThe integration of AI techniques in remote sensing has\
    \ emerged as a powerful\nparadigm with tremendous potential for practical applications.\
    \ This convergence cre-\nRemote Sens. 2023, 15, 4112\n26 of 34\nates exciting\
    \ opportunities to advance our understanding of Earth’s dynamics, support\ndecision-making\
    \ processes, and foster sustainable development. This review paper pro-\nvides\
    \ a comprehensive overview of the current state of AI in remote sensing, emphasizing\n\
    its signiﬁcance and impact. This paper covers the fundamentals of remote sensing\
    \ tech-\nnologies, including optical remote sensing, radar remote sensing, LiDAR,\
    \ thermal remote\nsensing, and multispectral/HSI. It delves into key AI techniques\
    \ used in remote sensing,\nsuch as conventional ML and deep learning, including\
    \ DCNNs, ResNets, YOLO, Faster\nR-CNN, and self-attention methods. Various practical\
    \ applications of AI in remote sensing\nare discussed in this paper, including\
    \ image classiﬁcation and land cover mapping, object\ndetection and change detection,\
    \ data fusion and integration, and hyperspectral/LiDAR\ndata analysis. These applications\
    \ showcase the effectiveness of AI in enhancing data anal-\nysis, improving accuracy,\
    \ and automating processes. The paper also identiﬁes several\nchallenges: data\
    \ availability, training optimization, data quality, security of sensitive re-\n\
    mote sensing data, uncertainty in real-world scenarios, integrity, and diversity.\
    \ Addressing\nthese challenges requires further research and innovative solutions\
    \ to ensure practical\nimplementation. This paper outlines ongoing and potential\
    \ applications, such as wildﬁre\ndetection and management, illegal logging and\
    \ deforestation monitoring, coastal and ma-\nrine ecosystem monitoring, biodiversity\
    \ conservation and habitat monitoring, airborne\ndisease monitoring and forecasting,\
    \ precision forestry, urban heat island mitigation, pre-\ncision water management,\
    \ and disaster resilience planning. Beyond these applications,\nthere are even\
    \ more possibilities, including precision agriculture optimization, renewable\n\
    energy site selection, disaster management, early warning systems, and urban planning\
    \ and\ninfrastructure development. These envisioned applications highlight the\
    \ transformative\nbeneﬁts of AI in addressing critical challenges and improving\
    \ decision making in diverse\nﬁelds, showcasing its potential to solve environmental\
    \ and societal issues.\nAuthor Contributions: Conceptualization, Z.S. and N.C.;\
    \ methodology, Z.S., B.J. and N.C.; formal\nanalysis, B.J., Z.S. and N.C.; investigation,\
    \ B.J., Z.S. and N.C.; resources, Z.S. and N.C.; data curation,\nB.J. and G.P.A.;\
    \ writing—original draft preparation, B.J. and Z.S.; writing—review and editing,\n\
    B.J., Z.S., N.C. and G.P.A.; visualization, B.J., Z.S. and N.C.; supervision,\
    \ Z.S. and N.C.; project\nadministration, Z.S.; funding acquisition, Z.S. and\
    \ N.C. All authors have read and agreed to the\npublished version of the manuscript.\n\
    Funding: This study was supported by the NASA ACCESS program (#80NSSC21M0028).\
    \ Drs.\nCristea and Sun were supported by the National Science Foundation award\
    \ EAR-1947875 and EAR-\n1947893, and OAC-2117834. N. Cristea was additionally\
    \ supported by the University of Washington\neScience Institute.\nData Availability\
    \ Statement: Not applicable.\nAcknowledgments: Thanks to Lakshmi Chetana Gomaram\
    \ Bikshapathireddy for the help in orga-\nnizing the references.\nConﬂicts of\
    \ Interest: The authors declare no conﬂict of interest.\nReferences\n1.\nCampbell,\
    \ J.B.; Wynne, R.H. Introduction to Remote Sensing; Guilford Press: New York,\
    \ NY, USA, 2011.\n2.\nEarthdata Cloud Evolution. Earthdata. 30 March 2022. Available\
    \ online: https://www.earthdata.nasa.gov/eosdis/cloud-\nevolution (accessed on\
    \ 4 July 2023).\n3.\nJensen, J.R. Remote Sensing of the Environment: An Earth\
    \ Resource Perspective 2/e; Pearson Education: Bangalore, India, 2009.\n4.\nMohan,\
    \ E.; Rajesh, A.; Sunitha, G.; Konduru, R.M.; Avanija, J.; Babu, L.G. A deep neural\
    \ network learning-based speckle noise\nremoval technique for enhancing the quality\
    \ of synthetic-aperture radar images. Concurr. Comput. Pract. Exp. 2021, 33, e6239.\n\
    [CrossRef]\n5.\nZhang, L.; Zhang, L. Artiﬁcial Intelligence for Remote Sensing\
    \ Data Analysis: A review of challenges and opportunities. IEEE\nGeosci. Remote\
    \ Sens. Mag. 2022, 10, 270–294. [CrossRef]\n6.\nLi, J.; Li, Y.; He, L.; Chen,\
    \ J.; Plaza, A. Spatio-temporal fusion for remote sensing data: An overview and\
    \ new benchmark. Sci.\nChina Inf. Sci. 2020, 63, 1–17. [CrossRef]\nRemote Sens.\
    \ 2023, 15, 4112\n27 of 34\n7.\nXu, S.; Cheng, J.; Zhang, Q. A Random Forest-Based\
    \ Data Fusion Method for Obtaining All-Weather Land Surface Temperature\nwith\
    \ High Spatial Resolution. Remote Sens. 2021, 13, 2211. [CrossRef]\n8.\nKinaneva,\
    \ D.; Hristov, G.; Raychev, J.; Zahariev, P. Early Forest Fire Detection Using\
    \ Drones and Artiﬁcial Intelligence. In\nProceedings of the 2019 42nd International\
    \ Convention on Information and Communication Technology, Electronics and\nMicroelectronics\
    \ (MIPRO), Opatija, Croatia, 20–24 May 2019; pp. 1060–1065.\n9.\nGhamisi, P.;\
    \ Rasti, B.; Yokoya, N.; Wang, Q.M.; Hoﬂe, B.; Bruzzone, L.; Bovolo, F.; Chi,\
    \ M.M.; Anders, K.; Gloaguen, R.; et al.\nMultisource and multitemporal data fusion\
    \ in remote sensing a comprehensive review of the state of the art. IEEE Geosci.\
    \ Remote\nSens. Mag. 2019, 7, 6–39. [CrossRef]\n10.\nMo, Y.; Xu, Y.; Liu, Y.;\
    \ Xin, Y.; Zhu, S. Comparison of gap-ﬁlling methods for producing all-weather\
    \ daily remotely sensed\nnear-surface air temperature. Remote Sens. Environ. 2023,\
    \ 296, 113732. [CrossRef]\n11.\nPeng, J.; Loew, A.; Merlin, O.; Verhoest, N.E.C.\
    \ A review of spatial downscaling of satellite remotely sensed soil moisture.\
    \ Rev.\nGeophys. 2017, 55, 341–366. [CrossRef]\n12.\nHong, D.; He, W.; Yokoya,\
    \ N.; Yao, J.; Gao, L.; Zhang, L.; Chanussot, J.; Zhu, X. Interpretable Hyperspectral\
    \ Artiﬁcial Intelligence:\nWhen nonconvex modeling meets hyperspectral remote\
    \ sensing. IEEE Geosci. Remote Sens. Mag. 2021, 9, 52–87. [CrossRef]\n13.\nChen,\
    \ H.; Qi, Z.; Shi, Z. Remote sensing image change detection with transformers.\
    \ IEEE Trans. Geosci. Remote Sens. 2021, 60, 1–14.\n[CrossRef]\n14.\nSun, Z.;\
    \ Sandoval, L.; Crystal-Ornelas, R.; Mousavi, S.M.; Wang, J.; Lin, C.; Cristea,\
    \ N.; Tong, D.; Carande, W.H.; Ma, X.; et al. A\nreview of earth artiﬁcial intelligence.\
    \ Comput. Geosci. 2022, 159, 105034.\n15.\nLe Moigne, J. Artiﬁcial Intelligence\
    \ and Machine Learning for Earth Science. In Proceedings of the 2021 International\
    \ Space\nUniversity (ISU) Alumni Conference, Online, 30 July 2021.\n16.\nSayer,\
    \ A.M.; Govaerts, Y.; Kolmonen, P.; Lipponen, A.; Luffarelli, M.; Mielonen, T.;\
    \ Patadia, F.; Popp, T.; Povey, A.C.; Stebel,\nK.; et al. A review and framework\
    \ for the evaluation of pixel-level uncertainty estimates in satellite aerosol\
    \ remote sensing.\nAtmospheric Meas. Tech. 2020, 13, 373–404. [CrossRef]\n17.\n\
    Lillesand, T.; Kiefer, R.W.; Chipman, J. Remote Sensing and Image Interpretation,\
    \ 5th ed.; John Wiley & Sons: Hobokan, NJ, USA,\n2004; ISBN 0471152277.\n18.\n\
    Gupta, R.P. Remote Sensing Geology; Springer: Berlin/Heidelberg, Germany, 2017;\
    \ ISBN 9783662558744.\n19.\nPrasad, S.; Bruce, L.M.; Chanussot, J. Optical Remote\
    \ Sensing—Advances in Signal Processing and Exploitation Techniques; Springer:\n\
    Berlin/Heidelberg, Germany, 2011.\n20.\nAggarwal, S. Principles of remote sensing.\
    \ Satell. Remote Sens. GIS Appl. Agric. Meteorol. 2004, 23, 23–28.\n21.\nCheng,\
    \ G.; Han, J. A survey on object detection in optical remote sensing images. ISPRS\
    \ J. Photogramm. Remote Sens. 2016, 117,\n11–28. [CrossRef]\n22.\nYang, H.; Nguyen,\
    \ T.-N.; Chuang, T.-W. An Integrative Explainable Artiﬁcial Intelligence Approach\
    \ to Analyze Fine-Scale\nLand-Cover and Land-Use Factors Associated with Spatial\
    \ Distributions of Place of Residence of Reported Dengue Cases. Trop.\nMed. Infect.\
    \ Dis. 2023, 8, 238. [CrossRef]\n23.\nKamarulzaman, A.M.M.; Jaafar, W.S.W.M.;\
    \ Said, M.N.M.; Saad, S.N.M.; Mohan, M. UAV Implementations in Urban Planning\
    \ and\nRelated Sectors of Rapidly Developing Nations: A Review and Future Perspectives\
    \ for Malaysia. Remote Sens. 2023, 15, 2845.\n[CrossRef]\n24.\nPettorelli, N.\
    \ The Normalized Difference Vegetation Index; Oxford University Press: Cary, NC,\
    \ USA, 2013.\n25.\nSun, Z.; Peng, C.; Deng, M.; Chen, A.; Yue, P.; Fang, H.; Di,\
    \ L. Automation of Customized and Near-Real-Time Vegetation\nCondition Index Generation\
    \ Through Cyberinfrastructure-Based Geoprocessing Workﬂows. IEEE J. Sel. Top.\
    \ Appl. Earth Obs.\nRemote Sens. 2014, 7, 4512–4522. [CrossRef]\n26.\nGholizadeh,\
    \ A.; Kopaˇcková, V. Detecting vegetation stress as a soil contamination proxy:\
    \ A review of optical proximal and remote\nsensing techniques. Int. J. Environ.\
    \ Sci. Technol. 2019, 16, 2511–2524. [CrossRef]\n27.\nStone, M.L.; Solie, J.B.;\
    \ Raun, W.R.; Whitney, R.W.; Taylor, S.L.; Ringer, J.D. Use of Spectral Radiance\
    \ for Correcting In-season\nFertilizer Nitrogen Deﬁciencies in Winter Wheat. Trans.\
    \ ASAE 1996, 39, 1623–1631. [CrossRef]\n28.\nOsborne, S.L.; Schepers, J.S.; Francis,\
    \ D.D.; Schlemmer, M.R. Detection of Phosphorus and Nitrogen Deﬁciencies in Corn\
    \ Using\nSpectral Radiance Measurements. Agron. J. 2002, 94, 1215–1221. [CrossRef]\n\
    29.\nCannistra, A.F.; Shean, D.E.; Cristea, N.C. High-resolution CubeSat imagery\
    \ and machine learning for detailed snow-covered\narea. Remote Sens. Environ.\
    \ 2021, 258, 112399. [CrossRef]\n30.\nJohn, A.; Cannistra, A.F.; Yang, K.; Tan,\
    \ A.; Shean, D.; Lambers, J.H.R.; Cristea, N. High-Resolution Snow-Covered Area\
    \ Mapping\nin Forested Mountain Ecosystems Using PlanetScope Imagery. Remote Sens.\
    \ 2022, 14, 3409. [CrossRef]\n31.\nRichards, J.A. Remote Sensing with Imaging\
    \ Radar; Springer: Berlin/Heidelberg, Germany, 2009; Volume 1. [CrossRef]\n32.\n\
    Dinh, H.T.M.; Hanssen, R.; Rocca, F. Radar interferometry: 20 years of development\
    \ in time series techniques and future\nperspectives. Remote Sens. 2020, 121,\
    \ 1364.\n33.\nOguchi, T.; Hayakawa, Y.S.; Wasklewicz, T. Remote Data in Fluvial\
    \ Geomorphology: Characteristics and Applications. In Treatise\non Geomorphology;\
    \ Elsevier: Amsterdam, The Netherlands, 2022; pp. 1116–1142.\n34.\nMoreira, A.;\
    \ Prats-Iraola, P.; Younis, M.; Krieger, G.; Hajnsek, I.; Papathanassiou, K.P.\
    \ A tutorial on synthetic aperture radar. IEEE\nGeosci. Remote Sens. Mag. 2013,\
    \ 1, 6–43. [CrossRef]\nRemote Sens. 2023, 15, 4112\n28 of 34\n35.\nDevaney, J.;\
    \ Barrett, B.; Barrett, F.; Redmond, J.; O’halloran, J. Forest Cover Estimation\
    \ in Ireland Using Radar Remote Sensing: A\nComparative Analysis of Forest Cover\
    \ Assessment Methodologies. PLoS ONE 2015, 10, e0133583. [CrossRef]\n36.\nDubayah,\
    \ R.O.; Drake, J.B. Lidar remote sensing for forestry. J. For. 2000, 98, 44–46.\n\
    37.\nDassot, M.; Constant, T.; Fournier, M. The use of terrestrial LiDAR technology\
    \ in forest science: Application ﬁelds, beneﬁts and\nchallenges. Ann. For. Sci.\
    \ 2011, 68, 959–974. [CrossRef]\n38.\nDeems, J.S.; Painter, T.H.; Finnegan, D.C.\
    \ Lidar measurement of snow depth: A review. J. Glaciol. 2013, 59, 467–479. [CrossRef]\n\
    39.\nDisney, M.; Kalogirou, V.; Lewis, P.; Prieto-Blanco, A.; Hancock, S.; Pfeifer,\
    \ M. Simulating the impact of discrete-return lidar\nsystem and survey characteristics\
    \ over young conifer and broadleaf forests. Remote Sens. Environ. 2010, 114, 1546–1560.\
    \ [CrossRef]\n40.\nPrakash, A. Thermal remote sensing: Concepts, issues and applications.\
    \ Int. Arch. Photogramm. Remote Sens. 2000, 33, 239–243.\n41.\nBakker, W.H.; Feringa,\
    \ W.; Gieske, A.S.M.; Gorte, B.G.H.; Grabmaier, K.A.; Hecker, C.A.; Horn, J.A.;\
    \ Huurneman, G.C.; Janssen,\nL.L.F.; Kerle, N.; et al. Thermal Remote Sensing;\
    \ Humboldt.Edu: Arcata, CA, USA, 2009.\n42.\nAllison, R.S.; Johnston, J.M.; Craig,\
    \ G.; Jennings, S. Airborne Optical and Thermal Remote Sensing for Wildﬁre Detection\
    \ and\nMonitoring. Sensors 2016, 16, 1310. [CrossRef]\n43.\nVoogt, J.A.; Oke,\
    \ T.R. Thermal remote sensing of urban climates. Remote Sens. Environ. 2003, 86,\
    \ 370–384. [CrossRef]\n44.\nShaw, G.A.; Burke, H.K. Spectral imaging for remote\
    \ sensing. Linc. Lab. J. 2003, 14, 3–28.\n45.\nManolakis, D.G.; Lockwood, R.B.;\
    \ Cooley, T.W. Hyperspectral Imaging Remote Sensing: Physics, Sensors, and Algorithms;\
    \ Cambridge\nUniversity Press: Cambridge, UK, 2016.\n46.\nSun, W.; Du, Q. Hyperspectral\
    \ band selection: A review. IEEE Geosci. Remote Sens. Mag. 2019, 7, 118–139. [CrossRef]\n\
    47.\nDong, P.; Chen, Q. LiDAR Remote Sensing and Applications; CRC Press: Boca\
    \ Raton, FL, USA, 2017.\n48.\nWeiss, M.; Jacob, F.; Duveiller, G. Remote sensing\
    \ for agricultural applications: A meta-review. Remote Sens. Environ. 2020,\n\
    236, 111402. [CrossRef]\n49.\nGhosh, A.; Fassnacht, F.E.; Joshi, P.K.; Koch, B.\
    \ A framework for mapping tree species combining hyperspectral and LiDAR data:\n\
    Role of selected classiﬁers and sensor across three spatial scales. Int. J. Appl.\
    \ Earth Obs. Geoinf. 2014, 26, 49–63. [CrossRef]\n50.\nLary, D.J.; Alavi, A.H.;\
    \ Gandomi, A.H.; Walker, A.L. Machine learning in geosciences and remote sensing.\
    \ Geosci. Front. 2016, 7,\n3–10. [CrossRef]\n51.\nSarker, I.H. Deep Learning:\
    \ A Comprehensive Overview on Techniques, Taxonomy, Applications and Research\
    \ Directions. SN\nComput. Sci. 2021, 2, 420. [CrossRef]\n52.\nSun, Z.; Cristea,\
    \ N.; Tong, D.; Tullis, J.; Chester, Z.; Magill, A. A review of cyberinfrastructure\
    \ for machine learning and big data\nin the geosciences. Recent Adv. Geoinformatics\
    \ Data Sci. 2023, 558, 161. [CrossRef]\n53.\nSun, Z.; Cristea, N.; Rivas, P. (Eds.)\
    \ Artiﬁcial Intelligence in Earth Science: Best Practices and Fundamental Challenges;\
    \ Elsevier-Health\nSciences Division: Amsterdam, The Netherlands, 2023.\n54.\n\
    Saini, R.; Ghosh, S. Ensemble classiﬁers in remote sensing: A review. In Proceedings\
    \ of the 2017 International Conference on\nComputing, Communication and Automation\
    \ (ICCCA), Greater Noida, India, 5–6 May 2017; pp. 1148–1152. [CrossRef]\n55.\n\
    Miao, X.; Heaton, J.S.; Zheng, S.; Charlet, D.A.; Liu, H. Applying tree-based\
    \ ensemble algorithms to the classiﬁcation of ecological\nzones using multi-temporal\
    \ multi-source remote-sensing data. Int. J. Remote Sens. 2011, 33, 1823–1849.\
    \ [CrossRef]\n56.\nZhang, Y.; Liu, J.; Shen, W. A Review of Ensemble Learning\
    \ Algorithms Used in Remote Sensing Applications. Appl. Sci. 2022, 12,\n8654.\
    \ [CrossRef]\n57.\nBreiman, L. Bagging predictors. Mach. Learn. 1996, 24, 123–140.\
    \ [CrossRef]\n58.\nSchapire, R.E. A Brief Introduction to Boosting. Psu.Edu. 1999.\
    \ Available online: https://citeseerx.ist.psu.edu/document?repid=\nrep1&type=pdf&doi=fa329f834e834108ccdc536db85ce368fee227ce\
    \ (accessed on 4 August 2023).\n59.\nFreund, Y.; Schapire, R.E. A Decision-Theoretic\
    \ Generalization of On-Line Learning and an Application to Boosting. J. Comput.\n\
    Syst. Sci. 1997, 55, 119–139. [CrossRef]\n60.\nBreiman, L. Random forests. Mach.\
    \ Learn. 2001, 45, 5–32. [CrossRef]\n61.\nPal, M. Random forest classiﬁer for\
    \ remote sensing classiﬁcation. Int. J. Remote Sens. 2005, 26, 217–222. [CrossRef]\n\
    62.\nGislason, P.O.; Benediktsson, J.A.; Sveinsson, J.R. Random Forests for land\
    \ cover classiﬁcation. Pattern Recognit. Lett. 2006, 27,\n294–300. [CrossRef]\n\
    63.\nRodriguez-Galiano, V.F.; Ghimire, B.; Rogan, J.; Chica-Olmo, M.; Rigol-Sanchez,\
    \ J.P. An assessment of the effectiveness of a\nrandom forest classiﬁer for land-cover\
    \ classiﬁcation. ISPRS J. Photogramm. Remote Sens. 2012, 67, 93–104. [CrossRef]\n\
    64.\nMascaro, J.; Asner, G.P.; Knapp, D.E.; Kennedy-Bowdoin, T.; Martin, R.E.;\
    \ Anderson, C.; Higgins, M.; Chadwick, K.D. A Tale of\nTwo “Forests”: Random Forest\
    \ Machine Learning Aids Tropical Forest Carbon Mapping. PLoS ONE 2014, 9, e85993.\
    \ [CrossRef]\n[PubMed]\n65.\nPhan, T.N.; Kuch, V.; Lehnert, L.W. Land Cover Classiﬁcation\
    \ using Google Earth Engine and Random Forest Classiﬁer—The\nRole of Image Composition.\
    \ Remote Sens. 2020, 12, 2411. [CrossRef]\n66.\nYang, K.; John, A.; Shean, D.;\
    \ Lundquist, J.D.; Sun, Z.; Yao, F.; Todoran, S.; Cristea, N. High-resolution\
    \ mapping of snow cover in\nmontane meadows and forests using Planet imagery and\
    \ machine learning. Front. Water 2023, 5, 1128758. [CrossRef]\n67.\nRittger, K.;\
    \ Krock, M.; Kleiber, W.; Bair, E.H.; Brodzik, M.J.; Stephenson, T.R.; Rajagopalan,\
    \ B.; Bormann, K.J.; Painter, T.H.\nMulti-sensor fusion using random forests for\
    \ daily fractional snow cover at 30 m. Remote Sens. Environ. 2021, 264, 112608.\n\
    [CrossRef]\nRemote Sens. 2023, 15, 4112\n29 of 34\n68.\nHam, J.; Chen, Y.; Crawford,\
    \ M.M.; Ghosh, J. Investigation of the random forest framework for classiﬁcation\
    \ of hyperspectral\ndata. IEEE Trans. Geosci. Remote Sens. 2005, 43, 492–501.\
    \ [CrossRef]\n69.\nSabat-Tomala, A.; Raczko, E.; Zagajewski, B. Comparison of\
    \ Support Vector Machine and Random Forest Algorithms for Invasive\nand Expansive\
    \ Species Classiﬁcation Using Airborne Hyperspectral Data. Remote Sens. 2020,\
    \ 12, 516. [CrossRef]\n70.\nBelgiu, M.; Drăgu¸t, L. Random forest in remote sensing:\
    \ A review of applications and future directions. ISPRS J. Photogramm.\nRemote\
    \ Sens. 2016, 114, 24–31. [CrossRef]\n71.\nBehnamian, A.; Banks, S.; White, L.;\
    \ Millard, K.; Pouliot, D.; Pasher, J.; Duffe, J. Dimensionality Reduction in\
    \ The Presence of\nHighly Correlated Variables for Random Forests: Wetland Case\
    \ Study. In Proceedings of the IGARSS 2019–2019 IEEE International\nGeoscience\
    \ and Remote Sensing Symposium, Yokohama, Japan, 28 July–2 August 2019; pp. 9839–9842.\
    \ [CrossRef]\n72.\nGeorganos, S.; Grippa, T.; Vanhuysse, S.; Lennert, M.; Shimoni,\
    \ M.; Kalogirou, S.; Wolff, E. Less is more: Optimizing classiﬁcation\nperformance\
    \ through feature selection in a very-high-resolution remote sensing object-based\
    \ urban application. GIScience Remote\nSens. 2017, 55, 221–242. [CrossRef]\n73.\n\
    Millard, K.; Richardson, M. On the Importance of Training Data Sample Selection\
    \ in Random Forest Image Classiﬁcation: A Case\nStudy in Peatland Ecosystem Mapping.\
    \ Remote Sens. 2015, 7, 8489–8515. [CrossRef]\n74.\nChen, T.; Carlos, G. XGBoost:\
    \ A Scalable Tree Boosting System. arXiv 2016, arXiv:1603.02754.\n75.\nGhatkar,\
    \ J.G.; Singh, R.K.; Shanmugam, P. Classiﬁcation of algal bloom species from remote\
    \ sensing data using an extreme\ngradient boosted decision tree model. Int. J.\
    \ Remote Sens. 2019, 40, 9412–9438. [CrossRef]\n76.\nMountrakis, G.; Im, J.; Ogole,\
    \ C. Support vector machines in remote sensing: A review. ISPRS J. Photogramm.\
    \ Remote Sens. 2011,\n66, 247–259. [CrossRef]\n77.\nKavzoglu, T.; Colkesen, I.\
    \ A kernel functions analysis for support vector machines for land cover classiﬁcation.\
    \ Int. J. Appl. Earth\nObs. Geoinf. 2009, 11, 352–359. [CrossRef]\n78.\nSheykhmousa,\
    \ M.; Mahdianpari, M.; Ghanbari, H.; Mohammadimanesh, F.; Ghamisi, P.; Homayouni,\
    \ S. Support Vector Machine\nVersus Random Forest for Remote Sensing Image Classiﬁcation:\
    \ A Meta-Analysis and Systematic Review. IEEE J. Sel. Top. Appl.\nEarth Obs. Remote\
    \ Sens. 2020, 13, 6308–6325. [CrossRef]\n79.\nZhu, J.-Y.; Park, T.; Isola, P.;\
    \ Efros, A.A. Unpaired image-to-image translation using cycle-consistent adversarial\
    \ networks. arXiv\n2017, arXiv:1703.10593.\n80.\nMa, L.; Liu, Y.; Zhang, X.; Ye,\
    \ Y.; Yin, G.; Johnson, B.A. Deep learning in remote sensing applications: A meta-analysis\
    \ and review.\nISPRS J. Photogramm. Remote Sens. 2019, 152, 166–177. [CrossRef]\n\
    81.\nYuan, Q.; Shen, H.; Li, T.; Li, Z.; Li, S.; Jiang, Y.; Xu, H.; Tan, W.; Yang,\
    \ Q.; Wang, J.; et al. Deep learning in environmental remote\nsensing: Achievements\
    \ and challenges. Remote Sens. Environ. 2020, 241, 111716. [CrossRef]\n82.\nGoodfellow,\
    \ I.; Bengio, Y.; Courville, A. Deep Learning; MIT Press: Cambridge, MA, USA,\
    \ 2016.\n83.\nZhang, L.; Zhang, L.; Du, B. Deep Learning for Remote Sensing Data:\
    \ A Technical Tutorial on the State of the Art. IEEE Geosci.\nRemote Sens. Mag.\
    \ 2016, 4, 22–40. [CrossRef]\n84.\nTraore, B.B.; Kamsu-Foguem, B.; Tangara, F.\
    \ Deep convolution neural network for image recognition. Ecol. Inform. 2018, 48,\n\
    257–268. [CrossRef]\n85.\nChen, L.; Li, S.; Bai, Q.; Yang, J.; Jiang, S.; Miao,\
    \ Y. Review of Image Classiﬁcation Algorithms Based on Convolutional Neural\n\
    Networks. Remote Sens. 2021, 13, 4712. [CrossRef]\n86.\nAgarap, A.F. Deep learning\
    \ using rectiﬁed linear units (relu). arXiv 2018, arXiv:1803.08375.\n87.\nAloysius,\
    \ N.; Geetha, M. A review on deep convolutional neural networks. In Proceedings\
    \ of the 2017 International Conference\non Communication and Signal Processing\
    \ (ICCSP), Chennai, India, 6–8 April 2017; pp. 0588–0592.\n88.\nDubey, A.K.; Jain,\
    \ V. Comparative Study of Convolution Neural Network’s ReLu and Leaky-ReLu Activation\
    \ Functions. In\nApplications of Computing, Automation and Wireless Systems in\
    \ Electrical Engineering; Springer: Singapore, 2019; pp. 873–880.\n89.\nZhang,\
    \ Y.-D.; Pan, C.; Sun, J.; Tang, C. Multiple sclerosis identiﬁcation by convolutional\
    \ neural network with dropout and\nparametric ReLU. J. Comput. Sci. 2018, 28,\
    \ 1–10. [CrossRef]\n90.\nRonneberger, O.; Fischer, P.; Brox, T. U-Net: Convolutional\
    \ networks for biomedical image segmentation.\narXiv 2015,\narXiv:1505.04597.\n\
    91.\nBadrinarayanan, V.; Kendall, A.; Cipolla, R. Segnet: A deep convolutional\
    \ encoder-decoder architecture for image segmentation.\nIEEE Trans. Pattern Anal.\
    \ Mach. Intell. 2017, 39, 2481–2495. [CrossRef] [PubMed]\n92.\nAlom, M.Z.; Taha,\
    \ T.M.; Yakopcic, C.; Westberg, S.; Sidike, P.; Nasrin, M.S.; Van Esesn, B.C.;\
    \ Awwal, A.A.S.; Asari, V.K. The history\nbegan from alexnet: A comprehensive\
    \ survey on deep learning approaches. arXiv 2018, arXiv:1803.01164.\n93.\nChen,\
    \ L.-C.; Papandreou, G.; Kokkinos, I.; Murphy, K.; Yuille, A.L. DeepLab: Semantic\
    \ Image Segmentation with Deep\nConvolutional Nets, Atrous Convolution, and Fully\
    \ Connected CRFs. arXiv 2016, arXiv:1606.00915. [CrossRef] [PubMed]\n94.\nZhao,\
    \ Y.; Zhang, X.; Feng, W.; Xu, J. Deep Learning Classiﬁcation by ResNet-18 Based\
    \ on the Real Spectral Dataset from\nMultispectral Remote Sensing Images. Remote\
    \ Sens. 2022, 14, 4883. [CrossRef]\n95.\nHe, K.; Zhang, X.; Ren, S.; Sun, J. Deep\
    \ Residual Learning for Image Recognition. In Proceedings of the 2016 IEEE Conference\
    \ on\nComputer Vision and Pattern Recognition (CVPR), Las Vegas, NV, USA, 27–30\
    \ June 2016; pp. 770–778.\n96.\nLi, H.; Wu, X.-J.; Durrani, T.S. Infrared and\
    \ visible image fusion with ResNet and zero-phase component analysis. Infrared\
    \ Phys.\nTechnol. 2019, 102, 103039. [CrossRef]\nRemote Sens. 2023, 15, 4112\n\
    30 of 34\n97.\nRedmon, J.; Divvala, S.; Girshick, R.; Farhadi, A. You Only Look\
    \ Once: Uniﬁed, Real-Time Object Detection. arXiv 2015,\narXiv:1506.02640.\n98.\n\
    Redmon, J. Darknet: Open Source Neural Networks in C. Pjreddie.Com. 2013. Available\
    \ online: https://pjreddie.com/darknet/\n(accessed on 4 August 2023).\n99.\nWu,\
    \ Z.; Chen, X.; Gao, Y.; Li, Y. Rapid Target Detection in High Resolution Remote\
    \ Sensing Images Using Yolo Model. ISPRS Int.\nArch. Photogramm. Remote Sens.\
    \ Spat. Inf. Sci. 2018, 42, 1915–1920. [CrossRef]\n100. Redmon, J.; Farhadi, A.\
    \ YOLO9000: Better, Faster, Stronger. arXiv 2016, arXiv:1612.08242.\n101. Xu,\
    \ D.; Wu, Y. Improved YOLO-V3 with DenseNet for Multi-Scale Remote Sensing Target\
    \ Detection. Sensors 2020, 20, 4276.\n[CrossRef]\n102. Yang, F. An improved YOLO\
    \ v3 algorithm for remote Sensing image target detection. J. Phys. Conf. Ser.\
    \ 2021, 2132, 012028.\n[CrossRef]\n103. Redmon, J.; Farhadi, A. Yolov3: An incremental\
    \ improvement. arXiv 2018, arXiv:1804.02767.\n104. Jiang, P.; Ergu, D.; Liu, F.;\
    \ Cai, Y.; Ma, B. A Review of Yolo Algorithm Developments. Procedia Comput. Sci.\
    \ 2022, 199, 1066–1073.\n[CrossRef]\n105. Terven, J.; Cordova-Esparza, D. A Comprehensive\
    \ Review of YOLO: From YOLOv1 and Beyond. arXiv 2023, arXiv:2304.00501.\n106.\
    \ Ren, S.; He, K.; Girshick, R.; Sun, J. Faster R-CNN: Towards real-time object\
    \ detection with region proposal networks. arXiv 2015,\narXiv:1506.01497. [CrossRef]\n\
    107. Girshick, R. Fast r-cnn. In Proceedings of the IEEE International Conference\
    \ on Computer Vision, Santiago, Chile, 13–16 December\n2015; pp. 1440–1448.\n\
    108. Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A.N.;\
    \ Kaiser, L.; Polosukhin, I. Attention Is All You Need.\narXiv 2017, arXiv:1706.03762.\n\
    109. Aleissaee, A.A.; Kumar, A.; Anwer, R.M.; Khan, S.; Cholakkal, H.; Xia, G.-S.;\
    \ Khan, F.S. Transformers in Remote Sensing: A\nSurvey. Remote Sens. 2023, 15,\
    \ 1860. [CrossRef]\n110. Devlin, J.; Chang, M.W.; Lee, K.; Toutanova, K. Bert:\
    \ Pre-training of deep bidirectional transformers for language understanding.\n\
    arXiv 2018, arXiv:1810.04805.\n111. He, J.; Zhao, L.; Yang, H.; Zhang, M.; Li,\
    \ W. HSI-BERT: Hyperspectral Image Classiﬁcation Using the Bidirectional Encoder\n\
    Representation from Transformers. IEEE Trans. Geosci. Remote Sens. A Publ. IEEE\
    \ Geosci. Remote Sens. Soc. 2020, 58, 165–178.\n[CrossRef]\n112. Hochreiter, S.;\
    \ Schmidhuber, J. Long short-term memory. Neural Comput. 1997, 9, 1735–1780. [CrossRef]\n\
    113. Sun, Z.; Di, L.; Fang, H. Using long short-term memory recurrent neural network\
    \ in land cover classiﬁcation on Landsat and\nCropland data layer time series.\
    \ Int. J. Remote Sens. 2018, 40, 593–614. [CrossRef]\n114. Graves, A.; Graves,\
    \ A. Long short-term memory. In Supervised Sequence Labelling with Recurrent Neural\
    \ Networks; Springer:\nBerlin/Heidelberg, Germany, 2012; pp. 37–45.\n115. Goodfellow,\
    \ I.J.; Pouget-Abadie, J.; Mirza, M.; Xu, B.; Warde-Farley, D.; Ozair, S.; Courville,\
    \ A.; Bengio, Y. Generative Adversarial\nNets. Neurips.Cc. 2014. Available online:\
    \ https://proceedings.neurips.cc/paper_ﬁles/paper/2014/ﬁle/5ca3e9b122f61f8f064\n\
    94c97b1afccf3-Paper.pdf (accessed on 7 August 2023).\n116. Ankan, D.; Ye, J.;\
    \ Wang, G. A Review of Generative Adversarial Networks (GANs) and Its Applications\
    \ in a Wide Variety of\nDisciplines—From Medical to Remote Sensing. arXiv 2021,\
    \ arXiv:2110.01442.\n117. Jozdani, S.; Chen, D.; Pouliot, D.; Johnson, B.A. A\
    \ review and meta-analysis of Generative Adversarial Networks and their\napplications\
    \ in remote sensing. Int. J. Appl. Earth Obs. Geoinf. 2022, 108, 102734. [CrossRef]\n\
    118. Creswell, A.; White, T.; Dumoulin, V.; Arulkumaran, K.; Sengupta, B.; Bharath,\
    \ A.A. Generative Adversarial Networks: An\nOverview. IEEE Signal Process. Mag.\
    \ 2018, 35, 53–65. [CrossRef]\n119. Xu, C.; Zhao, B. Satellite Image Spooﬁng:\
    \ Creating Remote Sensing Dataset with Generative Adversarial Networks (Short\
    \ Paper); Schloss\nDagstuhl—Leibniz-Zentrum fuer Informatik GmbH.: Wadern/Saarbruecken,\
    \ Germany, 2018.\n120. Zi, Y.; Xie, F.; Song, X.; Jiang, Z.; Zhang, H. Thin Cloud\
    \ Removal for Remote Sensing Images Using a Physical-Model-Based\nCycleGAN With\
    \ Unpaired Data. IEEE Geosci. Remote Sens. Lett. 2021, 19, 1–5. [CrossRef]\n121.\
    \ Ledig, C.; Theis, L.; Huszár, F.; Caballero, J.; Cunningham, A.; Acosta, A.;\
    \ Aitken, A.P.; Tejani, A.; Totz, J.; Wang, Z.; et al.\nPhoto-Realistic Single\
    \ Image Super-Resolution Using a Generative Adversarial Network. In Proceedings\
    \ of the 2017 IEEE\nConference on Computer Vision and Pattern Recognition (CVPR),\
    \ Honolulu, HI, USA, 21–26 July 2017; pp. 105–114.\n122. Isola, P.; Zhu, J.-Y.;\
    \ Zhou, T.; Efros, A.A. Image-to-Image Translation with Conditional Adversarial\
    \ Networks. arXiv 2017,\narXiv:1611.07004.\n123. Sun, H.; Wang, P.; Chang, Y.;\
    \ Qi, L.; Wang, H.; Xiao, D.; Zhong, C.; Wu, X.; Li, W.; Sun, B. HRPGAN: A GAN-based\
    \ Model to\nGenerate High-resolution Remote Sensing Images. IOP Conf. Series Earth\
    \ Environ. Sci. 2020, 428, 012060. [CrossRef]\n124. Lin, D.; Fu, K.; Wang, Y.;\
    \ Xu, G.; Sun, X. MARTA GANs: Unsupervised Representation Learning for Remote\
    \ Sensing Image\nClassiﬁcation. IEEE Geosci. Remote Sens. Lett. 2017, 14, 2092–2096.\
    \ [CrossRef]\n125. Liu, X.; Wang, Y.; Liu, Q. Psgan: A Generative Adversarial\
    \ Network for Remote Sensing Image Pan-Sharpening. In Proceedings\nof the 2018\
    \ 25th IEEE International Conference on Image Processing (ICIP), Athens, Greece,\
    \ 7–10 October 2018; pp. 873–877.\n126. Hu, A.; Xie, Z.; Xu, Y.; Xie, M.; Wu,\
    \ L.; Qiu, Q. Unsupervised Haze Removal for High-Resolution Optical Remote-Sensing\
    \ Images\nBased on Improved Generative Adversarial Networks. Remote Sens. 2020,\
    \ 12, 4162. [CrossRef]\nRemote Sens. 2023, 15, 4112\n31 of 34\n127. Singh, P.;\
    \ Komodakis, N. Cloud-Gan: Cloud Removal for Sentinel-2 Imagery Using a Cyclic\
    \ Consistent Generative Adversarial\nNetworks. In Proceedings of the IGARSS 2018—2018\
    \ IEEE International Geoscience and Remote Sensing Symposium, Valencia,\nSpain,\
    \ 22–27 July 2018; pp. 1772–1775. [CrossRef]\n128. Arulkumaran, K.; Deisenroth,\
    \ M.P.; Brundage, M.; Bharath, A.A. Deep Reinforcement Learning: A Brief Survey.\
    \ IEEE Signal\nProcess. Mag. 2017, 34, 26–38. [CrossRef]\n129. Li, Y. Deep Reinforcement\
    \ Learning: An Overview. arXiv 2017, arXiv:1701.07274.\n130. Mou, L.; Saha, S.;\
    \ Hua, Y.; Bovolo, F.; Bruzzone, L.; Zhu, X.X. Deep Reinforcement Learning for\
    \ Band Selection in Hyperspectral\nImage Classiﬁcation. IEEE Trans. Geosci. Remote.\
    \ Sens. 2021, 60, 1–14. [CrossRef]\n131. Fu, K.; Li, Y.; Sun, H.; Yang, X.; Xu,\
    \ G.; Li, Y.; Sun, X. A Ship Rotation Detection Model in Remote Sensing Images\
    \ Based on\nFeature Fusion Pyramid Network and Deep Reinforcement Learning. Remote\
    \ Sens. 2018, 10, 1922. [CrossRef]\n132. Filar, J.; Vrieze, K. Competitive Markov\
    \ Decision Processes; Springer Science & Business Media: New York, NY, USA, 2012.\
    \ [CrossRef]\n133. Maxwell, A.E.; Warner, T.A.; Fang, F. Implementation of machine-learning\
    \ classiﬁcation in remote sensing: An applied review.\nInt. J. Remote Sens. 2018,\
    \ 39, 2784–2817. [CrossRef]\n134. Li, Y.; Zhang, H.; Xue, X.; Jiang, Y.; Shen,\
    \ Q. Deep learning for remote sensing image classiﬁcation: A survey. WIREs Data\
    \ Min.\nKnowl. Discov. 2018, 8, e1264. [CrossRef]\n135. Song, J.; Gao, S.; Zhu,\
    \ Y.; Ma, C. A survey of remote sensing image classiﬁcation based on CNNs. Big\
    \ Earth Data 2019, 3, 232–254.\n[CrossRef]\n136. Methodology & Accuracy Summary\
    \ 10m Global Land Use Land Cover Maps. Impactobservatory.Com. 2022. Available\
    \ online:\nhttps://www.impactobservatory.com/static/lulc_methodology_accuracy-ee742a0a389a85a0d4e7295941504ac2.pdf\
    \ (accessed on\n29 June 2023).\n137. AI Enables Rapid Creation of Global Land\
    \ Cover Map. Esri. 7 September 2021. Available online: https://www.esri.com/about/\n\
    newsroom/arcuser/ai-enables-rapid-creation-of-global-land-cover-map/ (accessed\
    \ on 5 July 2023).\n138. SpaceKnow. GEMSTONE CASE STUDY: Global Economic Monitoring\
    \ Using Satellite Data and AI/ML Technology. Medium.\n25 April 2022. Available\
    \ online: https://spaceknow.medium.com/gemstone-case-study-global-economic-monitoring-using-\n\
    satellite-data-and-ai-ml-technology-6526c336bf18 (accessed on 29 June 2023).\n\
    139. Qi, W. Object detection in high resolution optical image based on deep learning\
    \ technique. Nat. Hazards Res. 2022, 2, 384–392.\n[CrossRef]\n140. Yang, W.; Song,\
    \ H.; Du, L.; Dai, S.; Xu, Y. A Change Detection Method for Remote Sensing Images\
    \ Based on Coupled Dictionary\nand Deep Learning. Comput. Intell. Neurosci. 2022,\
    \ 2022, 3404858. [CrossRef] [PubMed]\n141. Schmitt, M.; Zhu, X.X. Data Fusion\
    \ and Remote Sensing: An ever-growing relationship. IEEE Geosci. Remote Sens.\
    \ Mag. 2016, 4,\n6–23. [CrossRef]\n142. Floodly AI. Esa.Int. 15 January 2021.\
    \ Available online: https://business.esa.int/projects/ﬂoodly-ai (accessed on 29\
    \ June 2023).\n143. Paganini, M.; Wyniawskyj, N.; Talon, P.; White, S.; Watson,\
    \ G.; Petit, D. Total Ecosystem Management of the InterTidal Habitat\n(TEMITH).\
    \ Esa.Int. 12 September 2020. Available online: https://eo4society.esa.int/wp-content/uploads/2021/06/TEMITH-\n\
    DMU-TEC-ESR01-11-E_Summary_Report.pdf (accessed on 5 July 2023).\n144. Zhong,\
    \ H.; Lin, W.; Liu, H.; Ma, N.; Liu, K.; Cao, R.; Wang, T.; Ren, Z. Identiﬁcation\
    \ of tree species based on the fusion of UAV\nhyperspectral image and LiDAR data\
    \ in a coniferous and broad-leaved mixed forest in Northeast China. Front. Plant\
    \ Sci. 2022, 13,\n964769. [CrossRef]\n145. Woodie, A. AI Opens Door to Expanded\
    \ Use of LIDAR Data. Datanami. 17 September 2020. Available online: https://www.\n\
    datanami.com/2020/09/17/ai-opens-door-to-expanded-use-of-lidar-data/ (accessed\
    \ on 5 July 2023).\n146. Technology. Metaspectral. 20 September 2022. Available\
    \ online: https://metaspectral.com/technology/ (accessed on 29 June\n2023).\n\
    147. Redins, L. Metaspectral’s AI Platform Uses Hyperspectral Imaging, Edge Computing\
    \ to Transform Space, Recycling and Other\nIndustries. 26 January 2023. Available\
    \ online: https://www.edgeir.com/metaspectrals-ai-platform-uses-hyperspectral-imaging-\n\
    edge-computing-to-transform-space-recycling-and-other-industries-20230125 (accessed\
    \ on 5 July 2023).\n148. Skulovich, O.; Gentine, P. A Long-term Consistent Artiﬁcial\
    \ Intelligence and Remote Sensing-based Soil Moisture Dataset. Sci.\nData 2023,\
    \ 10, 154. [CrossRef] [PubMed]\n149. Esen, Berivan, and Jonathan Wentworth. 2020.\
    \ “Remote Sensing and Machine Learning.” Parliament.Uk. 19 June 2020. Available\n\
    online: https://post.parliament.uk/research-brieﬁngs/post-pn-0628/ (accessed on\
    \ 5 July 2023).\n150. Holland, S.; Hosny, A.; Newman, S.; Joseph, J.; Chmielinski,\
    \ K. The dataset nutrition label. Data Prot. Priv. 2020, 12, 1.\n151. Verbesselt,\
    \ J.; Zeileis, A.; Herold, M. Near real-time disturbance detection using satellite\
    \ image time series. Remote Sens. Environ.\n2012, 123, 98–108. [CrossRef]\n152.\
    \ Dörnhöfer, K.; Oppelt, N. Remote sensing for lake research and monitoring—Recent\
    \ advances. Ecol. Indic. 2016, 64, 105–122.\n[CrossRef]\n153. Engel-Cox, J.A.;\
    \ Hoff, R.M.; Haymet, A. Recommendations on the Use of Satellite Remote-Sensing\
    \ Data for Urban Air Quality.\nJ. Air Waste Manag. Assoc. 2004, 54, 1360–1371.\
    \ [CrossRef]\n154. Wang, Q.; Ma, Y.; Zhao, K.; Tian, Y. A Comprehensive Survey\
    \ of Loss Functions in Machine Learning. Ann. Data Sci. 2020, 9,\n187–212. [CrossRef]\n\
    Remote Sens. 2023, 15, 4112\n32 of 34\n155. Kotsiantis, S.B.; Pintelas, P.E. Mixture\
    \ of expert agents for handling imbalanced data sets. Ann. Math. Comput. Teleinform.\
    \ 2003,\n1, 46–55.\n156. Alzubaidi, L.; Zhang, J.; Humaidi, A.J.; Al-Dujaili,\
    \ A.; Duan, Y.; Al-Shamma, O.; Santamaría, J.; Fadhel, M.A.; Al-Amidie, M.;\n\
    Farhan, L. Review of deep learning: Concepts, CNN architectures, challenges, applications,\
    \ future directions. J. Big Data 2021, 8,\n1–74. [CrossRef] [PubMed]\n157. Soydaner,\
    \ D. A comparison of optimization algorithms for deep learning. Int. J. Pattern\
    \ Recognit. Artif. Intell. 2020, 34, 2052013.\n[CrossRef]\n158. Sheng, V.S.; Provost,\
    \ F.; Ipeirotis, P.G. Get another label? improving data quality and data mining\
    \ using multiple, noisy labelers.\nIn Proceedings of the 14th ACM SIGKDD International\
    \ Conference on Knowledge Discovery and Data Mining, Las Vegas, NV,\nUSA, 24–27\
    \ August 2008; pp. 614–622.\n159. Shan, J.; Aparajithan, S. Urban DEM generation\
    \ from raw LiDAR data. Photogramm. Eng. Remote Sens. 2005, 71, 217–226.\n[CrossRef]\n\
    160. Gao, F.; Hilker, T.; Zhu, X.; Anderson, M.; Masek, J.; Wang, P.; Yang, Y.\
    \ Fusing Landsat and MODIS Data for Vegetation Monitoring.\nIEEE Geosci. Remote\
    \ Sens. Mag. 2015, 3, 47–60. [CrossRef]\n161. Petitjean, F.; Inglada, J.; Gancarski,\
    \ P. Satellite Image Time Series Analysis Under Time Warping. IEEE Trans. Geosci.\
    \ Remote Sens.\n2012, 50, 3081–3095. [CrossRef]\n162. Grifﬁth, D.A.; Chun, Y.\
    \ Spatial Autocorrelation and Uncertainty Associated with Remotely-Sensed Data.\
    \ Remote Sens. 2016, 8, 535.\n[CrossRef]\n163. Miura, T.; Huete, A.; Yoshioka,\
    \ H. Evaluation of sensor calibration uncertainties on vegetation indices for\
    \ MODIS. IEEE Trans.\nGeosci. Remote Sens. 2000, 38, 1399–1409. [CrossRef]\n164.\
    \ Güntner, A.; Stuck, J.; Werth, S.; Döll, P.; Verzano, K.; Merz, B. A global\
    \ analysis of temporal and spatial variations in continental\nwater storage. Water\
    \ Resour. Res. 2007, 43, W05416. [CrossRef]\n165. Alvarez-Vanhard, E.; Corpetti,\
    \ T.; Houet, T. UAV & satellite synergies for optical remote sensing applications:\
    \ A literature review.\nSci. Remote Sens. 2021, 3, 100019. [CrossRef]\n166. Himeur,\
    \ Y.; Rimal, B.; Tiwary, A.; Amira, A. Using artiﬁcial intelligence and data fusion\
    \ for environmental monitoring: A review\nand future perspectives. Inf. Fusion\
    \ 2022, 86–87, 44–75. [CrossRef]\n167. von Eschenbach, W.J. Transparency and the\
    \ black box problem: Why we do not trust AI. Philos. Technol. 2021, 34, 1607–1622.\n\
    [CrossRef]\n168. Kakogeorgiou, I.; Karantzalos, K. Evaluating explainable artiﬁcial\
    \ intelligence methods for multi-label deep learning classiﬁcation\ntasks in remote\
    \ sensing. Int. J. Appl. Earth Obs. Geoinf. 2021, 103, 102520. [CrossRef]\n169.\
    \ Belle, V.; Papantonis, I. Principles and Practice of Explainable Machine Learning.\
    \ Front. Big Data 2021, 4, 688969. [CrossRef]\n[PubMed]\n170. Shorten, C.; Khoshgoftaar,\
    \ T.M. A survey on Image Data Augmentation for Deep Learning. J. Big Data 2019,\
    \ 6, 60. [CrossRef]\n171. Torrey, L.; Shavlik, J. Transfer learning. In Handbook\
    \ of Research on Machine Learning Applications and Trends: Algorithms, Methods,\n\
    and Techniques; IGI Global: Hershey, PA, USA, 2010; pp. 242–264.\n172. Ganaie,\
    \ M.A.; Hu, M.; Malik, A.K.; Tanveer, M.; Suganthan, P.N. Ensemble deep learning:\
    \ A review. Eng. Appl. Artif. Intell. 2022,\n115, 105151. [CrossRef]\n173. Chi,\
    \ M.; Plaza, A.; Benediktsson, J.A.; Sun, Z.; Shen, J.; Zhu, Y. Big Data for Remote\
    \ Sensing: Challenges and Opportunities. Proc.\nIEEE 2016, 104, 2207–2219. [CrossRef]\n\
    174. Xie, M.; Jean, N.; Burke, M.; Lobell, D.; Ermon, S. Transfer Learning from\
    \ Deep Features for Remote Sensing and Poverty Mapping.\nIn Proceedings of the\
    \ AAAI Conference on Artiﬁcial Intelligence, Phoenix, AZ, USA, 12–17 February\
    \ 2016; Volume 30. [CrossRef]\n175. Benchaita, S.; Mccarthy, B.H. IBM and NASA\
    \ Open Source Largest Geospatial AI Foundation Model on Hugging Face. IBM\nNewsroom.\
    \ 3 August 2023. Available online: https://newsroom.ibm.com/2023-08-03-IBM-and-NASA-Open-Source-Largest-\n\
    Geospatial-AI-Foundation-Model-on-Hugging-Face (accessed on 10 August 2023).\n\
    176. Wang, J.; Lan, C.; Liu, C.; Ouyang, Y.; Qin, T.; Lu, W.; Chen, Y.; Zeng,\
    \ W.; Yu, P. Generalizing to Unseen Domains: A Survey on\nDomain Generalization.\
    \ IEEE Trans. Knowl. Data Eng. 2022, 35, 8052–8072. [CrossRef]\n177. Mehrabi,\
    \ N.; Morstatter, F.; Saxena, N.; Lerman, K.; Galstyan, A. A Survey on Bias and\
    \ Fairness in Machine Learning. ACM\nComput. Surv. 2021, 54, 1–35. [CrossRef]\n\
    178. Roselli, D.; Matthews, J.; Talagala, N. Managing bias in AI. In Proceedings\
    \ of the 2019 World Wide Web Conference, New York,\nNY, USA, 13–17 May 2019; pp.\
    \ 539–544.\n179. Raji, I.D.; Smart, A.; White, R.N.; Mitchell, M.; Gebru, T.;\
    \ Hutchinson, B.; Smith-Loud, J.; Theron, D.; Barnes, P. Closing the AI\naccountability\
    \ gap: Deﬁning an end-to-end framework for internal algorithmic auditing. In Proceedings\
    \ of the 2020 Conference\non Fairness, Accountability, and Transparency, Barcelona,\
    \ Spain, 27–30 January 2020; pp. 33–44.\n180. Alkhelaiwi, M.; Boulila, W.; Ahmad,\
    \ J.; Koubaa, A.; Driss, M. An Efﬁcient Approach Based on Privacy-Preserving Deep\
    \ Learning\nfor Satellite Image Classiﬁcation. Remote Sens. 2021, 13, 2221. [CrossRef]\n\
    181. Zhang, X.; Zhu, G.; Ma, S. Remote-sensing image encryption in hybrid domains.\
    \ Opt. Commun. 2012, 285, 1736–1743. [CrossRef]\n182. Potkonjak, M.; Meguerdichian,\
    \ S.; Wong, J.L. Trusted sensors and remote sensing. In Proceedings of the SENSORS,\
    \ 2010 IEEE,\nWaikoloa, HI, USA, 1–4 November 2010; pp. 1104–1107. [CrossRef]\n\
    Remote Sens. 2023, 15, 4112\n33 of 34\n183. Ismael, C.; Molina, P. Unmanned aerial\
    \ systems for photogrammetry and remote sensing: A review. ISPRS J. Photogramm.\
    \ Remote\nSens. 2014, 92, 79–97.\n184. Jain, P.; Coogan, S.C.P.; Subramanian,\
    \ S.G.; Crowley, M.; Taylor, S.W.; Flannigan, M.D. A review of machine learning\
    \ applications\nin wildﬁre science and management. Environ. Rev. 2020, 28, 478–505.\
    \ [CrossRef]\n185. Bouguettaya, A.; Zarzour, H.; Taberkit, A.M.; Kechida, A. A\
    \ review on early wildﬁre detection from unmanned aerial vehicles\nusing deep\
    \ learning-based computer vision algorithms. Signal Process. 2022, 190, 108309.\
    \ [CrossRef]\n186. Nguyen, G.; Dlugolinsky, S.; Bobák, M.; Tran, V.; García, L.;\
    \ Heredia, I.; Malík, P.; Hluchý, L. Machine Learning and Deep Learning\nframeworks\
    \ and libraries for large-scale data mining: A survey. Artif. Intell. Rev. 2019,\
    \ 52, 77–124. [CrossRef]\n187. Amani, M.; Ghorbanian, A.; Ahmadi, S.A.; Kakooei,\
    \ M.; Moghimi, A.; Mirmazloumi, S.M.; Moghaddam, S.H.A.; Mahdavi, S.;\nGhahremanloo,\
    \ M.; Parsian, S.; et al. Google Earth Engine Cloud Computing Platform for Remote\
    \ Sensing Big Data Applications:\nA Comprehensive Review. IEEE J. Sel. Top. Appl.\
    \ Earth Obs. Remote Sens. 2020, 13, 5326–5350. [CrossRef]\n188. Garbini, S. How\
    \ Geospatial AI Can Help You Comply with EU’s Deforestation Law—Customers. Picterra.\
    \ 25 April 2023.\nAvailable online: https://picterra.ch/blog/how-geospatial-ai-can-help-you-comply-with-eus-deforestation-law/\
    \ (accessed on 6\nJuly 2023).\n189. Mujetahid, A.; Nursaputra, M.; Soma, A.S.\
    \ Monitoring Illegal Logging Using Google Earth Engine in Sulawesi Selatan Tropical\n\
    Forest, Indonesia. Forests 2023, 14, 652. [CrossRef]\n190. González-Rivero, M.;\
    \ Beijbom, O.; Rodriguez-Ramirez, A.; Bryant, D.E.; Ganase, A.; Gonzalez-Marrero,\
    \ Y.; Herrera-Reveles,\nA.; Kennedy, E.V.; Kim, C.J.; Lopez-Marcano, S.; et al.\
    \ Monitoring of Coral Reefs Using Artiﬁcial Intelligence: A Feasible and\nCost-Effective\
    \ Approach. Remote Sens. 2020, 12, 489. [CrossRef]\n191. Lou, R.; Lv, Z.; Dang,\
    \ S.; Su, T.; Li, X. Application of machine learning in ocean data. Multimedia\
    \ Syst. 2021, 29, 1815–1824.\n[CrossRef]\n192. Ditria, E.M.; Buelow, C.A.; Gonzalez-Rivero,\
    \ M.; Connolly, R.M. Artiﬁcial intelligence and automated monitoring for assisting\n\
    conservation of marine ecosystems: A perspective. Front. Mar. Sci. 2022, 9, 918104.\
    \ [CrossRef]\n193. Shaﬁq, S.I. Artiﬁcial intelligence and big data science for\
    \ oceanographic research in Bangladesh: Preparing for the future. J. Data\nAcquis.\
    \ Process. 2023, 38, 418.\n194. Weeks, P.J.D.; Gaston, K.J. Image analysis, neural\
    \ networks, and the taxonomic impediment to biodiversity studies. Biodivers.\n\
    Conserv. 1997, 6, 263–274. [CrossRef]\n195. Silvestro, D.; Goria, S.; Sterner,\
    \ T.; Antonelli, A. Improving biodiversity protection through artiﬁcial intelligence.\
    \ Nat. Sustain.\n2022, 5, 415–424. [CrossRef]\n196. Toivonen, T.; Heikinheimo,\
    \ V.; Fink, C.; Hausmann, A.; Hiippala, T.; Järv, O.; Tenkanen, H.; Di Minin,\
    \ E. Social media data for\nconservation science: A methodological overview. Biol.\
    \ Conserv. 2019, 233, 298–315. [CrossRef]\n197. Tong, D.Q.; Gill, T.E.; Sprigg,\
    \ W.A.; Van Pelt, R.S.; Baklanov, A.A.; Barker, B.M.; Bell, J.E.; Castillo, J.;\
    \ Gassó, S.; Gaston, C.J.; et al.\nHealth and Safety Effects of Airborne Soil\
    \ Dust in the Americas and Beyond. Rev. Geophys. 2023, 61, e2021RG000763. [CrossRef]\n\
    198. Alnuaim, A.; Ziheng, S.; Didarul, I. AI for improving ozone forecasting.\
    \ In Artiﬁcial Intelligence in Earth Science; Elsevier:\nAmsterdam, The Netherlands,\
    \ 2023; pp. 247–269.\n199. Bragazzi, N.L.; Dai, H.; Damiani, G.; Behzadifar, M.;\
    \ Martini, M.; Wu, J. How Big Data and Artiﬁcial Intelligence Can Help Better\n\
    Manage the COVID-19 Pandemic. Int. J. Environ. Res. Public Heal. 2020, 17, 3176.\
    \ [CrossRef]\n200. Alnaim, A.; Sun, Z.; Tong, D. Evaluating Machine Learning and\
    \ Remote Sensing in Monitoring NO2 Emission of Power Plants.\nRemote Sens. 2022,\
    \ 14, 729. [CrossRef]\n201. Vaishya, R.; Javaid, M.; Khan, I.H.; Haleem, A. Artiﬁcial\
    \ Intelligence (AI) applications for COVID-19 pandemic. Diabetes Metab.\nSyndr.\
    \ Clin. Res. Rev. 2020, 14, 337–339. [CrossRef]\n202. Lim, K.; Treitz, P.; Wulder,\
    \ M.; St-Onge, B.; Flood, M. LiDAR remote sensing of forest structure. Prog. Phys.\
    \ Geogr. Earth Environ.\n2003, 27, 88–106. [CrossRef]\n203. Liu, L.; Zhang, Q.;\
    \ Guo, Y.; Chen, E.; Li, Z.; Li, Y.; Wang, B.; Ri, A. Mapping the Distribution\
    \ and Dynamics of Coniferous Forests\nin Large Areas from 1985 to 2020 Combining\
    \ Deep Learning and Google Earth Engine. Remote Sens. 2023, 15, 1235. [CrossRef]\n\
    204. Sharma, M.K.; Mujawar, R.; Mujawar, A.; Dhayalini, K. Precision Forestry:\
    \ Integration of Robotics and Sensing Technologies for\nTree Measurement and Monitoring.\
    \ Eur. Chem. Bull. 2023, 12, 4747–4764.\n205. Stere´nczak, K. Precision Forestry.\
    \ IDEAS NCBR—Intelligent Algorithms for Digital Economy. 13 April 2023. Available\
    \ online:\nhttps://ideas-ncbr.pl/en/research/precision-forestry/ (accessed on\
    \ 5 July 2023).\n206. Liu, W.; Quijano, K.; Crawford, M.M. YOLOv5-Tassel: Detecting\
    \ Tassels in RGB UAV Imagery With Improved YOLOv5 Based on\nTransfer Learning.\
    \ IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 2022, 15, 8085–8094. [CrossRef]\n\
    207. Amila, J.; Ranaweera, N.; Abenayake, C.; Bandara, N.; De Silva, C. Modelling\
    \ vegetation land fragmentation in urban areas of\nWestern Province, Sri Lanka\
    \ using an Artiﬁcial Intelligence-based simulation technique. PLoS ONE 2023, 18,\
    \ e0275457.\n208. Kolokotroni, M.; Zhang, Y.; Watkins, R. The London Heat Island\
    \ and building cooling design. Sol. Energy 2007, 81, 102–110.\n[CrossRef]\n209.\
    \ Lyu, F.; Wang, S.; Han, S.Y.; Catlett, C.; Wang, S. An integrated cyberGIS and\
    \ machine learning framework for ﬁne-scale prediction\nof Urban Heat Island using\
    \ satellite remote sensing and urban sensor network data. Urban Inform. 2022,\
    \ 1, 1–15. [CrossRef]\n210. Rahman, A.; Roy, S.S.; Talukdar, S.; Shahfahad (Eds.)\
    \ Advancements in Urban Environmental Studies: Application of Geospatial\nTechnology\
    \ and Artiﬁcial Intelligence in Urban Studies; Springer International Publishing:\
    \ Cham, Switzerland, 2023.\nRemote Sens. 2023, 15, 4112\n34 of 34\n211. Alnaim,\
    \ A.; Ziheng, S. Using Geoweaver to Make Snow Mapping Workﬂow FAIR. In Proceedings\
    \ of the 2022 IEEE 18th\nInternational Conference on e-Science (e-Science), Salt\
    \ Lake City, UT, USA, 11–14 October 2022; pp. 409–410.\n212. Yang, K.; John, A.;\
    \ Sun, Z.; Cristea, N. Machine learning for snow cover mapping. In Artiﬁcial Intelligence\
    \ in Earth Science; Elsevier:\nAmsterdam, The Netherlands, 2023; pp. 17–39.\n\
    213. An, S.; Rui, X. A High-Precision Water Body Extraction Method Based on Improved\
    \ Lightweight U-Net. Remote. Sens. 2022,\n14, 4127. [CrossRef]\n214. Al-Bakri,\
    \ J.T.; D’Urso, G.; Calera, A.; Abdalhaq, E.; Altarawneh, M.; Margane, A. Remote\
    \ Sensing for Agricultural Water\nManagement in Jordan. Remote Sens. 2022, 15,\
    \ 235. [CrossRef]\n215. Xiang, X.; Li, Q.; Khan, S.; Khalaf, O.I. Urban water\
    \ resource management for sustainable environment planning using artiﬁcial\nintelligence\
    \ techniques. Environ. Impact Assess. Rev. 2020, 86, 106515. [CrossRef]\n216.\
    \ Sun, A.Y.; Scanlon, B.R. How can Big Data and machine learning beneﬁt environment\
    \ and water management: A survey of\nmethods, applications, and future directions.\
    \ Environ. Res. Lett. 2019, 14, 073001. [CrossRef]\n217. Sun, W.; Bocchini, P.;\
    \ Davison, B.D. Applications of artiﬁcial intelligence for disaster management.\
    \ Nat. Hazards 2020, 103,\n2631–2689. [CrossRef]\n218. Chapman, A. Leveraging\
    \ Big Data and AI for Disaster Resilience and Recovery; Texas A&M University College\
    \ of Engineering:\nCollege Station, TX, USA, 2023. Available online: https://engineering.tamu.edu/news/2023/06/leveraging-big-data-and-ai-for-\n\
    disaster-resilience-and-recovery.html (accessed on 10 August 2023).\n219. Imran,\
    \ M.; Castillo, C.; Lucas, J.; Meier, P.; Vieweg, S. AIDR: Artiﬁcial Intelligence\
    \ for Disaster Response. In Proceedings of\nthe 23rd International Conference\
    \ on World Wide Web, Seoul, Republic of Korea, 7–11 April 2014; ACM: New York,\
    \ NY, USA;\npp. 159–162.\n220. Gevaert, C.M.; Carman, M.; Rosman, B.; Georgiadou,\
    \ Y.; Soden, R. Fairness and accountability of AI in disaster risk management:\n\
    Opportunities and challenges. Patterns 2021, 2, 100363. [CrossRef] [PubMed]\n\
    221. Cao, L. AI and Data Science for Smart Emergency, Crisis and Disaster Resilience.\
    \ Int. J. Data Sci. Anal. 2023, 15, 231–246.\n[CrossRef]\nDisclaimer/Publisher’s\
    \ Note: The statements, opinions and data contained in all publications are solely\
    \ those of the individual\nauthor(s) and contributor(s) and not of MDPI and/or\
    \ the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury\
    \ to\npeople or property resulting from any ideas, methods, instructions or products\
    \ referred to in the content.\n"
  inline_citation: '>'
  journal: Remote Sensing
  limitations: '>'
  pdf_link: https://www.mdpi.com/2072-4292/15/16/4112/pdf?version=1692753489
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: A Review of Practical AI for Remote Sensing in Earth Sciences
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1201/9781003337454-7
  analysis: '>'
  authors:
  - Payam Barnaghi
  - Martin Bauer
  - Abdur Rahim Biswas
  - Maarten Botterman
  - Bin Cheng
  - Flavio Cirillo
  - Markus Dillinger
  - Hans Graux
  - Seyed Amir Hoseinitabatabaie
  - Ernő Kovács
  - Salvatore Longo
  - Swaroop Nunna
  - Alois Paulin
  - R. R. Venkatesha Prasad
  - John Soldatos
  - Christoph Thüemmler
  - Mojca Volk
  citation_count: 1
  full_citation: '>'
  full_text: '>

    Web Store Add shortcut Name URL Customize Chrome'
  inline_citation: '>'
  journal: River Publishers eBooks
  limitations: '>'
  pdf_link: https://api.taylorfrancis.com/content/chapters/oa-edit/download?identifierName=doi&identifierValue=10.1201/9781003337454-7&type=chapterpdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts of
    Operational Data – Research and Innovation Challenges'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/info14080470
  analysis: '>'
  authors:
  - K. Saravanan
  - Abbas Z. Kouzani
  citation_count: 1
  full_citation: '>'
  full_text: ">\nCitation: Saravanan, K.; Kouzani,\nA.Z. Advancements in On-Device\n\
    Deep Neural Networks. Information\n2023, 14, 470. https://doi.org/\n10.3390/info14080470\n\
    Academic Editors: Lorenzo\nCarnevale and Massimo Villari\nReceived: 22 June 2023\n\
    Revised: 20 July 2023\nAccepted: 17 August 2023\nPublished: 21 August 2023\nCopyright:\n\
    © 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an\
    \ open access article\ndistributed\nunder\nthe\nterms\nand\nconditions of the\
    \ Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n\
    4.0/).\n  \ninformation\nReview\nAdvancements in On-Device Deep Neural Networks\n\
    Kavya Saravanan 1,2 and Abbas Z. Kouzani 1,*\n1\nSchool of Engineering, Deakin\
    \ University, Geelong, VIC 3216, Australia\n2\nDepartment of Sensor and Biomedical\
    \ Technology, Vellore Institute of Technology, Vellore 632014, India\n*\nCorrespondence:\
    \ kouzani@deakin.edu.au\nAbstract: In recent years, rapid advancements in both\
    \ hardware and software technologies have\nresulted in the ability to execute\
    \ artiﬁcial intelligence (AI) algorithms on low-resource devices. The\ncombination\
    \ of high-speed, low-power electronic hardware and efﬁcient AI algorithms is driving\
    \ the\nemergence of on-device AI. Deep neural networks (DNNs) are highly effective\
    \ AI algorithms used\nfor identifying patterns in complex data. DNNs, however,\
    \ contain many parameters and operations\nthat make them computationally intensive\
    \ to execute. Accordingly, DNNs are usually executed on\nhigh-resource backend\
    \ processors. This causes an increase in data processing latency and energy\n\
    expenditure. Therefore, modern strategies are being developed to facilitate the\
    \ implementation\nof DNNs on devices with limited resources. This paper presents\
    \ a detailed review of the current\nmethods and structures that have been developed\
    \ to deploy DNNs on devices with limited resources.\nFirstly, an overview of DNNs\
    \ is presented. Next, the methods used to implement DNNs on resource-\nconstrained\
    \ devices are explained. Following this, the existing works reported in the literature\
    \ on the\nexecution of DNNs on low-resource devices are reviewed. The reviewed\
    \ works are classiﬁed into\nthree categories: software, hardware, and hardware/software\
    \ co-design. Then, a discussion on the\nreviewed approaches is given, followed\
    \ by a list of challenges and future prospects of on-device AI,\ntogether with\
    \ its emerging applications.\nKeywords: artiﬁcial intelligence; deep neural networks;\
    \ resource-constrained devices; on-device AI\n1. Introduction\nExecuting artiﬁcial\
    \ intelligence algorithms on hardware devices with limited resources,\nsuch as\
    \ low-end microcontrollers, is becoming a reality because of the increasing power\n\
    and decreasing cost of electronic hardware technology, as well as the creation\
    \ of more\nefﬁcient AI algorithms. In emerging research ﬁelds such as on-device\
    \ AI, data can be\nanalyzed where sensors generate data instead of backend servers.\
    \ This has created new\nopportunities for advanced AI applications such as autonomous\
    \ vehicles. Moreover, the rise\nof modern methods for on-device inference and\
    \ the creation of pre-trained AI algorithms\nhave contributed to a reduction in\
    \ resources needed for the execution of AI algorithms. The\ndevelopment of AI\
    \ algorithms being implemented on devices has been making consistent\nprogress\
    \ in recent years. It is now possible to execute AI algorithms on devices rather\
    \ than\ncloud servers, and it is anticipated that this trend will continue to\
    \ grow [1]. Processing\nthat happens locally on the device, as opposed to that\
    \ on the cloud, and saves time and\nenergy expenditure and enhances data security,\
    \ since there is no need to transmit raw data\nbetween the source device and a\
    \ distant back-end server.\nAI algorithms are built to analyze enormous amounts\
    \ of data, identify patterns within\nthose data, and then learn from those data.\
    \ AI algorithms refer to a host of methods used\nto solve complex problems, recognize\
    \ patterns, and make predictions based on data. Some\nexamples of well-known AI\
    \ algorithms include gradient boosting, support vector machines\n(SVM), random\
    \ forest, decision trees, k-means, artiﬁcial neural networks (ANNs), etc. To\n\
    develop an AI algorithm, necessary data are ﬁrst collected and preprocessed. The\
    \ next step\nis to train, validate, and test the algorithm. The goal of training\
    \ is to teach the AI algorithm\nInformation 2023, 14, 470. https://doi.org/10.3390/info14080470\n\
    https://www.mdpi.com/journal/information\nInformation 2023, 14, 470\n2 of 19\n\
    to recognize patterns and make accurate predictions or decisions based on the\
    \ test data it\nreceives. The goal of validation is to check how well the trained\
    \ model works and optimize\nit. The goal of testing is to provide an assessment\
    \ of the ﬁnal model. The common types of\nlearning approaches for AI algorithms\
    \ include (1) deep learning, (2) supervised learning,\n(3) unsupervised learning,\
    \ and (4) reinforcement learning [2]. In deep learning, large\nquantities of data\
    \ are sent into the network (with many layers) during training. Supervised\nlearning\
    \ occurs when the algorithm is provided with both inputs and outputs, whereas\n\
    unsupervised learning involves only the provision of inputs. Reinforcement learning,\
    \ on\nthe other hand, requires the model to learn through experimentation and\
    \ feedback, as it\nreceives rewards or penalties in response to its actions. Deep\
    \ neural networks (DNNs)\nare a popular and effective type of AI algorithm. They\
    \ have proven to be one of the most\nefﬁcient methods for dealing with complex\
    \ data such as videos and images. They consist\nof numerous layers of processing\
    \ in between their input and output layers [3]. For DNNs\nthat analyze images\
    \ and videos, a widely used technique is to combine convolutional\nﬁlter operations\
    \ with matrix multiplications. A DNN model contains larger quantities\nof parameters\
    \ and calculations, requiring larger memory when compared to other types\nof ANNs.\
    \ In addition, a DNN demands a large amount of processing time, energy, and\n\
    computing resources. Deploying DNNs on resource-constrained devices is thus a\
    \ difﬁcult\nproblem. Therefore, DNNs are often deployed on remote back-end cloud\
    \ servers. In some\nemerging applications, e.g., autonomous vehicles, data need\
    \ to be analyzed where they\nare captured by sensors instead of backend servers.\
    \ Therefore, the execution of a trained\nDNN model should take place on low-resource\
    \ devices. This helps circumvent problems\nassociated with latency-sensitive data,\
    \ security and privacy data, and always-on service.\nWhen deploying a DNN model\
    \ on a resource-constrained device, there is a need to make\ncompromises between\
    \ several criteria such as the model’s size, the amount of energy\nused, and processing\
    \ speed [4]. To enable the execution of DNNs on resource-restricted\ndevices,\
    \ there have been advancements in creating methods based on software, hardware,\n\
    or combined hardware and software.\nOn the software side, new programming frameworks\
    \ and libraries have been created\nto make it simpler to design DNNs for resource-constrained\
    \ devices. These include well-\nknown frameworks like TensorFlow, PyTorch, and\
    \ Keras. These frameworks provide\nhigh-level abstractions and pre-built components\
    \ for DNN development such as training\nand inference. In addition, there have\
    \ been developments in the tools that are used for\ndata preparation, model selection\
    \ and hyperparameter tuning, and model deployment and\nserving, as well as other\
    \ applications. On the hardware side, customized processors and\narchitectures\
    \ have been built specially to boost the deployment and execution of DNNs.\nThese\
    \ include graphics processing units (GPUs), ﬁeld-programmable gate arrays (FPGAs),\n\
    application-speciﬁc integrated circuits (ASICs), and tensor processing units (TPUs).\
    \ There\nhave been a few publications containing a conceptual description of implementing\
    \ DNNs\non Internet of things (IoT) devices with joint back-end computation. These\
    \ papers, however,\ndo not provide an analysis of the current work in the same\
    \ ﬁeld of research. Accordingly,\nthe contributions of this paper include a detailed\
    \ review of the existing methods and archi-\ntectures for optimizing DNNs and\
    \ executing them on resource-constrained devices. This\nreview is presented under\
    \ three categories: software, hardware, and hardware/software\nco-design. In addition,\
    \ a comparison of the methods in the three categories is given together\nwith\
    \ a discussion on the suitability of the reviewed methods.\n2. Overview of DNN\n\
    A DNN architecture is constructed by connecting a series of layers, where each\
    \ layer\nconsists of a grouping of units (neurons) interconnected with one another\
    \ as shown in\nFigure 1. In a DNN architecture, the input layer is the initial\
    \ layer that receives the raw\ndata, which may consist of audio or images. On\
    \ the other hand, the output layer is the ﬁnal\nlayer that represents the inferred\
    \ classes. The remaining layers are the hidden layers which\nconvert the input\
    \ values into the inferred classes. Every unit has its own activation function,\n\
    Information 2023, 14, 470\n3 of 19\nwhich deﬁnes how to compute the unit’s own\
    \ state. Weights are learnable parameters on\nthe connection lines between the\
    \ layers converting an incoming value to adjust an outgoing\nvalue [5].\nInformation\
    \ 2023, 14, x FOR PEER REVIEW \n3 of 2\n \ndata, which may consist of audio or\
    \ images. On the other hand, the output layer is the\nﬁnal layer that represents\
    \ the inferred classes. The remaining layers are the hidden layer\nwhich convert\
    \ the input values into the inferred classes. Every unit has its own activation\n\
    function, which deﬁnes how to compute the unit’s own state. Weights are learnable\n\
    parameters on the connection lines between the layers converting an incoming value\
    \ to\nadjust an outgoing value [5]. \n \nFigure 1. A sample feedforward deep neural\
    \ network. \nThere are a variety of DNN architectures. As an example, with a feedforward\
    \ DNN\nthe inference starts at the input layer and then proceeds forward layer\
    \ by layer until it ha\ncompleted. The output of each unit is updated in a feedforward\
    \ fashion at each successiv\nlayer. When all the units in the output layer have\
    \ been updated, the classiﬁcation result\nwill become available. The inferred\
    \ class is equivalent to the output layer unit that has the\nmost signiﬁcant value.\
    \ The majority of DNN’s operations consist of layer-wise\nmultiplications and\
    \ accumulations. All the inputs are multiplied by their respective\nweights. \n\
    Figure 1 depicts a feedforward neural network that consists of an input layer,\
    \ thre\nhidden layers, and one output layer. Each layer in the network is connected\
    \ to the nex\nthrough a weight matrix, resulting in a total of four weight matrices:\
    \ \U0001D464ଵ \U0001D464ଶ, \U0001D464ଷ, and \U0001D464ସ\nWhen an input vector\
    \ \U0001D465⃗is provided, the ﬁrst weight matrix \U0001D464ଵ is used to calculate\
    \ a do\nproduct, and the activation function is applied to the result. This produces\
    \ a new vecto\nℎଵ\nሬሬሬሬ⃗ representing the neurons’ values in hidden layer 1. ℎଵ\n\
    ሬሬሬሬ⃗ is then employed as the inpu\nvector of the following hidden layer, repeating\
    \ the described operations. The same proces\nis repeated to obtain the ﬁnal output\
    \ \U0001D466⃗ which serves as the networks’ prediction. The\ncomplete process\
    \ is expressed through the subsequent equations, in which σ denotes an\nactivation\
    \ function: \nℎଵ\nሬሬሬሬ⃗ = σ(\U0001D465ሬሬ⃗ · \U0001D464ଵ) \nℎଶ\nሬሬሬሬ⃗ = σ(ℎଵ\n\
    ሬሬሬሬሬ⃗ · \U0001D4642) \nℎଷ\nሬሬሬሬ⃗ = σ(ℎଶ\nሬሬሬሬሬ⃗ · \U0001D4643) \n\U0001D466ሬሬ⃗\
    \ = σ(ℎଷ\nሬሬሬሬሬ⃗·\U0001D4644) \n(1\n \n \nFigure 1. A sample feedforward deep\
    \ neural network.\nThere are a variety of DNN architectures. As an example, with\
    \ a feedforward DNN,\nthe inference starts at the input layer and then proceeds\
    \ forward layer by layer until it has\ncompleted. The output of each unit is updated\
    \ in a feedforward fashion at each successive\nlayer. When all the units in the\
    \ output layer have been updated, the classiﬁcation results will\nbecome available.\
    \ The inferred class is equivalent to the output layer unit that has the most\n\
    signiﬁcant value. The majority of DNN’s operations consist of layer-wise multiplications\n\
    and accumulations. All the inputs are multiplied by their respective weights.\n\
    Figure 1 depicts a feedforward neural network that consists of an input layer,\
    \ three\nhidden layers, and one output layer. Each layer in the network is connected\
    \ to the next\nthrough a weight matrix, resulting in a total of four weight matrices:\
    \ w1 w2, w3, and w4.\nWhen an input vector\n→x is provided, the ﬁrst weight matrix\
    \ w1 is used to calculate a dot\nproduct, and the activation function is applied\
    \ to the result. This produces a new vector\n→\nh1 representing the neurons’ values\
    \ in hidden layer 1.\n→\nh1 is then employed as the input\nvector of the following\
    \ hidden layer, repeating the described operations. The same process\nis repeated\
    \ to obtain the ﬁnal output\n→y which serves as the networks’ prediction. The\n\
    complete process is expressed through the subsequent equations, in which σ denotes\
    \ an\nactivation function:\n→\nh1 = σ(\n→x ·w1)\n→\nh2 = σ(\n→\nh1·w2)\n→\nh3\
    \ = σ(\n→\nh2·w3)\n→y = σ(\n→\nh3·w4)\n(1)\n3. Implementation of DNN On-Device\n\
    In recent years, developments in software, hardware, or combined hardware and\n\
    software have made it feasible to implement DNNs directly on devices that contain\
    \ sensors.\nThe execution of data in real-time on the cloud comes with a drawback\
    \ of increased latency.\nThe communications that take place between devices and\
    \ a cloud server are long-distance\nand have a limited bandwidth, which is the\
    \ cause of latency [1]. Running DNNs on a cloud\nInformation 2023, 14, 470\n4\
    \ of 19\nserver presents additional security and privacy challenges. During communications,\
    \ there\nis the possibility that sensitive information may be accessed improperly.\
    \ The reliability of\nthe communication connection is another challenge that comes\
    \ with operating DNNs on a\ncloud server. Safe and secure processing of sensor\
    \ data by DNNs needs to be established\nfor reliable operation. Thus, implementing\
    \ real-time data processing directly on the device\nitself is strongly recommended\
    \ [6].\nTo deploy a DNN on a resource-constrained device, a number of approaches\
    \ can be\nemployed. A DNN typically includes millions of parameters and processes,\
    \ so several\napproaches have been developed to optimize the parameters and processes\
    \ of the DNN\nwhile simultaneously maintaining its classiﬁcation accuracy. Examples\
    \ of such approaches\ninclude network optimization, quantization and compression,\
    \ data augmentation, power\nmanagement, and hardware acceleration approaches.\
    \ These approaches can be categorized\ninto three groups: software, hardware,\
    \ and hardware software co-design. The software\napproaches include pruning, compact\
    \ structure, quantization, and so on. The hardware\napproaches alter the architecture,\
    \ design, and memory hierarchy and dataﬂow mapping.\nThe hardware software co-design\
    \ includes work carried out based on both hardware and\nsoftware techniques.\n\
    3.1. Software Approaches\nIn DNNs, compression refers to the process of shrinking\
    \ the model’s size by elim-\ninating redundant or unnecessary parameters without\
    \ substantially compromising its\nperformance. Several approaches have been developed\
    \ to compress a DNN and ﬁt it into a\nresource-constrained hardware platform.\
    \ These approaches have been illustrated in the\nfollowing. Pruning refers to\
    \ the elimination of the connections of a DNN that are not\nhighly essential for\
    \ its operation. As a result, its memory footprint and computational\nrequirement\
    \ are reduced to improve its energy efﬁciency and ﬁt it into a low-resource\n\
    device [7]. Several pruning techniques have been developed, including weight pruning,\n\
    neuron pruning, ﬁlter pruning, structured pruning, and unstructured pruning. To\
    \ achieve\nadditional compression, the pruning procedure may be carried out either\
    \ during or after\ntraining. Pruning should be used in combination with other\
    \ strategies like regularization to\npreserve the efﬁciency of the network. If\
    \ pruning is not performed appropriately, it might\nalso lead to a loss of accuracy.\n\
    Weight sharing reduces the memory footprint of the model by allowing multiple\n\
    neurons to use the same set of weights, which can reduce the number of unique\
    \ parameters\nthat need to be stored in memory [8]. The common method for achieving\
    \ weight sharing in\nCNNs is to apply the same set of weights to each position\
    \ of the input feature maps. These\nrefer to a 3D matrix that represents the input\
    \ data for a convolutional layer. The input\nfeature map has a width, a height,\
    \ and a depth, where the depth corresponds to several\nchannels in the input data.\n\
    In a CNN, the same set of weights, also called ﬁlters or kernels, is used to convolve\
    \ the\ninput feature map at different locations, resulting in different output\
    \ feature maps. Each\nﬁlter generates one output feature map, and the number of\
    \ ﬁlters determines the number\nof output feature maps produced by the layer [9].\
    \ Each output feature map represents\na set of learned spatial features that the\
    \ layer is sensitive to. Siamese networks typically\ncombine the two identical\
    \ sub-networks with the same set of weights at some point in\nthe network, either\
    \ through concatenation or by determining the absolute difference or\nEuclidean\
    \ distance between their outputs [10].\nWeight tying involves arranging the weights\
    \ of several layers to be equal in order to\nbind them together. This is often\
    \ accomplished by designating a layer as a child layer of\nanother layer, after\
    \ which the weights of the child layer are adjusted to match those of the\nparent\
    \ layer [11]. The idea behind weight tying is to decrease various parameters in\
    \ the\nnetwork, which can help prevent overﬁtting and improve generalization.\n\
    Compact structure in DNNs refers to the process of reducing the number of parameters\n\
    in the network by simplifying its architecture or by using more efﬁcient building\
    \ blocks.\nInformation 2023, 14, 470\n5 of 19\nMethods such as depth-wise separable\
    \ convolution, squeeze-and-excitation (SE) blocks,\nResNet skip connections, MobileNet\
    \ architecture, and transformer-based architectures help\nachieve compact structures\
    \ in DNN. Low-rank approximation involves approximating\nthe weight matrices in\
    \ a DNN with low-rank matrices, which can reduce the number of\nparameters and\
    \ computations required during inference [12]. Some common methods for\nlow-rank\
    \ approximation in DNNs include singular value decomposition (SVD), tucker\ndecomposition,\
    \ low-rank factorization, and matrix completion. Low-rank approximation\ncan be\
    \ used to enhance generalization ability of the network. The speciﬁc method used\
    \ for\nlow-rank approximation depends on the type of network and the speciﬁc implementation.\n\
    In the technique of knowledge distillation [3], a smaller and less intricate network\
    \ is\ntrained to replicate the behavior of a larger and more intricate network,\
    \ which can lead to\nthe development of a condensed model that performs comparably\
    \ to its larger counterpart.\nSeveral techniques used for knowledge distillation\
    \ in DNNs are temperature scaling,\nfeature maps, inter-layer activations and\
    \ multi-task learning. Knowledge distillation can be\na powerful technique for\
    \ transferring knowledge to a smaller, simpler model from a larger,\nmore complex\
    \ model (see Figure 2).\n \nWeight tying involves arranging the weights of several\
    \ layers to be equal in order to \nbind them together. This is often accomplished\
    \ by designating a layer as a child layer of \nanother layer, after which the\
    \ weights of the child layer are adjusted to match those of the \nparent layer\
    \ [11]. The idea behind weight tying is to decrease various parameters in the\
    \ \nnetwork, which can help prevent overﬁtting and improve generalization. \n\
    Compact structure in DNNs refers to the process of reducing the number of \nparameters\
    \ in the network by simplifying its architecture or by using more eﬃcient \nbuilding\
    \ blocks. Methods such as depth-wise separable convolution, squeeze-and-\nexcitation\
    \ (SE) blocks, ResNet skip connections, MobileNet architecture, and transformer-\n\
    based architectures help achieve compact structures in DNN. Low-rank approximation\
    \ \ninvolves approximating the weight matrices in a DNN with low-rank matrices,\
    \ which can \nreduce the number of parameters and computations required during\
    \ inference [12]. Some \ncommon methods for low-rank approximation in DNNs include\
    \ singular value \ndecomposition (SVD), tucker decomposition, low-rank factorization,\
    \ and matrix \ncompletion. Low-rank approximation can be used to enhance generalization\
    \ ability of the \nnetwork. The speciﬁc method used for low-rank approximation\
    \ depends on the type of \nnetwork and the speciﬁc implementation. \nIn the technique\
    \ of knowledge distillation [3], a smaller and less intricate network is \ntrained\
    \ to replicate the behavior of a larger and more intricate network, which can\
    \ lead to \nthe development of a condensed model that performs comparably to its\
    \ larger \ncounterpart. Several techniques used for knowledge distillation in\
    \ DNNs are temperature \nscaling, feature maps, inter-layer activations and multi-task\
    \ learning. Knowledge \ndistillation can be a powerful technique for transferring\
    \ knowledge to a smaller, simpler \nmodel from a larger, more complex model (see\
    \ Figure 2). \n \nFigure 2. Sketch of knowledge distillation of a DNN model by\
    \ logits transfer, adopted from [3]. \nWinograd transformation involves transforming\
    \ the convolution operation in a CNN \ninto a set of smaller matrix multiplications,\
    \ and thus can reduce the number of \ncomputations required during inference [13].\
    \ This can result in a smaller and more \neﬃcient model, while maintaining the\
    \ accuracy of the larger model. Techniques used for \nimplementing the Winograd\
    \ transformation include F(2×2,3×3) and G(2×2,3×3) \ntransformations, direct convolution,\
    \ hybrid approaches, and optimization techniques. \nThe speciﬁc techniques used\
    \ for implementing the Winograd transformation depend on \nthe architecture of\
    \ the CNN, the size of the convolutional kernels, and the available \ncomputational\
    \ resources. The goal is to balance the computational eﬃciency of the \nconvolution\
    \ operation with the accuracy and generalization performance of the model. \n\
    Quantization is the process of transforming deep learning models to use parameters\
    \ \nand computations at a lower precision. By using lower-precision data types,\
    \ the model’s \nmemory requirements can be reduced, which can make it easier to\
    \ deploy on devices with \nlimited memory. Some types of quantization techniques\
    \ used in DNNs are ﬁxed-point \nquantization, dynamic range quantization, hybrid\
    \ quantization, and vector quantization. \nThe parameters of a DNN may be quantized\
    \ into predetermined levels through the \nprocess of quantization, which results\
    \ in a reduction in the number of bits that are \nrequired to hold those parameters.\
    \ As is the case with pruning, it requires striking a \nFigure 2. Sketch of knowledge\
    \ distillation of a DNN model by logits transfer, adopted from [3].\nWinograd\
    \ transformation involves transforming the convolution operation in a CNN\ninto\
    \ a set of smaller matrix multiplications, and thus can reduce the number of computations\n\
    required during inference [13]. This can result in a smaller and more efﬁcient\
    \ model, while\nmaintaining the accuracy of the larger model. Techniques used\
    \ for implementing the\nWinograd transformation include F(2×2,3×3) and G(2×2,3×3)\
    \ transformations, direct\nconvolution, hybrid approaches, and optimization techniques.\
    \ The speciﬁc techniques used\nfor implementing the Winograd transformation depend\
    \ on the architecture of the CNN,\nthe size of the convolutional kernels, and\
    \ the available computational resources. The goal\nis to balance the computational\
    \ efﬁciency of the convolution operation with the accuracy\nand generalization\
    \ performance of the model.\nQuantization is the process of transforming deep\
    \ learning models to use parameters\nand computations at a lower precision. By\
    \ using lower-precision data types, the model’s\nmemory requirements can be reduced,\
    \ which can make it easier to deploy on devices with\nlimited memory. Some types\
    \ of quantization techniques used in DNNs are ﬁxed-point\nquantization, dynamic\
    \ range quantization, hybrid quantization, and vector quantization.\nThe parameters\
    \ of a DNN may be quantized into predetermined levels through the process\nof\
    \ quantization, which results in a reduction in the number of bits that are required\
    \ to hold\nthose parameters. As is the case with pruning, it requires striking\
    \ a balance between the\ntwo competing goals of reducing the size of the DNN and\
    \ maintaining its accuracy. At the\nother end of the spectrum are the binarized\
    \ DNNs, which have weights and activations\nthat are either +1 or −1 [14]. This\
    \ results in a reduction in the amount of memory that is\nrequired to keep the\
    \ parameters, and the action of multiplication and adding in binary\nDNNs is converted\
    \ into a simple XNOR operation, which is much quicker and saves a\nsigniﬁcant\
    \ amount of energy [15].\nInformation 2023, 14, 470\n6 of 19\n3.2. Hardware Approaches\n\
    For implementing a DNN algorithm on a resource-constrained device, a number of\n\
    hardware platforms can be used. These include digital signal processors (DSPs),\
    \ systems-\non-chips (SoC), graphics processing units (GPUs), ﬁeld-programmable\
    \ gate arrays (FPGAs),\nand neural processing units (NPUs). Some popular SoC platforms\
    \ for DNNs include\nQualcomm Snapdragon, Apple A-series, Nvidia Jetson, etc. Some\
    \ popular FPGA platforms\nfor DNNs include Xilinx FPGAs, Intel FPGAs, and Amazon\
    \ F1 instances.\nIn addition, microcontrollers have been recently used for hosting\
    \ DNNs. The follow-\ning microcontroller platforms are recommended for hosting\
    \ DNNs [16]: Arduino Nano\n33 BLE Sense, STM32 microcontrollers, SparkFun Edge,\
    \ Espressif ESP32-DevKitC, Adafruit\nEdgeBadge, Espressif ESP-EYE, Wio Terminal:\
    \ ATSAMD51, Himax WE-I Plus EVB End-\npoint AI Development Board, Synopsys DesignWare\
    \ ARC EM Software Development\nPlatform, and Sony Spresense.\nTo deploy an optimized\
    \ DNN into a resource-constrained device, hardware-based\nmethods have been developed\
    \ as discussed in the following. When deploying DNNs on\nresource-constrained\
    \ devices, it is important to select an appropriate hardware architecture\nthat\
    \ can support the computational requirements of the DNN while minimizing power\n\
    consumption and memory usage. There have been attempts made to decrease the total\n\
    time needed by the network to make an inference on the device. The majority of\
    \ DNN\noperations require a lot of processing power, such as multilayered matrix\
    \ multiplications.\nHowever, low-resource devices often have restricted memory\
    \ size and computational\npower. As a result, DNN architectures that use much\
    \ less processing power are becoming\nmore common [7]. Convolution and matrix\
    \ multiplication operations should be performed\nusing speciﬁc hardware blocks,\
    \ and low-precision data formats should be used for weight,\nand activation values\
    \ and the network’s size and complexity should be supported by the\nmemory and\
    \ processing capabilities of the selected platform. Since the energy requirement\n\
    of low-resource devices needs to be limited, it is essential to optimize the power\
    \ usage of\nthe DNN execution. Power reduction techniques may be utilized in hardware,\
    \ such as\npower gating, dynamic voltage, frequency scaling, and clock gating\
    \ without compromising\nperformance. Memory is often limited to low-resource devices;\
    \ hence, memory utilization\nand optimization are crucial. Without losing speed,\
    \ hardware modiﬁcations like memory\ncompression, caching, and scratchpad memory\
    \ may be employed to lower the memory\nneeds of DNNs. DNN calculations may be\
    \ accelerated using on-chip accelerators like DSPs\nor GPUs. On-chip accelerators\
    \ may decrease the computational demands of DNNs and\nenhance performance by ofﬂoading\
    \ computation off the primary processor. The calculations\nneeded by DNNs may\
    \ be sped-up FPGAs, SoCs, or NPUs. DNN calculations may be\naccelerated by using\
    \ parallel processing methods like pipelining or parallel execution. The\nperformance\
    \ of DNNs on low-resource devices may be enhanced by parallel processing\nand\
    \ dividing the calculations into smaller, parallelizable tasks.\nMost of the power\
    \ is consumed during the process of obtaining the parameters and\nweights from\
    \ the main memory to the processor, which is where the actual calculations are\n\
    carried out. The implementation of the DNN requires the use of specialized hardware\
    \ to\nbe successful. This often requires the expenditure of a substantial quantity\
    \ of energy [17].\nAdditionally, the delay rises whenever data are retrieved from\
    \ the main memory. These\nissues are being tackled by DNN accelerators. In a broad\
    \ sense, it is possible to represent\nthe training and inference processes of\
    \ DNNs as matrix multiplications, unlike those seen in\ngraphics processing. Therefore,\
    \ GPUs have emerged as the pillar for training and deploying\nDNNs. The single\
    \ instruction, multiple threads (SIMT) parallelization approach is used to\nreduce\
    \ latency during the DNN inference process. The matrix multiplications may also\
    \ be\noptimized for quicker calculations using software tools, which is another\
    \ way to enhance\ncurrent hardware [17].\nMemory hierarchy in DNNs refers to the\
    \ organization of different types of memory\nused in a DNN system to store and\
    \ access data during training and inference [18]. The\nprimary objective of the\
    \ memory hierarchy in DNNs is to enhance their efﬁciency and\nInformation 2023,\
    \ 14, 470\n7 of 19\nperformance by utilizing faster, smaller, and costlier memory\
    \ at the higher levels of the\nhierarchy, and slower, larger, and more economical\
    \ memory at the lower levels. Memory\nhierarchy approaches that can be used to\
    \ improve the performance of DNNs include\ncaching, tiling, compression, and data\
    \ layout optimization. Memory hierarchy is created\nso that data may be delivered\
    \ rapidly and prevent memory access from being performed\ntwice. The generic memory\
    \ hierarchy provides support for dataﬂow mapping and lowering\nthe amount of energy\
    \ used and enhancing acceleration. Dataﬂow mapping is the process\nof mapping\
    \ the computations involved in DNN onto the available hardware resources. It\n\
    involves breaking down the DNN computation into smaller blocks and mapping them\
    \ onto\nthe hardware resources in a way that maximizes the utilization of the\
    \ available resources\nand minimizes the overall execution time of the DNN. Some\
    \ speciﬁc techniques used in\noptimizing dataﬂow mapping in DNNs are spatial and\
    \ temporal locality, memory reuse,\nparallelism, and custom hardware accelerators.\
    \ These techniques can help optimize the\nplacement and movement of data and computations\
    \ and improve the overall performance\nof DNN computations on a wide range of\
    \ platforms. It is necessary to perform dataﬂow\nmapping since DNN parameters\
    \ may not be stored on the constrained on-chip memory [1].\nThus, an external\
    \ memory may be used to transmit the parameters.\n3.3. Hardware/Software Co-Design\
    \ Approaches\nDNN inference can be deployed on resource-constrained devices using\
    \ hardware/\nsoftware co-design approaches. These approaches consist of a combination\
    \ of a hardware\napproach and a software approach. Examples of hardware approaches\
    \ include power\nreduction techniques; parallel processing methods like pipelining\
    \ or parallel execution; the\nsingle instruction, multiple threads (SIMT) parallelization\
    \ approach; memory hierarchy;\ndataﬂow mapping, etc. Examples of software approaches\
    \ include pruning, weight sharing,\nweight tying, compact structure, low-rank\
    \ approximation, knowledge distillation, Wino-\ngrad transformation, quantization,\
    \ etc. As the hardware and software approaches have\nalready been described in\
    \ the previous subsections, they are not therefore explained here.\n4. Existing\
    \ On-Device DNNs\nThe works that have already been reported on the implementation\
    \ of DNNs on\nresource-constrained devices can be categorized either into software,\
    \ hardware, and hard-\nware/software co-design approaches. The following subsections\
    \ provide a review on the re-\nported works involving software, hardware, and\
    \ hardware/software co-design techniques.\n4.1. Current Works Based on Software\
    \ Approaches\nYao et al. [19] propose a novel approach based on a compressor–critic\
    \ framework. The\ncompressor-critic framework consists of two components: a compressor\
    \ network and a critic\nnetwork. The compressor network takes a pre-trained deep\
    \ neural network as input and\ncompresses it by removing unnecessary parameters\
    \ and reducing the number of layers. The\ncritic network evaluates the compressed\
    \ network and provides feedback to the compressor\nnetwork, guiding the compression\
    \ process to produce a compressed network with high\naccuracy. They also use a\
    \ reinforcement learning approach to train the compressor and\ncritic networks,\
    \ with the goal of maximizing the accuracy of the compressed network while\nminimizing\
    \ the compression rate. The authors also introduce a novel technique called “layer\n\
    fusion,” which combines multiple layers of the original NN into a particular layer\
    \ in the\ncompressed network, reducing the number of parameters and improving\
    \ the compression\nrate. The paper provides experimental results demonstrating\
    \ the effectiveness of the\nproposed method, showing that it can achieve high\
    \ compression rates while maintaining\nhigh accuracy on a range of datasets and\
    \ deep neural network architectures.\nMolchanov et al. [20] propose a method for\
    \ pruning CNNs by removing unimportant\nweights. The pruning process is based\
    \ on the magnitude of the weights in the network,\nwhere weights with small magnitudes\
    \ are considered unimportant and can be pruned\nwithout signiﬁcantly affecting\
    \ the network’s accuracy. Several different pruning tech-\nInformation 2023, 14,\
    \ 470\n8 of 19\nniques are proposed, including pruning individual weights, entire\
    \ ﬁlters, and even entire\nlayers of the network. To mitigate the potential accuracy\
    \ loss caused by pruning, the\nauthors propose a technique called “iterative pruning\
    \ and retraining,” where the network\nis repeatedly pruned and then retrained\
    \ on the pruned architecture to recover the lost\naccuracy. The authors also propose\
    \ a method for initializing the pruned network with the\nweights of the original\
    \ network, which can speed up the convergence of the retraining\nprocess. This\
    \ paper [20] provides experimental results demonstrating the effectiveness of\n\
    the proposed methods, showing that it can achieve signiﬁcant reductions in the\
    \ number\nof parameters and computations without sacriﬁcing accuracy on a range\
    \ of datasets and\nCNN architectures.\nAnwar et al. [21] propose a method for\
    \ pruning large blocks of ﬁlters simultaneously,\nwhich can signiﬁcantly reduce\
    \ several parameters and computations needed during in-\nference. The method is\
    \ based on a two-stage process. In the ﬁrst stage, the network is\ntrained to\
    \ identify the redundant blocks of ﬁlters using a set of heuristics, such as the\n\
    L1-norm of ﬁlter weights or activations. In the second stage, the redundant blocks\
    \ of ﬁlters\nare pruned, and the network is retrained on the pruned architecture\
    \ to recover the lost\naccuracy. To further optimize the network, a technique\
    \ is proposed called “coarse pruning,”\nwhere entire blocks of ﬁlters are removed\
    \ from the network, rather than individual ﬁlters,\nwhich signiﬁcantly decrease\
    \ the calculation and memory requirements of the network\nwithout sacriﬁcing accuracy.\
    \ The aforementioned paper [21] provides experimental results\ndemonstrating the\
    \ effectiveness of the proposed methods, showing that it can achieve\nsigniﬁcant\
    \ reductions in the number of parameters and computations without sacriﬁcing\n\
    accuracy on a range of datasets and CNN architectures.\nYang et al. [22] propose\
    \ a method for designing energy-efﬁcient CNNs through a\ntechnique called energy-aware\
    \ pruning. The main idea behind energy-aware pruning\nis to identify and remove\
    \ the less important connections in a CNN that contribute less\nto its overall\
    \ accuracy. By removing these connections, the resulting pruned network\nhas fewer\
    \ operations to perform, and therefore requires less energy to compute, while\n\
    maintaining a high level of accuracy. Firstly, a ranking algorithm to identify\
    \ the most\nsigniﬁcant connections in the network is used. The ranking algorithm\
    \ assigns a score to each\nconnection based on its contribution to the overall\
    \ accuracy of the network. Connections\nwith lower scores are then pruned. Secondly,\
    \ an iterative pruning approach is used where\nthey gradually prune the network\
    \ while monitoring its accuracy. At each iteration, a\ncertain percentage of the\
    \ connections with the lowest scores are pruned and retrained in\nthe network\
    \ to recover their accuracy. This process is repeated until the required level\n\
    of pruning is achieved. The proposed pruning technique is applied to several popular\n\
    CNN architectures, including VGG-16, ResNet-50, and AlexNet, showing that the\
    \ pruned\nnetworks achieve signiﬁcant energy savings while maintaining a similar\
    \ level of accuracy\ncompared to the original networks. The authors also compare\
    \ their method to other pruning\ntechniques and show that their approach outperforms\
    \ them in terms of energy savings and\naccuracy. Overall, the paper provides a\
    \ useful method for designing energy efﬁcient CNNs\nby leveraging the beneﬁts\
    \ of pruning techniques.\nNarang et al. [23] propose a method for introducing\
    \ sparsity into the weight matrices\nof recurrent neural networks (RNNs), which\
    \ can reduce various computations and memory\naccesses essential during inference.\
    \ The sparsity is introduced through a process called\n“structured pruning,” where\
    \ groups of weights in the weight matrices are pruned simulta-\nneously to maintain\
    \ the structure of the matrices. The authors propose several different\npruning\
    \ techniques, including pruning individual weights, entire rows and columns, and\n\
    even entire matrices. To mitigate the potential accuracy loss caused by pruning,\
    \ the authors\npropose a technique called “iterative pruning and retraining,”\
    \ like the method proposed\nin [20], where the network is repeatedly pruned and\
    \ then retrained on the pruned architec-\nture to recover the lost accuracy. The\
    \ paper provides experimental results demonstrating\nthe effectiveness of the\
    \ proposed method, showing that it can achieve signiﬁcant reductions\nInformation\
    \ 2023, 14, 470\n9 of 19\nin the number of parameters and computations without\
    \ sacriﬁcing accuracy on a range of\ndatasets and RNN architectures.\nGuo et al.\
    \ [24] propose a method for surgically removing redundant neurons and\nconnections\
    \ that do not contribute signiﬁcantly to the network’s performance during train-\n\
    ing, without compromising the network’s accuracy. The method is based on a two-stage\n\
    process. In the ﬁrst stage, the network is trained to identify the redundant components\n\
    using a set of heuristics, such as the magnitude of weights or the magnitude of\
    \ activa-\ntions. In the second stage, the redundant components are surgically\
    \ removed, and the\nnetwork is retrained on the pruned architecture to recover\
    \ the lost accuracy. To further\noptimize the network, the authors propose a technique\
    \ called “channel pruning,” where\nentire channels of feature maps are removed\
    \ from CNNs, which can signiﬁcantly reduce\nvarious computations and memory accesses\
    \ essential during inference. The paper provides\nexperimental results demonstrating\
    \ the effectiveness of the proposed method, showing\nthat it can achieve signiﬁcant\
    \ reductions in the number of parameters and computation\nwithout sacriﬁcing accuracy\
    \ on a range of datasets and architectures.\nHinton et al. [25] propose a method\
    \ called “knowledge distillation”, which is for\nreducing the size and computational\
    \ complexity of DNNs while maintaining their accuracy.\nThe authors use a smaller,\
    \ simpler neural network (referred to as the student network) to\nmimic the behavior\
    \ of a larger, more complex neural network (referred to as the teacher\nnetwork)\
    \ by learning to match the teacher network’s output. This is carried out by using\
    \ the\noutput probabilities of the teacher network as soft targets during the\
    \ training of the student\nnetwork. In other words, instead of using the hard\
    \ labels (e.g., one-hot encoded vectors)\ntypically employed during supervised\
    \ training, the student network is trained to match\nthe probability distribution\
    \ produced by the teacher network for each input. In addition\nto using soft targets,\
    \ the authors introduce several regularization techniques to prevent\noverﬁtting\
    \ and improve the generalization of the student network. These techniques\ninclude\
    \ adding a temperature parameter to the softmax function used to calculate the\n\
    output probabilities and adding a term to the loss function that encourages the\
    \ student\nnetwork to produce similar activations as the teacher network. The\
    \ paper provides several\nexperimental results demonstrating the effectiveness\
    \ of the proposed method, including\ncomparisons with other methods for reducing\
    \ the size of neural networks. The results\nshow that knowledge distillation can\
    \ reduce the size of neural networks by a factor of two\nto ten while maintaining\
    \ or even improving their accuracy.\nRavi et al. [26] propose a three-stage approach\
    \ to using deep learning for on-node\nsensor data analytics. The ﬁrst stage involves\
    \ collecting data from the sensors on the device,\nwhich can include accelerometers,\
    \ gyroscopes, magnetometers, or other sensors depending\non the application. The\
    \ collected data are then preprocessed to remove noise, normalize\nthe data, and\
    \ perform feature extraction to prepare it for input into the deep learning\n\
    model. In the second stage, a deep learning model is used to process the preprocessed\
    \ data.\nIt is proposed using a CNN architecture, which is well suited for processing\
    \ sequential\ndata such as sensor readings. CNN is trained on a labeled dataset\
    \ of sensor data using\nsupervised learning, where the labels represent the activity\
    \ or state that corresponds to\neach sequence of sensor readings. Finally, in\
    \ the third stage, the trained model is deployed\non the device for real-time\
    \ processing of new sensor data. A sliding window approach is\nused to process\
    \ the data in real time, where the window size is determined by the expected\n\
    duration of the activity or state being classiﬁed. The model outputs a prediction\
    \ for each\nwindow of sensor data, which can be used to trigger actions or provide\
    \ feedback to the\nuser. This approach achieves high accuracy on both datasets\
    \ while consuming minimal\nresources, making it well suited for deployment on\
    \ mobile or wearable devices with limited\nprocessing power and battery life.\n\
    He et al. [27] propose the ResNet architecture, which introduces residual connections,\n\
    which allow the network to learn residual functions instead of directly learning\
    \ the underly-\ning mapping. In the ResNet architecture, each layer learns a residual\
    \ function that is added\nto the input of the layer. This allows the network to\
    \ learn the difference between the input\nInformation 2023, 14, 470\n10 of 19\n\
    and the desired output, rather than trying to directly learn the output from the\
    \ input. This\nmakes it easier for the network to optimize the weights and avoid\
    \ the vanishing gradient\nproblem. The ResNet architecture also includes bottleneck\
    \ blocks, which reduce the number\nof parameters and improve computational efﬁciency.\
    \ These blocks consist of three layers,\nwith the ﬁrst and last layers having\
    \ fewer ﬁlters than the middle layer. This reduces the\nnumber of parameters while\
    \ still allowing the network to learn complex features.\nHam et al. [28] propose\
    \ the NNStreamer framework, which provides an efﬁcient and\nﬂexible pipeline for\
    \ on-device AI development. The framework includes modular compo-\nnents that\
    \ can be easily integrated and customized to suit different hardware platforms\
    \ and\nuse cases. The NNStreamer pipeline includes several components such as\
    \ data source, pre-\nprocessing, neural network, post-processing, and data sink,\
    \ which can be customized and\nconnected in a ﬂexible manner. The framework also\
    \ provides a set of built- in operators that\ncan be used for common preprocessing\
    \ and post-processing tasks, as well as support for\nhardware acceleration and\
    \ optimization. The paper provides several experimental results\ndemonstrating\
    \ the effectiveness and efﬁciency of the NNStreamer framework, including\nbenchmarks\
    \ on various hardware platforms and use cases such as object detection and\nimage\
    \ classiﬁcation.\n4.2. Current Works Based on Hardware Approaches\nShen et al.\
    \ [29] trained a CNN model using a large dataset of images containing human\n\
    heads and non-human objects. They used this model to develop an algorithm that\
    \ can\nclassify whether an image contains a human head or not. The authors then\
    \ optimized the\nalgorithm for implementation on an edge device by decreasing\
    \ the number of operations\nand weights needed for the network to run efﬁciently\
    \ on the chip. To implement the algo-\nrithm on an edge device, the authors used\
    \ Mipy evaluation board. “AVSdsp”, a technology\ncompany, created the Mipy evaluation\
    \ board to execute the task of detecting human heads\nthrough images. They devised\
    \ a software pipeline that comprises the subsequent stages.\nFirstly, an image\
    \ is captured using a camera connected to the FPGA board. Secondly, the\nimage\
    \ is preprocessed to resize it to the desired input size for the CNN model. Thirdly,\n\
    the image is run through the CNN model on the FPGA to detect whether a human head\n\
    is present. Finally, the results of the human head detection algorithm are displayed\
    \ on\nan output display. The authors evaluated the performance of their implementation\
    \ by\nmeasuring the power consumption, accuracy, and real-time performance of\
    \ the algorithm\non the FPGA board. They showed that the implementation achieves\
    \ high accuracy and\nreal-time performance while consuming minimal power, making\
    \ it suitable for use in edge\nAI applications.\nDong et al. [30] propose a system\
    \ that employs a hierarchical architecture consisting\nof edge devices and cloud\
    \ servers. The edge devices capture video streams and perform\npreliminary processing\
    \ to decrease the amount of data sent to the cloud. The cloud servers\nare responsible\
    \ for performing more complex processing, such as object detection and\ntracking,\
    \ using deep learning models. They describe the hardware implementation of\ntheir\
    \ system using Nvidia Jetson TX2 edge devices. They also propose a data compression\n\
    technique to reduce the amount of data sent from the edge devices to the cloud,\
    \ thereby\nreducing latency and bandwidth requirements. The authors evaluate their\
    \ system on an\nopen-air object detection dataset and show that their system achieves\
    \ real-time performance\nwith high accuracy. They also compare their system to\
    \ existing state-of-the-art systems and\nshow that their system outperforms them\
    \ in terms of accuracy and processing speed.\nSuleiman et al. [31] propose the\
    \ concept of visual–inertial odometry (VIO), which\nuses a custom CNN architecture,\
    \ which is a navigation method that combines visual\nand inertial data to estimate\
    \ the position and orientation of a drone in real time. They\nthen discuss the\
    \ challenges associated with implementing VIO on small drones that have\nlimited\
    \ power, processing, and memory resources. The paper presents Navion, a fully\n\
    integrated hardware accelerator that is designed to be low-power and lightweight,\
    \ making\nit ideal for use on small drones. The accelerator is based on a custom-designed\
    \ systolic\nInformation 2023, 14, 470\n11 of 19\narray architecture that is optimized\
    \ for VIO computations. The authors also present an\nalgorithm that is speciﬁcally\
    \ designed to run on Navion, which combines feature tracking\nand ﬁltering techniques\
    \ to estimate the drone’s position and orientation. The authors\nevaluate the\
    \ performance of Navion using a custom-built quadcopter and compare it with\n\
    other state-of-the-art VIO algorithms. They demonstrate that Navion can achieve\
    \ accurate\nand real-time navigation while consuming only 2 milliwatts of power,\
    \ which is several\norders of magnitude lower than other VIO accelerators.\nLi\
    \ et al. [32] propose a hardware architecture to implement the accelerator, which\n\
    consists of multiple processing elements (PEs) connected through a network on\
    \ chip (NoC)\nto form a systolic array. The PEs perform the convolution and pooling\
    \ operations in parallel,\nwhich allows for high throughput and low latency. The\
    \ authors also developed a software\nstack that includes a compiler and a runtime\
    \ system to translate CNN models into conﬁgu-\nrations that can be executed on\
    \ the FPGA accelerator. The compiler optimizes the CNN\nmodel by mapping its layers\
    \ to the PEs and generating conﬁguration ﬁles for the FPGA.\nThe runtime system\
    \ manages the communication between the host computer and the FPGA\nand controls\
    \ the execution of the CNN model. The authors evaluated the performance of\ntheir\
    \ FPGA-based accelerator by comparing it with a software implementation of the\
    \ same\nCNN model running on a high-end CPU. They showed that their FPGA-based\
    \ accelerator\nachieved signiﬁcant speedup and energy efﬁciency compared to the\
    \ CPU implementation,\nwhile maintaining high accuracy.\nDinelli et al. [33] use\
    \ a CNN architecture called SqueezeNet as the target network\nfor their accelerator.\
    \ The hardware accelerator is designed to perform the convolutional\nand pooling\
    \ operations of the SqueezeNet architecture using only on-chip memories,\nwhich\
    \ helps to reduce the latency and energy consumption of the accelerator. The hardware\n\
    accelerator is implemented on a Xilinx Zynq UltraScale+ FPGA, which includes a\
    \ processing\nsystem and programmable logic. The authors use programmable logic\
    \ to implement the\nhardware accelerator, which consists of a convolutional layer,\
    \ a max-pooling layer, and\na ReLU activation layer. The on-chip memories are\
    \ used to store the weights and input\nfeature maps of the convolutional layer\
    \ and the output feature maps of the max-pooling\nand ReLU layers. The authors\
    \ benchmark their hardware accelerator using the Intel\nMovidius Neural Compute\
    \ Stick, a popular edge device for running neural networks. They\ncompare the\
    \ performance of their hardware accelerator with the Neural Compute Stick\nusing\
    \ two different CNN architectures, SqueezeNet and MobileNet. The results show\
    \ that\nthe hardware accelerator outperforms the Neural Compute Stick in terms\
    \ of both latency\nand energy consumption for both CNN architectures.\nChen et\
    \ al. [34] propose an energy-efﬁcient accelerator for CNNs called Eyeriss. Eye-\n\
    riss is designed to optimize the computation and communication patterns of CNNs,\
    \ which\nare the most computationally intensive operations in deep learning. Eyeriss\
    \ uses a recon-\nﬁgurable architecture that allows it to adapt to different CNN\
    \ models and layers. The\narchitecture is composed of PEs that perform the convolution\
    \ and pooling operations and\na memory hierarchy that stores the weights, activations,\
    \ and feature maps. The PEs are\narranged in a mesh topology, and each PE is connected\
    \ to its neighboring PEs through\na communication network. Eyeriss also uses a\
    \ dataﬂow organization that optimizes the\ncommunication between the PEs and the\
    \ memory hierarchy. The dataﬂow organization\nensures that the data are streamed\
    \ from memory to the PEs only when they are needed,\nand that the data are processed\
    \ in the correct order. This reduces data movement and\nenergy consumption. To\
    \ further reduce energy consumption, Eyeriss uses a technique\ncalled weight stationary,\
    \ which exploits the fact that the weights in a CNN are reused\nmultiple times.\
    \ The weight stationary technique stores the weights in a separate memory\nbank\
    \ and streams them to the PEs as needed, reducing the energy consumption of fetching\n\
    the weights from memory. The authors of the paper implemented Eyeriss on a FPGA\n\
    platform and evaluated its performance on several CNN models. The results show\
    \ that\nEyeriss achieves high energy efﬁciency compared to other state-of-the-art\
    \ accelerators while\nmaintaining high accuracy on image classiﬁcation tasks.\n\
    Information 2023, 14, 470\n12 of 19\nChen et al. [35] propose the Eyeriss v2 accelerator,\
    \ which is implemented using a tiled\narchitecture, where each tile consists of\
    \ a PE array and a local memory. The processing\nelement array is responsible\
    \ for performing the computation of the neural network layers,\nwhile the local\
    \ memory stores the weights and input feature maps of the layers. The\nEyeriss\
    \ v2 accelerator uses a ﬂexible dataﬂow scheduling scheme to handle the complex\n\
    computation and data movement patterns of emerging deep neural networks. The dataﬂow\n\
    scheduling scheme allows the accelerator to dynamically allocate resources to\
    \ different\nlayers of the network, based on their computation and memory requirements.\
    \ The authors\nuse several emerging architectures, such as RNNs and attention-based\
    \ models, to eval-\nuate the performance of the Eyeriss v2 accelerator. The results\
    \ show that the Eyeriss v2\naccelerator achieves high energy efﬁciency and performance\
    \ compared to state-of-the-art\nmobile accelerators, such as the Google Pixel\
    \ Visual Core and the Apple Neural Engine.\nThe authors also introduce a new performance\
    \ metric called the “energy- delay product”\n(EDP), which considers both the energy\
    \ consumption and the latency of the accelerator. The\nEDP metric shows that the\
    \ Eyeriss v2 accelerator outperforms other mobile accelerators in\nterms of energy\
    \ efﬁciency and latency.\n4.3. Current Works Based on Hardware/Software Co-Design\
    \ Approaches\nLane et al. [5] propose a system called DeepX, which accelerates\
    \ the inference of\nDNNs on mobile devices. The authors use a combination of software\
    \ techniques and\nhardware optimizations to achieve this goal (see Figure 3).\
    \ The software techniques include\noptimizing the computation graph, pruning the\
    \ network, and quantizing the weights and\nactivations. The hardware optimizations\
    \ include using a custom hardware accelerator\nand reducing the number of memory\
    \ accesses. The authors use a custom instruction set\narchitecture (ISA) to efﬁciently\
    \ map the computations required for deep learning inference\nonto the hardware\
    \ accelerator. The hardware accelerator is designed to work in conjunction\nwith\
    \ a software stack that includes a compiler, runtime library, and driver. The\
    \ authors\nevaluate their system on several benchmark datasets and compare it\
    \ to existing state-of-\nthe-art systems. They show that their system achieves\
    \ a signiﬁcant speedup compared\nto the baseline system, while consuming signiﬁcantly\
    \ less power. They also show that\ntheir system achieves state-of-the-art performance\
    \ on several benchmark datasets. Overall,\nthe paper presents an interesting approach\
    \ to accelerating deep learning inference on\nmobile devices. The authors provide\
    \ a detailed description of their system and evaluation\nmethodology, and the\
    \ results show that their system is effective in reducing the power\nconsumption\
    \ of deep learning inference on mobile devices while maintaining high accuracy.\n\
    However, it should be noted that the proposed system is still in the research\
    \ stage and has\nnot been widely deployed or evaluated in real-world scenarios.\n\
    FOR PEER REVIEW \n13 of 20 \n \nFigure 3. Model decomposition and compression\
    \ in DeepX; reprinted with permission from Ref. \n[5]. \nDing et al. [36] propose\
    \ a novel method for quantizing weights and activations of \nDNNs using integer\
    \ and binary representations, which reduces the amount of memory \nrequired to\
    \ store the network parameters and improve the computational eﬃciency of the \n\
    inference process. They show that their proposed method achieves competitive accuracy\
    \ \non benchmark datasets such as CIFAR-10 and ImageNet, while reducing the memory\
    \ \nFigure 3. Model decomposition and compression in DeepX; reprinted with permission\
    \ from Ref. [5].\nDing et al. [36] propose a novel method for quantizing weights\
    \ and activations of\nDNNs using integer and binary representations, which reduces\
    \ the amount of memory\nrequired to store the network parameters and improve the\
    \ computational efﬁciency of the\nInformation 2023, 14, 470\n13 of 19\ninference\
    \ process. They show that their proposed method achieves competitive accuracy\n\
    on benchmark datasets such as CIFAR-10 and ImageNet, while reducing the memory\n\
    footprint and energy consumption by up to 4× compared to full-precision networks.\
    \ The\nauthors also propose a hardware architecture for implementing the quantized\
    \ DNN, which\nuses parallel processing and pipelining to accelerate the inference\
    \ process. The hardware\naccelerator is designed to support low-precision computations,\
    \ speciﬁcally 1-bit and 2-bit\nquantization. This enables the accelerator to perform\
    \ computations using a reduced number\nof bits, which reduces power consumption\
    \ and hardware complexity. To evaluate their\nimplementation, the authors tested\
    \ their system on several benchmark datasets, including\nCIFAR-10 and SVHN. The\
    \ results showed that their hardware accelerator achieved high\naccuracy while\
    \ consuming signiﬁcantly less power than existing DNN accelerators.\nZhang et\
    \ al. [37] propose FitNN, a low-resource FPGA- based CNN accelerator that\ncan\
    \ be integrated with a drone’s on-board processor. This involves the design and\
    \ imple-\nmentation of a CNN accelerator software stack for drones, which is optimized\
    \ for use with\na low-resource FPGA-based hardware accelerator. The software stack\
    \ consists of several\ncomponents, including a front end that handles input data\
    \ processing and communication\nwith the FPGA accelerator, and a back end that\
    \ performs output processing and sends\nresults back to the drone’s main processor.\
    \ The FPGA accelerator itself is designed to\nperform the computationally intensive\
    \ convolutional and pooling operations that are re-\nquired for CNN inference.\
    \ The authors also develop a custom hardware-software co-design\nmethodology that\
    \ allows for efﬁcient communication between the FPGA accelerator and\nthe software\
    \ stack. This methodology involves the use of specialized hardware interfaces\n\
    and a communication protocol that optimizes the transfer of data between the FPGA\
    \ and\nthe software stack. To evaluate their software and hardware co-design approach,\
    \ the au-\nthors implemented their system on a low-cost FPGA development board\
    \ and tested it using\nthe CIFAR-10 dataset. The results showed that their approach\
    \ achieved high accuracy and\nspeed, while consuming very little power.\n5. Analysis\
    \ and Comparison\n5.1. Comparison of Software-Based Approaches\nThe software-based\
    \ approaches utilize algorithms to implement DNNs on low-resource\ndevices, which\
    \ can improve efﬁciency and accuracy. With the wide range of existing works\n\
    reported in this paper, it is essential to compare their features, beneﬁts, and\
    \ limitations.\nIn Tables 1 and 2, we compare different software-based approaches\
    \ to understand their\nkey features and differences, and ultimately make an informed\
    \ choice for speciﬁc needs\nat hand.\nTable 1. Comparison of software-based approaches.\n\
    Author\nArchitecture\nCompression Rate\nMemory\nYao et al. [19]\nDNN\nNot Available\n\
    Before: 90% After: 98.9%\nMolchanov et al. [20]\nCNN\nBefore: 9× After: 13×\n\
    Not Available\nAnwar et al. [21]\nDeep\nCNN\nNot Available\nBefore: Not Available\n\
    After: 10×\nYang et al. [22]\nCNN\nBefore: Not Available\nAfter: 13×\nNot Available\n\
    Narang et al. [23]\nRNN\nBefore: Not Available\nAfter: 16×\nBefore: Not Available\n\
    After: 90%\nGuo et al. [24]\nDNN\nBefore: Not Available\nAfter: 17.7×\nBefore:\
    \ Not Available\nAfter: 108×\nHinton et al. [25]\nDNN\nNot Available\nBefore:\
    \ Not Available\nAfter: 30×\nRavi et al. [26]\nCNN\nNot Available\nNot Available\n\
    He et al. [27]\nDNN\nNot Available\nBefore: Not Available\nAfter: 52 MB\nInformation\
    \ 2023, 14, 470\n14 of 19\nTable 2. Comparison of software-based features.\nAuthor\n\
    Speed\nPower\nConsumption\nCompression\nRatio\nAccuracy\nYao et al. [19]\nNot\
    \ Available\nBefore: Not\nAvailable\nAfter: 90.6%\nBefore: 71.4%\nAfter: 94.5%\n\
    Not Available\nMolchanov et al.\n[20]\nBefore: 2×\nAfter: 4×\nNot Available\n\
    Not Available\nBefore: 2×\nAfter: 4×\nAnwar et al. [21]\nNot Available\nNot Available\n\
    Before: 98.88%\nAfter: 98.78%\nNot Available\nYang et al. [22]\nBefore: Not\n\
    Available\nAfter: 3.7×\nBefore: Not\nAvailable\nAfter: 13×\nBefore:\nNot Available\n\
    After: 1%\nNot Available\nNarang et al. [23]\nNot Available\nNot Available\nNot\
    \ Available\nBefore: 2×\nAfter: 7×\nGuo et al. [24]\nNot Available\nNot Available\n\
    Not Available\nNot Available\nHinton et al. [25]\nNot Available\nNot Available\n\
    Before:\nNot Available\nAfter: 80%\nNot Available\nRavi et al. [26]\nNot Available\n\
    Not Available\nNot Available\nNot Available\nHe et al. [27]\nNot Available\nNot\
    \ Available\nBefore:\nNot Available\nAfter 3.57%.\nBefore: Not\nAvailable\nAfter:\
    \ 34%\nVarious techniques such as pruning, compression, and knowledge distillation\
    \ can\nsigniﬁcantly reduce the model size and computational requirements of DNNs\
    \ while main-\ntaining high accuracy on various tasks. In terms of compression\
    \ rate, Guo et al. [24]\nreported a greater compression rate of 17.7× when compared\
    \ with reported works of\nMolchanov et al. [20], Yang et al. [22], and Narang\
    \ et al. [23]. In terms of power consump-\ntion, the approaches proposed in these\
    \ papers vary in their focus and methodology, but\nthey all aim to reduce the\
    \ power consumption of DNNs in different ways. Some papers\nfocus on model compression\
    \ and pruning, while others focus on design. Yao et al. [19]\nreported average\
    \ power consumption of 94.5%, as many papers did not report power\nconsumption\
    \ of their works. Overall, it is difﬁcult to compare the accuracy results across\n\
    these papers as they use different datasets and tasks, and some of them focus\
    \ on aspects\nother than accuracy. However, Molchanov et al. [20] reported a greater\
    \ accuracy of 94.2%\nwhen compared with other reported existing works’ accuracy.\n\
    5.2. Comparison of Hardware-Based Approaches\nThe hardware- based approaches utilize\
    \ various hardware components such as pro-\ncessors, memory, etc., to ﬁt DNNs\
    \ on low-resource devices, which can improve efﬁciency\nand accuracy. With various\
    \ existing works we have reported in this paper, it is essential\nto compare various\
    \ aspects of these approaches. In Tables 3 and 4, we compare different\nhardware-based\
    \ approaches and features to provide greater insight of these reported works.\n\
    These papers propose different hardware architectures for accelerating DNNs, with\n\
    a focus on different application scenarios and optimization goals.\nLi et al.\
    \ [32] and\nChen et al. [34,35] present designs that achieve high energy efﬁciency\
    \ while maintaining\naccuracy, while Dinelli et al. [33] propose a design that\
    \ reduces off-chip memory accesses.\nShen et al. [29] focus on the application\
    \ scenario of edge devices, while Chen et al. [34,35]\npresent ﬂexible architectures\
    \ that support emerging NN models. Suleiman et al. [31] re-\nported greater speed\
    \ with 200 FPSwhen compared with Dong et al. [30] and Chen et al. [34].\nSuleiman\
    \ et al. [31] reported the lowest power consumption, with 2 mW. Shen et al. [29]\n\
    reported a higher accuracy of 98.7% when compared with other accuracies reported.\n\
    Information 2023, 14, 470\n15 of 19\nTable 3. Comparison of hardware-based approaches.\n\
    Author\nNetwork\nType\nAccelerator\nPlatform\nSize\nShen et al. [29]\nCNN\nNA\n\
    SoC\nNot Available\nDong et al. [30]\nCNN\nNvidia Jetson\nTX2\nNot Available\n\
    Not Available\nSuleiman et al. [31]\nCNN\nVIO\naccelerator\nCMOS\nBefore: Not\
    \ Available\nAfter: 6.4 mm\nLi et al. [32]\nCNN\nXilinx VC709\nFPGA\nBefore: Not\
    \ Available\nAfter: 1.45\nDinelli et al. [33]\nCNN\nXilinx, Intel\nFPGA\nNot Available\n\
    Chen et al. [34]\nCNN\nEyeriss\nNOC\nBefore: Not Available\nAfter: 168 PEs\nChen\
    \ et al. [35]\nDNN\nEyeriss v2\nNoC\nBefore: Not Available\nAfter: 1024 PEs\n\
    Table 4. Comparison of hardware-based features.\nAuthor\nSpeed\nPower Consumption\n\
    Accuracy\nShen et al. [29]\nNot Available\nNot Available\nBefore: Not Available\n\
    After: 98.7%\nDong et al. [30]\nBefore: Not Available\nAfter: 30 FPS\nNot Available\n\
    Not Available\nSuleiman et al. [31]\nBefore: Not Available\nAfter: 200 FPS\n2\
    \ mW\nBefore: Not Available\nAfter: 2.3%\nLi et al. [32]\nBefore: Not Available\n\
    After: 156 MHz\nBefore: Not Available\nAfter: 330 W\nNot Available\nDinelli et\
    \ al. [33]\nNot Available\nBefore: Not Available\nAfter: 2.259\nBefore: Not Available\n\
    After: 90.23%\nChen et al. [34]\nBefore: Not Available\nAfter: 35 FPS\nBefore:\
    \ Not Available\nAfter: 45%\nNot Available\nChen et al. [35]\nBefore: Not Available\n\
    After: 42.5×\nBefore: Not Available\nAfter: 11.3×\nBefore: Not Available\nAfter:\
    \ 80.43%\n5.3. Comparison of Hardware-/Software-Based Approaches\nHardware/software\
    \ co-design approaches leverage the strengths of both hardware\nand software methods,\
    \ combining their capabilities to achieve optimized solutions for com-\nplex computing\
    \ tasks. In Tables 5 and 6, we compare various aspects of hardware/software\n\
    co-design approaches and features. By providing a comprehensive overview of these\
    \ ap-\nproaches, we aim to assist in making informed decisions when choosing and\
    \ implementing\nhardware/software co-design approaches.\nThe three listed papers\
    \ focus on developing efﬁcient accelerators for deep learning\ninference on different\
    \ platforms. In terms of memory, Lane et al. [5] reduced the memory\nusage size\
    \ by 75.5%, whereas the remaining two papers did not mention the memory\nusage.\
    \ In terms of power consumption, Ding et al. [36] reduced the power usage by 61.6%,\n\
    whereas Zhang et al. [37] reduced the power usage by 1.97 w. Lane et al. [5] improved\
    \ the\nspeed by 5.8 times when compared with other networks. Overall, it is difﬁcult\
    \ to compare\nthe accuracy results across these papers, as some papers did not\
    \ report the accuracy of the\ndeveloped approaches.\nTable 5. Comparison of hardware/software\
    \ co-design-based approach.\nAuthor\nNetwork Type\nAccelerator\nPlatform\nMemory\n\
    Lane et al. [35]\nDNN\nDeepx\nSoC\nNot Available\nDing et al. [36]\nDNN\nNot Available\n\
    Custom\nNot Available\nZhang et al. [37]\nCNN\nFitNN\nFPGA\nNot Available\nInformation\
    \ 2023, 14, 470\n16 of 19\nTable 6. Comparison of hardware/software co-design-based\
    \ features.\nAuthor\nSpeed\nPower Consumption\nAccuracy\nLane et al. [35]\nBefore:\
    \ Not Available\nAfter: 5.8 faster\nNot Available\nBefore: Not Available\nAfter:\
    \ 15%\nDing et al. [36]\nNot Available\nBefore: Not Available\nAfter: 61.6%\n\
    Not Available\nZhang et al. [37]\nBefore: Not Available\nAfter: 9 FPS\nBefore:\
    \ Not Available\nAfter: 1.97 W\nNot Available\n6. Discussions\nThis review paper\
    \ examined various hardware/software-based solutions for the im-\nplementation\
    \ of deep learning networks (DNNs) on devices that are limited in resources.\n\
    These solutions include model compression, quantization, and hardware-based solutions.\n\
    Model compression allows for a reduction in model size, a decrease in memory consump-\n\
    tion, and an increase in inference speed. Quantization techniques reduce the number\n\
    of parameters, allowing DNNs to be deployed on devices with fewer resources. Addi-\n\
    tionally, quantization methods can be used to reduce the precision of data types,\
    \ further\nreducing memory usage and computing requirements. Finally, hardware-based\
    \ solutions\nallow for the ofﬂoading of intensive calculations from the primary\
    \ processor, allowing\nfor more system resources to be used for other tasks. Hardware/software\
    \ co-design is a\ncombination of hardware and software approaches that seeks to\
    \ achieve optimal DNN\nperformance on devices with limited resources. By combining\
    \ hardware accelerators with\nsoftware optimization, co-designed systems can be\
    \ more efﬁcient and cost-effective than\npure software implementations. This type\
    \ of approach allows for more granular optimiza-\ntion, including hardware-speciﬁc\
    \ optimization for critical operations, while also taking\nadvantage of software-based\
    \ modeling and quantization techniques. Both co-design and\nhardware-based approaches\
    \ have their own trade-offs, with software-based approaches\ntypically requiring\
    \ additional hardware components that can increase system complexity\nand cost.\
    \ Ultimately, the selection of an approach is dependent on the device’s resource\n\
    limitations, performance needs, and the desired application. Table 7 provides\
    \ a comparison\nof all three approaches for various parameters that were discussed\
    \ earlier.\nTable 7. Comparison of all three approaches.\nParameter\nApproach\n\
    Author\nNetwork\nType\nAccelerator\nObtained\nResult\nPower\nconsumption\nSoftware\n\
    Yao et al. [19]\nDNN\nNot available\n90.6%\nHardware\nSuleiman et al. [31]\nCNN\n\
    VIO\naccelerator\n2 mW\nHardware/\nsoftware co-design\nZhang et al. [37]\nCNN\n\
    FitNN\n1.97 W\nCompression rate\nSoftware\nGuo et al. [24]\nDNN\nNot available\n\
    17.7×\nHardware\nNot available\nNot available\nNot available\nNot\navailable\n\
    Hardware/\nsoftware co-design\nNot available\nNot available\nNot available\nNot\n\
    available\nSpeed\nSoftware\nMolchanov et al. [20]\nCNN\nNot available\n4×\nHardware\n\
    Suleiman et al. [31]\nCNN\nVIO\naccelerator\n200 FPS\nHardware/\nsoftware co-design\n\
    Zhang et al. [37]\nCNN\nFitNN\n9 FPS\nInformation 2023, 14, 470\n17 of 19\nTable\
    \ 7. Cont.\nParameter\nApproach\nAuthor\nNetwork\nType\nAccelerator\nObtained\n\
    Result\nMemory\nSoftware\nYao et al. [19]\nDNN\nNot available\n98.8%\nHardware\n\
    Not available\nNot available\nNot available\nNot\navailable\nHardware/\nsoftware\
    \ co-design\nNot available\nNot available\nNot available\nNot\navailable\nAccuracy\n\
    Software\nMolchanov et al. [20]\nCNN\nNot available\n94.2%\nHardware\nShen et\
    \ al. [29]\nCNN\nNot available\n98.7%\nHardware/\nsoftware co-design\nLane et\
    \ al. [35]\nDNN\nDeepX\n15%\nincrease\n7. Future Prospectus, Challenges, Advantages,\
    \ Applications\nFuture Prospectus: Low-resource devices are poised to have a signiﬁcant\
    \ impact\non various industries and domains in the coming years. With advancements\
    \ in edge\ncomputing and the proliferation of IoT devices, low-resource devices\
    \ are expected to play a\nmajor role in enabling smart cities, smart homes, and\
    \ smart industries [38]. They can enable\nreal-time data processing, improve automation,\
    \ and facilitate seamless communication\nbetween devices, paving the way for a\
    \ more interconnected and intelligent world.\nSecurity Considerations: Security\
    \ is a crucial aspect of low-resource devices, as they\nare often connected to\
    \ the Internet and may handle sensitive data. Securing low-resource\ndevices presents\
    \ unique challenges due to their limited processing power and memory,\nmaking\
    \ it essential to implement efﬁcient security measures [39]. Ensuring data integrity,\n\
    authentication, and conﬁdentiality are key considerations for securing low-resource\
    \ devices\nand protecting against potential cyber threats.\nChallenges: Low-resource\
    \ devices face several challenges, including limited process-\ning power, memory,\
    \ and storage, which can impact their performance and functionality.\nDeveloping\
    \ NNs that can run efﬁciently on resource-constrained devices can be challenging,\n\
    as they require optimization to operate with limited resources [40]. Power management\n\
    is another challenge, as low-resource devices are often battery-powered and need\
    \ to be\nenergy-efﬁcient to extend their operational lifespan.\nAdvantages: Despite\
    \ their limitations, low-resource devices offer several advantages. They\nare\
    \ cost-effective, as they are often cheaper to manufacture and maintain compared\
    \ to high-\nend computing devices. Low-resource devices are also compact and portable,\
    \ making them\nsuitable for deployment in remote or constrained environments [39].\
    \ They can enable real-time\ndata processing at the edge, reducing the requirement\
    \ for data transmission to the cloud and\nminimizing latency. Additionally, low-resource\
    \ devices can operate in harsh environments and\nhave longer battery life, making\
    \ them ideal for IoT and embedded applications.\nApplications: Low-resource devices\
    \ ﬁnd applications in various domains, including\nhealthcare, agriculture, logistics,\
    \ industrial automation, and smart home systems [41]. In\nhealthcare, low-resource\
    \ devices can be used for remote patient monitoring, telemedicine,\nand wearable\
    \ health devices. In agriculture, they can enable precision farming, smart\nirrigation,\
    \ and livestock monitoring. In logistics, low-resource devices can be utilized\
    \ for\ntracking and monitoring assets, optimizing supply chain operations, and\
    \ improving ﬂeet\nmanagement. In industrial automation, they can be used for machine\
    \ monitoring, predictive\nmaintenance, and process optimization [42]. In smart\
    \ home systems, low-resource devices\ncan control and automate household appliances,\
    \ lighting, and security systems.\n8. Conclusions\nDeploying neural networks on\
    \ low-resource devices can aid in reducing network\ncongestion by enabling computations\
    \ to be executed near the data sources, maintaining\nprivacy, and lowering power\
    \ consumption. This study was undertaken to provide a\ndescription of the current\
    \ methods that ensure the performance of neural network models\nInformation 2023,\
    \ 14, 470\n18 of 19\non hardware with low resources. This review focuses on previously\
    \ published studies\nrelated to the implementation of DNNs on various devices.\
    \ The examined methods detail\nhow to reduce DNN models and implement them on\
    \ resource-constrained hardware\nplatforms. This deployment process may be carried\
    \ out using either software, hardware, or\ncombined hardware and software. It\
    \ is essential to note that the three approaches are not\nmutually exclusive.\
    \ Requirements such as computational complexity, privacy, and energy\nconsumption\
    \ will determine which software and hardware approach will be required.\nSoftware\
    \ and hardware advancements have played a crucial role in the recent success and\n\
    broad acceptance of AI technologies, making it faster and more efﬁcient to design\
    \ and\ndeploy intelligent systems. However, many obstacles remain, such as the\
    \ need for more\nefﬁcient and scalable electronic technology, improved algorithms\
    \ and architectures, and\nmore resilient AI solutions.\nFunding: This research\
    \ received no external funding.\nConﬂicts of Interest: The authors declare no\
    \ conﬂict of interest.\nReferences\n1.\nFowers, J.; Ovtcharov, K.; Papamichael,\
    \ M.; Massengill, T.; Liu, M.; Lo, D.; Alkalay, S.; Haselman, M.; Adams, L.; Ghandi,\
    \ M.;\net al. A conﬁgurable cloud-scale DNN processor for real-time AI. In Proceedings\
    \ of the 45th Annual International Symposium on\nComputer Architecture, Los Angeles,\
    \ CA, USA, 1–6 June 2018.\n2.\nMerenda, M.; Porcaro, C.; Iero, D. Edge machine\
    \ learning for ai-enabled IoT devices: A review. Sensors 2020, 20, 2533. [CrossRef]\n\
    3.\nMishra, R.; Gupta, H.P.; Dutta, T. A survey on deep neural network compression:\
    \ Challenges, overview, and solutions. arXiv\n2020, arXiv:2010.03954.\n4.\nZhichao,\
    \ Z.; Abbas, Z.K. Implementation of DNNs on IoT devices. Neural Comput. Appl.\
    \ 2020, 1, 1327–1356.\n5.\nLane, N.D.; Bhattacharya, S.; Georgiev, P.; Forlivesi,\
    \ C.; Jiao, L.; Qendro, L.; Kawsar, F. DeepX: A Software Accelerator for\nLow-Power\
    \ Deep Learning Inference on Mobile Devices. In Proceedings of the 15th ACM/IEEE\
    \ International Conference on\nInformation Processing in Sensor Networks (IPSN),\
    \ Vienna, Austria, 11–14 April 2016; pp. 1–12.\n6.\nWu, B.; Wan, A.; Iandola,\
    \ F.; Jin, P.H.; Keutzer, K. SqueezeDet: Uniﬁed, Small, Low Power Fully Convolutional\
    \ Neural Networks\nfor Real-Time Object Detection for Autonomous Driving. In Proceedings\
    \ of the 2017 IEEE Conference on Computer Vision and\nPattern Recognition Workshops\
    \ (CVPRW), Honolulu, HI, USA, 21–26 July 2017; pp. 446–454.\n7.\nRamasubramanian,\
    \ A.K.; Mathew, R.; Preet, I.; Papakostas, N. Review and application of Edge AI\
    \ solutions for mobile collabora-\ntive robotic platforms. Procedia CIRP 2022,\
    \ 107, 1083–1088. [CrossRef]\n8.\nDupuis, E.; Novo, D.; O’Connor, I.; Bosio, A.\
    \ Fast exploration of weight sharing opportunities for CNN compression. arXiv\
    \ 2021,\narXiv:2102.01345.\n9.\nChmiel, B.; Baskin, C.; Banner, R.; Zheltonozhskii,\
    \ E.; Yermolin, Y.; Karbachevsky, A.; Bronstein, A.M.; Mendelson, A. Feature\n\
    map transform coding for energy-efﬁcient cnn inference. In Proceedings of the\
    \ 2020 International Joint Conference on Neural\nNetworks (IJCNN), Glasgow, UK,\
    \ 19–24 July 2020; pp. 1–9.\n10.\nRoy, S.K.; Harandi, M.; Nock, R.; Hartley, R.\
    \ Siamese networks: The tale of two manifolds. In Proceedings of the IEEE/CVF\n\
    International Conference on Computer Vision, Seoul, Republic of Korea, 27 October–2\
    \ November 2019; pp. 3046–3055.\n11.\nDiaconu, N.; Worrall, D. Learning to convolve:\
    \ A generalized weight-tying approach. In Proceedings of the International\nConference\
    \ on Machine Learning, Long Beach, CA, USA, 9–15 June 2019; pp. 1586–1595.\n12.\n\
    Jain, S.; Hamidi-Rad, S.; Racapé, F. Low rank based end-to-end deep neural network\
    \ compression. In Proceedings of the 2021\nData Compression Conference (DCC),\
    \ Snowbird, UH, USA, 23–26 March 2021; pp. 233–242.\n13.\nZhang, Q.; Cheng, X.;\
    \ Chen, Y.; Rao, Z. Quantifying the knowledge in a DNN to explain knowledge distillation\
    \ for classiﬁcation.\nIEEE Trans. Pattern Anal. Mach. Intell. 2022, 45, 5099–5113.\
    \ [CrossRef] [PubMed]\n14.\nCourbariaux, M.; Hubara, I.; Soudry, D.; El-Yaniv,\
    \ R.; Bengio, Y. Binarized Neural Networks: Training Deep Neural Networks\nwith\
    \ Weights and Activations Constrained to +1 or −1. arXiv 2016, arXiv:1602.02830.\n\
    15.\nRastegari, M.; Ordonez, V.; Redmon, J.; Farhadi, A. XNOR-Net: ImageNet Classiﬁcation\
    \ Using Binary Convolutional Neural\nNetworks. In Proceedings of the Computer\
    \ Vision–ECCV 2016, 14th European Conference, Amsterdam, The Netherlands, 11–14\n\
    October 2016; Volume 9908, pp. 525–542.\n16.\nC.C.A. License. TensorFlow Lite\
    \ for Microcontrollers. Available online: https://www.tensorﬂow.org/lite/microcontrollers\n\
    (accessed on 22 July 2022).\n17.\nSze, V.; Chen, Y.-H.; Yang, T.-J.; Emer, J.S.\
    \ Efﬁcient Processing of Deep Neural Networks: A Tutorial and Survey. Proc. IEEE\
    \ 2017,\n105, 2295–2329. [CrossRef]\n18.\nParashar, A.; Raina, P.; Shao, Y.S.;\
    \ Chen, Y.H.; Ying, V.A.; Mukkara, A.; Venkatesan, R.; Khailany, B.; Keckler,\
    \ S.W.; Emer, J.\nTimeloop: A systematic approach to dnn accelerator evaluation.\
    \ In Proceedings of the 2019 IEEE International Symposium on\nPerformance Analysis\
    \ of Systems and Software (ISPASS), Madison, WI, USA, 24–26 March 2019; pp. 304–315.\n\
    Information 2023, 14, 470\n19 of 19\n19.\nYao, S.; Zhao, Y.; Zhang, A.; Su, L.;\
    \ Abdelzaher, T.F. DeepIoT: Compressing Deep Neural Network Structures for Sensing\
    \ Systems\nwith a Compressor-Critic Framework. In Proceedings of the 15th ACM\
    \ Conference on Embedded Network Sensor Systems, Delft,\nThe Netherlands, 6–8\
    \ November 2017; pp. 1–14.\n20.\nMolchanov, P.; Tyree, S.; Karras, T.; Aila, T.;\
    \ Kautz, J. Pruning Convo-lutional Neural Networks for Resource Efﬁcient Inference.\n\
    In Proceedings of the International Conference on Learning Representation (ICLR),\
    \ Toulon, France, 24–26 April 2017.\n21.\nAnwar, S.; Sung, W. Compact Deep Convolutional\
    \ Neural Networks with Coarse Pruning. arXiv 2016, arXiv:1610.09639.\n22.\nYang,\
    \ T.-J.; Chen, Y.-H.; Sze, V. Designing Energy-Efﬁcient Convo- lutional Neural\
    \ Networks Using Energy-Aware Pruning. In\nProceedings of the IEEE Conference\
    \ on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 18–20\
    \ June 2017;\npp. 5687–5695.\n23.\nNarang, S.; Diamos, G.; Sengupta, S.; Elsen,\
    \ E. Exploring Sparsity in Recurrent Neural Networks. In Proceedings of the\n\
    International Conference on Learning Representations, Toulon, France, 24–26 April\
    \ 2017.\n24.\nGuo, Y.; Yao, A.; Chen, Y. Dynamic Network Surgery for Efﬁcient\
    \ DNNs. In Proceedings of the 30th International Conference on\nNeural Information\
    \ Processing Systems (NIPS’16), Barcelona, Spain, 5 December 2016; pp. 1387–1395.\n\
    25.\nHinton, G.; Vinyals, O.; Dean, J. Distilling the Knowledge in a Neural Network.\
    \ In Proceedings of the NIPS Deep Learning and\nRepresentation Learning Workshop,\
    \ Montréal, QC, Canada, 11 December 2015.\n26.\nRavi, D.; Wong, C.; Lo, B.; Yang,\
    \ G.-Z. A Deep Learning Approach to on-Node Sensor Data Analytics for Mobile or\
    \ Wearable\nDevices. IEEE J. Biomed. Health Inform. 2017, 21, 56–64. [CrossRef]\
    \ [PubMed]\n27.\nHe, K.; Zhang, X.; Ren, S.; Sun, J. Deep Residual Learning for\
    \ Image Recognition. In Proceedings of the 2016 IEEE Conference on\nComputer Vision\
    \ and Pattern Recognition (CVPR), Las Vegas, NV, USA, 27–30 June 2016; pp. 770–778.\n\
    28.\nHam, M.; Moon, J.; Lim, G.; Jung, J.; Ahn, H.; Song, W.; Woo, S.; Kapoor,\
    \ P.; Chae, D.; Jang, G.; et al. NNStreamer: Efﬁcient and\nAgile Development of\
    \ On- Device AI Systems. In Proceedings of the IEEE/ACM 43rd International Conference\
    \ on Software\nEngineering: Software Engineering in Practice (ICSE-SEIP), Madrid,\
    \ Spain, 25–28 May 2021; pp. 198–207.\n29.\nShen, F.-J.; Chen, J.-H.; Wang, W.-Y.;\
    \ Tsai, D.-L.; Shen, L.-C.; Tseng, C.-T. A CNN-Based Human Head Detection Algorithm\n\
    Implemented on Edge AI Chip. In Proceedings of the 2020 International Conference\
    \ on System Science and Engineering (ICSSE),\nKagawa, Japan, 31 August–3 September\
    \ 2020; pp. 1–5.\n30.\nDong, L.; Yang, Z.; Cai, X.; Zhao, Y.; Ma, Q.; Miao, X.\
    \ WAVE: Edge-Device Cooperated Real-time Object Detection for Open-air\nApplications.\
    \ IEEE Trans. Mob. Comput. 2022, 22, 4347–4357. [CrossRef]\n31.\nSuleiman, A.;\
    \ Zhang, Z.; Carlone, L.; Karaman, S.; Sze, V. Navion: A 2-mW Fully Integrated\
    \ Real-Time Visual-Inertial Odometry\nAccelerator for Autonomous Navigation of\
    \ Nano Drones. IEEE J. Solid-State Circuits 2019, 54, 1106–1119. [CrossRef]\n\
    32.\nLi, H.; Fan, X.; Jiao, L.; Cao, W.; Zhou, X.; Wang, L. A high performance\
    \ FPGA-based accelerator for large-scale convolutional\nneural networks. In Proceedings\
    \ of the 26th International Conference on Field Programmable Logic and Applications\
    \ (FPL),\nLausanne, France, 29 August–2 September 2016; pp. 1–9.\n33.\nDinelli,\
    \ G.; Meoni, G.; Rapuano, E.; Benelli, G.; Fanucci, L. An FPGA-Based Hardware\
    \ Accelerator for CNNs Using On-Chip\nMemories Only: Design and Benchmarking with\
    \ Intel Movidius Neural Compute Stick. Int. J. Reconﬁgurable Comput. 2019,\n2019,\
    \ 7218758. [CrossRef]\n34.\nChen, Y.-H.; Krishna, T.; Emer, J.S.; Sze, V. Eyeriss:\
    \ An Energy-Efﬁcient Reconﬁgurable Accelerator for Deep Convolutional\nNeural\
    \ Networks. IEEE J. Solid-State Circuits 2017, 52, 127–138. [CrossRef]\n35.\n\
    Chen, Y.-H.; Yang, T.-J.; Emer, J.S.; Sze, V. Eyeriss v2: A Flexible Accelerator\
    \ for Emerging Deep Neural Networks on Mobile\nDevices. IEEE J. Emerg. Sel. Top.\
    \ Circuits Syst. 2019, 9, 292–308. [CrossRef]\n36.\nDing, R.; Liu, Z.; Blanton,\
    \ R.D.S.; Marculescu, D. Quantized Deep Neural Networks for Energy Efﬁcient Hardware-based\n\
    Inference. In Proceedings of the 2018 23rd Asia and South Paciﬁc Design Automation\
    \ Conference (ASP-DAC), Jeju, Republic of\nKorea, 22–25 January 2018; pp. 1–8.\n\
    37.\nZhang, Z.; Mahmud, M.P.; Kouzani, A.Z. FitNN: A Low-Resource FPGA-Based CNN\
    \ Accelerator for Drones. IEEE Internet Things\nJ. 2022, 9, 21357–21369. [CrossRef]\n\
    38.\nSarker, I.H. AI-Based Modeling: Techniques, Applications and Research Issues.\
    \ SN Comput. Sci. 2022, 3, 158. [CrossRef] [PubMed]\n39.\nTan, B.; Karri, R. Challenges\
    \ and New Directions for AI and Hard-ware Security. In Proceedings of the 2020\
    \ IEEE 63rd International\nMidwest Symposium on Circuits and Systems (MWSCAS),\
    \ Springﬁeld, MA, USA, 9–12 August 2020; pp. 277–280.\n40.\nPabby, G.; Kumar,\
    \ N. A Review on Artiﬁcial Intelligence, Challenges Involved and Its Applications.\
    \ Int. J. Adv. Res. Comput. Eng.\nTechnol. 2017, 6.\n41.\nBezboruah, T.; Bora,\
    \ A. Artiﬁcial intelligence: The technology, challenges and applications. Trans.\
    \ Mach. Learn. Artif. Intell. 2020,\n8, 44–51.\n42.\nHu, Y.; Li, W.; Wright, D.;\
    \ Aydin, O.; Wilson, D.; Maher, O.; Raad, M. Artiﬁcial Intelligence Approaches.\
    \ The Geographic\nInformation Science and Technology Body of Knowledge (3rd Quarter\
    \ 2019 Edition). arXiv 2019, arXiv:1908.10345. [CrossRef]\nDisclaimer/Publisher’s\
    \ Note: The statements, opinions and data contained in all publications are solely\
    \ those of the individual\nauthor(s) and contributor(s) and not of MDPI and/or\
    \ the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury\
    \ to\npeople or property resulting from any ideas, methods, instructions or products\
    \ referred to in the content.\n"
  inline_citation: '>'
  journal: Information (Basel)
  limitations: '>'
  pdf_link: https://www.mdpi.com/2078-2489/14/8/470/pdf?version=1692619844
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: Advancements in On-Device Deep Neural Networks
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.22617/fls200124
  analysis: '>'
  authors: []
  citation_count: 2
  full_citation: '>'
  full_text: ">\n20\n48\nCONTENTS\nCHAPTER 1   \nSUPPORTING A PROSPEROUS, \nINCLUSIVE,\
    \ RESILIENT,  \nAND SUSTAINABLE ASIA  \nAND THE PACIFIC\nCHAPTER 2  \nREGIONS\n\
    20  \nCentral and West Asia\n24 \nEast Asia\n28 \nPacific\n32 \nSouth Asia\n36\
    \ \nSoutheast Asia\nCHAPTER 3 \nDEVELOPING  \nTHE PRIVATE SECTOR\nPrivate Sector\
    \ Operations and  \nthe Promotion of Public–Private \nPartnerships\nCHAPTER 4\
    \ \nORGANIZATIONAL  \nEFFECTIVENESS\nDelivering Through a Stronger,  \nBetter,\
    \ and Faster ADB\n2  \nPRESIDENT’S MESSAGE\n4  \nBOARD OF DIRECTORS\n6  \nFINANCIAL\
    \ HIGHLIGHTS\n56  \nAPPENDIXES\n10\n40\nSMART READER\nRead the Annual Report on\
    \ your \nsmart device or screen at:  \nwww.adb.org/ar2019/digital \nThe Annual\
    \ Report of  \nthe Asian Development \nBank fulfills a requirement \nunder the\
    \ bank’s By‑Laws \nfor a report from the \nBoard of Directors to the \nAnnual\
    \ Meeting of the \nBoard of Governors on the \noperations and policies \nof the\
    \ bank. This Annual \nReport covers the period \nJanuary to December 2019 \nto\
    \ align with ADB’s financial \nstatements for that year.  \nIt therefore does\
    \ not discuss \nin detail the bank’s response \nto COVID‑19. To find out \nhow\
    \ ADB is supporting its \nmembers across Asia and \nthe Pacific to tackle the\
    \ \ncrisis, please see  \nwww.adb.org/covid‑19.\n2019\nANNUAL \nREPORT\nASIAN\
    \ DEVELOPMENT BANK\n2\nADB ANNUAL REPORT 2019 \nThis Annual \nReport provides\
    \ \na comprehensive \naccount of the \nactivities and \nfinancial results \nof\
    \ the Asian \nDevelopment Bank \n(ADB) in 2019. \nWe present this \nreport after\
    \ the \nfirst full year of \nimplementation of ADB’s Strategy 2030, and as I \n\
    begin my tenure as President. \nI am pleased to return to ADB after 30 years,\
    \ \nwhen I served as chief advisor to former President \nKimimasa Tarumizu. Asia\
    \ and the Pacific has \nmade remarkable economic and social progress \nin that\
    \ time, and our operations have since \nevolved to respond to the emerging needs\
    \ of \nour developing member countries (DMCs). \nHowever, extreme poverty still\
    \ exists and income \ninequality is widening. Globalization and digitization \n\
    have transformed economies while placing some \ngroups at greater risk, particularly\
    \ in the face of \naging trends and demographic shifts. Despite some \nprogress,\
    \ gender inequality persists, and climate \nchange, ocean pollution, and disasters\
    \ have placed a \nheavy burden on the poor and vulnerable.\nThese challenges will\
    \ now magnify as a result of \nCOVID‑19. As I write these words in April 2020,\
    \ the \npandemic has become a global health emergency \nrequiring forceful action\
    \ at the national, regional, \nand international levels. Working closely with\
    \ our \nDMCs and partner institutions, we responded with \na $20 billion package\
    \ to finance an aggressive set of \nactions to empower governments and businesses\
    \ \nin Asia and the Pacific to tackle the severe health \nand macroeconomic impacts,\
    \ address the urgent \nneeds of the poor, sick, and vulnerable; and blaze a \n\
    path to strong recovery. To deliver the package in a \nmuch faster, more tailored,\
    \ and impactful manner, \nwe further streamlined our business processes, and \n\
    made the terms and conditions of our lending more \nflexible. Our swift response\
    \ was made possible by \na strong capital base, capable and motivated staff, \n\
    and a close relationship with member countries that \nspeaks to our reputation\
    \ as a steadfast and long‑\nterm development partner in Asia and the Pacific.\n\
    The demand for ADB assistance remained strong \nin 2019. We committed $21.64 billion\
    \ in loans and \nPRESIDENT’S \nMESSAGE\nI am encouraged \nby our efforts \nin\
    \ 2019. I am \nheartened by \nwhat we have \nachieved so far \nin 2020. We will\
    \ \nbuild on these \nachievements \nto ensure we \nremain relevant \nand responsive\
    \ \nto our members’ \nneeds as they \ntake action to \ncombat, and \nthen recover\
    \ \nfrom, the \nCOVID-19 \npandemic. \ngrants to support our DMCs. We provided\
    \ $4.49 billion \nin concessional assistance and $17.15 billion from \nour regular\
    \ ordinary capital resources. This included \na $1 billion special policy‑based\
    \ loan to Pakistan \nas part of a comprehensive multidonor economic \nreform program\
    \ led by the International Monetary \nFund to stabilize the country’s economy\
    \ after a major \ndeterioration in its fiscal and financial position. \nOur nonsovereign\
    \ operations exceeded $3 billion \nfor the second year in a row. This result reflects\
    \ \nour plan to expand our private sector investments \ninto new sectors and frontier\
    \ markets and increase \nsupport for fragile and conflict‑affected situations,\
    \ \nsmall‑island developing states, and low‑income \ncountries. Our private operations\
    \ also mobilized \ncofinancing of $6.98 billion. Together with official and \n\
    commercial confinancing and technical assistance, \nADB’s total commitments for\
    \ 2019 were $33.74 billion. \nDisbursements, excluding cofinancing, improved \n\
    again in 2019, rising 16.1% to a record $16.47 billion.\nOur operations strongly\
    \ supported the thematic \ntargets of Strategy 2030. We met our 2015 goal of \n\
    doubling climate financing to $6 billion—1 year \nahead of schedule—and under\
    \ Strategy 2030 have \nfurther strengthened our climate targets to ensure \nthat\
    \ at least 75% of our operations focus on climate \nadaptation and mitigation\
    \ efforts, while providing \n$80 billion in cumulative climate financing by \n\
    2030. We are also on track to achieve our target of \npromoting gender equality\
    \ in at least 75% of ADB’s \nsovereign and nonsovereign operations. This is vital\
    \ \nwork that tackles the structural challenges that impede \nwomen and girls’\
    \ ability to reach their full potential. \nOur knowledge work is an important\
    \ resource \nfor DMCs. In 2019, to mark the 50th edition of \nour flagship Key\
    \ Indicators for Asia and the Pacific \nseries, we launched a new database to\
    \ broaden \naccess to its comprehensive macroeconomic \nand social indicators.\
    \ We also hosted events \non key development issues, such as the Digital \nDevelopment\
    \ Forum and Asia Clean Energy Forum, \nand continued to share practical knowledge\
    \ from \nADB’s development projects to help improve the \ndesign and implementation\
    \ of future projects.\nInternally, we strengthened staff mobility and talent \n\
    development. We accelerated information technology \nreforms and digital transformation\
    \ initiatives, which, \ncritically, allowed ADB to transition smoothly and \n\
    effectively—without disruption to operations—to \nwork‑from‑home arrangements\
    \ for all staff beginning \nMarch 2020 during the COVID‑19 pandemic. We \n3\n\
    PRESIDENT’S MESSAGE \nPresident Asakawa visits an ADB project to improve living\
    \ conditions for the poor \nin Makassar City, Indonesia; his first visit to the\
    \ country since assuming office.\nLeft to right: Vice-Presidents Bambang Susantono,\
    \ Diwakar Gupta, Deborah Stokes, Ingrid van Wees, Shixin Chen, Ahmed M. Saeed\
    \ (succeeded \nStephen Groff on 26 February 2019); The Secretary Eugenue Zhukov\n\
    MANAGEMENT TEAM\nMASATSUGU ASAKAWA \nPresident and Chairperson  \nof the Board\
    \ of Directors\nalso increased the number of women international \nstaff. Women\
    \ now account for 36.6% of ADB’s \ninternational staff, demonstrating good progress\
    \ \ntoward the target of 40% by the end of 2022. \nFurther, an independent study\
    \ found no significant \nor unexplained gaps in pay between women and \nmen in\
    \ comparable roles at ADB. These measures \nhelped ADB become the first international\
    \ financial \ninstitution to achieve Economic Dividends for \nGender Equality\
    \ Move (level 2) certification, the \nleading standard for workplace gender equality.\n\
    These activities—and the many others highlighted \nin this report—strongly align\
    \ with the priorities \nof Strategy 2030. I am grateful to former ADB \nPresident\
    \ Takehiko Nakao for overseeing the \ndevelopment of the strategy along with its\
    \ first year \nof implementation. I applaud the Board and our \nmembers for improving\
    \ ADB’s financing capacity \nby introducing differentiated financing terms \n\
    for developing and more developed borrowing \ncountries. I deeply appreciate the\
    \ commitment \nof our members to support our poorest and most \nvulnerable DMCs\
    \ during the Asian Development \nFund 13 replenishment discussions. I thank Fiji\
    \ for \nsuccessfully hosting the ADB Annual Meeting in \nMay, the first time our\
    \ meeting has been hosted by a \nPacific‑island nation. And I extend a warm welcome\
    \ \nto Niue as our newest member, the bank’s 68th \noverall member and 49th from\
    \ Asia and the Pacific.\nOur strategy for the next decade is guided by a \nvision\
    \ of a prosperous, inclusive, resilient, and \nsustainable Asia and the Pacific.\
    \ Our immediate \npriority is to provide vital support to DMCs as they \naddress\
    \ the challenges presented by COVID‑19 and \nseek to return their economies to\
    \ a path of growth \nand prosperity. Throughout our interventions, we \nwill collaborate\
    \ closely with peer organizations, \nincluding the International Monetary Fund;\
    \ the \nWorld Bank Group; regional development banks; \nthe World Health Organization,\
    \ United Nations \nChildren’s Fund, and other United Nations agencies; \nand the\
    \ global community. And we will continue to \nfollow the roadmap we have set.\
    \ We will address \nthe need for large‑scale infrastructure financing \nby mobilizing\
    \ more private sector resources; \nsupport domestic resource mobilization through\
    \ \nstrengthening tax policy and administration, the \nfinance sector, and domestic\
    \ capital markets; target \nhigh‑quality support to our members through \ndifferentiated\
    \ approaches, relevant knowledge, and \nlocal currency lending; respond to immediate\
    \ financial \nand technical needs of countries due to crisis or \ndisaster; and\
    \ coordinate among partners to scale up \nfinancing and tackle global development\
    \ agendas. \nWe will accomplish these through an integrated \nOne ADB approach\
    \ and by celebrating the \ndiversity of our staff across the organization—\nboth\
    \ of which are essential to maintaining ADB’s \ncountry presence and global leadership.\n\
    I am encouraged by our efforts in 2019. I am \nheartened by what we have achieved\
    \ so far in \n2020. We will build on these achievements to \nensure we remain\
    \ relevant and responsive to our \nmembers’ needs as they take action to combat,\
    \ and \nthen recover from, the COVID‑19 pandemic.\n4\nADB ANNUAL REPORT 2019 \n\
    BOARD OF \nDIRECTORS\nADB Board of Directors as of 31 December 2019: Front, left\
    \ to right: Directors Warotai Kosolpisitkul, Paul Dominguez, Kris Panday, In-chang\
    \ Song,  \nTakeshi Kurihara, Kshatrapati Shivaji, President and Chairperson of\
    \ the Board Takehiko Nakao, Zhijun Cheng, Syurkani Ishak Kasim, Pierre-Emmanuel\
    \ \nBeluche, Tony McDonald, Helmut Fischer. Back, left to right: Alternate Directors\
    \ Yuemin Li-Misra, Shahid Mahmood, Leena Viljanen, Yu-Peng Tseng, Kenzo \nOhe,\
    \ Bayrammuhammet Garayev, Jin Lu, Karen Murray, Enrique Galán, Scott Dawson, Burak\
    \ Müezzinoğlu, Jason Chung.\nIn 2019, the ADB Board of Directors held 40 formal\
    \ \nmeetings and 49 informal sessions. It approved \n116 loans, grants, financing\
    \ facilities, equity \ninvestments, and guarantees, and endorsed \nnew country\
    \ partnership strategies for Armenia, \nAzerbaijan, Bhutan, Cambodia, Fiji, Georgia,\
    \ \nNepal, and Uzbekistan. \nMAJOR INITIATIVES\nIn 2019, the Board endorsed plans\
    \ that set out \nhow ADB will implement the seven operational \npriorities of\
    \ Strategy 2030, the bank’s new \nlong term corporate framework. These plans will\
    \ \nguide ADB’s work on (i) poverty and inequality; \n(ii) gender equality; (iii) climate\
    \ change, disaster \nresilience, and environmental sustainability; \n(iv) livable\
    \ cities; (v) rural development and food \nsecurity; (vi) governance and institutional\
    \ capacity; \nand (vii) regional cooperation and integration.\nThe Board approved\
    \ a new corporate results \nframework for 2019–2024 that focuses on \noutcomes\
    \ and aligns with Strategy 2030. It \nincludes new indicators for poverty reduction\
    \ \nand disability inclusion, digital transformation, \nknowledge and innovation,\
    \ renewable energy, and \nquality infrastructure.\nThe contingent disaster financing\
    \ mechanism, \napproved in August, is an important new tool for \ndisaster resilience.\
    \ It will help developing member \ncountries (DMCs) prepare for, and respond to,\
    \ \ndisaster events such as extreme weather. \nThe Board approved mainstreaming\
    \ the use of \nresults‑based lending to enhance ADB operations \nin DMCs, drive\
    \ achievement of development \nresults in government programs, strengthen \ngovernment\
    \ institutions, and foster partnerships \nwith other development agencies. \n\
    In November, the Board approved the \ndiversification of financing terms for regular\
    \ \nordinary capital resources sovereign lending to \ncountries borrowing only\
    \ from these resources. \nNew financing terms will take effect on 1 January \n\
    2021, in line with Strategy 2030 guidance to apply \ndifferentiated approaches\
    \ to meet diverse client \ncountries’ needs.\nThe first‑ever Board forum, held\
    \ in February, \ndiscussed measures to improve Board \neffectiveness. The forum\
    \ complements the Board \nand Management retreat, which in 2019 discussed \nfostering\
    \ innovation, transforming the bank into \na knowledge‑based organization, and\
    \ expanding \nprivate sector operations.\n5\nAPPRECIATION FOR FORMER PRESIDENT\
    \ NAKAO \nMembers of the Board wish to acknowledge the significant  \ncontribution\
    \ made to ADB by former President and Chairperson of  \nthe Board of Directors,\
    \ Takehiko Nakao, who ended his term on  \n16 January 2020 after nearly 7 years\
    \ in office. Under Mr. Nakao’s \nleadership, ADB implemented a number of major\
    \ reforms \nand new policies, including Strategy 2030, that strengthened \nADB’s\
    \ ability to deliver its core mission to help developing \nmembers reduce poverty\
    \ and improve people’s quality of life. \nThe Board will continue to build on\
    \ Mr. Nakao’s legacy under the \nleadership of his successor, President Masatsugu\
    \ Asakawa. \nFormer ADB President Takehiko Nakao delivers his farewell \nspeech\
    \ at ADB headquarters.\n116 \nLOANS, GRANTS, \nFINANCING \nFACILITIES, \nEQUITY\
    \ \nINVESTMENTS, \nAND \nGUARANTEES \nWERE APPROVED \nBY THE BOARD \nOF DIRECTORS\
    \ IN \n2019. DIRECTORS \nALSO ENDORSED \n8 NEW COUNTRY \nPARTNERSHIP \nSTRATEGIES\
    \ \nAND 7 NEW \nOPERATIONAL \nPRIORITY PLANS.\nPARTNERSHIPS AND DIALOGUE\nThe\
    \ Board values the exchange of ideas and \nopinions with government and donor\
    \ partners, \nprivate sector groups, civil society organizations, \nand project\
    \ beneficiaries. Board members gather \nfirst‑hand knowledge of development needs\
    \ \nby visiting several DMCs each year, where they \ninspect ADB‑financed projects\
    \ and consult \nstakeholders, and by engaging with experts in \nspecialist areas.\
    \ \nIn February, directors traveled to Papua New \nGuinea (PNG) and Cambodia,\
    \ where they met \nthe Prime Minister of PNG and the Deputy \nPrime Minister of\
    \ Cambodia. In PNG, the group \nvisited ADB‑supported road projects and local\
    \ \ncommunities in Goroka. In Cambodia, directors \nvisited project sites for\
    \ wastewater treatment, \nirrigation, and skills training.  \nIn June, directors\
    \ visited Mongolia and the People’s \nRepublic of China (PRC), meeting Mongolia’s\
    \ \nDeputy Prime Minister and the PRC’s Vice Premier. \nIn Mongolia, they visited\
    \ a hospital, an urban \ndevelopment project for informal settlements, \nand a\
    \ solar power plant. In the PRC’s Guizhou and \nYunnan provinces, directors visited\
    \ rural poverty \nreduction, urban development, skills training,  \nand water\
    \ resource management project sites. \nIn September, the Board held a colloquium\
    \ with \na high‑level advisory group on digital technology. \nThe eight leaders\
    \ from academia and prominent \ntechnology companies provided expert advice on\
    \ \napplying digital technologies to ADB’s work.\nIn October, directors also visited\
    \ Bangladesh, \nwhere they met the Prime Minister, and the \nLao People’s Democratic\
    \ Republic, where they \nmet the Deputy Prime Minister. In Bangladesh, \nthey\
    \ visited camps in Cox’s Bazar where ADB is \nproviding emergency assistance for\
    \ displaced \npeople. In the Lao People’s Democratic Republic, \ndirectors travelled\
    \ to Vientiane, Bolikhamxay, \nand Luang Prabang provinces to observe flood \n\
    and drought‑risk management and mitigation, \nhydropower and tourism development\
    \ projects.  \nCOMMITTEE HIGHLIGHTS \nDirectors serve on committees to oversee\
    \ and \nguide ADB’s operations. \nIn 2019, the Audit Committee initiated an action\
    \ \nplan to improve oversight of the private sector \nportfolio. It also recommended\
    \ the selection of \nADB’s external auditor and reviewed the Respectful \nWorkplace\
    \ Unit.\nThe Development Effectiveness Committee \nassessed evaluations of ADB’s\
    \ use of private sector \nequity investments, Asian Development Fund \noperations,\
    \ and multitranche financing facilities. \nThe Budget Review Committee discussed\
    \ ADB’s \npreparation of the work program for 2020–2022, \n2019 budget utilization,\
    \ reforms in capital \nexpenditure budgeting, and the bank’s 2020 budget.\nThe\
    \ Board Compliance Review Committee \nassessed action on complaints raised under\
    \ the \nAccountability Mechanism and recommended \nselection of a new member and\
    \ chair to the \nCompliance Review Panel.\nThe Ethics Committee reviewed the code\
    \ of \nconduct, ethics procedures, and associated \nguidelines applicable to ADB\
    \ directors and  \nthe President. The review recommended \namendments to bring\
    \ these standards and \nprocedures into line with the best practices of \ncomparable\
    \ institutions. \nThe Human Resources Committee discussed \npreparations for the\
    \ 2020 review of ADB staff \nbenefits. It also reviewed issues of respect in the\
    \ \nworkplace, staff mobility, use of experts, workforce \nanalysis, and the human\
    \ resources framework to \nsupport Strategy 2030.\nFAST FACTS:\nBOARD OF DIRECTORS\
    \ \n6\nADB ANNUAL REPORT 2019 \nFINANCIAL\nHIGHLIGHTS\nOPERATIONAL HIGHLIGHTS\n\
    ADB Commitments,a 2015–2019 ($ million)\nItem\n2015\n2016\n2017\n2018\n2019\n\
    A. Loans, Grants, and Others\nBy Source\nRegular Ordinary Capital Resources\n\
    \ 13,059  10,967  17,230  16,286 \n 17,155 \nLoans\n 12,894  10,703 \n 16,445\
    \ \n 16,012  16,824 \nEquity Investments\n 152 \n 96 \n 287 \n 274 \n 155 \nGuarantees\n\
    \ 12\n 168 \n 498 \n ‑ \n 175\nConcessional Resources\n 3,125 \n 2,287 \n 2,457\
    \ \n 5,290 \n 4,488 \nConcessional Ordinary Capital Resources Loansb, c\n 2,570\
    \ \n 1,805 \n 2,267 \n 3,872 \n 3,644 \nAsian Development Fund Grants\n 555 \n\
    \ 481 \n 191 \n 1,418 \n 844 \nRegular Ordinary Capital and Concessional \nResources\n\
    \ 16,184  13,253  19,687  21,576  21,643 \nSpecial Fundsd\n 7 \n 9 \n 2 \n 6 \n\
    \ - \nGrants\n 7 \n 9 \n 2 \n 6 \n ‑ \nSubtotal (A)\n 16,191  13,263  19,689 \n\
    \ 21,581  21,643 \nBy Operations\nSovereign\n 14,559 \n 11,512  17,403  18,446\
    \  18,643 \nLoansb\n 13,997 \n 11,021 \n 16,712 \n 17,022 \n 17,799 \nGuarantees\n\
    \ ‑ \n ‑ \n 498\n ‑ \n ‑ \nGrants\n 562 \n 491 \n 193 \n 1,423 \n 844 \nNonsovereign\n\
    \ 1,632 \n 1,750 \n 2,287 \n 3,136 \n 3,000 \nLoans\n 1,467 \n 1,486 \n 2,000\
    \ \n 2,862 \n 2,670 \nEquity Investments\n 152 \n 96 \n 287 \n 274 \n 155 \nGuarantees\n\
    \ 12\n 168 \n ‑ \n ‑ \n 175\nSubtotal (A)\n 16,191  13,263  19,689 \n 21,581 \
    \ 21,643 \nB. Technical Assistancee\nSovereign\n 146 \n 170 \n 192 \n 227 \n 221\
    \ \nNonsovereign\n 4 \n 11 \n 9 \n 14 \n 17 \nSubtotal (B)\n 151 \n 181 \n 201\
    \ \n 241 \n 237 \nC. Cofinancing Including Trust Funds\nSovereignf\n 6,439 \n\
    \ 6,369 \n 5,976 \n 6,489 \n 4,887 \nTrust Funds Administered by ADB\n 189 \n\
    \ 399 \n 86 \n 216 \n 181 \nBilateral\n 1,626 \n 2,577 \n 3,460 \n 1,849 \n 3,592\
    \ \nMultilateral\n 4,330 \n 3,310 \n 2,120 \n 3,304 \n 1,112 \nOthersg\n 294 \n\
    \ 83 \n 310 \n 1,120 \n 1 \nNonsovereignh\n 3,759 \n 5,654 \n 5,947 \n 7,152 \n\
    \ 6,976 \nSubtotal (C)\n 10,198  12,022 \n 11,922  13,641  11,863 \nTOTAL (A +\
    \ B + C)\n 26,540  25,466 \n 31,813  35,464  33,743 \n‑ = nil.\nNote: Numbers\
    \ may not sum precisely because of rounding.\na Commitment is the financing approved\
    \ by ADB’s Board of Directors or Management for which the investment \nagreement\
    \ has been signed by the borrower, recipient, or the investee company and ADB.\
    \  It is the amount indicated in \nthe investment agreement that may or may not\
    \ be equal to the approved amount, depending on the exchange rate at the \ntime\
    \ of signing. In the case of official and commercial cofinancing not administered\
    \ by ADB for which the signed amount \nis not readily available, the approved\
    \ amount is used.  \nb The 2016 and 2017 adjusted figures exclude the transfer,\
    \ respectively, of a $2 million Bangladesh and a $5 million \nPakistan project\
    \ design advance to their 2019 ensuing loans.\nc Formerly Asian Development Fund\
    \ loans. Effective 1 January 2017, ADB transferred loans and other assets from\
    \ the \nAsian Development Fund to ordinary capital resources in accordance with\
    \ the Board of Governors’ resolution authorizing \nthe termination of the Asian\
    \ Development Fund’s lending operations and retaining the Asian Development Fund\
    \ as a \ngrant‑only operation.\nd Special funds other than Asian Development Fund\
    \ such as the Asia Pacific Disaster Response Fund and the Climate \nChange Fund.\
    \ \ne Technical assistance in 2019 totaled $464 million, comprising $237 million\
    \ in technical assistance from the Technical \nAssistance Special Fund and other\
    \ Special Funds, and $226 million from partner cofinancing, including trust funds\
    \ (see \nAppendix 1).\nf The 2018 adjusted figures include an additional Tajikistan\
    \ grant cofinancing amounting to $10 million and exclude a \ncanceled Georgia\
    \ loan cofinancing amounting to $349 million. \ng “Others” includes cofinancing\
    \ for sovereign operations from other sources such as concessionaires, foundations,\
    \ \ngovernment entities, commercial banks, and sovereign wealth funds.\nh Nonsovereign\
    \ cofinancing includes commercial cofinancing such as Trade Finance Program cofinancing,\
    \ B loans, and \nparallel loans, among others. B loans are cofinancing arrangements\
    \ involving the coordinated process of pooling funds \nfrom various sources for\
    \ a single borrower or grant recipient, and/or distributing related risks among\
    \ such other financiers. \nThe 2018 adjusted figure excludes a terminated Bangladesh\
    \ equity cofinancing amounting to $15 million.\n2019 COMMITMENTS\n$21.64 B\nLOANS,\
    \ GRANTS, \nEQUITY INVESTMENTS, \nAND GUARANTEES\n$237 M\nTECHNICAL \nASSISTANCE*\n\
    * Excludes cofinancing  \n(see note e)\n$11.86 B\nCOFINANCING,     \nINCLUDING\
    \  \nTRUST FUNDS\n7\nFINANCIAL HIGHLIGHTS\nRegular Ordinary Capital and Concessional\
    \ Resources Commitments  \nby Sector, 2015–2019 ($ million)\nSector\n2015\n2016\n\
    2017\n2018\n2019\nAgriculture, Natural Resources,  \nand Rural Development\n 916\
    \ \n 976 \n 1,525 \n 2,344 \n 2,271 \nEducation\n 905 \n 619 \n 710 \n 1,629 \n\
    \ 1,127 \nEnergy\n 3,280 \n 2,984 \n 6,211 \n 5,066 \n 2,631 \nFinance\n 2,392\
    \ \n 1,607 \n 2,761 \n 1,992 \n 2,160 \nHealth\n 330 \n 226 \n 211 \n 515 \n 636\
    \ \nIndustry and Trade\n 412 \n 552 \n 357 \n 607 \n 576 \nInformation and Communication\
    \ \nTechnology\n 169 \n 25 \n 70 \n 59 \n 575 \nPublic Sector Management\n 2,084\
    \ \n 1,755 \n 1,250 \n 2,258 \n 2,945 \nTransport\n 3,996 \n 2,852 \n 5,025 \n\
    \ 4,914 \n 7,502 \nWater and Other Urban \nInfrastructure and Services\n 1,702\
    \ \n 1,658 \n 1,567 \n 2,192 \n 1,221 \nTOTAL\n     16,184 \n     13,253 \n     19,687\
    \ \n21,576\n     21,643 \nRegular Ordinary Capital and Concessional Resources\
    \ Commitments   \nby Region, 2015–2019 ($ million)  \n \n \n \n \n \nRegion\n\
    2015\n2016\n2017\n2018\n2019\nCentral and West Asia\n 4,462 \n 3,734 \n 5,314\
    \ \n 4,460 \n 5,203 \nEast Asia\n 2,023 \n 1,873 \n 2,671 \n 3,054 \n 2,617 \n\
    Pacific\n 80 \n 381 \n 736 \n 405 \n 453 \nSouth Asia\n 5,168 \n 3,501 \n 6,756\
    \ \n 6,978 \n 6,687 \nSoutheast Asia\n 4,409 \n 3,683 \n 4,039 \n 6,275 \n 6,519\
    \ \nRegional\n 43 \n 81 \n 171 \n 403 \n 163 \nTOTAL\n 16,184 \n 13,253 \n 19,687\
    \ \n 21,576 \n 21,643 \nCOMMITMENTS BY \nSECTOR, 2019 \n(REGULAR ORDINARY CAPITAL\
    \ \nAND CONCESSIONAL RESOURCES) \nCOMMITMENTS BY \nREGION, 2019 \n(REGULAR ORDINARY\
    \ CAPITAL \nAND CONCESSIONAL RESOURCES)\nTRANSPORT\n35%\nSOUTH ASIA\n31%\nSOUTHEAST\
    \ ASIA\n30%\nCENTRAL AND WEST ASIA\n24%\nEAST ASIA\n12%\nPACIFIC\n2%\nREGIONAL\n\
    1%\nENERGY\n12%\nPUBLIC SECTOR MANAGEMENT\n14%\nAGRICULTURE, NATURAL RESOURCES,\
    \ \nAND RURAL DEVELOPMENT\n10%\nFINANCE\n10%\nEDUCATION\n5%\nINDUSTRY AND TRADE\n\
    3%\nWATER AND OTHER URBAN \nINFRASTRUCTURE AND SERVICES\n6%\nHEALTH\n3%\nINFORMATION\
    \ AND COMMUNICATION \nTECHNOLOGY\n3%\n8\nADB ANNUAL REPORT 2019 \nPortfolio, 2015–2019\
    \ ($ million)\nItem\n2015\n2016\n2017\n2018a\n2019\nA.  Ongoing Projectsb\nBy\
    \ Source\nRegular Ordinary Capital Resources\n 55,485 \n 57,970 \n 65,330 \n 72,099\
    \ \n 74,726 \nConcessional Resources\nLoans\n 12,949 \n 13,685 \n 14,336 \n 15,504\
    \ \n 17,907 \nGrants\n 4,667 \n 4,601 \n 4,249 \n 5,233 \n 5,321 \nBy Operations\n\
    Sovereign\n 65,217 \n 67,008 \n 73,074 \n 80,422 \n 84,169 \nNonsovereign\n 7,884\
    \ \n 9,249 \n 10,842 \n 12,414 \n 13,785 \nTotal\n 73,101 \n 76,257 \n 83,916\
    \ \n 92,836 \n 97,954 \nB. Disbursements\nBy Source\nRegular Ordinary Capital\
    \ Resources\n     Loans\n 9,667 \n 9,763 \n 8,717 \n 11,475 \n 13,148 \n     Equity\
    \ Investments\n 123 \n 79 \n 242 \n 143 \n 135 \n     Debt Securities\n‑ \n 148\
    \ \n 75 \n 446 \n 161 \nConcessional Resources\n     Loans\n 2,048 \n 2,027 \n\
    \ 1,926 \n 1,645 \n 2,512 \n     Grants\n 503 \n 463 \n 481 \n 476 \n 511 \nOther\
    \ Special Funds\n 7 \n 9 \n 2 \n 2 \n 3 \nBy Operations\nSovereignc\n 10,781 \n\
    \ 10,746 \n 10,072 \n 12,234 \n 14,210 \nNonsovereign\n 1,567 \n 1,743 \n 1,371\
    \ \n 1,953 \n 2,260 \nTotal\n 12,348 \n 12,489 \n 11,443 \n 14,186 \n 16,470 \n\
    C.  Net Resources Transfer  \nto Developing Member Countriesd\n 6,546 \n 5,397\
    \ \n 3,608 \n 4,622 \n 5,670 \n‑ = nil. \nNote: Numbers may not sum precisely\
    \ because of rounding. Excludes technical assistance and cofinancing.\na 2018\
    \ figures differ from those in the 2018 Annual Report due to adjustments after\
    \ year‑end. \nb  Sovereign portfolio consists of loans, grants, equity investments,\
    \ and guarantees committed and not financially closed. \nNonsovereign portfolio\
    \ consists of outstanding plus undisbursed balances of loans, equities, guarantees,\
    \ and other debt \nsecurities.\nc Includes Asian Development Fund and Other Special\
    \ Funds grants.\nd  Net Resource Transfer includes loans, other debt securities,\
    \ equity investments, Asian Development Fund, and other  \nSpecial Fund grants.\
    \ Net Resource Transfer to developing member countries refers to the net amount\
    \ of disbursements in \nexcess of payments of principal, interest, and other charges.\n\
    INSTITUTIONAL HIGHLIGHTS\nItem\n2015\n2016\n2017\n2018\n2019\nA.  Staff\nStaff a\
    \ (number)\n 3,098 \n 3,085 \n 3,127 \n 3,374\n3,548\nInternational Staff and\
    \ Board Staff\n 1,104 \n 1,103 \n 1,136 \n 1,242\n1,287\nNational and Administrative\
    \ Staff\n 1,994 \n 1,982 \n 1,991 \n2,132\n2,261\nNational Staff\n 763 \n 762\
    \ \n 790 \n876 \n943\nAdministrative Staff\n 1,231 \n 1,220 \n 1,201 \n 1,256\n\
    1,318\nInternational Staff and Board Staff \nLocationa (number)\n 1,104 \n 1,103\
    \ \n 1,136 \n 1,242\n1,287\nResident Missionsb\n 150 \n 160 \n 182 \n 194\n193\n\
    Headquarters\n 954 \n 943 \n 954 \n1,048 \n1,094\nInternational Staff and Board\
    \ Staff \nGendera (number)\n 1,104 \n 1,103 \n 1,136 \n 1,242\n1,287\nMale \n\
    \ 731 \n 728 \n 736 \n 791\n815\nFemale\n 373 \n 375 \n 400 \n 451\n472\nB. Internal\
    \ Administrative Budget ($ ’000)\n 617,701 \n 635,624 \n 646,988 \n 672,264\n\
    690,488\na  “Staff” refers to all international staff, board staff (i.e., Director’s\
    \ Advisors), national staff, and administrative staff. The figures \nexclude Management,\
    \ Board of Directors, and Secondees.  \n \nb Includes staff in outposted positions\
    \ and in ADB’s Philippines Country Office.\n2015\n12,348\n2016\n12,489\n2017\n\
    11,443\n2018\n14,186\n2019\n16,470\nDISBURSEMENTS  \nFOR LOANS, GRANTS, \nDEBT\
    \ SECURITIES, AND \nEQUITY INVESTMENTS,\n2015–2019\n($ MILLION)\n52.6\n50.1\n\
    48.1\n49.7\n49.0\n0\n10\n20\n30\n40\n50\n60\n70\n2015 2016 2017 2018 2019\n($'000)\n\
    INTERNAL \nADMINISTRATIVE \nEXPENSES PER $1 MILLION \nDISBURSEMENT\n9\nFINANCIAL\
    \ HIGHLIGHTS\n 0\n 10.0\n 20.0\n 30.0\n 40.0\n 50.0\n 60.0\n2015\n2016\n2017\n\
    2018\n2019\n(%)\nEQUITY-TO-LOANS RATIO \nPRELIMINARY DATA\nADB RESOURCES AND FINANCIAL\
    \ DATA ($ million)\nItem\n2015\n2016\n2017\n2018\n2019\nOrdinary Capital Resources\n\
    Selected Balance Sheet Data\nTotal Assets\n 117,697  125,854  182,381  191,860\
    \  221,866 \nof which\nLoans Outstanding ‑ Operations\n 61,941 \n 67,599  101,008\
    \  106,405  114,389 \nInvestments for Liquidity Purpose\n 23,309 \n 26,025 \n\
    \ 36,478 \n 35,215 \n 39,312 \nEquity Investments ‑ Operations\n 862 \n 814 \n\
    \ 1,185 \n 1,280 \n 1,619 \nDerivative Assets\n 29,538 \n 29,143 \n 40,761 \n\
    \ 45,500 \n 62,619 \nTotal Liabilities\n 100,251  108,640  132,112  140,876  169,948\
    \ \nof which\nOutstanding Borrowingsa\n 66,054 \n 74,476 \n 87,281 \n 90,423 \
    \ 104,996 \nDerivative Liabilities\n 32,272 \n 32,079  42,852 \n 48,996 \n 62,569\
    \ \nTotal Equityb\n 17,446 \n 17,214  50,269 \n 50,984 \n 51,918 \nof which\n\
    Paid‑in Capital\n 6,433 \n 6,399 \n 7,002 \n 7,029 \n 7,175 \nReservesc\n 11,013\
    \ \n 10,815 \n 43,267d  43,955 \n 44,743 \nIncome Statement Data\nTotal Revenue\n\
    \ 1,029 \n 1,532 \n 2,625 \n 3,741 \n 4,265 \nTotal Expenses\n (768)\n (1,163)\n\
    \ (1,869)\n (2,883)\n (3,173)\nof which\nBorrowings and Related Expenses\n (374)\n\
    \ (751)\n (1,247)\n (2,159)\n (2,530)\nAdministrative Expenses\n (383)\n (390)\n\
    \ (578)\n (591)\n (598)\nNet Realized Gains\n 56 \n 158 \n 9 \n 22 \n 28 \nNet\
    \ Unrealized Gains (Losses)\n 239 \n (520)\n 9 \n (130)\n 434 \nNet Income\n 556\
    \ \n 7 \n 774e\n 750 \n 1,554 \nOperating Incomef\n 343 \n 521 \n 725 \n 889 \n\
    \ 1,093 \nAnnual Borrowingsg\n 18,948 \n 20,602 \n 28,593 \n 23,538 \n 24,613\
    \ \nof which\nThematic Bonds and Green Bonds\n 687 \n 1,300 \n 1,662 \n 1,822\
    \ \n 2,657 \nLocal Currency Fundingh\n 245 \n 617 \n 744 \n 535 \n 764 \nEquity-to-Loans\
    \ Ratio (%)\n 27.8 \n 25.9 \n 50.0 \n 47.5 \n 45.3 \nCapital Utilization Ratio\
    \ (%)i\n NA \n NA \n 56.0  \n 54.6 \n 62.1 \nAllocable Net Income\n 368 \n 488\
    \ \n 690 \n 841 \n 1,069j\nAllocation to Ordinary Reserve\n 208 \n 124 \n 351\
    \ \n 499 \n 616 \nAllocation to ADF\n 120 \n 259 \n 259 \n 259 \n 259 \nAllocation\
    \ to Other Special Funds\n 40 \n 105 \n 80 \n 83 \n 194 \nAsian Development Fund\
    \ Resources - Available \n Resourcesk\n 32,522 \n 32,581 \n 2,067d \n 1,956 \n\
    \ 2,498 \nOther Special Fund Resources - Uncommitted Balances\nTechnical Assistance\
    \ Special Fund\n 147 \n 41 \n 400 \n 304 \n 196 \nJapan Special Fundl\n 105 \n\
    \ 106 \n 107 \n 109 \n 112 \nADB Institute\n 9 \n 10 \n 12 \n 16 \n 19 \nRegional\
    \ Cooperation and Integration Fund\n 8 \n 6 \n 14 \n 10 \n 5 \nClimate Change\
    \ Fund\n 11 \n 8 \n 20 \n 18 \n 10 \nAsia Pacific Disaster Response Fund\n 17\
    \ \n 8 \n 26 \n 21 \n 21 \nFinancial Sector Development Partnership \n Special\
    \ Fund\n 7 \n 7 \n 5 \n 4 \n 5 \n    Total\n 304 \n 186 \n 584 \n 482 \n 368 \n\
    ADF = Asian Development Fund, NA = not applicable.\na Includes accrued interest\
    \ and commission, unamortized premium and/or discounts.\nb As of 31 December 2019,\
    \ authorized and subscribed capital amounted to $147,120 million.\nc Reserves\
    \ includes ordinary reserve, special reserve, loan loss reserve, surplus, net\
    \ income after appropriation, nonnegotiable, \nnoninterest‑bearing demand obligations\
    \ and receivables on account of subscribed capital, net notional amounts required\
    \ to \nmaintain value of currency holdings, cumulative revaluation adjustment\
    \ and accumulated other comprehensive income or \nloss.  Reserves includes the\
    \ one‑time income from ADF asset transfer on 1 January 2017.\nd The transfer of\
    \ ADF loans and other assets to ordinary capital resources on 1 January 2017 resulted\
    \ in the increase in ordinary \ncapital resources reserves and decrease in ADF\
    \ resources in 2017.\ne 2017 Net Income refers to net income after allocation\
    \ of one‑time income from ADF asset transfer to Ordinary Reserve.\nf Operating\
    \ income is net income before unrealized gains or losses and ADB’s proportionate\
    \ share of unrealized earnings of \nequity investments accounted for under the\
    \ equity method.\ng Excludes short‑term borrowings.\nh Local Currency Funding\
    \ includes bond, swaps, repo.\ni The capital utilization ratio (CUR) is the ratio\
    \ of total economic capital used (numerator) to equity (denominator).  \nThe higher\
    \ the ratio, the lower the remaining deployable capital or excess risk‑bearing\
    \ capacity.\nj 2019 net income allocation is subject to the approval of the Board\
    \ of Governors at the ADB Annual Meeting in 2020.\nk Includes the total fund balance\
    \ and nonnegotiable, noninterest‑bearing demand obligations on account of contributions.\n\
    l Japan Special Fund resources include Asian Currency Crisis Support Facility\
    \ uncommitted balance and net accumulated \ninvestment income.\nIn 2019, \n45%\
    \ of  \ninternational and \nnational staff \npositions in operations \ndepartments\
    \ were  \nin ADB’s field offices.  \nField offices now \nadminister \n53% of \
    \ \nsovereign operations.\nCOUNTRY PRESENCE \n10\nADB ANNUAL REPORT 2019 \nTo\
    \ continue \nthe region’s \nimpressive \ndevelopment \ntrajectory, \npolicymakers\
    \ \nwill need to \nidentify new \ngrowth engines \nand give greater \nemphasis\
    \ to \nthe quality of \ngrowth.\n1\nSupporting a Prosperous, Inclusive, Resilient,\
    \ \nand Sustainable Asia and the Pacific\nUnderpinned by robust economic growth\
    \ and \nclear development strategies, the Asia and \nPacific region has made significant\
    \ progress in \nreducing poverty and improving the quality of \nlife. The number\
    \ of people living in extreme \npoverty (on less than $1.90 a day) in the region\
    \ \nhas reduced from 1.5 billion to 264 million \nsince 1990. Electricity is now\
    \ available to most \nhouseholds in 80% of countries in the region, \ncompared\
    \ to 44% in 2000. Between 2000 and \n2018, life expectancy at birth increased\
    \ from \n65.8 years to 71.8 years, and the under‑5 mortality \nrate declined from\
    \ 69.8 to 31.7 deaths per 1,000 \nlive births in the region. \nThe growth that\
    \ drove these achievements, \nthough still strong, is beginning to moderate. \n\
    Economic expansion in Asia and the Pacific \nwas 5.2% in 2019, down from an average\
    \ of 6.6% \nacross the previous decade. The countries of \nthe region are being\
    \ affected by sluggish global \neconomic activity, trade tensions, weakening \n\
    domestic investment, and worsening impacts of \ndisasters. Key development challenges\
    \ include \nlarge infrastructure gaps, rising inequality, and \nchanging demographics.\n\
    To continue the region’s impressive development \ntrajectory, policymakers will\
    \ need to identify \nnew growth engines and give greater emphasis \nto the quality\
    \ of growth. They will need to \nharness technological innovation and foster new\
    \ \nindustries such as sustainable tourism, which \ncan help generate quality\
    \ jobs. Urbanization \ncan also spur growth, but requires increased \ninfrastructure\
    \ investments, effective urban \nplanning, and efforts to tackle congestion, rising\
    \ \nhousing costs, and pollution.\nNote: The onset of the COVID‑19 pandemic in\
    \ \nearly 2020 now threatens to severely set back \neconomic, social, and development\
    \ gains  \nin Asia and the Pacific, reverse progress on \npoverty reduction, and\
    \ throw economies \ninto recession. This Annual Report covers \nthe calendar year\
    \ of 2019 and therefore does \nnot discuss in detail the bank’s response to \n\
    COVID‑19. To find out how ADB is supporting \nits members across the region to\
    \ tackle the crisis \nand return to economic growth, please see www.\nadb.org/covid‑19.\n\
    IMPLEMENTING STRATEGY 2030 \nADB launched Strategy 2030 in 2018 to guide \nthe\
    \ support given to the bank’s developing \nmember countries (DMCs). The strategy’s\
    \ \noverarching vision is to achieve a prosperous, \ninclusive, resilient, and\
    \ sustainable Asia and \nthe Pacific, while sustaining efforts to eradicate \n\
    extreme poverty. \nADB’s development objectives are aligned  \nwith the Sustainable\
    \ Development Goals \n(SDGs) and the Financing for Development \nagenda, the Paris\
    \ Agreement on climate \nchange, the Sendai Framework for Disaster \nRisk Reduction,\
    \ and the G20 agenda for quality \ninfrastructure.\nUnder Strategy 2030, the bank\
    \ aims to continue \nadding value to its provision of financing \nby developing\
    \ new and innovative funding \nmechanisms, creating insightful knowledge \nproducts\
    \ and services, and building strong \ndevelopment partnerships. ADB will expand\
    \ \nits private sector operations and mobilize \nlarger volumes of long‑term cofinancing\
    \ for \ngreater development impact. ADB strives to \nimprove the quality and speed\
    \ of its services \nto its DMCs. This includes fostering the One \nADB approach,\
    \ which combines knowledge \nand expertise from across the organization \nto provide\
    \ the best possible solutions to \nthe diverse needs of the bank’s developing\
    \ \nmembers.  \nIn 2019, ADB responded to these needs by \ncommitting $33.74 billion\
    \ in loans, grants, \nguarantees, equity investments, technical \nassistance,\
    \ and cofinancing from partners. \nThe bank provided $4.49 billion in concessional\
    \ \nassistance and $17.15 billion from its regular \nordinary capital resources,\
    \ which includes \n$3 billion in nonsovereign operations. It \nalso generated\
    \ $11.64 billion in project loan \ncofinancing. ADB extended $464 million in \n\
    technical assistance including $226 million  \nfrom cofinancing. During 2019,\
    \ the bank \ndisbursed a record $16.47 billion in loans, \ngrants, equity investments,\
    \ guarantees, and \ndebt securities, an increase of 16% from 2018.\n11\nSUPPORTING\
    \ A PROSPEROUS, INCLUSIVE, RESILIENT, AND SUSTAINABLE ASIA AND THE PACIFIC\nDuring\
    \ 2017–2019, \n80%\nof ADB committed \noperations \npromoted gender \nequality,\
    \ on track \nto achieve the \nStrategy 2030 \ntarget of 75%.\n \nPROGRESS \nAGAINST\
    \ \nSTRATEGY 2030 \nTARGETS \nGENDER\nAccelerating \nprogress \nin gender \nequality\n\
    Making cities \nmore livable\nFostering\n regional \ncooperation and \nintegration\n\
    Addressing \nremaining \npoverty and \nreducing \ninequalities \nTackling climate\
    \ \nchange, building \nclimate and \ndisaster resilience, \nand enhancing \nenvironmental\
    \ \nsustainability\nStrengthening \ngovernance and \ninstitutional \ncapacity\n\
    Promoting rural \ndevelopment \nand food \nsecurity\n* Shares sum to more than\
    \ 100%. Reﬂecting the more integrated approach to development challenges outlined\
    \ in Strategy 2030, most new \nADB operations address multiple operational priorities.\
    \  \nACTING ON OPERATIONAL PLANS \nFOR STRATEGY 2030\nStrategy 2030 highlights\
    \ seven operational \npriorities that are designed to respond effectively \nto\
    \ global and regional development challenges. In \nSeptember, ADB approved operational\
    \ plans for \nthe seven priorities. The plans will guide decisions \non the selection,\
    \ design, and implementation of \nprojects, programs, and knowledge work to support\
    \ \nthe operational priorities of Strategy 2030. The \nplans identify expected\
    \ outcomes, likely activities, \nand the links across sectors and themes to ensure\
    \ \nthe plans complement and reinforce each other. \nAddressing Remaining Poverty\
    \ and \nReducing Inequalities\nThis operational plan emphasizes support for \n\
    lagging areas and vulnerable populations to reduce \ninequalities in access to\
    \ opportunities; expand \ninvestment in human capital through education, \nuniversal\
    \ health coverage, and social protection; \nand help generate quality jobs to\
    \ support inclusive \ngrowth.\nIn 2019, for example, ADB provided an additional\
    \ \n$200 million in financing to Pakistan for the \ngovernment’s social protection\
    \ program, the \nBenazir Income Support Program. The program \nsupports the income\
    \ of more than 5 million poor \nfamilies across the country and has so far disbursed\
    \ \nover $3.6 billion in cash transfers to improve their \nliving conditions.\
    \ ADB’s support for this, which \nbegan in 2013, has enabled the enrollment of\
    \ over \n855,000 women beneficiaries to the program.\nAs part of broader efforts\
    \ to reduce poverty by \npreparing people for job opportunities, ADB \ncommitted\
    \ a $300 million loan to support the \nGovernment of the Philippines to improve\
    \ access to \nhigh‑quality secondary education oriented to labor \nmarket needs.\
    \ This results‑based program  \nwill benefit about 10.6 million students already\
    \ \nenrolled in high school nationwide and another \n2 million secondary school\
    \ entrants every year \nthrough to 2023. \nAccelerating Progress  \nin Gender\
    \ Equality\nThis operational plan highlights support for \nwomen’s economic empowerment\
    \ and gender \nequality in human development, decision‑making, \nand leadership.\
    \ The bank will work to reduce \nwomen’s time poverty and help increase their\
    \ \nresilience to external shocks. ADB investments \naim to achieve these goals\
    \ by supporting safer \n12\nADB ANNUAL REPORT 2019 \nDuring 2019, ADB \ncommitted\n\
    $6.5B\nfor climate change \nmitigation and \nadaptation,  \nan important step\
    \ \ntoward the Strategy \n2030 cumulative \ntargets of $35 billion \nby 2024 and\
    \ \n$80 billion by 2030.\nPROGRESS \nAGAINST \nSTRATEGY 2030 \nTARGETS \nCLIMATE\
    \ \nCHANGE\ncommunity infrastructure, greater access to \nemployment and economic\
    \ opportunities, and \nequality in skills development and leadership \nroles.\
    \ ADB’s target is that, by 2030, at least 75% \nof its committed sovereign and\
    \ nonsovereign \ninvestments will promote gender equality.  \nIn May, the bank\
    \ signed a $926 million loan \nto fund two lines for the Mumbai Metro Rail \n\
    System in India, which will cater for an estimated \n2 million passengers each\
    \ day. The loan covers the \nprocurement of 63 six‑car trains, installation of\
    \ \nsignaling and safety systems, and establishment of \na new dedicated metro\
    \ operations organization. \nFeatures to directly benefit women include \nwomen‑only\
    \ carriages, mobile phone applications \nfor women’s security, separate ticket\
    \ counters, and \nreporting desks to address incidents of harassment. \nWomen\
    \ will also have improved opportunities \nfor employment along the new lines,\
    \ including a \nstation staffed only by women. \nIn April, ADB became the first\
    \ multilateral \ndevelopment bank to secure a second grant from \nthe Women Entrepreneurs\
    \ Finance Initiative. The \nbank is using the $20.2 million grant to help 5,000\
    \ \nwomen in Viet Nam and the Pacific establish \nmicroenterprises and develop\
    \ existing businesses. \nThe program will expand access to finance, deliver \n\
    courses in commercial acceleration and financial \nliteracy, and provide mentoring\
    \ and networking \nopportunities.\nTackling Climate Change, Building \nClimate\
    \ and Disaster Resilience, and \nEnhancing Environmental Sustainability\nIn the\
    \ face of rapidly growing greenhouse \ngas (GHG) emissions, increasing risks and\
    \ \nimpacts from climate change and disasters, and \naccelerating environmental\
    \ degradation, ADB \nrecognizes that tackling climate change, building \nclimate\
    \ and disaster resilience, and enhancing \nenvironmental sustainability are critical\
    \ to \nachieving its Strategy 2030 vision of a prosperous, \ninclusive, resilient,\
    \ and sustainable Asia and the \nPacific. This operational plan focuses on scaling\
    \ \nup support to address climate change, disaster \nrisks, and environmental\
    \ degradation; accelerating \nlow GHG emission development; ensuring a \ncomprehensive\
    \ approach to build climate and \ndisaster resilience; ensuring environmental\
    \ \nsustainability; and increasing focus on the water–\nfood–energy nexus. To\
    \ support these goals, by \n2030, at least 75% of ADB’s committed operations \n\
    (on a 3‑year rolling average, including sovereign \nand nonsovereign operations)\
    \ will address climate \nchange mitigation and adaptation, and climate \nfinance\
    \ from ADB’s own resources will  \nreach $80 billion for the period 2019–2030.\
    \  \nIn May, ADB launched a comprehensive action \nplan for healthy oceans and\
    \ sustainable blue \neconomies, targeting $5 billion in projects by \n2024. The\
    \ plan covers the development of \nsustainable marine economies, coastal pollution\
    \ \ncontrol, sustainable coastal infrastructure \nand ports, and ecosystem management\
    \ and \nrehabilitation. Technical assistance will help \nDMCs develop policies\
    \ and regulations to reduce \nmarine plastic pollution and prepare investments\
    \ \nin integrated solid waste management. The \nRepublic of Korea pledged $350 million\
    \ of \ncofinancing and $5 million for technical \nassistance for the Association\
    \ of Southeast \nAsian Nations (ASEAN) Catalytic Green \nFinance Facility. This\
    \ financing will support green \ninfrastructure in Southeast Asia, focusing on\
    \ \nprojects to boost ocean health.  \nIn September, ADB provided a $100 million\
    \ \nloan to help establish the Shandong Green \nDevelopment Fund, which will attract\
    \ private, \ninstitutional, and commercial finance for \ninvestments in climate‑friendly\
    \ development in \nthis eastern province of the People’s Republic of \nChina.\
    \ Shandong is the second most populous \nprovince in the country and is home to\
    \ almost \n100 million people. Its carbon‑intensive economy \nhas resulted in\
    \ high GHG emissions. Projects \nunder the fund are expected to reduce emissions\
    \ \nby 2.5 million metric tons of carbon dioxide \nequivalent  per year and will\
    \ build climate \nresilience for at least 2 million people by 2027 \nby protecting\
    \ coastal areas and introducing \nflood and drought control measures, including\
    \ \nin agricultural regions. These investments \nwill demonstrate a shift to a\
    \ low‑carbon \nand sustainable growth model that could be \nreplicated by other\
    \ regional economies. \nIn December, ADB met a key commitment to \ndouble its\
    \ annual climate investments from \n$3 billion in 2014, setting a record high\
    \ of \n$6.55 billion in climate‑related financing in 2019, \n1 year ahead of schedule.\n\
    Making Cities  \nMore Livable\nADB aims to build cities in Asia and the Pacific\
    \ \nthat are competitive, green, inclusive, and \nresilient. This operational\
    \ plan strives to improve \nthe accessibility, quality, and reliability of services\
    \ \nin urban areas; strengthen urban planning and \nfinancial sustainability of\
    \ cities; and improve \ncities’ environment, climate resilience, and \ndisaster\
    \ management. \nAn example of innovative and integrated urban \ntransport planning\
    \ can be found in an ADB‑\nsupported project in Gui’an, a fast‑growing \n13\n\
    SUPPORTING A PROSPEROUS, INCLUSIVE, RESILIENT, AND SUSTAINABLE ASIA AND THE PACIFIC\n\
    Maryam lives in the Multan district of Pakistan. \nShe completed 12th grade education,\
    \ but \ncould not afford to continue her studies. \nBefore Maryam learned about\
    \ ADB‑supported \ntraining on solar energy technology, she had no \nopportunity\
    \ to work. \n“The solar panel training interested me,” \nMaryam says. “I talked\
    \ to my father, but he \nrefused because we were to be taught by male \nteachers.\
    \ He said it is not right for a female to \nwork outside, and especially on roofs\
    \ and in \nbuildings.” \nHowever, with her mother’s help, Maryam was \nable to\
    \ get permission and admission to the \ntraining. \n“During this course, I learned\
    \ about electrical \nwiring, basic repair, and how to make electric \nswitchboards.”\
    \ \nMaryam successfully completed the course \nand secured a job in the district’s\
    \ premier solar \ncompany as a solar panel assistant. \nSolar Panel Training Changes\
    \ a Woman’s Life\nMaryam’s story is one of several in ADB’s 2019 \npublication\
    \ Gender in Infrastructure: Lessons from \nCentral and West Asia, which illustrates\
    \ how gender \ninclusion contributes to meeting the needs of all \nbeneficiaries\
    \ and creating opportunities for regional \neconomic growth.\nSolar technicians\
    \ at work in Pakistan’s Multan district.\nnew city of Guizhou Province in the\
    \ People’s \nRepublic of China. The bank committed a \n$192.8 million loan for\
    \ an intelligent transport \nsystem that will reduce pollution, cut traffic \n\
    congestion, and improve transport safety in \nthe city. This investment will finance\
    \ real‑\ntime traffic and road‑weather monitoring, a \nmultimodal transport operations\
    \ center, a traffic \nsafety and emergency management system, \nand sustainable\
    \ transport infrastructure such as \nclean‑energy buses and electric‑vehicle charging\
    \ \nstations. The project will be a pilot for other \ncities, demonstrating integrated\
    \ smart transport \ndevelopment.\nIn Tonga, ADB committed an $18.3 million grant\
    \ \nin 2019 to fund priority urban infrastructure \nthat will also enhance the\
    \ country’s resilience \nto disasters and the effects of climate change, \nincluding\
    \ rising sea levels. The project is designed \nto improve living conditions for\
    \ around 36,000 \nTongans in Nuku’alofa and other towns, with \ninvestment in\
    \ flood management and drainage \ninfrastructure, improved water supply services,\
    \ \nand better solid waste management. ADB is also \nsupporting the preparation\
    \ of a climate‑ and \ndisaster‑resilient urban development strategy \nand investment\
    \ plan for Tonga.\nPromoting Rural Development  \nand Food Security\nUnder this\
    \ operational plan, ADB will help transform \nagriculture and food supply systems\
    \ to achieve \nhigher incomes for farmers, provide safe and \nnutritious food\
    \ to consumers, and spur economic \ngrowth in rural areas. The plan also highlights\
    \ ADB’s \nrole in supporting rural development by enhancing \nconnectivity and\
    \ services; building agriculture value \nchains with market infrastructure; and\
    \ improving \nfood security through better irrigation, farm inputs, \nand capacity\
    \ building. \nADB will explore opportunities to help develop \nmodern agriculture\
    \ value chains; improve food \nsafety policy and regulatory frameworks, standards,\
    \ \nand certification; promote climate‑smart and \nknowledge‑intensive agriculture;\
    \ enhance water \nservice delivery and efficiency; improve access to \nrural finance;\
    \ provide off‑grid energy access; and \nimprove rural health and education. \n\
    ADB’s efforts to improve water resources \nmanagement and transform farming practices\
    \ \nare highlighted in Cambodia, where agriculture \ncontributes 22% of the gross\
    \ domestic product. In \nDecember, the bank committed a $119.2 million \nAgency\
    \ for Technical Cooperation and \nDevelopment (ACTED)\n14\nADB ANNUAL REPORT 2019\
    \ \nEnhanced \nCooperation and \nIntegration between \nIndonesia and \nTimor-Leste\
    \ \nAt the request of \nthe governments \nof Indonesia and \nTimor‑Leste, \nADB\
    \ prepared a \nstudy identifying \nopportunities for \ncooperation between \n\
    the two countries, \nparticularly on \ntourism and \nlivestock. This \nstudy led\
    \ to an \nagreement between \nTimor‑Leste and \nNusa Tenggara \nTimur Province\
    \ in \nIndonesia to reduce \nbarriers to livestock \ntrade, ease cross‑\nborder\
    \ land‑and‑\nair transportation, \nand harmonize \nprocedures at border \ncrossing\
    \ points.\nThe Kacific1 satellite supported by ADB was launched on 16 December\
    \ 2019 to bring low-cost broadband to remote areas \nof the region. It will boost\
    \ access to services, information, and economic opportunities. \nKacific/SpaceX\n\
    financing package to help modernize and improve \nirrigation systems in four provinces,\
    \ helping supply \nwater to 43,500 hectares of farmland and benefiting \n290,000\
    \ people. The project will also promote \ncrop diversification through training\
    \ and the \nestablishment of at least 200 demonstration plots.\nDuring 2019, ADB\
    \ also continued to raise farming \nincomes and improve the quality of life in\
    \ rural \nareas of Asia and the Pacific. In October, ADB \nprovided a $45 million\
    \ financing package for four \nnorthern provinces in the Lao People’s Democratic\
    \ \nRepublic, where poverty rates are three times higher \nthan in the country’s\
    \ urban areas. The project \nwill help increase the production of high‑value \n\
    crops, introduce climate‑resilient technologies to \nmaximize production with\
    \ less inputs, and provide \nup to 200 grants to farmers and entrepreneurs.\n\
    Strengthening Governance and \nInstitutional Capacity\nThis operational plan specifies\
    \ that ADB will help \nimprove public sector management functions and \nfinancial\
    \ stability, develop institutional capacity to \nimprove service delivery, and\
    \ strengthen country \nsystems and standards, with a focus on improving \nthe\
    \ efficient and effective implementation of \ndevelopment projects and programs.\n\
    The bank is working to boost revenue collection \nby broadening countries’ tax\
    \ bases and, through \ninternational tax cooperation, is helping protect \nthem\
    \ against tax base erosion and profit shifting. ADB \nis facilitating state‑owned\
    \ enterprise (SOE) reforms \nto strengthen the accountability and performance\
    \ \nof SOEs through improved corporate governance, \ncompetition and market contestability,\
    \ and asset \ncommercialization or divestment. The bank is \nalso building capacity\
    \ in subnational governments \nin recognition of the critical role they play in\
    \ \ncontributing to the SDGs.    \nIn Indonesia, ADB committed a $500 million\
    \ \npolicy‑based loan to support critical fiscal and \npublic expenditure management\
    \ reforms that aim \nto improve the quality of government spending \non health,\
    \ education, social protection, and \ninfrastructure. Consistent with the government’s\
    \ \nstrategy to create sustainable and equitable growth, \nthe program promotes\
    \ reforms aligning medium‑\nterm expenditure with the National Medium‑Term \n\
    Development Plan and SDG targets, enhancing the \nnational public expenditure\
    \ system, and improving \nfiscal transfers and subnational governments’ \nspending\
    \ for service delivery. In Uzbekistan, ADB \ncommitted policy‑based assistance\
    \ of $300 million \nfor an ongoing program to strengthen the country’s \neconomic\
    \ management, leading to greater \nmacroeconomic stability and sustained economic\
    \ \ngrowth. The program is improving the government’s \neconomic decision‑making\
    \ by modernizing \nmacroeconomic data management systems. It is \nhelping the\
    \ government introduce reforms in fiscal \nand public financial management, strengthen\
    \ risk‑\nbased banking supervision by the central bank, \n15\nSUPPORTING A PROSPEROUS,\
    \ INCLUSIVE, RESILIENT, AND SUSTAINABLE ASIA AND THE PACIFIC\nIn Asia’s tropical\
    \ highlands, a $20 million ADB private sector loan in 2016 helped Hasfarm \nexpand\
    \ and replicate its high-value horticulture business. The project is helping to\
    \ boost jobs \nin rural areas of Viet Nam, the People’s Republic of China, and\
    \ Indonesia.\nDuring 2019, the \nnumber of ADB\nprivate sector \noperations \n\
    increased to\n24%\nof total operations, \non track to meet \nthe Strategy 2030\
    \ \ntarget of 33%  \nby 2024.\nPROGRESS \nAGAINST \nSTRATEGY 2030 \nTARGETS\n\
    PRIVATE \nSECTOR\nimprove the governance and viability of SOEs, \nand promote\
    \ an enabling environment for public–\nprivate partnerships (PPPs).\nFostering\
    \ Regional Cooperation  \nand Integration\nThis operational plan specifies that\
    \ ADB will help \nbuild greater and higher‑quality connectivity \nbetween economies,\
    \ expand global and regional \ntrade and investment opportunities, and increase\
    \ \nand diversify regional public goods such as \nsustainable management of shared\
    \ natural \nresources, access to regional education and health \nservices, and\
    \ improved mechanisms for regional \ncoordination.\nEmphasizing regional cooperation\
    \ in health, ADB \nsigned agreements with the governments of \nSamoa and Vanuatu\
    \ to fund the introduction of \nnew vaccines through an ADB‑supported Pacific\
    \ \nregional project, which provided grants to Tonga \nand Tuvalu in 2018. The\
    \ project will support the \ndelivery of vaccines to reduce the incidence of \n\
    pneumonia and diarrhea in children and protect \nyoung girls against the human\
    \ papillomavirus, \nlowering the risk of cervical cancer, a leading cause \nof\
    \ death in women in the Pacific. The project will \nbenefit more than 500,000\
    \ young women and \nchildren across Samoa, Tonga, Tuvalu, and Vanuatu. \nADB committed\
    \ a $45 million loan to Viet Nam \nto develop climate‑resilient transport and\
    \ urban \ninfrastructure for cross‑border tourism, including \nthe upgrade of\
    \ access roads and boat piers. This \ninvestment will generate economic opportunities\
    \ to \nbenefit about 168,000 residents, especially women, \nwho manage or are\
    \ employed in the majority of \ntourism‑related enterprises, and improve living\
    \ \nstandards in secondary towns along the Greater \nMekong Subregion Eastern\
    \ Economic Corridor. \nTo strengthen regional infrastructure, ADB formed \na partnership\
    \ with Kacific Broadband Satellites \nInternational Limited to help construct,\
    \ launch, \nand operate a state‑of‑the‑art satellite that will \nprovide affordable,\
    \ high‑speed broadband internet \nconnections to  countries in Asia and the Pacific,\
    \ \nespecially in remote areas of small island nations \nin the Pacific; larger\
    \ island nations like Indonesia \nand the Philippines; and others. ADB provided\
    \ a \n$25 million loan from its own funds and mobilized \na $25 million loan from\
    \ the Japan International \nCooperation Agency to finance the project.\nIMPLEMENTING\
    \ A NEW CORPORATE \nRESULTS FRAMEWORK \nIn September 2019, ADB approved a new\
    \ corporate \nresults framework for 2019–2024. The framework  \nwill be used as\
    \ a basis for reporting on ADB’s \noperational and organizational performance\
    \ and \nmonitoring the implementation of Strategy 2030, \nincluding its targets\
    \ for operations supporting \ngender equality and addressing climate change as\
    \ \nwell as increasing nonsovereign operations and \ncommercial cofinancing. \n\
    The new framework is well‑ integrated with global \ndevelopment priorities, with\
    \ almost three‑quarters \nof its indicators mapped to the SDGs. ADB \nalso reduced\
    \ the number of results framework \nindicators by almost one‑third while increasing\
    \ \ntheir coverage and relevance. The framework \nincorporates new areas for measurement,\
    \ including \noutcomes from the seven operational priority plans, \nOne ADB collaboration,\
    \ and knowledge work. More \naspects of ADB’s nonsovereign operations are also\
    \ \ncovered by the new results framework.\nEXPANDING PRIVATE SECTOR \nOPERATIONS\
    \ \nUnder Strategy 2030, ADB is committed to scaling \nup its private sector operations\
    \ to one‑third of total \noperations by 2024. The bank also aims to attract \n\
    $2.50 of long‑term cofinancing for every $1.00 of its \nown financing for private\
    \ sector operations by 2030. \nDuring 2019, ADB prepared a new Operational Plan\
    \ \nfor Private Sector Operations, 2019–2024. This was \nendorsed by the Board\
    \ in January 2020. While ADB \nwill continue to support energy and finance sector\
    \ \ninvestments, it will also increase its focus on private \nsector opportunities\
    \ in agribusiness, education, \nand health as well as infrastructure projects\
    \ beyond \nthe energy sector. ADB will increase investments in \nfragile and conflict‑affected\
    \ situations, small‑island \n16\nADB ANNUAL REPORT 2019 \nThe One ADB approach,\
    \ introduced as part of Strategy 2030, \ncombines ADB’s expertise across a range\
    \ of sectors, themes, \nand public and private sector operations to offer integrated\
    \ \nsolutions to meet the increasingly complex and diverse \ndevelopment challenges\
    \ facing ADB’s developing members. \nIn 2019, an ADB project to construct a 100‑megawatt\
    \ capacity \nsolar power park in Cambodia applied the One ADB approach \nto provide\
    \ end‑to‑end support to the client. Sovereign \nfinancing helped build the solar\
    \ park and transmission \ninfrastructure, reducing private investment risk in\
    \ solar \ngeneration projects in Cambodia. The bank’s Office of Public–\nPrivate\
    \ Partnership’s transaction advisory services helped \nthe utility agency design\
    \ and conduct a competitive tender \nfor procuring the first power plant to be\
    \ built by the private \nsector within the park. Private sector operations staff\
    \ helped \nin project structuring and design. Nearly 5 million Cambodians \nstill\
    \ lack access to electricity. Cambodia can add about 200 \nmegawatts of solar\
    \ energy to the grid by 2021, using available \ntechnology and without disrupting\
    \ the grid. \nIn the Pacific, ADB extended the adoption of renewable \nenergy\
    \ through a joint effort by sovereign and nonsovereign \noperations staff. The\
    \ bank’s Pacific Department used its \nclose relationship with public utilities\
    \ in the region to identify \nrenewable energy projects in the pipeline. The Private\
    \ \nSector Operations Department developed a program using \na credit enhancement\
    \ structure to deliver project financing \nto the identified projects without\
    \ the need for government \nguarantees.  \nADB’s relationship with public utilities\
    \ in the Pacific region helped to identify \nrenewable energy projects in the\
    \ pipeline and provide project financing.\nONE ADB FOR RENEWABLE ENERGY  \ndeveloping\
    \ states, and low‑income countries. \nIn middle‑income and upper middle‑income\
    \ \ncountries, private sector operations will focus \nmore on lagging and poorer\
    \ areas. \nTo implement the operational plan, ADB \nwill provide tailored debt\
    \ and guarantee \nproducts, broaden its local currency offerings, \nand reinforce\
    \ its equity operations. ADB will \nuse concessional finance to improve project\
    \ \nbankability and technical assistance to improve \nproject outcomes. The bank\
    \ will attract third‑\nparty development financing through various \ncredit enhancement\
    \ products, including B‑loans \n(cofinancing arrangements for a single borrower\
    \ \nthat are funded by commercial banks and \nother eligible financial institutions,\
    \ helping to \ndistribute related risks, with ADB acting as the \nlender of record),\
    \ partial credit guarantees, and \npartial risk guarantees as well as through\
    \ risk \ntransfers, blended finance structures, third‑party \nfunding platforms\
    \ for co‑investment, and PPPs. \nOne of 38 private sector projects the bank \n\
    committed in 2019 is a $14.2 million loan to the \nPRAN food and agribusiness\
    \ group in Bangladesh \nto support the expansion plans of Sylvan \nAgriculture\
    \ Limited. Sylvan aims to support \ninclusive agribusiness by boosting the incomes\
    \ \nand skills of farmers, particularly women. ADB \nassistance will finance new\
    \ processing facilities \nto produce potato‑based foods and pasta. Under \na gender\
    \ action plan, women will comprise at \nleast half of the 450 people directly\
    \ employed \nin the new facilities. Gender wage gaps will be \nreduced, women’s\
    \ facilities introduced, and \ngreater technological assistance provided to \n\
    women farmers. Potatoes for the new processing \nfacilities, located in northeastern\
    \ Bangladesh, will \nbe sourced from around 2,000 contract farmers. \nTheir incomes\
    \ are expected to increase by at \nleast 50% as they introduce new potato varieties\
    \ \nand expand the areas they cultivate.\nCATALYZING AND MOBILIZING \nFINANCIAL\
    \ RESOURCES \nEngaging Development Partners\nIn line with Strategy 2030, ADB continues\
    \ to \nstrengthen collaboration with multilateral, \nbilateral, and private sector\
    \ partners. In 2019, \nADB actively engaged with existing partners to \nrenew\
    \ collaboration and stepped up its outreach \nto philanthropic institutions and\
    \ corporate \nfoundations to catalyze both finance and \nknowledge to assist its\
    \ DMCs more effectively. \nIn total, sovereign cofinancing from bilateral \nand\
    \ multilateral agencies and other financing \n17\nSUPPORTING A PROSPEROUS, INCLUSIVE,\
    \ RESILIENT, AND SUSTAINABLE ASIA AND THE PACIFIC\nA  $926 million ADB loan to\
    \ operationalize two lines for the Mumbai Metro Rail System in India will ease\
    \ the distress of \nmillions of commuters each day and help provide a cleaner,\
    \ less congested city. See page 12 for details.\nIn total, \nsovereign \ncofinancing\
    \ \nfrom bilateral \nand multilateral \nagencies and \nother financing \npartners\
    \ \nreached \n$4.89 billion  \nin 2019.\npartners reached $4.89 billion in 2019,\
    \ including \n$2.01 billion from the Japan International \nCooperation Agency\
    \ for the Malolos–Clark \nrailway project. Several partners expressed their \n\
    intentions to expand cooperation with ADB. \nAgence Française de Développement\
    \ signed \na memorandum of understanding to achieve \n$2.5 billion in cofinancing\
    \ during the next 3 years, \nwhile Germany’s state‑owned development bank \nKfW\
    \ signed a memorandum of understanding \nto achieve $2 billion in cofinancing\
    \ during the \nnext 4 years. ADB also signed a new framework \nagreement with\
    \ the Asian Infrastructure \nInvestment Bank that will guide overall \ncofinancing\
    \ arrangements between the two \ninstitutions.\nDuring the year, ADB established\
    \ two new \ntrust funds. The Ireland Trust Fund for Building \nClimate Change\
    \ and Disaster Resilience in \nSmall Island Developing States will provide \n\
    $13.4 million for 2019–2024. The ASEAN \nAustralia Smart Cities Trust Fund—which\
    \ \nfocuses on building livable cities that are green, \ncompetitive, inclusive,\
    \ and resilient—has an \ninitial allocation of $15.1 million. \nTo build stronger\
    \ and more diversified \npartnerships and expand collaboration with new \nand\
    \ emerging partners, ADB is working to align \nresource planning for external\
    \ grants and trust \nfunds with ADB’s internal resources and provide \nbetter\
    \ access to financing partnerships data. \nPromoting Public–Private Partnerships\
    \ \nADB supports DMCs to develop sustainable \ninfrastructure projects and deliver\
    \ efficient and \neffective public services through PPPs. The bank \nhelps DMCs\
    \ improve their investment climates, \nformulate sound market regulations, and\
    \ build \nrobust legal and institutional frameworks to \nattract private sector\
    \ interest in PPPs.\nDuring the year, ADB was appointed as transaction \nadvisor\
    \ for the preparation of 13 infrastructure projects \nunder the PPP modality,\
    \ with a total estimated capital \ninvestment requirement of over $3 billion.\
    \ ADB’s \ntransaction advisory services achieved commercial \nclosure of another\
    \ PPP transaction in 2019, bringing \nmobilization of capital investments to $915\
    \ million \nsince the inception of these services in 2014. \nADB also manages\
    \ the Asia Pacific Project \nPreparation Facility—a multidonor trust fund with\
    \ \ncontributions from the governments of Australia, \nCanada, and Japan—to help\
    \ prepare and monitor \nPPP projects, build government capacity, and create \n\
    an enabling environment for PPPs. In 2019, the \nbank approved 17 new applications\
    \ for the fund’s \nassistance and completed 6 preparatory projects. \nThrough\
    \ its support for a solid waste \nmanagement PPP project in Uzbekistan, ADB \n\
    established collaboration with the Global \nInfrastructure Facility. The bank\
    \ continues to \nseek further collaboration with other multilateral \ndevelopment\
    \ banks to promote PPPs.\nFly2Blue (CC0 1.0)\n18\nADB ANNUAL REPORT 2019 \nIn\
    \ June, more than \n1,600 people from 70 \ncountries attended \nthe 2019 Asia\
    \ Clean \nEnergy Forum at \nADB headquarters in \nManila. The annual \nevent attracted\
    \  \nprivate sector \nentrepreneurs, project \ndevelopers, and \nbanks and financial\
    \ \ninstitutions, together \nwith government \nrepresentatives, \ntechnical specialists,\
    \ \nresearchers, youth \norganizations, and \ncivil society. Cohosted \nby ADB,\
    \ the United \nStates Agency \nfor International \nDevelopment, and the \nKorea\
    \ Energy Agency, \nwith the support of the \nInternational Energy \nAgency as\
    \ knowledge \npartner, the forum’s \ntheme was “Partnering \nfor Impact” and \n\
    highlighted the \nneed to focus \non collaborative \npartnerships, ideas, \nand\
    \ efforts that have \nmarket potential, with \nthe goal of delivering \ntangible\
    \ clean energy \nimpact across the Asia \nand Pacific region.\nSTRENGTHENING KNOWLEDGE\
    \ SERVICES\nADB continues to prioritize capacity building in its \ndeveloping\
    \ member countries (DMCs), knowledge \nresources on Asia and the Pacific, and\
    \ regional and \nglobal dialogue and learning on policy challenges.  \nBuilding\
    \ the Knowledge Base  \nof Developing Countries\nADB works closely with its DMCs\
    \ to provide them \nwith knowledge products and services relevant to \ntheir needs.\
    \ \nIn 2019, ADB knowledge products and services \nresponded to development challenges\
    \ as diverse \nas climate finance, education sector reform, the \nagriculture–climate–water–energy\
    \ nexus, and air \npollution. The practical focus of ADB’s knowledge \nwork is\
    \ illustrated by a study on the impact of \ndams on fish in the rivers of Nepal,\
    \ which mapped \nthe routes of fish in the country’s rivers to inform \ndecision‑making\
    \ on dam locations. \nADB also produced the pioneering Trade \nFinance Gaps, Growth,\
    \ and Jobs Survey, which \nidentifies market gaps for trade finance, provides\
    \ \nunderstanding on why gaps exist, explains their \nimpact on economic growth\
    \ and job creation, and \nsuggests actions to close them. The study is the \n\
    first of its kind and has been cited by The Economist \nand Financial Times. \n\
    Supporting the first rigorous education \nsector assessment for Myanmar in 2 decades,\
    \ \nADB provided analytical, policy, and capacity \ndevelopment, as well as pilot\
    \ testing to help the \ngovernment’s Ministry of Education formulate \ncomponents\
    \ of the National Education \nStrategic Plan. \nADB also introduced programs on\
    \ futures \nthinking—a method that considers major changes \nthat may happen in\
    \ the years ahead and how \nto prepare for them—to enhance development \nplanning\
    \ in Armenia, Cambodia, Mongolia, the \nPeople’s Republic of China, the Philippines,\
    \ and \nTimor‑Leste. For instance, in developing the new \ncountry partnership\
    \ strategy for Armenia  \n(approved in October 2019), the futures thinking \n\
    program helped identify how the country can \nuse technology for economic diversification,\
    \ \nplan programs in science and technology, and \nleverage investments in human\
    \ capital and urban \ndevelopment to become a knowledge‑driven \neconomy. \nTo\
    \ help DMCs adapt to a rapidly changing \ninformation environment, ADB began technical\
    \ \nassistance to foster more effective management and \nimplementation of development\
    \ communications. \nDevelopment communications has an important \nrole to play\
    \ in the success of government projects \nand programs, allowing stakeholders\
    \ to understand \nthe development outcomes and benefits of projects \nand programs\
    \ and build consensus through dialogue. \nThe technical assistance will build\
    \ capacity among \ngovernment communications staff. \n19\nSUPPORTING A PROSPEROUS,\
    \ INCLUSIVE, RESILIENT, AND SUSTAINABLE ASIA AND THE PACIFIC\n19\nVéronique Salze-Lozac’h,\
    \ IED deputy director general, speaks \nat the 2019 Asian Evaluation Week, co-organized\
    \ by ADB.   \nADB works \nclosely with \nits DMCs \nto provide \nthem with \n\
    knowledge \nproducts \nand services \nrelevant to \ntheir needs.\nADB also began\
    \ developing a knowledge \nmanagement action plan for 2020–2024. The \nplan outlines\
    \ how the bank can deliver relevant \nknowledge to its DMCs even more effectively.\
    \  \nIt is expected to be adopted in 2020. \nInforming and Influencing Through\
    \ \nDevelopment Research\nADB’s development research underpins its role as a \n\
    knowledge institution.\nIn 2019, the bank’s Tokyo‑based think tank, the \nAsian\
    \ Development Bank Institute (ADBI), \nsuccessfully chaired Think20, the G20’s\
    \ policy \nresearch and advisory network, under Japan’s \n2019 G20 presidency.\
    \ As chair, ADBI launched 10 \nThink20 policy innovation task forces and led those\
    \ \nfocused on infrastructure financing, the future of \neducation and work for\
    \ the digital age, and aging \npopulations.\nTo expand knowledge sharing, ADBI\
    \ launched a \nvirtual classroom for development topics in Asia and \nthe Pacific.\
    \ ADBI E‑Learning provides free, online \ncertificate courses to develop the public\
    \ policy \nknowledge of government officials, development \nprofessionals, academics,\
    \ and students. It allows \n24/7 access to lectures from experts on key topics\
    \ \nsuch as private financing for infrastructure and \nsustainable growth; financial\
    \ inclusion, financial \nliteracy, and financial education; advancing the \ndigital\
    \ economy for sustainable growth; and more.\nOther digital resources launched\
    \ in 2019 include \nADB’s new Key Indicators Database, one of the \nworld’s most\
    \ comprehensive online resources  \nfor macroeconomic and social indicators from\
    \ \nacross Asia and the Pacific. The database will \nbroaden access to the development\
    \ information \nprovided by Key Indicators for Asia and the Pacific,  \nan annual\
    \ flagship publication that marked its 50th \nyear in 2019. \nEngaging in Regional\
    \ and Global Dialogue\nIn 2019, ADB prepared the Central Asia Regional \nEconomic\
    \ Cooperation (CAREC) Transport Strategy \n2030, which was endorsed by CAREC ministers\
    \ \nduring the 18th CAREC Ministerial Conference in \nNovember. The strategy will\
    \ guide CAREC member \ncountries and development partners in the aligned \ndevelopment\
    \ of high‑quality, sustainable, and \nintegrated transport infrastructure and\
    \ logistics \noperations. \nADB delivered signature knowledge events \nthroughout\
    \ the year, convening regional and \ninternational forums on clean energy, skills,\
    \ social \nprotection, urban transport, food security, and \nfinance. It also\
    \ worked with other development \norganizations to establish a global community\
    \ on \nknowledge management.\nADB, the Japan International Cooperation \nAgency,\
    \ the Global Fund, and the World Health \nOrganization joined representatives\
    \ from 25 DMCs \nto discuss innovative approaches for mobilizing \nresources to\
    \ achieve universal health coverage in \nAsia and the Pacific.  \nSharing Evaluation\
    \ Knowledge for Better \nDevelopment Results \nADB’s Independent Evaluation Department\
    \ \n(IED) helps ensure the bank’s accountability \nfor results and supports greater\
    \ effectiveness in \noperations. The IED also plays an active role in \nensuring\
    \ that evaluation knowledge is shared within \nADB and with other multilateral\
    \ institutions and \ndevelopment practitioners.\nIn 2019, the IED conducted key\
    \ knowledge events \nand evaluation capacity‑building activities. \nThis included\
    \  What Works, What Doesn’t and \nWhy panel discussions, a learning series that\
    \ \ncommunicates evaluation findings to internal \nand external audiences. The\
    \ department also \nintroduced a series of videos, Evaluation Bytes and \nEvaluation\
    \ Matters, with interviews and feedback \nfrom users on the importance and use\
    \ of evaluation.\nIn September, the IED collaborated with the \nMinistry of Finance\
    \ of the People’s Republic of \nChina, through the Asia‑Pacific Finance and \n\
    Development Institute, to organize the fourth \nAsian Evaluation Week, with the\
    \ theme “Quality \nEvaluation for Better Results: Local, National, and \nRegional\
    \ Perspectives.” Considered the premier \nevaluation forum in Asia, the event\
    \ attracted \nparticipants from across the region and beyond to \ndiscuss the\
    \ importance and influence of quality \nevaluation to increase development effectiveness.\n\
    20\nADB ANNUAL REPORT 2019 \nREGIONS:  Central and West Asia\nAfghanistan, Armenia,\
    \ Azerbaijan, Georgia, Kazakhstan,  \nthe Kyrgyz Republic, Pakistan, Tajikistan,\
    \ Turkmenistan, Uzbekistan\nBY THE \nNUMBERS\n$5.07 B\nCOMMITTED\n$4.62 B\nDISBURSED\n\
    $442.2 M\nCOFINANCED\n$48.3 M\nTECHNICAL \nASSISTANCE\n2\nEconomic growth in Central\
    \ and West Asia \nremained broadly stable in 2019, supported by a \nmore expansionary\
    \ fiscal stance and private sector \ncredit growth. \nInfrastructure spending\
    \ and continued export \ngains boosted growth in Georgia. In Azerbaijan, \nfiscal\
    \ stimulus and a pickup in gas production \ndrove growth, while an expansionary\
    \ fiscal policy \nsupported growth in Kazakhstan and Tajikistan. In \nArmenia\
    \ and the Kyrgyz Republic, the economy \naccelerated as a result of strong domestic\
    \ \ndemand and growing mining and manufacturing \nsectors, while Uzbekistan benefited\
    \ from an \nimproved investment climate. Faster expansion in \nhydrocarbon production\
    \ and gas exports supported \ngrowth in Turkmenistan. A robust agricultural sector\
    \ \nsupported the economy in Afghanistan. In Pakistan, \ndecisive policy measures\
    \ helped reduce large \nmacroeconomic imbalances and narrow the current \naccount\
    \ deficit in fiscal year 2019, although growth \nwas constrained due to weaker\
    \ economic activity.\nTo foster higher and more inclusive growth \nand raise living\
    \ standards, the region must \nfocus on promoting private sector‑led growth, \n\
    while improving the efficiency of state‑owned \nenterprises. Improvements in human\
    \ capital \ndevelopment through strengthening the quality of \neducation, skills\
    \ development, health and social \nprotection services are needed in most countries.\
    \ \nContinued investment in infrastructure and social \nservices is required,\
    \  together with policies to \nachieve stable and low inflation. \nIn 2019, ADB\
    \ continued to help developing member \ncountries (DMCs) address these challenges\
    \ and \nachieve their development goals. The bank focused \non helping to build\
    \ competitive and inclusive \neconomies, accelerate diversification away from\
    \ \nhydrocarbons and other commodities, develop \ntransformative investments in\
    \ road corridors and \nmunicipal projects for livable and prosperous cities \n\
    across the region, and promote renewable energy \nprojects. ADB closely engaged\
    \ with its DMCs \nthrough policy dialogue, technical assistance, \npolicy‑based\
    \ loans, sector development programs, \nand financial intermediation projects;\
    \ and by \nproviding local currency financing. \nADB also endorsed new country\
    \ partnership \nstrategies for Armenia, Azerbaijan, Georgia, and \nUzbekistan.\
    \ All four strategies cover 2019–2023 and \nshare the common goals of building\
    \ market‑oriented \neconomies, ensuring inclusive and sustainable growth, \nand\
    \ expanding trade. \nSTRATEGIC FOCUS\nAddressing Remaining Poverty and \nReducing\
    \ Inequalities\nAcross Central and West Asia, ADB focuses on creating \neconomic\
    \ and social development opportunities to \nreduce poverty and inequality. This\
    \ is done through \nstrengthening the investment climate for private \nsector\
    \ development, investing in infrastructure, and \nimproving education and health\
    \ services for citizens. \nADB committed a $10 million policy‑based loan \nin\
    \ November as its first social sector investment \nin Armenia to help improve\
    \ the quality and \naccessibility of education and health services \nfor impoverished\
    \ children and young people. In \nTajikistan, implementation began on a $32 million\
    \ \ngrant to improve hospital and health‑care \ncenters. New infrastructure and\
    \ equipment will \nbe supplied, and staff and oversight agencies will \nbe trained\
    \ to plan and deploy human resources \nmore effectively. A system to provide continuous\
    \ \nmedical education for doctors and midwives to \nimprove the quality of maternal\
    \ and child health care \nwill also be established. In Pakistan, a $75 million\
    \ \nsecondary education improvement project in Sindh \nProvince aims to improve\
    \ the quality and access to \nsecondary education, especially for girls, and bring\
    \ in \nmanagement of public schools by the private sector.\nAccelerating Progress\
    \  \nin Gender Equality\nADB’s operations in Central and West Asia continue \n\
    to prioritize gender mainstreaming. In 2019 ADB \ncompleted country gender assessments\
    \ for Armenia, \nAzerbaijan, and the Kyrgyz Republic, which will inform \nthe\
    \ design of future investments and facilitate policy \ndialogue with country counterparts\
    \ on accelerating \ngender equality. \nIn Kazakhstan, ADB partnered with the country’s\
    \ \nNational Chamber of Entrepreneurs to conduct \na series of workshops on developing\
    \ women’s \n21\nCENTRAL AND WEST ASIA\n29%\nPUBLIC SECTOR  \nMANAGEMENT\n21%\n\
    TRANSPORT\n16%\nAGRICULTURE, \nNATURAL RESOURCES, \nAND RURAL \nDEVELOPMENT\n\
    10%\nFINANCE\n10%\nINDUSTRY AND \nTRADE\nIn 2014, floods devastated thousands\
    \ of villages \nand killed hundreds of people in northern \nPakistan. More than\
    \ 2.5 million people were \ndisplaced. In the districts of Poonch, Kotli, and\
    \ \nHaveli in the mountains near Islamabad, roads, \nbasic services, and livelihoods\
    \ were washed \naway. “We were very badly affected,” says Saira \nIlyas, a nursery\
    \ owner from Hajira.\nADB responded to this emergency with a \nreconstruction\
    \ project that has helped rebuild \nsome of the worst‑hit areas, reopening roads,\
    \ \nbridges, and other vital infrastructure. The \nproject included innovative\
    \ bioengineering \nsolutions to protect the new roads against \nfuture landslides\
    \ by planting trees into the \nsteep slopes to stabilize the soil. Local women\
    \ \nwere encouraged to start nurseries and grow \nseedlings, which could then\
    \ be sold and \nreplanted along the roads.\n“The forest department needed more\
    \ plants \nand, to meet the demand, we expanded our \nnursery from 30 kanals (around\
    \ one‑eighth of \nan acre) to 70,” says Saira. “It has brought lots of \nPakistan’s\
    \ Natural Solution to Landslides\nprofit. I am educating my sisters and have opened\
    \ \na school nearby.”  \nBy 2019, more than 2.5 million trees had been \nplanted—70%\
    \ of them grown by women—and \nover PRs23 million (around $135,000) had been \n\
    paid to thriving nurseries. The project employed \nabout 170 people, of which\
    \ 57 were women. In \naddition, 107 forest wardens, 31 of them women, \nwere employed\
    \ to monitor and protect the \nplanted trees.\nSaira Ilyas expanded her nursery\
    \ to meet demand.\nentrepreneurship in rural areas, ultimately \naimed at improving\
    \ livelihood opportunities and \ngrowing incomes. Since May 2019, 300 women \n\
    entrepreneurs have participated in the workshops. \nTackling Climate Change, Building\
    \ \nClimate and Disaster Resilience, and \nEnhancing Environmental Sustainability\n\
    In 2019, ADB continued to advance climate change \nmitigation and adaptation and\
    \ disaster resilience \nin its projects across Central and West Asia. This \n\
    includes support for climate‑resilient transport \ninfrastructure, renewable electricity\
    \ generation, \ndisaster preparedness, and promotion of advanced \nclimate technologies.\
    \ \nUnder its transport investments, ADB integrated \nclimate resilience into\
    \ a $410 million road project \nin Georgia, a country with high exposure to natural\
    \ \nhazards, and financed 24 state‑of‑the‑art electric \nlocomotives in a $170\
    \ million railway project  that \nwill cut Uzbekistan’s greenhouse gas (GHG) \n\
    emissions by 900,000 metric tons of carbon \ndioxide equivalent a year.    \n\
    ADB committed $100 million to upgrade \nhydropower generation in the Kyrgyz Republic\
    \ and \nadded $1.5 million in additional financing from the \nGovernment of Switzerland\
    \ for Pakistan’s National \nDisaster Risk Management Fund. \nIn 2019, ADB signed\
    \ an agreement with the United \nNations Development Programme to pilot, deploy,\
    \ \nand scale up the business models of climate \nchange technology ventures in\
    \ Armenia. Through \nthe agreement, ADB and the United Nations \nDevelopment Programme\
    \ will provide technical \nexpertise and funding to help environment‑oriented\
    \ \ncompanies market new and emerging technologies \nthat support the Sustainable\
    \ Development Goals.\nMaking Cities  \nMore Livable  \nIn many parts of Central\
    \ and West Asia, \ncities are under intense pressure from rapid \nurbanization,\
    \ uncoordinated expansion, and \nlimited infrastructure. ADB’s work in the region\
    \ is \nprioritizing the transformation of such cities into \nsafe, inclusive,\
    \ and sustainable urban centers.\nIn 2019, ADB committed two $15 million loans\
    \ \nand a $10 million grant from project readiness \nfinancing to respectively\
    \ help fast‑track projects \ndelivering urban services in Uzbekistan; support\
    \ \nIn 2019, ADB’s \ncommitments \nin this region \nwere primarily \nin the following\
    \ \nsectors:\n22\nADB ANNUAL REPORT 2019 \nAccess to safe drinking water and sanitation\
    \ services in rural \nareas of the Kyrgyz Republic has become a crucial social\
    \ \nand economic issue. Most of the country’s water supply and \nsanitation infrastructure\
    \ is outdated, while poor water quality \nand sanitation costs the government\
    \ over $100 million each \nyear. \nOnly about 20% of rural households in the Kyrgyz\
    \ Republic \nhave piped water connections and only 10% have access to \nimproved\
    \ sanitation facilities.\nIn 2019, ADB committed $27.4 million to address these\
    \ \nsignificant shortfalls. The investment will help provide safe \nand reliable\
    \ water and sanitation services to more than 64,000 \npeople living in 31 villages\
    \ across the province of Naryn, a \nmountainous rural area where 29% of the population\
    \ is living \nbelow the poverty line. \nThe program will contribute toward goals\
    \ set by the \nGovernment of the Kyrgyz Republic to increase national \naccess\
    \ to safe water supplies from current levels of 40% to \n90%, and for sanitation\
    \ services from 10% to 70%, by 2026.\nRURAL DEVELOPMENT  \nIN THE KYRGYZ REPUBLIC\n\
    ADB’s investment is helping provide safe and reliable water and sanitation \n\
    services to more than 64,000 people living in 31 villages in Naryn.\nbalanced\
    \ regional development in Georgia; and \nprepare a comprehensive tourism development\
    \ \nplan in Tajikistan to inform the selection of strategic \npriorities in the\
    \ tourism ecosystem and help develop \na priority investment pipeline.\nIn Pakistan,\
    \ ADB approved a $235 million loan \nfor a bus rapid transit system in Karachi\
    \ City. The \nproject will provide quality public transport in the \ncity, shorten\
    \ travel times for users, reduce vehicle \noperating costs, and improve air quality\
    \ and GHG \nemissions through an innovative waste‑to‑fuel \nscheme. In partnership\
    \ with the Urban Climate \nChange Resilience Trust Fund, ADB also committed \n\
    $9 million to support the preparation and engineering \ndesign of urban projects\
    \ that will improve the quality \nof life for about 3.5 million people in at least\
    \ five cities \nof Khyber Pakhtunkhwa Province.  \nPromoting Rural Development\
    \  \nand Food Security\nADB’s support for agricultural enterprises and rural \n\
    communities in Central and West Asia involves \nsignificantly improving irrigation to\
    \ help increase \nfarming incomes, generating jobs in agricultural value \nchains,\
    \ and improving food security in rural and \nurban populations. \nIn Afghanistan,\
    \ ADB committed $348.8 million to \nprovide a long‑term sustainable solution to the\
    \ \navailability and management of water in the \nArghandab basin of Kandahar\
    \ Province by increasing \nthe storage capacity of Dahla Dam. \nIn Uzbekistan,\
    \ the bank made new commitments to \nimprove horticultural and livestock value\
    \ chains. A \n$197 million loan is helping establish logistics centers \nin Andijan\
    \ and Samarkand to improve the processing \nand distribution of horticultural\
    \ products. Meanwhile, \na $150 million loan will expand access to finance and\
    \ \nmarkets for Uzbekistan’s livestock farmers and help \ndevelop veterinary practices.\n\
    Strengthening Governance  \nand Institutional Capacity\nADB continued to support\
    \ its DMCs in Central \nand West Asia to strengthen their governance \nand institutional\
    \ capacities in 2019. This includes \nmeasures to support the private sector by\
    \ improving \naccess to finance, and supporting public financial \nstability.\n\
    In 2019 ADB extended a total of $1.8 billion to \nPakistan to support key economic,\
    \ energy, and \ntrade reforms. This includes a $1 billion special \npolicy‑based\
    \ loan approved in December as part \nof international efforts, led by the International\
    \ \nMonetary Fund, to support Pakistan’s economic \nreforms. It is the first time\
    \ ADB has used this lending \nmodality. The package aims to help Pakistan address\
    \ \n23\nCENTRAL AND WEST ASIA\nEducation and Skills \nDevelopment under \nthe\
    \ CAREC Program  \nADB produced a \nscoping study that \nidentified important\
    \ \nopportunities \nin Central Asia \nRegional Economic \nCooperation \ncountries\
    \ to \nharmonize education \nand skill standards, \nenhance student \nand worker\
    \ mobility, \nstrengthen labor \nmarket information, \nand facilitate \nknowledge\
    \ exchange.\nCAREC SECRETARIAT\nwww.carecprogram.org\nEducation and Skills Development\
    \ under the CAREC Program\nA Scoping Study\nThe global employment and skills landscape\
    \ is changing fast in the fourth industrial revolution. Investing \nin human development\
    \ is essential to meet the needs of rapidly evolving competitive labor markets\
    \ and \nachieve sustainable economic growth. Recognizing this, the CAREC Program’s\
    \ 2030 strategy features \nhuman development as one of its ﬁ ve operational priorities\
    \ and speciﬁ es education as a key area of focus. \nThis report examines how CAREC\
    \ member countries can collaborate for education and skills development. \nIt identiﬁ\
    \ es important opportunities to harmonize education and skill standards, enhance\
    \ student and \nworker mobility, strengthen labor market information and movement,\
    \ and facilitate knowledge exchange. \nAbout the Central Asia Regional Economic\
    \ Cooperation Program \nThe Central Asia Regional Economic Cooperation (CAREC)\
    \ Program is a partnership of 11 member countries \nand development partners working\
    \ together to promote development through cooperation, leading \nto accelerated\
    \ economic growth and poverty reduction. It is guided by the overarching vision\
    \ of “Good \nNeighbors, Good Partners, and Good Prospects.” CAREC countries include:\
    \ Afghanistan, Azerbaijan, \nthe People’s Republic of China, Georgia, Kazakhstan,\
    \ the Kyrgyz Republic, Mongolia, Pakistan, Tajikistan, \nTurkmenistan, and Uzbekistan.\
    \ \nAbout the Asian Development Bank\nADB is committed to achieving a prosperous,\
    \ inclusive, resilient, and sustainable Asia and the Paciﬁ c, \nwhile sustaining\
    \ its ef orts to eradicate extreme poverty. Established in 1966, it is owned by\
    \ 68 members\n—49 from the region. Its main instruments for helping its developing\
    \ member countries are policy dialogue, \nloans, equity investments, guarantees,\
    \ grants, and technical assistance.\nASIAN DEVELOPMENT BANK\n6 ADB Avenue, Mandaluyong\
    \ City\n1550 Metro Manila, Philippines\nwww.adb.org\nEDUCATION AND SKILLS \nDEVELOPMENT\
    \ UNDER \nTHE CAREC PROGRAM\nSCOPING STUDY\nSEPTEMBER 2019\nWith ADB support,\
    \ Tajikistan will upgrade the existing highway connecting its capital to the \n\
    Kyrgyz Republic.\nthe root causes of its chronic fiscal crisis, diversify \navenues\
    \ to trade, enhance competitiveness, and \nreform its energy sector.\nADB committed\
    \ policy‑based loans of \n$300 million and $40 million for Uzbekistan and \nArmenia,\
    \ respectively, to improve economic \nmanagement in the two countries by supporting\
    \ \nfiscal sustainability, private sector investment, and \nfinancial and capital\
    \ market development. \nAs part of its ongoing assistance to Azerbaijan, \nADB\
    \ extended $250 million to strengthen \npublic sector governance and fiscal management\
    \ \nand encourage private sector development.  \nThis policy‑based loan will support\
    \ the \nimplementation of rule‑based fiscal planning, \na public debt management\
    \ strategy, and state‑\nowned‑enterprise reforms. It will help to develop \nnon‑oil\
    \ enterprises and reduce the country’s \nvulnerability to external shocks.\nADB\
    \ committed a $50 million policy‑based grant \nto the Kyrgyz Republic to help\
    \ create jobs and \nraise employment prospects by improving the \ncountry’s trade\
    \ and investment climate, facilitating \nthe growth of small and medium‑sized\
    \ enterprises, \nsupporting public–private partnerships, and \nfostering industry‑linked\
    \ skills.\nFostering Regional Cooperation  \nand Integration\nADB’s efforts to\
    \ promote regional cooperation and \nintegration across Central and West Asia\
    \ are largely \nchanneled through the Central Asia Regional \nEconomic Cooperation\
    \ (CAREC) platform. \nAt the 18th CAREC Ministerial Conference in \nUzbekistan\
    \ in November, ADB emphasized its \nsupport for the energy and transport strategies\
    \ that \nare part of CAREC Strategy 2030.  \nADB committed a $110 million grant\
    \ to Tajikistan \nto improve connectivity and safety along the \nObigarm–Nurobod\
    \ road, part of CAREC  \nCorridors 2, 3, and 5, connecting Tajikistan to the \n\
    Kyrgyz Republic. The road carries about 2,000 \nvehicles a day.\nIn August, the\
    \ bank also committed $500 million \nto introduce important tariff and tax‑related\
    \ \npolicy reforms that will bolster Pakistan’s export \nindustries and increase\
    \ their competitiveness. \nThe investment will also strengthen key trade‑\nfacilitating\
    \ institutions. \nIn 2019, ADB supported an assessment to \ndetermine Afghanistan’s\
    \ readiness to join an \nexpanded Central Asian Power System, joining \nKazakhstan,\
    \ the Kyrgyz Republic, Tajikistan, and \nUzbekistan. An expanded Central Asian\
    \ Power \nSystem will enhance regional energy security, \nimprove regional power\
    \ trade, and reduce  \nGHG emissions from electricity consumption  \nin the region.\
    \ \nKNOWLEDGE HIGHLIGHTS \nIn 2019, ADB provided tailored support to national\
    \ \nstatistical offices in Central and West Asia, assisting \nevidence‑based policymaking\
    \ and modernization \nof national statistical systems. \nThe bank formulated a\
    \ skills‑gap analysis for the \nAlmaty–Bishkek Economic Corridor, suggesting \n\
    ways to develop sustainable tourism in Kazakhstan \nand the Kyrgyz Republic, and\
    \ produced a policy \nbrief to examine the use of public–private \npartnerships\
    \ for education in the Pakistan province \nof Sindh. \nThrough a joint program\
    \ for knowledge and \nexperience exchange, ADB is supporting the \nGovernment\
    \ of Kazakhstan’s voluntary national \nreview and nationalization of the Sustainable\
    \ \nDevelopment Goals. \nADB contributed to the first CAREC forum for \ncapital\
    \ market regulators, held in Islamabad, \nPakistan, to discuss regional cooperation\
    \ for \ndeveloping capital markets, enhancing access \nto finance, and supporting\
    \ private sector \ndevelopment. A CAREC high‑level forum \non infrastructure,\
    \ jointly organized with the \nInternational Monetary Fund and the World Bank,\
    \ \ndiscussed infrastructure financing needs,  \nfiscal constraints, debt sustainability,\
    \ and the \nneed for more private sector involvement in \ninfrastructure financing.\n\
    \  \n24\nADB ANNUAL REPORT 2019 \nBY THE \nNUMBERS\n$2.19 B\nCOMMITTED\n$1.75\
    \ B\nDISBURSED\n$376.1 M\nCOFINANCED\n$23.1 M\nTECHNICAL \nASSISTANCE\n2\nREGIONS:\
    \  East Asia\nThe People’s Republic of China, Mongolia\nEconomic growth decelerated\
    \ in East Asia during \n2019. In the People’s Republic of China (PRC), \ngrowth\
    \ moderated from 6.7% in 2018 to 6.1% in \n2019, the lowest since 1990. In Mongolia,\
    \ economic \ngrowth slowed to 5.1% in 2019 from 7.2% in 2018. \nInternational\
    \ trade tensions and other external \nfactors were the key causes of decline.\
    \ \nThe countries of East Asia, while confronted \nby their own specific issues,\
    \ still face common \nand long‑standing development challenges. \nEnvironmental\
    \ concerns—especially pollution—\nare significant, with considerable resources\
    \ needed \nto mitigate the impacts of climate change. In the \nPRC, government\
    \ efforts to eradicate extreme \npoverty by the end of 2020 were hampered by \n\
    the recent economic slowdown. The PRC also \nneeds to embrace industrial transformation\
    \ and \naccommodate aging populations, while Mongolia \nneeds to address underdeveloped\
    \ infrastructure,  \na lack of export diversification, and unemployment. \nADB’s\
    \ investments in East Asia are working to \nhelp overcome these challenges, with\
    \ a focus on \nreducing pollution, strengthening responses to \nclimate change,\
    \ providing better access to social \nservices, and boosting transport connectivity \
    \ \nand trade in border areas. The bank is also working \nto improve the well‑being\
    \ of rural residents  \nand promote inclusive economic growth across  \nthe region.\n\
    In particular, ADB is helping the PRC and Mongolia \nby informing policies and\
    \ laws, building more \neffective institutions, supporting the use of \nadvanced\
    \ technologies, and establishing innovative \ngreen financing mechanisms. Some\
    \ of this work \nhas resulted in policy and institutional changes \nthat can be\
    \ shared with, and adapted by, ADB \ndeveloping member countries (DMCs) in other\
    \ \nregions.\nSTRATEGIC FOCUS\nAddressing Remaining Poverty \nand Reducing Inequalities\n\
    ADB’s work in East Asia to address poverty and \nreduce inequalities centers on\
    \ improving health \noutcomes for the poor and disadvantaged, \nengaging the private\
    \ sector to create quality \njobs and raise income levels, and providing more\
    \ \ninclusive services for aging populations.\nIn Mongolia, where the government\
    \ has \nprioritized greater access to health services for \nimpoverished and remote\
    \ communities, ADB \ncommitted $16 million of additional financing \nin 2019 to\
    \ fund the completion of a new district \nhospital that will directly benefit\
    \ 320,000 poor \nresidents of Ulaanbaatar. This complements an \ninitial $76.1\
    \ million commitment to a program to \nimprove primary health services in the\
    \ country.   \nIn the PRC, an example of ADB’s work to \nimprove the quality of\
    \ life for older residents is \nin the city of Yichang, where around 22% of the\
    \ \npopulation is aged over 60. The bank committed \na $150 million loan to pilot\
    \ an integrated \napproach that will improve elderly care services \nand facilities,\
    \ including for dementia patients; \nbuild a geriatric hospital and nursing home;\
    \ and \ndevelop an advanced patient management and \nmonitoring system.\nAccelerating\
    \ Progress  \nin Gender Equality\nAs part of broader efforts to advance gender\
    \ \nequality in East Asia, ADB is helping develop \nhigh‑technology transport\
    \ systems that will ease \nthe burden of travel for women and girls—the \nmost\
    \ frequent users of public transport—as well \nas provide them with more job opportunities.\
    \ \nIn December 2019, for example, ADB committed \na $192.8 million loan for a\
    \ transport project \nin the district of Gui’an in Guizhou Province. \nThe project\
    \ includes gender‑sensitive safety \nmeasures such as bright lighting and security\
    \ \ncameras at bus stops and stations. The intelligent \ntransport system (ITS)\
    \ provides real‑time traffic \nand road‑weather monitoring and a facility to \n\
    report incidents on a real‑time basis to enhance \nsecurity and respond to emergencies.\
    \ At least \n30% of people employed in the ITS control \ncenter will be women.\
    \ The project will also run \ntraining courses in primary and middle schools \n\
    to teach ITS coding concepts to at least 600 \ngirls and encourage them to pursue\
    \ science and \ntechnology careers.\n25\nEAST ASIA\n19%\nWATER AND \nOTHER URBAN\
    \ \nINFRASTRUCTURE \nAND SERVICES\n18%\nAGRICULTURE, \nNATURAL RESOURCES, \nAND\
    \ RURAL \nDEVELOPMENT\n16%\nHEALTH\n13%\nTRANSPORT\n21%\nENERGY\nEmissions were\
    \ reduced in this Shandong copper smelting plant.\nShandong is the People’s Republic\
    \ of China’s \nsecond most populous province. In 2011, it \nwas also the second‑ranking\
    \ province in terms \nof industrial outputs. Its energy supply relied \nheavily\
    \ on high carbon fossil fuels—coal (71%) \nand oil (26%)—causing high levels of\
    \ emissions. \nIndustry consumed over 75% of Shandong’s \ntotal energy supply.\
    \ To improve energy \nefficiency and conservation, the province \nmade plans to\
    \ reduce energy intensity by 17% \nby 2015 in comparison with 2010 levels, and\
    \ by \n17% by 2020 in comparison with 2015 levels. \nTo support those goals, in\
    \ 2011, ADB \napproved a financial intermediation loan \nof $100 million for an\
    \ energy efficiency and \nemission reduction project. The project \nsupported\
    \ industry to invest in technology \ninnovations that lead to reduced energy costs\
    \ \nand enhanced market competitiveness. The \nfinancial intermediation loan modality\
    \ helped \nto accelerate private sector investment in \nimproving energy efficiency\
    \ and enhanced \nprovincial capacity in financing and \nmanaging energy conservation\
    \ projects. \nCleaning Shandong’s Air with Private Sector Support\nThe investment\
    \ was a success. The province \nreduced energy intensity by 19.8% by 2015 in \n\
    comparison with 2010, and by 16.3% by 2018 \ncompared to 2015. The total energy\
    \ saved from the \ninvestment translated to an annual greenhouse \ngas emission\
    \ reduction of almost 680,000 \nmetric tons of carbon dioxide equivalent. The\
    \ \ninvestment’s energy efficiency and emissions \nreduction objectives were achieved.\
    \ The \nimprovement in air quality particularly benefited \nthe poor who are more\
    \ exposed to health \nrisks such as air pollution and coal burning.\nTackling\
    \ Climate Change, Building \nClimate and Disaster Resilience, and \nEnhancing\
    \ Environmental Sustainability\nPollution in general, and air pollution in particular,\
    \ \nare serious concerns for the governments of the \nPRC and Mongolia. \nIn December,\
    \ ADB committed a $160 million \npolicy‑based loan to further strengthen the \n\
    Government of Mongolia’s ability to address \nsevere air pollution in Ulaanbaatar.\
    \ The loan \nis supporting immediate actions to reduce the \nburning of coal,\
    \ together with reforms to promote \nthe use of clean‑energy resources for heating.\n\
    While ADB takes specialized approaches to \naddress climate, environment, and\
    \ disaster \nmanagement challenges across East Asia, the bank \nprioritizes reducing\
    \ the region’s greenhouse gas \nemissions.\nIn May, ADB signed a $392 million\
    \ loan to \ndemonstrate the use of advanced clean \ntechnologies for heating and\
    \ cut greenhouse gas \nemissions by about 4 million metric tons of carbon \ndioxide\
    \ equivalent annually in Shandong Province \nin the PRC. The investment showcases\
    \ the use of \ngeothermal, biomass, and waste heat to improve \nthe living conditions\
    \ and health of around 647,000 \npeople. \nMaking Cities  \nMore Livable\nRapid\
    \ urbanization is a major development \nchallenge in East Asia and ADB is working\
    \ to \nfoster inclusive and green urban development \nin the region. The bank\
    \ signed a $200 million \nloan in May to support the use of advanced \ntechnologies\
    \ to improve the urban environment \nand livability of Ziyang Municipality in\
    \ Sichuan \nProvince. The project is expected to benefit an \nestimated 3.6 million\
    \ people by building flood \ncontrol embankments, rehabilitating wetland \nareas,\
    \ and turning a polluted landfill site into a \npark. A research and development\
    \ center will be \nconstructed and is expected to generate at least \n5,000 jobs\
    \ in the service and lighting industries. \nThe experience and knowledge gained\
    \ from \nwetland rehabilitation, landfill transformation, and \nsustainable city\
    \ development can be replicated in \nother cities along the Yangtze River Basin\
    \ in the \nPRC and shared with DMCs in other regions. \nLufang subproject\nIn\
    \ 2019, ADB’s \ncommitments \nin this region \nwere primarily \nin the following\
    \ \nsectors:\n26\nADB ANNUAL REPORT 2019 \nMongolia’s small tourism sector is\
    \ growing rapidly and \npresents an opportunity to create quality jobs and help\
    \ more \npeople move out of poverty. Khuvsgul National Park and \nOnon‑Balj National\
    \ Park are eco‑tourism priorities for the \nGovernment of Mongolia, but as major\
    \ sources of biodiversity, \nthey need to be carefully managed.\nIn June 2019,\
    \ ADB signed a $38 million loan agreement \nwith Mongolia to help the country\
    \ seize these economic \nopportunities while also safeguarding the environment.\
    \ The \nproject will adopt community‑based approaches to improve \ninfrastructure,\
    \ sanitation, and capacity to manage tourism \ngrowth in the two national parks\
    \ and will help develop \nsustainable tourism activities. \nThe loan—ADB’s first\
    \ lending product for tourism in \nthe country—is expected to create jobs for\
    \ over 11,000 \nlargely disadvantaged residents. The project will be closely \n\
    monitored as a potential model of economically inclusive \ndevelopment and conservation\
    \ for other ADB developing \nmember countries.\nPOVERTY REDUCTION  \nTHROUGH ECO-TOURISM\n\
    ADB support is helping Mongolia develop sustainable eco-tourism \nmeasures to\
    \ protect biodiversity in their national parks.\nPromoting Rural Development \
    \ \nand Food Security\nFarmers, rural producers, and agribusiness \nentrepreneurs\
    \ in East Asia have enormous \npotential to tap into high‑value markets both \n\
    domestically and internationally. ADB supports \nthese rural enterprises with\
    \ project financing \nand knowledge products that explore new \ntechnologies and\
    \ techniques to maximize \nagricultural productivity.  \nIn the PRC’s Gansu Province,\
    \ the bank \ncommitted a $130 million loan to develop a \nweb‑based platform to\
    \ enhance market access \nthrough a two‑way automated information \nexchange system\
    \ between farmers and \nconsumers. The approach offers production \ninformation\
    \ for consumers, while farmers will get \naccess to market information and production\
    \ \nsupport services, providing opportunities to \nimprove livelihoods by accessing\
    \ high‑value \nmarkets. The project will also help improve food \nsafety and the\
    \ competitiveness of agricultural \ngoods by using internet‑of‑things applications\
    \ \nsuch as QR code scanners, soil fertility and \nmoisture sensors, and remote\
    \ sensing. Nearly \n13,000 farming households are likely to be \ninvolved in contract\
    \ farming and around 110,000 \nrural households are expected to benefit from \n\
    using the information platform. \nAs part of ADB’s ongoing support for rural \n\
    vitalization in the PRC, the bank committed \na $300 million loan to address environmental\
    \ \ndegradation, modernize agricultural production \nsystems, and boost rural\
    \ incomes for 1.8 million \npeople in the upper and middle reaches of the \nYangtze\
    \ River Basin. \nStrengthening Governance  \nand Institutional Capacity \nADB\
    \ investments help to enhance public \nfinancial management and increase stability\
    \ in \nthe finance sector in East Asia. \nADB committed $1.2 million in technical\
    \ \nassistance to help Mongolia strengthen the \ncapabilities of its national\
    \ audit office by \nsharpening the monitoring of use of public funds \nand improving\
    \ capacity to conduct financial, \nperformance, and compliance audits. The project\
    \ \nwill also help develop a digital master plan in \naudit and financial management.\
    \ \nADB also signed a memorandum of \nunderstanding with the PRC’s central bank,\
    \ \nthe People’s Bank of China, to support reforms \nand knowledge cooperation\
    \ in the finance \nsector from 2019 to 2023. This will help \nthe PRC strengthen\
    \ its legal and regulatory \n27\nEAST ASIA\nEffective Approaches \nto Poverty\
    \ Reduction: \nSelected Cases  \nfrom the Asian \nDevelopment Bank  \nThese nine\
    \ case studies \nfrom across Asia and \nthe Pacific, including \nfour from East\
    \ Asia, \nfocus on providing \nbroader access to \neconomic opportunities, \n\
    promoting resilience, \nand empowering \ncommunities through \nimproved governance.\
    \ \nBy sharing experiences \nfrom successful projects, \nthis report contributes\
    \ to \ninternational efforts  \nto eradicate poverty.\nA $130 million loan to\
    \ the People’s Republic of China’s Gansu Province to develop a web-\nbased platform\
    \ to link farmers with consumers will improve competition and quality, and help\
    \ \nfarmers get the best prices for their products.\nframeworks for the finance\
    \ sector and expand \nthe use of technology to increase access to \nfinance, particularly\
    \ for small and medium‑\nsized enterprises. ADB approved a $700,000 \ntechnical\
    \ assistance project in December to \nsupport the implementation of initiatives\
    \ under \nthe memorandum of understanding and identify \nlessons from the PRC’s\
    \ experience that can be \napplied in other countries.\nFostering Regional  \n\
    Cooperation and Integration\nADB’s efforts to foster regional cooperation \nand\
    \ integration in East Asia focus on improving \ntransport connectivity and streamlining\
    \ cross‑\nborder trade and travel.  \nADB committed a $27 million loan to expand\
    \ \nMongolia’s international trade by upgrading \nfacilities at the border crossings\
    \ of Bichigt and \nBorshoo, which connect the country to the PRC \nand the Russian\
    \ Federation. \nThe bank also committed a loan of $58.5 million, \ncofinanced\
    \ by the High‑Level Technology \nFund, to help improve surfaces and safety along\
    \ \n176 kilometers of Mongolia’s Ulaanbaatar–Darkhan \nand Khuiten Valley–Arvaikheer\
    \ road sections, \nwhich link the PRC and the Russian Federation \nthrough Mongolia’s\
    \ capital.\nKNOWLEDGE HIGHLIGHTS \nADB emphasizes adding value to its financial\
    \ \ninvestments through knowledge work targeted \nto the needs of East Asia. This\
    \ helps to identify \ninnovative approaches that can be replicated both \nwithin\
    \ and outside the region. \nIn 2019, in response to a request by the \nGovernment\
    \ of the PRC, ADB supported a series \nof workshops to promote dialogue on aging,\
    \ \ntechnical and vocational education and training, \nand rural vitalization.\
    \ Participants from central \nand provincial governments and academia shared \n\
    their knowledge and experiences to help identify \npriorities for policy reform\
    \ and investment \nplanning. \nTo assist the PRC’s National Development  \nand\
    \ Reform Commission, ADB prepared \npapers giving detailed research and policy\
    \ \nrecommendations for the country’s 14th Five‑Year \nPlan, 2021–2025. These\
    \ papers focus on climate \nchange, ecosystem services, rural vitalization, \n\
    urbanization, inclusive development, the role \nof local government, and the development\
    \ \nframework for the PRC’s modernization strategy. \nADB signed two significant\
    \ knowledge \ncollaboration agreements in 2019. It partnered \nwith Alibaba to\
    \ better assist the implementation \nof the PRC’s rural vitalization strategy,\
    \ taking \nadvantage of the latest digital technologies such \nas e‑commerce and\
    \ cloud computing; and with \nthe Asia‑Pacific Finance and Development \nInstitute\
    \ on South–South knowledge cooperation \nand capacity building of DMC officials\
    \ in related \nareas of finance and development. The bank also \norganized innovation\
    \ workshops on topics such \nas education, elderly care, and green finance to\
    \ \ndiscuss next‑generation investments.\nIn November, using research gathered\
    \ during \nan ADB investment project, the bank published \na brief, Integrating\
    \ Persons with Disabilities into \nMongolia’s Society, which suggests reforms to\
    \ \nbetter assess the needs of persons with disabilities \nand improve their access\
    \ to infrastructure, \ntransportation, education, and employment.\n28\nADB ANNUAL\
    \ REPORT 2019 \nBY THE \nNUMBERS\n$443.5 M\nCOMMITTED\n$446.5 M\nDISBURSED\n$206.1\
    \ M\nCOFINANCED\n$27.1 M\nTECHNICAL \nASSISTANCE\n2\nREGIONS:  Pacific\nThe Cook\
    \ Islands, Fiji, Kiribati, the Marshall Islands, the Federated States of Micronesia,\
    \ Nauru, \nNiue, Palau, Papua New Guinea, Samoa, Solomon Islands, Timor-Leste,\
    \ Tonga, Tuvalu, Vanuatu\nIn 2019, the combined gross domestic \nproduct of Pacific\
    \ economies expanded \nby 4%, the region’s fastest average growth \nsince 2015.\
    \ It followed historically low economic \ngrowth of 0.4% in 2018, when the Pacific\
    \ was hit \nby a major earthquake and tropical cyclones. \nThis growth story highlights\
    \ the crucial role \nplayed by disaster response and recovery in \nshaping the\
    \ region’s development progress \nand explains why ADB moved to expand its \n\
    financing for disaster resilience in 2019. \nOn top of the support for disaster\
    \ response, \nrecovery, and reconstruction, financing is needed \nfor climate\
    \ change adaptation and to overcome \nan infrastructure backlog causing gaps in\
    \ \nbasic services. For example, access to reliable \nelectricity is only about\
    \ 33% among Pacific \ndeveloping member countries (DMCs), \ncompared with 87.4%\
    \ globally. Similarly, provision \nof safe water (52.6% versus 88.5% globally)\
    \ and \nsanitation services (30% versus 68% globally) are \nlagging.\nThe 2019\
    \ ADB Annual Meeting was the first \nheld in a Pacific DMC, Fiji. It was attended\
    \ \nby more than 3,500 representatives from \n76 countries. Among the issues discussed\
    \ at \nthe Annual Meeting were sustainable tourism \nand its potential to boost\
    \ national and regional \ndevelopment efforts, the role of private sector \nfinancing\
    \ for disaster risk management and \nclimate resilience, and the importance of\
    \ actions \nto improve ocean health. There were also \ndiscussions on ways to\
    \ respond to heightening \nglobal economic uncertainty, the role of digital \n\
    technologies for financial inclusion,  new tools \nfor sustainable infrastructure\
    \ development, and \nother topics. The event’s theme was “Prosperity \nThrough\
    \ Unity.”\nDuring the year, ADB endorsed a new country \npartnership strategy\
    \ for Fiji, covering 2019–2023. \nThe strategy aligns with the government’s goals\
    \ \nfor Fiji to become a South Pacific business hub \nby improving transport and\
    \ digital connectivity, \ndeveloping a skilled workforce, and creating \nproductive\
    \ jobs.\nSTRATEGIC FOCUS\nAddressing Remaining Poverty \nand Reducing Inequalities\n\
    Extreme poverty has declined in the Pacific, but \nat a rate significantly slower\
    \ than the overall \ndecline across the Asia and Pacific region. In \n2019, ADB\
    \ accelerated efforts to ensure access \nto adequate health care, essential infrastructure,\
    \ \nand social services.\nThe bank is working to reduce the incidence \nof pneumonia\
    \ and diarrhea in children and \nminimize outbreaks of vaccine‑preventable \n\
    diseases. In February 2019, ADB committed \n$11.3 million to Vanuatu and $7.5\
    \ million to \nSamoa as part of a $25.1 million package to \ndeliver a comprehensive\
    \ vaccination program in \nthe region. This follows commitments to Tonga \nand\
    \ Tuvalu in 2018. \nIn Papua New Guinea (PNG), ADB is \nadministering  $38 million\
    \ additional financing \nfrom the Government of Australia to improve \nhealth\
    \ outcomes in lagging rural areas by \nupgrading 20 district hospitals.\nTo advance\
    \ the delivery of basic services into \npoor and disadvantaged communities, ADB\
    \ \ncommitted $11 million to prepare projects for \nimproved urban water supply,\
    \ sanitation, and \nsolid waste management in the Federated States \nof Micronesia,\
    \ Solomon Islands, and Vanuatu. \nThe bank also committed $37 million in 2019\
    \ to \nimprove urban water and sanitation in Solomon \nIslands, with an additional\
    \ $3 million as project \nreadiness financing.\nAccelerating Progress  \nin Gender\
    \ Equality\nEmpowering women is vital to achieving \ninclusive, resilient, and\
    \ sustainable development \nin the Pacific. Despite progress in advancing \ngender\
    \ equality in many Pacific DMCs, a \nsignificant proportion of women and girls\
    \ \nstill face poverty and inequality as well as \nlimitations on their access\
    \ to essential services \nand resources. There is a gender gap in labor \n29\n\
    PACIFIC \n29%\nPUBLIC SECTOR  \nMANAGEMENT\n24%\nHEALTH\n18%\nENERGY\nThe Pacific\
    \ accounts for only 0.1% of the \nworld’s population, but the region experiences\
    \ \na disproportionately high share of global \ndisaster impacts relative to its\
    \ economic and \ndemographic size. Disaster risk is growing \nbecause of climate\
    \ change, poor development \nplanning, unplanned urbanization, and \necosystem\
    \ decline. \nContingent disaster financing is a leading‑\nedge mechanism designed\
    \ by ADB to provide \nquick‑disbursing and flexible financing for \ndeveloping\
    \ member countries impacted by \ndisaster events.\nWhen Tonga was hit hard by\
    \ Cyclone Gita in \nFebruary 2018, Kaveinga Taufa and his family \nlost their\
    \ home.\n“All that was left was part of the roof and a big \npile of rubble,”\
    \ Kaveinga says. \nThrough contingent disaster financing, funds \nwere released\
    \ to Tonga for early recovery \nactivities just 3 days after the cyclone struck.\
    \ \nQuick Response Keeps Kaveinga’s Family Safe\nRepairing Tonga’s electricity\
    \ network after Cyclone Gita.\n12%\nTRANSPORT\nKaveinga and his family were provided\
    \ temporary \nshelter until their house could be rebuilt, and food \nand drinking\
    \ water via the National Emergency \nManagement Office.\nIn 2019, ADB expanded\
    \ coverage of its contingent \ndisaster financing to include the Federated States\
    \ \nof Micronesia, the Marshall Islands, and Solomon \nIslands, as well as replenished\
    \ funds for the Cook \nIslands and Tonga.\n14%\nWATER AND \nOTHER URBAN \nINFRASTRUCTURE\
    \ \nAND SERVICES\nforce participation—in 2017, the Pacific female \nlabor force\
    \ participation rate was at 44.3%, more \nthan 8 percentage points lower than\
    \ for males. \nPacific women have limited representation in \ndecision‑making\
    \ structures—in 2017, only 6% \nof parliamentarians in the Pacific were women.\
    \ \nViolence against women and girls remains a \nconcern—in several Pacific DMCs,\
    \ more than \n30% of women reported being sexually abused \nbefore 15 years of\
    \ age.\nADB continues to incorporate gender \nconsiderations into its projects,\
    \ with a view to \ncreating livelihood and career opportunities for \nwomen. As\
    \ part of a $5 million grant to Tonga, for \nexample, ADB included actions addressing\
    \ key \nlegislative barriers to employment for women in \nthe labor market.\n\
    In Fiji, an ADB loan of $65 million supports \nthe economic empowerment of women\
    \ by \nembedding gender considerations into measures \nto improve budget systems\
    \ and institutions, \nboost the productivity and competitiveness \nof state‑owned\
    \ enterprises, and generate new \nbusiness and quality jobs. \nTackling Climate\
    \ Change, Building \nClimate and Disaster Resilience, and \nEnhancing Environmental\
    \ Sustainability\nADB continues to offer innovative solutions \nfor Pacific DMCs\
    \ to develop renewable energy \nsources, reduce greenhouse gas emissions, and\
    \ \nbuild environmental sustainability.\nThrough the Pacific Renewable Energy\
    \ Investment \nFacility, ADB has committed $55.2 million and will \nadminister\
    \ $32.4 million in cofinancing from the \nGovernment of Australia and the Green\
    \ Climate \nFund, to support renewable energy projects in the \nFederated States\
    \ of Micronesia, Nauru, Tonga, and \nTuvalu. Under the $6 million project for\
    \ Tuvalu—\nADB’s first‑ever assistance to the country’s energy \nsector—the bank\
    \ is helping install solar power and \nbattery systems to reduce Tuvalu’s heavy\
    \ reliance \non fossil fuels for power generation. \nMaking Cities  \nMore Livable\n\
    Small island developing states across the \nPacific have limited expertise in\
    \ urban planning, \ndevelopment, and management. \nIn 2019, ADB’s \ncommitments\
    \ \nin this region \nwere primarily \nin the following \nsectors:\n30\nADB ANNUAL\
    \ REPORT 2019 \nIn Papua New Guinea, ADB is supporting women and \ngirls through\
    \ the expansion of rural health services and \ntargeted training of health workers\
    \ to improve the delivery of \nobstetrics and reproductive health care. \nUnder\
    \ a $195 million sector development program starting \nin 2018, ADB is supporting\
    \ the integration of gender equality \nprinciples and processes across the health\
    \ system. This \nincludes ensuring gender considerations in the construction \n\
    of health facilities, mainstreaming gender in national health \nstrategies, enhancing\
    \ health workers’ skills in reproductive \nhealth and safe birthing, and providing\
    \ training on family \nplanning and sexual health. \nIn 2019, ADB committed a\
    \ further $100 million to support \ngender policy reforms such as including women\
    \ in senior \ndecision‑making roles in the health sector; ensuring a budget \n\
    for family, maternal, and child health services; and including \ncontraceptives\
    \ and maternal and neonatal medication in \nstocks of essential drugs. \nGENDER\
    \ EQUALITY  \nIN PAPUA NEW GUINEA\nMaria Talpa runs a rural primary health project\
    \ in Papua New Guinea, part of \nthe health sector program supported by ADB and\
    \ Australia.\nThere is an urgent need to improve water and \nsanitation services\
    \ in the fast‑growing urban \npopulations of Kiribati and the Marshall Islands.\
    \ \nADB is providing a $13 million grant for Kiribati \nto address the high incidence\
    \ of waterborne \ndiseases and improve hygiene practices in South \nTarawa. For\
    \ the Marshall Islands, a $5 million \ngrant was approved to prepare projects\
    \ that will \nimprove urban water and sanitation services in \nMajuro and solid\
    \ waste management in Ebeye. \nIn Tonga, ADB committed $18.3 million to \nprovide\
    \ high‑priority urban infrastructure in \nNuku’alofa, supporting flood risk management,\
    \ \nwater supply and solid waste management, and \ndisaster and climate resilience.\
    \ The bank is also \nadministering  additional financing of $290,000 \nfrom the\
    \ Government of Australia for an ongoing \nproject to support waste management\
    \ services in \nthe capital. \nIn PNG, ADB is administering cofinancing of \n\
    $800,000 from the People’s Republic of China \nPoverty Reduction and Regional\
    \ Cooperation \nFund to expand access to safe water in the \nTete settlement of\
    \ Port Moresby.  \nPromoting Rural Development  \nand Food Security\nRural communities\
    \ in the Pacific generally \nhave fewer economic opportunities and \nless access\
    \ to basic services than the \nurban population. ADB works to improve \nlivelihoods in rural\
    \ areas and outer island \ncommunities by strengthening their connections \nto\
    \ major markets.\nIn Samoa, for example, ADB committed \n$62.3 million in grant\
    \ funds to upgrade Apia’s \nport, which is the country’s only international \n\
    maritime gateway. Given Samoa’s geographical \nisolation from international markets,\
    \ maritime \nconnectivity is critical to the economy. The \nrehabilitation of\
    \ port infrastructure, along \nwith the construction of a customs facility, will\
    \ \nenhance agricultural exports and streamline \nimports of basic commodities.\
    \ The project will \nhelp stimulate the economy, generate local \nemployment,\
    \ increase domestic as well as \ninternational trade, and improve food security.\n\
    Strengthening Governance  \nand Institutional Capacity\nImproving public service\
    \ delivery is a key priority \nfor ADB in the Pacific, alongside support for \n\
    government reforms to fiscal and monetary \npolicy, state‑owned enterprises, revenue\
    \ \nmobilization, and private sector development.\n31\nPACIFIC \nGreen and Smart\
    \ \nPorts: Regional \nWorkshop\nIn May, government \nand private sector \nrepresentatives\
    \ \nfrom the Pacific \nattended an ADB \nworkshop in \nSingapore focused \non\
    \ maritime trade \nand logistics and \nbest practices in \ngreen and smart \n\
    ports, particularly \nstrategies for low‑\ncarbon growth and \ngender equality.\
    \ \nA chore soon to be obsolete in Ebeye, the Marshall Islands. ADB support is\
    \ now connecting \nthousands of homes to a 24/7 supply of safe drinking water.\
    \ A $5 million grant from ADB in \n2015, and a $4 million grant from Australia,\
    \ financed the construction of a new desalination \nplant for the island.\nADB\
    \ is providing $74.5 million in assistance \nto Fiji, the Marshall Islands, Tonga,\
    \ and Tuvalu, \nalong with a $225,000 technical assistance grant \nto Niue, to\
    \ improve government management \nof public finances; build capacity to respond to\
    \ \nexternal shocks; and expand private investment by \nstreamlining the policy,\
    \ legislative, and regulatory \nenvironments for business. \nIn Tonga, where lack\
    \ of information to guide \nresource allocation has led to poor health services\
    \ \nand outcomes, ADB committed $7.5 million to \nhelp design and implement a\
    \ new digital health \ninformation system. The system will improve \nthe quality\
    \ and reliability of health statistics and \npromote digital patient records,\
    \ allowing for \nmore consistent patient care and better strategic \ndecision‑making.\n\
    Fostering Regional  \nCooperation and Integration\nTransport infrastructure plays\
    \ a key role in \nintegrating the many small island economies of \nthe Pacific.\
    \ In addition to the seaport project in \nSamoa, ADB provided a $5 million grant\
    \ to Tonga \nfor preparatory work to construct a bridge across \nthe Fanga’uta\
    \ Lagoon and upgrade the main wharf \nof Nuku’alofa Port.\nMany of ADB’s flagship\
    \ technical assistance \nprograms for the Pacific are regional in coverage \n\
    and foster cooperation and dialogue among \nDMCs. In 2019, ADB committed $2 million\
    \ \nin technical assistance grants to help Pacific \nmember countries improve\
    \ their business \nenvironments and generate inclusive economic \ngrowth led by\
    \ the private sector. The bank also \ncommitted $2 million in grants to the Pacific\
    \ \nRegion Infrastructure Facility Coordination \nOffice, which helps plan, prioritize,\
    \ coordinate, \nand manage infrastructure in the Pacific.\nKNOWLEDGE HIGHLIGHTS\n\
    In May 2019, ADB published a special 10th \nanniversary issue of the Pacific Economic\
    \ \nMonitor, one of the most influential economic \npublications in the region.\
    \ It features policy \nbriefs on the effects of climate change, impacts \nof natural\
    \ hazards, income and purchasing \npower, service delivery, women’s economic \n\
    empowerment, and labor markets.\nIn August, ADB’s Pacific Private Sector \nDevelopment\
    \ Initiative released Finding Balance \n2019: Benchmarking the Performance of\
    \ State-\nOwned Banks in the Pacific, a report that profiles \nthe roles, performance,\
    \ market context, and \nregulatory frameworks of 13 state‑owned banks \nin 10\
    \ Pacific countries. The report suggests \nthese banks can deliver much‑needed\
    \ business \nfinancing, particularly for small to medium‑sized \nenterprises and\
    \ in sectors such as agriculture and \nfisheries.\nADB’s Pacific Fellows Program\
    \ aims to enhance \nthe capacities of government officials to plan and \nmanage\
    \ development initiatives and projects. In \n2019, officials from PNG, Timor‑Leste,\
    \ and Tonga \nparticipated in the program. \n32\nADB ANNUAL REPORT 2019 \n2\n\
    BY THE \nNUMBERS\n$5.67 B\nCOMMITTED\n$3.85 B\nDISBURSED\n$1.30 B\nCOFINANCED\n\
    $42.8 M\nTECHNICAL \nASSISTANCE\nREGIONS: South Asia\nBangladesh, Bhutan, India,\
    \ Maldives, Nepal, Sri Lanka\nReflecting South Asia’s economic expansion in \n\
    recent years, countries within the region have \ncontinued to make solid development\
    \ progress. \nBangladesh moved to lower middle‑income status \nin 2015 (joining\
    \ regional counterparts Bhutan and \nIndia), while Sri Lanka achieved upper middle‑\n\
    income status in 2018 (joining the Maldives).\nIn 2019, domestic demand—particularly\
    \ private \nconsumption and infrastructure spending—\nboosted growth in Bhutan,\
    \ Bangladesh, and Nepal. \nHowever, in India, economic growth fell to 5% \nfrom\
    \ 6.1% in the previous year as a credit shortage \nlowered domestic demand. In\
    \ the Maldives, weak \ninfrastructure investment dragged on growth, while \nSri\
    \ Lanka’s growth also fell following a terrorist \nattack in April. \nSouth Asia\
    \ requires significant investment in both \neconomic and social infrastructure\
    \ to sustain its \neconomic growth, deal with the impacts of climate \nchange,\
    \ and promote gender equality and social \ninclusion. \nADB’s operations in South\
    \ Asia are focused on \ninfrastructure connectivity, including developing \nregional\
    \ transport corridors, linking farming \ncommunities to markets, and developing\
    \ advanced \nurban transport infrastructure such as metro and \nrailway connectivity.\n\
    In India, ADB committed a record $3.18 billion \nfor sovereign projects and $965\
    \ million for \nnonsovereign projects. \nSouth Asia’s advanced infrastructure\
    \ needs \nrequire an integrated multisector approach, \nas well as substantial\
    \ investment from the \nprivate sector. ADB has undertaken  economic \ncorridor\
    \ and other studies to determine \nwhere growth centers would be located and \n\
    ensure coordinated planning of investments \nfor sustainable growth. To help address\
    \ South \nAsia’s environmental challenges, ADB is also \nincorporating the latest\
    \ high‑efficiency, low‑\ncarbon technologies into its infrastructure projects.\n\
    ADB committed more than $2.2 billion in \ninvestments across sovereign and nonsovereign\
    \ \noperations to railway development in South Asia \nin 2019, marking a significant\
    \ strategic shift in the \nbank’s infrastructure portfolio.\nSocial services across\
    \ the region need to \naddress not only areas of market demand, \nbut also barriers\
    \ to gender equality and social \ninclusion. \nTo ensure optimum economic and\
    \ social \nimpact, development projects ranging \nfrom transport and trade to\
    \ education and \ntechnology must consider the impoverished \nand socially disadvantaged\
    \ members of South \nAsian societies.\nIn 2019, ADB endorsed new country \npartnership\
    \ strategies for Bhutan and Nepal. \nBhutan’s strategy covers 2019–2023 and focuses\
    \ \non fostering economic diversification and \nreducing spatial and social disparities.\
    \ Nepal’s \nstrategy covers 2020–2024 and aims to improve \ninfrastructure for\
    \ private sector‑led growth, \naccess to devolved services, and environmental\
    \ \nsustainability and resilience.\nSTRATEGIC FOCUS\nAddressing Remaining Poverty\
    \ \nand Reducing Inequalities\nNew ADB commitments in 2019 for inclusive \nskills\
    \ training and more reliable and competitive \npower will help tackle poverty\
    \ and inequalities \nin the region.\nIn Bangladesh, where many vulnerable \ncommunities\
    \ lack industry‑relevant skills, ADB \ncommitted $150 million for a training program\
    \ \nto boost the employment prospects and \nproductivity of the country’s young\
    \ workforce. \nIn Sri Lanka, where the government has \nprioritized applied science\
    \ and technology as \navenues to better‑paid jobs, ADB committed \n$145 million\
    \ for a project that is enabling \nfour universities to equip graduates with \n\
    technology‑oriented skills and entrepreneurial \nattitudes. It is estimated that\
    \ 7,250 students \n(35% of them women) will enroll in these new \nscience and\
    \ technology programs.\nTo spur jobs growth and improve livelihoods, \nIndia requires\
    \ a more reliable and competitive \npower supply for industry and services. ADB\
    \ \n33\nSOUTH ASIA\nMoving Forward Against Domestic Violence in Nepal\nsuccess,\
    \ plans to extend the project throughout \nthe country are already being made.\n\
    The project has so far been backed by a $950,000 \ngrant from the Japan Fund for\
    \ Poverty Reduction, \na $3.5 million grant from the Government of the \nUnited\
    \ Kingdom, $300,000 from ADB’s Gender \nand Development Cooperation Fund, and\
    \ \n$380,000 from the Government of Nepal.\nMaintenance activities of energy infrastructure\
    \ in Tonga. \nThe Cyclone Gita Recovery Project reconstructed and \n5%\nEDUCATION\n\
    56%\nTRANSPORT\n18%\nENERGY\n10%\nAGRICULTURE, \nNATURAL \nRESOURCES, \nAND RURAL\
    \ \nDEVELOPMENT\nSita Singh, left, runs a safe shelter for women in Nepal.\n8%\n\
    WATER AND \nOTHER URBAN \nINFRASTRUCTURE \nAND SERVICES   \nHarina is a 36‑year‑old\
    \ woman from Bajhang \nin western Nepal, who suffered domestic \nviolence for\
    \ more than 10 years. One day, \nHarina decided enough was enough. She \ncomplained\
    \ to Sita Singh, who runs a nearby \nsafe shelter for women.\nIn a country where\
    \ at least 60% of women \nwho face domestic abuse never report it, ADB \nhas worked\
    \ with civil society organizations to \nhelp police establish a gender‑based violence\
    \ \nnetwork in 20 districts. \nUnder the project, police are trained to \nhandle\
    \ complaints and make women feel \nmore comfortable reporting gender‑based \n\
    crime and domestic violence. The network \nalso runs community awareness campaigns,\
    \ \nencouraging the reporting of cases and \npromoting access to justice.\nIn\
    \ the districts in which the network operates, \nreporting of cases of gender‑based\
    \ violence \nhas increased by more than 46%, indicating a \ngrowing trust in the\
    \ justice system. Due to its \nhas committed $451 million for a power investment\
    \ \nproject along the Chennai–Kanyakumari Industrial \nCorridor, which will allow\
    \ more power—including \nfrom renewable sources—to be transferred from \nnew generation\
    \ facilities in the south to the north \nwhere it is most in demand. \nAccelerating\
    \ Progress  \nin Gender Equality\nADB is advancing gender equality across South\
    \ \nAsia by supporting inclusive infrastructure \ndevelopment, improving financial\
    \ literacy, and \nexpanding access to commercial capital. \nIn India, ADB has\
    \ invested in a project in \nChhattisgarh to enhance transport connectivity  \n\
    with bus stops that are accessible to women, \nchildren, the elderly, and people\
    \ with disabilities \n(many of whom are cared for by women). The \nproject also\
    \ includes bright streetlighting for better \nuser security.\nTo foster enterprises\
    \ led by women in Bangladesh, \nADB committed $50 million to support \nmicroenterprise\
    \ owners and aims for a loan \nportfolio with at least 70% women borrowers. ADB\
    \ \nalso committed a $50 million loan to a Sri Lankan \nstate‑owned bank to promote\
    \ financial inclusion \nand support micro, small, and medium‑sized \nenterprises—including\
    \ women‑led businesses—\nlocated outside Colombo District.\nTackling Climate Change,\
    \ Building \nClimate and Disaster Resilience, and \nEnhancing Environmental Sustainability\n\
    In South Asia, ADB’s approach to climate change, \ndisasters, and other environmental\
    \ issues focuses \non investments in economically viable and \nsustainable projects\
    \ that promote climate‑resilient \ninfrastructure and low‑carbon technology.\n\
    In Bangladesh, ADB committed $392.1 million \nto finance a new railway link connecting\
    \ \nthe Cox’s Bazar district to the national and \nregional rail network. By reducing\
    \ the need \nfor road travel, the project will decrease \ngreenhouse gas emissions\
    \ by 46,647 metric \ntons of carbon dioxide equivalent annually. \nIn Nepal, ADB\
    \ committed $63 million in additional \nfinancing to improve flood management\
    \ and \nriver health in the polluted Bagmati River Basin. \nThe funds will rebuild\
    \ and reinforce riverbanks, \nconstruct a wastewater treatment plant, \nIn 2019,\
    \ ADB’s \ncommitments \nin this region \nwere primarily \nin the following \n\
    sectors:\n34\nADB ANNUAL REPORT 2019 \nLike many small island economies, the Maldives\
    \ relies heavily \non imports for food, fuel, and other goods, while exports—\n\
    primarily of fresh fish and fish products—have been increasing. \nDespite these\
    \ higher volumes of goods moving in and out of \nthe country, the Maldives is\
    \ lacking in several areas of trade \nfacilitation.  \nThe flow of imports and\
    \ exports is hampered by bottlenecks \nthat cause delays and increase the cost\
    \ of doing business for \ntraders. These include a reliance on paper‑based processing,\
    \ \noverlapping and redundant document requirements, lengthy \ncargo procedures\
    \ caused by limited screening capability, and \nunderuse of technology.\nIn 2019,\
    \ ADB committed a financial package totaling $11 million \nto provide the Maldives\
    \ with an innovative solution to its \ntrading environment.\nThe Maldives will\
    \ establish a national single window to reduce \ndelays and lower costs associated\
    \ with the clearance of goods, \nwhile maintaining control over fees and duties\
    \ on imports and \nexports. The project will pilot‑test a blockchain application\
    \ as \npart of the project to see how the technology will improve the \nspeed\
    \ and efficiency of cross‑border procedures..\nBlockchain technology and an e-payment\
    \ gateway will improve the speed \nand efficiency of cross-border control procedures\
    \ in the Maldives.\nHIGH-TECH SYSTEMS FACILITATE \nTRADE IN MALDIVES\ntrain communities\
    \ along the river on flood \nearly warning systems, and restore heritage \nbuildings\
    \ damaged in the 2015 earthquakes.\nADB also collaborated with the Korea \nEnvironmental\
    \ Industry and Technology Institute \nto prepare a prefeasibility study on solid\
    \ waste \nmanagement in the state of Uttarakhand in India.\nMaking Cities  \n\
    More Livable\nADB is helping build livable cities across \nSouth Asia through\
    \ projects that alleviate \ncongestion and improve water supply \nand sanitation.\
    \ \nIn October 2019, ADB committed two loans \ntotaling $148 million to finance\
    \ infrastructure \nsuch as roads and drains that will relieve traffic \ncongestion\
    \ and prevent flooding in Dhaka and \nKhulna, densely populated and rapidly growing\
    \ \ncities in Bangladesh. As part of a $160 million rail \ninvestment in Sri Lanka,\
    \ ADB will help provide \nelectric locomotives and training in modern \nrailway\
    \ technologies to improve city services, cut \njourney times, and reduce air pollution.\n\
    As part of further knowledge collaboration \nwith the Republic of Korea, ADB and\
    \ the Korea \nWater Resources Corporation (K‑water) helped \nbuild long‑term capacity\
    \ for enhanced water \nmanagement in Bangladesh. They assisted the \nDhaka Water\
    \ Supply and Sewerage Authority to \nplan improved training facilities, a research\
    \ center, \nand an integrated water operations center. \nIn a different kind of\
    \ living environment, ADB \ncontinues to provide amenities for around \n632,000\
    \ displaced people in temporary camps \naround Cox’s Bazar. In 2019, the bank\
    \ helped \ninstall community bathing facilities, streetlights, \nand piped water\
    \ supply; and began work on food \ndistribution centers, cyclone shelters, and\
    \ storm \nwater drainage systems.\nPromoting Rural Development  \nand Food Security\n\
    ADB is working to connect rural communities, \nensure food safety, and strengthen\
    \ agricultural \ntrade standards to help guarantee sufficient \nand sustainable\
    \ food production in South Asia. \nImproving farmers’ access to markets will help\
    \ \nboost agricultural productivity and incomes, as \nwell as promote investment\
    \ in agribusiness and \nagriculture value chains.\nAcross Bangladesh, India, and\
    \ Sri Lanka, \nADB committed a combined $550 million to \nconnect people living\
    \ in farming communities \nto agricultural markets and regional centers \n35\n\
    SOUTH ASIA\nAccounting for Unpaid \nCare Work in Bhutan  \nADB published a first-\n\
    of-its-kind study on \nvaluation of unpaid care \nwork in Bhutan.  \nThe study\
    \ finds that  \nthe value of unpaid \nhousehold and care work \nranged from 10%\
    \ to 16% \nof the gross domestic \nproduct. It also finds  \nthat women spend\
    \ \nmore time on unpaid \nwork than men. The \nstudy will help shape \npolicy\
    \ to narrow the \ngender gap in unpaid \ncare work and increase \nwomen’s participation\
    \ \nin public life and \nthe formal sector.   \nStudent Bibi Marium learns a new\
    \ skill to boost her job prospects.  An ADB-supported program \nin Bangladesh\
    \ is helping train more than 320,000 people for jobs relevant to industry needs.\n\
    by upgrading rural roads. It also committed \n$91 million to improve water management\
    \ and \nagricultural productivity in Karnataka, India.\nADB committed a $50 million\
    \ policy‑based \nloan to the Government of Nepal to improve \nits food safety\
    \ measures, enhance agricultural \ntrade standards, and promote agricultural \n\
    commercialization. Through a separate \n$50 million project, the bank is also\
    \ helping \nNepalese farmers develop collective enterprises \nsuch as commercial\
    \ farming, milk collection \ncenters, mustard oil and rice mills, and seed \n\
    and tea processing factories, with value chain \ndevelopment and business facilitation\
    \ support.\nStrengthening Governance  \nand Institutional Capacity\nEffective\
    \ and inclusive development in South \nAsia hinges on strong institutional capacity,\
    \ good \ngovernance, and stable financial markets. ADB \nsupports public sector\
    \ reforms, helps improve \nservice delivery, and develops governance \ncapacity.\
    \ \nIn 2019, the bank committed a $30 million \npolicy‑based loan to develop Bhutan’s\
    \ financial \nmarkets. The reforms are expected to lead to \na 7% increase in\
    \ the volume of bonds traded in \nthe capital market through to 2023. Technical\
    \ \nassistance will help the government prepare \nregulatory frameworks and conduct\
    \ background \nanalyses, build the capacity of government \nagencies and financial\
    \ institutions to implement \nreforms, and improve the financial literacy of \n\
    disadvantaged people.\nAs part of major new commitments for road \nprojects in\
    \ India, ADB has introduced financial \nconcessions that will increase investments\
    \ \nand harness private sector expertise in project \ndesign, implementation,\
    \ and operation.\nFostering Regional  \nCooperation and Integration\nSouth Asia\
    \ needs to attract investment \nin cross‑border infrastructure to drive \nregional cooperation\
    \ and integration. \nSuch investment will help build economic \nconnectivity,\
    \ lower trade and energy costs, \nand improve access to social infrastructure\
    \ \nand services. \nIn 2019, ADB committed $495 million to reduce \ntravel times\
    \ along regional corridors connecting \nNepal with India and Bangladesh and improve\
    \ \nconnections to Sri Lanka’s international port \nunder the South Asia Subregional\
    \ Economic \nCooperation (SASEC) Program.\nKNOWLEDGE HIGHLIGHTS\nADB supported\
    \ the development of an action plan \nby India’s Ministry of Shipping to promote\
    \ coastal \nshipping. The plan details the initiatives required  \nto achieve\
    \ annual cost savings of $1.19 billion  \nwhile adding 150–160 million tons of\
    \ cargo yearly \nby 2025.\nThe bank also conducted a study on Asian \nexperience\
    \ in intergovernmental fiscal transfers, \nwhich was submitted to India’s 15th\
    \ Finance \nCommission to support the country’s public \nfinancial management.\n\
    ADB released the book Border without Barriers: \nFacilitating Trade in SASEC Countries,\
    \ which \nexamines priorities for trade facilitation in member \ncountries of\
    \ the SASEC Program. To buttress the \ncase for trade facilitation, the publication\
    \ discusses \nthe expected development impacts of increased \ntrade for SASEC\
    \ member countries.\n36\nADB ANNUAL REPORT 2019 \nBY THE \nNUMBERS\n$5.26 B\n\
    COMMITTED\n$1.63 B\nDISBURSED\n$2.88 B\nCOFINANCED\n$35.6 M\nTECHNICAL \nASSISTANCE\n\
    2\nREGIONS: Southeast Asia\nCambodia, Indonesia, the Lao People’s Democratic Republic,\
    \ Malaysia, Myanmar, \nthe Philippines, Thailand, Viet Nam\nSoutheast Asia has\
    \ averaged solid economic \ngrowth over the past 15 years, but uncertainties \n\
    in global trade, weaker investments, and extreme \nweather have dampened growth\
    \ performance \nin the past 3 years. Nevertheless, the number \nof people living\
    \ in extreme poverty on less \nthan $1.90 a day fell from 129 million in 2002\
    \ to \n33 million in 2015. \nYet countries across the region exhibit the \nhighest\
    \ levels of economic inequality in all of Asia \nand the Pacific, and infrastructure\
    \ investment of \n$184 billion a year is needed to support inclusive \nand sustainable\
    \ growth.\nSoutheast Asia’s populations are aging rapidly, \nparticularly in Thailand,\
    \ and Viet Nam, putting \npressure on national budgets to pay for pensions \n\
    and health‑care costs. Reforms are needed to \nensure a social safety net, adapt\
    \ to an older \nworkforce, and address rapid urbanization. \nThe region is also\
    \ experiencing greenhouse gas \nemissions and vulnerability to climate change.\
    \ \nFour countries in Southeast Asia are among the \n36 nations with the highest\
    \ disaster risk. There \nis an urgent need for climate‑responsive project \ndesigns,\
    \ integrated disaster risk management, and \ngreen infrastructure development.\n\
    ADB devotes more than half of its portfolio for \nSoutheast Asia to infrastructure\
    \ development \n(transport, energy, water and urban services, and \nagriculture\
    \ and natural resources). By doing so, \nit is providing significant support for\
    \ improved \neconomic productivity and resilience to climate \nchange in the region’s\
    \ developing member \ncountries (DMCs). \nThe bank is also supporting reforms\
    \ in public \nsector management and finance. This is \nhelping to strengthen government\
    \ institutions, \nparticularly in expanding the delivery of, and \naccess to,\
    \ public services. \nIn 2019, ADB approved a new country \npartnership strategy\
    \ for Cambodia, covering \n2019–2023. The strategy aims to accelerate \nthe country’s\
    \ competitiveness and economic \ndiversification, strengthen human capital and\
    \ \nlifelong learning, foster sustainable and inclusive \ndevelopment, and improve\
    \ governance.\nSTRATEGIC FOCUS\nAddressing Remaining Poverty \nand Reducing Inequalities\n\
    ADB is helping its DMCs in Southeast Asia \nreduce poverty, expand access to employment\
    \ \nand other economic opportunities, and deliver \nthe education and skills training\
    \ needed to help \nthe disadvantaged acquire better jobs. \nIn 2019, ADB provided\
    \ $748.6 million in \npolicy‑based loans to finance measures that \nwill improve\
    \ government spending on health, \neducation, skills development and training,\
    \ and \nsocial protection in Indonesia, the Lao People’s \nDemocratic Republic\
    \ (Lao PDR), the Philippines, \nand Viet Nam. The bank also supported reforms\
    \ \nin curriculum, assessment, teacher development, \ntechnical‑vocational‑livelihood\
    \ education, \ncareer guidance, public financial management, \nand school‑based\
    \ management in the Philippine \nsecondary education system through a \n$300 million\
    \ results‑based loan to boost the \nemployment prospects of about 20 million \n\
    students from the poorest 40% of households  \nin the country by 2023.\nIn Cambodia,\
    \ ADB supported a $40 million \npolicy‑based loan to increase access to finance\
    \ \nand introduce new financial services for poor \ncommunities, including in\
    \ rural areas, the \nagricultural sector, and small and medium‑sized \nbusinesses.\
    \ The program supports the adoption \nof a national financial inclusion strategy;\
    \ key \nlegislation, including the Trust Law, e‑Commerce \nLaw, and Consumer Protection\
    \ Law; and \nincorporation of financial literacy in the school \ncurriculum. In\
    \ Indonesia, the bank is supporting \na program to deliver a 40% increase in access\
    \ to \nfinancial services for the country’s poorest 40% \nby the end of 2020.\n\
    Accelerating Progress  \nin Gender Equality\nTo support gender equality across\
    \ Southeast \nAsia, ADB financed projects specifically designed \nto improve the\
    \ education and health of women \nand girls. \n37\nSOUTHEAST ASIA \nSince 2012,\
    \ ADB has engaged with the \nGovernment of Myanmar to help formulate \nand implement\
    \ education reforms, particularly \nin secondary education and technical and \n\
    vocational education and training. ADB’s \nfirst loan for Myanmar’s education\
    \ sector \naims to strengthen the country’s education \nand skills base and promote\
    \ inclusive growth \nand job creation. It supports reforms to \nrealign secondary\
    \ education and technical \nand vocational education and training to \nMyanmar’s\
    \ evolving workforce needs. These \nreforms are vital to equip youth with skills\
    \ \nfor employment in a modern economy \nand meet employer skill demands. \nThe\
    \ reform of the secondary education \ncurriculum, pedagogy, and student \nassessments\
    \ aims to transform the focus of \nteaching and learning from rote education \n\
    to flexible soft skills such as critical thinking, \nproblem solving, and communication,\
    \ better \nequipping young people to benefit from and \ncontribute to Myanmar’s\
    \ socioeconomic \nEducation for Employability in Myanmar\nLearning new skills\
    \ at a technical high school in Myanmar.\n34%\nTRANSPORT\n26%\nPUBLIC SECTOR \
    \ \nMANAGEMENT\n14%\nFINANCE\n9%\nEDUCATION\n8%\nAGRICULTURE, \nNATURAL \nRESOURCES,\
    \ \nAND RURAL \nDEVELOPMENT\ntransformation and more inclusive growth. \nRoughly\
    \ 900,000 grade 6 students are benefiting \nfrom improved teaching and better\
    \ textbooks, \nand nearly 157,000 teachers have received \ntraining on the new\
    \ curriculum. These phased \nreforms will culminate in the extension of \nsecondary\
    \ education through grade 12 by 2022.\nIn the Lao PDR, ADB committed a $50 million\
    \ \nloan to improve girls’ enrollment, retention, \nand completion rates in formal\
    \ education in \n12 disadvantaged and ethnically diverse districts. \nThe project\
    \ is upgrading 60 schools to provide \nadditional classrooms, laboratories, libraries,\
    \ and \nseparate dormitories and washing facilities for \ngirls and boys. The\
    \ bank is also helping meet the \ndietary needs of around 9,400 girls and women\
    \ \nof reproductive age through a $45 million \nwatershed management project that,\
    \ as part of \nits outputs, will establish 100 nutrition schools. \nIn Viet Nam,\
    \ ADB committed $100.6 million \nto develop communication and awareness \ncampaigns on\
    \ sexual and reproductive health, \nincluding maternal and child health.\nThrough\
    \ a regional initiative, Mekong Innovative \nStartups in Tourism, ADB is promoting\
    \ \nyouth‑ and women‑led entrepreneurship. \nThe initiative has so far provided\
    \ access \nto a startup ecosystem—including advice \nfrom investors, mentors,\
    \ incubators, and \ngovernment agencies—for 43 promising tourism \ntechnology\
    \ firms and social enterprises in \nCambodia, the Lao PDR, Myanmar, Thailand,\
    \ \nand Viet Nam.\nTackling Climate Change, Building \nClimate and Disaster Resilience,\
    \ and \nEnhancing Environmental Sustainability\nThroughout 2019, ADB scaled up\
    \ support to \naddress Southeast Asia’s unique challenges \nrelating to climate\
    \ change, disaster risks, \nand environmental degradation. \nIn Cambodia, ADB\
    \ committed $7.6 million \nfor a solar power project to reduce the cost of \n\
    electricity through private sector investments \nin renewable energy. These plants\
    \ are expected \nto avoid emissions of at least 148,650 metric \ntons of carbon\
    \ dioxide equivalent annually. \nTo address disaster risk in Viet Nam, ADB \n\
    committed $188.4 million, with cofinancing of \n$4.5 million from the Government\
    \ of Australia, \nfor a transport connectivity project that \nincorporates climate‑resilient\
    \ features into \nGreater Mekong Subregion (GMS) corridors \nin northwestern provinces.\
    \ These features \ninclude slope protection in areas prone to \nlandslides and\
    \ rockfalls and higher standards \nof road construction to address climate risks.\n\
    Meanwhile, regional technical assistance to the \nGMS is helping to implement\
    \ climate investment \nIn 2019, ADB’s \ncommitments \nin this region \nwere primarily\
    \ \nin the following \nsectors:\n38\nADB ANNUAL REPORT 2019 \nIn 2019, ADB approved\
    \ financing of up to $2.75 billion for the \nconstruction of 53.1 kilometers of\
    \ a 163‑kilometer passenger \nrailway connecting Malolos, a suburb north of the\
    \ country’s \ncapital of Manila, to the growing, new city of Clark in Central\
    \ \nLuzon. The project is cofinanced by the Japan International \nCooperation\
    \ Agency, which will provide $2.01 billion for rolling \nstock and railway systems.\
    \ \nBy 2025, when the railway is fully operational, it will also \nstretch to\
    \ Calamba in the south. It is expected to cut the \ntravel time from Manila to\
    \ Clark International Airport to less \nthan 1 hour by rail, compared with 2–3\
    \ hours by car or bus.\nThe impact on densely populated Manila will be immediate.\
    \ \nIt will help ease chronic road congestion, reduce air pollution, \ncut the\
    \ costs of transport and logistics, and encourage a \npopulation shift from the\
    \ capital to growth centers in the \nnorth. More than 342,000 passengers are expected\
    \ to travel \ndaily along the Manila–Clark corridor and up to 696,000 \npassengers\
    \ per day to and from Calamba. \nThe Malolos–Clark railway is ADB’s single largest\
    \ \ninfrastructure investment and a flagship project under the \nGovernment of\
    \ the Philippines’ Build, Build, Build program, \nwhich is accelerating much‑needed\
    \ infrastructure investment.\nThe Malolos–Clark railway will ease congestion in\
    \ densely populated Manila.\nLIVABLE CITIES  \nIN THE PHILIPPINES\nplans for the\
    \ agriculture, energy, and transport sectors; \nconduct pilots on low‑carbon agriculture\
    \ and green \nfreight; boost capabilities in environmental planning, \nenvironmental\
    \ data management, and pollution \ncontrol; and foster policy dialogue on reducing\
    \ the \nenvironmental footprints of agricultural practices.\nMaking Cities  \n\
    More Livable\nADB takes an integrated approach to making \nSoutheast Asia’s cities\
    \ more livable. It is forging \nlong‑term partnerships by implementing a structured\
    \ \nroadmap with each city and financing projects that \naddress issues such as\
    \ water security, access to \nsanitation, flood protection, and urban mobility.\
    \ \nADB has also begun due diligence for projects to \naddress basic urban services\
    \ in rapidly urbanizing \ncities. These projects will also help to mitigate damage\
    \ \nfrom pollution, waste, and development on the \nenvironment—especially in\
    \ coastal cities in Cambodia, \nthe Lao PDR, the Philippines, and Viet Nam, where\
    \ \nthe urban impact on marine and biodiversity health is \na major concern. The\
    \ projects will strengthen urban \ndevelopment policy and regulatory frameworks\
    \ and \nimprove institutional effectiveness in cities and public \nutilities.\n\
    Promoting Rural Development  \nand Food Security\nADB is supporting sustainable\
    \ and resilient rural \ndevelopment and food security for Southeast Asian \ncountries\
    \ by upgrading irrigation efficiency, water \nresources management, and flood\
    \ and drought risk \nmanagement to enhance agricultural productivity. \nThe bank\
    \ also invests in agriculture value chain \ninfrastructure and agribusiness development\
    \ as well as \nenhancing livelihoods in rural and remote communities. \nDuring\
    \ 2019, ADB invested $3 million in a regional \ntechnical assistance project to\
    \ implement \nclimate‑smart agriculture, pilot innovative \nfarming technologies,\
    \ and help mobilize financing \nfor agribusinesses in GMS countries.\nIn Myanmar,\
    \ the bank committed $195 million to \nreduce the food insecurity and poverty\
    \ of about \n1.8 million people in the regions of Ayeyarwady, Chin, \nSagaing,\
    \ and Tanintharyi. The project will develop \nand finance at least 15,000 livelihood\
    \ subprojects \nthat build community resilience. This includes village \naccess\
    \ or farm roads, small bridges, water supply, \nelectric grid connection, and\
    \ multipurpose centers.\nStrengthening Governance  \nand Institutional Capacity\n\
    For some DMCs in Southeast Asia, the challenges \nof fiscal management, revenue\
    \ generation, and \n39\nSOUTHEAST ASIA \nPolicies for High \nQuality, Safe, and\
    \ \nSustainable Food \nSupply in the Greater \nMekong Subregion \nThe book examines\
    \ \nmeans of improving \nfood safety and quality \nin the Greater Mekong \nSubregion,\
    \ enhancing \nthe production of \nenvironment‑friendly \nagriculture products,\
    \ \nand strengthening \nvalue chains. It \nproposes policy options \nto help the\
    \ region \nbecome more organic, \nclimate‑resilient, and \ngender‑responsive.\n\
    POLICIES FOR HIGH QUALITY,\nSAFE, AND SUSTAINABLE\nFOOD SUPPLY IN THE\nGREATER\
    \ MEKONG SUBREGION\nEdited by Thomas R. D. Weaver, Pavit Ramachandran,  \nand\
    \ Lourdes S. Adriano\nMAY 2019\nGREATER MEKONG\nSUBREGION\nCORE AGRICULTURE \n\
    SUPPORT PROGRAM\nCommitments totaling $1.1 billion in Indonesia will support fiscal\
    \ and public expenditure \nmanagement reform, promote finance sector development\
    \ and inclusion and encourage \nprivate infrastructure investment, together bolstering\
    \ efforts to reduce poverty and income \ninequality.  \nfinancial market stability\
    \ continue to impede \ntheir development. ADB designs and finances \nprograms\
    \ to help these countries build institutional \ncapabilities and distribute financial\
    \ resources more \nappropriately and effectively. \nADB committed $1.1 billion\
    \ in 2019 across three \ninvestments supporting regulatory reform in \nIndonesia.\
    \ The first is designed to underpin \nfinancial stability, deepen the financial\
    \ market, \nand enhance financial inclusion. The second will \nhelp align Indonesia’s\
    \ expenditure program to its \nnational development plan and the Sustainable \n\
    Development Goals and improve service delivery \nat the subnational government\
    \ level. The third will \nhelp mobilize private sector investments for much‑\n\
    needed infrastructure projects. \nIn the Lao PDR and the Philippines, ADB \ncommitted\
    \ policy‑based loans of $45 million \nand $300 million, respectively, to bolster\
    \ public \nfinancial management and fiscal consolidation; \ndevelop new public\
    \ debt management and tax \nlaws; improve the governance of planning and \nbudgeting;\
    \ and enhance resource management, \nrevenue collection, and service delivery\
    \ by local \ngovernments.\nIn December, ADB committed $23.3 million \nto strengthen\
    \ the capabilities of the recently \nestablished Philippine Competition Commission.\n\
    Fostering Regional  \nCooperation and Integration\nIn Southeast Asia, ADB concentrates\
    \ on initiatives \nto develop economic corridors, reduce trade and \ntravel barriers,\
    \ enhance energy access, develop \nsustainable tourism, support agribusiness value\
    \ \nchains, and create biodiversity corridors. During \n2019, ADB committed $233.4\
    \ million to support \ntransport connectivity and strengthen tourism \ninfrastructure\
    \ in Viet Nam. Policy‑based loans to \nIndonesia and Viet Nam will also enhance\
    \ finance \nsector integration.\nIn April, ADB and the Association of Southeast\
    \ \nAsian Nations (ASEAN) launched the ASEAN \nCatalytic Green Finance Facility\
    \ in Thailand. The \nfacility has created a truly global partnership for \ngreen\
    \ finance in the ASEAN region and attracted \nfinancing commitments of $1.3 billion,\
    \ receiving \nsupport from 11 development partners across Asia, \nEurope, and\
    \ the United States. \nADB also prepared a long‑term strategic framework \nfor\
    \ the GMS to guide the subregion’s integration \nand economic growth. As part\
    \ of the bank’s role \nas regional development advisor for the Brunei \nDarussalam–Indonesia–Malaysia–Philippines\
    \ East \nASEAN Growth Area, ADB supported the creation \nof a Green City Action\
    \ Plan for Kota Kinabalu \nin Malaysia, making it a pilot for other cities in\
    \ the \nsubregion.\nKNOWLEDGE HIGHLIGHTS\nIn 2019, ADB and Indonesia’s Ministry\
    \ of National \nDevelopment Planning conducted a joint study \non policies to\
    \ support the development of the \ncountry’s manufacturing sector. This study\
    \ \nwas used in the formulation of Indonesia’s new \nnational development plan.\n\
    The bank helped leverage regional knowledge and \nhosted a workshop in Indonesia\
    \ on e‑mobility \nand electric vehicles to explore opportunities for \nsovereign\
    \ and nonsovereign investments. \nIn the Philippines, ADB and the Organisation\
    \ \nfor Economic Co‑operation and Development \nconducted a joint review of local\
    \ job creation \nand employment skills strategies. The technical \nstudy served\
    \ as the intellectual underpinning of \nADB’s investment in school‑to‑work transition\
    \ \nprograms.\nIn Myanmar, ADB held a series of workshops \nand other training\
    \ activities to build project \nimplementation capacities, including those \n\
    related to disbursement, procurement, financial \nmanagement, and monitoring and\
    \ evaluation. It \nalso conducted workshops during September and \nNovember to\
    \ help strengthen environmental and \nsocial safeguards in the country. \n40\n\
    ADB ANNUAL REPORT 2019 \n3\nDeveloping the Private Sector\nPrivate Sector Operations\
    \ and the Promotion of Public–Private Partnerships\nBY THE \nNUMBERS\n$3.00 B\n\
    COMMITTED\n$2.26 B\nDISBURSED\n$6.98 B\nCOFINANCED\n$16.7 M\nTECHNICAL \nASSISTANCE\n\
    The private sector is the single‑largest \ncontributor to economic growth in developing\
    \ \neconomies. Private enterprises not only \ngenerate most quality jobs, they\
    \ also contribute \nto government tax revenues and introduce \ninnovations that\
    \ heighten efficiency and \nproductivity. Yet significant challenges in \nbusiness\
    \ environments and gaps in financial \nmarkets in Asia and the Pacific hamper\
    \ efforts to \nachieve more inclusive and sustainable growth. \nIn response, ADB\
    \ continues to devise innovative \napproaches and apply critical thinking to \n\
    maximize the potential of private enterprise to \ndeliver on development goals.\n\
    Through policy advice, technical assistance, \npolicy‑based lending, guarantees,\
    \ and project \nlending, ADB sovereign operations help \ndeveloping member countries\
    \ (DMCs) create \nenabling market conditions and develop \nthe institutional capacity\
    \ to attract private \nsector investment. Through its nonsovereign \noperations,\
    \ the bank helps raise environmental, \nsocial, and governance standards; provide\
    \ \nfinancing that may not be available or is \nrestrictive via commercial markets;\
    \ and improve \ndevelopment outcomes.  \nADB is expanding into new and frontier\
    \ markets; \nscaling up its nonsovereign operations beyond \ntraditional energy\
    \ infrastructure and finance; \nand moving into environmental infrastructure,\
    \ \ntransport, information and communication \ntechnology, agribusiness, education,\
    \ and health. \nThe bank is also enhancing its local currency \nofferings and\
    \ further developing its equity \ninvestments platform, while mobilizing more\
    \ \ncofinancing through its credit enhancement, \nsyndications, and asset management\
    \ activities. \nADB has set a target to expand private \nsector operations to\
    \ reach one‑third of total \noperations in number by 2024. Solid progress \nwas\
    \ made on this undertaking in 2019, when \nthe bank committed private sector investments\
    \ \nfor 38 projects, covering 16 different DMCs \nas well as 7 regional projects.\
    \ Projects \ncommitted in 2019 totaled $3 billion. ADB \nalso generated a record\
    \ $6.98 billion in private \nsector cofinancing, almost half of which was \nlong‑term\
    \ cofinancing, and mobilized $125 \nmillion from transaction advisory services.\
    \ \nSTRATEGIC FOCUS\nAddressing Remaining Poverty \nand Reducing Inequalities\n\
    In 2019, ADB continued to assist in broadening \naccess to financial services\
    \ to support health care, \neducation, and business development. The bank \nfocused\
    \ 21% of its private sector investments on \ninclusive business initiatives that\
    \ will improve the \nlives of poor and disadvantaged people. \nIn the People’s\
    \ Republic of China (PRC), ADB \ncommitted $150 million to support an innovative\
    \ \nagreement with leasing company Far East Horizon \nLimited to improve 50 public\
    \ hospitals across the \n12 provinces where per capita income is lowest. \nThe\
    \ project will finance the lease or purchase of \nmodern medical equipment and\
    \ the construction, \nexpansion, or refurbishment of hospital buildings \nand\
    \ associated medical facilities. This scalable \nfinancing approach is a means\
    \ of rapidly delivering \nimprovements in hospital and medical care for \npeople\
    \ in communities where average health‑care \nexpenditure is only 40% of the level\
    \ in urban areas.\nIn the Philippines, ADB invested a combined \n$12.5 million\
    \ from its own funds and the Leading \nAsia’s Private Sector Infrastructure Fund\
    \ (LEAP) \nto support PHINMA Education Holdings’ plan to \nexpand capacity and\
    \ acquire new tertiary education \ninstitutions. The project focuses on students\
    \ from \nlow‑income households and aims to improve their \naccess to quality tertiary\
    \ education and increase \ntheir employability. The investment is projected \n\
    to help PHINMA Education expand student \nenrollments from 68,819 to 114,000 during\
    \ its first \n5 years of operation.\nIn India, where there is an ongoing need\
    \ to expand \nfinancing for micro, small, and medium‑sized \nenterprises (MSMEs),\
    \ ADB provided $150 million to \nFullerton India Credit Company Limited. Financing\
    \ \nwill be extended to borrowers in lagging areas and \nwomen‑led MSMEs. The\
    \ project aims to reach \nat least 2.9 million MSME borrowers, including \n2.7 million\
    \ women and 950,000 MSME borrowers \nfrom underserved states.\nIn many remote\
    \ and less‑developed areas of Asia \nand the Pacific, access to broadband internet\
    \ \nconnections can stimulate economic growth and \ngenerate employment to reduce\
    \ poverty and \n41\nDEVELOPING THE PRIVATE SECTOR \nIn 2015, ADB provided a loan\
    \ of up to \n$200 million to Axis Bank Limited to \nstrengthen financial inclusion\
    \ and improve \naccess to markets for farmers in India.\nThe project was ADB’s\
    \ first nonsovereign \ninitiative to target Indian smallholder \nfarmers and low‑income\
    \ women through \nprivate banks. With Axis Bank on‑loaning \nthe ADB funds to\
    \ rural borrowers, the \nproject expanded access to capital for micro, \nsmall,\
    \ and medium‑sized enterprises and \nbroadened (particularly non‑collateralized)\
    \ \nlending outside the country’s main urban \ncenters.\nLoans to farmers have\
    \ already exceeded the \nproject’s 2021 target of ₹150 billion (around \n$2 billion),\
    \ with nonperforming loans at \njust half of the 7% ceiling. Likewise, the \n\
    number of borrowing farmers stands at \nmore than 166,000 or 98% of the 2021 \n\
    target. The project has so far reached over \n1 million women, five times the\
    \ 2021 target \nof 200,000.\nFinancial Inclusion Measured on a New Axis\nThe success\
    \ of the project has helped enhance \nfinancial inclusion for agricultural enterprises\
    \ and \nrural communities, establish scalable financing \nmodels for sustainable\
    \ outreach to smallholder \nfarmers and women, expand banking services \nin remote\
    \ areas, improve financial literacy for \nwomen, and create screening systems\
    \ to exclude \nprojects with potentially adverse environmental \nand social impacts.\n\
    Malathi Raghu now has the financing to run her own business.\ninequality. In December,\
    \ ADB provided $50 million \nin funding to launch the Kacific1 satellite to deliver\
    \ \nhigh‑speed broadband internet to isolated areas \nacross the region. The satellite\
    \ will deliver internet \nthat will enable better education and health services,\
    \ \nimprove access to information, and drive more trade \nand connectivity between\
    \ countries.\nAccelerating Progress  \nin Gender Equality\nDuring 2019, ADB promoted\
    \ the economic \nempowerment of women through its private sector \noperations\
    \ by expanding their access to housing, \nfinance, and entrepreneurial opportunities.\n\
    ADB committed a $30 million loan to ASA \nPhilippines Foundation, a nongovernment\
    \ \norganization that provides microfinance solely \nto low‑income women borrowers,\
    \ allowing them \nto meet their livelihood and business needs. The \nproject will\
    \ support at least 2 million women‑owned \nmicroenterprises by 2024, especially\
    \ those in \nconflict‑affected and lagging areas.\nIn Georgia, where many small\
    \ businesses are \noperated by women and basic finance can be  \nscarce, ADB is\
    \ working to expand access to \naffordable loans. It committed a $22.3 million\
    \ \nloan and a $500,000 technical assistance grant \nfor Credo Bank to launch\
    \ new products, including \nhome improvement and mortgage loans, to reach \nlower‑income\
    \ households in rural areas and on the \nperiphery of the country’s capital of\
    \ Tbilisi. The \ninvestment will allow Credo to expand its services to \ncustomers,\
    \ most of whom are women, with a target \nof financing at least 26,000 additional\
    \ low‑income \nborrowers (half of them women) by 2023. \nIn Pakistan, ADB provided\
    \ a $25 million loan to \nassist the not‑for‑profit Kashf Foundation, one of \n\
    the country’s leading microfinance providers, in \nlending to low‑income households\
    \ and women‑led \nMSMEs. The investment will help women to access \nmarket opportunities\
    \ and maximize their commercial \npotential.  \nTackling Climate Change, Building\
    \ Climate \nand Disaster Resilience, and Enhancing \nEnvironmental Sustainability\n\
    Active private sector projects supported by ADB \nhelped reduce greenhouse gas\
    \ (GHG) emissions  \nby a combined 18.3 million metric tons of carbon \ndioxide\
    \ equivalent (CO2e) in 2019. \nIn India, ADB committed $746.2 million equivalent\
    \ \nin Indian rupees in long‑term financing—the largest \n42\nADB ANNUAL REPORT\
    \ 2019 \nSupport from ADB’s Leading Asia’s Private Sector Infrastructure Fund\
    \ is helping to build the first large-scale floating \nsolar photovoltaic farm\
    \ in Viet Nam and the largest installation in Southeast Asia.\n36%\nTRANSPORT\n\
    23%\nENERGY\n19%\nFINANCE\n17%\nINFORMATION AND \nCOMMUNICATION \nTECHNOLOGY\n\
    single nonsovereign loan ever committed by ADB—\nto Indian Railway Finance Corporation\
    \ to fund a \nrailways track electrification project. This is part of a \nbroad\
    \ modernization program that will help India’s \nrailway sector transition to\
    \ electric power and away \nfrom dependence on fossil fuels. \nIn Viet Nam, there\
    \ is a need to boost the share  \nof renewable energy in the country’s power mix\
    \  \nand decrease dependence on coal for power \ngeneration. ADB is therefore\
    \ supporting the first \nlarge‑scale installation of floating solar panels in\
    \ \nViet Nam, which will be the largest installation in \nSoutheast Asia. The\
    \ bank committed a $37 million \nloan to Da Nhim–Ham Thuan–Da Mi Hydro Power \n\
    Joint Stock Company for the installation of a \n47.5‑megawatt (MW) facility on\
    \ the reservoir of the \ncompany’s existing Da Mi hydropower plant. The \npackage\
    \ includes a $17.6 million loan from ADB’s \nown funds, supplemented by $15 million\
    \ from the \nCanadian Climate Fund for the Private Sector in \nAsia I and II,\
    \ and $4.4 million from the LEAP fund, \nboth to be administered by ADB. The project\
    \ aims \nto generate 63,000 megawatt‑hours of electricity \nand reduce GHG emissions\
    \ by at least 30,000 \nmetric tons of CO2e annually by 2023. \nIn Nepal, ADB committed\
    \ a $60 million loan to \nNepal Water and Energy Development Company \nPrivate\
    \ Limited to help build and operate a 216‑MW \nrun‑of‑river hydropower plant on\
    \ the Trishuli River. \nOne of the largest private sector investments in \nNepal\
    \ to date, the plant is expected to provide over \n1,200 gigawatt‑hours (GWh)\
    \ of clean electricity \nto the grid and reduce GHG emissions by 446,000 \nmetric\
    \ tons of CO2e annually. It will enhance Nepal’s \nenergy security and reduce\
    \ imports of electricity. \nIn Solomon Islands, the government has prioritized\
    \ \nreplacing diesel‑fired power generation to reduce \nGHG emissions and drive\
    \ down the electricity \ntariff by as much as 35% with least‑cost energy \ngeneration.\
    \ ADB provided public–private \npartnership (PPP) advisory services to the \n\
    Ministry of Finance and Treasury for its first PPP, a \nhydropower project developed\
    \ on the Tina River. \nThe project is unique in that six concessional \ncofinanciers’\
    \ loans, amounting to $201 million \nand with varying terms and conditions, are\
    \ on‑\nlent to a private entity to construct, operate, and \nmaintain the hydropower\
    \ plant. ADB helped the \nministry set up the fund administration procedure \n\
    by preparing operations manuals and engaging \nan administrative agent. It also\
    \ conformed all \nbilateral loan terms and conditions to reflect the \non‑lending\
    \ agreement, coordinated discussions \namong cofinanciers, and assisted negotiation\
    \ of \nbilateral loans. The advisory services provided \nhelped build the capacity\
    \ of the ministry to \nhandle potential PPP projects in the future.  \nMaking\
    \ Cities  \nMore Livable \nIn 2019, ADB facilitated private sector solutions to\
    \ \nhelp make city life more sustainable. These included \nIn 2019, ADB's \ncommitments\
    \ in \nthe private sector \nwere primarily \nin the following \nsectors:\n43\n\
    DEVELOPING THE PRIVATE SECTOR \nprojects in waste‑to‑energy, wastewater, and \n\
    transport.  \nThrough a $100 million loan, ADB is helping \nShanghai SUS Environment\
    \ Company Limited \ndeliver integrated urban waste management in \nthe PRC. The\
    \ loan will finance innovative waste‑\nto‑energy facilities in low carbon eco‑industrial\
    \ \nparks. The facilities will treat 1.8 million tons of \nmunicipal solid waste,\
    \ generate 437.5 GWh of \nclean energy, and reduce GHG emissions by \nabout 1.2\
    \ million metric tons of CO2e annually. \nADB also committed a $60.7 million loan\
    \ to \nMaxwealth Financial Leasing Company Limited \nto advance industrial and\
    \ municipal wastewater \ntreatment in the PRC. The investment will \nfinance at\
    \ least six wastewater treatment \nplants, helping to increase treatment capacity,\
    \ \nimprove the urban environment, and enhance \nquality of life for around 2.2\
    \ million residents.\nIn Thailand, ADB committed a $310.9 million loan \nfor the\
    \ construction of two new rail lines as part \nof Bangkok’s mass rapid transit\
    \ system. The new \nlines, to be operated by the Northern Bangkok \nMonorail Company\
    \ Limited and the Eastern \nBangkok Monorail Company Limited, will reduce \ntraffic\
    \ congestion and air pollution from vehicles. \nThe construction phase will generate\
    \ 2,000 jobs, \nwith the new lines projected to serve a combined \n592,000 passengers\
    \ every day when operations \nbegin in 2030. \nIn the Philippines, ADB provided\
    \ transaction \nadvisory services to the Bases Conversion and \nDevelopment Authority\
    \ for the procurement \nof electric power distribution infrastructure \nfor New\
    \ Clark City, the country’s first \ntechnologically smart, environmentally \n\
    sustainable metropolis. The city’s power project \nwill introduce the Philippines’\
    \ first wide‑scale, \nfully underground smart grid, delivering power \ngeneration\
    \ efficiencies and affordability for \ncustomers. \nPromoting Rural Development\
    \  \nand Food Security\nADB’s private sector agribusiness operations in \n2019\
    \ supported climate‑smart agriculture and \nenvironmentally responsible rural\
    \ development. \nIn Kazakhstan, ADB provided a $20 million \nloan to RG Brands,\
    \ a leading food and beverage \ncompany, to modernize its regional distribution\
    \ \nchains. The loan will finance the purchase \nof 18,750 energy‑efficient coolers\
    \ for small \nconvenience stores in Kazakhstan and the \nKyrgyz Republic, at least\
    \ half of which are owned \nby women. The coolers will help reduce GHG \nemissions\
    \ by 4,200 metric tons of CO2e and \nimprove the livelihoods of shopkeepers.\n\
    In Mongolia, the government has set development \ngoals to enhance agricultural\
    \ productivity, expand \nlocal value chains, diversify exports, and create jobs.\
    \ \nADB is providing a $7.4 million loan to help Milko \nLLC expand its raw milk\
    \ and fruit procurement \nand dairy processing capacity. The increased \nprocurement\
    \ will benefit around 1,000 smallholder \nfarmers and herders (the majority of\
    \ them women).\nIn Indonesia, ADB provided a $5 million loan to \nPT SASL and\
    \ Sons Indonesia to help develop the \ncoconut industry in Central Sulawesi. The\
    \ project will \nfinance a modern processing plant to manufacture \nhigh‑value\
    \ coconut products for export, benefiting \nabout 9,500 smallholder farmers and\
    \ creating jobs \nfor more than 1,200 people, mostly women.\nStrengthening Governance\
    \  \nand Institutional Capacity \nThrough lending and technical assistance \n\
    operations in 2019, ADB helped strengthen \nthe institutional capacity of DMCs\
    \ to improve \ntheir business environments for private sector \ndevelopment, attract\
    \ investment, and foster PPPs.\nIn Solomon Islands and Bhutan, ADB helped expand\
    \ \nknowledge of PPPs and develop project pipelines. \nThe bank also helped the\
    \ government establish a \nPPP Center of Excellence in Solomon Islands and \n\
    implemented a pilot project in Bhutan. \nIn Thailand, where long‑term development\
    \ plans \nrequire the expansion of water transport services \nand investments\
    \ in water infrastructure, an ADB \ntraining program helped the Marine Department\
    \ \nimprove its capacity to prepare and structure \nPPP projects for the development,\
    \ operation, \nand management of seaport infrastructure \nwith private sector\
    \ participation. The program \neducated departmental staff on PPP concepts \n\
    and models, the potential of PPPs to achieve \nnational targets in the port sector,\
    \ and the roles and \nresponsibilities of stakeholders in PPP projects. \nFostering\
    \ Regional Cooperation  \nand Integration \nIn 2019, ADB committed $50 million\
    \ to support \nregional cooperation and promote financial  \nresilience by enabling\
    \ corporations and \ninfrastructure projects to access local currency \nand regional\
    \ bond markets. The investment is \nan additional capital contribution to support\
    \ \ncontinuous guarantee operations of the bank’s Credit \nGuarantee and Investment\
    \ Facility (CGIF). ADB \ncreated the facility as a trust fund to help develop\
    \ \nlocal currency and regional bond markets in the \nAssociation of Southeast\
    \ Asian Nations (ASEAN) \n+3 region. The ASEAN+3 region is composed of \nBrunei\
    \ Darussalam, Cambodia, Indonesia, Japan, \n44\nADB ANNUAL REPORT 2019 \nADB’s\
    \ private sector operations seek to attract widescale \nfinancial support from\
    \ development partners and commercial \ninstitutions to help developing Asian\
    \ countries meet their \nenergy security needs and facilitate a transition to\
    \ a low‑carbon \neconomy.\nIn 2019, ADB was the anchor lender in financing a \n\
    2,500‑megawatt combined‑cycle gas turbine power plant  \nin the Rojana Rayong\
    \ 2 Industrial Park, located in the Rayong \nprovince of Thailand, about 150 kilometers\
    \ southeast of \nBangkok.\nA commitment of just $50 million from ADB’s own resources\
    \ \ncatalyzed over $1.1 billion of cofinancing from 12 international \nand domestic\
    \ commercial banks ($849 million), and the Japan \nBank for International Cooperation,\
    \ and Leading Asia’s Private \nSector Infrastructure Fund ($253 million combined).\n\
    The power plant will be fully operational by 2024, delivering \nat least 16,000\
    \ gigawatt‑hours of electricity to users. With the \nstate‑of‑the‑art combined‑cycle\
    \ gas turbine technology in use, \nthe project will help cut greenhouse gas emissions\
    \ by 1 million \nmetric tons of carbon dioxide equivalent annually   compared\
    \ \nwith current electricity grid emissions.\nThe plant will be integral to sustaining\
    \ Thailand’s energy security, \ngiven that more than 8,500 megawatts of generating\
    \ capacity—\nabout 20% of the current national energy requirements—in \naging,\
    \ carbon‑intensive power plants will be retired by 2025.\nEvening in Bangkok.\
    \ ADB support for a new power plant in Thailand will \nprovide reliable power\
    \ to industry and households.\nMOBILIZING COMMERCIAL FINANCE \nFOR ENERGY SECURITY\n\
    the Lao People’s Democratic Republic, Malaysia, \nMyanmar, the People's Republic\
    \ of China, the \nPhilippines, the Republic of Korea, Thailand, and \nViet Nam.\
    \ As of 31 December, CGIF has been able \nto issue 35 guarantees, with an outstanding\
    \ balance \nof $1.91 billion. Since its inception, none of the \nCGIF‑guarantee\
    \ bonds have defaulted and no CGIF \nguarantee has been called upon. \nADB’s Trade\
    \ Finance Program (TFP) facilitated  \n4,832 transactions in support of cross‑border\
    \ \ntrade finance during 2019. By providing banks with \nguarantees and loans,\
    \ the TFP helps close market \ngaps for trade finance, estimated in 2019 to be\
    \ \n$1.5 trillion globally. The 2019 transactions were \nvalued at $5.4 billion,\
    \ with $3.5 billion cofinanced \nby banks, private insurers, and official agencies.\
    \ \nOf the TFP’s 2019 transactions, 4,069 supported \nsmall and medium‑sized enterprises\
    \ (SMEs) and \n1,361 supported trade between DMCs. Among the \n21 countries covered\
    \ by the TFP, the most active in \n2019 were Armenia, Bangladesh, Mongolia, Pakistan,\
    \ \nSri Lanka, and Viet Nam. \nIn 2019, ADB’s Supply Chain Finance Program \n\
    supported 577 transactions valued at $119 million, \nwith $59.3 million cofinanced\
    \ by partner financial \ninstitutions. This program works with corporates and\
    \ \npartner financial institutions to enhance access of \nSME suppliers to working\
    \ capital. It complements the \nTFP by assuming corporate risk and developing\
    \ both \ndomestic and cross‑border trade. For 2019, 78% of \nthe transactions\
    \ supported SMEs. \nOTHER APPROACHES TO DEVELOPING \nTHE PRIVATE SECTOR \nWidening\
    \ Geographic Coverage\nIn many economies across Asia and the Pacific, \ndevelopment\
    \ needs go unfinanced and unmet \nbecause of real or perceived risks of investment.\
    \  \nADB works to encourage private sector investment  \nin these economies.\n\
    In 2019, the bank significantly expanded its private \nsector operations in new\
    \ and frontier markets, \nincluding fragile and conflict‑affected contexts and\
    \ \nsmall island developing states. \nIn April, ADB approved $100 million for\
    \ a renewable \nenergy program in the Pacific, which aims to drive \nself‑sustaining\
    \ private sector development, reduce \ncontinued reliance of power utilities on\
    \ grants and \nsubsidies, and increase renewable energy supply. \nThe program\
    \ uses an innovative blend of financing \nsupport and credit enhancement to overcome\
    \ \nbarriers to private investment. It is an umbrella \nfacility that uses donor\
    \ funds to backstop payment \nobligations of power utilities. This is combined\
    \ with \na partial risk guarantee to address long‑term liquidity \n45\nDEVELOPING\
    \ THE PRIVATE SECTOR \nBoosting Gender \nEquality Through \nADB Trade Finance\
    \ \nPartnerships \nThe Trade Finance \nProgram’s Gender \nInitiative assessed\
    \ \nhuman resources \npolicies to identify \nenhancements to \nattract, retain,\
    \ and \npromote women \nin banking. Twelve \nbanks implemented \n25 recommendations\
    \ \nfrom the report \nBoosting Gender \nEquality Through \nADB Trade Finance \n\
    Partnerships. \nA second phase \nis now covering \nadditional Trade \nFinance\
    \ Program \npartner banks. \nrisk and breach of contract. ADB is also sourcing\
    \ \nand using available grant funds from development \npartners as a credit enhancement\
    \ tool that will \nmobilize private financing in Pacific DMCs. \nIn Afghanistan,\
    \ ADB is promoting renewable \nenergy development and helping 77 Construction,\
    \ \nContracting, and Trading Group become \nthe country’s first private sector‑financed\
    \ \nindependent power producer. The bank provided \na $4 million loan to help\
    \ build a 15.1 MW solar \npower plant that will generate about 27.5 GWh of \n\
    electricity and avoid 8,500 metric tons of CO2e \nGHG emissions annually. As part\
    \ of the project, \nADB will also administer a $3.9 million loan from \nthe Canadian\
    \ Climate Fund for the Private Sector \nin Asia II.\nStrengthening the Finance\
    \ Sector  \nand Capital Markets\nAlthough domestic capital markets in Asia have\
    \ \ndeveloped significantly over the last 20 years, \nmany less developed countries\
    \ still struggle to \nfoster adequate financial market infrastructure \nand remain\
    \ largely dependent on bank lending. \nSpecialized financial products such as\
    \ project \nbonds and climate bonds remain generally \nunderdeveloped.\nTo help\
    \ overcome these issues, ADB now offers \nfinancing in the local currencies of\
    \ 22 DMCs, \nwith disbursed local currencies in nonsovereign \noperations almost\
    \ doubling from $1.03 billion in \n2015 to $1.99 billion in 2019, and the percentage\
    \ \nof local currency operations within the overall \ndisbursed nonsovereign operations\
    \ portfolio \nincreasing from 22% to nearly 29% over the same \nperiod. Local\
    \ currency loans and investments in \n2019 were denominated (in descending order\
    \ of \nmagnitude) in Indian rupee, Thai baht, Chinese \nrenminbi, Kazakhstan tenge,\
    \ Georgian lari, \nPhilippine peso and Malaysian ringgit.   \nIn 2019, ADB also\
    \ invested in two landmark \ngreen bond issuances—the AC Energy Green \nBond Project\
    \ ($20 million committed in January) \nand the Energy Absolute Green Bond for\
    \ Wind \nPower Project ($98.2 million, or B3 billion, \ncommitted in September).\
    \ Both were the first‑\never green bonds for the issuers. \nThrough ADB’s encouragement,\
    \ AC Energy \nobtained the Climate Bond Standard Certified \nstatus, making the\
    \ offering the first certified, \npublicly listed climate bond in Southeast Asia\
    \ \n(listed on the Singapore Stock Exchange). This \nregional project will support\
    \ private sector \nfinancing of green energy options across Southeast \nAsia.\
    \ It contributes to the ASEAN’s objective \nof sourcing 23% of its member nations’\
    \ primary \nenergy from renewable sources by 2025.\nThe proceeds from Energy Absolute’s\
    \ bond \nissuance will be used to support long‑term \nfinancing of the company’s\
    \ 260 MW Hanuman \nwind farm located in Chaiyaphum Province in \nThailand. The\
    \ project is expected to generate \n450 GWh of electricity annually and reduce\
    \ \nGHG emissions by 200,000 metric tons of CO2e \nevery year. \nIn Georgia, ADB\
    \ invested $6.8 million into  \nJSC Evex Hospitals’ corporate bond issuance. \n\
    The proceeds of the issuance will be used \nto refinance some of Evex Hospitals’\
    \ debt \nand support the company to achieve better \noperational efficiency, quality\
    \ of services, and \ngovernance. It will also support Georgia’s capital \nmarket\
    \ development, particularly the deepening \nof its corporate debt securities and\
    \ overall local \ncurrency bond market.\nUsing Private Equity Funds  \nto Extend\
    \ Reach\nPrivate equity fund investments enable ADB to \nleverage the local knowledge\
    \ of fund managers \nin unfamiliar markets and sectors. They also \ndiversify\
    \ risk across companies, industries, and \nregions to extend development impact\
    \ and \nprovide more reliable returns. ADB can partner \nwith private equity firms\
    \ to fulfill joint investment \nopportunities and complement the bank’s direct\
    \ \nequity investments.\nADB’s current private equity mandate was \nreinforced\
    \ by the findings of an independent \nevaluation report published in 2019. The\
    \ report \nsuggested refining the bank’s private equity funds \nstrategy to ensure\
    \ financial sustainability while \nprioritizing value addition and development\
    \ \nimpact. While ADB targets primarily growth \nequity funds in the region, it\
    \ also selectively \nsupports inclusive business and early‑stage funds. \nSince\
    \ its first private equity fund investment \nin 1984, ADB has invested over $1.8\
    \ billion and \nmobilized $12 billion of third‑party capital into \nmore than\
    \ 80 private equity funds across DMCs. \nIn 2019, ADB made a $5 million equity\
    \ investment \nin Kaizen Private Equity II Private Limited, a \n$79 million education‑focused\
    \ private equity \nfund. Kaizen will invest in up to eight education \nbusinesses\
    \ in South Asia and Southeast Asia to \nimprove the access, quality, and affordability\
    \ of \neducation in the lower middle‑market segments \nin those regions. In particular,\
    \ Kaizen will make \ninvestments in K–12 education, preschools, \nonline education,\
    \ vocational training, and test \npreparation. ADB’s involvement is expected to\
    \ \nhelp garner the trust of institutional financiers \nand enhance funding availability\
    \ for the private \neducation sector. \n46\nADB ANNUAL REPORT 2019 \nNaseema Kosar,\
    \ hard at work in her apricot drying plant. A $25 million syndicated ADB loan\
    \ is helping women-led micro, \nsmall, and medium-sized enterprises in Pakistan\
    \ access finance.\nADB also made a $40 million equity investment \nin Everbridge\
    \ Partners Fund I, a targeted private \nequity fund to provide growth capital\
    \ to middle‑\nmarket companies in the health‑care, business \nservices, and consumer\
    \ sectors in India, the PRC, \nand countries of Southeast Asia. The project will\
    \ \nhelp deepen capital markets and support Asia’s \ngrowing private sector.\n\
    In India, ADB made a $10 million equity investment \nin Tata Capital Growth Fund\
    \ II. Tata Capital will use \nthe proceeds to invest equity capital for minority\
    \ \nstakes in a portfolio of 10 to 12 lower middle‑\nmarket companies, including\
    \ SMEs. Focus sectors \nfor the fund include financial services, health \ncare,\
    \ manufacturing, and information technology. \nThrough the investment, ADB aims\
    \ to contribute \nto India’s economic development by providing \ncritical growth\
    \ capital to well‑managed companies, \nwhich will generate jobs in sectors servicing\
    \ the \ncountry’s increasing domestic consumption and \nurbanization.\nIn the\
    \ PRC, ADB made a $30 million equity \ninvestment in CDH VGC Fund, L.P. The fund\
    \ \nwill provide growth capital to about 20 private \ncompanies focusing on health\
    \ care, their supply \nchains and/or their customers, and technology. \nThis will\
    \ help promote private sector development, \nencourage entrepreneurship, and support\
    \ the \ntransition of the PRC’s economy from one focused \non manufacturing to\
    \ one driven increasingly by \ntechnology and innovation.\nSCALING UP SUPPORT\
    \ FOR  \nPUBLIC–PRIVATE PARTNERSHIPS \nADB encourages project financing in cooperation\
    \ \nwith the private sector in all its core operations. PPPs \ncan play an important\
    \ role in addressing the huge \nshortfall in infrastructure investment across\
    \ Asia \nand the Pacific. By investing in new technologies, \nbringing innovative\
    \ solutions, and encouraging more \ntransparent organizational structures, the\
    \ private \nsector has the potential to improve operational \nefficiency as well\
    \ as asset and service quality. \nADB provides transaction advisory services \n\
    and assists public and private sector clients  \nin structuring and procuring\
    \ viable projects, \nparticularly PPPs.\nDuring 2019, the bank secured 13 new\
    \ transaction \nadvisory mandates in Pakistan, Palau, the Philippines, \nthe PRC,\
    \ and Uzbekistan. These mandates include \nthe development of information and\
    \ communication \ntechnology facilities, transport infrastructure, \na health‑care\
    \ facility, solar power plants, the \nrehabilitation of public schools, and the\
    \ long‑term \noperations and management of district heating \nfacilities and water\
    \ supply and sanitation services. \nThe Asia Pacific Project Preparation Facility\
    \ (AP3F) \nand transaction advisory services assist DMCs \nand their public sector\
    \ agencies to prepare and \nstructure infrastructure projects with private sector\
    \ \nparticipation, including privatization through PPPs, \nand bring them to the\
    \ global market. Technical \n47\nDEVELOPING THE PRIVATE SECTOR \nEngineers at\
    \ a power plant in central Sumatra, Indonesia. ADB provided support for the \n\
    construction of the 275-megawatt combined-cycle gas turbine power plant.\nassistance\
    \ through the AP3F was completed in \n2019 to Bhutan (project definition for the\
    \ Ministry \nof Finance), Thailand (capacity building for the \nMarine Department),\
    \ Solomon Islands (capacity \nbuilding for the PPP Center of Excellence and the\
    \ \nTina River hydro project), Samoa (outsourcing \nfor the Electric Power Corporation),\
    \ and Timor‑\nLeste (support for the Tibar Bay Port PPP). During \nthe year, the\
    \ AP3F also approved 15 applications \nfor technical assistance totaling $15.8 million.\
    \ \nFour countries will receive project definition and \ncapacity‑building assistance,\
    \ and six will receive \nproject preparation and monitoring assistance.\nCATALYZING\
    \ AND  \nMOBILIZING FINANCE \nA key development challenge for Asia and the \n\
    Pacific is limited available financing, whether \nlong‑term for infrastructure\
    \ and other productive \nassets, or short‑term for trade, early‑stage business\
    \ \ndevelopment, or microenterprises. Developing Asia \nalone will require annual\
    \ infrastructure investments \nof $1.7 trillion per year. A notable 30% of the\
    \ \n$1.5 trillion global trade finance gap also originates \nfrom developing Asia.\n\
    ADB continues its efforts to address these \nsignificant financing gaps. In 2019,\
    \ the bank \nmobilized long‑term cofinancing of $3.54 billion, \nwith more than\
    \ 90% coming from commercial \ncofinancing partners and the rest from official\
    \ \nsources. The main cofinancing products used \nwere parallel loans (47%), risk\
    \ transfers to the \nprivate insurance market (18%), parallel equity \n(17%),\
    \ B‑loans (5%), and guarantees (4%). This \ncofinancing was against ADB’s own\
    \ nonsovereign \nfinancing commitment of $2.36 billion, net of risk \ntransfers.\
    \ \nIn 2019, every $1.00 of ADB’s own committed \nnonsovereign financing was matched\
    \ by $1.50 in \nlong‑term cofinancing. This compares with $1.20 in \n2018. The\
    \ bank aims to mobilize $2.50 in long‑term \ncofinancing for every $1.00 of its\
    \ own nonsovereign \nfinancing by 2030. \nOf the 38 nonsovereign projects signed\
    \ in 2019, \n19 featured cofinancing from partners. \nIn Pakistan, ADB extended\
    \ $15 million from its own \nresources and raised cofinancing of $10 million \n\
    through a B‑loan to help expand the lending \noperations of microfinance institution\
    \ the Kashf \nFoundation. The B‑loan comprised $5 million from \nthe Netherlands\
    \ Development Finance Company \nand $5 million from responsAbility Investments,\
    \ a \nSwiss international impact investor, contributing for \nthe first time to\
    \ an ADB‑financed project.\nIn Indonesia, where there is a priority to use cleaner\
    \ \nfuels to generate electricity, ADB provided support \nfor the construction\
    \ of a 275 MW combined‑\ncycle gas turbine power plant in Riau Province in \n\
    central Sumatra. The project is expected to reduce \nGHG emissions by 375,000\
    \ metric tons of CO2e \nevery year from 2022 onwards. Having committed \n$70 million\
    \ from its own capital resources, ADB \ncatalyzed cofinancing through an $82 million\
    \ \nB‑loan from commercial banks by providing a \npartial risk guarantee and another\
    \ $20 million loan \nfrom the LEAP fund. \nKNOWLEDGE HIGHLIGHTS \nIn May, ADB\
    \ released the second edition of the \nPublic–Private Partnership Monitor, which\
    \ sets out \nthe status of the PPP environment in 12 DMCs. \nWith the aim of providing\
    \ business intelligence to \nthe private sector, the publication assesses 200\
    \ \nquantitative and qualitative indicators relating \nto regulatory frameworks,\
    \ institutional capacity \nfor implementation, PPP market maturity, and \nfinancial\
    \ facilities. These assessments are intended \nto foster dialogue between the\
    \ public and private \nsectors and support an enabling environment  \nfor PPPs.\
    \ \nThrough the Trade Finance Program (TFP), ADB \nprovided training in anti‑money\
    \ laundering and \ncountering the financing of terrorism (AML/CFT) \nto partner\
    \ banks in Bangladesh, Fiji, Pakistan, and \nUzbekistan. The TFP also expanded\
    \ its online \ntraining to include internationally recognized \ncourses and certifications\
    \ in AML/CFT. Since \nregulatory issues around AML/CFT are a major \ncontributor\
    \ to trade finance market gaps, the TFP \ndeveloped a diagnostic tool, the Trade\
    \ Finance \nScorecard, to address these.\nIn 2019, every\n$1.00 of\nADB’s own\n\
    committed\nnonsovereign\nfinancing was\nmatched by \n$1.50\nin long-term \ncofinancing.\
    \ \nThis compares  \nwith $1.20 in 2018.  \nADB’s target is\n$2.50 by 2030. \n\
    PROGRESS \nAGAINST \nSTRATEGY 2030 \nTARGETS \nCOFINANCING\n48\nADB ANNUAL REPORT\
    \ 2019 \n4\nOrganizational Effectiveness\nDelivering Through a Stronger, Better,\
    \ and Faster ADB\nENHANCING SERVICE TO  \nADB MEMBERS \nImproving ADB Products\
    \ and Instruments\nIn August 2019, ADB introduced contingent \ndisaster financing\
    \ as a type of policy‑based lending \nto help vulnerable countries prepare for,\
    \ and \nrespond to, natural hazards such as typhoons, \nfloods, earthquakes, droughts,\
    \ and tsunamis. Five \nPacific island member countries are already using \nthe\
    \ modality to strengthen disaster preparedness, \nwith quick‑disbursing and flexible\
    \ budget \nsupport available when disaster events occur. \nIn September, ADB approved\
    \ the use of results‑\nbased lending (RBL) as a regular financing modality \n\
    for its operations. Since it was piloted by the bank \nin 2013, RBL has supported\
    \ 19 programs developed \nby governments of developing member countries \n(DMCs),\
    \ enhanced the accountability of these \nprograms, and created incentives to deliver\
    \ and \nsustain results. The findings from the pilot phase \nshowed that RBL helped\
    \ strengthen country \nownership of development projects by linking funds \ndisbursement\
    \ with the achievement of agreed \nresults.\nIn 2019, ADB increasingly used new\
    \ financing \nmodalities introduced in 2018, such as project \nreadiness financing\
    \ and small expenditure financing, \nin its regional operations. The bank committed\
    \ \nover $107 million in project readiness financing in \n2019. Small expenditure\
    \ financing of $10 million \nwas also approved for the Kyrgyz Republic, enabling\
    \ \nsupport for small pilot projects to demonstrate \nnew technologies, international\
    \ standards, and \nmanagement approaches for possible scale‑up.\nThroughout the\
    \ year, ADB continued to provide \ntraining to ADB staff and DMC officials on\
    \ its \nlending modalities and products. The bank \nconducted 22 learning events.\
    \ To reach a wider \naudience and enhance learning, ADB also \ndeveloped an e‑learning\
    \ module on lending \nmodalities. \nMaintaining a Strong Country Presence \nThrough\
    \ Field Offices\nIn 2019, ADB started a review of the operations \nof its field\
    \ offices to help build their capacity to \nimplement Strategy 2030. The review\
    \ focuses on \nhow ADB, through its field offices, can strengthen \nthe quality\
    \ and efficiency of its support to \nDMCs, including its sovereign and nonsovereign\
    \ \noperations and knowledge services. The review is \nscheduled for completion\
    \ in 2020.\nADB maintained its commitment to strengthen \nstaff numbers in its\
    \ field offices in 2019. More than \n900 staff are based in field offices, with\
    \ over 80% \nof the field office staff locally recruited. \nModernizing Business\
    \ Processes and \nImproving Operational Efficiency\nIn 2019, ADB continued efforts\
    \ to modernize \nits business processes and improve operational \nefficiency.\n\
    In order to improve process efficiency and \nreflect the new operational priorities\
    \ of Strategy \n2030, ADB updated operations manuals and \nstaff instructions\
    \ on bank policies and financing \nmodalities.These included the templates for\
    \ \ncountry partnership strategies and approvals for \nsovereign operations and\
    \ the operations manual \nand staff instructions for small expenditure \nfinancing\
    \ facilities. \nPromoting Digital Transformation \nCritical to delivering on Strategy\
    \ 2030, ADB \naccelerated its information technology (IT) \nreforms and digital\
    \ transformation initiatives. \nIt adopted a cloud‑based content and \ntelecommunication\
    \ platform to improve \ncollaboration and sustainability and increase \nmobility\
    \ and resiliency. The 27 new digital products \nintroduced include a customer\
    \ relationship \nmanagement system that tracks leads and \nactivities and a loan\
    \ system for guarantees for \nnonsovereign operations. The e‑procurement \nsystem\
    \ was deployed to 25 field offices to \nincrease efficiency. An integrated partner\
    \ fund \naccounting system was also delivered, streamlining \nand automating processes\
    \ for income and cost \nallocations reporting. A modern IT service desk \nsystem\
    \ was delivered to improve internal IT \nsupport services. A new procurement complaints\
    \ \nsystem was also implemented, while IT services \nsupported the establishment\
    \ of new ADB \noffices in the Pacific. These reforms and digital \n49\nORGANIZATIONAL\
    \ EFFECTIVENESS \nADB Indonesia Resident Mission, Jakarta. Indonesia was a founding\
    \ member of ADB in 1966. Today. it is among the \nbank’s largest shareholders\
    \ and sovereign borrowers.\nCritical to \ndelivering on \nStrategy 2030, \nADB\
    \ accelerated \nits information \ntechnology \nreforms \nand digital \ntransformation\
    \ \ninitiatives.\ntransformational initiatives, taken together as a \nwhole, allowed\
    \ ADB to transition smoothly and \neffectively, without disruption to its operations,\
    \ \nto work‑from‑home arrangements for all staff \nbeginning March 2020 during\
    \ the COVID‑19 \npandemic.\nFollowing the approval of the first stage of ADB’s\
    \ \nDigital Agenda 2030, the bank established \ngovernance mechanisms for effective\
    \ budget \nand project management and benefits tracking. \nIt initiated 12 new\
    \ projects, including the design \nof a new sovereign operations system. ADB also\
    \ \nestablished a digital innovation sandbox program, \nwhich will enable the\
    \ application of artificial \nintelligence and robotic process automation to be\
    \ \nexplored. Improving data quality continues to be a \npriority for the bank,\
    \ including the establishment \nof a corporate data dictionary. \nADB received\
    \ a 2019 CIO 100 Award for its use of \ncloud computing to optimize business processes.\
    \ \nThe awards celebrate the innovative use of IT to \ndeliver business value.\n\
    Achieving Timely and  \nValue-for-Money Procurement\nAfter signing a procurement\
    \ framework agreement \nwith the World Bank in December 2018, ADB \nsigned a similar\
    \ agreement with the European \nBank for Reconstruction and Development in \n\
    November 2019.\nAt the project level, ADB signed project \nimplementation agreements\
    \ that allow the \nuse of the procurement rules and procedures \nof the World\
    \ Bank and the European Bank for \nReconstruction and Development for two water\
    \ \nprojects in the Pacific (in Kiribati and Solomon \nIslands) and one power\
    \ project in Uzbekistan \ncofinanced by ADB.\nIn April 2019, ADB launched e‑learning\
    \ modules \non its new procurement framework to help the \nbank’s staff and borrowers\
    \ apply the framework. \nThis was supported by a series of guidance notes \nand\
    \ videos. ADB also held 54 capacity‑building \nevents and trained more than 1,800 participants\
    \ on \nthe new framework.  \nStrengthening and Use  \nof Country Safeguards\n\
    In 2019, ADB continued to support the \ngovernments of Indonesia and Sri Lanka\
    \ in \nundertaking diagnostic studies for use of country \nsafeguards in ADB‑supported\
    \ operations. The \nbank also updated preliminary country safeguard \nassessments\
    \ for Bangladesh, Bhutan, Myanmar, \nand Viet Nam. Across the year, ADB delivered\
    \ \nsafeguards training programs on the environment, \n50\nADB ANNUAL REPORT 2019\
    \ \nindigenous peoples, and resettlement, with each \nattended by staff, executing\
    \ and/or implementing \nagencies, and other stakeholders. The bank \nalso initiated\
    \ a study of project‑level grievance \nredress mechanisms across ADB‑supported\
    \ \nprojects. Throughout 2019, all ADB projects were \nassessed for environmental\
    \ and social impacts, as \nrequired by the bank’s Safeguard Policy Statement.\n\
    Addressing the Concerns of People \nAffected by ADB Projects\nIn 2019, the ADB\
    \ Accountability Mechanism—an \nindependent forum that allows people adversely\
    \ \naffected by ADB‑supported projects to voice \ncomplaints and seek solutions—received\
    \ \n37 complaints (compared to 39 in 2018). Of these, \n2 requested compliance\
    \ review (one was deemed \nineligible by the Compliance Review Panel and the \n\
    other was still being processed at year‑end),  \n10 requested problem‑solving,\
    \ and 3 were \nidentified as eligible by the Special Project \nFacilitator. There\
    \ was 1 complaint pending with \nthe Complaint Receiving Officer and 24 were \n\
    closed for failure to comply with the minimum \nrequirements under the policy.\
    \ \nThe Office of the Compliance Review Panel \nheld 10 outreach events in various\
    \ DMCs and \npublished guidance on compliance review. \nIt also organized workshops\
    \ that produced \na working draft of a regional and national \naccountability\
    \ mechanism framework for financial \nintermediaries. The Office of the Special\
    \ Project \nFacilitator conducted 10 training programs on \ngrievance redress\
    \ mechanisms and problem‑\nsolving, attended by ADB staff and executing and/\n\
    or implementing agencies from DMCs.\nA joint learning report—a collaboration \n\
    between the two offices mentioned above, the \nIndependent Evaluation Department,\
    \ and the \nSustainable Development and Climate Change \nDepartment—analyzed the\
    \ complaints received \nby the Accountability Mechanism from 2016 to \n2018 (when\
    \ the mechanism received the highest \nnumber of complaints since its inception\
    \ in 2002). \nThe report recommends improving risk screening \nas part of project‑level\
    \ safeguards and enhancing \nthe effectiveness of project‑level grievance \nredress\
    \ mechanisms.  \nStrengthening Collaboration  \nwith Civil Society Organizations\n\
    During 2019, ADB deepened its engagement with \ncivil society organizations (CSOs)\
    \ in Mongolia and \nGeorgia. In Mongolia, ADB and CSOs helped \ncommunity members\
    \ develop a transport project \nin ger areas (tent communities). In Georgia, CSOs\
    \ \nand government officials participated in training \ncourses to strengthen\
    \ collaboration on ADB‑\nfinanced projects. CSOs and ADB staff also worked \n\
    together to identify the environmental aspects of a \nproposed transport project\
    \ in Georgia.\nADB engaged with CSOs at a number of key events \nin 2019. At the\
    \ 52nd ADB annual meeting in Fiji, \nabout 140 CSO representatives joined discussions\
    \ \non the bank’s draft operational plans for Strategy \n2030. At the 7th Asian\
    \ Youth Forum, ADB project \nofficers and CSO representatives designed 70 \nyouth‑led\
    \ solutions in road safety, ocean health, \nyouth and disability, jobs and livelihoods,\
    \ and livable \ncities. The forum attracted over 300 young people \nand development\
    \ stakeholders from 28 countries.\nADB also launched an interactive suite of tools\
    \ \nfor ADB staff, government officials, and CSOs \non the bank’s Development\
    \ Asia website. These \ntools provide a range of options for deepening civil \n\
    society engagement in the Pacific. \nSTRENGTHENING ADB  \nAS AN INSTITUTION\n\
    Ensuring a Robust Resource Base\nIn February 2019, ADB completed the midterm \n\
    review of Asian Development Fund 12 and, \nin November, the bank began negotiations\
    \ \nwith donors for the replenishment of Asian \nDevelopment Fund 13, along with\
    \ the replenishment \nof Technical Assistance Special Fund 7.  \nTreasury\nIn\
    \ 2019, the Treasury Department led a new \ntechnical assistance project to build\
    \ capacity \nin sovereign asset and liability management. \nIt launched its first\
    \ secured overnight financing \nrate‑linked bond and continued to offer sterling\
    \ \novernight index average‑linked bonds and green \nbonds. Green bonds and thematic\
    \ bonds provide \nan opportunity for socially responsible investors \nto invest\
    \ in ADB projects in climate financing and \ndevelopment areas such as water,\
    \ gender, and \nhealth. The bank continued to expand its local \ncurrency borrowing\
    \ and initiatives, reaching 23 \nmember currencies.  \nIn 2019, ADB issued thematic\
    \ bonds and green \nbonds amounting to $2.7 billion in Australian \ndollars, euros,\
    \ Hong Kong dollars, Norwegian kroner, \npounds sterling, and Swedish kronor.\
    \ The bank’s \noutstanding green bonds at year‑end totaled about \n$6.8 billion\
    \ ($5 billion in 2018), while outstanding \nthematic bonds totaled $102 million\
    \ for water, $189 \nmillion for gender, and $110 million for health. \nAudit \n\
    The Office of the Auditor General (OAG) issued \n13 audit and 8 advisory reports\
    \ in 2019. These \nFAST FACTS:\nADB’S \nOUTSTANDING \nGREEN AND \nTHEMATIC BONDS\
    \ \nAS AT END-2019:\n$6.8 B \nGREEN BOND\n$102 M \nWATER BOND\n$189 M \nGENDER\
    \ BOND\n$110 M \nHEALTH BOND\n51\nORGANIZATIONAL EFFECTIVENESS \nThe AuditWithoutWalls!\
    \ \nonline community \nsurpassed 1,000 \nregistered members \nfrom all over the\
    \ world \nin 2019. ADB created \nthe Yammer‑based \ncommunity in 2017 \nto help\
    \ public sector \ninternal auditors ask \nquestions and share \nspecialist knowledge.\n\
    ADB’s Asian Youth Forum celebrates young people’s role as partners and beneficiaries\
    \ in advancing development throughout \nthe region. The 7th Asian Youth Forum\
    \ was held at ADB headquarters in August. \ncovered operations, administration\
    \ and operations \nsupport, finance and risk, and IT. \nThe OAG continued to support\
    \ ADB’s regional \ndepartments in helping DMCs strengthen public \nsector internal\
    \ audit offices. In August 2019, the \nOAG hosted an academic forum on applying\
    \ \ndigital technology to internal auditing. The \ndialogue with academic leaders\
    \ from universities \nin Asia and the Pacific, Europe, and North America \nprovided\
    \ insights on practical digital technology \nsolutions for internal auditors in\
    \ public sector \ninstitutions. \nDuring the year, the OAG continued to adopt\
    \ \nadvanced technology and innovative practices in \ninternal audit. It piloted\
    \ the use of drones in one \nof its country portfolio audits to capture bird’s‑eye\
    \ \nviews of project sites and is exploring the use of \ndrones to improve asset\
    \ inventory for complex site \nvisits. The OAG also expanded its annual country\
    \ \nrisk assessment model and built an automated \nvalidation tool for loan covenants.\n\
    Risk Management\nIn 2019, ADB devoted substantial resources to \nmonitoring, mitigating,\
    \ and managing the risks \nassociated with its operations. These include cyber\
    \ \nthreats and risks to business continuity, credit, and \ntreasury operations.\
    \ The bank strengthened the \nknowledge base of its risk professionals to support\
    \ \nADB’s expanding nonsovereign operations, \nreinforced its risk governance\
    \ framework, and \nimplemented a new information system to support \nand protect\
    \ the use of structured derivatives. \nADB reviewed its capital adequacy framework\
    \ in \nlight of Strategy 2030, reassessed its loss provisioning \npolicy to allow\
    \ for new accounting standards for \nexpected credit losses, and provided technical\
    \ \nassistance to regional financial institutions to expand \ntheir knowledge\
    \ and capabilities in risk management.\nAdministrative Expenses \nADB continues\
    \ to rationalize internal administrative \nspending and improve cost efficiency.\
    \ Among \nmajor contributors to cost efficiency are IT reforms, \noperational\
    \ efficiency improvements, and measures \nto strengthen budget management and\
    \ improve \nresource efficiency in ADB’s administrative services.\nEnhancing Human\
    \ Resources \nHuman Resource Management\nADB’s career opportunities continued\
    \ to attract \nstrong interest in 2019, with 493 job openings \ngenerating 41,275\
    \ applications from 66 of \nits 68 members. ADB implemented various \nrecruitment initiatives to\
    \ bring in staff with specialist \nskills in project design for sovereign operations,\
    \ \nexpand the bank’s nonsovereign operations, \nand increase its staff presence\
    \ in the Pacific. As \na result, ADB recruited 371 specialists in 2019, \nincluding 9 new\
    \ staff for the bank’s Pacific country \noffices. There was also a rise in uptake\
    \ of ADB’s \n52\nADB ANNUAL REPORT 2019 \nADB’s Independent Evaluation Department\
    \ (IED) supports both accountability and \nlearning. Its goal is to ensure that\
    \ its evaluations are valued and used by stakeholders and \ndecision-makers to\
    \ bring about positive changes in perception, attitude, decision-making, \nand\
    \ practice.\nIn 2019, the IED produced 1 country evaluation, 2 sector evaluations,\
    \ 3 corporate \nevaluations, and 10 project and technical assistance-level evaluations.\
    \ It also validated  \n55 project completion reports, 11 extended annual review\
    \ reports, and 7 country \npartnership strategy final reviews.\nThe IED completed\
    \ a country program evaluation for Indonesia and validated country \npartnership\
    \ strategy final reviews for Armenia, Bhutan, Cambodia, Fiji, Georgia, Nepal,\
    \ \nand Thailand. The findings contributed to the preparation and design of new\
    \ country \npartnership strategies and operational plans for these developing\
    \ member countries.\nThe department evaluated the relevance and results of the\
    \ use of ADB’s concessional \nresources from Asian Development Fund (ADF) XI and\
    \ ADF 12. The recommendations of \nthis evaluation contributed to discussions\
    \ on the ADF 13 replenishment.\nThe IED also assessed the performance and results\
    \ of ADB’s use of multitranche \nfinancing facilities. These facilities have been\
    \ used to deliver over $52 billion in ADB \nfinancing from 2005 to 2018. The evaluation\
    \ supported the use of these facilities, but \nrecommended changes to improve\
    \ their transformational development impact, improve \ntimely completion of operations,\
    \ enhance learning, and reduce transaction costs. \nSector-level evaluations examined\
    \ ADB’s support for Pakistan’s power sector from \n2005 to 2017, which totaled\
    \ $6.2 billion, and Indonesia’s finance sector from 2005 \nto 2018, which totaled\
    \ about $2 billion. These evaluations provided evidence to help \nADB continue\
    \ to improve project design, operations, and development outcomes. For \nexample,\
    \ a subsequent policy-based loan for Pakistan benefited from the evaluation’s\
    \ \nrecommendations to improve financial sustainability, strengthen sector governance\
    \ and \nintegrated planning, and support physical and technological investments.\
    \ These became \nthe program’s reform areas.\nINDEPENDENT EVALUATION  \nThis evaluation\
    \ assesses the \nrelevance and results of the \nuse of concessional resources\
    \ \nby ADB over 2013–2018, \nthe period covered by Asian \nDevelopment Fund XI\
    \ \nand the first half of Asian \nDevelopment Fund 12.\nsecondment and internship\
    \ programs, which \nhosted 41 secondees and 37 graduate students as \ninterns,\
    \ respectively.  \nIn December, ADB began using artificial \nintelligence to enhance\
    \ its recruitment and \nselection processes, with the introduction of \n“MARI,”\
    \ the bank’s artificial intelligence chatbot. \nMARI allows ADB to screen applicants\
    \ more \nefficiently and enables real‑time interaction to \nimprove the recruitment\
    \ experience for candidates.\nADB also commissioned an independent gender \npay\
    \ gap study. The findings showed that there are \nno significant or unexplained\
    \ gaps in pay between \nwomen and men in comparable roles at ADB. The \nbank has\
    \ continued to focus on hiring and retaining \nwomen in senior roles. Women now\
    \ account for \n36.6% of ADB’s international staff, demonstrating \ngood progress\
    \ toward the target of 40% by the end \nof 2022.\nThese initiatives saw ADB receive\
    \ Economic \nDividends for Gender Equality (EDGE) Move \n(level 2) certification.\
    \ EDGE is the leading \nstandard for workplace gender equality, and \nADB is the\
    \ first international financial institution \ncertified with EDGE level 2. \n\
    Maintaining its strong culture of diversity and \ninclusion, ADB supported its\
    \ lesbian, gay, \nbisexual, transgender, and related communities \n(LGBT+) in\
    \ celebrating International Day \nAgainst Homophobia, Transphobia, and \nBiphobia\
    \ and the LGBT+ Pride celebration \nmonth. \nADB also developed a human resource\
    \ \nframework to support the implementation \nof Strategy 2030. The framework\
    \ includes \ninitiatives on employment agility, talent \nmanagement, job architecture,\
    \ investment in \nhuman capital, and corporate culture and values.\n53\nORGANIZATIONAL\
    \ EFFECTIVENESS \nAt ADB, women now account for 36.6% of international staff,\
    \ demonstrating good progress toward the bank’s target of \n40% by the end of\
    \ 2022. \nFAST FACTS:\n82 STAFF  \nPARTICIPATED \nIN LEADERSHIP \nPROGRAMS\n72\
    \ STAFF \nPARTICIPATED \nIN ROTATION \nPROGRAMS AND \nSHORT-TERM \nASSIGNMENTS\n\
    Learning and Development \nADB continued to support the career development \n\
    and growth of its staff and encouraged the sharing \nof knowledge and expertise\
    \ across its departments, \nlocations, and job roles.\nIn 2019, 72 staff participated\
    \ in rotation programs \nand short‑term assignments, broadening their skills \n\
    and knowledge and enhancing their workplace \nexperiences as they engaged in work\
    \ with a \ndifferent department or region. \nADB updated its executive leadership\
    \ program, \nlaunched three new leadership programs, and \nintroduced an executive\
    \ coaching program. The \nsuite of practical programs now targets leaders \nat\
    \ all levels of the organization, with a focus on \nfostering innovation and collaboration.\
    \ In 2019, 82 \nstaff participated in the leadership programs and 6 \nstaff commenced\
    \ executive coaching. \nTo encourage supervisors and their teams to \nembrace\
    \ a performance culture, 11% of ADB \nsupervisors completed training to improve\
    \ team \nperformance in 2019.\nConflict Management\nIn 2019, ADB sought to manage\
    \ conflict within \nthe organization more proactively by involving the \nOffice\
    \ of the Ombudsperson earlier in the conflict \nresolution process. In 2019, this\
    \ independent office \nhelped address approximately 450 cases that \ninvolved\
    \ over 650 individuals. \nThe office also hosted the 4th annual conference \n\
    of the Asia Pacific Ombuds Regional Advisory \nCommittee, providing an opportunity\
    \ to share \nknowledge with professionals in ADB member \ncountries.\nLeading\
    \ Anticorruption  \nand Integrity Initiatives\nADB’s Office of Anticorruption\
    \ and Integrity \n(OAI) improved the efficiency of its investigative \nprocess\
    \ in 2019. This resulted in a record number \nof closed complaints and investigations\
    \ (up 16% \nand 93%, respectively, from 2018) and an increase \nin remedial actions\
    \ imposed on external parties, \nincluding debarments and reprimands (up 47% \n\
    from 2018).\nThe OAI expanded its in‑country partnerships \nwith eight DMCs in\
    \ Central and West Asia, \nSoutheast Asia, and the Pacific, helping to \nstrengthen\
    \ tax integrity policy and law reforms. \nIt also assisted seven DMCs in Central\
    \ and West \nAsia, East Asia, South Asia, and Southeast Asia to \nstrengthen governance,\
    \ institutional capacity, and \ncompliance with international standards for anti‑\n\
    money laundering and combating the financing of \nterrorism.\n54\nADB ANNUAL REPORT\
    \ 2019 \nThroughout 2019, the Asian Development Bank Institute \n(ADBI)—ADB’s\
    \ think tank based in Tokyo—continued to \nadvance innovative policy solutions\
    \ for the bank’s developing \nmember countries. Research outputs provided new\
    \ thinking \non the blue economy; climate risk; credit guarantee funds; \ndemographic\
    \ changes, productivity, and the role of technology; \neconomic integration; energy\
    \ security; financial technology, inclusion, and literacy; \nfinance for small\
    \ and medium-sized enterprises; and infrastructure financing.\nADBI’s research\
    \ department published 14 open access books, 154 working papers, \n27 blog articles,\
    \ and 22 journal articles. It also organized 38 research events for an \nestimated\
    \ 1,300 policymakers and stakeholders.\nThe institute also conducted 54 capacity-building\
    \ and training events—including \npolicy dialogues, workshops, university format\
    \ courses, and e-learning—all promoting \nknowledge-sharing among policymakers\
    \ and stakeholders, development of new policy \nideas, and innovative concepts\
    \ for policy implementation. About one-third were hosted \nat ADBI in Tokyo and\
    \ two-thirds in other regions of Asia and the Pacific, convening more \nthan 1,500\
    \ participants. The capacity-building and training department also published 4\
    \ \nADBI-edited books, 7 working papers, 4 policy briefs, and blog articles. \n\
    In 2019, ADBI chaired Think20, the G20’s policy research and advisory network,\
    \ under \nJapan’s 2019 G20 presidency. \nADBI was named the world’s number one\
    \ government-affiliated think tank by the 2019 \nGlobal Go To Think Tank Index\
    \ Report published by the University of Pennsylvania. The \ninstitute also placed\
    \ 24th in the report’s worldwide think tank ranking. \nASIAN DEVELOPMENT BANK\
    \ INSTITUTE \nThis book outlines how a \nservices economy can help \nachieve long-term\
    \ income \ngrowth and sustainable \ndevelopment.\nA review of ADB’s Respectful\
    \ Workplace Unit’s \npilot period affirmed the value of the unit, which \nin 2019\
    \ served 107 visitors. Based on the review, \nan Office of Professional Conduct,\
    \ which will \nraise awareness, deliver training, and advise \nstaff on workplace\
    \ concerns, was established. \nThe OAI will continue to investigate workplace\
    \ \nmisconduct.\nThe OAI conducted eight proactive integrity \nreviews of projects\
    \ valued at a total of \n$1.8 billion, including an emergency assistance \nproject.\
    \ It organized 98 outreach events catering \nto over 8,700 participants, supported\
    \ high‑level \nlearning events across Asia, contributed to the \nG20 anticorruption\
    \ working group, and launched \nADB’s first gamified e‑learning course. \nStrengthening\
    \ Disclosure  \nand Transparency\nADB’s Access to Information Policy came \ninto\
    \ effect on 1 January 2019. In 2019, ADB \nproactively disclosed to the public\
    \ 4,930 project \ndocuments.\nADB recognizes the right of people to seek and \n\
    receive information about its operations. In \n2019, the bank received 4,209 formal\
    \ requests \nfor information. Of these, 3,544 (84%) were \ndeemed valid and the\
    \ rest were identified \nas spam. ADB acknowledged 69% of the \nvalid requests\
    \ within the required 7 days and \nresponded to 83% within the required 30 days.\
    \ \nADB responded to 93% of the valid requests by \nthe end of the year. \nProviding\
    \ Legal Services \nThe Office of the General Counsel (OGC) \ncontributed legal\
    \ perspectives to key ADB \npolicies in 2019. It helped develop policies on \n\
    the diversification of financing terms for regular \nordinary capital resources\
    \ sovereign lending \noperations and contingent disaster financing, \nand on the\
    \ implementation of project readiness \nfinancing and the small expenditure financing\
    \ \nfacility. The OGC successfully concluded host \ncountry agreements with Singapore\
    \ and for \nsix ADB country offices in the Pacific. It also \nsupported the processing\
    \ of ADB’s sovereign, \n55\nORGANIZATIONAL EFFECTIVENESS \nADB staff member at\
    \ the Tajikistan Resident Mission. ADB established a new team to provide administrative\
    \ services support \nto its field offices.\nnonsovereign, and transaction advisory\
    \ projects, \nand implementation of its borrowing program.\nThe OGC’s role in\
    \ law and policy reform work \nin 2019 included supporting Papua New Guinea \n\
    in its enactment of an arbitration law and \naccession to the United Nations Convention\
    \ \non the Recognition and Enforcement of Foreign \nArbitral Awards. The office\
    \ also conducted a \nnationwide judicial training program in Pakistan to \nprepare\
    \ judges for the establishment of gender‑\nbased violence courts, as well as supporting\
    \ the \nPhilippines in its enactment of a new Islamic \nbanking law.\nDelivering\
    \ Effective Administrative \nServices\nIn January 2019, ADB established a new\
    \ team to \nprovide administrative services support to its field \noffices. This\
    \ team coordinates action on requests \nthat relate to field office creation,\
    \ expansion, \nor relocation. The team helped establish a new \nfield office in\
    \ Singapore and two in the Pacific. \nIt also assisted in relocating five field\
    \ offices and \ncoordinated the expansion of another seven.\nADB’s corporate e‑procurement\
    \ system—which \nreduces purchase processing times, enhances \nsourcing, and provides\
    \ auditable processes—\nwas fully implemented into the bank’s Manila \nheadquarters\
    \ in 2019. The system was launched \ninto ADB field offices starting March 2019.\n\
    ADB extended measures to ensure business \ncontinuity—responding to unforeseen\
    \ \ncircumstances or changes in the operational \nenvironment—to its regional\
    \ and operational \ndepartments. As well as providing crisis \nmanagement training\
    \ for staff, the bank deployed \nnew technologies and training packages to help\
    \ \nkeep staff appraised of changing security situations \nand provided assistance\
    \ when needed. ADB \nalso launched an entry access project that will \nsubstantially\
    \ modernize security arrangements at \nheadquarters and serve as a baseline for\
    \ security \nmeasures at its field offices.  \nIn addition to using renewable\
    \ energy to power \nthe building, ADB ensures that activities at \nheadquarters\
    \ are carbon neutral by purchasing \ncredits for unavoidable emissions. In 2019,\
    \ the \nbank purchased carbon credits to offset emissions \nmade from 2016 to\
    \ 2018. \nSince ADB promotes a working environment that \nencourages staff interaction\
    \ and the exchange of \nideas, several workspace fit‑outs were completed \nthat\
    \ showcase modern approaches to more open \nworkplace communication and collaboration.\n\
    56\nADB ANNUAL REPORT 2019 \nAPPENDIXES\nADB Armenia Resident Mission, Yerevan.\n\
    The demand for ADB assistance remained strong in 2019 \nand our activities strongly\
    \ aligned with the priorities of \nStrategy 2030. \nMasatsugu Asakawa, ADB President\n\
    57\nAPPENDIXES \n58\nAppendix 1: \nCommitments by  \nCountry, 2019\n65\n70\nAppendix\
    \ 5:  \nMembers, Capital Stock, \nand Voting Power\nAppendix 8A:  \nADB Organizational\
    \ \nStructure\n59\nAppendix 2: \nLoans and Grants  \nCommitted, 2019\n66\nAppendix\
    \ 6: \nContributions to Asian \nDevelopment Fund\n72\nAppendix 8B: \nADB Sector\
    \ and \nThematic Groups\n63\nAppendix 3:  \nApprovals, 2015–2019\n67\nAppendix\
    \ 7A: 2019 \nProject-Specific \nSovereign Cofinancing \nCommitments\n73\nAppendix\
    \ 9:  \nADB Corporate \nReports\n64\nAppendix 4:  \nADB Regional and \nNonregional\
    \ Members\n68\nAppendix 7B:  \nActive Trust Funds \nand Special Funds\n74\nAppendix\
    \ 10: Operational \nData and Organizational \nInformation as of  \n31 December\
    \ 2019\n58\nADB ANNUAL REPORT 2019 \nAppendix 1: Commitments by Country, 2019\
    \ ($ million)\nLoans, Grants, and Others\nTechnical \nAssistancea\nCofinancingb\n\
    Regular OCR\nConcessional\nADF\nCountry\nSovereign Nonsovereign\nOCR\nGrant\n\
    Subtotal\nProject\nTA\nSubtotal\nTotal\nAfghanistan\n ‑ \n 4.0 \n ‑ \n 348.8 \n\
    \ 352.8 \n 4.7 \n 3.9 \n ‑ \n 3.9 \n 361.4 \nArmenia\n 50.3 \n 43.9 \n ‑ \n ‑\
    \ \n 94.2 \n 2.1 \n 46.7 \n ‑ \n 46.7 \n 142.9 \nAzerbaijan\n 250.0 \n ‑ \n ‑\
    \ \n ‑ \n 250.0 \n 1.0 \n ‑ \n 0.5 \n 0.5 \n 251.5 \nBangladesh\n 915.8 \n 14.2\
    \ \n 369.3 \n ‑ \n 1,299.2 \n 3.8 \n 804.7 \n 2.7 \n 807.4 \n 2,110.4 \nBhutan\n\
    \ ‑ \n ‑ \n 30.0 \n ‑ \n 30.0 \n 2.7 \n ‑ \n ‑ \n ‑ \n 32.7 \nCambodia\n ‑ \n\
    \ ‑ \n 269.3 \n 6.6 \n 275.8 \n ‑ \n 16.6 \n 0.8 \n 17.4 \n 293.2 \nChina, People’s\
    \  \nRepublic of\n 1,813.6 \n 381.0 \n ‑ \n ‑ \n 2,194.6 \n 12.0 \n 310.5 \n 8.0\
    \ \n 318.5 \n 2,525.1 \nFederated States of Micronesia\n ‑ \n ‑ \n ‑ \n 26.0 \n\
    \ 26.0 \n ‑ \n ‑ \n ‑ \n ‑ \n 26.0 \nFiji\n 65.0 \n ‑ \n ‑ \n ‑ \n 65.0 \n 0.7\
    \ \n 65.7 \n 2.4 \n 68.1 \n 133.8 \nGeorgia\n 706.4 \n 29.1 \n ‑ \n ‑ \n 735.5\
    \ \n 5.3 \n 65.7 \n ‑ \n 65.7 \n 806.5 \nIndia\n 3,180.0 \n 965.1 \n ‑ \n ‑ \n\
    \ 4,145.1 \n 14.8 \n 1,512.7 \n 8.1 \n 1,520.7 \n 5,680.6 \nIndonesia\n 1,487.8\
    \ \n 152.9 \n ‑ \n ‑ \n 1,640.7 \n 0.3 \n 709.8 \n 19.3 \n 729.1 \n 2,370.0 \n\
    Kazakhstan\n 97.6 \n 41.2 \n ‑ \n ‑ \n 138.9 \n 1.8 \n 121.6 \n ‑ \n 121.6 \n\
    \ 262.3 \nKyrgyz Republic\n ‑ \n ‑ \n 73.7 \n 103.7 \n 177.4 \n 2.4 \n ‑ \n ‑\
    \ \n ‑ \n 179.8 \nLao People’s Democratic \nRepublic\n ‑ \n ‑ \n 135.0 \n 5.0\
    \ \n 140.0 \n ‑ \n 4.5 \n ‑ \n 4.5 \n 144.5 \nMalaysia\n ‑ \n ‑ \n ‑ \n ‑ \n ‑\
    \ \n ‑ \n 25.0 \n ‑ \n 25.0 \n 25.0 \nMaldives\n ‑ \n ‑ \n 5.0 \n 5.0 \n 10.0\
    \ \n 1.0 \n ‑ \n 0.5 \n 0.5 \n 11.5 \nMarshall Islands\n ‑ \n ‑ \n ‑ \n 6.5 \n\
    \ 6.5 \n ‑ \n ‑ \n ‑ \n ‑ \n 6.5 \nMongolia\n 319.6 \n 47.0 \n 56.0 \n ‑ \n 422.6\
    \ \n 8.9 \n 180.6 \n 7.3 \n 187.8 \n 619.4 \nMyanmar\n ‑ \n 597.5 \n 230.4 \n\
    \ 15.8 \n 843.7 \n 0.2 \n 215.9 \n 2.1 \n 218.0 \n 1,061.9 \nNauru\n ‑ \n ‑ \n\
    \ ‑ \n 22.0 \n 22.0 \n ‑ \n ‑ \n ‑ \n ‑ \n 22.0 \nNepal\n ‑ \n 30.0 \n 358.0 \n\
    \ ‑ \n 388.0 \n 5.4 \n 150.6 \n 0.4 \n 151.0 \n 544.4 \nNiue\n ‑ \n ‑ \n ‑ \n\
    \ ‑ \n ‑ \n 0.2 \n ‑ \n ‑ \n ‑ \n 0.2 \nPakistan\n 1,282.0 \n 15.0 \n 900.0 \n\
    \ ‑ \n 2,197.0 \n 8.1 \n 983.9 \n 3.9 \n 987.8 \n 3,192.9 \nPapua New Guinea\n\
    \ 100.0 \n 10.0 \n ‑ \n ‑ \n 110.0 \n 4.1 \n 38.8 \n 0.8 \n 39.6 \n 153.6 \nPhilippines\n\
    \ 2,523.3 \n 30.0 \n ‑ \n ‑ \n 2,553.3 \n 2.3 \n 2,011.6 \n 3.0 \n 2,014.6 \n\
    \ 4,570.1 \nSamoa\n ‑ \n ‑ \n ‑ \n 69.8 \n 69.8 \n ‑ \n ‑ \n ‑ \n ‑ \n 69.8 \n\
    Solomon Islands\n ‑ \n ‑ \n 49.0 \n 27.0 \n 76.0 \n 0.8 \n 20.3 \n ‑ \n 20.3 \n\
    \ 97.1 \nSri Lanka\n 743.0 \n ‑ \n 72.0 \n ‑ \n 815.0 \n 3.0 \n 1,199.4 \n 1.2\
    \ \n 1,200.6 \n 2,018.6 \nTajikistan\n ‑ \n ‑ \n ‑ \n 120.0 \n 120.0 \n 1.8 \n\
    \ 41.3 \n ‑ \n 41.3 \n 163.0 \nThailand\n ‑ \n 459.1 \n ‑ \n ‑ \n 459.1 \n ‑ \n\
    \ 1,326.1 \n ‑ \n 1,326.1 \n 1,785.2 \nTimor‑Leste\n ‑ \n ‑ \n ‑ \n ‑ \n ‑ \n\
    \ 1.9 \n ‑ \n 0.5 \n 0.5 \n 2.4 \nTonga\n ‑ \n ‑ \n ‑ \n 54.0 \n 54.0 \n ‑ \n\
    \ 43.2 \n ‑ \n 43.2 \n 97.2 \nTuvalu\n ‑ \n ‑ \n ‑ \n 10.0 \n 10.0 \n ‑ \n 10.6\
    \ \n ‑ \n 10.6 \n 20.6 \nUzbekistan\n 620.0 \n ‑ \n 517.3 \n ‑ \n 1,137.3 \n 14.9\
    \ \n 319.1 \n 3.2 \n 322.3 \n 1,474.5 \nVanuatu\n ‑ \n ‑ \n 2.3 \n 12.0 \n 14.3\
    \ \n 1.5 \n ‑ \n ‑ \n ‑ \n 15.8 \nViet Nam\n ‑ \n 17.6 \n 577.0 \n 12.0 \n 606.6\
    \ \n 0.8 \n 1,091.5 \n 13.9 \n 1,105.4 \n 1,712.8 \nRegionalc\n ‑ \n 162.5 \n\
    \ ‑ \n ‑ \n 162.5 \n 131.2 \n 316.0 \n 148.1 \n 464.1 \n 757.8 \nTotal ADB\n 14,154.4\
    \ \n 3,000.1 \n 3,644.1 \n 844.1  21,642.7 \n 237.5 \n 11,636.2  226.5  11,862.6\
    \ 33,742.8 \nADB = Asian Development Bank, ADF = Asian Development Fund, OCR =\
    \ ordinary capital resources, SF = special funds,  TA = technical assistance.\
    \ \nNotes: Commitment is the financing approved by ADB’s Board of Directors or\
    \ Management for which the investment agreement has been signed by the borrower,\
    \ recipient, or the \ninvestee company and ADB.  It is the amount indicated in\
    \ the investment agreement that may or may not be equal to the approved amount,\
    \ depending on the exchange rate at the \ntime of signing. In the case of official\
    \ and commercial cofinancing not administered by ADB for which the signed amount\
    \ is not readily available, the approved amount is used. \na Refers to Technical\
    \ Assistance Special Fund and other SF.\nb Including trust funds.\nc Regional\
    \ includes nonsovereign operations, which involve two or more countries, and all\
    \ regional technical assistance.\n59\nAPPENDIXES \ncontinued on next page\nAppendix\
    \ 2: Loans and Grants Committed, 2019\nRegular Ordinary Capital and Concessional\
    \ Resources Commitments ($ million)\nRegion/Country/Loan or Grant Title\nModality\
    \ Regular OCR Concessional OCR\nADF Grant\n Total \nA. SOVEREIGN OPERATIONS\n\
    \ 14,154.4 \n 3,644.1 \n 844.1 \n 18,642.6 \nCentral and West Asia\n 3,006.3 \n\
    \ 1,491.0 \n 572.5 \n 5,069.8 \nAfghanistan\n -  \n -  \n 348.8 \n 348.8 \nArghandab\
    \ Integrated Water Resources Development\n Project \n ‑  \n ‑  \n 348.8 \n 348.8\
    \ \nArmenia\n 50.3 \n -  \n -  \n 50.3 \nSecond Public Efficiency and Financial\
    \ Markets Program (Subprogram 1)\n PBL \n 40.3 \n ‑  \n ‑  \n 40.3 \nHuman Development\
    \ Enhancement Program\n PBL \n 10.0 \n ‑  \n ‑  \n 10.0 \nAzerbaijan\n 250.0 \n\
    \ -  \n -  \n 250.0 \nImproving Governance and Public Sector Efficiency Program\
    \ \n(Subprogram 2)\n PBL \n 250.0 \n ‑  \n ‑  \n 250.0 \nGeorgia\n 706.4 \n -\
    \  \n -  \n 706.4 \nNorth–South Corridor (Kvesheti–Kobi) Road\n Project \n 410.2\
    \ \n ‑  \n ‑  \n 410.2 \nEast–West Highway (Shorapani–Argveta Section) Improvement\n\
    \ Project \n 281.1 \n ‑  \n ‑  \n 281.1 \nLivable Cities Investment Program\n\
    \ PRF \n 15.0 \n ‑  \n ‑  \n 15.0 \nKazakhstan\n 97.6 \n -  \n -  \n 97.6 \nPromoting\
    \ Gender Equality in Housing Finance\n Project \n 97.6 \n ‑  \n ‑  \n 97.6 \n\
    Kyrgyz Republic\n -  \n 73.7 \n 103.7 \n 177.4 \nPromoting Economic Diversification\
    \ Program (Subprogram 1)\n PBL \n ‑  \n ‑  \n 50.0 \n 50.0 \nUch–Kurgan Hydropower\
    \ Plant Modernization\n Project \n ‑  \n 60.0 \n 40.0 \n 100.0 \nNaryn Rural Water\
    \ Supply and Sanitation Development Program\n RBL \n ‑  \n 13.7 \n 13.7 \n 27.4\
    \ \nPakistan\n 1,282.0 \n 900.0 \n -  \n 2,182.0 \nBalochistan Water Resources\
    \ Development Sector\n Project \n ‑  \n 100.0 \n ‑  \n 100.0 \nKhyber Pakhtunkhwa\
    \ Provincial Roads Improvement –  \nAdditional Financing\n Project \n 75.0 \n\
    \ ‑  \n ‑  \n 75.0 \nKhyber Pakhtunkhwa Cities Improvement Projects\n PRF \n 7.0\
    \ \n ‑  \n ‑  \n 7.0 \nTrade and Competitiveness Program (Subprogram 1)\n PBL\
    \ \n ‑  \n 500.0 \n ‑  \n 500.0 \nSocial Protection Development – Additional Financing\n\
    \ Project \n 200.0 \n ‑  \n ‑  \n 200.0 \nEconomic Stabilization Program\n PBL\
    \ \n 1,000.0 \n ‑  \n ‑  \n 1,000.0 \nEnergy Sector Reforms and Financial Sustainability\
    \ Program \n(Subprogram 1)\n PBL \n ‑  \n 300.0 \n ‑  \n 300.0 \nTajikistan\n\
    \ -  \n -  \n 120.0 \n 120.0 \nCentral Asia Regional Economic Cooperation Corridors\
    \ 2, 3, and 5 \n(Obigarm–Nurobod) Road\n Project \n ‑  \n ‑  \n 110.0 \n 110.0\
    \ \nTourism Development\n PRF \n ‑  \n ‑  \n 10.0 \n 10.0 \nUzbekistan\n 620.0\
    \ \n 517.3 \n -  \n 1,137.3 \nHorticulture Value Chain Infrastructure\n Project\
    \ \n ‑  \n 197.0 \n ‑  \n 197.0 \nSecond Tashkent Province Water Supply Development\n\
    \ Project \n ‑  \n 105.3 \n ‑  \n 105.3 \nRailway Efficiency Improvement\n Project\
    \ \n 170.0 \n ‑  \n ‑  \n 170.0 \nLivestock Value Chain Development\n Project\
    \ \n ‑  \n 150.0 \n ‑  \n 150.0 \nProject Readiness Financing for Urban Services\n\
    \ PRF \n ‑  \n 15.0 \n ‑  \n 15.0 \nEconomic Management Improvement Program (Subprogram\
    \ 2)\n PBL \n 300.0 \n ‑  \n ‑  \n 300.0 \nMortgage Market Sector Development\
    \ Program\n SDP \n 150.0 \n 50.0 \n ‑  \n 200.0 \nEast Asia\n 2,133.2 \n 56.0\
    \ \n -  \n 2,189.2 \nChina, People’s Republic of\n 1,813.6 \n -  \n -  \n 1,813.6\
    \ \nYunnan Lincang Border Economic Cooperation Zone Development\n Project \n 250.0\
    \ \n ‑  \n ‑  \n 250.0 \nYangtze River Green Ecological Corridor Comprehensive\
    \ Agriculture \nDevelopment\n Project \n 300.0 \n ‑  \n ‑  \n 300.0 \nAir Quality\
    \ Improvement in the Greater Beijing–Tianjin–Hebei Region—\nShandong Clean Heating\
    \ and Cooling\n Project \n 392.0 \n ‑  \n ‑  \n 392.0 \nSichuan Ziyang Inclusive\
    \ Green Development\n Project \n 200.0 \n ‑  \n ‑  \n 200.0 \nHubei Yichang Comprehensive\
    \ Elderly Care Demonstration\n Project \n 150.0 \n ‑  \n ‑  \n 150.0 \nDemonstration\
    \ of Guangxi Elderly Care and Health Care Integration  \nand Public–Private Partnership\n\
    \ Project \n 100.0 \n ‑  \n ‑  \n 100.0 \nGansu Internet‑Plus Agriculture Development\n\
    \ Project \n 130.0 \n ‑  \n ‑  \n 130.0 \nGuizhou Gui’an New District New Urbanization\
    \ Smart Transport  \nSystem Development\n Project \n 192.8 \n ‑  \n ‑  \n 192.8\
    \ \nShandong Green Development Fund\n Project \n 98.8 \n ‑  \n ‑  \n 98.8 \nMongolia\n\
    \ 319.6 \n 56.0 \n -  \n 375.6 \nSustainable Tourism Development\n Project \n\
    \ 19.0 \n 19.0 \n ‑  \n 38.0 \nFourth Health Sector Development – Additional Financing\n\
    \ Project \n 16.0 \n ‑  \n ‑  \n 16.0 \nRegional Improvement of Border Services\
    \ – Additional Financing\n Project \n ‑  \n 27.0 \n ‑  \n 27.0 \nRegional Road\
    \ Development and Maintenance – Additional Financing\n Project \n 58.5 \n ‑  \n\
    \ ‑  \n 58.5 \nUlaanbaatar Air Quality Improvement Program (Phase 2)\n PBL \n\
    \ 160.0 \n ‑  \n ‑  \n 160.0 \nImproving Access to Health Services for Disadvantaged\
    \ Groups \nInvestment Program – Tranche 1\n MFF \n 66.1 \n 10.0 \n ‑  \n 76.1\
    \ \n60\nADB ANNUAL REPORT 2019 \nAppendix 2 continued\ncontinued on next page\n\
    Region/Country/Loan or Grant Title\nModality Regular OCR Concessional OCR\nADF\
    \ Grant\n Total \nPacific\n 165.0 \n 51.3 \n 227.2 \n 443.5 \nFederated States\
    \ of Micronesia\n -  \n -  \n 26.0 \n 26.0 \nPacific Disaster Resilience Program\
    \ (Phase 2)\n PBL \n ‑  \n ‑  \n 6.0 \n 6.0 \nRenewable Energy Development\n Project\
    \ \n ‑  \n ‑  \n 15.0 \n 15.0 \nChuuk Water Supply and Sanitation\n PRF \n ‑ \
    \ \n ‑  \n 5.0 \n 5.0 \nFiji\n 65.0 \n -  \n -  \n 65.0 \nSustained Private Sector‑Led\
    \ Growth Reform Program (Subprogram 2)\n PBL \n 65.0 \n ‑  \n ‑  \n 65.0 \nMarshall\
    \ Islands\n -  \n -  \n 6.5 \n 6.5 \nPublic Financial Management – Additional\
    \ Financing\n Project \n ‑  \n ‑  \n 0.5 \n 0.5 \nPacific Disaster Resilience\
    \ Program (Phase 2)\n PBL \n ‑  \n ‑  \n 6.0 \n 6.0 \nNauru\n -  \n -  \n 22.0\
    \ \n 22.0 \nSolar Power Development\n Project \n ‑  \n ‑  \n 22.0 \n 22.0 \nPapua\
    \ New Guinea\n 100.0 \n -  \n -  \n 100.0 \nHealth Services Sector Development\
    \ Program (Subprogram 2)\n PBL \n 100.0 \n ‑  \n ‑  \n 100.0 \nSamoa\n -  \n -\
    \  \n 69.8 \n 69.8 \nSystems Strengthening for Effective Coverage of New Vaccines\
    \  \nin the Pacific\n Project \n ‑  \n ‑  \n 7.5 \n 7.5 \nEnhancing Safety, Security,\
    \ and Sustainability of Apia Port\n Project \n ‑  \n ‑  \n 62.3 \n 62.3 \nSolomon\
    \ Islands\n -  \n 49.0 \n 27.0 \n 76.0 \nUrban Water Supply and Sanitation Sector\n\
    \ PRF \n ‑  \n ‑  \n 3.0 \n 3.0 \nTina River Hydropower\n Project \n ‑  \n 18.0\
    \ \n 12.0 \n 30.0 \nUrban Water Supply and Sanitation Sector\n Project \n ‑  \n\
    \ 28.0 \n 9.0 \n 37.0 \nPacific Disaster Resilience Program (Phase 2)\n PBL \n\
    \ ‑  \n 3.0 \n 3.0 \n 6.0 \nTonga\n -  \n -  \n 54.0 \n 54.0 \nBuilding Macroeconomic\
    \ Resilience (Subprogram 3)\n PBL \n ‑  \n ‑  \n 5.0 \n 5.0 \nTransport Project\
    \ Development Facility\n PRF \n ‑  \n ‑  \n 5.0 \n 5.0 \nIntroducing eGovernment\
    \ through Digital Health\n Project \n ‑  \n ‑  \n 7.5 \n 7.5 \nIntegrated Urban\
    \ Resilience Sector\n Project \n ‑  \n ‑  \n 18.3 \n 18.3 \nRenewable Energy\n\
    \ Project \n ‑  \n ‑  \n 12.2 \n 12.2 \nPacific Disaster Resilience Program (Phase\
    \ 2)\n PBL \n ‑  \n ‑  \n 6.0 \n 6.0 \nTuvalu\n -  \n -  \n 10.0 \n 10.0 \nImproved\
    \ Fiscal and Infrastructure Management Program\n PBL \n ‑  \n ‑  \n 4.0 \n 4.0\
    \ \nIncreasing Access to Renewable Energy\n Project \n ‑  \n ‑  \n 6.0 \n 6.0\
    \ \nVanuatu\n -  \n 2.3 \n 12.0 \n 14.3 \nSystems Strengthening for Effective\
    \ Coverage of New Vaccines  \nin the Pacific\n Project \n ‑  \n 2.3 \n 9.0 \n\
    \ 11.3 \nLuganville Urban Water Supply and Sanitation\n PRF \n ‑  \n ‑  \n 3.0\
    \ \n 3.0 \nSouth Asia\n 4,838.8 \n 834.2 \n 5.0 \n 5,678.1 \nBangladesh\n 915.8\
    \ \n 369.3 \n -  \n 1,285.0 \nRural Connectivity Improvement\n Project \n 100.0\
    \ \n 100.0 \n ‑  \n 200.0 \nMicroenterprise Development\n Project \n 50.0 \n ‑\
    \  \n ‑  \n 50.0 \nSouth Asia Subregional Economic Cooperation Chittagong–Cox’s\
    \ Bazar \nRailway Connectivity (Phase 1) – Tranche 2\n MFF \n 392.1 \n ‑  \n ‑\
    \  \n 392.1 \nSecond City Region Development\n Project \n 73.0 \n 75.0 \n ‑  \n\
    \ 148.0 \nSkills for Employment Investment Program – Tranche 3\n MFF \n ‑  \n\
    \ 150.0 \n ‑  \n 150.0 \nUrban Infrastructure Improvement Preparatory Facility\n\
    \ PRF \n ‑  \n 11.0 \n ‑  \n 11.0 \nDhaka and Western Zone Transmission Grid Expansion\n\
    \ Project \n 300.7 \n ‑  \n ‑  \n 300.7 \nDhaka Mass Rapid Transit Development\
    \ Project Readiness Financing \n(Line 5, Southern Route)\n PRF \n ‑  \n 33.3 \n\
    \ ‑  \n 33.3 \nBhutan\n -  \n 30.0 \n -  \n 30.0 \nFinancial Market Development\
    \ Program (Subprogram 1)\n PBL \n ‑  \n 30.0 \n ‑  \n 30.0 \nIndia\n 3,180.0 \n\
    \ -  \n -  \n 3,180.0 \nMumbai Metro Rail Systems\n Project \n 926.0 \n ‑  \n\
    \ ‑  \n 926.0 \nAssam Urban Infrastructure Investment Program – Tranche 2 \n(Additional\
    \ Financing)\n MFF \n 26.0 \n ‑  \n ‑  \n 26.0 \nChhattisgarh Road Connectivity\n\
    \ Project \n 350.0 \n ‑  \n ‑  \n 350.0 \nMaharashtra Rural Connectivity Improvement\n\
    \ Project \n 200.0 \n ‑  \n ‑  \n 200.0 \nRajasthan State Highway Investment Program\
    \ – Tranche 2\n MFF \n 190.0 \n ‑  \n ‑  \n 190.0 \nKarnataka Integrated and Sustainable\
    \ Water Resources Management \nInvestment Program – Tranche 2\n MFF \n 91.0 \n\
    \ ‑  \n ‑  \n 91.0 \nChennai–Kanyakumari Industrial Corridor: Power Sector Investment\n\
    \ Project \n 451.0 \n ‑  \n ‑  \n 451.0 \nTamil Nadu Urban Flagship Investment\
    \ Program – Tranche 2\n MFF \n 206.0 \n ‑  \n ‑  \n 206.0 \nScaling Up Demand‑Side\
    \ Energy Efficiency Sector\n Project \n 250.0 \n ‑  \n ‑  \n 250.0 \nPublic–Private\
    \ Partnership in Madhya Pradesh Road Sector\n Project \n 490.0 \n ‑  \n ‑  \n\
    \ 490.0 \nMaldives\n -  \n 5.0 \n 5.0 \n 10.0 \nSouth Asia Subregional Economic\
    \ Cooperation National Single Window\n Project \n ‑  \n 5.0 \n 5.0 \n 10.0 \n\
    Nepal\n -  \n 358.0 \n -  \n 358.0 \nBagmati River Basin Improvement – Additional\
    \ Financing\n Project \n ‑  \n 63.0 \n ‑  \n 63.0 \n61\nAPPENDIXES \nAppendix\
    \ 2 continued\ncontinued on next page\nRegion/Country/Loan or Grant Title\nModality\
    \ Regular OCR Concessional OCR\nADF Grant\n Total \nFood Safety and Agriculture\
    \ Commercialization Program\n PBL \n ‑  \n 50.0 \n ‑  \n 50.0 \nRural Enterprise\
    \ Financing\n Project \n ‑  \n 50.0 \n ‑  \n 50.0 \nSouth Asia Subregional Economic\
    \ Cooperation Mugling–Pokhara \nHighway Improvement (Phase 1)\n Project \n ‑ \
    \ \n 195.0 \n ‑  \n 195.0 \nSri Lanka\n 743.0 \n 72.0 \n -  \n 815.0 \nScience\
    \ and Technology Human Resource Development\n Project \n 83.0 \n 62.0 \n ‑  \n\
    \ 145.0 \nSouth Asia Subregional Economic Cooperation Port Access  \nElevated\
    \ Highway\n Project \n 300.0 \n ‑  \n ‑  \n 300.0 \nUrban Project Preparatory\
    \ Facility\n Project \n ‑  \n 10.0 \n ‑  \n 10.0 \nStrengthening the Regional\
    \ Development Bank\n Project \n 50.0 \n ‑  \n ‑  \n 50.0 \nRailway Efficiency\
    \ Improvement\n Project \n 160.0 \n ‑  \n ‑  \n 160.0 \nSecond Integrated Road\
    \ Investment Program – Tranche 2\n MFF \n 150.0 \n ‑  \n ‑  \n 150.0 \nSoutheast\
    \ Asia\n 4,011.1 \n 1,211.6 \n 39.4 \n 5,262.0 \nCambodia\n -  \n 269.3 \n 6.6\
    \ \n 275.8 \nNational Solar Park\n Project \n ‑  \n 7.6 \n ‑  \n 7.6 \nSkills\
    \ for Competitiveness\n Project \n ‑  \n 60.0 \n ‑  \n 60.0 \nInclusive Financial\
    \ Sector Development Program (Subprogram 2)\n PBL \n ‑  \n 40.0 \n ‑  \n 40.0\
    \ \nThird Rural Water Supply and Sanitation Service Sector Development \nProgram\n\
    \ SDP \n ‑  \n 44.6 \n 4.4 \n 49.0 \nIrrigated Agriculture Improvement\n Project\
    \ \n ‑  \n 117.0 \n 2.2 \n 119.2 \nIndonesia\n 1,487.8 \n -  \n -  \n 1,487.8\
    \ \nFinancial Market Development and Inclusion Program (Subprogram 3)\n PBL \n\
    \ 500.0 \n ‑  \n ‑  \n 500.0 \nEmergency Assistance for Rehabilitation and Reconstruction\n\
    \ EAL \n 297.8 \n ‑  \n ‑  \n 297.8 \nFiscal and Public Expenditure Management\
    \ Program (Subprogram 3)\n PBL \n 500.0 \n ‑  \n ‑  \n 500.0 \nState Accountability\
    \ Revitalization – Additional Financing\n Project \n 90.0 \n ‑  \n ‑  \n 90.0\
    \ \nLeveraging Private Infrastructure Investment\n Project \n 100.0 \n ‑  \n ‑\
    \  \n 100.0 \nLao People’s Democratic Republic\n -  \n 135.0 \n 5.0 \n 140.0 \n\
    Education for Employment Sector Development Program\n SDP \n ‑  \n 50.0 \n ‑ \
    \ \n 50.0 \nStrengthening Public Finance Management Program (Subprogram 1)\n PBL\
    \ \n ‑  \n 45.0 \n ‑  \n 45.0 \nSustainable Rural Infrastructure and Watershed\
    \ Management Sector\n Project \n ‑  \n 40.0 \n 5.0 \n 45.0 \nMyanmar\n -  \n 230.4\
    \ \n 15.8 \n 246.2 \nResilient Community Development\n Project \n ‑  \n 185.0\
    \ \n 10.0 \n 195.0 \nRural Roads and Access\n Project \n ‑  \n 45.4 \n 5.8 \n\
    \ 51.2 \nPhilippines\n 2,523.3 \n -  \n -  \n 2,523.3 \nSecondary Education Support\
    \ Program\n RBL \n 300.0 \n ‑  \n ‑  \n 300.0 \nMalolos–Clark Railway – Tranche\
    \ 1\n MFF \n 1,300.0 \n ‑  \n ‑  \n 1,300.0 \nLocal Governance Reform Program\
    \ (Subprogram 1)\n PBL \n 300.0 \n ‑  \n ‑  \n 300.0 \nCapacity Building to Foster\
    \ Competition\n Project \n 23.3 \n ‑  \n ‑  \n 23.3 \nFacilitating Youth School‑to‑Work\
    \ Transition Program (Subprogram 2)\n PBL \n 400.0 \n ‑  \n ‑  \n 400.0 \nInfrastructure\
    \ Preparation and Innovation Facility – Additional Financing\n Project \n 200.0\
    \ \n ‑  \n ‑  \n 200.0 \nViet Nam\n -  \n 577.0 \n 12.0 \n 589.0 \nNorthern Mountain\
    \ Provinces Transport Connectivity\n Project \n ‑  \n 188.4 \n ‑  \n 188.4 \n\
    Financial Sector Development and Inclusion Program (Subprogram 1)\n PBL \n ‑ \
    \ \n 100.0 \n ‑  \n 100.0 \nSecond Greater Mekong Subregion Tourism Infrastructure\
    \  \nfor Inclusive Growth\n Project \n ‑  \n 45.0 \n ‑  \n 45.0 \nLocal Health\
    \ Care Sector Development Program\n SDP \n ‑  \n 88.6 \n 12.0 \n 100.6 \nSecond\
    \ Health Human Resources Development\n Project \n ‑  \n 80.0 \n ‑  \n 80.0 \n\
    Skills and Knowledge for Inclusive Economic Growth\n Project \n ‑  \n 75.0 \n\
    \ ‑  \n 75.0 \nB. NONSOVEREIGN OPERATIONS\n 3,000.1 \n -  \n -  \n 3,000.1 \n\
    Afghanistan\n 4.0 \n -  \n -  \n 4.0 \nKandahar Solar Power\n Loan \n 4.0 \n ‑\
    \  \n ‑  \n 4.0 \nArmenia\n 43.9 \n -  \n -  \n 43.9 \nYerevan Gas‑Fired Combined‑Cycle\
    \ Power\n Loan \n 43.9 \n ‑  \n ‑  \n 43.9 \nBangladesh\n 14.2 \n -  \n -  \n\
    \ 14.2 \nSecond PRAN Agribusiness\n Loan \n 14.2 \n ‑  \n ‑  \n 14.2 \nChina,\
    \ People’s Republic of\n 381.0 \n -  \n -  \n 381.0 \nEco‑Industrial Park Waste‑to‑Energy\n\
    \ Loan \n 100.0 \n ‑  \n ‑  \n 100.0 \nHealth Care Finance in Underdeveloped Provinces\n\
    \ Loan \n 150.0 \n ‑  \n ‑  \n 150.0 \nIndustrial and Municipal Wastewater Treatment\n\
    \ Loan \n 60.7 \n ‑  \n ‑  \n 60.7 \nCDH VGC Fund II, L.P.\n Equity \n 30.0 \n\
    \ ‑  \n ‑  \n 30.0 \nIntegrated and Sustainable Livestock Value Chain\n Loan \n\
    \ 40.2 \n ‑  \n ‑  \n 40.2 \nGeorgia\n 29.1 \n -  \n -  \n 29.1 \nLow‑Income Housing\
    \ Finance\n Loan \n 22.3 \n ‑  \n ‑  \n 22.3 \nHospital Bond\n Debt \nSecurity\
    \ \n 6.8 \n ‑  \n ‑  \n 6.8 \n62\nADB ANNUAL REPORT 2019 \nAppendix 2 continued\n\
    Region/Country/Loan or Grant Title\nModality Regular OCR Concessional OCR\nADF\
    \ Grant\n Total \nIndia\n 965.1 \n -  \n -  \n 965.1 \nAvaada Solar\n Debt \n\
    Security/\nEquity \n 25.0 \n ‑  \n ‑  \n 25.0 \nSupporting Access to Finance for\
    \ Women in Rural Areas\n Debt \nSecurity \n 10.9 \n ‑  \n ‑  \n 10.9 \nRailways\
    \ Track Electrification\n Loan \n 746.2 \n ‑  \n ‑  \n 746.2 \nHighway Equipment\
    \ Finance\n Debt \nSecurity \n 23.0 \n ‑  \n ‑  \n 23.0 \nTata Capital Growth\
    \ Fund II\n Equity \n 10.0 \n ‑  \n ‑  \n 10.0 \nExpanding Micro, Small, Medium‑Sized\
    \ Enterprise Lending\n Debt \nSecurity \n 150.0 \n ‑  \n ‑  \n 150.0 \nIndonesia\n\
    \ 152.9 \n -  \n -  \n 152.9 \nRiau Natural Gas Power\n Loan/\nGuarantee \n 147.9\
    \ \n ‑  \n ‑  \n 147.9 \nHigh‑Value Coconut Processing\n Loan \n 5.0 \n ‑  \n\
    \ ‑  \n 5.0 \nKazakhstan\n 41.2 \n -  \n -  \n 41.2 \nBaikonyr Solar Power\n Loan\
    \ \n 11.5 \n ‑  \n ‑  \n 11.5 \nTotal Eren Access M‑KAT Solar Power\n Loan \n\
    \ 29.7 \n ‑  \n ‑  \n 29.7 \nMongolia\n 47.0 \n -  \n -  \n 47.0 \nSermsang Khushig\
    \ Khundii Solar\n Loan \n 9.6 \n ‑  \n ‑  \n 9.6 \nGender Inclusive Dairy Value\
    \ Chain\n Loan \n 7.4 \n ‑  \n ‑  \n 7.4 \nMicro, Small, and Medium‑Sized Enterprises\
    \ Financing\n Loan \n 30.0 \n ‑  \n ‑  \n 30.0 \nMyanmar\n597.5 \n -  \n -  \n\
    \ 597.5 \nMyingyan Natural Gas Power\n Guarantee \n 97.5 \n ‑  \n ‑  \n 97.5 \n\
    Nationwide Data Connectivity\n Loan \n 500.0 \n ‑  \n ‑  \n 500.0 \nNepal\n 30.0\
    \ \n -  \n -  \n 30.0 \nUpper Trishuli‑1 Hydropower\n Loan \n 30.0 \n ‑  \n ‑\
    \  \n 30.0 \nPakistan\n 15.0 \n -  \n -  \n 15.0 \nExpanding Access to Credit\
    \ for Women\n Loan \n 15.0 \n ‑  \n ‑  \n 15.0 \nPapua New Guinea\n 10.0 \n -\
    \  \n -  \n 10.0 \nSupporting Inclusive Finance through the Development  \nof\
    \ Private Sector Banking\n Equity \n 10.0 \n ‑  \n ‑  \n 10.0 \nPhilippines\n\
    \ 30.0 \n -  \n -  \n 30.0 \nFostering Women’s Empowerment Through Financial Inclusion\
    \  \nin Conflict‑Impacted and Lagging Provinces\n Loan \n 30.0 \n ‑  \n ‑  \n\
    \ 30.0 \nRegional\n 162.5 \n -  \n -  \n 162.5 \nAC Energy Green Bond\n Debt \n\
    Security \n 20.0 \n ‑  \n ‑  \n 20.0 \nTertiary Education\n Equity \n 10.0 \n\
    \ ‑  \n ‑  \n 10.0 \nProposed Additional Capital Contribution Credit Guarantee\
    \  \nand Investment Facility\n Equity \n 50.0 \n ‑  \n ‑  \n 50.0 \nKaizen Private\
    \ Equity II Pte. Ltd.\n Equity \n 5.0 \n ‑  \n ‑  \n 5.0 \nAsia‑Pacific Remote\
    \ Broadband Internet Satellite\n Loan \n 25.0 \n ‑  \n ‑  \n 25.0 \nInclusive\
    \ Beverage Production and Distribution\n Loan \n 12.5 \n ‑  \n ‑  \n 12.5 \nEverbridge\
    \ Partners Fund I, L.P.\n Equity \n 40.0 \n ‑  \n ‑  \n 40.0 \nThailand\n 459.1\
    \ \n -  \n -  \n 459.1 \nBangkok Mass Rapid Transit (Pink and Yellow Lines)\n\
    \ Loan \n 310.9 \n ‑  \n ‑  \n 310.9 \nEnergy Absolute Green Bond for Wind Power\n\
    \ Debt \nSecurity \n 98.2 \n ‑  \n ‑  \n 98.2 \nEastern Economic Corridor Independent\
    \ Power\n Loan \n 50.0 \n ‑  \n ‑  \n 50.0 \nViet Nam\n 17.6 \n -  \n -  \n 17.6\
    \ \nFloating Solar Energy\n Loan \n 17.6 \n ‑  \n ‑  \n 17.6 \nTOTAL\n 17,154.5\
    \ \n 3,644.1 \n 844.1 \n 21,642.7 \nADF = Asian Development Fund, ASEAN = Association\
    \ of Southeast Asian Nations, EAL = emergency assistance loan, MFF = multitranche\
    \ financing facility, OCR = ordinary capital \nresources, PBL = policy‑based lending,\
    \ PDA = project design advance, PRF = project readiness facility, RBL = results‑based\
    \ lending, SDP = sector development program.\nNote: Numbers may not sum precisely\
    \ because of rounding.\n63\nAPPENDIXES \nAppendix 3: Approvals, 2015–2019 ($ million)\n\
    Item\n2015a\n2016a\n2017a\n2018a\n2019\nLoans, Grants, and Others\nBy Source\n\
    Regular Ordinary Capital Resources\n 12,731 \n 13,911 \n 16,584 \n 14,105 \n 16,011\
    \ \nLoans\n 12,256 \n 13,369b\n 15,764c\n 13,342d\n 15,671e \nEquity Investments\n\
    \ 134 \n 27 \n 390 \n 235 \n 290 \nGuarantees\n 291 \n 515 \n 330 \n 78 \n 50\
    \ \nTrade Finance Program\n ‑ \n ‑ \n ‑ \n 350 \n ‑ \nSupply Chain Finance Program\n\
    \ ‑ \n ‑ \n ‑ \n 100 \n ‑ \nMicrofinance Program \n 50 \n ‑ \n 100 \n ‑ \n ‑ \n\
    Concessional Resources\n 2,869 \n 3,066\n 2,267 \n 5,205 \n 3,522 \nLoans\n 2,514\
    \ \n 2,549 \n 1,715 \n4,165 \n 2,679\nGrants\n 355 \n 518 \n 551 \n1,040 \n 843\
    \ \nSpecial Fundsf\n 7 \n 9 \n 2 \n 6 \n ‑ \nGrants\n 7 \n 9 \n 2 \n 6 \n ‑ \n\
    Subtotal\n 15,607 \n 16,986 \n 18,853 \n 19,316 \n 19,532 \nBy Operations\nSovereign\n\
    \ 13,159 \n 14,625 \n 15,799 \n 15,642 \n 17,892 \nLoans\n 12,796 \n 13,598 \n\
    \ 15,246 \n 14,596 \n 17,049 \nGuarantees\n ‑ \n 500 \n ‑ \n ‑ \n‑ \nGrants\n\
    \ 362 \n 527 \n 553 \n1,046\n843\nNonsovereign\n 2,448 \n 2,361 \n 3,054 \n 3,674\
    \ \n 1,641 \nLoans\n 1,973 \n 2,320b\n 2,234c \n 2,911d \n 1,301d\nEquity Investments\n\
    \ 134 \n 27 \n 390 \n 235 \n290 \nGuarantees\n 291 \n 15 \n 330 \n78 \n 50 \n\
    Trade Finance Program\n ‑ \n ‑ \n ‑ \n 350 \n ‑ \nSupply Chain Finance Program\n\
    \ ‑ \n ‑ \n ‑ \n 100 \n ‑ \nMicrofinance Program \n50\n ‑ \n 100 \n ‑ \n ‑ \n\
    Subtotal\n 15,607 \n 16,986 \n 18,853 \n 19,316 \n 19,532 \nTechnical Assistance\n\
    Sovereign\n 135 \n 162 \n 196 \n 200 \n 220 \nNonsovereign\n 5 \n 7 \n 9 \n 15\
    \ \n 17 \nSubtotal\n 141 \n 169 \n 205 \n 215 \n 237 \nCofinancing Including Trust\
    \ Funds\nSovereign\n 6,092 \n 8,110 \n 3,657 \n 6,111 \n 5,538 \nTrust Funds Administered\
    \ by ADB\n 205 \n 399 \n 143 \n 151 \n 168 \nBilateral\n 2,232 \n 3,258 \n 1,899\
    \ \n 1,883 \n 3,711 \nMultilateral\n 3,442 \n 4,140 \n 1,214 \n 3,357 \n 1,657\
    \ \nOthersg\n 213 \n 311 \n 400 \n 720 \n 1 \nNonsovereignh\n 4,568 \n 5,836 \n\
    \ 5,947 \n 7,343 \n 7,274 \nSubtotal\n 10,660 \n 13,947 \n 9,604 \n 13,453 \n\
    \ 12,812 \nTOTAL\n 26,407 \n 31,102 \n 28,663 \n 32,985 \n 32,582 \n‑ = nil.\n\
    Note: Numbers may not sum precisely because of rounding.\na Excludes terminated\
    \ loans, grants, equities, guarantees, and technical assistance.\nb Includes $225\
    \ million classified as debt securities in financial statements in accordance\
    \ with accounting standards.\nc Includes $300 million classified as debt securities\
    \ in financial statements in accordance with accounting standards.\nd Includes\
    \ $20 million classified as debt securities in financial statements in accordance\
    \ with accounting standards.\ne Includes $357 million classified as debt securities\
    \ in financial statements in accordance with accounting standards.\nf \nSpecial\
    \ funds other than Asian Development Fund such as Asia Pacific Disaster Response\
    \ Fund and Climate Change Fund.\ng “Others” includes private sector cofinancing\
    \ through foundations and corporate social responsibility programs, and any public\
    \ source, such as national development banks, that do \nnot fall under official\
    \ cofinancing.\nh Nonsovereign cofinancing includes commercial cofinancing such\
    \ as Trade Finance Program cofinancing, B loans and parallel loans, among others.\n\
    Approvals by Region, 2015–2019 ($ million) \n \n \n \n \n \n \n \n \n \nRegion\n\
    2015\n2016\n2017\n2018\n2019\nCentral and West Asia\n 7,276 \n 8,056 \n 7,517\
    \ \n 5,582 \n 7,781 \nEast Asia\n 3,125 \n 3,065 \n 4,291 \n 3,849 \n 3,118 \n\
    Pacific\n 403 \n 817 \n 532 \n 512 \n 883 \nSouth Asia\n 7,497 \n 7,859 \n 7,809\
    \ \n 10,782 \n 9,118 \nSoutheast Asia\n 7,569 \n 11,110 \n 7,280 \n 11,370 \n\
    \ 10,813 \nRegional\n 537 \n 195 \n 1,234 \n 890 \n 868 \nTOTAL\n 26,407 \n 31,102\
    \ \n 28,663 \n 32,985 \n 32,582 \n64\nADB ANNUAL REPORT 2019 \nAppendix 4: ADB\
    \ Regional and Nonregional Members\n(as of 31 December 2019)\n65\nAPPENDIXES \n\
    Appendix 5: Members, Capital Stock, and Voting Power\n(as of 31 December 2019)\n\
    Year of \nMembership\nSubscribed \nCapitala \n(% of total)\nVoting \nPowerb  \n\
    (% of total)\nREGIONAL\nAfghanistan\n1966\n0.034\n0.321\nArmenia\n2005\n0.298\n\
    0.532\nAustralia\n1966\n5.773\n4.913\nAzerbaijan\n1999\n0.444\n0.649\nBangladesh\n\
    1973\n1.019\n1.109\nBhutan\n1982\n0.006\n0.299\nBrunei Darussalam\n2006\n0.351\n\
    0.575\nCambodia\n1966\n0.049\n0.334\nChina, People’s Republic of \n1986\n6.429\n\
    5.437\nCook Islands\n1976\n0.003\n0.296\nFiji\n1970\n0.068\n0.348\nGeorgia\n2007\n\
    0.341\n0.567\nHong Kong, China\n1969\n0.543\n0.729\nIndia\n1966\n6.317\n5.347\n\
    Indonesia\n1966\n5.434\n4.641\nJapan\n1966\n15.571\n12.751\nKazakhstan\n1994\n\
    0.805\n0.938\nKiribati\n1974\n0.004\n0.297\nKorea, Republic of \n1966\n5.026\n\
    4.315\nKyrgyz Republic\n1994\n0.298\n0.533\nLao People’s Democratic \nRepublic\n\
    1966\n0.014\n0.305\nMalaysia\n1966\n2.717\n2.468\nMaldives\n1978\n0.004\n0.297\n\
    Marshall Islands\n1990\n0.003\n0.296\nMicronesia, Federated  \nStates of \n1990\n\
    0.004\n0.297\nMongolia\n1991\n0.015\n0.306\nMyanmar\n1973\n0.543\n0.729\nNauru\n\
    1991\n0.004\n0.297\nNepal\n1966\n0.147\n0.411\nNew Zealand\n1966\n1.532\n1.520\n\
    Niue\n2019\n0.001\n0.295\nPakistan\n1966\n2.174\n2.033\nPalau\n2003\n0.003\n0.297\n\
    Papua New Guinea\n1971\n0.094\n0.369\nPhilippines\n1966\n2.377\n2.196\nSamoa\n\
    1966\n0.003\n0.297\nSingapore\n1966\n0.340\n0.566\nSolomon Islands\n1973\n0.007\n\
    0.299\nSri Lanka\n1966\n0.579\n0.757\nTaipei,China\n1966\n1.087\n1.164\nTajikistan\n\
    1998\n0.286\n0.523\nThailand\n1966\n1.358\n1.381\nTimor‑Leste\n2002\n0.010\n0.302\n\
    Tonga\n1972\n0.004\n0.297\nTurkmenistan\n2000\n0.253\n0.496\nTuvalu\n1993\n0.001\n\
    0.295\nUzbekistan\n1995\n0.672\n0.832\nVanuatu\n1981\n0.007\n0.299\nViet Nam\n\
    1966\n0.341\n0.567\nSubtotal \n63.390\n65.124\nYear of \nMembership\nSubscribed\
    \ \nCapitala \n(% of total)\nVoting \nPowerb  \n(% of total)\nNONREGIONAL\nAustria\n\
    1966\n0.340\n0.566\nBelgium\n1966\n0.340\n0.566\nCanada\n1966\n5.219\n4.469\n\
    Denmark\n1966\n0.340\n0.566\nFinland\n1966\n0.340\n0.566\nFrance\n1970\n2.322\n\
    2.152\nGermany\n1966\n4.316\n3.747\nIreland\n2006\n0.340\n0.566\nItaly\n1966\n\
    1.803\n1.737\nLuxembourg\n2003\n0.340\n0.566\nThe Netherlands\n1966\n1.023\n1.113\n\
    Norway\n1966\n0.340\n0.566\nPortugal\n2002\n0.340\n0.566\nSpain\n1986\n0.340\n\
    0.566\nSweden\n1966\n0.340\n0.566\nSwitzerland\n1967\n0.582\n0.760\nTurkey\n1991\n\
    0.340\n0.566\nUnited Kingdom\n1966\n2.038\n1.924\nUnited States\n1966\n15.571\n\
    12.751\nSubtotal \n36.610\n34.876\nTOTAL\n100.000\n100.000\nNotes: Numbers may\
    \ not sum precisely because of rounding. For other details, see \ntable on Statement\
    \ of Subscriptions to Capital Stock and Voting Power (OCR‑8) in the \nFinancial\
    \ Statements of Annual Report 2019.\na  Subscribed capital refers to a member’s\
    \ subscription to shares of the capital stock  \nof ADB.\nb  The total voting\
    \ power of each member consists of the sum of its basic votes and  \nproportional\
    \ votes. The basic votes of each member consist of such number of votes \nas results\
    \ from the equal distribution among all members of 20% of the aggregate sum \n\
    of the basic votes and proportional votes of all members. The number of proportional\
    \ \nvotes of each member is equal to the number of shares of the capital stock\
    \ of ADB \nheld by that member.\n66\nADB ANNUAL REPORT 2019 \nPRELIMINARY DATA\n\
    Appendix 6: Contributions to Asian Development Fund ($ million)\nContributor\n\
    Cumulative\nEffective Amounts  \nCommitteda\nof which,\nADF XI (2013–2016)\nof\
    \ which,\nADF 12 (2017–2020)b\nAustralia\n2,668 \n589 \n276 \nAustria\n294 \n\
    40 \n19 \nBelgium\n244 \n32 \n‑ \nBrunei Darussalam\n21 \n6 \n0 \nCanada\n2,035\
    \ \n179 \n84 \nChina, People’s Republic of \n183 \n41 \n82 \nDenmark\n265 \n23\
    \ \n11 \nFinland\n201 \n27 \n11 \nFrance\n1,410 \n119 \n47 \nGermany\n1,933 \n\
    179 \n71 \nHong Kong, China\n123 \n31 \n14 \nIndia\n64 \n30 \n34 \nIndonesia\n\
    26 \n‑ \n12 \nIreland\n107 \n25 \n12 \nItaly\n1,193 \n85 \n40 \nJapan\n12,888\
    \ \n1,875 \n929 \nKazakhstan\n8 \n5 \n3 \nKorea, Republic of\n643 \n155 \n73 \n\
    Luxembourg\n60 \n10 \n7 \nMalaysia\n33 \n9 \n4 \nNauru\n0 \n‑\n‑\nThe Netherlands\n\
    774 \n75 \n13 \nNew Zealand\n187 \n30 \n13 \nNorway\n310 \n47 \n22 \nPortugal\n\
    92 \n0 \n0 \nSingapore\n25 \n8 \n4 \nSpain\n482 \n62 \n6 \nSweden\n490 \n73 \n\
    20 \nSwitzerland\n405 \n49 \n23 \nTaipei,China\n115 \n21 \n10 \nThailand\n19 \n\
    4 \n2 \nTurkey\n124 \n5 \n2 \nUnited Kingdom\n1,692 \n290 \n136 \nUnited States\n\
    4,677 \n331 \n155 \nTOTAL\n33,793 \n4,455 \n2,133 \n‑ = nil, 0 = less than $0.5\
    \ million, ADF = Asian Development Fund.\nNote: Numbers may not sum precisely\
    \ because of rounding. \na Valued at Board of Governors’ Resolutions exchange\
    \ rates. Based on submitted and acknowledged instruments of contribution of ADF\
    \ I to ADF 12 as of 31 December 2019. \nIncludes the proportionate share of ADF\
    \ donors in the transferred assets as of 1 January 2017 of $29,309 million and\
    \ excludes the allocation to the Technical Assistance \nSpecial Fund of $1,612\
    \ million. \nb Following the combination of certain ADF assets with the ordinary\
    \ capital resources and retaining the ADF as a grant‑only operation beginning\
    \ 1 January 2017, there was a \nreduction of 52% in donor contributions for ADF\
    \ 12 as compared with ADF XI. \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n\
    \  \n \n \n \n \n \n \n \n67\nAPPENDIXES \nAppendix 7A: 2019 Project-Specific\
    \ Sovereign Cofinancing Commitments \n($ million)\nFinancing Partner\nLoans\n\
    \ Grants \nTA\nBilaterals\n Australia \n ‑ \n 49 \n 34 \n France \n 115 \n ‑ \n\
    \ ‑ \n Germany \n 892 \n ‑ \n 0 \n Japan  \n 2,354 \n ‑ \n ‑ \n Korea, Republic\
    \ of \n 140 \n ‑ \n 1 \n New Zealand \n ‑ \n 2 \n 3 \n Norway \n ‑ \n ‑ \n 0 \n\
    \ Switzerland \n ‑ \n 2 \n 0 \n United States \n ‑ \n ‑ \n 1 \nSubtotal - Bilaterals\n\
    \ 3,500 \n 53 \n 40 \nMultilateral\n Asian Infrastructure Investment Bank \n 200\
    \ \n ‑ \n ‑ \n Climate Investment Fund \n 57 \n 3 \n 4 \n European Bank for Reconstruction\
    \ and Development \n 300 \n ‑ \n ‑ \n European Union \n ‑ \n 29 \n ‑ \n Global\
    \ Agriculture and Food Security Program \n ‑ \n ‑ \n 1 \n Global Environment Facility\
    \ \n ‑ \n ‑ \n 11 \n Green Climate Fund \n 95 \n 30 \n ‑ \n New Development Bank\
    \ \n 260 \n ‑ \n ‑ \n OPEC Fund for International Development \n 40 \n ‑ \n ‑\
    \ \n United Nations Development Programme \n ‑ \n ‑ \n 0 \n Women Entrepreneurs\
    \ Finance Initiative \n ‑ \n ‑ \n 6 \n World Bank \n 64 \n 13 \n ‑ \n Subtotal\
    \ - Multilaterals \n 1,016 \n 74 \n 22 \n Private Partners \nJP Morgan Chase Foundation\n\
    \ ‑ \n ‑ \n 1 \nSubtotal - Private Partners\n ‑ \n ‑ \n 1 \nTotal\n 4,516 \n 127\
    \ \n 63 \n0 = less than $1 million, TA = technical assistance. \nNote: Totals\
    \ may not add up due to rounding.\n68\nADB ANNUAL REPORT 2019 \ncontinued on next\
    \ page\nPRELIMINARY DATA\nAppendix 7B: Active Trust Funds and Special Funds  \n\
    ($ million)\nFund Name\nPartner(s)\nYear of  \nEstablishment\nContributions \n\
    for 2019b\nCumulative  \nContribution as of  \n31 December \n2019c\nUncommitted\
    \ \nBalance as of           \n31 December \n2019d\nCommitted \n(Signed \nAgreements)\
    \ \nfor 2019\nSingle Partner Trust Fundsh\nJapan Scholarship Programg\nJapan\n\
    1988\n 4.3 \n 186.6 \n 7.4 \n NA \nAustralian Technical Assistance Grant\nAustralia\n\
    1993\n ‑ \n 61.4 \n 3.7 \n ‑ \nJapan Fund for Poverty Reductiong\nJapan\n2000\n\
    \ 17.8 \n 832.0 \n 105.4 \n 37.8 \nSpanish Cooperation Fund for \nTechnical Assistanceg\n\
    Spain\n2000\n 1.7 \n 14.4 \n 4.1 \n ‑ \nJapan Fund for Information and \nCommunication\
    \ Technologyg\nJapan\n2001\n ‑ \n 10.7 \n 2.0 \n 0.8 \nCooperation Fund for Project\
    \ \nPreparation in the Greater Mekong \nSubregion and in Other Specific \nAsian\
    \ Countriesg\nFrance\n2004\n 1.1 \n 7.4 \n 1.7 \n 0.5 \nJapan Fund for Public\
    \ Policy Trainingg\nJapan\n2004\n ‑ \n 22.0 \n 7.5 \n ‑ \nPeople’s Republic of\
    \ China \nPoverty Reduction and Regional \nCooperation Fundg\nPeople’s Republic\
    \ of China\n2005\n ‑ \n 90.0 \n 36.3 \n 7.2 \nRepublic of Korea e‑Asia and \n\
    Knowledge Partnership Fundg\nRepublic of Korea\n2006\n 16.6 \n 118.8 \n 52.9 \n\
    \ 8.0 \nNetherlands Trust Fund under Water \nFinancing Partnership Facilityg\n\
    Netherlands\n2006\n ‑ \n 44.2 \n 6.2 \n 1.8 \nAsian Clean Energy Fund under Clean\
    \ \nEnergy Financing Partnership \nFacilityg\nJapan\n2008\n ‑ \n 55.7 \n 10.6\
    \ \n 2.0 \nInvestment Climate Facilitation Fund \nunder Regional Cooperation and\
    \ \nIntegration Financing Partnership \nFacilityg\nJapan\n2008\n ‑ \n 31.5 \n\
    \ 8.1 \n 1.5 \nCanadian Climate Fund for the \nPrivate Sector in Asia under Clean\
    \ \nEnergy Financing Partnership \nFacilityg\nCanada\n2013\n 80.7 \n 8.1 \n 11.8\
    \ \nSanitation Financing Partnership \nTrust Fund under Water Financing \nPartnership\
    \ Facilityg\nBill and Melinda Gates \nFoundation\n2013\n 3.0 \n 19.0 \n 2.0 \n\
    \ 4.1 \nJapan Fund for the Joint Crediting \nMechanismg\nJapan\n2014\n 9.2 \n\
    \ 71.1 \n 39.5 \n 3.5 \nLeading Asia’s Private Sector \nInfrastructure Fund \n\
    Japan\n2016\n 109.0 \n 419.7e \n NA \n 138.5 \nCanadian Climate Fund for the \n\
    Private Sector in Asia IIg\nCanada\n2017\n 16.2f \n 126.9e \n 58.2 \n 37.9 \n\
    United Kingdom Fund for Asia \nRegional Trade and Connectivityg\nUnited Kingdom\n\
    2018\n ‑ \n 27.9 \n 14.9 \n 9.2 \nASEAN Australia Smart Cities  \nTrust Fundg\n\
    Australia\n2019\n 15.1 \n 15.1 \n 4.5 \n 10.0 \nIreland Trust Fund for Building\
    \ \nClimate Change and Disaster \nResilience in Small Island \nDeveloping Stateg\n\
    Ireland\n2019\n 13.4 \n 13.4 \n 13.3 \n ‑ \nMulti-Partner Trust Fundsh\nMulti‑Donor\
    \ Trust Fund under Water \nFinancing Partnership Facilityg\nAustralia, Austria,\
    \ Norway, \nSpain, Switzerland\n2006\n 0.7 \n 52.4 \n 0.6 \n 1.6 \nClean Energy\
    \ Fund under Clean \nEnergy Financing Partnership \nFacilityg\nAustralia, Norway,\
    \ Spain, \nSweden, United Kingdom\n2007\n 20.8 \n 131.0 \n 39.4 \n 5.9 \nFuture\
    \ Carbon Fundg\nBelgium, ENECO Energy \nTrade, Finland, Republic of \nKorea, POSCO,\
    \ Sweden\n2008\n ‑ \n 82.0 \n 72.5 \n ‑ \nCarbon Capture and Storage Fund \nunder\
    \ Clean Energy Financing \nPartnership Facilityg\nAustralia, United Kingdom\n\
    2009\n ‑ \n 64.9 \n 45.4 \n 4.3 \n69\nAPPENDIXES \nAppendix 7B continued\nFund\
    \ Name\nPartner(s)\nYear of  \nEstablishment\nContributions \nfor 2019b\nCumulative\
    \  \nContribution as of  \n31 December \n2019c\nUncommitted \nBalance as of  \
    \         \n31 December \n2019d\nCommitted \n(Signed \nAgreements) \nfor 2019\n\
    Afghanistan Infrastructure Trust Fund\nANA Trust Fund, Japan, \nGermany, United\
    \ \nKingdom, United States\n2010\n 93.0 \n 740.5 \n 305.3 \n ‑ \nCredit Guarantee\
    \ Investment Facility\nADB, Brunei Darussalam, \nCambodia, Indonesia, \nJapan,\
    \ Republic of Korea, \nLao People’s Democratic \nRepublic, Malaysia, \nMyanmar,\
    \ People’s \nRepublic of China, \nPhilippines, Singapore, \nThailand, Viet Nam\n\
    2010\n 50.8 \n 1,149.0 \n NA \n ‑ \nUrban Climate Change Resilience \nTrust Fund\
    \ under Urban Financing \nPartnership Facilityg\nRockefeller Foundation, \nSwitzerland,\
    \ United \nKingdom, \n2013\n ‑ \n 140.5 \n 20.0 \n 23.3 \nAsia Pacific Project\
    \ Preparation \nFacilityg\nAustralia, Canada, Japan\n2014\n 10.2 \n 63.3 \n (1.3)\n\
    \ 45.0 \nDomestic Resource Mobilization \nTrust Fundg\nJapan\n2017\n 1.8 \n 5.7\
    \ \n 3.1 \n ‑ \nHigh Level Technology Fundg\nJapan\n2017\n 15.2 \n 54.5 \n 28.9\
    \ \n 12.1 \nAsia Pacific Climate Finance Fundg\nGermany\n2017\n ‑ \n 32.0 \n 32.1\
    \ \n ‑ \nCities Development Initiative for Asia \nTrust Fundg\nAustria, Germany,\
    \ \nSwitzerland\n2017\n 2.8 \n 9.1 \n 4.3 \n 4.6 \nSpecial Fundsa\nJapan Special\
    \ Fund \nJapan\n1988\n ‑ \n 1,124.7 \n 111.8 \n ‑ \nADB Institute\nADB, Australia,\
    \ Indonesia, \nJapan, Republic of Korea, \nPeople’s Republic of China\n1996\n\
    \ 15.8 \n 298.0 \n 18.8 \n NA \nRegional Cooperation and \nInfrastructure Fund\
    \ \nADB, Japan\n2007\n ‑ \n 69.6 \n 4.9 \n 5.6 \nFinancial Sector Development\
    \ \nPartnership Special Fund \nADB, Luxembourg\n2013\n 4.7 \n 21.0 \n 4.6 \n 4.6\
    \ \n‑ = nil, 0.0 = less than $50,000; NA = not applicable\nNote:  \na  Special\
    \ funds (except the Japan Special Fund) get contributions from ADB through transfers\
    \ from ordinary capital resources.  The list of special funds excludes Asian Development\
    \ \nFund (ADF), Technical Assistance Special Fund (TASF), Climate Change Fund,\
    \ and Asia Pacific Disaster Response Fund.  Contributions to the ADF are presented\
    \ in Appendix 6.  \nContributions to the TASF are made through direct and voluntary\
    \ contributions from members and through allocations from the ADF replenishments.\
    \  Finally, no external partners \ncontribute to the Climate Change Fund and Asia\
    \ Pacific Disaster Response Fund.\nb Contributions for 2019 include only additional\
    \ and new commitments made during the year revalued at reporting date, as applicable.\n\
    c Cumulative Contribution as of 31 December 2019 is net of cancellation of the\
    \ commitments, if any, and revalued at reporting date, as applicable.\nd Represents\
    \ balances available for new projects; excludes funding request allocations by\
    \ fund managers not yet approved by ADB. Amount is inclusive of contribution receivable,\
    \  \nif any, and revalued at reporting date, as applicable.\ne Represents actual\
    \ amount remitted from partner.\nf Represents Can$170 million actual amount remitted\
    \ from partner.\ng Trust funds with balances for new project/initiatives. \nh\
    \ Excludes the following active trust funds with no contribution for 2019 and\
    \ less than $1 million uncommitted balance as of 31 December 2019: Canadian Cooperation\
    \ Fund on \nClimate Change, Cooperation Fund for Regional Trade and Financial\
    \ Security Initiative, Cooperation Fund in Support of Managing for Development\
    \  Results, Denmark Cooperation \nFund for Renewable Energy and Energy Efficiency\
    \ in Rural Areas, Financial Sector Development Partnership Fund, Gender and Development\
    \ Cooperation Fund, Governance \nCooperation Fund, Integrated Disaster Risk Management\
    \ Fund, Project Readiness Improvement Trust Fund, Regional Malaria and other Communicable\
    \ Disease Threats Trust Fund \nunder Health Financing Partnership Facility, Technical\
    \ Assistance Grant Fund (France), and Urban Environmental Infrastructure Fund\
    \ under Urban Financing Partnership Facility.\n71\n70\nADB ANNUAL REPORT 2019\
    \ \nAPPENDIXES \nAppendix 8A: Organizational Structure1\n(as of 31 December 2019)\n\
    1 To contact ADB Management and senior staff, go to http://www.adb.org/contacts/management‑senior‑staff.\n\
    2 The Compliance Review Panel reports to the Board of Directors.\n3 The Independent\
    \ Evaluation Department reports to the Board of Directors through the Development\
    \ Effectiveness Committee.\nBOARD OF GOVERNORS\nBOARD OF DIRECTORS\nINDEPENDENT\
    \ EVALUATION DEPARTMENT3\nM. Taylor-Dormond, Director General\nOFFICE OF THE COMPLIANCE\
    \ REVIEW PANEL2\nE. Gozun, Chair\nPRESIDENT\nT. Nakao\nSPECIAL SENIOR ADVISORS\
    \ TO THE PRESIDENT\nA. Konishi\nX. Yao\nASIAN DEVELOPMENT\nBANK INSTITUTE\nN.\
    \ Yoshino, Dean \nOFFICE OF\nANTICORRUPTION\nAND INTEGRITY\nJ. Versantvoort, Head\
    \  \nOFFICE OF\nTHE AUDITOR GENERAL\nH. Ong, Auditor General  \nOFFICE OF \nTHE\
    \ OMBUDSPERSON\nW. Blair, Ombudsperson\nOFFICE OF \nPROFESSIONAL CONDUCT\n(Vacant)\n\
    OFFICE OF \nTHE SPECIAL PROJECT \nFACILITATOR\nW. Evans, Special Project Facilitator\n\
    STRATEGY, POLICY, AND \nPARTNERSHIPS DEPARTMENT\nT. Kimura, Director General\n\
    VICE-PRESIDENT\n(Knowledge Management \nand Sustainable Development)\nB. Susantono\n\
    DEPARTMENT OF  \nCOMMUNICATIONS \nV. Tan, Principal Director\nSUSTAINABLE DEVELOPMENT\
    \ \nAND CLIMATE CHANGE \nDEPARTMENT\nW. Um, Director General\nECONOMIC RESEARCH\
    \ AND \nREGIONAL COOPERATION \nDEPARTMENT\nY. Sawada, Chief Economist \nand Director\
    \ General\nVICE-PRESIDENT\n(Private Sector Operations and \nPublic–Private Partnerships)\n\
    D. Gupta\nPRIVATE SECTOR OPERATIONS\nDEPARTMENT\nM. Barrow, Director General\n\
    OFFICE OF PUBLIC–PRIVATE \nPARTNERSHIPS\nY. Morishita, Head\n \n \nOFFICE OF THE\
    \ SECRETARY\nE. Zhukov, The Secretary\n \n \n \n \nVICE-PRESIDENT\n(Administration\
    \ and \nCorporate Management)\nD. Stokes\nOFFICE OF \nADMINISTRATIVE SERVICES\n\
    C. L. Menon, Principal Director\nOFFICE OF THE \nGENERAL COUNSEL\nR. Nagpal, OIC\
    \ General Counsel\nBUDGET, PERSONNEL, AND \nMANAGEMENT SYSTEMS \nDEPARTMENT\n\
    Y. Takamura, Director General \nPROCUREMENT, PORTFOLIO \nAND FINANCIAL MANAGEMENT\
    \ \nDEPARTMENT\nR. Z. Teng, Director General\nOFFICE OF INFORMATION \nSYSTEMS\
    \  AND TECHNOLOGY\nS. Hamid, Principal Director\nVICE-PRESIDENT\n(Finance and\
    \ Risk Management)\nI. van Wees\nOFFICE OF RISK MANAGEMENT\nA. Agha, Head\nTREASURY\
    \ DEPARTMENT\nP. Van Peteghem, Treasurer\nCONTROLLER’S DEPARTMENT\nC. Kim, Controller\n\
    VICE-PRESIDENT\n(Operations 1)\nS. Chen\nSOUTH ASIA \nDEPARTMENT\nH. Kim, Director\
    \ General\nCENTRAL AND WEST ASIA\nDEPARTMENT\nW. Liepach, Director General\n \n\
    \ \n \nVICE-PRESIDENT\n(Operations 2)\nA. Saeed\nEAST ASIA DEPARTMENT \nA. Leung,\
    \ Director General\nPACIFIC DEPARTMENT\nC. Locsin, Director General\nSOUTHEAST\
    \ ASIA  \nDEPARTMENT\nR. Subramaniam, Director General\n72\nADB ANNUAL REPORT\
    \ 2019 \nAppendix 8B: ADB Sector and Thematic Groups\n(as of 31 December 2019)\n\
    \ \nTHEMATIC\n \n \nWATER\nT. Panella \nChief of Water \nSector Group\nEDUCATION\n\
    B. Panth\nChief of Education \nSector Group \nENERGY\nY. Zhai\nChief of Energy\n\
    Sector Group\nFINANCE\nJ. Lee\nChief of Finance \nSector Group\nHEALTH\nP. Osewe\
    \ \nChief of Health \nSector Group\n \nTRANSPORT\nJ. Leather \nChief of Transport\
    \ \nSector Group\nURBAN\nM. Sharma \nChief of Urban \nSector Group\nCLIMATE \n\
    CHANGE AND  \nDISASTER RISK \nMANAGEMENT \nP. Bhandari \nChief of Climate \nChange\
    \ and \nDisaster Risk \nManagement \nThematic Group\nENVIRONMENT\nB. Dunn\nOIC,\
    \ Environment \nThematic Group\nGENDER \nEQUITY\nS. Tanaka \nChief of Gender \n\
    Equity Thematic \nGroup\nGOVERNANCE \nAND PUBLIC \nMANAGEMENT\nB. Carrasco \n\
    Chief of Governance \nThematic Group \nPUBLIC–PRIVATE \nPARTNERSHIP\nS. Sampath\n\
    Chief of \nPublic–Private\nPartnership \nThematic Group\nREGIONAL \nCOOPERATION\
    \ \nAND \nINTEGRATION\nA. Goswami\nChief of Regional \nCooperation and \nIntegration\
    \ \nThematic Group\nRURAL \nDEVELOPMENT \nAND FOOD \nSECURITY \n(Agriculture)\n\
    A. Siddiq\nChief of Rural \nDevelopment and \nFood Security \nThematic Group\n\
    SOCIAL \nDEVELOPMENT\nW. Walker\nChief of Social \nDevelopment \nThematic Group\
    \ \nSECTOR\n73\nAPPENDIXES \nAppendix 9: ADB Corporate Reports\nA. Key Corporate\
    \ Overview Reports\n• Development Effectiveness Review \n• Development Effectiveness\
    \ Report (Private Sector \nOperations) \n• ADB Sustainability Report \n• Annual\
    \ Evaluation Review\nB. Board Committee Reports\n• Annual Report of the Audit\
    \ Committee of the Board, \n2018‑2019\n• Annual Report of the Human Resources\
    \ Committee, \n2018‑2019\nC. Treasury, Finance, and Risk Management\n• 2019 Information\
    \ Statement\nD. Operations\n1. Overview of ADB Operations\n• Statement of the\
    \ Asian Development Bank’s \nOperations \n• ADB Projects and Tenders: Project\
    \ Data Sheets for \nLoans, Grants, Technical Assistance \n2. Portfolio Reports\n\
    • Annual Portfolio Performance Report\n• Quarterly Portfolio Updates \n3. Country\
    \ Operations\n• ADB Members Fact Sheets \n• Report on the Country Performance\
    \ Assessment \nExercise \n4. Partnership Reports\n• Partnering for Development:\
    \ Annual Donors’ Report \n• Annual Report of ADB–Japan Scholarship Program\n•\
    \ Japan Fund for Poverty Reduction Annual Report \n• People’s Republic of China\
    \ Regional Cooperation \nand Poverty Reduction Fund: Annual Report \n• Clean Energy\
    \ Financing Partnership Facility Annual \nReport \n• Annual Report of the e‑Asia\
    \ and Knowledge \nPartnership Fund \n• Financial Sector Development Partnership\
    \ Special \nFund Annual Report \n• Future Carbon Fund (print only)\n• Gender and\
    \ Development Cooperation Fund \nProgress Report \n• Japan Fund for Joint Crediting\
    \ Mechanism (print \nonly) \n• Urban Financing Partnership Facility Annual Report\
    \ \n• Water Financing Partnership Facility Annual Report \nand Semiannual Progress\
    \ Report \n• High‑Level Technology Fund Annual Progress \nReport (print only)\n\
    E. Planning and Budget\n• Work Program and Budget Framework \n• Budget of the\
    \ Asian Development Bank \nF. Accountability\n• ADB Accountability Mechanism Annual\
    \ Report \n• Learning Report on the Implementation of the \nAccountability Mechanism\
    \ Policy\nG. Key Economic and Financial Research\n• Asian Development Outlook\
    \ \n• Asia Bond Monitor \n• Key Indicators for Asia and the Pacific \n• Basic\
    \ Statistics \n• Asian Economic Integration Report \n• Asian Development Review\
    \ \n• ADB Economics Working Papers \n• Aid for Trade in Asia and the Pacific:\
    \ Promoting \nEconomic Diversification and Empowerment\nH. ADB Institute\n• ADBI\
    \ Three‑Year Rolling Work Program and Budget\n• ADBI Working Papers\n• ADBI Policy\
    \ Briefs \nI. Other Reports\n• Office of Anticorruption and Integrity (OAI): Annual\
    \ \nReport \n• Highlights of the ADB Annual Meeting \n• Highlights of ADB’s Cooperation\
    \ with Civil Society \nOrganizations \n74\nADB ANNUAL REPORT 2019 \nAppendix 10:\
    \ Operational Data and Organizational Information as of 31 December 2019 \nThe\
    \ tables and other information listed below are available for download in PDF\
    \ and XLS format from  \nhttps://www.adb.org/documents/adb‑annual‑report‑2019\n\
    Operational Data \n1 \nTotal ADB Operations by Sector and by Region, 2019 \n2\
    \ \nSovereign Commitments, 2019 \n3 \nNonsovereign Commitments, 2019 \n4 \nCommitments\
    \ by Modality, 2018–2019 \n5 \nSovereign and Nonsovereign Commitments, 2018–2019\
    \ \n6 \nSectoral Distribution (Sovereign and Nonsovereign Commitments \nIncluding\
    \ Cofinancing), 2018–2019\n7 \nNonsovereign Commitments by Year, 2007–2019 \n\
    8 \nNonsovereign Commitments by Developing Member Country,  \n2007–2019 \n9 \n\
    Top Recipients by Commitments Including Cofinancing, 2019 \n10 Top Recipients\
    \ by Commitments Excluding Cofinancing, 2019 \n11 \nNonsovereign Commitments by\
    \ Top Countries, Ordinary Capital \nResources, 2018–2019 \n12 Projects Involving\
    \ Commercial Cofinancing \n13 Technical Assistance Commitments, 2019 \n14 Technical\
    \ Assistance Grant Commitments, 2019 \n15 Amount of Loans and Grants Made Effective,\
    \ Contracts Awarded,  \nand Disbursements \n16 Number of Projects Under Administration,\
    \ Actual Problem, Completed, \nand PCRs/XARRs/PPERs Circulated \n17 Net Transfer\
    \ of Resources (Ordinary Capital Resources, Asian \nDevelopment Fund, and Other\
    \ Special Funds Grants), 2018–2019\n18 Evaluation Results for Sovereign Operations\
    \ by Developing Member \nCountry by PCR Year, 2009–2019 \n19 Evaluation Results\
    \ for Sovereign Operations by Sector by PCR Year, \n2009–2019 \n20 Evaluation\
    \ Results for Nonsovereign Operations by Developing Member \nCountry by Evaluation\
    \ Year, 2009–2019 \n21 Evaluation Results for Nonsovereign Operations by Sector\
    \ by Evaluation \nYear, 2009–2019 \n22 Cofinancing Arrangements, 2018–2019 (Volume)\
    \ \n23 Cofinancing Arrangements, 2018–2019 (Number of Projects) \n24 Projects\
    \ Involving Sovereign Cofinancing, 2019 \n25 Projects Involving Sovereign Grant\
    \ Cofinancing, 2019\n26 Overall Procurement of Goods, Works, and Consulting Services,\
    \ 2019 \nProject/Program Loans, Grants, and Technical Assistance Operations \n\
    Combined, By Origin of Goods and Services \n27 Overall Procurement of Goods, Works,\
    \ and Consulting Services, 2019 \nProject/Program Loans, Grants, and Technical\
    \ Assistance Operations \nCombined, By ADB Member \n28 Cumulative Contracts Awarded\
    \ by Origin of Goods and  \nServices as of 31 December 2019, Loans, Grants, and\
    \ Technical \nAssistance Operations \n29 Cumulative Contracts Awarded by ADB Members\
    \ as of 31 December \n2019, Loans, Grants, and Technical Assistance Operations\
    \ \n30 ADF‑Contributed Resources \n31 Japan Special Fund—Regular and Supplementary\
    \ Contributions \n32 Japan Special Fund—Asian Currency Crisis Support Facility\
    \ \nOrganizational Information  \n1 \nMembers, Capital Stock, and Voting Power\
    \ \n2 \nResolutions of the Board of Governors Adopted in 2019 \n3 \nSelected Policy,\
    \ Strategy, and Financial Papers Discussed by the Board \nin 2019\n4 \nBoard of\
    \ Governors \n5 \nBoard of Directors and Voting Groups \n6 \nCommittees of the\
    \ Board of Directors \n7 \nADB Institute Advisory Council \n8 \nOrganizational\
    \ Structure  \n9 \nSummary of Internal Administrative Expenses—2018 and Budget\
    \  \nfor 2019\n10 2019 Annual Base Salary of the Board of Directors and \nManagement\
    \ \n11 \nStaff Representation of ADB Members \n12 Number of Authorized Positions\
    \ in Resident Missions \n13 Growth in Resident Missions and Assigned Staff Positions\
    \ at Resident \nMissions\nACKNOWLEDGMENTS\nBoard of Directors Working Group on\
    \ the Annual Report 2019 Scott Dawson (Chair), Jason Chung, Enrique Galan, \n\
    Bayrammuhammet Garayev, Jin Lu, Yu‑Peng (James) Tseng • Publisher Vicky C.L. Tan\
    \ • Managing Editor (Print and \nDigital) Sarah O’Connor • Copyediting Paul Dent\
    \ • Proofreading Anima Slangen, Kae Sugawara • Art Director Anthony \nVictoria\
    \ • Design and Information Graphics Cleone Baradas • Typesetting Edith Creus,\
    \ Prince Nicdao • Programming \nand Design (Digital) Christopher Charleson \n\
    The Board of Directors Working Group on the Annual Report 2019 would like to thank\
    \ all ADB departments and offices for \ntheir significant contributions to this\
    \ report. \nEvery effort has been made to ensure the accuracy of the data used\
    \ in this publication. Variations in data in ADB \npublications often result from\
    \ different publication dates, although differences may also come from the source\
    \ and \ninterpretation of data. ADB accepts no responsibility from any consequence\
    \ of their use. \nBy making any designation of or reference to a particular territory\
    \ or geographical area, or by using the term “country” in \nthis document, ADB\
    \ does not intend to make any judgments as to the legal or other status of any\
    \ territory or area. \nIn this publication, “$” refers to United States dollars,\
    \ unless otherwise stated. ADB recognizes “China” as the  \nPeople’s Republic\
    \ of China; “Hong Kong” as Hong Kong, China; and “Korea” as the Republic of Korea.\
    \ \n©2020 Asian Development Bank \nISBN 978‑92‑9262‑176‑6 (print), 978‑92‑9262‑177‑3\
    \ (electronic), 978‑92‑9262‑178‑0 (ebook) \nISSN 0116‑1164 (print) \nPublication\
    \ Stock No. FLS200124 \nDOI: http://dx.doi.org/10.22617/FLS200124 \n \nAsian Development\
    \ Bank\n6 ADB Avenue, Mandaluyong City\n1550 Metro Manila, Philippines\nadbpub@adb.org\n\
    www.adb.org\nSubscriptions to ADB’s Annual Report are available to reference libraries\
    \ and institutions. \nTo subscribe, e‑mail adbpubs@adb.org\nAll photos by ADB\
    \ unless otherwise indicated.\nCOVER: ADB‑supported projects (in order of appearance)\
    \ in Mongolia (Sermsang Khushig Khundii Solar Project), \nKazakhstan (RG Brands\
    \ Agribusiness Project), Fiji (Fiji Ports Development Project); Row 2: Tajikistan\
    \ (Maternal and \nChild Health Integrated Care Project), Lao People’s Democratic\
    \ Republic (Results for Malaria Elimination and Control of \nCommunicable Disease\
    \ Threats in Asia and the Pacific); Row 3: India (West Bengal Drinking Water Sector\
    \ Improvement \nProject), Bangladesh (Chittagong Hill Tracts Rural Development\
    \ Project); Row 4: the People’s Republic of China (Hubei‑\nYichang Sustainable\
    \ Urban Transport Project), Nauru (Improving Internet Connectivity for Micronesia\
    \ Project), and the \nPhilippines (Fisheries Resource Management Project).\nFinancial\
    \ statements incorporated by reference. Management’s Discussion and Analysis and\
    \ the Annual \nFinancial Statements of the Asian Development Bank shall be deemed\
    \ to be incorporated in and to form part \nof this Annual Report. The Financial\
    \ Report, organizational information, and operational data are available at \n\
    https://www.adb.org/documents/adb‑annual‑report‑2019 and via the QR code on this\
    \ page.\nOur strategy for the next decade is guided by a vision of \na prosperous,\
    \ inclusive, resilient, and sustainable Asia \nand the Pacific. Our immediate\
    \ priority is to provide vital \nsupport to our developing members as they address\
    \ the \nchallenges presented by COVID-19 and seek to return their \neconomies\
    \ to a path of growth and prosperity. \n- Masatsugu Asakawa, ADB President\n"
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: https://www.adb.org/sites/default/files/institutional-document/650011/adb-annual-report-2019.pdf
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 2019 Asian Development Bank Annual Report
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.36227/techrxiv.19642977
  analysis: '>'
  authors:
  - Chintan Patel
  - Shubham Vyas
  - Pallabi Saikia
  - Denish kalariya
  - naman parmar
  citation_count: 0
  full_citation: '>'
  full_text: '>

    LOG IN SIGN UP TechRxiv 9,172,904 views 4,235,710 downloads About TechRxiv TechRxiv
    (pronounced "tech archive") is an open, moderated preprint server for unpublished
    research in the areas of engineering, computer science, and related technology.
    https://www.techrxiv.org/ Public Documents 9174 Members by author by title by
    keyword Filter All Sort by Most Recent BIOENGINEERING 871 COMMUNICATION, NETWORKING
    AND BROADCAST TECHNOLOGIES 2284 COMPONENTS, CIRCUITS, DEVICES AND SYSTEMS 1068
    COMPUTING AND PROCESSING 3373 ENGINEERED MATERIALS, DIELECTRICS AND PLASMAS 248
    ENGINEERING PROFESSION 543 FIELDS, WAVES AND ELECTROMAGNETICS 853 GENERAL TOPICS
    FOR ENGINEERS 647 GEOSCIENCE 268 NUCLEAR ENGINEERING 70 PHOTONICS AND ELECTROOPTICS
    345 POWER, ENERGY AND INDUSTRY APPLICATIONS 1201 ROBOTICS AND CONTROL SYSTEMS
    879 TRANSPORTATION 387 AEROSPACE 265 SIGNAL PROCESSING AND ANALYSIS 1949 Terahertz
    Communications and Sensing for 6G and Beyond: A Comprehensive Review Wei Jiang
    and 14 more April 04, 2024 Next-generation cellular technologies, commonly referred
    to as the sixth generation (6G), are envisioned to support a higher system capacity,
    better performance, and network sensing capabilities. The terahertz (THz) band
    is one potential enabler to this end due to the large unused frequency bands and
    the high spatial resolution enabled by the short signal wavelength and large bandwidth.
    Different from earlier surveys, this paper presents a comprehensive treatment
    and technology survey on THz communications and sensing in terms of advantages,
    Rapid Feasibility Assessment of Energy Unit Integration in Distribution Networks
    Sicheng Gong and 2 more April 03, 2024 In contemporary heavy-load distribution
    networks, preceding feasibility assessment is imperative before incorporating
    additional energy units. However, the feasibility examination for massive combined
    operational scenarios of relevant units is computationally intensive with repetitive
    power flow calculations. To this end, this paper proposes a rapid assessment framework,
    the kernel of which is to learn from formerly examined scenarios, thus forming
    expansive feasible/infeasible regions to geometrically rule in/out subsequent
    scenarios. Without running the power flow computation in most scenarios, we accelerate
    the assessment process. Moreover, enlightened by heuristic hypersurface search,
    such prechecking efficiency can be further boosted. In a risk-averse manner, this
    framework can be conceptualized using the exact grid model. Especially, evidenced
    by testing on a 10.5kV distribution grid, the framework shows a significant assessment
    efficiency improvement and strict accuracy guarantee, where we observe at least
    76.13% assessment time reduction and zero accuracy loss in all testing cases.
    We anticipate this work to be a starting point for more sophisticated geometry-accelerating
    feasibility assessment methods. Improving Molecular De Novo Drug Design with Transformers
    Dhaval Soni and 7 more April 03, 2024 Drug design is undergoing a transformation
    as we challenge conventional methods by integrating state-of-the-art artificial
    intelligence with the intricate domain of molecular biology. At the heart of our
    endeavor lies a significant challenge: the scarcity of datasets containing active
    compounds for emerging target proteins. To confront this obstacle, we''re pioneering
    an innovative approach. We''re merging the advanced Generative Pre-trained Transformer
    (GPT) architecture with the nuanced capabilities of Long Short-Term Memory (LSTM)
    networks, with the aim of generating Simplified Molecular Input Line Entry System
    (SMILES) strings to unveil novel therapeutic pathways. Additionally, we''re employing
    a Bidirectional Encoder Representations from Transformers (BERT) pretraining strategy
    to enrich our model with comprehensive molecular data, including amino acid sequences
    and molecular SMILES datasets. Through meticulous fine-tuning on a meticulously
    curated protein-ligand complex dataset, we''re achieving precise conditional generation
    via autoregressive supervised learning. Our research introduces a groundbreaking
    method to assess molecular affinity, validated against established proteins, showcasing
    superior binding affinities compared to certain FDA-approved drugs in docking
    experiments. By pushing the boundaries of generative algorithms and establishing
    a robust framework for evaluating molecular affinity, we''re driving forward the
    field of de novo drug design, offering promising therapeutic avenues and enabling
    deeper exploration of the chemical landscape. Formalising a Gateway-based Blockchain
    Interoperability Solution with Event-B Guzmán Llambías and 2 more April 03, 2024
    A document by Guzman Llambias . Click on the document to view its contents. Magnetic
    Behavior of NO Fe-Si Sheets under Tensile and Compressive Stress Carlo Appino
    and 6 more April 03, 2024 The stress dependence of the magnetic properties of
    non-oriented Fe-Si steel sheets has been investigated by measurement and analysis
    of hysteresis loop, magnetization curve, and energy losses taken at different
    peak polarization values Jp (0.5 T – 1.5 T) between DC and f = 400 Hz. The salient
    feature of the material response to the stress lies in the monotonic deterioration
    of the soft magnetic properties, across the whole (Jp - f) domain, on passing
    from the maximum tensile stress (σ = +30 MPa) to the maximum compression (σ =
    -30 MPa). This is understood in terms of stress-induced redistribution of the
    domains between easy axes, making magnetic hardening by compression directly related
    to unfavorably directed domains and 90° domain-wallmediated magnetization transitions.
    The loss decomposition is carried out across the whole investigated frequency
    range, taking into account the skin effect at the highest frequencies. Quasi-static
    and dynamic losses follow a same trend with σ, both monotonically increasing on
    passing from the tensile to the compressive stress limits, according to the theoretically
    expected relationship existing between the hysteresis and the excess loss components.
    The latter is shown to identify the correlation regions where the magnetization
    is reversed of size comparable with the average grain size and loosely following
    the dependence of the loss figure on the applied stress. A bio-inspired hardware
    implementation of an analog spike-based hippocampus memory mo... Daniel Casanueva-Morato
    and 4 more April 03, 2024 The need for processing at the edge the increasing amount
    of data that is being produced by multitudes of sensors has led to the demand
    for mode power efficient computational systems, by exploring alternative computing
    paradigms and technologies. Neuromorphic engineering is a promising approach that
    can address this need by developing electronic systems that faithfully emulate
    the computational properties of animal brains. In particular, the hippocampus
    stands out as one of the most relevant brain region for implementing auto associative
    memories capable of learning large amounts of information quickly and recalling
    it efficiently. In this work, we present a computational spike-based memory model
    inspired by the hippocampus that takes advantage of the features of analog electronic
    circuits: energy efficiency, compactness, and real-time operation. This model
    can learn memories, recall them from a partial fragment and forget. It has been
    implemented as a Spiking Neural Networks directly on a mixed-signal neuromorphic
    chip. We describe the details of the hardware implementation and demonstrate its
    operation via a series of benchmark experiments, showing how this research prototype
    paves the way for the development of future robust and low-power mixed-signal
    neuromorphic processing systems. Exploratory Study of oneM2M-based Interoperability
    Architectures for IoT: A Smart Cit... VJS Pranavasri and 6 more April 03, 2024
    The advent of the Internet of Things (IoT) has ushered in transformative possibilities
    for smart cities, with the potential to revolutionize urban living through enhanced
    connectivity and data-driven decision-making. However, the effective realization
    of IoT in smart cities hinges upon the seamless interoperability of diverse devices
    and systems. To address this critical need, the oneM2M standards initiative has
    emerged as a foundational framework for IoT interoperability. In this research
    paper, we perform an exploratory analysis of three prominent open-source oneM2M
    based interoperability systems-Mobius, OM2M, and ACME. We leverage an existing
    large-scale system provided by our Smart City Living Lab deployed at IIIT Hyderabad,
    sprawling a 66-acre campus featuring over 370 nodes across eight verticals. We
    investigate the architectural characteristics of each solution, considering their
    strengths and limitations in facilitating IoT interoperability. Through this analysis,
    our paper aims to provide valuable insights for stakeholders seeking to implement
    IoT interoperability solutions in the context of smart cities. By evaluating the
    strengths and limitations of Mobius, OM2M, and ACME, we seek to offer guidance
    for selecting the most suitable solution. Our analysis reveals that the optimal
    framework choice depends on specific quality constraints: Mobius excels in performance,
    while ACME offers advantages in ease of setup for smaller-scale implementations.
    Comparing Concepts of Service Blocking Queues in Hardware-in-the-Loop Systems
    Tobias Konheiser and 3 more April 03, 2024 ZF is developing an autonomous driving
    system, which requires extensive testing of the developed devices and software
    on hardware-in-the-loop (HIL) systems. Therefore, a robust and high-performing
    HIL system is essential. The purpose of a HIL system is to replay recorded data
    to the device-undertest. Recordings are loaded, processed and streamed to the
    deviceunder-test with real-time requirements. This streaming chain includes processing
    nodes and queues. This requires careful management of queue configurations. An
    overflow in the queue will result in packet loss, while an underflow may violate
    the real-time constraint. This study aims to develop and evaluate concepts for
    service blocking queues. These concepts block or pause the incoming service to
    a queue when necessary to avoid queue overflows and associated data loss. However,
    an out-of-the-box solution is not available and different approaches affect the
    behaviour and performance of the system. Therefore, the developed concepts are
    evaluated against each other and against the existing system based on selected
    performance parameters in specific scenarios. The scenarios cover a wide range
    of situations, reflecting standard input data with varying numbers of parallel
    streams and bottleneck scenarios forcing queue overflows or blockages. The developed
    service blocking queue concepts eliminate data loss in all scenarios, but introduce
    overhead, resulting in reduced system performance. However, the service blocking
    queue concept using a modified token-bucket approach proved to be the best solution,
    as the elimination of data loss justifies the additional overhead. This concept
    is proposed for implementation and deployment on the HIL system. Generative AI-Based
    Text Generation Methods Using Pre-Trained GPT 2 Model Rohit Pandey and 7 more
    April 03, 2024 A text generation model is a machine learning model that uses neural
    networks, especially transformers architecture to generate contextually relevant
    text based on linguistic patterns learned from extensive corpora. The models are
    trained on a huge amount of textual data so that they can model and learn complex
    concepts of any language like its grammar, vocabulary, phrases, and styles. FlowDep
    - An efficient and optical-flow-based algorithm of obstacle detection for aut...
    Chen-Fu Yeh and 7 more April 03, 2024 Obstacle detection is crucial for the safety
    and efficiency of autonomous vehicles. For mini-vehicles such as palm-sized drones,
    it is a challenge to implement traditional methods like Lidar due to high costs
    and physical constraints. Vision-based deep learning approaches, while accurate,
    are too resource-intensive for the mini-vehicles. To address this issue, we introduce
    Flowdep, a novel optical-flow-based algorithm inspired by the low-resolution but
    efficient motion-detection mechanisms in insects. Flowdep combines optic flow
    and IMU (or positioning information) to estimate the depth of every image pixel.
    We also generate a variant of Flowdep using the artificial neural network (Flowdep-ANN).
    Our tests show that Flowdep and Flowdep-ANN are 5.8 to 114.7 times faster than
    the DNN networks we tested, while the accuracies of Flowdep and Flowdep-ANN are
    on par with these networks. We further tested Flowdep and Flowdep-ANN on a small
    autonomous vehicle with Raspberry Pi4 as the computing platform, and both models
    successfully performed real-time object detection. The present work demonstrates
    the potential of using optical flow as an efficient approach to estimate depth
    and detect obstacles in resource-constrained mini-vehicles. Misinformative Data
    Visualizations in the Sports Media Domain Drew Scott April 03, 2024 Sports are
    data-driven: individual performances are measured using statistics and teams leverage
    data analytics to outperform competition. Sports media-which is created by media
    outlets, teams, and individuals-engage its consumers by creating narratives about
    the sport, teams, and players. Due to the importance of data in the sports world,
    data visualizations are a pillar in the sports media landscape. These data visualizations,
    while appearing to accurately convey data to its consumers, can be misinformative;
    media creators often have incentives to present specific narratives which don''t
    always fit the data. This work contributes to an existing misinformative data
    visualization taxonomy. In doing so, it makes it easier to understand the techniques
    and design choices used to create misinformative visualizations in all domains,
    not only in sports media. A Survey of RFID Authentication Protocols Drew Scott
    April 03, 2024 "Radio frequency identification" (RFID) systems are ubiquitous
    in today''s world. In an RFID system, it is a desirable to attain mutual authentication
    between a reader and a tag before commencing application-level communications.
    This is because tags should not share secret information with unknown parties
    and readers need to defend against tag impersonation. Authentication protocols
    designed for communication between computers, however, are not appropriate for
    RFID systems because tags are extremely resource constrained (low energy, small
    memory, etc.). Thus, there have been many attempts to design secure and practical
    authentication protocols for RFID systems over the years since RFID systems became
    prevalent. This survey summarizes and compares these protocols. The Effect of
    Multipath in Distributed Arrays with Time Reversal Hassna Ouassal and 2 more April
    03, 2024 This article examines the effect of multipath channels on the performance
    of distributed arrays that employ time reversal. A model of the signal received
    from a distributed array is formulated, and a statistical analysis of the variation
    in signal power in the presence of phase noise and multipath is given. We present
    the impact these nonidealities have on received signal power, and we analyze the
    received power for three specific cases: continuous waveform, impulse waveform,
    and modulated rectangular pulse waveform in the presence of standard channel models.
    It is shown that for larger arrays in multipath channels, the change in power
    between coherent and incoherent states converges to the line-of-sight channel.
    It is further shown that in a line-of-sight channel time-reversal completely cancels
    unknown channel delays resulting in coherent signals from all nodes in a distributed
    array, while in a multipath channel only the main diagonal round-trip paths are
    coherent. Nevertheless, this additional benefit improves signal coherence in complex
    channels and can aide in distributed array synchronization using two-way time
    transfer. Disproof of Hodge Conjecture by Graph Theory Jihyeon Yoon April 02,
    2024 Hodge conjecture is turned out to be false in extension of graph theory based
    on its algebraic attribute. Hash3D: Training-free Acceleration for 3D Generation
    Xingyi Yang and 1 more April 02, 2024 The evolution of 3D generative modeling
    has been notably propelled by the adoption of 2D diffusion models. Despite this
    progress, the cumbersome optimization process per se presents a critical hurdle
    to efficiency. In this paper, we introduce Hash3D, a universal acceleration for
    3D generation without model training. Central to Hash3D is the insight that feature-map
    redundancy is prevalent in images rendered from camera positions and diffusion
    time-steps in close proximity. By effectively hashing and reusing these feature
    maps across neighboring timesteps and camera angles, Hash3D substantially prevents
    redundant calculations, thus accelerating the diffusion model''s inference in
    3D generation tasks. We achieve this through an adaptive grid-based hashing. Surprisingly,
    this feature-sharing mechanism not only speed up the generation but also enhances
    the smoothness and view consistency of the synthesized 3D objects. Our experiments
    covering 5 textto-3D and 3 image-to-3D models, demonstrate Hash3D''s versatility
    to speed up optimization, enhancing efficiency by 1.3 ∼ 4×. Additionally, Hash3D''s
    integration with 3D Gaussian splatting largely speeds up 3D model creation, reducing
    text-to-3D processing to about 10 minutes and image-to-3D conversion to roughly
    30 seconds. The code is provided in https://github.com/Adamdad/hash3D. Area and
    Power Efficient Implementation of Configurable Ring Oscillator PUF Enas Abulibdeh
    and 4 more April 02, 2024 Physically Unclonable Function (PUF) is an emerging
    hardware security primitive that provides a promising solution for lightweight
    security. PUFs can be used to generate a secret key that depends on the random
    manufacturing process variation of the device for lightweight authentication and
    device identification. This work proposes an optimized version of the Configurable
    Ring Oscillator (CRO) PUF that aims to reduce power consumption and area overhead.
    The proposed design eliminates the duplication of ROs, reduces the switching activity,
    and introduces the inter-stage delay as an additional source of randomness. The
    proposed PUF has been implemented in 22nm FDSOI technology using the Synopsys
    tools. A comprehensive security analysis has been acquired utilizing Challenge-Response
    Pairs collected from 8 chips. Results show an average of 49.42%, 38.25%, 9.95%,
    and 45.5% for uniformity, diffuseness, reliability, and uniqueness, respectively.
    Compared with the state-of-the-art, the proposed design achieves an area and power
    reduction of 75% and 65.1%, respectively. With the proposed PUF delivering 10
    32 CRPs, it is classified as a strong PUF. Additionally, the proposed design passes
    NIST tests and achieves an average prediction accuracy of 67.1% of machine learning
    modeling. A Hero Or A Killer? Overview Of Opportunities, Challenges, And Implications
    Of Text-T... Mijat Kustudic and 1 more April 02, 2024 SORA is a text-to-video
    model that can create videos based on simple user prompts. The model promises
    to revolutionize the way content is created. When SORA is released to the general
    public, it may transform a wide array of industries but also pose significant
    challenges and risks. This research aims to provide a comprehensive understanding
    of SORA''s opportunities, challenges, and implications. It explores its potential
    applications in film-making, education, gaming, advertising, accessibility, healthcare,
    and social media content creation. Additionally, it delves into its potential
    challenges and risks, including misinformation, privacy concerns, bias, regulatory
    complexities, and dependence on technology. This research provides important recommendations
    to promote responsible deployment of the AI model. Advancements and Challenges
    in Robot Grasping and Manipulation for Aspiring Researche... Claudio Zito April
    02, 2024 Robot grasping and manipulation represent pivotal aspects of robotics
    research with profound implications for the future of autonomous systems. This
    report delves into the intricacies of designing robotic hands, the hurdles in
    creating robust manipulation actions, and the advancements in the field that poised
    to catalyze a new era of autonomy. Drawing inspiration from science fiction''s
    portrayal of robotics, we bridge the conceptual gap between fiction and ongoing
    real-world technical research, aiming to provide a comprehensive overview for
    students interested in robotics. ← Previous 1 2 3 4 5 6 7 8 9 … 509 510 Next →
    TechRxiv | Powered by Authorea.com Home About Submission Guidelines FAQs Terms
    of Use Privacy Policy Contact Us'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: https://www.techrxiv.org/articles/preprint/A_Futuristic_Survey_on_Learning_Techniques_for_Internet_of_Things_IoT_Security_Developments_Applications_and_Challenges/19642977/1/files/34888401.pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'A Futuristic Survey on Learning Techniques for Internet of Things (IoT)
    Security : Developments, Applications, and Challenges'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/ccece53047.2021.9569199
  analysis: '>'
  authors: []
  citation_count: 0
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2021 IEEE Canadian Conference... Program
    Publisher: IEEE Cite This PDF 149 Full Text Views Abstract Metrics Abstract: Provides
    a schedule of conference events and a listing of which papers were presented in
    each session. Published in: 2021 IEEE Canadian Conference on Electrical and Computer
    Engineering (CCECE) Date of Conference: 12-17 September 2021 Date Added to IEEE
    Xplore: 26 October 2021 ISBN Information: ISSN Information: DOI: 10.1109/CCECE53047.2021.9569199
    Publisher: IEEE Conference Location: ON, Canada Metrics More Like This Decoding
    by linear programming IEEE Transactions on Information Theory Published: 2005
    Program Slicing IEEE Transactions on Software Engineering Published: 1984 Show
    More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/9569025/9569028/09569199.pdf
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: Program
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.31428/10317/10416
  analysis: '>'
  authors:
  - Marouane Salhaoui
  citation_count: 0
  full_citation: '>'
  full_text: ">\n \n  \n \nvrbvnjnnbbttbbtbt  \n\"SMART IOT MONITORING AND REAL-TIME\
    \ CONTROL \nBASED ON AUTONOMOUS ROBOTS, VISUAL \nRECOGNITION AND CLOUD/EDGE COMPUTING\
    \ \nSERVICES\" \n \nPrograma de Doctorado: ENERGÍAS RENOVABLES Y \nEFICIENCIA\
    \ ENERGÉTICA \n \n \n \n \nAutor: Marouane Salhaoui \n \nCartagena (2021) \n \n\
    i \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n \n \n \n \n \n \n\
    \ \n \n \nABDELMALEK ESSAADI UNIVERSITY \nFACULTY OF SCIENCE AND TECHNIQUES \n\
    TANGER / MOROCCO \n \nPOLYTECHNIC UNIVERSITY OF CARTAGENA \nUPCT / SPAIN \n \n\
    \ \nDOCTORAL THESIS (Year 2021) \n \nPresented By: \n \nMAROUANE SALHAOUI \n \n\
    Directors:  \n \nAntonio Guerrero-González, Mounir Arioua  \n \nCo-Directors:\
    \ \n \nFrancisco J. Ortiz, Ahmed El Oualkadi \n \nThesis Title: \n \n\"SMART IOT\
    \ MONITORING AND REAL-TIME CONTROL \nBASED ON AUTONOMOUS ROBOTS, VISUAL RECOGNITION\
    \ \nAND CLOUD/EDGE COMPUTING SERVICES\" \n \n \nAccredited research institution:\
    \ \n \n• Laboratoire des Technologies de l’Information et de la Communication\
    \ de ENSA de \nTanger (Morocco) \n• Departamento de Automática, Ingeniería Eléctrica\
    \ y Tecnología Electrónica, UPCT \nCartagena (Spain) \n \nii \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n \nAbstract \n \nIn the fourth industrial revolution\
    \ in which we are immersed, new \ntechnologies are being introduced in production\
    \ processes, such as the use of \nUnmanned Vehicles (UVs) data collection in large\
    \ surfaces, and the use of the \nIndustrial Internet of Things (IIoT). The main\
    \ keys to integrate this new \ntechnology in the industry is to face the challenge\
    \ of making the IT network \ncompatible with its machines, including interoperability,\
    \ fog and cloud \ncomputing, security, decreasing latency and improving data accuracy\
    \ and \nquality of service. \nSmart industrial platforms require multiple synchronized\
    \ processes that \nrequire low latency and higher reliability to achieve the necessary\
    \ performance. \nIn addition, Artificial Intelligence (AI) methods applied to\
    \ IIoT must be able to \naddress these issues as well as other parameters such\
    \ as network deployment \nand resource management. \nThe issues of high-latency\
    \ and unreliable links between the cloud and \nIndustrial IoT endpoints are significant\
    \ challenges. Each fog and edge application \nmay have different latency requirements\
    \ and may generate different types of \ndata and network traffic.  Such generated\
    \ data can be photos received from an \nUV system. The latter can be connected\
    \ to other control system, being used both \nto perform enhancements and to make\
    \ decisions based on the captured photos. \nThis type of connection is sensitive\
    \ in terms of accuracy and latency, as the whole \nplatform must decide quickly\
    \ and with certainty. \nOne of the solutions to overcome the latency challenge\
    \ is the fog/edge \narchitecture. This architecture can also be a viable solution\
    \ regarding the \ninteroperability barrier between interconnected systems. Fog\
    \ computing extends \ncomputation and storage to the edge of the network and presents\
    \ an effective tool \nfor integrating new complex interconnected processing systems.\
    \   \nThe constraint of interoperability can be overcome by adopting advanced\
    \ \nsoftware deployed in the edge and fog installed in an IoT gateway. This software\
    \ \ninteracts simultaneously with the different systems involved through different\
    \ \nprotocols. However, the choice of an IoT gateway is crucial in terms of latency\
    \ \nand accuracy, as it is at the heart of processing and transmitting data to\
    \ the \ndifferent systems and platforms and considered the interface of junction\
    \ between \nthe physical level and cloud. The latter also affects performance\
    \ as it must ensure \nthat data is transferred, processed and returned at speeds\
    \ that meet the needs of \nthe application. \n \niii \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nWe address all these challenges by considering appropriate\
    \ protocols and \nsoftware for interoperability and connectivity constraints and\
    \ we discuss the \nperformance some appropriate IoT devices capable of providing\
    \ minimal \nresponse time. \nDeep Learning (DL) services can be deployed near\
    \ requesting users and the \ncloud only intervenes when additional processing\
    \ is required, significantly \nreducing the latency and cost of sending data to\
    \ the cloud for processing. In this \nthesis, we propose novel approaches to solve\
    \ the latency issue by deploying \nintelligence at the edge that pushes DL computations\
    \ from the cloud to the edge \nenabling various distributed, low-latency and reliable\
    \ intelligent services. \nThe main benefit of the proposed approaches is the integration\
    \ of cloud \nservices into a control loop to improve a platform’s decision making\
    \ and the \nperformance of an industrial control system. Cloud AI services are\
    \ also \nintegrated into a drone control loop as an input that helps improve the\
    \ \nmonitoring capability to find and track stationary and mobile objects. \n\
    In this work, we evaluate the latency and accuracy of different systems \ninvolved\
    \ and we propose an intelligent algorithm to select the appropriate AI \ntechnology\
    \ for the scenario to be monitored. This proved to be crucial in deciding \nthe\
    \ best source of artificial intelligence to be used to achieve the specified goals\
    \ \nat each stage in real time. The proposed intelligent algorithms offer a compromise\
    \ \nbetween latency and accuracy. \n \n \n \niv \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \nResumen \n \nEn la cuarta revolución industrial en\
    \ la que estamos inmersos, se están \nintroduciendo nuevas tecnologías en los\
    \ procesos productivos, como el uso de \nvehículos autónomos (UVs) para recogida\
    \ de datos en grandes superficies y el \nuso del Internet Industrial de las Cosas\
    \ (IIoT). Las principales claves para integrar \nesta nueva tecnología en la industria\
    \ es afrontar el reto de compatibilizar la red \ninformática con sus máquinas,\
    \ incluyendo la interoperabilidad, computación en \nla niebla/nube/borde (fog/cloud/edge\
    \ computing), la seguridad, la disminución \nde la latencia y la mejora de la\
    \ precisión de los datos y la calidad del servicio. \nLas plataformas industriales\
    \ inteligentes requieren múltiples procesos \nsincronizados que exigen una baja\
    \ latencia y una mayor fiabilidad para lograr el \nrendimiento necesario. Además,\
    \ los métodos de Inteligencia Artificial (IA) \naplicados a la IIoT deben ser\
    \ capaces de abordar estas cuestiones, así como otros \nparámetros como el despliegue\
    \ de la red y la gestión de recursos. \nLos problemas de alta latencia y enlaces\
    \ poco fiables entre la nube y los \npuntos finales del IoT industrial son retos\
    \ importantes. Cada aplicación de niebla \ny borde puede tener diferentes requisitos\
    \ de latencia y puede generar diferentes \ntipos de datos y tráfico de red.  Estos\
    \ datos generados pueden ser imágenes \nrecibidas de un sistema UV, por ejemplo.\
    \ Este sistema puede a su vez conectarse \na otro sistema de control, utilizándose\
    \ tanto para realizar mejoras en el proceso \ncomo para tomar decisiones basadas\
    \ en las imágenes capturadas. Este tipo de \nconexión es sensible en términos\
    \ de precisión y latencia, ya que toda la \nplataforma debe decidir con rapidez\
    \ y seguridad. \nUna de las soluciones para superar el reto de la latencia es\
    \ la arquitectura \nbasada en la niebla/borde (fog/edge). Esta arquitectura también\
    \ puede ser una \nsolución viable en cuanto a la barrera de interoperabilidad\
    \ entre los sistemas \ninterconectados. La computación en la niebla extiende la\
    \ computación y el \nalmacenamiento al borde de la red y presenta una herramienta\
    \ eficaz para \nintegrar nuevos sistemas complejos de procesamiento interconectados.\
    \   \nLa limitación de la interoperabilidad puede superarse adoptando un \nsoftware\
    \ avanzado desplegado en el borde y la niebla instalado en una pasarela \nde IoT.\
    \ Este software interactúa simultáneamente con los distintos sistemas \nimplicados\
    \ a través de diferentes protocolos. Sin embargo, la elección de una \npasarela\
    \ IoT es crucial en términos de latencia y precisión, ya que está en el centro\
    \ \ndel procesamiento y la transmisión de datos a los diferentes sistemas y \n\
    plataformas y se considera la interfaz de unión entre el nivel físico y la nube.\
    \ Esta \núltima también afecta al rendimiento, ya que debe garantizar que los\
    \ datos se \n \nv \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \ntransfieran,\
    \ procesen y devuelvan a velocidades que satisfagan las necesidades \nde la aplicación.\
    \ \nAbordamos todos estos retos teniendo en cuenta los protocolos y el software\
    \ \napropiados para la interoperabilidad y las restricciones de conectividad,\
    \ y \nanalizamos el rendimiento de algunos dispositivos IoT apropiados capaces\
    \ de \nproporcionar un tiempo de respuesta mínimo. \nLos servicios de Deep Learning\
    \ (DL) pueden desplegarse cerca de los \nusuarios que los solicitan y la nube\
    \ solo interviene cuando se requiere un \nprocesamiento adicional, reduciendo\
    \ significativamente la latencia y el coste de \nenviar los datos a la nube para\
    \ su procesamiento. En esta tesis, proponemos \nenfoques novedosos para resolver\
    \ el problema de la latencia mediante el \ndespliegue de inteligencia en el borde\
    \ que empuja los cálculos de DL desde la \nnube hasta el borde permitiendo varios\
    \ servicios inteligentes distribuidos, de \nbaja latencia y fiables. \nLa principal\
    \ ventaja de los enfoques propuestos es la integración de los \nservicios en la\
    \ nube en un lazo de control para mejorar la toma de decisiones de \nuna plataforma\
    \ y el rendimiento de un sistema de control industrial. Los servicios \nde IA\
    \ en la nube también se integran en un lazo de control donde interviene un \n\
    dron como una entrada que ayuda a mejorar la capacidad de monitorización para\
    \ \nencontrar y rastrear objetos estacionarios y móviles. \nEn este trabajo, evaluamos\
    \ la latencia y la precisión de los diferentes sistemas \nimplicados y proponemos\
    \ un algoritmo inteligente para seleccionar la tecnología \nde IA adecuada para\
    \ el escenario a vigilar. Esto resulta crucial para decidir cuál \nes la mejor\
    \ fuente de inteligencia artificial que debe utilizarse para alcanzar los \nobjetivos\
    \ especificados en cada escenario en tiempo real. Los algoritmos \ninteligentes\
    \ propuestos ofrecen un compromiso entre latencia y precisión. \n \n \n \nvi \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \n \n صخلملا \n \n \n يفعمج\
    \ مادختسا لثم ، جاتنلإا تايلمع يف ةديدج تاينقت لاخدإ متي ، اهيف كراشن يتلا ةعبارلا\
    \ ةيعانصلا ةروثلا \nةيسيئرلا حيتافملا لثمتت .ءايشلأل يعانصلا تنرتنلإا مادختساو\
    \ ، ةعساو قطانم يف ةلوهأملا ريغ تابكرملا تانايب \n ةهجاوم يف ةعانصلا يف ةديدجلا\
    \ ايجولونكتلا هذه جمدلةقفاوتم تامولعملا ايجولونكت ةكبش لعج يف لثمتملا يدحتلا \n\
    ينمزلا ريخأتلا ليلقتو نملأاو ةيباحسلاو ةيبابضلا ةبسوحلاو يليغشتلا قفاوتلا ةيناكمإ\
    \ كلذ يف امب ، اهتزهجأ عم \nةمدخلا ةدوجو تانايبلا ةقد نيسحتو )نومكلا(  \n \nةددعتم\
    \ ةنمازتم تايلمع ةيكذلا ةيعانصلا تاصنملا بلطتتىلعأ ةيقوثومو ضفخنم ينمزريخأت بجوتست\
    \ يتلاو ، \nءايشلأا تنرتنإ ىلع ةقبطملا يعانطصلاا ءاكذلا بيلاسأ نوكت نأ بجي ، كلذ\
    \ ىلإ ةفاضلإاب .مزلالا ءادلأا قيقحتل \nدراوملا ةرادإو ةكبشلا تيبثت لثم ىرخأ تاملعم\
    \ ىلإ ةفاضلإاب تلاكشملا هذه ةجلاعم ىلع ةرداق  \n   \nاورلا تلاكشم دعتءايشلأا تنرتنإو\
    \ ةيباحسلا ةياهنلا طاقن نيب يلاع ينمزريخأت تاذ و اهب قوثوملاريغ طب \nعاونأ هنع\
    \ جتني دقو ةفلتخم نومك تابلطتم ةفاحلاو بابضلا تاقيبطت نم قيبطت لكل نوكي دق .ريبك\
    \ يدحت ةيعانصلا \nيتلا تانايبلا هذه نوكت نأ نكمي .تاكبشلا ربع ةلوادتملا تانايبلا\
    \ نم ةفلتخم نم ةملتسملا روصلا نم اهؤاشنإ مت \nتانيسحت ءارجلإ همادختسا متي ثيح\
    \ ، رخآ مكحت ماظنب ريخلأا اذه ليصوت نكمي .ةلوهأملا ريغ تابكرملا ماظن \nبجي ثيح\
    \ ، نومكلاو ةقدلا ثيح نم ساسح لاصتلاا نم عونلا اذه .ةطقتلملا روصلا ىلع ًءانب تارارقلا\
    \ ذاختلاو \nفنملا يساسلأا ماظنلا ىلعدكؤم لكشبو ةعرسب ررقي نأ هلمكأب ذ  \n \nيف\
    \ ةتبثم ، بابضلاو ةفاحلا يف ةرشتنم ةمدقتم جمارب دامتعا للاخ نم يليغشتلا قفاوتلا\
    \ دويق ىلع بلغتلا نكمي \nتلاوكوتورب للاخ نم ةكراشملا ةفلتخملا ةمظنلأا عم نمازتم\
    \ لكشب جمانربلا اذه لعافتي .ءايشلأا تنرتنإ ةباوب \n كلذ عمو .ةفلتخمإف ،اهنإ ثيح\
    \ ، ةقدلاو ينمزلاريخأتلاب قلعتي اميف ةيمهلأا غلاب رمأ ءايشلأا تنرتنإ ةباوب رايتخا\
    \ ن \nةقبطلا( ةيداملا ةقبطلا نيب عطاقتلا ةهجاو ربتعت يتلاو ، ةفلتخملا ىنبلاو ةمظنلأا\
    \ ىلإ اهلقنو تانايبلا ةجلاعم بلق \nباحسلاو )يرايعملا لاصتلاا جذومن يف ةقبط ىندأ،ىلولأانمضت\
    \ نأ بجي هنلأ ءادلأا ىلع اًضيأ ةريخلأا هذه رثأت .ة \n قيبطتلا تاجايتحا يبلت تاعرسب\
    \ اهتداعإو اهتجلاعمو تانايبلا لقن \n \nلاصتلاا دويقو يليغشتلا قفاوتلل ةبسانملا\
    \ جماربلاو تلاوكوتوربلا يف رظنلا للاخ نم تايدحتلا هذه لك عم لماعتن  \nيشلأا تنرتنإ\
    \ ةزهجأ ضعب ءادأ شقاننوينمزلا ريخأتلا نم ىندلأا دحلا ريفوت ىلع ةرداقلا ةبسانملا\
    \ ءا  \n \nىلإ ةجاحلا دنع لاإ ةباحسلا لخدتت لاو ، ةبولطملا نيمدختسملا ةمظنأ نم\
    \ برقلاب قيمعلا ملعتلا تامدخ رشن نكمي \nملل ةباحسلا ىلإ تانايبلا لاسرإ ةفلكتو\
    \ ينمزلا ريخأتلا نم ريبك لكشب للقي امم ، ةيفاضإ ةجلاعمهذه يف .ةجلاع \nتاباسح عفدت\
    \ يتلا ةفاحلا ىلع ءاكذلا رشن للاخ نم ينمزلا ريخأتلا ةلكشم لحل ةديدج بيلاسأ حرتقن\
    \ ، ةحورطلأا \nضفخنم ينمز ريخأت تاذو ةعزومو ةقوثومو ةعونتم ةيكذ تامدخ حيتي امم\
    \ ةفاحلا ىلإ ةباحسلا نم قيمعلا ملعتلا  \n \n ةحرتقملا قرطلل ةيسيئرلا ةدئافلا لثمتتيف\
    \ رارقلا عنص ةيلمع نيسحتل مكحتلا ةقلح يف ةيباحسلا تامدخلا جمد يف \nكذلا تامدخ\
    \ جمد اًضيأ متي .يعانصلا مكحتلا ماظن ءادأو يساسلأا ماظنلايف مكحتلا ةقلح يف ةيباحسلا\
    \ يعانطصلاا ءا \nةتباثلا ءايشلأا ىلع روثعلل ةبقارملا ةردق نيسحت ىلع دعاسي لخدمك\
    \ ةلوهأملا ريغ تابكرملا اهعبتتو ةكرحتملاو  \n  \nءاكذلا ةينقت ديدحتل ةيكذ ةيمزراوخ\
    \ حرتقنو ةينعملا ةفلتخملا ةمظنلأا ةقدو ينمزلا ريخأتلا مييقتب موقن ، لمعلا اذه\
    \ يف \nيعانطصلاا ءاكذلل ردصم لضفأ ديدحت يف مساح رمأ اذه نأ تبث .هتبقارم دارملا\
    \ ويرانيسلل ةبسانملا يعانطصلاا \nلأا قيقحتل همادختسلااطسو لاح ةحرتقملا ةيكذلا\
    \ تايمزراوخلا مدقت .يلعفلا تقولا يف ةلحرم لك يف ةبولطملا فاده \nةقدلاو نومكلا\
    \ نيب  \n \n \n \nvii \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    \ \n \nList of Acronyms  \nAI Artificial Intelligence  \nAIS Automatic Identification\
    \ System \nANN Artificial Neural Network  \nAPI Application programming interfaces\
    \ \nASV Autonomous Surface Vehicle \nAUV Autonomous Underwater Vehicle \nCAN Controller\
    \ area network \nCCM Cloud custom model \nCGM Cloud General Model \nCoAP Constrained\
    \ Application Protocol \nCPS cyber-physical systems \nCPU Central processing unit\
    \  \nCSMA/CD with NDBA Carrier Sense Multiple Access / Collision Detection \n\
    with Non-Destructive Bitwise Arbitration \nCV Computer vision \nDAyRA División\
    \ de Automatización y Robótica Autónoma \nDNNs Deep Neural Networks \nDP Deep\
    \ Learning \nDPM Dynamic Position Mode  \nDVL Doppler Velocity Logger \n \nviii\
    \ \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nECM Edge custom model\
    \ \nEI Edge Intelligence  \nERP enterprise resource planning \nFN False Negative\
    \ \nFP False Positive \nGPS Global Positioning System \nGPU Graphics Processing\
    \ Unit \nHD High-definition \nHVAC Heating, Ventilating, and Air Conditioning\
    \ \nIaaS Infrastructure-as-a-Service  \nIETF The Internet of Engineering Task\
    \ \nILSVRC ImageNet Large Scale Visual Recognition Challenge \nIM Inspection Mode\
    \  \nIMARS IBM multimedia analysis and retrieval system \nIoS Internet of services\
    \ \nIoT Internet of things \nIoU Intersection on union \nIPM Image Processing\
    \ Algorithm \nIUCN International Union for the Conservation of Nature \nIUNO Interface\
    \ for Unmanned Drones \nM2M machine-to-machine \nMASS Maritime Autonomous Surface\
    \ Ships  \nMES manufacturing execution systems \n \nix \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nML Machine Learning  \nMLaaS Machine Learning as a service\
    \  \nMMM Main Mission Mode \nMPA Marine Protected Area \nMQTT The Message Queuing\
    \ Telemetry Transport \nND Not detected \nNFC Near Field Communication  \nNIC\
    \ network interface controller  \nOPC UA Open Platform Communications Unified\
    \ Architecture  \nOWD One-way delay \nPaaS Platform as-a-Service \nPC-G PC Gateway\
    \ \nPID Proportional–Integral–Derivative \nPV Process Variables \nQoS Quality\
    \ of Service  \nRFID Radio frequency identification  \nRPI-G Raspberry PI Gateway\
    \ \nRTD Round-trip delay time \nS-G Siemens Gateway \nSAAO Smart algorithm for\
    \ autonomy optimization \nSaaS Software-as-a-Service \nSAR Synthetic Aperture\
    \ Radar \nSHDL ScatterNet hybrid deep learning \n \nx \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nSISO single-input–single-output \nSOA Service-oriented\
    \ architecture \nSP Set Points \nSVM Support vector machine \nTAS Time-aware scheduler\
    \  \nTM Tracking Mode  \nTP True Positive \nTSN Time sensitive networking \nUAV\
    \ Unmanned Autonomous Vehicle \nUVs Unmanned vehicles \nVPL Visual Programming\
    \ Language  \nWFQ weighted fair queuing \nWSN Wireless Sensor Network  \nWVR Watson\
    \ Visual Recognition \n \n \n \nxi \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \n \nList of Publications  \nThe work presented in this thesis has appeared\
    \ in the articles reported below.  \nJournal papers:  \n(J1) Salhaoui Marouane;\
    \ Guerrero-González Antonio; Arioua Mounir; Ortiz, \nFrancisco J.; El Oualkadi\
    \ Ahmed; Torregrosa Carlos L. 2019. \"Smart Industrial IoT \nMonitoring and Control\
    \ System Based on UAV and Cloud Computing Applied to \na Concrete Plant\" Sensors\
    \ 19, no. 15: 3316. https://doi.org/10.3390/s19153316  \n \n(J2) Salhaoui Marouane;\
    \ Molina-Molina J. C.; Guerrero-González Antonio; Arioua \nMounir; Ortiz Francisco\
    \ J. 2020. \"Autonomous Underwater Monitoring System for \nDetecting Life on the\
    \ Seabed by Means of Computer Vision Cloud Services\" \nRemote Sens. 12, no. 12:\
    \ 1981. https://doi.org/10.3390/rs12121981  \n \n(J3) Molina-Molina J. C.; Salhaoui\
    \ Marouane; Guerrero-González, Antonio; Arioua, \nMounir. 2021. \"Autonomous Marine\
    \ Robot Based on AI Recognition for \nPermanent Surveillance in Marine Protected\
    \ Areas\" Sensors 21, no. 8: 2664. \nhttps://doi.org/10.3390/s21082664  \n \n\
    (J4) Benbarrad, Tajeddine; Salhaoui Marouane; Kenitar Soukaina B.; Arioua \nMounir.\
    \ 2021. \"Intelligent Machine Vision Model for Defective Product Inspection \n\
    Based \non \nMachine \nLearning\" J. \nSens. \nActuator \nNetw. 10, \nno. \n1:\
    \ \n7. \nhttps://doi.org/10.3390/jsan10010007  \n \nInternational conference papers:\
    \  \n(C1) Marouane Salhaoui, Mounir Arioua, Otman Chakkor, and Jihane Elaasri.\
    \ 2017. \nPerformance Evaluation Survey of WSN Physical Layer. In Proceedings\
    \ of the 2nd \nInternational Conference on Computing and Wireless Communication\
    \ Systems \n(ICCWCS'17). Association for Computing Machinery, New York, NY, USA,\
    \ Article \n68, 1–5. DOI: https://doi.org/10.1145/3167486.3167557 \n \n(C2) Marouane\
    \ Salhaoui, Mounir Arioua, Antonio Guerrero-González, María \nSocorro García-Cascales,\
    \ \"An IoT Control System for Wind Power Generators\", \n17th International Conference,\
    \ IPMU, Published in Information Processing and \nManagement of Uncertainty in\
    \ Knowledge-Based Systems. Applications, \nSpringer, Cádiz, Spain, 2018. https://doi.org/10.1007/978-3-319-91479-4_39\
    \ \n \nxii \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \n(C3) Soukaina\
    \ Bakhat Kenitar, Salhaoui Marouane, Arioua Mounir, Ali Younes, and \nA. Guerrero\
    \ Gonzalez. 2018. Evaluation of the MQTT Protocol Latency over \nDifferent Gateways.\
    \ In Proceedings of the 3rd International Conference on Smart \nCity Applications\
    \ (SCA '18). Association for Computing Machinery, New York, NY, \nUSA, Article\
    \ 87, 1–5. DOI: https://doi.org/10.1145/3286606.3286864   \n \n(C4) Soukaina B.K.,\
    \ Ali Y., Mounir A., Marouane Salhaoui. (2019) Latency \nAssessment of MQTT Protocol\
    \ in Transferring Data from the Field to the Cloud \nOver Different Gateways.\
    \ In: Ben Ahmed M., Boudhir A., Younes A. (eds) \nInnovations in Smart Cities\
    \ Applications Edition 2. SCA 2018. Lecture Notes in \nIntelligent \nTransportation\
    \ \nand \nInfrastructure. \nSpringer, \nCham. \nhttps://doi.org/10.1007/978-3-030-11196-0_71\
    \  \n \n(C5) S. B. Kenitar, M. Arioua, A. Younes, M. Radi and Marouane Salhaoui,\
    \ \n\"Comparative Analysis of Energy Efficiency and Latency of Fog and Cloud \n\
    Architectures,\" 2019 International Conference on Sensing and Instrumentation\
    \ in \nIoT Era (ISSI), 2019, pp. 1-5, doi: 10.1109/ISSI47111.2019.9043738. \n\
    \ \n(C6) Yassine Yazid, Imad Ez-zazi, Marouane Salhaoui, Mounir Arioua, El Oualkadi\
    \ \nAhmed, Antonio Guerrero González. Extensive Analysis of Clustered Routing\
    \ \nProtocols For Heteregeneous Sensor Networks. Third International Conference\
    \ on \nComputing and Wireless Communication Systems, ICCWCS 2019, April 24-25,\
    \ \n2019, \nFaculty \nof \nSciences, \nIbn \nTofaïl \nUniversity \n-Kénitra- \n\
    Morocco. \nhttp://dx.doi.org/10.4108/eai.24-4-2019.2284208 \n \n(C7) Marouane\
    \ Salhaoui, Molina-Molina, J. C, A. Guerrero-González, Antonio; \nArioua, Mounir;\
    \ Ortiz, Francisco J.; El Oualkadi, Ahmed. Edge-Cloud Architectures \nUsing UAVs\
    \ Dedicated To Industrial IoT Monitoring And Control Applications. \nIEEE- International\
    \ Symposium on Advanced Electrical and Communication \nTechnologies ISAECT2020,\
    \ November 25th-27th, 2020 Ibn Tofail University, \nMorocco \n \n(C8) Benbarrad\
    \ Tajeddine; Salhaoui Marouane; Arioua Mounir. Impact of Standard \nImage Compression\
    \ on the Performance of Image Classification with Deep \nLearning. ICDATA21 (International\
    \ Conference on Digital Age & Technological \nAdvances for sustainable development),\
    \ 2021. 29 - 30 June 2021 Marrakech, \nMorocco. \n \n \n \nxiii \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \n \n \nContents  \n \n \nAbstract  \n\
    \ \nResumen \n \n صخلملا \n \nList of Acronyms  \n \nList of Publications  \n\
    \ \n1. Introduction   \n \n1.1 \nBackground \n \n1.1.1 Applications  \n1.1.2 IoT\
    \ Monitoring and Control \n1.1.3. Advantages of Using AI in the cloud \n1.1.4.\
    \ Constraints \n \n1.2 \nMotivation \n \n1.3 \nObjectives and contributions  \n\
    \ \n1.4 \nThesis organization  \n \n2. Performance analysis of IoT Monitoring\
    \ and Control System Based on \nUV, machine vision and artificial intelligence\
    \   \n \n2.1 \nIntroduction  \n \n2.2 \nUV IoT architecture  \n2.2.1. Most Common\
    \ IoT Architectures \n2.2.2. IoT Monitoring and Control Architecture Based on\
    \ Unmanned \nVehicles \n2.2.3 IoT Gateway Capabilities \n \nxiv \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \n2.3 \nUV & IoT Protocols \n \n2.3.1\
    \ UV Protocols \n2.3.2 IoT Protocols \n2.3.3 Industrial protocols \n2.3.4 OPC\
    \ UA protocol \n \n \n3. Performance and latency assessment using AI for UV  \
    \ \n \n3.1. Introduction  \n \n3.2. Related works \n \n3.3. Artificial Intelligence\
    \ and Machine Vision \n3.3.1 Artificial Intelligence \n \n3.3.1.2 Inference Versus\
    \ Training \n3.3.1.3 Methods of Machine Learning \n3.3.1.4 Convolutional Neural\
    \ Network for Object Recognition \n \n3.4. Cloud-Edge DL \n \n3.4.1 Cloud AI at\
    \ the edge \n3.4.2 Evaluating performance of an object detection model \n \n3.5.\
    \ Latency Assessment  \n \n3.5.1 Latency between Two Terminals \n3.5.2 OPC UA\
    \ Architecture and delay assessment \n3.5.3 UAV System Delay \n \n4. Energy Efficiency\
    \ and Latency of Smart IoT Monitoring and Control \nSystems Based on cloud Computing\
    \ and Intelligent Machine Vision \n \n4.1 Smart Industrial IoT Monitoring and\
    \ Control Systems Based on cloud \nComputing and Intelligent Machine Vision \n\
    \ \n4.2 Autonomous Underwater Monitoring System for Detecting Life on the Seabed\
    \ \nby Means of Computer Vision Cloud Services \n \nxv \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n4.3 Autonomous Marine Robot Based on AI Recognition\
    \ for Permanent \nSurveillance in Marine Protected Areas \n \n4.4 An IoT Control\
    \ System for Wind Power Generators \n \n5. Conclusions and future work  \n \n\
    5.1 Contributions summary  \n5.2 Future Works  \n \nBibliography  \n \n \nxvi\
    \ \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n \nList of Tables \
    \ \n \n \nTable 2.1. Main protocols used in the IoT field \nTable 2.2. Comparison\
    \ of Internet of Things (IoT) protocols \nTable 4.1. Confusion matrix. \nTable\
    \ 4.2. Specification of each machine environment. \nTable 4.3. RTD test of 5200\
    \ samples from the OPC UA client to the OPC UA server (PLC) \nover different clients\
    \ through different machines. \nTable 4.4. RTD Test of 200 photos sent from the\
    \ IoT gateway to the AR.Drone 2.0. \nTable 4.5. RTD test of 100 samples from the\
    \ IoT gateway to IBM Watson over different \nmachines.  \nTable 4.6. Speed Test\
    \ over the three gateways (S-G, RPI-G, PC-G). \nTable 4.7. GPS coordinates of\
    \ the area explored. \nTable 4.8. Accuracy measurement in different platforms.\
    \ \nTable 4.9. Latency measurement in different platforms. \nTable 4.10. Definition\
    \ of mission stages. \nTable 4.11. AI source preferences according to mission\
    \ stage. \nTable 4.12. RTD test of 300 samples of the Edge and Cloud model. \n\
    Table 4.13. Experimental SAAO results \nTable 4.14. Summary of SAAO logs during\
    \ the experiment \n \n \n \nxvii \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nList of Figures \n  \n \nFigure 1.1. A three-layer IoT architecture based\
    \ on: Device, Edge and Cloud for \nPredictive Maintenance (PM) [8]. \nFigure 1.2\
    \ Major limitations of current IoT platforms \nFigure 1.3 Mapping of interoperability\
    \ levels to OSI layers \nFigure 1.4.  Automation Pyramid vs Automation Network\
    \ [43] \nFigure 1.5. Capabilities comparison of cloud, on-device and edge intelligence\
    \ [40] \nFigure 2.1. Most common IoT architectures \nFigure 2.2. UV-IoT Architecture\
    \ \nFigure 2.3. Wiring diagrams in vehicles before and after the appearance of\
    \ CAN \nFigure 2.4. Controller area network bus node \nFigure 2.5. Node of the\
    \ CAN bus system \nFigure 2.6. Comparison of protocols for the exchange of messages:\
    \ (a) MQTT; (b) \nMODBUS TCP. \nFigure 2.7. The IEEE model (a); compared to the\
    \ HTTP (b); the CoAP (c); the MODBUS \nTCP (d); and the MQTT (e). \nFigure 2.8.\
    \ OPC UA in the automation pyramid \nFigure 2.9. Architecture of the OPC UA Server\
    \ \nFigure 3.1. Node-Red Platform \nFigure 3-2: Deep learning in the context of\
    \ artificial intelligence \nFigure 3-3. Connections to a neuron in the brain.\
    \ xi, wi, f (·), and b are the activations, \nweights, nonlinear function, and\
    \ bias, respectively \nFigure 3.4 Simple neural network example and terminology.\
    \ (a) Neurons and synapses. \n(b) Compute weighted sum for each layer. \nFigure\
    \ 3.5. Training and inference comparison \nFigure 3.6. Six-level rating for edge\
    \ intelligence \nFigure 3.7. IoU equation, Red is ground truth bounding box and\
    \ green is predicted \nbounding box \nFigure 3.8. Latency between two terminals\
    \ in a network \nFigure 3.9. OPC UA delay in OPC UA client server in an Ethernet\
    \ network \nFigure 3.10 Video transmission system delay sources. \nFigure 4.1:\
    \ Proposed UAV-IIoT Platform \nFigure 4.2. Development design of autonomous IIoT\
    \ flight \nFigure 4.3. Node-RED flow in the IoT gateway including the path from\
    \ the PLCs to the \nUAV, from the UAV to IBM Watson, and from Watson to the control\
    \ center. \nFigure 4.4. SCADA Industrial concrete plant with a typical concrete\
    \ formula. \nFigure 4.5. AR.Drone 2.0 mission in the concrete plant. \nFigure\
    \ 4.6. Communication process in the fog layer. \nFigure 4.7. Path used by the\
    \ drone to execute the mission in a concrete plant. \nFigure 4.8. Dataset used\
    \ to train the custom model in WVR service: (a) Shows images \nused to train the\
    \ Mixed class; (b) Shows Images used to train the Normal class. \nFigure 4.9.\
    \ Watson visual recognition test of new images not used in the training phase.\
    \ \nFigure 4.10. Node-RED flow and WVR results of an UAV photo. \nFigure 4.11.\
    \ OPC UA delay in OPC UA client server in an Ethernet network. \n \nxviii \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nFigure 4.12. Node-RED flow\
    \ used to calculate round trip latency (OPC UA Client to the \nOPC UA Server).\
    \ \nFigure 4.13. OPC UA client-server RTD to read one bit through different machines.\
    \ \nFigure 4.14. (a) Simulation results of CPU load (%) versus OPC UA RTD (ms)\
    \ in the S-G; \n(b) Simulation results of CPU load (%) versus OPC UA RTD (ms)\
    \ in the RPI-G. \nFigure 4.15. Probability density function of the delay of the\
    \ drone connected to the \ngateway when successive pictures from PC-G and RPI-G\
    \ are taken. \nFigure 4.16. Probability density function of the delay of the drone\
    \ connected to the \ngateway when successive pictures from S-G are taken. \nFigure\
    \ 4.17. CPU Load while taking successive photos and writing them in a folder in\
    \ \nthe PC-G. \nFigure 4.18. CPU Load while taking successive photos and writing\
    \ them in a folder in \nthe RPI-G. \nFigure 4.19. CPU Load while taking successive\
    \ photos and writing them in a folder in \nthe S-G. \nFigure 4.20. Probability\
    \ density function estimation of IBM WVR latency to classify an \nimage located\
    \ in the IoT gateway. \nFigure 4.21. Proposed AUV-IoT Platform \nFigure 4.22.\
    \ Proposed hardware architecture. \nFigure 4.23. Node intercommunications and\
    \ concurrent threads in the IoT gateway. \nFigure 4.24. Communication between\
    \ platforms. \nFigure 4.25. Fan mussel recognition training: defining a fan mussel\
    \ bounding box in \ndifferent cloud services. \nFigure 4.26. Pictures used for\
    \ custom CV model training. \nFigure 4.27. New specimen detection using the IBM\
    \ Python API. \nFigure 4.28. Triangular similarity using a single camera [47].\
    \ \nFigure 4.29. Closed control loop for object detection and tracking. \nFigure\
    \ 4.30. Basic closed-loop system with sensor and actuator delays. \nFigure 4.31.\
    \ Mission generated in IUNO and uploaded into AUV. \nFigure 4.32. Deploying the\
    \ platform to initiate the mission. AUV submarine connected \nto a buoy via a\
    \ DSL cable. \nFigure 4.33. Specimen detection and positioning in IUNO. \nFigure\
    \ 4.34. Communication edge cloud. (a) Training and inference in the cloud; (b)\
    \ \ntraining in the cloud, inference in the edge. \nFigure 4.35. Latency in the\
    \ proposed platform within the cloud architecture. \nFigure 4.36. Edge architecture\
    \ latency in the proposed platform. \nFigure 4.37. Cloud-based custom models for\
    \ detecting new specimens. \nFigure 4.38. BUSCAMOS-VIGIA framework. \nFigure 4.39.\
    \ BUSCAMOS-VIGIA ASV. \nFigure 4.40. Platform’s communications in the tracking\
    \ algorithm. \nFigure 4.41. SAAO diagram. \nFigure 4.42. Calculation of acceptable\
    \ latency limits. Main ASV camera point of view. \nFigure 4.43. Comparison of\
    \ three different clouds vision API detection of boat in Los \nNietos port (Murcia,\
    \ Spain). \nFigure 4.44. Types and number of vessels used to train the vision\
    \ custom models. \nFigure 4.45. Performance of the cloud custom model object detection\
    \ in discerning \ndifferent boat types. \n \nxix \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nFigure 4.46. Performance differences between the Edge\
    \ and the cloud custom models. \nFigure 4.47. Cloud and edge custom models for\
    \ detecting new vessels. \nFigure 4.48. Latency of more than 300 samples. \nFigure\
    \ 4.49. Images analysed. Cloud/edge results comparison \nFigure 4.50. Scale experiment.\
    \ Equivalence of area and distance from integral reserve \n(Islas Hormigas) to\
    \ base station (right) and equivalent area in Mar Menor (left). \nFigure 4.51:\
    \ Edge (left) / cloud (right) trained model recognition tests. \nFigure 4.52.\
    \ Start of mission (MMM) of surveillance of area equivalent to integral \nreserve.\
    \ \nFigure 4.53. (a) Stopped vessel detected. Start TM mode. (b) Tracking Mode\
    \ (TM) test \nduring the experiment.  \nFigure 4.54. Wind energy IoT communication\
    \ architecture \nFigure 4.55. Hardware Setup \nFigure 4.56. Data flow between\
    \ different systems and across different protocols. \nFigure 4.57. Checking OPC\
    \ UA connection using UaExpert Software \nFigure 4.58. Communication between the\
    \ PLC 1512 and IBM Cloud through OPC UA \nprotocol using Node-RED installed the\
    \ industrial Gateway IOT2040. \nFigure 4.59. Dashboard Data of wind Sensors in\
    \ the IoT2040 Gateway \nFigure 4.60. Dashboard data wind sensors in the IBM Watson\
    \ Platform. \n \n \n1 \n \n \nCHAPTER 1 \n \n \n \n--------------------------------------------------\
    \ \n \nIntroduction \n \n-------------------------------------------------- \n\
    \ \n \n \n \nThis chapter presents the background, motivation and main contributions\
    \ of \nthis thesis. It presents an overview of using computer vision and AI in\
    \ IoT \nmonitoring and its applications. The limitations are highlighted of using\
    \ AI in \nIoT monitoring and control and its main constraints as motivations for\
    \ the \npresented work. Subsequently, the main contributions of this thesis are\
    \ \npresented. Finally, the organization of this thesis is detailed. \n \n2.3\
    \ \nBackground  \n \nEmerging new market demands and autonomous technologies such\
    \ as IoT \nare moving the environment of manufacturing companies towards smart\
    \ \nfactories.  The fundamental idea of IoT is a system where physical objects\
    \ are \nenhanced with embedded electronics (RFID tags, sensors, etc.) and connected\
    \ to \nthe Internet. Thus, IoT is based on both smart objects and smart networks\
    \ [1]. The \ndevices in the IoT network can be employed for collecting information\
    \ based on \nthe use cases. These include retail, manufacturing industries, autonomous\
    \ \nvehicles, smart grid, etc. These IoT devices can be used for tasks such as\
    \ tracking \nitems and objects, remote monitoring, and fully autonomous robots.\
    \ It is reported \nthat the amount of IoT devices has been growing every year\
    \ with the predicted \nnumber of devices by 2025 reaching 75.44 billion [2]. \n\
    \ \n2 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nThe use of IoT has\
    \ become ubiquitous and IoT devices are common in many \nfields. The integration\
    \ of IT and Operational Technology (OT) in the Industrial \nInternet of Things\
    \ (IIoT) enables the “smart factory” concept. IIoT uses IoT \ndevices and sensors\
    \ to monitor machines and environments to ensure the highest \nperformance of\
    \ equipment and processes. \nIn practice, IoT has stimulated the factories and\
    \ the governments to launch \nan evolutionary journey toward the fourth industrial\
    \ revolution called Industry \n4.0. The first industrial revolution started with\
    \ the introduction of mechanical \nmanufacturing equipment, followed by a second\
    \ that entailed the mass \nproduction of goods.  Since the beginning of the 1970's\
    \ and until today, the \nincreasing automation and control of manufacturing processes\
    \ through the use \nof electronics and computers is considered the third revolution\
    \ (digital \nrevolution). Leveraging IoT technology in the manufacturing environment\
    \ leads \nto the fourth stage of industrialization [3]. \nAt the heart of IoT\
    \ and smart manufacturing is the basic principle of Industry \n4.0, products being\
    \ manufactured, components and production machines must \ncollect and share data\
    \ in real time. This leads to a shift from centralized factory \ncontrol systems\
    \ to decentralized intelligence.  \n The exchange of real-time data and information\
    \ between different devices \nand parties is the key element of smart factories;\
    \ this data could represent the \nstate of production. Therefore, the next generation\
    \ of smart factories will need to \nbe able to adapt, almost in real time, to\
    \ constantly technological options and \nregulations [4].  \nTo perform effective\
    \ predictive maintenance (PM), massive amounts of data \nare collected, processed\
    \ and ultimately analyzed by machine learning (ML) \nalgorithms. ML can be used\
    \ on collected data to make predictions. Indeed, the \naccuracy of ML models depends\
    \ primarily on the data collected. \nTraditionally, IoT sensors transmit their\
    \ data readings to the cloud for \nprocessing and modeling. Processing and transmitting\
    \ massive amounts of data \nbetween IoT devices and infrastructure comes at a\
    \ cost. Edge computing, in \nwhich sensors and intermediate nodes can process\
    \ data, can reduce data \ntransmission costs and increase processing speed. These\
    \ techniques can reduce \nthe amount of data sent to the cloud for processing,\
    \ however there are potential \naccuracy trade-offs when ML algorithms use reduced\
    \ data sets. Another \napproach is to move ML algorithms closer to the data to\
    \ reduce the amount of \ndata transmitted [5]. \nVisual recognition technologies\
    \ based on artificial intelligence (AI) and the \nInternet of Things (IoT) can\
    \ offer a detection capacity close to human capabilities \n[6]. The AI cloud services\
    \ allows training of customized ML models that are able \nto classify the received\
    \ data or detect individual objects in a given image along \nwith their bounding\
    \ box and label. There are many different cloud APIs for \ncomputer vision, e.g.,\
    \ IBM, Google, Microsoft Azure and Amazon. They all \n \n3 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nprovide fairly similar capabilities, although some emphasize\
    \ object recognition, \nAmazon, or building custom models, like Microsoft Azure\
    \ and IBM.  \nThe strength of these cloud APIs is their ability to develop custom\
    \ models \nrapidly and download trained custom models to deploy them on the edge\
    \ for \nreal-time applications and low-latency requirements [7-8]. \nWhen computing\
    \ is deployed at the edge for real-time data processing, \naccuracy is also of\
    \ paramount importance. Further, it is also clear that for data \nreduction, the\
    \ edge or device is mainly exploited. However, since the initial \ntraining is\
    \ computationally intensive, the cloud is still used in most of the \nproposed\
    \ techniques for model training. In cases where a dedicated edge node is \nnot\
    \ available, network devices can also be exploited.  \n \n1.1.1 APPLICATIONS \
    \ \n \nMany fields and industries are using IoT as part of their architecture\
    \ today. \nIn the following, we will look at some of them and how IoT can be used\
    \ to further \nimprovements. \n \nA. Smart Factory  \n \nThe main concept of Industry\
    \ 4.0 is smart manufacturing and IIoT, where the \ncomponent, product and machine\
    \ will exchange data on the basis of real time [9]. \nSince exchange of data between\
    \ different devices in real time is the main element \nof smart factory, this\
    \ information can be considered as control, production status, \nsupplier and\
    \ customer order feedback information, material movement, \nsimulation. Smart\
    \ factory will provide the customer with service and smart \nproduct, which will\
    \ be connected to a network based on IoT. The smart factory \ngathers and scans\
    \ data from a related smart application and the product. \n \nB. Smart Vehicles\
    \  \n \nA fully autonomous vehicle can be defined as a vehicle that is capable\
    \ of \nperceiving its environment, deciding on a route to its destination and\
    \ driving it. \nIt is a smart car or robocar that uses a variety of sensors, computer\
    \ processors \nand databases such as maps to take over some or all of the driving\
    \ functions of \nhuman operators. In a few words, an autonomous (or driverless)\
    \ car can also be \ndefined as a vehicle that relies on a combination of Internet\
    \ of Things (IoT) \ndevices (e.g., sensors, cameras, and lidars), appropriate\
    \ software, and artificial \nintelligence to move without a human operator [10].\
    \ \n \nC. Smart grid  \n \n \n4 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nToday most of the power supply system is manually operated, and due to \n\
    some human error, there is loss of power. These small losses result in massive\
    \ \noutrage of power supply. This loss can be brought under control, and a 100%\
    \ \nefficient power transfer system can be designed using IoT, and it is known\
    \ as the \nSmart grid. It is a fully automated system based on blockchain technology,\
    \ which \nis entirely robust & encrypted. This power is divided into channels\
    \ for each \nindividual, and this channel is wholly encrypted with its stash key,\
    \ which is to \nbe decrypted. This results in an equalized power supply throughout\
    \ the grid \nwithout any power loss [11]. Given that millions of end users will\
    \ be involved in \nthe processes and information flows of smart grids, the high\
    \ scalability of these \nmethods becomes an important issue. To solve these problems,\
    \ cloud computing \nservices emerge as a viable solution by providing reliable,\
    \ distributed and \nredundant capabilities on a global scale. Moreover, the implementation\
    \ of an \nintelligent network application on top of mixed cloud and edge processing\
    \ \nmiddleware is able to achieve higher performance by leveraging edge node \n\
    processing and data aggregation to reduce communication with the cloud \nenvironment\
    \ [12]. \n \n \nD. Monitoring environmental parameters   \n \nEnvironmental monitoring,\
    \ as an integral part of smart campuses, is an \napplication that describes any\
    \ activity in a surrounding area to monitor the \nquality of an environment [13].\
    \ It is used in the assessment of any risk that may \nbe posed to the environment\
    \ and humans. The applications of IoT in \nenvironmental monitoring are vast:\
    \ Industrial site monitoring, seabed \nmonitoring, sea or ocean monitoring, environmental\
    \ protection, extreme weather \nmonitoring, \nwater \nsafety, \nendangered \n\
    species \nprotection, \ncommercial \nagriculture, etc. In these applications,\
    \ sensors detect and measure every type of \nenvironmental change [14]. \n \n\
    E. Smart Waste Management  \n \nOne of the major issues that modern cities are\
    \ facing is waste management. \nIt consists of multiple processes like managing\
    \ and monitoring waste, transport, \ncollection, disposal, etc. These processes\
    \ are costly and time-consuming. One can \noptimize these processes to reduce\
    \ cost, which can be used for solving other \nissues that smart cities can be\
    \ deal with. For instance, various sensors can be \ninstalled in places like trucks\
    \ or cans of garbage, which can detect type and \namount of garbage [15]. \n \n\
    F. Smart agriculture  \n \n \n5 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nThanks to the IoT, it is possible to meet the food needs of a constantly \n\
    growing population. The analysis of smart agriculture data, i.e., land condition,\
    \ \nweather situation, and soil type, collected from the IoT network, can provide\
    \ \npractical information if used in combination with the data captured by sensors,\
    \ \nwhich measure the level of water resources, heat, humidity, chemicals, water\
    \ \nstress, pump condition, etc. This allows farmers to use fertilizers, water\
    \ and \npesticides in the most accurate amounts, at precise positions and with\
    \ efficient \nscheduling to improve crop yields. Smarter water use, such as monitoring\
    \ and \nsupervising the capacity, location, timing and period of water flow based\
    \ on data \nanalysis, increases irrigation efficiency and thus reduces costs [16].\
    \ \n \nG.  Smart Home  \n \nTo reduce user’s interference in controlling and monitoring\
    \ home settings as \nwell as home appliances, smart home is an emerging application\
    \ [17]. A smart \nhome provides many features for the user like measuring home\
    \ conditions (i.e., \nlight intensity, temperature, heating, etc.), operate home’s\
    \ Heating, Ventilating, \nand Air Conditioning (HVAC) appliances and control them\
    \ with reduced human \ninteraction [18]. Paper [19] presents an example of procedure\
    \ to develop a smart \nhome by combining IoT with cloud computing and web services,\
    \ use a platform \nfor implanting intelligence in actuators as well as in sensors\
    \ and facilitates \ninteraction within smart things using cloud services.  \n\
    \ \nH. Weather Forecasting  \n \nTo predict the state of the atmosphere for a\
    \ future time and for a given \nlocation, weather forecasting is very important.\
    \ Weather forecasting and \nmonitoring consist of a collection of data, assimilation\
    \ of data, and forecast \npresentation. Sensors at weather station used to sense\
    \ humidity, temperature \nwind speed, the moisture of soil, the intensity of light,\
    \ radiation, etc. Data coming \nfrom these sensors is huge in size and difficult\
    \ to monitor. The integration of this \nsensor infrastructure with cloud increases\
    \ its storage and computational \ncapabilities. It also provides effective solutions\
    \ for monitoring and presentation \nof data [20].  \n \nI. Health Care  \n \n\
    Sensors of pervasive healthcare applications make use of cloud computing \nand\
    \ IoT to allows a machine-to-machine communication regardless of the \nlocation\
    \ [21]. Nowadays, in modern hospitals, various body sensors are used to \nmeasure\
    \ and monitor physiological data of the patients. This sensitive collected \n\
    data is maintained for future diagnosis of patient. In some hospitals, this data\
    \ is \nmaintained at the local database. Due to this, doctors who are called to\
    \ handle \n \n6 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \ncritical cases\
    \ unable to analyze disease. After visiting to the patient only they can \ngive\
    \ proper treatment. However, using the cloud service, this issue can be solved\
    \ \ni.e., data of patients can be maintained and shared with doctors who are abroad,\
    \ \nso that they can treat the patient, independent of location [22].  \n \n1.1.2\
    \ IoT monitoring and controlling \n \nThe rising trends of the Internet of Things\
    \ (IoT) paradigm are attracting \nincreasing attention from both academia and\
    \ industry for their highly emerging \napplications of smartly connecting the\
    \ surrounding things or objects without \nhuman intervention [23]. Collecting\
    \ information from the surrounding \nenvironment to analyze, control, and making\
    \ correct action is the main idea for   \nIoT. To interchange data, IoT resources\
    \ using internet makes use of multiple \ninterconnected technologies like wireless\
    \ sensor network (WSN) and radio \nfrequency identification (RFID). IoT consists\
    \ of smart objects, which can be read, \nlocate, address, and control through\
    \ the internet using RFID, wireless LAN, or   \nsome other means [24]. In recent\
    \ time, IoT is getting more attention due to the \nadvancement of wireless technology.\
    \ The basic idea is due to variety of objects \nsuch as Sensors, RFID, actuators,\
    \ Near Field Communication (NFC), mobile \nphones, etc., which can interact with\
    \ each other by having a distinct address. \nArtificial Intelligence (AI) may\
    \ greatly support Internet of things in different \nways for physical (PHY), data\
    \ link (MAC), network, transport, and application \nlayers. AI cloud computing\
    \ is the fusion of machine learning (ML) capabilities of \nAI with cloud-based\
    \ computing environments, enabling connected, and intuitive \nexperiences. AI\
    \ has become more affordable through the use of cloud platforms. \nThe affordable\
    \ cost, coupled with cloud providers promoting AI as having a \nwidespread value,\
    \ leads to concerns that the technology will be misapplied. \nThere are different\
    \ IoT architectures adopted in research and development \nworks. The three-layer\
    \ IoT architecture shown in Figure 1.1, consists of a sensing \nor device layer,\
    \ which is also call as physical object layer whose main purpose is \nsensing\
    \ and data collection [25]. The second layer is the edge layer, its role is to\
    \ \nperform data transmission over the network, including sometimes being \nresponsible\
    \ for preprocessing and data storage before sending the data to the \ncloud. The\
    \ edge layer is also an appropriate place for ML deployment, allowing \nthe frameworks\
    \ to be implemented using hybrid architectures. \nA layer exists for the primary\
    \ processing of data. Data can be stored and \nprocessed by high-performance servers.\
    \ Predictive maintenance (PM) can \nmonitor machine health to determine likely\
    \ component failure. ML optimization \nmodels are deployed to help make intelligent\
    \ decisions about which production \nparameters to monitor. \n \n \n7 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \nFigure 1.1. A three-layer IoT architecture\
    \ based on: Device, Edge and Cloud for Predictive \nMaintenance (PM) [25]. \n\
    \ \n \n1.1.3. Advantages of Using AI in the cloud \n \nAI technology is being\
    \ applied in most cloud services to drive interest in \napplication development.\
    \ Typical offerings combine the ability to leverage AI \nservices at a lower cost\
    \ with important data management systems that provide \nthe source of the data,\
    \ and thus the source of the models.  \nCloud-based AI solutions are different;\
    \ however, they have some \ncommonalities, as well as benefits and limitations.\
    \ First of all, the great benefit is \nthat these systems are inexpensive to operate.\
    \ To drive an AI application, \npayment can be made per hour used of each service.\
    \ This is perhaps the largest \nbenefit of cloud AI, really bringing AI down to\
    \ the level of a basic enabling \ntechnology. \nPublic clouds also offer cheap\
    \ data storage. Real databases or storage systems \ncan be leveraged as data input\
    \ into AI applications. Finally, they all provide SDKs \nand APIs that allow us\
    \ to integrate AI features directly into applications, and they \nsupport most\
    \ programming languages. \nWhile AI is a technology that allows a machine to simulate\
    \ human behavior, \nML is a subset of AI that allows a machine to automatically\
    \ learn from prior data \nwithout explicit programming. ML as a service (MLaaS)\
    \ is an umbrella concept \n \n8 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nof various cloud-based platforms that cover most infrastructure issues such\
    \ as \ndata pre-processing, model training, and model evaluation, with further\
    \ \nprediction. \nML offers several advantages, including accurate predictions,\
    \ speed, \nautomation, and scalability [26]. The ML method uses algorithms to\
    \ analyze data, \nfind rules and abstract the rules into models to classify and\
    \ predict unknown \ndata. It can significantly enhance the efficiency of data\
    \ processing and the \naccuracy of prediction results by applying machine learning\
    \ methods to \nmonitoring complex IIoT data. Furthermore, it can also detect abnormal\
    \ \nconditions of the IIoT to the greatest extent possible and reduce the loss\
    \ of \nproperties and lives [27]. On the one hand, Deep learning (DL) structures\
    \ the \nalgorithms into multiple layers in order to create an “artificial neural\
    \ network \n(ANN)”. Complex DL models are being developed, and in addition, CE\
    \ research \nis accelerating to provide more computational resources for DL models\
    \ to \nsupport more applications [28]. Prior to the use of ML in IIoT, the cognitive\
    \ ability \n(to learn the environment) of machines was simply a predefined heuristic.\
    \ \nHowever, sophisticated ML algorithms have improved the cognitive capability\
    \ \nby finding patterns in the data and making predictions [29]. \n \n1.1.4. Constraints\
    \ \n \nIoT is a novel paradigm to interconnect massive wireless devices, which\
    \ has \nthe potentials to be applied in diverse applications and fields. However,\
    \ due to a \nhuge number of wireless devices in IoT networks, many technical challenges\
    \ \nneed to be addressed, Figure 1.2 presents some limitations of current IoT\
    \ \nplatforms. \n \nFigure 1.2 Major limitations of current IoT platforms \n \n\
    \ \n9 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nBased on the presented\
    \ limitations, there are imperative directions that have \nto be considered in\
    \ the future for IoT research studies. \n \nA. Scalability  \n \nThe growing idea\
    \ of IoT which generates a tremendous amount of data for \nprocessing and storage\
    \ guide to enormous leap in the forthcoming year, and \nhence it becomes insistent\
    \ on making the scalable system. The vast application of \nIoT has increased the\
    \ number of devices being connected to the internet, which \nmeets the concern\
    \ to consider various complications that are arising in \nconnectivity [25]. Different\
    \ sources like the internet, social media, machine, and \nmany other devices generate\
    \ data. Thus, special attention must be given for \ntransportation, access, storage,\
    \ and processing of these large sets of structured \nand unstructured digital\
    \ data [25].  \n \nB. Interoperability  \n \nAs the data sharing among smart devices\
    \ is increasing day by day, it is \nnecessary to manage these data transfer properly\
    \ among the system [30]. \nInteroperability can be considered as the potentiality\
    \ of two systems to \ncommunicate, exchange information, or program, or transfer\
    \ the data among \neach other and to implement the given data [31]. It is the\
    \ exchange of information \namong different computers through wide area networks\
    \ or local area networks. \nIt is critical for IoT as most of the communication\
    \ takes place as a machine to \nmachine [32]. \n \nC. Real-Time (Delay)  \n \n\
    Meeting real-time latency requirements depends on how data is collected \nand\
    \ processed [33]. This becomes more severe as IoT applications that involve \n\
    rich data types such as images evolve. In addition, developing real-time analytics\
    \ \nin the cloud is nearly impossible to achieve. \nA variety of IoT applications\
    \ require local analytics. For instance, in the \ncontext of IIoT, to quickly\
    \ turn on or off a piece of equipment in a production \nenvironment can prevent\
    \ a catastrophic situation. Analytics depend on ML \nalgorithms that are computationally\
    \ expensive for some tiny sensors. In addition, \nthe power consumption of small\
    \ sensors has been one of the main concerns even \nbefore the emergence of ML\
    \ in IoT. Thus, achieving the goal of real-time with a \nsensor cloud architecture\
    \ seems ambitious. \nThe limited computational capacity of sensor nodes is a major\
    \ challenge. \nTherefore, a hybrid architecture to implement computationally intensive\
    \ tasks \nsuch as training on the cloud and model deployment for prediction on\
    \ the \nsensing node has emerged. However, this approach also presents challenges\
    \ in \n \n10 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nthe case where\
    \ models require retraining based on new data. In this case, all new \ndata must\
    \ be moved to the cloud, which incurs costs in terms of latency, energy \nconsumption,\
    \ and network resource usage [34]. \n \nD. Accuracy  \n \nThere are many possibilities\
    \ for designing a Neural Network (NN) model, \nprovided that different hyperparameters\
    \ in the network provide a different level \nof accuracy. Particularly, a high\
    \ accuracy model requires more memory than a \nlow accuracy model due to the number\
    \ of parameters. The metric used to \nmeasure accuracy depends on the domain in\
    \ which the ML algorithm is applied. \nIn IIoT, a traditional approach to data\
    \ collection is to stream data from \nsensing devices to the cloud where it is\
    \ processed and modeled. Sensing devices \ngenerate huge amounts of data, continuously\
    \ or periodically, often in a very short \nperiod of time. For instance, in one\
    \ second, thousands of records can be generated \nby one machine [35]. According\
    \ to the Cisco cloud index (2013-2018), an \nautomated facility can generate one\
    \ terabyte of data per hour. For this purpose, \napproaches such as sampling,\
    \ compression, filtering are used to reduce the size \nof data. These techniques\
    \ reduce the amount of data transmitted to the cloud. \nHowever, there are potential\
    \ accuracy trade-offs for ML models that use reduced \ndatasets, as the accuracy\
    \ of ML models depends primarily on the data collected. \nThe accuracy of models\
    \ trained on reduced data should also be a concern \nwhen optimizing for energy\
    \ consumption and latency. This is more important in \ndeep learning approaches\
    \ that require more data to be trained. \nIn current IIoT systems based on edge\
    \ computing, edge devices can only \nperform lightweight computing tasks. To enable\
    \ edge devices and servers to \nperform more complex tasks with higher data processing\
    \ performance and lower \nlatency, edge intelligence (EI) is applied to the IIoT\
    \ edge to make the devices and \nservers intelligent. However, an AI model can\
    \ be trained to make predictions and \ndecisions with high accuracy; however significant\
    \ amounts of training and \nverification data are required. For edge devices,\
    \ training and operating the AI \nmodel is challenging due to limited computing\
    \ and storage resources. \n \nE. Security  \n \nAs the IoT trend inflates multiple\
    \ interconnections and device heterogeneity, \nit eventually generates cyber-attacks.\
    \ Thus, data security is one of the most \ncritical issues. As there is an increase\
    \ in the number of connected devices, there \nare possibilities of cyber-physical\
    \ security vulnerabilities that can be exploited by \nvarious attackers [36].\
    \ Security is a key pillar of the internet, which is the main \nchallenge of IoT.\
    \  \nTherefore, it is necessary to learn from these incidents: industries are\
    \ now the \ntarget of attackers and there is an urgent need to address this issue.\
    \ IIoT is \n \n11 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nsometimes thought\
    \ of as the integration of operational technology (OT) and \ninformation technology\
    \ (IT), with OT comprising the factory network where \nmanufacturing is performed\
    \ and IT comprising the enterprise network [37]. \nThese two components have different\
    \ security requirements, which must be \naddressed to prevent compromise of the\
    \ IIoT infrastructure. \n \n1.2 Motivation  \n \nAlthough IoT has been widely\
    \ used in the above applications, a number of \ncritical limitations have hindered\
    \ the use of AI in various implementations. These \nlimitations tend to mainly\
    \ affect the system response time and the efficiency of \nthe proposed solution.\
    \ The various aspects of DL that need to be improved in an \nIoT concept include\
    \ smart algorithms with improved efficiency and support for \nbetter platforms.\
    \ For this reason, the following issues had to be investigated to \novercome these\
    \ limitations of using AI in IoT architecture. \n \nA. Interoperability \n \n\
    Recent advances in manufacturing technology, such as industrial internet, \ncyber–physical\
    \ systems, AI (Artificial Intelligence), and machine learning have \ndriven the\
    \ evolution of manufacturing architectures into integrated networks of \nautomation\
    \ devices, services, and enterprises. One of the resulting challenges of \nthis\
    \ evolution is the increased need for interoperability at different levels of\
    \ the \nmanufacturing ecosystem. Interoperability means the ability of two or\
    \ more \nparties, machine or human, to make a perfect exchange of content.  \n\
    The IoT is a dynamic global network infrastructure with self-configuring \ncapabilities\
    \ based on interoperable, standard communication protocols, enabling \nall objects\
    \ to communicate with each other. The application of IoT to the \nindustrial domain\
    \ has given rise to a new research area called the Industrial \nInternet of Things\
    \ (IIoT). IIoT is a new service-oriented industrial ecosystem that \nuses networked\
    \ interconnection of industrial resources, data interoperability, \nand system\
    \ interoperability to enable flexible resource allocation, rational \nprocess\
    \ optimization, on-demand process execution, and rapid adaptation of \nenvironments\
    \ [38]. In general, interoperability is defined as the ability of \nheterogeneous\
    \ networks, applications, or computer components to exchange and \nuse information,\
    \ i.e., to speak and comprehend each other [39]. Suited to the IoT \ncontext,\
    \ this refers to the ability of heterogeneous components to exchange and \nshare\
    \ data and functions to achieve a desired goal (defined by a use case or \napplication),\
    \ regardless of the communication protocol used or the format of the \nexchanged\
    \ data.  \nUp to only a few years ago the communication systems for industrial\
    \ \nautomation aimed only at real-time performance suitable for industry and \n\
    \ \n12 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nmaintainability based\
    \ on international standards [40]. The Industry 4.0 concept \nhas the flexibility\
    \ to achieve interoperability between the different industrial \nengineering systems.\
    \ To connect the different industrial equipment and systems, \nthe same standards\
    \ and safety levels are required. Open Platform \nCommunications Unified Architecture\
    \ (OPC UA) is a machine-to-machine \n(M2M) communications protocol developed to\
    \ create inter-operable and reliable \ncommunications and is now generally accepted\
    \ as standard in industrial plant \ncommunications [41].  \nThe domain extends\
    \ from software, devices, and control systems on the \nfactory floor to Internet-based\
    \ cloud platforms that provide various on-demand \nservices. \nA successful implementation\
    \ of interoperability in smart manufacturing \nwould therefore result in efficient\
    \ communication and error-free data exchange \nbetween machines, sensors, actuators,\
    \ users, systems and platforms. The \narchitecture and platforms used by machines\
    \ and software packages are a major \nchallenge in this regard. A better understanding\
    \ of the subject can be obtained by \nstudying industry-specific communication\
    \ protocols and their respective logical \nsemantics.  \nTo be more precise and\
    \ in accordance with [42], three levels of \ninteroperability can be specified\
    \ to achieve horizontal interoperability between \ndifferent components, each\
    \ level covering a different facet of interoperability and \ncommunication: \n\
    \ \n• Technological interoperability is given if the two components are physically\
    \ \nconnected to each other and can transmit any type of information on the \n\
    transmission layer [42]. This level of interoperability concerns the lower \n\
    transmission layers of the OSI model (i.e., the physical, data link, network and\
    \ \ntransport layers) and the corresponding protocols. \n \n• Syntactic interoperability\
    \ is ensured if the data format, including encodings, \nas well as the communication\
    \ interface format are clearly defined and agreed \nupon between the two components\
    \ [42]. The abstract term \"communication \ninterface format\" refers to the protocol\
    \ used on the application layer and \nprovided as communication interface by the\
    \ respective component. As with \ntechnological interoperability, it is not necessarily\
    \ required that the two \ncomponents agree on the same protocol, as long as there\
    \ is a possibility of \nadapting two different protocols (the same applies to\
    \ the format and encoding \nof the data embedded in the protocol(s)). \n \n• Semantic\
    \ interoperability is ensured if both components agree on the same \ninformation\
    \ model describing the topic of the exchanged information as well \nas the provided\
    \ communication interfaces [42] (i.e., the meaning of the \nexchanged messages\
    \ with respect to the used protocol). \n \n13 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 1.3 depicts the mapping of these three interoperability\
    \ levels defined \nin [42] to the OSI layers. It should be noted that this mapping\
    \ is not strict and that \nthe boundaries between the OSI layers may vary depending\
    \ on the \nimplementation of the application concerned. \n \n \nFigure 1.3 Mapping\
    \ of interoperability levels to OSI layers \n \n \nThe evolution from traditional\
    \ hierarchical models of enterprise control \nsystem integration, or automation\
    \ pyramid, to integrated networks of smart \ndevices, \ncloud \nservices, \nand\
    \ \nextended \nenterprises \nrequires \nseamless \ncommunication and information\
    \ exchange between heterogeneous and \ntraditionally silent systems (Figure 1.4).\
    \  \nDifferent types of interoperability problems may arise, due to the diverse\
    \ \nnature of interactions in the emerging automation networks. Thus, there is\
    \ a need \nfor vertical interoperability between devices and shop floor automation\
    \ services, \nas well as horizontal interoperability between enterprises and cloud\
    \ service \nplatforms. \n \n \n \n \n14 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \n \nFigure 1.4. Automation Pyramid vs Automation Network [43] \n\
    \ \n \nB. Low-latency and ultra-Reliability \n \nThe industrial smart facility\
    \ requires multiple synchronized processes that \nrequire low latency and higher\
    \ reliability to achieve the necessary performance \n[44]. Furthermore, AI methods\
    \ applied to IIoT must be able to address these \nissues as well as other parameters\
    \ such as network deployment and resource \nmanagement [45]. Nevertheless, the\
    \ competence and usefulness of DL-based IIoT \nscenarios are still in the evolutionary\
    \ phase, requiring exclusively the strict low-\nlatency and ultra-reliability\
    \ requirements of IIoT. Therefore, further research \nefforts are needed in this\
    \ direction to establish a theoretical and practical \nbackground for DL-IIoT\
    \ to ensure low-latency and ultra-reliable communication. \nFast and efficient\
    \ computing is another key feature that can affect not only \nlatency and reliability\
    \ but also many other performance parameters in smart \nindustries. As mentioned\
    \ earlier, IIoT requires powerful and useful tools to \ncompute big data obtained\
    \ from various processes and analyze them on specific \nplatforms including servers,\
    \ transmission media, and storage. \nIntelligence at the edge should push DL computations\
    \ from the cloud to the \nedge as much as possible, enabling various distributed,\
    \ low-latency and reliable \nintelligent services, as shown in Figure 1.5. \n\
    \ \n15 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nDL services can be\
    \ deployed close to the requesting users and the cloud only \nintervenes when\
    \ additional processing is required [46], which significantly \nreduces the latency\
    \ and cost of sending data to the cloud for processing. \n \n \n \nFigure 1.5.\
    \ Capabilities comparison of cloud, on-device and edge intelligence [47] \n \n\
    Currently, hybrid cloud-edge computing is used to perform fast and efficient \n\
    computation and provides a comprehensible computing infrastructure for IIoT. \n\
    It is considered appropriate to use the edge-based computing infrastructure due\
    \ \nto its ability to reduce latency and improve the learning process in the network.\
    \ \nNonetheless, the integration of distributed and edge computing infrastructure\
    \ \nfor IIoT remains an open research issue [48]. Particularly, the coupled realization\
    \ \nof distributed and parallel learning for edge-based designs requires further\
    \ \noptimization to attain higher productivity, self-organization, and lower runtime.\
    \ \n \n \nC- Energy consumption of mobile IoT devices \n \nRobotic engineering\
    \ systems are deployed in industry today and are \nconsidered vital to the progress\
    \ of humanity from an industrial perspective in \nthe new digital age. \nThe Internet\
    \ of Robotic Things (IoRT) empowers robotic objects in different \nenvironments\
    \ to be active players in various applications and to share and \nexchange information\
    \ with other robotic objects, IIoT devices and humans. IoRT \napplications are\
    \ developing in parallel with IIoT advancements, combining \ninformation technology\
    \ (IT) used for data-centric computing and operational \n \n16 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \ntechnology (OT) used in enterprise and\
    \ industrial operations integrating \nsupervisory control and data acquisition\
    \ (SCADA) systems and programmable \nlogic controllers (PLCs), where industrial\
    \ applications are increasingly \nintegrated, and where new smart connectivity\
    \ networks are used.  \nTransferring large datasets to a central cloud is an energy-intensive\
    \ \noperation, and new computing paradigms are being used and implemented for\
    \ \nIoRT applications. Smart connectivity networks can facilitate the transfer\
    \ and \nprocessing of information in an energy-efficient and high-performance\
    \ manner. \nHowever, deployed batteries have a specific charge rate and, therefore,\
    \ the \noperating time of robots is limited. Autonomous mobile robots are powered\
    \ by \nbatteries mounted on their platforms to provide energy to the on-board\
    \ sensors, \nmicrocontrollers, peripheral modules and servos.  \nDevelopments\
    \ in IoT, AI, and connectivity technology [49] enable IoRT \napplications to reduce\
    \ power consumption and improve energy efficiency, \nresulting in lower costs\
    \ and latency. Energy efficiency, real-time processing, \ncomputation, and analysis\
    \ efficiency of IoRT devices, efficient task offloading, \nand intelligent service\
    \ response time of other IoRT devices and agents must be \naddressed by developing\
    \ new collaborative processing techniques at the edge. \nAlong with ensuring dynamic\
    \ network/resource slice management, dynamic \ndevice management, and the necessary\
    \ containment between different IoRT \ndevices and different complex applications.\
    \ \n \n1.3 Objectives and contributions \n \nThe objective of this thesis is to\
    \ develop and evaluate a real-time IoT \nframework capable of connecting AI cloud\
    \ services with different industrial \nsystems and platforms, trying to overcome\
    \ the limitations and challenges \nshowed in previous sections. Therefore, the\
    \ required systems and networks must \nensure the optimal trade-off between response\
    \ time and system accuracy, \nkeeping in mind that cloud computing is introduced\
    \ in the control loop. In this \ncontext, the main objectives of this work are:\
    \ \n \n1. The design of an IoT architecture to enable interoperable systems \n\
    connecting different IoT devices using different protocols and technologies, \n\
    together with the different proposed systems and networks. To this end, some \n\
    considerations were considered: \n \n \n- \nProtocols and software suitable for\
    \ interoperability and connectivity \nconstraints: The interoperability challenge\
    \ can be overcome by using \nadvanced software deployed in the IoT gateway, which\
    \ can be considered \nas the junction interface between the physical and cloud\
    \ worlds. This \n \n17 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    software must interact simultaneously with the different systems \ninvolved through\
    \ different protocols.  \n \n- \nThe appropriate devices capable of providing\
    \ minimal response time: The \nchoice of an IoT gateway is crucial in terms of\
    \ latency and accuracy, as it \nis at the heart of processing and transmitting\
    \ data to the different systems \nand platforms. \n \n \n2. To further improve\
    \ the trade-off between latency and accuracy, the \nfollowing points are considered:\
    \ \n \n- \nThe most efficient cloud computing solutions for each use case: The\
    \ \nimplemented cloud services must ensure that data is transferred, \nprocessed\
    \ and returned at speeds that meet the needs of the application. \n \n- \nFlexibility\
    \ to use AI models in the edge and the cloud for improved \nperformance: The ability\
    \ to deploy the cloud AI models at the edge can \nfacilitate the use of cloud\
    \ technologies in different sectors. In addition, the \nhybrid cloud/edge architecture\
    \ must ensure a real-time control loop for \nrelevant latency and accuracy. \n\
    \ \nContributions:  \n \nThe main innovative contribution of this thesis is to\
    \ include cloud services in \na control loop, to improve the decision making of\
    \ a factory and improve the \nperformance of an industrial control system.  \n\
    Cloud AI services can also be integrated into a drone control loop as an input\
    \ \ncontributing to improve the monitoring capability to find and track stationary\
    \ \nand moving objects. To this end, the work in this thesis has been divided\
    \ into \nseveral parts depending on the scenario used. Thus, several contributions\
    \ could \nbe enumerated: \n \n1. The validation of the IoT architecture proposed\
    \ in this thesis in the industry \nas a way to control and monitor the status\
    \ of devices and systems integrating \nIoT protocols and edge-computing \n \n\
    2. The Introduction of cloud services computer vision (CV) techniques as a part\
    \ \nof the industrial control loop to improve the operation of the production\
    \ \nprocess in a factory. \n \n3. The integration of CV cloud services into the\
    \ control loop of a drone for \nmonitoring and seeking for a new object using\
    \ the drone's cameras. \n \n18 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \n4. The demonstration of that a hybrid AI cloud architecture can solve the\
    \ \nproblem of latency and accuracy of the control system. Choosing the correct\
    \ \nAI CV cloud services is crucial in terms of latency and accuracy of the control\
    \ \nsystem, as the systems need to respond in real time with accuracy.  \n \n\
    5. The use of edge computing topology to reduce latency in low-bandwidth \nenvironments.\
    \ Cloud computing topology improves accuracy at the expense \nof increased latency.\
    \ To meet the system’s requirements, in this thesis, a smart \nalgorithm to optimize\
    \ autonomy is propose and developed. This Is done by \nselecting the appropriate\
    \ AI technology for the scenario being monitored. \nThis proved to be crucial\
    \ in deciding the best source of artificial intelligence \nto be used to achieve\
    \ the specified objectives in each stage in real time. The \nproposed smart algorithms\
    \ ensure a trade-off between latency and accuracy. \n \n6. The validation of the\
    \ proposed IoT architecture for an autonomous marine \nrobot for protection and\
    \ permanent surveillance in marine protected areas \nbased on AI cloud recognition\
    \ services. \n \n \n2.5 Thesis organization \n \nThis thesis is organized and\
    \ divided into 5 chapters. This first chapter has \nbeen dedicated to the presentation\
    \ of IoT, especially Industrial IoT, and the \nchallenges faced in using an IoT\
    \ architecture as the one presented in this thesis. \nMoreover, we discuss the\
    \ constraints and benefits of using AI in the cloud and \nfinally the main motivations\
    \ and contributions of this thesis have also been \nrevealed. The core of this\
    \ thesis is detailed in the following chapters:  \n \n \nChapter 2: Outlines the\
    \ IoT Monitoring and Control Architecture Based on \nUnmanned Vehicles and defines\
    \ some of the protocols adopted in Industrial IoT. \nIt describes also the types\
    \ of IoT architectures, and the use of computer vision \nand AI at the edge using\
    \ cloud services. \n \nChapter 3: This chapter provides an overview of the different\
    \ solutions \nproposed to employ artificial intelligence for monitoring systems\
    \ in an IoT \narchitecture. We start with a review of the state of the art for\
    \ the different AI \ntechniques used for an interoperable IoT architecture. Then,\
    \ a comparison \nbetween the different proposed methods is highlighted. We discuss\
    \ the different \nmethods and factors used to appraise the latency and accuracy\
    \ of the proposed \n \n19 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nAI models and finally a latency assessment for an unmanned vehicle IoT \n\
    architecture. \n \nChapter 4: This chapter focuses on monitoring and control applications\
    \ in a \nIoT architecture. This chapter presents different applications using\
    \ advanced \ndevices and robots to control and monitor areas using computer vision\
    \ and AI \ncloud services. The proposed AI approaches are compared in terms of\
    \ latency \nand accuracy to validate their performance.  \nThe first application\
    \ was about a wind power system connected to the IBM \ncloud for monitoring. The\
    \ second application was to feed results from AI services \nin the cloud into\
    \ an industrial control loop. The AI results come from an \nunmanned aerial vehicle\
    \ camera taking images of materials being transported in \na concrete plant. The\
    \ other application, proposes an AUV model system designed \nto track a species\
    \ of Mediterranean fan mussel, using cloud computing services \nwith edge computing\
    \ as alternative processing units. \nThe latter, proposes an autonomous marine\
    \ robot for protection and \npermanent surveillance in marine protected areas\
    \ based on AI cloud recognition \nservices. \n \nChapter 5: Summarizes the contributions\
    \ of the whole thesis and outlines \nsome directions for future work. \n  \n \n\
    \ \n \n20 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nCHAPTER\
    \ 2 \n \n \n \n-------------------------------------------------- \n \nPerformance\
    \ analysis of IoT Monitoring \nand Control System Based on UV, \nMachine Vision\
    \ and Artificial \nIntelligence \n--------------------------------------------------\
    \ \n \n \n \n \n2.1 Introduction  \n \nAutonomous vehicles have played an increasingly\
    \ important role in \nmonitoring different environments, they are now considered\
    \ one of the best \nremote sensing techniques for collecting data over large areas.\
    \ They are now used \nin different sectors as detection tools to proactively solve\
    \ or prevent many \nproblems. In industry, as an example, unmanned aerial vehicles\
    \ (UAVs) can be \nused for inspections [50], to quantify production and monitor\
    \ construction \nprocesses [51] \nand help make decisions.  \nAutonomous underwater\
    \ vehicles (AUVs) are widely used in various marine \napplications: visual inspection\
    \ of infrastructures [52], aquaculture [53], marine \nbiodiversity mapping [54],\
    \ marine geoscience [55], and visual monitoring of \nmarine life [56] and recovery\
    \ of autonomous underwater vehicles [57]. \nUSVs are currently the subject of\
    \ a number of publications related to ocean \nmonitoring applications related\
    \ to weather/storm forecasting and disaster \n \n21 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nmanagement [58]. They can play a critical role in disaster\
    \ research [59] by \nreplacing rescue teams in remote and dangerous areas [60],\
    \ or by monitoring \ncovered environmental areas such as water bodies [61], or\
    \ by performing long-\nterm monitoring [62]. AI has the potential to be a powerful\
    \ tool and be deployed \nfor marine area surveillance by detecting and recognizing\
    \ vessels through \nartificial intelligence (AI)-based image recognition services.\
    \ \nComputer vision (CV) has particularly improved the field of object detection\
    \ \nand image classification. Visual recognition systems can reach impressive\
    \ \nperformances, thanks to the latest developments in neural networks, in particular\
    \ \ndeep learning (DL). Although all the developed DL algorithms can be deployed\
    \ \nin the cloud, the present cloud computing systems are unable to manage and\
    \ \nanalyze the massive amount of computing power and data. Edge intelligence\
    \ is \nenvisioned to replace DL computing in the cloud, providing a variety of\
    \ reliable, \nlow latency, distributed intelligent services. \n The IoT gateway\
    \ is used to connect the autonomous vehicles and control \nsystems to the internet\
    \ and cloud services, it is able to connect the sensor network \nto the cloud\
    \ computing infrastructure and perform edge and fog computing and \nserves as\
    \ a bridge between sensor networks and cloud services.  \nIntegrating autonomous\
    \ robots into the IoT represents an interoperability \nchallenge, as every IoT\
    \ system has its own communications protocol. Moreover, \na small error or delay\
    \ beyond the tolerated limit could result in a disaster for \nvarious applications.\
    \ The IoT gateway must not only address the challenge of \ninteroperability of\
    \ interconnected systems but also process and transmit data in \nreal-time. \n\
    The current cloud computing system is increasingly unable to cope with the \n\
    massive amount of data it receives [63]. Edge computing, which is composed of\
    \ \nsmart nodes and could take the place of cloud processing, is expected to solve\
    \ \nthis problem since it is closer to the users than the cloud [64]. These smart\
    \ nodes \nrange from smart gateways to offsite ruggedized nodes, to on-premises\
    \ heavy \nstorage nodes and data center servers at the edge. \nNew architectures\
    \ have recently been proposed to address the latency issue. \nA hybrid cloud/edge\
    \ architecture can provide a real-time control loop for better \nlatency and accuracy\
    \ and meet several system requirements. \nThis chapter begins with a description\
    \ of the architecture of three IoT layers, \nand its main components, from data\
    \ detection to its processing. It describes \nseparately the technology used in\
    \ each layer for different use cases. We discuss \nthe use of computer vision\
    \ techniques at the edge and in the cloud, and the effect \nof interoperability\
    \ and real-time requirements. Finally, we end the chapter by \npresenting the\
    \ different cloud APIs used. \n \n2.2 UV IoT architecture \n \n \n22 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n2.2.1. Most Common IoT Architectures \n\
    \ \n1. Common IoT Architectures \n \nOne of the main challenges in the technology\
    \ domain to support the \ndeployment of IoT systems is to define a reference architecture\
    \ that supports both \ncurrent and future features. Therefore, such an architecture\
    \ must be: -scalable, -\ninteroperable, -distributive, -able to operate with few\
    \ resources (Computational \npower) -secure so as not to allow unauthorized access.\
    \ \nCurrently, a single reference architecture does not exist, and creating one\
    \ is \nvery complicated regardless of many standardization efforts. One of the\
    \ main \nproblems is related to the natural fragmentation of possible applications,\
    \ each of \nwhich depends on many different variables and design specifications.\
    \ Figure 2.1 \ndescribes some of the most common IoT architectures. \n \n \nFigure\
    \ 2.1. Most common IoT architectures [67] \n \n2. Three-Layer architecture  \n\
    \ \n- Perception, represents the physical layer of the objects and includes all\
    \ the \nfeatures. \n- Network, that stands for the communication layer responsible\
    \ for the \ntransmission of data to the application layer through various protocols\
    \ and \ntechnologies. \n- The application, which is the application layer in which\
    \ the software offering a \nspecific service is implemented. \n \n \n23 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \n \n3. Service-oriented architecture\
    \ \n \nIt represents the four-layer IoT architecture based on SoA, in which there\
    \ is \nthe perception layer, the network layer, the service layer and finally\
    \ the \napplication layer. The SoA is designed to coordinate services and enable\
    \ the reuse \nof hardware and software components. Generally, SoA is based on\
    \ a component \nmodel, which can be designed to connect different functional units\
    \ of \napplications through interfaces and protocols [65-66-67]. \nSoA can be\
    \ easily integrated into the IoT architecture, by extending the three-\nlayer\
    \ architecture, by adding a new layer between the network layer and the \napplication\
    \ layer, called the service layer, which provides services to support the \napplication\
    \ layer. \n \n4. Middleware Architecture \n \nAnother important and very common\
    \ architecture in IoT is the middleware-\nbased IoT architecture or five-layer\
    \ architecture [68]. A five-layer is composed of \nfive levels: perception layer,\
    \ network layer, middleware layer, application layer, \nand business layer. \n\
    Middleware is gaining more and more importance in recent years due to its \nmajor\
    \ role in simplifying the development of new services and integrating legacy \n\
    technologies into new ones.  \nA proposed IoT architecture has to consider many\
    \ factors such as reliability, \ninteroperability, scalability, quality of service,\
    \ etc. In this regard, middleware \nbased IoT architectures help create applications\
    \ more efficiently; they act as a \nconnection between users, data and applications.\
    \ \nMiddleware, in general, is a software or programming service that can \nprovide\
    \ an interposed abstraction between IoT technologies and applications. In \nmiddleware,\
    \ the details of the different technologies are hidden, and standard \ninterfaces\
    \ are provided to allow developers to focus on application development \nwithout\
    \ regard to compatibility between applications and infrastructures. \nMiddleware\
    \ architecture has various advantages, as it can support various \napplications,\
    \ standard protocols, provides standard interfaces and can run on \nvarious operating\
    \ systems and platforms. Middleware plays an important role in \nstandardization,\
    \ providing portability and standard protocols to enable \ninteroperability and\
    \ interaction of services between heterogeneous networks, \ndevices and applications.\
    \ \nMiddleware supports distributed computing and provides a stable high-\nlevel\
    \ interface for applications. \nRegardless, the middleware layer has some critical\
    \ functionality, such as \naggregation and filtering of data received from hardware\
    \ devices, information \nretrieval and device access control for applications.\
    \ \n \n24 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nIn summary,\
    \ depending on the application, it may be necessary to add \nadditional layers\
    \ or adapt the architecture to the specific application to be \nrealized. An architecture\
    \ can be realized by being adapted to the context of \nexisting IoT architectures,\
    \ such as a server-based architecture, or an architecture \nbuilt from scratch\
    \ such as cloud-based architectures, Edge computing-based \narchitectures, or\
    \ Social Internet of Things (SIoT) architectures [67]. \n \n2.2.2. IoT Monitoring\
    \ and Control Based on Unmanned Vehicles \n \nA drone monitoring system is developed\
    \ as a control system to reduce the \ntime and cost of inspection. The integration\
    \ of drones or unmanned vehicles into \nthe IoT architecture can be presented\
    \ in three layers (Figure 2.2), with drones \nbeing part of the first layer as\
    \ the data generation layer. The first layer can also \ncontain a control system\
    \ connected to a central collection point, which is the IoT \ngateway. The second\
    \ layer is edge/fog computing for computation, storage and \ncommunications. The\
    \ last layer is a cloud back-end with image processing \ntechniques. The Edge/fog\
    \ layer connects the control layer to the drone system, \nthe drone system to\
    \ the cloud, and finally the cloud to the control system. \n \nIn general, the\
    \ Three-Layer architecture can be defined as below:  \n \n• Generation and control\
    \ layer: this represents the physical layer of the objects \nand includes all\
    \ the control systems. \n• Network and data communication layer (Edge/Fog): this\
    \ is the \ncommunication layer responsible for transmitting data to the visualization\
    \ \nand processing layer through various technologies and protocols, can also\
    \ be \nused as a processing layer in case of real time applications. \n• The visualization\
    \ and processing layer, which represents the application layer \nin which the\
    \ software offering a specific service is actually implemented or \nmay just be\
    \ an interface to analyze and visualize the data received from the \nconnected\
    \ systems. \n \n \n \n25 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \n \nFigure 2.2. Industrial UV-IoT Architecture \n \n \nThe control system\
    \ (controllers) receives data from remote or connected \nsensors that measure\
    \ the process variables’ (PVs) setpoints (SP). When the system \ndetects a trend\
    \ change between PVs and SP, the change is routed to the \nprogrammable logic\
    \ controllers (PLCs) and the central point (IoT gateway) to \ntrigger the UV system’s\
    \ reaction. \nThe traditional monitoring system illustrated by humans is replaced\
    \ by a \nremote computing algorithm in the cloud and a UV system, in that the\
    \ UV camera \nserves as an additional monitoring sensor that is processed in the\
    \ cloud to imitate \nthe visual inspection of an operator. The UV can navigate\
    \ to a specific point to \noversee the process using the front camera. The UV\
    \ system is triggered \nautomatically by responding to sensor data from the monitoring\
    \ system and data \nanalyzed in the IoT gateway. The IoT gateway receives the\
    \ captured photos and \nsends them to the cloud, which adopts deep learning techniques\
    \ to analyze and \nsend the results to the IoT gateway and the control system\
    \ to confirm the \nanomaly and make the necessary changes. \n \n2.2.3 IoT Gateway\
    \ Capabilities \n \nThe IoT gateway is capable of connecting the sensor network\
    \ to the cloud \ninfrastructure, performing edge computing, and serving as a bridge\
    \ between the \nsensor networks and cloud services [69]. \n \n26 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nIn the IoT gateway, various software and\
    \ APIs can be installed to establish \nthe connection with different parts of\
    \ each IoT layer. It also allows collecting, \nprocessing, and transmitting the\
    \ data and results to other systems for further \nprocessing or decision making.\
    \ \n In the IoT gateway, various IoT software and APIs, drone libraries and AI\
    \ \nmodels can be installed. These packages are required to ensure the transmission\
    \ \nof data between the different systems according to the protocols involved.\
    \ Since \neach IoT system has its own communication protocol, the IoT gateway\
    \ has to \nsupport different communication protocols, which presents an interoperability\
    \ \nchallenge. \nAn IoT gateway can be defined as a physical device with software\
    \ programs \nand protocols that mediate between smart devices, sensors, controllers\
    \ and the \ncloud. The IoT gateway provides the necessary connectivity, security\
    \ and \nmanageability, while some of the existing devices cannot share data with\
    \ the \ncloud [70]. \n \n2.4 \nUV & IoT Protocols \n \n2.3.1 UV Protocols \n \n\
    Unmanned vehicles (UVs) are widely used for civilian and military \napplications.\
    \ They can be used for remote sensing, transportation, scientific \nresearch,\
    \ search and rescue, and armed attacks. They can be used in applications \nwhere\
    \ human presence is dangerous, or in repetitive surveillance and monitoring \n\
    tasks. Unmanned vehicles can be equipped with sensors, cameras, \ncommunication\
    \ equipment and weapons.  \nUVs are primarily equipped with omni-directional antennas,\
    \ although \ndirectional antennas can also be used to increase the gain of the\
    \ \ntransmitter/receiver, at the cost of designing a mechanism to control the\
    \ direction \nof the antenna.  \nUnmanned vehicles (UVs) can operate autonomously\
    \ or be remotely piloted \nby ground teams. UVs can communicate with the base\
    \ station using different \nprotocols, depending on the network structure and\
    \ the design of the UV system. \nCANbus (CANopen, NMEA2000), Ethernet and WiFi\
    \ (TCP/IP, UDP), RS232, are \nthe most commonly used protocols in autonomous vehicles.\
    \ In this section we \nwill mainly address the CANbus protocol. \n \n \n• CAN\
    \ Protocol \n \nBack in the 1980s, progress in automotive electronics had made\
    \ the number \nof devices that were suddenly required in vehicles grow in a worrying\
    \ way. All \nthese devices had to be connected in some way, generally to each\
    \ other, causing \n \n27 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nan alarming increase in the amount of wiring that had to be introduced into\
    \ a \nvehicle (As shown in Figure 2.3). All this led to problems of assembly,\
    \ \nstandardization of equipment, connections and weight. \nIn February 1986,\
    \ Robert Bosch presented CAN (Controller Area Network) \nat the Society of Automotive\
    \ Engineers (SAE) as a solution to the problem of \nwiring in vehicles. Intel,\
    \ as a manufacturer, and Mercedes-Benz, as a collaborator \nin the development\
    \ project, also worked together on developing the bus. \n \n \nFigure 2.3. Wiring\
    \ diagrams in vehicles before and after the appearance of CAN \n \nIn 1987, Intel\
    \ released the first CAN integrated, followed shortly after by \nPhilips Semiconductors.\
    \ After several improvements and disputes with other \nmanufacturers, it became\
    \ a standard (version 2.0) in 1993, the specifications of \nwhich are reflected\
    \ in ISO11898. Although CAN was initially developed for the \nautomotive industry,\
    \ its robustness and the efficiency of its protocol have \nallowed its entry into\
    \ many industrial applications requiring high transfer rates \nand high reliability\
    \ in the face of errors. Manufacturers in fields as diverse as \nelevators (Kone\
    \ in Finland) and textile machinery have used CAN in their \nproducts. \n \n \n\
    28 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nCAN Characteristics\
    \  \n \nCAN is one of the widest known vehicle bus standards for vehicle networks.\
    \ \nIt is very popular in industrial and automotive applications because of an\
    \ \naffordable and flexible design, which reduces the number of wires. For example,\
    \ \nthe number of wires has been reduced by 40% in the Peugeot 307, which \nincorporates\
    \ two CAN buses [71]. CAN is a message-based protocol; the packets \nhave no information\
    \ about the sender and receiver of the messages, and each \nnode can read the\
    \ messages transmitted over the bus. Functions supported by \nthe protocol in\
    \ the automotive domain are automatic start/stop, parking \nassistance, electric\
    \ parking brakes, collision avoidance, automatic lane detection, \netc. Figure\
    \ 2.4 shows a CAN bus node. It includes a central processing unit (CPU), \nthe\
    \ CAN controller and a transceiver. The function of the CPU is to decode the \n\
    received messages and decide which messages to transmit. Each node can send \n\
    or receive messages, but not simultaneously. A message or frame consists of an\
    \ \nID and a data payload of up to eight bytes (64 bits). \n \n \nFigure 2.4.\
    \ Controller area network bus node \n \nThe network uses two cables as a transmission\
    \ medium. The two cables are \nCAN High and CAN Low. All the system nodes connected\
    \ to the CAN bus \nthrough the corresponding hardware interface. All nodes share\
    \ the same data \nchannel. Each node consists of a CAN Transceiver, CAN Controller\
    \ and CPU as \nshown in Figure 2.5. \n \n \n29 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 2.5. Node of the CAN bus system \n \nThe CAN protocol is\
    \ optimized for short messages and uses a CSMA/CD \nwith NDBA (Carrier Sense Multiple\
    \ Access / Collision Detection with Non-\nDestructive Bitwise Arbitration) arbitration\
    \ access method. A node that needs to \ntransmit a message waits until the bus\
    \ is free and then starts to send the identifier \nof its message bit by bit.\
    \  \n \n2.3.2 IoT Protocols \n \nThere are a large number of protocols that can\
    \ be used in the IoT. Table 1 \nshows some of the most commonly used protocols,\
    \ grouped according to the \nISO/OSI model. Each has advantages and disadvantages,\
    \ and their use must be \nevaluated based on the application. The choice of which\
    \ protocol to use is \ndetermined by the size of the network, the energy consumption\
    \ of each node, \nand the transmission speed needed for a given application. For\
    \ instance, the IPv6 \nprotocol was born first to solve the problem of address\
    \ space (which, with the \nold IPv4 protocol, was about to run out) and second\
    \ to ensure scalability of \nsystems. Nevertheless, this protocol is designed\
    \ for wired networks. To address \nwireless sensor networks (WSN), the 6LoWPAN\
    \ protocol [72] was created. \n \nTable 2.1. Main protocols used in the IoT field\
    \ \nApplication Layer \nCoAP, MQTT, AMQP, XMPP, DSS \nService Discovery: mDMS,\
    \ DNS-SD, SSDP \nSecurity: TLS, DTLS \nTransport Layer \nTCP, UDP \nNetwork Layer\
    \ \nAddressing: IPv4/IPv6                Routing: RPL, CORPL, CARP, etc. \n \n\
    30 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nAdaption Layer \n6LoWPAN,\
    \ 6TiSCH, 6Lo, etc. \nData Link Layer \nIEEE 802.15.4       IEEE 802.15.1    \
    \ LPWAN      RFID, NFC  \n(ZigBee, etc.)        (Bluetooth)    (LoRaWAN, etc.)\
    \  \nIEEE 802.11      IEEE 802.3      IEEE 1901  \n(Wi-Fi)      (Ethernet)   \
    \   (PLC)      Z-Wave \nPhysical Layer \n \n \nIoT devices can support various\
    \ interoperable communication protocols, \nwhether Internet-related or service-related,\
    \ and can communicate with other \ndevices of different genre and infrastructure.\
    \  \n \n2-3-3. Industrial Protocols \n \nEtherCat, CANOpen, Modbus/Modbus TCP,\
    \ Ethernet/IP, PROFIBUS, \nPROFINET, DeviceNet, IEEE802.11, ISA100.11a, and Wireless\
    \ HART are the \nmost frequently used industrial protocols [18]. Until a few years\
    \ ago, \ncommunication systems for industrial automation only aimed at industry-\n\
    specific real-time performance and maintainability based on international \nstandards\
    \ [73]. The Industry 4.0 concept has the flexibility to provide \ninteroperability\
    \ between different industrial engineering systems. To connect \ndifferent industrial\
    \ equipment and systems, the same standards and security \nlevels are needed.\
    \ Open Platform Communications Unified Architecture (OPC \nUA) is a machine-to-machine\
    \ (M2M) communication protocol developed to \ncreate interoperable and reliable\
    \ communications and is now widely accepted as \na standard in industrial plant\
    \ communications [74]. \nAnother important industrial protocol that is still largely\
    \ used in most plants \nis MODBUS TCP exclusively for synchronous polling communications;\
    \ this \nsolution is compatible with most industrial control systems and SCADA-type\
    \ \napplications. However, if asynchronous event-based communications are \nrequired,\
    \ MQTT complements MODBUS TCP operations. The Message Queuing \nTelemetry Transport\
    \ (MQTT) is a lightweight, publish-subscribe network \nprotocol that transports\
    \ messages between IoT devices. An Industrial Internet of \nThings (IIoT) environment\
    \ integrates an event-based message-oriented protocol, \ni.e., MQTT, with a polling-based\
    \ request–response protocol, intended for \nindustrial applications, i.e., MODBUS\
    \ TCP.  \nMODBUS meets industrial requirements, primarily for remote control,\
    \ \nmonitoring and automation functions. MQTT works in parallel with MODBUS \n\
    TCP and complements its functions, however, cannot replace MODBUS [75]. \n \n\
    31 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nHTTP can also be used\
    \ in conjunction with MODBUS, as a web-based real-\ntime data monitoring system\
    \ that uses MODBUS TCP communications, in which \nall data is displayed in a real-time\
    \ graph in a web browser, which is refreshed at \nregular intervals using HTTP\
    \ polling communications [76]. \nThese protocols use the client–server communication\
    \ architecture. MQTT \nuses the publish–subscribe model and is message-oriented,\
    \ whereas HTTP uses \nthe request–response model and is a document-oriented protocol.\
    \ Thus, HTTP is \none-to-one (peer-to-peer), and MQTT is one-to-many. \nThe figure\
    \ 2.6 illustrates a comparison between the MODBUS philosophy \nand the MQTT philosophy\
    \ from a message exchange perspective. The MODBUS \nrequest uses a TCP connection\
    \ and employs a frame format based on an \noptimized application layer message\
    \ structure dedicated to telecontrol and \nmonitoring. The case is different with\
    \ MQTT; while the first client (publisher) \ngenerates an event using four messages,\
    \ the second client (subscriber) consumes \nthis event in six messages. \n \n\
    \ \nFigure 2.6. Comparison of protocols for the exchange of messages: (a) MQTT;\
    \ (b) \nMODBUS TCP. \n \n \nThe Internet of Engineering Task (IETF) has developed\
    \ a lighter application \nprotocol (Constrained Application Protocol (CoAP)) for\
    \ constrained IoT devices \noperating in lossy environments.    \nBased on UDP,\
    \ CoAP is an efficient and lightweight protocol compared to \nother IoT protocols\
    \ such as MQTT, HTTP, etc. CoAP also achieves reliable \ncommunication between\
    \ nodes in wireless sensor networks, along with features \nsuch as resource discovery,\
    \ resource observation, congestion control, etc. These \n \n32 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \ncapabilities of CoAP have enabled CoAP\
    \ to be implemented in various domains \nranging from home automation to health\
    \ management systems [77]. \nCoAP uses a specific infrastructure—namely, 6LoWPAN\
    \ (IEEE802.15.4)—\nwhich employs IPv6 in the network layer. Both HTTP and MQTT\
    \ use an \ninexpensive and available communication infrastructure, which is Internet\
    \ or \nIntranet in wireless mode (Wi-Fi—IEEE 802.11) or wire mode (Ethernet—\n\
    IEEE802.3) —which may employ either IPv4 or IPv6 in the network layer. In the\
    \ \ntransport layer, HTTP and MQTT protocols use TCP port numbers 80 and 1883,\
    \ \nrespectively. However, CoAP uses UDP port number 5683. Given that MQTT is\
    \ \nevent-based, it is a message-oriented protocol. Thus, CoAP mimics HTTP in\
    \ \nusing polling-based messaging, but in a shorter time and smaller frame-size,\
    \ \ntable 2 depicts more the difference between these protocols. \n \nTable 2.2.\
    \ Comparison of Internet of Things (IoT) protocols \nFeature \n \nHTTP \nCoAP\
    \ \nMQTT \nMODBUS TCP \ninfrastructure \nnetwork layer \ntransport layer \ntransport\
    \ port \nmodel \npattern \nmechanism \nmethodology \nparadigm \nquality level\
    \ \nstandard \nencoding \nsecurity \nEthernet, Wi-Fi \nIPv4 or IPv6 \nTCP \n80,\
    \ 443 \nsynchronous \nrequest-response \none-to-one \ndocument-oriented \nlong\
    \ polling-based \none level \nIETF (RFC7230) \nASCII text \nSSL, TLS \n6LoWPAN\
    \ \nIPv6 \nUDP \n5683 \nAsynchronous \nboth \none-to-one \ndocument-oriented \n\
    polling-based \ntwo: CON or NON \nIETF (RFC7252) \nRESTful (Binary) \nDTLS  \n\
    Ethernet, Wi-Fi \nIPv4 or IPv6 \nTCP \n1883, 8883 \nasynchronous \npublish-subscribe\
    \ \none-to-many \nmessage-oriented \nevent-based \nthree: QoS 0, 1, 2 \nISO/IEC,\
    \ OASIS \nUTF-8 (Binary) \nSSL, TLS \nEthernet, Wi-Fi \nIPv4 or IPv6 \nTCP \n\
    502, 802 \nSynchronous \nRequest-response \none-to-one \nbyte-oriented \npolling-based\
    \ \none level \nmodbus.org \nBinary \nTLS \n \nIn Figure 2.7, a comparison between\
    \ the different protocols is conducted \nbased on the protocol communication model\
    \ in the original IEEE model. CoAP \nruns over the connection less UDP in the\
    \ transport layer, whereas in the network \nlayer, CoAP uses either IPv6 or 6LoWPAN.\
    \ When CoAP uses IPv6, it is necessary \nfor it to use Ethernet or Wi-Fi for the\
    \ data link and physical layers, respectively. \nWhen CoAP uses 6LoWPAN, it employs\
    \ IEEE 802.15.4e for the data link and \nphysical layers. \nThe MODBUS TCP and\
    \ the MQTT protocols are both in the same level in the \nIEEE model. While the\
    \ MODBUS TCP uses a byte-encoded frame format for the \nuser data, which is intended\
    \ for industrial applications, the MQTT protocol \nencodes the user data in UTF-8.\
    \ \nThe content (payload) of HTTP may vary according to the type of transferred\
    \ \ndata, called content-type, which could be plain text, PDF application, HTML,\
    \ \nXML, GIF image or audio. For the exchange of data using HTTP, XML is used,\
    \ \nwhich handles verbose plain text for solving interoperability issues. However,\
    \ \n \n33 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nfor CoAP, the\
    \ efficient XML interchange (EXI) [78] is used, which encodes \nverbose XML documents\
    \ in binary format, if interoperability is considered [75]. \nThis is normally\
    \ used for constrained devices to increase the performance \nand decrease the\
    \ consumed power. Hence, CoAP is suitable for constrained \ndevices in IoT-based\
    \ wireless sensor networks that employ IPv6-based \ninfrastructure. However, it\
    \ needs a gateway to exchange data over the Internet. \n \n \n \nFigure 2.7. The\
    \ IEEE model (a); compared to the HTTP (b); the CoAP (c); the MODBUS \nTCP (d);\
    \ and the MQTT (e). \n \nIn summary, there are many IoT protocols, and event-based\
    \ protocols are of \nconsiderable interest for data transfer in the form of notifications\
    \ to complement \nthe MODBUS TCP protocol. This MODBUS protocol is polling-based,\
    \ \nsynchronous, request-response, and optimized for control and monitoring in\
    \ \nindustrial applications, it can establish an IIoT environment. MQTT can \n\
    complement MODBUS TCP with its asynchronous model, event-based \nparadigm, and\
    \ publish-subscribe model. On the other hand, CoAP requires a \nspecific infrastructure,\
    \ and a gateway to move data over the Internet, which adds \nadditional costs\
    \ and causes complications for the environment. \n \n2-3-4. OPC UA Protocol \n\
    \ \nThe Internet's ubiquity is unfortunately only one aspect of this new era,\
    \ not \neven the main one. The most studied topic is the utopian \"single protocol\"\
    \ (i.e., \naccepted by any application market, industry and consumer) that could\
    \ \nintelligently and flexibly describe methods and data. There are several examples\
    \ \nof shared and widely used protocols in specific application markets, and \n\
    probably in the industry the most accepted protocol that harmonizes machine-\n\
    to-machine (M2M) interaction is OPC UA (Open Process Communications \n \n34 \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nUnified Architecture). The\
    \ OPC Foundation achieved great success with the \n\"OPC Classic\" protocol and\
    \ is now offering the OPC UA protocol as a more \npowerful successor for its platform-independent\
    \ architecture. \nOPC systems, particularly the latest OPC UA version, plays an\
    \ important \npart in current industrial environments, and more specifically to\
    \ sustain the \nupcoming IIoT environments [79-80]. Basically, they provide a\
    \ standard way to \nestablish a reliable and secure data exchange between industrial\
    \ devices from \nmultiple providers and software systems. This provides us with\
    \ an interface or \ngateway that allows us to interact directly with PLC. In fact,\
    \ OPC UA can be \nconsidered the basic protocol for harmonizing different industrial\
    \ automation \nnetworks and systems [73]. \nAs shown in Figure 2.8, OPC UA has\
    \ been designed to facilitate the exchange \nof information across the hierarchy\
    \ of systems that commonly coexist in industry: \ncontrol systems; manufacturing\
    \ execution systems (MES); enterprise resource \nplanning (ERP); and, finally,\
    \ field devices. OPC UA has a message-based \ncommunication and a service-oriented\
    \ architecture (SOA) with clients and \nservers connected to any types of networks.\
    \ \n \n \nFigure 2.8. OPC UA in the automation pyramid \n \n \nFigure 2.9 reveals\
    \ the architecture of the OPC UA server. The server \napplication is the code\
    \ that implements the server function. Real objects are \nphysical or software\
    \ objects that are accessible by the OPC UA server or \ninternally maintained\
    \ by it, such as physical devices and diagnostic counters. \nParticular objects,\
    \ such as Nodes, are used by OPC UA servers to represent real \nobjects, their\
    \ definitions and references; all nodes are called Address Space.  \n \n35 \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nNodes are accessible by clients\
    \ using OPC UA services (interfaces and \nmethods) [80]. In other words, the OPC\
    \ UA address space is the information \nmodel for the communication: real hardware\
    \ devices or real software “objects” \n(sensors, actuators, software applications,\
    \ etc.) are available for OPC UA \ncommunication only if they are modelled, added\
    \ to the address space and finally \ndiscovered by the OPC UA clients. In the\
    \ OPC UA API, there is a discovery \nservice that can be used to find available\
    \ OPC UA servers and to explore their \naddress space. Clearly, the OPC UA communication\
    \ stack converts the calls to \nthe OPC UA API to proper messages for the underlying\
    \ network layers. \n \n \nFigure 2.9. Architecture of the OPC UA Server \n \n\
    \ \nA client application may use the OPC UA client API (application program \n\
    interface) in order to send/receive OPC UA service requests/responses to/from\
    \ \nthe OPC UA server. From the programmer point of view, the OPC UA client API\
    \ \nis like an interface that decouples the client application code from the client\
    \ OPC \nUA communication stack. \n  \n \n \n \n36 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \nCHAPTER 3 \n \nRelated works and evaluation of the\
    \ \nlatency of the proposed architecture \n--------------------------------------------------\
    \ \n \n \n1- Introduction  \n \nOne of the main concerns of IoT is the interconnectivity\
    \ and integration of \ndifferent systems in the same architecture. Different challenges\
    \ can arise when it \ncomes to achieving this interconnectivity. \n Ensuring reliable\
    \ communications with all the devices and platforms \ninvolved is a major challenge\
    \ due to the diversity of protocols used in each \nconnected part. Interoperability\
    \ is considered as the primary issue to be solved, \nespecially when new technology\
    \ solutions need to be connected to existing \nnetworks. In addition, most IoT\
    \ architectures need to react in real time while \nensuring the highest level\
    \ of accuracy. Delay in connections affects not only the \ndecision-making, but\
    \ also the energy consumption for different energy \nconstrained devices [81].\
    \ \nThe use of new technologies and their connection to existing networks is \n\
    increasing. Different protocols, APIs and software have been introduced to \n\
    facilitate the interaction of connected systems and services. Node-RED, which\
    \ is \nan effective option for applications to prototype some IoT connectivity,\
    \ is a \ngraphical tool created by IBM to wire together hardware devices, APIs\
    \ and online \nservices. \nPython is also considered a programming tool for IoT\
    \ projects, which has \nbuilt-in support for scientific computing. Its use is\
    \ growing fastest in data science \nand machine learning. Versatility, stable\
    \ libraries with great support and ease of \nuse are its main advantages [82].\
    \ These platforms can be good solutions for \ninteroperability, as they have most\
    \ of the libraries that can facilitate connections \nbetween different systems.\
    \ \n \n37 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nThe communication\
    \ protocols of the IoT platform allow different devices to \ncommunicate and share\
    \ their data with controllers or decision centers. IoT \nplatforms offer the ability\
    \ to select the type of communication technologies based \non the needs of the\
    \ application. However, not all protocols can be used in all \nscenarios. \nIndustry\
    \ now faces the challenge of making the IT network compatible with \nits machines,\
    \ including interoperability, fog/cloud computing, security, latency, \nand quality\
    \ of service. One of the proposed solutions is smarter IoT gateways \n[83], which\
    \ are the bridges between the traditional network and sensor networks \n[84].\
    \ The IoT gateway provides the necessary connectivity, security, and \nmanageability,\
    \ while some of the existing devices cannot share data with the \ncloud [85].\
    \ \nMost of IoT gateways can support all the necessary tools and protocols \n\
    needed to provide communication, computation and storage. The IoT gateway \ncan\
    \ affect the performance of an IoT system in terms of latency and accuracy, \n\
    especially when different software and APIs are implemented. It can be \nconnected\
    \ to the physical layers and transmit the received data to be processed \nin the\
    \ cloud. Using the cloud for AI solutions has its advantages and \ndisadvantages.\
    \ The IoT gateway can be used to implement cloud-based AI \nmodels at the edge\
    \ for processing and decision making, which makes the choice \nof IoT gateway\
    \ selection so crucial for a high-performance IoT architecture. \n \n2- Related\
    \ works \n \n \n2-1 Industrial Protocols  \n \n \nEtherCat, CANOpen, Modbus/Modbus\
    \ TCP, EtherNet/IP, PROFIBUS, \nPROFINET, DeviceNet, IEEE802.11, ISA100.11a, and\
    \ Wireless HART are the \nmost frequently used industrial protocols [86]. Due\
    \ to the incompatible \ninformation models for the data and services of the different\
    \ protocols, \ninteroperability between the different systems with different protocols\
    \ is always \ndifficult. The Industry 4.0 concept has the flexibility to achieve\
    \ interoperability \nbetween the different industrial engineering systems. To\
    \ connect the different \nindustrial equipment and systems, the same standards\
    \ and safety levels are \nrequired. Open Platform Communications Unified Architecture\
    \ (OPC UA) is a \nmachine-to-machine (M2M) communications protocol developed to\
    \ create inter-\noperable and reliable communications and is now generally accepted\
    \ as standard \nin industrial plant communications [87]. OPC UA is an independent\
    \ service-\noriented architecture that integrates all the functionality of the\
    \ individual OPC \nClassic specifications into one extensible framework [88].\
    \ OPC UA enable to \n \n38 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nconnect sub-manufacturing systems and ensure real-time communication \nbetween\
    \ devices and can be deployed in a service-oriented architecture for the \noptimization\
    \ of industrial applications [89]. \n \nOPC UA can allocate all manufacturing\
    \ resources, including embedded \nsystems, to specific areas and extensible computing\
    \ nodes through the address \nspace and a pre-defined model. It solves the problem\
    \ of unified access to the \ninformation of different systems [10]. Infrastructure\
    \ protocols have been \nproposed in many studies; for instance, in [90-91] an\
    \ edge IoT gateway was \ndeveloped to extend the connectivity of MODBUS devices\
    \ to IoT by storing the \nscanned data from MODBUS devices locally and then transferring\
    \ the changes \nvia an MQTT publisher to MQTT clients via a broker. \n \n2-2 Visual\
    \ Programming Languages \n \nVisual Programming Languages (VPL) are widely used\
    \ in IoT applications, \nin [92], a survey on Visual Programming Languages (VPL)\
    \ for IoT was proposed. \nThe analysis mainly focused on comparing them on the\
    \ basis of the programming \nenvironment, project repository, licensing, and supported\
    \ platforms. Some of \nthem are Open-Source platforms, while others are proprietary.\
    \ Among the Open-\nSource platforms (Node-RED, Modkit, miniBloq, NooDL, NETLab,\
    \ Ardublock, \nand Scratch), only some can be programmed using a Web interface\
    \ and executed \non some dockers or on-cloud virtual machines. \nIn addition to\
    \ being open source and having the possibility of adding new \nmodules and functionalities,\
    \ Visual Programming Language (VPL) IoT platforms \nshould exhibit a number of\
    \ non-functional requirements \nThey should demonstrate the capabilities of robustness,\
    \ availability (in terms \nof availability and fault tolerance), scalability,\
    \ security, full respect for privacy, \ninteroperability and openness, etc. \n\
    There are tools that make it easier for devices and their functionality to be\
    \ \ncomposed and combined at a higher level with IoT applications. For the device\
    \ \nlevel, an example of a tool is Node-RED that supports IoT application \ndevelopment\
    \ with a visual flow programming approach (Figure 3.1). Node-RED \nprovides an\
    \ integrated view of the application and the network and interacts \nsimultaneously\
    \ with the different systems involved through different protocols. \nIn [73] Node-RED\
    \ is used in both the IIoT gateway and the Cloud application, \nwhere a methodology\
    \ is proposed to measure delay metrics in OPC UA systems \nto study the impact\
    \ that QoS parameters have on the communication delay from \nthe production line\
    \ to the Cloud and vice versa.  \n \n \n39 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 3.1. Node-Red Platform \n \nIn [93] Node-RED is proposed\
    \ and applied in an IoT application for oil \nleakage detection in wind turbine\
    \ bearings. In [94], a new method introduced to \nmigrate Node-RED workflows into\
    \ a decentralized execution environment, so \nthat such workflow scan run on Edge\
    \ networks, where nodes are extremely \ntransient in nature. \nThe programming\
    \ of IoT applications is carried out in several ways, using \ndifferent tools\
    \ [95]. For example, in the Google IoT platform, various \nprogramming languages,\
    \ such as Java, Node.js, Python, PHP, Go, Ruby, and C#, \ncan be utilized to program\
    \ data flows from devices to dashboards. In these cases, \ndata flows are deployed\
    \ using programming languages. \n \n2.3 IoT architecture for Robots \n \nImplementing\
    \ an Industry 4.0 architecture requires integration of the latest \ntechnologies,\
    \ for example, IIoT, cyber-physical systems, additive manufacturing, \nbig data\
    \ and data analytics, cyber-security, cloud and edge computing, \naugmented and\
    \ virtual reality, as well as autonomous robots and vehicles [96]. \nA typical\
    \ cloud robotics architecture is based on two elements: the cloud \nplatform and\
    \ its associated equipment and the bottom facility. Bottom facilities \nusually\
    \ encompass all kinds of mobile robots, unmanned aerial vehicles, \nmachines,\
    \ and other equipment [97]. The next generation of robots will include \ninterconnected\
    \ industrial robots [98], cobots [99] and autonomous land vehicles \n(AGVs) [100].\
    \ Cobots support human workers in various tasks, while robots can \ncarry out\
    \ specific tasks, such as looking for objects or transporting tools. \nUnmanned\
    \ Vehicles (UVs) are among the emerging robot technologies that \nleverage the\
    \ power of perception science and are now the preferred remote \n \n40 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nsensing system for gathering data over\
    \ long distances in difficult-to-access \nenvironments [101]. Drone cameras can\
    \ collect remotely sensed images from \ndifferent areas safely and efficiently.\
    \ \nUnmanned vehicles can be deployed in air (Unmanned Aerial Vehicles – \nUAV),\
    \ at the sea surface (Autonomous Surface Vehicles – ASV) or in the water \ncolumn\
    \ (Autonomous Underwater Vehicles – AUV). \nUAVs can save time and money in different\
    \ sectors, such as agriculture, \npublic safety, inspection and maintenance, transportation\
    \ and autonomous \ndelivery systems. This technological revolution was conceived\
    \ to make people’s \nlives easier and to provide machine-to-machine communications\
    \ without human \nintervention [102]. They can be used to check a given installation\
    \ or production \nareas, to transmit data, monitor construction processes, and\
    \ detect anomalies. \nFor instance, in [103], drones’ platform was deployed to\
    \ detect trees and \nbuildings close to power lines. They can also be deployed\
    \ to monitor oil, gas and \nwater pipelines. \nUAVs combined with digital image\
    \ processing have been applied to crack \nassessment as a cost-effective and time-effective\
    \ solution, instead of visual \nobservation [104]. In [105], Machine Learning\
    \ Techniques were used to estimate \nNitrogen nutrition levels in corn crops (Zea\
    \ mays). The work described in [106] \nintroduced a real-time drone surveillance\
    \ system to identify violent individuals \nin public areas by a ScatterNet hybrid\
    \ deep learning (SHDL) network. In [107], \nthe images from a drone camera were\
    \ processed by the bag-of-words algorithm \nto detect crops, soils and flooded\
    \ areas, with MATLAB to program the feature \nextraction algorithm. In [108],\
    \ a solution was proposed to detect a final target \nusing the drone’s camera.\
    \ The system implemented image processing algorithms \nusing the open-source computer\
    \ vision library OpenCV. Cloud solutions like \nGoogle AI, Amazon Web Services,\
    \ and IBM Watson offer on-demand access to \ntheir image recognition services\
    \ to connect with other systems on the internet. \nThe authors in [109] propose\
    \ to move computationally demanding object \nrecognition to a remote computing\
    \ cloud, instead of implementing it on the drone \nitself, by means of a cloud-based\
    \ approach that allows real-time performance \nwith hundreds of object categories.\
    \  \n \n2.4. Applications in Marine field \n \nMarine scientists and robotic engineers\
    \ now have at their disposal a \nheterogeneous collection of robotic vehicles,\
    \ including AUVs, deep-sea landing \nvehicles, unmanned/autonomous surface vehicles,\
    \ remotely operated vehicles, \nand gliders/drifters [110]. These robotic vehicles\
    \ are untethered, self-propelled, \nself-navigating vehicles that can operate\
    \ autonomously from a shore or vessel for \na period of hours to a few days and\
    \ carry scientific payloads to perform sampling \nin the marine environment [111].\
    \  \n \n41 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nDirect vision\
    \ or camera vision is the simplest way to acquire a wealth of \ninformation from\
    \ aquatic environments and plays a vital role in underwater \nrobots. AUVs equipped\
    \ with the most recent cameras are now capable of \ncollecting massive amounts\
    \ of data from the seabed [112]. Computer vision \nalgorithms for underwater robotic\
    \ systems are attracting attention due to \nsignificant advances in vision capacities.\
    \  \nThe authors of [113] propose a stereo-imaging technique for recovering \n\
    underwater images by considering the visibility coefficients. This stereo-imaging\
    \ \napproach was realized using real-time algorithms and was implemented in \n\
    AUVs. The authors of [114] propose the new Qu index, which is used to assess \n\
    the similarity of structures and colors in underwater images. The authors of [115]\
    \ \nintroduce a human perception technique, the High-Dynamic Range Visual \nDifference\
    \ Predictor 2, to predict both overall image quality and artefact \nvisibility.\
    \ The authors of [116] propose a real-time system for object recognition \nin\
    \ acoustic images. A 3D acoustic camera is implemented to produce range \nimages\
    \ of the underwater area [117]. The authors of [118] propose a system for \nautomatic\
    \ interpretation of 3D objects based on 2D image data generated by a \nsector\
    \ scanning sonar unit. Their overall interpretation achieves a success rate of\
    \ \n86% for underwater objects seen in various conditions. \n \nArtificial intelligence\
    \ and machine learning have been proposed to enhance \nAUV missions and analyze\
    \ their data. The authors of [119] describe a system for \nautomatically detecting\
    \ pipelines and other objects on the seabed. Artificial \nneural networks are\
    \ applied to classify, in real time, the pixels of the input image \nof the objects\
    \ into various classes. The authors of [120] propose CNN to learn a \nmatching\
    \ function that can be trained from labelled sonar images after pre-\nprocessing\
    \ to produce matching and non-matching pairs. The authors of [121] \ndescribe\
    \ a DL method to assist in identifying fish species on underwater images. \n \n\
    Collaboration between the QUT University of Australia, Google and the \nGreat\
    \ Barrier Reef Foundation developed the world’s first underwater robotics \nsystem\
    \ specifically designed for coral reef environments [122]. Using real-time \n\
    computer vision, processed on board the robot, it can identify harmful starfish\
    \ \nwith 99.4% accuracy [122]. Marine researchers and robotics specialists tested\
    \ the \neffectiveness of a CV system in identifying sea creatures and found it\
    \ be around \n80% accurate. The system can even be 93% accurate if enough data\
    \ is used to train \nthe algorithm [123]. \n \nUnmanned surface vehicles (USVs)\
    \ are the main investigation areas of \nmaritime autonomous surface ships (MASSs),\
    \ being used in surveillance, \nresearch, scientific investigation and security.\
    \ USVs are defined as self-contained \nunmanned, untethered vessels that can transit\
    \ on the surface of the water \nautonomously or be remotely controlled [124].\
    \ \n \n42 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nThrough\
    \ detailed maps and satellite navigation, an ASV can detect and avoid \nstatic\
    \ obstacles. For in instance, in [125] a performed approach was proposed \nusing\
    \ Google Maps to build a map of static obstacles. \n \nTo respond quickly and\
    \ effectively to the challenges of a highly dynamic \nenvironment, the ASV needs\
    \ on-board logic to monitor the scene, identify critical \nsituations, and perform\
    \ appropriate route modifications [126]. An outstanding \nfeature is its capacity\
    \ to recognize an obstacle at a safe distance and avoid a \ncollision by changing\
    \ its course. Kristan et al. [126] proposed a new graphical \nmodel that supplies\
    \ fast and continuous obstacle image-map estimation from a \nsingle video stream\
    \ captured on-board a USV. \nIn order to ensure accurate detection and tracking\
    \ of objects at sea, \nautonomous vessels require a range of sensing capabilities.\
    \ Radar can provide \nsuch an overview, although certain small vessels and floating\
    \ objects are \nchallenging to recognize. Computer vision by onboard cameras can\
    \ be used for \nthis as a reasonable alternative to a human lookout [127]. The\
    \ work proposed in \n[128] examines the technical challenges of marine image processing\
    \ and artificial \nvision problems for video streams generated by cameras. These\
    \ challenges \ninclude the dynamic nature of the background, the lack of static\
    \ cues, the \npresence of small faraway objects, and lighting effects. Authors\
    \ of [129] propose \na method of identifying and tracking vessels using video\
    \ streams of existing port \nand river surveillance systems. The method detects\
    \ all types of moving vessels, \noperates under varying lighting conditions, and\
    \ assigns a unique identifier to \neach vessel detected. \nIn [130], a monocular\
    \ camera mounted on a USV was used, automatic feature \nextraction and tracking\
    \ filter algorithms are applied for real-time vision-based \ndetection and tracking.\
    \ The approach aims to detect and track another surface \nvessel by deploying\
    \ computer vision techniques. \nNovel technology has already been deployed on\
    \ autonomous craft as part of \nthe Marine 4.0 concept, where AI, cloud, and edge\
    \ technologies are of great \nimportance. For instance, the IBM-funded project,\
    \ the Mayflower Autonomous \nShip (MAS), will use the IBM power servers, IBM Watson\
    \ AI, cloud, and edge \ncomputing technologies to navigate autonomously and avoid\
    \ ocean hazards as \nit travels from Plymouth (England, UK) to Plymouth (Massachusetts,\
    \ USA) [131] \n, thus expanding knowledge of the ocean and removing barriers to\
    \ marine \nresearch. In [132], a Google Cloud Machine Learning Engine is used\
    \ to deploy an \nAI-based object classification system: a software suite for detecting,\
    \ identifying, \nand tracking surface objects. It makes ships safer and more efficient\
    \ by \nautomatically analyzing data from a number of new sensors, along with the\
    \ \nship’s own automatic identification system (AIS) and radar. \nVision and image\
    \ processing applications can benefit from cloud computing, \nas many are data-\
    \ and compute-intensive. By remotely locating storage and \n \n43 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nprocessing capabilities in the cloud,\
    \ image processing applications can be \ndeployed remotely and paid for by the\
    \ user in pay-as-you-go or pay-per-use \nbusiness models.  \nOverall, cloud, edge\
    \ and hybrid vision processing solutions each provide \nboth strengths and weaknesses;\
    \ assessing the capabilities of each will allow the \nselection of an optimal\
    \ strategy for any specific design situation. \n \n3. Artificial Intelligence\
    \ and Machine Vision \n \nArtificial intelligence (AI) is the intelligence achieved\
    \ by machines. The \nresearch field of AI is defined as the study of \"intelligent\
    \ agents\": any device that \nsenses its environment and performs actions that\
    \ maximize its chances of \nachieving a given goal [133].  In common parlance,\
    \ the term \"artificial \nintelligence\" is applied when a machine mimics the\
    \ \"cognitive\" functions that \nhumans associate with other human minds, such\
    \ as \"learning\" and \"problem \nsolving\". Capabilities currently classified\
    \ as AI include autonomous driving of \ncars, human speech understanding, high-level\
    \ competition in strategic gaming \nsystems, intelligent routing in content delivery\
    \ networks, military simulations, \nand complex data interpretation. \nThe central\
    \ problems of AI research include learning, planning, reasoning, \nknowledge,\
    \ communication, natural language processing, perception, and the \nability to\
    \ move and manipulate objects [134]. \nAs AI applications are recently also designed\
    \ for commercial solutions, it is \nobliged to deal with the wide availability\
    \ of GPUs (graphics processing units), \nwhich make parallel processing ever faster,\
    \ cheaper and more powerful. \nComputer processors are designed to handle just\
    \ about anything. Central \nprocessing units (CPUs), however, they are very limited\
    \ and, as such, can only \nperform certain mathematical calculations. Very complicated\
    \ combinations are \nimpractical because of the very long processing time. GPUs,\
    \ on the other hand, \nhave become so specialized that they outperform traditional\
    \ processors when it \ncomes to rendering large amounts of complex calculations.\
    \ GPUs offer 10 to 100 \ntimes the computational power of traditional CPUs, which\
    \ is one of the main \nreasons graphics cards are currently being used to power\
    \ some of the most \nadvanced neural networks responsible for deep learning [135].\
    \ \nDeep neural networks (DNNs), also known as deep learning (DL), are part \n\
    of the broad field of AI, which is the science and engineering of creating \n\
    intelligent machines with the ability to achieve goals like humans. Machine \n\
    learning is the subfield of computer science that, according to Arthur Samuel\
    \ in \n1959, gives \"computers the ability to learn without being explicitly \n\
    programmed\"[136]. Evolving from the study of pattern recognition and \ncomputational\
    \ learning theory in artificial intelligence, machine learning \nexplores the\
    \ study and construction of algorithms capable of learning from and \n \n44 \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nmaking predictions about data\
    \ [137] by building a model from sample inputs. \nThe relationship between deep\
    \ learning and the whole of artificial intelligence is \nillustrated in Figure\
    \ 3.2. In other words, DL is the study of artificial neural \nnetworks and related\
    \ machine learning algorithms that contain more than one \nhidden layer (Figure\
    \ 3.5).  \n \n \n \nFigure 3.2. Deep learning in the context of artificial intelligence\
    \ \n \nThe upside of an efficient Machine Learning Algorithm is clear. Instead\
    \ of \nthe laborious and haphazard approach of creating a separate, customized\
    \ \nprogram to solve each individual problem in a domain, the single machine \n\
    learning algorithm simply has to learn, through a process called training, to\
    \ \nhandle each new problem. The brain is now considered the best \"machine\"\
    \ we \nknow for understanding and solving problems, so it is perfectly natural\
    \ to look \nto it for a machine learning approach. Therefore, a brain-inspired\
    \ computation is \na kind of algorithm or program that has some aspects of its\
    \ basic functionality or \nform inspired by the way the brain works. \nScientists\
    \ believe that the main computational component of the brain is the \nneuron.\
    \ There are about 86 billion neurons in the average human brain. The \nneurons\
    \ themselves are connected by a number of elements that enter them, \ncalled dendrites,\
    \ and one element that exits them, called an axon, as shown in \nFigure 3.3. The\
    \ neuron accepts signals that arrive via the dendrites, computes on \nthese signals\
    \ and outputs a signal to the axon. These input and output signals are \ncalled\
    \ activations. The axon of a neuron branches and is connected to the \ndendrites\
    \ of many other neurons. The connection between a branch of the axon \nand a dendrite\
    \ is called a synapse. It is estimated that there are 1014 to 1015 \nsynapses\
    \ in the average human brain [138]. A key feature of the synapse is that \nit\
    \ can scale the signal (xi) that passes through it, as shown in Figure 3.3.  \n\
    \ \n \n45 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 3.3.\
    \ Connections to a neuron in the brain. xi, wi, f (·), and b are the activations,\
    \ \nweights, nonlinear function, and bias, respectively \n \nThis scaling factor\
    \ can be called a weight (wi), and the brain is thought to \nlearn by changing\
    \ the weights associated with synapses. Thus, having different \nweights results\
    \ in different responses to an input. It is important to note that \nlearning\
    \ is the adjustment of weights in response to a learning stimulus, whereas \n\
    the organization (what we might think of as the program) of the brain remains\
    \ \nunchanged. This characteristic marks the brain as an excellent source of \n\
    inspiration for a machine learning algorithm. \nAs shown in figure 3.2, Within\
    \ the paradigm of brain-inspired computing \nexists a subarea called spiking computation.\
    \ The inspiration in this subarea is \ntaken from the fact that communication\
    \ in dendrites and axons are spike-shaped \npulses and that the information that\
    \ is transmitted is not based only on the \namplitude of the spike. Rather, it\
    \ also depends on the time at which the pulse \narrives and that the computation\
    \ that takes place in the neuron is a function not \nonly of a single value, but\
    \ of the pulse width and the temporal relationship \nbetween the different pulses.\
    \ In contrast to spiking computing, another sub-area \nof brain-inspired computing\
    \ is called neural networks, which is the focus of most \nresearch articles. \n\
    Neural networks are based on the notion that the computation of a neuron \nconsists\
    \ of a weighted sum of input values. These weighted sums reflect the \nscaling\
    \ of values by the synapses and the combination of those values in the \nneuron.\
    \ Moreover, the neuron does not simply produce this weighted sum, as \nthe computation\
    \ associated with a cascade of neurons would otherwise be a \nsimple linear algebra\
    \ operation. There is instead a functional operation within \nthe neuron that\
    \ is being performed on the combined inputs.   \nFigure 3.4 presents a diagrammatic\
    \ picture of a computational neural \nnetwork.  The neurons in the input layer\
    \ receive some values and propagate them \nto the neurons in the middle layer\
    \ of the network, which is also frequently called \n \n46 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \na “hidden layer.” The weighted sums from one or more\
    \ hidden layers are \nultimately propagated to the output layer, which presents\
    \ the final outputs of the \nnetwork to the user. To align brain-inspired terminology\
    \ with neural networks, \nthe outputs of the neurons are often referred to as\
    \ activations, and the synapses \nare often referred to as weights as shown in\
    \ Figure 3(a). \n \n \n \nFigure 3.4 Simple neural network example and terminology.\
    \  (a) Neurons and synapses. \n(b) Compute weighted sum for each layer. \nAccording\
    \ to Figure 3.3, the computation of each layer can be expressed as \nfollow: \
    \ \n\U0001D44C\U0001D457= f (∑\n\U0001D44A\U0001D456\U0001D457 \n3\n\U0001D456\
    =1\n\U0001D465\U0001D456 + \U0001D44F)                                       \
    \          (3.1) \n \nWhere Wij, xi and yj are the weights, input activations,\
    \ and output activations, \nrespectively, and f (⋅) is a nonlinear function. The\
    \ bias term b is omitted from \nFigure 3.3 for simplicity. \n \n3.1 Inference\
    \ Versus Training \n \nThe IoT data can be used to train the machine learning\
    \ model and inference \nbefore technical professionals can begin to design a system\
    \ that integrates a \nmachine learning inference server with the IoT, the relationship\
    \ between how IoT \ndata can be used for training the machine learning model and\
    \ inference must be \nunderstood. Figure 3.6 compare the training with inference.\
    \ \n \n• Training \n \nTraining is the process of creating a machine learning\
    \ algorithm. Training \nimplies the use of a deep learning framework (e.g., TensorFlow)\
    \ and a training \ndataset (Figure 3.5). IoT data supplies a source of training\
    \ data that data scientists \n \n47 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nand engineers can use to train machine learning models for a diversity of\
    \ use \ncases, from fault detection to consumer intelligence. \n \n \nFigure 3.5.\
    \ Training and inference comparison \n \n• Inference \n \nInference relates to\
    \ the process of using a trained machine learning algorithm \nto make a prediction.\
    \ IoT data can be used as input to a trained machine learning \nmodel, which enables\
    \ predictions that can provide guidance to decision-making \nlogic on the device,\
    \ at the edge gateway or elsewhere in the IoT system. \n \n2.4.2 Methods of Machine\
    \ Learning \n \nTwo of the most widely adopted machine learning methods are supervised\
    \ \nlearning and unsupervised learning. machine learning – about 70 percent –\
    \ is \nsupervised learning. Unsupervised learning accounts for 10 to 20 percent.\
    \ Semi-\nsupervised and reinforcement learning are two other technologies that\
    \ are \nsometimes used [139]. \n \n• Supervised learning  \n \nSupervised learning\
    \ algorithms are trained using labeled examples, typically \nan input where the\
    \ desired output is known. For example, a computer might \nhave data points labeled\
    \ \"R\" (works) or \"F\" (failure). The learning algorithm is \n \n48 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nprovided with a set of inputs along with\
    \ the corresponding correct outputs, and \nthe algorithm learns by comparing its\
    \ actual output with the correct outputs to \nfind errors. It then modifies the\
    \ model accordingly.  \nBy means of methods such as regression, classification,\
    \ prediction and \ngradient boosting, supervised learning uses patterns to predict\
    \ label values in \nadditional unlabeled data. \n \n• Unsupervised learning  \n\
    \ \nUnsupervised learning is used with data that have no historical labels. The\
    \ \nsystem is not told the \"correct answer\". The algorithm is supposed to find\
    \ out \nwhat it is shown. The goal is to explore the data and find some structure\
    \ in it. \nUnsupervised learning performs well on transactional data. For instance,\
    \ it can \nidentify customer segments with similar attributes that later can be\
    \ treated in \nsimilar ways in marketing campaigns. Alternatively, it can find\
    \ the main \nattributes that separate customer segments from each other. Popular\
    \ techniques \ninclude nearest neighbor mapping, self-organizing maps, k-means\
    \ clustering and \nsingular value decomposition. These algorithms are also used\
    \ to recommend \nitems, segment text topics, and identify data outliers. \n \n\
    • Semi-supervised learning  \n \nSemi-supervised learning is used for the same\
    \ applications as supervised \nlearning. But it uses both labeled and unlabeled\
    \ data for training: usually a small \namount of labeled data with a large amount\
    \ of unlabeled data (unlabeled data is \nless expensive and costs less effort\
    \ to acquire). This type of learning can be used \nwith methods such as regression,\
    \ classification and prediction. Semi-supervised \nlearning is useful when the\
    \ cost associated with labeling is too high to allow a \nfully labeled training\
    \ process. Some of the earliest examples of this type include \nidentifying a\
    \ person's face on a webcam. \n \n• Reinforcement learning  \n \nReinforcement\
    \ learning is often used in the areas of robotics, gaming and \nnavigation with\
    \ reinforcement learning, the algorithm discovers, via trial and \nerror which\
    \ actions produce the greatest rewards. This type of learning has three \nmain\
    \ constituents: the agent (the learner or decision maker), the environment \n\
    (everything the agent interacts with) and the actions (what the agent can do).\
    \ The \ngoal is for the agent to choose the actions that maximize the expected\
    \ reward in \na given time. The agent will reach the goal much faster if it follows\
    \ a good policy. \nThus, the goal of reinforcement learning is to learn the best\
    \ policy. \n \n \n \n49 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n3.2 Convolutional Neural Network for Object Recognition \n \nSeveral deep\
    \ learning architectures, such as deep neural networks, deep \nconvolutional neural\
    \ networks, deep neural networks, and recurrent neural \nnetworks, have been applied\
    \ to fields such as audio recognition, computer vision, \nautomatic speech recognition,\
    \ natural language processing, and bioinformatics, \nwhere they have been shown\
    \ to produce state-of-the-art results on a variety of \ntasks. Deep neural networks\
    \ have demonstrated their ability to outperform other \nmachine learning algorithms\
    \ in tasks such as object recognition in the field of \ncomputer vision. \nApplying\
    \ computer vision to automatically detect objects is an extremely \nchallenging\
    \ task. Noise disturbance, complex background, occlusion, scale and \nattitude\
    \ changes, low resolution, and other factors strongly influence object \ndetection\
    \ capabilities. Conventional object detection methods, based on the \nhand-crafted\
    \ feature, are not robust to lighting changes, occlusions and \nvariations in\
    \ scale or lack of good generalization ability [140]. Unlike handmade \nfeatures,\
    \ which are designed in advance by human experts to extract a particular \nset\
    \ of chosen properties, the features extracted by CNN are learned from the data.\
    \ \nThe core idea behind this is to learn object models from raw pixel data rather\
    \ than \nusing hand-set features, as in traditional recognition approaches. Training\
    \ these \ndeep models usually requires large training datasets, although this\
    \ problem has \nalso been surmounted by new large-scale labelled datasets such\
    \ as ImageNet \n[141]. \nA convolutional neural network (CNN) works by combining\
    \ different layers \nof neurons that extract certain characteristics from the\
    \ image. Each layer learns a \ndifferent level of abstraction, and in the end\
    \ gives a prediction of whether the \nobject was detected or not [142]. Different\
    \ online resources on deep CNN \narchitectures and vision-related datasets have\
    \ been implemented and are \navailable on the internet.  \nCNN-based methods have\
    \ achieved significant advances in computer vision. \nIn the 2012 ImageNet Large\
    \ Scale Visual Recognition Challenge (ILSVRC) [143], \nHinton and his student\
    \ Krizhevsky [141] applied CNN to image classification \nand achieved a winning\
    \ top-5 test error rate of 15.3%, compared to the 26.2% \nachieved by the second-best\
    \ entry. Applying various convolutional filters, CNN \nmodels can capture the\
    \ high-level representation of the input data, making it \nhighly popular for\
    \ CV tasks. The breakthrough and rapid adoption of DL in 2012 \nbrought into existence\
    \ modern and highly accurate object detection algorithms \nand methods, such as\
    \ the regions with CNN features (R-CNN) method [144], fast \nR-CNN [145], faster\
    \ R-CN [146], RetinaNet [147] and fast yet highly accurate \nmethods like SSD\
    \ [148] and YOLO [149]. CNN-based methods can provide more \naccurate target boxes\
    \ and multi-level semantic information for identification and \nlocalization.\
    \ However, handcrafted features are complementary and can be \ncombined with CNN\
    \ for improved performance [150]. \n \n50 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nBy using the cloud infrastructure, it becomes possible to apply CNN\
    \ \ntechniques which are used in most object detection cloud services [151]. There\
    \ \nare two ways that can help leverage these techniques for a particular application.\
    \ \nThe first one consists of employing our own data and a framework in our own\
    \ \nmachine and training our custom model for custom object detection. The second\
    \ \nis to use cloud services through an API, which is a suite of machine learning\
    \ (ML) \nproducts and CV software development services that allows developers\
    \ with \nlimited ML expertise to train high-quality models specific to the needs\
    \ of their \nproject.  \n \n3.3 Deep Learning for Object Detection \n \nIn the\
    \ last decade, prominent applications like robotics, video surveillance, \nscene\
    \ understanding, and self-driving systems have initiated a significant \namount\
    \ of computer vision research. Thanks to the advancement of neural \nnetworks,\
    \ particularly deep learning, visual recognition systems have achieved \nimpressive\
    \ outcomes, especially in object detection. \nObject detection is the process\
    \ of identifying the instance of the class to which \nthe object belongs and estimating\
    \ its location by outputting the bounding box \naround the object [151]. Although\
    \ object detection and image classification both \nshare a common technical challenge,\
    \ they must handle significant numbers of \nhighly variable objects. Object detection\
    \ is more complex than image \nclassification due to the fact that it must identify\
    \ the precise location of the object \nof interest [152]. Being one of the main\
    \ computer vision issues, object detection is \ncapable of providing useful insights\
    \ for the semantic understanding of images \nand videos [153]. Object detection,\
    \ i.e., the detection of the positions and \ncategories of multiple instances\
    \ of objects in a single image, is a major challenge \nin a diverse set of applications\
    \ such as self-driving vehicles and robotics [154, \n155,156].  \nObject recognition\
    \ efficiency is steadily increasing, with advanced computer \nvision techniques\
    \ working successfully on a wide range of objects. Most of these \ntechniques\
    \ are based on deep learning with convolutional neural networks and \nhave achieved\
    \ impressive performance improvements in a variety of recognition \nproblems [157].\
    \ \n \n3.4 Cloud-Edge DL \n \nPublic clouds have emerged as a new opportunity\
    \ to deliver compute-\nintensive applications. A public cloud refers to a networked\
    \ set of computers that \nfurnish a variety of computing and storage resources\
    \ and offer the appearance of \nunlimited computing capacity on demand at a nominal\
    \ price and under a flexible \npricing model [158-159]. Deep Learning (DL) technology\
    \ is popular nowadays \n \n51 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nthanks to its good results in the fields of object detection, image classification\
    \ and \nnatural language processing. The easy availability of powerful data sets\
    \ and \ngraphic processing units are the main reasons for DL’s present popularity.\
    \ \nSeveral smart DL-based applications and services have changed all kinds of\
    \ \npeople’s lives because of the significant advantages of deep learning in the\
    \ \ncomputer vision (CV) fields [160-161]. CV seeks to enable computer systems\
    \ to \nautomatically identify and understand the visual world, simulating human\
    \ \nvision [162]. Algorithms for visual perception tasks have been developed,\
    \ \nincluding (i) object recognition to identify specific objects in image data,\
    \ (ii) object \ndetection to locate semantic objects of a given class, and (iii)\
    \ scene understanding, \nto parse an image into meaningful segments for analysis\
    \ [163]. All these \nalgorithm techniques can be deployed in the cloud.  \nEdge\
    \ computing is progressively being merged with artificial intelligence \n(AI)\
    \ and is intended to migrate DL computation from the cloud to the edge, \nthereby\
    \ enabling distributed, reliable and low-latency intelligent services [161]. \n\
    DL services are implemented nearby the service requests and the cloud is only\
    \ \ninvolved when extra processing is needed [164]. Both the cloud and edge \n\
    computing are considered adequate platforms to incorporate artificial \nintelligence\
    \ approaches.  \n \n3.5 Cloud AI at the Edge \n \nCloud computing is also impacting\
    \ many applications that currently rely on \nlocal storage and processing power.\
    \ Cloud computing provides computing \nresources in the form of a service or application\
    \ over a network. Its services are \ngenerally divided into three categories:\
    \ Platform as-a-Service (PaaS), \nInfrastructure-as-a-Service (IaaS) and Software-as-a-Service\
    \ (SaaS). By remotely \nlocating storage and processing capacity, image processing\
    \ applications and \nmachine vision systems can be performed remotely and paid\
    \ for on a pay-per-\ndemand or pay-per-use business model. Cloud-based systems\
    \ optimally aim to \nautomatically balance and distribute processing loads. \n\
    Building a visual recognition model is a difficult and time-consuming task. \n\
    In addition, the training of deep neural networks demand access to massive data\
    \ \nand computing power, however this issue has also been overcome by new large-\n\
    scale tagged datasets such as ImageNet [165]. Fortunately, there are many ready-\n\
    to-run solutions on the market where these neural networks are often trained by\
    \ \nlower-cost and more powerful clusters of cloud GPUs. \nThese solutions were\
    \ developed by several companies such as Google, \nAmazon, Microsoft, IBM, and\
    \ others, and are provided in the form of application \nprogramming interfaces\
    \ (APIs) which can be integrated into various application. \nVision pre-trained\
    \ models are either hosted for private use or offered as public \nservices for\
    \ deep learning in the cloud [165]. To use the pre-trained cloud-based \n \n52\
    \ \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nmodels, application\
    \ developers employ the cloud-exposed APIs to offload deep \nlearning inference\
    \ tasks to the hosting server. \n \nThe advantage of a customized AI model is\
    \ the possibility to train it \naccording to the use case, in addition to detecting\
    \ the location of objects in the \nimage. The AI model can be trained to identify\
    \ different types of objects and their \nposition in an image. The trained custom\
    \ object detection model in the cloud can \nbe further implemented in an IoT gateway,\
    \ as the cloud service supports the edge \ncomputing option. \nEdge computing\
    \ has recently been envisioned to push cloud computing \nservices closer to IoT\
    \ devices and data sources. Edge computing is designed to \ndrive low-latency\
    \ data processing by migrating computing capacity from the \ncloud data centre\
    \ to the edge [166-167]. Influential cloud computing vendors, \nsuch as Google\
    \ [168] and Microsoft Azure [169], have released service platforms \nto drive\
    \ intelligence to the edge, allowing end devices to execute machine \nlearning\
    \ inference locally with pre-formed models. \nFigure 3.6 describes the six different\
    \ ways of using edge intelligence for ML \napplications, in which the edge can\
    \ be combined with the cloud or used alone for \nthe entire application process.\
    \ In this paper, we adopt two main methods: the \ncloud intelligence method, in\
    \ which training and inferencing are both performed \nin the cloud, and the Level\
    \ 3 method, with on-device inference and cloud \ntraining. \n \n \nFigure 3.6.\
    \ Six-level rating for edge intelligence [170] \n \n \n \n \n \n53 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n3.6  Evaluating performance of an object\
    \ detection model \n \nRapid advances in DL and improvements in device capabilities,\
    \ \nincorporating image sensor resolution, and optics, power consumption, memory\
    \ \ncapacity and computing power, have enhanced the cost-effectiveness and \n\
    efficiency of accelerating the spread of vision-based applications. Compared to\
    \ \ntraditional CV techniques, the DL allows CV engineers to achieve greater task\
    \ \naccuracy [171]. The neural networks used in DL are trained rather than \n\
    programmed; therefore, applications using this method often require less expert\
    \ \nanalysis and tuning and leverage the large amount of video data already present\
    \ \nin current systems. \nThe potential of cloud-based platforms is expected to\
    \ be exploited in the \nfuture for the development of computationally intensive\
    \ CNN applications [172]. \nThe obvious advantage is the possibility of creating\
    \ intelligent systems with \nlonger battery life, because the intense calculations\
    \ are performed elsewhere. \nWide and deep CNNs present a major challenge for\
    \ deployment and \nexecution on resource-constrained devices. Cloud computing\
    \ not only enables \nthe handling of massive amounts of data, but also takes advantage\
    \ of the benefit \nof high computing efficiency at a negligible cost. World leaders\
    \ such as Google, \nAmazon, IBM, and Microsoft offer the public highly scalable,\
    \ fast, and flexible \ncloud computing facilities to train CNN’s resource-hungry\
    \ architectures. The \ncloud environment also facilitates setting up libraries\
    \ for both researchers and \nnew practitioners. \nIn computer vision, one of the\
    \ most powerful algorithms is object detection, \nwhich aids in the classification\
    \ and localization of objects. Object detection is \nmore complicated due to the\
    \ fact that it requires drawing a bounding box around \neach object in the image.\
    \ \nMultiple deep learning algorithms exist for object detection like RCNN: Fast\
    \ \nRCNN, Faster RCNN, YOLO, Mask RCNN, etc. Moreover, Azure Custom Vision, \n\
    Google cloud and IBM Watson services allow users to load an image dataset to \n\
    classify or define the bounding box for each desired object in the image for \n\
    training. \nThe objective of an object detection model is to perform object classification\
    \ \nand localization, the former is to identify whether an object is present in\
    \ the \nimage and the class of the object, and the latter is to predict the boundary\
    \ box \ncoordinates around the object when an object is present in the image.\
    \ \nClassification models are evaluated on accuracy, precision, and recall, while\
    \ \nfor object detection, the concept of intersection over union (IoU) is employed\
    \ \n(Figure 3.7).  \nPrecision indicates the fraction of identified classifications\
    \ that are correct, \nwhile recall indicates the fraction of actual classifications\
    \ that are correctly \nidentified. IoU (intersection on union) is a measure of\
    \ how well a model predicts \n \n54 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nthe location of objects and is evaluated using the area of overlap of the\
    \ predicted \nbounding box regions and the ground truth, defined as follows: \n\
    \ \n\U0001D43C\U0001D45C\U0001D448 =\n\U0001D434\U0001D45F\U0001D452\U0001D44E\
    \ \U0001D45C\U0001D453 \U0001D442\U0001D463\U0001D452\U0001D45F\U0001D459\U0001D44E\
    \U0001D45D\n\U0001D434\U0001D45F\U0001D452\U0001D44E \U0001D45C\U0001D453 \U0001D448\
    \U0001D45B\U0001D456\U0001D45C\U0001D45B                                     \
    \              (3.2) \n \n \n \n \nFigure 3.7. IoU equation, Red is ground truth\
    \ bounding box and green is \npredicted bounding box \n \nPrecision indicates\
    \ the fraction of identified detections that were correct, and \nrecall indicates\
    \ the fraction of actual detections that were correctly \nidentified. FP (False\
    \ Positive) represents the number of negative samples judged \nto be positive,\
    \ TP (True Positive) is the number of positive samples judged to be \npositive,\
    \ and FN (False Negative) is the number of positive samples judged to be \nnegative.\
    \ \n \n\U0001D443\U0001D45F\U0001D452\U0001D450\U0001D456\U0001D460\U0001D456\U0001D45C\
    \U0001D45B =\n\U0001D447\U0001D443\n\U0001D439\U0001D443+\U0001D447\U0001D443\
    \                                                 (3.3) \n \n\U0001D445\U0001D452\
    \U0001D450\U0001D44E\U0001D459\U0001D459 =\n\U0001D447\U0001D443\n\U0001D439\U0001D441\
    +\U0001D447\U0001D443                                                  (3.4) \n\
    \ \n \n4. Latency Assessment  \n \nOne of the important challenges to overcome\
    \ is the high-latency and \nunreliable link issues between the cloud and the IIoT\
    \ terminals. Fog computing \nextends computing and storage to the network edge\
    \ and is not only considered \nfor computation and storage, but also as a way\
    \ of integrating new systems \ncapable of interconnecting urgent and complex processing\
    \ systems. However, \neach fog and edge application may have different latency\
    \ requirements and may \ngenerate different types of data and network traffic\
    \ [173].  \n \n \n \n55 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n4-1 Latency between Two Terminals \n \nLatency is the time network traffic\
    \ delayed by the system processing, or the \ntotal time needed to send a network\
    \ packet from the application on one server to \nthe application on another server\
    \ through the network interface controller (NIC), \nnetwork (cable, Wi-Fi etc.),\
    \ and into an application on another server (or client). \nTo assess the latency\
    \ between two terminals, most approaches use the round-trip \ndelay time (RTD)\
    \ or the one-way delay (OWD). The latency in the context of \nnetworking is the\
    \ time spent by propagation through the network support and \nhardware of the\
    \ adapter, as well as the software execution times (application and \nOS) (Figure\
    \ 3.8). \n \n \n \nFigure 3.8. Latency between two terminals in a network \n \n\
    The hardware latency inside switches and on wires can be easily identified \n\
    from the switch specifications, length of the wires, and the maximal transmission\
    \ \ndata rates, while the software latency imposed by processing a packet in the\
    \ \nsoftware stack is more arduous to evaluate. Several parameters like system\
    \ \nworkload, operating system and executed application influence software latency.\
    \ \nEquation 3.5 defines the RTD between two terminals in a network, where tA\
    \ \nand tB are the software latency of the terminals A and B respectively, and\
    \ tH \nmarks the hardware latency of switches and wires connecting the terminals\
    \ A \nand B.  \n \n\U0001D445\U0001D447\U0001D437 = 2 \U0001D442\U0001D44A\U0001D437\
    \ = 2 \U0001D461\U0001D434 + 2 \U0001D461\U0001D43B + 2 \U0001D461\U0001D435 \
    \                                (3.5) \n \nTo accurately calculate OWD (by dividing\
    \ the round-trip time by two), the \nconfiguration of the test systems must be\
    \ perfectly symmetrical, meaning they \n \n56 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nmust be running the same software, using the same settings, and have\
    \ equal \nnetwork and system performance. \n \n4-2 OPC UA Architecture and delay\
    \ assessment  \n \nA client application may use the OPC UA client API (application\
    \ program \ninterface) in order to send/receive OPC UA service requests or responses\
    \ to or \nfrom the OPC UA server. From the programmer point of view, the OPC UA\
    \ client \nAPI is like an interface that decouples the client application code\
    \ from the client \nOPC UA communication stack. \n \nIn this section, we analyze\
    \ the delays involved in client-server OPC UA \ncommunications in a switched Ethernet\
    \ network. This model serves to define in \ndetail the non-deterministic sources\
    \ of end-to-end delay. The proposed model is \nbased on time delays defined in\
    \ [174-175] in an Ethernet-based network. Figure \n3.9 shows the round-trip data\
    \ path from an OPC UA server in PLC automate to \nan OPC UA client on the IoT\
    \ gateway and the hardware OWD required. \n \n \n \nFigure 3.9. OPC UA delay in\
    \ OPC UA client server in an Ethernet network \n \nWe consider the end-to-end\
    \ network delay in the switches and wires from \nthe client request to the server,\
    \ which can be divided into three categories, the \nframe transmission delay (dt),\
    \ the time required to transmit all of the packet’s \nbits to the link, the propagation\
    \ delay (dl), the time for one bit to propagate from \nsource to destination at\
    \ propagation speed of the link, and the switching delays \n(ds), which depend\
    \ on the route through the network to the server. \nThe transmission delay depends\
    \ on the length of packet L and capacity of \nlink C. The propagation delay is\
    \ related to the distance between two switches \nand the propagation speed of\
    \ the link S.  \n \n57 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    \ \n \n\U0001D451\U0001D459 =\n\U0001D437\n\U0001D446  , \U0001D451\U0001D461\
    \ =\n\U0001D43F\n\U0001D436                                                  \
    \      \n(3.6) \n \nThe switch delay is defined as the time for one bit to traverse\
    \ from switch \ninput port to the switch output port. It is divided into four\
    \ delays: the first is the \nswitch input delay (dSin), the delay of the switch\
    \ ingress port, including the \nreception of the PHY and MAC latency. The second\
    \ is the switch output delay \n(dSout), the delay of the switch egress port, including\
    \ the transmission PHY and \nMAC latency. The third delay is the switch queuing\
    \ delay (dSq), the time a frame \nwaits in the egress port of a switch to start\
    \ the transmission onto the link. The last \nis the switch processing delay (dSp),\
    \ the time required to examine the packet’s \nheader and determine where to direct\
    \ the packet is part of the processing delay.  \n \n\U0001D451\U0001D446(\U0001D461\
    ) = \U0001D451\U0001D446\U0001D456\U0001D45B + \U0001D451\U0001D446\U0001D45D\
    \ + \U0001D451\U0001D446\U0001D45C\U0001D462\U0001D461 + \U0001D451\U0001D446\U0001D45E\
    (\U0001D461)                                     (3.7) \n \nThe hardware end-to-end\
    \ delay dCS presented as a request from an endpoint \nserver S to the destination\
    \ endpoint in a client C can be expressed as the sum of \nthe delays of all the\
    \ switches and links in the path, n being the number of links \nand n − 1 the\
    \ number of switches along the path.  \n \n\U0001D451\U0001D436\U0001D446(\U0001D461\
    ) = \U0001D451\U0001D461 + ∑\n(\U0001D451\U0001D459,\U0001D456) + ∑\n\U0001D45B\
    −1 \U0001D451\U0001D460,\U0001D456(\U0001D461) \n\U0001D456=1\n \n\U0001D45B\n\
    \U0001D456=1\n                                   (3.8) \n \nFigure 2.8 reveals\
    \ the architecture of the OPC UA server. The server \napplication is the code\
    \ that implements the server function. Real objects are \nphysical or software\
    \ objects that are accessible by the OPC UA server or \ninternally maintained\
    \ by it, such as physical devices and diagnostic counters. \nParticular objects,\
    \ such as Nodes, are used by OPC UA servers to represent real \nobjects, their\
    \ definitions and references; all nodes are called AddressSpace. \nNodes are accessible\
    \ by clients using OPC UA services (interfaces and methods) \n[176]. \n \nIn the\
    \ case of m number of requests from clients to the nodes in the OPC UA \nserver,\
    \ the overall hardware end-to-end delay of the OPC UA client-server (dCS) \ncommunication\
    \ over an Ethernet network, when there are m requests from the \nclient to the\
    \ server, is presented as: \n \n\U0001D461\U0001D43B = \U0001D451\U0001D436\U0001D446\
    (\U0001D461) =  ∑\n(\U0001D451\U0001D461,\U0001D457) + ∑\n(\U0001D451\U0001D459\
    ,\U0001D456) + ∑\n\U0001D45B−1(\U0001D451\U0001D460,\U0001D456)\n\U0001D456=1\n\
    \U0001D45B\n\U0001D456=1\n\U0001D45A\n\U0001D457=1\n                         \
    \    (3.9) \n \n \n \n58 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nBy analyzing all the delays mentioned in the hardware, we admit that the \n\
    end-to-end delay on Ethernet network is deterministic, except the delay in the\
    \ \nswitch queue, which depends on the link utilization. The packet queuing delay\
    \ \nincreases in a frequently used link. \nBy investigating the hardware delays\
    \ for an OPC UA client/server \ncommunication in an Ethernet network, we conclude\
    \ that it is hard to define \nexactly the hardware delay on the account of the\
    \ queuing delay. In that case, \nwhen it comes to complex processes with real-time\
    \ requirements, OPC UA \nreaches its limits. Different ways of defining this delay\
    \ exist, for example QoS \ntechniques such as WFQ (weighted fair queuing) or strict\
    \ priority [177]; \nnevertheless, there is always a certain amount of delay and\
    \ jitter that limits real-\ntime performance. Time sensitive networking (TSN)\
    \ provides mechanisms for \nthe transmission of time-sensitive data over Ethernet\
    \ networks. The adoption of \nOPC-UA over TSN will also drive this paradigm in\
    \ the world of deterministic \nand real-time machine to machine communications.\
    \ TSN provides mechanisms \nfor the transmission of time-sensitive data over Ethernet\
    \ networks. With \nEthernet’s limitations in terms of traffic prioritization,\
    \ the TSN working group \nhas developed the time-aware scheduler (TAS), defined\
    \ in 802.1Qbv [178]. TAS \nis based on TDMA, which solves the problem of synchronization\
    \ and traffic \npriority in the Ethernet. By using this technique, queuing delay\
    \ can be completely \neliminated, hence the end-to-end latency becomes deterministic.\
    \ This technique \nwas adopted in [179] to evaluate OPC UA performance on TSN\
    \ with the most \ncommonly used communication technologies. \n \n3-3 UAV System\
    \ Delay \n \nThere are several ways to introduce latency in a drone’s video compression\
    \ \nand transmission system. The end-to end delay in the system can be divided\
    \ into \nseven categories (Figure.3.10): Tcap is the capture time, Tenc the time\
    \ required to \nencode, the resulting transmission delay is Ttx, Tnw is the delay\
    \ network when \nthe drone is connected to the remote ground station via a network,\
    \ Trx is due to \nthe ground station also being wirelessly connected to a network,\
    \ Tdec is the \ndecoding delay at the reception station, and Tdisp is the display\
    \ latency.  \n \n\U0001D447 = \U0001D447\U0001D450\U0001D44E\U0001D45D + \U0001D447\
    \U0001D452\U0001D45B\U0001D450 + \U0001D447\U0001D461\U0001D465 + \U0001D447\U0001D45B\
    \U0001D464 + \U0001D447\U0001D45F\U0001D465 + \U0001D447\U0001D451\U0001D452\U0001D450\
    \ + \U0001D447\U0001D451\U0001D456\U0001D460\U0001D45D                       \
    \          (3.10) \n \n \n \n \n \n59 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 3.10 Video transmission system delay sources. \n \nNote\
    \ that when the drone is communicating directly with the ground station, \nno\
    \ network is involved and there is only a single transmission delay (Tnw = 0 \n\
    and Trx = 0).  \n\U0001D447 = \U0001D447\U0001D450\U0001D44E\U0001D45D + \U0001D447\
    \U0001D452\U0001D45B\U0001D450 + \U0001D447\U0001D461\U0001D465 + \U0001D447\U0001D451\
    \U0001D452\U0001D450 + \U0001D447\U0001D451\U0001D456\U0001D460\U0001D45D    \
    \                                    (3.11) \n \nIn the H.264 system, each video\
    \ frame is organized into slices which are in \nturn divided into non-overlapping\
    \ blocks and macro-blocks (two-dimensional \nunit of a video frame). Every slice\
    \ is independently encoded and can decode itself \nwithout reference to another\
    \ slice. The main advantage of this system is that it is \nnot required to wait\
    \ for the entire frame to be captured before starting to encode. \nAs soon as\
    \ one slice is captured, the encoding process can start, and slice \ntransmission\
    \ can begin. This technique has a consistent effect on the overall \nlatency as\
    \ it influences all the system latencies from encoding to display. \nTheoretically,\
    \ we define the overall latency by the number of slices N, \nalthough in practice\
    \ this may not be the case due to setting up and processing \nindividual slices.\
    \  \n \n\U0001D447 = \U0001D447\U0001D450\U0001D44E\U0001D45D + \U0001D441. (\U0001D447\
    \U0001D452\U0001D45B\U0001D450 + \U0001D447\U0001D461\U0001D465 + \U0001D447\U0001D451\
    \U0001D452\U0001D450 + \U0001D447\U0001D451\U0001D456\U0001D460\U0001D45D)   \
    \                               (3.12) \n \nIn order to efficiently transmit and\
    \ minimize the bandwidth, it is important \nto use video compression techniques,\
    \ although the slice technique also has an \neffect on the compression ratio.\
    \ The higher the number of slices, the faster they \ncan be encoded and transmitted,\
    \ although as this number increases, the number \nof bits used for a slice and\
    \ the effective slice transmission time also increase. \nOther types of delay\
    \ also affect the overall delay. Some factors can be \nadjusted when a UAV system\
    \ is used. For example, Tcap depends on the frame \nrate of the UAV camera, the\
    \ higher the frame rate, the shorter the capture time. \nTx relies on the available\
    \ data bandwidth of the transmission channel, while \nTdisp (video capture) is\
    \ based on the refresh rate of the display. \n \n \n \n \n \n \n60 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \n \n \n \n \n \nCHAPTER 4 \n \n--------------------------------------------------\
    \ \n \nEnergy Efficiency and Latency of Smart \nIoT Monitoring and Control Systems\
    \ \nBased on cloud Computing and \nIntelligent Machine Vision \n \n \n--------------------------------------------------\
    \ \n \n \n \n \nI. Smart Industrial IoT Monitoring and Control \nSystems Based\
    \ on cloud Computing and Intelligent \nMachine Vision \n \n61 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n1. Introduction   \n \nIndustry 4.0 is the information-intensive\
    \ transformation trend towards \nautomation and data exchange of manufacturing\
    \ technologies and processes \nincluding, robotics, cyber-physical systems (CPS),\
    \ the Internet of things (IoT), the \nInternet of services (IoS), cloud manufacturing,\
    \ big data and augmented reality \n[180]. Industry 4.0, the Fourth Industrial\
    \ Revolution, has already made \nsignificant changes to manufacturing and production\
    \ industries and offers a \nwealth of opportunities. Nevertheless, numerous issues\
    \ are also becoming the \nfocus of active research. These relate to concerns about\
    \ delays, data security, \ndevice communication and service availability. The\
    \ lack of ubiquitous \ninteroperability between heterogeneous devices is also\
    \ a major concern. \nAttempting to achieve seamless interoperability is further\
    \ complicated by the \nlong life of typical industrial equipment, to which costly\
    \ upgrades or \nreplacements are required to operate with the latest technologies\
    \ [181].  \nDue to the interactions between servers and IoT devices, massive amounts\
    \ of \ndata need to be transmitted through the IoT network, raising significant\
    \ data \ntransmission overhead to the network. As a number of IIoT systems are\
    \ time \nsensitive, the large increase in network traffic causes high network\
    \ latency and \nlarge packet loss, significantly affecting the performance of\
    \ IIoT systems. Fog \ncomputing is a potential middleware that can be very useful\
    \ for various \nindustrial scenarios. Since industrial processes require most\
    \ tasks to be carried \nout locally due to time and security limitations. Fog\
    \ computing can reduce and \nrefine large industrial data locally, before it is\
    \ sent to the cloud. Also, it can \nprovide local processing support with acceptable\
    \ latency for robots and actuators \nin a manufacturing industry [182]. However,\
    \ each fog and edge application may \nhave different latency requirements and\
    \ may generate different types of data and \nnetwork traffic [183]. \nRecent advances\
    \ in robotics, geomatics, and computer vision technologies \nhave made it possible\
    \ to capture an enormous amount of visual data using low-\ncost unmanned aerial\
    \ vehicles (UAVs). As a kind of flexible, fast and low-cost \ndata acquisition\
    \ system, UAVs have demonstrated great capabilities in \nperforming numerous mapping,\
    \ surveying and remote sensing tasks with very \nhigh-resolution data [184]. \n\
    UAVs have been widely used in manufacturing companies to monitor \njobsites in\
    \ real time and to provide high-definition (HD) images and video to \nidentify\
    \ changes and solve or prevent many problems [185]. They have also been \nused\
    \ for maintenance, inspection and tasks that are dangerous, inaccessible or \n\
    costly from the ground [186]. The integration of UAVs in the IoT represents an\
    \ \ninteroperability challenge, since each IoT system has its own communication\
    \ \n \n62 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nprotocol. Besides,\
    \ a small delay or error beyond the tolerated limit could result \nin a disaster\
    \ for various applications, such as manufacturing and monitoring of \naircraft\
    \ and UAVs.  \nUAVs technology has undergone a significant transformation and\
    \ has found \napplications in different fields, the off-board base station gives\
    \ them higher \ncomputational capacity and the ability to carry out more complex\
    \ actions using \nhigh-level programming languages, or leveraging services from\
    \ computer vision \ntools by acquiring, processing, analyzing and understanding\
    \ digital images in \nreal-time.  \nCrack assessment systems for concrete structures\
    \ are constantly improving \nthanks to computer vision technologies and UAVs.\
    \ UAVs combined with digital \nimage processing have been applied to crack assessment\
    \ as a cost-effective and \ntime-effective solution, instead of visual observation\
    \ [187]. Image recognition \ntechnology has a great potential in various industries\
    \ and has been improved by \ndeep learning and machine learning image recognition\
    \ systems (TensorFlow, \nand MATLAB) or image processing techniques such as computer\
    \ algorithms for \ndigital image processing. \n \nConcrete batching plant also\
    \ is a critical process, which is susceptible to \nchanges of mixed materials.\
    \ Due to some errors in the discharge and filtering \nprocess, these materials\
    \ are sometimes mixed incorrectly, which affects the \nquality and consistency\
    \ of the concrete. The drone's camera and cloud-based \nservices can identify\
    \ the condition of the aggregates being transported on the \nconveyor belts so\
    \ that adjustments can be made to the production process. \n \nImage processing\
    \ has become a significant asset for UAVs systems and not \nonly in industry.\
    \ Capturing footage and videos generates a huge amount of data, \nfor which cloud\
    \ computing is vital [188]. \nComputing capabilities can be extended to the cloud,\
    \ taking advantage of the \nservices offered, and saving the cost and energy consumption\
    \ of an embedded \nUAV system. While the fog can be responsible for technical\
    \ assistance between \nhumans and machines, information transparency, interoperability,\
    \ decentralized \ndecision-making, information security, and data analysis.  \n\
    The rest of this chapter is organized as follows, we introduce the proposed \n\
    the three-layer IIoT-based UAV architecture, then we define the different \nprotocols\
    \ and applications used to connect the different systems. Following, we \ndiscuss\
    \ three-layer architecture latency using different IoT gateways in the fog \n\
    layer.  \n \n2. System model \n \n \n63 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nA three-layer IIoT-based UAV architecture (Industrial IoT) is considered\
    \ in \nthis work. An IIoT monitoring and control system based on a UAV integrated\
    \ \ninto traditional industrial control system architecture. The first layer consists\
    \ of \ntwo different systems, the first is industrial control system connected\
    \ to \nindustrial sensors, actuators and PLCs, and the second is the UAV monitoring\
    \ \nsystem. The second layer is the fog computing layer for storage, computing\
    \ and \ncommunications. The last layer is a cloud computing layer with image processing\
    \ \nservices. Communication between the layers and systems is provided by the\
    \ IoT \ngateway installed in the fog layer, which links securely in real time\
    \ the industrial \ncontrol layer to the UAV system, the UAV system to the cloud,\
    \ and finally the \ncloud to the industrial control system. We validated our design\
    \ proposal in an \nindustrial concrete manufacturing plant as a case study with\
    \ the aim of \nimproving production and reducing costs. \n \n \nFigure 4.1: Proposed\
    \ UAV-IIoT Platform \n \nThe control system receives data from remote or connected\
    \ sensors that \nmeasure set points (SP) of process variables (PV). When the system\
    \ detects a \nchange in trend between the PVs and SPs, the change is routed to\
    \ PLCs and the \nIoT Gateway that triggers the UAV system's reaction. The UAV\
    \ goes to a specific \npoint to supervise the process using the front camera.\
    \ Once the images are \ncaptured, the IoT Gateway receives them and sends them\
    \ to the cloud, which \nadopts deep learning techniques to analyze and send the\
    \ results to the IoT \nGateway and the control system to confirm the anomaly.\
    \ The fog layer is \nresponsible for communications between all other layers;\
    \ it automatically makes \ndecisions based on the results and data received and\
    \ transmits the results to other \napplications and layers. The fog layer, presented\
    \ as an IoT gateway, can support \nall the necessary tools and protocols to ensure\
    \ storage, communication and \ncomputing. Between the different layers of the\
    \ IIoT-UAV proposed architecture, \nthere are different network protocols (Figure\
    \ 4.2). In the first layer, the industrial \nsensors of the control system are\
    \ connected to a PLC that acts as an OPC UA \n \n64 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nserver, which routes the sensor data to the IoT Gateway\
    \ using the OPC UA \nprotocol. The IoT gateway integrates an OPC UA client installed\
    \ in Node-RED. \nNode-RED can also communicate with cloud services using IBM Visual\
    \ \nRecognition Nodes (WVR), which sends the UAV’s images to the cloud using \n\
    Internet protocols. The Ar.Drone Node.js library installed in the IoT Gateway\
    \ can \ncommunicate with Node-RED using the Exec node, which launches the UAV\
    \ \nmission and establishes the wireless connection between the UAV and the IoT\
    \ \ngateway using the Wi-Fi protocol. \n \n \nFigure 4.2. Development design of\
    \ autonomous IIoT flight \n \nNode-RED can connect all systems in the proposed\
    \ architecture using a wide \nrange of nodes. The OPC UA server installed in the\
    \ control system (PLC), \ncommunicates with the OPC UA Node-RED client node, which\
    \ reads the sensor \nvalues and launches the UAV program using the Exec node if\
    \ certain conditions \nare met. While receiving new images from the UAV, Node-RED\
    \ send them to the \ncloud for recognition or storage, using the Watson Visual\
    \ Recognition and \nCloudant nodes respectively. Ultimately, based on the results\
    \ received from the \nWVR node, a message is sent to the industrial control system\
    \ using the OPC UA \nnodes to adjust the concrete plant's production. Figure 4.3\
    \ shows the Node-RED \nflow and the connections between the nodes. \n \n \n65\
    \ \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.3. Node-RED\
    \ flow in the IoT gateway including the path from the PLCs to the \nUAV, from\
    \ the UAV to IBM Watson, and from Watson to the control center. \n \n \n2.1. Use\
    \ Case description   \n \nConcrete batching plants form part of the construction\
    \ sector. Their many \nimportant components include cement and bins, aggregate,\
    \ aggregate batchers, \ncement silos, dust collectors, conveyors, mixers, heaters,\
    \ and control panels. \nConcrete plants involve a human–machine interaction between\
    \ the operator and \nthe control system. The operator inputs the concrete formula\
    \ by specifying the \nquantities of material to be mixed and this data is processed\
    \ by a control system \nso that the correct amount of material is conveyed to\
    \ the mixer (Figure 4.4). The \nmaterials used in the concrete plant are cement,\
    \ admixtures, aggregates, and \nwater. The quality and uniformity of the concrete\
    \ depend on the slump value, air \ncontent, water-cement ratio, and homogeneity.\
    \ \n \n \nFigure 4.4. SCADA Industrial concrete plant with a typical concrete\
    \ formula. \n \nTraditionally, microwave sensors have been used in aggregate bins\
    \ to \nmeasure the aggregate water content and then adjust the formula as required\
    \ to \n \n66 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \ncontrol concrete\
    \ quality. Aggregates of different sizes are stored in bins for \ndifferent formulas.\
    \ Due to some errors during the filtering and unloading \nprocess, these materials\
    \ are sometimes mixed incorrectly, affecting concrete \nconsistency and quality.\
    \ Both the UAV camera and the IBM WVR service in the \ncloud can track the state\
    \ of the aggregate materials being transported on the \nconveyor belts with the\
    \ aim of adjusting the production process. \nThe cloud service is used to classify\
    \ normal and mixed aggregates. The role \nof the UAV in this is to take pictures\
    \ when materials are being transported on the \nbelts before they reach the mixer.\
    \ The cloud classifies each image sent by the \ndrone and returns the results\
    \ to the IoT gateway as a score between 0.0 and 1.0 \nfor each class. This result\
    \ is sent to the PLC after being processed in the IoT \nGateway. Using these results,\
    \ any excess amount of a material can be measured, \nand the necessary adjustments\
    \ can be made to obtain the final formula. This \noperation eliminates wasted\
    \ time and allows the desired formula to be obtained \nbefore the final mixing.\
    \ The proposed approach is considered a cost-effective \nsolution and eliminates\
    \ repeated and unnecessary operator controls, traditional \nmonitoring and control\
    \ systems. \n \n2.2. UAV Mission Planning  \n \nThe novelty of the proposed IoT\
    \ control system is that it provides real-time \ninteraction between an industrial\
    \ control system, UAVs and the cloud. Based on \nthe input information from the\
    \ concrete plant, the UAV can interact and execute \nthe mission automatically\
    \ and provide the necessary photos to the cloud to \ncompute and analyze the data\
    \ by deep learning methods and send the result back \nto the control system for\
    \ decision-making. The drone mission (Figure 4.5) is split \ninto three paths:\
    \ planning the mission, taking photos, and returning to the \nstarting point.\
    \  \nThe drone takes off at position (x, y), climbs to a certain altitude, hovers,\
    \ \nreturns to the start, and lands. The autonomous flight library was based on\
    \ the \nAR.Drone library [189] , which is an implementation of networking protocols\
    \ for \nthe Parrot AR Drone 2.0. This library has four features: a camera projection,\
    \ an \nextended Kalman filter, a PID Controller to control drone position, back-\n\
    projection to estimate distance to an object, and a VSLAM to improve the drone\
    \ \nposition estimates [190-191]. The AR. Drone 2.0 is equipped with sensors with\
    \ \nautomatic stabilization features and precise controls, two cameras, a 60-fps\
    \ \nvertical QVGA camera for measuring ground speed and a 1280 × 720 at 30 fps\
    \ \nresolution front camera with a 92◦ (diagonal) field of view, three-axis \n\
    magnetometer with 6◦ precision, three-axis accelerometer with +/-50 mg \nprecision,\
    \ Ultrasound sensors to measure height, three-axis gyroscope with \n2000◦/s precision,\
    \ and a pressure sensor with +/-10 Pa precision. The drone can \nmonitor its own\
    \ position and mapping (SLAM), robustness and controls. \n \n \n67 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \nFigure 4.5. AR.Drone 2.0 mission in\
    \ the concrete plant. \n \nUAVs are easy to deploy, flexible, can quickly change\
    \ position in a time-\ncritical situation and can be quickly configured. Integrating\
    \ them into a control \nsystem accelerates the production chain by responding\
    \ in real time to the various \nchallenges of the control system thanks to the\
    \ cloud services. Figure 4.6 details \nthe communication process between the different\
    \ parts of the proposed \napproach, including the industrial control system, UAVs\
    \ and the cloud, and data \nflows between the different nodes. Two main applications\
    \ are installed in the IoT \ngateway: the Node.js application and the Node-RED\
    \ application. The former \ncontrols the drone, while the latter facilitates communication.\
    \ \nNode-RED controls the flow by reading data from the OPC UA node, which \n\
    is connected to the automation control system. In case a certain issue is confirmed\
    \ \nby the PLC, Node-RED triggers the UAV mission executed by Node.js. The \n\
    UAV's mission (figure 4.5-4.7) is divided into three parts: planning the mission,\
    \ \ntaking pictures and returning to the starting point. The WVR Node and the\
    \ \nCloudant Node receive the images and send them to the IBM cloud for \nprocessing\
    \ and storage. Node-RED collects the classification scores of each new \nimage\
    \ from the cloud and processes them in the IoT gateway before transmitting \n\
    the evaluation to the control system using OPC UA. \n \n \n68 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nFigure 4.6. Communication process in the fog layer. \n\
    \ \n3. Results and Discussion \n \nThe drone in the worksite (concrete batching\
    \ plant) is located in the base \nstation, which is at a distance from the conveyor\
    \ belts the conveyor belts and is \nalways ready to respond to the new demands\
    \ of the industrial control system. \nThe UAV carried out 10 test missions over\
    \ three days in a real concrete plant in \nCartagena, Spain. The first step was\
    \ to fly automatically over a distance of about \n130 m to position the UAV at\
    \ the beginning of the conveyor belts. Then, the UAV \nmoved over the conveyors,\
    \ took pictures and sent them to the IoT gateway. The \nlast step was to bring\
    \ the UAV back to the starting point (Workstation) (Figure \n4.7). \n \nFigure\
    \ 4.7. Path used by the drone to execute the mission in a concrete plant. \n \n\
    \ \n \n \n69 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n3.1. IBM Watson\
    \ Image Recognition Training  \nOff-board image processing techniques were selected\
    \ due to the asset of the \ncloud services. IBM’s Watson visual recognition (WVR)\
    \ service analyzes the \ncontent of images from the drone camera transmitted through\
    \ the IoT gateway \n(Figure 4.1). MATLAB, OpenCV or TensorFlow could also have\
    \ been used as the \ncontrol system; however, the cloud completes the computing\
    \ activities and \nprovides an efficient time and cost optimization. The WVR service\
    \ can classify \nand train visual content using machine learning techniques. \n\
    WVR is based in part on the technology developed for the IBM multimedia \nanalysis\
    \ and retrieval system (IMARS) [192], supplemented by “deep features” \nthat are\
    \ extracted on Caffe software [193]. The WVR service extracts feature \nvectors\
    \ from a particular layer of a Caffe network for all the supplied examples \n\
    and uses them to train a one-versus-all support vector machine (SVM) model for\
    \ \neach class. The feature extraction process is therefore equivalent to “inferencing”\
    \ \nwith the neural network, but the SVM learning process is less CPU intensive\
    \ than \ninferencing [194]. \nThe Watson service generally accepts a maximum of\
    \ 10,000 images or 100 MB \nper .zip file and a minimum of 10 images per .zip\
    \ file, with different angles and \nscenarios to obtain the maximum precision.\
    \ The service recommends that the \nimages be at least 224 × 224 pixels and contain\
    \ at least 30% of the subject matter. \nIn order to train the custom model, we\
    \ used a dataset of the images captured by \nthe UAV camera from the field of\
    \ practice in different positions. In addition, we \nroughly divided the use case\
    \ into two parts: a mixed material set and a normal \nmaterial set (Figure 4.8).\
    \ \n \n \n                                    (a)                            \
    \                                    (b) \nFigure 4.8. Dataset used to train the\
    \ custom model in WVR service: (a) Shows images \nused to train the Mixed class;\
    \ (b) Shows Images used to train the Normal class. \n \nIn the training stage\
    \ we used the dataset images to create two new classes, a \nMixed class, and a\
    \ Normal class. These classes were grouped to define a single \ncustom model.\
    \ In the testing stage, the results of the Watson tests are shown as a \nconfidence\
    \ score for the image in the range of 0 to 1. A higher score indicates that \n\
    \ \n70 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nthe class is more likely\
    \ to be depicted in the image. The scores are considered as \na threshold for\
    \ action, and the confidence score are based on training images, \nevaluation\
    \ images, and the types of criteria of the desired classification. Figure \n4.9\
    \ shows the test of three different new images and the results of each class score.\
    \ \nWVR recognized the difference between the images according to the density\
    \ of \nthe normal material on the conveyors. For instance, the confidence score\
    \ for the \ntest-3 .jpg image is 0.92 for the normal class, indicating the greater\
    \ likelihood of \nthis class being in the image. \n \n \nFigure 4.9. Watson visual\
    \ recognition test of new images not used in the training \nphase. \n \n3.1.1\
    \ WVR Performance Evaluation \n \nTo assess the performance of the WVR, we used\
    \ a formula to calculate the \naccuracy as defined by equation (4.1). In our case,\
    \ we tested a data set of more \nthan 100 photos and obtained a final detection\
    \ accuracy of 87.28%. The \nmisclassified cases are listed in Table 4.1, which\
    \ represents the confusion matrix. \nOn the basis of a large number of tests with\
    \ new images not used in the training \nphase, a threshold for each score class\
    \ was defined, a decision was made, and the \norder was sent to the industrial\
    \ control system to adjust the quantities of material \nbeing transported on the\
    \ conveyor belts. \n \n \n                      \n\U0001D434\U0001D450\U0001D450\
    \U0001D462\U0001D45F\U0001D44E\U0001D450\U0001D466 =\n\U0001D447\U0001D443 + \U0001D447\
    \U0001D441\n\U0001D447\U0001D443 + \U0001D447\U0001D441 + \U0001D439\U0001D443\
    \ + \U0001D439\U0001D441 \n            \n(4.1) \n \n \nWhere TP is the number\
    \ of positive samples judged to be positive, FP \nrepresents the number of negatives\
    \ samples that are judged to be positive, FN is \nthe number of positive samples\
    \ judged to be negative, and TN the number of \nnegative samples judged negative.\
    \ \n \n \n71 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nTable 4.1.\
    \ Confusion matrix \n \nPredictive Positive \nPredictive Negative \nTrue Positive\
    \ \n58 (TP) \n6 (FN) \nTrue Negative \n9 (FP) \n45  (TN) \n \nAfter training the\
    \ WVR model in the cloud, the WVR Node can send the new \nphotos received in the\
    \ IoT gateway to the cloud service (Figure 4.10). The cloud \nservice classifies\
    \ the new photos and returns the results to the WVR node as a \nscores for each\
    \ class, which are then analyzed and sent to the PLC via the OPC \nUA protocol.\
    \ Figure 4.10 shows the results obtained from the WVR node in Node-\nRED. \n \n\
    Figure 4.10. Node-RED flow and WVR results of an UAV photo \n \n3.2. Delay Assessment\
    \ in the Proposed Platform \nThis section presents the RTD time metrics of the\
    \ IoT gateway connections in \nits conditions of use and highlights the crucial\
    \ role of the IoT gateway in terms \nof latency. In this application, the IoT\
    \ gateway is connected to different systems \nwith different transmitted data.\
    \ Below, we evaluate this difference by using three \ngateways with different\
    \ performances. Each IoT gateway has its own software \nand hardware components\
    \ to process the data with different processing times. \nTable 4.2 shows the specification\
    \ of each of the three selected platforms. \n \nTable 4.2. Specification of each\
    \ machine environment. \n \nSiemens Gateway \nIOT2040 \nRaspberry Pi 3 \nModel\
    \ B \nToshiba \nSATELLITE C870 \nEthernet \n2 x 10/100 Ethernet \nRJ45 \n10/100\
    \ BaseT Ethernet \nsocket \n10/100 BaseT \nEthernet RJ-45 \nProcessor \nIntel\
    \ Quark x1020 \n400 MHz \n1.2 GHz Quad-Core ARMv7 \nIntel Core i3 2348-M \nCPU\
    \ 2.3GHz \nOperation \nSystem \nLinux Kernel 4-4-18 \nYocto Standard \nLinux Raspbian\
    \ 4.14.79-v7+ \n \nWindows 7 \nProfessional \nRAM \n1 GB \n1 GB \n8 GB \nDisk\
    \ Memory \n32 GB \n16 GB \n500 GB \n \n \n72 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \n3.2.1. OPC Experimental Method and Results \n \nA case study was\
    \ used to define the latency of the OPC UA client-server \narchitecture. The experimental\
    \ set-up was based on an industrial plant and \nsoftware in addition to three\
    \ different IoT-based platforms. The industrial control \nsystem deployed as an\
    \ OPC UA server uses a Siemens S7-1512 with embedded \nOPC UA communication stack.\
    \ The OPC UA client is implemented using Node-\nRED OPC UA client node in the\
    \ three different devices, the IoT gateway IOT2040 \nfrom Siemens (S-G), a PC\
    \ computer Toshiba SATELLITE (PC-G), and a Raspberry \nPi 3 Model B (RPI-G) (Figure\
    \ 4.11). In the first step of the latency study, we \ncompared the RTD with the\
    \ three different devices considered as OPC UA client \nattached to the same Siemens\
    \ S7-1512 OPC UA server network. \n \n \nFigure 4.11. OPC UA delay in OPC UA client\
    \ server in an Ethernet network. \n \nThe given application is deployed in a local\
    \ network and is based on a typical \nuse case which consists in reading a bit\
    \ from the OPC UA server. All the RTD \nmeasurements were performed on the same\
    \ network. Under these conditions, we \nconsider that RTD delay is derived mainly\
    \ from the Tx software latency of the \nsoftware stack of device X (Equation3.4)\
    \ assuming an insignificant hardware \nlatency tH of the wires and the switch.\
    \ \nAn MX machine is defined as well as a pair of software setup SW and a \nhardware\
    \ setup HW : \n           \U0001D440\U0001D465 = (\U0001D43B\U0001D464,\U0001D446\
    \U0001D464)                                              (4.2) \n \nThe hardware\
    \ setup HW is defined as the set of all hardware elements in this \nmachine and\
    \ the software setup SW is defined as the set of all software elements \n[195].\
    \ \n \n \U0001D43B\U0001D464 = {\U0001D440\U0001D452\U0001D45A\U0001D45C\U0001D45F\
    \U0001D466,\U0001D443\U0001D45F\U0001D45C\U0001D450\U0001D452\U0001D460\U0001D460\
    \U0001D45C\U0001D45F, \U0001D441\U0001D43C\U0001D436 … }                     \
    \               (4.3) \n                                     \U0001D446\U0001D464\
    \ = {\U0001D434\U0001D45D\U0001D45D\U0001D459\U0001D456\U0001D450\U0001D44E\U0001D461\
    \U0001D456\U0001D45C\U0001D45B, \U0001D442\U0001D446, \U0001D437\U0001D45F\U0001D456\
    \U0001D463\U0001D452\U0001D45F\U0001D460 … }                                 \
    \    (4.4) \n \n73 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nIn order to\
    \ measure latency, a timestamp contained in an injection node in Node-\nRED was\
    \ used (Figure 4.12). In every request, the timestamp request is saved by \na\
    \ function node. The latency L is defined as the difference between the timestamp\
    \ \nof the server response and the client timestamp request saved in the first\
    \ function \nnode. Hence, latency L is measured as : \n \n\U0001D43F = \U0001D447\
    \U0001D45F\U0001D452\U0001D45E\U0001D462\U0001D452\U0001D460\U0001D461 − \U0001D447\
    \U0001D45F\U0001D452\U0001D460\U0001D45D\U0001D45C\U0001D45B\U0001D460\U0001D452\
    \ = \U0001D445\U0001D447\U0001D437)                                      (4.5)\
    \ \n \n \nFigure 4.12. Node-RED flow used to calculate round trip latency (OPC\
    \ UA Client to the \nOPC UA Server). \n \nThe latency results are summarized in\
    \ Table 4.3, showing the minimal and \nmaximal values, RTD average, and the standard\
    \ deviation calculated for each fog \ncomputing machine. The OPC UA requests were\
    \ repeated each second to read \nthe one-bit value in the OPC UA server (Figure\
    \ 4.12). All the samples were \nthoroughly checked for the same architecture on\
    \ different days in an \nexperimental campaign with more than 5000 valid samples.\
    \ S-G gateway latency \nis higher than in the RPI-G and PC-G gateways, approximately\
    \ three times that \nof the RPI-G and seven times that of the S-G. This difference\
    \ is evident in the \nprobability density function as shown in Figure 4.13. The\
    \ shapes of the RPI-G \nand the PC-G are almost the same with a single peak, while\
    \ the S-G shape is \nnarrower and scattered over a large time area. \n \nTable\
    \ 4.3. RTD test of 5200 samples from the OPC UA client to the OPC UA server (PLC)\
    \ \nover different clients through different machines. \n \nClient Test \nEnvironment\
    \ \nData Type \nAverage \nStandard \nDeviation \nMinimum \nLatency \nMaximum \n\
    Latency \nS-G \nBOOL (1 bit) \n23.160 ms \n23.56 ms \n19 ms \n878 ms \nRPI-G \n\
    BOOL (1 bit) \n8.22 ms \n3.48 ms \n5 ms \n76 ms \nPC-G \nBOOL (1 bit) \n3.288\
    \ ms \n2.65 ms \n0 ms \n32 ms \n \n74 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 4.13. OPC UA client-server RTD to read one bit through\
    \ different machines. \n \nIn order to analyze this large difference in the recorded\
    \ RTD between RPI-G \nand S-G, we continuously monitored the CPU load for 5 min\
    \ during the OPC UA \nchannel' s RTD. The RPI-G and S-G gateways were tested individually\
    \ in the \nsame network conditions and running only Node-RED, which runs the OPC\
    \ UA \nclient. The computed CPU usage was calculated as the average of all cores\
    \ of the \nRPI-G and S-G gateways (see figure 4.14). \n \n \n \nFigure 4.14. (a)\
    \ Simulation results of CPU load (%) versus OPC UA RTD (ms) in \nthe S-G; (b)\
    \ Simulation results of CPU load (%) versus OPC UA RTD (ms) in the \nRPI-G. \n\
    \ \nGiven the analogy of a similar situation [196], which assumes that the larger\
    \ \nthe RTD pattern peaks the higher the probability they are due to the higher\
    \ CPU \nload, although the recorded CPU load patterns are not only due to the\
    \ OPC UA \nclient implemented in Node-RED. Nonetheless, we compared the impact\
    \ of CPU \nusage in the RTD as regards the same conditions in the two gateways.\
    \ It should \n \n75 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nbe noted that\
    \ the impact of Node.js can be estimated to be around 10% of the \nprocessing\
    \ power of the gateway used in the demonstration case, and the number \nof devices\
    \ connected to the gateway linearly increases CPU and memory usage \n[73]. \n\
    There is always intense use of CPU in the S-G RTD when high latency is \ndetected.\
    \ The S-G peaks sometimes exceed 400 ms (Figure 4.14, Table 4.3) while \nin the\
    \ RPI-G they do not exceed 80 ms. Furthermore, the average CPU load of the \n\
    RPI-G is much lower than that of the S-G. The average value of the CPU load in\
    \ \nthe S-G is around 8%, while in the RPI-G it is around 1.7% and the number\
    \ of \ndevices connected to the gateway linearly increases the CPU load. \n \n\
    3.2.2. UAV Experimental Results \n \nThe streaming quality of the proposed Node.js\
    \ application was measured \nunder certain conditions of use to compare the response\
    \ time on different IoT \ngateways in the same configurations and conditions.\
    \ The transmission channel, \nframe rates and compression techniques were the\
    \ same in all the tests on the \nrecording of camera images and saving them to\
    \ a folder in the IoT gateway. The \nimage frames were captured and registered\
    \ in a buffer before being sent to the \ngateway. Encoding was performed by FFMPEG\
    \ codec, and the received frames \nwere decoded in the gateway before being saved\
    \ on the gateway disk. \n \n• Codec Latency \n \nThe AR.Drone library [197] uses\
    \ the basic H264 profile (MPEG4.10 AVC) for \nhigh quality streaming and video\
    \ recording. The Baseline profile was targeted at \napplications in which a minimum\
    \ of computational complexity and a maximum \nof error robustness are required.\
    \ H.264/MPEG4-AVC baseline supports two slice-\ncoding types (I and P slice types),\
    \ designed for progressive video such as video \nconferencing, video-over-IP,\
    \ and mobile applications [198]. The simplest is \nthe I slice, in which all macro-blocks\
    \ are coded without referring to any other \npictures in the video sequence. Previously\
    \ coded images are used to form a \nprediction signal for macro-blocks of the\
    \ predictive-coded P [199]. \nTheoretically, based on Equation (3.12), UAV delay\
    \ can be estimated by: \n \n\U0001D447 = \U0001D447\U0001D450\U0001D44E\U0001D45D\
    \ + 2. (\U0001D447\U0001D452\U0001D45B\U0001D450 + \U0001D447\U0001D461\U0001D465\
    \ + \U0001D447\U0001D451\U0001D452\U0001D450 + \U0001D447\U0001D451\U0001D456\U0001D460\
    \U0001D45D)                                  (4.6) \n \n \nThe experiments focus\
    \ on the mission delay generated by taking pictures in \na concrete production\
    \ plant. We measured the time needed for the drone to \nconnect with the IoT gateway,\
    \ take a picture and save it in a file in the IoT \ngateway (WriteFile function\
    \ from Node.js). Table 4.4 shows the results of an \nAR.Drone 2.0 mission with\
    \ around 200 images on the Node.js application, \n \n76 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \ntriggered from Node-RED. The latencies in both machines\
    \ are expressed in \nmilliseconds and calculated in the Node.js application. \n\
    \ \nTable 4.4. RTD Test of 200 photos sent from the IoT gateway to the AR.drone\
    \ \n2.0. \n \nThe results provided in Table 4.4 shows the large difference in\
    \ terms of \nlatency between RPI-G, S-G and PC-G. The average RPI-G latency is\
    \ almost three \ntimes that of PC-G, and RPI-G standard deviation is much higher\
    \ than in PC-G. \nNote that these tests were made with an image resolution of\
    \ 640 × 360 px, frame \nrate of 5 fps and a codec with H264 baseline. \nOn the\
    \ other hand, the S-G results are consistently different from those of PC-\nG\
    \ and RPI-G; the average S-G latency is very high, while the standard deviation\
    \ \nis lower than RPI-G. \nFigure 4.15 shows the probability density function\
    \ of the delay of the drone \nconnected to the gateway when successive pictures\
    \ from PC-G and RPI-G are \ntaken. While Figure 4.16 shows the probability density\
    \ function of the delay of \nthe drone connected to the gateway when successive\
    \ pictures from S-G are taken. \nHere, the distributions are clearly different,\
    \ the data spreading of the PC-G \ndistribution covers a narrower range, with\
    \ a larger spread in the S-G and RPI-G \ndistributions. \n \n \nFigure 4.15. Probability\
    \ density function of the delay of the drone connected to \nthe gateway when successive\
    \ pictures from PC-G and RPI-G are taken. \n \nClient Test \nEnvironment \nConnection\
    \ \nEstablished \nAverage  \nStandard \nDeviation  \nMinimum \nLatency \nMaximum\
    \ \nLatency \nS-G \n11429 ms \n1229.92 ms \n365.71 ms \n160 ms \n2906 ms \nRPI-G\
    \  \n5348 ms \n317.76 ms \n411.18 ms \n12 ms \n1706 ms \nPC-G  \n4562 ms \n132.72\
    \ ms \n35.90 ms \n4 ms \n230 ms \n \n77 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 4.16. Probability density function of the delay of the\
    \ drone connected to \nthe gateway when successive pictures from S-G are taken.\
    \ \n \nFigure 4.17, figure 4.18 and figure 4.19 compare the CPU load of the same\
    \ \nprogram implemented in the IoT gateways. The program continuously takes \n\
    images from the drone and stores them in a file in the gateway. The first time\
    \ \nperiod (red interval) in all three graphs shows the first connection between\
    \ the \ndrone and the gateways, while the rest of the time period is the time\
    \ of execution \nof the Node.js program in the gateways. \n \n \nFigure 4.17.\
    \ CPU Load while taking successive photos and writing them in a \nfolder in the\
    \ PC-G. \n \n \nFigure 4.18. CPU Load while taking successive photos and writing\
    \ them in a \nfolder in the RPI-G. \n \n78 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \n \nFigure 4.19. CPU Load while taking successive photos and writing\
    \ them in a \nfolder in the S-G. \n \nThe three IoT gateways have different environmental\
    \ specifications. Figures \n4.17-4.19 show these differences in terms of CPU usage\
    \ in the three gateways \nwhile executing the mission. In S-G, it increases from\
    \ 3% to 100%, while in RPI-\nG, the CPU load increases from 2% to 60%. In the\
    \ PC-G gateway the average CPU \nload while executing the mission was around 20%.\
    \ This difference is justified \nmainly by the numbers of cores implemented in\
    \ each gateway processor. S-G \nused a 400 MHz Intel Quark ×1020 processor with\
    \ a single core, while RPI-G used \na 1.2 GHz Quad-Core ARMv7 processor with four\
    \ cores. Furthermore, RPI-G and \nPC-G both support the Graphics Processing Unit\
    \ (GPU), while S-G does not. \n \n3.2.3. Watson Experimental Method \n \nThe IBM\
    \ Watson visual recognition service uses deep neural networks to \nanalyze images\
    \ and is currently operated in a data center in Dallas (USA). \nMultiple servers\
    \ are used to ensure high throughput and reliability. Node-RED \nprovides a node\
    \ to connect to the WVR service which takes an image as input \nand produces a\
    \ set of image labels as output. \nThe experiments carried out were based on Equation\
    \ 4.5 and used the Node-\nRED flow. The latency results are summarized in Table\
    \ 4.5, the RTD average, \nstandard deviation, minimal and maximal values calculated\
    \ for each fog \ncomputing machine.  \nThe experiment was repeated for one sample\
    \ field case image less than a data \nblock size of 154,076 bytes. All the samples\
    \ were carefully and thoroughly \nchecked for the same architecture on the same\
    \ day. Each experimental campaign \nhad around 100 valid samples for each machine.\
    \ Between each 100 requests, the \nnext request is triggered at the time of receiving\
    \ the results of the previous \nrequest from the WVR. \n \n \n79 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nTable 4.5. RTD test of 100 samples from\
    \ the IoT gateway to IBM Watson over different \nmachines.  \n \n \nThe results\
    \ reported in Table 4 display the differences between the different \nfog machines.\
    \ The average RPI-G and PC-G scores are lower than the S-G. \nHowever, RPI-G is\
    \ faster than S-G and has a larger standard deviation, while PC-\nG is faster\
    \ than RSP-G with a low standard deviation. The probability density \nfunction\
    \ estimates of the WVR delay for the three gateway machines are given in \n(Figure\
    \ 4.20). In this case, the probability density of the S-G has almost the same\
    \ \ncurvature as that of RPI-G, while the probability density of PC-G is larger.\
    \ \n \n \nFigure 4.20. Probability density function estimation of IBM WVR latency\
    \ to classify an \nimage located in the IoT gateway. \n \nGiven that the WVR node\
    \ in Node-RED relies on the HTTP protocol to send \nthe images to the cloud, we\
    \ performed another test using SpeedTest to measure \nthe HTTP throughput between\
    \ the web server and the client over the three \ngateways considered as clients\
    \ (on the same day with the same network \nconditions). The results obtained in\
    \ Table 4.6 indicate similar results for the \ndownload, while the S-G upload\
    \ is lower than the other gateways. \n \n \nClient Test \nEnvironment \nAverage\
    \  \nStandard \nDeviation  \nMinimum \nLatency \nMaximum \nLatency \nS-G \n1913.18\
    \ ms \n522.17 ms \n1454 ms \n5594 ms \nRPI-G \n1373.09 ms \n453.64 ms \n1080 ms\
    \ \n5151 ms \nPC-G \n1129.29 ms \n181.97 ms \n980 ms \n2491 ms \n \n80 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nTable 4.6. Speed Test over the three gateways\
    \ (S-G, RPI-G, PC-G) \nMachine \nPing \nDownload \nUpload \nS-G \n169.4 ms \n\
    16.3 Mbps \n9.5 Mbps \nRPI-G \n96.4 ms \n17.6 Mbps \n13.8 Mbps \nPC-G \n55.7 ms\
    \ \n17.5 Mbps \n12.3 Mbps \n \n \n \nII.  Autonomous Underwater Monitoring System\
    \ for \nDetecting Life on the Seabed by Means of \nComputer Vision Cloud Services\
    \ \n \n \n1. General introduction \n \nThe world's seas, as a valuable asset and\
    \ a vital part of its ecology, must be \nprotected as an essential source of life,\
    \ food and wealth. This implies monitoring \nsystems to ensure their condition\
    \ and sustainable management, which involves \nsurveying chemical and physical\
    \ parameters related to water quality, such as \ndissolved oxygen, nitrates, salinity,\
    \ temperature, density and chlorophyll levels, \namong others. Other purposes\
    \ of seabed monitoring are the detection and \nconservation of archaeological\
    \ artifacts and the monitoring of the state of marine \nflora and fauna, including\
    \ particularly sensitive endangered species [200]. \nStudies have been carried\
    \ out in different regions of the Mediterranean, \nparticularly in the Mar Menor,\
    \ a zone of particular interest due to its exceptional \nenvironment. Studies\
    \ have been carried out in different regions of the \nMediterranean, particularly\
    \ in the Mar Menor, a zone of particular interest due \nto its exceptional environment.\
    \  \nThe Mar Menor in southeast Spain, with unique salinity and temperature \n\
    characteristics, is Europe’s largest Salt Lake, with an area of 180 km2. It is\
    \ a \nvaluable resource with a remarkable ecosystem and a wide range of habitats\
    \ for \nendangered species. It has been the subject of numerous scientific studies\
    \ when \nit was recently contaminated biologically and chemically by torrential\
    \ rains \ncontaining large amounts of fresh water and agricultural runoff from\
    \ the \nsurrounding farmland, which affected its flora and fauna [200]. It also\
    \ shelters \nconsiderable plankton and phytobenthic populations during the warm\
    \ season. \nAll these factors have affected many of its indigenous species. \n\
    27 types of habitats of special interest have been inventoried in the Mar \nMenor\
    \ and its surroundings, eight of which are of priority [201]. Protected \nspecies\
    \ are also abundant and include seagrass meadows (Cymodocea nodosa \nand Ruppia\
    \ cirrhosa), marine fauna of special interest, such as seahorses \n \n81 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \n(Hippocampus ramulosus) or\
    \ toothed carp (Aphanius iberus), large quantities of \nfan mussels (Pinna nobilis)\
    \ and a wide range of seabirds [202]. The fan mussel is \nan endemic bivalve mollusc,\
    \ the largest in the Mediterranean and the second \nlargest in the world. The\
    \ International Union for the Conservation of Nature \n(IUCN) has included Pinna\
    \ nobilis in its updated list of critically endangered \nspecies due to parasitic\
    \ diseases [203]. In 2019, the discovery of a series of \nspecimens in the Mar\
    \ Menor confirmed that this natural area was a refuge for \nthis endangered species\
    \ on the verge of extinction along the entire Mediterranean \ncoastline and that\
    \ it was therefore essential for its monitoring. Although such \nmonitoring can\
    \ be carried out from manned vessels, it is time-consuming, \nlaborious and costly\
    \ and can be carried out much more effectively by AUVs [204]. \nAUVs are now widely\
    \ in use for a variety of tasks, including oceanographic \nsurveys, mine clearance,\
    \ demining and bathymetric data collection in marine and \nriver environments\
    \ [205]. They are valuable for mapping underwater \nenvironments and are playing\
    \ an increasing role in marine development [8]. \nThey now have power sources\
    \ and an intelligent control system that can perform \nautonomously programmed\
    \ tasks with appropriate decision-making capabilities \n[200]. Advances in computer\
    \ science, sensor technology, new materials and \nadvanced algorithms have significantly\
    \ increased their performance, although \nmany issues remain to be resolved [206,207].\
    \ \nAlong with the challenges and difficulties of an autonomous robot \nnavigating\
    \ in an unstructured environment, the marine environment has its own \nlimitations,\
    \ not only because of the currents but also because of the difficulty of \ngeolocating\
    \ the submerged AUV. The absence of communication networks and \nthe complexity\
    \ of real-time connection is also a drawback and could be a \ndetermining factor\
    \ not only for transmitting exploration results, but also for \nleveraging increased\
    \ computing capacity and information management when \nnecessary, such as artificial\
    \ intelligence (AI) provided by cloud computing \nservices.  \nSome AUV architectures\
    \ imply the technological challenge of a high \nprocessing, connection and communication\
    \ capacity. This necessitates an \narchitecture that is capable of integrating\
    \ with a nearby base station, the Internet \nand cloud architectures. The information\
    \ gathered during an operation also \nentails interpretation, which can be crucial\
    \ for decision making. This means that \nnot only the local connection is important,\
    \ as well as the connection with web \nservices (cloud computing, data centers,\
    \ etc.). The latter can be used to create \nwizards for specific purposes and\
    \ processes to which complex and specific tasks \ncan be delegated. \nWe propose\
    \ and assess an AUV system designed to collect and interpret \nunderwater images\
    \ in Mar Menor in order to trace the fan mussel population in \nreal time, using\
    \ georeferenced mosaics generated from the images by an \nautomatic processing\
    \ method. \n \n \n82 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    \ \n \n \n2. System model \n \nThe proposed AUV-IoT architecture is structured\
    \ in three layers, with the \nAUV being in the data generation and pre-processing\
    \ layer. The first layer \nconsists of an AUV composed of different sensors and\
    \ blocks for data generation, \nconversion and pre-processing (figure 4.21). The\
    \ pre-processing system is \ndeployed in an IoT gateway installed in the head\
    \ box and connected to the \ncamera by a switch. The IoT Gateway is defined as\
    \ an edge node. Another layer \nis the data communication layer with the cloud\
    \ via Wi-Fi or 4G networks. The \nlast layer is a back-end cloud with image processing\
    \ techniques. \n \nFigure 4.21. Proposed AUV-IoT Platform \n \nAs shown in Figure\
    \ 4.22, the three layers are made up of different electronic \ndevices with access\
    \ to software services, the physical layer is constituted by a \nvariety of electronic\
    \ devices interconnected by three different networks \naccording to their functionality:\
    \ The Internet/cloud network, the Ethernet \nnetwork and the CAN (controller area\
    \ network). The CAN network is composed \nof one master and four slave nodes.\
    \ Each node consists of an electronic card \nspecifically designed for this vehicle\
    \ and its assigned tasks, and has as a core a \nPIC 18F4685 microcontroller, working\
    \ at a frequency of 25 MHz. \n \n \n83 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 4.22. Proposed hardware architecture. \n \nThe CAN network\
    \ is the fieldbus that interconnects the elements dedicated \nto instrumentation,\
    \ measurement and actuation. It connects equipment devoted \nto specific processes\
    \ (inputs/outputs, sensor reading, engine control). The CAN \nnetwork has a master/slave\
    \ configuration, and the elements of this network \ncommunicate via the CAN field\
    \ bus, using the CANopen protocol at a speed of \n250 kbps, sufficient for real-time\
    \ exchange of process information. This protocol \nis particularly robust and\
    \ immune to electromagnetic interference, a feature that \nmakes it ideal for\
    \ this vehicle. \nThe CAN network consists of four slave nodes and a master. Each\
    \ node \nconsists of an electronic board specially designed for this vehicle and\
    \ the tasks \nassigned to it, and has a PIC 18F4685 microcontroller as its core,\
    \ operating at a \nfrequency of 25 MHz. The main functions of each node are as\
    \ follows: \n \n• \nNode 1 (in the head of the vehicle) manages its movement,\
    \ lighting, \ncamera power, tilt reading (pitch and roll) and the acquisition\
    \ of inertial \nunit variables. \n• \nNode 2 (DVL: Doppler velocity logger) manages\
    \ data acquisition \nand body tilt reading (pitch and roll). \n• \nNode 3 governs\
    \ GPS reading, engine management and control \n(propulsion, rudder and dive).\
    \ \n• \nNode 4 monitors marine instrumentation sensors (side-scan sonar, \nimage\
    \ sonar, microUSBL) and their energy management. \n• \nThe master node consists\
    \ of a National Instrument single-board \nRemote Input/Output (NI sbRIO) 9606\
    \ (the main vehicle controller). Its \nfunction in this network is to collect\
    \ process information from each of the \nnodes and send commands. It is the link\
    \ with the superior Ethernet \nnetwork. \n \n84 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \nThe Ethernet network permits higher data transfer\
    \ rates between devices and \nis formed by the AUV sbRIO control system, IP camera,\
    \ IoT gateway, and the 4G \nrouter. All of these are connected to the buoy via\
    \ an umbilical cable. \nEthernet/DSL (Digital Subscriber Line) gateways are used\
    \ owing to the number \nof wires in the umbilical cable connecting the vehicle\
    \ to the surface buoy (only \ntwo wires are available for data).  \nAs at least\
    \ four cables are used with Ethernet, and only two with DSL, the \nEthernet protocol\
    \ is converted to DSL before and after the umbilical cable by the \nDSL to Ethernet\
    \ gateways. The local bandwidth is 100.0 Mbps, with latencies of \nless than 1\
    \ ms. \nThe Internet/cloud network connects the vehicle to the cloud. The 4G router\
    \ \nintegrated in the surface buoy ensures the connection to the cloud. The aim\
    \ of \nthis network is the communication of the IoT gateway with the cloud and\
    \ \ncommunication of sbRIO control system with IUNO (Interface for Unmanned \n\
    Drones) fleet management software. The IUNO software platform was designed \n\
    at the Automation and Autonomous Robotics Division (DAyRA) of the \nPolytechnic\
    \ University of Cartagena. The platform is intended to manage the \nintegrated\
    \ control of multiple unmanned marine vehicles with the aim of \nsimplifying maritime\
    \ operations. The results obtained from each vehicle, \nregardless of its characteristics,\
    \ facilitate the success of the operation with a high \ndegree of automation [200].\
    \ AEGIR is the name of the AUV developed by \nDAyRA, and it is the main vehicle\
    \ used in this paper; its structure is described in \nFigure 4.22. \n \n3.1. IoT\
    \ Gateway: The Edge Node and Connection to the Cloud \n \nThe implemented IoT\
    \ gateway is capable of connecting the sensor network \nto the cloud computing\
    \ infrastructure, performing edge computing and serving \nas a bridge between\
    \ the sensor networks and the cloud services [208]. \nExperiments were carried\
    \ out using Python installed in the IoT gateway. \nThe Python program employed\
    \ serves as an interface to communicate with \nthe submarine sensors and actuators,\
    \ the cloud computer vision APIs and the \nunderwater controller (Figure 4.23).\
    \ \n \n \n85 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.23.\
    \ Node intercommunications and concurrent threads in the IoT \ngateway. \n \n\
    Python has a built-in support for scientific computing. Its use is growing \n\
    fastest in data science and machine learning [209]. Versatility, the stability\
    \ of \nlibraries with great support, and ease of use are its main benefits [210].\
    \ The IoT \ngateway also features Open-source Computer Vision (OpenCV) which is\
    \ a \nlibrary of programming functions mainly for real-time CV. In our application,\
    \ \nOpenCV is used for live video streaming over an Ethernet network connected\
    \ to \nthe prospective IP camera (model Sony SNC-CH110) installed in the head\
    \ box. \nAll the Python cloud libraries required for image recognition are installed\
    \ in the \nIoT gateway. \nWhereas the Python program in the IoT gateway is started\
    \ (Algorithm 1), \nconnection is established with the camera by the Real-Time\
    \ Streaming Protocol \n(RTSP). The Python program in the IoT gateway is executed\
    \ to run four threads \n(tasks) at the same time (Figure 4.24). \nThe first thread\
    \ is tasked with capturing and streaming video images from \nthe IP camera to\
    \ the IoT gateway internal memory. If a specimen is detected using \nthe cloud\
    \ object detection service, the AUV’s movements are adjusted to focus \nthe camera\
    \ on the object. The distance between the detected specimen and the \nvehicle\
    \ is computed in the IoT gateway and employed to steer the AUV to track \nits\
    \ position. The AUV’s heading and mission control commands are routed via \nTCP/IP\
    \ (Transmission Control Protocol/Internet Protocol) to the sbRIO controller \n\
    in the head box, which is connected to several nodes via a CAN bus protocol. \n\
    Each node is connected to a different group of sensors and actuators.  \nThe cloud\
    \ service used in this case is the vision object detection service, \nwhich allows\
    \ training of customized machine learning models that are able to \ndetect individual\
    \ objects in a given image along with their bounding box and \nlabel. There are\
    \ many different cloud APIs for computer vision, e.g., IBM, Google, \nMicrosoft\
    \ Azure and Amazon. They all provide fairly similar capabilities, \nalthough some\
    \ emphasize object recognition, Amazon, or building custom \n \n86 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nmodels, like Microsoft Azure and IBM.\
    \ The strength of these cloud APIs is their \nability to develop custom models\
    \ rapidly and download trained custom models \nto deploy them on the edge for\
    \ real-time applications and low-latency \nrequirements [211-212]. \nTo appraise\
    \ the effectiveness of the suggested platform, we assessed its \noverall latency,\
    \ in order to act quickly when an underwater specimen is detected \nand control\
    \ the AUV mission according to the cloud results of each photo. The \nPython program\
    \ is divided into four threads; however, the response time of the \ncloud services\
    \ takes significantly longer, depending on different factors. Figure \n4.23 presents\
    \ clearly the connection between the IoT gateway and the different \nsystems.\
    \ Each thread of the IoT gateway is responsible for synchronously \ntriggering\
    \ a task and ensures maintenance of the connection. \n \n3. The AUV-IoT Architecture\
    \ Development \n \nIn this section, we itemize and outline the development of\
    \ the above-\nmentioned IoT-AUV autonomous system and its network protocols, portraying\
    \ \nfive main blocks, namely, the IoT gateway, the IP camera, the AUV control\
    \ \nsystem, the AUV control station and the cloud.  \nThe overall mission is triggered\
    \ in the AUV control station by setting the \ndesired waypoints and activating\
    \ the AUV engines and IP camera streaming. The \nIoT gateway in the head box connects\
    \ the AUV nodes and the IP camera with \ncloud services. The IoT gateway receives\
    \ image data from the IP camera in the \nsubmarine’s head box and sensor data\
    \ from the body box. Likewise, the IoT \ngateway seizes the image processing results\
    \ from the cloud for each sent photo. \nIf a fan mussel is detected, the results\
    \ contain its delimitation box in the image \nand the percentage of image accuracy.\
    \ When a fan mussel is detected using the \ncloud API (Application Programming\
    \ Interface), the IoT gateway links up with \nthe main controller to modify the\
    \ submarine’s mission and track the specimen \ndetected. \nThe submarine’s new\
    \ mission is based on the results received from the cloud \nAPI and the algorithm\
    \ processed in the IoT gateway. The algorithm implemented \nin the IoT gateway\
    \ is in charge of adjusting AUV movements to keep the targeted \nspecimen in the\
    \ centre of the field of view. The distance to the detected specimen \nis computed\
    \ using the cloud API and a triangular similarity algorithm [213-214].  \nThe\
    \ desired mission modifications are routed to the main controller to handle \n\
    the engines and vehicle heading. In this case, the AUV’s manual tracking control\
    \ \nis replaced by an automatic specimen detection system using the cloud APIs\
    \ and \nthe distance measurement algorithm implemented in the IoT gateway. A specific\
    \ \narea is explored based on a specific mission with settled waypoints. The tracking\
    \ \nalgorithm in the IoT gateway is triggered automatically if the forward camera\
    \ \ndetects a specimen (Figure 4.24). \n \n87 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \n \nFigure 4.24. Communication between platforms. \nThe IoT gateway’s\
    \ main function is to acquire the camera image, timing the \nshot according to\
    \ the AUV’s depth and speed, to obtain photographic mosaics \nwith overlapping\
    \ images. The IoT gateway receives the captured images and \nforwards them to\
    \ the cloud, which uses advanced learning techniques to analyse \nthe results\
    \ and send them to the IoT gateway. The obtained results from the cloud \nare\
    \ exploited to adjust the new underwater mission to pinpoint the specimen’s \n\
    exact location. This is described in Algorithm 1, as well as in the flowchart\
    \ in \nFigure 4.23. \n \nAlgorithm 1. Specimen tracking algorithm \nStart () \n\
    Step 1:  \n     While (mission has not started) {}         \nStep 2: \n     If\
    \ (mission has ended) \n         {End()} \n     Else \n         {Acquire frame\
    \ and send to cloud} \n         {Get the answer} \n         If (accuracy > 20%)\
    \  \n             {Go to step 3} \n         Else \n             {Go to step 2}\
    \ \nStep 3: \n     {Calculate the bounding box centre of detected object} \n \
    \    {Calculate the distance between the centre of the detected nacre bounding\
    \ box (C1) and \n      the center of the captured frame (C2)} \n     {Conversion\
    \ of distance (C = C2–C1) into degrees (new heading and tilt setpoint)} \n   \
    \  {Send command to sbRIO with new heading and tilt setpoint.} \n     If (C==0)\
    \  \n          {Go to step 4} \n \n88 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n     Else \n          {Go to step 3} \nStep 4: \n     {Send the command\
    \ to sbRIO to set the speed (fixed speed setpoint)} \n     {Take images I1 and\
    \ I2 in two different positions, where P1 and P2 are the pixel widths \n     \
    \ of the objects detected in both images} \n     {Calculate the distance using\
    \ the following equations. \n \n \n \n  \n     where F = 2.34 mm is the focal\
    \ distance, W is the width of the real detected object \n     If (the distance\
    \ D calculated > 2m) \n          {Go to step 4} \n     Else \n          {Go to\
    \ step 5} \nStep 5: \n     {Get accuracy of the specimen image} \n     If (accuracy\
    \ ≥ 80%)  \n          {Save point, save picture and resume mission} \n       \
    \   {Send command to sbRIO to save specimen’s position} \n     Else \n       \
    \   {Go back to the main mission without saving. It is not a specimen} \n    \
    \      {Go to Step 2} \nEnd () \n \n3.3. AUV Control \n \nThe most relevant characteristics\
    \ of the AUV used in the experiment are as \nfollows: the vehicle is physically\
    \ divided into two compartments (head and \nbody), consisting of five thrusters\
    \ (two for propulsion, two for depth control and \none for the rudder) and weighs\
    \ 170 kg. This vehicle is capable of submerging to \n200 m and has 7-hour autonomy.\
    \ Its two battery blocks (one supplies power to \nthe electronics and sensors\
    \ and the second to the thrusters) are reconfigurable to \n24V for greater autonomy\
    \ or to 48V for greater power and cruising speed. It can \nmove at 4 knots and\
    \ perform long-term missions while locating and identifying \nsubmerged targets,\
    \ photogrammetry and sonar inspection of the seabed. It is \nequipped with the\
    \ following devices: image sonar, side scan sonar, micro-USBL \n(UltraShort BaseLine)\
    \ for acoustic positioning, an inertial unit, GPS (Global \nPositioning System),\
    \ a DVL (Doppler Velocity Logger) for measuring \nunderwater movements, a camera\
    \ and a depth meter. \nAs shown in Figure 4.23, our underwater vehicle has a number\
    \ of elements \nand devices interconnected through different networks. While the\
    \ IoT gateway \nis in charge of recognition and communications with the camera\
    \ and the cloud, \nthe sbRIO controller is the AUV’s main control backbone. The\
    \ National \nInstrument sbRIO 9606 embedded controller integrates a real-time\
    \ processor \nwith a reconfigurable FPGA through its LabVIEW environment [215-216].\
    \ It \ncomprises Ethernet, CAN and I/O connectivity, as well as a 400-MHz CPU,\
    \ \n \n89 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n256MB DRAM,\
    \ 512MB storage, and other features listed in [215-216]. A consistent \ncode for\
    \ the sbRIO controller was fully developed in the LabVIEW environment \nfor AUV\
    \ management, control and command. \nThe modules in the sbRIO’s vehicle control\
    \ program comprise these operations: \n• CAN bus (reading and writing interface):\
    \ There are a number of nodes \nconnected to the vehicle's CAN bus, whose network\
    \ master is the sbRIO. Each \nof the nodes has a series of sensors and actuators\
    \ connected. The function of \nthese blocks is to receive information and send\
    \ commands to the different \nnodes through the CANopen protocol. The type of\
    \ data received or sent will \ndepend on the function of the node. \n• TCP/IP\
    \ \n(reading \nand \nwriting \ninterface): \nThis \nmanages \nTCP/IP \ncommunications\
    \ for receiving commands from IUNO and the IoT gateway, \nas well as sending navigation\
    \ information from the vehicle to the rest of the \nequipment on the Ethernet\
    \ network. \n• Data manipulation: This is responsible for adapting the data formats\
    \ from the \ndifferent sources (CAN, inertial unit, IUNO) to a common format within\
    \ the \nprogram and vice versa: e.g., conversion of latitude received through\
    \ the \nCAN network interface (UINT8 array type, extracted from a buffer) to I32\
    \ \ndata type. \n• Data saving: This saves the process and navigation information\
    \ in the sbRIO \nin TDMS (Technical Data Management Streaming) format files. TDMS\
    \ is a \nbinary measurement file format, focused on storing information in the\
    \ \nsmallest possible space. It can be exported to several formats (csv, xls,\
    \ txt, \netc.). \n• Heading \ncontrol/depth \ncontrol/velocity \ncontrol/heading\
    \ \ntilt \ncontrol: \nManagement of the different control loops for heading, depth,\
    \ velocity and \nhead tilt. These take on special importance in automatic or semi-automatic\
    \ \nnavigation modes. \n• Thruster control: As a result of the previous timed\
    \ loop, a heading, depth or \nposition setpoint is obtained. In this module, they\
    \ are processed to obtain as \na result a PWM (Pulse-Width Modulation) value to\
    \ be applied to each of the \nvehicle’s engines. \n• Automatic (IUNO)/manual mode\
    \ navigation: AEGIR developed at the \nDivision of Automation and Autonomous Robotics\
    \ (DAyRA) of the \nPolytechnic University of Cartagena, and the Ocean Server AUV\
    \ IVER2. \nIUNO’s capabilities and characteristics. An AEGIR vehicle can be handled\
    \ in \nboth modes: manual and automatic. This timed loop is in charge of selecting\
    \ \nthe appropriate navigation source. Only the automatic mode is considered in\
    \ \nthis paper. \n• Mission management: Once the mission created in IUNO is downloaded,\
    \ this \nmodule manages each of the waypoints to which the vehicle must navigate,\
    \ \ndispatching the different navigation commands for the heading control/depth\
    \ \ncontrol/position control timed loops. This module also handles the main \n\
    \ \n90 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nnavigation mode in\
    \ normal operations and the specimen tracking navigation \nmode, as described\
    \ in Section 7. \n \n4. Artificial Intelligence and Vision-Based Object Recognition\
    \ \n \n4.1 Object Detection Training in the Cloud \n \nThe Mar Menor, as the largest\
    \ saltwater lake in Europe with a wide range of \nflora, requires constant monitoring.\
    \ The 4G network covers the entire zone and \nconnects a large area to the Internet\
    \ to take full advantage of cloud computing \nservices. As described above, AUVs\
    \ are a complete fan mussel monitoring system \nthanks to being interconnected\
    \ to the latest cloud computing services. \nBesides the general object detection\
    \ models provided by cloud services, \ncertain others can be used to create their\
    \ own custom object detection model to \nidentify items and their location in\
    \ an image. Object detection models can be \ntrained to recognize objects that\
    \ are important to the user in specific domains. \nObject detection training data\
    \ is the set of object labels and locations in each \ntrained image. The tag or\
    \ label identifies what the object is. The location identifies \nwhere it is in\
    \ the image. It is also possible to identify more than one object in an \nimage.\
    \ Cloud services offer users a friendly interface to develop and deploy \ncustom\
    \ CV models. We identify the location by drawing a bounding box around \nthe object\
    \ and providing the top and left pixel coordinates of that box, along with \n\
    the width and height in pixels (Figure 4.25). \n \n \nFigure 4.25. Fan mussel\
    \ recognition training: defining a fan mussel bounding \nbox in different cloud\
    \ services. \nIn the case study, we trained about 90 photos on the same data set\
    \ in Azure, \nGoogle and IBM Watson cloud services, all of which offer nearly\
    \ the same service \nfor custom object detection. The training photos are a mix\
    \ of our own photos and \nothers from Creative Commons sources [217] (Figure 4.26).\
    \ The system is very \nsimilar to custom classification, except that this service\
    \ identifies the location of \nthe items in the image. The response also includes\
    \ a classification label for each \nitem detected and an identification confidence\
    \ score. \n \n \n91 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.26.\
    \ Pictures used for custom CV model training. \nAfter creating a custom object\
    \ detection model and completing the training, \nwe tested its fan mussel detection\
    \ capacity in other images using the Python \ncloud API, as shown in Figure 4.27.\
    \ \nThe trained vision model successfully identified a new specimen in the image\
    \ \nand also its location and its probability percentage score. The blue bounding\
    \ box \nis drawn by the Python program using the results received from the cloud.\
    \ \nAccording to the results and the AUV navigation sensor data, the proposed\
    \ \nAlgorithm 1 can estimate the distance between the AUV head box and the \n\
    detected specimen. \n \n \nFigure 4.27. New specimen detection using the IBM Python\
    \ API. \n5. Visual Servo Control and Distance Estimation \nVisual servo control\
    \ consists of computer vision data usage to control the \nAUV’s motion [218].\
    \ Related works on underwater vision tracking and visual \nservo control for autonomous\
    \ underwater vehicles have shown that vision and \nvisual servo control are imperative\
    \ in developing AUV systems, as the vision–\n \n92 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nAUV combination yields substantial benefits. Several\
    \ studies on underwater \ntracking focus on visual servoing, such as autonomous\
    \ alignment and dynamic \npositioning [218-219], pipeline following and planet\
    \ target tracking [220]. With \nthe advent of machine vision and deep learning,\
    \ it is currently viable to specify \nthe object to be tracked. ML object tracking\
    \ has already been tested in different \nunderwater applications, such as fish\
    \ tracking and diver following and tracking \n[221-222].  \nTo perform underwater\
    \ vision tracking in Mar Menor and track the \nunderwater Pinna nobilis species,\
    \ the fan mussel tracking algorithm is solved \nusing the object recognition cloud\
    \ API incorporated in the AUV control loop. \nThrough this algorithm, we verify\
    \ that a specimen has been detected, and from \nthere we calculate the coordinates\
    \ of its center (x, y). In this scenario, the AUV \nreduces speed, and a PID (Proportional–Integral–Derivative)\
    \ controller will keep \nthe object in the centre of the frame by adjusting AUV\
    \ yaw and head tilt to keep \nthe camera centred on the object detected [223-224].\
    \  \nWhen more than one specimen is detected, the system follows the one with\
    \ \nthe highest score. The x and y coordinates are adopted as information in the\
    \ object \ntracking process. To make the system effectual, the port and starboard\
    \ engines \nand AUV head tilt are adjusted to track the object using the object’s\
    \ coordinates \nas feedback. The thrust motors follow the position changes of\
    \ the object’s \ncoordinates by means of PID controllers. When the detected object\
    \ is centred, its \ndistance from the AUV camera is computed using the cloud API\
    \ results and a \ntriangular similarity algorithm [213-214]: \n \n    \U0001D437\
    \ = \U0001D44A \U0001D439\n\U0001D443\n \n(4.7) \n \nwhere P is the width of\
    \ the object in pixels and W is the width of the object itself. \nThe camera focal\
    \ distance F is fixed and the apparent P is obtained from the \ncloud results.\
    \ To obtain W and estimated distance D, a minimum of two pictures \nare required\
    \ at different distances from the object for calibration, as presented in \nFigure\
    \ 4.28 and Algorithm 1. \n \n \n93 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nFigure 4.28. Triangular similarity using a single camera [225]. \n(\U0001D437\
    \ +  ∆\U0001D451) \U0001D443\U0001D4611 = \U0001D437 \U0001D443\U0001D4612 =\
    \ \U0001D44A \U0001D439 \n(4.8) \n \n\U0001D437 =\n(∆\U0001D451 \U0001D443\U0001D461\
    1)\n(\U0001D443\U0001D4612− \U0001D443\U0001D4611)                           \
    \                                                                  (4.9) \n  \n\
    The cloud object detection API and the tracking algorithm are fully \nimplemented\
    \ using Python. The entire Python program is processed in the IoT \ngateway while\
    \ yaw and tilt are processed in the sbRIO main controller. The \noutput data coordinates\
    \ from the cloud are used to keep the AUV automatically \nfocused on the object\
    \ itself in the desired position. \nThe sbRIO main controller drives the robot’s\
    \ movements to keep the target’s \nbounding box in the centre of the camera image.\
    \ The IoT gateway continuously \nsends coordinate errors (distance, X position,\
    \ Y position) to this controller, so that \nthese data become the input for the\
    \ closed loop for tilt, heading and speed \nadjustments (Figure 4.29). \n \nFigure\
    \ 4.29. Closed control loop for object detection and tracking. \nFigure 29 presents\
    \ the modules and process involved in detecting \nand tracking the target. In\
    \ the object detection algorithm block, the \nsystem aims to keep the target in\
    \ the centre of the image. When the \nrelative size of the target has been obtained\
    \ from the object detection \nAPI, these control loops are kept operative while\
    \ the speed is \ngradually increased to calculate the estimated distance by means\
    \ of \nthe similarity triangulation algorithm. From then on, tilt, heading, \n\
    speed and control loops keep the target in the centre until the vehicle \nis at\
    \ the desired distance. The tilt and heading closed control loop \n \n94 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nwere successfully tested in\
    \ calm waters and slow currents, although \ndifficulties were encountered with\
    \ stronger currents. \nServo Control Latency \nThe visual system is required to\
    \ provide real-time results from the control \nloop with very low latencies. The\
    \ principal concern is the ability to detect the \ntarget and aim the camera at\
    \ the centre of the image. To obtain effective real-time \ncontrol, the delays\
    \ involved in initially detecting the target and those of the \nsensor and actuator\
    \ while tracking the object must be minimised (Figure 4.30) \n[226]. Three distinct\
    \ types of delay are involved. The first is actuator delays, \nwhich occur in\
    \ the feedforward loop when the delay is in the robot itself. The \nsecond type\
    \ is sensor delays in the feedback path of a closed-loop system, derived \nfrom\
    \ a sensor delay. This delay is present in any real-time control system with \n\
    visual feedback and depends on the amount of visual processing required. The \n\
    third type is transportation delays, or pure time delays, usually due to long-\n\
    distance communications. \n \nFigure 4.30. Basic closed-loop system with sensor\
    \ and actuator delays. \nTo reliably assess the servo control latencies, we modelled\
    \ the basic closed-\nloop system with sensor and actuator delays, as shown in\
    \ Figure 4.30. Y(s) is the \noutput signal and R(s) is the reference signal. The\
    \ sensor and actuator delays are \nrepresented, respectively, as \nand \nin the\
    \ frequency domain, the \n(undelayed) sensor dynamics by H(s), the (undelayed)\
    \ plant dynamics by G(s), \nand the controller by C(s). \nThe most important delays\
    \ in a control loop with visual feedback are those \ncaused by the sensor, and\
    \ the delay time directly affects the dynamic stability of \nthe control system.\
    \ System stability is determined by the poles of the \ninput/output transfer function,\
    \ i.e., the roots of the denominator. For a single-\ninput–single-output (SISO)\
    \ system, the denominator (characteristic equation of \nthe system) is simply\
    \ 1+ the loop gain, so that any stability analysis would \nincorporate the total\
    \ actuator and sensor delay to determine stability bounds. \n \n\U0001D44C(\U0001D460\
    )\n\U0001D445(\U0001D460) = \n\U0001D436(\U0001D460)\U0001D43A(\U0001D460)\U0001D452\
    −\U0001D460(\U0001D447\U0001D44E)\n1 + \U0001D436(\U0001D460)\U0001D43A(\U0001D460\
    ) \U0001D452−\U0001D460(\U0001D447\U0001D44E)\U0001D43B(\U0001D460) \U0001D452\
    −\U0001D460(\U0001D447\U0001D460)                                            \
    \    (4.10) \n \n95 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \n \nand the\
    \ characteristic equation is: \n \n1 + C(s)G(s)H(s)\U0001D452−\U0001D460(\U0001D447\
    \U0001D44E+\U0001D447\U0001D460)  = 0 \n(4.11) \n \nThe effects of stability can\
    \ be analysed by studying the conditions of marginal \nstability. From the above\
    \ equation, the following expressions are deduced: \n \n|\U0001D436(\U0001D457\
    ⍵)\U0001D43A(\U0001D457⍵)\U0001D43B(\U0001D457⍵)||\U0001D452−\U0001D457\U0001D714\
    \U0001D447| = 1 \n(4.12) \n \n \n\U0001D43F(\U0001D436(\U0001D457⍵)\U0001D43A\
    (\U0001D457⍵)\U0001D43B(\U0001D457⍵))\U0001D43F(\U0001D452−\U0001D457\U0001D714\
    \U0001D447) = 180º  \n(4.13) \n \nAs \n = 1 for all \n, the magnitude of the system\
    \ is not affected by the delay. \nHowever, as L \nradians, it is clear that the\
    \ phase margin for a system \nwith a time delay decreases as the time delay increases,\
    \ leading to instability and \nthus constraining the bandwidth achievable in the\
    \ face of delays. \nOne way to deal with the pernicious effect of known or unknown\
    \ delays is \nto detune first-order gains. With a PID controller, this is performed\
    \ by reducing \nthe proportional gain (P) to levels where the system remains stable.\
    \ This \napproach has the disadvantage that the resulting response is slowed down\
    \ and, \ntherefore, the overall performance of the system is worsened. The servo\
    \ control \nmust ensure a compromise between performance and stability. The performance\
    \ \nis proportional to the value of the gain of the corrector; however, above\
    \ a certain \nvalue, the corrector tends to destabilize the system. \n \n5. Exploration\
    \ Case Study \n \nThe experimental exploration mission was carried out with the\
    \ objective of \ndetermining the viability of the previously described approaches\
    \ in detecting fan \nmussel specimens in an area of 250 m x 100 m in the Mar Menor\
    \ (with the \ncoordinates of Table 4.7). A cloud architecture approach (Figure\
    \ 4.34-a) and a \nhybrid approach, a combination of cloud architecture (main mission)\
    \ and edge \narchitecture (tracking mission) were adopted (Figure 4.34-b). The\
    \ aim of the \nhybrid approach was to take advantage of edge architecture’s lower\
    \ latency and \nfavourable cloud precision. The tests achieved in the previous\
    \ section lead us to \nconclude that the results of Azure custom vision are more\
    \ pertinent to our use \ncase application (in terms of latency and accuracy);\
    \ therefore, we decided to \nadopt both the cloud and edge Azure models for the\
    \ mission described below. \nTable 4.7. GPS coordinates of the area explored.\
    \ \n \n96 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nCorner \nLatitude\
    \ \nLongitude \nNorth east \n37.697635º −0.780121º \nNorth west 37.697635º −0.782876º\
    \ \nSouth west 37.696825º −0.782876º \nSouth east \n37.696825º −0.780121º \n \n\
    Our sailing operation started in a vessel equipped with a robotic arm that \n\
    placed the vehicle in the water. After defining the coordinates of the inspection\
    \ \narea, the mission was planned on IUNO software (Figure 4-31) according to\
    \ the \nweather forecast, the time available and the width of the vehicle’s search\
    \ path. \n \nFigure 4.31. Mission generated in IUNO and uploaded into AUV. \n\
    The AUV employed for the experiment was connected to the buoy as shown \nin Figure\
    \ 4-32. The control station on board the vessel was connected to the AUV \nby\
    \ 4G communications. The different systems were checked before the AUV was \n\
    placed in the water: control, lighting, thrusters, 4G communications, vision,\
    \ etc. \nAfter successfully validating the systems, the vehicle was launched,\
    \ and the \nmission was transferred from IUNO to the AUV. \nWe initiated the main\
    \ mission using the first approach (cloud architecture for \ndetection and tracking).\
    \ The AUV started to explore the area for possible \nspecimens. The average depth\
    \ of the inspection area was 5.02 m and the vehicle \nremained at an average height\
    \ of 2.01 m above the seabed. \nThe first of the six sweeps (Figure 4.31) was\
    \ completed without detecting any \npossible specimens. The first fan mussel was\
    \ detected with 63% accuracy in the \nsecond track, when the AUV switched to the\
    \ secondary mission mode to track it \n(object location in the frame and distance\
    \ calculation). However, this turned out \nto be quite impractical due to the\
    \ high latency of the cloud connection. A timeout \nexception occurred during\
    \ the tracking mission and the algorithm chose to ignore \nit and resume the main\
    \ mission. As described in Section 6, the detection fails if a \ndeadline is missed\
    \ due to transmission delays, which affects the dynamic \nstability of the control\
    \ system. The technical team therefore decided to abort the \n \n97 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nmission, return to the starting point\
    \ and launch the same mission in the “hybrid” \nmode. \n \n \nFigure 4.32. Deploying\
    \ the platform to initiate the mission. AUV submarine \nconnected to a buoy via\
    \ a DSL cable. \nThe hybrid mission mode was initiated, and the cloud connection\
    \ was used \nto process the photos sent during the main tracking mission. On the\
    \ second \nsweep, the cloud results in the gateway indicated the presence of a\
    \ specimen with \n64% probability. The vehicle switched to the tracking mode.\
    \ At this point, the \nAUV began manoeuvring to place the target in the centre\
    \ of the image, while the \ninference was switched to the edge model in the IoT\
    \ gateway instead of the cloud \nto reduce latency. The AUV was able to follow\
    \ the suspected specimen up to a \ndistance of 2.13 m. The accuracy of the analysed\
    \ image at this distance was 83.8%, \nusing the trained edge model. For greater\
    \ certainty, the inference was switched \nto the cloud for the last picture to\
    \ confirm the find. In this hybrid mode, the edge \nwas used to speed up tracking\
    \ and AUV response. At this point, the AUV ended \nthe secondary mission mode,\
    \ registered the find as positive, saved its coordinates \nand resumed the main\
    \ mission (Figure 4.33). \n \n \nFigure 4.33. Specimen detection and positioning\
    \ in IUNO. \n \n98 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nNo further\
    \ specimens were detected until the fourth sweep, when another \nwas detected\
    \ with 38% probability. Once again, the vehicle switched to tracking \nmode, centred\
    \ the target in the image and performed the approach manoeuvre \nas before. After\
    \ halting at 2.06 m from the target, the recognition algorithm \nindicated that\
    \ the target was a fan mussel with 59% probability. As the minimum \nconfirmation\
    \ requirement in terms of the probable detection threshold at this \nstage is\
    \ 80%, the target was ignored, and the main mission was resumed. Due to \nthe\
    \ real-time communications, the target was in fact found not to be a fan mussel\
    \ \nbut a dark-coloured rock. On the sixth sweep, the mission and inspection were\
    \ \ncompleted after detecting one target specimen and discarding another possible\
    \ \ndetection that turned out to be a rock. \n \n6. Performance \n \nCloud and\
    \ edge computing are considered adequate platforms to \nincorporate artificial\
    \ intelligence approaches. This paper primarily focuses on the \nissues related\
    \ to the real-time constraints of using an AI cloud in both \nenvironments. Our\
    \ AUV system is designed to collect and interpret underwater \nimages to track\
    \ the fan mussel population in real time by an automatic processing \nmethod.\
    \ This automated approach is based on DL image processing techniques, \nsuch as\
    \ CNN, to detect the position of a possible specimen in a captured photo. \nThe\
    \ IoT gateway algorithm establishes the connection between the AUV control \n\
    system and cloud image processing techniques. The results of our proposed \nsystem\
    \ are compared with cloud and edge image processing in terms of latency \nand\
    \ certainty. Therefore, we aim to compare the response time between the cloud\
    \ \nand edge inference. \nMicrosoft Azure cloud was first compared with IBM and\
    \ Google clouds, as \nshown in Figure 4.34 [227-229]. The second comparison evaluated\
    \ the same cloud \nservice with inference in the edge and comparing the same results\
    \ in the cloud. \n \n \n                                                     \
    \         (a)                                                                (b)\
    \ \n \n99 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nFigure 4.34.\
    \ Communication edge cloud. (a) Training and inference in the \ncloud; (b) training\
    \ in the cloud, inference in the edge. \nWe describe the various network connections\
    \ and the performance metrics \nfor the architectures given in Figure 4.34. We\
    \ first assessed the delay between the \ndifferent terminals in the cloud architecture\
    \ and then compared it to that of the \nedge computing architecture. We evaluated\
    \ the performance of each trained \nmodel in the cloud and in the edge. Below,\
    \ we compare the performance of each \narchitecture, using LattePanda as an IoT\
    \ gateway, with a 1.8-GHz Intel quad-core \nprocessor, 4 GB RAM and 64 GB on-board\
    \ flash memory. \n6.1. Delay Assessment in the Proposed Platforms \nFigures 4.35\
    \ and 4.36 exhibit the different data flows via the various \ncommunication networks\
    \ for the cases of cloud and edge computing. From data \nacquisition (sensors)\
    \ to actuators, the information flow goes through different \nnetworks: CAN and\
    \ Ethernet in the case of edge architecture, and the Internet \nand DSL for the\
    \ cloud architecture. This represents the difference in latency \nbetween the\
    \ two modes and highlights the critical points in each case. \nThe highest latency\
    \ expected in the case of edge computing is Tinference, and the Tcloud \nis the\
    \ one expected in the cloud. \n6.1.1. Cloud Architecture \nIn the adopted cloud\
    \ architecture, all the generated images are sent to the \ncloud services and\
    \ the inference is performed entirely in the cloud. This makes \nthe application\
    \ fully dependent on the cloud results in order to make the \nnecessary adjustments,\
    \ which are crucial in the case of intermittent connectivity. \nFigure 4.35 shows\
    \ the different delays in the use case process. \n \nFigure 4.35. Latency in the\
    \ proposed platform within the cloud architecture. \n \n100 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nThe response time in the system can be divided into delays,\
    \ as modelled in \nEquation (4.14): \n \n\U0001D447 = \U0001D447\U0001D45B\U0001D44E\
    \U0001D463 + \U0001D447\U0001D460\U0001D44F1 + \U0001D447\U0001D454\U0001D461\
    1 + \U0001D447\U0001D44F\U0001D4661 + \U0001D447\U0001D450\U0001D459\U0001D45C\
    \U0001D462\U0001D451 + \U0001D447\U0001D44F\U0001D4662 + \U0001D447\U0001D454\U0001D461\
    2 + \U0001D447\U0001D460\U0001D44F2 + \U0001D447\U0001D44E\U0001D450\U0001D461\
    \ \n(4.14) \n \n \nwhere: \n(1) Tnav is the navigation sensor time, \n(2) Tsb1\
    \ is the acquisition time of the sensor data in sbRIO, \n(3) Tgt1 is the processing\
    \ time of the first and second threads in the IoT gateway \npresented, \n(4) Tby1\
    \ is the transmission time from the AUV to the buoy, \n(5) Tcloud is the time\
    \ needed to send photos to the cloud and receive the response \nresults, \n(6)\
    \ Tby2 is the transmission time of cloud results to the AUV, \n(7) Tgt2 is the\
    \ processing time of the first, second, and third threads in the IoT \ngateway\
    \ presented, \n(8) Tsb2 is the IoT gateway data acquisition time in sbRIO, and\
    \ \n(9) Tact is the actuation time. \nWhen the AUV starts up the IP camera stream,\
    \ the Tsens value can be expressed \nin two ways depending on the data stream,\
    \ according to Equations (15) and (16): \n \n\U0001D447\U0001D460\U0001D452\U0001D45B\
    \U0001D460 = {\U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\U0001D460\U0001D44F\
    1  if  \U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\U0001D460\U0001D44F\
    1 > \U0001D447\U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\U0001D44E\n\U0001D447\
    \U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\U0001D44E if \U0001D447\U0001D45B\
    \U0001D44E\U0001D463 + \U0001D447\U0001D460\U0001D44F1 < \U0001D447\U0001D450\U0001D44E\
    \U0001D45A\U0001D452\U0001D45F\U0001D44E  \n(4.15) \n \n\U0001D447 = \U0001D447\
    \U0001D460\U0001D452\U0001D45B\U0001D460 + \U0001D447\U0001D454\U0001D4611 + \U0001D447\
    \U0001D44F\U0001D4661 + \U0001D447\U0001D450\U0001D459\U0001D45C\U0001D462\U0001D451\
    \ + \U0001D447\U0001D44F\U0001D4662 + \U0001D447\U0001D454\U0001D4612 + \U0001D447\
    \U0001D460\U0001D44F2 + \U0001D447\U0001D44E\U0001D450\U0001D461 \n(4.16) \n \n\
    \ \nTcloud is composed of three different delays: Trequest is the transmission\
    \ time of each \nphoto to the cloud, Tinference is the processing time of the\
    \ transmitted photo in the \ncloud service, and Tresponse is the time from the\
    \ cloud to the buoy. \n \n\U0001D447\U0001D450\U0001D459\U0001D45C\U0001D462\U0001D451\
    \ = \U0001D447\U0001D45F\U0001D452\U0001D45E\U0001D462\U0001D452\U0001D460\U0001D461\
    \ + \U0001D447\U0001D43C\U0001D45B\U0001D453\U0001D452\U0001D45F\U0001D452\U0001D45B\
    \U0001D450\U0001D452 + \U0001D447\U0001D45F\U0001D452\U0001D460\U0001D45D\U0001D45C\
    \U0001D45B\U0001D460\U0001D452 \n(4.17) \n \n6.1.2. Edge Architecture \nIn the\
    \ edge architecture, the data remains in the local machine and the images \nare\
    \ not sent to the cloud; however, the application needs a minimal connection \n\
    to the cloud to report usage, which is suitable for intermittent connectivity.\
    \ The \ncloud connection is almost negligible; instead of sending photos to the\
    \ cloud for \nprocessing, the model uploads to the local IoT gateway and performs\
    \ the \ntreatment. We therefore neglect the cloud connection in this architecture\
    \ and only \nconsider the connections in the AUV. \n \n101 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n \nFigure 4.36. Edge architecture latency in the proposed\
    \ platform. \nIn the edge model deployed in the IoT gateway, the overall response\
    \ time of \nthe edge architecture in the AUV over the Ethernet and CAN networks\
    \ is \nmodelled as: \n \n\U0001D447 = \U0001D447\U0001D460\U0001D452\U0001D45B\
    \U0001D460 + \U0001D447\U0001D460\U0001D44F1 + \U0001D447\U0001D454\U0001D461\
    \ + \U0001D447\U0001D460\U0001D44F2 + \U0001D447\U0001D44E\U0001D450\U0001D461\
    \ \n(4.18) \n \nWhere Tsens is expressed as: \n \n\U0001D447\U0001D460\U0001D452\
    \U0001D45B\U0001D460 = {     \U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\
    \U0001D460\U0001D44F1   if.  \U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\
    \U0001D460\U0001D44F1 > \U0001D447\U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\
    \U0001D44E\n\U0001D447\U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\U0001D44E\
    \    if.\U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\U0001D460\U0001D44F\
    1 < \U0001D447\U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\U0001D44E  \n\
    (4.19) \n \nTgt in this case depends on Tthreads executing the 4 threads in the\
    \ IoT \ngateway and the custom model Tinference uploaded from the cloud. \n \n\
    \U0001D447\U0001D454\U0001D461 = \U0001D447\U0001D461ℎ\U0001D45F\U0001D452\U0001D44E\
    \U0001D451\U0001D460 + \U0001D447\U0001D456\U0001D45B\U0001D453\U0001D452\U0001D45F\
    \U0001D452\U0001D45B\U0001D450\U0001D452 \n(4.20) \n \n6.2. Metrics \nThe Azure\
    \ Custom Vision, Google cloud and Watson IBM services allow \nusers to load a\
    \ set of image data and define the bounding box of each desired \nobject in the\
    \ image. To train the model effectively, the images must be varied and \nas close\
    \ as possible to the data on which the predictions will be made. Camera \nangle,\
    \ blurring, background, lighting, size, low resolution and type are all \nimportant\
    \ variations of the image that affect the training process. \nOnce the training\
    \ was completed, we calculated the model’s performance \nusing new image datasets\
    \ (i.e., not included in the training dataset), shown in \nTable 8. Precision\
    \ indicates the fraction of identified classifications that are \n \n102 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \ncorrect, while recall indicates\
    \ the fraction of actual classifications that are \ncorrectly identified. IoU\
    \ (intersection over union) is a metric of how successfully \na model predicts\
    \ the objects’ locations and is gauged using the area of \noverlapping regions\
    \ of the predicted and ground truth bounding boxes, defined \nas: \n \n\U0001D43C\
    \U0001D45C\U0001D448 = \U0001D434\U0001D45F\U0001D452\U0001D44E \U0001D45C\U0001D453\
    \ \U0001D442\U0001D463\U0001D452\U0001D45F\U0001D459\U0001D44E\U0001D45D\n\U0001D434\
    \U0001D45F\U0001D452\U0001D44E \U0001D45C\U0001D453 \U0001D448\U0001D45B\U0001D456\
    \U0001D45C\U0001D45B  \n \n  (4.21) \n \nUnlike IBM in Azure Custom Vision and\
    \ Google cloud, the AI model can be \nexported in different formats (TensorFlow,\
    \ Docker) specially adapted to edge \ndevices, as opposed to in the cloud. The\
    \ model trained for cloud use is different \nfrom that trained for the edge as\
    \ regards accuracy and response time. We used \nthe same photos to train and test\
    \ the trained models for both edge and cloud use \nin the trials. Figure 4.37\
    \ shows some differences in terms of the accuracy of new \nphotos not used in\
    \ the training phase. The five tests clearly show the limits of \neach example;\
    \ for instance, in test 3, the picture was blurred, and Google cloud \ncould not\
    \ detect the mussel, while Microsoft detected it with 83% accuracy and \nIBM only\
    \ 15% accuracy. In test 2, all three clouds detected an unknown red object \n\
    stuck in the sub-bottom as a mussel with different percentages, which shows the\
    \ \nlimitation of the models regarding colour changes. \n \n \nFigure 4.37. Cloud-based\
    \ custom models for detecting new specimens. \n \n103 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nIn order to evaluate the performance of the proposed\
    \ object detection \nmodels, in both the cloud and edge, we used the following\
    \ standard performance \nmetrics: \n \n\U0001D45D\U0001D45F\U0001D452\U0001D450\
    \U0001D456\U0001D460\U0001D456\U0001D45C\U0001D45B =\n\U0001D447\U0001D443\n\U0001D439\
    \U0001D443+\U0001D447\U0001D443 \n \n(4.22) \n \n\U0001D45F\U0001D452\U0001D450\
    \U0001D44E\U0001D459\U0001D459 =\n\U0001D447\U0001D443\n\U0001D439\U0001D441+\U0001D447\
    \U0001D443 \n \n(4.23) \nwhere precision indicates the fraction of identified\
    \ detections that were correct, \nand recall indicates the fraction of actual\
    \ detections that were correctly identified. \nFP (False Positive) represents\
    \ the number of negative samples judged to be \npositive, TP (True Positive) is\
    \ the number of positive samples judged to be \npositive, and FN (False Negative)\
    \ is the number of positive samples judged to be \nnegative. \nTable 4.8. Accuracy\
    \ measurement in different platforms. \n \nTP \nFP \nFN \nPrecision \nRecall \n\
    IoU \nIBM \n28 \n2 \n8 \n0.933333 \n0.777778 \n0.82506 \nGoogle \n22 \n3 \n13\
    \ \n0.916666 \n0.611111 \n0.83364 \nAzure cloud \n33 \n4 \n3 \n0.891892 \n0.916667\
    \ \n0.86601 \nAzure edge \n24 \n3 \n11 \n0.888889 \n0.666667 \n0.678634 \n \n\
    The accuracy measurement tests were performed on all three cloud \nplatforms.\
    \ We also adopted the Azure edge model as it shows a better IoU metric \nscore\
    \ than Google. The accuracy test was performed on more than thirty photos \nof\
    \ mussels detected by our AUV camera, using the same photos in the three \ndifferent\
    \ clouds. The results given in Table 8 clearly show the difference between \n\
    the AI cloud services. \n6.3. Latency Evaluation \nSince most of the cloud APIs\
    \ are based on the HTTP protocol, we performed \na total of 100 HTTP throughput\
    \ tests using SpeedTest between the web server \nand the IoT gateway installed\
    \ in the AUV. The tests were performed in the Mar \nMenor experimental area through\
    \ the 4G connection. The average results of the \ntests carried out in this experimental\
    \ area were as follows: round trip delay: 66ms; \ndownload: 16.6 Mbps; upload:\
    \ 19.3 Mbps. The average size of the image sent \nfrom the AUV to the cloud was\
    \ approximately 194 kb. \nThe local network which connects the vehicle, and the\
    \ buoy presents a low \nfixed latency. This was measured by a 100-automated-delay\
    \ measurement \ncampaign. The average latencies between the IoT gateway and the\
    \ different \n \n104 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    devices in the vehicle’s Ethernet network were as follows: sbRIO: 0.9ms; camera:\
    \ \n1.1ms; 4G router (buoy): 1.2 ms. \nThe latency results are summarized in Table\
    \ 4.9, where average, minimum \nand maximum response time values are calculated\
    \ for each endpoint \narchitecture. The experimental set-up was based on Azure\
    \ and IBM cloud \narchitectures, plus another edge architecture using a custom\
    \ model formed by \nAzure and processed by the IoT gateway. Although IBM Watson\
    \ and Azure \ncustom vision are available worldwide, the locations of the deployments\
    \ differ; \nWatson is deployed in the U.S. and South Korea [226], while Google\
    \ cloud and \nAzure are deployed in various locations around the world [227, 228].\
    \ In this case, \nthe Azure and Google cloud services are deployed in Western\
    \ Europe, while IBM \nis in Dallas, USA. All the samples in each architecture\
    \ were thoroughly verified \nin an experimental campaign with over 100 valid samples.\
    \ The experiments \ncarried out were based on Equations (4.14) and (4.16) and\
    \ Python software. The \nlatter was employed to measure the overall latency. \n\
    Table 4.9. Latency measurement in different platforms. \n \nTotal Response \n\
    \ time (ms) \nCloud response  \ntime (ms) \nIoT Computing  \ntime (ms) \nCapturing\
    \ and \nwriting time (ms) \n \nMin \nMax \nMean \nMin \nMax \nMean \nMin \nMax\
    \ \nMean \nMin \nMax \nMean \nIBM \n1407 \n4060 \n2064 \n1280 \n3896 \n1935 \n\
    0 \n0 \n0 \n93 \n192 \n129 \nGoogle \n1291 \n4384 \n1696 \n1160 \n4071 \n1520\
    \ \n0 \n0 \n0 \n92 \n196 \n130 \nAzure \n1298 \n4572 \n1703 \n1171 \n4435 \n1571\
    \ \n0 \n0 \n0 \n92 \n196 \n131 \nAzure \nedge \n623 \n687 \n634 \n0 \n0 \n0 \n\
    523 \n595 \n532 \n93 \n194 \n130 \n \nThe results reported in Table 9 show the\
    \ differences between the proposed \narchitectures in terms of latency. Despite\
    \ the fact that image processing in edge \ncomputing is performed on the IoT gateway,\
    \ the total response time is \nsignificantly lower than the latency obtained with\
    \ cloud computing. The faster \nrunning time of the custom AI detection model\
    \ ensures real-time tracking and \nnavigation adjustment. Edge average response\
    \ time is almost three times less \nthan that of the cloud. However, the edge\
    \ model is less accurate than the cloud \nmodel; in fact, the edge model loaded\
    \ from the cloud is optimized as far as \npossible to meet the requirements of\
    \ tiny device platforms. \n \n \n \n \n \n \n105 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n \nIII. System 3. Autonomous Marine Robot Based on\
    \ AI \nRecognition for Permanent Surveillance in Marine \nProtected Areas \n \n\
    1. Introduction  \n  \nThere are unique areas in the marine environment that must\
    \ be protected due \nto their singular characteristics and high environmental\
    \ value. These habitats are \nparticularly sensitive to alteration or disturbance\
    \ by humans, changes in the \necosystem or changes in climate. One of the legal\
    \ tools for their protection is the \ndeclaration of the area as a Marine Protected\
    \ Area (MPA), which legally allows \nfor the establishment of a scenario of maximum\
    \ protection [229]. The main \npurpose of MPAs is to regenerate fishing resources,\
    \ preserve natural resources, \nconserve marine species and recover ecosystems.\
    \ \nA marine reserve is defined as a category of marine protected area with legal\
    \ \nprotection mainly against fishing or development. The main limits as a general\
    \ \nrule are professional fishing (with the exception of a few authorized boats)\
    \ and \ndiving (also with authorized exceptions), while recreational fishing,\
    \ underwater \nfishing and anchoring are totally prohibited. These activities\
    \ in marine reserves \nmust be monitored by the authorities to guarantee the care\
    \ of the ecosystem by \nlaw [230]. A marine reserve can be made up of a single\
    \ area or different non-\nadjacent areas and contains at least one integral reserve,\
    \ which is a natural space \nwith high ecological and biological value due to\
    \ a unique and delicate ecosystem \nsensitive to any alterations. \nThe restrictions\
    \ are even stricter in integral reserves: all activities are \nforbidden, with\
    \ the exception of authorized scientific activities and sailing at a \nlimited\
    \ speed. In Spain there are a total of eleven marine reserves [231], four are\
    \ \non islets, islands and reefs far from inhabited areas and ports, and the rest\
    \ are on \nthe coast or near inhabited areas. The surveillance of areas far from\
    \ the coast is a \nreal challenge: inspection vehicles must be autonomous and\
    \ must not be \ncompromised by the risk of going adrift. Long-distance communications\
    \ with the \nland-based station must be fluid and stable, especially if 4G or\
    \ 5G coverage is not \navailable, as in most marine areas far from the coast and\
    \ in the video surveillance \nscenario, image transmission requires a highly stable\
    \ bandwidth. All these \nrestrictions are a major challenge for the surveillance\
    \ of marine reserves on the \nhigh seas. \nSeveral measures have been adopted\
    \ for the monitoring and surveillance of \nmarine reserves. The materials and\
    \ human resources are available to carry out \n \n106 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nroutine inspections or to set up devices to detect illegal\
    \ fishing. In general, all \nmarine reserves are equipped with vessels, georeferenced\
    \ cameras, night vision \nbinoculars, telescopes and ROVs, among others [231].\
    \ However, all these \nmeasures and means have the same disadvantage: the lack\
    \ of a permanent \npresence. Despite the measures adopted, it is not possible\
    \ to permanently \nmonitor the nature reserve with these means, and the identification\
    \ and arrest of \noffenders is practically incidental. This is why it is very\
    \ difficult to obtain records \nof those who have accessed protected areas and\
    \ to obtain real-time alerts to \nidentify those responsible in the event of damage\
    \ or alteration of the ecosystem. \nUnfortunately, even with the above-described\
    \ means and resources illegal \nactivities such as anchoring or poaching still\
    \ take place. \nProtecting remote marine areas with the currently available means\
    \ is not \nenough for their full protection, especially in integral reserves.\
    \ The challenges are \nquite demanding and even more so in permanent surveillance.\
    \ Autonomous \nSurface Vehicles (ASV) are ideal in this scenario for autonomous\
    \ navigation, but \nthere is also another issue. In order to monitor remote marine\
    \ reserves, the \ncapacity to detect and identify specific types of vessels is\
    \ required. Detection and \nidentification by humans is difficult to equal in\
    \ this scenario and only visual \nrecognition technologies based on artificial\
    \ intelligence (AI) and the Internet of \nThings (IoT) can offer a detection capacity\
    \ close to human capabilities. \nThere are also other issues, mainly water quality,\
    \ pollution and the effect on \nthe ecosystem. In a previous work we proposed\
    \ an autonomous system \nconsisting of an autonomous solar-powered marine robot\
    \ with specialized \nsensing systems [232], designed to carry out long-term observation\
    \ missions in \nshallow water, collecting georeferenced oceanic data to monitor\
    \ and analyse \nphysical-chemical water parameters. \nWe therefore consider permanent\
    \ surveillance and inspection of marine \nreserves to be vital. For this, we introduce\
    \ the concept of the \"watchdog\"; a \nwatchdog roams around an area (for example,\
    \ a fenced-in area around a house). \nAs soon as an intruder is detected, the\
    \ watchdog alerts the owner and deters the \nintruder from entering. If he enters\
    \ the premises, the guard dog chases him out. \nThis concept, applied to autonomous\
    \ navigation by means of ASV craft together \nwith the concepts of Industry 4.0\
    \ applied to marine environments, gives us a \npowerful proposal for the permanent\
    \ surveillance of marine reserves. \nThis paper proposes and evaluates an autonomous\
    \ marine vehicle based on \nartificial intelligence, designed to recognize and\
    \ classify vessels considered as \npotential risks according to their type and\
    \ activity. Its main goal is to track and \nfollow them in real time to obtain\
    \ information (identification and position, video \nrecording, etc) using automatic\
    \ image recognition. When a vessel classified by \nthe algorithms as a potential\
    \ risk inside an integral reserve is detected and \nremains in the same position\
    \ for a certain period, it could mean illegal activity. \nIn the experiment, the\
    \ proposed Autonomous Guard based on the ASV was \n \n107 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \ntested in this scenario in order to recognize, follow\
    \ and identify vessels based on \nan autonomous navigation and AI image recognition.\
    \ \nThe series of requirements for this include the following factors: it cannot\
    \ \nalter the ecosystem, so its energy source must be totally renewable; its capacity\
    \ \nto detect and recognise target vessels must be precise and reliable, the ability\
    \ to \ndistinguish between different types, and most importantly, the detection\
    \ capacity \nshould not compromise the ASV’s autonomy. \nThere are radar-based\
    \ detection AUVs with fast and accurate detection \nsystems, but this is not enough\
    \ for precise recognition and identification [233]. In \n[234] SAR (Synthetic\
    \ Aperture Radar) images are used together with deep \nlearning (DL) algorithms\
    \ to detect and recognize ships by means of a powerful \nCPU and local graphics\
    \ cards and low computational time, but these have a high-\npower consumption,\
    \ which is incompatible with a stand-alone vehicle. Due to \nthe inevitable vibration\
    \ and constant movement of the autonomous vehicle it is \nadvisable to use single\
    \ board devices and CPUs. This type of solution is suitable \nfor fixed surveillance\
    \ stations, but not for autonomous vehicles, whose autonomy \nis compromised.\
    \ On the other hand, fixed stations are not applicable in this case \ndue to several\
    \ factors, such as limited monitoring range, low reaction capacity, \nexposure\
    \ to environmental conditions and marine environments (in case of \nbuoys), ecosystem\
    \ alteration (in case of installations on islets or reefs), among \nothers. In\
    \ [236] a unified energy management framework was used to enable a \nsustainable\
    \ edge computing paradigm powered by distributed renewable energy \nresources.\
    \ Edge computing technologies significantly simplify local computing \ncapacity\
    \ and increase energy efficiency, while maintaining low latency. AI-based \ntechnologies\
    \ such as edge and cloud computing have proven to be accurate in \nterms of recognition\
    \ results and data analysis [236-238]. In [239] hybrid use of \ncloud/edge technologies\
    \ is considered optimal, significantly reducing the \npercentage of local computing\
    \ by deriving most of the calculation to remote \n(cloud) servers and highly optimised\
    \ algorithms through suitable and specific \ntraining processes. \nAs the paper’s\
    \ main contribution and novelty, we propose a hybrid \nCloud/Edge technology,\
    \ optimised for high image recognition accuracy, \nminimum power consumption and\
    \ low latency, in order to increase vehicle \nautonomy and efficiency, increase\
    \ the likelihood of mission success and security \nduring autonomous surveillance\
    \ missions in marine reserves with MASS. High \npower consumption compromises\
    \ vehicle autonomy during image recognition \nand identification, and high latency\
    \ compromises the control and tracking \nalgorithms. To select the most appropriate\
    \ technology according to the scenario \nand circumstances, we propose the SAAO\
    \ (Smart Algorithm for Autonomy \nOptimization by selecting the proper AI technology\
    \ according to the current scenario). \nThis algorithm is optimized to select\
    \ the appropriate technology (cloud or edge \ncomputing) according to the situation\
    \ and circumstances. \n \n \n108 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n2. Proposed Platform for Surveillance in Marine Protected Areas \n \nThe BUSCAMOS-VIGIA\
    \ ASV was developed by DAyRA (División de \nAutomatización y Robótica Autónoma)\
    \ group at the UPCT. One of its achievements \nis described in [232], where we\
    \ gave the ASV the capability to make long-term \nmissions to acquire data from\
    \ multiparameter probes in the Mar Menor (Murcia, \nSpain) on factors to decide\
    \ the urgency in inspecting a specific area based on \nfuzzy logic. \n \n2.1.\
    \ The ASV–IoT Architecture Development \n \nA framework of this description together\
    \ with the hardware and software \narchitecture in the proposed system are shown\
    \ in Figure 4.38: \n \n \nFigure 4.38. BUSCAMOS-VIGIA framework. \nThe framework\
    \ represents the whole system as follows: it is structured into \ntwo main blocks:\
    \ the ASV block, Communication base station AP (Access Point) \nblock and Cloud/Internet\
    \ block. The first represents the logic or physical \nelements included in the\
    \ vehicle, and the second collects the elements in the \n \n109 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nremote station and cloud computing server.\
    \ Each main block is classified into \nlayers. The ASV block is divided into 4\
    \ layers: The Energy layer, \nSensors/Actuators layer, Navigation control layer,\
    \ and Edge layer. The energy \nlayer is formed of the elements that provide energy\
    \ and autonomy to the vehicle. \nAs can be seen, the batteries can be charged\
    \ in two ways: through photovoltaic \ntechnology (during navigation - so as to\
    \ extend the vehicle’s range - or in port) \nor through an AC source, when solar\
    \ power is not enough, or a quick charge is \nneeded when moored. The next layer\
    \ is the Sensors / Actuators layer, with the \ndifferent detection elements, which\
    \ provide information to the upper layers in \nthe framework (such as GPS, inertial\
    \ unit, LiDAR and cameras). Here also are the \nrudder and thrusters. The upper\
    \ layer is for Navigation and Control and consists \nof a NI cRIO controller (National\
    \ Instrument Compact Remote Input Output) \n9022 model and its peripheral elements\
    \ and modules. The elements in this layer \nare responsible for autonomous navigation\
    \ and use information from the sensors \nin the lower layer and the AI image recognition\
    \ response obtained from the IoT \nGateway in the upper layer. The cRIO controller\
    \ is formed of a main body, based \non a processor and FPGA, together with a reconfigurable\
    \ chassis, with a series of \nmodules necessary for several communication protocols\
    \ to command and \nacquire data from the lower layer, such as CAN-NMEA2000, I2C,\
    \ RS232 and \nRS485, according to the current hardware architecture. There are\
    \ also a serial of \ncode block and algorithms, described in Section 3.3. The\
    \ Upper or Edge layer is \nformed by the IoT Gateway where on-board AI takes place\
    \ by running the \nalgorithms in charge of the camera’s image processing and analysing\
    \ system. \nThe second main block, called “Cloud / Internet”, contains just one\
    \ layer in \nthe highest position of the framework, called the Cloud layer, containing\
    \ not only \nthe AI services, but also information and resources provided in real\
    \ time from \nauthorities and services, which are essential for planning or modifying\
    \ the ASV \nmission. Also found here is the IUNO (Interface for Unmanned drones)\
    \ software. \nThe IUNO software platform was also designed by the DAyRA group\
    \ of the \nPolytechnic University of Cartagena. The platform manages the integrated\
    \ \ncontrol of multiple unmanned marine vehicles with the aim of simplifying \n\
    maritime operations. The results obtained from each vehicle, regardless of its\
    \ \ncharacteristics, facilitate the success of the operation with a high degree\
    \ of \nautomation. This software has already been used in previous experiments\
    \ and \noperations, such as [223,239], and is the only point with human intervention.\
    \ \nActivities such as mission planning or remote supervision are commanded and\
    \ \nmanaged from here.  \nBetween the ASV and Cloud/Internet blocks we find the\
    \ Communications \nbase station AP block, containing the Radio link layer. This\
    \ provides high \nwideband, low latency and long-range WiFi communications between\
    \ the \nvehicle and the land. It is formed by two Ubiquiti ROCKET M2 2.4 GHz modules\
    \ \n(one on land and another in the vehicle) and its antennas, with Ubiquiti airMAX\
    \ \nconnection. Due to the characteristics of the communications scenario, the\
    \ land \n \n110 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nantenna is\
    \ the sector type and the on-board is omnidirectional. The land station \nis connected\
    \ to the Internet. This layer is especially crucial in areas where 4G-5G \ncover\
    \ is not available, as in most integral reserves. \nThere is an extra block in\
    \ both the ASV and Cloud/Internet main blocks called \nthe AI (Artificial Intelligence)\
    \ block. As explained in Section 4, it is formed of the \nAzure Cloud general\
    \ model, Azure cloud custom model and Azure Edge custom \nmodel for AI recognition\
    \ according to the smart algorithm criteria described in \nSection 4.4. \nThe\
    \ most relevant characteristics of the ASV used in the experiment \ndescribed\
    \ in this paper are as follows: the vehicle is 5 meters long. It has a robust\
    \ \nstructure that protects the devices from the weather, as well as a sunroof.\
    \ The \ninside of the vessel is subdivided into two sections by means of a bulkhead.\
    \ In \nthe stern are the elements related to power and propulsion: Block of 8\
    \ 100Ah \nbatteries configured in 2 parallel lines, providing 48V nominal power\
    \ and 14h \nautonomy. Two electric outboard motors, Torqeedo C4.0 Cruise model,\
    \ allow it \nto sail at a maximum speed of 6 knots. It has two racks, located\
    \ on the starboard \nand port sides. In the starboard rack are the IoT Gateway\
    \ (LattePanda single \nboard computer, with 1.8-GHz Intel quad-core processor,\
    \ 4 GB RAM and 64 GB \non-board flash memory) and the WiFi communications elements,\
    \ energy \nmanagement of different equipment, photovoltaic regulator and electrical\
    \ panel. \nThe main elements of the port rack are: the NI cRIO 9022 (National\
    \ Instruments \nCompact Remote Input Output) controller, the rudder controller\
    \ and the \nelectronic periphery. It is equipped with side-scan sonar, echo sounder,\
    \ GPS, \ninertial unit and radar. It also has 4 LiDAR-Lite 3 (Garmin) in both\
    \ bands, bow \nand stern, as safety elements for obstacle detection. It has a\
    \ solar roof formed by \n5 Enecom HF 130 panels that extend the autonomy of the\
    \ vessel according to the \nenvironmental conditions, connected to a photovoltaic\
    \ regulator and its battery \npack. The battery pack can also be charged by AC\
    \ chargers. In terms of vision, \nthe ASV is equipped with an AXIS P5534-E PTZ\
    \ camera (in the bow) with 18x \noptical and 12x digital zoom (total 216x), with\
    \ a resolution of 1280x720p, as well \nas three additional Ubiquiti Air Cam cameras\
    \ in the stern on both starboard and \nport. Its renewable energy source does\
    \ not leave a carbon footprint and it thus \nhas no environmental impact, which\
    \ makes it suitable for permanent navigation \nin marine reserves, particularly\
    \ in integral reserves. Figure 4.39 shows a picture \nof the BUSCAMOS-VIGIA vehicle.\
    \   \n \n \n111 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.39.\
    \ BUSCAMOS-VIGIA ASV. \n2.2 Implemented Vessel recognition and tracking algorithm\
    \ \nIn this section, we outline and itemize the development of the above-\nmentioned\
    \ IoT-ASV autonomous system, specifically the algorithm related with \noverall\
    \ mission management and its stages, vessel recognition system and the \nimplemented\
    \ tracking algorithm. It has five main blocks, namely, the IoT \ngateway, the\
    \ IP cameras, the ASV control system, the remote-control station and \nthe cloud/edge\
    \ AI image recognition source. \nThe overall mission is planned and triggered\
    \ by IUNO software in the cloud \nbase station by setting either the desired area\
    \ of inspection or the desired \nwaypoints. The navigation controller consists\
    \ of four navigation modes: Main \nMission Mode (MMM), where the vehicle navigates\
    \ by following preprogramed \ntracks, Dynamic Position Mode (DPM), where the vehicle\
    \ stays at specific GPS \ncoordinates while maintaining a fixed heading, Tracking\
    \ Mode (TM), where the \nASV follows a target (vessel) until specific conditions\
    \ are met, and finally, \nInspection Mode (IM), where once the target has been\
    \ reached, the vehicle stays \nat a fixed distance and heading from it, in order\
    \ to obtain and classify general \ninformation about it. Depending on the current\
    \ navigation mode, there will be a \nserial of priorities, targets and outputs,\
    \ as seen in Table 4.10: \nTable 4.10. Definition of mission stages. \n \nStage\
    \ 1 \nMain \nMission \nMode \n(MMM) \nStage 2 \nFixed Buoy \nMode (FBM) \nStage\
    \ 3 \nTracking Mode \n(TM) \nStage 4 \nInspection Mode (IM) \nPriority \nAccuracy\
    \ \n(recognition) \nLatency \nLatency \nBoth accuracy \n(recognition) and \nlatency.\
    \ \n \n112 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nTarget \nVessel\
    \ \nrecognition \nand \nclassification \nBounding box \nstudy (size and \npositions)\
    \ for a \ndetermined \nperiod. \nRemain in the \nsame position \nwith fixed \n\
    heading \n \nReach target \nvessel within \ndefined limits \nStay at a fixed distance\
    \ \nfrom target and \nheading it. \nObtain general and \nadditional information\
    \ \nabout target vessel. \nOutput \nIs the target \na risk \nvessel? (YES \n/\
    \ NO) \nIs the target \nvessel in the \nsame position?  \n(YES / NO) \nAlerts.\
    \ \nTarget has been \nreached inside \ndefined limits? \n(YES / NO). \nAlerts.\
    \ Save \ninformation. \nAlerts. Obtain \ninformation of target \nvessel. Video\
    \ \nstreaming. Save \ninformation. \n \nThe navigation mode will change according\
    \ to the scenario and the current \nstage of the general mission, as specified\
    \ in Algorithm 2 and Figure 4.38. The IoT \ngateway connects the navigation controller\
    \ and IP cameras with cloud services. \nDuring the entire mission, the IoT gateway\
    \ receives image data from the IP \ncameras and sensors (through the cRIO controller).\
    \ If a vessel is detected, the \nresults contain its classification (according\
    \ to the trained AI models), a bounding \nbox in the images (centre, relative\
    \ X-Y position, and size) and accuracy \n(percentage). Likewise, the IoT gateway\
    \ receives the image processing results \nfrom the AI recognition source for each\
    \ photo sent. The AI source (edge or cloud \ncomputing) to analyze images is determined\
    \ by the “Smart algorithm for autonomy \noptimization by selecting the proper\
    \ AI technology according to the current scenario” \n(SAAO) described in Section\
    \ 4.4. The AI source uses advanced learning \ntechniques to analyse the results\
    \ and sends them to the IoT gateway. The results \nobtained from the AI source\
    \ are used according to the specific target of each \nmission stage as described\
    \ in Table 10. This process is carried out throughout the \nmission. \nOnce the\
    \ mission starts (MMM), BUSCAMOS-VIGIA ASV follows the \ndefined mission whilst\
    \ analysing images until a vessel is detected. The AI source \nthen classifies\
    \ it according to the trained AI models to determine the risk level. \nThe mission\
    \ mode then moves to the next stage, the Fixed Buoy Mode (FBM).  \nIn FBM, if\
    \ the vessel has been detected with a camera other than the bow \ncamera, the\
    \ vehicle will initially change its heading (stern: +180°, starboard: +90°, \n\
    port: -90°) until the vessel is detected with the bow camera. IoT image processing\
    \ \nis used with the navigation controller to perform heading modifications to\
    \ keep \nthe detected vessel in the centre of the bow camera. Once the heading\
    \ points to \n \n113 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    the target vehicle, BUSCAMOS-VIGIA ASV will remain in that heading, \nregardless\
    \ of the detected vessel’s behaviour. The ASV can act as a fixed buoy or \nstay\
    \ in same position and heading. This mode is used to study the target’s \nbehaviour\
    \ by analysing the bounding box (size and position) of the processed \nimages\
    \ for a specific period to determine whether the target vessel is immobile \n\
    in the same position, which could mean a potential risk as it could be fishing\
    \ or \nanchored in a protected area. \nAt this point, the mission changes to Tracking\
    \ Mode (TM). The ASV starts \nnavigating and tracking the target by using the\
    \ bounding box’s analysed image \ncollection to fix and update the heading. The\
    \ IoT gateway links up with the main \ncontroller to modify the heading according\
    \ to the target’s position in the image, \nkeeping it in the centre of the bow\
    \ camera’s field of vision. It will continue in this \nmode until LiDAR detects\
    \ the target at a specific distance or if it leaves the \nprotected area. If the\
    \ TM is successful and the target is reached, several actions \ncan take place,\
    \ such us saving the vessel’s position or generating remote alerts. \nWhen the\
    \ target is reached, the last stage, Inspection Mode (IM) starts. The \nASV will\
    \ remain at a fixed distance from the target vehicle and heading as long \nas\
    \ possible. The objective of this stage is to obtain information about the target\
    \ \nand generate alerts in the remote base station. \nThis is described in Algorithm\
    \ 2, as well as in the flowchart in Figure 4.40. \n \n \n \nAlgorithm 2. Vessel\
    \ recognition and tracking algorithm. \nStart () \nStep 1:  \n    While (mission\
    \ has not started) {}    \n    {Starts Main Mission Mode (MMM)}      \nStep 2:\
    \ \n    If (mission has ended) \n        {End ()} \n    Else \n        {Navigate\
    \ follow defined mission} \n        {Select the right AI image recognition source\
    \ (AIsource) trough SAAO} \n        {Acquire frames from 4 cameras and send to\
    \ AIsource} \n        {Get the answer of every frame and add label with camera\
    \ position (bow, stern, \nstarboard, port) of detected vessel, called camera position\
    \ (CP)} \n        If ((accuracy of detected vessel > acceptable limits) AND (type\
    \ of vessel == \nclassified as potential \n        risk)) \n            {Go to\
    \ step 3} \n        Else \n            {Go to step 2} \nStep 3: \n{Starts Fixed\
    \ Buoy Mode (FBM)}      \n \n114 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n{Get the answer of every frame and add label with camera position (bow, stern,\
    \ \nstarboard, port) of detected vessel, called camera position (CP)} \n    Switch\
    \ (CP) \n        Case (CP == bow)  \n             If (accuracy < accuracy results\
    \ acceptable)  \n                {Discard detected vessel. No risk.}         \
    \                \n                {Go to step 2} \n            Else \n      \
    \          {Set new heading pointing detected vessel. Keep current position and\
    \ \nheading} \n                {Start study of target behaviour by analysing bounding\
    \ box of images for a \nspecific period} \n                 If (Detected vessel\
    \ is in the same position)  \n                    {Discard detected vessel. No\
    \ risk}                         \n                    {Go to step 2} \n      \
    \          Else \n                    {Target vessel in the same position. Risk\
    \ (anchoring, fishing)}                         \n                    {Go to step\
    \ 4} \n        Case (CP == stern) \n            {Vehicle turns +180º} \n     \
    \       {Go to step 3} \n        Case (CP == starboard) \n            {Vehicle\
    \ turns +90º} \n            {Go to step 3} \n        Case (CP == port) \n    \
    \        {Vehicle turns -90º} \n            {Go to step 3}    \n        Default:\
    \ \n            {Go to step 2}    \nStep 4: \n    {Start Tracking Mode (TM)} \n\
    \    {Navigate to track target vessel}      \n    {Acquire new frame from bow\
    \ camera and send to AIsource}  \n    {Calculate the bounding box center and vessel\
    \ position in order to fix heading \nwhile tracking} \n    If (LiDAR detects vessel\
    \ at 20m) \n        {Stop navigation. Target reached}  \n        {Go to step 5}\
    \ \n    Else If (vessel leaves integral reserve while tracking) \n        {Target\
    \ not reached}  \n        {Go to step 2} \n    Else  \n        {Go to step 4}\
    \ \nStep 5: \n    {Starts Inspection Mode (IM)} \n    {Acquire new frame from\
    \ bow camera and send to AIsource}  \n \n115 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n    {Calculate the bounding box centre and vessel position in order\
    \ to fix heading and \nkeep distance} \n    While (Target vessel is stopped) \n\
    \    {Record videos, save vessel’s position, obtain additional information, send\
    \ \ndata and alerts to cloud station} \n    If (Vessel starts moving) \n     \
    \   {Stage finished. Information collected} \n        {Go to Step 2} \nSecurity\
    \ Step:     \n    If (Energy == 25%) \n        {Return back to port area. Send\
    \ alert to cloud station} \n    If (Energy == 50%)  \n        {Send alert to cloud\
    \ station} \nEnd () \n \n \n \n \nFigure 4.40. Platform’s communications in the\
    \ tracking algorithm. \n2.3. ASV control \nAs shown in Figure 4.38, our marine\
    \ vehicle has a number of elements and \ndevices interconnected through different\
    \ networks. While the IoT gateway is in \ncharge of image recognition and communications\
    \ with the camera and the cloud, \nthe cRIO controller is the ASV’s main control\
    \ backbone. The National Instrument \ncRIO 9022 controller includes a real-time\
    \ processor and reprogrammable FPGA \nthrough its LabVIEW environment [240], as\
    \ well as a chassis that can be \nreconfigured according to the project architecture.\
    \ By default, it comprises two \nEthernet ports, USB port and serial connectivity.\
    \ For this architecture, the chassis \n \n116 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nhas been equipped with several modules that enable CAN-NMEA2000,\
    \ I2C, \nRS232 and RS485 communications. Its specifications are a 533-MHz CPU,\
    \ 256MB \nDRAM, 2GB storage, one Ethernet port and other features listed in [241].\
    \ A \nconsistent code for the cRIO controller was fully developed in the LabVIEW\
    \ \nenvironment for ASV management, control and command. \nThe software modules\
    \ in the cRIO’s vehicle control program comprise these \nmain operations, as shown\
    \ in Figure 4.38: \n \n• Commands management: It allows cRIO dispatch commands\
    \ from cloud \nstation, such as receive and launch main mission after definition\
    \ trough IUNO \nsoftware, stop it, or execute safety manoeuvres \n• Propulsion\
    \ and rudder control: Management of the different control loops for \nboth propulsion\
    \ and rudder, according to the obtained setpoint from Mission \nexecution control\
    \ module. \n• Incidents management: Security module that manages different actions\
    \ \ndepending on the incidents that may occur during the mission, such as loss\
    \ \nof communications or the impossibility of continuing the defined trajectories\
    \ \ndue to external conditions, such as strong winds or rough seas. \n• Mission\
    \ execution control: This module manages navigation to each of the \nprogrammed\
    \ waypoints, according to the running mission, by dispatching \nthe different\
    \ navigation commands for the heading and position control loops \nwith the information\
    \ received from sensors and IoT image analysis algorithm.  \n• Energy efficiency\
    \ manager: The vehicle contains some non-critical navigation \ndevices that can\
    \ be disconnected in the event of energy and autonomy being \ncompromised. This\
    \ module executes the disconnection if required. \n \n3. Smart algorithm for autonomy\
    \ optimization by selecting the \nproper AI technology according to the current\
    \ scenario (SAAO)  \n \nMaritime Autonomous Surface Ships (MASS) have to guarantee\
    \ a series of \nrequirements in order to fulfil their purpose, in particular,\
    \ autonomy and \nsecurity, while accuracy and latency in the image analysis are\
    \ vital in the \nsurveillance of marine reserves through AI-based visual recognition.\
    \  \nAs defined previously, the surveillance mission is divided into four stages\
    \ in \norder to optimize them according to the objectives and a series of priorities\
    \ to \nattend to each stage, as defined in Table 10. Optimizing the mission execution\
    \ \nmeans accomplishing it in the minimum time possible and with the highest \n\
    guarantee of success, or in other words, execute every stage of the mission in\
    \ the \nmost efficient manner possible. An efficient mission means making the\
    \ most of \nthe energy available, a limited and essential resource for autonomous\
    \ vehicles. \nThe restrictive objective is to save energy and guarantee the success\
    \ of the \n \n117 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nmission and\
    \ its security by taking the appropriate decisions in real time, which \nis the\
    \ crucial task of the proposed AI hybrid cloud/edge SAAO algorithm. \nIn stages\
    \ where accuracy is a priority, optimizing mission execution means \nusing AI\
    \ to obtain the best recognition results, detecting vessels that are a \npotential\
    \ risk to the marine reserve with the maximum precision and success. On \nthe\
    \ other hand, once the potential target has been detected and identified, \noptimizing\
    \ the mission in stages in which latency is a priority means obtaining \naccurate\
    \ results as fast as possible as setpoint for the heading controller block.  \n\
    As a single board low-power CPU is used to extend ASV autonomy, SAAO \nis designed\
    \ to be efficient and executed in platforms where energy is a limitation. \nUsing\
    \ both cloud and edge computing technologies to analyze images at the \nsame time\
    \ will entail extra consumption and increased latency in the image \nanalysis,\
    \ especially in edge computing, where CPU resources are limited. Balance \nis\
    \ the key to efficient and successful decision-making. These decisions are related\
    \ \nto selecting the best AI source technology for the success of every stage,\
    \ all of \nwhich have a series of priorities for optimizing the mission execution,\
    \ as shown \nin Table 4.11: \nTable 4.11. AI source preferences according to mission\
    \ stage. \n \nStage 1 \nMain \nMission \nMode \n(MMM) \nStage 2 \nFixed Buoy \n\
    Mode (FBM) \nStage 3 \nTracking \nMode (TM) \nStage 4 \nInspection \nMode (IM)\
    \ \nPriority \nAccuracy \n(recognition) \nLatency \nLatency \nBoth accuracy \n\
    (recognition) \nand latency. \nPreference \nAzure Cloud \nCustom \nModel \nAzure\
    \ Edge \nCustom \nModel \nAzure Edge \nCustom \nModel \nAzure Cloud \nGeneral\
    \ Model \nAlternativ\ne \nAzure Edge \nCustom \nModel \nAzure Cloud \nCustom \n\
    Model \nAzure \nCloud \nCustom \nModel \nAzure Edge \nCustom Model \n \nIn normal\
    \ conditions latency is adequate in edge models and accuracy is \nsuitable in\
    \ cloud models. That is the reason why there is a logic preference in \nevery\
    \ stage according to the defined priority, provided that accuracy is good \nenough.\
    \ Knowing when and what to offload while maintaining real-time \napplication Quality\
    \ of Service (QoS) requirements are the challenges to \novercome. Depending on\
    \ the mission stage, accuracy and latency results, a \ntechnique of offloading\
    \ to edge computing device (IoT gateway) or remote cloud \nservices is performed\
    \ to complete its execution, as shown in Figure 4.41. \n \n118 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nBasically, intelligent offloading can\
    \ be used as an optimization-based \napproach with constraints such as bandwidth,\
    \ network latency, accuracy \nrequirements or monetary cost. In this application,\
    \ latency and accuracy have \nbeen defined as critical throughout the process,\
    \ and that is why the output results \nof the AI source are linked as inputs to\
    \ the SAAO algorithm after analysing the \nimages.  \nThe decision to offload\
    \ or not depends on hardware capabilities, data size, \nthe deep neural network\
    \ (DNN) model to be used and network quality, among \nother factors. These factors\
    \ can be measured indirectly through latency and \naccuracy. Latency and accuracy\
    \ are the main elements to be considered in this \noptimization approach. Figure\
    \ 4.41 shows the SAAO diagram: \n \nFigure 4.41. SAAO diagram. \nThis diagram\
    \ describes how the SAAO works. The latency and accuracy \nobtained from the previous\
    \ analysis are analyzed according to the mission stage \nand the defined AI source\
    \ preference. In the stages where latency is the priority, \nthe accuracy result\
    \ is analyzed to check whether it is within acceptable limits. \nThis means that\
    \ they should at least be able to identify the target and obtain its \nrelative\
    \ coordinates in the analyzed image in order to obtain the bounding box \ncoordinates\
    \ and use them as a setpoint for the heading control loop. There is no \npoint\
    \ in using a fast AI source if the algorithm cannot detect the target in its \n\
    analysis. This is the critical line for accuracy. \nIn stages where accuracy is\
    \ the priority, latency is analyzed in order to select \nthe preferred or alternative\
    \ AI source. The latency results may vary significantly \ndepending on several\
    \ factors, such us the percentage of bandwidth used, \n \n119 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \ndistance from ship to base station, or weather conditions,\
    \ among others. With \nlatency not being the priority in these stages, it has\
    \ to be low enough to obtain an \nacceptably fast response, especially in the\
    \ last stage, where the general cloud \nmodel is used to obtain general information\
    \ about the target vessel. Latency is \nalso crucial to keep the target in the\
    \ centre of the vision field. \nLatency average is updated for edge and cloud\
    \ model with each new \nanalysis. This determines acceptable limits for latency\
    \ dynamically, considering \nparameters such as network quality and bandwidth\
    \ indirectly. \n \n \nFigure 4.42. Calculation of acceptable latency limits. Main\
    \ ASV camera point of \nview. \n= \U0001D443\U0001D45B − \U0001D443\U0001D45B\
    −1 \n(4.24) \n\U0001D447 = \U0001D447\U0001D45B − \U0001D447\U0001D45B−1 \n(4.25)\
    \ \n\U0001D445\U0001D446 = \U0001D437\U0001D435\U0001D436\U0001D436\n\U0001D447\
    \  \n(4.26) \n \nFigure 4.42 shows the difference of position between 2 consecutive\
    \ analysed \nimages. From each successfully analysed image, the bounding box of\
    \ the detected \nvessel, its relative coordinates in the image, as well as its\
    \ timestamp are obtained. \nBy knowing the distance between bounding box centres\
    \ (BBC) and the time \ndifference between analyses (T), the relative speed (RS)\
    \ at which the target moves \nin the image can be obtained. During the time lapse\
    \ between the analysis of 2 \nconsecutive images we can approximate the relative\
    \ speed of displacement of the \ntarget vessel and the ASV as a constant value,\
    \ due to the considerable inertia of \nvessels at sea. With this information,\
    \ it is calculated when the target BBC will \nleave the range of vision, and SAAO\
    \ can determine the selection of the preferred \nor alternative source of AI with\
    \ regard to latency. \n \n120 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nSeveral factors affect SAAO decisions, and they can be measured indirectly\
    \ \nthrough latency and accuracy. Low latency and high accuracy are always \n\
    desirable results, but every AI cloud or edge platform has its advantages and\
    \ \nhandicaps, and we cannot always achieve both simultaneously. Balance and \n\
    effective decision making are the keys to make a mission efficient and successful.\
    \ \n \n4. Experiments and Results  \n4.1. AI recognition and proposed algorithm\
    \ for autonomy optimization  \n \nFigure 4.43 shows an example of three different\
    \ cloud vision APIs analyzing \nthe same image, with different types of boats\
    \ in a port. All three cloud services \nmanaged to detect most of the boats in\
    \ the image. The bounding box location is \naccurate, although the cloud response\
    \ cannot exactly specify the type of each \nboat. Our objective is not only to\
    \ detect each boat in the image but also to group \nthem into more specific categories.\
    \ The general model offered by the cloud has \nits limits in this regard. \n \n\
    \ \nFigure 4.43. Comparison of three different clouds vision API detection of\
    \ boat in \nLos Nietos port (Murcia, Spain). \n4.1.1. Custom model training for\
    \ detection specific vessels \nThe advantage of the customized model is the possibility\
    \ of training it \naccording to the use case, in addition to detecting the location\
    \ of objects in the \nimage. Our model has been trained to identify different\
    \ types of vessels and their \nposition in an image. We created our own custom\
    \ object detection model to be \nimplemented in the proposed IoT gateway using\
    \ the Azure cloud service, as it \nsupports the edge computing technologies and\
    \ gives a better performance than \nthe other solutions [242]. More than 600 photos\
    \ of different types of vessels found \naround the inspection area in the experiment\
    \ have been used to train the custom \nmodel. The model has been trained to recognize\
    \ 7 different types of vessels \n(Figure 4.44). The position of each vessel in\
    \ the image was identified by drawing \na bounding box around the object and providing\
    \ the top and left pixel \ncoordinates of the box, along with the width and height\
    \ in pixels. \n \n \n121 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nFigure 4.44. Types and number of vessels used to train the vision custom models.\
    \ \nAzure can retrain our model in different ways, by quick training or advanced\
    \ \ntraining by specifying the training computation time. The more time and pictures\
    \ \nused train the model in the platform, the better the results and performance\
    \ will \nbe.  \nFigure 4.45 shows the detection testing of new photos not used\
    \ in the training \nphase. The cloud trained model was able to differentiate between\
    \ different types \nof boats, as for instance a man fishing in a kayak. The model\
    \ detected the \nsituation perfectly by the training photos. \n \nFigure 4.45.\
    \ Performance of the cloud custom model object detection in discerning \ndifferent\
    \ boats types. \n4.1.2. Cloud and Edge custom models. \nIn the proposed architecture,\
    \ we put forward the LattePanda IoT gateway \nrunning under Windows 10 LTSB OS,\
    \ where the trained edge model has been \ndeployed by using Microsoft Azure. Azure\
    \ offers the possibility of choosing \nbetween different object detection custom\
    \ model domains, namely General, \nLogo, Products on shelves and General Compact.\
    \ The General domain is trained \nto be used only in the cloud (Cloud Custom Model),\
    \ while the General Compact \ndomain is trained to be used in Edge devices (Edge\
    \ Custom Model). The model \nperformance varies by the selected domain; models\
    \ generated by General \nCompact domains can be exported to run locally, so they\
    \ are lightweight models \n \n122 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nand optimized for the constraints of real-time object detection on edge devices,\
    \ \nalthough they are less accurate than the General domain. \nFigure 4.46 shows\
    \ the training performance of 600 photos using the 7-hour \ntraining budget. The\
    \ edge and cloud models were trained with the same number \nof photos and training\
    \ budget. The figure 4.46 shows the difference between the \ntwo models after\
    \ the training. \n \nFigure 4.46. Performance differences between the Edge and\
    \ the cloud custom \nmodels. \nAs the models generated by the compact domains\
    \ are optimized for the constraints \nof real-time classification on edge and\
    \ mobile devices, they are slightly less accurate than \na standard domain with\
    \ the same amount of training data. Figure 4.47 clearly shows the \ndifference\
    \ between the custom model for cloud and edge uses, i.e. between the edge-\ntrained\
    \ model and the cloud-trained model. As can be seen, the distance from the object\
    \ \nto the ships' cameras affects the model’s percentage of accuracy. For instance,\
    \ as shown \nin case 3 in the figure 4.47, the cloud model was able to recognize\
    \ the vessel in the \ndistance accurately, while the edge model was not. \n \n\
    123 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.47. Cloud\
    \ and edge custom models for detecting new vessels. \n \n4.2. Latency assessment\
    \ in edge and cloud custom models \nPerforming powerful DNNs (Deep Neural Networks)\
    \ with real-time execution \nrequirements on edge devices is still a challenge,\
    \ regardless of the hardware \nacceleration and compression techniques deployed.\
    \ Considering offloading the \nDNN computation from local devices to more powerful\
    \ entities such as the cloud \nis a common scenario. Today, the cloud offers an\
    \ edge model for deployment on \ntiny devices, however, cloud models are also\
    \ needed to provide satisfactory \nperformance. Another important factor to consider\
    \ is that the cloud is known to \nfacilitate storage, computational complexity\
    \ and the energy load on the edge and \non local devices. Nevertheless, the cloud\
    \ servers are topologically and spatially \ndistant from the local stations, which\
    \ causes significant communication latency. \nReal-time inference is absolutely\
    \ required for many applications. For instance, \nframes from an autonomous vehicle’s\
    \ camera must be processed rapidly to \nidentify and evade obstacles, or a voice-based\
    \ solution must have a rapid analysis \nand understanding of the user's input\
    \ to provide a feedback. However, \ntransferring data to the cloud for inference\
    \ or training may result in more queues \nand delays in transmission from the\
    \ network and cannot meet the stringent \nrequirements of low end-to-end latency\
    \ required for real-time interactive \napplications. For example, experiments\
    \ have revealed that offloading a camera \nframe to Amazon Web Services and performing\
    \ a computer vision task requires \nmore than 200ms of end-to-end data [243].\
    \ \nIn this use case, Azure Custom Vision's used service works in Western \nEurope.\
    \ The experiments were carried out in the IoT gateway mentioned above \nby using\
    \ Python programming language. The results of the latency are \nsummarized in\
    \ Table 4.12, including: average latency, standard deviation, and \nthe minimum\
    \ and maximum values calculated for each model. The time that the \ncloud model\
    \ needs to send the photos to the cloud for processing and get the \n \n124 \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nresults back has been measured.\
    \ Given that the trained edge model is migrated \nas a TensorFlow lite program,\
    \ the photos are analyzed at the IoT gateway instead \nof being sent to the cloud.\
    \ The performance of the edge models varies with the \noperating platform; hence\
    \ the inference time may vary. All samples were \ncarefully and thoroughly checked\
    \ for the same data on the same day. The \nexperiment was repeated using the same\
    \ data for both cloud and edge models. \nEach experimental campaign had about\
    \ 300 different valid samples. \n \nTable 4.12. RTD test of 300 samples of the\
    \ Edge and Cloud model. \n \nMin \nlatency (s) \nMax \nlatency (s) \nAverage \
    \ \n(s) \nVariance  \n(s2) \nStandard \ndeviation \n(s) \nCloud \nModel \n0.805\
    \ \n5.298 \n1.412 \n0.872 \n0.934 \nEdge \nModel \n0.213 \n0.896 \n0.336 \n0.012\
    \ \n0.108 \n \nThe results reported in Table 12 show the latency differences between\
    \ edge \nand cloud models on the same machine. The average cloud model score is\
    \ higher \nthan the edge model by more than 1s. However, the variance of the edge\
    \ model \nis almost null compared to the cloud model, which is close to 900ms,\
    \ which \njustifies the edge model’s better stability in time than compared to\
    \ the cloud \nmodel. \nFigure 4.48 compares the experimental latency results of\
    \ both edge and cloud \nmodel. The edge model shows more stability and all values\
    \ do not exceed the 1s \nlatency. Cloud model can sometimes extend beyond 4s.\
    \ According to the cloud \nlatency results, they can be classified into two ranges.\
    \ The first extends for about \n1 and 2 seconds, while the second extends for\
    \ around 4 and 5 seconds. In \naddition, there is a band where no data has been\
    \ registered, between \napproximately 2.5 and 3.5 seconds. \n \n \n \n125 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nFigure 4.48. Latency of more\
    \ than 300 samples. \n \nThe cloud model’s apparent processing time instability\
    \ can be explained by \nthe internet connection volatility as the photos have\
    \ to be sent to the cloud model \non remote servers for processing, unlike the\
    \ edge model in which all photos are \nprocessed on board or at the local station.\
    \  \nThe cloud and edge models are different in terms of accuracy, even though\
    \ \nthey are trained on the same reference images. In contrast to latency, the\
    \ cloud \nmodel is more accurate, which eventually makes it challenging to choose\
    \ \nbetween both models. Real-time and high accuracy are both essential. However,\
    \ \nin an autonomous marine vehicle where computing power is limited and \nenvironmental\
    \ conditions are variable, low latency and high accuracy in every \nanalysis are\
    \ not guaranteed. The aim is to find an acceptable performance \ncompromise, considering\
    \ the evolution of the ongoing mission phases, as \ndescribed in detail in the\
    \ next section. \n4.3. Experimental test and results (SAAO Algorithm) \nIn order\
    \ to test the decision making of the SAAO algorithm, an experiment \nwas carried\
    \ out based on the analysis of a 1.5-hour video filmed in the Bay of \nCartagena.\
    \ The most interesting results were from a 2-minute sequence of a \nfishing boat,\
    \ whose results were analysed as described below. A 10-second \nextract of the\
    \ analysis is shown in this experiment. \nFor the experiment, this video was used\
    \ as the image source for the IoT \nGateway device, replacing the \"Cameras\"\
    \ block shown in Figure 438. The \ncaptures extracted by the IPM (Image processing\
    \ algorithm) were analysed in \nthree different scenarios. First, only an edge\
    \ computing analysis was carried out, \nrecording latency and accuracy results,\
    \ without the intervention of SAAO. The \nexperiment was then repeated with the\
    \ same images analysed using cloud \ncomputing. Finally, the SAAO algorithm was\
    \ tested in making decisions on the \nmost suitable AI source for the analysis\
    \ of the next image, based on the results \nobtained, and for each of the four\
    \ stages, as shown in Table 4.13 and Figure 4.49. \nTable 4.13. Experimental SAAO\
    \ results \nNº \nSampl\ne \nEdge \nCloud \nSAAO answer for next analysis \nLat\
    \ \n(s) \nAcc \n(%) \nLat \n(s) \nAcc \n(%) \nMM\nM \nFBM \nTM \nIM \n1 \n0.447\
    \ \nND \n1.412 \n16.7 \nCCM \nCCM \nCCM \nCGM \n2 \n0.418 \n64.3 \n1.814 \n68.7\
    \ \nCCM \nECM \nECM \nCGM \n3 \n0.324 \n19.5 \n2.816 \n50.5 \nECM \nECM \nECM\
    \ \nCGM \n4 \n0.356 \n47.9 \n1.313 \n65.8 \nCCM \nECM \nECM \nCGM \n5 \n0.403\
    \ \n23.1 \n4.211 \n33.8 \nECM \nECM \nECM \nECM \n6 \n0.392 \n36.8 \n1.284 \n\
    55.7 \nCCM \nECM \nECM \nECM \n \n126 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nND – Not detected \nCCM – Cloud custom model \nECM – Edge custom\
    \ model \nCGM – Cloud General Model \n \n \nFigure 4.49. Images analysed. Cloud/edge\
    \ results comparison \nAs can be seen in Figure 4.49, there is a difference between\
    \ the edge and cloud \nmodels when detecting the same image. Sometimes the difference\
    \ between the \ntwo percentages is not so significant, while in other cases there\
    \ is a notable \ndifference, especially when the boat is at a distance, which\
    \ sometimes \ncomplicates the detection by using the edge model as seen in the\
    \ example of \nPhoto 1, or the latency results were high, in cloud computing mostly.\
    \ These \nvalues condition the SAAO response, with different decision making in\
    \ each \nstage, according to the preferred or alternative AI source. Special attention\
    \ to \nImages 1 and 5, where the low accuracy in the edge model and the high latency\
    \ \nin the cloud model conditioned SAAO's decision for the alternative AI model.\
    \ In \nImage 6, the alternative AI model (according to Table 11) has also been\
    \ selected \nin IM (Stage 4), due to the risk of losing the bounding box’s centre\
    \ of the target \nin the range of vision. \n4.4 Experiment of BUSCAMOS-VIGIA with\
    \ SAAO \nAs mentioned in the Introduction, the complexity of autonomous \nsurveillance\
    \ varies significantly in different scenarios in the Spanish Network of \nMarine\
    \ Reserves. The Cabo de Palos and Islas Hormigas Marine Reserve [244] in \nthe\
    \ Region of Murcia (Figure 4.50) has medium complexity according to the \npreviously\
    \ defined criteria.  \n \n127 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nThis reserve covers an area of 18.98 km2 and is a zone with high biodiversity\
    \ \nand prairies of oceanic posidonia and rocky coralligenous beds, as well as\
    \ \nremarkable marine dynamics. This is a natural underwater area that contains\
    \ an \nintegral reserve in the surroundings of Hormiga Island, El Bajo, El Mosquito\
    \ and \nthe islets of El Hormigón and La Losa. \nThis marine reserve is very near\
    \ the Mar Menor, the largest saltwater lagoon \nin Europe, which was selected\
    \ as the scenario for the case study as the water there \nis usually calm, and\
    \ winds are light (Figure 4.50). \n \n \nFigure 4.50. Scale experiment. Equivalence\
    \ of area and distance from integral reserve \n(Islas Hormigas) to base station\
    \ (right) and equivalent area in Mar Menor (left) \n \nThe test exploration mission\
    \ was carried out to survey a marine space with a \nsurface and distance to the\
    \ base station equivalent to the Cabo de Palos and Islas \nHormigas Marine Reserve.\
    \ The objective was to detect, track and identify \nsuspicious vessels within\
    \ the area to validate the proposed architecture and the \nSAAO algorithm. The\
    \ defined inspection area has a radius of 915 m, with a \nsurface area of 2.63\
    \ km2 and a centre at coordinates 37.689634° N and 0.787109° \nW. To avoid detecting\
    \ vessels outside the test area due to the vision field, the area \ncovered by\
    \ the main mission was reduced by a radius of 100m, as shown in \nFigure 4.52.\
    \ The mission was planned on the IUNO platform.  \nThe recognition system was\
    \ tested in port before the mission through the \nmain bow camera to ensure that\
    \ both Azure cloud and edge AI sources worked \nas expected (Figure 4.51). A fishing\
    \ boat, a recreational boat and a sailing boat \nwere detected by the edge model,\
    \ and an extra sailing boat by the cloud model, \nwith better accuracy in all\
    \ detections.  \n \n \n \n128 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \nFigure 4.51: Edge (left) / cloud (right) trained model recognition tests.\
    \ \n \nThe ASV was remotely monitored and supervised from the fishing boat used\
    \ \nas the auxiliary vessel for safety reasons during the entire mission. The\
    \ auxiliary \nvessel was also used to verify the detection, recognition and tracking\
    \ capabilities \nimplemented, as explained below. The different systems (control,\
    \ lighting, \nthrusters, \ncommunications, \nvision, \netc \n(control, \nlighting,\
    \ \nthrusters, \ncommunications, vision, etc) were tested before the BUSCASMOS-VIGIA\
    \ \nmission. After successful validation, the mission was transferred from IUNO\
    \ to \nthe ASV and launched and the vehicle headed for the starting point. Surveillance\
    \ \nof the area began following the previously defined route (Figure 4.52). From\
    \ the \nfirst point of the mission to the fifth sweep in the Main Mission Mode\
    \ (MMM) no \nincidents or detections occurred.   \n \n \nFigure 4.52. Start of\
    \ mission (MMM) of surveillance of area equivalent to integral \nreserve. \n \n\
    \ \n129 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nThe technical team\
    \ on board the fishing boat remained at a specific point in \nthe fifth sweep\
    \ to study the ASV’s behaviour. The fishing boat was detected by \nBUSCAMOS-VIGIA\
    \ (Figure 4.53-a) and classified as a possible risk. According to \nSAAO logs\
    \ during this stage all image analysis was performed by the cloud-\ntrained model\
    \ except for one case in which the edge-trained model was used due \nto high latency.\
    \ The target vessel’s behaviour was studied to determine if it was \nstationary,\
    \ according to the rules defined Stage 2, Fixed Buoy Mode (FBM). The \nregisters\
    \ showed that only the edge model was used. The bounding boxes of all \nthe analyzed\
    \ images were determined as the accuracy was high enough at this \nstage. After\
    \ the FBM stage, when the results determined that the target vessel \nwas stationary,\
    \ the Tracking Mode (TM) stage began. The technical team on \nboard the target\
    \ vessel then started the motors to verify the tracking capabilities \n(Figure\
    \ 4.53-b). \n \n \n \n                         (a)                           \
    \                                                (b) \nFigure 4.53. (a) Stopped\
    \ vessel detected. Start TM mode. (b) Tracking Mode (TM) test \nduring the experiment.\
    \  \n \nThe ASV successfully reached the target. As in FBM, only the edge model\
    \ \nwas used by the SAAO during all the TM. The vehicle stopped over 15m away\
    \ \nand changed to Inspection Mode (IM), the last mission stage. \nThe results\
    \ obtained from the Azure Cloud AI General Model on additional \ninformation about\
    \ the target vessel were as follows: the three people on board \nwere detected.\
    \ The automatically generated sentences “a group of people on a boat” \nand “a\
    \ group of people riding on the back of a boat in the water” by the cloud general\
    \ \nmodel were useful for obtaining details of the target vessel without the need\
    \ to \nview cameras in real time and without human intervention. At this stage,\
    \ the \nrecords show that the SAAO used both the cloud general model and the edge-\n\
    trained model. The cloud results were not fast enough to determine the target\
    \ \nvessel’s bounding box in some cases. Table 4.14 shows a summary of the SAAO\
    \ \nlogs during the experiment: \n \nTable 4.14. Summary of SAAO logs during the\
    \ experiment \n \n130 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    Stage \nEdge (custom model) \nCloud (custom and general \nmodel) \nSAAO answers\
    \  \nAv. \nLat \n(s) \nAv.  \nAcc \n(%) \nNº \nuses \nDetect\n-ions \nAv. \nLat\
    \ \n(s) \nAv.  \nAcc \n(%) \nNº \nuses \nDetections \nUse of the preferred \n\
    AI source (%) \nMMM \n0.22\n0 \n21 \n1 \n1 \n1.52\n1 \n34 \n2414 \n1 \n99.95 \n\
    FBM \n0.20\n5 \n31 \n58 \n58 \n- \n- \n0 \n- \n100.00 \nTM \n0.23\n1 \n39 \n436\
    \ \n436 \n- \n- \n0 \n- \n100.00 \nIM \n0.21\n8 \n57 \n29 \n27 \n1.58\n9 \n68\
    \ \n92 \n88 \n76.03 \n \nWhen the fishing boat left the area, BUSCAMOS-VIGIA ended\
    \ the IM stage \nand continued with the planned mission (in MMM) until the eighth\
    \ sweep was \ncompleted. The vessel was then commanded to return to port and no\
    \ further \nincidents were registered during the rest of the mission. \n \n \n\
    \ \nIV. An IoT Control System for Wind Power Generators \n \n1. Introduction \
    \  \n \nAs an important source of energy in different countries, renewable energy\
    \ is \nwidely used today, renewable electricity generation in 2018 was 6.1% higher\
    \ than \nin 2017, representing about 16% of global power generation, as reported\
    \ in \nIRENA (2017) [245]. This percentage is expected to double in the next 15\
    \ years \nand 65% of energy use could come from renewable resources by 2050. Wind\
    \ and \nsolar energy production in 2018 increased by 11% and 28%, respectively.\
    \ \nAltogether, these two sources of energy remain dominant in the growth of \n\
    renewable generation, accounting for 73% of growth since 2014 [245]. \nPresent\
    \ machines used for manufacturing already support digital or analog \nsensing\
    \ connected to a central control station to be monitored via a wired \nEthernet\
    \ system [246]. These systems, nevertheless, are not usually connected to \nthe\
    \ Internet [247]. This is the era that meets the important evolution of the \n\
    industry and the Internet. In order to be able to follow this important evolution\
    \ \nof wind energy, it is necessary to enforce the capacity of the Internet to\
    \ assess all \n \n131 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    data collected from the different industrial elements, sensors, actuators, motors,\
    \ \netc. \nA \nvariety \nof \nadvanced \ntechnologies \nsuch \nas \nintelligent\
    \ \nrobots, \ncommunication systems (e.g., 5G), and the Internet of Things (IoT)\
    \ are expected \nto enhance the fourth industrial revolution [248]. IoT connects\
    \ a number of \npeople, devices, processes, and data, enabling them to communicate\
    \ with each \nother seamlessly. IoT can therefore help improve different processes\
    \ to make \nthem more measurable and quantifiable by gathering and processing\
    \ large \namounts of data [249]. IoT can potentially improve the quality of life\
    \ in different \nareas. In the energy sector, IoT can be deployed to increase\
    \ energy efficiency, \nexpand the share of renewable energy, limit the environmental\
    \ impacts of energy \nuse [250], and to have a clear vision of the entire system,\
    \ in real-time, without the \nnecessity of physically being in the area of the\
    \ installation. This will consequently \nreduce waiting times and decrease unnecessary\
    \ costs.  \nThe idea of the IoT is to treat each object as a thing, the renewable\
    \ energy \nresource is considered an object and is assigned a unique IP address,\
    \ where all \ndata gathered by sensors and actuators can be measured, analyzed\
    \ and managed, \nthrough the cloud-based platforms. The communication protocols\
    \ of the IoT \nplatform allow the different devices to communicate and share their\
    \ data with \nthe controllers or decision centers. The IoT platforms offer the\
    \ flexibility to select \nthe type of communication technologies according to\
    \ the needs of the \napplication. Each of these communication technologies has\
    \ specific features and \ncan be carried out through wired and wireless networks,\
    \ including, but not \nlimited to, RS485, Wi-Fi, Bluetooth, ZigBee [251] and cellular\
    \ technology such as \nLTE-4G and 5G networks [252]. The IoT is considered one\
    \ of the complex \nsystems, and this complexity is due to the interactions in\
    \ the environment, an \ninterconnection of the IoT components and the number of\
    \ networks and \nprotocols that are involved. The IoT gateway is the component\
    \ that allows these \ndifferent networks to communicate [253]. \nThe data analysis\
    \ is performed for decision making about the functioning of \nthe application.\
    \ As needed, data analysis can be accomplished offline or in real \ntime. When\
    \ analyzing off-line, the stored data is first collected and then \nvisualized\
    \ on site using visualization tools installed in the IoT gateway or in a \nbase\
    \ station). However, In the case of real-time analysis, cloud or edge servers\
    \ \nare used to perform the visualization, e.g. stream analysis [254].  \nThe\
    \ rest of this chapter is organized as follows. We present a study of related\
    \ \nwork in the field of IoT solutions in the renewable energy sector. We then\
    \ \nintroduce the system model and the different protocols and applications used\
    \ to \nconnect the wind energy control system to the cloud. Following, we describe\
    \ the \nproposed hardware and software used to connect the system to the cloud.\
    \   \nFinally, the possibilities that can be done using the data transmitted offline\
    \ at the \nIoT gateway and in real time in the cloud. \n \n \n132 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n2. Modelling System Architecture \n \n\
    Within a wind energy system, a wind turbine converts wind energy into \nelectrical\
    \ energy. First it consists of a rotor, that transforms the aerodynamic \nthrust\
    \ into rotation movement, second a Multiplier, that adapts the rotation \nspeed\
    \ to the speed of the generator, then also an Alternator, that transforms the\
    \ \nrotation energy into electrical energy, and finally a Dump to the grid, that\
    \ injects \nenergy into the electrical network. \nThe wind energy system consists\
    \ of sensors, motors and actuators to be \nmonitored and controlled continuously.\
    \ The system must guarantee a safe and \nreliable operation, monitor the components\
    \ and variables, verify that the \nvariables are in an allowable range and must\
    \ perform fault detection and \nprediction. In a wind turbine, a yaw-guiding motor\
    \ turns the nacelle to face the \nwind, and the movement of the motor depends\
    \ on data from wind direction \nsensors. In fact, predictive analysis will alert\
    \ operators in advance if a component \nneeds to be repaired or inspected.  \n\
    New technologies such as IoT, machine learning, cloud, large data can \nfacilitate\
    \ better use of resources and help harness clean energy along with \noptimization.\
    \ IoT has an important impact on the energy sector, especially wind \nenergy,\
    \ given that this technology is applied to inaccessible environments and \nremote\
    \ areas. \nThe general architecture of an IoT system is composed mainly of three\
    \ parts, \nthe first one is the data generation and control system where it is\
    \ connected to \nthe devices and sensors, secondly it is the IoT gateway where\
    \ the main programs \nand protocols are installed to communicate the received\
    \ data, and finally, the \ncloud service, which reports all the data coming from\
    \ the wind energy system \nthrough the IoT gateway.  \n \n \n133 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \nFigure 4.54 : Wind energy IoT communication\
    \ architecture \n \nIn this proposal we present two of the most important sensors\
    \ used in a wind \nenergy system, which are the wind energy direction sensor (Anemometer)\
    \ and \nthe wind speed sensor (Vane). Also proposed in this architecture, the\
    \ Siemens \ntechnology, using two types of PLCs: the PLC 1214 and the PLC 1512\
    \ and an \nindustrial gateway IoT2040 which is the first in the Siemens market\
    \ and can \nexecute different tasks, as handling the data received from the PLCs\
    \ before \nsending it to the cloud or to other machines and systems.  \n \n \n\
    Figure 4.55. Hardware Setup \n \n \n134 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nThe connected sensors are directly connected to the Siemens PLC 1214\
    \ to \nmonitor the wind status and send a command to the engine generator to change\
    \ \nthe direction of the blades in order to maximize the use of the system. \n\
    Furthermore, it permits the operation to be shut down in the event of a strong\
    \ \nwind flow. In parallel, power quality can be monitored and displayed using\
    \ the \nSENTRON PAC (3200), which delivers the important data for evaluating the\
    \ \nquality of an electrical network. All information received in the sensors\
    \ PLC 1214 \nis transmitted to the PLC 1512 using the industrial communication\
    \ standard \nPROFINET via Ethernet. \nThis solution allows to connect a legacy\
    \ network, presented by the old PLC \n1214 by using another powerful PLC 1512\
    \ with more capabilities to connect to \nanother network, which speaks more communication\
    \ protocols. The OPC \nUnified Architecture (UA) is an independent service-oriented\
    \ architecture that \nintegrates all the functionality of the individual OPC Classic\
    \ specifications into \nan extensible framework [255]. OPC UA is also a machine-to-machine\
    \ \ncommunication protocol, developed to create a reliable, secure, and interoperable\
    \ \ncommunication protocol. OPC-UA uses a client-server architecture, the servers\
    \ \nare applications that present information following the OPC-UA information\
    \ \nmodel, and the clients are applications that retrieve information from the\
    \ servers \nby reading and browsing the information model. In each server is defined\
    \ an \naddress space containing nodes of the OPC-UA model, these nodes represent\
    \ \nphysical objects or software [256]. the Siemens PLC 1512 comes with an OPC\
    \ UA \nserver implemented, which permits the communication with OPC UA clients\
    \ \nsuch as HMI panels, SCADA systems, etc. The OPC UA client is implemented in\
    \ \nthis application in the Siemens IOT2040 gateway, through the application Node-\n\
    RED that has a sample set of nodes that can be used for the communication \nbetween\
    \ different protocols and platforms. It is a programming tool for wiring \ntogether\
    \ hardware devices, APIs and online services, it is a solution to control \nflows\
    \ to be designed and managed graphically [257]. Figure 4.56 shows the setup \n\
    application and the different components from the wind sensors to the cloud \n\
    platform. \n \n \nFigure 4.56. Data flow between different systems and across\
    \ different protocols. \n \n \n \n135 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nThe OPC UA client implemented in the UAExpert software can \ncommunicates\
    \ with the OPC UA server in the Siemens PLC, its role is to check \nand read all\
    \ the information related to the communication with the PLC, so as to \nshow the\
    \ information model of the UA server, such as labels, blocks, etc (Figure \n4.57).\
    \ This application needs to control the two variables of the speed sensor and\
    \ \nthe orientation sensor. UaExpert can read the NodeID of each variable, which\
    \ is \nthe most important ID used in Node-RED in order to be connected to the\
    \ PLC \nOPC UA server. \n \n \nFigure 4.57 . Checking OPC UA connection using\
    \ UaExpert Software \n \nWe implemented mainly four different nodes for each sensor,\
    \ in order to read \nthe data information from the PLC 1512 and then forward it\
    \ to the cloud for \nvisualization (Figure 4.58). In the first blue node (Inject\
    \ Node) we have \nintroduced the topic, used to connect with the variable Orientation\
    \ in the PLC, \nthis topic is also called Node-ID that can be taken from the software\
    \ UaExpert. \nWe then connected the Inject Node to the OPC UA Client Node that\
    \ has the \naddress of the PLC server to which we want to connect, and finally\
    \ we linked the \nIBM Watson IoT Node that has all the information about our variables\
    \ created in \nour IBM Bluemix cloud account. \n \n \n136 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \nFigure 4.58. Communication between the PLC 1512 and\
    \ IBM Cloud \nthrough OPC UA protocol using Node-RED installed the industrial\
    \ \nGateway IOT2040. \n \nC. Discussion and Results \n \n \nFigure 4.59. Dashboard\
    \ Data of wind Sensors in the IoT2040 Gateway \n \nAfter having all the information\
    \ about our sensors in the IoT2040 gateway \n(Figure 4.59), we have created an\
    \ account in IBM Bluemix, then we created a \ndevice in this account, which is\
    \ the IoT2040 gateway in order to connect it to the \nIBM Watson node in Node-RED.\
    \ IBM allows to create different boards, and for \neach board it is possible to\
    \ create cards that present your data and each data is a \nrepresentation for\
    \ your devices, sensors, actuators, or other. In the IBM Watson \nIoT Platform,\
    \ we created the board Wind-Energy, in order to present in a real-\ntime the two\
    \ wind sensors (Figure 4.60). \n \n \n137 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 4.60 : Dashboard data wind sensors in the IBM Watson Platform\
    \ \n \n \n \n \n138 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nCHAPTER\
    \ 5 \n \n-------------------------------------------------- \n \nConclusions and\
    \ Future Work \n \n \n \nThe lack of interoperability between Internet of Things\
    \ (IoT) devices \nsignificantly increases the complexity and cost of implementing\
    \ IoT and \nintegrating it into existing industrial systems and autonomous robots.\
    \ The quest \nfor seamless interoperability is further complicated by the long\
    \ lifespan of typical \nindustrial equipment, which requires costly upgrades or\
    \ replacements to support \nthe latest technologies. Integrating new and old technologies\
    \ into the IoT \npresents an interoperability challenge, as each IoT system has\
    \ its own \ncommunication protocol. In addition, a small error or delay beyond\
    \ the tolerated \nlimit could result in a disaster for various applications. IoT\
    \ gateways provide an \neffective solution for data communication, security and\
    \ manageability, and serve \nas a bridge between sensor networks and cloud services.\
    \ While the \nenvironmental specifications of each IoT gateway are crucial when\
    \ it comes to \napplications that require efficient computing performance. Cloud\
    \ services can \nhandle many cases efficiently, although latency is a major challenge\
    \ due to the \ninteraction between different systems. Unmanned vehicles (UVs)\
    \ now have great \npotential for many applications. At every stage of many surveillance\
    \ and tracking \nmissions using UVs, priority must be given to either accuracy\
    \ or latency. \nHowever, in some scenarios, stability of measurements and results\
    \ is difficult to \nensure, and certainty is far from guaranteed. Edge computing\
    \ topology reduces \nlatency to support IoT performance in low-bandwidth environments\
    \ and \nmitigates overall network congestion. Cloud computing topology improves\
    \ \naccuracy at the expense of increased latency. This proved crucial in deciding\
    \ the \nbest source of artificial intelligence to use to achieve the specified\
    \ goals at each \nstage in real time. \nAzure Custom Vision, Google cloud, and\
    \ IBM Watson services allow users \nto load a set of images and train them into\
    \ a custom AI model. However, to date, \n \n139 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \njust some of the cloud services allow trained AI models\
    \ to be exported in different \nformats (TensorFlow, Docker) specifically tailored\
    \ for devices, as opposed to the \ncloud. The model trained for use in the cloud\
    \ is different from the one trained for \nthe edge in terms of accuracy and response\
    \ time.  \nThe main contributions of this thesis are summarized in this chapter,\
    \ and the \neminent obtained results are discussed. Then, we emphasize the most\
    \ research \nlines that this thesis opens and can be considered as the future\
    \ works of the work \ndescribed in this report.  \n \n1. Contributions’ summary\
    \ \n \nThe main contributions of this thesis and the eminent results obtained\
    \ are \nsummarized. We highlight the most important research directions that this\
    \ thesis \nopens and that can be considered as future work of the work described\
    \ in this \nreport.  \nIn this thesis, different contributions are proposed to\
    \ address the issues of \nsupervision, interoperability, latency and detection\
    \ accuracy for object tracking.  \nThese contributions can be grouped into four\
    \ main axes. The first one, an \ninteroperable architecture and reliable real-time\
    \ communication have been \nproposed to improve the production process of a concrete\
    \ plant. In the second, \nan AUV model system designed to track a Mediterranean\
    \ fan mussel species, \nusing cloud services with edge computing as alternative\
    \ processing units. In the \nthird line, we propose an intelligent algorithm to\
    \ optimize the autonomy of an \nautonomous marine robot by selecting the appropriate\
    \ AI technology for \nprotection and continuous monitoring in marine protected\
    \ areas. Finally, In the \nfourth, the line focuses on proposing an IoT solution\
    \ to supervise in real time a \nwind system in the cloud. \nIn the first part\
    \ of this thesis, we have introduced a model designed to \nmonitor the smart industrial\
    \ Internet of things based on an unmanned aerial \nvehicle, leveraging cloud computing\
    \ services and using fog computing as a \nbridge between the different IIoT layers.\
    \  \n \n• The proposed model can monitor the condition of a concrete plant \n\
    production line and the condition of the materials transported on \nconveyor belts\
    \ to control the process.  \n• The results reveal the effectiveness of integrating\
    \ drones with deep \nlearning cloud services for processing and analyzing photos\
    \ acquired in \nreal-time.  \n• We demonstrate how to overcome the challenge of\
    \ interoperability using \nfog and Node-RED computation on the IoT gateway.  \n\
    • Node-RED interacts simultaneously with the different systems involved \nthrough\
    \ different protocols. \n \n140 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n• The period of time available to the control system to decide and adjust\
    \ the \nformula is assessed and estimated, depending on the quantity ordered by\
    \ \nthe customer and the composition of the formula. Given these points, the \n\
    overall latency of the proposed solution is acceptable for plant control \ndecisions.\
    \ \n• The Siemens IoT gateway S-G is expected to provide better performance \n\
    in an industrial setting, although it has less capacity than Raspberry \ngateway\
    \ RPI-G.  \n• The second work outlines an AUV model system designed to track a\
    \ \nMediterranean fan mussel species, using cloud services with edge \ncomputing\
    \ as alternative processing units. \n• An innovative algorithm was proposed to\
    \ autonomously track the target \nspecies without human intervention by integrating\
    \ the object detection \nsystem into the AUV control loop. \n• The proposed model\
    \ is capable of detecting, tracking and georeferencing \nspecimens with IUNO software.\
    \ \n• The obtained results highlight the system’s effectiveness and feature the\
    \ \nasset of combining an AUV with deep learning cloud services for \nprocessing\
    \ and analyzing photos.  \n• Although cloud-based architecture automatically distributes\
    \ and balances \nprocessing loads, we overcame latency challenges in the tracking\
    \ process \nby using edge computing in the IoT gateway.  \n• The IoT gateway installed\
    \ in the AUV replaces the cloud processing unit \nby virtue of the interaction\
    \ between the different AUV components. We \nintegrated cloud-based ML services\
    \ into the AUV system to achieve a \ncompletely autonomous pre-programmed search\
    \ mission with relevant \naccuracy.  \n• Furthermore, with the aim of ensuring\
    \ that data is transferred, processed \nand returned at speeds that meet the needs\
    \ of the application, the two \nobject detection services were implemented in\
    \ the cloud and compared in \nterms of latency and accuracy.  \n• The obtained\
    \ experimental results clearly justify the proposed hybrid \ncloud/edge architecture\
    \ and highlight the combination of the system \nperformances that ensure a real-time\
    \ control loop for relevant latency and \naccuracy. \n• Addressing system requirements,\
    \ lower latency and improved cloud \naccuracy, our solution on AUV servo control\
    \ ensures a balance between \nperformance and stability. The hybrid cloud/edge\
    \ architecture is therefore \nrecommended to ensure a real-time control loop and\
    \ achieve consistent \nresults.  \n \n \n141 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nIn the third part, we have presented an autonomous marine robot for\
    \ \ncontinuous protection and surveillance of marine protected areas based on\
    \ AI \nrecognition.  \n \n• The robot was designed to survey and inspect marine\
    \ reserves using AI-\nbased image recognition services, looking for vessels conducting\
    \ \nsuspicious activities. \n• Azure cloud computing and Azure edge computing\
    \ services were used \nfor image analysis, each with their own advantages and\
    \ disadvantages, \nmainly related to accuracy and latency.  \n• To meet the system\
    \ requirements, we proposed and developed an \nintelligent algorithm to optimize\
    \ the autonomy by selecting the \nappropriate AI technology for the monitored\
    \ scenario.  \n• The proposed intelligent algorithm (SAAO) provides a trade-off\
    \ between \nlatency and accuracy. \n \nIn the fourth part of this thesis, we have\
    \ performed a control system using a \nsmart IoT gateway to create a connection\
    \ between an industrial case and the \ncloud.  \n \n• We have provided a solution\
    \ for a wind energy system in order to \nvisualize in a real-time and remotely\
    \ the different components and devices \ninside a wind turbine control system.\
    \  \n• We proposed, the IOT2040 gateway from Siemens, and we have installed, \n\
    several tools that helped us connect our device’s information.  \n• It is simple\
    \ to connect each sensor information of the wind turbine to the \ncloud by using\
    \ the tool Node-RED, and through different communication \nprotocols like OPC\
    \ UA. This solution can really ease the control system of \nwind energy, by collecting,\
    \ saving and communicating relevant data in \nreal-time.  \n• With the help of\
    \ an IoT gateway, analyzed data can be transferred from \nthe cloud to the control\
    \ system and to the devices. \n \n2. Future Works  \n \nThe research conducted\
    \ in this thesis can be extended in future work. Below \nwe present most of the\
    \ possible future contributions: \n \n• Introducing new devices into drones, so\
    \ that they can not only track \nobjects but also interact with them. \n• Introducing\
    \ swarm of drones connected as IOT-drone device and \ncoordinated to perform swarm\
    \ operations. \n \n142 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    • New technologies can be implemented in drones to track and catch \ndetected\
    \ objects. \n• More research is needed in terms of accuracy when tracking a moving\
    \ \nobject. \n \n \n \n \n143 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \nReferences \n \n \n \n1- \nG. Miragliotta, A. Perego, and A. Tumino, “Internet\
    \ of Things: Smart Present or Smart Future?” \nItaly, 2012.  \n2- \nStatista.\
    \ IoT: Number of Connected Devices Worldwide 2012–2025; Statista: Hamburg, Germany,\
    \ \n2019. \n3- \nH. Kagermann, W. Wahlster, and J. Helbig, “Recommendations for\
    \ implementing the strategic \ninitiative INDUSTRIE 4.0,” 2013. \n4- \n25. A.\
    \ Azevedo and A. Almeida, “Factory Templates for Digital Factories Framework,”\
    \ Robot. \nComput. Integr. Manuf., vol. 27, no. 4, pp. 755–771, Aug. 2011. \n\
    5- \n46. \nT. Hafeez, L. Xu and G. Mcardle, \"Edge Intelligence for Data Handling\
    \ and Predictive \nMaintenance \nin \nIIOT,\" \nin \nIEEE \nAccess, \nvol. \n\
    9, \npp. \n49355-49371, \n2021, \ndoi: \n10.1109/ACCESS.2021.3069137. \n6- \n\
    Molina-Molina, J.C.; Salhaoui, M.; Guerrero-González, A.; Arioua, M. Autonomous\
    \ Marine Robot \nBased on AI Recognition for Permanent Surveillance in Marine\
    \ Protected Areas. Sensors 2021, 21, \n2664. https://doi.org/10.3390/s21082664\
    \ \n7- \nZhou, Z.; Chen, X.; Li, E.; Zeng, L.; Luo, K.; Zhang, J. Edge Intelligence:\
    \ Paving the Last Mile of \nArtificial Intelligence with Edge Computing. Proc.\
    \ IEEE 2019, 107.  \n8- \nSikeridis, D.; Papapanagiotou, I.; Rimal, B.P.; Devetsikiotis,\
    \ M. A Comparative Taxonomy and Survey \nof Public Cloud Infrastructure Vendors.\
    \ arXiv 2018, arXiv:1710.01476v2. \n9- \nY. Zhong, Xun Xu, Eberhard Klotz, Stephen\
    \ T. Newman. Intelligent Manufacturing in the Context \nof Industry 4.0: A Review.\
    \ Elservier, https://doi.org/10.1016/J.ENG.2017.05.015 \n10- \nK. \nKritayakirana\
    \ \nand \nJ. \nC. \nGerdes, “Autonomous \nvehicle \ncontrol \natthe \nlimits \n\
    of \nhandling,”International Journal of Vehicle AutonomousSystems, vol. 10, no.\
    \ 4, pp. 271–296, 2012. \n11- \nS. E.Collier, “The emerging enernet: Convergence\
    \ of the smart grid with the internet of things”, \nIEEE Industry Applications\
    \ Magazine, 23(2), 12-16, 2016. \n12- \nCarvalho O., Garcia M., Roloff E., Carreño\
    \ E.D., Navaux P.O.A. (2018) IoT Workload Distribution \nImpact Between Edge and\
    \ Cloud Computing in a Smart Grid Application. In: Mocskos E., \nNesmachnow S.\
    \ (eds) High Performance Computing. CARLA 2017. Communications in Computer \n\
    and Information Science, vol 796. Springer, Cham. https://doi.org/10.1007/978-3-319-73353-1_14\
    \ \n13- \nS. Marstijepovic and S. Williams, \"Environmental monitoring and field\
    \ surveillance reference \nguide.pdf\". \n14- \nXu, G.; Shi, Y.; Sun, X.; Shen,\
    \ W. Internet of Things in Marine Environment Monitoring: A Review. \nSensors\
    \ 2019, 19, 1711. https://doi.org/10.3390/s19071711 \n15- \nC. Perera, A. Zaslavsky,\
    \ P. Christen, & D. Georgakopoulos, “Sensing as a service model for smart \ncities\
    \ supported by internet of things”, Transactions on Emerging Telecommunications\
    \ \nTechnologies, 25(1), 81-93, 2014. \n16- \nAkhtar, M.N.; Shaikh, A.J.; Khan,\
    \ A.; Awais, H.; Bakar, E.A.; Othman, A.R. Smart Sensing with Edge \nComputing\
    \ in Precision Agriculture for Soil Assessment and Heavy Metal Monitoring: A Review.\
    \ \nAgriculture 2021, 11, 475. https://doi.org/10.3390/agriculture11060475 \n\
    17- \nL. R. Stojkoska, &K. V. Trivodaliev, “A review of Internet of Things for\
    \ smart home: Challenges and \nsolutions”, Journal of Cleaner Production, 140,\
    \ 1454-1464, 2017. \n18- \nR. Sfar, E. Natalizio, Y. Challal, &Z. Chtourou, “A\
    \ roadmap for security challenges in the Internet of \nThings”, Digital Communications\
    \ and Networks, 118-137, 2018. \n19- \nM. Soliman, T. Abiodun, T. Hamouda, J.\
    \ Zhou, & C. H. Lung, “Smart home: Integrating internet of \nthings with web services\
    \ and cloud computing”, In Cloud Computing Technology and Science \n(CloudCom),\
    \ 2013 IEEE 5th International Conference on (Vol. 2, pp. 317-320). 2013. \n \n\
    144 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n20- \nD. Miorandi,\
    \ S. Sicari, F. De Pellegrini, & I. Chlamtac, “Internet of things: Vision, applications\
    \ and \nresearch challenges”, Ad Hoc Networks, 10(7), 1497-1516, 2012. \n21- \n\
    F. Firouzi, A. M. Rahmani, K. Mankodiya, M. Badaroglu, G. V. Merrett, P. Wong,\
    \ & B. Farahani, \n“Internet-of-Things and big data for smarter healthcare: from\
    \ device to architecture, applications \nand analytics”, 2018. \n22- \nS. K.Dash,\
    \ J. P. Sahoo, S. Mohapatra, & S. P. Patil,“Sensor-cloud: assimilation of wireless\
    \ sensor \nnetwork and the cloud”, Advances in Computer Science and Information\
    \ Technology. Networks \nand Communications, 455-464, 2012. \n23- \nL. Atzori,\
    \ A. Iera, and G. Morabito, “The Internet of Things: A survey,” Comput. Netw.,\
    \ vol. 54, no. \n15, pp. 2787–2805, Oct. 2010. \n24- \nM. Kavre, A. Gadekar and\
    \ Y. Gadhade, \"Internet of Things (IoT): A Survey,\" 2019 IEEE Pune Section \n\
    International Conference (PuneCon), 2019, pp. 1-6, doi: 10.1109/PuneCon46936.2019.9105831.\
    \ \n25- \nEdge Computing Task Group.Introduction to Edge Computing in IIoT.Accessed:\
    \ Aug. 2, 2021. \n[Online]. \nAvailable: \nhttps://www.iiconsortium.org/pdf/Introduction_to_Edge_Computing_in_IIoT%_2018-06-18.pdf\
    \ \n26- \nLi, L. Lyu, X. Liu, X. Zhang, and X. Lyu, ‘‘FLEAM: A federated learn-ing\
    \ empowered architecture to \nmitigate \nDDoS \nin \nindustrial \nIoT,’’ \n2020,\
    \ \narXiv:2012.06150. \n[Online]. \nAvailable: \nhttp://arxiv.org/abs/2012.06150\
    \ \n27- \nDong, G. Qin, and H. Tian, ‘‘Enhancing data monitoring scheme based\
    \ on reinforcement learning \nin IIoT systems,’’ inProc. 12th Int. Conf.Commun.\
    \ Softw. Netw. (ICCSN), Jun. 2020, pp. 69–72. \n28- \nF. Wang, M. Zhang, X. Wang,\
    \ X. Ma, and J. Liu, ‘‘Deep learning for edgecomputing applications: A \nstate-of-the-art\
    \ survey,’’IEEE Access, vol. 8, pp. 58322–58336, 2020 \n29- \nChen, J. Wan, Y.\
    \ Lan, M. Imran, D. Li, and N. Guizani, ‘‘Improvingcognitive ability of edge intelligent\
    \ \nIIoT through machine learning,’’IEEE Netw., vol. 33, no. 5, pp. 61–67, Sep.\
    \ 2019. \n30- \nI. Yaqoob, E. Ahmed, I. A. T. Hashem, A. I. A. Ahmed, A. Gani,\
    \ M. Imran & M. Guizani, “Internet of \nthings architecture: Recent advances,\
    \ taxonomy, requirements, and open challenges”, IEEE \nwireless communications,\
    \ 24(3), 10-16, 2017. \n31- \nM. Diaz, C. Martín, & B. Rubio, “State-of-the-art,\
    \ challenges, and open issues in the integration of \nInternet of things and cloud\
    \ computing”, Journal of Network and Computer Applications, 67, 99-\n117, 2016.\
    \ \n32- \nL. R. Stojkoska, &K. V. Trivodaliev, “A review of Internet of Things\
    \ for smart home: Challenges and \nsolutions”, Journal of Cleaner Production,\
    \ 140, 1454-1464, 2017. \n33- \nLa, Quang Duy. Ngo, Mao V. Dinh, Thinh Quang.\
    \ Quek, Tony Q.S. Shin, Hyundong. Enabling \nintelligence in fog computing to\
    \ achieve energy and latency reduction. Digital Communications \nand Networks.\
    \ https://doi.org/10.1016/j.dcan.2018.10.008 \n34- \nDong, G. Qin, and H. Tian,\
    \ ‘‘Enhancing data monitoring scheme based on reinforcement learning \nin IIoT\
    \ systems,’’ in Proc. 12th Int. Conf.Commun. Softw. Netw. (ICCSN), Jun. 2020,\
    \ pp. 69–72. \n35- \nD. Xu and L. Duan, ‘‘Big data for cyber physical systems\
    \ in indus-try 4.0: A survey,’’Enterprise Inf. \nSyst., vol. 13, no. 2, pp. 148–169,\
    \ Feb. 2019. \n36- \nS. E.Collier, “The emerging enernet: Convergence of the smart\
    \ grid with the internet of things”, \nIEEE Industry Applications Magazine, 23(2),\
    \ 12-16, 2016. \n37- \nA. C. Panchal, V. M. Khadse and P. N. Mahalle, \"Security\
    \ Issues in IIoT: A Comprehensive Survey of \nAttacks on IIoT and Its Countermeasures,\"\
    \ 2018 IEEE Global Conference on Wireless Computing \nand Networking (GCWCN),\
    \ 2018, pp. 124-130, doi: 10.1109/GCWCN.2018.8668630. \n38- \nE. Sisinni, A. Saifullah,\
    \ S. Han, U. Jennehag, and M. Gidlund,“Industrial Internet of Things: \nChallenges,\
    \ opportunities, and direc-tions,”IEEE Trans. Ind. Informat., vol. 14, no. 11,\
    \ pp. 4724–\n4734,Nov. 2018. \n39- \nN. L. Tsilias, “Open Innovation and Interoperability,”\
    \ inOpening standards: The global politics of \ninteroperability,L. DeNardis,\
    \ Ed. Cambridge, MA, USA: MIT Press, 2011,pp. 97–117. \n40- \nFerrari, P.; Flammini,\
    \ A.; Rinaldi, S.; Sisinni, E.; Malara, D.M.M. Impact of Quality of Service on\
    \ Cloud \nBased Industrial IoT Applications with OPC UA. Electronics 2018, 7,\
    \ 109. \n41- \nForsstrom, S.; Jennehag, U. A performance and cost evaluation of\
    \ combining OPC-UA and \nMicrosoft Azure IoT Hub into an industrial Internet-of-Things\
    \ system. In the Proceedings of the \n2017 Global Internet of Things Summit (GIoTS),\
    \ Geneva, Switzerland, 6–9 June 2017; pp. 1–6. \n42- \nG. Hatzivasilis, I. G.\
    \ Askoxylakis, G. Alexandris, D. Anicic,A. Br ̈oring, V. Kulkarni, K. Fysarakis,\
    \ and G. \nSpanoudakis,“The Interoperability of Things: Interoperable solutions\
    \ as an enabler for IoT and \nWeb 3.0,” in23rd IEEE International Workshop on\
    \ Computer Aided Modeling and Design of \nCommunication Links and Networks, CAMAD\
    \ 2018, Barcelona, Spain, September 2018, pp. 1–7. \n \n145 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n43- \nMonostori, L.; Kádár, B.; Bauernhansl, T.; Kondoh,\
    \ S.; Kumara, S.; Reinhart, G.; Sauer, O.; Schuh, G.; \nSihn, W.; Ueda, K. Cyber-physical\
    \ systems in manufacturing. CIRP Ann. 2016, 65, 621–641. \n44- \nX. Zuo, Y. Cui,\
    \ M. Wang, T. Xiao, and X. Wang, “Low-latencynetworking: Architecture, techniques,\
    \ \nand opportunities,”IEEE InternetComput., vol. 22, no. 5, pp. 56–63, 2018.\
    \ \n45- \nM. Bennis, M. Debbah, and H. V. Poor, “Ultrareliable and Low-latencyWireless\
    \ Communication: \nTail, risk, and scale,”Proceedings of theIEEE, vol. 106, no.\
    \ 10, pp. 1834–1853, 2018 \n46- \nKang, J. Hauswald, C. Gaoet al., “Neurosurgeon:\
    \ CollaborativeIntelligence Between the Cloud and \nMobile Edge,” inProc. 22nd\
    \ Int.Conf. Archit. Support Program. Lang. Oper. Syst. (ASPLOS \n2017),2017, pp.\
    \ 615–629. \n47- \nXiaofei Wang, Senior Member, IEEE, Yiwen Han, Student Member,\
    \ IEEE, Victor C.M. Leung, Fellow, \nIEEE, Dusit Niyato,Fellow, IEEE, Xueqiang\
    \ Yan, Xu Chen, Member, IEEE. Convergence of Edge \nComputing and Deep Learning:\
    \ A Comprehensive Survey. arXiv:1907.08349v3 [cs.NI]  28 Jan 2020 \n48- \nZ. Li,\
    \ J. Kang, R. Yu, D. Ye, Q. Deng, and Y. Zhang, “ConsortiumBlockchain for Secure\
    \ Energy trading \nin Industrial Internet of Things,”IEEE Trans. Ind. Informat.,\
    \ vol. 14, no. 8, pp. 3690–3700, 2017. \n49- \nAlsamhi, S. H., Ma, O., and Ansari,\
    \ M. S. (2019b). Survey on artificial intelligence-based techniques \nfor emerging\
    \ robotic communication. Telecommun. Syst. 72, 483–503. doi: 10.1007/s11235-019-\n\
    00561-z \n50- \nLarrauri, J.I.; Sorrosal, G.; Gonzalez, M. Automatic system for\
    \ overhead power line inspection using \nan unmanned aerial vehicle RELIFO project.\
    \ In Proceedings of the International Conference on \nUnmanned Aircraft Systems\
    \ (ICUAS), Atlanta, GA, USA, 28–31 May 2013; pp. 244–252. \n51- \nKim, H.; Lee,\
    \ J.; Ahn, E.; Cho, S.; Shin, M.; Sim, S.-H. Concrete Crack Identification Using\
    \ a UAV \nIncorporating Hybrid Image Processing. Sensors 2017, 17, 2052.  \n52-\
    \ \nGeneration and Processing of Simulated Underwater Images for Infrastructure\
    \ Visual Inspection \nwith UUVs. Sensors 2019, 19, 5497.  \n53- \nBao, J.; Li,\
    \ D.; Qiao, X.; Rauschenbach, T. Integrated navigation for autonomous underwater\
    \ \nvehicles in aquaculture: A review. Inf. Process. Agric. 2020, 7, 139–151.\
    \  \n54- \nBarrett, N.; Seiler, J.; Anderson, T.; Williams, S.; Nichol, S.; Hill,\
    \ N. Autonomous Underwater Vehicle \n(AUV) for mapping marine biodiversity in\
    \ coastal and shelf waters: Implications for Marine \nManagement. In Proceedings\
    \ of the OCEANS’10 IEEE Conference, Sydney, Australia, 24−27 May \n2010. \n55-\
    \ \nWynn, R.B.; Huvenne, V.A.I.; le Bas, T.P.; Murton, B.; Connelly, D.P.; Bett,\
    \ B.J.; Ruhl, H.A.; Morris, K.J.; \nPeakall, J.; Parsons, D.R.; et al. Autonomous\
    \ Underwater Vehicles (AUVs): Their past, present and \nfuture contributions to\
    \ the advancement of marine geoscience. Mar. Geol. 2014.  \n56- \nCorgnati, L.;\
    \ Marini, S.; Mazzei, L.; Ottaviani, E.; Aliani, S.; Conversi, A.; Griffa, A.\
    \ Looking inside the \nOcean: Toward an Autonomous Imaging System for Monitoring\
    \ Gelatinous Zooplankton. Sensors \n2016, 16, 2124. \n57- \nLiu, S.; Xu, H.; Lin,\
    \ Y.; Gao, L. Visual Navigation for Recovering an AUV by Another AUV in Shallow\
    \ \nWater. Sensors 2019, 19, 1889.  \n58- \nJorge, V.A.M.; Granada, R.; Maidana,\
    \ R.G.; Jurak, D.A.; Heck, G.; Negreiros, A.P.F.; Dos Santos, D.H.; \nGonçalves,\
    \ L.M.G.; Amory, A.M. A Survey on Unmanned Surface Vehicles for Disaster Robotics:\
    \ \nMain Challenges and Directions. Sensors 2019, 19, 702. \n59- \nNuţă, I.; Orban,\
    \ O.; Grigore, L. Development and Improvement of Technology in Emergency \nResponse.\
    \ Procedia Econ. Financ. 2015, 32, 603–609. \n60- \nBellingham, J.G.; Rajan, K.\
    \ Robotics in Remote and Hostile Environments. Science 2007, 318, 1098–\n1102.\
    \ \n61- \nMarques, F.; Lourenço, A.; Mendonça, R.; Pinto, E.; Rodrigues, P.; Santana,\
    \ P.; Barata, J. A critical \nsurvey on marsupial robotic teams for environmental\
    \ monitoring of water bodies. In Proceedings \nof the OCEANS 2015, Genova, Italy,\
    \ 19–22 October 2015; pp. 1–6. \n62- \nColey, K. Unmanned Surface Vehicles: The\
    \ Future of Data-Collection. Ocean. Chall. 2015, 21, 14–\n15. \n63- \nMoysiadis,\
    \ V.; Sarigiannidis, P.; Moscholios, I. Towards Distributed Data Management in\
    \ Fog \nComputing. Wirel. Commun. Mob. Comput. 2018, 2018. [Google Scholar] [CrossRef]\
    \ \n64- \nG. Plastiras, M. Terzi, C. Kyrkou and T. Theocharidcs, \"Edge Intelligence:\
    \ Challenges and \nOpportunities of Near-Sensor Machine Learning Applications,\"\
    \ 2018 IEEE 29th International \nConference on Application-specific Systems, Architectures\
    \ and Processors (ASAP), 2018, pp. 1-7, \ndoi: 10.1109/ASAP.2018.8445118. \n \n\
    146 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n65- \n Miorandi, D.\
    \ ; Sicari, S.; De Pellegrini, F.; Chlamtac, I. Internet of Things. Ad Hoc Netw.2012,10,\
    \ \n1497–1516.  \n66- \nXu, L.D. Enterprise systems: State-of-the-art and future\
    \ trends. IEEE Trans. Ind. Informat.2011,7, \n630–640. \n67- \nLombardi, M.; Pascale,\
    \ F.; Santaniello, D. Internet of Things: A General Overview between \nArchitectures,\
    \ Protocols and Applications. Information 2021, 12, 87.  \n68- \nNgu, A.H.H.;\
    \ Gutierrez, M.; Metsis, V.; Nepal, S.; Sheng, M.Z. Iot middleware: A survey on\
    \ issues \nand enabling technologies. IEEE Internet Things J.2016,4, 1.  \n69-\
    \ \nSalhaoui, M.; Guerrero-Gonzalez, A.; Arioua, M.; Ortiz, F.J.; El Oualkadi,\
    \ A.; Torregrosa, C.L. Smart \nindustrial iot monitoring and control system based\
    \ on UAV and cloud computing applied to a \nconcrete plant. Sensors 2019, 19,\
    \ 3316.  \n70- \nFerrández-Pastor, F.J.; García-Chamizo, J.M.; Nieto-Hidalgo,\
    \ M.; Mora-Pascual, J.; Mora-Martínez, \nJ. Developing Ubiquitous Sensor Network\
    \ Platform Using Internet of Things: Application in \nPrecision Agriculture. Sensors\
    \ 2016, 1141. \n71- \nNavet, N.; Simonot-Lion, F.; Delong, C. In-Vehicle Communication\
    \ Networks: A Historical \nPerspective and Review; Apple Academic Press: Palm\
    \ Bay, FL, USA, 2017; pp. 50–51. \n72- \n[33] Colakovi ́c, A.; Hadžiali ́c, M.\
    \ Internet of Things (IoT): A review of enabling technologies, \nchallenges, and\
    \ open research issues.Comput. Netw.2018,144, 17–39.  \n73- \nFerrari, P.; Flammini,\
    \ A.; Rinaldi, S.; Sisinni, E.; Malara, D.M.M. Impact of Quality of Service on\
    \ Cloud \nBased Industrial IoT Applications with OPC UA. Electronics 2018, 7,\
    \ 109.  \n74- \nForsstrom, S.; Jennehag, U. A performance and cost evaluation\
    \ of combining OPC-UA and \nMicrosoft Azure IoT Hub into an industrial Internet-of-Things\
    \ system. In the Proceedings of the \n2017 Global Internet of Things Summit (GIoTS),\
    \ Geneva, Switzerland, 6–9 June 2017; pp. 1–6.  \n75- \nJaloudi, S. Communication\
    \ Protocols of an Industrial Internet of Things Environment: A \nComparative Study.\
    \ Future Internet 2019, 11, 66. \n76- \nTrancă, D.-C.; Pălăcean, A.V.; Mihu, A.C.;\
    \ Rosner, D. ZigBee based wireless modbus aggregator for \nintelligent industrial\
    \ facilities. In Proceedings of the IEEE 25th Telecommunication Forum, \nBelgrade,\
    \ Serbia, 21–22 November 2017.  \n77- \nTariq, M.A.; Khan, M.; Raza Khan, M.T.;\
    \ Kim, D. Enhancements and Challenges in CoAP—A Survey. \nSensors 2020, 20, 6391.\
    \  \n78- \nKäbisch, S.; Peintner, D. W3C Recommendation Canonical EXI. 2018. Available\
    \ online: \nhttps://www.w3.org/TR/exi-c14n/ (accessed on 4 February 2019). \n\
    79- \nCavalieri, S.; Stefano, D.D.; Salafia, M.G.; Scroppo, M.S. A web-based platform\
    \ for OPC UA \nintegration in IIoT environment. In Proceedings of the 2017 22nd\
    \ IEEE International Conference \non Emerging Technologies and Factory Automation\
    \ (ETFA), Limassol, Cyprus, 12–15 September \n2017; pp. 1–6. \n80- \nCavalieri,\
    \ S.; Chiacchio, F. Analysis of OPC UA performances. Comput. Stand. Interfaces\
    \ 2013, 36, \n165–177.  \n81- \nGu, Xiaohui et al. “Energy-Optimal Latency-Constrained\
    \ Application Offloading in Mobile-Edge \nComputing.” Sensors (Basel, Switzerland)\
    \ vol. 20,11 3064. 28 May. 2020, doi:10.3390/s20113064 \n82- \nNetguru. Available\
    \ online: https://www.netguru.com/blog/why-is-python-good-for-research-\nbenefits-of-the-programming-language\
    \ (accessed on 3 May 2020). \n83- \nChen, S.; Xu, H.; Liu, D.; Hu, B.; Wang, H.\
    \ A Vision of IoT: Applications, Challenges, and \nOpportunities with China Perspective.\
    \ IEEE Internet Things J. 2014, 1.  \n84- \nSuárez-Albela, M.; Fernández-Caramés,\
    \ T.M.; Fraga-Lamas, P.; Castedo, L. A Practical Evaluation of \na High-Security\
    \ Energy-Efficient Gateway for IoT Fog Computing Applications. Sensors 2017, 17,\
    \ \n1978. [ \n85- \nFerrández-Pastor, F.J.; García-Chamizo, J.M.; Nieto-Hidalgo,\
    \ M.; Mora-Pascual, J.; Mora-Martínez, \nJ. Developing Ubiquitous Sensor Network\
    \ Platform Using Internet of Things: Application in \nPrecision Agriculture. Sensors\
    \ 2016, 1141.  \n86- \nGutiérrez, C.S.V.; Juan, L.U.S.; Ugarte, I.Z.; Vilches,\
    \ V.M. Time-Sensitive networking for \nrobotics. arXiv 2018, arXiv:1804.07643v2.\
    \  \n87- \nForsstrom, S.; Jennehag, U. A performance and cost evaluation of combining\
    \ OPC-UA and \nMicrosoft Azure IoT Hub into an industrial Internet-of-Things system.\
    \ In the Proceedings of the \n2017 Global Internet of Things Summit (GIoTS), Geneva,\
    \ Switzerland, 6–9 June 2017; pp. 1–6. \n88- \nOPC Foundation. Available online:\
    \ https://opcfoundation.org/about/opc-technologies/opc-\nua/ (accessed on 14 September\
    \ 2018). \n \n147 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n89- \nGirbea,\
    \ A.; Suciu, C.; Nechifor, S.; Sisak, F. Design and implementation of a service-oriented\
    \ \narchitecture for the optimization of industrial applications. IEEE Trans.\
    \ Ind. Inform. 2014, 10, 185–\n196. \n90- \nChen, B.; Wan, J.; Shu, L.; Li, P.;\
    \ Mukherjee, M.; Yin, B. Smart Factory of Industry 4.0: Key \nTechnologies, Application\
    \ Case, and Challenges. IEEE Access 2017, 6, 6505–6519 \n91- \nJaloudi, S. Communication\
    \ Protocols of an Industrial Internet of Things Environment: A \nComparative Study.\
    \ Futur. Internet 2019, 11, 66. \n92- \nRay, P.P. A Survey on Visual Programming\
    \ Languages in Internet of Things. Sci. \nProgram. 2017, 2017, 1231430.  \n93-\
    \ \nBröring, A.; Seeger, J.; Papoutsakis, M.; Fysarakis, K.; Caracalli, A. Networking-Aware\
    \ IoT Application \nDevelopment. Sensors 2020, 20, 897. https://doi.org/10.3390/s20030897\
    \ \n94- \nChris Simpkin, Ian Taylor, Daniel Harborne, Graham Bent, Alun Preece,\
    \ Raghu K. Ganti, Efficient \norchestration of Node-RED IoT workflows using a\
    \ Vector Symbolic Architecture, Future \nGeneration Computer Systems, Elsevier,\
    \ Volume 111, 2020, Pages 117-131, ISSN 0167-\n739X,https://doi.org/10.1016/j.future.2020.04.005.\
    \ \n95- \nYasumoto, K.; Yamaguchi, H.; Shigeno, H. Survey of Real-time Processing\
    \ Technologies of IoT \nData Streams. J. Inf. Process. 2016, 24, 195–202.  \n\
    96- \nFernández-Caramés, T.M.; Fraga-Lamas, P. A Review on Human-Centered IoT-Connected\
    \ Smart \nLabels for the Industry 4.0. IEEE Access 2017, 6, 25939–25957.  \n97-\
    \ \nWan, J.; Tang, S.; Yan, H.; Li, D.; Wang, S.; Vasilakos, A.V. Cloud Robotics:\
    \ Current Status and \nOpen Issues. IEEE Access 2016, 4, 2797–2807.  \n98- \n\
    Robla-Gömez, S.; Becerra, V.M.; Llata, J.R.; González-Sarabia, E.; Ferrero, C.T.;\
    \ Pérez-Oria, J. \n‘Working together: A review on safe human-robot collaboration\
    \ in industrial environments. IEEE \nAccess 2017, 5, 26754–26773.  \n99- \nKoch,\
    \ P.J.; van Amstel, M.; Dębska, P.; Thormann, M.A.; Tetzlaff, A.J.; Bøgh, S.;\
    \ Chrysostomou, D. A \nSkill-based Robot Co-worker for Industrial Maintenance\
    \ Tasks. In Proceedings of the 27th \nInternational Conference on Flexible Automation\
    \ and Intelligent Manufacturing (FAIM 2017), \nModena, Italy, 27–30 June 2017.\
    \  \n100- \nAndreasson, H.; Bouguerra, A.; Cirillo, M.; Dimitrov, D.N.; Driankov,\
    \ D.; Karlsson, L.; Lilienthal, A.J.; \nPecora, F.; Saarinen, J.P.; Sherikov,\
    \ A.; et al. Autonomous transport vehicles: Where we are and \nwhat is missing.\
    \ IEEE Robot. Autom. Mag. 2015, 22, 64–75.] \n101- \nAlsamhi, S.H.; Ma, O.; Ansari,\
    \ M.S.; Gupta, S.K. Collaboration of Drone and Internet of Public \nSafety Things\
    \ in Smart Cities: An Overview of QoS and Network Performance \nOptimization.\
    \ Drones 2019, 3, 13.  \n102- \nSoorki, M.N.; Mozaffari, M.; Saad, W.; Manshaei,\
    \ M.H.; Saidi, H. Resource Allocation for Machine-\nto-Machine Communications\
    \ with Unmanned Aerial Vehicles. In Proceedings of the 2016 IEEE \nGlobecom Workshops\
    \ (GC Wkshps), Washington, DC, USA, 4–8 December 2016; pp. 1–6.  \n103- \nLarrauri,\
    \ J.I.; Sorrosal, G.; Gonzalez, M. Automatic system for overhead power line inspection\
    \ using \nan unmanned aerial vehicle RELIFO project. In Proceedings of the International\
    \ Conference on \nUnmanned Aircraft Systems (ICUAS), Atlanta, GA, USA, 28–31 May\
    \ 2013; pp. 244–252.  \n104- \nKim, H.; Lee, J.; Ahn, E.; Cho, S.; Shin, M.; Sim,\
    \ S.-H. Concrete Crack Identification Using a UAV \nIncorporating Hybrid Image\
    \ Processing. Sensors 2017, 17, 2052. \n105- \nArroyo, J.A.; Gomez-Castaneda,\
    \ C.; Ruiz, E.; de Cote, E.M.; Gavi, F.; Sucar, L.E. UAV Technology and \nMachine\
    \ Learning Techniques applied to the Yield Improvement in Precision Agriculture.\
    \ In \nProceedings of the IEEE Mexican Humanitarian Technology Conference (MHTC),\
    \ Puebla, Mexico, \n29–31 March 2017.  \n106- \nSingh, A.; Patil, D.; Omkar, S.N.\
    \ Eye in the Sky: Real-time Drone Surveillance System (DSS) for \nViolent Individuals\
    \ Identification using ScatterNet Hybrid Deep Learning Network. In Proceedings\
    \ \nof the IEEE Computer Vision and Pattern Recognition (CVPR) Workshops, Salt\
    \ Lake City, UT, USA, \n18–22 June 2018.  \n107- \nManohar, A.; Sneha, D.; Sakhuja,\
    \ K.; Dwivedii, T.R.; Gururaj, C. Drone based image processing \nthrough feature\
    \ extraction. In Proceedings of the 2017 2nd IEEE International Conference on\
    \ \nRecent Trends in Electronics Information & Communication Technology (RTEICT),\
    \ Bangalore, \nIndia, 19–20 May 2017.  \n108- \nJunaid, A.B.; Konoiko, A.; Zweiri,\
    \ Y.; Sahinkaya, M.N.; Seneviratne, L. Autonomous Wireless Self-\nCharging forMulti-Rotor\
    \ Unmanned Aerial Vehicles. Energies 2017, 10, 803. \n \n148 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n109- \nLee, J.; Wang, J.; Crandall, D.; Sabanovic, S.;\
    \ Fox, G. Real-Time Object Detection for Unmanned \nAerial Vehicles based on Cloud-based\
    \ Convolutional Neural Networks. In Proceedings of the First \nIEEE International\
    \ Conference on Robotic Computing, Taichung, Taiwan, 10–12 April 2017. \n110-\
    \ \nSilva, E.; Martins, A.; Dias, A.; Matos, A.; Olivier, A.; Pinho, C.; Silva,\
    \ E.; de Sá, F.A.; Ferreira, H.; Silva, \nH.; et al. Strengthening marine and\
    \ maritime research and technology. In Proceedings of the \nOCEANS 2016 MTS/IEEE\
    \ Monterey, Monterey, CA, USA, 19–23 September 2016; pp. 1–9.  \n111- \nNicholson,\
    \ J.; Healey, A. The present state of autonomous underwater vehicle (AUV) applications\
    \ \nand technologies. Mar. Technol. Soc. J. 2008, 42, 44–51.  \n112- \nWeidner,\
    \ N.; Rahman, S.; Li, A.Q.; Rekleitis, I. Underwater cave mapping using stereo\
    \ vision. In \nProceedings of the IEEE International Conference on Robotics and\
    \ Automation, Singapore, 29 \nMay–3 June 2017; pp. 5709–5715.  \n113- \nRoser,\
    \ M.; Dunbabin, M.; Geiger, A. Simultaneous underwater visibility assessment,\
    \ enhancement \nand improved stereo. In Proceedings of the IEEE International\
    \ Conference on Robotics and \nAutomation, Hong Kong, China, 31 May–7 June 2014;\
    \ pp. 1–8.  \n114- \nLu, H.; Li, Y.; Xu, X.; He, L.; Dansereau, D.; Serikawa,\
    \ S. Underwater image descattering and quality \nassessment. In Proceedings of\
    \ the IEEE International Conference on Image Processing, Phoenix, \nAZ, USA, 25–28\
    \ September 2016; pp. 1998–2002.  \n115- \nLu, H.; Serikawa, S. Underwater scene\
    \ enhancement using weighted guided median filter. In \nProceedings of the IEEE\
    \ International Conference on Multimedia and Expo, Chengdu, China, 14–\n18 July\
    \ 2014; pp. 1–6. \n116- \nForesti, G.L.; Murino, V.; Regazzoni, C.S.; Trucco,\
    \ A. A Voting-Based Approach for Fast Object \nRecognition in Underwater Acoustic\
    \ Images. IEEE J. Ocean. Eng. 1997, 22, 57–65.  \n117- \nHansen, R.K.; Andersen,\
    \ P.A. 3D Acoustic Camera for Underwater Imaging. Acoust. \nImaging 1993, 20,\
    \ 723–727.  \n118- \nLane, D.M.; Stoner, J.P. Automatic interpretation of sonar\
    \ imagery using qualitative feature \nmatching. IEEE J. Ocean. Eng. 1994, 19,\
    \ 391–405. \n119- \nForesti, G.L.; Gentili, S. A Vison Based System for Object\
    \ Detection In Underwater Images. Int. J. \nPattern Recognit. Artif. Intell. 2000,\
    \ 14, 167–188. \n120- \nValdenegro-Toro, M. Improving Sonar Image Patch Matching\
    \ via Deep Learning. In Proceedings \nof the 2017 European Conference on Mobile\
    \ Robots (ECMR), Paris, France, 6–8 September 2017.  \n121- \nVillon, S.; Mouillot,\
    \ D.; Chaumont, M.; Darling, E.S.; Subsolb, G.; Claverie, T.; Villéger, S. A Deep\
    \ \nLearning method for accurate and fast identification of coral reef fishes\
    \ in underwater \nimages. Ecol. Inform. 2018.  \n122- \nQut University. Available\
    \ online: https://www.qut.edu.au/news?id=135108 (accessed on 3 May \n2020). \n\
    123- \nPiechaud, N.; Hunt, C.; Culverhouse, P.F.; Foster, N.L.; Howell, K.L. Automated\
    \ identification of \nbenthic epifauna with computer vision. Mar. Ecol. Prog.\
    \ Ser. 2019, 615, 15–30.  \n124- \nGelin, C. Introduction. In A High-Rate Virtual\
    \ Instrument of Marine Vehicle Motions for \nUnderwater Navigation and Ocean Remote\
    \ Sensing. Springer Series on Naval Architecture, Marine \nEngineering, Shipbuilding\
    \ and Shipping; Springer: Berlin/Heidelberg, Germany, 2013; Volume 1. \n125- \n\
    Heidarsson, H.K.; Sukhatme, G.S. Obstacle detection from overhead imagery using\
    \ self-supervised \nlearning for autonomous surface vehicles. In Proceedings of\
    \ the 2011 IEEE/RSJ International \nConference on Intelligent Robots and Systems,\
    \ San Francisco, CA, USA, 25–30 September 2011; \npp. 3160–3165. \n126- \nKristan,\
    \ M.; Kenk, V.S.; Kovacic, S.; Pers, J. Fast Image-Based Obstacle Detection from\
    \ Unmanned \nSurface Vehicles. IEEE Trans. Cybern. 2015, 46, 641–654 \n127- \n\
    Blanke, M.; Hansen, S.; Stets, J.D.; Koester, T.; Brøsted, J.E.; Llopart Maurin,\
    \ A.; Nykvist, N.; Bang, J. \nOutlook for navigation—comparing human performance\
    \ with a robotic solution. In Proceedings \nof the 1st International Conference\
    \ on Maritime Autonomous Surface Ships (ICMASS 2018), Busan, \nKorea, 8–9 November\
    \ 2018.  \n128- \nPrasad, D.K.; Prasath, C.K.; Rajan, D.; Rachmawati, L.; Rajabaly,\
    \ E.; Quek, C. Challenges in video-\nbased object detection in maritime scenario\
    \ using computer vision. arXiv 2016, arXiv:1608.0107. \nAvailable online: https://arxiv.org/abs/1608.01079\
    \ (accessed on 17 November 2020). \n129- \nWawrzyniak, N.; Hyla, T.; Popik, A.\
    \ Vessel Detection and Tracking Method Based on Video \nSurveillance. Sensors\
    \ 2019, 19, 5230.  \n130- \nCho, Y.; Park, J.; Kang, M.; Kim, J. Autonomous detection\
    \ and tracking of a surface ship using \nonboard monocular vision. In Proceedings\
    \ of the 2015 12th International Conference on \nUbiquitous Robots and Ambient\
    \ Intelligence (URAI), Goyang, Korea, 28–30 October 2015. \n \n149 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n131- \nIBM \nBoards \nthe \nMayflower\
    \ \nAutonomous \nShip \nProject. \nAvailable \nonline: https://newsroom.ibm.com/2019-10-16-IBM-Boards-the-Mayflower-Autonomous-Ship-\n\
    Project (accessed on 17 November 2020). \n132- \nGoogle and Rolls-Royce Partner\
    \ on Autonomous Ships. Available online: https://maritime-\nexecutive.com/article/google-and-rolls-royce-partner-on-autonomous-ships\
    \ (accessed on 17 \nNovember 2020). \n133- \nHansen, R.K.; Andersen, P.A. 3D Acoustic\
    \ Camera for Underwater Imaging. Acoust. \nImaging 1993, 20, 723–727.  \n134-\
    \ \nLane, D.M.; Stoner, J.P. Automatic interpretation of sonar imagery using qualitative\
    \ feature \nmatching. IEEE J. Ocean. Eng. 1994, 19, 391–405. \n135- \nForesti,\
    \ G.L.; Gentili, S. A Vison Based System for Object Detection In Underwater Images.\
    \ Int. J. \nPattern Recognit. Artif. Intell. 2000, 14, 167–188. \n136- \nVillon,\
    \ S.; Mouillot, D.; Chaumont, M.; Darling, E.S.; Subsolb, G.; Claverie, T.; Villéger,\
    \ S. A Deep \nLearning method for accurate and fast identification of coral reef\
    \ fishes in underwater \nimages. Ecol. Inform. 2018.  \n137- \nPiechaud, N.; Hunt,\
    \ C.; Culverhouse, P.F.; Foster, N.L.; Howell, K.L. Automated identification of\
    \ \nbenthic epifauna with computer vision. Mar. Ecol. Prog. Ser. 2019, 615, 15–30.\
    \  \n138- \nValdenegro-Toro, M. Improving Sonar Image Patch Matching via Deep\
    \ Learning. In Proceedings \nof the 2017 European Conference on Mobile Robots\
    \ (ECMR), Paris, France, 6–8 September 2017.  \n139- \nGelin, C. Introduction.\
    \ In A High-Rate Virtual Instrument of Marine Vehicle Motions for \nUnderwater\
    \ Navigation and Ocean Remote Sensing. Springer Series on Naval Architecture,\
    \ Marine \nEngineering, Shipbuilding and Shipping; Springer: Berlin/Heidelberg,\
    \ Germany, 2013; Volume 1. \n140- \nHeidarsson, H.K.; Sukhatme, G.S. Obstacle\
    \ detection from overhead imagery using self-supervised \nlearning for autonomous\
    \ surface vehicles. In Proceedings of the 2011 IEEE/RSJ International \nConference\
    \ on Intelligent Robots and Systems, San Francisco, CA, USA, 25–30 September 2011;\
    \ \npp. 3160–3165. \n141- \nKristan, M.; Kenk, V.S.; Kovacic, S.; Pers, J. Fast\
    \ Image-Based Obstacle Detection from Unmanned \nSurface Vehicles. IEEE Trans.\
    \ Cybern. 2015, 46, 641–654 \n142- \nGu, J.; Wang, Z.; Kuen, J.; Ma, L.; Shahroudy,\
    \ A.; Shuai, B.; Liu, T.; Wang, X.; Wang, G.; Cai, J.; et al. \nRecent advances\
    \ in convolutional neural networks. Pattern Recognit. 2018, 77 \n143- \n48. Krizhevsky,\
    \ A.; Sutskever, I.; Hinton, G.E. ImageNet classification with deep convolutional\
    \ neural \nnetworks. In Proceedings of the International Conference on Neural\
    \ Information Processing \nSystems, Lake Tahoe, NV, USA, 3–8 December 2012; pp.\
    \ 1097–1105. \n144- \n Deng, J.; Dong, W.; Socher, R.; Li, L.J.; Li, K.; Li, F.F.\
    \ ImageNet: A large-scale hierarchical image \ndatabase. In Proceedings of the\
    \ Computer Vision and Pattern Recognition, 2009 (CVPR 2009), \nMiami, FL, USA,\
    \ 20–25 June 2009; pp. 248–255.  \n145- \n50. Girshick, R. Fast R-CNN. In Proceedings\
    \ of the 2015 IEEE International Conference on Computer \nVision (ICCV), Santiago,\
    \ Chile, 7–13 December 2015.  \n146- \n Ren, S.; He, K.; Girshick, R.; Sun, J.\
    \ Faster R-CNN: Towards Real-Time Object Detection with Region \nProposal Networks.\
    \ IEEE Trans. Pattern Anal. Mach. Intell. 2017, 39, 1137–1149.  \n147- \n Lin,\
    \ T.; Goyal, P.; Girshick, R.; He, K.; Dollár, P. Focal Loss for Dense Object\
    \ Detection. In \nProceedings of the 2017 IEEE International Conference on Computer\
    \ Vision (ICCV), Honolulu, HI, \nUSA, 21–26 July 2017. \n148- \n53.  Liu, W.;\
    \ Anguelov, D.; Erhan, D.; Szegedy, C.; Reed, S.; Fu, C.Y.; Berg, A.C. SSD: Single\
    \ shot \nmultibox detector. In Proceedings of the European Conference on Computer\
    \ Vision, Amsterdam, \nThe Netherlands, 11–14 October 2016; pp. 21–37. \n149-\
    \ \n54. Redmon, J.; Divvala, S.; Girshick, R.; Farhadi, A. You only look once:\
    \ Unified, real-time object \ndetection. In Proceedings of the IEEE Conference\
    \ on Computer Vision and Pattern Recognition \n(CVPR 2016), Las Vegas, NV, USA,\
    \ 27–30 June 2016; pp. 779–788.  \n150- \nGhidoni, P.L.N.S.; Brahnam, S. Handcrafted\
    \ vs. non-handcrafted features for computer vision \nclassification. Pattern Recognit.\
    \ 2017, 71, 158–172. \n151- \nPathak, A.R.; Pandey, M.; Rautaray, S. Application\
    \ of Deep Learning for Object Detection. In \nProceedings of the International\
    \ Conference on Computational Intelligence and Data Science \n(ICCIDS 2018), Gurugram,\
    \ India, 7–8 April 2018. \n152- \nFeng, X.; Jiang, Y.; Yang, X.; Du, M.; Li, X.\
    \ Computer Vision Algorithms and Hardware \nImplementations: A Survey. Integration\
    \ 2019, 69, 309–320.  \n153- \n58. Zhao, Z.; Zheng, P.; Xu, S.; Wu, X. Object\
    \ Detection with Deep Learning: A Review. IEEE Trans. \nNeural Netw. Learn. Syst.\
    \ 2019, 30, 3212–3232.  \n \n150 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n154- \nDahlkamp, H.; Kaehler, A.; Stavens, D.; Thrun, S.; Bradski, G.R. Self\
    \ supervised monocular road \ndetection in desert terrain. In Proceedings of the\
    \ Robotics: Science and Systems, Philadelphia, PA, \nUSA, 16–19 August 2006. \n\
    155- \n Chen, C.; Seff, A.; Kornhauser, A.; Xiao, J. Deep Driving: Learning affordance\
    \ for direct perception \nin autonomous driving. In Proceedings of the 2015 IEEE\
    \ International Conference on Computer \nVision (ICCV), Santiago, Chile, 7–13\
    \ December 2015; pp. 2722–2730.  \n156- \nChen, X.; Ma, H.; Wan, J.; Li, B.; Xia,\
    \ T. Multi-view 3D object detection network for autonomous \ndriving. In Proceedings\
    \ of the 2017 IEEE International Conference on Computer Vision (ICCV), \nHonolulu,\
    \ HI, USA, 21–26 July 2017; pp. 6526–6534. \n157- \nCoates, A.; Ng, A.Y. Multi-camera\
    \ object detection for robotics. In Proceedings of the 2010 IEEE \nInternational\
    \ Conference on Robotics and Automation, Anchorage, AK, USA, 3–7 May 2010; pp.\
    \ \n412–419. \n158- \nArmbrust, M.; Fox, A.; Griffith, R.; Joseph, A.D.; Katz,\
    \ R.; Konwinski, A.; Lee, G.; Patterson, D.; Rabkin, \nA.; Stoica, I.; et al.\
    \ A view of cloud computing. Commun. ACM 2010, 53, 50–58.  \n159- \n63. Kenitar,\
    \ S.B.; Arioua, M.; Younes, A.; Radi, M.; Salhaoui, M. Comparative Analysis of\
    \ Energy \nEfficiency and Latency of Fog and Cloud Architectures. In Proceedings\
    \ of the 2019 International \nConference on Sensing and Instrumentation in IoT\
    \ Era (ISSI), Lisbon, Portugal, 29–30 August 2019; \nIEEE: Piscataway, NJ, USA,\
    \ 2020.  \n160- \n64. Redmon, J.; Divvala, S.; Girshick, R.; Farhadi, A. You only\
    \ look once: Unified, real-time object \ndetection. In Proceedings of the IEEE\
    \ Conference on Computer Vision and Pattern Recognition \n(CVPR 2016), Las Vegas,\
    \ NV, USA, 27–30 June 2016; pp. 779–788.  \n161- \nWang, X.; Victor, C.M.; Niyato,\
    \ D.; Yan, X.; Chen, X. Convergence of Edge Computing and Deep \nLearning: A Comprehensive\
    \ Survey. IEEE Commun. Surv. Tutor. 2020, 22, 869–904.  \n162- \nComputer Vision,\
    \ WikiPedia. Available online: https://en.wikipedia.org/wiki/Computer_vision \n\
    (accessed on 18 June 2020). \n163- \nFeng, X.; Jiang, Y.; Yang, X.; Du, M.; Li,\
    \ X. Computer Vision Algorithms and Hardware \nImplementations: A Survey. Integration\
    \ 2019, 69, 309–320.  \n164- \nKang, Y.; Hauswald, J.; Gao, C.; Rovinski, A.;\
    \ Mudge, T.; Mars, J.; Tang, L. Neurosurgeon: \nCollaborative Intelligence Between\
    \ the Cloud and Mobile Edge. In Proceedings of the 22nd \nInternational Conference\
    \ on Architectural Support for Programming Languages and Operating \nSystems (ASPLOS\
    \ 2017), Xi’an, China, 8–12 April 2017; pp. 615–629.  \n165- \nRussakovsky, O.;\
    \ Deng, J.; Su, H.; Krause, J.; Satheesh, S.; Ma, S.; Huang, Z.; Karpathy, A.;\
    \ Khosla, A.; \nBernstein, M.; et al. ImageNet Large Scale Visual Recognition\
    \ Challenge. Int. J. Comput. Vis. 2015, \n115, 211–252. \n166- \nZhou, Z.; Chen,\
    \ X.; Li, E.; Zeng, L.; Luo, K.; Zhang, J. Edge Intelligence: Paving the Last\
    \ Mile of \nArtificial Intelligence with Edge Computing. Proc. IEEE 2019, 107.\
    \  \n167- \nSikeridis, D.; Papapanagiotou, I.; Rimal, B.P.; Devetsikiotis, M.\
    \ A Comparative  Taxonomy and \nSurvey of Public Cloud Infrastructure Vendors.\
    \ arXiv 2018, arXiv:1710.01476v2.  \n168- \nGoogle Cloud. Available online: https://cloud.google.com/vision/?hl=en\
    \ (accessed on 3 May \n2020). \n169- \nAzure. Available online: https://azure.microsoft.com/en-au/services/cognitive-services/computer-\n\
    vision/ (accessed on 3 May 2020). \n170- \nZhou, Z.; Chen, X.; Li, E.; Zeng, L.;\
    \ Luo, K.; Zhang, J. Edge Intelligence: Paving the Last Mile of \nArtificial Intelligence\
    \ with Edge Computing. Proc. IEEE 2019, 107. \n171- \nO’Mahony, N.; Campbell,\
    \ S.; Carvalho, A.; Harapanahalli, S.; Hernandez, G.V.; Krpalkova, L.; Riordan,\
    \ \nD.; Walsh, J. Deep Learning vs. Traditional Computer Vision. In Advances in\
    \ Computer Vision; Arai, \nK., Kapoor, S., Eds.; Springer: Cham, Switzerland,\
    \ 2020; Volume 943.  \n172- \nStefanini, M.; Lancellotti, R.; Baraldi, L.; Calderara,\
    \ S.A. Deep-learning-based approach to VM \nbehavior Identification in Cloud Systems.\
    \ In Proceedings of the 9th International Conference on \nCloud Computing and\
    \ Services Science, Crete, Greece, 2–4 May 2019; pp. 308–315. \n173- \nSvorobej,\
    \ S.; Endo, P.T.; Bendechache, M.; Filelis-Papadopoulos, C.; Giannoutakis, K.M.;\
    \ Gravvanis, \nG.A.; Tzovaras, D.; Byrne, J.; Lynn, T. Simulating Fog and Edge\
    \ Computing Scenarios: An Overview \nand Research Challenges. Future Internet\
    \ 2019, 11, 55 \n174- \nKurose, J.F.; Ross, K.W. Computer Networking: A Top-Down\
    \ Approach, 6th ed.; Pearson: London, \nUK, 2012.  \n175- \nThangamuthu, S.; Concer,\
    \ N.; Cuijpers, P.J.L.; Lukkien, J.J. Analysis of ethernet-switch traffic shapers\
    \ \nfor in-vehicle networking applications. In Proceedings of the 2015 Design,\
    \ Automation Test in \nEurope Conference Exhibition (DATE), Grenoble, France,\
    \ 9–13 March 2015; pp. 55–60 \n \n151 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n176- \nCavalieri, S.; Chiacchio, F. Analysis of OPC UA performances.\
    \ Comput. Stand. Interfaces 2013, 36, \n165–177 \n177- \nGutiérrez, C.S.V.; Juan,\
    \ L.U.S.; Ugarte, I.Z.; Vilches, V.M. Time-Sensitive networking for \nrobotics.\
    \ arXiv 2018, arXiv:1804.07643v2.  \n178- \nIEEE standard for local and metropolitan\
    \ area networks—Bridges and bridged networks-\namendment 25: Enhancements for\
    \ scheduled traffic. In IEEE Std 802.1Qbv-2015 (Amendment to \nIEEE Std 802.1Q-2014\
    \ as amended by IEEE Std 802.1Qca-2015, IEEE Std 802.1Qcd-2015, and IEEE \nStd\
    \ 802.1Q-2014/ Cor 1-2015); IEEE: New York, NY, USA, 2016; pp. 1–57. \n179- \n\
    Bruckner, D.; Blair, R. OPC, UA, TSN: A New Solution for Industrial Communication.\
    \ 2018. Available \nonline: https://www.automationworld.com/sites/default/files/opc_ua_tsn_whitepaper_1.pdf\
    \ (acce\nssed on 13 May 2019). \n180- \nTatum, M.C.; Liu, J. Unmanned Aerial Vehicles\
    \ in the Construction Industry. In Proceedings of the \nUnmanned Aircraft System\
    \ Applications in Construction, Creative Construction Conference, \nPrimosten,\
    \ Croatia, 19–22 June 2017. \n181- \nSisinni, E.; Saifullah, A.; Han, S.; Jennehag,\
    \ U.; Gidlund, M. Industrial Internet of Things: Challenges, \nOpportunities,\
    \ and Directions. IEEE Trans. Ind. Inform. 2018, 14, 4724–4734.   \n182- \nAazam,\
    \ M.; Zeadally, S.; Harras, K.A. Deploying Fog Computing in Industrial Internet\
    \ of Things and \nIndustry 4.0. IEEE Trans. Ind. Inform. 2018.   \n183- \nSvorobej,\
    \ S.; Endo, P.T.; Bendechache, M.; Filelis-Papadopoulos, C.; Giannoutakis, K.M.;\
    \ Gravvanis, \nG.A.; Tzovaras, D.; Byrne, J.; Lynn, T. Simulating Fog and Edge\
    \ Computing Scenarios: An Overview \nand Research Challenges. Future Internet\
    \ 2019, 11, 55.  . \n184- \nLarrauri, J.I.; Sorrosal, G.; Gonzalez, M. Automatic\
    \ system for overhead power line inspection using \nan unmanned aerial vehicle\
    \ RELIFO project. In Proceedings of the International Conference on \nUnmanned\
    \ Aircraft Systems (ICUAS), Atlanta, GA, USA, 28–31 May [32] 2013; pp. 244–252.\
    \   32. \nIndustrial \nSkyworks. \nDrone \nInspections \nServices. \nAvailable\
    \ \nonline: \nhttps://industrialskyworks.com/droneinspections-services (accessed\
    \ on 21 April 2019). \n185- \nSoria, P.R.; Bevec, R.; Arrue, B.C.; Ude, A.; Ollero,\
    \ A. Extracting Objects for Aerial Manipulation on \nUAVs Using Low Cost Stereo\
    \ Sensors. Sensors 2016, 16, 700.      \n186- \nLagkas, T.; Argyriou, V.; Bibi,\
    \ S.; Sarigiannidis, P. UAV IoT Framework Views and Challenges: \nTowards Protecting\
    \ Drones as “Things”. Sensors 2018, 18, 4015.     \n187- \nKim, H.; Lee, J.; Ahn,\
    \ E.; Cho, S.; Shin, M.; Sim, S.-H. Concrete Crack Identification Using a UAV\
    \ \nIncorporating Hybrid Image Processing. Sensors 2017, 17, 2052.   \n188- \n\
    Sara Mahmoud, Nader Mohamed, Jameela Al-Jaroodi, Integrating UAVs into the Cloud\
    \ Using the \nConcept of the Web of Things. Article in Journal of Robotics, published\
    \ January 2015. DOI\n \n10.1155/2015/631420 \n189- \nGithub. Available online:\
    \ https://github.com/felixge/node-ar-drone (accessed on 14 September \n2018).\
    \ \n190- \nGithub. \nAvailable \nonline: https://github.com/eschnou/ardrone-autonomy\
    \ (accessed \non \n14 \nSeptember 2018). \n191- \nEngel, J.; Sturm, J.; Cremers,\
    \ D. Accurate Figure Flying with a Quadrocopter Using Onboard Visual \nand Inertial\
    \ Sensing. In Proceedings of the International Conference on Intelligent Robot\
    \ Systems \n(IROS), Algarve, Portugal, 7–12 October 2012; p. 240. [Google Scholar]\
    \ \n192- \nSmith, J.R.; Cao, L.; Codella, N.C.F.; Hill, M.L.; Merler, M.; Nguyen,\
    \ Q.-B.; Pring, E.; Uceda-Sosa, R.A. \nMassive-scalelearning of image and video\
    \ semantic concepts. IBM J. Res. Dev. 2015, 59, 7-1–7-13. \n193- \nCaffe. Available\
    \ online: http://caffe.berkeleyvision.org (accessed on 14 September 2018). \n\
    \ \n194- \nBhattacharjee, B.; Hill, M.L.; Wu, H.; Chandakkar, P.S.; Smith, J.R.;\
    \ Wegman, M.N. Distributed \nlearning of deep feature embeddings for visual recognition\
    \ tasks. IBM J. Res. Dev. 2017, 61, 4-1. \n[Google Scholar] [CrossRef] \n195-\
    \ \nPuttnies, H.; Konieczek, B.; Heller, J.; Timmermann, D.; Danielis, P. Algorithmic\
    \ approach to estimate \nvariant software latencies for latency-sensitive networking.\
    \ In Proceedings of the 2016 IEEE 7th \nAnnual Information Technology, Electronics\
    \ and Mobile Communication Conference (IEMCON), \nVancouver, BC, Canada, 13–15\
    \ October 2016; pp. 1–7. [Google Scholar] \n196- \nNakutis, Z.; Deksnys, V.; Jarusevicius,\
    \ I.; Dambrauskas, V.; Cincikas, G.; Kriauceliunas, A. Round-Trip \nDelay \nEstimation\
    \ \nin \nOPC \nUA \nServer-Client \nCommunication \nChannel. Elektron \nElektrotechnika\
    \ 2016, 22, 80–84.  \n197- \nGithub. Available online: https://github.com/felixge/node-ar-drone\
    \ (accessed on 14 September \n2018). \n \n152 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n198- \nKeith Jack,Digital Television (DTV).  in Digital Video and\
    \ DSP, 2008. ScienceDirect. \nhttps://doi.org/10.1016/B978-0-7506-8975-5.00008-X\
    \ \n199- \nMarpe, D.; Wiegand, T.; Heinrich Hertz Institute (HHI); Sullivan, G.J.\
    \ The H.264/MPEG4 Advanced \nVideo Coding Standard and its Applications. IEEE\
    \ Commun. Mag. 2006, 8, 134–143. [Google \nScholar] [CrossRef] \n200- \nGonzález-Reolid,\
    \ I.; Molina-Molina, J.C.; Guerrero-González, A.; Ortiz, F.J.; Alonso, D. An \n\
    Autonomous Solar-Powered Marine Robotic Observatory for Permanent Monitoring of\
    \ Large \nAreas of Shallow Water. Sensors 2018, 18, 3497. [Google Scholar] [CrossRef]\
    \ [PubMed] \n201- \nBoletín Oficial de la Región de Murcia, Numero 298, Viernes,\
    \ 27 de Diciembre de 2019, Página \n36008, 8089 Decreto-Ley N° 2/2019, de 26 de\
    \ Diciembre, de Protección Integral del Mar Menor. \nAvailable \nonline: https://www.borm.es/services/anuncio/ano/2019/numero/8089/pdf?id=782206\
    \ (accesse\nd on 18 June 2020). \n202- \nInforme Integral Sobre el Estado Ecológico\
    \ del Mar Menor; Comité de Asesoramiento Científico \ndel Mar Menor: Murcia, Spain,\
    \ 2017. \n203- \nKersting, D.; Benabdi, M.; Čižmek, H.; Grau, A.; Jimenez, C.;\
    \ Katsanevakis, S.; Öztürk, B.; Tuncer, S.; \nTunesi, L.; Vázquez-Luis, M.; et\
    \ al. Pinna nobilis. IUCN Red List Threat. Species 2019, \ne.T160075998A160081499.\
    \ \nAvailable \nonline: https://www.iucnredlist.org/species/160075998/160081499\
    \ (accessed on 19 June 2020). \n[CrossRef] \n204- \nBelando, M.D.; García-Muñoz,\
    \ M.R.; Ramos-Segura, A.; Franco-Navarro, I.J.; García-Moreno, P.; \nRuiz-Fernández,\
    \ J.M. Distribución y Abundancia de las Praderas de MACRÓFITOS bentónicos y las\
    \ \nPoblaciones de Nacra (Pinna nobilis) en el Mar Menor; Informe del Instituto\
    \ Español de \nOceanografía y la Asociación de Naturalistas del Sureste: Murcia,\
    \ Spain, 2014; 60p. [Google \nScholar] \n205- \nPaull, L.; Seto, M.; Saeedi, S.;\
    \ Leonard, J.J. Navigation for Underwater Vehicles; Springer: \nBerlin/Heidelberg,\
    \ Germany, 2018. [Google Scholar] [CrossRef] \n206- \nLiu, X.; Xu, X.; Liu, Y.;\
    \ Wang, L. Kalman filter for cross-noise in the integration of SINS and \nDVL.\
    \ Math. Probl. Eng. 2014, 2014, 1–8. [Google Scholar] [CrossRef] \n207- \nPaull,\
    \ L.; Saeedi, S.; Seto, M.; Li, H. AUV navigation and localization: A review.\
    \ IEEE J. Ocean. \nEng. 2014, 39, 131–149. [Google Scholar] [CrossRef] \n208-\
    \ \nSalhaoui, M.; Guerrero-Gonzalez, A.; Arioua, M.; Ortiz, F.J.; El Oualkadi,\
    \ A.; Torregrosa, C.L. Smart \nindustrial iot monitoring and control system based\
    \ on UAV and cloud computing applied to a \nconcrete plant. Sensors 2019, 19,\
    \ 3316. [Google Scholar] [CrossRef] \n209- \nStackoverflow. \nAvailable \nonline:\
    \ https://stackoverflow.blog/2017/09/14/python-growing-\nquickly/ (accessed on\
    \ 3 May 2020). \n210- \nNetguru. Available online: https://www.netguru.com/blog/why-is-python-good-for-research-\n\
    benefits-of-the-programming-language (accessed on 3 May 2020). \n211- \nZhou,\
    \ Z.; Chen, X.; Li, E.; Zeng, L.; Luo, K.; Zhang, J. Edge Intelligence: Paving\
    \ the Last Mile of \nArtificial Intelligence with Edge Computing. Proc. IEEE 2019,\
    \ 107. [Google Scholar] [CrossRef] \n212- \nSikeridis, D.; Papapanagiotou, I.;\
    \ Rimal, B.P.; Devetsikiotis, M. A Comparative Taxonomy and Survey \nof Public\
    \ Cloud Infrastructure Vendors. arXiv 2018, arXiv:1710.01476v2. [Google Scholar]\
    \ \n213- \nKim, D.; Han, K.; Sim, J.S.; Noh, Y. Smombie Guardian: We watch for\
    \ potentialobstacles while you \nare walking andconducting smartphone activities.\
    \ PLoS ONE 2018, 13, e0197050. [Google \nScholar] [CrossRef] \n214- \nMegalingam,\
    \ R.K.; Shriram, V.; Likhith, B.; Rajesh, G.; Ghanta, S. Monocular distance estimation\
    \ \nusing pinhole camera approximation to avoid vehicle crash and back-over accidents.\
    \ In \nProceedings of the 2016 10th International Conference on Intelligent Systems\
    \ and Control (ISCO), \nCoimbatore, India, 7–8 January 2016; IEEE: Coimbatore,\
    \ India. [Google Scholar] [CrossRef] \n215- \nNational \nInstruments. \nAvailable\
    \ \nonline: https://www.ni.com/es-es/support/model.sbrio-\n9606.html (accessed\
    \ on 3 May 2020). \n216- \nNational Instruments. Available online: https://www.ni.com/en-us/shop/labview.html\
    \ (accessed \non 3 May 2020). \n217- \nMarine Species. Available online: http://www.marinespecies.org/\
    \ (accessed on 2 June 2020). \n218- \nShi, W.; Cao, J.; Zhang, Q.; Li, Y.; Xu,\
    \ L. Edge computing: Vision and challenges. IEEE Internet Things \nJ. 2016, 3,\
    \ 637–646. [Google Scholar] [CrossRef] \n \n153 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n219- \nKrupinski, S.; Desouche, R.; Palomeras, N.; Allibert,\
    \ G.; Hua, M.D. Pool Testing of AUV Visual \nServoing for Autonomous Inspection.\
    \ IFAC-PapersOnLine 2015, 48, 274–280. [Google Scholar] \n[CrossRef] \n220- \n\
    Kumar, G.S.; Unnikrishnan, V.; Painumgal, M.N.V.; Kumar, C.; Rajesh, K.H.V. Autonomous\
    \ \nUnderwater Vehicle for Vision Based Tracking. Procedia Comput. Sci. 2018.\
    \ [Google Scholar] \n[CrossRef] \n221- \nIslam, M.J.; Fulton, M.; Sattar, J. Towards\
    \ a Generic Diver-Following Algorithm: Balancing \nRobustness and Efficiency in\
    \ Deep Visual Detection. IEEE Robot. Autom. Lett. 2019, 4, 113–120. \n[Google\
    \ Scholar] [CrossRef] \n222- \nYosafat, R.; Machbub, C.; Hidayat, E.M.I. Design\
    \ and Implementation of Pan-Tilt for Face Tracking. \nIn Proceedings of the International\
    \ Conference on System Engineering and Technology, Shah \nAlam, Malaysia, 2–3\
    \ October 2017. [Google Scholar] \n223- \nZhang, B.; Huang, J.; Lin, J. A Novel\
    \ Algorithm for Object Tracking by Controlling PAN/TILT \nAutomatically. In Proceedings\
    \ of the ICETC 2nd International Conference on Intelligent System \n2010, Shanghai,\
    \ China, 22–24 June 2010; Volume VI, pp. 596–602. [Google Scholar] \n224- \nGonzález,\
    \ A.G.; Coronado, J. Tratamiento de los retrasos del procesamiento visual en el\
    \ sistema \nde control de un cabezal estereoscópico. In XX Jornadas de Automática:\
    \ Salamanca, 27, 28 y 29 \nde Septiembre; Universidad de Salamanca: Salamanca,\
    \ Spain; pp. 83–87. \n225- \nKim, D.; Han, K.; Sim, J.S.; Noh, Y. Smombie Guardian:\
    \ We watch for potentialobstacles while you \nare walking andconducting smartphone\
    \ activities. PLoS ONE 2018, 13, e0197050. [Google \nScholar] [CrossRef] \n226-\
    \ \nIBM. \nAvailable \nonline: https://cloud.ibm.com/docs/services/visual-recognition?topic=visual-\n\
    recognition-object-detection-overview (accessed on 3 May 2020). \n227- \nGoogle\
    \ Cloud. Available online: https://cloud.google.com/vision/?hl=en (accessed on\
    \ 3 May \n2020). \n228- \nAzure. \nAvailable \nonline: https://azure.microsoft.com/en-au/services/cognitive-\n\
    services/computer-vision/ (accessed on 3 May 2020). \n229- \nMarine protected\
    \ areas in Europe’s seas. An overview and perspectives for the future. European\
    \ \nEnvironment \nAgency. \nNo \n3/2015. \nISSN \n1977-8449. \nAvailable \nonline:\
    \ \nhttps://www.eea.europa.eu/publications/marine-protected-areas-in-europes (accessed\
    \ on 17 \nNovember 2020) \n230- \nLey 3/2001, de Pesca Marítima del Estado. Boletín\
    \ Oficial del Estado del Gobierno de España.  \nAvailable online: https://www.boe.es/eli/es/l/2001/03/26/3/con\
    \ (accessed on 17 November 2020) \n231- \nGobierno \nde \nEspaña. \nReservas \n\
    Marinas \nde \nEspaña. \nAvailable \nonline: \nhttps://www.mapa.gob.es/es/pesca/temas/proteccion-recursos-pesqueros/reservas-marinas-de-\n\
    espana/(accessed on 17 November 2020) \n232- \nGonzález-Reolid, I.; Molina-Molina,\
    \ J.C.; Guerrero-González, A.; Ortiz, F.J.; Alonso, D. An \nAutonomous Solar-Powered\
    \ Marine Robotic Observatory for Permanent Monitoring of Large \nAreas of Shallow\
    \ Water. Sensors 2018, 18, 3497; doi:10.3390/s18103497. \n233- \nA. Manjunath,\
    \ Y. Liu, B. Henriques and A. Engstle, \"Radar Based Object Detection and Tracking\
    \ for \nAutonomous Driving,\" 2018 IEEE MTT-S International Conference on Microwaves\
    \ for Intelligent \nMobility (ICMIM), Munich, 2018, pp. 1-4, doi: 10.1109/ICMIM.2018.8443497\
    \ \n234- \nYang-Lang Chang, Amare Anagaw, Lena Chang, Yi Chun Wang, Chih-Yu Hsiao\
    \ and Wei-Hong Lee. \nShip Detection Based on YOLOv2 for SAR Imagery. Remote Sens.\
    \ 2019, 11, 786; \ndoi:10.3390/rs11070786 \n235- \nWei Li, Ting Yang, Flavia C.\
    \ Delicato, Paulo F. Pires, Zahir Tari, Samee U. Khan, and Albert Y. Zomaya. \n\
    On Enabling Sustainable Edge Computing with Renewable Energy Resources. IEEE \n\
    Communications Magazine. May 2018, 10.1109/MCOM.2018.1700888 \n236- \nJ. Lee,\
    \ J. Wang, D. Crandall, S. Šabanović and G. Fox, \"Real-Time, Cloud-Based Object\
    \ Detection \nfor Unmanned Aerial Vehicles,\" 2017 First IEEE International Conference\
    \ on Robotic Computing \n(IRC), Taichung, 2017, pp. 36-43, doi: 10.1109/IRC.2017.77.\
    \ \n237- \nK. Zhang, S. Leng, Y. He, S. Maharjan and Y. Zhang, \"Mobile Edge Computing\
    \ and Networking for \nGreen and Low-Latency Internet of Things,\" in IEEE Communications\
    \ Magazine, vol. 56, no. 5, pp. \n39-45, May 2018, doi: 10.1109/MCOM.2018.1700882.\
    \ \n \n154 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n238- \nAkar\
    \ E., Marques O., Andrews W.A., Furht B. (2019) Cloud-Based Skin Lesion Diagnosis\
    \ System \nUsing Convolutional Neural Networks. In: Arai K., Bhatia R., Kapoor\
    \ S. (eds) Intelligent \nComputing. CompCom 2019. Advances in Intelligent Systems\
    \ and Computing, vol 997. \nSpringer, Cham. https://doi.org/10.1007/978-3-030-22871-2_70\
    \ \n239- \nMarouane Salhaoui, J. Carlos Molina-Molina, Antonio Guerrero-González,\
    \ Mounir Arioua, \nFrancisco J Ortiz, Autonomous Underwater Monitoring System\
    \ for Detecting Life on the Seabed \nby Means of Computer Vision Cloud Services.\
    \ Journal, Remote Sensing MDPI, 2020. \n240- \nNational Instruments. Available\
    \ online: https://www.ni.com/en-us/shop/labview.html (accessed \non 17 Nov 2020).\
    \ \n241- \nNational Instruments. Available online: https://www.ni.com/es-es/support/model.crio-9022.html\
    \ \n(accessed on 17 Nov 2020).  \n242- \nMarouane Salhaoui, J. Carlos Molina-Molina,\
    \ Antonio Guerrero-González, Mounir Arioua, \nFrancisco J Ortiz, Autonomous Underwater\
    \ Monitoring System for Detecting Life on the Seabed \nby Means of Computer Vision\
    \ Cloud Services. Journal, Remote Sensing MDPI, 2020. \n243- \nM. Satyanarayanan,\
    \ “The emergence of edge computing,” Computer, vol. 50, no. 1, pp. 30–39, \n2017.\
    \ \n244- \nGobierno de España - Reservas Marinas de España. Cabo de Palos – Islas\
    \ Hormigas: Características. \nAvailable \nonline: \nhttps://www.mapa.gob.es/es/pesca/temas/proteccion-recursos-\n\
    pesqueros/reservas-marinas-de-espana/cabo-de-palos-islas-\nhormigas/caracteristicas/default.aspx\
    \ (accessed on 17 Nov 2020). \n245- \nIRENA - International Renewable Energy Agency.\
    \ Available online : https://www.irena.org, 07 \nJanuary 2021. \n246- \nMönks,\
    \ U., Trsek, H., Dürkop, L., Geneiß, V., Lohweg, V.: Towards distributed intelligent\
    \ \nsensor and information fusion. Mechatronics 34, 63–71 (2016). https://doi.org/10.1016/j.\
    \ \nmechatronics.2015.05.005 \n247- \nDhondge, K., Shorey, R., Tew, J.: HOLA:\
    \ heuristic and opportunistic link selection \nalgorithm for energy efficiency\
    \ in Industrial Internet of Things (IIoT) systems. In: \nCOMSNETS 2016 - Workshop\
    \ on Wild and Crazy Ideas on the Interplay Between IoT and \nBig Data. IEEE (2016)\
    \ \n248- \nDatta, S.K.; Bonnet, C. MEC and IoT Based Automatic Agent Reconfiguration\
    \ in Industry 4.0. In \nProceedings of the 2018 IEEE International Conference\
    \ on Advanced Networks and \nTelecommunications Systems (ANTS), Indore, India,\
    \ 16–19 December 2018; pp. 1–5. 7.  \n249- \nShrouf, F.; Ordieres, J.; Miragliotta,\
    \ G. Smart factories in Industry 4.0:  A review of the concept and \nof energy\
    \ management approached in production based on the Internet of Things paradigm.\
    \ In \nProceedings of the 2014 IEEE International Conference on Industrial Engineering\
    \ and Engineering \nManagement (IEEM), Selangor Darul Ehsan, Malaysia, 9–12 December\
    \ 2014; pp. 697–701. \n250- \nHossein Motlagh, N.; Mohammadrezaei, M.; Hunt, J.;\
    \ Zakeri, B. Internet of Things (IoT) and the \nEnergy Sector. Energies 2020,\
    \ 13, 494. \n251- \nAyesha Hafeez, Nourhan H. Kandil, Ban Al-Omar, T. Landolsi,\
    \ and A. R. Al-Ali, \"Smart \nHome Area Networks Protocols within the Smart Grid\
    \ Context\", Journal of Communications Vol. \n9, No. 9, September 2014 \n252-\
    \ \nLi, S.; Da Xu, L.; Zhao, S. 5G Internet of Things: A survey. J. Ind. Inf.\
    \ Integr. 2018, 10, 1–9 \n253- \nAhmed B. Altamimi and Rabie A. Ramadan, \"Towards\
    \ internet of things modeling: a gateway \napproach\", \nSpringer, \nComplex \n\
    Adapt \nSyst \nModel \n(2016) \n4:25, \nDOI \nhttps://doi.org/10.1186/s40294-016-0038-3\
    \ \n254- \nWatson Internet of Things. Securely Connect with Watson IoT Platform.\
    \ 2019. Available online: \nhttps://www.ibm.com/internet-of-things/solutions/iot-platform/watson-iot-platform\
    \  (accessed \non 15 October 2019). \n255- \n “The OPC Unified Architecture (UA)”\
    \ [Online]. Available: https://opcfoundation.org/about/opc-\ntechnologies/opc-ua/\
    \ \n256- \nThomas Bangemann, StamatisKarnouskos, Roberto Camp, Oscar Carlsson,MatthiasRiedl,\
    \ \nStuart McLeod, Robert Harrison, Armando W. ColomboandPetrStluka, “State of\
    \ the Art in \nIndustrial Automation”, Industrial Cloud-Based Cyber-Physical Systems,\
    \ Springer International \nPublishing Switzerland 2014, DOI: 10.1007/978-3-319-05624-1_2\
    \ \n257- \nNode-RED, Low-code programming for event-driven applications. [Online].\
    \ Available:  \nhttps://nodered.org/  \n"
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: https://repositorio.upct.es/bitstream/10317/10416/1/msa.pdf
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: Smart IoT monitoring and real-time control based on autonomous robots, visual
    recognition and cloud/edge computing services
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.20868/upm.thesis.69244
  analysis: '>'
  authors:
  - José Andrés Muñoz Arcentales
  citation_count: 0
  full_citation: '>'
  full_text: ">\nUNIVERSIDAD POLITÉCNICA DE MADRID\nEscuela Técnica Superior de Ingenieros\
    \ de Telecomunicación\nCONTRIBUTION TO THE ADVANCEMENT OF DATA\nENGINEERING FOR\
    \ SMART SPACES THROUGH DATA USAGE\nCONTROL AND CONTEXT-AWARE SYSTEMS\nDOCTORAL\
    \ THESIS\nJosé Andrés Muñoz Arcentales\nIngeniero en Telemática\nMadrid, Spain\n\
    October, 2021\nDepartamento de Ingeniería de Sistemas Telemáticos\nEscuela Técnica\
    \ Superior de Ingenieros de Telecomunicación\nCONTRIBUTION TO THE ADVANCEMENT\
    \ OF DATA ENGINEERING FOR\nSMART SPACES THROUGH DATA USAGE CONTROL AND CONTEXT-AWARE\n\
    SYSTEMS\nDOCTORAL THESIS\nAutor: José Andrés Muñoz Arcentales\nIngeniero en Telemática\n\
    Director: Joaquín Salvachúa Rodriguez\nDoctor Ingeniero de Telecomunicación\n\
    Director: Álvaro Alonso González\nDoctor Ingeniero de Telecomunicación\nOctober,\
    \ 2021\nTribunal nombrado por el Magníﬁco. y Excelentísimo. Sr. Rector de la Universidad\
    \ Politécnica\nde Madrid, el día\nde\nde 2021.\nPresidente:\nVocal:\nVocal:\n\
    Vocal:\nSecretario:\nSuplente:\nSuplente:\nRealizado el acto de defensa y lectura\
    \ de la Tesis el día\nde\nde 2021 en Madrid,\nhabiendo obtenido la caliﬁcación\
    \ de\nEl presidente,\nEl secretario,\nLos vocales,\nAcknowledgments\nComo no puede\
    \ ser de otra forma quiero dar las gracias primero a Dios por ser mi guía en cada\n\
    momento y permitirme estar aquí este día. A mis padres Mirian Arcentales y José\
    \ Muñoz, por\nla excelente labor que han hecho como padres, por su constante guía,\
    \ por siempre encontrar las\npalabras exactas para levantarme e impulsame a seguir\
    \ y por el inagotable apoyo que siempre\nme han dado a lo largo de mi vida, sin\
    \ ustedes esto no hubiera sido posible. A mi hermano\nEnrique y mis hermanas Mirian\
    \ y Astrid , por siempre conﬁar en mi y darme las fuerzas para\navanzar día a\
    \ día en este largo camino. A mi abuela Rosa Flores, en la que siempre encontré\
    \ una\nayuda cuando más la necesitaba. Al amor de mi vida, mi futura esposa, mi\
    \ compañera de vida\nCynthia Pineda, gracias por la alegría que traes a mi vida,\
    \ por tu paciencia inﬁnita y la conﬁanza\nque siempre has tenido en mi, gracias\
    \ por estar conmigo en todo este proceso y por impulsarme\nsiempre a conseguir\
    \ mis objetivos que son aún más satisfactorios al poder compartirlos contigo.\
    \ A\nmis mentores Ignacio Marín y Patricia Chávez por ser los primeros que apostaron\
    \ por mi en esta\nruta y mostrarme este maravilloso camino hacia la búsqueda del\
    \ conocimieto. A Rafael Pérez por\nimpulsar mis ansias investigadoras y darme\
    \ la conﬁanza para dar este primer paso. A mis panas\ndel alma Washington Valásquez,\
    \ Sonsoles y Alex, quienes siempre me apoyaron y me acogieron,\nustedes se convirtieron\
    \ en mi familia en este sitio y fueron quienes hicieron de este camino una\nmaravillosa\
    \ experiencia. Finalmente, a Juan Quemada, Gabriel Huecas y a mis directores Joaquín\n\
    Salvachúa y Ávaro Alonso por su gran paciencia y dedicación, por apostar por mi\
    \ e impulsar mi\ncarrera desde el principio de mis dás en esta Universidad. Gracias\
    \ y mil gracias por todo, este\nlogro va dedicado a ustedes.\nAbstract\nCurrently,\
    \ one of the most promising application ﬁelds of context-aware systems is that\
    \ of\nIoT-based (Internet of Things) smart spaces. A smart space is a physical\
    \ space that relies on\ntechnology to connect \"things\" to the virtual world,\
    \ increasing the level of awareness of what is\noccurring in physical environments.\n\
    Besides IoT devices, IoT-based smart spaces include\nsoftware platforms and services,\
    \ artiﬁcial intelligence (AI), machine learning (ML), big data,\ncloud computing,\
    \ heterogeneous connectivity, virtual/mixed realities, and a huge range of\ntechnologies\
    \ to improve people’s quality of life, to decrease environmental impact, and to\n\
    optimize the use of physical resources.\nMost previous works provide a generic\
    \ high-level\nstructure of how a context-aware system can be operationalized,\
    \ but do not offer clues on how to\nimplement it.\nOn the other hand, there are\
    \ many implementations of context-aware systems\napplied to speciﬁc IoT-based\
    \ smart environments that are context-speciﬁc: it is not clear how they\ncan be\
    \ extended to other use cases.\nAdditionally, in recent years, a new business\
    \ paradigm has emerged which revolves around\neffectively extracting value from\
    \ data. In this scope, providing a secure ecosystem for data sharing\nthat ensures\
    \ data governance and traceability is of paramount importance as it holds the\
    \ potential\nto create new applications and services. Protecting data goes beyond\
    \ restricting who can access\nwhat resource (covered by identity and Access Control):\
    \ it becomes necessary to control how data\nare treated once accessed, which is\
    \ known as data usage control. Data usage control provides a\ncommon and trustful\
    \ security framework to guarantee the compliance with data governance rules\n\
    and responsible use of organizations’ data by third-party entities, easing and\
    \ ensuring secure data\nsharing in ecosystems such as Smart Cities and Industry\
    \ 4.0.\nThis thesis encompasses the design, implementation, and validation of\
    \ two architectures for\nenabling context-aware data analytics and data usage\
    \ control in smart spaces. Both architectures\nhave been implemented relying on\
    \ the building blocks of the FIWARE ecosystem, presenting\nagnostic end-to-end\
    \ solutions that take into consideration the complete data lifecycle, ﬁlling the\n\
    existing gap in the literature.\nOn the one hand, on the topic of context-aware\
    \ systems, I provide an architecture and a\nreference implementation that can\
    \ be readily operationalized in any IoT-based smart environment\nregardless of\
    \ its ﬁeld of application, providing a context-aware data analytics solution that\
    \ is not\ncontext-speciﬁc. I provide two sample application scenarios that showcase\
    \ how the reference\nimplementation can be used in a variety of ﬁelds, covering\
    \ from data acquisition and modeling,\nto data reasoning and dissemination.\n\
    On the other hand, regarding data usage control, I present an architecture proposal\
    \ and its\nsubsequent implementation that achieves access and usage control in\
    \ shared data ecosystems\namong multiple organizations. The proposed architecture\
    \ is based on the UCON (Usage Control)\nmodel and an extended XACML (eXtensible\
    \ Access Control Markup Language) Reference\nArchitecture, relying on key aspects\
    \ of the IDS (International Data Spaces) Reference\nArchitecture Model. The implementation\
    \ presented has been validated with a use case in the food\nindustry, presenting\
    \ a series of metrics of the response time of policy compliance veriﬁcation and\n\
    punishment enforcement.\nFinally, the results reported in this thesis contributes\
    \ to the advancement of data engineering\nnot only by enabling data analytics\
    \ capabilities in context-aware systems but also by providing a\ntrustworthy mechanism\
    \ to ensure that the data generated by those systems can be continuously\ncontrolled\
    \ and monitored using the proposed data usage control framework.\nResumen\nActualmente,\
    \ uno de los campos de aplicación más prometedores de los sistemas conscientes\
    \ del\ncontexto es el de los espacios inteligentes basados en el IoT (Internet\
    \ de las cosas). Un espacio\ninteligente es un espacio físico que se apoya en\
    \ la tecnología para conectar las \"cosas\" con el\nmundo virtual, aumentando\
    \ el nivel de conciencia de lo que ocurre en los entornos físicos.\nAdemás de\
    \ los propios dispositivos IoT, los espacios inteligentes basados en IoT incluyen\n\
    plataformas y servicios de software, inteligencia artiﬁcial (IA), aprendizaje\
    \ automático (ML), big\ndata, computación en la nube, conectividad heterogénea,\
    \ realidades virtuales/mixtas y una\nenorme gama de tecnologías para mejorar la\
    \ calidad de vida de las personas, disminuir el impacto\nmedioambiental y optimizar\
    \ el uso de los recursos físicos. La mayoría de los trabajos anteriores\nproporcionan\
    \ una estructura genérica de alto nivel sobre cómo puede funcionar un sistema\n\
    consciente del contexto, pero no ofrecen pistas sobre cómo implementarlo. Por\
    \ otra parte, hay\nmuchas implementaciones de sistemas conscientes del contexto\
    \ aplicadas a entornos inteligentes\nespecíﬁcos basados en IoT que son especíﬁcos\
    \ del campo de aplicación: no está claro cómo\npueden extenderse a otros casos\
    \ de uso.\nAdemás, en los últimos años ha surgido un nuevo paradigma empresarial\
    \ que gira en torno a la\nextracción efectiva de valor de los datos. En este ámbito,\
    \ proporcionar un ecosistema seguro para\nel intercambio de datos que garantice\
    \ la gobernanza y la trazabilidad de los mismos es de vital\nimportancia, ya que\
    \ encierra el potencial de crear nuevas aplicaciones y servicios. La protección\n\
    de los datos va más allá de la restricción de quién puede acceder a qué recurso\
    \ (cubierta por el\ncontrol de identidad y acceso): se hace necesario controlar\
    \ cómo se tratan los datos una vez que se\naccede a ellos, lo que se conoce como\
    \ control de uso de los datos. El control de uso de los datos\nproporciona un\
    \ marco de seguridad común y de conﬁanza para garantizar el cumplimiento de las\n\
    normas de gobernanza de datos y el uso responsable de los datos de las organizaciones\
    \ por parte\nde terceras entidades, facilitando y garantizando el intercambio\
    \ seguro de datos en ecosistemas\ncomo las Ciudades Inteligentes y la Industria\
    \ 4.0.\nEsta tesis abarca el diseño, la implementación y la validación de dos\
    \ arquitecturas para permitir\nel análisis de datos conscientes del contexto y\
    \ el control del uso de datos en espacios inteligentes.\nAmbas arquitecturas se\
    \ han implementado basándose en los bloques del ecosistema FIWARE,\npresentando\
    \ soluciones agnósticas de extremo a extremo que tienen en cuenta el ciclo de\
    \ vida\ncompleto de los datos, llenando el vacío existente en la literatura.\n\
    Por un lado, en lo relacionado con el tema de los sistemas conscientes del contexto,\n\
    proporciono una arquitectura y una implementación de referencia que puede ser\
    \ fácilmente\noperacionalizada en cualquier entorno inteligente basado en IoT,\
    \ independientemente de su\ncampo de aplicación, proporcionando una solución de\
    \ análisis de datos consciente del contexto\nque no es especíﬁca del mismo.\n\
    Proporciono dos escenarios de aplicación de ejemplo que\nmuestran cómo la implementación\
    \ de referencia puede ser utilizada en una variedad de campos,\ncubriendo desde\
    \ la adquisición de datos y el modelado, hasta el razonamiento de datos y la\n\
    difusión.\nPor otro lado, en lo que respecta al control del uso de los datos,\
    \ presento una propuesta de\narquitectura y su posterior implementación que logra\
    \ el control de acceso y uso de datos en\necosistemas de datos compartidos entre\
    \ múltiples organizaciones. La arquitectura propuesta se\nbasa en el modelo UCON\
    \ (Usage Control) y en una arquitectura de referencia XACML\n(eXtensible Access\
    \ Control Markup Language) ampliada, apoyándose en aspectos clave del\nmodelo\
    \ de arquitectura de referencia IDS (International Data Spaces).\nLa implementación\n\
    presentada ha sido validada con un caso de uso en la industria alimentaria, presentando\
    \ una serie\nde métricas del tiempo de respuesta de la veriﬁcación del cumplimiento\
    \ de las políticas y de la\naplicación de las sanciones.\nFinalmente, los resultados\
    \ reportados en esta tesis contribuyen al avance de la ingeniería de\ndatos, no\
    \ sólo al habilitar las capacidades de análisis de datos en los sistemas conscientes\
    \ del\ncontexto, sino también al proporcionar un mecanismo conﬁable para asegurar\
    \ que los datos\ngenerados por esos sistemas puedan ser controlados y monitoreados\
    \ continuamente usando el\nmarco de control de uso de datos propuesto en esta\
    \ tesis.\nContents\nAcknowledgments\nAbstract\nResumen\nList of Illustrations\n\
    List of Tables\nList of Acronyms\n1\nIntroduction\n1\n1.1\nContext and Motivation\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2\n1.2\nObjectives\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\
    4\n1.3\nMethodology and Document Structure . . . . . . . . . . . . . . . . . .\
    \ . . . . .\n4\n1.3.1\nChapter 2: State of the Art . . . . . . . . . . . . . .\
    \ . . . . . . . . . . .\n5\n1.3.2\nChapter 3: Context-aware Systems and Data Analytics\
    \ in Smart Spaces .\n5\n1.3.3\nChapter 4: Data Usage Control for Data Spaces .\
    \ . . . . . . . . . . . . .\n5\n1.3.4\nChapter 5: Validation and Results . . .\
    \ . . . . . . . . . . . . . . . . . .\n5\n1.3.5\nChapter 6: Conclusions . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2\nState of the Art\n7\n\
    2.1\nSmart Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . .\n8\n2.1.1\nIntroduction to Smart Spaces . . . . . . . . . . . .\
    \ . . . . . . . . . . . .\n8\n2.1.2\nInternet of Things (IoT)\n. . . . . . . .\
    \ . . . . . . . . . . . . . . . . . .\n9\n2.1.3\nIoT-Based Smart Spaces . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . .\n11\n2.1.4\nIoT-Based Smart Spaces\
    \ Taxonomy . . . . . . . . . . . . . . . . . . . .\n12\n2.1.5\nSystems of Systems\n\
    . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n2.1.6\nData Space\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n2.2\n\
    Cloud Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . .\n17\n2.2.1\nIntroduction to Cloud Computing\n. . . . . . . . . . . . .\
    \ . . . . . . . .\n17\n2.2.2\nCloud Computing Services . . . . . . . . . . . .\
    \ . . . . . . . . . . . . .\n18\n2.2.3\nCloud Computing Platforms . . . . . .\
    \ . . . . . . . . . . . . . . . . . .\n20\n2.3\nMicroservices . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n25\n2.3.1\nIntroduction\
    \ to Microservices\n. . . . . . . . . . . . . . . . . . . . . . .\n25\n2.3.2\n\
    Microservices Architecture . . . . . . . . . . . . . . . . . . . . . . . . .\n\
    26\n2.4\nBig Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . .\n28\n2.4.1\nIntroduction to Big Data . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . .\n29\n2.4.2\nBig Data Architecture\n. . . . . .\
    \ . . . . . . . . . . . . . . . . . . . . .\n30\n2.4.3\nData Engineering . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n2.5\nContext-Aware\
    \ Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\n\
    2.5.1\nIntroduction to Context-Aware Systems . . . . . . . . . . . . . . . . .\
    \ .\n35\n2.5.2\nContext Information Handling . . . . . . . . . . . . . . . . .\
    \ . . . . . .\n36\nCONTENTS\n2.5.3\nAbstract Architecture of Context-Aware Systems\
    \ . . . . . . . . . . . . .\n36\n2.6\nAccess Control\n. . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . .\n37\n2.6.1\nAccess Control Models\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n2.6.2\nXACML\n. .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n2.7\nUsage\
    \ Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . .\n39\n3\nContext-Aware Systems and Data Analytics for Smart Spaces\n43\n\
    3.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . .\n43\n3.2\nObjectives . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . .\n44\n3.3\nRelated Work . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . .\n44\n3.3.1\nContext-aware\
    \ systems architectures . . . . . . . . . . . . . . . . . . . .\n44\n3.3.2\nImplementations\
    \ of context-aware systems to IoT-based smart environments 45\n3.4\nArchitecture\
    \ Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n47\n\
    3.4.1\nData Standardization . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . .\n47\n3.4.2\nNGSI-LD . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . .\n48\n3.4.3\nArchitecture . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . .\n51\n3.4.4\nMiddleware . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . . . . .\n52\n3.4.5\nApplication Layer\n\
    . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n54\n3.4.6\nSecurity\
    \ layer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n54\n\
    3.5\nImplementation using FIWARE\n. . . . . . . . . . . . . . . . . . . . . .\
    \ . . . .\n54\n3.5.1\nPhysical layer . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . .\n55\n3.5.2\nMiddleware . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . .\n55\n3.5.3\nSecurity . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . .\n57\n3.5.4\nApplication . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n58\n3.6\nApplication\
    \ Scenarios . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\
    59\n3.6.1\nSmart Farm . . . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . .\n59\n3.6.2\nSupermarket purchase prediction . . . . . . . . . . .\
    \ . . . . . . . . . . .\n68\n3.6.3\nData Collection . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . .\n72\n3.7\nConclusions . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n77\n4\nData Usage Control\
    \ for Data Spaces\n79\n4.1\nIntroduction . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . .\n79\n4.2\nObjectives . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n81\n4.3\nRelated Work\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n82\n\
    4.4\nData Usage Control Architecture Design . . . . . . . . . . . . . . . . .\
    \ . . . . .\n87\n4.4.1\nDesign Principles . . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . .\n87\n4.4.2\nAgents involved\n. . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . .\n88\n4.4.3\nArchitecture and Workﬂow . .\
    \ . . . . . . . . . . . . . . . . . . . . . . .\n89\n4.5\nData Usage Control Implementation\
    \ . . . . . . . . . . . . . . . . . . . . . . . .\n90\n4.6\nValidation: A case\
    \ study in the food industry . . . . . . . . . . . . . . . . . . . .\n96\n4.6.1\n\
    Scenario overview\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\
    96\n4.6.2\nPolicy speciﬁcation . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . .\n96\n4.6.3\nData processing and policy enforcement . . . . . . . .\
    \ . . . . . . . . . .\n99\n4.6.4\nResults\n. . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . .\n100\n4.7\nConclusions . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . .\n103\nCONTENTS\n5\nValidation\
    \ and Results\n105\n5.1\nInternational Projects . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . .\n105\n5.1.1\nFIWARE, FICORE and FI-NEXT .\
    \ . . . . . . . . . . . . . . . . . . . .\n105\n5.1.2\nA/RporTWIN . . . . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . .\n106\n5.1.3\nYour Open Data\
    \ YODA\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n106\n5.1.4\nResearch\
    \ Stay FIWARE Foundation . . . . . . . . . . . . . . . . . . . .\n107\n5.2\nDissemination\
    \ of Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n107\n\
    5.2.1\nJournals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . .\n107\n5.2.2\nConference and Workshops\n. . . . . . . . . . . . . . .\
    \ . . . . . . . . .\n108\n5.3\nTeaching and Seminars . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . .\n109\n6\nConclusions and Future Works\n\
    111\n6.1\nConclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . .\n115\n6.2\nFuture Work . . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . .\n116\nBibliography\n119\nCONTENTS\nIllustrations\n\
    2.1\nSmart Space Overview . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . .\n9\n2.2\nIoT-Based Smart Space . . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . .\n13\n2.3\nIoT-Based Smart Space Taxonomy[Ahmed 2016]\
    \ . . . . . . . . . . . . . . . . .\n14\n2.4\nGeneral Representation of Systems\
    \ . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n2.5\nCloud Computing\
    \ Services . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n2.6\n\
    Cloud Computing Types\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . .\n20\n2.7\nIaaS Cloud Providers and Technologies\n. . . . . . . . . . . .\
    \ . . . . . . . . . .\n21\n2.8\nAWS Cloud Stack . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . .\n22\n2.9\nAzure Cloud Stack [Microsoft\
    \ 2019] . . . . . . . . . . . . . . . . . . . . . . . .\n23\n2.10 Google Cloud\
    \ Stack [Carter 2021] . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n\
    2.11 Openstack Cloud Stack [OpenStack 2021] . . . . . . . . . . . . . . . . .\
    \ . . . .\n24\n2.12 Microservices Architecture . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . .\n27\n2.13 Microservices Techonologies Timiline[Jamshidi\
    \ 2018]\n. . . . . . . . . . . . . .\n28\n2.14 Big Data Service Architecture [Wang\
    \ 2020] . . . . . . . . . . . . . . . . . . . .\n31\n2.15 Big Data Tools Architecture\
    \ Representation . . . . . . . . . . . . . . . . . . . .\n33\n2.16 Data Engineering\
    \ Pipeline Example [GoogleCloud 2021] . . . . . . . . . . . . .\n34\n2.17 XACML\
    \ Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\
    39\n2.18 UCON model . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . .\n40\n2.19 Usage Control Overview . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . .\n41\n3.1\nAbstract Architecture for Context-Aware\
    \ Systems . . . . . . . . . . . . . . . . .\n51\n3.2\nArchitecture Implementation\
    \ using FIWARE GE’s\n. . . . . . . . . . . . . . . .\n59\n3.3\nEntities and Relationships\
    \ in FMIS . . . . . . . . . . . . . . . . . . . . . . . . .\n61\n3.4\nGraphical\
    \ overview of the smart farming scenario . . . . . . . . . . . . . . . . .\n64\n\
    3.5\nScenario Workﬂow . . . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . .\n68\n3.6\nGraphical overview of the supermarket scenario . . . . .\
    \ . . . . . . . . . . . . .\n69\n3.7\nTraining Pipeline . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . . . . . . . . . .\n73\n3.8\nPrediction Pipeline\n\
    . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n74\n3.9\nService\
    \ components of purchase prediction system\n. . . . . . . . . . . . . . . .\n\
    74\n3.10 Prediction web application GUI\n. . . . . . . . . . . . . . . . . . .\
    \ . . . . . . .\n75\n3.11 Schema of entities and service subscriptions . . . .\
    \ . . . . . . . . . . . . . . . .\n76\n3.12 Purchase prediction systems workﬂow\
    \ . . . . . . . . . . . . . . . . . . . . . . .\n77\n4.1\nData usage control architecture\
    \ . . . . . . . . . . . . . . . . . . . . . . . . . . .\n90\n4.2\nData usage control\
    \ with three actors architecture . . . . . . . . . . . . . . . . . .\n91\n4.3\n\
    Workﬂow for the DP\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . .\n92\n4.4\nWorkﬂow for the DC . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . . . . . .\n93\n4.5\nData usage control architecture using FIWARE\n\
    . . . . . . . . . . . . . . . . . .\n95\nILLUSTRATIONS\n4.6\nSimpliﬁed Execution\
    \ Graph of Job I . . . . . . . . . . . . . . . . . . . . . . . .\n99\n4.7\nSimpliﬁed\
    \ Execution Graph of Job II\n. . . . . . . . . . . . . . . . . . . . . . .\n100\n\
    4.8\nPolicy A enforcement metrics\n. . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . .\n101\n4.9\nPolicy B enforcement metrics . . . . . . . . . . . . .\
    \ . . . . . . . . . . . . . . .\n102\nTables\n2.1\nMicroservices Technologies\
    \ Classiﬁcation . . . . . . . . . . . . . . . . . . . . .\n29\n3.1\nSummary of\
    \ context-aware applications in smart spaces . . . . . . . . . . . . . .\n47\n\
    3.2\nTraining Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . .\
    \ . . . . . . .\n73\n4.1\nComparison of usage control architectures . . . . .\
    \ . . . . . . . . . . . . . . . .\n86\n4.2\nSummary of enforcement time metrics\
    \ . . . . . . . . . . . . . . . . . . . . . . .\n101\nTABLES\nAcronyms\nAI Artiﬁcial\
    \ Intelligence\nAODV Ad-hoc on-demand distance vector\nAPI Application Programming\
    \ Interfaces\nAWS Amazon Web Services\nCoAP Constrained Application Protocol\n\
    GDPR General Data Protection Regulation\nGE Generic Enabler\nGPS Global Positioning\
    \ System\nIDS International Data Space\nIdP Identity Provider\nIoT Internet of\
    \ Things\nJSON JavaScript Object Notation\nML Machine Learning\nMQTT Message Queuing\
    \ Telemetry Transport\nNGSI Next Generation Service Interfaces\nNGSI-LD Next Generation\
    \ Service Interfaces-Linked Data\nNIST National Institute of Standards and Technology\n\
    OASIS Organization for the Advancement of Structured Information Standards\nODRL\
    \ Open Digital Rights Language\nREST Representational State Transfer\nSE Smart\
    \ Environments\nSoS System of Systems\nSS Smart Space\nUCON Usage Control\nTABLES\n\
    UPM Universidad Politecnica de Madrid\nVM Virtual Machine\nWSN Wireless Sensor\
    \ Network\nXACML eXtensible Access Control Markup Language\nChapter 1\nIntroduction\n\
    Context can be deﬁned by as “any information that can be used to characterize\
    \ the situation of an\nentity where an entity can be a person, place, or object\
    \ that is considered relevant to the interaction\nbetween a user and an application,\
    \ including the user and applications themselves\" [Abowd 1999].\nIn turn, context-aware\
    \ systems are those that can use context for performing intelligent or smart\n\
    actions [Alegre 2016]. Currently, one of the most promising application ﬁelds\
    \ of context-aware\nsystems is that of IoT-based (Internet of Things) smart spaces.\
    \ A smart space is a physical space\nthat relies on technology to connect \"things\"\
    \ to the virtual world, increasing the level of awareness\nof what is occurring\
    \ in physical environments.\nAccording to [Hong 2009], one of the goals of context-aware\
    \ systems is to capture and\nprocess the information in the context of a device\
    \ to provide services built on a particular person,\nplace, time, event. etc.\
    \ Worded differently, context-aware systems capture context, analyze and\ninterpret\
    \ the context, and make adjustments to the system’s behavior for the user’s changing\n\
    situation without explicit intervention from the user.\nThe majority of existing\
    \ works in the ﬁeld of context-aware systems often provide a generic\nhigh-level\
    \ structure of how a system of that kind can be operationalized, but do not offer\
    \ many\nclues on how to implement it. On the other hand, there are many implementations\
    \ of context-aware\nsystems applied to speciﬁc IoT-based smart spaces use cases\
    \ (e.g., smart farming, smart cities).\nHowever, although these implementations\
    \ are context-aware, they are also context-speciﬁc: it is\nnot clear how they\
    \ can be extended to other use cases.\nAdditionally, in recent years, a new business\
    \ paradigm has emerged which revolves around\neffectively extracting value from\
    \ data. In this regard, smart spaces are considered as structures\nthat provide\
    \ trust and security for sharing data between multiple agents or stakeholders.\
    \ This is\nachieved thanks to the homogeneous data sharing by the use of combined\
    \ mechanisms of\ngovernance, legal and technical.\nThese spaces facilitate the\
    \ interoperability for accessing or\ntransferring data and allow the efﬁcient\
    \ and legitimate re-utilization of data in a context of data\nsovereignty and\
    \ control for all the parties over their own data. In this scope, providing a\
    \ secure\necosystem for data sharing that ensures data governance and traceability\
    \ is of paramount\nimportance as it holds the potential to create new applications\
    \ and services. Protecting data goes\nbeyond restricting who can access what resource\
    \ (covered by identity and access control\nrespectively): it becomes necessary\
    \ to control how data are treated once accessed, which is\nknown as data usage\
    \ control.\nData usage control provides a common and trustful security\nframework\
    \ to guarantee the compliance with data governance rules and responsible use of\n\
    INTRODUCTION\norganizations’ data by third-party entities, easing and ensuring\
    \ secure data sharing in ecosystems\nsuch as Smart Cities and Industry 4.0.\n\
    Due to these facts, this thesis provides an architecture and a reference implementation\
    \ that\ncan be used in any context-aware system development of an IoT-based smart\
    \ space. Afterward,\nthe data generated by these systems need to be protected\
    \ in terms of privacy and security. Due to\nthis reason, another contribution\
    \ is covered by this work in terms of providing a data usage control\nsolution\
    \ that can manage all the data generated by the context-aware systems used in\
    \ smart spaces.\n1.1\nContext and Motivation\nIn order to understand the motivation\
    \ for this doctoral thesis and to put all the contributions that\nthis work provides\
    \ in context, it becomes necessary to refer to the beginning of my research career.\n\
    In early 2013, I worked as a researcher at the Escuela Superior Politecnica del\
    \ Litoral (Ecuador),\nwithin the Telematics’ Systems research group. At that time,\
    \ the research lines of this group were\nwireless sensor networks, embedded and\
    \ distributed systems.\nWhen I started to work in this research group, we received\
    \ a grant for building a Smart\nIrrigation System for precision agriculture. In\
    \ this project, I was in charge of designing and\nimplementing an embedded system\
    \ capable of managing the wireless sensor network\ncommunication using the AODV\
    \ (Ad-hoc on-demand distance vector) protocol between multiple\nnodes. These nodes\
    \ were composed of a set of sensors capable of measuring the soil moisture as\n\
    well as the temperature and fertilizer levels.\nThe data gathered by each node\
    \ was sent to a\ngateway that allowed to store it in a cloud infrastructure for\
    \ later use. Also, in this project, I\ndeveloped a web application system to allow\
    \ to perform actions in each of the nodes (actuation),\ne.g., opening a valve.\n\
    This work was disseminated and materialized in the paper \"Ad-hoc\nnetwork implementation\
    \ and experimental testing using low cost and COTS components\"\n[Chavez-Burbano\
    \ 2014] in 2014.\nIt is at this point when I had my ﬁrst contact with the\ntechnologies\
    \ that I used in this thesis.\nAfterward, in 2015, my research group got another\
    \ grant.\nThis time, the topic was the\ndevelopment of Smart Buildings focused\
    \ on ensuring security in case of unforeseen events that\naffect the building\
    \ structure (e.g., ﬁre, ﬂooding, earthquakes, etc). My contribution to this project\n\
    was the design and implementation of a wireless sensor network architecture for\
    \ managing\nemergency responses inside of buildings. In this research, I had to\
    \ work with WSN, distributed\nsystems, and reactive signaling.\nThis work was\
    \ also presented as a journal paper entitled\n\"Adaptive evacuation management\
    \ system based on monitoring techniques\" [Munoz 2015]. At\nthis point, I decided\
    \ to acquire more knowledge about all of these technologies and the advances\n\
    in these topics. Thereby, I decide to start a Master’s Degree at Universidad Politécnica\
    \ de Madrid\nin 2016.\nDuring my master’s degree, I learned more about networking,\
    \ web services, cloud computing,\nbut also about big data and distributed systems.\
    \ With all of this knowledge I could identify a\n2\n1.1. CONTEXT AND MOTIVATION\n\
    set of technologies that can be used for improving the communication models with\
    \ which I had\nbeen working before. Thus, I decide to make my Master’s degree\
    \ thesis about the management of\nemergency systems, this time using big data\
    \ tools for facing the issues that had not been covered by\nthe previous project.\
    \ As a result, I published the paper \"Practical approach of fast-data architecture\n\
    applied to alert generation in emergency evacuation systems\" [Munoz-Arcentales\
    \ 2018] in the\n2018 International Symposium on Networks, Computers, and Communications.\n\
    In the last trimester of 2017, I started my PhD in Telematics Engineering and\
    \ I began to work\nas a researcher for Universidad Politécnica de Madrid in the\
    \ Next Generation Internet Research\nGroup (GING) of the Telematics Engineering\
    \ Department. In this group, I started to work on\nmultiple projects using technologies\
    \ like cloud computing and distributed systems focused on Big\nData applications.\
    \ Working in this group allowed me to identify the potential of Big Data and\n\
    Data Engineering tools for ﬁlling the gaps in the current literature about how\
    \ to manage smart\nspaces. During the subsequent years, I worked with this group\
    \ on many research projects about\ndata persistence models, big data connectors\
    \ and system deployment, building intelligent systems\nbased on machine learning\
    \ models, and AI for smart spaces. However, I noticed that despite\nthe fact that\
    \ the technologies used in these projects solved several of the issues of smart\
    \ spaces,\nthere were still some open challenges that needed to be addressed in\
    \ the ﬁeld. Speciﬁcally, a way\nof managing the whole data life-cycle and of providing\
    \ a structured manner to build and deploy\ncontext-aware systems that enable data\
    \ analytics in smart spaces was an important issue that had\nnot been faced so\
    \ far. Additionally, another key characteristic to consider in smart spaces is\
    \ that\nmultiple actors can be involved in the data-sharing process. Thus, it\
    \ is crucial to guarantee that the\ndata is processed and used according to alignments\
    \ speciﬁed by the owner of the data. Therefore,\nI determined that it was necessary\
    \ to go one step beyond and consider some additional design\nfactors.\nHence,\
    \ in order to investigate how to solve the identiﬁed open issues in context-aware\
    \ smart\nenvironments, I posed the following research questions:\n1. What should\
    \ be the design characteristics of an architecture capable of enabling context-\n\
    aware data analytics in smart spaces?\n2. How can advanced data processing and\
    \ machine learning techniques be integrated into the\naforementioned architecture?\n\
    3. How should an architecture for providing data usage control in smart spaces\
    \ be designed so\nthat it can be used in data sharing ecosystems with multiple\
    \ stakeholders?\n4. How can the implementation feasibility of the proposed data\
    \ usage control architecture be\nveriﬁed?\nThe motivation of this doctoral thesis\
    \ is to give answer to the aforementioned research\nquestions. In the last trimester\
    \ of 2017, I started to work in the research that led me to providing\n3\nINTRODUCTION\n\
    an answer to these questions and, as a consequence, accomplishing the objectives\
    \ that I present in\nthe next section.\n1.2\nObjectives\nThe main objective of\
    \ the study is to contribute to the advancement of data engineering for smart\n\
    spaces through Data Usage Control and Context-Aware Systems.\nIn order to provide\
    \ these\ncontributions, two points of action have been deﬁned. The ﬁrst point\
    \ deals with providing data\nengineering models, techniques, and architectures\
    \ for enabling context-aware data analytics in\nsmart spaces. The second point\
    \ is to identify the challenges and needs for providing data usage\ncontrol over\
    \ data spaces and to propose viable solutions.\nTo fully comply with the main\
    \ objective of this thesis, the following speciﬁc objectives are\nproposed:\n\
    • Deﬁne a conceptual model of context-aware systems adapted to smart spaces -\
    \ This research\nneeds to perform a review of the current solutions of context-aware\
    \ systems and identify\nwhat is the work that needs to be conducted for deﬁning\
    \ an architecture that can be applied\nin smart spaces.\n• Propose an architecture\
    \ and a reference implementation for enabling context-aware data\nanalytics in\
    \ Smart Spaces - This research has to be based on a conceptual architecture for\n\
    building context-aware systems capable of providing data analytics in smart spaces.\n\
    Afterward, a reference implementation needs to be provided in order to validate\
    \ the\nproposal using real use cases.\n• Identify the key characteristics and\
    \ needs of data usage control systems for being\nintroduced and applied in the\
    \ context of data spaces - This study has to be aware of the\nexisting solutions\
    \ for conducting a review of the literature that allows extracting possible\n\
    design references.\n• Propose a design, implementation and validation of an architecture\
    \ for providing data\nusage and access control in data spaces - This proposal\
    \ considers the design principles\nprovided for designing and implementing an\
    \ architecture that enables data usage control\nand its application in Industrial\
    \ Data Spaces.\n1.3\nMethodology and Document Structure\nThe methodological approach\
    \ of this study involves a documentary and experimental section. In\nthe documentary\
    \ part, an exhaustive review of the state of the art is described for each chapter,\n\
    allowing the development of overtures, schemes, and architectures to carry out\
    \ a set of experiments\nthat enable the analysis and validation of the different\
    \ proposals. Experimentally, implementations\n4\n1.3. METHODOLOGY AND DOCUMENT\
    \ STRUCTURE\nfor different environments have been proposed. The systems included\
    \ in these implementations\ngenerate a set of data that is used for training and\
    \ deploying machine learning models. Also, it\nprovides a mechanism for controlling\
    \ the use of the data generated by the systems all encompassed\nin the smart spaces\
    \ ecosystem. Moreover, considering the results obtained in the experiments,\n\
    some outstanding issues that need greater analysis, implementation, and experimentation\
    \ have\nbeen identiﬁed as a future line of research.\nThis document is divided\
    \ into the following sections:\n1.3.1\nChapter 2: State of the Art\nThis chapter\
    \ is intended to provide the context of the current technologies and disciplines\
    \ related\nto the work conducted in this thesis. It includes an overview of the\
    \ current cloud technologies,\nconcepts about context-aware, data spaces, data\
    \ engineering, data access, and usage control\npresenting the key characteristics\
    \ of each of these technologies, and their current state in the\nliterature.\n\
    1.3.2\nChapter 3: Context-aware Systems and Data Analytics in Smart Spaces\nThis\
    \ chapter presents the ﬁrst block of contributions of this thesis: the proposal\
    \ of an architecture\nfor enabling context-aware data analytics in smart spaces.\
    \ For this purpose, I take into account\nthe current solutions available and how\
    \ these can be adapted, implemented, and validated for\ntheir use in the scope\
    \ of smart spaces. In this regard, not only a conceptual model is presented,\n\
    but also an implementation using two use cases. Through this implementation, it\
    \ is possible to\nprovide a direct contribution to data engineering through the\
    \ provision of connectors and models\nfor managing data analytics of context data.\n\
    1.3.3\nChapter 4: Data Usage Control for Data Spaces\nThis chapter presents my\
    \ contributions to the ﬁeld of data usage control, presenting an architecture\n\
    capable of providing data usage control in shared data spaces in which multiple\
    \ stakeholders are\ninvolved. This work provides contributions at the design level,\
    \ implementation level, and semantic\nlevel.\n1.3.4\nChapter 5: Validation and\
    \ Results\nThis chapter presents the validation and results of the proposals presented\
    \ throughout the thesis.\nThis validation encompasses many international projects\
    \ where these contributions have been\nused. Moreover, I provide an overview of\
    \ the different results from the dissemination point of\nview, including the works\
    \ presented in journals and conferences.\n5\nINTRODUCTION\n1.3.5\nChapter 6: Conclusions\n\
    In the ﬁnal chapter of the thesis, I provide a brief overview of the work developed,\
    \ extracting the\nmain conclusions and verifying that all the objectives deﬁned\
    \ at the beginning of this work have\nbeen accomplished. Additionally, I analyze\
    \ the possible lines of research that can be generated\nfrom this thesis.\n6\n\
    Chapter 2\nState of the Art\nThis section presents the concepts and technologies\
    \ directly related to the topics proposed in this\nthesis. This section aims to\
    \ provide the reader with a global perspective of the status of the\ntechnologies\
    \ used in this proposal to understand how the work presented in this document\n\
    contributes to the current state of the art.\nSince all the contributions proposed\
    \ in this thesis are focused on the ﬁeld of application of\nSmart Spaces, I ﬁrst\
    \ present a conceptual review of this type of technological ecosystem, along\n\
    with its most relevant characteristics. As has been stated before, in order to\
    \ take advantage of the\ndata generated by the different data sources that are\
    \ presented in the SS, a robust infrastructure for\nmanaging the different types\
    \ of services is needed. For this reason, it is recommended to deploy all\nof\
    \ these services in a robust and scalable cloud service. Thus, the next technology\
    \ to be analyzed\nis Cloud Computing: I present a general review including the\
    \ concept and the overview of the\ndifferent Cloud Service Providers in all of\
    \ their levels of abstraction.\nIn the introduction of section 1, an overview\
    \ of smart space was presented.\nOne of the\nhighlighted aspects of this type\
    \ of environment was the wide range of services that need to be\ndeployed for\
    \ providing a full interaction among all the systems involved.\nA few years ago,\n\
    deploying this type of service was very costly at the computational level. However,\
    \ nowadays,\nwith the huge contribution of the Microservices technologies, a new,\
    \ scalable, robust, and\nefﬁcient way to manage and interact with a huge amount\
    \ of services is available. Hence, a review\nof the Microservices technologies\
    \ is the next topic that is covered in this Chapter.\nAnother topic that needs\
    \ to be faced in the smart spaces ecosystem is how to handle the vast\namount\
    \ of data generated by multiple sources. Traditional ways of data processing are\
    \ not the\nbest solution in this scenario. Accordingly, in this thesis, I propose\
    \ an architecture based on Big\nData tools for processing and managing the complete\
    \ data cycle. However, this contribution is not\nonly focused on the use of these\
    \ tools but also on how all of these components can be integrated\ninto the SS\
    \ ecosystem to gain knowledge from the analyzed data. This convergence is called\
    \ Data\nEngineering and it is another concept that is described in section 2.4.\n\
    After providing the reader with the necessary context and background about the\
    \ main concepts\nand components involved in smart spaces scenarios, it is turn\
    \ to describe the state of the art and\nrelated work of one of the main contributions\
    \ that this thesis proposes: the development of a\nContext-Aware System for smart\
    \ spaces. Thus, section 2.5 provides a conceptual description and\nrepresentation\
    \ of this type of system for providing all the background needed to understand\
    \ how\nthese systems work.\nSTATE OF THE ART\nFinally, the convergence of all\
    \ of these technologies and the need to provide a full framework\ncapable, not\
    \ only to take advantage of using the data, but also protecting and allowing to\
    \ control\ndata according to the current regulation. This leads to present as\
    \ a contribution the development\nof a fully compatible architecture for providing\
    \ a Data Usage Control framework in smart spaces.\nDue to this fact, in section,\
    \ 2.7 a conceptual review of the concepts of Access Control and Data\nUsage Control\
    \ is conducted.\n2.1\nSmart Spaces\nIn the introduction of this document is stated\
    \ that the main contributions of this thesis are directly\nrelated to the implementation\
    \ of solutions to some issues that need to be addressed in the ﬁeld of\nSmart\
    \ Spaces, due to this reason, in this section I present a conceptual review of\
    \ this concept and\nthe principal characteristics of this type of ecosystem.\n\
    2.1.1\nIntroduction to Smart Spaces\nOne of the ﬁrst concepts of Smart Spaces\
    \ was presented by the National Institute of Standards\nand Technology (NIST)\
    \ [Rosenthal 2000] as work environments with embedded computers,\ninformation\
    \ appliances, and multi-modal sensors allowing people to perform tasks efﬁciently\
    \ by\noffering unprecedented levels of access to information and assistance from\
    \ computer and devices.\nAlso, the smart space support stationary and mobile information\
    \ environments that can be\nconnected to the Internet. Another more informal deﬁnition\
    \ is presented by [Pahl 2016] where\nthey called Smart Spaces to the physical\
    \ space where the Smart Devices are connected and\nworking together and also state.\
    \ Nowadays, in our daily lives connected sensors and IoT devices\nare omnipresent,\
    \ and interacting with people any time and any location. On the other hand,\n\
    [Oliver 2009] and [Cook 2007] states that a smart space also called smart environment,\
    \ can get\nand administer knowledge about its environment and adapt to its inhabitants\
    \ to improve their\nexperience in that environment. Moreover, according to [Balandin\
    \ 2009] the smart space needs\nsoftware that captures and represents all the information\
    \ of the space in programmable entities. A\nstructured way for capturing this\
    \ information is shown in Fig 2.1 in where segmentation of the\nsmart space into\
    \ the following three layers is provided:\n• Physical Space - with sensing devices\
    \ like buildings, vehicles, etc\n• Service Spaces - where all the connectivity,\
    \ information, retrieval, and processing\ncapabilities are placed.\n• User Space\
    \ - whit information about the user, like personal data.\n8\n2.1. SMART SPACES\n\
    Figure 2.1 : Smart Space Overview\n2.1.2\nInternet of Things (IoT)\nThe concept\
    \ of Internet of Things (IoT) was presented for the ﬁrst time by [Ashton 2009]\
    \ in 2009.\nHe explains that the idea of IoT relies on the importance of connecting\
    \ objects and making them\nsmart. According to [Mehmood 2017], IoT is a paradigm\
    \ of communication that has as the main\ngoal to establish an ideal framework\
    \ to connect devices to the Internet, i.e., multiple objects could\nbe interconnected\
    \ between them to build a network in which intercommunicate and execute actions\n\
    intelligently.\nThe practical applications of IoT embrace multiple domains such\
    \ as agriculture, transportation,\neducation, e-Health, among others. Multiple\
    \ applications represent a challenge for both academy\nand industry seeking to\
    \ improve the quality of life through this technology [Gubbi 2013].\nAt present,\
    \ multiple companies and cities use a large amount of data in order to determine\
    \ the\nbest option for statistical analysis and machine learning models.\nDue\
    \ to this fact,\n[Camargo-Vega 2015] concludes that data revolution is now quantiﬁable,\
    \ measurable, and then\ncan be processed and interpreted.\nCommunication Models\n\
    IoT uses communication models for sharing the data between them and establish\
    \ a common\nscheme of connection. Some of the principal communication models are\
    \ the following:\n• MQ Telemetry Transport (MQTT) - It is an OASIS standard protocol\
    \ for publish/subscribe\nmessaging.\nIt is lightweight, open, straightforward,\
    \ and simple to implement.\nThese\n9\nSTATE OF THE ART\ncharacteristics make this\
    \ communication model ideal for being used in (IoT) contexts in\nwhich the device\
    \ has very limited resources [Hunkeler 2008].\n• Constrained Application Protocol\
    \ (CoAP) - It is a protocol that uses the client/server model\nfor communicating\
    \ through the internet using the UDP transport protocol. This model is\noriented\
    \ to limited low-power wireless nodes [Shelby 2014].\n• Common Object Request\
    \ Broker Architecture (CORBA) - It deﬁnes a standard that promotes\nthe development\
    \ of distributed applications in environments with multiple heterogeneous\ndata\
    \ sources [Siegel 2000].\nIoT Architectures\nThis section presents an overview\
    \ of some relevant IoT architectures solutions available at this\nmoment [Rodriguez\
    \ Espinoza 2017, Alberto 2014, Gubbi 2013].\n• SMART-SANTANDER - This proposes\
    \ the use of the smart city infrastructure currently\ndeployed for conducting\
    \ research and deploy new services to the citizens, SMART\nSantander is composed\
    \ of a wide IoT infrastructure at different levels as communication\nprotocols,\
    \ architectures, and IoT services to users [Vakali 2014].\n• SENSEI - It was designed\
    \ for business applications to focus his ﬁeld of action on the\nscalability for\
    \ a large number of devices [Genge 2014].\n• BRIDGE - Provides a solution for\
    \ security and software applications with two main\ninterfaces for queering a\
    \ request and capturing operations. [Uckelmann 2011]\n• CUBIQ - It is a solution\
    \ for data access, processing, and federation in IoT environments.\n[Dempo 2010].\n\
    • Zigbee - It is a commercial wireless technology based on IEEE 802.15.4 standards.\
    \ These\ndevices are designed for connecting things with minimum use of energy\
    \ resources and a low\ndata transmission rate.\n• WirelessHART - It is a wireless\
    \ communication technology based on IEEE 802.15.4. It\nenables secured real-time\
    \ communication with a central management routing the TDM slots\nand networking\
    \ mesh [Chen 2010].\n• Sensinode - It uses 6LoWPAN for providing network-embedded\
    \ software and hardware\nproducts. It is a commercial solution technology for\
    \ business applications.\n• SunSPOT (Sun Small Programmable Object Technology)\
    \ - It is Sun Microsystems platform\nthat allows the developing sensor networks\
    \ and embedded systems. In order to provide that\nfeatures they have created their\
    \ own Java virtual machine named Squawk-VM\n[Castro 2011].\n10\n2.1. SMART SPACES\n\
    The advancement in communication technologies and the rapid adoption of the Internet\
    \ of\nThings have enabled the physical world to invisibly interact with actuators,\
    \ sensors, and other\ncomputational elements while maintaining continuous network\
    \ connectivity. Due to this fact,\nmany research efforts have been conducted for\
    \ integrating a new generation of smart spaces\ncentered in IoT being is known\
    \ as IoT-Based Smart Spaces.\n2.1.3\nIoT-Based Smart Spaces\nCurrently, Smart\
    \ Spaces also called Smart environments to take advantage of the IoT devices by\n\
    extending the capabilities of smart objects by enabling the user to monitor the\
    \ environment from\nremote. IoT can be integrated with different smart spaces\
    \ based on the application requirements.\nAccording to [Ahmed 2016] IoT-Based\
    \ Smart Spaces, can be classiﬁed by the following areas:\nsmart cities, smart\
    \ homes, smart grid, smart buildings, smart transportation, smart health, and\n\
    smart industry. A general picture of this classiﬁcation in showed in Fig 2.2\n\
    • Smart Transportation - One of the most important aspect to consider within Smart\n\
    ecosystems\nis\nmobility,\nwhere,\nthe\nsafety\nand\nefﬁciency\ncan\nbe\nimproved\n\
    [Kyriazis 2013, Janota 2016], quality of life, time, and routes of users within\
    \ cities, e.g. An\nautonomous vehicle can introduce a personal assistant, autonomous\
    \ driving and automatic\nparking, also, by the use of sophisticated sensors, the\
    \ intensity of the lights can be\ncontrolled or [Bodenheimer 2014] even improving\
    \ contaminant emissions like CO2. A\nmore expanded perspective is obtained when\
    \ it is introduce them in an entire city, the\noptimization of vehicle urban routes\
    \ allows to improve trafﬁc efﬁciency for example during\ntrafﬁc congestion hours\
    \ or massive public events.\nEven, can be included in dedicated\nbicycles lanes\
    \ [Barco 2017] contributing to minimizing the use of automobiles and also the\n\
    gases emission.\n• Smart Homes - It is focused on home applications for the digital\
    \ consumer. Some of the\nareas of home automation led IoT enabled connectivity,\
    \ such as lighting control, gardening,\nsafety and security, air quality, water-quality\
    \ monitoring, voice assistants, switches, locks,\nenergy, and water meters.[Verma\
    \ 2016]\n• Smart Cities - The aim is to improve the quality of life and safety\
    \ of citizens\n[Munoz-Arcentales 2017], e.g. Avoiding noise in cities [Montalvo\
    \ 2016], early warning of\nincidents or unexpected events, congestion maps of\
    \ people, and safe areas in case of natural\ndisasters, e.g., earthquakes [Velásquez\
    \ 2017], ﬂoods, volcanic eruptions, and forest ﬁres. It\nis also focused on the\
    \ creation of communities [Colldahl 2013], e.g., smart education uses\nlife-long\
    \ learning programs,\nwhich may focus on employability,\ndigital inclusion\n[Buscher\
    \ 2013], or speciﬁc citizens groups, e.g., elderly or those with physical disabilities.\n\
    Governance is also important in Smart Cities.\nThus, transparency in government\n\
    transactions, efﬁciency in local governments, and prevention of crimes against\
    \ citizens are\n11\nSTATE OF THE ART\nsome of the goals of the Smart Governance\
    \ [Belanche-Gracia 2015, SpliTech 2017]. For\nexample, through the use of open\
    \ data, cities can get immediate information from\ngovernments to prevent fraudulent\
    \ procedures.\nAlso, electronic appointments for\nprocedures in agencies help\
    \ to avoid waiting in long queues for getting that public service.\n• Smart Grid\
    \ the aim is the energy, gas, and light reduction to create and maintain a more\n\
    efﬁcient and sustainable city, e.g. Smart grid applications [Kurt 2017] and distributed\
    \ energy\nstorage.\n• Smart Buildings - The aim is to adopt or improve sustainability\
    \ capabilities to residencies,\nhomes, and commercial buildings, based on energy\
    \ efﬁciency to enhance the quality of life,\ne.g. smart buildings can monitor\
    \ their structural health [Stojkoska 2017], regulate lighting\nand heating based\
    \ on presence detection, and use intelligent appliances to automate\neveryday\
    \ tasks [Bartolli 2011].\n• Smart Health - The aim is to enhance health care systems,\
    \ improving the care of patients in\nterm of efﬁciency and effectiveness in both\
    \ ways manually or remotely [Torres 2017], e.g.,\nThe wearable devices could send\
    \ information from patients with a disease (cardiac\npathology’s, insufﬁciency’s,\
    \ arrhythmia’s, etc.) to real-time monitoring systems, allowing\ndoctors to act\
    \ in the minimum possible time when something unexpected is taking place\n[Narvaez\
    \ 2017].\nAmbulances could send real-time measurements of a patient to be\ntransferred\
    \ to the ER, in consequence when the patient arrives at the hospital, a doctor\
    \ can\nadminister medication for his/her speedy recovery, or even save a life.\
    \ Even, Ambulance\nDrones can be integrated into this ecosystem for being sent\
    \ to remote or difﬁcult access\nareas in optimal times. [Momont 2017].\n• Smart\
    \ Industry - The aim is to provide suitable environments for industries like\n\
    manufacturing or agriculture.\nIt is focused on providing ﬂexibility, optimized\
    \ decision\nmaking, mass customization, and remote monitoring, [Gadgil 2017],\
    \ e.g., in a Smart Farm,\nestablishing remote monitoring zones for plantations,\
    \ robots from collecting and planting\nvegetables, automated processing of products,\
    \ and breeding in closed environments of\nanimals and vegetables.\n2.1.4\nIoT-Based\
    \ Smart Spaces Taxonomy\nThis section describes the taxonomy of IoT-Based Smart\
    \ Spaces classiﬁed by: communication\nenablers, network types, technologies, wireless\
    \ standards, objectives, and characteristics. An\noverview can be seen in Figure\
    \ 2.3.\n• Communication Enablers - Correspond to the wireless technologies for\
    \ connecting the\ndevices across the Internet. The principal mediums of connection\
    \ are WIFI, 3G, 4G, and\nvery recently the 5G.\n12\n2.1. SMART SPACES\nFigure\
    \ 2.2 : IoT-Based Smart Space\n• Network Types - Rely on the different types of\
    \ networks to perform collaborative tasks. The\nmain networks are wireless local\
    \ area networks (WLANs), wireless personal area networks\n(WPANs), wide area networks\
    \ (WANs), metropolitan area networks (MANs), and wireless\nregional area networks\
    \ (WRANs).\n• Technologies - Sensing technologies are used to collect data from\
    \ different data sources and\ntransmit it using communication technologies to\
    \ a central location. The emerging computing\ntechnologies, such as cloud computing\
    \ and fog computing, deployed in the central location\nlet the data fusion technologies\
    \ the task of integrating the data coming from heterogeneous\nresources.\n• Wireless\
    \ Standards - These standard technologies are used inside the smart space to share\n\
    the collected data to the different devices in the ecosystem.\n• Objectives -\
    \ IoT-based smart spaces are deployed to facilitate inhabitants’ lives in different\n\
    situations.\nThus, The objectives must be aligned regarding the requirements and\n\
    functionalities implemented.\nThe principal objectives of these environments are\
    \ cost\n13\nSTATE OF THE ART\nFigure 2.3 : IoT-Based Smart Space Taxonomy[Ahmed\
    \ 2016]\nreduction, utilization improvement, proactive maintenance, and minimal\
    \ user interaction.\n• Characteristics - IoT-based smart spaces have some unique\
    \ features that make them\nvaluable. These characteristics are prediction capabilities,\
    \ newly enhanced services, remote\nmonitoring, and decision-making capabilities.\n\
    Moreover, it can apply data fusion and\nmining techniques to make intelligent\
    \ decisions system with the gathered data from\ndifferent sources.\n2.1.5\nSystems\
    \ of Systems\nNowadays, initiatives such as Smart Cities are displaying how multiple\
    \ systems within the city\nlike transport, health, governance, etc. can work together\
    \ to exploit the potential to optimize the\noperations city. Fig 2.4 shows a general\
    \ overview of the different types of system integration’s,in\nwhere the architecture\
    \ of Smart Solution, Systems of Systems and Data Sharing Ecosystems is\npresented.\n\
    Due to this fact, the integration and collaboration between multiple systems inside\
    \ of a smart\nspace have become a standard requirement. This integration is known\
    \ as System of Systems (SoS)\nand its main goal is to allow the connection of\
    \ systems beyond their organizational boundaries\nlike city, automotive, personal\
    \ data coming from different domains like logistics, manufacturing,\nagriculture\
    \ and allowing their operation over multiple levels like city, building, home,\
    \ an individual\ncustomer.\nAccording to [Maier 1998], the following are the most\
    \ relevant features that describe a SoS:\n• Operational independence - It refers\
    \ that each of the systems that build the SoS can operate\n14\n2.1. SMART SPACES\n\
    Figure 2.4 : General Representation of Systems\nindependently from the SoS and\
    \ other systems.\n• Managerial independence - Each of the systems can be managed\
    \ by different entities.\n• Geographic distribution - It describes how the systems\
    \ are located being this widely spread\nor localized.\n• Evolutionary development\
    \ - It refers to the capability to maintain the consistency in the\ninterfaces\
    \ that are used to communicate systems due to the continuous evolutionary nature\n\
    of the systems.\n• Emergent behavior - It allows identifying each of the SoS changes.\n\
    2.1.6\nData Space\nThe concept of Data Space has emerged to take advantage of\
    \ the incoming phenomena of digital\ntransformation of the real world. This transformation\
    \ turns around the digitization of all the\nsystems and devices that conform to\
    \ a smart space in all of its levels.\n15\nSTATE OF THE ART\nFirst, for deﬁning\
    \ a Data Space is needed to know how a Data Ecosystem is built. A data\necosystem\
    \ can be formed in different manners, focusing on an organization, an activity\n\
    (mobility), a community of interest (music), a geographical location (city), or\
    \ within or across\nindustrial sectors (automotive, manufacturing, pharmaceutical).\
    \ In the context of smart space, the\ndata ecosystem is a deﬁnition that allows\
    \ us to understand the challenges in maximizing the value\nof data within the\
    \ environment [Curry 2018]. One of the main beneﬁts that a smart ecosystem\nprovides\
    \ is the cross-fertilization and data sharing of crucial resources and datasets\
    \ from different\nparticipants promoting new business opportunities and easier\
    \ access to knowledge and data.\nThus, a data space can be deﬁned as a decentralized\
    \ data ecosystem built around commonly\nagreed building blocks enabling an effective\
    \ and trusted sharing of data among participants.\nAdditionally, Smart Spaces\
    \ are considered as structures that provide trust and security for\nsharing data\
    \ between multiple agents or stakeholders.\nThis is achieved thanks to the\nhomogeneous\
    \ data sharing by the use of combined mechanisms of governance, legal and\ntechnical.\
    \ These spaces facilitate the interoperability for accessing or transferring the\
    \ data and\nallow its efﬁcient and legitimate re-utilization in a context of data\
    \ sovereignty and control for all\nthe parties over its owns data. The design\
    \ principles of data spaces are:\n• Data Sovereignty - Regarding data, the concept\
    \ of sovereignty deals with reaching a balance\nbetween the need for protecting\
    \ someone’s data and sharing these data with a third party.\n• Level Playing Field\
    \ - It refers that for all data space participants don’t face insurmountable\n\
    barriers for example avoiding a quasi-monopolistic data ecosystem.\nIt is ruled\
    \ by the\nconcept of cooperation instead of competition. The competence in this\
    \ principle is focused\non the quality of the data and services and not on the\
    \ amount of data that they control.\n• Decentralised soft Infrastructure - It\
    \ refers that data space must include a fully distributed\ninfrastructure for\
    \ providing interoperability, portability, ﬁndability, security, privacy, and\n\
    trustworthiness.\n• Public-private Governance - It foments the conﬁrmation of\
    \ strong governance with a high\nlevel of commitment that allows all the parties\
    \ to feel included and represented\nFrom a technical perspective, several technology\
    \ building blocks are required:\n• Data Interoperability - Data spaces should\
    \ provide a solid framework for an efﬁcient\nexchange of data among participants,\
    \ supporting full decoupling of data providers and\nconsumers.\nThis requires\
    \ the adoption of a “common lingua” every participant uses,\nmaterialized in the\
    \ adoption of common APIs for the data exchange, and the deﬁnition of\ncommon\
    \ data models. Common mechanisms for traceability of data exchange transactions\n\
    and data provenance are also required.\n16\n2.2. CLOUD COMPUTING\n• Data Sovereignty\
    \ and trust - Data spaces should bring technical means for guaranteeing\nthat\
    \ participants in a data space can trust each other and exercise sovereignty over\
    \ the data\nthey share. This requires the adoption of common standards for managing\
    \ the identity of\nparticipants, the veriﬁcation of their truthfulness, and the\
    \ enforcement of policies agreed\nupon in data access and usage control.\n• Data\
    \ value creation - Data spaces should provide support for the creation of multi-sided\n\
    markets where participants can generate value out of sharing data (i.e., creating\
    \ data value\nchains). This requires the adoption of common mechanisms enabling\
    \ the deﬁnition of terms\nand conditions (including pricing) linked to data offerings,\
    \ the publication, and discovery\nof such offerings, and the management of all\
    \ the necessary steps supporting the lifecycle of\ncontracts that are established\
    \ when a given participant acquires the rights to access and use\ndata.\n2.2\n\
    Cloud Computing\nThis section provides a review of the concept of Cloud Computing,\
    \ the key components of this\ntechnology, and also a brief overview of the commercial\
    \ providers and platforms available at the\nmoment.\n2.2.1\nIntroduction to Cloud\
    \ Computing\nAccording to the NIST Deﬁnition of Cloud Computing by [Mell 2011].\
    \ Cloud Computing is a\nmodel that provision ubiquitous, convenient, on-demand\
    \ network access to a shared pool of\nconﬁgurable computing resources, like: networks,\
    \ servers, storage, applications, and services\nwhich can be rapidly provided\
    \ with a minimal service provider or manager intervention. This\nmodel is structured\
    \ by the following ﬁve principal characteristics:\n• On-demand self-service. -\
    \ The users have access to manage the computational resources\nlike CPU, RAM,\
    \ Storage, etc Network according to their needs without the intervention of\n\
    the service provider.\n• Broad network access. - This capabilities are available\
    \ by the network and can be accessed\nby the use of standard mechanisms.\n• Resource\
    \ pooling. - The cloud platform, use a multi-tenant model allowing to provide\
    \ the\nresource provisioning to the different users.\n• Rapid elasticity. - The\
    \ resources can by provisioned and released in an automatic ways\naccording to\
    \ the users needs.\n• Measured service.\n- The resources are automatically monitored\
    \ and reported by\nmeasurement tools.\n17\nSTATE OF THE ART\nOn the other hand,\
    \ [Wang 2010] presents some factors to differentiate the could computing of\n\
    other technologies. They deﬁne ﬁve factors: User Centered Interfaces, On-demand\
    \ provisioning\nresources, Guarantee quality of services, Autonomous systems and\
    \ Adaptability and ﬂexibility to\nthe demand. Additionally, [Linthicum 2009] present\
    \ the relationship between could computing\nand software oriented services. Through\
    \ this relationship they conclude that cloud computing\nis presented as the next\
    \ generation of IT on-demand service and products. Despite each of the\nauthors\
    \ add some contributions to the deﬁnition of cloud computing, it is clearly stated\
    \ that the\nfundamental idea is basically the same.\nThere is no doubt that cloud\
    \ computing provides a huge range of advantages in term of the\nprovision of computational\
    \ resources. In this work a a full description of how it can take advantage\n\
    of cloud computing focused on deploying the services presented in a smart space.\
    \ However, the\ndesign of these type of solution is not trivial and involve another\
    \ additional components that will\nbe presented in the next sections.\n2.2.2\n\
    Cloud Computing Services\nAccording to [Zhang 2010, Hill 2012, Höfer 2011] cloud\
    \ computing services are divide into three\nmain categories in where some speciﬁc\
    \ services are placed. Fig 2.5 the services, the user proﬁle,\nand also the level\
    \ of control for each category.\nFigure 2.5 : Cloud Computing Services\n18\n2.2.\
    \ CLOUD COMPUTING\n• Infrastructure as a Service (IaaS) - IaaS gives users access\
    \ to storage, networking, servers,\nand other computing resources via the cloud.\
    \ At this level, the user is still responsible for\nmanaging their applications,\
    \ data, and computer resources. However, IaaS gives automated\nand scalable environments\
    \ with a high degree of control and ﬂexibility for the user. This\ntype of automation\
    \ and ﬂexibility allows the services hosted in the cloud to manage\ncomplex situations\
    \ like control of workload spikes during busy seasons.\nEven could\ncomputing\
    \ providers are not described yet, I like to list some of the popular IaaS providers\n\
    like Amazon Web Services (AWS), Microsoft Azure, Google Compute Engine (GCE),\
    \ the\nIaaS component of Google Cloud Platform (GCP), and Openstack.\n• Platform\
    \ as a Service (PaaS) - PaaS provides a framework for providing the most efﬁcient\n\
    way to create, customize, and deploy applications. This service layer is primarily\
    \ used by\ndevelopers and operations professionals, currently know as DevOps.\
    \ Usually, the way of\naccess to these resources is through the rent of cloud-based\
    \ platforms for users to develop\nand deliver applications.\n• Software as a Service\
    \ (SaaS) - Nowadays, cloud application services are the well-known\nof the cloud\
    \ service models. Usually, the software is hosted, packaged, and delivered by\
    \ a\nthird party typically on a browser-based interface and all the workload is\
    \ directly managed\nby the cloud service. However, it also allows distributing\
    \ the workload between the cloud\nplatform and the client. In both cases, users\
    \ don’t need to execute all the workload on their\nside. This service offers to\
    \ the enterprises the possibility of ofﬂoad the costs of management\nand maintenance\
    \ to the vendor. A few examples of this type of service are Google Docs,\nOutlook,\
    \ Gmail, SalesForce, etc.\nTo understand not only the services that cloud computing\
    \ offer to the user but also the type of\ncloud computer available, this section\
    \ presents the three main cloud service types (see Fig 2.6):\nprivate, public,\
    \ and hybrid clouds.\nEach of the mentioned options has his advantages and\ndisadvantages\
    \ depending of the type of service that the user or enterprise need to deal with\n\
    [Furht 2010].\n• Private - A private cloud provides IT services for by different\
    \ interfaces like the Internet or a\nprivate network to a very speciﬁc set of\
    \ users, rather than to the general public. This type of\ncloud allows the organization\
    \ the capability of the cloud with a wide range of customization\nand security.\
    \ Private clouds can reside on-site or off-site. The differentiating characteristic\n\
    is that the single private tenant who rules the IT services. Usually, private\
    \ clouds are chased\nby organizations whit high priorities on security and compliance.\n\
    • Public - In a public cloud, all the services and infrastructure are administrated\
    \ off-site over\nthe Internet and shared across multiple tenants. Public clouds\
    \ are run by third parties, and\napplications from different tenants are expected\
    \ to be mixed on the cloud’s servers, storage\n19\nSTATE OF THE ART\nFigure 2.6\
    \ : Cloud Computing Types\nsystems, and networks. One of the most relevant advantages\
    \ of using a public cloud is the\nincreased efﬁciency and posterior cost-effectiveness\
    \ of shared resources. Public clouds are\nconsidered the cheapest solution of\
    \ the three types of cloud computing as well as traditional\non-premise computing\
    \ due to they rely on economies of scale.\n• Hybrid - The combination of both\
    \ private and public cloud elements are known as hybrid\ncloud environments. One\
    \ of the main features of this type of cloud is the independence\nof operation.\
    \ Regardless of how it way of operating, the clouds in a hybrid environment\n\
    permit the portability of data and applications over a secured and encrypted connection.\n\
    This solution is becoming very popular due to it allows organizations greater\
    \ ﬂexibility to\nmeet their IT needs.\n2.2.3\nCloud Computing Platforms\nIn this\
    \ section, a review of the principal features of the providers and cloud computing\
    \ platform is\nconducted. Fig 2.7 presents a picture of the most popular IaaS\
    \ classiﬁed by public cloud and open\nsource technologies.\nAmazon Web Services\
    \ AWS\nAWS is composed of a set of services IaaS and PaaS that nowadays has been\
    \ considered as one of\nthe most used platforms.\nEven, back in 2009 [Reese 2009]\
    \ considered the term \"cloud\n20\n2.2. CLOUD COMPUTING\nFigure 2.7 : IaaS Cloud\
    \ Providers and Technologies\ninfrastructure\" as a synonym of Amazon EC2 and\
    \ Amazon S3 that was the two principal cloud\nservices of that provider by that\
    \ time.\nCurrently, AWS has a full stack of components that\nprovides a wide range\
    \ of services. In Fig 2.8 is showed the AWS global infrastructure grouped by\n\
    levels classiﬁed by Foundation Services, Application Services, and Deployment\
    \ and Monitoring.\nThis division provides a good segmentation of the service that\
    \ each component provides. For\nexample, EC2 is the service in charge of manage\
    \ all the virtual servers that are deployed by the\nusers while S3 is focused\
    \ on providing an external persistence store system as a service and in the\n\
    same way provide load balancer service, network management, and monitoring all\
    \ in the same\nplatform but administered by independent components.\nMicrosoft\
    \ Azure\nAzure is the service for Cloud Computing provided by Microsoft in terms\
    \ of IaaS and PaaS.\nCurrently, it is one of the tops could service providers\
    \ in term of use together with AWS and\n21\nSTATE OF THE ART\nFigure 2.8 : AWS\
    \ Cloud Stack\nGoogle Cloud Platform.\nAs is showed in Fig 2.9 Azure provides\
    \ computation resources,\non-demand storage services in the same way as Amazon\
    \ and also provides a huge range of\ncomponents for managing, storage, data, analytics,\
    \ development tools and manage IoT devices.\nGoogle Cloud Platform\nGoogle Cloud\
    \ Platform (GCP) is the cloud platform that Google provides for its computation\n\
    service. It uses the same infrastructure where it hosted its services like the\
    \ search engine, Gmail,\nYoutube, etc. The service provided by offers also on-demand\
    \ storage, API translate, and his PaaS\nservice Google App Engine.\nIn the same\
    \ way that the most used service providers, google\nprovides some advantages features\
    \ that allow to the user work with complex tasks like\nMicroservices Orchestration\
    \ using Kubernetes, Big Data and Machine Learning, AI, and more. A\ngeneral view\
    \ of the stack of Google Cloud is shown in the Fig 2.10.\nRackspace\nThis platform\
    \ offers the possibility of host virtual machines in a similar way to Amazon EC2,\
    \ and\nalso storage, web services, and cloud infrastructure. The following are\
    \ the most relevant services\nof Rackspace:\n• Cloud Files - It offers Storage\
    \ and Content Delivery Network.\n22\n2.2. CLOUD COMPUTING\nFigure 2.9 : Azure\
    \ Cloud Stack [Microsoft 2019]\nFigure 2.10 : Google Cloud Stack [Carter 2021]\n\
    23\nSTATE OF THE ART\n• Cloud Servers - It provides the cloud computing infrastructure.\n\
    • Cloud Sites - It allows the deployment of featured for web platforms supporting\
    \ multiple\nlanguages like PHP, Python, etc.\nOpen Stack\nOne of the most relevant\
    \ Open Source tools for providing Cloud Computing Services is\nOpenstack. This\
    \ technology was impulsed by Rackspace and currently has an active community\n\
    with thousands of members and sponsor companies. Openstack is more oriented to\
    \ provide IaaS\nand it has sub-projects that are in charge of the speciﬁc task\
    \ inside of the infrastructure. Fig 2.11\nshows the complete view of the component\
    \ of Openstack. However, this document describes only\nthe most relevant components\
    \ for providing a general perspective of these services.\nFigure 2.11 : Openstack\
    \ Cloud Stack [OpenStack 2021]\n• Nova - It is the piece in charge of the computing\
    \ service. Manage the virtual machines,\nsecurity groups, key-pairs, etc.\n• Glance\
    \ - It manage the system images. It is an image repository where new operating\n\
    systems and pre-conﬁgured virtual machines can be uploaded.\n• Cinder - This component\
    \ deals with the virtual data volumes. It provides the capability to\nadd persistence\
    \ to virtual machines.\n• Swift - It is in charge of the management of containers,\
    \ being a separated component from\nthe volumes.\n24\n2.3. MICROSERVICES\n• Neutron\
    \ - It is in charge of the networking operations of the infrastructure like virtual\n\
    networks, routers, sub-networks, etc.\n• Keystone - It is the Identity management\
    \ and a key component of Openstack. Additionally,\nIdentity management also provides\
    \ authentication and authorization capabilities to the\nplatform.\n2.3\nMicroservices\n\
    As was stated before, IoT and cloud computing are enabling technologies in smart\
    \ space. However,\ndue to the nature of the devices and systems presented in this\
    \ type of environment a technology\nstack that allows communicating the services\
    \ between them but keeps their working independence\nhas to be included. The technology\
    \ that promotes these features is called Microservices. In this\nsection, an introduction\
    \ about microservices is presented exploring the concept of this technology\n\
    and also his architecture, patterns, and the most widely adopted open source technologies\
    \ to build,\ndeploy and manage microservices. Finally, an overview of the different\
    \ orchestration systems for\nmicroservices technologies is presented.\n2.3.1\n\
    Introduction to Microservices\nAs is stated by many authors in the current literature,\
    \ Microservices is an architectural style\nadopted from the Software Oriented\
    \ Architectures (SOAs).\nFollowing SOA, a system is\nstructured by small independent\
    \ building blocks (microservices) that have full communication\nbetween them through\
    \ message passing [Lewis 2014, Dragoni 2017]. This concept is extended\nby [Jamshidi\
    \ 2018] where they state that \"Microservices are an architectural approach emerging\n\
    out of service-oriented architecture, emphasizing self-management and lightweightness\
    \ as the\nmeans to improve software agility, scalability, and autonomy\". Worded\
    \ differently, Microservices\nis a software architecture design pattern, where\
    \ large or complex applications are decomposed in\na small, independent process\
    \ using as a communication interface language-agnostic APIs. These\nservices are\
    \ characterized for being small-scale, highly decoupled, and focus on doing a\
    \ tiny task.\nThe principles where the microservices are build was presented by\
    \ [Dragoni 2017] as:\n• Bounded Context - Deﬁned as one of the main points of\
    \ microservices and it is focused\non business capabilities. It principle states\
    \ that related functionalities are combined into a\nsingle business capability,\
    \ being implemented as a service.\n• Size - Size is a key principle of microservices.\
    \ This principle states that if a service is too\nlarge, it must be divided or\
    \ distributed into two or more service if is needed.\n• Independency - This concept\
    \ promotes the decoupling of the service for providing to each of\nthem the operational\
    \ Independence from the other microservices and pushing that the way\nof interoperation\
    \ is over their message interfaces.\n25\nSTATE OF THE ART\nAdditionally, the principal\
    \ system features of microservices are:\n• Flexibility - This feature provides\
    \ the systems support and adaptation of any change that the\nbusinesses need to\
    \ adopt.\n• Modularity - Provides that every system component works independently\
    \ but each of these\ncomponents contributes to the whole system operation.\n•\
    \ Evolution - Stating that the system must be maintainable and support a constant\
    \ evolution\nfro adding new features.\n2.3.2\nMicroservices Architecture\nThe\
    \ best way to describe the microservices architecture is by presenting a good\
    \ example of how a\nservice can be decoupled by a set of microservices. A graphical\
    \ representation of this is shown in\nFig 2.12 on the right side of the picture\
    \ a monolith application is presented. A monolith application\nis described as\
    \ a single piece of software in where all the components of the application such\
    \ as\nuser interface, business logic, and data access are combined into a single\
    \ program. This application\nputs all its functionality into a single process,\
    \ and scale by replicating the monolith on multiple\nservers. On the other hand,\
    \ the left side presents how that monolith can be decoupled in a set\nof microservice\
    \ that even can be replicated in different platforms. A microservice architecture\n\
    puts each element of functionality into a separate service and scales by distributing\
    \ these services\nacross servers.\nMicroservices Patterns\nMany patterns are applied\
    \ to microservices for helping to determine how an application can be\ndecomposed\
    \ into microservices.\nIn this regard, [Richardson 2018] states an overview of\
    \ the\nsuggested patterns to build a microservices application. A brief description\
    \ of the most relevant\npatterns are the following:\n• Decomposition patters -\
    \ It provides some insights into how the system can be segmented\ninto microservices\
    \ and is divided in:\n– Decompose by business capability\n- It deﬁnes services\
    \ that match with business\ncapabilities. A business capability usually is aligned\
    \ to a business object, e.g. Order\nManagement is responsible for orders.\n– Decompose\
    \ by sub-domain - This is focused on the segmentation by Domain-Driven\nDesign\
    \ where each sub-domain corresponds to a different part of the business: Core\n\
    supporting and generic.\n• Database per Service pattern - Deﬁnes that a database\
    \ must be included with each service\nin order to ensure loose coupling.\n26\n\
    2.3. MICROSERVICES\nFigure 2.12 : Microservices Architecture\n• API Gateway pattern\
    \ - Describes the interface of interaction between the clients and\nservices.\n\
    • Client-side Discovery and Server-side Discovery patterns - Deﬁnes how the request\
    \ of a\nclient is routed to an available service.\n• Messaging and Remote Procedure\
    \ Invocation patterns - Describes the two methods that the\nservice used for communication.\n\
    • The Single Service per Host and Multiple Services per Host patterns - Deﬁning\
    \ the\ndeployment strategies.\n• Cross-cutting concerns patterns - It shows how\
    \ the code of the microservice is packaged.\n• Testing patterns: - This describes\
    \ the ways for deﬁning the tests in this architecture.\n• Observability patterns:\
    \ - It deﬁnes all the component for monitoring, it includes: Lo\naggregation,\
    \ application metrics, audit logging, distributed tracking, exception tracking\n\
    health check API, and log deployments and changes.\n27\nSTATE OF THE ART\n• UI\
    \ patterns: - Deﬁnes how the user interface is segment: Server-side page fragment\n\
    composition, Client-side UI composition.\nMicroservices Technologies\nA few years\
    \ ago many technologies have been developed for allowing the use of microservices.\n\
    According to [Jamshidi 2018], since 2008 many technologies have been developed\
    \ and the\ntechnology stack has been continuously increased.\nIn Fig 2.13 the\
    \ evolution and waves that\npromote the development of new solutions for addressing\
    \ challenges microservices are presented.\nThis ﬁgure shows the apparition of\
    \ the ﬁrst lightweight container technologies (for example,\nLXC and Docker) to\
    \ the technologies that manage the most complex tasks like Orchestration\n(Kubernetes)\
    \ Serverless computing (AWS Web Service Lambda), and Service mesh (Istio). The\n\
    classiﬁcation list of these technologies and the link to the documentation is\
    \ provided in Table 2.1\nFigure 2.13 : Microservices Techonologies Timiline[Jamshidi\
    \ 2018]\n2.4\nBig Data\nIn this section, I present a brief review of the concepts\
    \ and characteristics of Big Data and Data\nengineering. These two concepts are\
    \ essential for the purpose of this thesis allowing us to have a\nbetter comprehension\
    \ of the contributions of this work.\n28\n2.4. BIG DATA\nTable 2.1 : Microservices\
    \ Technologies Classiﬁcation\nCategory\nName\nURL\nContainer Engine\nLXC\nhttps://linuxcontainers.org\n\
    Docker\nhttps://www.docker.com\nrkt\nhttps://github.com/rkt/rkt/\nService Discovery\n\
    Zookeeper\nhttps://zookeeper.apache.org\nEureka\nhttps://github.com/Netﬂix/eureka\n\
    etcd\nhttps://etcd.io\nSynapse\nhttps://github.com/airbnb/synapse\nConsul\nhttps://www.consul.io\n\
    Monitoring\nGraphite\nhttps://graphiteapp.org\nInﬂuxDB\nhttps://www.inﬂuxdata.com\n\
    Sensu\nhttps://sensu.io\nCAdvisor\nhttps://github.com/google/cadvisor\nPrometheus\n\
    https://prometheus.io\nGrafana\nhttps://grafana.com\nContainer Orchestation\n\
    Mesos\nhttp://mesos.apache.org\nKubernetes\nhttps://kubernetes.io/\nDocker Swarm\n\
    https://docs.docker.com/engine/swarm\nAmazon Elastic Container\nhttps://aws.amazon.com/es/ecs\n\
    Nomad\nhttps://www.nomadproject.io\nFoul Tolerance\nFinagle\nhttps://github.com/twitter/ﬁnagle\n\
    Hystrix\nhttps://github.com/Netﬂix/Hystrix\nProxigen\nhttps://github.com/facebook/proxygen\n\
    Resilience4j\nhttps://github.com/resilience4j/resilience4j\nContinuos Delivery\n\
    Ansible\nhttps://www.ansible.com\nDrone\nhttps://www.drone.io\nSpinnaker\nhttps://spinnaker.io\n\
    AWS CodePipeLine\nhttps://aws.amazon.com/es/codepipeline/\nChaos Engineering\n\
    Chaos Monkey\nhttps://github.com/Netﬂix/chaosmonkey\nSimian Army\nhttps://github.com/Netﬂix/SimianArmy\n\
    Pumba\nhttps://github.com/alexei-led/pumba\nChaos Toolkit\nhttps://chaostoolkit.org\n\
    2.4.1\nIntroduction to Big Data\nSince 2001, many researchers have pointed the\
    \ challenges and opportunities about the increased\ndata with the 3V model, Volume,\
    \ Velocity, and Variety, which can be considered how the ﬁrst\ndeﬁnition of the\
    \ concept of Big Data [Laney 2001, Zikopoulos 2011, Beyer 2011],. However a\n\
    formal concept was not presented until 2011 in an IDC report in where they deﬁne\
    \ Big data as\n29\nSTATE OF THE ART\n\"big data technologies describe a new generation\
    \ of technologies and architectures, designed to\neconomically extract value from\
    \ very large volumes of a wide variety of data, by enabling the\nhigh-velocity\
    \ capture, discovery, and/or analysis\"[Gantz 2011]. Another deﬁnition that expands\n\
    the previous one was presented by [Wang 2020] a refers to large growing datasets\
    \ build from\nheterogeneous sources and formats: structured, unstructured, and\
    \ semi-structured data in where\nthe traditional technologies, methods, and theories\
    \ can not be used for presenting, processing and\nanalyzing this data. The characteristics\
    \ of Big Data have been evolving from the 3V’s after adding\nValue for building\
    \ the 4V’s and ﬁnally including the Veracity to built the 5V’s that nowadays\n\
    compose the current components of Big Data:\n• Volume - It deﬁnes as a huge amount\
    \ of data. In Big Data volume play’s a key role in\ndetermining the value of the\
    \ data. It is also the property that allows determining if some\nparticular data\
    \ can be considered as Big Data.\n• Velocity - This refers to the speed of the\
    \ data accumulation. In Big Data, many sources\ngenerate a massive and continuous\
    \ ﬂow of data.\n• Variety - It classiﬁes the data by its nature, which could be\
    \ structured like data with ﬁxed\nlength and format, semi-structured like logs,\
    \ and unstructured such as text, pictures, videos,\netc.\n• Veracity - It deals\
    \ with the inconsistency and uncertainty in data, due to the wide data\ndimension\
    \ obtained from multiple disparate data types and sources.\n• Value - It deﬁnes\
    \ the characteristic for extracting valuable information from the data because\n\
    data in itself is not valuable.\n2.4.2\nBig Data Architecture\nAccording to [Wang\
    \ 2020] Big Data service architecture is divided into three layers: Data\nCollecting\
    \ and Storage, Processing and Application Layer each of these layers have a set\
    \ of tools\nfor performing a speciﬁc task inside of the architecture.\nA graphical\
    \ representation of this\narchitecture is shown in Fig 2.14 in where the three\
    \ layers are presented and also the operation\nand component of each layer:\n\
    • Data Collecting and Storage - In this layer, all the operation of Extract, Transform\
    \ and\nLoad (ETL) are performed in order to use and capture the data coming from\
    \ different data\nsources: Batch as Relational and No Relational Databases and\
    \ also streaming data sources\nthought Distributed message systems or Data-ﬂow\
    \ Systems.\n• Processing - It provides the processing capabilities for batch,\
    \ streaming, hybrid, and graph\ndata processing through the Big data processing\
    \ frameworks designed for this purpose,\nincluding also machine learning.\n30\n\
    2.4. BIG DATA\n• Application - It is the layer in where all Big Data applications\
    \ that use the processed data or\nmachine learning models generated by the processing\
    \ layer are placed.\nAdditionally, a transverse layer for providing the infrastructure\
    \ for deploying the Big Data\nservice over the cloud (Saas, PaaS, IaaS) is included.\n\
    Figure 2.14 : Big Data Service Architecture [Wang 2020]\nCurrently, the most used\
    \ tools for each of the aforementioned layers are represented in Fig\n2.15 and\
    \ can be summarized as it follows:\nEvent Streaming and Dataﬂow Systems\nApache\
    \ Kafka gives a scalable, reliable, and durable\nshort-term storage of data, segmented\
    \ into topics (similar to traditional message queues), which\ncan be consumed\
    \ by downstream applications. This data can then be persisted into long-term\n\
    storage using Kafka Connect and consumed by the four streaming engines, Akka Streams,\
    \ Sparki,\nFlinkii, and Kafka Streams, which might write the results to new Kafka\
    \ topics. A way of more\nefﬁcient administration which includes different aspects\
    \ of transmission and reception of data is\nApache Niﬁiii, it supports powerful\
    \ and scalable directed graphs of data routing, transformation,\nand system mediation\
    \ logic. Another tool that provides similar functionality to Kafka but includes\n\
    ihttp://spark.apache.org\niihttps://ﬂink.apache.org/\niiihttps://niﬁ.apache.org/\n\
    31\nSTATE OF THE ART\ncontext management and a standardized way to manage the\
    \ events is called Orion context Broker\n(Orion). Orion GEi manages the entire\
    \ lifecycle of context information including updates, queries,\nregistrations,\
    \ and subscriptions. The Context Broker offers the FIWARE NGSI (Next Generation\n\
    Service Interface) [Open Mobile Alliance 2012] APIs and associated information\
    \ model (entity,\nattribute, metadata) as the main interface for sharing data\
    \ among stakeholders.\nStreaming & Machine Learning\nApache Spark is a widely\
    \ used, highly ﬂexible engine for\nbatch-mode and stream data processing that\
    \ is well suited for scalable performance at high\nvolumes. Spark’s capabilities\
    \ include SQL-based analytics, dataﬂow processing, such as for ETL\n(extract,\
    \ transform, and load), a rich library of built-in machine learning algorithms\
    \ (Spark\nMLlib), and third-party libraries, such as Intel’s BigDL for deep learning.\
    \ Spark’s streaming\nmodel is an average latency ’mini-batch model, where data\
    \ is captured in ﬁxed time windows,\nthen each batch is processed at once. Moreover,\
    \ Spark MLlib provides tools for common learning\nalgorithms (classiﬁcation, regression,\
    \ clustering, and collaborative ﬁltering), feature extraction\n(transformation,\
    \ dimensionality reduction, and selection), and tools for constructing, evaluating,\n\
    and tuning ML pipelines.\nStorage inside Big-Data\nBig Data Platform’s architecture\
    \ con be integrated with various SQL\nand NoSQL databases, distributed ﬁle systems\
    \ such as Hadoop Distributed File System (HDFS),\ncloud-based object stores such\
    \ as AWS S3, and search technologies such as Elasticsearch.\nStorage\nDatabase\
    \ Management Systems (DBMS) are composed by a group of database used in\napplications\
    \ [Vargas 2014] as Relational Database (RDBMS) MySQL, PostgresSQL, Oracle,\netc.,\
    \ No-Relational Database (NoSQL) Mongo, Neo4j, Cassandra, etc. Additionally, new\
    \ DBMSs\nhave been released for generating values, decisions and statistics applied\
    \ to research and\nenterprise such as Elasticsearchii. With the use of Big Data,\
    \ now also logs are another important\nasset that is processed by applications.\
    \ This type of processing the identiﬁcation and resolution of\nmany security and\
    \ ICT failures [Kreps 2014].\n2.4.3\nData Engineering\nNowadays, it is very well\
    \ known that data is considered a very valuable asset. Technologies\nlike IoT,\
    \ Big Data, Cloud Computing, and Microservices have become in a complete stack\
    \ for\ngenerating, processing, and deploying many applications that use data as\
    \ a core component. Since\niFIWARE Orion:https://ﬁware-orion.readthedocs.io\n\
    iiwww.elastic.co/\n32\n2.4. BIG DATA\nFigure 2.15 : Big Data Tools Architecture\
    \ Representation\nevery one of these systems also generates new data and it is\
    \ an asset that is ﬂowing every day and\nevery moment, a new concept called Data\
    \ Engineering has emerged.\nData engineering is considered as a subdiscipline\
    \ of Big Data that focuses speciﬁcally on the\ntransportation, transformation,\
    \ and storage of the data. The main goal of Data Engineering is to\nenable organized,\
    \ consistent data ﬂow to provides data-driven work like Training machine learning\n\
    models, doing exploratory data analysis, and populate the ﬁeld in an application\
    \ outside the data\n[Stratis 2021].\nThis data ﬂow can be achieved by different\
    \ methods, and speciﬁc tools, techniques, and skills.\nOne of the key patterns\
    \ that data engineering introduces is the Data Pipeline. This is a system that\n\
    consists of independent programs that do various operations on incoming or collected\
    \ data. The\nprocess of pipeline creation is not trivial in most cases due to\
    \ the nature of the big data system it can\ninvolve 10 to 30 different Big Data\
    \ technologies working together. This leads the responsibilities\n33\nSTATE OF\
    \ THE ART\nto the optimal tool selection to the Data engineers which are who possess\
    \ the knowledge for\nunderstanding the various technologies and frameworks in-depth,\
    \ and how to combine them to\ncreate solutions to enable a company’s business\
    \ processes with data pipelines [Furbush 2018].\nFigure 2.16 : Data Engineering\
    \ Pipeline Example [GoogleCloud 2021]\nMoreover, Data engineering is focused on\
    \ the production readiness of that data and all that\ncomes with it: formats,\
    \ scaling, resilience, security, and more. The principal areas where data\nengineering\
    \ is focused are:\n• Data Flow - It refers to the building of the complete pipeline\
    \ for designing a system that\ncan take this data as input from one or many sources,\
    \ transform it, and then store it for their\ncustomers. Worded differently, This\
    \ is focused on the ETL process.\n• Data Normalization and Modelling - This part\
    \ of the process is focused on normalizing the\ndata to make the data more accessible\
    \ to the users. It involves: removes duplications, ﬁx\nconﬂicting data, and conforming\
    \ data to a speciﬁc data model. This process includes the\nnormalization and standardization\
    \ of the data sources and storing the normalized data in a\ndatabase system. Data\
    \ normalization and modelling are usually part of the transform step\nof ETL,\
    \ but they’re not the only ones in this category. Another common transformative\
    \ step\nis data cleaning.\n34\n2.5. CONTEXT-AWARE SYSTEMS\n• Data Cleaning - This\
    \ works together with the Data Normalization process But while data\nnormalization\
    \ is mostly focused on making disparate data conform to some data model, data\n\
    cleaning includes several actions that make the data more uniform and complete.\n\
    • Data Accessibility - This refers to how clear is the data available for the\
    \ customers, it does\nnot involve too many operations like the previous ones but\
    \ deﬁnes how the pipeline should\nbe deﬁned according to the customers like Data\
    \ Scientist, Analytic teams, or product teams.\nDue to data accessibility is closely\
    \ tied to how data is stored, it’s a major component of the\nload step of ETL,\
    \ which refers to how data is stored for later use.\nOn the other hand, Data engineering\
    \ is focused on some areas that involve knowledge in\nGeneral Programming concepts,\
    \ Databases, Big data, Microservices, distributed systems, and\ncloud computing.\
    \ All of these technologies involved allow us to build very complex tasks. One\n\
    example of that is shown in Fig 2.16 in where a pipeline for deﬁning a Machine\
    \ learning process\nfor data collection, processing, machine learning, and system\
    \ application is displayed.\n2.5\nContext-Aware Systems\nIn this section, I present\
    \ a review of the concept of Context-Aware systems pointing out the key\ncharacteristics,\
    \ architecture, and how these types of systems have been integrated with the\n\
    previously mentioned technologies: IoT, Could Computing and Big Data in order\
    \ to present a\nnew generation of Context-Aware Systems centered in IoT. This\
    \ overview provides a strong\nbackground for understanding one of the main contributions\
    \ of this thesis, the design and\nimplementation of Big Data Framework for Context-Aware\
    \ Systems in Smart Spaces.\n2.5.1\nIntroduction to Context-Aware Systems\nIn order\
    \ to provide an accurate concept about Context-Aware Systems, ﬁrst is needed to\
    \ understand\nthe concept of Context. Context is deﬁned by [Abowd 1999] \"any\
    \ information that can be used\nto characterize the situation of an entity where\
    \ an entity can be a person, place, or object that is\nconsidered relevant to\
    \ the interaction between a user and an application, including the user and\n\
    applications themselves\". The same author also deﬁnes a Context-Aware System\
    \ as the system\nthat uses context to provide relevant information or services\
    \ depending on the user tasks. Other\ndescriptions available in the literature\
    \ point that Context-Aware Systems are systems that can use\ncontext for performing\
    \ intelligent or smart actions [Alegre 2016]. According to [Hong 2009] one\nof\
    \ the goals of the Context-Aware Systems is to capture and process the information\
    \ in the context\nof a device to provide services build on a particular people,\
    \ place, time, event. etc. Worded\ndifferently Context-aware systems capture context,\
    \ analyze and interpret the context, and make\nadjustments to the system behavior\
    \ for the user’s changing situation without explicit intervention\nfrom the user.\n\
    35\nSTATE OF THE ART\n2.5.2\nContext Information Handling\nA good structure of\
    \ how context-awareness can be enable was presented by [Alegre 2016] where\nthey\
    \ state that Context-Aware systems need to separate the process of how the context\
    \ is captured\nfrom how it is used. This approach allows applications to be able\
    \ to use contextual information\nwithout concerning the speciﬁc details of devices\
    \ or how it was implemented. A lot of literature\nis available about the techniques\
    \ for context information management [Perera 2013] these\nresearches permit to\
    \ build a reference for deﬁning the life cycle of context information presenting\n\
    the following requirements:\n• Acquisition - It reefers to the operations that\
    \ need to be included for gathering the context\ninformation. This is not a trivial\
    \ phase, because, information comes from multiple devices\nand systems making\
    \ imperative the need to build and provide scalable systems that not only\ncapture\
    \ these data but also that have the capability to avoid overlapping contradictory\
    \ or\nmissing data.\n• Modelling - The next phase after capturing the information\
    \ is modelling. This phase is\nwhere the information is translated into usable\
    \ values through the use of real-world concepts\nin modelling constructs. These\
    \ models require to represent any kind of information into\nentities and relations,\
    \ providing uniquely contextual information, context, and entities.\n• Reasoning\
    \ - Using the modeled data, this phase is in where different type of conclusions\n\
    can be obtained or inferred. This process usually is conformed by three stages:\
    \ Context pre-\nprocessing, for cleaning the data to get rid of the non-desirable\
    \ values. Device data fusion\nis where the data from multiple data sources is\
    \ combined from producing more accurate\ninformation, and Context Inference, from\
    \ low-level information to high level one, IN this\nphase is where different techniques\
    \ like fuzzy logic, rule bases reasoning, machine learning\nare applicable.\n\
    • Dissemination - Finally, this phase is in where all the information is distributed\
    \ to the\nconsumer considering both the low level and high level. One of the most\
    \ desirable features\nis that the context information could be distributed in\
    \ real-time.\nMoreover, security and privacy concerns need to be addressed due\
    \ to the proper nature of\ncontext information to provide the right balance between\
    \ privacy and system potential.\n2.5.3\nAbstract Architecture of Context-Aware\
    \ Systems\nOne architecture proposal for Context-Aware Systems was stated by [Baldauf\
    \ 2007] they\npresented a conceptual framework segmented by ﬁve layers:\nsensors,\
    \ raw data retrieval,\npre-processing, storage and management, and application.\n\
    On the other hand, [Hong 2009]\npresents an abstract architecture of this type\
    \ of system based on a review of the literature\n36\n2.6. ACCESS CONTROL\navailable\
    \ at that moment. That proposal of four layers architecture was presented involving\
    \ the\nfollowing layers: Network, Middleware, Application, and User Infrastructure.\
    \ The second of that\nproposals show a better way for representing these systems.\
    \ However, these proposals still lack\ncovering the integration of new devices\
    \ like IoT and also security aspects. A more recent study\nwas conducted by [Symeonaki\
    \ 2020] in where they were focused on providing a context-aware\nmiddleware cloud\
    \ approach for integrating precision farming facilities into the IoT toward\n\
    agriculture 4.0.\nThis proposal also presented the conceptual architecture of\
    \ Context-Aware\nSystems divided into three layers: Physical Layer, Middleware\
    \ layer, and Application layer.\nDespite the last architecture shows a good level\
    \ of abstraction of the conceptual model, this\nproposal was presented for a scenario\
    \ Precision Farming leading its application only to that speciﬁc\nﬁeld.\n• Physical\
    \ Interface - This ﬁrst layer corresponds to the interface for managing the different\n\
    data sources that not only cover the physical devices like, sensors, actuators,\
    \ IoT devices, etc\nbut also the data generated by other systems like AI and web\
    \ applications, REST systems,\netc.\n• Middleware - The second layer named middleware\
    \ is composed of two segments for one\nside the Context Management which provides\
    \ the Context-Aware services involved in the\nacquisition storage and manipulation\
    \ of the context data and for the other side is also\nincluded the Context processing\
    \ that is in were is placed all the components in charge of\nproviding all the\
    \ Big Data processing and machine learning capabilities for managing the\ndata\
    \ coming from the different sources and as a result being capable of providing\
    \ the\nknowledge discovery phase.\n• Application - The application layer is which\
    \ provides the interface to the applications and\nservices that it can be provided\
    \ to the different users and entities depending on the ﬁeld of\noperation.\n•\
    \ Security - Finally, a transverse layer is included to provide security at authentication\
    \ and\nauthorization level for the whole components that are part of the context-aware\
    \ systems\ncovering and protecting the three previously mentioned layers.\n2.6\n\
    Access Control\nAccess Control (AC) refers to a technique that determines who\
    \ a user is and what are the\noperation that the users are allowed to do over\
    \ some determining system or resource\n[Sandhu 1994]. Access Control allows that\
    \ authorized users have access to determined resources\nand ensure that those\
    \ authorized users are not banned from such access [Yuan 2005]. The ﬂow of\nthe\
    \ processes involved in access control is deﬁned by the following sequence and\
    \ operations:\nIdentiﬁcation, Authentication, and Authorization.\nTraditionally,\
    \ larger systems security was\n37\nSTATE OF THE ART\nsimpliﬁed by the use of Role-Based\
    \ Access Control (RBAC), a policy mechanism deﬁned around\nroles and privileges.\
    \ This approach improves the scalability of other models like Identity-Based\n\
    Access Control (IBAC) which is based on the authenticated identity of an individual\n\
    [Coyne 1996]. Another method of AC is Attribute-Based Access Control (ABAC) this\
    \ model\nsolves the issue of managing a high number of rules through the generation\
    \ of dynamic access\npolicies.\n2.6.1\nAccess Control Models\nCurrently, there\
    \ are a considerable number of access control models. This review is it showed\
    \ a\nbrief description of the most used access control model: Role-Based Access\
    \ Control (RBAC) and\nAttribute-Based Access Control (ABAC):\n• Role-Based Access\
    \ Control (RBAC) - Due to its simplicity this model is used for a huge\nnumber\
    \ of applications. This model turns all of his features over the concept of a\
    \ role. A\nrole a set of permissions over speciﬁc resources. Permissions grant\
    \ or restrict what the user\ncan access.\n• Attribute-Based Access Control (ABAC)\
    \ - In contrast to RBAC, ABAC deﬁnes the operations\nover resource attributes\
    \ and environment attributes instead of roles. Due to this reason, the\nABAC model\
    \ allows the deﬁnition of more ﬁne-grained permissions over resources but is\n\
    needed to consider that this can increase the complexity at the time of deﬁning\
    \ rules and\npermissions.\n2.6.2\nXACML\nThe models commented in the previous\
    \ section allow conceptualizing how to perform access\ncontrol. However, they\
    \ do not specify a software architecture or a policy language to accomplish\n\
    that mission. The principal standard for deﬁning and enforcing access control\
    \ policies is the one\ncreated\nby\nOASIS:\nXACML\n(eXtensible\nAccess\nControl\n\
    Markup\nLanguage)\n[OASIS Standard 1994].\nThis standard mainly implements ABAC\
    \ or RBAC access control\nmodels. However, it can be extended or modiﬁed to provide\
    \ other models, such as UCON, as\nchapter 4.2 shows.\nThe XACML standard provides\
    \ the language for deﬁning the policies based on the XML\nmarkup language. The\
    \ language allows creating policies as a set of rules, including targets and\n\
    conditions. It also provides the architecture for enforcing the rules. Fig 2.17\
    \ broadly describes the\nprincipal elements and how they interact.\n38\n2.7. USAGE\
    \ CONTROL\nFigure 2.17 : XACML Architecture\n• Policy Administration Point (PAP)\
    \ - This provides the capabilities for creating and managing\nthe XACML policies.\
    \ Also, it provides an interface for being used by the PDP.\n• Policy Enforcement\
    \ Point (PEP) - This component is in charge of enforces the decisions\nprovided\
    \ by the PDP including grant or deny access to a speciﬁc resource.\n• Policy Decision\
    \ Point (PDP) - It evaluates access requests against authorization policies\n\
    before issuing access decisions.\n• Policy Information Point (PIP) - This is the\
    \ system entity that acts as a source of information\nand interacts with the resource,\
    \ subject, and environment.\n2.7\nUsage Control\nIn the scope of Usage Control,\
    \ the Usage Control model (UCON) stated by Sandhu and Park\n[Sandhu 2003] was\
    \ presented as a new framework for providing not only traditional data Access\n\
    Control but also enabling the control of the data during and after the usage.\
    \ The UCON model\nextends the traditional Access Control models, not only by introducing\
    \ new concepts of mutability\napplicable to attributes of subjects and objects\
    \ but also by providing a new way of guaranteeing\nthe continuity of policy enforcement.\
    \ Moreover, UCON presents a family of ABC models built\naround three decision\
    \ factors: authorizations (A), obligations (B) and conditions (C), which can all\n\
    be used for pre-decision and ongoing decisions. As a complementary part of the\
    \ conceptualization\nof UCON, one of the formal model proposals of policies aligned\
    \ with Usage Control is presented\nby [Bettini 2003], in which they attach two\
    \ sets of predicates, namely provisions and obligations.\n• Provisions - These\
    \ are concerned with the pre decision phase (past and present),\ncorresponding\
    \ to the traditional Access Control.\n39\nSTATE OF THE ART\n• Obligations - These\
    \ deal with the rules applied to the future use of data and are related\nto the\
    \ ongoing decision phase which, instead, is executed after the access is initiated\
    \ and\nimplements the continuity of control over the data.\nFig 2.18 shows in\
    \ a) graphical representation of UCON model and b) the provisions and\nobligations\
    \ in a timeline.\nFigure 2.18 : UCON model\nUsage control is a promising approach\
    \ for access control in open, distributed, heterogeneous\nand network-connected\
    \ computer environments. It encompasses and enhances traditional access\ncontrol\
    \ models, Trust Management (TM) and Digital Rights Management (DRM), and its main\n\
    novelties are mutability of attributes and continuity of access decision evaluation.\
    \ Usage control\nencompasses Data Access control and Data Usage Control. A good\
    \ representation of this concepts\nis shown in the Figure 2.19:\n40\n2.7. USAGE\
    \ CONTROL\nFigure 2.19 : Usage Control Overview\n• Data Access Control:\n– Speciﬁes\
    \ who can access what resource.\n– Also the rights to access it (actions).\n•\
    \ Data Usage Control:\n– Ensures data sovereignty.\n– Regulates what is allowed\
    \ to happen with data (future use).\n– Related with data ingestion and processing.\n\
    – Context of intellectual property protection, privacy protection, compliance\
    \ with\nregulations and digital rights management.\n41\nSTATE OF THE ART\n42\n\
    Chapter 3\nContext-Aware Systems and Data Analytics for Smart Spaces\n3.1\nIntroduction\n\
    As I stated in the introduction of chapter 1 at this time, one of the most promising\
    \ application\nﬁelds of context-aware systems is that of IoT-based (Internet of\
    \ Things) smart spaces, and further\nof IoT devices, IoT-based smart spaces include\
    \ software platforms and services, artiﬁcial\nintelligence (AI), machine learning\
    \ (ML), big data, cloud computing, heterogeneous connectivity,\nvirtual/mixed\
    \ realities, and a huge range of technologies to improve people’s quality of life,\
    \ to\ndecrease environmental impact, and to optimize the use of physical resources\
    \ [Alberti 2019].\nSince context-aware systems may include data from multiple\
    \ sources and, at the same time, a\nsingle data source may be used for multiple\
    \ applications, they need to separate the process of\nhow the context is captured\
    \ from how it is used, as pointed out by [Alegre 2016]. By so doing,\napplications\
    \ may use contextual information without accounting for the speciﬁc details of\
    \ devices\nor how they have been implemented. This is of special relevance in\
    \ IoT-based smart spaces.\nMoreover, context-aware systems need to consider the\
    \ security and privacy aspects of data,\nproviding the right balance between privacy\
    \ and system potential. A number of prior works have\nprovided frameworks and\
    \ architectures for designing context-aware systems. However a huge\nnumber of\
    \ the existing works often provide a generic high-level structure of how a context-aware\n\
    system can be operationalized, but do not offer many clues on how to implement\
    \ it. On the other\nhand, there are many implementations of context-aware systems\
    \ applied to speciﬁc IoT-based\nsmart spaces use cases (e.g., smart farming, smart\
    \ cities).\nHowever, although these\nimplementations are context-aware, they are\
    \ also context-speciﬁc: it is not clear how they can be\nextended to other use\
    \ cases.\nIn this chapter, I provide an architecture and a reference implementation\
    \ that can be used in\nany context-aware system development of an IoT-based smart\
    \ space. For that purpose, I rely on the\nbuilding blocks of the FIWARE ecosystem,\
    \ providing an agnostic end-to-end solution that takes\ninto consideration the\
    \ complete data lifecycle, ﬁlling the existing gap in the literature. In other\n\
    words, the architecture can be readily operationalized in any IoT-based smart\
    \ space regardless of\nits ﬁeld of application, providing a context-aware solution\
    \ that is not context-speciﬁc. I provide\ntwo sample application scenarios that\
    \ showcase how this proposal can be used in a variety of ﬁelds,\ncovering from\
    \ data acquisition and modelling, to data reasoning and dissemination.\nThe remaining\
    \ of the chapter is structured as follows. Next section shows the objectives and\n\
    research questions of this thesis covered by this chapter. Section 3.3 presents\
    \ the related work on\ncontext-aware systems and their speciﬁc application to\
    \ IoT-based smart spaces.\nSection 3.4\nCONTEXT-AWARE SYSTEMS AND DATA ANALYTICS\
    \ FOR SMART SPACES\npresents an overview of the conceptual representation of the\
    \ architecture and the description of\neach of its layers.\nSection 3.5 shows\
    \ the implementation of the previous architecture using\nFIWARE GE’s including\
    \ the data modelling and the building blocks. Section 3.6 describes two\nexample\
    \ application scenarios in which the posed implementation has been operationalized.\n\
    Lastly, Section 3.7 presents the conclusions of the chapter and proposes some\
    \ lines of future\nwork.\n3.2\nObjectives\nThe two objectives of this chapter\
    \ are:\n1. Deﬁne a conceptual model of context-aware systems adapted to smart\
    \ spaces\n2. Propose an architecture and a reference implementation for enabling\
    \ context-aware data\nanalytics in Smart Spaces\nIn this chapter, I provide a\
    \ conceptual architecture and its posterior implementation that can\nbe used in\
    \ any context-aware system development of an IoT-based smart space. For that purpose,\
    \ I\nrely on the building blocks of the FIWARE ecosystem, providing an agnostic\
    \ end-to-end solution\nthat takes into consideration the complete data lifecycle,\
    \ ﬁlling the existing gap in the literature.\nThis chapter also covers the following\
    \ research questions:\n• What should be the design characteristics of an architecture\
    \ capable of enabling context-\naware data analytics in smart spaces?\n• How can\
    \ advanced data processing and machine learning techniques be integrated into\
    \ the\naforementioned architecture?\nThese questions are answered based on the\
    \ results of the implementation and the use cases\npresented.\n3.3\nRelated Work\n\
    3.3.1\nContext-aware systems architectures\nResearchers have diverging opinions\
    \ when it comes to how to structure a context-aware system.\nIn the work by [Baldauf\
    \ 2007], the authors presented a conceptual framework for context-aware\nsystems\
    \ segmented into ﬁve layers: sensors, raw data retrieval, pre-processing, storage\
    \ and\nmanagement, and application. Not long after, the authors of [Hong 2009]\
    \ presented an abstract\narchitecture for context-aware systems based on a thorough\
    \ review of the literature, in which four\nlayers were included: network, middleware,\
    \ application, and user infrastructure. Although the\nlatter proposal shows a\
    \ more generalizable way of representing context-aware systems, both of\nthem\
    \ fail to cover the integration of new devices like IoT and to take into consideration\
    \ the\n44\n3.3. RELATED WORK\nsecurity aspects.\nA more recent study by [Symeonaki\
    \ 2020] presented a context-aware\nmiddleware cloud approach for integrating precision\
    \ farming facilities into the IoT toward\nagriculture 4.0.\nThis proposal also\
    \ presented the conceptual architecture of context-aware\nsystems divided into\
    \ three layers:\nphysical layer, middleware layer, and application layer.\nAlthough\
    \ this last proposal shows a higher level of abstraction of the conceptual model,\
    \ it was\ncontextualized in the ﬁeld of Precision Farming and its operationalization\
    \ was limited only to that\nscenario.\nAlthough the number of layers in which\
    \ context-aware architectures are segmented differs\nacross the literature, most\
    \ of them share the same key elements combined in different\nconﬁgurations. For\
    \ example, in the works mentioned above, the sensors and raw data retrieval\n\
    layers proposed by [Baldauf 2007] are equivalent to the network layer proposed\
    \ by [Hong 2009]\nand to the physical layer described in [Symeonaki 2020].\nRegardless\
    \ of how the different\nelements in the architecture are organized, a crucial\
    \ aspect to take into account is data\nstandardization, which provides an effective\
    \ communication mechanism between the different\nlayers and also with the outside\
    \ or complementary systems.\n3.3.2\nImplementations of context-aware systems to\
    \ IoT-based smart environments\nA burgeoning number of implementations of context-aware\
    \ IoT-based smart environments have\nbeen developed in the last decades. In the\
    \ case of Smart Transportation, proposals like Taxi-aware\nmap [Phithakkitnukoon\
    \ 2010] present the development of context-aware systems for identifying\nand\
    \ predicting vacant taxis in the city, based on three parameters: time of the\
    \ day, day, and weather\nconditions. These systems use contextual information\
    \ provided by a historical record of data stored\nin a database, for building\
    \ an inference engine, using a naive Bayesian classiﬁer to make the\npredictions.\
    \ For building the predictor, a dataset with GPS traces of 150 taxis in Lisbon-Portugal\n\
    was used. As a result, they provide a system able to predict the number of vacant\
    \ taxis in a 1x1 km2\narea with a 0.8% error rate. Additionally, the authors of\
    \ [Dobre 2014] present a platform designed\nto automate the process of collecting\
    \ and aggregating context information at a large scale. They\nintegrate services\
    \ for collecting context data like location, users’ proﬁle and environmental and\n\
    validate that platform through the implementation of an intelligent transportation\
    \ system to assist\nusers and city ofﬁcials better understand trafﬁc problems\
    \ in large cities. They use domain-speciﬁc\nontologies to describe events, dates,\
    \ locations, user activities, and relations with other people and\nobjects. Also,\
    \ a set of XML-based format rules are deﬁned for triggering a series of actions\
    \ when\ncertain conditions are met. The most recent work was provided in [Liu\
    \ 2020]. In this article, a\nrecommendation system that offers multi-modal transportation\
    \ planning and is adaptive to various\nsituational contexts is presented. They\
    \ use multi-source urban context data as an input to deﬁne\ntwo recommendation\
    \ models using gradient boosting decision tree and deep learning algorithms\n\
    for building multi-modal and uni-modal transportation routes. They conclude that\
    \ their extensive\nevaluations on real-world datasets validate the effectiveness\
    \ and efﬁciency of that proposal.\n45\nCONTEXT-AWARE SYSTEMS AND DATA ANALYTICS\
    \ FOR SMART SPACES\nAlthough the previous works present suitable proposals of\
    \ context-aware systems in the ﬁeld of\nsmart transportation, they also provide\
    \ some insights into the challenges that need to be addressed.\nScalability is\
    \ one of the most relevant concerns expressed in those articles. The need to provide\n\
    ways to not only capture context but also processing it efﬁciently must be considered.\
    \ Another\nimportant challenge identiﬁes is the need of unifying the way to capture\
    \ and store the data, every\nof the presented proposal uses its methods and structure\
    \ for dealing with this topic, as a result,\nmany compatibility issues can be\
    \ derived from this in case that many systems need to share data\nor coordinate\
    \ between them.\nMoreover, context-aware systems have been operationalized in\
    \ the development of smart\nhomes and smart buildings. The authors of [Najem 2017]\
    \ presented a context-aware wireless\nsensors system for IoT-centric energy-efﬁcient\
    \ campuses. They used context-based reasoning\nmodels for deﬁning transition rules\
    \ and triggering to reduce the energy consumption on a\nuniversity campus. Another\
    \ study [Hangli 2018] described a proposal for creating an elevator\nsystem in\
    \ smart buildings capable of reducing the passenger waiting time by preregistering\n\
    elevator calls using context information. This system captures the context data\
    \ of the location of\nthe passenger and based on a 3D localization model makes\
    \ automatic preregistration to the\nelevator considering the distance between\
    \ the passenger and the elevator. These two proposals\nare only two examples of\
    \ how context-aware systems play a key role in any space considered\nsmart. However,\
    \ these two proposals present some ﬂaws in terms of how heterogeneous and\nunstructured\
    \ data are managed.\nOne of the most widespread uses of context-aware systems\
    \ is in Smart Industry, speciﬁcally\nin Smart Farming. In [Dobrescu 2019], the\
    \ authors present a context-aware platform serving as\nmiddleware mechanism for\
    \ interfacing environmental sensors with IoT and Cloud for providing\nreal-time\
    \ process control agriculture application.\nTo achieve that goal, they combine\
    \ many\nsoftware platforms and tools, such as IBM Bluemix IoT form managing the\
    \ IoT data, a Java\napplication form data acquisition and storing in the cloud,\
    \ and a C# application for handling\nstored data. One of the most novel approaches\
    \ was presented in [Symeonaki 2020], in which a\ncomplete framework is proposed\
    \ including a middleware service that acts as a decision support\nsystem for the\
    \ entire framework. Moreover, several reviews of the IoT technologies used in\n\
    agriculture\nhave\nbeen\nperformed\nin\nthe\nlast\nfew\nyears\n[Gómez-Chabla 2019,\
    \ Khanna 2019, Symeonaki 2019, Madushanki 2019].\nThese reviews\nconcluded that,\
    \ despite the fact that IoT technologies are continuously advancing and promoting\n\
    the creation of novel agricultural applications and services, some critical issues\
    \ concerning the\ninteroperability as well as the semantic annotation of heterogeneous\
    \ data need to be addressed.\nTo that end, in recent years, many efforts have\
    \ been developed not only for providing semantic\nand interoperability within\
    \ this type of environment but also for including the data models,\nuniﬁed standards,\
    \ vocabularies, connectors, and platforms.\nMany of these efforts have been\n\
    materialized\nas\ndifferent\nproposals\nfor\ndifferent\napplication\nscenarios\n\
    [Martinez 2016,\n46\n3.4. ARCHITECTURE OVERVIEW\nAlonso 2018, Kamienski 2019,\
    \ Zyrianoff 2020, Muñoz 2020, López-Morales 2020]. All of these\nworks have one\
    \ thing in common, they consider the use of FIWARE as an enabler open-source\n\
    platform for providing context management, storage, data analytics, and security\
    \ for each of their\nservices.\nTable 3.1 : Summary of context-aware applications\
    \ in smart spaces\nReferences\nField\nContext Data\nContext Processing\nIdentiﬁed\
    \ Issues\nPlatform\n[Phithakkitnukoon 2010]\nSmart\nTransportation\nTime day\n\
    Day\nWeather\nNaive Bayesian\nclassiﬁer\nScalability\nAd-hoc\n[Dobre 2014]\nDates\n\
    Location\nUser activities\nContext\nontology,\nXML rules\nScalability\nAd-hoc\n\
    [Liu 2020]\nUser location,\nVehicle data,\nUrban Data\nGradient boosting\nDecision\
    \ tree\nDeep learning\nScalability\nAd-hoc\n[Najem 2017]\nSmart Buildings\nTemperature\n\
    Room\nUser location\nRule based\nthreshold\nNot address\nheterogenous data\nAd-hoc\n\
    [Hangli 2018]\nElevator position\nUser location\nGraph based\nrules\nNot address\n\
    heterogenous data\nScalability\nAd-hoc\n[Dobrescu 2019]\nSmart Farming\nTemperature\n\
    Humidity\nRule Based\nclassiﬁers\nNot address\nheterogenous data\nScalability\n\
    IBM Bluemix\nfor IoT\n[Symeonaki 2020]\nTemperature\nHumiditySoil\nMoisture\n\
    Rule Based\nclassiﬁers\nML Algorithms\nNot address\nheterogenous data\nScalability\n\
    Cloud-Based\n[Martinez 2016, Alonso 2018, Kamienski 2019, Muñoz 2020]\nTemperature\n\
    Humidity\nSoil Moisture\nWeather\nRule Based\nclassiﬁers\nML Algorithms\nOutdated\n\
    standard version\nCloud Based\nFIWARE\n3.4\nArchitecture Overview\nIn this section,\
    \ I present a conceptual overview of the proposed architecture.\nThe complete\n\
    architecture turns around NGSI-LD as enabling standard for proving data harmonization,\n\
    contextual acquisition, storage, reasoning, representation, and systems integration\
    \ in smart\nspaces. I state an overview of NGSI-LD key aspects. Afterward, I describe\
    \ Smart data models as\na reference data structure for managing NGSI-LD representation\
    \ of contextual data. With all of\nthis background in the following subsections,\
    \ I present the conceptual view of the proposed\narchitecture providing a description\
    \ of every layer stating all of the services and systems that each\nof them provides\
    \ to the whole architecture.\nFinally, a materialization of the conceptual\narchitecture\
    \ is presented using FIWARE generic enablers and big data open-source tools for\n\
    providing a standardized and interoperable context-aware system in smart spaces.\n\
    3.4.1\nData Standardization\nModelling data is a key aspect for building context-aware\
    \ systems. This phase is required because\ndeﬁning predeﬁned data models allows\
    \ to merge data, which may come from different origins, in a\n47\nCONTEXT-AWARE\
    \ SYSTEMS AND DATA ANALYTICS FOR SMART SPACES\nunique and understandable format;\
    \ and it eases the integration with other external systems. When\nmodelling data,\
    \ there are two main alternatives: (1) developing a new data model for each context\n\
    entity, or (2) modelling the data using data models widely extended in the industry.\
    \ The second\noption is preferable because it eases the integration with external\
    \ systems, and it is less error-\nprone as these data models are, in most cases,\
    \ developed by standards organizations and validated\nby the developers community.\
    \ In this section, I propose the NGSI-LD standard for modelling the\ndata in this\
    \ reference implementation. I further propose using available smart data models\
    \ to ease\ninteroperability with other systems existing in the industry.\n3.4.2\n\
    NGSI-LD\nThe Next Generation Service Interfaces-Linked Data (NGSI-LD) API (Application\
    \ Programming\nInterfaces) is an evolution of the NGSI interface for managing\
    \ context information following the\nprinciples of linked data. It was standardized\
    \ by ETSI (European Telecommunications Standards\nInstitute) with the aim of integrating\
    \ the NGSI entities in the semantic web. The API deﬁnes a set\nof HTTP methods\
    \ for creating, reading, updating, and deleting entities.\nIn NGSIv2, context\
    \ information is modelled as a set of entities (i.e., a representation of a real\n\
    object). An entity is determined generically by its type (e.g., Building) and\
    \ speciﬁcally by its\nidentiﬁer (e.g., Building:1). The state of the entity is\
    \ modelled with attributes which include the\nname of the attribute (e.g., height),\
    \ the type (e.g., Integer), and the value (e.g., 30). Lastly, the\nattributes\
    \ can be enhanced with metadata, including again its name (e.g., unitCode), type\
    \ (e.g.,\nString), and value (e.g., FOOT). Consequently, it resulted in a rigid\
    \ model, difﬁcult to integrate\nwith external systems with their own deﬁnition\
    \ of each entity (e.g., Building2).\nIn contrast,\nNGSI-LD was developed to increase\
    \ interoperability and enable to build a graph of knowledge\nthrough the establishment\
    \ of relationships. In the NGSI-LD case, the center piece of context\ninformation\
    \ is again the entity, which is deﬁned by its type (e.g., Building) and its identiﬁer\
    \ (e.g.,\nurn:ngsi-ld:Building1). The difference from NGSIv2 is that both the\
    \ identiﬁer and the entity type\nare identiﬁed unequivocally by URIs. In NGSI-LD,\
    \ there are not attributes: instead, there are\nproperties (e.g.,\nheight with\
    \ value 30) and relationships (e.g.,\nhasParking with value\nurn:ngsi-ld:Parking1),\
    \ deﬁned with URIs too. In the case of NGSI-LD there are no metadata for\nproperties,\
    \ but instead there can be properties of properties, relationships of properties,\
    \ properties\nof relationships, and relationships of relationships. Based on a\
    \ set of entities, along with their\nproperties and relationships, an RDF graph\
    \ can be established composed by triples in the form of:\n<subject (URI or blank\
    \ node)> <predicate (URI)> <object (URI,\nliteral, or blank node)>\nwith the following\
    \ possible structures:\n<entity> <property> <value>;\n<entity> <relationship>\
    \ <entity>;\nand the mentioned variants:\n48\n3.4. ARCHITECTURE OVERVIEW\n<property>\
    \ <property> <value>;\n<property> <relationship> <entity>;\n<relationship> <property>\
    \ <value>;\n<relationship> <relationship> <entity>.\nSmart Data Models\nThe FIWARE\
    \ Smart Data models i is an initiative that aims to integrate reference data models\n\
    with the NGSI-LD API. As I mentioned above, the NGSI-LD API is agnostic to its\
    \ domain of\napplication, in other words, it provides the mechanisms to access\
    \ context information but it does\nnot deﬁnes how the context information is modelled.\
    \ This initiative is impulsed by the FIWARE\nFoundation ii in collaboration with\
    \ other institutions as TM Forum iii, IUDX iv, or OASC v. All\nthe data models\
    \ are public and they grant the adopters adopters the rights All the data models\
    \ are\npublic and they grant the adopters the rights of free using, free modifying,\
    \ and free sharing the\nmodiﬁcations. Multiple institutions are participating\
    \ in this initiative both publishing new data\nmodels (e.g., Atos vi, Telefónica\
    \ vii, Universidad Politécnica de Madrid viii), and validating them\nthrough their\
    \ adoption in real projects (e.g., KWR Water Research Institue ix, Métropole Nice\n\
    Côte d’Azur x, National Technical University of Athens xi). Smart data models\
    \ are compliant with\nboth NGSIv2 and NGSI-LD, coded in JSON and JSON-LD, respectively.\
    \ The structure of the data\nmodels is hierarchical, divided into three levels:\n\
    • Data Model - It is the lowest level.\nA data model is deﬁned by its schema which\n\
    determines the structure of its NGSI properties and relationships. The schema\
    \ is coded\nwith the JSON Schema vocabulary xii which allows to ensure if the\
    \ payload ﬁts the model\ndeﬁnition. This JSON Schema enables to set restrictions\
    \ on the data types of properties and\nrelationships, and determine the list of\
    \ properties and relationships which are compulsory.\nA data model deﬁnition is\
    \ completed with other documents which include examples of\niFIWARE Smart Data\
    \ models: https://smartdatamodels.org/\niiThe FIWARE Foundation: https://www.ﬁware.org/\n\
    iiiTM Forum: https://tmforum.org\nivIndia Urban Data Exchange: https://iudx.org.in/\n\
    vOpen & Agile Smart Cities: https://oascities.org/\nviAtos: https://atos.net/\n\
    viiTelefónica: https://www.telefonica.com/\nviiihttps://www.upm.es/\nixKWR Water\
    \ Research Institue: https://www.kwrwater.nl/\nxMétropole Nice Côte d’Azur: https://www.nicecotedazur.org/\n\
    xiNational Technical University of Athens: https://www.ntua.gr/\nxiiJSON Schema\
    \ vocabulary: https://json-schema.org/\n49\nCONTEXT-AWARE SYSTEMS AND DATA ANALYTICS\
    \ FOR SMART SPACES\npayloads, speciﬁcations in different languages, swagger speciﬁcation\
    \ documents for an\ninteractive API REST documentation, etc.\n• Subject - It is\
    \ the container for one or more data models offering the possibility to deﬁne\
    \ a\ncommon schema for all of them.\n• Domain - It is the highest level, it is\
    \ an umbrella for subjects divided by sectors. Examples\nof domains are Smart\
    \ Energy Smart Aeronautics, or Smart Water. A subject could belong at\nthe same\
    \ time to one or more domains.\nAt this time, more than 550 data models have been\
    \ deﬁned spread over more than 40 different\nsubjects which compound 11 domains\
    \ (e.g., Smart Cities, Smart Energy, Smart AgriFood, Smart\nAeronautics). All\
    \ data models are published on GitHub i. Every domain has a repository with\n\
    pointers to its subjects, and every subject has a repository with its data models\
    \ deﬁnition. There\nare three special repositories: data-models ii, incubated\
    \ iii, and harmonization iv. The ﬁrst, includes\ntemplates for how to build a\
    \ new data model; the second, data models under development; and the\nthird, data\
    \ models that have to be updated. All data models follow the same life-cycle which\
    \ is\ncomposed by three states:\n• Incubation - If it does not exist a smart data\
    \ model that represents an entity, it should be\ncreated.\nThere are two possibilities\
    \ offered to the developers, (1) work on their own\nrepository, or (2) ask for\
    \ permission to work in the ofﬁcial incubated repository.\nThe\nsecond option\
    \ is recommended by the community because it enhances collaboration. At\nthis\
    \ point, the developers have to write the schema and examples of payloads in different\n\
    formats (JSON for NGSIv2, and JSON-LD for NGSI-LD). For these tasks, the initiative\n\
    provides a set of tools that help developers to write and validate the schema,\
    \ and to create\nand validate payloads compliant with the schema deﬁnition. From\
    \ this information, other\ndocuments are generated automatically (speciﬁcations,\
    \ license, swagger ﬁles, etc.).\n• Harmonization - A data model relies on this\
    \ state when it has been approved but it has to be\ncompleted or curated.\n• Ofﬁcial\
    \ publication - The process of publication of a new data model depends on the\n\
    existence or not of the subject and the domain which the data model belongs. If\
    \ both exist,\nthe contributor can make a pull request directly to the ofﬁcial\
    \ subject repository. In other\ncases, a new subject and/or domain has to be created\
    \ in the incubation repository before\npublishing. When a data model is published,\
    \ it is considered an ofﬁcial smart data model\niSmart Data Models GitHub organization:\
    \ https://github.com/smart-data-models\niiSmart Data Models data-models repository\
    \ https://github.com/smart-data-models/data-models\niiiSmart Data Models incubated\
    \ repository: https://github.com/smart-data-models/incubated\nivSmart Data Models\
    \ harmonization repository: https://github.com/smart-data-models/harmonization\n\
    50\n3.4. ARCHITECTURE OVERVIEW\nand can be used by all the community. Lastly,\
    \ the authorship of contributors and adopters\nare included.\n3.4.3\nArchitecture\n\
    As discussed in section 3.3 context-aware systems usually present an architecture\
    \ divided into a\nfew layers. Depending on the ﬁeld of application these layers\
    \ can be expanded or redistributed.\nHowever, in the case of smart spaces, a wide\
    \ range of data sources and systems are involved, even\none of the problems that\
    \ are currently presented in this type of ecosystems is the need of managing\n\
    the vast amount of data that is generated at every moment. Thus, I consider that\
    \ a fully compatible\narchitecture for managing context-aware systems in a smart\
    \ space not only needs to include context\nmanaging but also the big data components\
    \ for processing it. In this thesis, I propose a four layers\narchitecture that\
    \ covers the whole context data life-cycle in smart spaces. Fig 3.1 shows the\
    \ general\narchitecture proposed which is divided into physical, middleware, application,\
    \ and security layer.\nFigure 3.1 : Abstract Architecture for Context-Aware Systems\n\
    Physical layer\nData sources in smart spaces are heterogeneous by nature.\nThus,\
    \ accounting for this\ncharacteristic is a central part of the architecture of\
    \ smart spaces.\nThe physical layer in the\narchitecture provides all the tasks\
    \ related to collecting data from heterogeneous sources. On the\none hand, this\
    \ layer includes common IoT, wired and wireless sensors and actuators, that often\n\
    use well-deﬁned communication interfaces and protocols like MQTT, COAP, OMA-LWM2M,\n\
    OneM2M, etc. On the other hand, systems that generate data in a structured and\
    \ unstructured\nway are also included in this layer. Examples of such systems\
    \ are log servers, web applications,\nREST services, information systems, and\
    \ databases. These sources of information have another\nparticularity: they share\
    \ data using multiple communication protocols. For example, data can be\nshared\
    \ through transport messages via TCP/UDP or retrieved by querying a database.\
    \ Collecting\ndata is not the only process that needs to be performed over the\
    \ data sources. However, the\n51\nCONTEXT-AWARE SYSTEMS AND DATA ANALYTICS FOR\
    \ SMART SPACES\nphysical layer is only in charge of providing communication mechanisms\
    \ for capturing the data.\nIn turn, all the aspects of data transformation, standardization,\
    \ and cleaning are performed in the\nmiddleware layer.\n3.4.4\nMiddleware\nThe\
    \ middleware layer provides all the operations needed for managing the complete\
    \ context life-\ncycle after its collection. First, the raw data coming from the\
    \ physical layer needs to be pre-\nprocessed so it can be accessed by the rest\
    \ of the components of the architecture in a uniﬁed way\nas well as further processed\
    \ if complex operations on the data are needed.\nPreprocessing\nData coming from\
    \ the physical layer can be real-time data (streaming) or static data (batch).\
    \ The\nway in which each of these data types is handled is different. In the case\
    \ of streaming data,\naccounting for its instability is crucial. Moreover, this\
    \ type of data is usually structured in small\nchunks. Therefore, raw data can\
    \ be deleted after preprocessing, without the need to store the\ncomplete original\
    \ dataset. In the case of batch data processing, the regular ETL (Extract Transform\n\
    and Load) procedure can be applied. For example, when retrieving data from a database,\
    \ the ﬁrst\nstep is to deﬁne the extraction mechanism (polling, programmed, incremental,\
    \ etc). Then, a data\nﬁltering and cleaning process for discarding duplicates,\
    \ redundant, and erroneous data should\nbe applied. Finally, the data must be\
    \ sent to the correspondent recipient system. Regardless of\nthe nature of the\
    \ data, it is necessary to provide a way to facilitate the deﬁnition and capture\n\
    of the context. This can be achieved through standardization of the data to a\
    \ common format\nand structure. To facilitate this process, I take advantage of\
    \ a data-ﬂow management system like\nApache NiFii which is capable of capturing\
    \ and processing raw data from streaming, batch, and\nheterogeneous data sources,\
    \ as well as of transforming this data to the NGSI-LD format through\ndifferent\
    \ processors. At this point, data is ready to be used by the next component of\
    \ this layer:\nthe Context Management\nContext Management\nAccording to [Sezer\
    \ 2017], context life-cycle refers to how data are gathered, modeled,\nprocessed,\
    \ and how knowledge is deduced from the captured data. In this regard, the context\n\
    management component is where all the logic for representing the context is deﬁned.\
    \ There are\nmany\ntechniques\navailable\nfor\ndata\nmodelling,\ne.g.,\nlogic-based,\n\
    markup,\nkey-value,\nobject-oriented, graphical and ontology-based are available[Al-Shdifat\
    \ 2018]. In this proposal,\nthe ontology-based modelling technique was selected,\
    \ taking advantage of the wide set of smart\niApache NiFi: https://nifi.apache.org\n\
    52\n3.4. ARCHITECTURE OVERVIEW\ndata models currently available. These data models\
    \ allow deﬁning multiple entities and attributes\nwith a common structure for\
    \ multiple application domains as was stated in subsection 3.4.2. The\ncontext\
    \ management component is also responsible for providing an interface to access\
    \ the\nmodeled context data, acting as a context broker between the physical layer\
    \ and the application\nlayer through a publish/subscribe mechanism.\nThis system\
    \ allows to retrieve the context\ninformation previously modeled using two different\
    \ approaches, querying and subscribing.\nQuerying allows to access the current\
    \ context information available. In turn, subscribing allows\nto receive notiﬁcations\
    \ when context information changes. Ontology-based reasoning capabilities\nare\
    \ introduced in this component, which allow to deﬁne rules to notify of context\
    \ changes only\nwhen some special behavior is reached. For example, a system can\
    \ subscribe to changes in Entity\n\"A\" if the attribute b is greater than 10.\
    \ If that condition is not met, a notiﬁcation will not be sent\neven if the value\
    \ of b changes in any other way.\nContext storage is also an aspect to consider\
    \ in context management. The context broker only\nstores the latest context information\
    \ available.\nThus, another component needs to provide\nconnections to multiple\
    \ storage systems, capable to store the context data in relational and\nnon-relational,\
    \ graph, cloud-oriented or distributed databases. By so doing, it is possible\
    \ to keep\ntrack of the evolution of context data. It is important to remark that\
    \ data standardization is also\napplicable to the storage of context data. This\
    \ process is also achieved through the NGSI-LD\nstandard that deﬁnes guidelines\
    \ like name conventions, for tables databases, tables, and column\nattributes\
    \ mapping some encoding parameters for saving context data in different storage\n\
    systems.\nAlthough context management provides some basic reasoning functionalities\
    \ using\ncontext, in a wide range of applications more complex tasks need to be\
    \ performed, e.g, complex\nevent processing and machine learning. As such, in\
    \ this proposal, the component of context\nprocessing is introduced for extending\
    \ the features that context management provides.\nContext Processing\nThe context\
    \ processing component is introduced to handle the processing of large amounts\
    \ of\ncontext data coming from smart environments.\nAs was stated before, smart\
    \ environments\ngenerate high volumes of data with high velocity. Thus, traditional\
    \ methods for data processing\nin which this process is done by a single computing\
    \ instance is not sufﬁcient.\nInstead, it is\nnecessary to distribute or parallelize\
    \ the processing jobs.\nHence, in the context processing\ncomponent of this proposal,\
    \ the processing capabilities rely on well know big data processing\nengines.\
    \ A processing engine is a software system in charge of performing operations\
    \ on data. It\nusually consists of a series of computing nodes that implement\
    \ some clustering technology for\nparallelizing operations in order to process\
    \ data at a large scale. Some of the most well-known\ntechnologies for this purpose\
    \ are Apache Sparki and Apache Flinkii. These technologies offer a\niApache Spark:\
    \ https://spark.apache.org\niiApache Flink: https://flink.apache.org\n53\nCONTEXT-AWARE\
    \ SYSTEMS AND DATA ANALYTICS FOR SMART SPACES\nprogramming interface that facilitates\
    \ the task of performing transformations on data. Both of\nthem provide a wide\
    \ assortment of resources and libraries for processing data both in streaming\n\
    and batch modes, such as complex event processing and machine learning. For example,\
    \ Spark\noffers the MLLib library which provides a set of resources and algorithms\
    \ that can be used for\nbuilding, e.g., recommendation systems, predictors, classiﬁcation\
    \ systems, deep learning and\nmore.\n3.4.5\nApplication Layer\nThe application\
    \ layer includes the components that provide high-level services. It serves as\
    \ an\ninterface between the user and the middleware layer to provide different\
    \ solutions that need to be\ndeveloped for each application ﬁeld. These can be\
    \ provided as generic Software as a Services\n(SaaS) solutions or a speciﬁc development\
    \ can be created ad-hoc. From a functional point of\nview, some examples of services\
    \ included in the application layer could be dashboard views,\nartiﬁcial intelligence\
    \ systems, advanced analytic, real-time monitoring, data sharing, etc. The\ndata\
    \ that is needed to operationalize these systems can be retrieved from the middleware\
    \ layer,\neither directly through the context management component or through\
    \ the context processing\ncomponent if complex and costly transformations are\
    \ necessary before the data can be consumed\nby the applications.\n3.4.6\nSecurity\
    \ layer\nEnsuring security and privacy is essential in any context-aware system\
    \ due to the own nature of\nthe data generated and collected[Li 2015]. This becomes\
    \ more important when such systems\ncollect information from smart environments\
    \ like Smart Heath, where security and privacy play a\nkey role. In this proposal,\
    \ a security layer has been included for securing the data exchange\nbetween all\
    \ of the components of the architecture. The security aspects of authentication\
    \ and\nauthorization are provided by an access control mechanism based on the\
    \ XACML reference\narchitecture [OASIS Standard 1994].\nI consider a combination\
    \ of Attribute-Based Access\nControl (ABAC) and Role-Based Access Control (RBAC)\
    \ [Sandhu 1996, Yuan 2005] to control\nthe access of users, groups, or applications\
    \ to individual contextual data based on their level of\nprivacy.\n3.5\nImplementation\
    \ using FIWARE\nIn this section, I present the complete reference implementation\
    \ based on the architecture detailed\nin section 3.4 (Fig 3.2). The implementation\
    \ relies on the building blocks of FIWARE, which\nare called Generic Enablers\
    \ (GEs). Each GE is responsible for providing a speciﬁc feature that is\nnecessary\
    \ for handling data in smart environments. They can be easily conﬁgured for a\
    \ speciﬁc\nsetting without the need to develop ad-hoc software components. Moreover,\
    \ the NGSI standard,\n54\n3.5. IMPLEMENTATION USING FIWARE\ndescribed in section\
    \ 3.4.1 is the ofﬁcial format supported by all the GEs, easing communication\n\
    among each one of them.\n3.5.1\nPhysical layer\nIn this section, I describe the\
    \ GEs that are used for providing an interface to interact with IoT\ndevices,\
    \ wireless sensor networks and other third party systems .\n• IoT Agent GE i -\
    \ It is a set of software modules handling South IoT Speciﬁc protocols and\nNorth\
    \ OMA NGSI interaction. These agents allow working with the IoT devices that use\n\
    communication\nprotocols\nlike\nLWM2M\nover\nCoaP,\nJSON,\nor\nUltraLight\nover\n\
    HTTP/MQTT, OPC-UA, Sigfox, or LoRaWAN. By using this component, the IoT devices\n\
    will be represented in a FIWARE platform as NGSI entities in a Context Broker.\n\
    Additionally, the IoT agents GE allows to trigger commands to actuation devices\
    \ just by\nupdating speciﬁc command-related attributes in their NGSI entities\
    \ representation at the\nContext Broker.\nAdditionally, another set of incubating\
    \ GE’s are provided for allowing to manage other devices\nor systems that are\
    \ not considered by IoT Agents. This component allows the interaction with a\n\
    wide range of devices and systems providing full integration in smart spaces.\
    \ The following list\npresents some of these GE’s and its description:\n• Fast\
    \ DDSii - It is an incubated Generic Enabler that has been adopted as default\
    \ middleware\nin ROS2iii, the widely known Robot Operating System, therefore it\
    \ helps to interface with\nROS2-based robotics systems.\n• OpenMTC\niv - The OpenMTC\
    \ Incubated Generic Enabler brings an open-source\nimplementation of the OneM2M\
    \ standard.\n• Micro-XRCE-DDS v - It is a GE that provides a lite version of the\
    \ DDS middleware,\nadapted to run in extremely constrained resource devices (e.g.\
    \ micro-controllers).\n3.5.2\nMiddleware\nIn this subsection are shown all GE’s\
    \ that take care of the data operations performed in the\nMiddleware layer.\n\
    iIoT Agents: https://github.com/FIWARE/catalogue/blob/master/iot-agents/README.md\n\
    iiFast DDS: https://github.com/eProsima/Fast-RTPS\niiiROS: https://docs.ros.org/en/foxy/\n\
    ivOpenMTC: https://ﬁware-openmtc.readthedocs.io/\nvhttps://github.com/eProsima/Micro-XRCE-DDS\n\
    55\nCONTEXT-AWARE SYSTEMS AND DATA ANALYTICS FOR SMART SPACES\nContext Management\n\
    Context Management is the central piece of the whole architecture. It handles\
    \ the whole context\nlifecycle, providing a standard way to manage, store, and\
    \ model the context. As stated in section\n3.4.4 a piece of software that provides\
    \ these capabilities is known as a Context Broker. In this\nregard, FIWARE has\
    \ a set of GEs that provide context management capabilities using NGSI-LD\nas\
    \ standard. The following is a list of the implementations currently available:\
    \ Orion-LD Context\nBroker, Scorpio Broker, and Stellio Context Broker. This reference\
    \ implementation is based on the\nOrion-LD Context Broker, which is the most extended\
    \ GE and the one endorsed by the European\nCommission as a CEF Building Block.[Digital\
    \ CEF 2018]\n• Orion-LDi: The Context Broker (Orion-LD) GE manages the entire\
    \ lifecycle of context\ninformation including updates, queries, registrations,\
    \ and subscriptions. It manages context\ninformation through the implementation\
    \ of a publish-subscribe system through an NGSI\ninterface. Users can create context\
    \ elements, query and update them, and subscribe to\nchanges in context information\
    \ that they can receive as notiﬁcations.\nOther elements\ninteract with Orion\
    \ through HTTP/HTTPS requests.\nThe Context Broker offers the\nFIWARE\nNGSI-LD\n\
    and\nNGSIv2\n(Next\nGeneration\nService\nInterface)\n[Open Mobile Alliance 2012]\
    \ APIs and associated information model (entity, attribute,\nmetadata) as the\
    \ main interface for managing context data.\nIn this architecture, Orion-LD provides\
    \ a complete solution for managing the latest context\ndata available. However,\
    \ storing the evolution of context data needs to be performed separately.\nFor\
    \ that purpose, this reference implementation relies on the Draco GE, which receives\
    \ each\ncontext update as a stream of data and injects them into multiple data\
    \ storage systems:\n• Dracoii is a dataﬂow management system based on Apache NiFiiii\
    \ that supports powerful\nand scalable directed graphs of data routing, transformation,\
    \ and system mediation logic\nusing a set of processors and controllers. Draco\
    \ is aimed at providing storage of historical\ncontext data, allowing to receive\
    \ data events and dynamically recording them with a\npredeﬁned structure in several\
    \ data storage systems. In the scope of this implementation,\nDraco is proposed\
    \ to cover the context storage in the Context Management component.\nPreprocessing\n\
    As stated in section 3.4.4, in this proposal, I also consider alternative data\
    \ sources that can feed\nthe context management and processing components. On\
    \ the one hand, there are REST APIs\niFIWARE Orion: https://fiware-orion.readthedocs.io\n\
    iiFIWARE Draco: https://fiware-draco.readthedocs.io\niiiApache NiFi: https://nifi.apache.org\n\
    56\n3.5. IMPLEMENTATION USING FIWARE\nor Database systems that need to be queried\
    \ periodically. On the other hand, there are systems\nlike TCP or HTTP servers\
    \ that send a continuous ﬂow of data. These data, possibly coming from\nexternal\
    \ applications, also need to be converted into NGSI-LD data and sent to the Context\
    \ Broker.\nIn order to deal with this type of systems that are not covered by\
    \ the IoT Agents, FIWARE relies\non the Draco GE. The suite of processors and\
    \ controllers provided in this GE allows converting the\nincoming data into NGSI-LD\
    \ entities and attributes, required for their publication in the Context\nBroker.\n\
    Context Processing\nThe context processing component relies on big data technologies\
    \ to extract valuable insights or\nderive smart actions. Although big data frameworks\
    \ provide well-deﬁned interfaces and systems\nthat can be integrated with a wide\
    \ range of systems and devices, standardized data injection is\nstill an open\
    \ issue in these systems. In this regard, FIWARE provides a set of connectors\
    \ and\nlibraries that allow to process NGSI (NGSIv2 and NGSI-LD) context data\
    \ using two of the most\nwell-known big data frameworks through the Cosmos GE.\n\
    • Cosmosi provides an interface for integrating Apache Flink and Apache Spark\
    \ with the\nrest of the components in the FIWARE Ecosystem. Over the last years,\
    \ Apache Flink and\nApache Spark have established themselves as the most popular\
    \ open-source data\nprocessing frameworks with the rest of the components of the\
    \ FIWARE Ecosystem. This\nGE consists of a set of connectors that allow receiving\
    \ data from the Context Broker\n(through its subscription/notiﬁcation feature)\
    \ directly within data processing jobs running\nin these engines, enabling the\
    \ processing of context data in real time, as well as to send the\nresult from\
    \ this processing back to a given entity in the Context Broker so other\ncomponents\
    \ in the architecture can subscribe to changes in its attributes.\n3.5.3\nSecurity\n\
    In the FIWARE Ecosystem, several GEs manage authorization and authentication concerning\
    \ users\nand devices:\n• Keyrockii The Keyrock GE is responsible for Identity\
    \ Management.\nUsing Keyrock\nenables OAuth 2.0-based authentication and authorization\
    \ security to services and\napplications, as described in [Alonso 2017, Fernández\
    \ 2017].\nIn the context of this\nimplementation, Keyrock plays the role of IdM:\
    \ it manages authorization policies (PAP)\nand decides who can access which resources\
    \ in smart environments.\niFIWARE Cosmos: https://fiware-cosmos.readthedocs.io\n\
    iiFIWARE Keyrock: https://fiware-idm.readthedocs.io\n57\nCONTEXT-AWARE SYSTEMS\
    \ AND DATA ANALYTICS FOR SMART SPACES\n• Wilmai:\nThe Wilma GE brings support\
    \ of proxy functions within OAuth 2.0-based\nauthentication schemas.\nIt also\
    \ implements Policy Enforcement Point (PEP) functions\nwithin an XACML-based access\
    \ control schema [OASIS Standard 1994]. In the scope of\nthis implementation,\
    \ several Wilma instances might be needed depending on what service\nthe users\
    \ want to provide or control the access to. Wilma is in charge of enforcing access\n\
    policies over requests sent to a speciﬁc endpoint. When a user or device is authenticated\n\
    through Keyrock, an OAuth 2.0 token is generated, which must be included in every\n\
    request sent to any protected component. Wilma intercepts requests and asks Keyrock\
    \ to\nvalidate the token, verifying the identity. Since Keyrock also acts as the\
    \ Policy Decision\nPoint (PDP), it checks the DC’s access authorization policies.\
    \ In case that the request\ncomplies with the established policies, Wilma grants\
    \ access to the requested resource.\n• AuthZForceii: The AuthZForce GE brings\
    \ additional support to PDP/PAP functions within\nan access control schema based\
    \ on the XACML standard.\n3.5.4\nApplication\nIn this section, I describe a set\
    \ of GE’s aimed at facilitating the processing, analysis and\nvisualization of\
    \ context information for the purpose of implementing the “smart behavior”\nexpected\
    \ in some of the context-aware systems:\n• Wirecloud GEiii brings a powerful web\
    \ mashup platform making it easier to develop\noperational dashboards which are\
    \ highly customizable by end-users.\n• Kurento\nGEiv\nenables\nreal-time\nprocessing\n\
    of\nmedia\nstreams\nsupporting\nthe\ntransformation of video cameras into sensors\
    \ as well as the incorporation of advanced\napplication functions (integrated\
    \ audiovisual communications, augmented reality, ﬂexible\nmedia playing and recording,\
    \ etc)\n•\nFogFlow GEv is a distributed execution framework to support dynamic\
    \ processing ﬂows\nover cloud and edges.\nAlthough FIWARE provides a set of software\
    \ components that facilitate the visualization and\nrepresentation of the data,\
    \ third-party applications can also be easily integrated into this\necosystem\
    \ by using the NGSI-LD format to represent the data. For example, data generated\
    \ by a\nrecommendation system can be offered to third parties through an extended\
    \ CKAN portal\niFIWARE Wilma: https://fiware-pep-proxy.readthedocs.io\niiFIWARE\
    \ AuthZForce: https://authzforce-ce-fiware.readthedocs.io\niiihttps://wirecloud.rtfd.io/\n\
    ivhttps://kurento.rtfd.io/\nvhttps://fogﬂow.rtfd.io/\n58\n3.6. APPLICATION SCENARIOS\n\
    enabling the publication of real-time data and the assignment of terms and conditions\
    \ to data\nresources or even Complex Event Processing, advanced artiﬁcial intelligence\
    \ or machine learning\nfunctions can be implemented on top of the integrated processing\
    \ engines.\nAfter the description of all the components used in this FIWARE Oriented\
    \ architecture\nimplementation. In Fig 3.2 I present a graphical representation\
    \ of how all the aforementioned\ncomponents and how they are placed in this proposal.\n\
    Figure 3.2 : Architecture Implementation using FIWARE GE’s\n3.6\nApplication Scenarios\n\
    This section presents a set of implementation examples to study and validate the\
    \ proposed\nframework in different scenarios. First, I present a complete implementation\
    \ of a Smart Farm that\nuses big data techniques for building a ruled-based threshold\
    \ system to trigger automatic actions\ndepending on the inputs received by a set\
    \ of IoT devices. Afterward, another example is the\nbuilt-in Food Industry.\n\
    In this example, a static dataset of purchases is used for building a\nmachine\
    \ learning prediction system capable of determining the number of purchases in\
    \ a given\ndate and time.\n3.6.1\nSmart Farm\nThis section presents an example\
    \ of use case based on the FIWARE step-by-step tutorialsi. This\nscenario shows\
    \ a complete digital infrastructure that emulates a Smart Farm.\nihttps://ngsi-ld-tutorials.readthedocs.io/en/latest/iot-sensors.html\n\
    59\nCONTEXT-AWARE SYSTEMS AND DATA ANALYTICS FOR SMART SPACES\nData Modelling\n\
    All the context data in this scenario are modeled using the Smart Data models\
    \ deﬁned for\nAgriculturei. These Data models deﬁne a set of mandatory and optional\
    \ attributes that every\nentity needs to include. The context of an entity represents\
    \ the state of a physical or conceptual\nobject which exists in the real world.\n\
    In this scenario, the following set of entities and relationships have been created\
    \ in order to\nbuild a Farm Management Information Systems (FMIS) based on NGSI-LD.\
    \ For this simpliﬁed\nFMIS, it is only needed a small number of entities. The\
    \ relationship between the entities is\ndeﬁned as shown in Fig. 3.3. A Buildingii\
    \ is a real-world brick and mortar construct. Building\nentities would have properties\
    \ such as name, address, physical location, ﬁllingLevel, temperature,\nand an\
    \ association to the owner of the building.\nOn the other hand, smart devices\
    \ such as\ntemperature sensors or ﬁlling level sensors would extend a common Device\
    \ data modeliii. Each\nDevice entity would have properties such as: description,\
    \ category of device, and association to\nthe asset (controlledAsset). A Personiv\
    \ is an entity representing a farmer or farm laborer. Each\nPerson entity would\
    \ have properties such as: name, jobTitle, and an association to the farm\nbuildings\
    \ they own (owner).\nAdditionally,\nan agricultural parcel operation or task\n\
    (AgriParcelOperationv) is a conceptual entity used to associate workers, agricultural\
    \ products,\nand locations. AgriParcelOperation entities would have properties\
    \ such as: name, status of the\ntask and an association to the worker (i.e., a\
    \ Person entity, hasOperator) who performs the task,\nan association to the product\
    \ (i.e., an AgriProductTypevi entity, hasAgriProductType) to be used,\nan association\
    \ to the parcel (i.e., an AgriParcelvii entity, hasAgriParcel) where applied,\
    \ which\npoints to the crop (i.e., an AgriCrop entityviii entity, hasAgriCrop)\
    \ grown.\nAs can be seen, multiple entities are involved in this scenario. I now\
    \ present an example of\nthe command for creating the TemperatureSensor entity\
    \ in the Context Broker. In this regard, as\nshown in Fig.\n3.3, the TemperatureSensor\
    \ entity is composed by the attributes: id, type,\ndescription, category, controlledProperty\
    \ and temperature.\nThis entity can be created in the\ncontext broker by the HTTP\
    \ request presented in Listing in 3.1:\niSmart Agrifood Domain: https://github.com/smart-data-models/SmartAgrifood\n\
    iiBuilding Data Models: https://github.com/smart-data-models/dataModel.Building\n\
    iiiDevice Data Models: https://github.com/smart-data-models/dataModel.Device\n\
    ivPerson\nData\nModel:\nhttps://smart-data-models.github.io/data-models/common-\n\
    schema.json\nvAgriculture\nParcel\nOperation\nData\nModel:\nhttps://github.com/smart-data-models/\n\
    dataModel.Agrifood/blob/master/AgriParcelOperation\nviAgriculture\nProduct\nData\n\
    Model:\nhttps://github.com/smart-data-models/\ndataModel.Agrifood/blob//master/AgriProductType\n\
    viiAgricultural\nParcel\nData\nModel:\nhttps://github.com/smart-data-models/\n\
    dataModel.Agrifood/blob/master/AgriParcel\nviiiAgricultural\nCrop\nData\nModel:\n\
    https://github.com/smart-data-models/\ndataModel.Agrifood/blob/master/AgriCrop\n\
    60\n3.6. APPLICATION SCENARIOS\nid\n△ category\n△ name\n△ address\n△ location\n\
    △ temperature\n△ fillingLevel\n□ owner\nBuilding\nid\n△ value\n△ category\n△ description\n\
    △ controlledProperty\n□ controlledAsset\nTemperatureSensor\nid\n△ name\n△ status\n\
    □ hasAgriParcel\n□ hasAgriProductType\n□ hasOperator\nAgriParcelOperation\nid\n\
    △ location\n□ hasAgriCrop\nAgriParcel\nid\n△ name\n△ agroVocConcept\nAgriProductType\n\
    id\n△ name\nAgriCrop\n1\n▲ contains\n1\n \nid\n△ name\n△ jobTitle\nPerson\n* ◀\
    \ contains 1\n 1 ▶ contains *\n*\n▼ owns\n1 \n1\n▼ assignedTo\n*\n \n 1 ◀ sprays\
    \ *\n* ▶ uses 1\nid\n△ value\n△ category\n△ description\n△ controlledProperty\n\
    □ controlledAsset\nFillingLevelSensor\nFigure 3.3 : Entities and Relationships\
    \ in FMIS\ncurl −X POST ’http://locahost:1026/ngsi−ld/v1/entityOperations/upsert’\
    \ \\\n−H ’Content−Type: application/json’ \\\n−H ’Link: <’http://context/ngsi−context.jsonld’>;\
    \ rel=\"http://www.w3.org/ns/json−ld#context\"; type=\"\napplication/ld+json\"\
    ’ \\\n−H ’Accept: application/ld+json’ \\\n−−data−raw ’[\n{\n\"id\": \"urn:ngsi−ld:TemperatureSensor:001\"\
    ,\n\"type\": \"Device\",\n\"description\" :{\"type\": \"Property\", \"value\"\
    : \"Temperature Gauge 1\"},\n\"category\": {\"type\": \"Property\", \"value\"\
    : \"sensor\"},\n\"controlledProperty\" :{\"type\": \"Property\", \"value\": \"\
    temperature\"},\n\"value\": {\"type\": \"Property\", \"value\": 20,\"unitCode\"\
    : \"CEL\"}\n}\n]\nListing 3.1: Request for creating a temperature entity\n61\n\
    CONTEXT-AWARE SYSTEMS AND DATA ANALYTICS FOR SMART SPACES\nIoT Devices\nThe scenario\
    \ is composed by a collection of IoT devices. Each one of the devices uses UltraLight\n\
    2.0 as a communication protocol on top of HTTP. UltraLight 2.0 is a lightweight\
    \ text-based\nprotocol for devices and communications where bandwidth and device\
    \ memory resources are\nlimited [?].\nThis protocol is structured as a list of\
    \ key-value pairs divided by the pipe (“|”)\ncharacter. Below (3.1) is an example\
    \ of an UltraLight 2.0 payload containing two attributes \"a\"\nwith value of\
    \ \"10\" and \"b\" with value \"xyz\".\na|10|b|xyz\n(3.1)\nIn this example, the\
    \ following IoT sensors and actuators are included:\n• Soil Sensor - It reports\
    \ the quantity of humidity in the soil.\n• Temperature Sensor - It measures the\
    \ ambient or soil temperature at that instant.\n• Filling Sensor - It shows the\
    \ feed quantity available in an speciﬁc silo.\n• Irrigation System - It is an\
    \ actuator that can be activated and open the valves for a small\nperiod of time.\n\
    • Animal Collars - These are devices that allow showing the current location,\
    \ the health, and\nstress level of the animals.\n• Farm Management Information\
    \ Systems - These are devices installed in the agricultural\nmachinery that allows\
    \ communication (send/receive) messages or instructions to laborers,\nand monitor\
    \ the current state of the work assigned.\nThe communication between IoT devices\
    \ and the Context Broker is achieved by using IoT\nAgents. These agents deﬁne\
    \ two interfaces for the communication with the Context Broker:\nsouthbound and\
    \ northbound. On the one hand, southbound trafﬁc includes the requests originated\n\
    by the Context Broker and redirected to an IoT device. Southbound trafﬁc is formed\
    \ by a set of\nmessages with instructions for the actuator devices in order to\
    \ change the state of the\nenvironment by the execution of those actions. On the\
    \ other hand, northbound trafﬁc collects the\nrequests originated by the IoT devices\
    \ and sends them back to the Context Broker. Northbound\ntrafﬁc instead has the\
    \ measurements gather by the sensors and collect the state of the environment\n\
    for including it into context data of the system.\nIn this regard, the communication\
    \ schema deﬁned for this example is presented in (3.2), where\nthe entity id represented\
    \ in the Context broker is < device_name > , and one of the commands\nthat can\
    \ be executed is represented by < command > and any other needed values can be\
    \ added\nin subsequent parameters < param >.\n62\n3.6. APPLICATION SCENARIOS\n\
    < device_name > @ < command > | < param > | < param >\n(3.2)\nFor example, the\
    \ message presented in (3.3) sends a message to a device with the following\n\
    content: \"The Context Broker knows me as ’urn:ngsi-ld:Robot:001’. I need that\
    \ the device that is\nconnected to this endpoint execute the command of turn.\
    \ I have provided the parameters left and\n’30 (degrees) in order to the device\
    \ to accomplish the task\".\nurn : ngsi−ld : Robot : 001@turn|left|30\n(3.3)\n\
    The corresponding response deﬁned in the northbound interface will be as is stated\
    \ in (3.4): \"I\nhave complied with a request from the entity known as ’urn:ngsi-ld:Robot:001’\
    \ within the Context\nBroker. The command I have performed was a turn command.\
    \ The result was ’Turnok’\".\nurn : ngsi−ld : Robot : 001@turn|Turnok\n(3.4)\n\
    Real-time processing and Big Data analysis\nFIWARE relies on microservices for\
    \ building Smart Solutions. One of the advantages of using\nthis approach is that\
    \ they are designed to scale up, from basic or simple applications to city-wide\n\
    systems by means of a huge amount of IoT sensors, actuators, and many other systems\
    \ like context\ndata providers. As mentioned, any Smart solution has as a core\
    \ context data, and we take advantage\nof the Context Broker for providing a mechanism\
    \ that allows us to keep updated about the changes\nof state and provide notiﬁcations\
    \ as the context changes. In the case of small scenarios, each of\nthe notiﬁcation\
    \ events can be treated and processed as it comes by a single endpoint.\nOur example\
    \ implementation in Smart Farming uses the elements and dummy IoT devices\npreviously\
    \ described. In this regard, the FIWARE components used in this example are chosen\n\
    for providing a speciﬁc task in the whole system. The context broker was chosen\
    \ as the core\nfor manage all the context data. The IoT Agent for managing the\
    \ devices that work with the\nUltralight 2.0 protocol, and Cosmos Orion Spark\
    \ Connector for providing the connection between\nthe Context Broker and the Spark\
    \ Cluster in where the program is running. The Spark cluster\nconsists of a single\
    \ master that acts as a cluster manager to coordinate the execution and some\n\
    worker nodes to execute the tasks. For providing the historic context information,\
    \ Orion Context\nBroker relies on Draco to store the historic in MongoDB. Therefore\
    \ the overall architecture is\npresented inf Fig. 3.4 and it consists of the following\
    \ elements:\n• Two independent microservices using the FIWARE GEs:\n– The Orion\
    \ Context Broker for managing the context data by receiving the NGSI-LD\nrequests.\n\
    63\nCONTEXT-AWARE SYSTEMS AND DATA ANALYTICS FOR SMART SPACES\nFigure 3.4 : Graphical\
    \ overview of the smart farming scenario\n– The FIWARE IoT Agent for UltraLight\
    \ 2.0 which will receive southbound requests\nusing NGSI-LD and convert them to\
    \ UltraLight 2.0 commands for the devices.\n• An Apache Spark cluster consisting\
    \ of a single Cluster Manager and Worker Nodes.\n– The FIWARE Cosmos Orion Spark\
    \ Connector will be deployed as part of the dataﬂow\nwhich will subscribe to context\
    \ changes and make operations on them in real-time.\n• One MongoDB database :\n\
    – Used by the Orion Context Broker to hold context data information such as data\n\
    entities, subscriptions, and registrations\n– Used by the IoT Agent to hold device\
    \ information such as device URLs and Keys\n• This Application does the following:\n\
    – Offers static @context ﬁles deﬁning the context entities within the system.\n\
    – Acts as a set of dummy agricultural IoT devices using the UltraLight 2.0\nOnce\
    \ all the components and their connection have been established, it is the time\
    \ to deﬁne the\nprogram that will be run over the spark cluster. In this case,\
    \ I deﬁne a scala program for providing\na rule-based decision application able\
    \ to detect and trigger actions depending on the sensor values.\nFor this speciﬁc\
    \ use case, I have deﬁned a program that opens a water faucet when the soil humidity\n\
    is too low and turns it back off when the soil humidity is back to normal levels.\
    \ This way, the soil\nhumidity is always kept at an adequate level. In this regard,\
    \ Cosmos provides two mechanisms for\nworking with streaming data one for reading\
    \ Context data as a Source Operator NGSILDSource\n64\n3.6. APPLICATION SCENARIOS\n\
    and other for pushing Context data back to the context broker as a Sink Operator\
    \ NGSILDSink\nThe dataﬂow stream uses the NGSILDSource operator in order to receive\
    \ notiﬁcations and ﬁlters\nthe input to only respond to motion sensors and then\
    \ uses the NGSILDSink to push processed\ncontext back to the Context Broker. The\
    \ code written in scala for building this program is shown\nin 3.2. In that program,\
    \ LOW_THRESHOLD and HIGH_THRESHOLD have been set to 30 and\n35 respectively.\n\
    o b j e c t\nFeedbackLD {\nf i n a l\nval CONTENT_TYPE = ContentType . JSON\n\
    f i n a l\nval METHOD = HTTPMethod .PATCH\nf i n a l\nval CONTENT = \" { \\ \"\
    \ type \\ \" : \\ \" P r op e rt y \\ \" , \\ \" value \\ \" : \\ \" \\ \" } \"\
    \nf i n a l\nval HEADERS = Map(\n\"NGSILD−Tenant \" −> \" openiot \" ,\n\" Link\
    \ \" −> \"< h t t p : / / c o n t e x t / ngsi −c o n t e x t . jsonld >\" ;\n\
    r e l =\" h t t p : / /www. w3 . org / ns / json −ld # c o n t e x t \" ;\ntype\
    \ =\" a p p l i c a t i o n / ld + json \"\n)\nf i n a l\nval LOW_THRESHOLD =\
    \ 35\nf i n a l\nval HIGH_THRESHOLD = 50\ndef\nmain ( args :\nArray [ S t r i\
    \ n g ] ) :\nUnit = {\nval\nconf = new SparkConf ( ) . setAppName ( \" Feedback\
    \ \" )\nval\nssc = new StreamingContext ( conf ,\nSeconds ( 1 0 ) )\n/ /\nCreate\n\
    Orion\nReceiver .\nReceive\nn o t i f i c a t i o n s\non\nport\n9001\nval\neventStream\
    \ = ssc . r e c e i v e r S t r e a m ( new NGSILDReceiver (9001))\n/ /\nProcess\n\
    event\nstream\nval\nprocessedDataStream = eventStream . flatMap ( event => event\
    \ . e n t i t i e s )\n. f i l t e r ( ent => ent . ‘ type ‘ == \" S o i l S e\
    \ n s o r \" )\n/∗\nHigh\nhumidity\n∗/\nval\nhighHumidity = processedDataStream\n\
    . f i l t e r ( ent =>\n( ent . a t t r s ( \" humidity \" )\n!=\nnull ) &&\n\
    ( ent . a t t r s ( \" humidity \" ) ( \" value \" )\n. a s I n s t a n c e O\
    \ f [ BigInt ] > HIGH_THRESHOLD) )\n. map ( ent => ( ent . id , ent . a t t r\
    \ s ( \" humidity \" ) ( \" value \" ) ) )\nval\nhighSinkStream= highHumidity\
    \ . map ( sensor => {\nOrionSinkObject (CONTENT,\n\" h t t p : / / orion :1026/\
    \ ngsi −ld / v1 / e n t i t i e s / urn : ngsi −ld : Device : water \"\n+ sensor\
    \ . _1 . t a k e R i g h t (3)+ \" / a t t r s / o f f \" ,\nCONTENT_TYPE,METHOD,HEADERS)\n\
    65\nCONTEXT-AWARE SYSTEMS AND DATA ANALYTICS FOR SMART SPACES\n})\nhighHumidity\
    \ . map ( sensor => \" Sensor \" + sensor . _1 +\n\" has\nd e t e c t e d\na\n\
    humidity\nl e v e l\nabove \" + HIGH_THRESHOLD +\n\" .\nTurning\no f f\nwater\n\
    f a u c e t ! \" ) . p r i n t ( )\nOrionSink . addSink (\nhighSinkStream\n)\n\
    /∗ Low humidity\n∗/\nval\nlowHumidity = processedDataStream\n. f i l t e r ( ent\
    \ => ( ent . a t t r s ( \" humidity \" )\n!=\nnull ) &&\n( ent . a t t r s (\
    \ \" humidity \" ) ( \" value \" )\n. a s I n s t a n c e O f [ BigInt ] < LOW_THRESHOLD)\
    \ )\n. map ( ent => ( ent . id , ent . a t t r s ( \" humidity \" ) ( \" value\
    \ \" ) ) )\nval\nlowSinkStream= lowHumidity . map ( sensor => {\nOrionSinkObject\
    \ (CONTENT,\n\" h t t p : / / orion :1026/ ngsi −ld / v1 / e n t i t i e s / urn\
    \ : ngsi −ld : Device : water \"+\nse nsor . _1 . t a k e R i g h t (3)+ \" /\
    \ a t t r s / on \" ,\nCONTENT_TYPE,METHOD,HEADERS)\n})\nlowHumidity . map ( sensor\
    \ => \" Sensor \" + sensor . _1 +\n\" has\nd e t e c t e d\na\nhumidity\nl e v\
    \ e l\nbelow \" + LOW_THRESHOLD +\n\" .\nTurning on water\nf a u c e t ! \" )\
    \ . p r i n t ( )\nOrionSink . addSink (\nlowSinkStream\n)\nssc . s t a r t (\
    \ )\nssc . awaitTermination ( )\n}\n}\nListing 3.2: Scala program for controlling\
    \ humidity level\nThe last step for setting up the whole scenario is creating\
    \ a new subscription as is shown in 3.3\nfor listening to the changes of context\
    \ on the soil humidity sensor in order to the spark program\ncan receive notiﬁcations\
    \ about the changes in the humidity of these entities.\ncurl −X POST curl −L −X\
    \ POST ’http://localhost:1026/ngsi−ld/v1/subscriptions/’ \\\n−H ’Content−Type:\
    \ application/ld+json’ \\\n−H ’NGSILD−Tenant: openiot’ \\\n−−data−raw ’{\n\"description\"\
    : \"Notify Spark of changes of Soil Humidity\",\n\"type\": \"Subscription\",\n\
    \"entities\": [{\"type\": \"SoilSensor\"}],\n66\n3.6. APPLICATION SCENARIOS\n\"\
    watchedAttributes\": [\"humidity\"],\n\"notiﬁcation\": {\n\"attributes\": [\"\
    humidity\"],\n\"format\": \"normalized\",\n\"endpoint\": {\n\"uri\": \"http://spark−worker−1:9001\"\
    ,\n\"accept\": \"application/json\"\n}\n},\n\"@context\": \"http://context/ngsi−context.jsonld\"\
    \n}’\nListing 3.3: Subscription to the SoilSensor types of entities\nWorkﬂow\n\
    Once all the services are deployed and entities and subscriptions are created.\
    \ I can deﬁne the\nworkﬂow of the system presented in 3.5 and described as follows:\n\
    1. The system begins to generate context data when the user starts some of the\
    \ devices via\nthe device monitoring interface (Context Provider CP). For example,\
    \ the user raises the\ntemperature through Temperature Sensor (TS) in Farm001.\n\
    2. The temperature value sent from Orion is in NGSI-LD format. Thus, the IoT agent\
    \ (IoTA),\ntakes this value and transforms it into UltraLight 2.0.\n3. While the\
    \ temperature TS in Farm001 is rising, the value of the Humidity Sensor (HS) is\n\
    decreasing, the value of the HS is sent messages to the context broker via IoTA\
    \ converting\nthe messages from UltraLight 2.0 to NGSI-LD to forwarding to Orion.\n\
    4. Orion receives the data generated by HS and only when detects that the humidity\
    \ value is\nupdated, it sends a notiﬁcation to the Spark Job (SJ) via cosmos.\n\
    5. Since the application is running in the spark cluster, it is ready for receiving\
    \ the streaming\ndata from the Orion. Thus, when Orion sends a notiﬁcation, the\
    \ SJ reads the stream of data\nand map the humidity attribute value for determining\
    \ if it is below or under the deﬁned\nthresholds.\n6. Once that the SJ detects\
    \ that the humidity value is under the LOW_THRESHOLD (35). It\nsends an update\
    \ for tuning on the water faucet in the corresponding water entity hosted in\n\
    the Orion.\n7. When Orion receives the update request from the SJ. It performs\
    \ the update and sends back\nto the Water Actuator(WA) the order via IoTA.\n67\n\
    CONTEXT-AWARE SYSTEMS AND DATA ANALYTICS FOR SMART SPACES\nFigure 3.5 : Scenario\
    \ Workﬂow\n8. IoTA translates to Ultralight the turn-on action to the WA and send\
    \ it.\n9. The WA ﬁnally receives the message and turns on the water faucet.\n\
    10. This workﬂow continues until the HS value is above the HIGH_THRESHOLD (50).\
    \ And,\nwhen this happens the process is repeated but in this time sending back\
    \ the action for turning\noff the water faucet to the correspondent device.\n\
    3.6.2\nSupermarket purchase prediction\nIn this section, I present an example\
    \ use case in which I use the described reference implementation\nto build a prediction\
    \ system in the Food Industry. A static dataset of purchases in a grocery store\n\
    68\n3.6. APPLICATION SCENARIOS\nis used for building a machine learning system\
    \ capable of determining the number of purchases in\na given date and time.\n\
    This case presents two independent processes: training the model and deploying\
    \ the predictor\nsystem. First I use a dataset for building a machine learning\
    \ model based on the Random Forest\nRegression Algorithm. This process includes\
    \ all the stages of the training process such as: data\ncleaning, feature extraction,\
    \ algorithm selection, scoring, and tuning. Afterward, the trained model\nis deployed\
    \ as a job in a Spark cluster for providing the predictor system. In this stage,\
    \ I provide\nan implementation based on FIWARE GEs for providing a complete solution\
    \ that not only makes\npredictions but also includes all the context-aware capabilities\
    \ provided by the Context Broker. A\nrepresentation of the whole system components\
    \ is presented in Fig. 3.6\nFigure 3.6 : Graphical overview of the supermarket\
    \ scenario\nData Modelling\nIn this scenario, all data are modeled as Ticket entities.\
    \ However, there does not exist any data\nmodel in the FIWARE Smart Data Models\
    \ initiative for modelling tickets. Consequently, a new\ndata model should be\
    \ created and published in the Smart Cities domaini under a new subject named\n\
    Shop. The ﬁrst step for creating a new data model is deﬁning its schema. In this\
    \ model, a Ticket\nentity would have compulsory properties such as: id and type;\
    \ optional properties such as: type of\niSmart Cities Domain: https://github.com/smart-data-models/SmartCities\n\
    69\nCONTEXT-AWARE SYSTEMS AND DATA ANALYTICS FOR SMART SPACES\nticket (ticketType),\
    \ type of currency priceCurrency, total price, and date (dateIssued); and optional\n\
    relationships such as products (hasProducts). The resulting schema deﬁnition is\
    \ shown in Listing\n3.4, and an example of a Ticket entity in Listing 3.5.\n{\n\
    \"$schema\": \"http://json−schema.org/schema#\",\n\"$schemaVersion\": \"0.0.1\"\
    ,\n\"$id\": \"https://smart−data−models.github.io/dataModel.Shop/Ticket/schema.json\"\
    ,\n\"title\": \"Smart Data models − Ticket schema\",\n\"description\": \"Represent\
    \ a generic ticket\",\n\"type\": \"object\",\n\"allOf\": [\n{\n\"$ref\": \"https://smart−data−models.github.io/data−models/common−schema.json#/deﬁnitions/\n\
    GSMA−Commons\"\n},\n{\n\"$ref\": \"https://smart−data−models.github.io/data−models/common−schema.json#/deﬁnitions/\n\
    Location−Commons\"\n},\n{\n\"properties\": {\n\"type\": {\n\"type\": \"string\"\
    ,\n\"enum\": [\n\"Ticket\"\n],\n\"description\": \"Property. NGSI Entity type.\
    \ It has to be Ticket\"\n},\n\"ticketType\": {\n\"type\": \"string\",\n\"enum\"\
    : [\n\"Request\",\n\"Response\",\n\"other\"\n],\n\"description\": \"Property.\
    \ Model:’http://schema.org/Text’. Type of ticket\"\n},\n\"priceCurrency\": {\n\
    \"type\": \"string\",\n\"description\": \"Property. Model:’https://schema.org/priceCurrency’.\
    \ Price currency of the\npurchase\"\n},\n70\n3.6. APPLICATION SCENARIOS\n\"totalPrice\"\
    : {\n\"type\": \"number\",\n\"description\": \"Property. Model:’https://schema.org/totalPrice’.\
    \ Total price of the purchase\"\n},\n\"dateIssued\": {\n\"type\": \"string\",\n\
    \"format\": \"date−time\",\n\"description\": \"Property. Model:’http://schema.org/DateTime’.\
    \ Date when the purchase was\ntaken\"\n},\n\"hasProducts\": {\n\"type\": \"array\"\
    ,\n\"description\": \"Relationship. Array of URIs related to the products of the\
    \ ticket.\",\n\"items\": {\n\"anyOf\": [\n{\n\"type\": \"string\",\n\"minLength\"\
    : 1,\n\"maxLength\": 256,\n\"pattern\": \"^[\\\\w\\\\−\\\\.\\\\{\\\\}\\\\$\\\\\
    +\\\\∗\\\\[\\\\]‘|~^@!,:\\\\\\\\]+$\",\n\"description\": \"Property. Identiﬁer\
    \ format of any NGSI entity\"\n},\n{\n\"type\": \"string\",\n\"format\": \"uri\"\
    ,\n\"description\": \"Property. Identiﬁer format of any NGSI entity\"\n}\n]\n\
    }\n}\n}\n}\n],\n\"required\": [\n\"id\",\n\"type\"\n]\n}\nListing 3.4: Smart Data\
    \ Model Ticket JSON Schema\n{\n\"id\": \"urn:ngsi−ld:Ticket1\",\n\"type\": \"\
    Ticket\",\n71\nCONTEXT-AWARE SYSTEMS AND DATA ANALYTICS FOR SMART SPACES\n\"ticketType\"\
    : \"Response\",\n\"priceCurrency\": \"EUR\",\n\"totalPrice\": 10,\n\"dateIssued\"\
    : \"2021−06−15T08:43:22Z\",\n\"hasProducts\": [\n\"urn:ngsi−ld:Product1\",\n\"\
    urn:ngsi−ld:Product2\"\n],\n\"@context\": [\n\"https://smartdatamodels.org/context.jsonld\"\
    \n]\n}\nListing 3.5: Example of Ticket entity\n3.6.3\nData Collection\nThe data\
    \ collection process is the ﬁrst step for building the dataset.\nA diagram with\
    \ the\nrepresentation of this process is shown in Fig. 3.6. In this case, the\
    \ data is generated by a set of\nPoint of Sale Terminals (POS) located in two\
    \ different malls.\nEach of the POS Terminals\ngenerates a ticket with the purchase\
    \ information of each one of the customers that buy a product\nin that mall. In\
    \ order to collect this data, each of the terminals sends the ticket to Draco\
    \ for\nperforming the preprocessing task, transforming the raw ticket data into\
    \ an NGSI-LD ticket.\nAfter the preprocessing the NGSI-LD ticket is sent to the\
    \ Ticket Entity created in the CB. When\nthe CB detects a change in the Ticket\
    \ entity send a notiﬁcation to the second instance of Draco\nthat is conﬁgured\
    \ to be connected to a MongoDB for storing the ticket information received by\n\
    the context broker. Using this data collection pipeline, I can provide a structured\
    \ way NGSI-LD\ncompliant to store the information of each of the tickets generated\
    \ in the two stores. Using this\napproach I can build a dataset with a well-known\
    \ data structure that can be easy used by any\nsystem for its further processing.\n\
    Dataset\nThe dataset was built using data from a Supermarket Company located in\
    \ Europe. It consists of a\n1 GB JSON ﬁle. The ﬁle contains a sample of more than\
    \ 580,000 tickets for two different stores\nthat date from Jan 2016 to May 2016\
    \ containing more than 50,000 different products and over\n60,000 clients. The\
    \ dataset has the following ﬁelds:\n• id - Number id for that individual ticket.\n\
    • mall - Store where the ticket was printed. It has two values, 1 and 2.\n• date\
    \ - Date and time the ticket was printed.\n72\n3.6. APPLICATION SCENARIOS\nTable\
    \ 3.2 : Training Dataset\ntime\nday\nmonth\nyear\nweekDay\npurchases\n6\n14\n\
    1\n2016\n3\n12\n7\n14\n1\n2016\n3\n12\n8\n14\n1\n2016\n3\n23\n9\n14\n1\n2016\n\
    3\n45\n10\n14\n1\n2016\n3\n55\n11\n14\n1\n2016\n3\n37\n12\n14\n1\n2016\n3\n42\n\
    13\n14\n1\n2016\n3\n41\n14\n14\n1\n2016\n3\n38\n• client - Some tickets will have\
    \ a Customer ID. Many tickets will share a Customer ID.\n• items - List of items\
    \ contained in the printed ticket. The list contains a dictionary with a\nproduct\n\
    • description - the amount charged (net_am), and the number of units bought (n_unit).\n\
    Training\nIn order to train the model, the ﬁrst step was the perform a data cleaning\
    \ to avoid erroneous data.\nAfterward, the features extraction and data aggregation\
    \ process was made over the previously\ndescribed dataset obtaining, as a result,\
    \ the structure, showed in Table 3.2. In this new dataset\nthe columns of time,\
    \ day, month, year, and weekDay are set as input and the purchases as the\noutput.\
    \ The training process was performed using SparkMLlib. The data was split into\
    \ 80% for\ntraining and 20% form testing. According to the data provided a supervised\
    \ learning algorithm is\nthe best that suite in this case. The algorithm selected\
    \ for building the model was Random Forest\nRegression[Liaw 2002] showing a mean\
    \ square error of 0.22. A graphical representation of this\nprocess is shown in\
    \ Fig 3.7\nFigure 3.7 : Training Pipeline\n73\nCONTEXT-AWARE SYSTEMS AND DATA\
    \ ANALYTICS FOR SMART SPACES\nPrediction\nThe prediction system was built using\
    \ the training model previously deﬁning. In this case, this\nmodel is packaged\
    \ and deployed inside of a spark cluster. This program uses Spark Streaming\n\
    and the Cosmos-Orion-Spark-connector for reading the streams of data coming from\
    \ the context\nbroker. Once the prediction is made this result is written back\
    \ to the context broker. A graphical\nrepresentation of the prediction process\
    \ is shown in Fig 3.8\nFigure 3.8 : Prediction Pipeline\nPurchase Prediction System\n\
    In this subsection I provide an overview of the whole components of the prediction\
    \ system. The\nsystem architecture is presented in Fig 3.9. in where the following\
    \ component are involved:\nFigure 3.9 : Service components of purchase prediction\
    \ system\n• WWW - It represents a Node JS application that provides a GUI for\
    \ allowing the users to\nmake the request predictions choosing the date and time\
    \ (see Fig. 3.10 )\n• Orion - As the central piece of the architecture. It is\
    \ in charge of managing the context\nrequests from a web application and the prediction\
    \ job\n74\n3.6. APPLICATION SCENARIOS\n• Cosmos - It runs a Spark cluster with\
    \ one master and one worker with the capacity to scale\naccording to the system\
    \ needs. It is in this component where the prediction job is running.\n• MongoDB\
    \ - It is where the entities and subscriptions of the Context Broker are stored.\
    \ Also,\nit is used to store the historic context data of each entity.\n• Draco\
    \ - It is in charge of persisting the historic context of the prediction responses\
    \ through\nthe notiﬁcations sent by Orion.\nFigure 3.10 : Prediction web application\
    \ GUI\nAdditionally, two entities have been created in Orion, one form managing\
    \ the request ticket\nprediction,\nReqTicketPrediction1\nand\nanother\nfor\nthe\n\
    response\nof\nthe\nprediction\nResTicketPrediction1.\nMoreover, three subscriptions\
    \ have been created, one from the Spark Master to the\nReqTicketPrediction1 entity\
    \ for receiving the notiﬁcation with the values sent by the web\napplication to\
    \ the spark job and make the prediction and two more to the ResTicketPrediction1\n\
    entity for notifying the prediction values to Draco for store the historic context\
    \ and the web\napplication to present the prediction value to the user.\nA graphical\
    \ representation of the\ncomponent that interacts with the entities, subscriptions,\
    \ and also, the structure of how the two\nentities with all of their attributes\
    \ are modeled is presented in Fig 3.11\nWorkﬂow\nThe workﬂow of the system is\
    \ presented in 3.12 and is described as follows:\n1. The user send a prediction\
    \ request to the web application (WebApp)\n2. The WebApp generates a new prediction\
    \ request to the entity ReqTicketPrediction1 created\nin Orion\n3. Orion updates\
    \ the ReqTicketPrediction1 entity with the new values and send a notiﬁcation\n\
    with this update to the running SparkJob\n75\nCONTEXT-AWARE SYSTEMS AND DATA ANALYTICS\
    \ FOR SMART SPACES\nFigure 3.11 : Schema of entities and service subscriptions\n\
    4. SparkJob uses the trained model to compute the prediction based on the values\
    \ received in\nthe notiﬁcation.\n5. Once the prediction is generated SparkJob\
    \ sends a prediction response to the\nResTicketPrediction1 entity stored in Orion\n\
    6. Orion updates the ResTicketPrediction1 entity and generates 2 notiﬁcations.\
    \ One for the\nWebApp and the other for Draco\n7. Once the ResTicketPrediction1\
    \ notiﬁcation is received by the WebApp it shows the\nprediction to the user.\n\
    8. Finally, when Draco receives the notiﬁcation about the update of the ReqsTicketPrediction1\n\
    it takes the values and persists the historic context data into MongoDB\n76\n\
    3.7. CONCLUSIONS\nFigure 3.12 : Purchase prediction systems workﬂow\n3.7\nConclusions\n\
    This chapter presented a conceptual representation of context-aware systems that\
    \ enable data\nanalytics in smart spaces. The underlying architecture is divided\
    \ into four layers, informed by\navailable literature in the ﬁeld: physical, middleware,\
    \ application, and security.\nAs such, it\nconsiders the complete data lifecycle,\
    \ from data acquisition through sensors and other IoT\ndevices, to data processing\
    \ using Big Data technologies and presentation to the end user. The\nimplementation\
    \ relies on FIWARE GEs and commonly used open source technologies, a\ncombination\
    \ that has proven useful in the past for building other types of smart solutions\
    \ such as\ndigital\ntwins\n[Conde 2021],\ndata\nusage\ncontrolled\nsharing\nenvironments\n\
    [Munoz-Arcentales 2020,\nMunoz-Arcentales 2019],\nand\nenhanced\nauthentication\n\
    systems\n[Alonso 2020]. In this chapter, I show how, by combining these building\
    \ blocks, I provide a\nrobust, ﬂexible, scalable, and secure way to provide context-aware\
    \ data analytics in smart spaces.\nFurthermore, I take advantage of the existing\
    \ Smart Data Models based on the NGSI standard\nto easily adapt this implementation\
    \ to different domains. I provide two example use cases to\n77\nCONTEXT-AWARE\
    \ SYSTEMS AND DATA ANALYTICS FOR SMART SPACES\nvalidate the generalizability of\
    \ this proposal: one in Smart Farming and the other in Smart Retail.\nThese two\
    \ settings highlight how this implementation supports data from a number of different\n\
    sources, as well as a variety of operations including complex event processing\
    \ and machine\nlearning. I hope is that this reference implementation, along with\
    \ the step-by-step description of\nthose example use cases, offers some clues\
    \ to researchers, developers, and practitioners on how\nto operationalize their\
    \ own context-aware smart environments based on FIWARE.\nFurther research is needed\
    \ to determine how the reference implementation presented in this\nwork can be\
    \ applied to emerging paradigms such as edge computing and fog computing. These\n\
    new settings bring a set of additional requirements in terms of, e.g., privacy,\
    \ that would require\nadditional investigation, exploring options such as federated\
    \ learning to implement machine\nlearning capabilities in distributed environments.\
    \ Another line in need of further investigation is\nthat of providing customized\
    \ visualization dashboards to end users. Although the implementation\ncontemplates\
    \ the use of the Wirecloud GE for creating web dashboards that allow to easily\n\
    visualize the available data, I aim to explore how end user could customize their\
    \ interface by\nadding, e.g., personalized recommendation systems and alarms.\
    \ For this purpose, I have been\nworking as part of the YODA Action (2019-ES-IA-0121\
    \ co-ﬁnanced by the Connecting Europe\nFacility of the European Union), aimed\
    \ at empowering European citizens in the Big Data era.\n78\nChapter 4\nData Usage\
    \ Control for Data Spaces\n4.1\nIntroduction\nExtracting value from data is one\
    \ of the key aspects leading the development of applications and\nservices, especially\
    \ for Industry 4.0 [Jeschke 2017]. Consequently, ensuring data governance and\n\
    traceability becomes imperative in order to promote the exchange of data in this\
    \ new business\nparadigm. Another crucial aspect of the data economy is interoperability\
    \ [Lu 2017], since sharing\ndata between different stakeholders brings many new\
    \ opportunities for all parties involved. In this\nscope, the use of trusted and\
    \ secure platforms for sharing and processing personal and industrial\ndata is\
    \ essential for the creation of a data market and a data economy.\nRegarding data\
    \ sharing and in terms of security, not only is it important to control who can\n\
    access what resource (covered by identity and access control respectively), but\
    \ also how data are\nallowed to be used once accessed. This is of special relevance\
    \ in publish/subscribe scenarios in\nwhich data are sent in real-time to data\
    \ consumers.\nIn such cases, after providing the data,\nproviders have no knowledge\
    \ or control over how data are treated, leaving consumers the\npossibility to\
    \ make unauthorized or outlawed actions over data that may have implications such\n\
    as privacy or anonymity violation, which are some of the major concerns of the\
    \ General Data\nProtection Regulation (GDPR) [Voigt 2017]. Access Control seems\
    \ to be insufﬁcient to protect\ndata trafﬁc in these scenarios. This measure needs\
    \ to be extended to a more comprehensive\nmodel, such as usage control, in order\
    \ to meet the industry’s new requirements, guaranteeing that\ndata consumers make\
    \ appropriate use of data.\nOne of the foundations of data sharing environments\
    \ is trust. Trust management concerns\nguaranteeing privacy and securing the exchange\
    \ of data among different stakeholders.\nStandardizing trust systems fosters data\
    \ transactions in the marketplace and eases compliance\nwith the data governance\
    \ framework deﬁned by each organization. The International Data Spaces\n(IDS),\
    \ formerly known as Industrial Data Spaces, Reference Architecture Model establishes\
    \ a\ntrust model to fulﬁll these requirements in the scope of Industry 4.0 and\
    \ deﬁnes data usage\ncontrol as one of the fundamental pillars to be addressed\
    \ in the new digital revolution\n[Otto 2018].\nIn the scope of usage control,\
    \ the Usage Control model (UCON) stated by Sandhu and Park\n[Sandhu 2003] was\
    \ presented as a new framework for providing not only traditional data access\n\
    control but also enabling the control of the data during and after the usage.\
    \ The UCON model\nextends the traditional access control models, not only by introducing\
    \ new concepts of mutability\napplicable to attributes of subjects and objects\
    \ but also by providing a new way of guaranteeing\nDATA USAGE CONTROL FOR DATA\
    \ SPACES\nthe continuity of policy enforcement. Moreover, UCON presents a family\
    \ of ABC models built\naround three decision factors: authorizations (A), obligations\
    \ (B) and conditions (C), which can\nall be used for pre-decision and ongoing\
    \ decisions.\nAs a complementary part of the\nconceptualization of UCON, one of\
    \ the formal model proposals of policies aligned with usage\ncontrol is presented\
    \ by [Bettini 2003],in which they attach two sets of predicates, namely\nprovisions\
    \ and obligations. On the one hand, provisions are concerned with the pre decision\n\
    phase (past and present), corresponding to the traditional access control. On\
    \ the other hand,\nobligations deal with the rules applied to the future use of\
    \ data and are related to the ongoing\ndecision phase which, instead, is executed\
    \ after the access is initiated and implements the\ncontinuity of control over\
    \ the data. The new features that by UCON derives in several attempts to\nimplement\
    \ usage control. However, the development of a complete framework of data usage\n\
    control applied to industrial data sharing ecosystems is still an open issue.\n\
    This chapter relies on a comprehensive architecture for providing data access\
    \ and usage\ncontrol in industrial data sharing ecosystems. This proposal incorporates\
    \ the core concepts from\nthe UCON model, the key aspects of the IDS Reference\
    \ Architecture Model and the extended\nXACML\n(eXtensible\nAccess\nControl\nMarkup\n\
    Language)\nReference\nArchitecture\n[OASIS Standard 1994]. In addition, the architecture\
    \ is integrated into a complete identity and\naccess control solution with support\
    \ to delegated application-scoped security management\n[Alonso 2017, Fernández\
    \ 2017]. Thanks to this integration, data providers can easily manage\naccess\
    \ and usage policies scoped to different scenarios of application. The conceptual\
    \ model of\nthe architecture was previously described in [Munoz-Arcentales 2019]\
    \ . This chapter extends\nsaid work by providing an implementation of the proposed\
    \ architecture and a validation with an\noriginal case study in the food industry.\n\
    The proposed architecture fulﬁlls the main requirements [Ravidas 2019] of Internet\
    \ of Things\n(IoT) applications developed in shared data scenarios.\nIt guarantees\
    \ reliability and\ninteroperability through the trusted and standardized environment\
    \ established thanks to the IDS\nframework. Likewise, IoT applications are usually\
    \ very demanding in terms of scalability. Thus,\nthe data usage control architecture\
    \ needs to meet this requirement. The extended XACML-based\narchitecture separates\
    \ each component based on its role, so each of these components can be\nscaled\
    \ as needed. In terms of dynamism, the proposed architecture can easily apply\
    \ predeﬁned\naccess and usage policies to the new dynamically added nodes, as\
    \ it stores and manages those\npolicies in a centralized way.\nIn this scenario,\
    \ the FIWARE platformi seems particularly suitable for implementing a usage\n\
    control architecture. FIWARE is an open initiative whose mission is to ease the\
    \ development of\nnew Smart Applications in multiple sectors by providing a set\
    \ of components, known as Generic\nEnablers (GE), that enable the connection among\
    \ IoT devices and Context Information\nManagement and other services such as security\
    \ or big data analysis.\nIn a previous work\niFIWARE: The open-source platform\
    \ for our smart digital future, https://www.ﬁware.org/\n80\n4.2. OBJECTIVES\n\
    [Alonso 2018], they proposed an implementation of the IDS architecture using FIWARE\n\
    components focused on data brokering, identity and trust management, and the development\
    \ of\nIDS Connectors. In the present work, I extend such implementation by adding\
    \ the components\nthat are needed to achieve usage control by data providers on\
    \ the basis of the architecture I\npropose. The newly added components introduced\
    \ in this work are the Policy Translation Point\n(PTP), the Usage Policy Decision\
    \ Point (uPDP) and the Policy Execution Point (PXP). A\nthorough explanation of\
    \ every one of these components is presented in Section 4.\nThis chapter is structured\
    \ as follows.\nNext section presents the objectives and research\nquestions of\
    \ this thesis covered in this chapter. Section 4.3 reviews the most relevant related\
    \ work\non data usage control. Section 4.4 presents a brief description of the\
    \ architecture that I took as a\nreference for this implementation including some\
    \ additional considerations for this proposal. In\nSection 4.5, an implementation\
    \ of the proposed solution using FIWARE components is\ndescribed. Section 4.6\
    \ presents a validation of said implementation by means of a use case in the\n\
    food industry, which includes the results obtained from measuring the enforcement\
    \ time when\napplying usage control policies. Lastly, Section 4.7 ﬁnishes with\
    \ the conclusions of the chapter\nand an outlook on future work.\n4.2\nObjectives\n\
    After the introduction, the two objectives of this chapter are:\n1. Identify the\
    \ key characteristics and needs of data usage control systems for being introduced\n\
    and applied in the context of data spaces\n2. Propose a design, implementation\
    \ and validation of an architecture for providing data usage\nand access control\
    \ in data spaces\nIn this chapter, I present an implementation of an architecture\
    \ for enabling data access and\nusage control in data-sharing ecosystems among\
    \ multiple organizations using the FIWARE\nEuropean open-source platform. Additionally,\
    \ a validation of this implementation through a real\nuse case in the food industry\
    \ was conducted.\nThis chapter also covers the following research questions:\n\
    • How should an architecture for providing data usage control in smart spaces\
    \ be designed\nso that it can be used in data sharing ecosystems with multiple\
    \ stakeholders?\n• How can the implementation feasibility of the proposed data\
    \ usage control architecture be\nveriﬁed?\nThese questions are answered based\
    \ on the results of the literature review conducted, the\nimplementation, and\
    \ the validation of the architecture proposed.\n81\nDATA USAGE CONTROL FOR DATA\
    \ SPACES\n4.3\nRelated Work\nAccording to [Xu 2019, Lee 2014, Yin 2015], the adoption\
    \ of big data and industrial IoT (IIoT)\nis rapidly growing in Industry 4.0. Previous\
    \ works have provided industrial solutions that make\nuse of this type of technologies\
    \ such as recommendation and prediction systems, process\noptimization\ntechniques,\n\
    intelligent\nmanufacturing,\nand\nAI\napplications\n[Mourtzis 2016, Gölzer 2015].\n\
    In this regard, many open source big data tools have been\ndeveloped to enable\
    \ companies to process the vast amount of data that are generated by the IIoT.\n\
    Several proposals present a general view of the big data architecture needed to\
    \ manage industrial\nscenarios in which multiple sources of data are present [Gokalp\
    \ 2016, Osman 2019]. The authors\nof [Zhu 2019] present a ﬁve-layer architecture\
    \ for big data processing and analytics (BDPA):\ncollection, storage, processing,\
    \ analytics, and application. Since each layer involves different\ntasks, many\
    \ open source tools have been developed to help overcoming some of them. Some\n\
    examples include:\n• Collection: ApacheKafka (Apache Kafka:\ni), Apache NiFi (Apache\
    \ NiFi:\nii), Orion\nFIWARE Context Broker (FIWARE Orion: iii).\n• Storage: CassandraDB\
    \ (CassandraDB: iv), HDFS (HDFS: v), MongoDB (MongoDB: vi).\n• Processing and\
    \ analytics: Apache Spark (Apache Spark: vii), Apache Flink (Apache Flink:\nviii),\
    \ Apache Storm (Apache Storm: ix), FIWARE Cosmos (FIWARE Cosmos: x).\n• Application:\
    \ Apache Zeppelin (Apache Zeppelin:\nxi), Kibana (Kibana:\nxii), GeoSpark\n(GeoSpark:\
    \ xiii).\nAs stated in [Mosavi 2017], big data processing in industry is different\
    \ in several aspects\nfrom other scenarios. One of the major concerns in this\
    \ sort of environments is the way in which\ndata are collected, considering that\
    \ data can derive from multiple sources. This issue has become\nihttps://kafka.apache.org/\n\
    iihttps://niﬁ.apache.org/\niiihttps://ﬁware-orion.readthedocs.io\nivhttp://cassandra.apache.org/\n\
    vhttps://hadoop.apache.org/docs/r1.2.1/hdfs_design.html\nvihttps://www.mongodb.com/es\n\
    viihttps://spark.apache.org/\nviiihttps://ﬂink.apache.org/\nixhttp://storm.apache.org/\n\
    xhttps://ﬁware-cosmos.readthedocs.io\nxihttps://zeppelin.apache.org/\nxiihttps://www.elastic.co/es/kibana\n\
    xiiihttps://github.com/DataSystemsLab/GeoSpark\n82\n4.3. RELATED WORK\nmore crucial\
    \ in data ecosystems shared among multiple organizations, since each organization\n\
    can process and store data in different ways and has different access and usage\
    \ rights over data.\nThus, I identify the need to use a common standard, compatible\
    \ with the existing big data tools\nand IoT devices, that provides a standardized\
    \ way to gather, extract, process and store data in\nindustrial contexts. In this\
    \ regard, NGSI-LD provides a simple and powerful open API published\nas an ETSI\
    \ speciﬁcation for the management of context information [NGSI-LD 2020].\nThis\n\
    speciﬁcation promotes the adoption of a standard way to manage data in the whole\
    \ industrial data\nprocessing pipeline. However, the use of a common standard\
    \ makes it imperative to use big data\ntools that can work with data in this format.\
    \ To address this issue, I include the FIWARE GEs in\nthe industry’s BDPA pipeline\
    \ since they comprise a set of libraries, connectors, and protocols on\ntop of\
    \ the most widely used big data frameworks provided by the Apache Community, providing\n\
    these components with full support for the NGSI-LD standard.\nWith the adoption\
    \ of this\napproach, any organization can not only perform big data operations\
    \ more easily using a common\nstandard, but also mitigate additional needs such\
    \ as enforcing data Usage Control and securing\ndata exchange.\nAs far as data\
    \ Usage Control is concerned, most of the proposals in the literature take the\n\
    UCON model [Sandhu 2003] as a starting point for the development of their solutions.\
    \ However,\ndepending on the ﬁeld of application, these works take different approaches.\n\
    For instance,\nRussello and Dulay presented xDUCON [Russello 2009b], a cross-domain\
    \ Usage Control\nproposal for coordinating and enforcing Usage Control policies\
    \ across different collaborating\norganizations.\nIn said framework, a cross-domain\
    \ data space instance is shared among the\norganizations to be used as a local\
    \ enforcement point of the control policies.\nAs a result,\nthe coordination of\
    \ the enforcement policies is easier to specify since it is not necessary to\n\
    include details of the receiving organization structure.\nA posterior paper was\
    \ presented by the same authors [Russello 2009a]. As a complementary\npart of\
    \ the xDUCON framework, they deﬁned cross-domain policies, which are capable of\n\
    dealing with the mutability issues of the UCON model and providing a ﬁne-grained\
    \ decision\nmechanism that can be captured by the deﬁned policies. The xDUCON\
    \ framework provides a\ngeneral perspective for providing capabilities of policy\
    \ enforcement and speciﬁcation.\nFurthermore, Di Cerbo et al. present a solution\
    \ for avoiding security risks and providing a\nmechanism for allowing the data\
    \ owners to keep the data under their control.\nThey\npresent [Cerbo 2015] a solution\
    \ that allows the provision of a secure data sharing across the cloud\nand mobile\
    \ engines. This is achieved by relying the enforcing mechanism and rules deﬁnition\
    \ on\nPolicy Deﬁnition Languages (PSLs) like XACML and an extended version of\
    \ PPL (PrimeLife\nPolicy Language) [Ardagna 2009]. However, these works fall short\
    \ of providing an architecture\nthat not only covers the enforcement and deﬁnition\
    \ mechanisms for access and Usage Control but\nalso provides a full description\
    \ of the whole process that data Usage Control involves.\nLikewise, Lazouski et\
    \ al. use the principles presented in [Jiao 2011] for providing a Usage\n83\n\
    DATA USAGE CONTROL FOR DATA SPACES\nControl solution mainly focused on cloud systems\
    \ applications. The conducted research is based\non the UCON model and the OASIS\
    \ XACML standard to regulate the usage of cloud\nresources [Lazouski 2012].\n\
    This proposal was validated by implementing the authorization\nsystem integrated\
    \ with OpenNebula (OpenNebula:\ni).\nMore comprehensive research was\npresented\
    \ by Wu et al. [Wu 2015], in which data Usage Control is enforced in industrial\
    \ Wireless\nSensor Networks (WSN). Not only do they provide cross-domain ﬁne-grained\
    \ Access Control,\nbut they also use fuzzy clustering to analyze industrial sensing\
    \ data. This work uses a set of\nsimulations for verifying the suitability of\
    \ the overhead time and the effectiveness of the\nproposed model. A comparable\
    \ proposal was presented by Marra et al. [Marra 2017]. They used\nthe core concepts\
    \ of UCON model and the XACML reference architecture in order to implement\na\
    \ Java application for providing Usage Control operations over IoT devices. They\
    \ developed a\ncase study in which they evaluate the performance of the IoT devices\
    \ and determined the\nfeasibility of the system by implementing their proposal\
    \ on real devices.\nRecent works provide some interesting solutions for data Usage\
    \ Control based on the\nXACML\nreference\narchitecture\nproposal.\nFor\ninstance,\n\
    Barsocchi\net\nal.\nuse\nGLIMPSE [Bertolino 2011], a ﬂexible monitoring infrastructure\
    \ for performing Usage Control\non operations over sensors in a smart home. They\
    \ demonstrate the feasibility of carrying out\nUsage Control in this type of environments.\
    \ In addition, in said study, the authors provide a low\ncost, easy to install,\
    \ user-friendly, dynamic and ﬂexible infrastructure, capable of performing\nrun-time\
    \ resource management using control rules [Barsocchi 2018]. Similarly, Gkioulos\
    \ et al.\npresent a model that can integrate access and Usage Control mechanisms\
    \ for dealing with the\ndistributiveness and heterogeneity of systems like IoT\
    \ and online banking. At the same time they\nbring several improvements regarding\
    \ resilience on active attacks, policy writing simpliﬁcation,\nrun-time efﬁciency\
    \ and scalability [Gkioulos 2019] .\nAnother proposal by Martinelli et al.\npresents\
    \ a framework for applying QoS in a network in a Smart Building environment.\n\
    They combine UCON and SDN (Software Deﬁned Networks) in order to enforce a set\
    \ of\nmanagement, security, and safety policies aimed at ensuring the appropriate\
    \ QoS for the provided\nservices according to both the tenants’ Service Level\
    \ Agreements (SLAs) and the current\ncontext [Martinelli 2019].\nLastly,\nan approach\
    \ presented by Milan Petkovi´c et al.\nin [Petkovi´c 2011] uses the business model\
    \ of an organization to detect privacy infringements and\nto verify that data\
    \ have been processed only for the intended purpose. The work presents a strong\n\
    point in formal speciﬁcation using Calculus of Orchestration of Web Services (COWS).\
    \ These\nproposals show the growing interest of the scientiﬁc and industrial community\
    \ in exploiting all\nthe capabilities of Usage Control, and also demonstrate its\
    \ application in speciﬁc scenarios (IoT,\nCloud, etc.). Nevertheless, these overtures\
    \ do not cover topics like cross-domain data exchange,\ndata governance and trust\
    \ environments, highlighting the need to deal with these topics before\nusing\
    \ this type of architecture in industrial data-sharing ecosystems. Moreover, in\
    \ Industry 4.0,\nihttps://opennebula.org\n84\n4.3. RELATED WORK\ndata sharing\
    \ between multiple organizations is a key factor to be considered. Thus, guaranteeing\n\
    the compliance with data governance rules and the responsible use of organizations’\
    \ data by\nthird-party entities is one of the requirements that needs to be addressed.\
    \ Therefore, the need to\ngenerate a more ﬂexible framework, capable of adapting\
    \ to these mixed data ecosystems,\nis identiﬁed.\nMoreover, the Data Privacy Directive\
    \ 95/46/EC [Poullet 2006], currently replaced by the\nGDPR, played an important\
    \ role in data protection. In this regard, many Access Control solutions\nare\
    \ currently presented for protecting personal data. For instance, Bartolini et\
    \ al. proposed a\nsystematic approach for authoring Access Control policies that\
    \ are aligned with GDPR\nprovisions.\nThey present a methodology for generating\
    \ templates from the GDPR text and\nidentifying if a GDPR article can be deﬁned\
    \ as an Access Control policy. This is achieved by\nmatching actual attributes\
    \ gathered from the legal use cases and translating the resulting policies\ninto\
    \ a given formalism or language [Bartolini 2019b] in order to comply with GDPR’s\
    \ principle\nof “data protection by design and by default” [Bartolini 2019a].\
    \ In the same line, Calabró et al.\nconducted a preliminary study for integrating\
    \ Access Control and business processes for GDPR\ncompliance. The main goal of\
    \ said study was to extend the currently adopted Access Control\nmechanisms to\
    \ enforce GDPR compliance during business activities of data management and\n\
    analysis [Calabró 2019]. Nevertheless, although these works provide a ﬁrst step\
    \ towards a formal\ndeﬁnition of an Access Control solution based on GDPR, they\
    \ do not cover the Usage Control of\nthe data once access is granted, opening\
    \ an issue that needs to be addressed. Another interesting\nproposal was presented\
    \ by Arfelt et al. who identiﬁes formalizable GDPR articles and, by using\nMetric\
    \ First-order Temporal Logic (MFOTL), formalizes and monitors the articles in\
    \ which\ncontrollers, processors, or data subjects are required to take speciﬁc\
    \ and observable actions\n[Arfelt 2019].\nMoreover, the policies generated with\
    \ the previous process are deployed over\nMONPOLY, a monitoring tool for compliance\
    \ checking [Basin 2012]. Although previous works\nsolve the problems of GDPR formalization\
    \ and monitoring, these proposals do not consider other\nfactors such as data\
    \ governance and trust that affect data sharing in cross-domain industries.\n\
    Prior works have sought Access Control solutions based on Blockchain for distributed\n\
    environments [Neisse 2017, Outchakoucht 2017, Ouaddah 2016].\nIn particular, the\
    \ authors of\n[Neisse 2017] describe how contracts can be deployed in the ledger\
    \ to perform Usage Control\nfollowing GDPR provisions and avoiding central entities\
    \ in the authorization and authentication\nprocesses. Overall, the cited studies\
    \ outline that relying on Blockchain provides transparency and\ntrust\nsolutions\n\
    for\nAccess\nControl\nbut\nit\nmay\nimpose\nscalability\nlimitations\nfor\nreal-time\
    \ scenarios.\nAs can be seen, much of the research up to now has been descriptive\
    \ in nature. Table 4.1\npresents a comparison of the Usage Control architectures\
    \ found in the literature. Most solutions\nrely only on ABAC (Attribute Based\
    \ Access Control) for Access Control and just a few proposals\nsupplement it with\
    \ RBAC (Role Based Access Control) or IBAC (Identity Based Access\n85\nDATA USAGE\
    \ CONTROL FOR DATA SPACES\nControl), which play a crucial role in data-sharing\
    \ scenarios in which it is necessary to provide\nparticular access and usage permissions\
    \ to different stakeholders. In addition, the existing Usage\nControl solutions\
    \ focus on policy infringement detection. Only about half of the works studied\n\
    provide remediation capabilities for policy violation, rather than just detection.\n\
    Remediation\nactions are essential to automatize the enforcement of consequences\
    \ for policy noncompliance\nrather than issuing warnings or notiﬁcations and leaving\
    \ it up to the wrongdoer to redress the\nsituation.\nIn order to univocally deﬁne\
    \ obligations, prohibitions and permissions, and the\nconsequences for noncompliance,\
    \ it is convenient to use a Policy Speciﬁcation Language (PSL).\nMost works found\
    \ in the literature rely on XACML or U-XACML as their PSL, although some of\n\
    them do not use a speciﬁc language or deﬁne one of their own. Another important\
    \ aspect is the\nsupport for multi-actor architectures. About half of the works\
    \ studied provide support for several\nactors involved in the data-sharing process,\
    \ whereas the rest of them focus on one-on-one\nexchanges. The former is a key\
    \ requirement for scenarios in which multiple stakeholders share\ndata with one\
    \ another. Furthermore, it is worth mentioning that most of the studies analyzed\
    \ in\nthis section fail to provide a data Usage Control solution that is independent\
    \ of the context in\nwhich data are generated (WSN, IoT, SDNs, etc.), with only\
    \ a couple of them being\ndomain-agnostic. Lastly, far too little attention has\
    \ been paid to the topic of trust environments as\na pillar for providing capabilities\
    \ for secure and trusted data exchange and sharing between\nmultiple organizations.\n\
    Table 4.1 : Comparison of usage control architectures\nReferences\nAccess Control\n\
    Remediation\nPSL\nMulti-Actor\nApplication Domain\n[Russello 2009b]\nABAC\nCross-Domain\n\
    Policy (xDPolicy)\nGeneric\n[Cerbo 2015, Ardagna 2009]\nABAC\nPPL,XACML\nCloud,\
    \ mobile\n[Jiao 2011, Lazouski 2012]\nABAC, RBAC,\nIBAC\nU-XACML\nCloud\n[Wu 2015]\n\
    RBAC\nIndustrial WSNs\n[Marra 2017]\nABAC\nU-XACML\nIoT\n[Barsocchi 2018]\nABAC,RBAC\n\
    Drools Rule\nLanguage (DRL)\nIoT\n[Gkioulos 2019]\nABAC\nU-XACML\nIoT\n[Martinelli\
    \ 2019]\nABAC,RBAC\nSDN\n[Petkovi´c 2011]\nABAC\nad-hoc\nGeneric\nIn light of\
    \ this information, it becomes apparent that previous works have failed to provide\n\
    a standard solution for achieving data Usage Control in data-sharing ecosystems.\
    \ None of the\nworks reviewed provides advanced Access Control and Usage Control\
    \ capabilities in\n86\n4.4. DATA USAGE CONTROL ARCHITECTURE DESIGN\narchitectures\
    \ with several agents involved, while supporting an expressive policy deﬁnition\n\
    language that allows the deﬁnition of obligations, prohibitions and permissions\
    \ and providing\nremediation functionalities in the event of policy infringement.\
    \ This research contributes to ﬁll\nthe gap in the existing literature by providing\
    \ a generic multi-actor architecture to achieve\nadvanced data access and usage\
    \ control capabilities in real-time data-sharing scenarios. This\nproposal incorporates\
    \ the core concepts from the UCON model, the key aspects of the IDS\nReference\
    \ Architecture Model and the extended XACML Reference Architecture, and relies\
    \ on\nODRL as its PSL. In addition, I provide an implementation using one of the\
    \ core CEF\n(Connecting Europe Facility) building blocks and FIWARE GEs for providing\
    \ a reference\nframework fully adapted to the requirements of Industry 4.0.\n\
    4.4\nData Usage Control Architecture Design\nThis section presents an overview\
    \ of the design principles that have been considered for\ndesigning this proposal.\
    \ It is also summarized the resultant architecture as well as a workﬂow\nthat\
    \ illustrates the interaction between the described components.\nDetails about\
    \ both the\nprinciples and the architecture can be found in our previous work\
    \ [Munoz-Arcentales 2019].\n4.4.1\nDesign Principles\n• Trust. IDS Connectors\
    \ provide a trusted environment that enables the achievement of data\nusage control\
    \ [Otto 2018].\n• Interoperability.\nStandardization of protocols is crucial to\
    \ ensure the understanding\nbetween all the components involved in the architecture,\
    \ for managing both usage control\nand identity.\n• Governance. Emerging data-centered\
    \ businesses need to deﬁne data governance programs\nin order to exploit data\
    \ in a cost-effective manner [Panian 2010].\nData sharing should\ncomply with\
    \ the data governance rules deﬁned by each of the organizations involved. In\n\
    this scope, providing ways to respect and protect the data of all the parties\
    \ involved is one\nof the main requirements that data usage control must fulﬁll.\
    \ Thus, data providers must\nhave access to monitoring and conﬁguration tools\
    \ that allow them to control what becomes\nof their data.\nNevertheless, as pointed\
    \ out by [Paci 2018], in collaborative systems,\nresources can be administered\
    \ by multiple data owners. Due to this fact, the aspects of data\ngovernance model,\
    \ policy composition and conﬂict resolution need to be addressed. In this\ncontext,\
    \ the concept of \"data governance model\" deﬁnes the authority that entities\
    \ have\nover a resource; \"policy composition\" describes how the authorization\
    \ requirements\nauthored by multiple entities are combined or reconciled to regulate\
    \ the access to a\nresource, and \"conﬂict resolution\" indicates the method used\
    \ to resolve policy conﬂicts in\norder to obtain a conclusive decision [Paci 2018].\
    \ In this regard, the preliminary version of\n87\nDATA USAGE CONTROL FOR DATA\
    \ SPACES\nthis proposed architecture takes the work presented by Mahmudlu et al.\
    \ as a reference, in\nwhich they deﬁne multiple ownership, authoritative and predeﬁned\
    \ mechanisms for\naddressing the main aspects of governance model, policy combination\
    \ and conﬂict\nresolution respectively [Mahmudlu 2016].\n• Performance.\nThe accomplishment\
    \ data usage control policies can be only ensured if\nreaction to policies violation\
    \ is quick and efﬁcient.\n• Flexibility. As many data sharing scenarios and use\
    \ cases are contemplated, the solution has\nto be adaptable to the speciﬁc requirements\
    \ of such scenarios.\n4.4.2\nAgents involved\nAccording to the the International\
    \ Data Spaces Association and IDS Reference Architecture\npresented by Fraunhofer\
    \ [Otto 2018] four agents have to be provided in every system that\nconsiders\
    \ data sharing: Data Owner (DO), Data Provider (DP), Data Consumer (DC) and Data\n\
    User (DU). However, it is very frequent to assume a two actors model in which\
    \ the DP and the\nDO play the same role as well as the DC and the DU. Taking into\
    \ account this assumption, the\nDP is the organization or user who is the proprietary\
    \ of the data and decides what data is\navailable for sharing.\nAdditionally,\
    \ the DP deﬁnes the usage and access control policies\napplicable to the data\
    \ that the DC can consume. On the other hand, the DC represent every entity\n\
    that has the legal rights to use the data provided by a DP according with the\
    \ previously deﬁned\nusage control policies.\nBesides these two actors, the GDPR,\
    \ deﬁnes an additional component named Data Controller\n(DCr) [European Data Protection\
    \ Supervisor 2019]. According to the DCr deﬁnition, a third actor\nneeds to be\
    \ included in order to cover the IDS reference architecture and the one proposed\
    \ by\nthe GDPR. In this case, the DCr and the DP are responsible for guaranteeing\
    \ the protection of\ndata owners’ rights and for providing access to data respectively.\
    \ Nevertheless, I consider that a\nmodel capable of being GDPR-compliant needs\
    \ to contemplate some other factors, as stated in\n[Calabró 2019] that are out\
    \ of the scope of this work. Thus, I concentrate my efforts on presenting\na preliminary\
    \ version of data usage control with a two-actor model (DP-DC), mainly focused\n\
    on data sharing ecosystems in Industry 4.0. However, below I present an alternative\
    \ proposal\narchitecture including the three-actor model.\nFinally, I also consider\
    \ the Identity Provider (IdP) as an actor presented in the IDS Reference\nArchitecture:\
    \ The IdP veriﬁes the authenticity of all the actors involved in the architecture\
    \ and also\nprovides all the characteristics related to identity management. These\
    \ include actor registration,\nauthentication, password management and, the option\
    \ of grouping actors in organizations in order\nto manage them under identical\
    \ conditions.\n88\n4.4. DATA USAGE CONTROL ARCHITECTURE DESIGN\n4.4.3\nArchitecture\
    \ and Workﬂow\nBuilding on the design principles established and the simpliﬁed\
    \ agent model identiﬁed for data\nprocessing scenarios (DC, DP and IdP), I have\
    \ presented an architecture for providing data usage\nand access control in shared\
    \ ecosystems. Fig. 4.1 shows the proposed two-actor architecture,\nwhereas Fig\
    \ 4.2 presents the aforementioned alternative architecture including the DCr as\
    \ a\nseparate agent.\nOn the other hand, Figs 4.3 and 4.4 show the workﬂow of\
    \ the two main scenarios of data\nsharing: (1) DP deﬁnes the policies that apply\
    \ to the shared data and (2) DC preforms operations\nto the received data.\nThe\
    \ DP uses the Policy Administration Point (PAP) to deﬁne access and usage control\n\
    policies. Usage policies are deﬁned using an Open Digital Rights Language (ODRL)\
    \ extension\nmaterialized by the W3C [McRoberts 2014] and translated by the Policy\
    \ Translation Point (PTP)\nto a program that runs on the usage Policy Decision\
    \ Point (uPDP) and that is updated every time\npolicies are modiﬁed by the DP.\
    \ Once both access and usage policies are deﬁned, the data in the\nData Infrastructure\
    \ (both real-time and stored) can be made available in the Shared Data Space\n\
    (SDS).\nWhen the DC requests access to data available in the SDS (to save them\
    \ in its Storage System\nor to process them using a Processing Engine), the Policy\
    \ Enforcement Point (PEP) checks with\nthe access Policy Decision Point (aPDP)\
    \ if the DC has the necessary access permissions to make\nthe subscription effective.\
    \ If the result is positive, the DC starts receiving data from the SDS and\nprocessing\
    \ them performing the desired operations. As a result of such operations, traces\
    \ are\ngenerated and sent to the PEP that, after validating an authentication\
    \ token previously generated\nby the IdP, redirects them to the uPDP. The uPDP\
    \ checks the usage policies and in case of\nnoncompliance delegates the responsibility\
    \ of enforcing the established action for policy\nnoncompliance to the Policy\
    \ Execution Point (PXP) by sending the corresponding control signal.\nOne concern\
    \ identiﬁed in this proposal is that the logs generated when performing operations\n\
    on data could be easily manipulated due to the fact that log generation takes\
    \ place outside the\nscope of the DP. Nevertheless, the reference architecture\
    \ used in this work relies on the guidelines\nof the IDS connectors, which determine\
    \ that all the connectors involved in a data exchange must\nrun a trusted (certiﬁed)\
    \ software stack. Worded differently, IDS Connectors require a certiﬁcation\n\
    from the IDS Certiﬁcation Body in order to establish trust among all participants.\n\
    Moreover, the IDS guidelines also establish that any communication between connectors\
    \ from\ndifferent organizations should be encrypted and integrity protected. Thus,\
    \ by including the DP\nand DC inside IDS connectors, each DP is capable of ensuring\
    \ that their data are handled by the\nConnector of the DC according to the usage\
    \ policies speciﬁed, or else the data will not be sent\n[Otto 2018].\n89\nDATA\
    \ USAGE CONTROL FOR DATA SPACES\nFigure 4.1 : Data usage control architecture\n\
    4.5\nData Usage Control Implementation\nThis section presents an implementation\
    \ of the proposed architecture using the generic enablers\n(GEs) provided by FIWARE\
    \ and other open-source tools. Speciﬁcally, the GEs utilized in this\nimplementation\
    \ of the data usage architecture are the following:\n• Keyrock The Keyrock GEi\
    \ is responsible for Identity Management.\nUsing Keyrock\nenables OAuth 2.0-based\
    \ authentication and authorization security to services and\napplications, as\
    \ described in [Alonso 2017, Fernández 2017].\nIn the context of this\nimplementation,\
    \ Keyrock plays the role of IdP, manages authorization policies (PAP) and\ndecides\
    \ which DCs can access which resources in the data infrastructure (aPDP).\nTherefore,\
    \ DPs and DCs perform the authentication process relying on Keyrock.\nGuaranteeing\
    \ the unequivocal identiﬁcation of all the agents involved in the data usage\n\
    architecture is mandatory in order to ensure a secure way of providing or consuming\
    \ data.\nBy using Keyrock, DPs can create authorization policies to constrain\
    \ DCs’ access to the\ndata infrastructure.\niFIWARE Keyrock: https://ﬁware-idm.readthedocs.io\n\
    90\n4.5. DATA USAGE CONTROL IMPLEMENTATION\nFigure 4.2 : Data usage control with\
    \ three actors architecture\n• Wilma:\nThe Wilma GEi brings support of proxy functions\
    \ within OAuth 2.0-based\nauthentication schemas.\nIt also implements PEP functions\
    \ within an XACML-based\naccess control schema [OASIS Standard 1994]. In the scope\
    \ of this implementation, two\nWilma instances are needed. One Wilma instance\
    \ is in charge of enforcing access policies\nover requests sent to the data infrastructure\
    \ [Alonso 2018]. When a DC is authenticated\nthrough Keyrock, an OAuth 2.0 token\
    \ is generated, which must be included in every\nrequest sent to the DP’s data\
    \ infrastructure. Wilma intercepts requests and asks Keyrock to\nvalidate the\
    \ token, verifying the DC’s identity. Since Keyrock also acts as the aPDP, it\n\
    checks the DC’s access authorization policies. In case that the DC’s request complies\
    \ with\nthe established policies, Wilma grants access to the requested resource.\
    \ With regard to data\niFIWARE Wilma: https://ﬁware-pep-proxy.readthedocs.io\n\
    91\nDATA USAGE CONTROL FOR DATA SPACES\nFigure 4.3 : Workﬂow for the DP\nusage\
    \ control, a second Wilma instance is needed as a PEP proxy in order to authenticate\n\
    the traces sent from the DC’s processing engine to the uPDP.\n• AuthZForce: The\
    \ AuthZForce GEi brings additional support to aPDP/PAP functions\nwithin an access\
    \ control schema based on the XACML standard. It has not been included\nin the\
    \ present implementation, but it could be used to create more advanced ﬁne-grained\n\
    authorization policies and to make decisions over requests received from PEPs.\n\
    • Orion:\nThe Context Broker (Orion) GEii manages the entire lifecycle of context\n\
    information including updates, queries, registrations and subscriptions.\nThe\
    \ Context\nBroker\noffers\nthe\nFIWARE\nNGSI\n(Next\nGeneration\nService\nInterface)\n\
    [Open Mobile Alliance 2012] APIs and associated information model (entity, attribute,\n\
    metadata) as the main interface for sharing data among stakeholders. In addition\
    \ to being\nthe centerpiece of any platform “powered by FIWARE”, the Context Broker\
    \ has been\nrecognized as a CEF Building Block, which is one step forward on its\
    \ path towards\niFIWARE AuthZForce: https://authzforce-ce-ﬁware.readthedocs.io\n\
    iiFIWARE Orion:https://ﬁware-orion.readthedocs.io\n92\n4.5. DATA USAGE CONTROL\
    \ IMPLEMENTATION\nFigure 4.4 : Workﬂow for the DC\nbecoming a global standard\
    \ for large scale contextual information management\n[Digital CEF 2018] . In the\
    \ context of this implementation, it constitutes the DP’s data\ninfrastructure\
    \ and SDS, which enables the sharing of data between the DC and the DP in\na secure\
    \ way. In other words, the DP makes use of the NGSI API provided by the Orion\n\
    Context Broker in order to publish or expose the data they have to offer, whereas\
    \ DCs\nretrieve or subscribe to said data.\n• Cosmos: The Cosmos GEi provides\
    \ an interface for integrating Apache Flink and Apache\nSpark with the rest of\
    \ the components in the FIWARE Ecosystem. Over the last years,\niFIWARE Cosmos:\
    \ https://ﬁware-cosmos-ﬂink.readthedocs.io\n93\nDATA USAGE CONTROL FOR DATA SPACES\n\
    Apache Flink and Apache Spark have established themselves as the most popular\
    \ open-\nsource data processing frameworks. Both of them provide a wide assortment\
    \ of resources\nfor processing data both in streaming and batch modes. Since Apache\
    \ Spark and Apache\nFlink provide similar functionalities, an implementation with\
    \ only one of these frameworks\nis enough to validate the proposed architecture.\
    \ Therefore, for the implementation presented\nin this work, I have relied on\
    \ the Apache Flink as the processing engine on the DC’s side,\nin charge of performing\
    \ operations on the DP’s data.\n• Draco: The Draco GEi is aimed at providing storage\
    \ of historical context data, allowing to\nreceive data events and dynamically\
    \ recording them with a predeﬁned structure in several\ndata storage systems.\
    \ In the scope of this implementation, Draco is proposed as the building\nblock\
    \ for providing the storage system in the DC’s infrastructure.\nThe aforementioned\
    \ FIWARE GEs provide all the features needed to implement the\ncomponents on the\
    \ DC’s side (processing engine and data storage), the access control\ncomponents\
    \ (PAP, PEP, and aPDP), the SDS, and the IdP. As the FIWARE catalogue lacks any\n\
    GEs that aid in the implementation of usage control capabilities, I have developed\
    \ several ad-hoc\ncomponents for this purpose that will be included as FIWARE\
    \ GEs in the near future:\n• The PTP is a piece of software written in Python\
    \ in charge of translating the ODRL usage\npolicies deﬁned through Keyrock into\
    \ a Complex Event Processing (CEP) program using the\nFlink CEP Scala API. Every\
    \ time the usage policies that apply to a certain DC are modiﬁed\nby the DP, a\
    \ new program is generated by the PTP containing a CEP rule for each policy.\n\
    This program is then compiled, packaged, and sent to the uPDP.\n• The uPDP is\
    \ an Apache Flink computation cluster that runs all the CEP programs generated\n\
    by the PTP: one for each DC. These programs take advantage of the CEP capabilities\
    \ of\nApache Flink in order to verify whether the DC complies with the policies\
    \ deﬁned by the DP\nor not. This is done by analyzing the traces generated by\
    \ the processing engine on the DC’s\nside (Apache Flink in this case) which are\
    \ sent to the uPDP. In the event of noncompliance,\nthe PXP is notiﬁed.\n• The\
    \ PXP is a piece of software that is notiﬁed each time the uPDP detects policy\n\
    noncompliance. It is written in Scala and attached to each program that runs on\
    \ the uPDP.\nThe PXP enforces the control signal established by the DP for the\
    \ unfulﬁlled policy. For\ninstance, in order to stop a DC from receiving data\
    \ as a punishment for policy\nnoncompliance, the control signal sent by the PXP\
    \ is an unsubscription request to Orion. If\nthe DC is, in turn, processing data\
    \ in an incorrect manner, one way to punish this policy\nviolation would be to\
    \ send a control signal that kills the processing job on the DC’s side.\niFIWARE\
    \ Draco: https://ﬁware-draco.readthedocs.io\n94\n4.5. DATA USAGE CONTROL IMPLEMENTATION\n\
    Figure 4.5 : Data usage control architecture using FIWARE\nThese are the control\
    \ signals that have been implemented so far, but the goal is to extend\nthe capabilities\
    \ of the PXP in order to support custom control signals written by the DP.\nFig.\
    \ 4.5 shows the data usage architecture proposed using the aforementioned FIWARE\
    \ GEs\nand ad-hoc components developed, as well as the workﬂow mechanism presented\
    \ in subsection\n4.4.3. The operation ﬂow during one usage decision process is\
    \ deﬁned as follows:\n• The DC sends a subscription request to the Orion Context\
    \ Broker in order to retrieve data\nfrom the DP.\n• The subscription request is\
    \ intercepted by the access PEP Proxy and validated by the IdP\nand the aPDP by\
    \ checking whether the token containing the user information is valid an if\n\
    the user has the right to access the requested resource.\n• Once the subscription\
    \ is done, the DC starts receiving data from the Orion Context Broker\nat the\
    \ processing engine. The traces generated by the program containing all the operations\n\
    performed on data are sent to the uPDP, verifying the DC’s identity through the\
    \ usage PEP\nProxy. Moreover, this instance of the PEP Proxy is in charge of redirecting\
    \ the traces to\n95\nDATA USAGE CONTROL FOR DATA SPACES\neach speciﬁc uPDP CEP\
    \ program. When translating the deﬁned ODRL policies for a DC,\nthe PTP generates\
    \ a new CEP program and maps the port where it runs to the DC. Thus,\nwhen receiving\
    \ the traces and after verifying the DC’s identity, the PEP Proxy knows the\n\
    port in which the corresponding CEP program is running and can redirect the traces\
    \ to it.\nThe uPDP then veriﬁes that the DC complies with all the policies deﬁned\
    \ through the PAP.\nOtherwise, the uPDP notiﬁes the PXP, who sends the corresponding\
    \ control signal.\n4.6\nValidation: A case study in the food industry\nIn order\
    \ to validate the proposed architecture and implementation using FIWARE, a case\
    \ study\nhas been developed in the food industry. The components presented in\
    \ the implementation section\nhave been deployed in order to perform the policy\
    \ deﬁnition and enforcement in a shared data\necosystem. The main goal of this\
    \ case study is to perform access and usage control over industrial\ndata.\n4.6.1\n\
    Scenario overview\nThe scenario is composed by two actors: a food company (DP)\
    \ and a marketing company (DC).\nThe former generates a great amount of data on\
    \ a daily basis every time a client makes a purchase\nat one of their grocery\
    \ stores, which are later used for internal big data analysis. One data record\n\
    is generated for each purchase, which consists of the client id, the payment method,\
    \ and the list\nof products purchased, including the product name, price and quantity.\
    \ The board of the company\nrealizes that if they were to share these data, they\
    \ would allow other businesses to ﬁnd new ways of\nextracting value from them,\
    \ thus creating another source of revenue for the company. A marketing\ncompany\
    \ is interested in the food company’s real-time data in order to identify trends\
    \ and carry\nout instantaneous special offers that take these into account. In\
    \ order for the marketing company\nto be able to make this analysis, the food\
    \ company has to provide a real-time channel to make\ntheir data available to\
    \ them. However, the food company wants to keep the marketing company\nfrom making\
    \ an incorrect use of the data that would jeopardize customers’ privacy. For the\
    \ sake\nof data protection, a set of usage control policies are deﬁned in order\
    \ to enforce some constraints\nover the shared data. In this scenario, the DC\
    \ deploys one Flink Cluster for performing all the data\nprocessing operations.\
    \ On the other hand, the DP deploys all the components showed on the right\nside\
    \ of Fig 4.4, including the data generated and published by the cash registers\
    \ on the Context\nBroker as part of the data infrastructure stakeholder.\n4.6.2\n\
    Policy speciﬁcation\nIn the proposed scenario, the DP deﬁnes two main policies\
    \ regarding data usage that apply to any\nexternal DC. The natural language deﬁnition\
    \ for these policies is:\n96\n4.6. VALIDATION: A CASE STUDY IN THE FOOD INDUSTRY\n\
    • Policy A: The DC shall NOT save the data without aggregating them every 15 minutes\
    \ ﬁrst\nor else the processing job will be terminated\n• Policy B: The DC shall\
    \ NOT receive more than 200 notiﬁcations from the Context Broker\nin a minute\
    \ or else the subscription to the entity will be deleted\nAs mentioned, in order\
    \ to take full advantage of all the capabilities of data usage control, usage\n\
    policies must be deﬁned by using a policy speciﬁcation language and, although\
    \ ODRL provides\na powerful interface to deﬁne these [Steyskal 2015], in the future,\
    \ it will be necessary to develop\nof new vocabularies and ontologies for tackling\
    \ some currently uncovered cases. However, in this\ncase study I include a ﬁrst\
    \ approximation of the use of ODRL in order to declare the two policies\nthat\
    \ have been presented in natural language. The aim of using ODRL is to provide\
    \ dynamic\ncapabilities so as to enable the PTP to generate an extended automaton\
    \ on the basis of the policies,\nthat will run on the uPDP.\n{\n\"@context\":\
    \ [\n\"http://www.w3.org/ns/odrl.jsonld\",\n\"http://keyrock.ﬁware.org/FIDusageML/proﬁle/FIDusageML.jsonld\"\
    \n],\n\"@type\": \"Set\",\n\"uid\": \" http://keyrock.ﬁware.org/FIDusageML/policy:1010\"\
    ,\n\"proﬁle\": \"http://keyrock.ﬁware.org/FIDusageML/proﬁle\",\n\"permission\"\
    : [{\n\"target\": \"http://orion.ﬁware.org/NGSIkilljob\", \"action\": \"ReadNGSIWindow\"\
    ,\n\"constraint\": [\n{\n\"leftOperand\":\"WindowNotiﬁcation\",\n\"operator\"\
    : \"gt\",\n\"rightOperand\": {\n\"@value\": \"Sink\",\n\"@type\": \"xsd:String\"\
    \n}\n}]\n},\n{\n\"target\": \"http://orion.ﬁware.org/NGSInotiﬁcation\",\n\"action\"\
    : \"ReadNGSIWindow\",\n\"constraint\": [\n{\n\"leftOperand\": \"WindowNotiﬁcationValueSet\"\
    ,\n\"operator\": \"gt\",\n\"rightOperand\": {\n\"@value\": \"200\",\n97\nDATA\
    \ USAGE CONTROL FOR DATA SPACES\n\"@type\": \"xsd:integer\" }\n}]\n}],\n\"prohibition\"\
    : [\n{\n\"target\": \"http://orion.ﬁware.org/NGSInotiﬁcation\",\n\"action\": \"\
    SingleEventProcessing\" },\n{\n\"target\": \"http://orion.ﬁware.org/NGSIkilljob\"\
    ,\n\"action\": \"CopyConstrain\" }]\n}\nListing 4.1: ODRL Speciﬁcation of Policy\
    \ A and Policy B\nThe code that the PTP generates from the ODRL speciﬁcation is\
    \ showed in Listing 2. This\nprogram is in charge of correlating complex events\
    \ generated by the DC’s operations with the\nrules regarding data usage. The value\
    \ countPattern represents the maximum number of\nevents (timesOrMore) that can\
    \ be received in the time window (within) speciﬁed in Policy\nA. Whenever the\
    \ program detects a behaviour that fails to comply with this rule, it immediately\n\
    passes the control to the PXP (Signals.createAlert) in order to send the control\
    \ signal to\nthe corresponding component according to the punishment previously\
    \ deﬁned. A similar pattern\nis applied to Policy B.\nval\noperationStream\n:\n\
    DataStream [ ExecutionGraph ] = stream\n. f i l t e r ( _ . i s R i g h t )\n\
    . map ( _ . r i g h t . get )\n. flatMap ( _ . msg . s p l i t ( \" −> \" ) )\n\
    . map ( ExecutionGraph )\n/ /\nE n t i t y\nStream\nval\ne n t i t y S t r e a\
    \ m\n:\nDataStream [ E n t i t y ] = stream\n. f i l t e r ( _ . i s L e f t )\n\
    . map ( _ . l e f t . get\n)\n. flatMap ( _ . e n t i t i e s )\n/ /\nF i r s\
    \ t\np a t t e r n :\nAt\nl e a s t N e v e n t s\nin T .\nAny\nother\ntime\n\
    val\nc o u n t P a t t e r n = P a t t e r n . begin [ E n t i t y ] ( \" events\
    \ \"\n)\n. timesOrMore ( P o l i c i e s . numMaxEvents +1)\n. within ( Time .\
    \ seconds ( P o l i c i e s . f a c t u r a t i o n T i m e ) )\nCEP . p a t t\
    \ e r n ( entityStream ,\nc o u n t P a t t e r n )\n. s e l e c t ( events =>\n\
    S i g n a l s . c r e a t e A l e r t (\nPolicy .COUNT_POLICY,\nevents ,\nPunishment\
    \ . UNSUBSCRIBE ) )\n98\n4.6. VALIDATION: A CASE STUDY IN THE FOOD INDUSTRY\n\
    / /\nSecond\np a t t e r n :\nSource −> Sink .\nAggregation TimeWindow\nval\n\
    a g g r e g a t e P a t t e r n = P a t t e r n . begin [ ExecutionGraph ]\n(\
    \ \" s t a r t \" ,\nAfterMatchSkipStrategy . s k i p P a s t L a s t E v e n\
    \ t ( ) )\n. where ( P o l i c i e s . executionGraphChecker ( _ ,\n\" source\
    \ \" ) )\n. notFollowedBy ( \" middle \" )\n. where ( P o l i c i e s\n. executionGraphChecker\
    \ ( _ , \" a g g r e g a t i o n \" , P o l i c i e s . aggregateTime ) )\n. followedBy\
    \ ( \" end \" )\n. where ( P o l i c i e s . executionGraphChecker ( _ ,\n\" sink\
    \ \" ) )\n. timesOrMore ( 1 )\nCEP . p a t t e r n ( operationStream ,\na g g\
    \ r e g a t e P a t t e r n ) . s e l e c t ( events =>\nS i g n a l s . c r e\
    \ a t e A l e r t (\nPolicy .AGGREGATION_POLICY,\nevents ,\nPunishment . KILL_JOB\
    \ ) )\nListing 4.2: uPDP code generated from the ODRL Speciﬁcation by the PTP\n\
    4.6.3\nData processing and policy enforcement\nOnce the policies have been deﬁned,\
    \ the DC may start to deploy processing jobs on their own\ninfrastructure with\
    \ the aim of extracting value from the supermarket data received. In order to\n\
    validate the two policies deﬁned by the DP, I have created two sample jobs that\
    \ operate on the\nDP’s data:\nJob I: Direct sinking of ticket data\nThe ﬁrst job\
    \ reads the data received from the DP and sends\nthem somewhere else, outside\
    \ of the scope of the data usage architecture, where operations on\ndata are not\
    \ monitored. Since this use allows the DC to process each piece of data individually,\n\
    without prior aggregation, it is a clear violation of Policy A. When the DC deploys\
    \ this job in the\nFlink Cluster, an execution graph is calculated from the program\
    \ code, such as the one in Fig. 4.6.\nFigure 4.6 : Simpliﬁed Execution Graph of\
    \ Job I\nThe log containing the chain of operations is sent to the uPDP, which\
    \ will detect that the\nexecution graph contains no aggregation of data, thus\
    \ failing to comply with Policy A. The uPDP\nwill inform the PXP of this violation,\
    \ which will send the corresponding control signal described\nin the policy; in\
    \ this case, terminating the job as a punishment for noncompliance.\n99\nDATA\
    \ USAGE CONTROL FOR DATA SPACES\nJob II: Calculating average ticket price\nThe\
    \ second job calculates the average ticket price for\nall the clients of each\
    \ store every hour. This operation is an aggregation of data so, when the\nExecution\
    \ Graph is checked by the uPDP, it will be veriﬁed that it complies with Policy\
    \ A. Fig.\n4.7 shows the execution graph generated for this use case.\nFigure\
    \ 4.7 : Simpliﬁed Execution Graph of Job II\nEach time the DC receives information\
    \ from one ticket, this event is logged and sent to the\nuPDP. If the uPDP detects\
    \ that the DC has received more tickets than the amount speciﬁed by\nPolicy B\
    \ (200), the PXP will be notiﬁed and will enforce the corresponding punishment\
    \ (i.e.\nremoving the subscription to the tickets’ data).\nOverall, the case study\
    \ presented in this section, including the deployment of both DC’s jobs,\nshows\
    \ that the data usage architecture provides a way of verifying that the DC complies\
    \ with a set\nof predeﬁned policies by the DP and of executing punishments in\
    \ case of noncompliance.\n4.6.4\nResults\nThis subsection presents a series of\
    \ metrics carried out in the case study presented that aim to\ncalculate the enforcement\
    \ time of the policies deﬁned. To this end, the two jobs presented were\ndeployed,\
    \ achieving noncompliance conditions for both of them.\nIn accordance with the\
    \ scheme presented in the implementation section, I deﬁne the\ndeployment of all\
    \ the components as follows: every building block of the DC and DP was\ndeployed\
    \ using Docker Containersi. However, in order to test the usage control policies\
    \ and\nobtain more accurate metrics, I deployed the DC and the DP in different\
    \ platforms. On the one\nhand, the DP’s containers were placed inside of a VM\
    \ (Virtual Machine) in an Edge Computing\nInfrastructure using OpenStackii, this\
    \ VM has the following features: 2VCPU’s, 4GB RAM,\n40GB Disk. On the other hand,\
    \ the DC’s containers were placed in a local server located in the\nsame network\
    \ as the DP’s VM with the following speciﬁcations: 4.0 GHz Intel core I7 CPU with\n\
    8GB RAM and 256 SSD Disk. This deployment allowed testing different policies and\
    \ measure\noverhead time.\nThe workﬂow of submitting a job on the DC’s side, detecting\
    \ the policy\nnoncompliance, and enforcing the due punishment was repeated N times\
    \ (N = 100) for each\npolicy.\nThrough the system logs generated by the DC’s and\
    \ DP’s containers, three different\nmetrics were calculated:\niDocker: https://www.docker.com\n\
    iiOpenStack: https://www.openstack.org\n100\n4.6. VALIDATION: A CASE STUDY IN\
    \ THE FOOD INDUSTRY\n• Decision time (Td): Time between the policy infringement\
    \ on the DC’s side and the\ndetection of said infringement at the uPDP on the\
    \ DP’s side.\n• Execution time (Tx): Time between the policy infringement detection\
    \ at the uPDP and the\nexecution of the punishment at the PXP.\n• Total enforcement\
    \ time (Tt): Sum of Td and Tx.\nTable 4.2 summarizes the results obtained for\
    \ each policy and interval, including the mean\ntime (M) and the standard deviation\
    \ (SD). The results for each iteration can be seen in Fig. 4.8\nand 4.9.\nFigure\
    \ 4.8 : Policy A enforcement metrics\nTable 4.2 : Summary of enforcement time\
    \ metrics\nPolicy A\nPolicy B\nM\nSD\nM\nSD\nTd (ms)\n125.8\n33.8\n94.6\n31.4\n\
    Tx (ms)\n3.7\n5.0\n4.0\n1.5\nTt (ms)\n129.5\n34.5\n98.6\n31.6\n101\nDATA USAGE\
    \ CONTROL FOR DATA SPACES\nFigure 4.9 : Policy B enforcement metrics\nAs is apparent\
    \ from the results shown in Table 4.2, the times registered for Td are signiﬁcantly\n\
    larger than those recorded for Tx. The main reason for this difference is the\
    \ fact that Td involves\ngenerating the logs on the DC’s side, writing them on\
    \ the processing engine’s log ﬁle and sending\nthem to the uPDP, which will receive\
    \ them after they are ﬁrst veriﬁed by the PEP. By contrast, the\nTx is very low\
    \ since the PXP is embedded in the same program that the uPDP is running, which\n\
    means that the delay introduced stems from the time it takes to receive an acknowledgement\
    \ from\nthe control signal sent to the system in charge of performing the actual\
    \ punishment (to the Context\nBroker in order to remove a subscription, or to\
    \ the DC’s processing engine to cancel the job).\nFurthermore, the slight difference\
    \ in measurements for Tx between policies A and B draws\nfrom the difference in\
    \ response times between the Context Broker and the processing engine on\nthe\
    \ DC’s side. On the other hand, the difference in Td between policies A and B\
    \ is due to the\nfact that, in the former, the noncompliance is detected by inspecting\
    \ the execution graph, which is\nreceived by the uPDP as a single log, whereas\
    \ in the latter, the uPDP needs to inspect the message\nhistory to conﬁrm that\
    \ the notiﬁcation limit established within the policy has been exceeded, which\n\
    is a more costly operation.\nAs far as the total time (Tt) is concerned, the Tx\
    \ can be neglected for its calculation if the\npunishment does not involve interacting\
    \ with stakeholders outside a shared network (the Context\nBroker, for instance).\
    \ Otherwise, the network latency needs to be taken into account. This holds\n\
    true for the Td as well, since typically the DC and the DP are in physically separate\
    \ networks.\n102\n4.7. CONCLUSIONS\nThe results obtained for Tt fall within a\
    \ reasonable range of values for most use cases, in which\nnew data are generated\
    \ every second or few seconds. However, in scenarios in which new data are\npublished\
    \ within milliseconds, there could be a period between the infringement of the\
    \ rules and\nthe enforcement of the punishments in which new data are unduly received\
    \ by the DC. In order to\nverify that this was not the case, I tested the solution\
    \ under different stress situations. I deployed\nthe use case scenario using different\
    \ frequencies of generation of new data. The main goal was to\ncorroborate that\
    \ no additional data events arrived from the moment an infringement was committed\n\
    and the moment that the due punishment was executed. The use case scenario was\
    \ tested for\ndata generation periods ranging from 5s to 25ms (5s, 1s, 500ms,\
    \ 250ms, 100ms, 50ms, 25ms),\nrepeating each simulation 100 times. I found that\
    \ all the situations of data infringement were\ndetected and the appropriate punishment\
    \ was enforced in due time in 100% of the cases. Thus, no\nnew information was\
    \ unduly received after failing to comply with a certain policy. Nevertheless,\n\
    it is worth pointing out that, for periods under 25ms, I have to consider the\
    \ throughput limit of the\nSDS (in this case the Context Broker) since this component\
    \ is the one that determines the actual\nspeed at which data will be sent to the\
    \ endpoints that are subscribed to new data.\nPrior works [Wu 2015, Marra 2017]\
    \ have also collected a series of metrics in order to validate\ntheir models.\
    \ For example, [Marra 2017] determines if the performance of their usage control\n\
    system is higher whether it is applied to local or remote attributes.\nFurthermore,\
    \ instead of\nmeasuring enforcement time, [Wu 2015] focuses on performance at\
    \ the access control level.\nAlthough an exact comparison between said models\
    \ and the one presented in this work cannot be\nperformed, since none of the works\
    \ found in the existing literature provide measurements of the\ndecision and enforcement\
    \ times, it can be seen that the measurements for delay and response\ntimes are\
    \ in the same order of magnitude.\nThe implementation of the architecture presented\
    \ in this thesis provides a comprehensive and\naffordable solution for providing\
    \ access and usage control in industrial data ecosystems. One of\nthe advantages\
    \ of this proposal stems in the fact that it is suitable for being implemented\
    \ in a\nwide range of different scenarios since it is a technology-agnostic solution.\
    \ Moreover, this piece\nof research also presents an implementation of the referenced\
    \ architecture using FIWARE\nGeneric Enablers that completes the previously proposed\
    \ implementation of IDS architecture\n[Alonso 2018]. The implementation presented\
    \ has been validated with a use case in the food\nindustry, presenting a series\
    \ of metrics of the response time of policy compliance veriﬁcation and\npunishment\
    \ enforcement. The data usage control components developed in the scope of this\
    \ work\n(uPDP, PXP and PTP) have been proposed and accepted as a new Generic Enabler\
    \ in the\nFIWARE catalogue.\n4.7\nConclusions\nThe implementation of the architecture\
    \ presented in this chapter provides a comprehensive and\naffordable solution\
    \ for providing access and usage control in industrial data ecosystems. One of\n\
    103\nDATA USAGE CONTROL FOR DATA SPACES\nthe advantages of this proposal stems\
    \ in the fact that it is suitable for being implemented in a\nwide range of different\
    \ scenarios since it is a technology-agnostic solution. Moreover, this piece\n\
    of research also presents an implementation of the referenced architecture using\
    \ FIWARE\nGeneric Enablers that completes the previously proposed implementation\
    \ of IDS architecture\n[Alonso 2018]. The implementation presented has been validated\
    \ with a use case in the food\nindustry, presenting a series of metrics of the\
    \ response time of policy compliance veriﬁcation and\npunishment enforcement.\
    \ The data usage control components developed in the scope of this work\n(uPDP,\
    \ PXP and PTP) have been proposed and accepted as a new Generic Enabler in the\n\
    FIWARE catalogue.\nAs a conclusion to this work, I identify the need of deﬁning\
    \ a policy speciﬁcation language\ncapable of handling the ﬁne-grained policy deﬁnitions\
    \ in order to provide the data usage control\ncapabilities in Industry. Furthermore,\
    \ I consider this architecture could be expanded to provide\nGDPR compliance by\
    \ introducing the GDPR regulation rules inside the deﬁnition of the policies\n\
    and deploying them inside this architecture.\nI will focus the future efforts\
    \ on the Policy\nSpeciﬁcation Language deﬁnition, conceived as an extension of\
    \ ODRL, as Ill as the deﬁnition of\na common vocabulary that allows to standardize\
    \ and identify the events and traces of the system\nfor the different processing\
    \ engines. Additionally, I intend to develop new and more complex\ntests that\
    \ allow us to extract additional metrics in the scope of data protection.\n104\n\
    Chapter 5\nValidation and Results\nIn this chapter, I describe the work developed\
    \ during these four years of research serving as\nvalidation of the results obtained.\n\
    First, I present the works made in international research\nprojects. In his section,\
    \ I will provide details about the work conducted in each of them according\n\
    to the proposals of this thesis. The second block of this section corresponds\
    \ to the dissemination\nof the results. These are composed by the publication\
    \ of articles in Journals and Conferences and\neven are considered some seminars\
    \ and curses imparted about the contributions presented in this\ndocument.\n5.1\n\
    International Projects\n5.1.1\nFIWARE, FICORE and FI-NEXT\nThese are projects\
    \ with European ﬁnancing that are very closely related between them FICORE\nis\
    \ the continuation of FIWARE and the goal of both is the creation of a technological\
    \ ecosystem\nbased on generic and re-utilizable components known as General Capabilities\
    \ for the Internet of\nthe Future.\nThe aim of the FI-NEXT project is to put in\
    \ place all the measures necessary in order to make\nFIWARE materializing such\
    \ a potential. This will achieved pursuing the following objectives: a)\nbringing\
    \ FIWARE from an European Open Source project to a global Open Source Community,\
    \ b)\nensuring FIWARE meets the highest quality standards and best technical support,\
    \ c) positioning\nFIWARE as the de facto standard for the development of smart\
    \ applications, and d) ensuring\nFIWARE Lab to be a self-sustainable environment.\n\
    Our group has been contributing to this project on three main topics, Security,\
    \ Data\nPersistence, and Data Analytics. In this regard, we are owners of three\
    \ Generic enables that have\nbeen presented in the previous chapters. First Keyrock\
    \ in the security chapter. Second, Draco for\ndata persistence and prepossessing\
    \ system and connectors for context-aware systems and ﬁnally\nCosmos, for providing\
    \ data connectors in order to provide big data analytic of the Data. In this\n\
    project, I centered my work on developing a new data persistence model for Draco\
    \ and\nparticipate in the migration of the previous model of NGSIv1, to NGSIv2\
    \ and ﬁnally to\nNGSI-LD. Moreover, I developed a set of templates and processors\
    \ for allowing data\npre-processing capabilities compatible with big data systems.\
    \ Additionally, in terms of Big Data,\nI participated in the analysis and design\
    \ of the data connector between the core GE and the most\npopular Big Data frameworks.\
    \ As is clearly stated the main contributions of this thesis are clearly\nVALIDATION\
    \ AND RESULTS\nencompassed inside of the strategic objective of this project.\
    \ Afterward, in the latest years, this\nproject put a lot of interest in developing\
    \ data usage control capabilities for data sharing\necosystems.\n5.1.2\nA/RporTWIN\n\
    A/RporTWIN is a project ﬁnanced by European Institute of Innovation and Technology\
    \ Digital\n(EIT). EIT Digital is a leading European digital innovation and entrepreneurial\
    \ education\norganisation driving Europe’s digital transformation. In this regard,\
    \ A/RporTWIN is a project\nwith the aim to provides a powerful data visualization\
    \ and analytical tool to be used by managers\nand operators of various mobility\
    \ systems (airports, seaports, roads, railways, etc). It not only\nallows the\
    \ user to visualize the infrastructure itself but it also integrates data from\
    \ different\nsources and derived insights that are useful during day-to-day operations.\
    \ It supports standard 2D\nvisualization tools as well as proofs compatible with\
    \ Augmented Reality/Virtual Reality\n(AR/VR) equipment, depending on the selected\
    \ use case common data analysis and visualization\ntools for airport infrastructure\
    \ managers. It will bring together different sources of information\nthat are\
    \ useful during daily operations. This project presents a tool will act as a single\
    \ source of\ninformation for airport operators.\nSome of its most notable features\
    \ are compatibility with\nVR/AR technologies and third-party data integration\
    \ Additional information on EIT Digital,\nIPTC.\nA/RporTWIN is the next digital\
    \ twin powered by the FIWARE platform concerning the\nmanagement of various infrastructures.\n\
    In this regard, our research group was in charge of\nconﬁguring and deploying\
    \ the FIWARE infrastructure, modelling data and customizing FIWARE\ncomponents\
    \ to the requirements of the service. This solution was implemented at the Aberdeen\n\
    International Airport, located in Scotland, UK. The airport is owned and operated\
    \ by AGS\nAirports which also owns and operates Glasgow and Southampton airports.\
    \ A total of just under\n3.1 million passengers used the airport in 2018 with\
    \ more than 90,000 movements. Thanks to the\nA/RporTWIN deployment, operators\
    \ can visualize and manage turnaround operations and\ncommunicate with airport\
    \ staff for scheduling ﬂights and reporting delays in near real-time with a\n\
    digital solution.\nThe work developed in this project serves as a starting point\
    \ in the incursion of data modelling\nfor complex systems and also in preprocessing,\
    \ processing, and managing context information\nin the ﬁeld of aeronautics. Thus,\
    \ through this work, I could identify the issues that need to be\naddressed for\
    \ providing part of the contributions presented in chapter 3.\n5.1.3\nYour Open\
    \ Data YODA\nYour Open DAta (YODA co-ﬁnanced by the European Commission) provides\
    \ a service for\nEuropean citizens that allows them to create personalised dashboards\
    \ binding several sources of\ndata through a single application. In addition,\
    \ the action deploys a data processing infrastructure\n106\n5.2. DISSEMINATION\
    \ OF RESULTS\nthat, on the basis of real time and machine learning processing,\
    \ will provide additional processed\nresults and predictions to the developed\
    \ personalised service.\nThe data sources include relevant information retrieved\
    \ from the European Data Portal (EDP)\nand the additional data sources integrated\
    \ in the action, UPM Smart Campus CEI Moncloa, Málaga\nSmart City, Santander Smart\
    \ City and AEMET (Spanish Meteorological Agency). Moreover, data\nfrom these sources\
    \ will be published in the EDP.\nIn this regard, our group contributes to this\
    \ action in the development of a connector for\npublishing data coming from different\
    \ data sources into CKAN portals.\nThese connectors\nprocessors and templates\
    \ were developed under Draco GE. Moreover, one of the main goals of\nthese projects\
    \ is to design and implement a Machine learning architecture for providing a\n\
    personalized dashboard.\nIn this regard, the proposed reference implementation\
    \ presented in\nchapter 3 is used for providing these capabilities. Worded differently,\
    \ through this project I can\nverify and validate all the contributions presented\
    \ in this thesis, even the data usage control\narchitecture presented in chapter\
    \ 4, due to this is other of the actions that are considered to be\nincluded.\n\
    5.1.4\nResearch Stay FIWARE Foundation\nAs part of my doctoral studies, I made\
    \ a research stay of three months in FIWARE Foundation\nHeadquarters in Berlin\
    \ Germany. During my stay, I carried out research in the ﬁeld of NGSI-\nLD integration.\
    \ I participated in the re-design of a Historic Context Generic enabler for his\
    \ full\nintegration with NGSI LD, as part of the standardization work that I have\
    \ been developing during\nmy Ph.D. studies and that have been part of the contribution\
    \ of this thesis.\n5.2\nDissemination of Results\nThe results of this study have\
    \ allowed contributing to the state of the art of some topics through\nvarious\
    \ publications in journals with high impact factor, and international conferences\
    \ and\nworkshops. The proposals, simulations, and analysis of this issue are summarized\
    \ in:\n5.2.1\nJournals\n•\nAndres Munoz-Arcentales, Sonsoles López-Pernas, Alejandro\
    \ Pozo, Álvaro Alonso and J.\nSalvachúa, Data Usage and Access Control in Industrial\
    \ Data Spaces: Implementation\nUsing FIWARE, Sustainability (MDPI), 2020\nImpact\
    \ Factor: JCR: Q2 - 3.251 (2020)\n• Javier Conde, Andres Munoz-Arcentales, Sonsoles\
    \ López-Pernas, Álvaro Alonso and J.\nSalvachúa, Modeling Digital Twin Data and\
    \ Architecture: A Building Guide with FIWARE\nas Enabling Technology, IEEE Internet\
    \ Computing, 2021\nImpact Factor: JCR: Q1 - 2.341(2020)\n107\nVALIDATION AND RESULTS\n\
    • W. Velásquez, MS Alvarez-Alvarado, Andres Munoz-Arcentales, Sonsoles López-Pernas,\n\
    and J. Salvachúa, Relation between BMI and Walking Speed in Men with Cardiovascular\n\
    Disease in an Emergency Situation: Earthquake, Sensors MDPI, 2020\nImpact Factor:\
    \ JCR: Q1 - 3.576(2020)\n•\nÁlvaro Alonso, Alejandro Pozo, Sonsoles López-Pernas,\
    \ Aldo Gordillo, Andres Munoz-\nArcentales, Lourdes Marco and Enrique Barra, Enhancing\
    \ University Services by Extending\nthe eIDAS European Speciﬁcation with Academic\
    \ Attributes, Sustainability (MDPI), 2019\nImpact Factor: JCR: Q2 - 3.251 (2020)\n\
    •\nJavier Conde,Sonsoles López-Pernas, Alejandro Pozo, Andres Munoz-Arcentales,\
    \ Álvaro\nAlonso and Gabriel Hueas, Bridging the Gap between Academia and Industry\
    \ through\nStudents’ Contributions to the FIWARE European Open-Source Initiative:\
    \ A Pilot Study ,\nElectronics (MDPI), 2021\nImpact Factor: JCR: Q2 - 2.397 (2020)\n\
    • W. Velásquez, Andres Munoz-Arcentales, W. Yanez and J. Salvachúa, Relation between\
    \ BMI\nand Walking Speed in Men with Cardiovascular Disease in an Emergency Situation:\n\
    Earthquake, Pertanika Journal of Science & Technology, 2019\nImpact Factor: SJR:\
    \ Q4 - 0.121(2017)\n• W. Velásquez, A. Munoz-Arcentales and J. Salvachúa, Relation\
    \ between BMI and Exit Time\nof a Building in an Emergency Situation: Earthquake.,\
    \ Engineering Letters, 25, 4, 2017\nImpact Factor: SJR: Q2 - 0.268(2017)\n5.2.2\n\
    Conference and Workshops\n• Andres. Munoz-Arcentales, Sonsoles López-Pernas, Alejandro\
    \ Pozo, Álvaro Alonso and J.\nSalvachúa, An architecture for providing data usage\
    \ and access control in data sharing\necosystems, \"The 10th International Conference\
    \ on Emerging Ubiquitous Systems and\nPervasive Networks (EUSPN-2019)\", 1-6,\
    \ 2019, IEEE\nConference Venue: 1-4 November 2019, Coimbra, Portugal\n• Andres\
    \ Munoz-Arcentales, W. Velásquez and J. Salvachúa, Practical Approach of\nFast-Data\
    \ Architecture Applied to Alert Generation in Emergency Evacuation Systems,\n\"\
    2018 International Symposium on Networks, Computers and Communications (ISNCC)\"\
    ,\n1-6, 2018, IEEE\nConference Venue: 19-21 June 2018, Rome, Italy\n• Andres Munoz-Arcentales,\
    \ W. Yanez and W. Velásquez, Proposal of a communication\nstructure model for\
    \ activating reactive signaling in an emergency evacuation systems,\n\"Computing\
    \ and Communication Workshop and Conference (CCWC), 2017 IEEE 7th\n108\n5.3. TEACHING\
    \ AND SEMINARS\nAnnual\", 1-5, 2017, IEEE\nConference Venue: 9-11 January 2017,\
    \ Las Vegas, NV, USA\n• W. Velásquez, Andres Munoz-Arcentales, Thomas Michael\
    \ Bohnert and J. Salvachúa,\nWildﬁre Propagation Simulation Tool using Cellular\
    \ Automata and GIS, \"2019\nInternational Symposium on Networks, Computers and\
    \ Communications (ISNCC)\"\nConference Venue: 18-20 June 2019, Istanbul - Turkey\n\
    • W. Velásquez, Andres Munoz-Arcentales, M. Chalén and J. Salvachúa, Survival\
    \ analysis\nof people with cardiac problems in a simulated earthquake environment,\
    \ \"Computing and\nCommunication Workshop and Conference (CCWC), 2018 IEEE 8th\
    \ Annual\", 702-706,\n2018, IEEE\nConference Venue: 8-10 January 2018, Las Vegas,\
    \ NV, USA\n• W. Velásquez, Andres Munoz-Arcentales and J. Salvachúa, Fast-data\
    \ architecture proposal\nto alert people in emergency, \"Computing and Communication\
    \ Workshop and Conference\n(CCWC), 2018 IEEE 8th Annual\", 165-168, 2018, IEEE\n\
    Conference Venue: 8-10 January 2018, Las Vegas, NV, USA\n• W. Velásquez, Andres\
    \ Munoz-Arcentales, W. Yanez and J. Salvachúa, Resilient smart cities:\nAn approach\
    \ of damaged cities by natural risks, \"Computing and Communication Workshop\n\
    and Conference (CCWC), 2018 IEEE 8th Annual\", 591-597, 2018, IEEE\nConference\
    \ Venue: 8-10 January 2018, Las Vegas, NV, USA\n• W. Velásquez, Andres Munoz-Arcentales\
    \ and J. Salvachúa, A Case Study: Ingestion Analysis\nof WSN Data in Databases\
    \ using Docker, 2018 1st International Conference on Computer\nApplications &\
    \ Information Security (ICCAIS), 1-6, 2018, IEEE\nConference Venue: 4-6 April\
    \ 2018, Riyadh, Saudi Arabia\n• W. Velásquez, Andres Munoz-Arcentales and J. Salvachúa,\
    \ A distributed system model for\nmanaging data ingestion in a wireless sensor\
    \ network, \"Computing and Communication\nWorkshop and Conference (CCWC), 2017\
    \ IEEE 7th Annual\", 1-5, 2017, IEEE\nConference Venue: 9-11 January 2017, Las\
    \ Vegas, NV, USA\n5.3\nTeaching and Seminars\n• Data centers and provisioning\
    \ services,\nDegree in Engineering technologies and\ntelecommunication services,\
    \ Universidad Politécnica de Madrid.\n• Programing,\nDegree in Engineering technologies\
    \ and telecommunication services,\nUniversidad Politécnica de Madrid.\n109\nVALIDATION\
    \ AND RESULTS\n• Fundamentals of programming, Degree in Bio-engineering, Universidad\
    \ Politécnica de\nMadrid.\n• Data Bases, Degree in Bio-engineering, Universidad\
    \ Politécnica de Madrid.\n• Fundamentals of information systems for Big Data,\
    \ Masters Degree in Telecommunication\nEngineering technologies and telecommunication\
    \ services, Universidad Politécnica de\nMadrid.\n• Relational Databases and Structured\
    \ Data, Degree in Engineering of Data Systems ,\nUniversidad Politécnica de Madrid.\n\
    • non-Relational and distributed Databases , Degree in Engineering of Data Systems\
    \ ,\nUniversidad Politécnica de Madrid.\n• Analysis and software design, Degree\
    \ in Engineering technologies and telecommunication\nservices, Universidad Politécnica\
    \ de Madrid.\n• Cloud Computing 1st Edition, Thales Company, Universidad Politécnica\
    \ de Madrid.\n• Cloud Computing 2nd Edition, Thales Company, Universidad Politécnica\
    \ de Madrid.\n110\nChapter 6\nConclusions and Future Works\nThis chapter provides\
    \ a review of the conclusions extracted throughout the work presented in\nthis\
    \ thesis. I started this document by conducting an analysis of the current services\
    \ developed\nfor providing context-aware data analytics in smart spaces and their\
    \ evolution in the latest years.\nMoreover, I stated how the data generated by\
    \ these systems has become an important asset in the\nindustry, and also a concern\
    \ about how it can be guaranteed that this data is treated according to\nthe permissions\
    \ provided by the data owner.\nOne of the goals of context-aware systems is to\
    \ capture and process the information in the\ncontext of a device to provide services\
    \ built on a particular person, place, time, event, etc. Worded\ndifferently,\
    \ context-aware systems capture context, analyze and interpret the context, and\
    \ make\nadjustments to the system’s behavior for the user’s changing situation\
    \ without explicit intervention\nfrom the user. The majority of existing works\
    \ often provide a generic high-level structure of how a\ncontext-aware system\
    \ can be operationalized, but do not offer many clues on how to implement it.\n\
    On the other hand, there are many implementations of context-aware systems applied\
    \ to speciﬁc\nIoT-based smart spaces use cases (e.g., smart farming, smart cities).\
    \ However, although these\nimplementations are context-aware, they are also context-speciﬁc:\
    \ it is not clear how they can be\nextended to other use cases.\nAdditionally,\
    \ providing a secure ecosystem for data sharing that ensures data governance and\n\
    traceability is of paramount importance as it holds the potential to create new\
    \ applications and\nservices.\nProtecting data goes beyond restricting who can\
    \ access what resource (covered by\nidentity and access control respectively):\
    \ it becomes necessary to control how data are treated\nonce accessed, which is\
    \ known as data usage control. Data usage control provides a common and\ntrustful\
    \ security framework to guarantee the compliance with data governance rules and\n\
    responsible use of organizations’ data by third-party entities, easing and ensuring\
    \ secure data\nsharing.\nThis thesis provided a reference implementation that\
    \ can be used in any context-aware system\ndevelopment of an IoT-based smart space.\
    \ Afterward, the data generated by these systems need to\nbe protected in terms\
    \ of privacy and security. As such, another contribution covered by this thesis\n\
    deals with providing a data usage control solution that can manage all the data\
    \ generated by the\ncontext-aware systems used in smart spaces.\nThese challenges\
    \ motivate the questions that I presented in the introduction of this document\n\
    and serve as a starting point for beginning to develop the contributions of this\
    \ thesis. Now with\nall of this background, I will try to give the answers to\
    \ these questions based on the knowledge\nCONCLUSIONS AND FUTURE WORKS\nobtained\
    \ in this work.\nWhat should be the design characteristics of an architecture\
    \ capable of enabling context-\naware data analytics in smart spaces?\nThe ﬁrst\
    \ step for answering this question is conducting an analysis of the structure\
    \ that context-\naware systems often have but also identify the additional components\
    \ that need to be included in\norder to enable data analytics for these systems\
    \ in smart spaces.\nThe study of the structure of context-aware systems was conducted\
    \ in section 3.3. As was\nstated in that section, context-aware systems are presented\
    \ as a layered architecture segmented by\nthe different types of service that\
    \ provide every of the described components. This structure can\nadd or subtract\
    \ layers depending on the use case or the ﬁeld of application, making more complex\n\
    the adoption of a common framework to manage these types of systems. Moreover,\
    \ smart spaces\ncan have several devices and systems that generate a huge amount\
    \ of data. According to the review\nof the literature conducted in this work,\
    \ current solutions of context-aware systems are not ready\nto deal with these\
    \ types of issues. For ﬁlling this gap, big data and data engineering tools play\
    \ an\nimportant role in improving the architecture of context-aware systems.\n\
    This analysis serves as a starting point for determining how an architecture capable\
    \ of\nproviding context-aware data analytics in smart spaces should be designed,\
    \ that I conducted in\nsection 3.4. This proposal was used and validated in several\
    \ European projects such as FIWARE,\nFI-Core, and YODA, which promote the use\
    \ of Generic enablers for providing a technological\necosystem for Smart Cities\
    \ and in consequence give to the European Citizens the opportunity to\nextract\
    \ the value of the data. From this model, I proposed design patterns that were\
    \ fundamental\nfor designing the proposed architecture:\n• Service Oriented Components\
    \ - The architecture should be generic and modular. This\npattern aims to provide\
    \ a strong segmentation of the services by means of that every\ncomponent must\
    \ be dedicated to a speciﬁc task in the whole system. For example, the\nContext\
    \ Management layer has focused only in managing the context while the physical\n\
    layer is focused only on data collection from devices and systems.\n• Scalability\
    \ - For allowing replication, in case that more resources were needed, the system\n\
    is able to add more components for allowing the continuous availability of the\
    \ system.\n• Generic - Providing a reference architecture that can be used in\
    \ any data space regardless\nof the ﬁeld of application. This means that the systems\
    \ can be used and deployed in ﬁelds\nlike Smart Transportation, Smart Health,\
    \ Smart Industry, etc. without having to change the\ncore structure of the system.\n\
    • Distributed Processing - Depending on the needs in every moment or the load\
    \ of data\nmanaged, the system can distribute the work to different instances\
    \ for processing the data\n112\nwithout any interruption of the system.\nThis\
    \ also has a direct impact on reducing the\nresponse time of the system.\n• Data\
    \ Standardization - For providing a common framework for collect, store and retrieve\n\
    data in addition to promote cross-domain data sharing.\nThrough these patterns,\
    \ I designed an architecture that not only enables data analytics in\ncontext-aware\
    \ systems but also is scalable, standardized, fully distributed, and agnostic\
    \ to the\nﬁeld of application.\nHow can advanced data processing and machine learning\
    \ techniques be integrated into\nthe aforementioned architecture?\nIn the review\
    \ of the architecture proposed, one of the layers is dedicated to Context Processing.\n\
    Context processing is introduced in this proposal for providing big data processing\
    \ using context\ninformation coming from the data generated in smart spaces. Also,\
    \ I stated that, in this component,\nthe processing capabilities are relied on\
    \ well-know big data processing engines like Apache Spark\nand Apache Flink.\n\
    In addition to the usual tasks performed by these engines, advanced operations\
    \ like complex\nevent processing can be performed and even extended by the use\
    \ of libraries for including machine\nlearning resources to be used with data,\
    \ providing a set of resources and algorithms that can be\noperationalized for\
    \ build things like recommendation systems, predictors, data clustering, deep\n\
    learning and more.\nAt this point, it is clearly identiﬁed that the proposed architecture\
    \ and technological tools allow\nthe use of machine learning techniques for deﬁning\
    \ these type of system application. To provide a\nfull view of how these systems\
    \ can be implemented in a real scenario, I provide the implementation\nof a purchase\
    \ prediction system using the proposed architecture in a food industry scenario.\n\
    The implementation presented in section 3.5 provides all the details needed to\
    \ build and\ndeploy solutions based on Machine learning models that can be fed\
    \ with a static dataset and work\nwith data coming from external applications.\n\
    Here I pose the deﬁnition of the pipelines for\nimplementing this application.\
    \ These pipelines are based on Data Engineering techniques for\ndeﬁning connections\
    \ between the components and being able to provide the capabilities needed\nby\
    \ machine learning-based applications.\nAs part of the solution presented in that\
    \ section, additional descriptions are provided about\nhow to connect the components\
    \ of the architecture, which components are needed for that type of\nscenario,\
    \ and what the life cycle of the whole process is for deﬁning the machine learning\
    \ model\nbased on a real dataset. Thus, due to the design patterns deﬁned for\
    \ building the architecture and\nthe reference implementation provided in the\
    \ prior sections, the integration of advanced data\nprocessing using machine learning\
    \ techniques is fully achieved not only by the proposed\narchitecture but also\
    \ by the detailed use case presented.\n113\nCONCLUSIONS AND FUTURE WORKS\nHow\
    \ should an architecture for providing data usage control in smart spaces be designed\n\
    so that it can be used in data sharing ecosystems with multiple stakeholders?\n\
    In order to answer this question, I made a review of the current solutions available\
    \ in the literature.\nAfterward, I identiﬁed and deﬁned a set of design principles\
    \ needed for posing an architecture for\nproviding data usage control in smart\
    \ spaces.\nAs was presented in section 4.3 previous works have failed to provide\
    \ a standard solution for\nachieving data Usage Control in data-sharing ecosystems.\
    \ None of the works reviewed provides\nadvanced Access Control and Usage Control\
    \ capabilities in architectures with several agents\ninvolved, while supporting\
    \ an expressive policy deﬁnition language that allows the deﬁnition of\nobligations,\
    \ prohibitions and permissions and providing remediation functionalities in the\
    \ event\nof policy infringement.\nThis research contributes to ﬁll the gap in\
    \ the existing literature by\nproviding a generic multi-actor architecture to\
    \ achieve advanced data access and usage control\ncapabilities in real-time data-sharing\
    \ scenarios.\nSubsequently to the conducted analysis. I deﬁne the design principles\
    \ for this architecture, and\nthese can be summarized as follows:\n• Trust. It\
    \ is a pillar of any data-sharing ecosystem. In this case, I rely on this design\
    \ principle\non IDS Connectors to provide a trusted environment that enables the\
    \ achievement of data\nusage control.\n• Interoperability.\nStandardization of\
    \ protocols is crucial to ensure the understanding\nbetween all the components\
    \ involved in the architecture, for managing both usage control\nand identity.\n\
    • Governance. For providing ways to respect and protect the data of all the parties\
    \ involved\nis one of the main requirements that data usage control must fulﬁll.\n\
    • Performance. The accomplishment of data usage control policies can be only ensured\
    \ if\nreaction to policies violation is quick and efﬁcient.\n• Flexibility. As\
    \ many data sharing scenarios and use cases are contemplated, the solution has\n\
    to be adaptable to the speciﬁc requirements of such scenarios.\nThese design principles\
    \ were taken as the core consideration for building the architecture\npresented\
    \ in this thesis, considering not only a single data space but also providing\
    \ a solution\nwhen a multiple actors are involved. In this architecture ,I also\
    \ present a solution that provides a\ndata usage control in data sharing ecosystems\
    \ with multiple stakeholders.\nHow can the implementation feasibility of the proposed\
    \ data usage control architecture\nbe veriﬁed?\nThe answer to this question is\
    \ described in section 4.6. I present a validation of the proposed\n114\n6.1.\
    \ CONCLUSIONS\narchitecture and implementation using FIWARE, presenting a case\
    \ study in the food industry. The\ncomponents presented in the implementation\
    \ section have been deployed in order to perform the\npolicy deﬁnition and enforcement\
    \ in a shared data ecosystem. The main goals of this case study\nare to validate\
    \ and perform usage control over industrial data.\nIn this use case, I present\
    \ an overview of the scenario used for this validation, which uses the\narchitecture\
    \ proposed in chapter 4 for performing data usage control over that deployment.\
    \ The\ngoal of this use case is to determine the enforcement and execution times\
    \ of the policies deﬁned\nover the data that feed the previously mentioned infrastructure.\n\
    In this regard, a set of usage policies were deﬁned by a set of jobs. Overall,\
    \ the case study\npresented in that section, including the deployment of both\
    \ DC’s jobs, shows that the data usage\narchitecture provides a way of verifying\
    \ that the implementation complies with a set of predeﬁned\npolicies by a Data\
    \ Provider and of executing punishments in case of noncompliance.\nThe use case\
    \ scenario was tested for data generation periods ranging from 5s to 25ms (5s,\
    \ 1s,\n500ms, 250ms, 100ms, 50ms, 25ms), repeating each simulation 100 times.\
    \ I found that all the\nsituations of data infringement were detected and the\
    \ appropriate punishment was enforced in due\ntime in 100% of the cases. Thus,\
    \ no new information was unduly received after failing to comply\nwith a certain\
    \ policy. Thus, this validation analysis provides a feasible way to demonstrate\
    \ that the\nsolution presented is not only trustfully but also effective in terms\
    \ of infringement detection and\npunishment enforcement.\n6.1\nConclusions\nOnce\
    \ I have veriﬁed that the content proposed during this work is valid to answer\
    \ the questions\nposed at the beginning and in consequence the set objectives\
    \ are achieved. In this section, I\nsummarize the two main contributions that\
    \ this thesis promote to the research in data engineering,\ndata analytics for\
    \ context-aware systems and data usage control. These contributions match with\n\
    the work presented in the two core chapters of this document, chapters 3 and 4:\n\
    • Enabling Context-aware Data Analytics in Smart Spaces.\nFirst, I have conducted\
    \ an analysis of the challenges and opportunities that are presented in\ndata\
    \ analytics for context-aware systems focused on smart spaces. This analysis provided\n\
    me with a general overview to determine the key characteristics that I have to\
    \ include for\ndesigning an architecture that enables context-aware data analytics\
    \ in smart spaces.\nOnce I had the knowledge of all the pieces that I needed to\
    \ include, I designed the\narchitecture using generic components with a service-oriented\
    \ approach. After, I provided\nan implementation of this architecture relying\
    \ on the FIWARE Generic enablers and\npresenting this solution in that open source\
    \ community.\nThe last part of this contribution consists in presenting a set\
    \ of uses cases that provides a\nwalk-through guide for deploying this architecture\
    \ in different ﬁelds of application, not only\n115\nCONCLUSIONS AND FUTURE WORKS\n\
    providing a typical example but also an advanced use case for providing a predictive\
    \ model\nusing machine learning algorithms.\n• Promote Data Usage Control in Smart\
    \ Spaces with multiple stakeholders\nThe ﬁrst part of this contribution is focused\
    \ on providing solid design principles for building\nan architecture for providing\
    \ data usage control in data spaces over data sharing ecosystems.\nThis is achieved\
    \ by conducting a deep review of the current literature.\nAfterward, an implementation\
    \ is provided using FIWARE components for building the\nusage control infrastructure\
    \ and using as monitored infrastructure the food industry use\ncase developed\
    \ in Chapter 3. Additionally, a new proﬁle of a Policy Deﬁnition Language\n(ODRL)\
    \ is proposed and accepted by the W3C as a proﬁle for deﬁning data usage control\n\
    policies for big data environments.\nAnother contribution of this work is providing\
    \ all the software pieces needed for creating,\nconnecting, and monitoring data\
    \ usage control policies over data assets that are processed\nin streaming.\n\
    Finally, the last contribution of this chapter is providing a validation mechanism\
    \ that can be\nadopted by different data usage control platforms for determining\
    \ compliance time through\nthe analysis of the enforcement and execution time\
    \ of the data usage policies.\n6.2\nFuture Work\nIn each of the core chapters\
    \ of this document, I have presented some ideas for future work that can\nimprove\
    \ or provide new lines of research related to the contributions presented. In\
    \ this section, I\nsummarize a list of proposals of future research lines that\
    \ could be interesting for being added as\nnew works or as a continuation of the\
    \ posed in this document.\n• Provide an Edge computing Adaptation - Nowadays,\
    \ multiple researchers have focused on\ndeveloping solutions for contributing\
    \ to the ﬁeld of edge computing in a smart spaces. I\nhave identiﬁed that at a\
    \ conceptual level, this architecture can be easily adapted for its use\nin edge\
    \ computing. However, some further research needs to be conducted for adopting\
    \ in\nterms of implementation and the components that need to include for dealing\
    \ with the new\nrequirements of this type of environments.\n• Improvements for\
    \ managing Federated Learning Models - In the same line of the previous\nfuture\
    \ work, in order to take full advantage of edge computing, a new type of processing\n\
    has become a good solution for avoiding privacy issues and the problems that generate\n\
    the use of big computational resources. In this regard, Federated Leaning has\
    \ become an\ninteresting line of research for providing pre-processing in the\
    \ same place where the data is\ngenerated. Thus, this architecture also can be\
    \ improved for providing also federated learning\ncapabilities in the environment\
    \ that need to adopt this type of technology.\n116\n6.2. FUTURE WORK\n• Include\
    \ a data lake oriented Approach for data persistence - In recent years the adoption\
    \ of\ndata Lake as a way to persistence in different storage systems has become\
    \ very popular due\nto the advantages that this technology introduces in all the\
    \ systems considered as smart. An\ninteresting future work could be to adopt a\
    \ data lake approach for the presented\ninfrastructure.\nDespite that the current\
    \ architecture provides multiple connectors to\ndifferent storage systems, a data\
    \ lake approach could facilitate the exchange and\nstandardization of the data\
    \ in smart spaces.\n• Expand the architecture to provide GDPR compliance - I consider\
    \ this architecture could\nbe expanded to provide GDPR compliance by introducing\
    \ the GDPR regulation rules inside\nthe deﬁnition of the policies and deploying\
    \ them inside this architecture.\n• Expansion of the policy speciﬁcation language\
    \ - I identify the need of deﬁning a policy\nspeciﬁcation language capable of\
    \ handling the ﬁne-grained policy deﬁnitions in order to\nprovide the data usage\
    \ control capabilities in the Industry.\n117\nCONCLUSIONS AND FUTURE WORKS\n118\n\
    Bibliography\n[Abowd 1999] Gregory D Abowd, Anind K Dey, Peter J Brown, Nigel\
    \ Davies, Mark Smith\nand Pete Steggles.\nTowards a better understanding of context\
    \ and context-awareness.\nIn International symposium on handheld and ubiquitous\
    \ computing, pages 304–307.\nSpringer, 1999.\n[Ahmed 2016] Ejaz Ahmed, Ibrar Yaqoob,\
    \ Abdullah Gani, Muhammad Imran and Mohsen\nGuizani.\nInternet-of-things-based\
    \ smart environments: state of the art, taxonomy, and\nopen research challenges.\
    \ IEEE Wireless Communications, vol. 23, no. 5, pages 10–16,\n2016.\n[Al-Shdifat\
    \ 2018] Ali Al-Shdifat and Christos Emmanouilidis. Development of a Context-aware\n\
    framework for the Integration of Internet of Things and Cloud Computing for Remote\n\
    Monitoring Services. Procedia Manufacturing, vol. 16, pages 31–38, 2018. Proceedings\n\
    of the 7th International Conference on Through-life Engineering Services.\n[Alberti\
    \ 2019] Antonio Marcos Alberti,\nMateus A. S. Santos,\nRicardo Souza,\nHirley\n\
    Dayan Lourenço Da Silva, Jorge Roberto Carneiro, Vitor Alexandre Campos Figueiredo\n\
    and Joel J. P. C. Rodrigues.\nPlatforms for Smart Environments and Future Internet\n\
    Design: A Survey. IEEE Access, vol. 7, pages 165748–165778, 2019.\n[Alberto 2014]\
    \ Jurado Pérez Luis Alberto, Velásquez Vargas Washington Adrián and Vinueza\n\
    Escobar Nelson Fernando. Estado del Arte de las Arquitecturas de Internet de las\
    \ Cosas\n(IoT). UPM, 2014.\n[Alegre 2016] Unai Alegre, Juan Carlos Augusto and\
    \ Tony Clark.\nEngineering context-aware\nsystems and applications: A survey.\
    \ Journal of Systems and Software, vol. 117, pages\n55–83, 2016.\n[Alonso 2017]\
    \ Álvaro Alonso, Federico Fernández, Lourdes Marco and Joaquín Salvachúa.\nIAACaaS:\
    \ IoT Application-Scoped Access Control as a Service. Futur. Internet, vol. 9,\n\
    no. 4, page 64, oct 2017.\n[Alonso 2018] Álvaro Alonso, Alejandro Pozo, José Manuel\
    \ Cantera, Francisco la Vega and\nJuan José Hierro.\nIndustrial Data Space Architecture\
    \ Implementation Using FIWARE.\nSensors, vol. 18, no. 7, 2018.\nBIBLIOGRAPHY\n\
    [Alonso 2020] Álvaro Alonso, Alejandro Pozo, Aldo Gordillo, Sonsoles López-Pernas,\
    \ Andrés\nMunoz-Arcentales, Lourdes Marco and Enrique Barra.\nEnhancing University\
    \ Services\nby Extending the eIDAS European Speciﬁcation with Academic Attributes.\
    \ Sustainability,\nvol. 12, no. 3, page 770, jan 2020.\n[Ardagna 2009] C A Ardagna,\
    \ L Bussard, S De Capitani di Vimercati, G Neven, E Pedrini,\nS Paraboschi, F\
    \ Preiss, P Samarati, S Trabelsi and M Verdicchio.\nPrimeLife Policy\nLanguage.\
    \ In Proc. W3C Work. Access Control Appl. Scenar., Luxembourg, 2009.\n[Arfelt\
    \ 2019] Emma Arfelt, David Basin and Søren Debois.\nMonitoring the GDPR. In Kazue\n\
    Sako, Steve Schneider and Peter Y. A. Ryan, editeurs, Computer Security – ESORICS\n\
    2019, pages 681–699, Cham, 2019. Springer International Publishing.\n[Ashton 2009]\
    \ Kevin Ashton et al. That ’internet of things’ thing. RFID journal, vol. 22,\
    \ no. 7,\npages 97–114, 2009.\n[Balandin 2009] Sergey Balandin and Heikki Waris.\
    \ Key properties in the development of smart\nspaces. In International conference\
    \ on universal access in human-computer interaction,\npages 3–12. Springer, 2009.\n\
    [Baldauf 2007] Matthias Baldauf, Schahram Dustdar and Florian Rosenberg.\nA survey\
    \ on\ncontext-aware systems.\nInternational Journal of Ad Hoc and Ubiquitous Computing,\n\
    vol. 2, no. 4, pages 263–277, 2007.\n[Barco 2017] Aldo Alvarado Barco, Byron Bajana\
    \ Barahona, Andres Munoz Arcentales and\nWashington Velasquez Vargas. Geolocation\
    \ and security perimeter for bicycle care within\nthe university area. IEEE Latin\
    \ America Transactions, vol. 15, no. 6, pages 1137–1143,\n2017.\n[Barsocchi 2018]\
    \ Paolo Barsocchi, Antonello Calabrò, Erina Ferro, Claudio Gennaro, Eda\nMarchetti\
    \ and Claudio Vairo.\nBoosting a low-cost smart home environment with usage\n\
    and access control rules. Sensors, vol. 18, no. 6, page 1886, 2018.\n[Bartolini\
    \ 2019a] Cesare Bartolini, Said Daoudagh, Gabriele Lenzini and Eda Marchetti.\
    \ GDPR-\nBased User Stories in the Access Control Perspective. In International\
    \ Conference on the\nQuality of Information and Communications Technology, pages\
    \ 3–17. Springer, 2019.\n[Bartolini 2019b] Cesare Bartolini, Said Daoudagh, Gabriele\
    \ Lenzini and Eda Marchetti.\nTowards a lawful authorized access: a preliminary\
    \ GDPR-based authorized access. In\n14th International Conference on Software\
    \ Technologies (ICSOFT 2019), Prague, Czech\nRepublic, pages 26–28, 2019.\n120\n\
    BIBLIOGRAPHY\n[Bartolli 2011] A. Bartolli, J. Hernández-Serrano, M. Soriano, M.\
    \ Dohler, A. Kountouris and\nD. Barthel. Security and Privacy in your Smart City.\
    \ In Proceedings of Barcelona Smart\nCities Congress, Barcelona, Spain, 2011.\n\
    [Basin 2012] David Basin, Matúš Harvan, Felix Klaedtke and Eugen Z˘alinescu.\n\
    MONPOLY:\nMonitoring Usage-Control Policies.\nIn Sarfraz Khurshid and Koushik\
    \ Sen, editeurs,\nRuntime Veriﬁcation, pages 360–364, Berlin, Heidelberg, 2012.\
    \ Springer Berlin\nHeidelberg.\n[Belanche-Gracia 2015] Daniel Belanche-Gracia,\
    \ Luis V Casalo-Arino and Alfredo Pérez-Rueda.\nDeterminants of multi-service\
    \ smartcard success for smart cities development: A study\nbased on citizens’\
    \ privacy and security perceptions. Government information quarterly,\nvol. 32,\
    \ no. 2, pages 154–163, 2015.\n[Bertolino 2011] Antonia Bertolino, Antonello Calabrò,\
    \ Francesca Lonetti and Antonino Sabetta.\nGlimpse: a generic and ﬂexible monitoring\
    \ infrastructure. In EWDC, 2011.\n[Bettini 2003] Claudio Bettini, Sushil Jajodia,\
    \ X Sean Wang and Duminda Wijesekera.\nProvisions and Obligations in Policy Rule\
    \ Management. J. Netw. Syst. Manag., vol. 11,\nno. 3, pages 351–372, 2003.\n[Beyer\
    \ 2011] Mark Beyer.\nGartner Says Solving’Big Data’Challenge Involves More Than\
    \ Just\nManaging Volumes of Data. Gartner. Archived from the original on, vol.\
    \ 10, 2011.\n[Bodenheimer 2014] Robert Bodenheimer, Alexej Brauer, David Eckhoff\
    \ and Reinhard German.\nEnabling GLOSA for adaptive trafﬁc lights. In Vehicular\
    \ Networking Conference (VNC),\n2014 IEEE, pages 167–174. IEEE, 2014.\n[Buscher\
    \ 2013] V Buscher and L Doody. Global innovators: international case studies on\
    \ smart\ncities. BIS Research Paper, vol. 135, 2013.\n[Calabró 2019] Antonello\
    \ Calabró, Said Daoudagh and Eda Marchetti.\nIntegrating Access\nControl and Business\
    \ Process for GDPR Compliance: A Preliminary Study. In ITASEC,\n2019.\n[Camargo-Vega\
    \ 2015] Juan José Camargo-Vega, Jonathan Felipe Camargo-Ortega and Luis\nJoyanes-Aguilar.\n\
    Conociendo big data. Facultad de Ingeniería, vol. 24, no. 38, pages\n63–77, 2015.\n\
    [Carter 2021] Adam Carter, Wolfgang Schreiner, Andreas Grabner and April Slattery.\n\
    A Brief\nIntro to Full Stack Performance Monitoring on Google Cloud Platform,\
    \ May 2021.\n[Castro 2011] Miguel Castro, Antonio J Jara and Antonio FG Skarmeta.\n\
    Extending Terrestrial\nLogistics Solutions Using New-age Wireless Communications\
    \ based on SunSPOT.\nV\n121\nBIBLIOGRAPHY\nInternational Symposiumon Ubiquitous\
    \ Computing and Ambient Intelligence, UCAmI,\n2011.\n[Cerbo 2015] F Di Cerbo,\
    \ D Some, L Gomez and S Trabelsi. PPL v2.0: Uniform Data Access\nand Usage Control\
    \ on Cloud and Mobile. In Proc. 2015 IEEE/ACM 1st Int. Work. Tech.\nLeg. Asp.\
    \ Data Priv. Secur., pages 2–7, Los Alamitos, CA, USA, 2015. IEEE Computer\nSociety.\n\
    [Chavez-Burbano 2014] Patricia Chavez-Burbano, Ignacio Marin-Garcia and Andres\
    \ Muñoz-\nArcentales. Ad-hoc network implementation and experimental testing using\
    \ low cost and\nCOTS components: An ecuatorian case study. In 3rd IEEE International\
    \ Work-Conference\non Bioinspired Intelligence, pages 133–137. IEEE, 2014.\n[Chen\
    \ 2010] Deji Chen, Mark Nixon and Aloysius Mok. Why wirelesshart. In WirelessHARTTM,\n\
    pages 195–199. Springer, 2010.\n[Colldahl 2013] Caroline Colldahl, Sonya Frey\
    \ and Joseph E Kelemen.\nSmart cities: Strategic\nsustainable development for\
    \ an urban world, 2013.\n[Conde 2021] Javier Conde, Andres Munoz-Arcentales, Alvaro\
    \ Alonso, Sonsoles Lopez-Pernas\nand Joaquin Salvachua. Modeling Digital Twin\
    \ Data and Architecture: A Building Guide\nwith FIWARE as Enabling Technology.\
    \ IEEE Internet Computing, vol. 25, no. 4, 2021.\n[Cook 2007] Diane J Cook and\
    \ Sajal K Das. How smart are our environments? An updated look\nat the state of\
    \ the art. Pervasive and mobile computing, vol. 3, no. 2, pages 53–73, 2007.\n\
    [Coyne 1996] Edward J Coyne, HL Feinstein, R Sandhu and Charles E Youman.\nRole-based\n\
    access control models. IEEE Computer, vol. 29, no. 2, pages 38–47, 1996.\n[Curry\
    \ 2018] Edward Curry and Amit Sheth. Next-generation smart environments: From\
    \ system\nof systems to data ecosystems. IEEE Intelligent Systems, vol. 33, no.\
    \ 3, pages 69–76,\n2018.\n[Dempo 2010] Hiroshi Dempo and Makiko Yoshida.\nCUBIQ:\
    \ Cross UBIQuitous platform\nArchitecture.\nIn Applications and the Internet (SAINT),\
    \ 2010 10th IEEE/IPSJ\nInternational Symposium on, pages 213–216. IEEE, 2010.\n\
    [Digital CEF 2018] Digital\nCEF.\nContext\nBroker,\nMake\ndata-driven\ndecisions\n\
    in\nreal\ntime,\nat\nthe\nright\ntime.\nAvailable\nonline\n:\nhttps://ec.europa.eu/cefdigital/wiki/display/CEFDIGITAL/Context+Broker,\n\
    2018.\nAccessed: 2019-09-03.\n[Dobre 2014] Ciprian Dobre and Fatos Xhafa. Intelligent\
    \ services for big data science. Future\ngeneration computer systems, vol. 37,\
    \ pages 267–281, 2014.\n122\nBIBLIOGRAPHY\n[Dobrescu 2019] Radu Dobrescu, Daniel\
    \ Merezeanu and Stefan Mocanu. Context-aware control\nand monitoring system with\
    \ IoT and cloud support.\nComputers and Electronics in\nAgriculture, vol. 160,\
    \ pages 91–99, 2019.\n[Dragoni 2017] Nicola Dragoni, Saverio Giallorenzo, Alberto\
    \ Lluch Lafuente, Manuel Mazzara,\nFabrizio Montesi, Ruslan Mustaﬁn and Larisa\
    \ Saﬁna.\nMicroservices: yesterday, today,\nand tomorrow. Present and ulterior\
    \ software engineering, pages 195–216, 2017.\n[European Data Protection Supervisor\
    \ 2019] European Data Protection Supervisor.\nEuropean\nData Protection Supervisor\
    \ Glossary.\nAvailable online : https://edps.europa.eu/data-\nprotection /data-protection/glossary/d_en,\
    \ 2019. Accessed: 2019-06-03.\n[Fernández 2017] F Fernández, Á Alonso, L Marco\
    \ and J Salvachúa.\nA model to enable\napplication-scoped access control as a\
    \ service for IoT using OAuth 2.0. In Proc. 20th\nConf. Innov. Clouds, Internet\
    \ Networks, pages 322–324, Paris, France, 2017.\n[Furbush 2018] James Furbush.\
    \ Data engineering: A quick and simple deﬁnition, Jul 2018.\n[Furht 2010] Borko\
    \ Furht.\nCloud computing fundamentals. In Handbook of cloud computing,\npages\
    \ 3–19. Springer, 2010.\n[Gadgil 2017] Sulochana Gadgil.\nClimate-Smart Agriculture:\
    \ The Need of the Hour for Pulse\nProduction. Agriculture under Climate Change:\
    \ Threats, Strategies and Policies, vol. 1,\npage 14, 2017.\n[Gantz 2011] John\
    \ Gantz and David Reinsel. Extracting value from chaos. IDC iview, vol. 1142,\n\
    no. 2011, pages 1–12, 2011.\n[Genge 2014] B Genge, P Haller, A Gligor and A Beres.\n\
    An approach for cyber security\nexperimentation supporting sensei/IoT for smart\
    \ grid. In Second International Symposium\non Digital Forensics and Security,\
    \ pages 37–42, 2014.\n[Gkioulos 2019] Vasileios Gkioulos, Athanasios Rizos, Christina\
    \ Michailidou, Paolo Mori and\nAndrea Saracino.\nEnhancing Usage Control for Performance:\
    \ An Architecture for\nSystems of Systems.\nIn Sokratis K. Katsikas, Frédéric\
    \ Cuppens, Nora Cuppens,\nCostas Lambrinoudakis, Annie Antón,\nStefanos Gritzalis,\n\
    John Mylopoulos and\nChristos Kalloniatis, editeurs, Computer Security, pages\
    \ 69–84, Cham, 2019. Springer\nInternational Publishing.\n[Gokalp 2016] Mert Onuralp\
    \ Gokalp, Kerem Kayabay, Mehmet Ali Akyol, P Erhan Eren and\nAltan Koçyi˘git.\n\
    Big data for industry 4.0: A conceptual framework. In Proc. 2016 Int.\nConf. Comp.\
    \ Sci. Comp. Int.(CSCI), pages 431–434. IEEE, 2016.\n123\nBIBLIOGRAPHY\n[Gölzer\
    \ 2015] Philipp Gölzer, Patrick Cato and Michael Amberg. Data Processing Requirements\n\
    of Industry 4.0-Use Cases for Big Data Applications. In ECIS, 2015.\n[Gómez-Chabla\
    \ 2019] Raquel Gómez-Chabla, Karina Real-Avilés, César Morán, Paola Grijalva\n\
    and Tanya Recalde. IoT applications in agriculture: A systematic literature review.\
    \ In 2nd\nInternational conference on ICTs in agronomy and environment, pages\
    \ 68–76. Springer,\n2019.\n[GoogleCloud 2021] GoogleCloud.\nMLOps: Continuous\
    \ delivery and automation pipelines in\nmachine learning, 2021.\n[Gubbi 2013]\
    \ Jayavardhana\nGubbi,\nRajkumar\nBuyya,\nSlaven\nMarusic\nand\nMarimuthu\nPalaniswami.\n\
    Internet of Things (IoT): A vision, architectural elements, and future\ndirections.\
    \ Future generation computer systems, vol. 29, no. 7, pages 1645–1660, 2013.\n\
    [Hangli 2018] Ge Hangli,\nTakeo Hamada,\nTakahiro Sumitomo and Noboru Koshizuka.\n\
    Precaelevator: Towards zero-waiting time on calling elevator by utilizing context\
    \ aware\nplatform in smart building. In 2018 IEEE 7th Global Conference on Consumer\
    \ Electronics\n(GCCE), pages 566–570. IEEE, 2018.\n[Hill 2012] Richard Hill, Laurie\
    \ Hirsch, Peter Lake and Siavash Moshiri.\nGuide to cloud\ncomputing: principles\
    \ and practice. Springer Science & Business Media, 2012.\n[Höfer 2011] CN Höfer\
    \ and Georgios Karagiannis.\nCloud computing services: taxonomy and\ncomparison.\
    \ Journal of Internet Services and Applications, vol. 2, no. 2, pages 81–94,\n\
    2011.\n[Hong 2009] Jong-yi Hong, Eui-ho Suh and Sung-Jin Kim. Context-aware systems:\
    \ A literature\nreview and classiﬁcation. Expert Systems with applications, vol.\
    \ 36, no. 4, pages 8509–\n8522, 2009.\n[Hunkeler 2008] Urs Hunkeler, Hong Linh\
    \ Truong and Andy Stanford-Clark.\nMQTT-S-A\npublish/subscribe protocol for Wireless\
    \ Sensor Networks.\nIn Communication systems\nsoftware and middleware and workshops,\
    \ 2008. comsware 2008. 3rd international\nconference on, pages 791–798. IEEE,\
    \ 2008.\n[Jamshidi 2018] Pooyan Jamshidi, Claus Pahl, Nabor C Mendonça, James\
    \ Lewis and Stefan\nTilkov. Microservices: The journey so far and challenges ahead.\
    \ IEEE Software, vol. 35,\nno. 3, pages 24–35, 2018.\n[Janota 2016] Aleš Janota\
    \ and Juraj Spalek.\nWhere is the smart transport going?\nIn Applied\nMachine\
    \ Intelligence and Informatics (SAMI), 2016 IEEE 14th International Symposium\n\
    on, pages 11–16. IEEE, 2016.\n124\nBIBLIOGRAPHY\n[Jeschke 2017] Sabina Jeschke,\
    \ Christian Brecher, Tobias Meisen, Denis Özdemir and Tim\nEschert. Industrial\
    \ Internet of Things and Cyber manufacturing systems. In Ind. Internet\nThings,\
    \ pages 3–19. Springer, 2017.\n[Jiao 2011] D Jiao, L Lianzhong, L Ting and M Shilong.\n\
    Realization of UCON Model Based\non Extended-XACML. In Proc. 2011 Int. Conf. Futur.\
    \ Comput. Sci. Appl., pages 90–93,\nWashington, DC, USA, 2011.\n[Kamienski 2019]\
    \ Carlos Kamienski, Juha-Pekka Soininen, Markus Taumberger, Ramide Dantas,\nAttilio\
    \ Toscano, Tullio Salmon Cinotti, Rodrigo Filev Maia and André Torre Neto. Smart\n\
    Water Management Platform: IoT-Based Precision Irrigation for Agriculture. Sensors,\n\
    vol. 19, no. 2, 2019.\n[Khanna 2019] Abhishek Khanna and Sanmeet Kaur. Evolution\
    \ of Internet of Things (IoT) and\nits signiﬁcant impact in the ﬁeld of Precision\
    \ Agriculture. Computers and electronics in\nagriculture, vol. 157, pages 218–231,\
    \ 2019.\n[Kreps 2014] Jay Kreps. I heart logs: Event data, stream processing,\
    \ and data integration. \"\nO’Reilly Media, Inc.\", 2014.\n[Kurt 2017] Sinan Kurt,\
    \ Huseyin Ugur Yildiz, Melike Yigit, Bulent Tavli and Vehbi Cagri Gungor.\nPacket\
    \ size optimization in wireless sensor networks for smart grid applications. IEEE\n\
    Transactions on Industrial Electronics, vol. 64, no. 3, pages 2392–2401, 2017.\n\
    [Kyriazis 2013] Dimosthenis Kyriazis, Theodora Varvarigou, Daniel White, Andrea\
    \ Rossi and\nJoshua Cooper. Sustainable smart city IoT applications: Heat and\
    \ electricity management\n& Eco-conscious cruise control for public transportation.\
    \ In World of Wireless, Mobile\nand Multimedia Networks (WoWMoM), 2013 IEEE 14th\
    \ International Symposium and\nWorkshops on a, pages 1–5. IEEE, 2013.\n[Laney\
    \ 2001] Doug Laney et al.\n3D data management: Controlling data volume, velocity\
    \ and\nvariety. META group research note, vol. 6, no. 70, page 1, 2001.\n[Lazouski\
    \ 2012] Aliaksandr Lazouski, Gaetano Mancini, Fabio Martinelli and Paolo Mori.\n\
    Usage control in cloud systems. In Proc. 2012 Int. Conf. Internet Technol. Secur.\
    \ Trans.,\npages 202–207, Piscataway, NJ, 2012. IEEE.\n[Lee 2014] Jay Lee, Hung-An\
    \ Kao, Shanhu Yang et al. Service innovation and smart analytics\nfor industry\
    \ 4.0 and big data environment. Procedia Cirp, vol. 16, no. 1, pages 3–8, 2014.\n\
    [Lewis 2014] James Lewis and Martin Fowler.\nMicroservices:\na deﬁnition of this\
    \ new\narchitectural term. MartinFowler. com, vol. 25, pages 14–26, 2014.\n125\n\
    BIBLIOGRAPHY\n[Li 2015] Xin Li, Martina Eckert, José-Fernán Martinez and Gregorio\
    \ Rubio.\nContext aware\nmiddleware architectures: Survey and challenges. Sensors,\
    \ vol. 15, no. 8, pages 20570–\n20607, 2015.\n[Liaw 2002] Andy Liaw, Matthew Wiener\
    \ et al. Classiﬁcation and regression by randomForest.\nR news, vol. 2, no. 3,\
    \ pages 18–22, 2002.\n[Linthicum 2009] David S. Linthicum. Cloud computing and\
    \ soa convergence in your enterprise:\nA step-by-step guide. Addison-Wesley Professional,\
    \ 1st édition, 2009.\n[Liu 2020] Hao Liu, Yongxin Tong, Jindong Han, Panpan Zhang,\
    \ Xinjiang Lu and Hui Xiong.\nIncorporating multi-source urban data for personalized\
    \ and context-aware multi-modal\ntransportation recommendation. IEEE Transactions\
    \ on Knowledge and Data Engineering,\n2020.\n[Lu 2017] Yang Lu.\nIndustry 4.0:\
    \ A survey on technologies, applications and open research\nissues. J. Ind. Inf.\
    \ Integr., vol. 6, pages 1–10, 2017.\n[López-Morales 2020] Juan Antonio López-Morales,\
    \ Juan Antonio Martínez and Antonio F.\nSkarmeta.\nDigital Transformation of Agriculture\
    \ through the Use of an Interoperable\nPlatform. Sensors, vol. 20, no. 4, 2020.\n\
    [Madushanki 2019] R Madushanki, H Wirasagoda and M Halgamuge. Adoption of the\
    \ Internet\nof Things (IoT) in agriculture and smart farming towards urban greening:\
    \ A review. 2019.\n[Mahmudlu 2016] Rauf Mahmudlu, Jerry den Hartog and Nicola\
    \ Zannone.\nData governance\nand transparency for collaborative systems.\nIn IFIP\
    \ Annual Conference on Data and\nApplications Security and Privacy, pages 199–216.\
    \ Springer, 2016.\n[Maier 1998] Mark W Maier.\nArchitecting principles for systems-of-systems.\n\
    Systems\nEngineering: The Journal of the International Council on Systems Engineering,\
    \ vol. 1,\nno. 4, pages 267–284, 1998.\n[Marra 2017] A L Marra, F Martinelli,\
    \ P Mori and A Saracino. Implementing Usage Control in\nInternet of Things: A\
    \ Smart Home Use Case. In Proc. 2017 IEEE Trust., pages 1056–1063,\nSydney, NSW,\
    \ Australia, 2017.\n[Martinelli 2019] Fabio Martinelli, Christina Michailidou,\
    \ Paolo Mori and Andrea Saracino.\nManaging QoS in Smart Buildings Through Software\
    \ Deﬁned Network and Usage Control.\nIn 2019 IEEE International Conference on\
    \ Pervasive Computing and Communications\nWorkshops (PerCom Workshops), pages\
    \ 626–632. IEEE, 2019.\n[Martinez 2016] Ramon Martinez, Juan Angel Pastor, Barbara\
    \ Alvarez and Andres Iborra.\nA Testbed to Evaluate the FIWARE-Based IoT Platform\
    \ in the Domain of Precision\nAgriculture. Sensors, vol. 16, no. 11, 2016.\n126\n\
    BIBLIOGRAPHY\n[McRoberts 2014] Mo McRoberts and Victor Rodriguez Doncel. Open\
    \ Digital Rights Language\n(ODRL) Ontology. Rapport technique, W3C, may 2014.\n\
    [Mehmood 2017] Yasir Mehmood, Farhan Ahmad, Ibrar Yaqoob, Asma Adnane, Muhammad\n\
    Imran and Sghaier Guizani.\nInternet-of-Things-Based Smart Cities: Recent Advances\n\
    and Challenges. IEEE Communications Magazine, vol. 55, no. 9, pages 16–24, 2017.\n\
    [Mell 2011] Peter Mell, Tim Grance et al.\nThe NIST deﬁnition of cloud computing.\
    \ National\nInstitute of Standards and Technology, 2011.\n[Microsoft 2019] Microsoft.\
    \ Getting Started with Windows Azure Series 1. Overview, Mar 2019.\n[Momont 2017]\
    \ Alec Momont. Ambulance Drone. TUDelft University of Technology,[Online].\nAvailable:\
    \ http://www. io. tudelft. nl/onderzoek/delft-designlabs/applied-labs/ambulance-\n\
    drone/.[Accessed 5 February 2017], 2017.\n[Montalvo 2016] Juan Manuel Villacreses\
    \ Montalvo, Lissette Beatriz Munizaga Soria and\nWashington Adrián Velásquez Vargas.\n\
    Sistema integral para el monitoreo y control de\nlos sonidos en bares y zonas\
    \ céntricas de la ciudad en tiempo real. Revista Tecnológica-\nESPOL, vol. 29,\
    \ no. 2, 2016.\n[Mosavi 2017] Amir Mosavi, Alvaro Lopez and Annamária R Varkonyi-Koczy.\n\
    Industrial\napplications of big data: State of the art survey. In Int. Conf. Glob.\
    \ Res. and Educ.,\npages 225–232. Springer, 2017.\n[Mourtzis 2016] D Mourtzis,\
    \ E Vlachou and NJPC Milas. Industrial Big Data as a result of IoT\nadoption in\
    \ manufacturing. Procedia cirp, vol. 55, pages 290–295, 2016.\n[Munoz-Arcentales\
    \ 2017] Andres\nMunoz-Arcentales,\nWendy\nYánez-Pazmino\nand\nWashington Velásquez\
    \ Vargas.\nProposal of a communication structure model for\nactivating reactive\
    \ signaling in an emergency evacuation systems.\nIn Computing and\nCommunication\
    \ Workshop and Conference (CCWC), 2017 IEEE 7th Annual, pages 1–5.\nIEEE, 2017.\n\
    [Munoz-Arcentales 2018] Andres\nMunoz-Arcentales,\nWashington\nVelásquez\nand\n\
    Joaquin\nSalvachüa.\nPractical approach of fast-data architecture applied to alert\
    \ generation\nin emergency evacuation systems.\nIn 2018 International Symposium\
    \ on Networks,\nComputers and Communications (ISNCC), pages 1–6. IEEE, 2018.\n\
    [Munoz-Arcentales 2019] Andres Munoz-Arcentales, Sonsoles López-Pernas, Alejandro\
    \ Pozo,\nÁlvaro Alonso, Joaquín Salvachúa and Gabriel Huecas.\nAn Architecture\
    \ for Providing\nData Usage and Access Control in Data Sharing Ecosystems. Procedia\
    \ Computer Science,\nvol. 160, pages 590 – 597, 2019.\nThe 10th International\
    \ Conference on Emerging\nUbiquitous Systems and Pervasive Networks (EUSPN-2019).\n\
    127\nBIBLIOGRAPHY\n[Munoz-Arcentales 2020] Andres Munoz-Arcentales, Sonsoles López-Pernas,\
    \ Alejandro Pozo,\nÁlvaro Alonso, Joaquín Salvachúa and Gabriel Huecas. Data Usage\
    \ and Access Control\nin Industrial Data Spaces: Implementation Using FIWARE.\
    \ Sustainability, vol. 12, no. 9,\n2020.\n[Munoz 2015] Jose A Munoz, Vanesa Calero,\
    \ Ignacio Marin, Patricia Chavez and Rafael Perez.\nAdaptive evacuation management\
    \ system based on monitoring techniques. IEEE Latin\nAmerica Transactions, vol.\
    \ 13, no. 11, pages 3621–3626, 2015.\n[Muñoz 2020] Manuel Muñoz, Juan D. Gil,\
    \ Lidia Roca, Francisco Rodríguez and Manuel\nBerenguel.\nAn IoT Architecture\
    \ for Water Resource Management in Agroindustrial\nEnvironments: A Case Study\
    \ in Almería (Spain). Sensors, vol. 20, no. 3, 2020.\n[Najem 2017] Naji Najem,\
    \ Driss Ben Haddou, Mohamed Riduan Abid, Hassan Darhmaoui,\nNissrine Krami and\
    \ Ouadoudi Zytoune. Context-aware wireless sensors for IoT-centeric\nenergy-efﬁcient\
    \ campuses. In 2017 IEEE International Conference on Smart Computing\n(SMARTCOMP),\
    \ pages 1–6. IEEE, 2017.\n[Narvaez 2017] B. Narvaez, M. Villacis M. Challen and\
    \ W. Velásquez. Heart Rhythm Monitoring\nSystem and IoT Device for People with\
    \ Heart Problems. In International Symposium on\nNetworks, Computers and Communications\
    \ (ISNCC-2017). IEEE, 2017.\n[Neisse 2017] Ricardo Neisse, Gary Steri and Igor\
    \ Nai-Fovino.\nA Blockchain-Based Approach\nfor Data Accountability and Provenance\
    \ Tracking. In Proc. 12th Int. Conf. Avail. Rel.\nSec., ARES ’17, New York, NY,\
    \ USA, 2017. Association for Computing Machinery.\n[NGSI-LD 2020] ETSI NGSI-LD.\n\
    Context Information Management (CIM) and Application\nProgramming Interface (API).\
    \ ETSI GS CIM, vol. 4, page V1, 2020.\n[OASIS Standard 1994] OASIS Standard.\n\
    eXtensible Access Control Markup Language\n(XACML) Version 3.0. Available online\
    \ : http://docs.oasis-open.org/xacml/3.0/xacml-3.0-\ncore-spec-os-en.pdf, 1994.\
    \ Accessed: 2019-06-03.\n[Oliver 2009] Ian Oliver and Sergey Boldyrev.\nOperations\
    \ on spaces of information. In 2009\nIEEE International Conference on Semantic\
    \ Computing, pages 267–274. IEEE, 2009.\n[Open Mobile Alliance 2012] Open Mobile\
    \ Alliance .\nNGSI Context Management. Available\nonline : http://www.openmobilealliance\n\
    .org/release/NGSI/V1_0-20120529-A/OMA-TS-NGSI_Context_Management-V1_0-\n20120529-A.pdf,\
    \ 2012. Accessed: 2019-07-08.\n[OpenStack 2021] OpenStack. Open Source Cloud Computing\
    \ Platform Software, May 2021.\n128\nBIBLIOGRAPHY\n[Osman 2019] Ahmed M Shahat\
    \ Osman. A novel big data analytics framework for smart cities.\nFut. Gen. Comp.\
    \ Sys., vol. 91, pages 620–633, 2019.\n[Otto 2018] Boris Otto, Steffen Lohmann,\
    \ Sebastian Steinbuss and Andreas Teuscher.\nIDS\nReference Architecture Model\
    \ Version 2.0. Rapport technique, Fraunhofer, 2018.\n[Ouaddah 2016] Aafaf Ouaddah,\
    \ Anas Abou Elkalam and Abdellah Ait Ouahman. FairAccess:\na new Blockchain-based\
    \ access control framework for the Internet of Things. Sec. Comm.\nNetw., vol.\
    \ 9, no. 18, pages 5943–5964, 2016.\n[Outchakoucht 2017] Aissam Outchakoucht,\
    \ ES Hamza and Jean Philippe Leroy.\nDynamic\naccess control policy based on blockchain\
    \ and machine learning for the internet of things.\nInt. J. Adv. Comput. Sci.\
    \ Appl., vol. 8, no. 7, pages 417–424, 2017.\n[Paci 2018] Federica Paci, Anna\
    \ Squicciarini and Nicola Zannone. Survey on access control for\ncommunity-centered\
    \ collaborative systems. ACM Computing Surveys (CSUR), vol. 51,\nno. 1, pages\
    \ 1–38, 2018.\n[Pahl 2016] Marc-Oliver Pahl, Georg Carle and Gudrun Klinker.\n\
    Distributed smart space\norchestration. In NOMS 2016-2016 IEEE/IFIP Network Operations\
    \ and Management\nSymposium, pages 979–984. IEEE, 2016.\n[Panian 2010] Zeljko\
    \ Panian. Some practical experiences in data governance. World Academy\nof Science,\
    \ Engineering and Technology, vol. 62, no. 1, pages 939–946, 2010.\n[Perera 2013]\
    \ Charith Perera, Arkady Zaslavsky, Peter Christen and Dimitrios Georgakopoulos.\n\
    Context aware computing for the internet of things: A survey. IEEE communications\n\
    surveys & tutorials, vol. 16, no. 1, pages 414–454, 2013.\n[Petkovi´c 2011] Milan\
    \ Petkovi´c, Davide Prandi and Nicola Zannone.\nPurpose control: Did\nyou process\
    \ the data for the intended purpose? In Secur. Data Manag., pages 145–168.\nSpringer,\
    \ 2011.\n[Phithakkitnukoon 2010] Santi Phithakkitnukoon, Marco Veloso, Carlos\
    \ Bento, Assaf Biderman\nand Carlo Ratti. Taxi-aware map: Identifying and predicting\
    \ vacant taxis in the city. In\nInternational Joint Conference on Ambient Intelligence,\
    \ pages 86–95. Springer, 2010.\n[Poullet 2006] Yves Poullet. EU data protection\
    \ policy. The Directive 95/46/EC: Ten years after.\nComput. Law Secur. Rev., vol.\
    \ 22, no. 3, pages 206–217, 2006.\n[Ravidas 2019] Sowmya Ravidas, Alexios Lekidis,\
    \ Federica Paci and Nicola Zannone.\nAccess\ncontrol in Internet-of-Things: A\
    \ survey. Journal of Network and Computer Applications,\nvol. 144, pages 79 –\
    \ 101, 2019.\n129\nBIBLIOGRAPHY\n[Reese 2009] George Reese.\nCloud application\
    \ architectures:\nbuilding applications and\ninfrastructure in the cloud. \" O’Reilly\
    \ Media, Inc.\", 2009.\n[Richardson 2018] Chris Richardson. Microservices patterns.\
    \ Manning Publications Company„\n2018.\n[Rodriguez Espinoza 2017] Jessica Katherine\
    \ Rodriguez Espinoza et al.\nDiseño de una\narquitectura genérica de iot aplicada\
    \ a casos de emergencias para dispositivos médicos\ninalámbricos implantados.\
    \ B.S. thesis, Espol, 2017.\n[Rosenthal 2000] Lynne Rosenthal and Vincent Stanford.\n\
    NIST Smart Space:\npervasive\ncomputing initiative.\nIn Proceedings IEEE 9th International\
    \ Workshops on Enabling\nTechnologies: Infrastructure for Collaborative Enterprises\
    \ (WET ICE 2000), pages 6–11.\nIEEE, 2000.\n[Russello 2009a] G Russello and N\
    \ Dulay.\nxDUCON: Coordinating Usage Control Policies in\nDistributed Domains.\
    \ In Proc. 3rd Int. Conf. Netw. Syst. Secur. (NSS 2009), pages 246–\n253, Gold\
    \ Coast, QLD, Australia, 2009.\n[Russello 2009b] G Russello and N Dulay.\nxDUCON:\
    \ Cross Domain Usage Control through\nShared Data Spaces. In Proc. 2009 IEEE Int.\
    \ Sym. Pol. Dist. Sys. Net., pages 178–181,\n2009.\n[Sandhu 1994] R. S. Sandhu\
    \ and P. Samarati.\nAccess control: principle and practice. IEEE\nComm. Mag.,\
    \ vol. 32, no. 9, pages 40–48, 1994.\n[Sandhu 1996] R.S. Sandhu, E.J. Coyne, H.L.\
    \ Feinstein and C.E. Youman.\nRole-based access\ncontrol models. Computer, vol.\
    \ 29, no. 2, pages 38–47, 1996.\n[Sandhu 2003] Ravi Sandhu and Jaehong Park.\n\
    Usage Control: A Vision for Next Generation\nAccess Control. In Comput. Netw.\
    \ Secur. Proc. 2nd Int. Work. Math. Methods, Model.\nArchit. Comput. Netw. Secur.\
    \ (MMM-ACNS 2003), pages 17–31, St. Petersburg, Russia,\n2003.\n[Sezer 2017] Omer\
    \ Berat Sezer, Erdogan Dogdu and Ahmet Murat Ozbayoglu.\nContext-aware\ncomputing,\
    \ learning, and big data in internet of things: a survey. IEEE Internet of Things\n\
    Journal, vol. 5, no. 1, pages 1–27, 2017.\n[Shelby 2014] Zach Shelby, Klaus Hartke\
    \ and Carsten Bormann.\nThe constrained application\nprotocol (CoAP). Rapport\
    \ technique, RFC 7252, IETF, 2014.\n[Siegel 2000] Jon Siegel and Dan Frantz. Corba\
    \ 3 fundamentals and programming, volume 2.\nJohn Wiley & Sons New York, NY, USA:,\
    \ 2000.\n130\nBIBLIOGRAPHY\n[SpliTech 2017] SpliTech.\nOpportunities, risks and\
    \ challenges of using social media to foster\nsmart governance for smart cities.\
    \ In 2017 2nd International Multidisciplinary Conference\non Computer and Energy\
    \ Science (SpliTech), pages 1–5, July 2017.\n[Steyskal 2015] Simon Steyskal and\
    \ Axel Polleres.\nTowards Formal Semantics for ODRL\nPolicies. In Nick Bassiliades,\
    \ Georg Gottlob, Fariba Sadri, Adrian Paschke and Dumitru\nRoman, editeurs, Rule\
    \ Technologies: Foundations, Tools, and Applications, pages 360–\n375, Cham, 2015.\
    \ Springer International Publishing.\n[Stojkoska 2017] Biljana L Risteska Stojkoska\
    \ and Kire V Trivodaliev.\nA review of Internet of\nThings for smart home: Challenges\
    \ and solutions. Journal of Cleaner Production, vol. 140,\npages 1454–1464, 2017.\n\
    [Stratis 2021] Kyle Stratis. What Is Data Engineering and Is It Right for You?,\
    \ May 2021.\n[Symeonaki 2019] Eleni G Symeonaki, Konstantinos G Arvanitis and\
    \ Dimitrios D Piromalis.\nCurrent trends and challenges in the deployment of IoT\
    \ technologies for climate smart\nfacility agriculture. International Journal\
    \ of Sustainable Agricultural Management and\nInformatics, vol. 5, no. 2-3, pages\
    \ 181–200, 2019.\n[Symeonaki 2020] Eleni Symeonaki, Konstantinos Arvanitis and\
    \ Dimitrios Piromalis. A context-\naware middleware cloud approach for integrating\
    \ precision farming facilities into the IoT\ntoward agriculture 4.0. Applied Sciences,\
    \ vol. 10, no. 3, page 813, 2020.\n[Torres 2017] Johnny Torres and Carmen Vaca.\
    \ e-Health and ﬁtness in Ecuador: A social media\nbased analysis. In eDemocracy\
    \ & eGovernment (ICEDEG), 2017 Fourth International\nConference on, pages 132–139.\
    \ IEEE, 2017.\n[Uckelmann 2011] Dieter Uckelmann, Mark Harrison and Florian Michahelles.\
    \ An architectural\napproach towards the future internet of things. In Architecting\
    \ the internet of things, pages\n1–24. Springer, 2011.\n[Vakali 2014] Athena Vakali,\
    \ Leonidas Anthopoulos and Srdjan Krco.\nSmart Cities Data\nStreams Integration:\n\
    experimenting with Internet of Things and social data ﬂows.\nIn Proceedings of\
    \ the 4th International Conference on Web Intelligence, Mining and\nSemantics\
    \ (WIMS14), page 60. ACM, 2014.\n[Vargas 2014] Washington Velásquez Vargas.\n\
    Bases de datos orientadas a grafos y su enfoque\nen el mundo real. -, 2014.\n\
    [Velásquez 2017] W. Velásquez, Andres Munoz-Arcentales and Joaquin Salvachúa.\n\
    Relation\nbetween BMI and Exit Time of a Building in an Emergency Situation: Earthquake.\n\
    Engineering Letters, vol. 25, no. 4, pages 366–381, 2017.\n131\nBIBLIOGRAPHY\n\
    [Verma 2016] Himanshu Verma, Madhu Jain, Khushhali Goel, Aditya Vikram and Gaurav\
    \ Verma.\nSmart home system based on Internet of Things. In 2016 3rd International\
    \ Conference on\nComputing for Sustainable Global Development (INDIACom), pages\
    \ 2073–2075. IEEE,\n2016.\n[Voigt 2017] Paul Voigt and Axel von dem Bussche. The\
    \ EU General Data Protection Regulation\n(GDPR). A Practical Guide. Springer Int.\
    \ Publ., 2017.\n[Wang 2010] Lizhe Wang, Gregor Von Laszewski, Andrew Younge, Xi\
    \ He, Marcel Kunze, Jie\nTao and Cheng Fu. Cloud computing: a perspective study.\
    \ New generation computing,\nvol. 28, no. 2, pages 137–146, 2010.\n[Wang 2020]\
    \ Jin Wang, Yaqiong Yang, Tian Wang, R Simon Sherratt and Jingyu Zhang.\nBig\n\
    data service architecture: a survey. Journal of Internet Technology, vol. 21,\
    \ no. 2, pages\n393–405, 2020.\n[Wu 2015] J Wu, M Dong, K Ota, M Tariq and L Guo.\
    \ Cross-Domain Fine-Grained Data Usage\nControl Service for Industrial Wireless\
    \ Sensor Networks.\nIEEE Access, vol. 3, pages\n2939–2949, 2015.\n[Xu 2019] Li\
    \ Da Xu and Lian Duan.\nBig data for cyber physical systems in industry 4.0: a\n\
    survey. Ent. Inf. Sys., vol. 13, no. 2, pages 148–169, 2019.\n[Yin 2015] Shen\
    \ Yin and Okyay Kaynak. Big data for modern industry: challenges and trends\n\
    [point of view]. Proc. IEEE, vol. 103, no. 2, pages 143–146, 2015.\n[Yuan 2005]\
    \ Eric Yuan and Jin Tong. Attributed based access control (ABAC) for web services.\n\
    In IEEE International Conference on Web Services (ICWS’05). IEEE, 2005.\n[Zhang\
    \ 2010] Qi Zhang, Lu Cheng and Raouf Boutaba. Cloud computing: state-of-the-art\
    \ and\nresearch challenges. Journal of internet services and applications, vol.\
    \ 1, no. 1, pages\n7–18, 2010.\n[Zhu 2019] Julie Yixuan Zhu, Bo Tang and Victor\
    \ OK Li. A ﬁve-layer architecture for big data\nprocessing and analytics. Int.\
    \ Jour. Big Data Int., vol. 6, no. 1, pages 38–49, 2019.\n[Zikopoulos 2011] Paul\
    \ Zikopoulos and Chris Eaton.\nUnderstanding big data: Analytics for\nenterprise\
    \ class hadoop and streaming data. McGraw-Hill Osborne Media, 2011.\n[Zyrianoff\
    \ 2020] Ivan Zyrianoff, Alexandre Heideker, Dener Silva, João Kleinschmidt, Juha-\n\
    Pekka Soininen, Tullio Salmon Cinotti and Carlos Kamienski.\nArchitecting and\n\
    Deploying IoT Smart Applications: A Performance–Oriented Approach. Sensors, vol.\
    \ 20,\nno. 1, 2020.\n132\n"
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: https://oa.upm.es/69244/1/JOSE_ANDRES_MUNOZ_ARCENTALES.pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: Contribution to the advancement of data engineering for smart spaces through
    data usage control and context-aware systems
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
